id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
763ddd143806b13ed87f22f13ad32e55ad058bc4	randomly right		Game strategies used in tools such as Deep Blue and AlphaGo might be the key to improving and automating software verification.	alphago;deep blue (chess computer);randomness;software verification	Gerard J. Holzmann	2017	IEEE Software	10.1109/MS.2017.3571567	software engineering;software construction;software verification and validation;computer science;software quality;game testing;software reliability testing;software verification	Embedded	-63.63037855747304	25.756104888300516	90251
1c31802321653b7ccaf9429bf4e2cd1356c46f20	4th icse workshop on component-based software engineering: component certification and system prediction	component technology;distributed software development;component based software engineering;component composition;software architecture;internet	This workshop brings together researchers from the areas of component trust and certification, component technology, and software architecture. The goal of this workshop is to ensure that work in the areas of certification of software components and architectural analysis for prediction of system quality attributes will be mutually aware, if not mutually reinforcing. The output of the workshop will be a defined set of community model problems that reflects this intersection of interests.	component-based software engineering;icse;list of system quality attributes;software architecture	Ivica Crnkovic;Heinz W. Schmidt;Judith A. Stafford;Kurt C. Wallnau	2001	ACM SIGSOFT Software Engineering Notes	10.1145/505532.505540	software architecture;personal software process;the internet;computer science;systems engineering;engineering;social software engineering;component-based software engineering;software development;software design description;software engineering;software construction;software walkthrough;programming language;resource-oriented architecture;software system;software peer review;mechanical engineering	SE	-63.1565761010273	24.52818934492276	90305
43480d0352a279c20a9302831130b93b53f51216	the choice of new software development methodologies for software development projects	top down;data processing;software development methodology;research and development;software development;projective structure;structural design;structure analysis	"""Data processing managers have a number of new """"structured"""" methodologies to assist them in EDP software projects: structured programming, structured design, HIPO, top-down development, structured analysis, structured walkthroughs, and chief programmer teams. Since many of these methodologies are still considered new and """"experimental"""", it is often difficult for the manager to determine which of the methodologies should be used on a software project.  This paper briefly reviews each of the new structured methodologies. It then makes suggestions about the use of the methodologies for new projects, concluding that the use of informal walkthroughs is probably the best way for the manager to introduce the methodologies into an organization that has no previous experience with them.  The point is also made that """"research-and-development"""" projects have different trade-offs than """"bread-and-butter"""" projects. For projects that have hard deadlines and budgets, a number of trade-offs are suggested in order to help the manager decide which of the structured methodologies should be employed."""	electronic data processing;hipo model;programmer;software development process;software project management;software walkthrough;structured analysis;structured programming;top-down and bottom-up design	Edward Yourdon	1977		10.1145/1499402.1499447	computer science;systems engineering;software engineering;management science	SE	-66.33510724909023	23.0091811067064	90565
ddd4e1501270fdc9d64fc9ff0495545fc46e46da	eureka! why analysts should invent requirements	systems analysis;customers analysts requirements service;costs airplanes europe roads history internet peer to peer computing auditory system waste materials forward contracts	0 7 4 0 7 4 5 9 / 0 2 / $ 1 7 . 0 0 © 2 0 0 2 I E E E T he traditional job of the requirements analyst is to talk to users, find out how they work, ask them what they want, specify what is required, and have a system built. But something’s missing: this activity doesn’t improve anything. We need a step in the requirements activity called “invent something better.” This column is about how to go about doing that.	emoticon;eureka (opac);requirement	James Robertson	2002	IEEE Software	10.1109/MS.2002.1020281	public relations;systems analysis;business requirements;computer science;engineering;marketing;software engineering;advertising;management	Vision	-71.43137424665811	27.91933159128344	90735
179b47308418f9ca14c22cf2693b44269980a18f	managing agile teams: an inquiring systems perspective	agile software development;project manager		agile software development	Nancy Bonner	2009			agile unified process;agile usability engineering;systems engineering;knowledge management;agile software development;process management;empirical process;lean software development	Robotics	-64.81480327341087	22.186889056538806	91612
0fc7479be45d1232a052914933fee86ceb84a44f	more success and failure factors in software reuse	reuse;machine learning;data mining decision trees project management data analysis machine learning failure analysis stress web sites association rules;software reusability;expert opinion;software organizations software reuse machine learning;software reuse	Numerous discrepancies exist between expert opinion and empirical data reported in Morisio et.al.’s recent TSE article. The differences related to what factors encouraged successful reuse in software organizations. This note describes how those differences were detected and comments on their methodological implications.	code reuse;comment (computer programming)	Tim Menzies;Justin S. Di Stefano	2003	IEEE Trans. Software Eng.	10.1109/TSE.2003.1199076	reusability;verification and validation;software project management;computer science;systems engineering;package development process;social software engineering;component-based software engineering;software development;software engineering;domain engineering;software construction;data mining;reuse;database;software walkthrough;software analytics;software deployment;software system;software peer review	SE	-65.87075312559807	30.738489401704168	91821
bdb72d8a2028d604c8a8855c37c154ddf39574c6	software maintenance outsourcing: issues and strategies	software maintenance;risk management;software project management;software industry;software component;cost effectiveness;product quality;competitive advantage	Abstract   Software maintenance outsourcing is becoming a popular alternative in software industry. Software companies are looking at outsourcing their maintenance and support activities as an area for competitive advantage. There are risks and benefits of introducing subcontractors in the framework of software outsourcing. Reliable maintenance is only possible if adequate measures are taken in advance during project’s development and maintenance planning phase and are documented in the maintenance contract. In this paper, we present and make a justification for a set of recommendations to make such maintenance reliable and cost-effective. We analyze the associated risks and propose some product quality metrics to be monitored during the maintenance phase.		Rana Ejaz Ahmed	2006	Computers & Electrical Engineering	10.1016/j.compeleceng.2006.01.023	reliability engineering;long-term support;verification and validation;cost-effectiveness analysis;software quality management;risk management;software project management;systems engineering;social software engineering;component-based software engineering;software development;computerized maintenance management system;software asset management;software as a service;software maintenance;software deployment;software quality control;competitive advantage;software quality analyst	AI	-62.87846812782434	27.175243788598348	91963
1a7f37b7d178927f558c311433d2ac26e14e3150	from scrum to scrumban: a case study of a process transition	kanban;method adoption;process improvement;process introduction;development process;testing;interviews;scrum;software development;industry;programming	Transitioning from one development method to another has become a common routine for many companies. Despite this, very few reports describe how the process transition has been carried out, and provide suggestions for how to define a process transition model. This paper reports on a process transition from Scrum to Scrumban in one software development company. The paper gives an account on the process transition process, changes done to the development process undergoing the transition and the improvements achieved. It rounds up with lessons learned.	co-ment;iterative method;kanban (development);scrumban;software development;software development process	Natalja Nikitina;Mira Kajko-Mattsson;Magnus Strale	2012	2012 International Conference on Software and System Process (ICSSP)		systems engineering;engineering;software engineering;process management;empirical process	SE	-68.02330651467926	21.872244224977504	92272
d1e3d28ea7267b3406658f4ad9740b34324a90b8	bad modelling teaching practices		There are numerous excellent textbooks that provide guidance on what and how to teach modelling, founded on sound principles (e.g., mathematics, domain analysis, object-orientation) and engineering practice. There is less guidance available on what and how not to teach modelling i.e., what principles to avoid conveying either directly or indirectly, and what engineering practices should be ignored (e.g., because they misrepresent the practices of modelling). We describe a number of bad modelling teaching practices that we have identified, as a result of substantial individual and team teaching experience to both industry	domain analysis;modeling language	Richard F. Paige;Fiona A. C. Polack;Dimitrios S. Kolovos;Louis M. Rose;Nicholas Drivalos Matragkas;James R. Williams	2014			management science;domain analysis	SE	-65.07170883132407	18.82846601668686	92441
22db014f5ece242555438dcbfde0e946161e8c05	a web services based solution for online loan management via smartphone	tools and applications;case studies;unified modeling language;web services;e finance	Small microfinance institutions (in underdeveloped countries), despite their determination to expand into rural areas, are limited by geographic isolation and high transaction costs. For this, a solution has been proposed to access some features of the enterprise application via Smartphone. This solution is based on a service-oriented architecture in which the main features are developed as web services. The invocation of the methods is performed from a Smartphone or a PC, while the execution will be on a server that returns an understandable result through WSDL (Web Service Description Language) generated by web services, where the transport is provided by SOAP (Simple Object Access Protocol).	smartphone;web service	Théophile K. Dagba;Ercias Lohounmè;Ange Nambila	2012		10.1007/978-3-642-28490-8_23	web service;web application security;unified modeling language;web development;web modeling;business process execution language;web mapping;web standards;computer science;web api;ws-policy;service-oriented architecture;web navigation;web page;data mining;ws-addressing;database;ws-i basic profile;web 2.0;world wide web;universal description discovery and integration	HCI	-76.6543823109632	30.869992675560823	92549
75c3cf9a7741a2a4dd3153e5433f97245f72e187	measuring knowledge sharing in open source software development teams	open source software development;knowledge sharing	The study provides an approach to measure the extent of knowledge sharing in Open Source Software (OSS) development in terms of two aspects: the quality of knowledge sharing which is indicated by the helpfulness of the messages, and the quantity of knowledge sharing which is indicated by the volume of the messages. The study developed a computer-aided content analysis program to assess the helpfulness of the messages based on a set of keywords and the length of the messages. The approach was applied to measure the extent of knowledge sharing of 150 OSS projects. The results further confirmed that the two measures (i.e., helpfulness of messages and volume of messages) assess different aspects of knowledge sharing. Another contribution of this research is the computer-aided content analysis program, which has been shown to be effective and reliable and can be applied in future research.	open sound system;open-source software;software development	Yuan Long;Keng Siau;Kris Howell	2007			personal software process;knowledge management;social software engineering;software development;database;distributed computing;software walkthrough;software analytics;world wide web;domain knowledge	SE	-75.01454773775	24.305681832250798	92564
16448df7a0c9a2689502fc0fa1eae23840fdb3e0	advanced test modelling and execution based on the international standardized techniques ttcn-3 and utp		In systems and service engineering testing is an important part to get confidence in quality and trust in security issues. Standardized testing techniques support the unique definition of abstract test models, configurations and behavior scenarios that can be executed automatically. This contribution presents the state of the art and future directions of two international standards for testing: the Testing and Test Control Notation (TTCN-3) from the European Telecommunication Standardization Institute (ETSI), and the UML testing profile (UTP) from the Open Management Group (OMG). Special emphasize is given to the translation from UTP to TTCN-3 test models, automated test execution using standard-compliant tool support and related examples from European projects.	ttcn-3;twisted pair	Axel Rennoch;Marc-Florian Wendland;Andreas Hoffmann;Martin A. Schneider	2014		10.1007/978-3-662-47401-3_32	reliability engineering;real-time computing;computer science;database	SE	-63.42113460114663	19.737660500970026	92616
b196b280a38a8ed90d0f36932e947b0afe2a3feb	an investigation into the continued use of unified modeling language (uml) in information systems development	uml;expectation	As the de facto standard for object-oriented modeling language, UML is expected to play an increasingly important role in information systems development. The long-term viability and eventual success of UML depend, to a great extent, on the continued use by UML users such as developers and analysts. Systematic investigations on UML’s continued use have been missing from contemporary discussions. Our study attempts to fill this gap in the literature. We developed a research model, which is primarily based on the Expectation Disconfirmation Theory (EDT). According to this model, UML users’ perceived discrepancy between pre-adoption expectation and post-adoption perceived performance, which is conceptualized as performance disconfirmation and effort disconfirmation, is the determinant of satisfaction. UML users’ post-adoption expectation, in terms of perceived usefulness and perceived ease of use, is the determinant of attitude. Both satisfaction and attitude are posited as determinants of users’intention to continue using UML.	information system;unified modeling language	Keng Siau;Xin Lu Tan	2005			knowledge management;modeling language;applications of uml;de facto standard;computer science;usability;uml tool;information system;unified modeling language	Robotics	-71.6526301015977	23.53348453211771	92913
f807ad28e3a1b9b5f7e189d6c6e0285c0b06795d	taming a tiger: software engineering in the era of big data & continuous development		"""In this workshop, we describe software engineering challenges created by the introduction of Big Data, Data Science, and Continuous Development into corporate and research environments. Bloomberg Business reports """"Data scientists are the new superheroes"""". The desire to get immediate answers to complex questions is driving software development in new directions. Basic principles like Database modeling, Object Oriented Design, and Quality Metrics are taking a back seat to demands for more answers in less time."""	big data;software engineering	Craig Statchuk;Nazim H. Madhavji;Andriy V. Miranskyy;Frank Dehne	2015			computer science;data science;software engineering;data mining;database;management science	SE	-66.24461347731578	23.67604964894383	93302
ece4559a2c0b15aa8fe57297482a22a961bc4ccf	secure scrum: development of secure software with scrum		Nowadays, the use of agile software development methods like Scrum is common in industry and academia. Considering the current attacking landscape, it is clear that developing secure software should be a main concern in all software development projects. In traditional software projects, security issues require detailed planning in an initial planning phase, typically resulting in a detailed security analysis (e.g., threat and risk analysis), a security architecture, and instructions for security implementation (e.g., specification of key sizes and cryptographic algorithms to use). Agile software development methods like Scrum are known for reducing the initial planning phases (e.g., sprint 0 in Scrum) and for focusing more on producing running code. Scrum is also known for allowing fast adaption of the emerging software to changes of customer wishes. For security, this means that it is likely that there are no detailed security architecture or security implementation instructions from the start of the project. It also means that a lot of design decisions will be made during the runtime of the project. Hence, to address security in Scrum, it is necessary to consider security issues throughout the whole software development process. Secure Scrum is a variation of the Scrum framework with special focus on the development of secure software throughout the whole software development process. It puts emphasis on implementation of security related issues without the need of changing the underlying Scrum process or influencing team dynamics. Secure Scrum allows even non-security experts to spot security issues, to implement security features, and to verify implementations. A field test of Secure Scrum shows that the security level of software developed using Secure Scrum is higher then the security level of software developed using standard Scrum.	agile software development;algorithm;application security;computer security;cryptography;key size;scrum (software development);software development process	Christoph Pohl;Hans-Joachim Hof	2015	CoRR		software security assurance;scrum;agile software development;empirical process;computer security	Security	-67.8050638686093	23.690616451445106	93338
53e3e75cf1c03e6fa817109bf7c83e69b753319a	architectural description languages (adls) vs uml: a review	architecture description language;unified modeling language uml;software engineering;software architecture;architecture description languages adls;unified modeling language	The field of software architecture which is considered as a subfield of software engineering is now about two decades old. During this period a number of software Architecture Description Languages (ADLs) emerged and vanished. But none of the ADLs became much popular amongst the practitioners except a few, that too only in a specific domain. On the other hand Unified Modeling Language (UML) which some times is not even accepted as an ADL or accepted with a some hesitation has become an industry de facto standard notation for documenting software architectures. This paper makes an attempt to find an answer to this question as to what went wrong with the ADLs that they did not become much popular beyond their place of origin. Is UML really an Architecture Description Language.	architecture description language;software architecture description;software documentation;software engineering;unified modeling language	R. K. Pandey	2010	ACM SIGSOFT Software Engineering Notes	10.1145/1764810.1764828	functional software architecture;unified modeling language;software architecture;model-driven architecture;architecture description language;database-centric architecture;uml tool;architecture analysis & design language;computer science;engineering;theoretical computer science;software design description;darwin;software engineering;applications of uml;software architecture description;programming language	SE	-65.44055148065782	24.52954545947451	93346
402beba941ea61c2068cc431572a9f1d19c20b22	free software developers as an occupational community: resolving conflicts and fostering collaboration	conflict;computer supported cooperative work;organizational culture;free open source software development;occupational community;virtual organization;free open source software;internet relay chat;cooperative work;free software	In this paper, we present results from the study of a free software development virtual organization, the GNU Enterprise (GNUe) project, and how they develop software in a globally distributed free software development project. In particular, examples of how they mitigate and resolve conflict are presented. Conflict arises over the use of a non-free tool to create GNUe graphic, and over the use of a non-free tool for GNUe documentation. The GNUe developers resolve the conflict using internet relay chat (IRC), threaded email discussions, and community digests. We characterize the GNUe developers as an occupational subculture within the occupational community of free/open source software (F/OSS) developers and show how the beliefs in free software and freedom of choice, and values in cooperative work and community assist GNUe contributors in mitigating and resolving conflict. In addition, we show how, despite fluctuating boundaries of membership in a virtual organization, daily discussions on the GNUe IRC serve to build and perpetuate the global community of GNUe contributors as well as F/OSS developers in general.	documentation;email;gnu;internet relay chat;open sound system;open-source software;software developer;software development;virtual organization (grid computing)	Margaret S. Elliott;Walt Scacchi	2003		10.1145/958160.958164	organizational culture;simulation;human–computer interaction;computer science;knowledge management;artificial intelligence;software development;operating system;computer-supported cooperative work;communication;management;world wide web	SE	-76.9891298833882	20.83799026765659	93503
de4385be80405bffc21fff3a4fb71bd5b483d038	which factors affect the evangelist's support during training sessions in mobile software ecosystems?		In Mobile Software Ecosystems (MSECO), keystone organizations provide mobile platforms and perform training sessions to educate and motivate developers to achieve goals, such as increasing the number of mobile apps as well as reusing and integrating information. Dedicated official staff known as evangelists performs official training sessions. However, there is little discussion about the factors that affect training sessions in MSECO. It can support evangelist in planning and performing effective training sessions. In this paper, we share results from two experimental studies to evaluate factors that may affect training sessions: (1) Case study: we identified seven impact factors in the context of a real MSECO; and (2) Survey: these factors were evaluated by 25 evangelists with respect to impact level. Those seven factors ordered by impact level are: Commitment of the partner institution; Infrastructure; Evangelist's approach; Focus on goals; Synergy; Subjectivity of the training planning; and Risk mitigation.	ecosystem;keystone effect;mobile app;mobile device;risk assessment;synergy	Awdren de Lima Fontão;Bernardo José da Silva Estácio;Juliana Fernandes;Rodrigo Magalhães dos Santos;Arilo Claudio Dias-Neto	2018		10.1145/3241403.3241427	risk management;systems engineering;knowledge management;computer science;subjectivity;software;corporate governance	HCI	-72.18763817503803	20.939436664260093	93534
18acc26055a103065d3701dde20b3f6d19d493c6	the impact of project management heuristics to is projects	heuristics project management is projects resource allocation project specifications;project management;formal specification;information systems;resource allocation;project manager;software management;formal specification project management information systems software management resource allocation;project management process planning personnel decision making information technology quality management cost function time factors environmental management thumb	Formal Project management is vital to the effective application of organizational resources to competing demands within and across projects. The use of project management, however, is predicated upon valid and accurate project specifications. The introduction of biases into the formulation of these specifications can lead to compromised or even failed projects. In many cases, biases arise from the application of heuristics by project personnel. Project personnel can in many cases offset the impact of biases by recognizing and understanding these heuristics and their potential effects. This study surveys project personnel to attempt to identify heuristics and their use in actual IS projects.	heuristic (computer science)	Russell L. Purvis;Gordon E. McCray;Tom L. Roberts	2003		10.1109/HICSS.2003.1174704	basis of estimate;project management;extreme project management;program management;work breakdown structure;earned value management;software project management;resource allocation;opm3;knowledge management;resource breakdown structure;resource management;estimation;formal specification;project risk management;management science;project management 2.0;project management triangle;management;project charter;schedule;information system;project planning;project portfolio management	SE	-71.78628340163156	26.640067984073358	93571
b4a3fdf7007e031de7d16be659da92b46584c1a2	successfully transitioning a research project to a commercial spin-out using an agile software process	release cycle;automated testing;agile;commercialisation;verification and validation;software process	The ultimate success of any research activity is to see it bear fruit in terms of real life use and commercial success. A key element in driving a good concept or idea through the various research and development stages and into full commercial use is the software process that supports it. In the early days of its evolvement the product will require less in terms of unit test coverage and automated test packages and more in the way of room to research and discover the innovation that will make the product unique and of high value. However, as the project progresses and a horizon appears with capital investors and large customer bases, the supporting software process needs to adapt fluidly to these evolving requirements. Efficient use of resources, shorter release cycles and better levels of quality coverage are a necessity to meet stakeholder demands for new features, better features and all to be delivered more quickly. This paper examines the successful transition of a research project to a fully fledged commercial entity with an emphasis on the software process and quality methodologies used.	agile software development;fault coverage;real life;requirement;software development process;test automation;unit testing	Phelim Dowling	2014	Journal of Software: Evolution and Process	10.1002/smr.1611	personal software process;verification and validation;verification and validation;simulation;software quality management;software project management;computer science;systems engineering;engineering;package development process;operations management;software development;software engineering;agile software development;software release life cycle;empirical process;management;software quality control;software development process	SE	-67.926449980629	24.067921236852527	93573
5a7811f9f07a45949b902e2abe2c6f91249e366e	the mcc formal methods transition study: technology transfer for complex information technology and processes	information technology;formal method;technology transfer		formal methods;microelectronics and computer technology corporation	Susan L. Gerhart	1993			information technology architecture;computer science;systems engineering;computer engineering	Logic	-63.16671578569366	25.385129563824606	93587
3e75211dddda38af81d0d28151569327e7d994ae	further comparison of cross-company and within-company effort estimation models for web applications	different company;web projects;replication study;cross-company model;within-company estimation model;cross-company cost model;within-company effort estimation models;regression-based estimation models;web project;company model;stepwise regression model;effort estimation;previous study;web applications;within-company model;single web company;within-company cost model;case-based reasoning.;cross- company estimation models;regression analysis;case base reasoning;case based reasoning;stepwise regression;internet;project management;software metrics	This paper extends a previous study, using data on 67 Web projects from the Tukutuku database, investigating to what extent a cross-company cost model can be successfully employed to estimate effort for projects that belong to a single company, where no projects from this company were used to build the cross-company model. Our within-company model employed data on 14 Web projects from a single Web company. Our results were similar to those from the previous study, showing that predictions based on the within-company model were significantly more accurate than those based on the cross-company model. We also found that predictions were very poor when the within-company cost model was used to estimate effort for 53 Web projects from different companies. We analysed the data using two techniques, forward stepwise regression and case-based reasoning. We found estimates produced using stepwise regression models were better for the within company model while case-based reasoning predictions were better for the cross-company model.	analysis of algorithms;case-based reasoning;cost estimation in software engineering;software quality assurance;stepwise regression	Emilia Mendes;Barbara A. Kitchenham	2004	10th International Symposium on Software Metrics, 2004. Proceedings.	10.1109/METRIC.2004.1357920	project management;reliability engineering;case-based reasoning;computer science;data science;stepwise regression;data mining;management;regression analysis	SE	-65.48299658203642	30.82797015567887	93592
d18b67b35de956cb6cec13384d730d39c676e4a1	"""is there anything """"time-honored"""" in the field of software?"""	software life cycle	Step right up, ladies and gentlemen, and take a gander at the latest in software life cycles! We're displaying here the brand-new 1997 model, folks. It's lower and longer and - what's even more important - it guarantees you that your next software project will come in under budget, on schedule, and with more quality than you had ever hoped for!	software project management;software release life cycle	Robert L. Glass	1996	DATA BASE	10.1145/264417.264424	simulation;computer science;engineering;operations management;management;software development process	SE	-68.44525135161605	25.490397123461427	93681
bccded50c29cb99b77f3dd1f3d0b1f899fc4eaaf	developing a bayesian network model based on a state and transition model for software defect detection	software;belief networks;software testing;bayesian network;project management;probability;bayesian methods;testing;bayesian diagnosis;computational modeling;a state and transition model;program testing;evidence or observations bayesian network a state and transition model software defect detection software testing bayesian diagnosis genie;software development lifecycle bayesian network model state and transition model software defect detection software diagnosis software testing bn model defective software module software quality decision tool defect priority level software development project bn tool cause effect relationship probability software expert stm software reliability;genie;evidence or observations;predictive models;software defect detection;adaptation models;software reliability;software reliability belief networks probability program testing project management software development management software quality;software quality;software development management;software testing bayesian methods computational modeling product development predictive models adaptation models;product development	This paper describes a Bayesian Network model-to diagnose the causes-effect of software defect detection in the process of software testing. The aim is to use the BN model to identify defective software modules for efficient software test in order to improve the quality of a software system. It can also be used as a decision tool to assist software developers to determine defect priority levels for each phase of a software development project. The BN tool can provide a cause-effect relationship between the software defects found in each phase and other factors affecting software defect detection in software testing. First, we build a State and Transition Model that is used to provide a simple framework for integrating knowledge about software defect detection and various factors. Second, we convert the State and Transition Model into a Bayesian Network model. Third, the probabilities for the BN model are determined through the knowledge of software experts and previous software development projects or phases. Last, we observe the interactions among the variables and allow for prediction of effects of external manipulation. We believe that both STM and BN models can be used as very practical tools for predicting software defects and reliability in varying software development lifecycles.	agile software development;bayesian network;interaction;network model;software bug;software developer;software system;software testing;software transactional memory	Nipat Jongsawat;Wichian Premchaiswadi	2012	2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing	10.1109/SNPD.2012.41	project management;verification and validation;software sizing;computer science;software reliability testing;software framework;software development;software engineering;machine learning;software construction;data mining;software testing;goal-driven software development process;software quality;software metric	SE	-63.1159042254884	31.75980802543778	93741
2d9575e08c158f6d16afbdd3e833e5dfd481f7b6	an empirical evaluation of capture-recapture estimators in software inspection	software;biological system modeling;testing;inspection;software engineering;virtual groups;estimation;capture recapture estimators software quality post statistic testing software requirement specification software inspection;inspection capture recapture estimation;inspection software biological system modeling virtual groups estimation software engineering testing;statistical testing formal specification software quality	Context: Capture-recapture approach has been adopted in software inspection for decades for estimating remaining defects and supporting post-inspection decisions. A number of capture-recapture models and estimators have been borrowed from other disciplines (e.g., Biology and social sciences) and applied in software inspections. These models and estimators were created with different assumptions and the violation to these assumptions may lead to invalid application. Most of the reported empirical evaluations of the capture-recapture models and estimators used relatively small data sets (i.e., Small number of inspectors and/or defects), which leads varying conclusions. Objective: The research reported in this paper aims to better understand this approach for software inspection, and the efficacy of the models and estimators in particular, with large data sets. Method: We carried out an empirical study that evaluated several typical capture-recapture estimators (i.e., M0-ML, Mt-ML, Mt-CH, Mh-CH and Mh-JK). The study employed 57 student inspectors in reviewing software requirement specification and formed 1000 virtual teams at each team size in the post statistic testing. Results: The data analysis indicates that: 1) M0-ML and Mt-ML could not generate accurate estimates even with many inspectors. 2) All estimators suffer high level of failure rate with few inspectors. 3) For a small team, estimator Mh-CH performs the best, while with many inspectors, Mt-CH and Mh-JK perform better regarding the accuracy and the failure rate. Conclusion: Our work reveals that no estimator was superior to others under all situations. With an increased team size, estimates generated by estimator Mt-CH and Mh-JK turn to be more accurate than others. While, M0-ML and Mt-ML are able to offer reference value to support post-inspection because of their convergent underestimates.	data dredging;failure rate;flip-flop (electronics);high-level programming language;mark and recapture;monte carlo method;motion capture;requirement;sampling (signal processing);self-replication;software bug;software engineering;software inspection;the times	Qi Shan;Guoping Rong;He Zhang;Gaoxuan Liu;Dong Shao	2015	2015 24th Australasian Software Engineering Conference	10.1109/ASWEC.2015.17	reliability engineering;regression testing;software sizing;engineering;software reliability testing;data mining;software testing;software metric;statistics;software quality analyst	SE	-63.801671258807005	31.888393964871085	93785
eda30509d50844c3c7ec544a56aea1d33b57b2cf	requirement changes and project success: the moderating effects of agile approaches in system engineering projects	agile methods;system engineering;empirical study;integrable system;performance of systems;software engineering;agile development	This paper reports the findings of an empirical study on the influence agile development methods exert on the success of projects. The goal is to determine whether agile methods are able to mitigate negative effects requirement changes have on the performance of Systems Engineering projects, i.e. projects where systems consisting of hard- and software are developed. Agile methods have been proven to successfully support development projects in the field of traditional software engineering, but with an ever expending market of integrated systems manufacturers their usability for those complex projects has yet to be examined. This study focuses on 16 specific agile practices and their ability to improve the success of complex hard- and software projects.	agile software development;systems engineering	Sabine Maierhofer;Ernst Stelzmann;Markus Kohlbacher;Björn Fellner	2010		10.1007/978-3-642-15666-3_6	reliability engineering;requirements analysis;agile unified process;extreme programming practices;agile usability engineering;systems engineering;engineering;requirement;software engineering;agile software development;empirical process;lean software development	SE	-69.56640254590558	22.723891581703164	93841
49a4e860c11ea0b1db34d5dfad52055687e7869e	cohesion, structure and software complexity: a model of open source software development	group cohesion;software development;organizational structure;open source	As the use of open source software gains popularity, it is important to understand the factors that contribute to the success of open source software development projects. This research contributes to this understanding by developing a set of propositions about the organizational structure that supports open source software projects. We argue that in open source software development it is important to understand the existence and interaction of two related but distinct entities; the interest community and the software development group. We propose relationships between the development group, the interest community and software complexity in open source software development. Implications of the propositions for research and practice are discussed.	cohesion (computer science);conceptualization (information science);entity;open sound system;open-source software;programming complexity;software development process	Sherae L. Daniel;Katherine J. Stewart	2005			systems engineering;knowledge management;social software engineering;software development;software engineering	SE	-75.05387412542186	21.789861868965904	93953
b12d09a9f96153cec45011790347e1fabf1a4e89	building blocks for continuous experimentation	agile software development;lean software development;lean startup;continuous experimentation;architecture;product development	Development of software-intensive products and services increasingly occurs by continuously deploying product or service increments, such as new features and enhancements, to customers. Product and service developers need to continuously find out what customers want by direct customer feedback and observation of usage behaviour, rather than indirectly through up-front business analyses. This paper examines the preconditions for setting up an experimentation system for continuous customer experiments. It describes the building blocks required for such a system. An initial model for continuous experimentation is analytically derived from prior work. The model is then matched against empirical case study findings from a startup company and adjusted. Building blocks for a continuous experimentation system and infrastructure are presented. A suitable experimentation system requires at least the ability to release minimum viable products or features with suitable instrumentation, design and manage experiment plans, link experiment results with a product roadmap, and manage a flexible business strategy. The main challenges are proper and rapid design of experiments, advanced instrumentation of software to collect, analyse, and store relevant data, and the integration of experiment results in both the product development cycle and the software development process.	design of experiments;experiment;new product development;precondition;software development process;strategic management	Fabian Fagerholm;Alejandro Sánchez Guinea;Hanna Mäenpää;Jürgen Münch	2014		10.1145/2593812.2593816	simulation;systems engineering;engineering;architecture;operating system;software engineering;agile software development;lean software development;new product development	SE	-67.81000626316361	19.586317214240477	94420
380d9c3d4d4c757535d24b3f31b4a55ccc1af2da	usability work in agile systems development practice : a systematic review		In this paper we present the results of a systematic literature review of the recommendations in the existing research literature on usability work in agile systems development. The review contributes by summarizing the literature in light of seven claims about how to integrate usability work into an agile development project. By analyzing the claims we show how the previous literature provides grounds, warrants, backing, rebuttal, and qualification with regard to each of them. From this comprehensive overview of the literature we then discuss a research agenda with a particular focus on how situational factors for the claims must be researched and how this must encompass identified rebuttals and qualifications.		Adeola Yetunde Wale-Kolade;Peter Axel Nielsen;Tero Päivärinta	2012		10.1007/978-1-4614-7540-8_44	usability;agile unified process;agile usability engineering;systems engineering;engineering;knowledge management;software engineering;usability engineering	HCI	-65.90771811037018	18.275476186861038	94936
aa495087c2de7808e23c3de717a58170371cd8c8	software engineering in a first degree	software engineering	software engineering	software engineering	Russel Winder;Charles Easteal;Robert Cole	1987	Software Engineering Journal	10.1049/sej.1987.0017	personal software process;software sizing;software verification;social software engineering;component-based software engineering;software development;software construction;computer-aided engineering;software measurement;software requirements	SE	-63.27474417561201	26.009597242708853	95003
3a52f882ecc30867fd6010eafed5f67b121281eb	personal recommendations in requirements engineering: the openreq approach		[Context u0026 motivation] Requirements Engineering (RE) is considered as one of the most critical phases in software development but still many challenges remain open. [Problem] Recommender systems have been applied to solve open RE challenges like requirements and stakeholder discovery; however, the existent proposals focus on specific RE tasks and do not give a general coverage for the RE process. [Principal ideas/results] In this research preview, we present the OpenReq approach to the development of intelligent recommendation and decision technologies that support different phases of RE in software projects. For doing so, the OpenReq approach will be formed by different parts that will be integrated in a process. Specifically, we present in this paper the OpenReq part for personal recommendations for stakeholders, which takes place during requirements elicitation, specification and analysis stages. [Contribution] OpenReq aims to improve and speed up RE processes, especially in large and distributed systems, by incorporating intelligent recommendation and decision technologies.	recommender system;requirement;requirements engineering	Cristina Palomares;Xavier Franch;Davide Fucci	2018		10.1007/978-3-319-77243-1_19	management science;recommender system;systems engineering;requirements elicitation;requirements engineering;software development;software;speedup;computer science;stakeholder	SE	-62.931504513318984	19.56899772747356	95313
6d603bcfaa8695e3cdcb653372a24366aff5fee6	software product and process quality improvement using formal methods		viii	formal methods	Satish Mishra	2015			reliability engineering;verification and validation;software engineering process group;systems engineering;software development;software construction;process management;empirical process;software quality control;goal-driven software development process;software quality;software quality analyst	NLP	-62.876848703649266	26.239810202277308	95580
fea75b434f56ae0b92650c6e87619a6b9118d85c	human perception of software complexity: knowledge discovery from software data	software metrics;software measurement;software maintenance;software complexity;knowledge based systems software metrics software maintenance data mining data models;data mining;data model;complex data;humans software measurement software maintenance software metrics software performance software tools programming profession java anthropometry data processing;data model analysis human perception software complexity knowledge discovery software maintenance activities software measures human seen complexity data processing;human perception;knowledge based systems;data models	"""Complexity of software is an important aspect of development and maintenance activities. A lot of research is dedicated to defining different software measures that capture what software complexity is. In most cases description of complexity is given to humans in forms of numbers. These quantitative measures reflect human-seen complexity with different levels of success. The paper proposes a process of """"translating"""" human-seen complexity into numbers. The process starts with an experiment that involves human beings and provides data with embedded knowledge about human perception of complexity. Data processing and analysis of data models built based on the data lead to discovery of simple rules, which represent human perception of software complexity."""	code coverage;data model;data point;decision tree;embedded system;experiment;programming complexity;software engineering	Marek Reformat;Petr Musílek;Vanda Wu;Nicolino J. Pizzi	2004	16th IEEE International Conference on Tools with Artificial Intelligence	10.1109/ICTAI.2004.69	data modeling;software visualization;personal software process;medical software;long-term support;verification and validation;software sizing;software mining;data model;computer science;package development process;backporting;social software engineering;software development;software design description;knowledge-based systems;software construction;data mining;software walkthrough;software analytics;software maintenance;software measurement;perception;software deployment;programming complexity;software metric;software system;complex data type;software peer review	Robotics	-66.17638587623988	30.431263116953037	95720
5cef013f047b50e1e7ed855be88ec37a17cd1482	quick goms: a visual software engineering tool for simple rapid time-motion modeling	software engineering tools	D computer tools with well-designed human computer interactions (HCI) can be difficult, tedious, time-consuming, and expensive. Small improvements in one portion of the design often create disasters in another portion. And staffing necessities often imply that interfaces are designed by expert software engineers who understand neither the users nor their tasks and goals. DAVID V. BEARD SCOTT ENTRIKIN PAT CONROY NATHAN C. WINGERT COREY D. SCHOU DANA K. SMITH KEVIN M. DENELSBECK	goms;human computer;human–computer interaction;software engineer	David V. Beard;Scott Entrikin;Pat Conroy;Nathan C. Wingert;Corey D. Schou;Dana K. Smith;Kevin M. Denelsbeck	1997	Interactions	10.1145/255392.255398	verification and validation;computer science;systems engineering;software development;software construction;computer-aided engineering;computer-aided software engineering;computer engineering	HCI	-69.07753828695049	27.604659745578232	95789
1e7af2377568cb390c17433fd83a7a8d838edd5e	validating the iso/iec 15504 measure of software requirements analysis process capability	software metrics;international standard;measurement scale;iso standards iec standards software measurement software quality capability maturity model software standards software engineering productivity military standards design engineering;predictive validity;formal specification;standards;software process improvement;design engineering;software measurement;process capability;requirements analysis practices;iso standards;software process assessment;program verification;software engineering;software requirements;small organizations;budget commitments;iso iec 15504 measure validation;iec standards;validity;sra process capability measure;staff productivity;project performance;requirements engineering process;capability maturity model;software projects;military standards;performance measures;small organizations iso iec 15504 measure validation software requirements analysis process capability international standard software process assessment software engineering processes measurement scale process capability project performance predictive validity sra process capability performance measures budget commitments staff productivity sra process capability measure it staff requirements analysis practices software projects;software requirements analysis process capability;software standards;productivity;it staff;sra process capability;human resource management iso standards iec standards software standards software metrics formal specification software process improvement software development management program verification;software engineering processes;empirical evaluation;human resource management;software quality;software development management;requirements analysis process	ISO/IEC 15504 is an emerging international standard on software process assessment. It defines a number of software engineering processes, and a scale for measuring their capability. One of the defined processes is software requirements analysis (SRA). A basic premise of the measurement scale is that higher process capability is associated with better project performance (i.e., predictive validity). This paper describes an empirical study that evaluates the predictive validity of SRA process capability. Assessments using ISO/IEC 15504 were conducted on 56 projects world wide over a period of two years. Performance measures on each project were also collected using questionnaires, such as the ability to meet budget commitments and staff productivity. The results provide strong evidence of predictive validity for the SRA process capability measure used in ISO/IEC 15504, but only for organisations with more than 50 IT Staff. Specifically, a strong relationship was found between the implementation of requirements analysis practices as defined in ISO/IEC 15504 and the productivity of software projects. For smaller organisations evidence of predictive validity was rather weak. This can be interpreted in a number of different ways: that the measure of capability is not suitable for small organisations, or that the SRA process capability has less affect on project performance for small organisations.	computer performance;iso/iec 15504;requirement;requirements analysis;sequence read archive;software development process;software engineering;software requirements	Khaled El Emam;Andreas Birk	2000	IEEE Trans. Software Eng.	10.1109/32.852742	iso/iec 9126;reliability engineering;requirements analysis;productivity;predictive validity;process capability;iso/iec 12207;process capability index;computer science;systems engineering;engineering;software engineering;human resource management;formal specification;software measurement;capability maturity model;software requirements;software quality;validity;software metric	SE	-65.79147249869781	28.751029725248085	95864
d051cf7dfae922fd58e4db045435caded563c315	suitability of requirements prioritization methods for market-driven software product development	market driven requirements engineering;software process improvement;requirements engineering;requirements prioritization;product development	ion with each other. The pool of requirements is rarely so strictly defined and clear. In practice, the requirements management systems in the software companies are overloaded by requirements from different markets and local offices. The ability of requirements prioritization methods to scale in these situations seems to be quite low. Furthermore, the practitioners usually have experience-based outlook about the most important requirements that should be implemented first. However, they seem to instead be longing for help in validating their draft decisions. They would want to make sure that they are making their prioritization decisions rationally enough and based on the right aspects affecting the importance of the	microsoft outlook for mac;new product development;requirement;requirements management;software industry	Laura Lehtola;Marjo Kauppinen	2006	Software Process: Improvement and Practice	10.1002/spip.249	reliability engineering;requirements analysis;software requirements specification;requirements management;requirement prioritization;economics;systems engineering;engineering;requirement;software engineering;management science;requirements engineering;management;new product development	SE	-69.03317302202186	22.51319836094374	95883
3c47ac13e7b7e696101c35b59fea4105b0c3c12c	migrating the enterprise [software migration]	software engineering;sun computer architecture business middleware programming software maintenance;business data processing;business data processing software engineering;management architecture software migration operating environment it infrastructure e stack business architecture	"""The word """"migration"""" means many things to different people. Typically, it is used to refer to the act of moving a body of software from an existing compute platform, operating environment and IT infrastructure to a different platform, environment and infrastructure. In this paper, we introduce the concept of the e-stack, which we use to represent and capture the business, execution and management architectures. We follow this with an examination of four possible migration solutions and introduce a set of metrics that can be used to choose the correct solution. We conclude the paper with a discussion of tools that we have developed in-house that can used to implement one of the solutions. Where possible, real world examples are used."""	enterprise software;operating environment;software modernization	Brian Down	2004	20th IEEE International Conference on Software Maintenance, 2004. Proceedings.	10.1109/ICSM.2004.1357848	functional software architecture;business rule management system;reference architecture;real-time computing;enterprise software;computer science;systems engineering;engineering;social software engineering;operations architecture;software framework;component-based software engineering;software development;software engineering;middleware;software construction;software asset management;software as a service;software architecture description;programming language;business software;resource-oriented architecture;business process modeling;software quality;software system;business architecture	SE	-66.12287058006449	22.871009352204265	96228
0f4ddcf871ee67f3ac622aca6469489c635cdb0a	software maintenance and operations hybrid model: an it services industry architecture simulation model approach	software;it services industry;unified modeling language maintenance engineering business computer architecture software programming industries;softgoal interdependency graph;run time monitoring;architecture simulation model hybrid;software maintenance;architecture simulation model;service level agreements;simulation;industries;maintenance engineering;business function workflow discrete event simulation;transaction processing and performance council;modeling language;infrastructure operations;hybrid model;non functional requirement;software maintenance simulation;non functional requirements;software development artifacts;uniform modeling language;software operations artifacts;customer order system;computer architecture;nfr framework;large scale;hybrid approach;service industry;performance benchmark;business;software development;unified modeling language;service level agreement;transaction processing;annotated simulation model;programming;simulation model;uniform modeling language architecture simulation model business function workflow discrete event simulation infrastructure operations it services industry nfr framework non functional requirements performance benchmark run time monitoring service level agreement softgoal interdependency graph software maintenance transaction processing and performance council;high light;customer order system software maintenance hybrid model it services industry annotated simulation model service level agreements architecture simulation model hybrid software development artifacts software operations artifacts;discrete event simulation	Since its beginnings in the late 1960s, the IT services industry has signed long-term (10 to 20 year) contracts to maintain software and operate a system for a fixed decreasing price. The motivation for this paper stems from forty years of watching software maintenance artifacts and operations artifacts continue to diverge down two separate paths filled with duplication and unused information. Occasionally, a well-annotated simulation model has been used effectively to bring these two artifact-paths together and efficiently maintain the software and operate the system within contracted performance goals, called service level agreements. This paper proposes an architecture simulation model hybrid, built from existing software development artifacts and operations artifacts, which can endure for the operational life of a system (an average of eighteen years). In order to show the relevance of the hybrid approach, the complete development and maintenance lifecycle of a large-scale customer order system case is studied. The services industry case high-lights the gaps contained in current simulation models and presents modeling extensions to fill the breaches.	relevance;service-level agreement;simulation;software development;software maintenance	Tom Hill	2011	2011 FIFTH INTERNATIONAL CONFERENCE ON RESEARCH CHALLENGES IN INFORMATION SCIENCE	10.1109/RCIS.2011.6006833	maintenance engineering;simulation;computer science;systems engineering;engineering;artificial intelligence;operating system;software engineering;data mining;database;programming language;management;world wide web;goal-driven software development process;non-functional requirement	SE	-68.225787020715	26.656535746080593	96360
a009f13fa56699c3079f5b1bfc8b65bdc5cc02c9	an embedded multiple-case study on oss design quality assessment across domains	measurement;software quality program compilers public domain software;software engineering;design quality;application domain design quality open source;public domain software;application domain;measurement software engineering open source software games context couplings;games;quality metrics embedded multiplecase study oss design quality assessment open source software code reuser fitting research method;couplings;program compilers;context;software quality;open source software;open source	"""Context: Investing on Open Source Software (OSS) as a """"code reuser"""", involves certain risks, such as the difficulty in understanding the level of OSS design quality Aim: We investigate the levels of design quality of OSS projects, across different application domains. Method: We conducted a case study, which is the most fitting research method for observing a phenomenon in its real context, which is active for a long period of time, and for which variables cannot be controlled. Results: We present the values for seven design quality metrics of 546 OSS projects, as well as the statistically significant differences across application domains. Conclusions: The results of the study suggest that OSS application domains correlate with several design quality characteristics, in the sense that projects within one application domain appear to have similar levels of design quality. In addition to that, the results reveal application domains with high and low levels of design quality."""	application domain;embedded system;open sound system;open-source software	Apostolos Ampatzoglou;Antonios Gkortzis;Sofia Charalampidou;Paris Avgeriou	2013	2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement	10.1109/ESEM.2013.48	reliability engineering;games;application domain;computer science;systems engineering;engineering;software engineering;coupling;public domain software;software quality;measurement	SE	-65.92542831683727	30.10387920588099	96364
aab231ebdb2fa8ce6e0897dd3533d823264bdfd9	walking the talk: building quality into the software quality management tool	team software process;software quality management;software process improvement;software project management;quality product building software quality management tool software product market software project management commercial enterprise software project data presentation software product defect removal;software quality software development management software process improvement;legged locomotion software quality quality management project management software tools costs testing job shop scheduling productivity samarium;quality index;software quality;software development management;quality management	The market for products whose objective is to improve software project management and software quality management is expected to be large and growing. In this paper, we present data from a software project whose mission is to build a commercial enterprise software project and quality management tool. The data we present include: planned and actual schedule, earned value, size, productivity, and defect removal by phase. We present process quality index and percent defect free modules as useful measures to predict post development defects in the product. We conclude that vendors of software project and quality management tools must walk the talk by utilizing disciplined techniques for managing the project and building quality into their products with known quality methods. The Team Software Process is a proven framework for both software project management and software quality management.	enterprise software;software bug;software development process;software project management;software quality management;team software process	Girish Seshagiri;S. Priya	2003	Third International Conference on Quality Software, 2003. Proceedings.	10.1109/QSIC.2003.1319087	reliability engineering;personal software process;long-term support;quality management;verification and validation;team software process;software quality management;software sizing;software project management;systems engineering;engineering;package development process;social software engineering;software development;software engineering;software construction;software as a service;software walkthrough;application lifecycle management;software deployment;software quality control;software quality;software quality analyst;software peer review	SE	-66.00353179668852	28.0798130789412	96752
85a7895d1cf4ac59b7c3495a6ff63d460ff97635	using spi to achieve delivery objectives in e-commerce software development	testing;project management;methodology;e commerce;software development;action research	Software process improvement (SPI) initiatives in large commercial banking organisations are often constrained by the control mechanisms implemented by the organisation to protect it from financial loss. As such, any changes to the software development process must maintain the required level of independent quality control. However, commercial pressure from customers and competition dictate that high-quality software systems are delivered within shorter timeframes. In order to meet these increasing demands, whilst maintaining the desired level of quality, one option is for organisations to make more effective use of the quality assurance (QA) team during the software development process. This article reports on current research which is examining the impact on software delivery of involving testers earlier in the development life cycle. Copyright  2008 John Wiley & Sons, Ltd.	bachelor of computer science;control system;e-commerce;john d. wiley;lero (software engineering);reduced cost;software deployment;software development process;software engineering;software metric;software quality assurance;software system;while	Fergal Downey;Gerry Coleman	2008	Software Process: Improvement and Practice	10.1002/spip.394	software security assurance;project management;personal software process;long-term support;verification and validation;team software process;software quality management;software engineering process group;economics;software project management;systems engineering;engineering;package development process;operations management;software development;software engineering;action research;methodology;software testing;management;software deployment;software quality control;software development process;software metric;software quality analyst;software peer review	SE	-69.83838852072047	20.762478814699282	96972
8a85ec0a43e19820f5cd657fc372cfd4f811ad20	a minimal test practice framework for emerging software organizations	software testing;resistance to change;test;small organizations;software development;datavetenskap datalogi;practice framework;process improvement;test practice framework	Testing takes a large share of software development efforts, and is hence of interest when seeking improvements. Several test process improvement frameworks exist, but they are extensive and much too large for smaller organisations to be effective. This paper presents a minimal test practice framework (MTPF) that allows the incremental introduction of appropriate practices at the appropriate time in rapidly expanding organisations. The process for introducing the practice framework tries to minimise resistance to change by maximising the involvement of the entire organisation in the improvement effort and ensuring that changes are made in small steps with a low threshold for each step. The created practice framework and introduction method are evaluated at one company by applying the framework for a one-year period. 12 local software development companies also evaluate the produced framework in a survey.	software development	Daniel Karlström;Per Runeson;Sara Nordén	2005	Softw. Test., Verif. Reliab.	10.1002/stvr.317	systems engineering;engineering;knowledge management;software engineering;management science;software testing	SE	-69.23507744044213	21.789105042781916	97529
dac27eecad8910283488a5765c889e854bcb844b	human-maschine interaction: socio-psychological support regarding software engineering effectiveness.	software engineering		maschine;software engineering	I. D. Katerelos	2001			personal software process;verification and validation;software engineering process group;software verification;computer science;social software engineering;software development;software engineering;software construction;computer-aided engineering;software walkthrough;software deployment;software requirements;software system;software peer review	SE	-63.477436902684595	25.31908848725518	97615
34f0f41aec3a1b7de6446bee020dad8a7d993964	a philosophy to system measurement	measurement tool;point of view	Although a great deal of emphasis has been placed on system measurement during the past few years, each of us has his own opinion and ideas as to what it means. From a practical and immediate point of view, System Measurement is the process of obtaining useful information on the performance of software and software-controlled computer hardware. From the same viewpoint, System Measurement is the key to system efficiency. The measurement tools currently available commercially are normally artificially classed as either hardware or software, based on whether they are constructed with electronics or software elements. This particular distinction is rather meaningless to the user since what is being measured and how useful the measurements are, is of far more importance.	computer hardware	Henry O. Cureton	1972		10.1145/1480083.1480125	simulation;systems engineering;engineering	Metrics	-69.63931340440924	31.768526250011902	97876
8e1f59c32aed65f938c6b035ee63e6cc47c2e36c	agile data warehouse -- the final frontier: how a data warehouse redevelopment is being done in an agile and pragmatic way	databases;agile;software;project management;standards;software prototyping;data model agile data warehouse business intelligence operational data store;software prototyping competitive intelligence data warehouses project management;data model;operational data store;business;competitive intelligence;business intelligence;data models databases data warehouses adaptation models software standards business;data warehouses;data warehouse;adaptation models;data models;health benefits provider agile data warehouse final frontier data warehouse redevelopment project software development projects business intelligence projects agile practices	Although much progress has been made to plan and execute Software Development projects in an agile manner, Data Warehouse or Business Intelligence projects seem to still execute in a more traditional manner. Data Warehouse projects are quite different than Software Development projects and need a set of Agile practices that are distinctly their own. This paper is an account of Data Warehouse redevelopment project at a major Health Benefits provider and a walkthrough of the Agile Data Warehouse practices that were used; both successfully and unsuccessfully. The intent is to share the practices developed and used on the project so they can be evaluated and used by other projects.	agile software development;software walkthrough	Terry S. Bunio	2012	2012 Agile Conference	10.1109/Agile.2012.21	agile unified process;agile usability engineering;systems engineering;data mining;database;business	SE	-68.03114277290346	20.27970576286597	98023
7e15903675c6f8ac0aa1c8b33b7818c9b363e2b2	hitting the target: practices for moving toward innovation experiment systems	feedback loops;agile development;software development;continuous deployment;innovation experiment systems	The benefits and barriers that software development companies face when moving beyond agile development practices are identified in a multiplecase study in five Finnish companies. The practices that companies need to adopt when moving towards innovation experiment systems are recognised. The background of the study is the Stairway to Heaven (StH) model that describes the path that many software development companies take when advancing their development practices. The development practices in each case are investigated and analysed in relation to the StH model. At first the results of the analysis strengthened the validity of the StH model as a path taken by software development companies to advance their development practices. Based on the findings, the StH model was extended with a set of additional practices and their adoption levels for each step of the model. The extended model was validated in five case companies.	agile software development;mathematical model	Teemu Karvonen;Lucy Ellen Lwakatare;Tanja Sauvola;Jan Bosch;Helena Holmström Olsson;Pasi Kuvaja;Markku Oivo	2015		10.1007/978-3-319-19593-3_10	simulation;extreme programming practices;systems engineering;engineering;marketing;operations management;software development;software engineering;agile software development;feedback;management;best coding practices	SE	-68.20082373115517	21.739685353491545	98099
1e2bfc372622aeb30524d60291d1d25db6af2eed	risk themes discovered through architecture evaluations	quality assurance;corporations;predictions;failure;risk analysis;availability;department of defense;missions;computer program documentation;systems management;software engineering;integration;requirements;software architecture evaluations;performance engineering;software architecture;test and evaluation;information assurance;management planning and control;architecture evaluation;data processing security;system development;trade off analysis;business computer architecture software architecture risk analysis application software software engineering pattern analysis us government information systems embedded system;system development risk themes software architecture evaluations;risk themes	"""The output of 18 software architecture evaluations are analyzed to find patterns in the risk themes identified in the evaluations. The major results are: i) A categorization of risk themes ii) The observation that twice as many risk themes are risks of """"omission """" as are risks of """"commission """". iii) A failure to find a relationship between the business and mission goals of a system and the risk themes from an evaluation of that system. iv) A failure to find a relationship between the domain of a system being evaluated and the risk themes associated with the development of that system. The results of this investigation have application to practitioners by suggesting activities on which developers should put greater focus. They also have application to researchers by suggesting further areas of investigation."""	architecture tradeoff analysis method;categorization;software architecture	Leonard J. Bass;Robert L. Nord;William Wood;David Zubrow	2007	2007 Working IEEE/IFIP Conference on Software Architecture (WICSA'07)	10.1109/WICSA.2007.37	reliability engineering;quality assurance;software architecture;availability;requirements analysis;systems management;risk analysis;prediction;performance engineering;systems engineering;engineering;software engineering	SE	-65.01404490462136	28.846622187260337	98325
9644e3f0d9912c37c3b97d675099f76fbc8dc025	new practices to structure and elicit improvement opportunities in scientific software development teams	software;software programming sorting software engineering interviews scientific computing modeling;scientist;software process improvement;sorting;multi voting;card sorting;software engineering;team working;kelly grid;scientific software kelly grid card sorting multi voting survey scientist;scientific computing;interviews;team working natural sciences computing software process improvement sorting;natural sciences computing;scientific software;modeling;survey;programming;multivoting scientific software development teams software development process improvement opportunities tecnichal scientific teams bottom up approach standard improvement models structural deficiencies elicitation process requirement gathering technique card sorting kelly grid	This paper presents ongoing research on a new approach to structure and elicit improvement opportunities in the software development process followed by technical-scientific teams. The bottom-up approach has been proved as more effective in process improvement applied to technical and scientific environments, in opposition to standard improvement models such as ISO or CMMI. However, when bottom-up is applied to elicit improvement areas, the method is usually limited to the use of surveys that miss many of the root causes and structural deficiencies. To complement the elicitation process, we propose the use of requirement-gathering techniques such as Card Sorting, Kelly Grid and Multi-Voting. Initial results are discussed in this paper.	bottom-up proteomics;capability maturity model integration;card sorting;kelly criterion;requirements analysis;software development process;top-down and bottom-up design	Patricio Maller;Alicia Salamon;Natalia Mira;Alejandra Boggio;Juan Giro;Jose Cuozzo;Francisco Coenda;Sofia Perez	2012	2012 12th International Conference on Computational Science and Its Applications	10.1109/ICCSA.2012.30	programming;systems modeling;interview;card sorting;computer science;sorting;artificial intelligence;operating system;machine learning;data mining;database;programming language;computer security;algorithm	HPC	-66.11469917582758	23.260616114025314	98617
76890a89396fbcd5277edcd9a716270b381bc11a	private cloud for software firms - a case study			cloud computing	Yao-Chieh Yang;Jung-Sing Jwo	2014		10.3233/978-1-61499-484-8-2197	parallel computing;computer science;computer engineering;software;cloud computing	SE	-64.00720589239275	21.352051970027464	98909
98aa2198cb78ff8e5d5b28084e7e2babfe7e8cd9	dynamics of software sustainment		Trends in sustainment cost growth are beginning to alarm military planners. Although software drives most military functionality, the contribution of software sustainment to sustainment costs is not well understood. The Carnegie Mellon Software Engineering Institute is involved in a research effort to describe the dynamics of sustainment, focusing on the software aspects. This paper describes the development of a dynamic economicmodel of sustainment in order to predict the consequences of fundingdecisionswithin sustainment organizations. To create this model, a number of notions had to be defined, including sustainment capability, capacity, and performance. The initial systems dynamics model uses notional input data; calibration with specific organizations will increase the fidelity of the model and tailor it to those specific groups.	interaction;simulation;software engineering institute;subject-matter expert;system dynamics	Sarah Sheard;Robert Ferguson;Michael Phillips;Andrew Moore	2014	J. Aerospace Inf. Sys.	10.2514/1.I010169	simulation;systems engineering;engineering	SE	-64.45014968212841	20.406760373362953	98921
3d8844daaef3e790f22a5610122c4e4767e38580	card-rm: a reference model for airborne software	agile;software;do 178c software agile reference model certification safety critical;certification;software reusability aerospace computing safety critical software;reference model;do 178c;aerospace computing;safety critical software;software reusability;certification aircraft atmospheric modeling testing software design medical services;do 178c compliance card rm airborne software certifiable agile reusable disciplined reference model;safety critical	This paper summarizes the preliminary aspects of a doctoral research that has been conducted at the Brazilian Aeronautics Institute of Technology (ITA). This research has the objective of developing the CARD-RM, a Certifiable, Agile, Reusable, and Disciplined Reference Model for airborne software. It aims to define a generic model that can be instantiated in each airborne software project, integrating agile practices, in order to improve efficiency without interference in DO-178C compliance.	agile software development;airborne ranger;best practice;do-178c;formal verification;interference (communication);problem domain;reference model;refinement (computing);requirement;software project management;sprint (software development);system requirements	Johnny Cardoso Marques;Sarasuaty Megume Hayashi Yelisetty;Adilson Marques da Cunha;Luiz Alberto Vieira Dias	2013	2013 10th International Conference on Information Technology: New Generations	10.1109/ITNG.2013.44	personal software process;medical software;verification and validation;reference model;software sizing;extreme programming practices;do-178b;software project management;do-178c;package development process;social software engineering;software development;software design description;software engineering;software construction;agile software development;software testing;software walkthrough;empirical process;certification;software measurement;management;lean software development;software deployment;software development process;software peer review	SE	-63.43063939828683	24.697093472769073	99002
63746b45e15acd8bee9bf09622b379ee6a41d769	continuously evaluated research projects in collaborative decoupled environments		Often, research results from collaboration projects are not transferred into productive environments even though approaches are proven to work in demonstration prototypes. These demonstration prototypes are usually too fragile and error-prone to be transferred easily into productive environments. A lot of additional work is required.  Inspired by the idea of an incremental delivery process, we introduce an architecture pattern, which combines the approach of Metrics Driven Research Collaboration with microservices for the ease of integration. It enables keeping track of project goals over the course of the collaboration while every party may focus on their expert skills: researchers may focus on complex algorithms, practitioners may focus on their business goals.  Through the simplified integration (intermediate) research results can be introduced into a productive environment which enables getting an early user feedback and allows for the early evaluation of different approaches. The practitioners' business model benefits throughout the full project duration.	algorithm;cognitive dimensions of notations;microservices	Oliver Schmidts;Bodo Kraft;Marc Schreiber;Albert Zündorf	2018	2018 IEEE/ACM 5th International Workshop on Software Engineering Research and Industrial Practice (SER&IP)	10.1145/3195546.3195549	architecture;microservices;systems engineering;computer science;software architecture;duration (project management);business model;lean software development	SE	-65.35193491759084	20.038727347015623	99180
37593058e17d3ce156637b799e20c0a89e8266a5	architectures for adaptive software systems, 5th international conference on the quality of software architectures, qosa 2009, east stroudsburg, pa, usa, june 24-26, 2009, proceedings	inf;algorithm analysis;programming language;software systems;software engineering;operating system;problem complexity	Preparing the books to read every day is enjoyable for many people. However, there are still many people who also don't like reading. This is a problem. But, when you can support others to start reading, it will be better. One of the books that can be recommended for new readers is architectures for adaptive software systems 5th international conference on the quality of software. This book is not kind of difficult book to read. It can be read and understand by the new readers.	book;software quality;software system;don't take it personally, babe, it just ain't your story		2009		10.1007/978-3-642-02351-4	domain analysis;computer architecture;verification and validation;computing;software sizing;software verification;search-based software engineering;computer science;backporting;software design;social software engineering;theoretical computer science;software framework;component-based software engineering;software development;software construction;programming language;resource-oriented architecture;system programming;software deployment;software development process;software requirements;software system	SE	-68.05949724418318	27.691188284696636	99461
9caee55f32259a31ed2ca7157af41d81d604365f	using a predictive rating system for computer programmers to optimise recruitment: using ratings to optimise programmer recruitment		Using﻿ a﻿ quantitative﻿ assessment﻿ system,﻿ the﻿ number﻿ of﻿ resumes﻿ reviewed﻿ to﻿ identify﻿ a﻿ suitable﻿ developer﻿was﻿reduced﻿to﻿3.5%﻿with﻿a﻿successful﻿recruitment﻿decision﻿made﻿in﻿10﻿working﻿days﻿of﻿ posting﻿the﻿job﻿advertisement.﻿This﻿paper﻿summarises﻿the﻿methodology﻿for﻿developing﻿that﻿rating﻿ system.﻿The﻿depth﻿and﻿quality﻿of﻿an﻿available﻿talent﻿pool﻿is﻿a﻿function﻿of﻿demand,﻿which﻿is﻿demonstrated﻿ by﻿comparing﻿globally-scaled﻿individual﻿performance﻿metrics.﻿Public﻿code﻿repositories﻿are﻿accessed﻿ and﻿the﻿code﻿quality﻿assessed﻿algorithmically.﻿The﻿performance﻿score﻿combines﻿accuracy,﻿timeliness﻿ and﻿difficulty﻿from﻿a﻿series﻿of﻿challenges.﻿These﻿three﻿attributes﻿form﻿a﻿meaningful﻿predictive﻿measure﻿ of﻿performance﻿by﻿using﻿a﻿non-linear﻿optimisation﻿ routine.﻿Bootstrapping﻿ is﻿used﻿ to﻿validate﻿ the﻿ approach.﻿This﻿process﻿randomly﻿omitted﻿a﻿scored﻿performance﻿observation﻿per﻿coder﻿in﻿order﻿to﻿ calculate﻿the﻿performance﻿score﻿from﻿the﻿retained﻿scores.﻿There﻿was﻿a﻿strong﻿relationship﻿(r﻿=﻿0.70)﻿ between﻿the﻿predicted﻿1-omitted-performance﻿score﻿with﻿the﻿actual﻿omitted﻿score﻿highlighting﻿the﻿ predictive﻿power. KeywORdS Bootstrapping, Gamma Distribution, Log Concave, Performance Monitoring, Talent Identification		Paul J. Bracewell;Ankit K. Patel;Evan J. Blackie;Chris Boys	2017	J. Cases on Inf. Techn.	10.4018/JCIT.2017070101	computer engineering;knowledge management;programmer;engineering;simulation	Metrics	-75.49370079287905	26.897074440371288	99641
cb62d2742e3b258d4d50aca13ce6564f7b7c6348	understanding the role of reporting in work item tracking systems for software development: an industrial case study			software development;tracking system	Pavneet Singh Kochhar;Stanislaw Swierc;Trevor Carnahan;Hitesh Sajnani;Meiyappan Nagappan	2018		10.1109/ICSME.2018.00070		SE	-64.19204738612228	24.526705163549334	99911
37b7726cba5f60e95265c546aef4fabcc7a15bde	medium size project model: variations on a theme	software testing;software engineering;educational environment;software development;profitability;project selection	"""This paper describes some recent variations on a tested theme for teaching Software Engineering in an undergraduate Computer Science program. This theme is referred to here as the Medium-Size Project Model. It has been used as the basis for an introductory Software Engineering course which has been evolving for the last 7+ years at the University of Alaska Fairbanks. The course features 3-way reality in that it uses real software development projects supplied by real customers, and the projects are conducted under realistic schedule and cost constraints in a simulated computer industry environment. Small teams of students acting as a software development company develop a software product for a customer in one semester. The scope of the software development effort is from proposal through software test and customer sell-off. Complete documentation is required, including everything from the proposal through to the customer sell-off document. A short project history is also required. The software product is expected to be developed at a """"profit"""". Project status is monitored by frequent team presentations which cover cost and schedule as well as technical issues. Software engineering lectures are synchronized and interleaved with project reviews. Customer, student, and other feedback indicates that the course has been very successful. The 3-way reality feature is a basic reason for this success. The theme is readily portable to other educational environments, and it allows many interesting implementation variations. Current variations in the six areas of project generation, project selection, instructor roles, student team and role assignments, technical documentation, and grading bases are described."""		Peter J. Knoke	1991		10.1007/BFb0024282	personal software process;long-term support;verification and validation;software engineering process group;software sizing;software project management;systems engineering;engineering;package development process;social software engineering;software development;software design description;software engineering;software construction;software testing;software walkthrough;software deployment;software development process;software requirements;software quality;computer engineering;software peer review	Theory	-66.51685077124854	26.41866898298781	99990
4ccc9031a248c7532994dbfa5ddc6c8c29e1af99	usability integration in agile development processes: a practice-oriented best practice approach			agile software development;best practice;usability	Hartmut Schmitt;Dominik Magin;Andreas Maier;Richard Wacker;Josh J Wang	2015	i-com		agile unified process;extreme programming practices;agile usability engineering;systems engineering;engineering;knowledge management;scrum;agile software development;process management;empirical process;lean software development;best coding practices	Robotics	-64.7026130896793	22.490867248978326	100096
dc19f8ea1a878c4186859974928c68abc2c38002	a field experiment on gamification of code quality in agile development		Internal quality of software reduces development costs in the long run but is often neglected by developers. CollabReview, a web-based reputation system for improving the quality of collaboratively written source code, was introduced into an agile development team. The goal was to improve the quality of developed source code as evidenced by the amount of code entities furnished with Javadoc comments. A money prize as an extrinsic reward and peer-pressure in form of a published ranking table were tied to reputation scores. We report on the conduction of a field experiment, our observations and experiences, and relate the results to answers from concluding interviews. Although the gamification had less effect than we had hoped, our experiment teaches valuable lessons about social effects and informs the future design of similar systems.	agile software development;cryptographic hash function;documentation;entity;experience;experiment;gamification;institute for operations research and the management sciences;javadoc;money;pair programming;rejection sampling;reputation system;social dynamics;software project management;software quality;weak value;web application;wiki	Christian R. Prause;Jan Nonnen;Mark Vinkovits	2012			software quality;systems engineering;field experiment;agile software development;computer science	SE	-73.30267772229959	22.170141298019868	100249
3eced435d5088719fe0102732a7079f2faa2adc2	a bayesian based method for agile software development release planning and project health monitoring	agile software development;software;belief networks;bayesian network;decision support;project management;complexity theory;design and development;software prototyping;software development project;risk management;bayesian methods;decision maker;software quality belief networks decision making process monitoring project management risk management software development management software prototyping;software project management;decision maker agile software development project health monitoring asd technique iteration method software quality risk assessment project health measurement model software development project bayesian networks;health monitoring;intelligent networks agile software development bayesian networks software project management decision support;process monitoring;variable speed drives;number of factors;probability distribution;intelligent network;software development;variable speed drives programming planning probability distribution complexity theory software bayesian methods;risk assessment;planning;intelligent networks;iteration method;asd technique;project health measurement model;programming;software quality;software development management;project health monitoring;bayesian networks	Agile software development (ASD) techniques are iteration based powerful methodologies to deliver high quality software. To ensure on time high quality software, the impact of factors affecting the development cycle should be evaluated constantly. Quick and precise factor evaluation results in better risk assessment, on time delivery and optimal use of resources. Such an assessment is easy to carry out for a small number of factors. However, with the increase of factors, it becomes extremely difficult to assess in short time periods. We have designed and developed a project health measurement model to evaluate the factors affecting software development of the project. We used Bayesian networks (BNs) as an approach that gives such an estimation. We present a quantitative model for project health evaluation that helps decision makers make the right decision early to amend any discrepancy that may hinder on time and high quality software delivery.	agile software development;bayesian network;discrepancy function;display resolution;handy board;it risk management;iteration;risk assessment;software deployment;software release life cycle;software system;table (database)	Ahmed Nagy;Mercy Njima;Lusine Mkrtchyan	2010	2010 International Conference on Intelligent Networking and Collaborative Systems	10.1109/INCOS.2010.99	project management;intelligent network;verification and validation;software quality management;software sizing;risk management;computer science;software reliability testing;bayesian network;data mining;systems development life cycle;empirical process;management;software deployment;software quality control;goal-driven software development process;software metric;software quality analyst	SE	-63.371744542025944	31.60286962474611	100454
e008d63672f5b4706fb7846eb702c824e51251d1	object-oriented programming with devops		DevOps is an emerging culture that emphasizes continuous collaboration between software developers and IT operators through continuous standard process with automated tools for continuous delivery. DevOps participants take diverse roles to support its values - continuous collaboration, continuous process, and continuous delivery. A development team needs to be familiar with user cases, Object-Oriented Analysis (OOA), Object-Oriented Design (OOD), Object-Oriented Programming (OOP), and software testing. A quality assurance team must know use cases, abuse cases, software testing, and penetration testing. An operation team requires understanding deployment of Application Programming Interface (API) documents and executable components, and monitoring them and sharing their monitoring outcomes with both development and quality assurance teams.	abuse case;application programming interface;continuous delivery;devops;executable;penetration test;software deployment;software developer;software testing	Sam Chung	2017		10.1145/3125659.3125670	engineering;quality assurance;application programming interface;devops;software;continuous delivery;software deployment;systems engineering;release management;use case	SE	-63.93409629472227	25.99568339279367	100866
e003154fbea3f1b75a2ae54c03a9589f6f4930a0	initial findings from an observational study of software engineers	software;groupware;empirical study;instant messaging;electronic mail;collaboration;software engineering groupware;observers;software engineering;software engineers;cscw observational study software engineers;observational study;computer supported collaborative work;programming collaborative software collaborative work design engineering software design software tools communications technology context modeling software engineering collaborative tools;lead;software development;cscw;communication technology;organizations;computer supported collaborative work observational study software development instant messaging software design software engineering;software design;quality model;information seeking;programming;software process	For the last 30 years, several empirical studies have been conducted to understand how software engineers work. However, during this period, many changes occurred in the context of software development: new communication technologies like instant messaging appeared as well as new quality models to evaluate the work being conducted. Despite this new context, much of the research in the collaborative aspects of software design is based on research that does not reflect these new aspects of work. Thus, a more up-to-date understanding of the nature of software engineering work - as a type of information work - is necessary. The purpose of this paper is to present the initial findings of an observational study to understand how software developers' time is distributed during their workday. The main results are related to aspects of collaboration observed in 55% of their time, information seeking consuming 31,90% of developers' time, and poor use of software process tools in 5% of the time observed. In particular, this last result is different from what one would expect and which has been previously been reported in the literature.	expect;information seeking;instant messaging;software design;software developer;software development process;software engineer	Marcio K. Goncalves;Cleidson R. B. de Souza;Víctor M. González	2009	2009 13th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2009.4968108	programming;information and communications technology;lead;team software process;software engineering process group;human–computer interaction;computer science;organization;knowledge management;software design;software development;software engineering;computer-supported cooperative work;software walkthrough;empirical research;management;software development process;observational study;collaboration	SE	-72.25278157126692	21.528933421579882	100928
19f02d88459b65b6d0da221c768befdde55c556c	dispatching strategies for managing uncertainties in automated manufacturing systems	simulation;scheduling sequencing;experiments;operations;rescheduling	Manufacturers in the western world need to exploit and perfect all their strengths to reduce the flight of manufacturing to global outsourcing destinations. Use of automated manufacturing systems (AMSs) is one such strength that needs to be improved to perfection. One area for improvement is the management of uncertainties on the production floor. This paper explores strategies for modifying detailed event list schedules following the occurrence of an interruption. Advanced planning and scheduling (APS) software packages provide a detailed advance plan of production events. However, the execution of this advance plan is disrupted by a myriad of unanticipated interruptions, such as machine breakdowns, yield variations, and hot jobs. The alternatives available to respond to such interruptions can be classified in four groups: regenerating the complete schedule using APS, switching to dispatching mode, modifying the existing schedule, and continuing to follow the schedule and letting the production system gradually absorb the impact of the interruption. Regeneration of the complete schedule using APS requires a large computation effort, may result in large changes in the schedule, and hence is not recommended. This paper reports on an experimental study for evaluating 10 strategies for responding to machine failures in AMSs that broadly fall in the latter three groups. The strategies are evaluated using simulation under an experimental design with manufacturing scenario, load level, severity and duration of interruptions as factors. The results are analyzed to understand the strengths and weaknesses of the considered strategies and develop recommendations.	automation	Saachi Jain;W. J. Foley	2016	European Journal of Operational Research	10.1016/j.ejor.2015.06.060	real-time computing;simulation;economics;computer science;marketing;operations management	Robotics	-73.02299408200253	29.501066798486256	101638
5f3d43832771d329df96fea11fed22ae0207e5e1	15. workshop automotive software engineering (ase)			adaptive server enterprise;automotive software;software engineering	Alejandro Masrur;Wolfram Hardt;Rocco Deutschmann	2017		10.18420/in2017_145	automotive engineering;engineering;automotive software	SE	-63.111964770464446	24.601717769603273	101867
16f7ea585b9d927e5d8d757fff641eebe924523e	developer turnover in global, industrial open source projects: insights from applying survival analysis		Large open source software projects often have a globally distributed development team. Studies have shown developer turnover has a significant impact on the project success. Frequent developer turnover may lead to loss of productivity due to lacking relevant knowledge and spending extra time learning how projects work. Thus, lots of attention has been paid to which factors are related to developer retention, however, few of them focus on the impact of activities of individual developers. In this paper, we study five open source projects from different organizations and examine whether developer turnover is affected by when they start contributing and what types of contributions they are making. Our study reveals that developers have higher chances to survive in software projects when they 1) start contributing to the project earlier, 2) mainly modify instead of creating files, 3) mainly code instead of dealing with documentations. Our results also shed lights on the potential approaches to improving developer retention.	documentation;open-source software	Bin Lin;Gregorio Robles;Alexander Serebrenik	2017	2017 IEEE 12th International Conference on Global Software Engineering (ICGSE)	10.1109/ICGSE.2017.11	knowledge management;systems engineering;documentation;distributed development;software;engineering;survival analysis	SE	-69.33225528794183	23.57753942076345	101917
1c7bace4d3e71b0e51bb36154959d85f7c79474d	requirements engineering and industrial uptake	formal specification;systems analysis;business culture;industrial uptake;inherent complexity;internal business integration;requirements engineering;scenario planning;training	Technology transfer to smalland medium-sized enterprises has failed to achieve its full potential in the requirements engineering (RE) field. Most companies do not know how to start their RE improvement efforts even if they are aware of the problems in this field. The state-of-the-practice survey presented in this paper gives a realistic view of how marginal technology transfer from the research community to the industry has been. It also reveals that the key development needs in industry are (1) development of own RE process adaptations, (2) RE process improvement, and (3) automation of RE practices. Directing efforts to these areas would substantially improve the chances of successful technology transfer and process improvement efforts in industry.	marginal model;requirements engineering	Philip Morris;Marcelo Masera;Marc Wilikens	1998		10.1109/ICRE.1998.667818	systems analysis;computer science;systems engineering;engineering;requirement;software engineering;formal specification;management science;requirements engineering;management;industrial engineering and operations research	Visualization	-65.25663310930491	20.787205693286154	102131
7baa3436ea5d41190b699bb2e22051eb72082685	enhancing business appification using sms text messages: metrics, strategies and alternatives		Mobile App stores and marketplaces allow sellers and developers to monetize their Apps mainly through the desktop-based download point, or by using the mobile owner's credit card. We would like to turn monetization focus on the fact that there is already another payment channel that should not be overseen, which is fruitfully used through the premium SMSs. In this work, we propose new metrics and strategies to enhance business APPification using SMSs efficiently and effectively, in two ways: a) SMS as a premium text service can be the mean to monetize Apps more easily than using HTTP protocol and credit cards – premium SMSs cost more than regular SMSs and return usage earnings. b) SMSs can be widely used as an additional “web” data transport protocol that may reduce user data access costs in some cases and therefore, allow new margin for monetization of apps. We also show prototype results that the proposed strategies and metrics assist.	accessibility;data access;desktop computer;download;emoticon;erlang (unit);fragmentation (computing);knowledge society;mobile app;monetization;prototype;refinement (computing)	Mersini Paschou;Evangelos Sakkopoulos;Efrosini Sourla;Athanasios K. Tsakalidis	2012		10.1007/978-3-642-32498-7_15	business;internet privacy;world wide web;computer security	Mobile	-76.64809750821317	30.90274947679496	102175
b022c897bb719767e1c5a3ceb775160f7774d2ba	what contributes to the success of it projects? an empirical study of it projects in the norwegian public sector.		Each year the public sector invests large amounts of money in the development and modification of their software systems. These investments are not always successful and many public sector software projects fail to deliver the expected benefits. Goal. This study aims at reducing the waste of resources on failed software projects through better understanding of the success factors and challenges. Method. We collected information about project characteristics, project outcome, perceived success factors, challenges and lessons learned from 35 software projects in 11 organizations in the public sector of Norway. Results. The respondents experienced that extensive involvement and competence of the client, high priority of the project, good dialogue between the clients and the external supplier and application of agile practices were main success factors. The main challenges were related to the involvement and competence of the client, project planning and management, software architecture and integration issues, transition of the product to the user organization and benefit management. Small and large software projects reported different challenges, especially related to project priority and access to skilled personnel. Projects with time and materials contracts with suppliers and that involved clients during project execution were more successful than other projects. Conclusions. Success factors are usually human factors, e.g., involvement, competence and collaboration. Challenges tend to be due to human factors as well as issues of a technical nature. Both aspects need to be addressed to enable successful software projects and avoid failures.	agile software development;client (computing);human factors and ergonomics;software architecture;software system	Parastoo Mohagheghi;Magne Jørgensen	2017	JSW		machine learning;empirical research;management science;artificial intelligence;norwegian;computer science;public sector	SE	-69.26141434844925	22.268410413229404	102347
b6b039d69a071e3eba0977529f4083387ca121b6	quality based software project staffing and scheduling with cost bound	software;quality based software project staffing and scheduling cost based approach defect amplification model task severity genetic algorithm software quality software project planning cost bound;remuneration;software genetic algorithms biological cells mathematical model planning remuneration sociology;biological cells;mathematical model;planning;genetic algorithms;sociology;software quality genetic algorithms scheduling	Software project planning is becoming more complicated and important as the size of software project grows. Many approaches have been proposed to help project managers by providing optimal staffing and scheduling in terms of minimizing the cost (i.e., necessary expanse) or time (i.e., time span or duration) required for the software project. Unfortunately, the software quality, another critical factor in software project planning, is largely overlooked in previous work. In this paper, we propose the quality based software project staffing and scheduling approach using a genetic algorithm (GA). We define a quality score by considering practical issues in software project planning in addition to task severity and defect amplification model. Further, the cost is utilized as a cost-bound in the GA to consider not only quality but also cost. Case study shows that the proposed approach improves the quality while the cost is optimized as the same as the cost-based approach. In other words, we provide better software project plans considering both cost and quality for software project managers. Also, we show the relationship between the quality and the cost in terms of software project planning.	fitness function;genetic algorithm;schedule (project management);scheduling (computing);software bug;software development;software project management;software quality;software release life cycle	Dongwon Seo;Donghwan Shin;Doo-Hwan Bae	2015	2015 Asia-Pacific Software Engineering Conference (APSEC)	10.1109/APSEC.2015.47	planning;verification and validation;team software process;genetic algorithm;software sizing;software project management;computer science;systems engineering;software development;software design description;software construction;mathematical model;management science;project management triangle;management;software deployment;software quality control;software quality;project planning;software metric;software quality analyst	SE	-66.61096146612216	28.754391539481798	102389
46aff75001ca038c625f6356c82d12800f15403e	looking at data	data collection;scientific method;software architecture data analysis;data analysis;software architecture;system evaluation;system evaluation data analysis data collection;computer science mathematics microprocessors data engineering data analysis fasteners internet vector processors writing supercomputers;user behavior	Collecting and analyzing data lies at the basis of the scientific method: findings about nature usher new ideas, and experimental results support or refute theories. All this i s not very prevalent in computer science, possibly due to the fact that computer systems are man made, and not perceived as a natural phenomenon. But computer systems and their interactions with their users are actually complex enough to require objective observations and measurements. We’ll survey several examples related to parallel and other systems, in which we attempt to further our understanding of architectural choices, system evaluation, and user behavi or. In all the cases, the emphasis is not on heroic data collection efforts, but rather on a fresh look at existing data, and uncovering surprising, interesting, and useful informati on. Using such empirical information is necessary in order to ensure that systems and evaluations are relevant to the real world.	computer science;interaction;observations and measurements;relevance;theory	Dror G. Feitelson	2008		10.1109/IPDPS.2008.4536092	software architecture;parallel computing;scientific method;computer science;theoretical computer science;operating system;data mining;distributed computing;data analysis;programming language;algorithm;statistics;disparate system;data architecture;data collection	DB	-67.02673215591787	30.445195345599494	102547
2336eee1edaa0ad5716f87bd0dfc7c44fdade13d	interactive digital cardwalls for agile software development		Agile software development is characterized by very intensive communication and collaboration among members of the software development team and external stakeholders. In this context, we look specifically at cardwalls, noting that despite the wide availability of digital cardwalls, most Agile teams still use physical cardwalls to support their collaborative events. This is true even though a physical cardwall hinders efficient distributed software development and causes extra effort to capture story artefacts into digital tools to meet traceability and persistence requirements. We conducted two empirical studies in industry to understand the use of existing digital Agile cardwalls and to find out the needs for an ideal digital Agile cardwall. The first study was with eight Agile teams of committed digital cardwall users. The study showed the reasons why some teams use projected digital cardwalls and their detailed experiences with them. The study showed that most digital cardwalls seem not be sufficient for the highly interactive and collaborative Agile workstyle. The second study was with eleven Agile companies. The study comprised of the development of aWall, a software prototype of a large interactive high-resolution multi-touch display that supports varied Agile meetings where cardwalls are used. The results of the study emerged with design considerations for digital Agile cardwalls from the evaluation of aWall in a user workshop. Both studies, which were conducted concurrently, began with an interest in new large interactive surface technologies which might have the potential to provide not only the required interaction possibilities to support intensive collaboration, but also the required large display format necessary for a collaborative space. The results of the studies collectively seem to confirm our assumption, that large interactive surface technologies could bring the support for the collaboration of Agile teams to a new level, potentially making the teams more productive.	agile software development	Martin Kropp;Judith M. Brown;Craig Anslow;Stevenson Gossage;Magdalena Mateescu;Robert Biddle	2016		10.1007/978-3-319-45853-3_13	p-modeling framework;personal software process;agile unified process;extreme programming practices;agile usability engineering;package development process;software development;release management;software construction;agile software development;software documentation;empirical process;lean software development;software development process;best coding practices	SE	-72.8364387327072	22.298099526415722	102939
fa26a443de45142e4a9f1b66f975bb02f9a0e456	a global software inspection process for distributed software development		Globally distributed software development is an established trend towards delivering high-quality software to global users at lower costs. The main expected benefits from distributed software development are improvements in development time efficiency, being close to the customers and having flexible access to greater and less costly resources. Organizations require to use their existing resources as effectively as possible, and also need to employ resources on a global scale from different sites within the organization and from partner organization throughout the world. However, distributed software development particularly face communication and coordination problems due to spatial, temporal and cultural separation between team members. Ensuring quality issues in such projects is a significant issue. This paper presents global software inspection process in the distributed software development environment towards quality assurance and management.	distributed computing;integrated development environment;software deployment;software development;software inspection;version control	Deepti Mishra;Alok Mishra	2012	J. UCS	10.3217/jucs-018-19-2731	software security assurance;team software process;software quality management;software engineering process group;software project management;knowledge management;package development process;social software engineering;software development;software engineering;software deployment;software quality control;software metric;software quality analyst	SE	-67.30268674347516	21.100941595593792	103100
7617009e40668870b94070bcc41473db4a15b2b4	a framework for the classification of data quality costs and an analysis of their progression	data quality benefits;data quality costs;data quality;data quality cost benefit analysis;optimal data quality costs;cost measurement;information quality;business case;cost benefit analysis;cost estimation	Many information quality initiatives and projects need to demonstrate the potential benefits of their IQrelated activities already in their planning stage. In doing so, practitioners rely on cost estimates based on current non-quality data effects (that are then compared to data quality improvement costs). In producing such estimates on costs caused by low quality data, it is difficult to identify all potential negative monetary effects that are the result of low quality data (as well as all possible costs associated with assuring high quality data and their progression). Because of this, this article reviews and categorizes the potential costs associated with low quality data and examines their progression. This can help practitioners to identify cost saving potentials and argue a more convincing business case of their data quality imitative. For researchers, the proposed classification framework and the cost progression analyses can be helpful to develop quantifiable measures of data quality costs and to prepare – subsequently – benchmarking studies, comparing different cost levels in different organizations. Thus, this paper contributes elements of a future cost-benefit analysis method for data quality investments.	approximation algorithm;color gradient;data quality;display resolution;information quality;real life;statistical classification	Martin J. Eppler;Markus Helfert	2004			information quality;actuarial science;data mining;total cost;carrying cost;cost–benefit analysis;quality costs;cost contingency;cost estimate;business;data quality	HCI	-70.4934590482281	21.69063528950506	103453
868700c555bc42ee1948d9dcc828d9995c66379b	modeling software engineering education with i		Complex software systems play an increasingly important role in business and everyday life. Software engineering education needs to cover a wide range of technical and non-technical competencies and skills, while technologies and best practices in this area are evolving rapidly, enabling new applications for the industry. Therefore a crucial task in teaching software engineering is the incremental improvement and enhancement of courses. To make the complexity and evolution of software engineering education more transparent and traceable than through an unstructured documentation, we are searching for a way to model teaching goals. One promising candidate for modeling teaching goals is i*. We applied i* in a realistic setting and present a significant portion of the resulting model. We share some empirical experiences on using i* in this setting, highlight possible barriers and limitations, and outline potential next steps.	best practice;documentation;software engineering;software system;traceability	Michael Koch;Dieter Landes	2014			software construction;feature-oriented domain analysis;civil engineering software;software engineering;computer-aided engineering;engineering;software requirements;software engineering process group;software development;systems engineering;social software engineering	SE	-65.89736943746374	23.950398171865288	103472
061c227d93f8ad9446e89fd03f8110acdbe33711	on the use of hybrid development approaches in software and systems development: construction and test of the helena survey	empirical study;development;survey;software process	A software process is the game plan to organize project teams and run projects. Yet, it still is a challenge to select the appropriate development approach for the respective context. A multitude of development approaches compete for the users’ favor, but there is no silver bullet serving all possible setups. Moreover, recent research as well as experience from practice shows companies utilizing different development approaches to assemble the best-fitting approach for the respective company: a more traditional process provides the basic framework to serve the organization, while project teams embody this framework with more agile (and/or lean) practices to keep their flexibility. The paper at hand provides insights into the HELENA study with which we aim to investigate the use of “Hybrid dEveLopmENt Approaches in software systems development”. We present the survey design and initial findings from the survey’s test runs. Furthermore, we outline the next steps towards the full survey.	agile software development;no silver bullet;software development process;software system	Marco Kuhrmann;Jürgen Münch;Philipp Diebold;Oliver Linssen;Christian R. Prause	2016			systems engineering;engineering;software engineering;software peer review	SE	-67.29431274272868	22.892471865926016	103759
392d26373535deecbda8fe849e7f7c858e5c417b	comparing inspection methods using controlled experiments	pair inspection;fagan s method;distributed inspection;controlled experiment;code inspection	Objective: In this paper we present an empirical study that was aimed at comparing three software inspection methods, in terms of needed time, precision, and recall values. The main objective of this study is to provide software engineers with some insight into choosing the inspection method to adopt. Method: We conducted a controlled experiment and a replication. These experiments involved 48 Master students in Computer Science at the University of Salerno. In the experiments, 6 academic researchers were also involved. The students had to discover defects within a software artefact using inspection methods that differ in terms of discipline and flexibility. In particular, we selected a disciplined but not flexible method (the Fagan’s process), a disciplined and flexible method (a virtual inspection), and a flexible but not disciplined method (the pair inspection). Results: We observed a significant difference in favour of the Pair Inspection method for the time spent to perform the tasks. The data analysis also revealed a significant difference in favour of the Fagan’s inspection process for precision. Finally, the effect of the inspection method on the recall is not significant. Conclusions: The empirical investigation showed that the discipline and flexibility of an inspection method affect both the time needed to identify defects and the precision of the inspection results. In particular, more flexible methods require less time to inspect a software artefact, while more disciplined methods enable the identification of a lower number of false defects.	computer science;experiment;fagan inspection;precision and recall;software engineer;software inspection;visual artifact	Andrea De Lucia;Fausto Fasano;Giuseppe Scanniello;Genny Tortora	2008			simulation;engineering;forensic engineering;engineering drawing;visual inspection	SE	-67.75352219021914	30.16113720458336	103888
0c8b1a490572374decccc6a1510fbb56ab4f8b5b	towards an understanding of the causes and effects of software requirements change: two case studies	collaborative case study;requirements change;requirements volatility;requirements evolution	Changes to software requirements not only pose a risk to the successful delivery of software applications but also provide opportunity for improved usability and value. Increased understanding of the causes and consequences of change can support requirements management and also make progress towards the goal of change anticipation. This paper presents the results of two case studies that address objectives arising from that ultimate goal. The first case study evaluated the potential of a change source taxonomy containing the elements ‘market’, ‘organisation’, ‘vision’, ‘specification’, and ‘solution’ to provide a meaningful basis for change classification and measurement. The second case study investigated whether the requirements attributes of novelty, complexity, and dependency correlated with requirements volatility. While insufficiency of data in the first case study precluded an investigation of changes arising due to the change source of ‘market’, for the remainder of the change sources, results indicate a significant difference in cost, value to the customer and management considerations. Findings show that higher cost and value changes arose more often from ‘organisation’ and ‘vision’ sources; these changes also generally involved the co-operation of more stakeholder groups and were considered to be less controllable than changes arising from the ‘specification’ or ‘solution’ sources. Results from the second case study indicate that only ‘requirements dependency’ is consistently correlated with volatility and that changes coming from each change source affect different groups of requirements. We conclude that the taxonomy can provide a meaningful means of change classification, but that a single requirement attribute is insufficient for change prediction. A theoretical causal account of requirements change is drawn from the implications of the combined results of the two case studies.	causal filter;causality;complexity;convergence insufficiency;dependency theory (database theory);endeavour (supercomputer);information;predictive modelling;requirement;requirements management;software bug;software development;software evolution;software requirements;software requirements specification;taxonomy (general);usability;volatility	Sharon McGee;Des Greer	2012	Requirements Engineering	10.1007/s00766-012-0149-0	systems engineering;engineering;operations management;management science	SE	-70.32545798716232	22.315350682474143	103893
f8ce32ea583d26a5dc111a03e632fbfc980b72fb	green sigma and the technology of transformation for environmental stewardship	energy saving;environmental impact objective;effective technology solution;carbon footprint;actual case study;robust analysis tool;green sigma;green sigma methodology;positive impact;environmental stewardship	Many enterprises have launched initiatives and benefited from improving their position as stewards of the environment. Strategies that help determine where to focus investments and resources in order to improve the environment are also becoming more common. Not surprisingly, methodologies designed to reduce waste are well suited to help companies that have environmental impact objectives such as reducing their carbon footprint and conserving natural resources. Green Sigmae, developed by IBM, is one such methodology that enables transformation for environmental stewardship by applying a proven process, robust analysis tools, and effective technology solutions. It utilizes aspects of the traditional Lean and Six Sigmae methodologies while providing the necessary tools to identify, implement, and sustain improvements that have a positive impact on the environment. The Green Sigma methodology is explained and then applied to a manufacturing and warehouse facility in an actual case study. By following the five steps of Green Sigma, applying robust analysis tools, and creating a management dashboard system, an energy savings of at least 20% was identified and achieved.	align (company);bluetooth;dashboard (business);holism;lean software development;list of reporting software;system of measurement	Eric G. Olson;Niall Brady	2009	IBM Journal of Research and Development	10.1147/JRD.2009.5429016	engineering	HCI	-68.0693833630974	19.19724087124425	103992
131e1227019217cf18006734218b2211380985f1	reducing friction in software development	software;software development economics software engineering stakeholders sustainability maintenance engineering;software development software reengineering software maintenance software evolution innovation curve decision making data analysis data science economic theory investment activity software engineering life cycle software engineering progress internal software quality;industries;education technical debt software management software economics software quality software engineering software development software architecture maintenance and evolution sustainability;stakeholders;software engineering;economics;software quality data analysis decision making software maintenance;friction	Software is being produced so fast that its growth hinders its sustainability. Technical debt, which encompasses internal software quality, evolution and maintenance, reengineering, and economics, is growing such that its management is becoming the dominant driver of software engineering progress. It spans the software engineering life cycle, and its management capitalizes on recent advances in fields such as source code analysis, quality measurement, and project management. Managing technical debt will become an investment activity applying economic theories. It will effectively address the architecture level and will offer specific processes and tools employing data science and analytics to support decision making. It will also be an essential part of the software engineering curriculum. Getting ahead of the software quality and innovation curve will inevitably involve establishing technical-debt management as a core software engineering practice. This article is part of a special issue on the Future of Software Engineering.	code refactoring;data science;software development;software engineering;software quality;static program analysis;technical debt;theory	Paris Avgeriou;Philippe Kruchten;Robert L. Nord;Ipek Ozkaya;Carolyn B. Seaman	2016	IEEE Software	10.1109/MS.2016.13	reliability engineering;personal software process;long-term support;verification and validation;stakeholder;software engineering process group;software sizing;software project management;systems engineering;engineering;package development process;social software engineering;software development;software engineering;friction;software construction;software walkthrough;software analytics;software maintenance;software deployment;software requirements;software quality;software quality analyst;software system;software peer review	SE	-67.25544903653754	23.65799211176923	104274
d7caffafe0b56c38b5bee6af39ae3024a45ab02d	case study: successful deployment of industry-university collaborative visual analytics research	project management;paired analysis visual analytics industry university collaboration technology deployment;technology deployment;data visualisation;technology transfer;data analysis;technology transfer data analysis data visualisation educational institutions organisational aspects project management research initiatives;paired analysis;visual analytics safety educational institutions companies laboratories industries aircraft;industry university collaboration;research initiatives;visual analytics;joint industry university project industry university collaborative visual analytics research deployment academic research laboratory industrial application;organisational aspects	Successful joint industry-university projects are as rewarding as they are rare. Even more rare is the effective transfer of technology from an academic research laboratory to an industrial application. Having the transfer take less than 3 years is rarest of all. This paper describes a case study where a successful joint industry-university project resulted in a considerable reduction in the time to move a new form of technology - Visual Analytics - from university laboratories into multiple industrial uses. Significant events and lessons learned along the way are described from both an industrial and an academic perspective.	software deployment;visual analytics	John Dill;David J. Kasik;David J. Darvill	2013	2013 46th Hawaii International Conference on System Sciences	10.1109/HICSS.2013.126	project management;analytics;visual analytics;simulation;computer science;knowledge management;data science;marketing;software engineering;data analysis;management;world wide web	Robotics	-67.06917656747989	23.60892457471183	104471
50051ae1f6341edfae95a62eb74072d472cdfe73	software performance testing based on workload characterization	software testing;workload characterization;performance test;software systems;software performance;software performance testing	A major concern of most businesses is their ability to meet customers' performance requirements. This paper describes our workload-based approach to performance testing, and includes a case study that demonstrates the application of this approach to a large, industrial software system. For this system, we collected data in the field to determine the current production usage, and then assessed the performance of the system under both current workloads, and those likely to be encountered in the future. This led to the identification of a software bottleneck, which, had it occurred in the field rather than in the test lab, would have likely had significant consequences.	requirement;software performance testing;software system	Alberto Avritzer;Joe Kondek;Danielle Liu;Elaine J. Weyuker	2002		10.1145/584369.584373	non-regression testing;reliability engineering;verification and validation;regression testing;test data generation;real-time computing;software performance testing;white-box testing;system integration testing;systems engineering;engineering;acceptance testing;package development process;software reliability testing;operating system;software engineering;software construction;software testing;non-functional testing;software deployment;test management approach;stress testing;software metric;software quality analyst	SE	-63.37719937057688	30.847167796214247	104899
0d36783dc670f070a380157d2fe9e11c7744e1fe	introduction to the special issue international conference on software engineering (icse 2012)	mining software repositories;inspection;open source software	The rapid evolution of software systems, the dynamic nature of modern software applications, the growing importance of distributed environments, the emerging role of the cloud technology, the pervasiveness of software solutions, and the increasing importance of software reliability are challenging the software engineering discipline with new problems and questions. The International Conference on Software Engineering (ICSE) is continuing a tradition that started in 1975 with the NCSE meeting in Washington DC and the ICSE meeting in 1976 in San Francisco. Over this time, the nature of software development has undergone many changes. New problems to tackle have arisen from new application domains, programming contexts, and architectural frameworks. These new problems sit alongside classic problems that still challenge the software engineering community. In 2012, ICSE was held in Zurich (Switzerland) and was animated by many interesting tracks, including three keynote speakers, a software engineering in practice track, a software engineering education track, a new ideas and emerging results track, a formal demonstrations track, a posters and informal demonstrations track, a software engineering horizons track, and the main technical research track, all together contributing to an exciting event. The technical research track was characterised by the presentation of 88 papers selected out of a total of over 400 submissions though a rigorous process. The ICSE 2012 program covered many hot areas of software engineering including fault handling, code generation, empirical studies, performance analysis, defect prediction, refactoring, human aspects, bug detection, multi-version software systems, program analysis for evolution, software and process models, concurrency, software architecture, formal verification, invariant generation, software vulnerability, code recommenders, test automation, and validation of specification. The program committee members identified seven papers that present novel and mature ideas that well sample the leading research in the field. The authors agreed to extend their conference papers with new in-depth contributions and experimental evidence. The new articles were thoroughly reviewed, and four have been selected for this special issue.	application domain;cloud computing;code generation (compiler);code refactoring;concurrency (computer science);formal verification;icse;profiling (computer programming);program analysis;software architecture;software bug;software development;software engineering;software quality;software system;switzerland;test automation;vulnerability (computing)	Gail C. Murphy;Mauro Pezzè	2014	ACM Trans. Softw. Eng. Methodol.	10.1145/2658849	inspection;systems engineering;social software engineering;software development;software engineering;database;software walkthrough;software analytics;software peer review	SE	-65.18100267904929	25.008541668716468	105177
16deba6b4f4b6840b1ebd01f43780b41bf179a7b	representing software system information in a topic map: a markup-centered approach	topic maps;software systems	This presentation will show how a company that uses XML on a large scale to deliver content to customers used XML technologies to make the management of software development easier. I led an effort to create an IS map for a complex set of interdependent metadata applications that had been developed over a period of 10–15 years. Having worked with these applications for years, I had a good sense of how the systems related to each other. My challenge was to build a presentation to explain and sell a system evolution plan. I reviewed documents that we had created over the years; while I found many excellent documents, I did not find a single document that I wanted to use as a basis for this effort. The presentation will demonstrate how we achieved some success with traditional data modeling tools that were available to us. We created a DTD model to describe a collections of software built over 10–15 years. The presentation will demonstrate how we achieved the most satisfying results using XML Topic Maps. Using a fictitious (and simplified) Editorial System example, I will demonstrate the creation of a pictorial model, a DTD model and finally a Topic Map model— comparing and contrasting the models along the way. Representing Software System Information in a Topic Map A markup-centered approach Table of	comparison of data modeling tools;image;interdependence;markup language;mathematical model;software development;software system;system information (windows);topic maps;xml	Terrence Brady	2004			software visualization;topic maps;software system;mathematics;markup language;software analytics;data mining	Web+IR	-63.04153044813543	23.08068005129933	105238
260ee599701a9d28a23b41accaaaeeb4706f47e7	low-rigour, rapid software process assessments for small software development firms	information systems;software process improvement;process capability;software process assessment;dp industry;computer industry;software engineering;software development management software process improvement dp industry;capability level;small software development firm;programming business costs australia computer industry software engineering software quality information systems educational programs statistics;business;software development;statistics;education level software process improvement assessment small software development firm capability level staff experience;software process improvement assessment;educational programs;process improvement;education level;280302 software engineering;programming;software quality;software development management;staff experience;australia	Rigorous software process improvement (SPI) assessments are considered by many small software development firms to be too expensive. We present the results from a program in which low-rigour, one-day SPI assessments were offered at no cost to 22 small software development firms. Analysis shows an association between capability levels achieved and staff experience and education level. Also, the process capability of firms varied depending on the industry sectors targeted by firms. About eight months after the assessment, the firms were contacted to arrange a follow-up meeting to determine the extent to which they had implemented the recommendations. Analysis of the capability levels at the time of assessment and later follow-up meeting reveals that the process improvement program was effective in improving the process capability of many of these small software development firms.	australian software engineering conference;capability maturity model integration;didactic organisation;directx;effective method;iso/iec 12207;iso/iec 15504;outsourcing;rapid;spice;software development process;software industry;software quality;while	Aileen Cater-Steel	2004	2004 Australian Software Engineering Conference. Proceedings.	10.1109/ASWEC.2004.1290490	reliability engineering;programming;team software process;process capability;software engineering process group;systems engineering;engineering;software development;software engineering;information system;software quality	SE	-65.97408214492783	27.972716867312965	105276
0235c64f3aea0d73bcbf3bc52c90a23705efdd5e	structural methodologies for auditing snomed	quality assurance;auditing;audit quality;partitioning;abstraction network;group based auditing;snomed;taxonomy;terminology;health care	SNOMED is one of the leading health care terminologies being used worldwide. As such, quality assurance is an important part of its maintenance cycle. Methodologies for auditing SNOMED based on structural aspects of its organization are presented. In particular, automated techniques for partitioning SNOMED into smaller groups of concepts based primarily on relationships patterns are defined. Two abstraction networks, the area taxonomy and p-area taxonomy, are derived from the partitions. The high-level views afforded by these abstraction networks form the basis for systematic auditing. The networks tend to highlight errors that manifest themselves as irregularities at the abstract level. They also support group-based auditing, where sets of purportedly similar concepts are focused on for review. The auditing methodologies are demonstrated on one of SNOMED's top-level hierarchies. Errors discovered during the auditing process are reported.	health care;high- and low-level;small;systematized nomenclature of medicine;taxonomy	Yue Wang;Michael Halper;Hua Min;Yehoshua Perl;Yan Chen;Kent A. Spackman	2007	Journal of biomedical informatics	10.1016/j.jbi.2006.12.003	quality assurance;computer science;knowledge management;nursing;snomed ct;data mining;database;quality audit;terminology;audit;taxonomy;health care	DB	-73.3197275539936	30.66703669628264	105391
2a77cce2157270ad6e6bbd88b3a9b215baa3fd29	peer testing in software engineering projects	software engineering	Software technical reviews are essential to the development and maintenance of high quality software. These review processes are complex group activities for which there exist an abundance of basic concepts evolved over years of practical experience. In a typical one-semester software engineering course very little of this information is adequately conveyed to students. Texts supporting this course are also very weak in this area. This paper provides a practical approach for teaching about software technical reviews in a one-semester software engineering course. The contents for two to three lectures on this topic are described as well as suggested exercises and an approach for integrating technical reviews with the usual team project. An extensive annotated bibliography is also provided to assist instructors and students.	display resolution;existential quantification;software engineering;software technical review	Nicole Clark	1987		10.1145/31820.31762	personal software process;technical peer review;software engineering process group;computer science;social software engineering;software development;software design description;software engineering;software technical review;software walkthrough;software analytics;software development process;software requirements;software peer review	SE	-66.14158406131097	25.73756015278169	105426
5e7031e057a5c4881a263e6d8ddc09bf78f0d23e	wise up: a new course for woman returners run at reading	new course;woman returners run	The course under discussion here is aimed at helping women return to the software industry. This is achieved by helping them to regain confidence in their existing skills in the computing industry and to update and consolidate their knowledge of software engineering; hence its name — Women In Software Engineering UPdate. The course covers the entire software life cycle from feasibility study to maintenance, looking at methodologies and tools for each phase2. For instance, formal methods of specification are introduced; very few women who have been out of the industry for any length of time will have experienced these more rigorous approaches to software specification. The course teaches aspects of project management, costing, general information gathering, data analysis, programming in C and systems analysis using Yourdon and JSD. In addition confidence building topics are covered, including such subjects as interview skills and CV preparation.		Jennifer Stapleton;Shirley Williams;Jane Goodwin	1990			real-time computing;engineering drawing;algorithm	NLP	-66.38799642534882	27.020493541441958	105497
9b0bfa66a2308ef85035a8aa102a43b9d4b5eb1d	analysis of software delivery process shortcomings and architectural pitfalls		This paper highlights the common pitfalls of overcomplicating the software architecture, development and delivery process by examining two enterprise level web application products built using Microsoft.Net framework. The aim of this paper is to identify, discuss and analyze architectural, development and deployment issues and learn lessons using real world examples from the chosen software products as case studies. Introduction: Software industry is undergoing massive globalization. Outsourcing and offshoring is not limited to the traditional information technology service industries in Asia. In fact, many software companies are hiring contractors from Mexico, Chile, East Europe, Vietnam and Bangladesh. Typically, the software development retains the core competencies (architects, team leads) and resources with business and technical knowledge and hand over the software maintenance tasks (bug fix, small enhancements, production environment troubleshooting, minor projects) to the offshore teams. These teams consist of developers with varying English and programming language skillset. With the increasing diversity of teams working on the code base it is critical to have a robust, consistent and easy to maintain architecture and software framework. (G. Abowd, 1997) has examined various software architecture evaluation practices for the software industry. (M. A. Babar & I Gorton, 2004) have studied scenario based software architecture evaluation methods. (M. Barbacci et. al, 1998) have done trade off analysis on software quality attributes. (P. Bengtsson & J. Bosch) have studied prediction of maintainability of software architecture. (P. Clement, R. Kazman & M.Klein, 2002) have provided methods and case studies for evaluating software architecture. (C. H. Lung & K. Kalaichelvan, 2000), (N. Lassing, D. Rijsenbrij & H. V. Vliet, 1999), (D. L. Parnas & D. M. Weiss, 1985) have examined architecture sensitivity, reviewed design practices and performed risk assessments on software development, delivery and architecture. (M. H. Klein et. al, 1993) and (M. R. Lyu) have analyzed real time software reliability and made recommendations in their handbooks for process improvements. Most of these studies have performed the analysis in the late nineties or early part of this century. Since then software industry has made technology advancements in terms of web development, client-server architecture, infrastructure availability (network speed, disk space and processor speeds). The nature of software development in terms of team size and location has also changed drastically. As a result, this paper tries to evaluate two enterprise level web applications built in recent years with a more diverse development team structure. Method: Two enterprise level web application products were chosen for comparative analysis. A series of questions was constructed and the software development and deployment process maturity and architectural quality was evaluated. Pitfalls and challenges in maintaining software consistency, architectural conformance and software delivery processes were identified. The author served as a senior level .NET consultant on both the products and was familiar with the development process, code and other information technology and operations departments in both organizations. Case Study 1: The first product (code name Product A, company name A) was a web application built using C# ASP.NET web forms. The web application was based on n-tier architecture. It used windows services and message queues (MSMQ) at the backend for asynchronous batch processing. The backend database used MS SQL 2008. The web application also interacted with external vendor systems using a legacy program based on C++ and WCF based web services. Case Study 2: The second product (code name Product B, company name B) was a web application built using C# ASP.NET model view controller (MVC) framework. The web application was based on micro-services architecture and interacted with several internal legacy systems built using MS Access and VB. The backend database used MS SQL 2008. The system also interacted with a JAVA based system and external vendors through WCF web services, SQL batch jobs and scheduled jobs. The next section contains the questionnaire used for evaluation of the software product, development and deployment process: 1) How many environments is the code deployed? Product A: Was deployed in development environment. If automated smoke tests passed the code was deployed to quality assurance department (QA) or the test environment. Once the feature was signed off the code was deployed to the user acceptance testing (UAT) environment. Once the feature was signed off by the business analyst, the code was pushed to the production environment. Product B: Was deployed in the development environment. If the sanity testing and smoke testing was signed off, it was pushed to the QA environment. Once the testing was signed off, UAT was performed on the same environment. Finally, the code was deployed to the staging (silo) environment and once it was signed off in the silo environment it was pushed to production. Product B also supported concurrent releases adding to the complexity. In both cases there were too many environments to maintain and the waterfall software development methodology meant, longer release duration for features and bug fix. Every time the code was deployed to a certain environment, significant time and resources had to be dedicated for troubleshooting environment issues. 2) How many load balanced servers exist in each tier? Product A: Three load balanced servers were used. The sessions were sticky. A request coming to server 1 went to the application server 1 and then to the database. Disadvantage: This meant the load balancing was not uniform leading to less than ideal performance. Product B: Three load balanced servers were used. The sessions were not sticky, which meant a request coming to a webserver could flow to any of the three load balanced application servers. Disadvantage: Troubleshooting a production issue was trickier since there was no good way to quickly track the error. 3) How many tiers exist in the deployed software? Product A: Consisted of web tier (3 servers), application server (3 servers), service layer (3 servers) and databases tier (3 servers). Product B: Consisted of web tier (3 servers), application server (3 servers), service layer (3 servers), database tier (3 servers). 4) Is the code deployed on a shared fileserver or on individual nodes? Product A code was deployed on a file share server. Multiple webservers on different tiers pointed to the same code base. Advantage: The code deployment needed to be done only in one location. This resulted in maintenance of fewer configuration file and lesser deployment errors. Disadvantage: All the servers pointed to the same location, causing contention issues, file locking and also the risk of single point of failure. Although there was backup and server restoration mechanism in place, but even then there was a risk of down time while the system came back up to full functionality. Product B code was deployed locally on each tier. As a result, paths, flags and other configuration changes were prone to errors such as human errors in manual deployment and errors due to access/ permission issue during automatic deployment. 5) Is the code easy to debug? Product A code contained proprietary and custom frameworks built on decade old .Net technology making the debugging process cumbersome. Product B code contained several micro services making the debugging process lengthy. The programmers had to setup break points in multiple instance of the service specific code files and projects. 6) Is the software web application easy to setup on a local developer machine? Product A code did not have automated scripts to assist in the local setup. Product B code used PowerShell scripts to automate most of the local setup process. 7) Is the deployment automated? Product A used a custom deployment tool with very little documentation. Product B used a custom deployment tool with very limited documentation. Not all the processes had been automated and thus the deployment was prone to human error. 8) How long does the deployment take? Product A build and deployment tool 2-3 hours. The build and deployment was lengthy and the automated smoke tests, database backup and restore process and application of database build scripts, took too long. Product B build and deployment took less than 30 min. There was no backup, restore and reapplication of database build script. 9) Does the architecture contain redundant libraries and framework? Product A contained business layer and a newly written custom xml based framework. But the old business layer was not completely removed. Product B contained several obsolete third party libraries and configuration files that could be potentially cleaned up. 10) Does the architecture contain redundant tiers? Product A contained externally available web services on a separate tier which could be combined with the web application tier. There was also a separate service layer that communicated with the web services which could be combined with the application tier. Product B contained an externally available service layer on its own tier which could be combined with the web tier. 11) Does the architecture use new technologies that were embraced to stay current with the market hype? Product A used BizTalk for business to business communication which led to high licensing call and maintenance effort. The same communication could have been implemented using custom web services. 12) Does the architecture contain inconsistencies in naming variables? Both Product A and B suffered from several inconsistencies in naming variable in the code which depended on the programmer preference instead of enforced coding standard. 13) Does the architecture contain inconsistencie	asp.net;acceptance testing;application server;backup and restore;batch processing;business logic;c++;capability maturity model;circuit restoration;client–server model;conformance testing;database;debugging;deployment environment;disk space;disk staging;documentation;downtime;emoticon;file server;hoare logic;human error;java;legacy system;library (computing);list of system quality attributes;load balancing (computing);lock (computer science);ms-dos;maxima and minima;microservices;microsoft access;microsoft biztalk server;microsoft message queuing;microsoft sql server;microsoft windows;mike lesser;model–view–controller;multitier architecture;outsourcing;patch (computing);powershell;programmer;programming language;qualitative comparative analysis;real-time computing;reliability engineering;risk assessment;sanity check;server (computing);service layer;silo;single point of failure;smoke testing (software);software architecture;software deployment;software development process;software framework;software industry;software maintenance;software quality assurance;sticky bit;visual basic;waterfall model;web application;web development;web server;web service;windows communication foundation;world wide web;xml	Amol Patwardhan	2016	CoRR		systems engineering;engineering;software engineering;computer engineering	SE	-68.22700090403147	26.894302302913825	105634
ab29d31eb759b0c8ff5e10d434de4ee6e145b776	the tutelkan spi framework for small settings: a methodology transfer vehicle	software process improvement;software process model;knowledge transfer;process engineering;quality model	Software organizations aim to improve their processes to increase their productivity, competitiveness and performance. Although numerous standards and models have been proposed, their adoption among small organizations is hard due to some size mismatches and to lack of experienced process engineers, which forces them to hire (expensive) external consultants. This article describes the Tutelkan SPI Framework, which proposes a three-fold approach to this problem: (1) providing a library of reusable process assets, (2) offering composition tools to describe small organizations processes using these assets, and (3) systematically training small organization focused consultants for these library and toolset. The framework has been successfully piloted with several Chilean small companies, and the library and tools are open and freely	capability maturity model integration;eclipse process framework;meta-process modeling;metamodeling;process modeling;programming tool;semiconductor industry;software industry;z/tpf	Gonzalo Valdes;Hernán Astudillo;Marcello Visconti;Claudia A. López	2010		10.1007/978-3-642-15666-3_13	systems engineering;engineering;knowledge management;operations management	NLP	-68.58471223810433	19.169023752335868	105757
eb7cf446e983e98c1400c8181949f038caf0c8a8	perpetual development: a model of the linux kernel life cycle	linux kernel;maintenance;software evolution;software release	Software evolution is widely recognized as an important and common phenomenon, whereby the system follows an ever-extending development trajectory w ith intermittent releases. Nevertheless there have been only few lifecycle models that attempt to por tray such evolution. We use the evolution of the Linux kernel as the basis for the formulation of such a model, integrating the progress in time with growth of the codebase, and differentiating bet ween development of new functionality and maintenance of production versions. A unique elem nt of the model is the sequence of activities involved in releasing new production versions, and how this has changed with the growth of Linux. In particular, the release follow-up phase before th forking of a new development version, which was prominent in early releases of production ve rsions, has been eliminated in favor of a concurrent merge window in the release of 2.6.x versions . We also show that a piecewise linear model with increasing slopes provides the best descr iption of the growth of Linux. The perpetual development model is used as a framework in which c ommonly recognized benefits of incremental and evolutionary development may be demonstra ted, nd to comment on issues such as architecture, conservation of familiarity, and failed p rojects. We suggest that this model and variants thereof may apply to many other projects in additio n to Linux.	agile software development;branching (version control);degree (graph theory);device driver;eclipse;interaction;interdependence;linear model;linux;linux;merge window;open-source software;pair programming;piecewise linear continuation;positive feedback;power-on reset;server (computing);software distribution;software engineering;software evolution;software product line;software release life cycle;software system;windows nt;x image extension	Dror G. Feitelson	2012	Journal of Systems and Software	10.1016/j.jss.2011.10.050	real-time computing;simulation;computer science;engineering;software evolution;operating system;software engineering;software release life cycle;linux kernel	SE	-67.45246550157339	29.560673917535095	105871
301baf9dbab595fb5187c4c61a9ca0c7293acb97	lessons learned from real dsl experiments	bob;visual programming specification languages formal specification command and control systems;formal specification;code generation dsl experiments domain specific languages communication format nato command and control messages naval ship formations graphics information text information declarative information cots products census survey instruments census data;code generation;visual programming;second language;command and control;specification languages;lessons learned;domain specific language;command and control systems;dsl graphics domain specific languages design engineering databases specification languages marine vehicles portable computers prototypes data mining	Over the years, our group, led by Bob Balzer, designed and implemented three domain-specific languages for use by outside people in real situations. The first language described the communication format of messages used by NATO to specify command-and-control messages between people and equipment; the processor we generated checked these messages for consistency. The second language was in part graphical, part textual, and was used to demonstrate how naval ship formations were constituted and the constrained movements they could undergo. The last language was a mixture of graphics, text, and declarative information specified using three different COTS products. It was used to describe census survey “instruments,” used to collect census data in the field. The code generated was to be installed in the survey takers’ laptops. Each of these was actually a prototype for what would have taken more time to engineer and polish before putting into practice. Although each effort was essentially successful, none of the languages was ever followed up with the subsequent engineering efforts that we expected or at least hoped for. The first two were demonstrated and reviewed informally. The last effort was more seriously reviewed, in that training sessions and a formal review process were undertaken to evaluate the potential effectiveness of the product. Herein I elaborate where these language efforts succeeded and where they failed, gleaning lessons for others who take the somewhat risky step of committing to develop a DSL for a particular user community.	declarative programming;digital subscriber line;domain-specific language;experiment;graphical user interface;graphics;laptop;prototype;virtual community	David S. Wile	2003		10.1109/HICSS.2003.1174893	command and control;simulation;computer science;domain-specific language;artificial intelligence;operating system;software engineering;formal specification;database;fifth-generation programming language;visual programming language;programming language;world wide web;second-generation programming language;code generation	Web+IR	-71.36214270848866	28.103172036635797	105903
cc8a1827ea5c46824104f3b810db69741f882fdc	a framework for managing interest in technical debt: an industrial validation		Technical debt management entails the quantification of principal and interest. In our previous work we had introduced a framework for calculating the Technical Debt Breaking Point (TD-BP), which is a point in time where the accumulated interest becomes larger than the principal; thus the debt of the company is no longer sustainable after this point in time. In this paper, we instantiate this framework and validate its ability to assess the breaking point of source code modules in an industrial setting. The results of the validation suggest that the calculated TD-BP is strongly correlated to experts' opinion on the sustainability of modules, and that it can accurately rank components, based on their maintenance difficulty.		Areti Ampatzoglou;Alexandros Michailidis;Christos Sarikyriakidis;Apostolos Ampatzoglou;Alexander Chatzigeorgiou;Paris Avgeriou	2018	2018 IEEE/ACM International Conference on Technical Debt (TechDebt)	10.1145/3194164.3194175	systems engineering;management science;empirical research;computer science;software;debt;maintenance engineering;source code;technical debt;sustainability;economic indicator	EDA	-65.13014217326491	31.019892106633474	106245
0948c624be316189b2010a5ec096a37893eb77b7	ready-set-transfer! technology transfer in the requirements engineering domain	serious goal;interactive panel;requirements engineering domain;primary goal;requirements engineering research;initial research phase;requirements engineering community;full industry adoption;different requirements engineering research;technology transfer;interactive presentation;requirement engineering;requirements engineering;software engineering;formal verification;collaboration;formal specification	The primary goal of requirements engineering research is to propose, develop, and validate effective solutions for important practical problems. However practice has shown that successful projects often take from 20–25 years to reach the stage of full industry adoption, while many other projects fizzle out and never advance beyond the initial research phase. In this interactive panel, teams of researchers representing several different requirements engineering research areas, bring ideas for technology transfer to a panel of industrial and government practitioners. The teams proceed through a series of interactive presentations and receive feedback from panelists. Underlying the game-show genre of the panel is the more serious goal to foster conversation between practitioners and researchers in order to improve the effectiveness of technology transfer in the requirements engineering community.	feedback;requirement;requirements engineering	Jane Cleland-Huang;Mona Rahimi;Mehdi Mirakhorli	2011	2011 IEEE 19th International Requirements Engineering Conference	10.1109/RE.2015.7320461	formal verification;computer science;systems engineering;engineering;knowledge management;software engineering;formal specification;requirements engineering;management;collaboration	SE	-66.64254500081044	23.925103464828645	106254
c1b511b0404bf2c17611dde46ad1a9eee6976860	an empirical study of offshore software development: the case of a ticketing application	large software project;project management;global software development;offshore insourcing	This is an industry report about a software development project that included a local team and an offshore team. Both teams contained highly qualified experts who had been selected before the project start up. After a year, which could be deemed as a break-in period, the project leaders observed that the quality and quantity of the software modules produced by the two teams were not up to expectation while costs had gone up. The management monitored the performance of the two groups by analysing the tests undertaken to ensure correctness of the modules. They reached the conclusion that the project failurewas influenced by cultural differences between the onshore and offshore teams. The management became convinced that the current work-organization prevented knowledge delivery and knowledge acquisition, so they established a new organization as the solution to this problem. A rapid validation of the new work arrangement convinced all the involved experts that the diagnosis was right.	correctness (computer science);knowledge acquisition;modular programming;software development	Carlo Consoli;Paolo Rocchi;Paolo Spagnoletti	2014	CIT	10.2498/cit.1002344	project management;team software process;software project management;knowledge management;project management triangle;project planning	SE	-69.20958997248674	21.036045956000642	106276
83dad64645fc84d4080978409b31dd24b345da87	wanna improve process mining results?	data mining business data processing;imprecise timestamps process mining data quality event data automatic process model discovery conformance checking bottleneck identification deviation identification processing time prediction improvement suggestion event log analysis event granularity case heterogeneity event log quality imprecise activity names missing events repair techniques analysis techniques missing timestamps;data mining;outliers process mining data quality event log preprocessing data cleansing;business data processing;data mining business information systems computational intelligence educational institutions electronic mail systematics	The growing interest in process mining is fueled by the increasing availability of event data. Process mining techniques use event logs to automatically discover process models, check conformance, identify bottlenecks and deviations, suggest improvements, and predict processing times. Lion's share of process mining research has been devoted to analysis techniques. However, the proper handling of problems and challenges arising in analyzing event logs used as input is critical for the success of any process mining effort. In this paper, we identify four categories of process characteristics issues that may manifest in an event log (e.g. process problems related to event granularity and case heterogeneity) and 27 classes of event log quality issues (e.g., problems related to timestamps in event logs, imprecise activity names, and missing events). The systematic identification and analysis of these issues calls for a consolidated effort from the process mining community. Five real-life event logs are analyzed to illustrate the omnipresence of process and event log issues. We hope that these findings will encourage systematic logging approaches (to prevent event log issues), repair techniques (to alleviate event log issues) and analysis techniques (to deal with the manifestation of process characteristics in event logs).	bottleneck (software);computation;computational intelligence;conformance testing;data mining;data quality;real life	Jagadeesh Chandra J. C. Bose;R. S. Mans;Wil M. P. van der Aalst	2013	2013 IEEE Symposium on Computational Intelligence and Data Mining (CIDM)	10.1109/CIDM.2013.6597227	computer science;data science;complex event processing;data mining;database;process mining;business process discovery	Security	-76.1245298991873	25.77271403940971	106504
c6c09edd1e71d8f60445e3b85fee1dd068f5b25f	critical software cultures: analyses of processes in four domains		Processes constrain developer freedom and impact software development cost. They can increase costs from only a few cents to almost 1000 USD per line of code. But they can also benefit the maintainability, dependability and safety of critical software. If failure risk costs are high, then the application of more expensive processes can actually reduce costs. Therefore it is important to understand which processes to apply when. This paper investigates development in four domains from aerospace to research, in order to extract some of the hidden expert knowledge expressed through the usage of processes. It analyzes data from a survey in a biotope of unregulated projects and three standards with respect to how process cost and benefit are balanced through criticality tailoring of processes. The results add to our understanding of criticality tailoring and the domainsu0027 engineering cultures, provide hints for what to address in process improvements, and can help to gauge if a standard might need adjustment.		Christian R. Prause	2016		10.1109/ICSSP.2016.010	reliability engineering;personal software process;long-term support;verification and validation;team software process;software quality management;software sizing;systems engineering;engineering;package development process;social software engineering;software reliability testing;operations management;software development;software construction;software walkthrough;software deployment;goal-driven software development process;avionics software;software peer review	SE	-69.13673249214006	21.887163597150618	106567
915226c17f1625e1639bbd84e0fe2d5023308940	knowledge management in distributed agile software development projects	agile;knowledge management;knowledge sharing;distributed;global software development	Knowledge management (KM) is essential for success in global software development. Software organizations are now managing knowledge in innovative ways to increase productivity. In agile software development, collaboration and coordination depend on the communication, which is the key to success. To maintain effective collaboration and coordination in distributed agile projects, practitioners need to adopt different types of knowledge sharing techniques and strategies. There are also few studies that focus on knowledge sharing in distributed agile projects. This research investigates the knowledge sharing techniques and strategies applied by the practitioners in distributed agile projects. In addition to that, challenges faced by the practitioners during knowledge sharing in distributed agile projects are also identified and discussed.	agile software development;knowledge management	Mohammad Abdur Razzak;Touhid Bhuiyan;Rajib Ahmed	2014		10.1007/978-3-319-28868-0_7	agile unified process;agile usability engineering;systems engineering;engineering;knowledge management;agile software development;management science;empirical process;lean software development;domain knowledge	SE	-68.46041411803965	20.44929825289256	106595
8f916ad0214fea9f52e6eda516ae08a70f091e17	where is software headed? a virtual roundtable	technological forecasting computer software;computer industry software tools computer networks communication system software communication industry software algorithms pervasive computing peer to peer computing genetic programming parallel programming;curriculum academia industry programming languages future software community polarization operating systems algorithms standards market leading trends evolutionary changes incremental changes revolutionary changes ideas tools installed base desktop computing software technology objects software agents software engineering parallel software;computer software;article;technological forecasting	To find out where software is headed, experts in academia and industry share their vision of software's future. It is a snapshot in time of where we have been and possibly where we are headed. The subjects discussed are: the desktop; software technology; objects; software agents; software engineering; parallel software; and the curriculum. The results suggest a strong polarization within the software community: a chasm exists between academia and industry. It appears that these two groups share radically different views on where software is headed. The impression is the heavy emphasis on programming languages, operating systems and algorithms by the academic group, in contrast to the clear emphasis on standards and market-leading trends by the industrial group. Academics worry about evolutionary or incremental changes to already poorly designed languages and systems, while industrialists race to keep up with revolutionary changes in everything. Academics are looking for better ideas, industrialists for better tools. To an industrial person, things are moving fast-they are revolutionary. To an academic, things are moving too slowly, and in the wrong direction-they are only evolutionary changes which are slave to an installed base. >		Ted G. Lewis;Dave Power;Bertrand Meyer;Jack Grimes;Mike Potel;Ronald J. Vetter;Phillip A. Laplante;Wolfgang Pree;Gustav Pomberger;Mark D. Hill;James R. Larus;David A. Wood;Hesham El-Rewini;Bruce W. Weide	1995	IEEE Computer	10.1109/2.402054	personal software process;technology forecasting;computing;simulation;computer science;artificial intelligence;package development process;backporting;software design;social software engineering;software framework;component-based software engineering;software development;software design description;operating system;software engineering;software construction;software walkthrough;programming language;software analytics;resource-oriented architecture;management;software deployment;computer security;statistics;software system;software peer review	Visualization	-69.16577700826348	27.35734969338929	106631
b21f0f0b8ecfceb42b9d1837cedce8fdbd814b8b	what next? advances in software-driven industries	complexity theory;software development software complexity software architecture model driven development software development life cycle distributed software development;computer architecture;software architecture;streamline development software driven industries collaboration comprehension connectivity cloud convergence software development life cycle globally distributed teams;software development;software architecture complexity theory software development modeling computer architecture;modeling;software engineering cloud computing dp industry groupware	Software-driven industries are advancing in five dimensions: collaboration, comprehension, connectivity, cloud, and convergence. However, companies often can get stuck in an overly narrow technology focus. To avoid this, they should connect architecture and functionality, master the entire software development life cycle, strengthen globally distributed teams, and streamline development.	adobe streamline;cloud computing;software development process;vergence	Christof Ebert;Gerd Höfner;V. S. Mani	2015	IEEE Software	10.1109/MS.2015.21	reference architecture;software architecture;personal software process;architecture tradeoff analysis method;verification and validation;systems modeling;computer science;systems engineering;engineering;package development process;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;software architecture description;software walkthrough;software analytics;resource-oriented architecture;software deployment;goal-driven software development process;software development process;software system;computer engineering;software peer review	SE	-65.71072290240681	21.940785767581545	106892
d5f32db0c91a53b272a8e40b5edd0c2e7f15078e	the maintenance problem of application software: an empirical analysis	empirical analysis	This paper presents findings from the analysis of data contained in reports and documents maintained by an MIS department of a major pharmaceutical and nutritional manufacturer. To guide data collection, the paper develops a conceptual framework consisting of a descriptive scheme and an explanation model. The descriptive scheme classifies maintenance activities into four categories: adaptive, corrective, perfective, and ongoing support. The explanation model identifies meta-factors that affect maintenance activity. The meta-factors are age, size, programming language, processing environment, structured programming, modularization, analysis and design methodologies, end-user involvement, documentation generation, and maintenance management. The paper analyses three business functions with high, middle, and low average time per repair maintenance project (ATM) measured in person-hours over a period of one year. Each function has several systems, and each system consists of modules. The analysis of available data for all functions maintained shows that maintenance (both repair and update) consumed 49% of data processing (DP) resources. For the three functions, the majority of these resources are devoted to perfective maintenance and corrective maintenance. Guided by the explanation model, several variables belonging to the meta-factors are identified, The following variables have the most significant influence over maintenance: real-time processing, database processing, end-user ongoing support, module size, number of runs and runtime per module, and number of reports and number of copies per function.	atm turbo;documentation generator;management information system;programming language;real-time transcription;structured programming	Ghazi I. Alkhatib	1992	Journal of Software Maintenance	10.1002/smr.4360040203	reliability engineering;computer science;engineering;software engineering;data mining	AI	-67.37872669423955	32.05230913449379	106916
5e70c3a4776f8dba1ecb3605165b439420f2c864	top-down system design a tutorial overview	software testing;performance evaluation;tutorials hardware microprogramming information processing system testing performance evaluation software debugging software performance software testing;top down;software performance;tutorials;system design;information processing;system testing;software debugging;microprogramming;hardware	In this introduction to hardware design topics within the ongoing tutorial series, the editors accent the essential link between software and hardware design.		Arthur V. Pohm;Terry A. Smay	1981	Computer	10.1109/C-M.1981.220497	computer architecture;verification and validation;software performance testing;information processing;system integration testing;computer science;package development process;software design;social software engineering;software reliability testing;component-based software engineering;software development;software design description;operating system;software engineering;top-down and bottom-up design;software construction;hardware architecture;microcode;software testing;software walkthrough;resource-oriented architecture;system testing;software deployment;software quality;software system;systems design;software peer review	EDA	-64.15070348125674	27.036094380493157	106931
f3f9150535d93c5dd0bf5474c9a65b62c6a5376c	systematic innovation mounted software development process and intuitive project management framework for lean startups		Today, software products are required to be more innovative and attractive because of unique circumstances in the software industry. Markets are changing fast and customers want to have more innovative products immediately. This paper provides a new process which integrates an inventive problem solving method into one modern software development program, making it part of the software development process. The Systematic Innovation Mounted Software Development Process (SPI), a combination of Agile and Systematic Innovation, provides an alternative development process which is targeted to adapt idea generation into software products. The intuitive project management framework helps technology driven companies to manage their software projects more effectively. This new software development process and associated techniques could impact the current software development industry significantly, especially software startup companies, because these powerful tools can help reduce managerial workloads of the companies and give them more time to remain focused on their key technologies.	agile software development;problem solving;programmer;software development process;software industry	Song-Kyoo Kim	2017	CoRR		software development process;software development;systems engineering;software;agile software development;project management;lean project management;software project management;engineering;lean software development	SE	-68.94176342159743	23.1463547037011	107247
81f3a941c8ae7982251a63960087ecdd6480e6bf	object-oriented software testing - introduction to the special section	object oriented software		software testing	Robert V. Binder	1994	Commun. ACM	10.1145/182987.182988	verification and validation;software sizing;system integration testing;computer science;package development process;backporting;social software engineering;component-based software engineering;software development;software construction;software testing;software walkthrough;software measurement;software deployment;software quality;software system	SE	-63.31116996598104	26.221711070880286	107339
73cc886221acf47798903baa99c029affcffdb83	object-oriented software: design and maintenance	object-oriented software	Give us 5 minutes and we will show you the best book to read today. This is it, the object oriented software design and maintenance that will be your best choice for better reading book. Your five times will not spend wasted by reading this website. You can take the book as a source to make better concept. Referring the books that can be situated with your needs is sometime difficult. But here, this is so easy. You can find the best thing of book that you can read.	book;situated;software design	Luiz Fernando Capretz;Miriam A. M. Capretz	1996		10.1142/3162	reliability engineering;reusability;personal software process;long-term support;verification and validation;computer science;systems engineering;package development process;backporting;software design;social software engineering;software development;software design description;software engineering;software construction;software walkthrough;software analytics;resource-oriented architecture;software maintenance;software deployment;software system;software peer review	PL	-64.09078819143453	25.959428650836042	107747
b098510029819e9947fac73d5d7f8ab8949139f4	choice of software development methodologies: do organizational, project, and team characteristics matter?	agile software development;project characteristics;information systems;hybrid software development;waterfall model software development methodologies organizational characteristics project characteristics team characteristics project managers team members agile methodologies agile unified process scrum;software development industries organizations information systems agile software development;waterfall model;industries;software engineering;software development methodologies;agile methodologies;organizational characteristics;software engineering software development methodologies agile methodologies traditional methodologies waterfall model hybrid software development project characteristics team characteristics organizational characteristics software development;team characteristics;software development;team working project management software development management software prototyping;traditional methodologies;organizations	Organizations can choose from software development methodologies ranging from traditional to agile approaches. Researchers surveyed project managers and other team members about their choice of methodologies. The results indicate that although agile methodologies such as Agile Unified Process and Scrum are more prevalent than 10 years ago, traditional methodologies, including the waterfall model, are still popular. Organizations are also taking a hybrid approach, using multiple methodologies on projects. Furthermore, their choice of methodologies is associated with certain organizational, project, and team characteristics.	agile unified process;agile software development;scrum (software development);software development process;waterfall model	Leo R. Vijayasarathy;Charles W. Butler	2016	IEEE Software	10.1109/MS.2015.26	agile unified process;systems engineering;engineering;knowledge management;software engineering;agile software development	SE	-69.53861159023114	20.555465949961572	107955
2b711f6738dd17458eccfb8f18b97e8539a83891	an application of quantitative techniques to the question of what contributes to a successful software development project	usability quantitative techniques software development project student project teams project management team involvement processes functionality;programming computer science australia computer industry project management software engineering application software industrial control usability costs;project management;student project;software development processes;project manager;analysis and design;software development process;software engineering;education software engineering computer science education computer science;computer science education;software development;computer science;product quality	Objectively answering the question of what contributes to a successful software development project has traditionally been difficult due to a lack of empirical data. The software development industry rarely has access to a controlled environment to conduct experiments. This paper shows the results of an analysis carried out in a controlled environment on 36 student project teams over 3 years. In each year, each team was charged with implementing the same project with the same resources, and the same access to the client, on the same technical platform. This enabled an observation of the contribution of factors like total time spent, proportion of time spent on analysis and design, quality of project management, quality of team involvement processes deployed and use of a methodology on the quality of the final product. Product quality was measured in functionality and usability. The results give some clear pointers on how to get a good software product from a development team.	software development	Ken Mullin;Stuart Hope	1996		10.1109/ASWEC.1996.534129	project management;personal software process;verification and validation;team software process;software quality management;project;software project management;computer science;systems engineering;engineering;knowledge management;package development process;social software engineering;software development;software design description;software engineering;software construction;software walkthrough;project management 2.0;project management triangle;software development process;software quality;project planning;software peer review	SE	-65.79599470255502	28.332380129101256	108171
8a66217053636149b416027159a9cf40bb254dca	licensing and certification of software professionals	quality assurance;it professional;project manager;information technology;satisfiability;software engineering;body of knowledge;software development;product development process	For many years, software organizations have needed to hire developers with a wide range of academic and professional qualifications, due to the ongoing shortage of individuals qualified to create and maintain the products required to satisfy marketplace demand. Many of these companies have used the certification credentials of such individuals to help judge whether they have the proper background for the development requirements of their particular software organization. Certification is a voluntary process intended to document the achievement of some level of skill or capability. Such certification can be awarded through a variety of organizations. To date, company-based certification programs have been dominant in the software field. These programs have been created and run by a particular company, and are usually centered on determining an individual’s qualification to use a particular type of software that is marketed by that business. However, these programs are often limited in scope, and sometimes make it possible to acquire certification with little practical software development background or formal training. However, there have recently been a growing number of efforts to provide more comprehensive certification programs for software professionals through professional societies and independent organizations. Some of such certificates are offered as a specialization in areas that in a number of fields are a part of the product development process, e.g., quality assurance and project management. In other cases, there are programs intended to certify individuals for having general knowledge and abilities across a wide range of software development areas. In some countries, such certification of software engineering professionals is done on a nationwide basis by an engineering professional society. There has also been an increased interest in the licensing of software engineering professionals. Licensing is a more formal version of certification that ADVANCES IN COMPUTERS, VOL. 60 1 Copyright © 2004 Elsevier Inc. ISSN: 0065-2458/DOI 10.1016/S0065-2458(03)60001-X All rights reserved.	credential;international standard serial number;new product development;partial template specialization;requirement;software development;software engineering	Donald J. Bagert	2004	Advances in Computers	10.1016/S0065-2458(03)60001-X	professional certification;personal software process;team software process;software quality management;software engineering process group;knowledge management;software development;body of knowledge;software engineering professionalism;software walkthrough;professional certification;certification;law;information technology;new product development;satisfiability	SE	-70.01486869809037	18.812227563843827	108495
37176f1adad8b178d2d1f2baed4509f9a65799ab	the visual variables in uml: how are they used by women?		This paper presents results of an empirical research study of the Unified Modeling Language (UML) actual state of practice. It reports on a quantitative analysis of > 3500 UML diagrams related to open source projects in GitHub. The aim of the study is to shed light on the use of the visual variables (i.e., color, size, brightness, texture/grain, shape and orientation) in UML, with a particular focus on the practices of women in such usages. The theoretical perspective of the study is to explore the usefulness of the visual variables in UML. These latter are highly significant in reducing the cognitive load of human beings, when effectively employed. We conclude by discussions of the obtained results and commenting on the role of women in the projects involving visual variations in their diagrams.		Yosser El Ahmar;Xavier Le Pallec;Sébastien Gérard	2018		10.1145/3241403.3241422	systems engineering;management science;empirical research;brightness;unified modeling language;computer science;cognitive load	SE	-71.92624511282817	23.52094724925869	108650
356207689cff02b9b27c49f01bb46a5b799e94f3	automotive-adept: a lightweight assessment method for the automotive software industry			automotive software;software industry	Fergal McCaffery;Ita Richardson;Peter Moller	2008	Software Process: Improvement and Practice	10.1002/spip.396		SE	-62.9898136203518	24.662309588747586	108742
1a052a088147c9ecfd2ee836d64d6b4c2ea35f02	current practice in the development and evaluation of spoken language dialogue systems	human factors;best practice;life cycle	The growing industrial take-up of spoken language dialogue systems (SLDSs), their constantly increasing sophistication, and the scarcity of teams which master the full system complexity as well as all the necessary steps in the SLDSs lifecycle, has created a felt need for a best practice model for development and evaluation of SLDSs. An obvious first step towards establishing a best practice model is to build a solid overview of current practice. This paper presents a model for the description of SLDS current practice with particular focus on dialogue management and human factors.	best practice;dialog system;human factors and ergonomics	Niels Ole Bernsen;Laila Dybkjær;Ulrich Heid	1999			scarcity;sophistication;natural language processing;best practice;spoken language;computer science;artificial intelligence	NLP	-70.95784996200733	24.274680685889006	108964
656de7c18f9f926828cfbe473d2fc6870baf4e59	oil-field services' data acquisition system – a globally distributed development	distributed development;globally distributed development;software testing;project management;acceptance testing;unit testing;software systems;data processing;testing;data acquisition system;companies;drilling;program testing;integrated software system;system integration;software development management data acquisition oil technology petroleum industry program testing project management;wireline cables;petroleum industry;data delivery;application component test;companies software testing data acquisition testing software systems project management natural gas industry;oil technology;natural gas industry;schlumberger oilfield services;data acquisition;project management schlumberger oilfield services data acquisition system globally distributed development integrated software system data processing data delivery drilling wireline cables application component development application component test system integration acceptance testing;software development management;application component development;level 1	"""Schlumberger's Oilfield Services' (OFS) data acquisition system is an integrated software system for acquiring, processing and delivering data from downhole tools, either during drilling or through wireline (i.e., electrical) cables. The project is largely distributed across six R&D centers in the US, France, Japan and China. Each center has sub-projects that have a clearly defined responsibility with either framework or application-components developments. All sub-projects share the common master plan for both development and testing. Furthermore, all unit tests and """"Level-1"""" application-component tests for particular applications are globally distributed and owned by each sub-project team. Together with the master test plan, a rigorous application-component test procedure/process is also in place to guarantee the success of the final system integration tests. Results from the distributed developments and the distributed first-level tests are finally assembled in one place, Beijing, for system integration and acceptance tests."""	acceptance testing;data acquisition;integrated software;integration testing;software system;system integration;test plan;unit testing	Di Cao	2008	2008 32nd Annual IEEE International Computer Software and Applications Conference	10.1109/COMPSAC.2008.227	project management;data processing;systems engineering;engineering;operating system;software engineering;database;software testing;data acquisition	SE	-66.40082868482607	20.88656599799008	109008
0fbb05273d196d626c94328c222ff325387c3aea	providing commercial open source software: lessons learned	business model	Even though companies like Sun, IBM, MySQL and others have released several commercial Open Source Software (OSS) products, little evidence exist of how to successfully launch such products and establish a living community around them. This paper presents a case study from a small software company succeeding at establishing a business model and a vivid community around their own OSS products. Based on this case study, the paper presents lessons learned which could help other OSS providers.	mysql;open sound system;open-source software	Øyvind Hauge;Sven Ziemer	2009			business model;systems engineering;engineering;software engineering;world wide web	SE	-70.60378641240759	26.824088482306955	109011
c6eac8cbfd58b9f2947b1f08d7c52cde1ffa65aa	software reusability metrics estimation: algorithms, models and optimization techniques		Abstract Objective In this paper, the proposed model is intended to employ a novel evolutionary computing-based artificial intelligence or machine learning scheme for regression tests to be used for reusability estimation. Such enhancement can lead to accurate reusability pattern estimation, which can be effective for optimal software design purposes. This model is popularly called an aging-resilient software reusability forecast representation. The proposed system employs predominant object-oriented software metrics, such as Chidamber and Kemereru0027s metrics to examine reusability. Here, cumulative metrics, object-oriented metrics, McCabeu0027s metrics, cohesion and a coupling-based reusability assessment model have been proposed which could be of paramount significance in software design optimization. In this paper, software metrics algorithms and their primary constructions have been developed for estimating the metrics from the UML/class diagrams. It is feasible to derive an efficient and robust reusability prediction model for web-service products using object-oriented metrics. Here, it was also found that OO-CK metrics, particularly complexity, cohesion and coupling-related metrics can be helpful in predicting reusability in web-service software products. Considering the above-mentioned key contributions, it can be stated that the proposed research could be of paramount significance in next-generation software computation systems, primarily for software component reusability, reliability, survivability, aging prediction and stability, and for software excellence assurance purposes.	algorithm;mathematical optimization	Neelamadhab Padhy;R. P. Singh;Suresh Chandra Satapathy	2018	Computers & Electrical Engineering	10.1016/j.compeleceng.2017.11.022	regression testing;component-based software engineering;software metric;class diagram;software;software design;computer science;algorithm;unified modeling language;reusability;reliability engineering	DB	-62.88180414854776	30.620613915782908	109382
110d9bdbd8bb396f95374a8d03682769afaa5d63	leveraging global resources: a process maturity framework for managing distributed software product development	distributed development;distributed software development;product management;data collection;virtual teams;software engineering;production management;virtual team;software industry;evolutionary process;software process;quality management;product development	Distributed software development is pervasive in the software industry as companies vie to leverage global resources. However popular quality and process frameworks do not specifically address the key processes needed for managing distributed software development. We develop an evolutionary process maturity framework for globally distributed software development that incorporates 24 new key process areas essential for managing distributed software product development We test the validity of our process framework using data collected from more than sixty large, distributed enterprise product development projects. We believe we have laid new ground for software process research by extending generic quality process frameworks to address the distributed development scenario.	capability maturity model;distributed computing;fold (higher-order function);new product development;pervasive informatics;software development process;software industry	Narayan Ramasubbu;Mayuram S. Krishnan	2005			personal software process;verification and validation;team software process;software engineering process group;software project management;systems engineering;engineering;knowledge management;package development process;social software engineering;software development;release management;software construction;process management;software walkthrough;empirical process;lean software development;software deployment;goal-driven software development process;software development process;software quality;software peer review	SE	-66.68099812539086	21.713563185454582	109502
27f0c616e7becce01b50ae1b519a7409206ba3eb	customer knowledge in value creation for software engineering process		The aim of this paper is to explain how we can achieve and integrate customer knowledge into the software engineering process in multi-disciplined product development, through developing dynamic capabilities. According to service dominant logic, knowledge assets are key drivers in creating competitive advantage for organizations. This research will provide significant new information about the role of customer knowledge in value creation for the software engineering process in the machinery industry. As the result of the research, a model for acquisition and use of customer knowledge in value creation of the software engineering process is created and guidelines produced.	customer knowledge;software development process;software engineering	Anne-Maria Aho;Lorna Uden	2012		10.1007/978-3-642-30867-3_13	voice of the customer;personal software process;team software process;software engineering process group;software mining;systems engineering;knowledge management;social software engineering;software development;domain engineering;customer intelligence;process management;knowledge value chain;software quality control;software quality;customer advocacy	SE	-66.88601688674851	18.563283114894986	110120
0f4465cc51896644fce158fbd7439d8938111099	software productivity analysis of a large data set and issues of confidentiality and data quality	project management;software productivity;multinational companies;project manager;software management;large data sets;confidentiality;incomplete data;data privacy;software management data privacy productivity;software productivity analysis;project management software productivity analysis confidentiality data quality;data quality software productivity confidentiality;data quality;productivity;software quality productivity databases size measurement data analysis software measurement technological innovation project management aerospace industry lab on a chip;data security	The paper reports on an ongoing investigation into software productivity and its influencing factors. Analysis of a data set containing project management of a large multinational company. The data set contains tables holding information about more than 25000 closed projects collected since 1990. Due to incomplete data only 1413 closed projects could be used for the investigation. Confidentiality was also considered as a major issue. The projects in the data set vary greatly in their productivity. Analysis of productivity and its influencing factors	confidentiality;data quality	Gernot Armin Liebchen;Martin J. Shepperd	2005	11th IEEE International Software Metrics Symposium (METRICS'05)	10.1109/METRICS.2005.43	project management;productivity;multinational corporation;confidentiality;data quality;computer science;systems engineering;data mining;database;data security	SE	-68.91745237764425	31.13327379057431	110401
7eadee8c20183baa2f5bb6f492063306a7f49303	tool usage within a globally distributed software development course and implications for teaching	feature complex collaboration infrastructures tool usage globally distributed software development course teaching work processes globally distributed software engineering teams data mining global software development class student teams gsd teaching implications learning effect;data mining;software engineering;google electronic mail software collaboration planning encoding education;computer science education;teaching computer science education data mining educational courses software engineering;educational courses;teaching	There have been many case studies looking at the work processes and use of tools within globally distributed software engineering teams. These studies usually use interviews, or other qualitative methods to ascertain their results. Additionally they may use data mining on particular modes of communication. In this paper, we report from observations in a Global Software Development class where students were free to choose the tools that best suited their needs, with minimal constraints. We discuss tool usage in three student teams and show how communication can be visually compared and correlated with implementation effort. We provide GSD teaching implications for tool selection and for monitoring progress of student teams. Finally, we suggest as a point of discussion that lightweight tools are not only preferred by students, but provide the same learning effect as more feature-complex collaboration infrastructures.	data mining;distributed computing;software development;software engineering	Jennifer Baldwin;Daniela E. Damian	2013	2013 3rd International Workshop on Collaborative Teaching of Globally Distributed Software Development (CTGDSD)	10.1109/CTGDSD.2013.6635240	personal software process;software engineering process group;computer science;systems engineering;knowledge management;package development process;social software engineering;software development;software engineering;software construction;software walkthrough;software analytics;software deployment;computer-aided software engineering;software system;software peer review	SE	-72.21047976389075	21.452540768157302	110619
02bb3e61efd340330277020b3141fa763eefe237	empirical comparison of two metrics suites for maintainability prediction in packages of object-oriented systems: a case study of open source software	software metrics;object oriented packages;software quality;maintainability;prediction models	Software maintainability has been an important exte rnal quality attribute that concerns both styles of software development, the proprietary model as well as open source. As lots of open source software ar e predominantly built using the OO paradigm, there ex ists a need for empirical validation with respect t o certain quality aspects especially maintainability. There are a few studies in the past which use code metrics and a few which use design metrics, much ea rlier in the software development life cycle to predict maintainability. In addition, there are stu dies which apply both code as well as design metric s o evaluate maintainability. The objective of this res earch is to perform an empirical comparison of two popular OO metrics suites, the Martin suite and the CK suite on four open source software systems by analysing a few key design metrics such as size, co upling, complexity, inheritance and stability. Two important observations were made with this empirica l study. First, between the two OO suite of design metrics, the prediction model developed using Marti n metrics scores better than the model developed using the CK suite. Second, the combination of Mart in and CK suites is helpful in predicting the maintainability of OO software, with a predictive a ccuracy of 66.7%, better than that of the models constructed by either Martin metrics or by the CK m etrics individually.	complexity;data mart;image resolution;open-source software;programming paradigm;software development process;software metric;software system	K. G. Madhwaraj	2014	JCS	10.3844/jcssp.2014.2330.2338	computer science;machine learning;predictive modelling;software quality;maintainability;software metric	SE	-62.98691468574323	27.504691552370055	110706
768fa1cf55b4a1e7f1ad01f55c4e7c9996d97f1b	experience of using a simple scm tool in a complex development environment	software systems;development environment	Five years ago our organization started the development of a new generation of real-time systems for process control. The new process supervision systems were based on Unix and Motif. The new development process has required a new, modern and efficient Software Configuration Management (SCM) tool. After the investigation of SCM tools on the market, and some unsuccessful tests of different commercial products, it was decided to start with a simple tool, well integrated in Unix. RCS (Revision Control System) was chosen.	motif;real-time computing;real-time transcription;revision control system;software configuration management;unix	Ivica Crnkovic	1996		10.1007/BFb0023096	human–computer interaction;systems engineering;software development;software engineering;software development process	Embedded	-69.38840532370138	28.925792925221987	110764
ac9376577b2e857ce75574f36c360452e308fa80	an empirical evaluation of the requirements engineering tool for socio-technical systems		One of the major problems of requirements engineering is the lack of sufficient empirical evidence that evaluates the benefits of modelling tools for Model-Driven Engineering (MDE). In this paper, we report on the results of empirical study that compares the modelling effort and effectiveness of the novel software tool for modelling requirements of sociotechnical systems against modelling on paper. We have asked 8 persons who received 2 different treatments – modelling on software against modelling on paper to create 2 requirements models – goal and domain models – for 2 different case studies. The study finds that modelling effort with a software tool nearly equals to modelling effort on paper while modelling effectiveness with a tool is higher than modelling effectiveness on paper. The major limitation of this study is the use of students as participants and the use of small sample size. In the future work, we will conduct another empirical study with a large sample size of professionals that aims to increase the confidence in the results obtained from this empirical study.	cognition;domain model;goal modeling;model-driven engineering;model-driven integration;programming tool;requirement;requirements engineering;sociotechnical system;software propagation	Msury Mahunnah;Kuldar Taveter;Raimundas Matulevicius	2018	2018 IEEE 7th International Workshop on Empirical Requirements Engineering (EmpiRE)	10.1109/EmpiRE.2018.00012	empirical research;domain model;requirements engineering;unified modeling language;software;systems engineering;sample size determination;sociotechnical system;empirical evidence;computer science	SE	-71.12966982370841	23.075389818816166	110846
230399f7e2c801dc2bd44bf9d4f32cd12c530bac	augmenting social awareness in a collaborative development environment	sns;tool support;workspace awareness;team foundation server;collaborative development environment;social network;development environment;social awareness;cde;visual studio;tfs	Adequate tool support is paramount to enable distributed teamwork, and thus global software teams usually rely on a Collaborative Development Environment (CDE) to cope with geographical distance. The most recent and full-featured CDEs typically provide presence and workspace awareness in one place, but lack any support to social awareness for reducing the sociocultural distance. We argue that disseminating social awareness information within a CDE can both speed up the establishment of a cross-organizational shared context and help developers who have little or no chances to meet and, then, develop trust-based inter-personal connections. For this reason, we propose to extend a commercial CDE in order to provide members of global software teams with information collected from corporate microblogging and professional social networks.	collaborative development environment;geographical distance;social network;workspace	Fabio Calefato;Filippo Lanubile	2011	2012 5th International Workshop on Co-operative and Human Aspects of Software Engineering (CHASE)	10.1145/2024645.2024656	simulation;engineering;knowledge management;world wide web	HCI	-77.2841534347445	20.898889521499704	110925
fb17793f4fabb58b3a4412a93eff5939e32cccbb	doing empirical research on software development: finding a path between understanding, intervention, and method development	software engineering;software development;programvaruteknik;empirical research	Doing empirical research on Software Development : Finding a path between Understanding, Intervention, and Method Development.	software development	Yvonne Dittrich	2002			personal software process;software engineering process group;computer science;systems engineering;social software engineering;software development;software engineering;iterative and incremental development;management science;systems development life cycle;software walkthrough;empirical process;software analytics;goal-driven software development process;software development process;software peer review	SE	-64.50629536757393	24.338408104795516	111069
c02b2769a0b4197f93477b5d222dfb04257f7ec6	software engineering beyond the project - sustaining software ecosystems	software ecosystems;qualitative empirical research;software product development	Context: The main part of software engineering methods, tools and technologies has developed around projects as the central organisational form of software development. A project organization depends on clear bounds regarding scope, participants, development effort and lead-time. What happens when these conditions are not given? The article claims that this is the case for software product specific ecosystems. As software is increasingly developed, adopted and deployed in the form of customisable and configurable products, software engineering as a discipline needs to take on the challenge to support software ecosystems Objective: The article provides a holistic understanding of the observed and reported practices as a starting point to device specific support for the development in software ecosystems. Method: A qualitative interview study was designed based on previous long-term ethnographical inspired research. Results: The analysis results in a set of common features of product development and evolution despite differences in size, kind of software and business models. Design is distributed and needs to be coordinated across heterogeneous design constituencies that, together with the software, build a product specific socio-technical ecosystem. The technical design has to support the deference of part of the development not only to 3-party developers but also to local designers tailoring the software in the use organisation. The technical interfaces that separate the work of different design constituencies are contested and need to be maintained permanently. Development takes place as cycles within cycles – overlaying development cycles with different rhythms to accommodate different evolution drivers. Conclusion: The reported practices challenge some of the very core assumptions of traditional software engineering, but makes perfect sense, considering that the frame of reference for product development is not a project but continuous innovation across the respective ecosystem. The article provides a number of concrete points for further research.	holism;knowledge-based configuration;new product development;sociotechnical system;software build;software development;software ecosystem;software engineering	Yvonne Dittrich	2014	Information & Software Technology	10.1016/j.infsof.2014.02.012	personal software process;simulation;software quality management;software engineering process group;software project management;computer science;systems engineering;engineering;knowledge management;package development process;social software engineering;software framework;software development;software design description;software engineering;database;software walkthrough;software analytics;resource-oriented architecture;management;software deployment;software development process;software requirements	SE	-66.70234218290257	19.178649410502576	111180
097f8f861d076fd20fb92f22bbb8258dec6ae9d7	summary for leadership and management in software architecture (lmsa 2008)	leadership;architect role;management	"""Software architecture, in education and practice, is primarily concerned with technical issues associated with the quality of software architecture and design. However, as project size increases, leadership, management skills, and the organizational context of the architect become more important, to the point where the non-technical duties of the project architect can """"make or break"""" a project. This workshop is focused on understanding these non-technical duties."""	software architecture	Brian Berenbach;Leonard J. Bass	2008		10.1145/1370175.1370238	leadership;software project management;systems engineering;engineering;knowledge management;software engineering;management	SE	-66.79998214611338	24.171481277202606	111538
08ab3a3de09f0951139bf8e54370a0034fd0e146	a flexible method for maintaining software metrics data: a universal metrics repository	corporate memory;software measurement;bepress selected works;data collection;software development process;software engineering;software development;software metric;software metrics software engineering repositories software engineering data collection	Abstract   A neglected aspect of software measurement programs is what will be done with the metrics once they are collected. Often databases of metrics information tend to be developed as an afterthought, with little, if any concessions to future data needs, or long-term, sustaining metrics collection efforts. A metric repository should facilitate an on-going metrics collection effort, as well as serving as the “corporate memory” of past projects, their histories and experiences. In order to address these issues, we describe a transformational view of software development that treats the software development process as a series of artifact transformations. Each transformation has inputs and produces outputs. The use of this approach supports a very flexible software engineering metrics repository.	software metric	Warren Harrison	2004	Journal of Systems and Software	10.1016/S0164-1212(03)00092-X	personal software process;medical software;verification and validation;software engineering process group;software sizing;computer science;systems engineering;package development process;backporting;social software engineering;software development;software design description;software engineering;software construction;database;software walkthrough;software analytics;software measurement;software deployment;software development process;software requirements;software metric;software system;data collection;software peer review	SE	-64.25168452735065	28.045280782621393	111626
13eec84fd1be4c7f303fd3d32d485d4f2052703d	experiences in process domain engineering at prc inc	domain engineering;process capability;software process reuse;software process engineering;software engineering;process domain engineering;managerial support;lessons learned;software reusability;software process domains;organizations;software process reuse process domain engineering prc incorporated software process domains software process engineering organizations managerial support;process engineering;prc incorporated;software process	This paper briefly describes experiences at PRC Inc. in performing domain engineering on software process domains. It describes the domain engineering method used, the results of the domain engineering, and lessons learned. At PRC, domain engineering is applicable to software processes, beneficial to organizations at varying levels of process capability, dependent upon sustained managerial support, and helpful in evolving increasingly reusable assets.	domain engineering;software development process	Craig Hollenbach	1996		10.1109/ISPW.1996.654376	domain analysis;personal software process;verification and validation;process capability;software engineering process group;leancmmi;systems engineering;organization;engineering;package development process;social software engineering;software development;feature-oriented domain analysis;software engineering;domain engineering;software construction;requirements engineering;empirical process;goal-driven software development process;software development process;software requirements;computer engineering	SE	-64.41324031928627	23.080548265373988	111768
3f6ac7e5d5916536d3855d44f7bd770a47e0d9f0	managing a y2k project - starting now	project management;data integrity;software maintenance;planning data integrity software maintenance software management project management;software management;project management application software costs space technology computer industry magnetic devices programming profession hardware operating systems aging;application programs year 2000 project management fast flawless solutions work plan;planning	As the year 2000 draws near, solutions to the Year 2000 (Y2K) problem seem both abundant and elusive. At this late date, Y2K problems require fast, flawless solutions. This article sets forth a practical work plan for assessing and correcting problems in existing application programs.		James E. Schultz	1998	IEEE Software	10.1109/52.676742	planning;project management;verification and validation;extreme project management;program management;software project management;opm3;computer science;systems engineering;engineering;software development;software engineering;release management;software construction;data integrity;software as a service;management science;application lifecycle management;project management 2.0;software maintenance;project management triangle;management;software development process;project planning;software system	Embedded	-68.54503875641687	26.10820493971919	111780
85f2b9cf4e7b770989c98672c39a9bbccd6a924d	measuring maintainability of spreadsheets in the wild	personal computing;spreadsheet programs personal computing software maintenance;reliability;measurement;measurement software systems organizations reliability spreadsheet programs iso standards;spreadsheet programs;software maintenance;iso standards;software systems;organizations;organization end user programming spreadsheet maintainability goal question metric spreadsheet corpus	Several studies have shown how spreadsheets are pervasive in many organizations as a form of end-user programming. Despite their importance and long lifespan, they are seldom developed with maintenance concerns in mind, and organizations have no efficient way of estimating the risk they present.	aggregate data;end-user development;gqm;pervasive informatics;spreadsheet;text corpus	José Pedro Correia;Miguel Alexandre Ferreira	2011	2011 27th IEEE International Conference on Software Maintenance (ICSM)	10.1109/ICSM.2011.6080821	reliability engineering;computer science;systems engineering;organization;engineering;software engineering;reliability;software maintenance;measurement;software system	Robotics	-64.20487552745657	28.78165868113122	111841
2282be22bdd5e5c51c21e66ff1856b63b14834db	reporting guidelines for simulation-based studies in software engineering	software engineering;guideline computer simulation simulation studies software engineering systematic review;sbs report quality reporting guidelines simulation based studies software engineering computerized experiment research protocol evidence based model se sbs understandability sbs replicability sbs generalization sbs validity simulation model building simulation model evaluation reporting standard reporting consistency	Background: Some scientific fields, such as automobile, drugs discovery or engineer have used simulation-based studies (SBS) to faster the observation of phenomena and evolve knowledge. All of them organize their working structure to perform computerized experiments based on explicit research protocols and evidence. The benefits have been many and great advancements are continuously obtained for the society. However, could the same approach be observed in Software Engineering (SE)? Are there research protocols and evidence based models available in SE for supporting SBS? Are the studies reports good enough to support their understanding and replication? AIM: To characterize SBS in SE and organize a set of reporting guidelines aiming at improving SBSu0027 understandability, replicability, generalization and validity. METHOD: To undertake a secondary study to characterize SBS. Besides, to assess the quality of reports to understand the usually reported information regarding SBS. RESULTS: From 108 selected papers, it has been observed several relevant initiatives regarding SBS in software engineering. However, most of the reports lack information concerned with the research protocol, simulation model building and evaluation, used data, among others. SBS results are usually specific, making their generalization and comparison hard. No reporting standard has been observed. CONCLUSIONS: Advancements can be observed in SBS in Software Engineering. However, the lack of reporting consistency can reduce understandability, replicability, generalization and compromise their validity. Therefore, an initial set of guidelines is proposed aiming at improving SBS report quality. Further evaluation must be accomplished to assess the guidelines feasibility when used to report SBS in Software Engineering.	simulation;software engineering	Breno Bernard Nicolau de França;Guilherme Horta Travassos	2012		10.1049/ic.2012.0019	simulation;systems engineering;engineering;data mining	SE	-74.92971886736143	28.11965300881849	111861
5709f9e4adc9c250918331ddc67b689010f68f21	a position study to investigate technical debt associated with security weaknesses		Context: Managing technical debt (TD) associated with potential security breaches found during design can lead to catching vulnerabilities (i.e., exploitable weaknesses) earlier in the software lifecycle; thus, anticipating TD principal and interest that can have decidedly negative impacts on businesses. Goal: To establish an approach to help assess TD associated with security weaknesses by leveraging the Common Weakness Enumeration (CWE) and its scoring mechanism, the Common Weakness Scoring System (CWSS). Method: We present a position study with a five-step approach employing the Quamoco quality model to operationalize the scoring of architectural CWEs. Results: We use static analysis to detect design level CWEs, calculate their CWSS scores, and provide a relative ranking of weaknesses that help practitioners identify the highest risks in an organization with a potential to impact TD. Conclusion: CWSS is a community agreed upon method that should be leveraged to help inform the ranking of security related TD items.		Clemente Izurieta;David Rice;Kali Kimball;Tessa Valentien	2018	2018 IEEE/ACM International Conference on Technical Debt (TechDebt)	10.1145/3194164.3194167	reliability engineering;quality assurance;software development process;software quality;technical debt;software;common weakness enumeration;business;software measurement;vulnerability	SE	-64.77828560889104	30.85606599656465	111873
460c26121ce3c44ac4710e29444820785f68d70f	support for computer forensics examination planning with domain modeling: a report of one experiment trial	domain model;empirical study;computer forensics;statistical testing security of data;large scale;statistical tests computer forensics examination planning domain modeling ad hoc planning approach;digital media;statistical testing;forensics software engineering unified modeling language power system modeling brain modeling information analysis large scale systems ontologies power engineering computing military computing;security of data	In any forensic investigation, planning and analysis activities are required in order to determine what digital media will be seized, what types of information will be sought in the examination, and how the examination will be conducted. Existing literature and suggested practices indicate that such planning should occur, but few tools provide support for such activities. Planning an examination may be an essential activity when investigators and technicians are faced with unfamiliar case types or unusually complex, large-scale cases. This paper presents the results of an empirical study that evaluates two planning methods for computer forensics examination: a methodology that includes domain modeling and a more typical, ad hoc planning approach. This paper briefly describes the case domain modeling and planning methodology, describes the empirical study, and presents preliminary results of and conclusions drawn from the empirical study	computer forensics;digital media;domain-specific modeling;hoc (programming language)	Alfred C. Bogen;David A. Dampier;Jeffrey C. Carver	2007	2007 40th Annual Hawaii International Conference on System Sciences (HICSS'07)	10.1109/HICSS.2007.505	statistical hypothesis testing;simulation;computer science;artificial intelligence;data science;digital media;software engineering;domain model;data mining;database;empirical research;world wide web;computer forensics;statistics	SE	-70.44138685179101	31.07334481997118	112547
2f99e8d8ee28b09a321a21b7c6054e5b1f66e889	antipractices: antipatterns for xp practices	mission critical systems;project management;object oriented methods;turning;application software;contracts extreme programming antipatterns antipractices xp practices team working;software management;contracts;xp practices;extreme programming;programming profession mission critical systems contracts crystallization turning application software books cultural differences atmosphere reflection;books;experience report;team working;side effect;crystallization;programming profession;antipatterns;atmosphere;high efficiency;programming;antipractices;object oriented methods project management software management team working contracts programming;reflection;cultural differences	"""When you introduce extreme programming (XP) to your project, the team gets fresh energy and high efficiency. However, sustaining the good condition becomes difficult when you are attacked by its side effects. We call these XP side effects """"AntiPractices"""", just as AntiPatterns come from Patterns. """"Turning all the knobs up to 10"""" is the XP way, but AntiPractices show bad symptoms of the overdrive. In this experience report, we identify AntiPractices discovered from our projects. We add prescriptions so that XPers can share the countermeasures."""	extreme programming;pentium overdrive;refactoring software, architectures, and projects in crisis	Yoshihito Kuranuki;Kenji Hiranabe	2004	Agile Development Conference	10.1109/ADEVC.2004.7	simulation;systems engineering;engineering;operations management;you aren't gonna need it	HCI	-68.92081884186737	26.316462068621586	112699
9d92472bee22c90d629332aeb4c722f73cf62680	engineering reliable software	q labs software reliability engineering software reliability models cost benefit analysis software life cycle software development cleanroom software engineering high level design techniques reliability certification;software engineering;reliability engineering software engineering communication system software software reliability certification fault tolerance electronic mail design methodology software safety software systems;design technique;software development;software reliability engineering;software life cycle;software reliability;cost benefit analysis	Software reliability engineering is not only the use of software reliability models and similar techniques, it is the use of sensible engineering principles with cosubenefit analysis throughout the software life cycle to obtain reliable software. The need to have a comprehensive view on somare development to engineer reliable sofnvare will be emphasized. Cleanroom Software Engineering is proposed as being the basis for developing reliable software. The paper will in particular discuss some extensions to Cleanroom, both in terms of adaptations and additions. Particular emphasis will be on high-level design techniques and methods for reliability Certification of the sofhvare. The comprehensive view of software is supported by several success stories, both with references to results presented in literature as well as experiences from projects conducted by Q-Labs. The results obtained are encouraging. The methods proposed are shown to give a substantial gain in the development of reliable sofnvare.	cleanroom software engineering;high- and low-level;level design;list of software reliability models;reliability engineering;requirements analysis;software release life cycle;software reliability testing	Claes Wohlin	1993		10.1109/ISSRE.1993.624272	reliability engineering;personal software process;medical software;long-term support;verification and validation;software engineering process group;software sizing;software verification;systems engineering;engineering;cost–benefit analysis;package development process;social software engineering;software reliability testing;software development;software design description;software engineering;software construction;software walkthrough;resource-oriented architecture;software measurement;software deployment;software development process;software requirements;software quality;software system;software peer review	SE	-63.36439307743721	27.417077277340276	112890
00c7d3f22105fba8c1f25ae89d83e152027d8119	a case study on the utilization of problem and solution domain measures for software size estimation	solution domain measures;problem domain measures;software size estimation;multiple regression	Detailed requirements is the primary input of software size measurement and effort estimation methodologies and a significant amount of time and expertise is needed for size measurement. In order to streamline size measurement and effort estimation, this study exploits the correlations between the problem domain measures such as the number of distinct nouns and distinct verbs in the requirements artifacts and the solution domain measures such as the number of software classes and methods in the corresponding object oriented software. In this case study, 12 commercial software projects are analyzed and multiple regression analysis is carried out to develop an estimation model for the solution domain metrics in terms of problem domain metrics. The results suggest that, for the projects examined, it is possible to use problem domain measures to make plausible predictions for the solution domain metrics.	adobe streamline;coefficient;commercial software;cost estimation in software engineering;problem domain;requirement;software sizing;vii	Tülin Erçelebi Ayyildiz;Altan Koçyigit	2016	2016 42th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)	10.1109/SEAA.2016.13	domain analysis;mathematical optimization;software sizing;computer science;linear regression;data mining	SE	-65.40597635236283	30.080434233020167	112984
37263b36249b6a606b010638d0d31f2efe7f7a27	software testing techniques for the information systems professional: a curriculum perspective			information systems professional;information system;software testing	Eldon Y. Li	1988			curriculum mapping;software development;knowledge management;software construction;computer science;curriculum;information system;software verification and validation;software	HCI	-65.55415977221271	25.145130766288855	113089
61134c15ba268fb934a8a0ef66be20e28ff0b4ce	08412 executive summary - science of design : high-impact requirements for software-intensive systems			requirement	Matthias Jarke;Kalle Lyytinen;John Mylopoulos	2008			software engineering;executive summary;software;systems engineering;engineering	Logic	-65.91399483889208	23.843652132527293	113137
a17d32dca875566c7bedadb41b885524c9ae142e	reinforcement learning-based dynamic adaptation planning method for architecture-based self-managed software	software systems process planning runtime environment humans software architecture intelligent robots computer science software performance research and development strategic planning;software;online planning reinforcement learning dynamic adaptation planning architecture based self managed software software systems software configurations;dynamic change;intelligent robots;probability density function;reinforcement learning;runtime environment;planning artificial intelligence;software systems;software architecture configuration management learning artificial intelligence planning artificial intelligence;data mining;strategic planning;software performance;dynamic environment;software architecture;research and development;online planning;architecture based self managed software;batteries;planning;humans;dynamic adaptation planning;computer science;process planning;learning artificial intelligence;environmental change;software configurations;dynamic adaptation;configuration management	Recently, software systems face dynamically changing environments, and the users of the systems provide changing requirements at run-time. Self-management is emerging to deal with these problems. One of the key issues to achieve self-management is planning for selecting appropriate structure or behavior of self-managed software systems. There are two types of planning in self-management: off-line and on-line planning. Recent discussion has focused on off-line planning which provides static relationships between environmental changes and software configurations. In on-line planning, a software system can autonomously derive mappings between environmental changes and software configurations by learning its dynamic environment and using its prior experience. In this paper, we propose a reinforcement learning-based approach to on-line planning in architecture-based self-management. This approach enables a software system to improve its behavior by learning the results of its behavior and by dynamically changing its plans based on the learning in the presence of environmental changes. The paper presents a case study to illustrate the approach and its result shows that reinforcement learning-based on-line planning is effective for architecture-based self-management.	online and offline;reinforcement learning;requirement;self-management (computer science);software system	Dongsun Kim;Sooyong Park	2009	2009 ICSE Workshop on Software Engineering for Adaptive and Self-Managing Systems	10.1109/SEAMS.2009.5069076	planning;reference architecture;software architecture;probability density function;error-driven learning;simulation;strategic planning;environmental change;software performance testing;computer science;systems engineering;knowledge management;software development;software design description;software engineering;configuration management;resource-oriented architecture;management;reinforcement learning;software metric;software system	SE	-64.89080578547147	21.20348216532226	113273
7758cbb0a6f409693335c04c4f54ff9dd0e9fb7a	big data software analytics with apache spark		At the beginning of every research effort, researchers in empirical software engineering have to go through the processes of extracting data from raw data sources and transforming them to what their tools expect as inputs. This step is time consuming and error prone, while the produced artifacts (code, intermediate datasets) are usually not of scientific value. In the recent years, Apache Spark has emerged as a solid foundation for data science and has taken the big data analytics domain by storm. We believe that the primitives exposed by Apache Spark can help software engineering researchers create and share reproducible, high-performance data analysis pipelines.  In our technical briefing, we discuss how researchers can profit from Apache Spark, through a hands-on case study.	apache spark;big data;cognitive dimensions of notations;data science;experimental software engineering;hands-on computing;pipeline (computing);software analytics	Georgios Gousios	2018	2018 IEEE/ACM 40th International Conference on Software Engineering: Companion (ICSE-Companion)	10.1145/3183440.3183458	computer science;raw data;spark (mathematics);systems engineering;data science;software;big data;empirical process (process control model);data analysis;software analytics	SE	-67.34505305180977	24.710284229103653	113302
3f4b290accedd9724c6bcb69643799f1294f5581	a comparison framework for runtime monitoring approaches (journal-first abstract)		This extended abstract summarizes our paper entitled “A Comparison Framework for Runtime Monitoring Approaches” published in the Journal on Systems and Software in vol. 125 in 2017 (https://doi.org/10.1016/j.jss.2016.12.034). This paper provides the following contributions: (i) a framework that supports analyzing and comparing runtime monitoring approaches using different dimensions and elements; (ii) an application of the framework to analyze and compare 32 existing monitoring approaches; and (iii) a discussion of perspectives and potential future applications of our framework, e.g., to support the selection of an approach for a particular monitoring problem or application context.	context (computing)	Rick Rabiser;Sam Guinea;Michael Vierhauser;Luciano Baresi;Paul Grünbacher	2018		10.1109/SANER.2018.8330238	software engineering;monitoring problem;application context;software;computer science	SE	-63.406274135454304	19.699527282287576	113486
32117965fdb6c63fbf347b98b50f6c257b406337	finding good design	off shore development;software legacy;agile development;roi	"""Martin Fowler was best described by Brian Foote as """"an intellectual jackal with good taste in carrion."""" He's not come up with great languages or tools, built major companies or found academic success. He's an author who has struggled with understanding what good design might be and how to communicate it. His books on patterns, refactoring, UML, and agile development reflect this question and his struggles to find an answer. He hasn't succeeded yet, but is happy to share his current position, lost in a maze of twisty objects, all alike."""	agile software development;book;brian;code refactoring;unified modeling language	Martin Fowler	2005		10.1145/1094855.1094858	return on investment;computer science;artificial intelligence;agile software development	HCI	-67.2219133370918	24.36453344109503	113583
a1c18ee0073e861a4cdefa947728b3b28ca38b5f	general message from the iwct workshop chairs	software;software testing;circuit faults;industries;optimization;conferences	None		Dimitris E. Simos;Rachel Tzoref	2017	2017 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)	10.1109/ICSTW.2017.33	real-time computing;computer science;engineering;software engineering;software construction;software testing;software walkthrough;computer engineering	Visualization	-63.797754679826994	26.002426833983304	113718
b6b5e1b1a8be53f825f6b5b559d20f832a653637	working time usage and tracking in a small software development organization	working time;software development	This paper represents a study of working time usage in a small software development organization. The purpose of the study was twofold. First, we wanted to understand how software developers in the organization work and second, we wanted to explore the attitudes they had toward different types of time tracking approaches. The aim was to provide practical suggestions of appropriate methods and tools for monitoring the developers’ time. According to the results, working with computer tools occupies the overwhelming majority of the working time although manual tasks and interruptions take some of the time. Even though the developers in the case company do not feel threatened by time monitoring, they do not either feel that monitoring is necessary, which is interesting and challenging from the project management viewpoint. We suggest that the case company should establish a lightweight, tool-based time tracking process and trains the developers to use the system and report their working time accurately.	software developer;software development process	Lasse Harjumaa;Tytti Pokka;Heidi Moisanen;Jukka Sirviö	2008			personal software process;verification and validation;real-time computing;software sizing;crowdsourcing software development;software project management;computer science;systems engineering;package development process;backporting;social software engineering;software development;software design description;software engineering;software construction;software analytics;lean software development;software deployment;software development process	SE	-69.30280678461412	25.281115169002014	113827
878308f0e4a51bbf222dd82bb59031605517f0af	case study on risk management practice in large offshore-outsourced agile software projects	software prototyping risk management;information systems;small teams;project ownership;it vendors;business model;performance improvement;performance improvement risk management practice information systems software engineering practices large offshore outsourced agile scrum software development project it vendors small teams collocated teams team members agile culture business model project ownership business knowledge development team distributed project teams team size characteristic;team members;business knowledge;development team;team size characteristic;risk management practice;large offshore outsourced agile scrum software development project;agile culture;software engineering practices;collocated teams;distributed project teams	Information systems, offshoring and outsourcing have resulted in significant changes to software engineering practices. In this study, the authors explore industry practices in risk management in a large offshore-outsourced Agile Scrum software development project. The project consisted of distributed teams from two different IT vendors. Agile method is suitable for small and collocated teams, where the team members have high level of knowledge and commitment. In this study, the authors explore the challenges to Agile culture and practices posed by offshore-outsourced business model (where project ownership is shared, and business knowledge of the development team is limited), distributed project teams and large team size characteristic of offshore projects. In this study, it was further examined how these challenges were managed; and how the best practices can be used to improved performance in the context of offshore-outsourced Agile projects in general.	agile software development;best practice;high-level programming language;information system;outsourcing;risk management;scrum (software development);software engineering	S. Sundararajan;M. Bhasi;Ponnuswamy Vijayaraghavan	2014	IET Software	10.1049/iet-sen.2013.0190	business model;team software process;extreme programming practices;agile usability engineering;systems engineering;knowledge management;scrum;agile software development;process management;project management 2.0;empirical process;lean software development;information system	SE	-68.61631537058463	20.235043988300706	113863
47987328eb832381b15575be738f34d8712ca035	five recommended practices for computational scientists who write software	software;testing;user interfaces military computing data structures computer interfaces writing software testing best practices guidelines computer architecture lifting equipment;data mining;software engineering;software engineering practice computational scientist software engineering technique handbook;software engineering practice;computational modeling;data structures;computational scientist;handbook;book reviews;software engineering technique;scientific software;user interfaces	Few software engineering techniques and approaches are specifically useful for computational scientists, and despite recent efforts, it could be many years before a consolidated handbook is available. Meanwhile, computational scientists can look to the practices of other scientists who write successful software.	computation;software engineering	Diane Kelly;Daniel Hook;Rebecca Sanders	2009	Computing in Science & Engineering	10.1109/MCSE.2009.139	computational science;personal software process;verification and validation;computing;software engineering process group;data structure;software verification;search-based software engineering;computer science;package development process;social software engineering;component-based software engineering;software development;software engineering;software construction;software testing;software walkthrough;user interface;software analytics;resource-oriented architecture;computational model;software deployment;software requirements;software system;software peer review	SE	-64.72502409999264	26.91062601311886	113926
0681b6f58cf264fe0bc6eef5780c08833a442007	modelling in information systems engineering when it works and when it doesn’t	informing science;formal method;profitability;information system	  This talk will reveal two secrets.    The first secret is that it is not due to lack of formal methods or inappropriate formalisms that roughly 50% of all implemented  system functionality is thrown away even before the roll out of the systems concerned – and 70% of the rest is unused after  some two years in production.        The second secret is that today, if you make a small effort, you will learn how to beat 80% of the consultants on the market  when it comes to modelling processes – just by a simple twist of perspective.        The aim of this talk is to make you less easy to fool and to give some hints concerning potentially profitable research directions  as well as some inspiration for further thinking. A basic assumption is that businesses as well as academia exist to create  value. After some 25 years of experience in commercial modelling, this leads to some questions concerning general aims and  basic paradigms in research and practice.        In my opinion, the academician has an extremely important role to play, but something seems to have gone wrong. The basic  reason might be that, paradoxically, the concept of information as well as the consequences of its proper definition seems  to be more or less completely disregarded in information science. Naturally, this leads to severe misconceptions concerning  the relevant problems to attack. As a further consequence, academic structures often represent a real mismatch with respect  to necessary interdisciplinary cooperation.        (Yes, yes, of course, there is a plethora of definitions of information.)      In my opinion, the practitioner in modelling has avoided responsibility and real influence by being too narrowly focused.  Modelling as an art has often deteriorated to simple description. While simple design instruments are used analytical instruments,  if they are at all known, are not. Moreover, in some cases, commercially developed methods are sometimes downright dangerous  to put in the hands of the normal analyst. Finally, inviting disaster, the modeller at large has limited abilities and instruments  for the necessary cooperation with management and business development representatives.        There are, however, some remedies available...    		Björn E. Nilsson	2004		10.1007/978-3-540-25975-6_1	formal methods;information engineering;computer science;systems engineering;knowledge management;management science;programming language;information system;profitability index	SE	-65.16461974504304	18.678950931009496	114127
188bfc4049a1bc01f1056b9e54fd5a76b7082563	simulating software development processes	software cost software development process simulation product development schedule rework consumer product market software market software bugs upgrading user testing software development organizations defect correction software release decisions business decisions sei capability maturity model software project management literature software estimation techniques software schedules;software cost estimation;project management;development process;software project management;simulation software;program testing;virtual machines;systems analysis;software development management software cost estimation virtual machines project management scheduling systems analysis program testing;scheduling;capability maturity model;software development;user testing;defect correction;software development management;programming scheduling capability maturity model costs product development consumer products computer bugs software testing project management;product development	One of the main factors affecting any product development schedule is rework. In the consumer product market, the risk of rework is often measured against the need to get to market quickly. This frequently happens in the software market as well; products are released with known bugs and then upgraded after user testing. Therefore, software development organizations may choose to limit the iterations of defect correction to meet schedules or control costs. The decision to release software after a certain point is a business decision, and there is little written about business decisions in any software-related literature, including the SEI's Capability Maturity Model. A quick review of software project management literature suggests that rework is implicit in software estimating techniques, but is not explicit. The amount of rework and the manner in which it is treated are very important factors in determining software schedules and cost.	software development	Gregory A. Hansen	1996	IEEE Computer	10.1109/2.481468	project management;systems analysis;long-term support;team software process;software quality management;software sizing;simulation software;software project management;computer science;virtual machine;package development process;software development;operating system;software engineering;software deployment;scheduling;software quality control;capability maturity model;software development process;new product development;software metric;software quality analyst;avionics software	Visualization	-65.88650800207705	28.40079629618466	114395
f844380e57569b9d5e0f42d2f7ee8c3e43389d92	requirement management in agile software environment		Understanding and fulfilling each individual customer requirements has been recognized as a pressing challenge for software industries. To produce high quality software products and meeting stakeholder’s requirement is a major challenge in software requirement. Poor requirements and changes to requirements are one of the causes for project overrun and quality issues in the delivered software. The paper discusses about how the different agile methodologies follow requirement management steps in a project. It tries to give an idea to those organizations who undergo projects with frequent change in the requirements so that they can produce quality products and survive in the market strategy. © 2015 The Authors. Published by Elsevier B.V. Peer-review under responsibility of organizing committee of The 2015 International Conference on Soft Computing and Software Engineering (SCSE 2015).	agile software development;customer relationship management;display resolution;organizing (structure);requirement;soft computing;software engineering	Nomi Baruah	2015		10.1016/j.procs.2015.08.414	p-modeling framework;personal software process;verification and validation;requirement prioritization;agile unified process;extreme programming practices;agile usability engineering;software project management;software development;requirement;release management;software construction;software as a service;agile software development;empirical process;lean software development;software development process	SE	-67.90419804823667	22.90116615063678	114506
3e3507567f5de5cacb893dab536ee14851ba4762	analysis of a deployed software	software analysis;software testing;profiling;field data;deployed software	Analyzing a deployed software provides a means to characterize and leverage the software's runtime behavior as it is employed by its intended users. Preliminary studies have shown that leveraging the information obtained from the field provides engineers an opportunity to improve their software testing activities. The analysis of a deployed software can be performed in three stages: (1) the analysis to determine, before the software is deployed, where the instrumentation probes should be inserted into the software and what information that they should capture, (2) the analysis to determine when the field data should be sent back to the company during deployment, and (3) the analysis to leverage the field information after deployment. To make the analysis activities more feasible, we need to take into consideration that there are distinct characteristic differences between the development and the deployed environment. Deployed environment allows for less overhead,provides less control for the engineers, and requires highlyscalable techniques due to the high volume of information. Hence, the existing approaches for in-house analysis may become ineffective, inefficient, or even useless when they are directly applied to the deployed environment. Existing approaches for analyzing deployed software also need to be more aware that a technique in one analysis stage may affect the performance of a technique in other analysis stage. This research proposal details the challenges that arise when analyzing a deployed software and seeks to develop a set techniques to address these challenges that can be applied to each stage or across the analysis stages.	overhead (computing);software deployment;software testing	Madeline Diep	2007		10.1145/1287624.1287719	reliability engineering;long-term support;verification and validation;team software process;software sizing;computer science;engineering;package development process;backporting;software reliability testing;software framework;software development;software design description;software analysis pattern;software engineering;software construction;data mining;profiling;software testing;software walkthrough;software analytics;software deployment;computer security;software metric;avionics software	SE	-64.09448067910324	31.646837014576835	114811
9a364aedc06b9a827504dfe74444ae09aa37253e	a tutorial on simulation conceptual modeling		Conceptual modeling is the abstraction of a simulation model from the part of the real world it is representing; in other words, choosing what to model, and what not to model. This is generally agreed to be the most difficult, least understood, but probably the most important activity to be carried out in a simulation study. In this tutorial we explore the definition, requirements and approach to conceptual modeling. First we ask ‘where is the model?’ We go on to define the term ‘conceptual model’, to identify the artefacts of conceptual modeling, and to discuss the purpose and benefits of a conceptual model. In so doing we identify the role of conceptual modeling in the simulation project life-cycle. The discussion then focuses on the requirements of a conceptual model, the approaches for documenting a conceptual model, and frameworks for guiding the conceptual modeling activity. One specific framework is described and illustrated in more detail. The tutorial concludes with a discussion on the level of abstraction.	requirement;simulation;software documentation	Stewart Robinson	2017	2017 Winter Simulation Conference (WSC)	10.1109/WSC.2017.8247815	conceptual model;systems engineering;computer science	EDA	-63.84127935529063	18.69844853099647	114972
b69e3dcc2facbb6faffe5ec9e7f2dcea167473bc	thinking tracks for multidisciplinary system design	architecting;systems design;systems thinking;application	Systems engineering is, for a large part, a process description of how to bring new systems to existence. It is valuable as it directs the development effort. Tools exist that can be used in this process. System analysis investigates existing and/or desired situations. However, how to create a system that instantiates the desired situation depends significantly on human creativity and insight; the required human trait here is commonly called systems thinking. In literature, this trait is regularly used, but information on how to do systems thinking is scarce. Therefore, we have introduced earlier twelve thinking tracks that are concrete and help system designers to make an optimal fit between the system under design, the identified issue, the user, the environment and the rest of the world. The paper provides the scientific rationale for the thinking tracks based on literature. Secondly, the paper presents three cases of application, leading to the conclusion that the tracks are usable and effective.	design rationale;experiment;fits;mind;organizing (structure);redundancy (engineering);system analysis;systems design;systems engineering;whole earth 'lectronic link	G. Maarten Bonnema;Jan F. Broenink	2016	Systems	10.3390/systems4040036	simulation;computer science;critical systems thinking;systems thinking;systems design	SE	-64.96600345002334	18.68375433119116	115352
76e9eeb602f311add21c466ef422a723a0723bf7	toward the use of blog articles as a source of evidence for software engineering research		Background: Blog articles have potential value as a source of practitioner-generated evidence to complement already accepted sources of evidence in software engineering research e.g. interviews and surveys. To be valuable to research, a method for extracting the high quality articles from the vast quantity available needs to be developed. Objective: To better define the benefits and challenges, scope the problem, develop a set of criteria for evaluating blog articles to be used in the method, and propose research questions. Method: We conducted a two-phase pilot study, using a preliminary set of criteria, to explore the challenges of classifying blog articles. We analyse credibility criteria that have been used in previous research, and cross reference those criteria with previous research in evidence-based software engineering. Results: Based on our analysis, we decide that blog articles need to be rigorous, relevant, well written and experience based for them to be considered credible to researchers. Conclusion: Our work provides an overview of the problem domain, as well as presenting criteria and suggested measurements for these criteria. These can be used by others to find blog articles of potential value to their research.	blog;compiler;cross-reference;display resolution;machine learning;problem domain;software engineering;two-phase locking;warez	Ashley Williams;Austen Rainer	2017		10.1145/3084226.3084268	software engineering;management science;argumentation theory;computer science;data mining;credibility;problem domain	SE	-73.0260855766072	24.893101967558767	115461
6f9fb3ba5a114439b8ee500096c66a620f96cbc7	software quality management and iso 9000 implementation	software quality management;iso 9000;maintenance cost;quality;software industry;computer software;quality standard;software quality	The software industry has matured into a global business with software products and applications growing in number, complexity, and market importance. Global sourcing and software production and operations sharing are becoming the industry standard. At the same time, the marketplace has become less tolerant of poor‐quality products and hidden maintenance costs. Reviews various existing standards and frameworks and discusses the massive consolidation and coordination efforts currently ongoing for the purpose of developing international quality standards. Also proposes an eight‐step framework that puts all 29 clauses required by ISO 9001 for certification implementation in the software industry into clusters for more efficient management. Warns, however, that becoming ISO 9000 registered is only the first step to achieving consistent software quality.	software quality management	Y. Helio Yang	2001	Industrial Management and Data Systems	10.1108/EUM0000000005821	quality control;long-term support;verification and validation;software quality management;iso/iec 12207;iso 9000;software project management;systems engineering;package development process;marketing;social software engineering;operations management;software development;software engineering;software construction;software walkthrough;software deployment;software quality control;software quality;software metric;software quality analyst;software peer review	DB	-66.5889365355559	21.685097403356014	115503
b3333fd43297a0b728f180e2e3e8c92096c99b00	td 2014: workshop on technical debt in a world of big data and big teams	agile development;technical debt	"""Technical debt is an unavoidable part of software development in today's fast-paced market, but it is ignored by many of the people who should care about it most. In large systems, a portion of the accumulating technical debt is just """"sloppy design"""" caused by schedule pressure and other project forces. But the most important part of technical debt is directly related to project size and data complexity. How much technical debt is about large development teams and geographical distribution? How do current """"big data"""" techniques (Hadoop, NoSQL, parallel algorithms, MapReduce) relate to technical debt issues? This workshop explored strategies for understanding the impact of technical debt. If we believe that technical debt is an important issue in long-term software product development, do we have ways to keep the technical debt from causing development gridlock?"""	big data;technical debt	Dennis Mancl;Steven Fraser	2014		10.1145/2660252.2663599	simulation;computer science;technical debt;agile software development	NLP	-69.21676894840486	23.907329154180132	115523
65a1ee06dd4d679957ad21b0f564f035c53b8352	quantitative cmmi assessment for offshoring through the analysis of project management repositories	offshore outsourcing;software process improvement;data gathering;project manager;best practice;distributed team;capability maturity model integration;software development;quantitative analysis;work in progress;software process	The nature of distributed teams and the existence of multiple sites in offshore software development projects pose a challenging setting for software process improvement. Often, the improvement and appraisal of software processes is achieved through a turnkey solution where best practices are imposed or transferred from a company’s headquarters to its offshore units. In so doing, successful project health checks and monitoring for quality on software processes requires strong project management skills, well-built onshore-offshore coordination, and often needs regular onsite visits by software process improvement consultants from the headquarters’ team. This paper focuses on software process improvement as guided by the Capability Maturity Model Integration (CMMI) and proposes a model to evaluate the status of such improvement efforts in the context of distributed multi-site projects without some of this overhead. The paper discusses the application of quantitative CMMI assessment through the collection and analysis of project data gathered directly from project repositories to facilitate CMMI implementation and reduce the cost of such implementation for offshore-outsourced software development projects. We exemplify this approach to quantitative CMMI assessment through the analysis of project management data and discuss the future directions of this work in progress.	agile software development;best practice;capability maturity model integration;exemplification;overhead (computing);software development process;turnkey	Thanwadee Sunetnanta;Ni-On Nobprapai;Olly Gotel	2009		10.1007/978-3-642-02987-5_6	project management;standard cmmi appraisal method for process improvement;personal software process;long-term support;verification and validation;team software process;software engineering process group;leancmmi;software project management;systems engineering;quantitative analysis;engineering;knowledge management;capability maturity model integration;software development;software engineering;work in process;software construction;management;software development process;best practice;data collection;software peer review	SE	-68.89850988383162	21.106310231732262	115575
432d2746b34d81c0b7eeab85066afdaea170a926	reasons for software effort estimation error: impact of respondent role, information collection approach, and data analysis method	performance evaluation software effort estimation error information collection approach data analysis software development statistical analysis project management interviews cost estimation project evaluation software review;index terms cost estimation;software cost estimation;project management;performance evaluation index terms cost estimation review and evaluation;performance evaluation;project manager;estimation error data analysis project management statistical analysis computer errors information analysis programming error analysis information management;data collection;software effort estimation;software performance evaluation;data analysis methods;indexing terms;software performance;experience report;data analysis;statistical analysis;software effort estimation error;software development;error handling;interviews;estimation error;economics;project evaluation;cost estimation;review and evaluation;software review;cost benefit analysis;software development management;software performance evaluation cost benefit analysis error handling project management software cost estimation software development management;software economics;information collection approach	This study aims to improve analyses of why errors occur in software effort estimation. Within one software development company, we collected information about estimation errors through: 1) interviews with employees in different roles who are responsible for estimation, 2) estimation experience reports from 68 completed projects, and 3) statistical analysis of relations between characteristics of the 68 completed projects and estimation error. We found that the role of the respondents, the data collection approach, and the type of analysis had an important impact on the reasons given for estimation error. We found, for example, a strong tendency to perceive factors outside the respondents' own control as important reasons for inaccurate estimates. Reasons given for accurate estimates, on the other hand, typically cited factors that were within the respondents' own control and were determined by the estimators' skill or experience. This bias in types of reason means that the collection only of project managers' viewpoints will not yield balanced models of reasons for estimation error. Unfortunately, previous studies on reasons for estimation error have tended to collect information from project managers only. We recommend that software companies combine estimation error information from in-depth interviews with stakeholders in all relevant roles, estimation experience reports, and results from statistical analyses of project characteristics	cost estimation in software engineering;error detection and correction;error message;mean squared error;software development effort estimation	Magne Jørgensen;Kjetil Moløkken-Østvold	2004	IEEE Transactions on Software Engineering	10.1109/TSE.2004.103	project management;reliability engineering;computer science;data mining;management science;data analysis;statistics	SE	-66.60326976338747	30.48541302899822	115689
44ecbfb17d7f623caee4c50169e622a30f28679c	software quality and reliability	compilers;program family;semantic processing;alternating semantic evaluator;attribute grammar evaluators	Has the institutionalization of software quality and reliability within industry and government improved software products and systems? And, if so, can this improvement be meaningfully quantified and the recipients of its benefits identified?  There is no simple answer to these questions since there may be no quantitative proof that things have improved. However, on the positive side it can be said that software quality has been improved because of: improvements in software technology, increased concern of government and industry resulting in the establishment of quality organizations, increased incidence of formal software quality audits and reviews, improved software documentation, and the use of independent V and V contractors. On the negative side, there are some major obstacles in assessing the improvement or implementation of software quality, among them is the lack of techniques and metrics for measuring software quality.  This session will address the above questions, in addition to the problems and accomplishments in software quality assurance from both the government and industry viewpoints, with an emphasis on potential standards and testing criteria applicable on a government-wide basis or within industry as a whole.  The principal elements of a quality plan for embedded software will also be highlighted by the panelists. Specific attention will be paid to the need for a well-ordered development methodology and to the review cycle attending it; to the array of hardware and software resources that may be required to assure software quality; and to the manner in which configuration control can be maintained. These matters will be discussed within the context of a synthesis of the disciplines of Software Engineering and Quality Assurance. Finally, experiences with Higher Level Language (HLL) compiler validation will be used as concrete examples to give the panel focus.	compiler;configuration management;embedded software;high-level programming language;incidence matrix;software documentation;software engineering;software quality assurance	James Stringer;Robert Dunn;Dennis Fife	1978		10.1145/800127.804109	software security assurance;reliability engineering;medical software;verification and validation;software quality management;software engineering process group;software sizing;computer science;systems engineering;package development process;software development;software design description;software engineering;software construction;software walkthrough;software deployment;software quality control;software quality;software metric;software quality analyst;avionics software;software peer review	SE	-67.0068274475918	24.68886781021733	115858
786d6600a701166fa7ea11936a53d9f9a9b4fe70	predicting maintenance effort with function points	function points;software metrics;point estimation;software cost estimation;analogy based estimates;data gathering;software maintenance;analogy based estimation;software metrics software cost estimation software maintenance;user view point;function point;function point analysis;data analysis;predictive maintenance;effort estimation;corrective factors;user view point analogy based estimates corrective factors data analysis function point analysis size software component software maintenance effort prediction system functionality;software component;maintenance function points;software maintenance effort prediction;point of view;size;article in monograph or in proceedings;change analysis;maintenance effort prediction;system functionality	Function Point Analysis (FPA) is a well-known method to measure the functionality of a system, from the user’s point of view. Both Albrecht ’s original model and a local variant we studied assume that eflort is primarily related to the size of a change. Analysis of data gathered on a major system over a period of18 months does not confrm this relation. Rathel; our data suggests that the size of the component to be changed has a much larger impact on effort than the size of the change itself: Furthermore, the various corrective factors of the function point model do not help to improve effort estimates in the environment we studied. Finally, we found that expert estimates outpevom the function point estimates, while analogy-based estimates slightly outperform the expert estimates.	complexity;f-spot;fits;fabric application interface standard;function point;katherine albrecht	Frank Niessink;Hans van Vliet	1997		10.1109/ICSM.1997.624228	reliability engineering;computer science;systems engineering;engineering;function point;software engineering;data mining	ML	-65.93575515358194	30.974854271767278	115915
621cc0e61b733e8a3ca76ae0808b2eebdcfbafca	when product managers gamble with requirements: attitudes to value and risk	prospect theory;decision maker;software engineering;production management;quality requirement;requirement engineering;business administration;programvaruteknik;perceived value;foretagsekonomi;product development	[Context and motivation] Finding a balance between commercial (customer specific, market pull and external quality requirements) and internal quality requirements is a recognized challenge in market driven software product development (MDSPD). In order to address this challenge it is important to understand the preferences and biases influencing decision makers selecting requirements for software releases. [Question/problem] Prospect theory has been successfully applied to many disciplines. Applying it to MDSPD suggests decision makers will avoid risk when selecting between commercial requirements, take risk with internal quality requirements, and prefer commercial requirements over internal quality requirements in order to maximize their perceived value. This paper seeks to investigate this claim. [Principal ideas/results] This paper presents an experiment investigating whether the biases proposed by prospect theory can be seen operating in MDSPD requirements engineering (RE). The results indicate risk avoidance when dealing commercial requirements, while greater risk is taken when dealing with internal quality requirements. [Contribution] As this is the first paper to use prospect theory to explain requirements selection decisions, it presents opportunity to educate people in the biases they bring to the RE process, and facilitate the creation of strategies for balancing the different requirements types.	requirement	Nina Dzamashvili-Fogelström;Sebastian Barney;Aybüke Aurum;Anders Hederstierna	2009		10.1007/978-3-642-02050-6_1	prospect theory;decision-making;requirements management;market requirements document;requirement prioritization;economics;business requirements;systems engineering;engineering;operations management;requirement;software engineering;requirements elicitation;management science;requirements engineering;management;non-functional requirement;new product development;vision document	SE	-70.13351220257695	22.87635679594326	115952
d626e46bc7d274131f6f27b3a238a24337c4c20e	design for change: one step at a time	design for change	Welcome to the first issue of 2007. Last year, it proved to be tremendous in terms of the number of good quality articles submitted to SPIP. This New Year, we expect it to be even better and hope to continue to build on our success. We have received excellent feedback from readers. To improve further, we need more feedback from readers. We have excellent articles the scheduled to be published this year, and a healthy, continuous stream of new articles means that the future of SPIP is looking to be very promising. This issue, once again, contains a mixture of regular and themed articles. The themed articles represent a selection of reworked and extended articles submitted to the 6th Workshop on Business Process Modelling, Design and Support. The underlying theme of the articles is ‘Design for Flexibility’: The need to ensure that systems are flexible enough to reflect and accommodate changes in business processes. Change pervades all aspects of life. With advances in technology, we seem to have become accustomed to the acceleration in terms of the demands and expectations for change. Such trends include more competitive environments, more demanding time-to-market, delivery on demand and various lean processes. The trends have resulted in more dynamic development patterns that are responsive to change, thereby placing similar demands on software process improvement. The regular articles in this issue are also concerned with the development	business process;software development process	Darren Dalcher	2007	Software Process: Improvement and Practice	10.1002/spip.325	engineering	SE	-67.47166004351844	23.39086121966493	116014
6108be9695c1dd9ca8b0d1afa23bbe520c55956c	decisive factors for the success of the carologistics robocup team in the robocup logistics league 2014	public records;websearch;rwth publications	The RoboCup Logistics League is one of the youngest applicationand industry-oriented leagues. Even so, the complexity and level of difficulty has increased over the years. We describe decisive technical and organizational aspects of our hardware and software systems and (human) team structure that made our successes in 2014 possible.	computer hardware;domain-specific language;hackathon;logistics;organizing (structure);simulation;software system;system integration	Tim Niemüller;Sebastian Reuter;Daniel Ewert;Alexander Ferrein;Sabina Jeschke;Gerhard Lakemeyer	2014		10.1007/978-3-319-18615-3_13	public records;simulation;computer science	AI	-66.0235399782774	21.259111025578754	116049
4ae55c5aeb332ac4821e1a8d87a07a8fb77205ba	generating a domain-specific inspection method through an adaptive framework		Many recent innovations and inventions have contributed to rapid technological development, which in turn have produced a wide variety of products that have had a major impact on many businesses in several different domains. These products have their own contextual attributes that have made their usability evaluation, by using traditional usability evaluation methods (UEMs), all the more critical. Almost all previous usability studies have used the Heuristic Evaluation (HE) and User Testing (UT) methods; however, the majority of such studies have described these methods as being not directly applicable to the product being tested, not directly related to the context of the tested product, and not able to identify specific areas and types of usability problems. Furthermore, the lack of a methodological framework that can be used systematically to generate a domain-specific inspection method, which can then be used to assess the usability for a product in any chosen domain and to improve the usability assessment process, represents a missing area in usability testing.#R##N#Thus, the goal of this research is to generate a domain-specific inspection evaluation method that does not involve users in an actual testing session, i.e. one that is applied by only experts. To reach this goal, firstly, a systematic adaptive framework is presented, called Domain Specific Inspection (DSI), which is characterized as being pertinent to the context and specific target of a chosen domain. This framework is designed to generate a method that avoids the drawbacks of having to use both HE and UT, although it combines their advantages. In addition, this framework assists researchers as it combines feedback from both expert evaluators and potential users in the chosen domain in order to create a focused method. Secondly, this research seeks to validate the adaptive framework practically by generating a DSI method for assessing the usability of selected products. In this regard, websites are chosen as the targeted product, and two experiments are conducted; the first examines the utility of the generated DSI method on the educational domain. The second examines another generated DSI method on the social network domain. In both experiments, the DSI methods are tested intensively through rigorous validation methods and a number of usability metrics to verify the extent to which it achieves the identified goals, needs and requirements that the methods were originally developed to address, and to identify which problems are identified by UT but not identified by HE and/or DSI, and vice versa. Also, an investigation into whether it is essential to conduct the DSI method in conjunction with UT or HE will be undertaken. Furthermore, the roles and numbers of evaluators (together with their types) and users will be examined.#R##N#The results show that the adaptive framework is able to generate a DSI method that can be used to generate ideas from the different perspectives of multidisciplinary teams in order to create engaging user experiences and to facilitate interactive design. This method enables the discovery of a larger number of serious problems than UT and HE. In addition, it provides optimal results with regard to the identification of comprehensive usability problem areas, and it is more efficient and effective than UT and HE, with minimum input in terms of cost and time. Furthermore, it is able to improve the evaluator performance; thus, the results of the single evaluators, who used the DSI method, provided results that approached or outperformed the effectiveness of the double evaluators, who used HE. Consequently, few evaluators are needed to find a majority of the usability problems if DSI is used.	domain-specific language	Roobaea Alrobaea	2015			usability goals;pluralistic walkthrough;web usability;cognitive walkthrough;simulation;computer science;systems engineering;data mining;heuristic evaluation;usability inspection	Vision	-73.28384372292548	23.550918212763282	116131
108f91acc309d1b31336124bec48657a7736737b	how reliable are systematic reviews in empirical software engineering?	software reviews;systematic review reliability;software cost estimation;systematic review;research instrument;software cost estimation systematic review reliability empirical software engineering research instrument;systematics;empirical software engineering;meta analysis;software engineering;research method;software engineering instruments robustness best practices stability costs mathematics computer science;research paper;medical services;best practices;software reviews software cost estimation;robustness;cost estimation empirical software engineering meta analysis systematic review;cost estimation;context	BACKGROUND-The systematic review is becoming a more commonly employed research instrument in empirical software engineering. Before undue reliance is placed on the outcomes of such reviews it would seem useful to consider the robustness of the approach in this particular research context. OBJECTIVE-The aim of this study is to assess the reliability of systematic reviews as a research instrument. In particular, we wish to investigate the consistency of process and the stability of outcomes. METHOD-We compare the results of two independent reviews undertaken with a common research question. RESULTS-The two reviews find similar answers to the research question, although the means of arriving at those answers vary. CONCLUSIONS-In addressing a well-bounded research question, groups of researchers with similar domain experience can arrive at the same review outcomes, even though they may do so in different ways. This provides evidence that, in this context at least, the systematic review is a robust research method.	experimental software engineering;systematic review	Stephen G. MacDonell;Martin J. Shepperd;Barbara A. Kitchenham;Emilia Mendes	2010	IEEE Transactions on Software Engineering	10.1109/TSE.2010.28	reliability engineering;meta-analysis;systematic review;computer science;systems engineering;data mining;systematics;programming language;management;cost estimate;robustness;best practice	SE	-68.12160148252104	30.578868105117458	116787
e43bf155180d4b23202e970f82162b36c0c6d851	a prototype tool for quper to support release planning of quality requirements	release planning;futures market;formal specification;empirical;production management;quper;quality requirement;planning prototypes companies usability adaptation models industries;software quality formal specification;empirical quper quality requirements release planning;datavetenskap datalogi;quality requirements;software product vendor prototype tool quper release planning quality requirements software intensive incremental products;software quality	Release planning plays an important role for the success of a software product vendor that develops software-intensive incremental products. It is important that the software product is released to the market at the right time, and offers higher quality than the competitors. However, an especially challenging problem for a software product vendor is to set the right quality target in relation to future market demands and competitor products. In this paper, we present a prototype for QUPER, a special-purpose tool for supporting release planning of quality requirements. The applicability of the QUPER prototype tool is demonstrated through academic and industrial evaluations. The study showed that the tool provides a clear overview of the current market situation by the generated roadmaps, and to reach an alignment between practitioners, e.g., product managers and developers, of what level of quality is actually needed.	breakpoint;plan;prototype;requirement;usability	Richard Berntsson-Svensson;Pontus Lindberg Parker;Björn Regnell	2011	2011 Fifth International Workshop on Software Product Management (IWSPM)	10.1109/IWSPM.2011.6046204	reliability engineering;software quality management;systems engineering;operations management;business;software quality control	SE	-67.39734535607332	22.626945195835084	116799
836150a3591e016ea677d6c9f5da0494792650f9	yp and urban simulation: applying an agile programming methodology in a politically tempestuous domain	town and country planning;environmental impact;testing traffic control environmental economics heart layout computational modeling computer simulation computer science documentation transportation;urban land use;simulation;politically tempestuous domain yp yare programming agile programming methodology software status indicator software development cycle urbansim urban simulation system public deliberation stakeholder real traffic light;object oriented programming;development process;software engineering;agile development;public domain software;program testing;agile methodologies;software engineering town and country planning program testing simulation object oriented programming public domain software	YP is an agile programming methodology that has evolved over the past 15 years. Many of its features are common to other agile methodologies; its novel features include using a highly visible, physical software status indicator (a real traffic light), and a well-defined nested set of development cycles. It is also an exceptionally open process, with the current status of the development process visible to the customers, as well as the code and documentation. We are using YP in developing the software for UrbanSim, a sophisticated simulation system for modeling urban land use, transportation, and environmental impacts over periods of 20 or more years under alternate possible scenarios. Our purpose in developing UrbanSim is to support public deliberation and debate on such issues as building a new light rail system or freeway, or changing zoning or economic incentives, as well as on broader issues such as sustainable, livable cities, economic vitality, social equity, and environmental preservation. The domain of use is thus politically charged, with different stakeholders bringing strongly held values to the table. Our goal is to not favor particular stakeholder values in the simulation or its output, but rather to let different stakeholders evaluate the results in light of what is important to them. There are several implications of this for the development process. First, having credible, reliable code is important — and further, both the code itself and the development process that produced it should be open and inspectable, not a black box. Second, to allow us to respond quickly to different stakeholder values and concerns, a flexible agile development process is required. Preprint – to appear in	agile software development;black box;bug tracking system;continuous integration;documentation;email;extreme programming practices;freeway;iteration;miranda;openness;pair programming;prototype;requirement;simulation;software development process;software project management;test-driven development	Bjørn N. Freeman-Benson;Alan Borning	2003		10.1109/ADC.2003.1231447	simulation;agile unified process;extreme programming practices;agile usability engineering;systems engineering;engineering;operations management;software development;requirement;agile software development;empirical process;lean software development;software development process	HCI	-66.31166270631597	21.852720009528962	116947
5eb72c3fd8cdcd7f673949c71cc3311a9b060e26	enterprise architecture institutionalization and assessment	enterprise architecture frameworks;assessment of enterprise architecture institutionalization;investments;measurement;standards organizations;it architectures;enterprise architecture frameworks enterprise architecture institutionalization it architectures business environment;computer architecture;business environment;enterprise architecture process;software architecture;software architecture enterprise resource planning organisational aspects;enterprise resource planning;enterprise architecture institutionalization;assessment of enterprise architecture institutionalization enterprise architecture frameworks enterprise architecture process;organizations;standards organizations organizations computer architecture investments architecture measurement;architecture;enterprise architecture;organisational aspects	The topic of enterprise architecture (EA) has been gaining significant attention from both academia and industry due to the inefficiency of current IT architectures to cope with rapid changes in business environment. In order to turn existing EA into efficient and agile one, it is necessary to institutionalize an EA based on well-established enterprise architecture frameworks (EAFs) into the enterprise. In this paper, we propose EA institutionalization processes and its metric based assessment for implemented EA based on the currently available EA frameworks. In the EA processes, we define institutionalization strategies specific to organizations’ goals, target architecture based on their baseline architecture, and transition plan for institutionalization.	agile software development;baseline (configuration management);enterprise architecture framework	Hyun-Kyung Song;Yeong-Tae Song	2010	2010 IEEE/ACIS 9th International Conference on Computer and Information Science	10.1109/ICIS.2010.127	enterprise architecture framework;systems engineering;knowledge management;architecture domain;software engineering;enterprise architecture management;solution architecture;enterprise architecture;business;view model;enterprise life cycle	DB	-68.89028514122572	19.591680250796387	117045
5080df36bec4017db692a363b42ae68683aca44b	introducing continuous delivery of mobile apps in a corporate environment: a case study		Software development is conducted in increasingly dynamic business environments. Organizations need the capability to develop, release and learn from software in rapid parallel cycles. The abilities to continuously deliver software, to involve users, and to collect and prioritize their feedback are necessary for software evolution. In 2014, we introduced Rugby, an agile process model with workflows for continuous delivery and feedback management, and evaluated it in university projects together with industrial clients.  Based on Rugby's release management workflow we identified the specific needs for project-based organizations developing mobile applications. Varying characteristics and restrictions in projects teams in corporate environments impact both process and infrastructure. We found that applicability and acceptance of continuous delivery in industry depend on its adaptability. To address issues in industrial projects with respect to delivery process, infrastructure, neglected testing and continuity, we extended Rugby's workflow and made it tailorable.  Eight projects at Capgemini, a global provider of consulting, technology and outsourcing services, applied a tailored version of the workflow. The evaluation of these projects shows anecdotal evidence that the application of the workflow significantly reduces the time required to build and deliver mobile applications in industrial projects, while at the same time increasing the number of builds and internal deliveries for feedback.	agile software development;continuous delivery;feedback;mobile app;outsourcing;process modeling;release management;scott continuity;software evolution	Sebastian Klepper;Stephan Krusche;Sebastian Peters;Bernd Brügge;Lukas Alperowitz	2015	2015 IEEE/ACM 2nd International Workshop on Rapid Continuous Software Engineering		systems engineering;engineering;knowledge management;software evolution;operating system;software engineering;release management;devops;agile software development;configuration management;management	SE	-68.06085888597342	20.13916383072981	117388
d8d47520911bbb08b97fa1d248938fbbbcef8c01	predicting numbers of errors using software science	probability distribution mixture;student project;decreasing failure rate;reliability growth;software failure rate;pareto distribution;software errors;design errors;model fitting;software faults;software reliability;software mttf;programming debugging modelling;design debugging	An earlier paper presented a model based on software science metrics to give quantitative estimate of the number of bugs in a programming project at the time validation of the project begins. In this paper, we report the results from an attempt to expand the model to estimate the total number of bugs to expect during the total project development. This new hypothesis has been tested using the data currently available in the literature along with data from student projects. The model fits the published data reasonably well, however, the results obtained using the student data are not conclusive.		Linda M. Ottenstein	1981	SIGMETRICS Performance Evaluation Review	10.1145/1010627.807924	verification and validation;regression testing;real-time computing;software sizing;computer science;software reliability testing;pareto distribution;software construction;data mining;software testing;software quality;software metric;statistics	SE	-62.95466999233601	31.9414935911308	117845
8c46c0912ff1dfe5f7b80ae3a04c36bf9d63affb	combining software engineering education and empirical research via instrumented real-client team project courses	software;real client team project courses;software engineering;software engineering education;multiyear se project software engineering education empirical research real client team project courses;computer science education;tutorials;educational courses;spirals;unified modeling language;modeling;multiyear se project;software engineering computer science education educational courses;software engineering software unified modeling language modeling spirals tutorials education;empirical research	Real-client, team project courses provide excellent opportunities for performing empirical research in software engineering (SE). Compared to empirical research on large, multi-year SE projects, a course with several team projects per year is the SE research equivalent of the fruit fly in species evolution research. Although their predictive power for large-project SE is more suggestive than definitive, the research results generally provide useful contributions to human knowledge in the SE area.	software engineering	Barry W. Boehm;Supannika Koolmanojwong	2014	2014 IEEE 27th Conference on Software Engineering Education and Training (CSEE&T)	10.1109/CSEET.2014.6816808	personal software process;team software process;software engineering process group;software project management;computer science;systems engineering;knowledge management;social software engineering;software development;software engineering;software construction;software walkthrough	SE	-65.96482466025058	26.472780924753557	117986
7b1592460f7282039e0cd9b369adbd9f63a99e2e	a survey of unit testing practices	developpement logiciel;survey unit testing test practice;software testing;software process improvement program testing;software process improvement;unit testing;computer and information science;software testing telecommunications automatic testing system testing banking medical services road transportation information systems books software standards;spin;natural sciences;unit testing practices;program testing;desarrollo logicial;software development;datavetenskap datalogi;spin unit testing practices software process improvement network;software process improvement network;focus group discussion;computer science;test practice;survey	Unit testing is testing of individual units or groups of related units. What are a company's typical strengths and weaknesses when applying unit testing? Per Beremark and the author surveyed unit testing practices on the basis of focus group discussions in software process improvement network (SPIN) and launched a questionnaire to validate the results. This survey is an indication of unit testing in several companies. You can use the questionnaire at your own company to clarify what you mean by unit testing, to identify the strengths and weaknesses of your unit testing practices, and to compare with other organizations to improve those practices	focus group;spin;software development process;unit testing	Per Runeson	2006	IEEE Software	10.1109/MS.2006.91	reliability engineering;computer science;systems engineering;software development;focus group;software engineering;software testing;unit testing;spin	SE	-65.71494496520397	27.89664825159548	118325
67f8942951d786a2d9f08a586f20d01e1c88864e	foreword of the thematic track quality aspects in agile methods	software;testing;information and communication technology;business;planning;security;context	There is no doubt that agile methods have become mainstream and with their increased use unanswered questions start to appear: How do we address cross-cutting concerns when software is developed vertically? Does value prioritization lead to increases in technical debt by promoting feature development over refactoring? Isn’t the reticence to write initial specifications on the premise of change an invitation to unnecessary change? As agile development matures answers, albeit partial, responses start to appear. The recurring themes in this year presentations are not whether agile is good or bad, better or worse,	agile software development;code refactoring;cross-cutting concern;technical debt	Eduardo Miranda;João M. Fernandes	2016	2016 10th International Conference on the Quality of Information and Communications Technology (QUATIC)	10.1109/QUATIC.2016.027	planning;information and communications technology;simulation;computer science;systems engineering;engineering;information security;operations management;software engineering;software testing;management	SE	-68.40019208932965	23.43818794842369	118412
a194e04f99ae1e99272aa7e945c86978b6a4adba	a simple framework for project communications		According to our research, communication is the most important area in managing software projects. Analyzing and improving communication practices may help us succeed in software projects. Developing frameworks and models of project communications is an important step in guiding us to conduct studies in project communications and project management. In this study, we developed a simple framework for project communications. The components of this simple framework include stakeholders, project information, communication capabilities, and project environment. Using this framework we were able to develop a project communications effectiveness measure as a part of project management effectiveness metric for software projects. This paper describes this simple framework.		Kadir Alpaslan Demir	2010			engineering;systems engineering	SE	-68.68845867520938	20.161890710342515	118434
74f6ab060577803045d52a272a20a10e32d6e10b	software development and system testing techniques	software development	Microcomputer software and development techniques are evolving rapidly. Text editors and debugging aids are becoming increasingly available, particularly on inexpensive hardware. A revolution will probably take place soon, with the appearance of complete development systems costing less than £1000. Software design methods are very much in vogue and the need for structure and documentation in microcomputer software cannot be overstressed. Which level of software to use is a problem that must be solved in the early days of system specification. The solution is often hybrid, composed of high-level code calling on lower-level assembler for fast or complex computations. System testing aids are becoming available with increased power and versatility. Multiprocessor development systems are now available with ICE (in-circuit emulation), a technique of real-time processor emulation that is receiving increased attention. This kind of support is still not cheap, but the value-for-money is improving rapidly.	software development;system testing	Martin Whitbread	1979	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(79)90087-5	development testing;personal software process;verification and validation;system integration testing;computer science;package development process;backporting;social software engineering;software reliability testing;software development;software construction;software testing;software walkthrough;software analytics;software deployment;goal-driven software development process;software development process;software system;software peer review	EDA	-68.39307851401958	28.052446172814992	118589
b906765b9b270764524a98b4f05619482f769534	outlier elimination in construction of software metric models	software metrics;least of median squares lms;outliers;prediction accuracy;software metric;models	"""Software metric models are models relating various software metrics of software projects. Such models' purpose is to predict some of these metrics for certain future projects given the other metrics for those projects. The construction of software metric models derives such relationships and is usually based on data samples of concerned software metrics for past software projects. Often, in such a data sample, there are inevitably a few very extreme projects which have relationships among their metrics deviating substantially from those among the metrics for the remaining """"mainstream"""" bulk of projects in the data sample. Such """"outlier"""" projects exert considerable undue influence on the derivation of the said relationships during model construction in that the relationships so derived cannot candidly reflect the true """"mainstream"""" relationships. The direct consequence is degraded prediction accuracy of the constructed models for future projects. To overcome this problem, we proposed a methodology to identify and thus eliminate such outliers prior to model construction. Our methodology makes use of the least of median squares (LMS) regression to uncover such outliers and is applicable irrespective of any subsequent model construction approaches. We also did a case study to apply our methodology, and the results prove our methodology being able to improve the prediction accuracy of most models experimented with in the study. Thus, our methodology is recommended for any further software metric model construction. This paper documents such a methodology and the successful case study."""	software metric	Victor K. Y. Chan;W. Eric Wong	2007		10.1145/1244002.1244319	computer science;software engineering;machine learning;data mining;software metric;statistics	SE	-66.44998849773665	31.294145421997193	118594
35f91a809173821cdd9ee5232e7186e4e9e74076	estimating the number of remaining defects after inspection	software engineering;evaluation;software inspection;capture recapture	An essential component of all software inspection processes is a well-founded decision about continuing or stopping the current process. This decision should be based upon directly relevant quantitative information – the number of defects remaining in the artefact. This quantity can be estimated by the use of capturerecapture methods. Several Software Engineering papers have explored this topic, but the questions: how applicable is this approach, and which capture-recapture technique is best, still remain unresolved. This paper attempts to shed further light upon these questions. After reviewing, the relevant capture-recapture models and the attempts at evaluating them within a Software Engineering context, the paper proceeds to evaluate the models by using data collected from subject-based experiments on software inspection. The experiments used artefacts where the number of defects are known and hence the paper produces a direct measure of the accuracy of the various capture-recapture techniques. The paper reports that the heterogeneity models are, in general, better especially the Jackknife estimator. But also reports that further work is required, to correct the limitations of the current models, if reliable estimates are to be achieved.	experiment;jackknife resampling;kaplan–meier estimator;mark and recapture;motion capture;resampling (statistics);software engineering;software inspection;visual artifact	James Miller	1999	Softw. Test., Verif. Reliab.	10.1002/(SICI)1099-1689(199909)9:3%3C167::AID-STVR185%3E3.0.CO;2-E	mark and recapture;engineering;evaluation;software engineering;data mining;software inspection;forensic engineering	SE	-66.36840414220553	31.391802347973822	118611
000630c48de1085c49cd879ab690c67b68ab742e	a perception of the practice of software security and performance verification		Security and performance are critical nonfunctional requirements for software systems. Thus, it is crucial to include verification activities during software development to identify defects related to such requirements, avoiding their occurrence after release. Software verification, including testing and reviews, encompasses a set of activities that have a purpose of analyzing the software searching for defects. Security and performance verification are activities that look at defects related to these specific quality attributes. Few empirical studies have been focused on how is the state of the practice in security and performance verification. This paper presents the results of a case study performed in the context of Brazilian organizations aiming to characterize security and performance verification practices. Additionally, it provides a set of conjectures indicating recommendations to improve security and performance verification activities.		Victor Vidigal Ribeiro;Daniela Cruzes;Guilherme Horta Travassos	2018	2018 25th Australasian Software Engineering Conference (ASWEC)	10.1109/ASWEC.2018.00018	empirical research;systems engineering;software system;software verification;non-functional requirement;software;software development;computer science;software security assurance	SE	-62.85026196432208	29.585586507478173	118789
15e27d014208f58993ad418455a4175e5dd16073	towards standard for experiments in program comprehension	software metrics;research needs;time measurement;software engineering delay costs time measurement programming profession standards development software systems computer science measurement standards humans;program comprehension;software systems;software engineering;dependent variables;standards development;reverse engineering program comprehension software engineering software standards dependent variables accurate response time inaccurate response time;accurate response time;programming profession;software metrics reverse engineering software standards;software standards;humans;computer science;measurement standards;inaccurate response time;reverse engineering	Program comprehension can make a unique contribution to the field of software engineering because it is feasible to validate its claims with inexpensive experiments. To fully realize this unique position, program comprehension researchers need to develop standards that will guide them in designing experiments and allow them to judge the strength of an experiment in supporting a claim. To begin the discussion leading to such standards, we propose that program comprehension experiments always measure and interpret the following dependent varaiables: accuracy, accurate response time, and inaccurate response time.	design of experiments;experiment;list comprehension;program comprehension;response time (technology);software engineering	Václav Rajlich;George S. Cowan	1997		10.1109/WPC.1997.601284	variables;computer science;systems engineering;engineering;software engineering;reverse engineering;software metric;time;software system;computer engineering	SE	-63.72469734893527	31.67233909617705	118913
52cd08e7c4b69c522d1ec4b2da55a181a8b9b041	an experience in facilitating process improvement with an integration problem reporting process simulation	software process improvement;integration problem processing;integration simulation;process improvement;process simulation	Software process improvement (SPI) has been a discernible theme in the software process simulation literature, which has recognized a wide variety of ways in which simulation can support SPI. This case study describes one of those ways, a very focused, retrospective modeling driven by integration delays in the development of an avionics system project. A simple simulation of the integration problem report flows offered a low cost means of looking into the dynamics of the backlogged integration process and clearly seeing a basic development problem that was difficult to see from existing reports. The model became especially helpful when alternative scenarios were run in order to see the relative benefits that different types of actions would have provided to the integration process. These experiments clarified lessons learned from other sources and suggested a major improvement for the next release cycle. The actual results of improvements deployed in the next release cycle were a reduced problem report backlog (1/3 that of the previous release) and 40% less test effort. Copyright  2006 John Wiley & Sons, Ltd.	avionics;experiment;john d. wiley;requirement;simulation;software development process;software release life cycle;test effort	Dan X. Houston	2006	Software Process: Improvement and Practice	10.1002/spip.283	simulation;process simulation;computer science;systems engineering;engineering;operations management;software engineering;management	SE	-68.01779743911273	22.494610945857335	118979
5d6b0642678090aa1840d5d804b63daded9c14c3	towards prioritizing architecture technical debt: information needs of architects and product owners	software;information need architecture technical debt prioritization aspects feature prioritization refactoring prioritization;computer and information science;prioritization aspects;maintenance engineering;portfolios;companies;refactoring prioritization;computer architecture;natural sciences;architecture technical debt;software development management software architecture;companies software computer architecture maintenance engineering portfolios conferences;information need;feature prioritization;information needs architecture technical debt prioritization architectural solutions technical debt measurements agile product owners feature development software architecture;conferences	Architectural Technical Debt is a metaphor for representing sub-optimal architectural solutions that might cause an interest, in terms of effort or quality, to be paid by the organization in the long run. Such metaphor has been regarded as useful for communicating risks of suboptimal solutions between technical and non-technical stakeholders. However, it's fundamental to understand the information needs of the involved stakeholders in order to produce technical debt measurements that would allow proper communication and informed prioritization. We have investigated, through a combination of interviews, observations and a survey, what key information is needed by agile product owners and software architects in order to prioritize the refactoring of risky architectural technical debt items with respect to feature development.	agile software development;code refactoring;information needs;software architect;technical debt	Antonio Martini;Jan Bosch	2015	2015 41st Euromicro Conference on Software Engineering and Advanced Applications	10.1109/SEAA.2015.78	maintenance engineering;reliability engineering;information needs;natural science;technical communication;computer science;systems engineering;engineering;software engineering;technical debt	SE	-68.0276021237908	21.952349710969425	119175
ecdcf2a48b55b985492e13605439e87bbc66323c	odhadování pracnosti it projektů		A large number of different methods in the field of estimation of IS/IT projects have been developed in past years. Those methods should be used with regard to several factors. The choice and the application of an estimation method should take into consideration the current phase of each project and the wide variety of external factors, whose composition and intensity are very diverse and individual. The accuracy of the estimation considerably influences the success of the whole project. This article aims to analyse the principles, which are used by methods for effort estimation, and finding strong and weak aspects of these methods.	cost estimation in software engineering;newton's method	Miroslav Král	2012	Acta Informatica Pragensia	10.18267/j.aip.3	speech recognition;linguistics;communication		-71.41043616951994	24.478075872455157	119306
20a827a846f61890e830d5128cc17b25a088c3f5	enterprise modeling in an agile world		As the pace of business increases, the speed at which enterprise models must be delivered increases accordingly. Enterprise modelers cannot spend years in an attic developing perfect models, but must deliver models that are useful in time to be used. In this paper I will take a look at the experiences we have with enterprise modeling in Statoil, a global oil company headquartered in Norway.	agile software development;attic;enterprise modelling	Harald Wesenberg	2011		10.1007/978-3-642-24849-8_10	enterprise systems engineering;enterprise software;enterprise modelling;agile unified process;agile usability engineering;integrated enterprise modeling;service-oriented modeling;process modeling;enterprise architecture management;process management;enterprise integration;enterprise planning system;enterprise information system;enterprise life cycle	OS	-66.9707303709389	20.12975129694684	119769
0b16724d5f80788014d3d5be07b2a3b009df304c	empirical evaluation of a process to increase consensus in group architectural decision making	postprint article;software architecture;group architecture decisions	Context: Many software architectural decisions are group decisions rather than decisions made by individuals. Consensus in a group of decision makers increases the acceptance of a decision among decision makers and their confidence in that decision. Furthermore, going through the process of reaching consensus means that decision makers understand better the decision (including the decision topic, decision options, rationales, and potential outcomes). Little guidance exists on how to increase consensus in group architectural decision making.		Dan Tofan;Matthias Galster;Ioanna Lytra;Paris Avgeriou;Uwe Zdun;Mark-Anthony Fouche;Remco C. de Boer;Fritz Solms	2016	Information & Software Technology	10.1016/j.infsof.2015.12.002	software architecture;r-cast;decision support system;decision analysis;decision engineering;computer science;systems engineering;engineering;knowledge management;software engineering;management science;business decision mapping	ECom	-71.56078869650904	19.282068307242294	119807
5d1cf132e37bbb641e11662e0fd0544819332549	coordinating open-source software development	open source software development coordination;electrical capacitance tomography;world wide contributors;distributed software development;project management;electronic mail;chaos;loose organizational structure;software projects open source software development coordination distributed software development world wide contributors loose organizational structure;internet;open source software development;software development;software projects;linux;web server;computer science;open source software programming electrical capacitance tomography internet web server computer science chaos linux radio access networks electronic mail;programming;software development management;open source software;radio access networks;open source;project management software development management	In the recent years a form of software development that was previously dismissed as too ad-hoc and chaotic for serious projects has suddenly taken the front stage. With products such as Apache, Linux, Perl, and others, open-source software has emerged as a viable alternative to traditional approaches to software development. With its globally distributed developer force and extremely rapid code evolution, open source is arguably the extreme in “virtual software projects” [1], and exemplifies many of the advantages and challenges of distributed software development. According to its (trademarked) definition, open-source software (OSS) is software for which the source code is distributed or accessible via the Internet without charge or limitations on modifications and future distribution by third parties [10]. While much of the early ARPANet and Unix software was distributed in this manner, during the 1980’s more ambitious open-source projects such as Free Software Foundation’s GNU were started and gained support of developers across the Internet. However, it wasn’t until the 1990’s that open-source software development truly gained momentum and become synonymous with highly distributed development characterized by frequent iterations, thanks to the wide availability of the source code and openess to contributions from the community. Today, open-source software dominates the Internet infrastructure — for example, in February 1999, over 54% of Web servers ran Apache server software [17], while it is estimated that Sendmail now handles about 80% of Internet e-mail [4] — and established computer companies such as IBM and Apple are starting to include OSS into their products [9, 2]. The main reason for this success is the growth of the Internet, which made collaboration between programmers feasible on a scale much larger than was possible before. With the global computer network in place, a huge pool of potential developers and testers willing to put their time into projects they found interesting or useful became available. Not surprisingly, this openess and fluidity also put unique demads on the development process. To cope with those issues, open-source software projects evolved their own methods and organization. This methodology has the potential to alter the whole approach to making software — resulting, its proponents would say, in more reliable products and faster and leaner development. However, it also faces some significant obstacles if it is to continue successfully growing. In my opinion, these obstacles cannot be surmounted by simply attempting to transplant ideas from the more traditional development models, even those that are also Internet-based. What is needed instead is research that will examine opensource software and development process, in light of their current accomplishments and respecting their specificities, and find what works, what doesn’t, and how it can be further improved. In this position paper, I will look at the ways some of the major and most successfull open-source projects deal with the issue of coordination among their many contributors. Although each of the projects examined here developed some unique practices, there are also significant commonalities. I will then indicate some of the problems caused by the existing practices, and put forward some possible approaches to OSS coordination that could make open-source software development more efficient.	distributed computing;email;gnu;hoc (programming language);internet;iteration;knowledge management;linux;open sound system;open-source software;perl;programmer;requirement;software development;software development process;software engineering;software industry;software project management;unix;web server	Davor Cubranic;Kellogg S. Booth	1999		10.1109/ENABL.1999.805176	project management;programming;the internet;computer science;software development;operating system;software engineering;database;distributed computing;management;world wide web;linux kernel;web server	SE	-69.96683982500666	27.890674963659816	119823
58a2346d87d74fc3aeff5f32e1d5dd534f911a74	promises and perils of porting software visualization tools to the web	software metrics;software;portals;groupware;measurement;software systems;software system complexity;porting software visualization tool;computer architecture;data analysis;visualization;web sites data analysis groupware internet program visualisation software metrics;data analysis porting software visualization tool software system complexity;internet;ecosystems;web sites;data visualization;software data visualization portals ecosystems measurement visualization computer architecture;program visualisation;software visualization	Software systems are hard to understand due to the complexity and the sheer size of the data to be analyzed. Software visualization tools are a great help as they can sum up large quantities of data in dense, meaningful pictures. Traditionally such tools come in the form of desktop applications. Modern web frameworks are about to change this status quo, as building software visualization tools as web applications can help in making them available to a larger audience in a collaborative setting. Such a migration comes with a number of promises, perils and technical implications that have to be taken into account before starting any migration process. In this paper we share our experiences in porting two such tools to the web and discuss the promises and perils that go hand in hand with such an endeavour.	debugging;desktop computer;endeavour (supercomputer);exception handling;image scaling;pareto efficiency;software system;software visualization;web application;web framework;webplatform;world wide web	Marco D'Ambros;Michele Lanza;Mircea Lungu;Romain Robbes	2009	2009 11th IEEE International Symposium on Web Systems Evolution	10.1109/WSE.2009.5631247	software visualization;ecosystem;the internet;visualization;human–computer interaction;computer science;software engineering;database;data analysis;world wide web;data visualization;software metric;measurement;software system	SE	-69.7641227218757	29.377037894163607	119957
99d833b00d4e8035129ac3aa03dc0cb71e17aec3	software localization for internet software: issues and methods	software engineering information resources internet health care;global telehealth company software localization internet software web sites;information resources;internet cultural differences medical services usability software testing calendars software measurement government software maintenance navigation;software localization;language transition;software engineering;cultural sensitivity;global information systems;internet;participant observation;web site usability;health care	For use by a global audience, Web sites must be adapted to many local requirements. This article examines key issues in such adaptation (termed localization), considers the costs and specific aspects of software that must be localized, and presents an approach for analyzing and documenting software localization. The article is based on a review of relevant literature, meetings with localization industry representatives, and an ongoing participant observation in a global telehealth company. Examples from the company illustrate the localization issues and their possible outcomes or solutions.	internationalization and localization	Rosann Webb Collins	2002	IEEE Software	10.1109/52.991367	software review;personal software process;medical software;long-term support;the internet;global information system;internationalization and localization;software engineering process group;computer science;systems engineering;knowledge management;social software engineering;component-based software engineering;software development;software engineering;software as a service;participant observation;software walkthrough;software analytics;software deployment;world wide web;software quality;health care;software system;software peer review	Embedded	-72.36344022737309	21.45049642319833	119994
df8fd112652cf737ccd1b7088a195d0a602d83c2	ten years of rich internet applications: a systematic mapping study, and beyond	verification;information systems;measurement;performance;web applications;info eu repo semantics article;human factors;systematic mapping study;theory;state of the art;web interfaces;algorithms;design;rich internet applications;experimentation;security;surveys and overviews;languages	BACKGROUND. The term Rich Internet Applications (RIAs) is generally associated with Web applications that provide the features and functionality of traditional desktop applications. Ten years after the introduction of the term, an ample amount of research has been carried out to study various aspects of RIAs. It has thus become essential to summarize this research and provide an adequate overview.  OBJECTIVE. The objective of our study is to assemble, classify, and analyze all RIA research performed in the scientific community, thus providing a consolidated overview thereof, and to identify well-established topics, trends, and open research issues. Additionally, we provide a qualitative discussion of the most interesting findings. This work therefore serves as a reference work for beginning and established RIA researchers alike, as well as for industrial actors that need an introduction in the field, or seek pointers to (a specific subset of) the state-of-the-art.  METHOD. A systematic mapping study is performed in order to identify all RIA-related publications, define a classification scheme, and categorize, analyze, and discuss the identified research according to it.  RESULTS. Our source identification phase resulted in 133 relevant, peer-reviewed publications, published between 2002 and 2011 in a wide variety of venues. They were subsequently classified according to four facets: development activity, research topic, contribution type, and research type. Pie, stacked bar, and bubble charts were used to depict and analyze the results. A deeper analysis is provided for the most interesting and/or remarkable results.  CONCLUSION. Analysis of the results shows that, although the RIA term was coined in 2002, the first RIA-related research appeared in 2004. From 2007 there was a significant increase in research activity, peaking in 2009 and decreasing to pre-2009 levels afterwards. All development phases are covered in the identified research, with emphasis on “design” (33%) and “implementation” (29%). The majority of research proposes a “method” (44%), followed by “model” (22%), “methodology” (18%), and “tools” (16%); no publications in the category “metrics” were found. The preponderant research topic is “models, methods and methodologies” (23%) and, to a lesser extent, “usability and accessibility” and “user interface” (11% each). On the other hand, the topic “localization, internationalization and multilinguality” received no attention at all, and topics such as “deep Web” (under 1%), “business processing”, “usage analysis”, “data management”, “quality and metrics” (all under 2%), “semantics”, and “performance” (slightly above 2%) received very little attention. Finally, there is a large majority of “solution proposals” (66%), few “evaluation research” (14%), and even fewer “validation” (6%), although the latter have been increasing in recent years.	accessibility;bubble bobble;categorization;cellular automaton;chart;computer performance;data validation;deep web;desktop computer;internationalization and localization;mike lesser;open research;reference work;rich internet application;usage analysis;user interface	Sven Casteleyn;Irene Garrigós;Jose-Norberto Mazón	2014	TWEB	10.1145/2626369	design;verification;simulation;performance;computer science;information security;human factors and ergonomics;machine learning;data mining;world wide web;theory;measurement	Web+IR	-74.59009156089284	26.80952005291042	120011
a9caedb40e56f1a3ecc17885c87188a060ba2f47	rapidly evolving software and the oversee environment	information flow;software systems;configuration management;software development	During its lifetime, a software system will sometimes need to “rapidly evolve,” that is, undergo a quick set of changes. Making the changes rapidly is difficult, especially if one's software development policies are rigorous; the need for test reports, signatures, etc., seems to create interminable delays. In this paper, we argue that much of the problem stems not from such policies, but from a lack of consideration to information flow in software environments. We present a configuration management environment called OVERSEE, and discuss how it helps solve the problems of information flow.	antivirus software;configuration management;information flow (information theory);software development;software system	Steven Wartik	1986		10.1145/24208.24218	simulation;information flow;software quality management;software configuration management;computer science;software development;software design description;distributed computing;configuration management;software metric;software system;avionics software	PL	-64.18996688574454	29.51430972848863	120119
cbda6c9b50d684deb5ddf3b799d1740d9faf6074	an architecture to support learning, awareness, and transparency in social software engineering	cooperative development environments;knowledge management;social software;learning systems;learning communities	Classical tools for supporting software engineering teams (collaborative development environment, CDE) are designed to support one team during the development of a product. Often the required data sources or experts reside outside of the internal project team and thus not provided by these CDEs. This paper describes an approach for a community-embedded CDE (CCDE), which is capable of handling multiple projects of several organizations, providing inter-project knowledge sharing and developer awareness. The presented approach uses the mashup pattern to integrate multiple data sources in order to provide software teams with an exactingly development environment.	awareness;collaborative development environment;common desktop environment;embedded system;mashup (web application hybrid);social software engineering	Wolfgang Reinhardt;Sascha Rinne	2010	iJET	10.3991/ijet.v5s1.1194	learning community;personal software process;team software process;simulation;computer science;knowledge management;social software engineering;software development;software development process	SE	-64.41812537480469	18.784321003708822	120388
c6ba5525784b1ecefa9f3ea8b5bb5a94d59b8e75	optimal weighted combinational models for software reliability estimation and analysis	weighted combinations genetic algorithm non homogeneous poisson process optimization problems software development process software reliability growth models;software reliability combinatorial mathematics genetic algorithms software fault tolerance software management software metrics software quality;software reliability software data models predictive models genetic algorithms testing;optimal release strategy optimal weighted combinational models software reliability growth models srgm safety critical application systems life critical application systems software products software quality prediction capability weighted arithmetic combinations weighted geometric combinations weighted harmonic combinations enhanced genetic algorithms ega real software failure data software development environments management metrics	Software is currently a key part of many safety-critical and life-critical application systems. People always need easy- and instinctive-to-use software, but the biggest challenge for software engineers is how to develop software with high reliability in a timely manner. To assure quality, and to assess the reliability of software products, many software reliability growth models (SRGMs) have been proposed in the past three decades. The practical problem is that sometimes these selected SRGMs by companies or software practitioners disagree in their reliability predictions, while no single model can be trusted to provide consistently accurate results across various applications. Consequently, some researchers have proposed to use combinational models for improving the prediction capability of software reliability. In this paper, three enhanced weighted-combinations, namely weighted arithmetic, weighted geometric, and weighted harmonic combinations, are proposed. To solve the problem of determining proper weights for model combinations, we further study how to incorporate enhanced genetic algorithms (EGAs) with several efficient operators into weighted assignments. Experiments are performed based on real software failure data, and numerical results show that our proposed models are flexible enough to depict various software development environments. Finally, some management metrics are presented to both assure software quality and determine the optimal release strategy of software products under development.	bell's theorem;combinational logic;computable function;computer-aided software engineering;genetic algorithm;mathematical induction;numerical analysis;polynomial;rule 90;social inequality;software bug;software development;software engineer;software quality;xojo	Chao-Jung Hsu;Chin-Yu Huang	2014	IEEE Transactions on Reliability	10.1109/TR.2014.2315966	reliability engineering;software sizing;search-based software engineering;computer science;software reliability testing;theoretical computer science;software construction;data mining;software testing;goal-driven software development process;software metric	SE	-62.97747600761689	31.581484214297262	120642
7b987e19ad2c4515f2198bbe5bb4bfe442e4c078	on testing process control software for reliability assessment: the effects of correlation between successive failures	process control;statistical testing;dependability	Statistical testing is the main available means for evaluating the reliability of software products. For ‘batch’ software, one can usually model both testing and operation as sequences of statistically independent trials (BentouZZi trials). Statistical inference from test results to reliability predictions is then straightforward. Things change when non-zero correlation is to be expected between the outcomes (failure or success) of successive executions of the software. This is the case, in particular, for most process control software: the inputs to each execution represent measurements on the controlled plant, and therefore follow quasi-continuous trajectories in the input space. For such software, this paper will: (i) show that the Bernoulli-trial model is inappropriate; (a) argue that the ‘failure rate’ (probability of failure per execution) is no longer an appropriate indicator of software dependability; (iii) discuss the relationships among the statistical parameters describing the failure behavlour of the software; (iv) argue for direct measurement of the parameters of interest.	bernoulli polynomials;dependability;list of version control software	Lorenzo Strigini	1996	Softw. Test., Verif. Reliab.	10.1002/(SICI)1099-1689(199603)6:1%3C33::AID-STVR109%3E3.0.CO;2-G	non-regression testing;recovery testing;reliability engineering;statistical hypothesis testing;regression testing;real-time computing;software performance testing;computer science;systems engineering;engineering;software reliability testing;process control;dependability;risk-based testing;software testing;software regression;stress testing;software metric	SE	-62.879203633056264	31.916627246479237	120720
af0243ccb05d6c08689ef065d926b270b93c4fcc	the use of a meta-model to support multi-project process measurement	requirement stability open source process monitoring cmmi process assessment;software metrics;software;monitoring application software programming project management large scale systems maintenance software engineering software measurement information technology computer science;project management;software measurement;cmmi;software management;process assessment;software companies;software systems;software development process;data mining;companies;requirement stability;business environment;large scale;process monitoring;multiple project metrics;monitoring;software tools project management software management software metrics;software development projects;software development;stability analysis;software tools;process model;spago4q;product quality;open source tool;spago4q multiproject process measurement software companies software systems software development projects multiple project metrics open source tool;programming;multiproject process measurement;meta model;open source	In today's environment, software companies are engaged in multiple projects delivered on heterogeneous platforms for a wide class of applications in disparate application domains. They are increasingly engaged in the co-development of software systems through joint software development projects including staff from partners and customers as well as their own. As a result, they must support multiple software development processes while trying to guarantee uniform levels of process enactment, and product quality across all projects. Our approach is capable of providing process measurement in a joint-project, multi-process model business environment. It is based on a simple meta-model for computing across-process, multiple-project metrics designed to permit monitoring of CMMI compliance. The open source tool Spago4Q has been developed to support our approach and is capable of producing the measurements needed for monitoring of a set of large-scale development projects using different process models, in a real industrial setting in Europe. The results support the view that that it will not always be possible to aggregate the same set of metrics across disparate process models.	aggregate data;application domain;capability maturity model integration;comparison of raster-to-vector conversion software;conformance testing;heart rate variability;metamodeling;open-source software;process modeling;software development;software system	Alberto Colombo;Ernesto Damiani;Fulvio Frati;Sergio Oltolina;Karl Reed;Gabriele Ruffatti	2008	2008 15th Asia-Pacific Software Engineering Conference	10.1109/APSEC.2008.55	metamodeling;project management;reliability engineering;programming;von neumann stability analysis;team software process;systems engineering;engineering;capability maturity model integration;software development;software engineering;process modeling;software measurement;goal-driven software development process;software development process;software metric;software system	SE	-64.64754480694172	21.241505252290427	121011
81f8f85196f39b6d4de3bade76ff07a63d78277a	putting into practice advanced software engineering techniques through students project	formal specification;object oriented design;student project;development process;software engineering;software engineering education	The paper describes an experience of software engineering education concerning the guidance of students project during about ten years. The project aims mainly at putting into practice the concepts, methods and techniques taught in a software engineering course through the development -by teams of students- of an actual, practical, real-size case. The concerned course involves several advanced topics, e.g., semi-formal requirements, formal specifications, transformational development process, Object-Oriented design,... which are sometimes considered as purely academic topics. Therefore, the main feature of the students project is to illustrate the applicability of these topics in a realistic project and thus to achieve an integration of modern techniques with more classical ones.	software engineering	Naji Habra;Eric Dubois	1994		10.1007/BFb0017622	personal software process;verification and validation;software engineering process group;software project management;computer science;systems engineering;package development process;software design;social software engineering;component-based software engineering;software development;civil engineering software;software engineering;software construction;systems development life cycle;software walkthrough;software development process;software requirements;computer engineering	SE	-65.7295845056172	25.54677486818821	121149
6a7ed4e2419d4fb8dffe202695908953e8c280ce	"""""""to deliver faster, build it in reverse"""""""	release planning;focusing;software;project management;software prototyping;feeds;testing;computer hacking;business;delivery;enterprise architecture;buildings;software development management;hands on session	Gap Inc. Direct is using Agile methodologies for IT project delivery. This paper discusses how building systems starting from the customer facing pieces allows Gap to deliver projects faster.	agile software development	Michael Elbaz	2011	2011 AGILE Conference	10.1109/AGILE.2011.32	simulation;enterprise software;software project management;systems engineering;engineering;software development;software engineering;release management;software as a service;software development process	Robotics	-68.40261383655672	25.82609996004456	121283
3a579855000bdb95cd228afa8fba95980e988b2d	continuously revised assurance cases with stakeholders' cross-validation: a deos experience	assurance cases;experience report;deos process;gsn;service dependability	Recently, assurance cases have received much attention in the field of software-based computer systems and IT services. However, software changes very often, and there are no strong regulations for software. These facts are two main challenges to be addressed in the development of software assurance cases. We propose a method of developing assurance cases by means of continuous revision at every stage of the system life cycle, including in operation and service recovery in failure cases. Instead of a regulator, dependability arguments are validated by multiple stakeholders competing with each other. This paper reported our experience with the proposed method in the case of Aspen education service. The case study demonstrates that continuous revisions enable stakeholders to share dependability problems across software life cycle stages, which will lead to the long-term improvement of service dependability. Subjects Security and Privacy, Software Engineering	algorithm;computation;cross-validation (statistics);dependability;embedded operating system;embedded system;experiment;hippi;software assurance;software engineering;software release life cycle;system lifecycle;table (database)	Kimio Kuramitsu	2016	PeerJ Computer Science	10.7717/peerj-cs.101		SE	-62.92120721323684	28.44446862826159	121304
7f35a59af11ac1929befc391de99f308abc6d699	multimodal modeling, analysis, and validation of open source software development processes	mdsd;model analysis;requirements processes;process modeling;open source software development;cmdsd;semantic web;model driven software development;software process	Understanding the context, structure, activities, and content of software development processes found in practice has been and remains a challenging problem. In the world of free/open source software development (F/OSSD), discovering and understanding what processes are used in particular projects is important in determining how they are similar to or different from those advocated by the software engineering community. Prior studies have revealed that development processes in F/OSSD projects are different in a number of ways. In this article, we describe how a variety of modeling perspectives and techniques are used to elicit, analyze, and validate software development processes found in F/OSSD projects, with examples drawn from studies of the software requirements process found in the NetBeans.org project.	modeling perspective;multimodal interaction;open-source software;requirement;software development;software engineering;software requirements	Walt Scacchi;Chris Jensen;John Noll;Margaret S. Elliott	2006	IJITWE	10.4018/jitwe.2006070104	personal software process;verification and validation;team software process;software engineering process group;software project management;computer science;package development process;software design;social software engineering;software framework;software development;software design description;software engineering;semantic web;software construction;process modeling;data mining;software walkthrough;empirical process;software analytics;software deployment;goal-driven software development process;software development process;software requirements;software peer review	SE	-64.74494552530956	24.029325378064907	121336
008712a162c7a70202c4cb305801c145664f4d6e	productivity monitoring process using fpa - improving your development process using productivity indicators	software development management process monitoring productivity project management;software;development;software measurement;data mining;companies;monitoring;productivity software monitoring software measurement data mining conferences companies;productivity;productivity development;project development process productivity monitoring process fpa development process productivity indicators software development processes sdp productivity control project manager;conferences	Companies that develop software are increasingly competitive. To learn how these firms are competitive need to measure the productivity of their software development processes (SDP). Knowing how to control productivity, the company is better able to predict various parameters and estimate their projects more closely the actual value of the projects. The project manager must monitor how the productivity of your project is during the course of the same. What factors are positively and negatively impacting the productivity of the development process of the project? How can I adjust it? This workshop will present a proposal for a process for monitoring the productivity of the development process of an application and show a case study of the practical use of this process.	software development process	Eduardo Alves de Oliveira	2014	2014 Joint Conference of the International Workshop on Software Measurement and the International Conference on Software Process and Product Measurement	10.1109/IWSM.Mensura.2014.57	personal software process;team software process;software project management;systems engineering;engineering;operations management;process management;empirical process	SE	-68.90564863982452	23.4061081919185	121558
afafb99a893632747a448e86a59c44baaaf7eb65	ten lessons learned from integrating interaction design and agile development	prototypes companies usability testing encoding interviews;agile;human computer interaction;software prototyping;integration;team working;lessons learned agile interaction design integration;team working human computer interaction software development management software prototyping;lessons learned;agile team working interaction design agile development;interaction design;software development management	Agile development have a distinct culture that at first glance seems to conflict with Interaction Design. Therefore, integrating these two areas becomes a challenging task. There is little guidance about integrating them. Very limited empirical evidence exists on Agile development and Interaction Design being combined in practice. In order to better understand how these approaches are combined in practice, a multiple-case study of Agile teams working with Interaction Designers was performed. In the paper, we present a set of ten lessons learned from these studies.	agile software development;interaction design	Tiago Silva da Silva;Milene Selbach Silveira;Frank Maurer	2013	2013 Agile Conference	10.1109/AGILE.2013.11	simulation;agile unified process;agile usability engineering;systems engineering;engineering;knowledge management;agile software development;empirical process;lean software development;software development process	HCI	-71.13524408255047	20.840624199892485	121720
7a9ea47628100fe060b149625a1c14d47e5d0212	towards a methodology for 24 hour software production using globally separated development teams	hour software production;globally separated development teams	The potential advantages of utilising software development teams which reside in different time zones are discussed. The experiences of an experimental study which attempted to share a software project between teams in Australia and India are then related. The results of this study show that, co-operative software development on a global scale is feasible, productivity gains are achievable and potentially enhanced product quality is an important by-product.	24-hour clock	Ian Gorton;Sanjeev Motwani	1994			real-time computing;systems engineering;engineering;operations management	HCI	-67.62645540874158	20.837437387882773	121747
a13250f9159e2b52d3e015e1b0c80a49e9084a6d	considering alternative strategies for value sustainment in systems-of-systems	value sustainment;context robustness uncertainty boats monitoring computational modeling;uncertainty;systems engineering;system of systems;architecture system of systems changeability evolvability value sustainment strategies;wave model;sos change;maritime security sos;systems of systems;computational modeling;monitoring;sose activities;systems analysis;value delivery;simulation based era analysis value sustainment systems of systems value delivery wave model time varying sos engineering sose activities sos change maritime security sos marsec sos;changeability;marsec sos;robustness;time varying sos engineering;simulation based era analysis;evolvability;systems engineering marine systems systems analysis;architecture;context;strategies;boats;marine systems	Systems of Systems (SoSs) operating in an uncertain world must overcome a variety of challenges in order to sustain value delivery over time. This paper describes strategies for value sustainment, using an application of the “wave model” to represent time-varying SoS Engineering (SoSE) activities and opportunities for SoS-change. A Maritime Security (MarSec) SoS case study is described, and simulation-based Era Analysis is used to evaluate SoS alternatives through different operational environments for an assumed 8-year time frame. Eight SoS designs are evaluated and compared across four strategies in terms of accumulated utility, discounted cost, and total down time. The four value sustainment strategies are: (1) self-recovery, the SoS is not changed (i.e., relating to survivability/robustness); (2) changes in the design of the SoS are allowed (i.e., relating to changeability); (3) changes in the architecture of the SoS are allowed (i.e., relating to evolvability) once, or (4) three times in the eight years. The results provide an example of how quantitative approaches can be used to gain insights into tradeoffs in how SoS architects can create value-sustainable SoSs for the long run.	apple sos;downtime;simulation;system of systems	Nicola Ricci;Donna H. Rhodes;Adam M. Ross;Matthew E. Fitzgerald	2013	2013 IEEE International Systems Conference (SysCon)	10.1109/SysCon.2013.6549963	simulation;systems engineering;engineering	SE	-64.26331802399577	20.405655273220212	122177
21f1c3b00ca99b031c9efef4d65679c56acf967b	requirements socio-technical graphs for managing practitioners’ traceability questions		To understand requirements traceability in practice, we contribute, in this paper, an automated approach to identifying questions from requirements repositories and examining their answering status. Applying our approach to 345 open-source projects results in 20 622 questions, among which 53% and 15% are classified as successfully and unsuccessfully answered, respectively. By constructing a novel requirements socio-technical graph, we explore the impact of stakeholder–artifact relationships on traceability. The number of people, surprisingly, has little influence compared to other graph-theoretic measures like the clustering coefficient. Based on the repository mining results, we formulate a set of novel hypotheses about traceability. A case study supports some hypotheses while offering new insights.		Nan Niu;Wentao Wang;Arushi Gupta;Mona Assarandarban;Li D. Xu;Juha Savolainen;Jing-Ru C. Cheng	2018	IEEE Transactions on Computational Social Systems	10.1109/TCSS.2018.2872059	data mining;traceability;sociotechnical system;computer science;requirements traceability;clustering coefficient;benchmark (computing);graph	SE	-75.25889074270697	22.517665465241972	122443
e790a92ec6c0528db7bbc69168602017da66319c	on the impact of passive voice requirements on domain modelling	quality assurance;analytical quality assurance;requirements engineering;natural language;experimentation	Context: The requirements specification is a central artefact in the software engineering (SE) process, and its quality (might) influence downstream activities like implementation or testing. One quality defect that is often mentioned in standards is the use of passive voice. However, the consequences of this defect are still unclear. Goal: We need to understand whether the use of passive voice in requirements has an influence on other activities in SE. In this work we focus on domain modelling. Method: We designed an experiment, in which we ask students to draw a domain model from a given set of requirements written in active or passive voice. We compared the completeness of the resulting domain model by counting the number of missing actors, domain objects and their associations with respect to a specified solution. Results: While we could not see a difference in the number of missing actors and objects, participants which received passive sentences missed almost twice the associations. Conclusion: Our experiment indicates that, against common knowledge, actors and objects in a requirement can often be understood from the context. However, the study also shows that passive sentences complicate understanding how certain domain concepts are interconnected.	business object;domain model;domain-driven design;downstream (software development);requirement;software bug;software engineering;software requirements specification;visual artifact	Henning Femmer;Jan Kučera;Antonio Vetro	2014		10.1145/2652524.2652554	quality assurance;simulation;computer science;engineering;domain engineering;data mining;requirements engineering;natural language	SE	-63.908441528586515	18.76976120948464	122493
043eefb7d4fcf56e6e425eed3e69b8e9a5b0399e	data center energy demand: what got us here won't get us there	energy efficiency;software;data center energy demand energy prices it workloads energy efficiency power efficiency;environmental factors;pragmatics;power aware computing computer centres energy conservation energy consumption;software engineering;computer architecture;software architecture;energy efficiency software engineering software architecture computer architecture software design green computing environmental factors;software development;software architect;organizations;software design;software engineering energy efficiency green computing software architect software architecture software design software development;cooling;green computing;hardware	Given environmentalism's rising tide and increasing energy prices and IT workloads, architects must determine whether they can continue designing systems without considering energy and power efficiency.	data center;performance per watt	Rabih Bashroush;Eoin Woods;Adel Noureddine	2016	IEEE Software	10.1109/MS.2016.53	software architecture;computer science;systems engineering;engineering;software engineering;computer engineering;pragmatics	Arch	-69.86859095272204	27.56382844141399	122786
35992bb35e38a905d888079e4ca1b51a360d0d13	applying and adjusting a software process improvement model in practice: the use of the ideal model in a small software enterprise	ideal model;project management;software process improvement;application software;knowledge management;constitution;software engineering institute;constitution software engineering companies application software knowledge management project management informatics continuous improvement permission europe;companies;software engineering;software development management software process improvement model ideal model small software enterprise software engineering institute danish software company organizational change;software houses;permission;continuous improvement;organizational change;danish software company;software process improvement model;informatics;europe;improvement models;software houses software process improvement software development management;software development management;small software enterprise	Software process improvement is a demanding and complex undertaking. To support the constitution and implementation of software process improvement schemes the Software Engineering Institute (SEI) proposes a framework, the so-called IDEAL model. This model is based on experiences from large organizations. The aim of the research described here was to investigate the suitability of the model for small software enterprises. It has therefore been deployed and adjusted for successful use in a small Danish software company. The course of the project and the application of the model are presented and the case is reflected on the background of current knowledge about managing software process improvement as organizational change.	organizational behavior;software engineering institute;software development process	Karlheinz Kautz;Henrik Westergaard Hansen;Kim Thaysen	2000		10.1145/337180.337492	project management;personal software process;verification and validation;team software process;application software;software engineering process group;software sizing;software project management;computer science;systems engineering;engineering;knowledge management;package development process;social software engineering;component-based software engineering;software development;software design description;software engineering;software construction;software walkthrough;empirical process;informatics;management;software deployment;goal-driven software development process;software peer review	SE	-69.46625837482328	19.977913807541324	122798
d9e5703bb945787e25b85392d37241673d6e6f7c	guest editorial software management: we must find a way	project management;seminars;financial management;job shop scheduling;software management;resource management;data processing;engineering management;us department of defense;software development;programming;software development management;data processing software development management programming engineering management us department of defense job shop scheduling seminars resource management project management financial management	SOFTWARE management is a term which inspires many different reactions from the broad range of practitioners in the field of data processing. The term has many dimensions ranging from the first and second line manager of a software development activity who plies his trade with little to fall back on other than his prior experience, and native skills and intuition. Contrast this with a senior executive who, because of lack of understanding of software management, is frustrated in trying to determine if his company can produce a software program on schedule and within budget. The data processing landscape is littered with examples of major software developments which faltered and then expired. That this situation should exist, after almost a quarter-century of experience with implementing these systems, is one of the enigmas of the rapidly expanding data processing industry.	computer program;ply (game theory);software development;software project management	Richard E. Merwin	1978	IEEE Transactions on Software Engineering	10.1109/TSE.1978.231516	project management;job shop scheduling;programming;program management;software quality management;enterprise software;data processing;software configuration management;software project management;data management;computer science;systems engineering;engineering;knowledge management;social software engineering;resource management;software development;operating system;software engineering;software asset management;software as a service;software walkthrough;application lifecycle management;management;human resource management system;software development process;software peer review	SE	-68.83784464889604	26.100802156012705	122893
7858abf0252ffc8f3d2a5809aa5d8d6b1bdd8e85	software process assessment validation and improvement prioritization		After a software process assessment is performed there are two main problems decision-makers face. First, how reliable are the assessment results presented. Though assessments are often performed by an independent competent third party, it is still important to be able to judge the validity of the determined capability profile and to assure that a faithful picture of the organisation has been captured. Second, in consideration of the results, identify what are the process-related risks for the organisation so they can guide the establishment of the priorities for a process improvement. This paper presents a method based on the dependencies between processes in order to support the validation of the assessment results and the identification of business critical processes for improvement.		Sven Richter;David Escorial Rico	2014		10.1007/978-3-662-43896-1_9	verification and validation	EDA	-69.40261168725229	21.430646879434924	123248
243c36604830c25a815e1fe22463aa9a8e929830	lightweight spi assessments: what is the real cost?	computer science	In this article, we describe the implementation of an assessment method that was developed to assess software processes within small to medium-sized Irish software organisations that have little or no experience of software process improvement (SPI) programmes. We discuss the actual overheads associated with performing software process assessments based upon our experiences of performing assessments in three small to medium-sized (SMEs) software development companies. Copyright © 2009 John Wiley & Sons, Ltd.		Fergal McCaffery;Gerry Coleman	2009	Software Process: Improvement and Practice	10.1002/spip.430	personal software process;verification and validation;team software process;software engineering process group;software project management;computer science;systems engineering;operations management;software engineering;software walkthrough;empirical process;software deployment;software quality analyst;software peer review	SE	-69.17879262087973	19.973943260001104	123269
0c8345079445bdbb7cd1a3339552012122481d1c	understanding software productivity: towards a knowledge-based approach	knowledge base	"""What affects software productivity and how do we improve it? This report examines the current state of the art in understanding and measuring software productivity. In turn, it describes a framework for understanding software productivity, identifies some fundamentals of measurement, surveys selected studies of software productivity, and identifies variables that affect software productivity. Then, a radical alternative to current approaches is suggested: to construct, evaluate, deploy, and evolve a knowledge-based """"software productivity modeling and simulation system."""""""	knowledge-based systems	Walt Scacchi	1991	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194091000214	knowledge base;team software process;computer science;systems engineering;engineering;knowledge management;software development;management science	SE	-70.47048535236621	21.695107084434323	123315
daa3a6c8aa806bf4dc8775d1873318e531030356	modeling unit testing processes - a system dynamics approach	system dynamics;unit testing	Software development is a complex activity that often exhibits counter-intuitive behavior, in that outcomes often vary quite radically from the intended results. The production of a high quality software product requires application of both defect prevention and defect detection techniques. A common defect detection strategy is to subject the product to several phases of testing such as unit, integration, and system. These testing phases consume significant project resources and cycle time. As software companies continue to search for ways for reducing cycle time and development costs while increasing quality, software-testing processes emerge as a prime target for investigation. This paper presents a system dynamics (SD) model of software development, better understanding testing processes. Motivation for modeling testing processes is presented along with an executable model of the unit test phase. Some sample model runs are described to illustrate the usefulness of the model.	counter (digital);display resolution;executable;iterative and incremental development;software bug;software development;software industry;system dynamics;system testing;unit testing	Kumar Saurabh	2008			computer science;unit testing;system dynamics;programming language	SE	-65.43099388361439	28.155957902159674	123574
62c2aa0566da9535ae469dad6bf24ff38234fc2f	continuous requirements risk profiling in information systems development	software;information systems development;complexity theory;delphi study requirements continuous profiling risk management information systems development;risk management;industries;requirements;continuous profiling;data collection continuous requirements risk profiling information systems development isd system development risk management focus group interview delphi study;software engineering information systems risk management;software risk management design methodology industries complexity theory encoding;delphi study;encoding;design methodology	With the increasing adoption of agile, lean, and iterative development methods, information systems development (ISD) has become continuous, meaning that system development moves rapidly from release to release. This means that work practices and challenges that practitioners face have changed. Despite these changes, requirements development is still critical in ISD. However, IS literature is silent on how to manage requirements-related risks in the practice of continuous IS development. To fill this gap, we propose a continuous requirements risk profiling method. The study is informed by design science research methodology, and we apply focus group interviews and a Delphi study for data collection to support the method development. The developed method can be integrated to ISD projects using different continuous ISD methods.	ansi escape code;agile software development;delphi method;embarcadero delphi;focus group;information system;iterative and incremental development;iterative method;lean software development;object pascal;requirement;risk management;software development process	Tuure Tuunanen;Tero Vartiainen;Mehdi Ebrahim;Murong Liang	2015	2015 48th Hawaii International Conference on System Sciences	10.1109/HICSS.2015.483	requirements analysis;design methods;risk management;delphi method;knowledge management;software engineering;risk management information systems;management;encoding	SE	-68.46009134254966	21.21213859233798	123737
172eb4f5c465b35de06ea3b6531912f5088a983c	describing what experimental software engineering experts do when they design their experiments - a qualitative study		Background: Although there has been a significant amount of research focused on designing and conducting controlled experiments, few studies report how experienced experimental software engineering researchers actually design and conduct their studies. Aims: This study aimed to offer a practical perspective from their viewpoint regarding controlled experiment planning. Method: We collected data through semi-structured interviews from 11 researchers, and we used qualitative analysis methods from the grounded theory approach to analyze them. Result: Although the complete study presents four research questions, in this paper, we answer the first one. As a result, we present a preliminary result about what these experts actually do when they design experiments. Conclusions: This work contributes to a better understanding of the practical performance of experimental software engineering.	experience;experiment;experimental software engineering;interviews;semiconductor industry	Liliane Sheyla da Silva Fonseca;Carolyn Budinger Seaman;Sérgio Castelo Branco Soares	2017	2017 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)	10.1109/ESEM.2017.63	computer science;experimental software engineering;systems engineering;software;qualitative research;grounded theory	SE	-71.9882346408527	23.392382905619492	123977
3d3ae63fcd757cc47b74ce46bc9a56877a2a37b5	top 10 software product of 1999				John Dill	2000	IEEE Computer Graphics and Applications			Visualization	-76.11317971360847	23.566390965651024	124224
e4920c36a64223000c72b769dca4358254014060	understanding success and failure profiles of erp requirements engineering: an empirical study	enterprise resource planning standards organizations packaging application software business process re engineering creep telecommunication standards software standards context modeling software packages;empirical study;formal specification;maturity assessment framework enterprise resource planning requirements engineering erp;maturity model;requirements engineering;erp;requirement engineering;capability maturity model;maturity assessment framework;enterprise resource planning;process model;formal specification capability maturity model enterprise resource planning	Organizations adopting Enterprise Resource Planning (ERP) are also adopting standard ERP- vendor-specific process models for engineering their requirements. Making successfully a live process out of such a model is hard. Maturity assessment frameworks can help ERP adopters identify and understand those practices which help their ERP processes succeed and those which do not. This paper deploys a Requirements Engineering maturity model to examine variations in instantiations of a standard ERP RE process. We draw on our previous results and our lessons learnt from eight years of experience in using ERP RE processes.	capability maturity model;erp;enterprise resource planning;failure cause;requirement;requirements engineering	Maya Daneva	2007	33rd EUROMICRO Conference on Software Engineering and Advanced Applications (EUROMICRO 2007)	10.1109/EUROMICRO.2007.58	process;reliability engineering;leancmmi;computer science;systems engineering;engineering;software engineering;requirements engineering;process management;service integration maturity model;capability maturity model	SE	-68.35524137686302	21.067856478379966	124260
464424ede5a61c27cdc970163a4be3b9a756344c	design science methodology: principles and practice	utility programs software engineering;qualitative research;ethnography;qualitative methods;software engineering conferences ieee computer society usa councils software psychology programming;empirical software engineering;software engineering;sensitivity analysis;software engineering design science methodology curiosity driven scientists utility driven engineers stakeholder motivated evaluation criteria omit trade off sensitivity analysis;evaluation criteria;utility programs;design science;empirical research	Design scientists have to balance the demands of methodological rigor that they share with purely curiosity-driven scientists, with the demands of practical utility that they share with utility-driven engineers. Balancing these conflicting demands can be conceptually complex and may lead to methodological mistakes. For example, treating a design question as an empirical research question may lead to researcher to omit the identification of the practical problem to solve, to omit the identification of stakeholder-motivated evaluation criteria, or to omit trade-off and sensitivity analysis. This tutorial aims to clear up this methodological mist in the case of software engineering (SE) research.	software engineering	Roel Wieringa	2010	2010 ACM/IEEE 32nd International Conference on Software Engineering	10.1145/1810295.1810446	software engineering process group;computer science;systems engineering;engineering;knowledge management;qualitative research;software design;social software engineering;software development;software engineering;software construction;management science;ethnography;management;software requirements	SE	-65.1906388275311	18.345561854671306	124503
10c8dcdf97ed5dc380f9e8d9cc876d41e82be855	multivendor deployment integration for future mobile networks		During the last few years, we have seen a tremendous explosion in the range of possibilities when speaking about software delivery. The web-scale IT capabilities have evolved drastically and complex web-based applications have adapted rapidly in an ever changing world where user experience is in the focus. Terms like Agile, Cloudification, microservices or DevOps are lately on the crest of the wave.		Manuel Perez Martinez;Tímea László;Norbert Pataki;Csaba Rotter;Csaba Szalai	2018		10.1007/978-3-319-73117-9_25	computer engineering;computer science;microservices;discrete mathematics;software;user experience design;devops;software deployment;agile software development	Mobile	-65.30885053858341	22.51778348033921	124696
28ecacf4cc87fbc3d6d89c459a6bc11476d312c2	questionnaire report on matter relating to software architecture evaluation	system architecture utilization software architecture evaluation quality attributes software architecture artifact utilization;software quality software architecture;utilization software architecture quality attributes eval uation;conference paper;software computer architecture software architecture software reliability sociology statistics	Evidence of the relationship between software architecture including it's styles/patterns and quality attributes continues to grow, but largely remains an art rather than a science in terms of being able to predict a relevant architecture from (known) quality attributes. The aim of this paper is to point out those aspects that influence utilization of software architecture artefacts and their evaluation by software developers, and is part of a continuing study the results of which are intended to aid professional software/system developers with their decisions surrounding choice of (concrete) software architectures. The earlier part of the study produced an analysis report based on a survey titled “Questionnaire on matters relating to Software Patterns - 2012”. The survey was issued to software developers possessing more than 5 years experience, and produced significant results which, in turn, led to the need for this second survey. Ninety seven (97%) percent of the participants, from six different nations, answering the first questionnaire supported this further investigation.	list of system quality attributes;software architecture;software architecture description;software developer;software documentation;software industry;systems architecture	Hassan Almari;Clive Boughton	2014	15th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)	10.1109/SNPD.2014.6888685	enterprise architecture framework;functional software architecture;reference architecture;software architecture;architecture tradeoff analysis method;verification and validation;computer science;applications architecture;social software engineering;software development;software design description;software engineering;software construction;software architecture description;resource-oriented architecture;software deployment;software quality;systems architecture;software system;software peer review	SE	-65.82358753309428	27.52015937706473	124824
706fa2b1925b8002219f28ee88e6c86c72091002	getting and staying agile	software development;face to face	The human side of software development thrives on face-to-face interaction and teamwork.	agile software development	David L. Largent	2010	ACM Crossroads	10.1145/1836543.1836555	simulation;computer science;knowledge management;software development	HCI	-65.35584949808229	21.755797315908175	124844
553bb053cc63db3eb861457bec2596ac22838153	use of non-it testers in software development	software testing;tester training;software development process;software development;process improvement;testing process improvement	Because of a shortage of IT specialists, many companies which are not involved in software development business are forced to use employees who have minimal or no any knowledge about software development as testers. The author of this paper has used years of experience in working with such testers to provide a description of them, looking also at their most typical testing styles and the problems which occur for testers, their colleagues and bosses, and the overall software development processes. Non-IT testers often feel like second-class employees, because they are forced to work in an environment in which they do not have sufficient skills. This paper reviews issues which should be taken into account when training these testers, including the question of what exactly they should be taught. Examples and conclusions are used to provide advice on the more effective use of non-IT testers to achieve positive results.	software development process	Vineta Arnicane	2007		10.1007/978-3-540-73460-4_17	test strategy;pair testing;systems engineering;engineering;package development process;operations management;software development;software engineering;software testing;software development process	SE	-67.78392610880056	26.073105952283477	124913
c37c175df027d883cbcb219cac2a5e62f19ca166	teaching cyber physical systems engineering		CPS engineers need to possess both technical and social skills to run CPS-engineering projects successfully. Especially social skills are crucial as the project fails are mostly caused because of lacking social skills of project members. Besides strong social skills, CPS engineers need to have a wide range of various technical skills as the products they deal with are getting increasingly complex integrating hardware, software and some kinds of communication mechanism with their environment. Students studying CPS engineering need to be well prepared for their future jobs. Therefore, they need to get an opportunity to face with realistic project situations. In this work we describe our experience gathered during the first run of a CPS engineering course based on a novel task-centric holistic agile teaching approach (T-CHAT).	agile software development;automated planning and scheduling;computer engineering;holism;job stream;occupations;systems engineering;technical documentation;meeting	Juho M&#x00E4;ki&#x00F6;;Elena M&#x00E4;ki&#x00F6;-Marusik;Eugeny Yablochnikov;Valery Arckhipov;Kirill Kipriianov	2017	IECON 2017 - 43rd Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2017.8216597	systems engineering;control engineering;cyber-physical system;engineering;software;agile software development;social skills	DB	-65.46221899326828	19.851979110212103	124923
a5c62b78ee8ac5a347e3f162eabc167f313d5e79	teaching devops in corporate environments - an experience report		This paper describes our experience of training a team of developers of an East-European phone service provider. The training experience was structured in two sessions of two days each conducted in different weeks with a gap of about fifteen days. The first session was dedicated to the Continuous Integration Delivery Pipeline, and the second on Agile methods. We summarize the activity, its preparation and delivery and draw some conclusions out of it on our mistakes and how future session should be addressed.	agile software development;continuous integration;devops	Manuel Mazzara;Alexandr Naumchev;Larisa Safina;Alberto Sillitti;Konstantin Urysov	2018		10.1007/978-3-030-06019-0_8	systems engineering;service provider;computer science;devops;agile software development	HCI	-68.67548123629257	24.48780226973813	124939
896bbd88902d3bc69c07c925cb27db310d2c9ba5	agile software development in large organizations	agile software development;agile methods;new technology;project management;software process improvement;programming software engineering mission critical systems driver circuits data analysis companies costs productivity software maintenance software quality;software management;project management organisational aspects programming software process improvement software management;software development;programming;software project management agile software development software experience center organizational needs extreme programming software process improvement software engineering;organisational aspects	I n recent years, the use of, interest in, and controversies surrounding agile methods have all increased dramatically—as has anecdotal evidence for agile methods’ effectiveness in certain environments and for specific project types. Exactly in which environments and under what conditions agile methods work remains unclear, however. A development team at Motorola, for example, noted that, “a plethora of subjective evidence exists to support the use of agile development methods on non-life-critical software projects.”1 Yet the team found no information about using the approach for its particular development focus: mission-critical software products. This shows the need for more evidence that a new technology works in a certain context before developers promote and deploy it on a larger scale. Although most organizations have similar needs, the need to see compelling evidence before adopting new methods looms greater in large organizations because of their complexity and the need to integrate new technologies and processes with existing ones. To further evaluate agile methods and their underlying software development practices, several Software Experience Center (SEC) member companies initiated a series of activities to discover if agile practices match their organizations’ needs. Although each organization evaluated agile methods according to its specific needs, here we attempt to generalize their findings by analyzing some of their common experiences in the particular context of large organizations with well-established structures and processes. We base this analysis on experience collected and shared among four SEC members—ABB, DaimlerChrysler, Motorola, and Nokia—and focus on the following areas:	agile software development;computer security;mission critical	Mikael Lindvall;Dirk Muthig;Aldo Dagnino;Christina Wallin;Michael Stupperich;David Kiefer;John May;Tuomo Kähkönen	2004	IEEE Computer	10.1109/MC.2004.231	project management;personal software process;verification and validation;software engineering process group;extreme programming practices;software project management;package development process;software evolution;social software engineering;software development;software engineering;release management;software construction;agile software development;software walkthrough;software documentation;empirical process;software analytics;management;lean software development;software deployment;software development process;software peer review	SE	-68.6430799238127	22.506355289311962	125104
9aa81b548451759f45a9be8a95fc6f9a84434540	agile architecture - changing application servers	software architecture file servers;engineering team;file servers;application server;architectural change;incremental delivery;software architecture;application software open source software programming profession software testing computer architecture maintenance engineering team working investments software tools project management;agile architecture;sacrifice one pattern;incremental delivery agile architecture engineering team architectural change sacrifice one pattern	"""Some projects are simply too big to finish on the release schedule that you want to maintain. Rally's agile engineering team delivered a very disruptive architectural change lasting nine months in parallel with three releases. This paper will show how this was done without prolonging the usual release cycles and without technically crippling our product or doing a lot of throwaway work. The main elements of our approach were: the """"sacrifice one"""" pattern, incremental delivery of the architectural change when possible, technical infrastructure modifications to support incremental changes to the architecture, and addressing the biggest risk first. When we were close to finished, we added the whole team for the final push to release with the new architecture. The end result was three successful releases of the existing system prior to the final release rolling out the new architecture."""	agile software development;software release life cycle	Veljko Krunic	2007	Agile 2007 (AGILE 2007)	10.1109/AGILE.2007.7	enterprise architecture framework;reference architecture;software architecture;space-based architecture;architecture tradeoff analysis method;real-time computing;simulation;architectural pattern;systems engineering;engineering;release management;solution architecture;software architecture description;resource-oriented architecture	Arch	-68.55865473734049	26.370966723392492	125216
422daef9f348c57e56872f79bb73414f45279131	teaching automated test case generation	automated test case generation software engineering education white box testing;quality assurance program testing computer science education software quality teaching;quality assurance;generation;software testing;software quality assurance;bepress selected works;student experience;swinburne;test;software engineering;software engineering education;automated test case generation;software engineering automated test case generation teaching software testing software quality assurance university computing curricula;computer science education;teaching automated test case generation;education automatic testing computer aided software engineering software testing computer science software engineering australia software quality information technology communications technology;program testing;test methods;white box testing;automated;teaching methods;software quality;case;teaching	Software testing is a major approach to software quality assurance, but it is relatively neglected in universities' computing curricula. For students majoring in computer science or software engineering, several basic testing methods need to be taught. These testing methods generate test cases based on either specifications or program code. When introducing the testing methods based on program code, it is not easy to let the students experience automated test case generation due to the lack of supporting tools and limited teaching hours. In this paper we report our experience in teaching this topic with limited resources. The evaluation result indicates that our teaching method is effective and can also be adopted in other computer science/software engineering subjects where similar constraints exist.	computer science;software engineering;software quality assurance;software testing;teaching method;test automation;test case	Tsong Yueh Chen;Fei-Ching Kuo;Zhiquan Zhou	2005	Fifth International Conference on Quality Software (QSIC'05)	10.1109/QSIC.2005.61	test strategy;quality assurance;verification and validation;test data generation;software performance testing;white-box testing;manual testing;system integration testing;computer science;systems engineering;engineering;software reliability testing;software development;software engineering;software construction;software testing;test case;test management approach;software quality analyst;computer engineering	SE	-65.6229692167124	27.125039365502314	125678
05cf8978c2ba45f471c9ac91f7117e2f22deb06b	requirements engineering for software product lines: a systematic literature review	computacion informatica;grupo de excelencia;requirements engineering;ciencias basicas y experimentales;requirement engineering;systematic literature review;product line engineering;software product line;software product lines	Context: Software product line engineering (SPLE) is a growing area showing promising results in research and practice. In order to foster its further development and acceptance in industry, it is necessary to assess the quality of the research so that proper evidence for adoption and validity are ensured. This holds in particular for requirements engineering (RE) within SPLE, where a growing number of approaches have been proposed. Objective: This paper focuses on RE within SPLE and has the following goals: assess research quality, synthesize evidence to suggest important implications for practice, and identify research trends, open problems, and areas for improvement. Method: A systematic literature review was conducted with three research questions and assessed 49 studies, dated from 1990 to 2009. Results: The evidence for adoption of the methods is not mature, given the primary focus on toy examples. The proposed approaches still have serious limitations in terms of rigor, credibility, and validity of their findings. Additionally, most approaches still lack tool support addressing the heterogeneity and mostly textual nature of requirements formats as well as address only the proactive SPLE adoption strategy. Conclusions: Further empirical studies should be performed with sufficient rigor to enhance the body of evidence in RE within SPLE. In this context, there is a clear need for conducting studies comparing alternative methods. In order to address scalability and popularization of the approaches, future research should be invested in tool support and in addressing combined SPLE adoption strategies. 2010 Elsevier B.V. All rights reserved.	requirement;requirements engineering;scalability;software product line;systematic review	Vander Alves;Nan Niu;Carina Frota Alves;George Valença	2010	Information & Software Technology	10.1016/j.infsof.2010.03.014	systematic review;systems engineering;engineering;software engineering;management science;requirements engineering;management	SE	-70.72508067044836	22.48624055987922	125772
46a5c84d016e8ccd4562363a7df53a70f753a5f7	comprehension support during knowledge transitions: learning from field	knowledge transition;field study;reverse engineering;java	Knowledge Transition (KT) of legacy applications is a critical activity, often determining the quality of maintenance in the early stages of a maintenance life-cycle. We developed an integrated reverse engineering tool-suite that bootstraps the KT process by providing knowledge recipients insights to application structure, quality and functionality. The tool-suite is based on an in-depth study with KT practitioners and a comparative study of existing tools. We evaluated the benefits of the tool-suite during KT in real-life projects. In this talk, we report our learning from the study and evaluation phases.	kosterlitz–thouless transition;list comprehension;real life;reverse engineering	Vikrant S. Kaulgud;K. M. Annervaz;Janardan Misra;Gary Titus	2014		10.1145/2597008.2597804	computer science;systems engineering;engineering;knowledge management;data science;programming language;java;reverse engineering;field research	HCI	-64.92552622242118	23.948616027578627	126345
0af90cd560e2e26ec82ff64f3261b1edbd8cacab	open source software development: expectations and experience from a small development project	software development process;large scale;open source software development;source code;software process;open source software	Open Source Software (OSS) is software that provides access to its source code in order to allow users to improve and redistribute the software. The emergence of OSS has introduced new ways to develop, test, and maintain software. While several success stories about large-scale OSS projects are reported, little research has been done on how small-scale OSS projects are managed by OSS developers. This paper reports preliminary findings from our experience with a small OSS project, while discussing differences between software processes in large- and small-scale OSS developments.	emergence;open sound system;open-source software;software development	Adanna Ezeala;Hyunju Kim;Loretta A. Moore	2008		10.1145/1593105.1593168	personal software process;long-term support;verification and validation;team software process;software project management;systems engineering;engineering;package development process;backporting;social software engineering;software framework;software development;software design description;software engineering;software construction;software as a service;database;software walkthrough;software analytics;software deployment;software development process;software quality;software peer review	SE	-67.36552239375744	22.218049979598394	126347
2c150d08f5318b52dbbb8d9bca0039bc16438d96	contributing to eclipse: a case study		Open source software has gained a lot of well-deserved attention during the last few years. Eclipse is one of the most successful open source communities providing an open development environment and an application lifecycle platform. The main aim of this paper is to describe a case study on contributing to the Eclipse open source community and report experiences. The most important experiences are related to building an architecture model repository tool as an Eclipse plug-in and starting a new community around it.	eclipse;open-source software;plug-in (computing)	Katja Henttonen;Mari Matinlassi	2007			thiourea;animal science;eclipse;chemistry	SE	-63.955705127957465	23.267866566625184	126504
f9fb75b42acae3c10e3cd3240c4ba33492c99125	guest editorial: special section on regression testing	ucl;discovery;theses;conference proceedings;digital web resources;ucl discovery;open access;datavetenskap datalogi;ucl library;book chapters;open access repository;ucl research	This issue of the Software Quality Journal contains a special section on Regression testing. Regression testing used to be considered as a special type of testing activity that is performed to prevent regression faults, i.e. damages to existing features, introduced by recent modifications to the software. This was a gigantic task involving an infeasible number of test cases, and so research has focused on how to optimise the test suites for a long time. However, in the days of agile and globally distributed development, cloud computing, and app markets, software is continuously evolving at such a lightning pace that, really, regression testing cannot be left out as a separate activity at the end of testing. The concept of regression faults and test suite optimisation should permeate testing activities of all kinds at all layers. The papers in the special section reflect the wide spectrum of domains and technical granularities that regression testing can be considered in. The paper ‘‘Influences on Regression Testing Strategies in Agile Software Development Environments’’ considers the influences of regression testing techniques on agile development on a strategic level. It provides insights into industry practice and needs on regression testing, based on three industrial experience reports. The paper ‘‘Identifying the Effects of Modifications as Data Dependencies’’ analyses the precise impact of modifications for more effective test optimisation. We believe that the diversification in the angles from which to consider regression testing will be the key to the wider adoption of the techniques we have developed so far and will develop in the future.	agile software development;cloud computing;data dependency;diversification (finance);mathematical optimization;regression testing;software quality;test case;test suite	Shin Yoo;Per Runeson	2014	Software Quality Journal	10.1007/s11219-014-9255-1	computer science;engineering physics	SE	-68.17452743223156	23.573566161552023	126720
a83d6b49baa49e8fc0302b9618b8a690ab90c447	a practical model for evaluating the energy efficiency of software applications	software measurement;green software;part of book or chapter of book	Evaluating the energy efficiency of software applications currently is an ad-hoc affair, since no practical and widely applicable model exists for this purpose. The need for such an evaluation model is pressing given the sharp increase in energy demand generated by the ICT industry. In particular, we need to get in control of our software applications since they play a key role in driving the consumption of energy. This paper proposes MESA, a Model for Evaluating the Energy Efficiency of Software Applications. MESA provides a practical breakdown of energy efficiency into measurements that can be applied to software applications in relation to the quantity of work they deliver. This approach makes it possible to measure and control energy efficiency similar to other software qualities such as performance efficiency or maintainability. Furthermore, we report on a case study in which the model was applied to an operational software system of the Software Improvement Group (SIG), a software advisory firm based in the Netherlands. The case study provides evidence that the proposed model is able to identify energy consumption hotspots and efficiency bottlenecks within software applications.	gqm;hoc (programming language);hotspot (wi-fi);mesa;software metric;software system	Georgios Kalaitzoglou;Magiel Bruntink;Joost Visser	2014		10.2991/ict4s-14.2014.9	verification and validation;simulation;software sizing;systems engineering;engineering;package development process;operations management;software framework;component-based software engineering;software development;software design description;software construction;software deployment;software requirements;software metric;avionics software	SE	-70.81297001377878	29.621681386776206	126906
3004b24539099be36a048c8156fab9b1d3494f74	providing value to customers in software development through lean principles	software engineering;software development	Lean thinking has created substantial benefits for a variety of industries. Although it is not easily apparent, the same principles can be utilized in reducing lead times for software development. Fundamentally, lean principles leverage the benefits of software engineering best practices to improve the work flow and the tactical management of the project. By managing the project more efficiently and reducing waste, tremendous performance benefits can be achieved. This article seeks to present and articulate a number of key lean principles in the context of software development. The goal is to provide insight into practical strategies for making trade-offs between the core lean principles of providing the highest possible customer value, maximizing work flow, and eliminating waste in the context of specific real world software development situations. Copyright  2008 John Wiley & Sons, Ltd.	best practice;john d. wiley;lean integration;software development;software engineering	Merwan Mehta;David Anderson;David Raffo	2008	Software Process: Improvement and Practice	10.1002/spip.367	lean project management;lean laboratory;personal software process;software engineering process group;systems engineering;engineering;operations management;software development;industrial engineering;software engineering;management;lean software development;goal-driven software development process;software development process;lean it	SE	-69.24914710225288	22.99595318913732	127422
b814013f8768a321dd9db1734669eda1a5b940ba	experiences in managing an automotive requirements engineering process	automotive engineering;daimlerchrysler passenger car development automotive requirements engineering software based systems specification documents;formal specification;formal specification automotive engineering;automotive engineering engineering management conference management;requirement engineering	The specification volume for all software-based systems that are built in a modern car has passed the 20,000 pages mark. Even for a single component, we find specification documents comprising several hundred pages. Clearly, such specification documents cannot be created and changed simply and quickly. We hence need a systematic process to elicit and maintain, negotiate and validate all requirements, i.e. a proper requirements engineering process. We present an example for such an automotive requirements engineering process and the instruments we employed to manage this process. The experiences are drawn from projects at DaimlerChrysler passenger car development. The paper sketches the requirements engineering process used, the core management instruments deployed, e.g. a feature list, and observations gained in utilizing this process.	algorithm;requirement;requirements engineering	Nadine Heumesser;Frank Houdek	2004	Proceedings. 12th IEEE International Requirements Engineering Conference, 2004.	10.1109/RE.2004.20	requirements analysis;software requirements specification;computer science;systems engineering;engineering;requirement;software engineering;system requirements specification;automotive engineering;formal specification;functional specification;requirements engineering;manufacturing engineering	SE	-63.10575365333033	21.359613391521286	127512
5a9ed073595d647e51d59f85edb531d35ba020a7	the impact of process maturity on defect density	software engineering software quality measurement companies software reliability;software quality capability maturity model;defect density;defect density software quality software process;capability maturity model;capability maturity model integration process maturity defect density software engineering process structure product quality maturity level cmmi assessment model software process software quality;software quality;software process	Context: A common assumption in software engineering is that a more structured process delivers higher quality products. However, there are limited empirical studies that support this assumption. Objective: In this paper we analyze 61 projects looking for a relationship between process structured and quality of the product. The structure is considered under two dimensions: level of maturity (as measured by the CMMI assessment model) and type (e.g. TSP, RUP). The quality of the product is measured in terms of Defect Density (DD) defined as the number of delivered defects divided per size. Results: We found a small and statistically not significant difference of DD between the projects developed under CMMI and those that are not developed under CMMI. Considering the CMMI levels, the pair (CMMI 1, CMMI 3) is characterized by a statistically significant different DD. CMMI 1 exhibiting higher DD than CMMI 3. By comparing different software processes with each other we found that Hybrid process exhibits statistically significant lower DD than Waterfall. Conclusion: Software process in either dimension, level of maturity and type has an impact on the software quality but smaller than one might expect.	capability maturity model integration;software bug;software engineering;software quality;waterfall model	Syed Muhammad Ali Shah;Maurizio Morisio;Marco Torchiano	2012	Proceedings of the 2012 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement	10.1145/2372251.2372308	standard cmmi appraisal method for process improvement;reliability engineering;software sizing;leancmmi;systems engineering;engineering;capability maturity model integration;software engineering;capability maturity model;software development process;software quality	SE	-65.73812194699359	29.634134259628926	127601
83978eedf3ca2f1935ad19268d5d63d27b6e76fc	keynote speaker 2: cyber ranges: the (r)evolution in cybersecurity training		The consolidation of cyber threats as a primary concern of governments, the industry and society in general along with the ever increasing diversity and complexity of technology lie behind the recent explosion in the demand for highly skilled and trained cybersecurity professionals. In regard to this, much effort has been expended and many initiatives have been pursued in recent years, both from academia (e.g. graduate and postgraduate specialisations), industry (e.g. professional certifications, training programmes, technological training platforms) and governments (e.g. standardisation of training curricula, joint education and training programmes at international level). In spite of this, the reality shows that the number of proficient cybersecurity professionals produced is still lagging behind the actual needs and, contrary to what may be expected, the situation is getting worse.	computer security	Jorge Lopez Hernandez-Ardieta	2016		10.1109/ICITST.2016.7856653	simulation;engineering;knowledge management;management	Vision	-71.00790195577346	26.197584812428154	127765
6af54c37ed68e1ac917be2bae48125ee24a2d58b	ground rules for software maintenance	legislation;intellectual property;software maintenance;software management software maintenance industrial property legislation computer facilities consultancies;software management;restrictions identification software maintenance us congress bill third party computer service companies licensed software intellectual property user rights agreement types;computer facilities;consultancies;industrial property;software maintenance licenses acceleration law computer bugs intellectual property circuits software design read write memory software debugging	homas Swift, an independent software consultant, was ready for action. He’d just received a T distress call from Carla Carmichael, president of Soften-the-Blow Computer Systems, which designs software applications. Its popular Turbo Charge-UR-Engine can double processing speed. Carla called Tom to examine another recently purchased package called Speed, which can be used with Turbo Charge-UR-Engine to further increase processing speed.	distress (novel);software maintenance;swift (programming language);tom;ur, ur/web	Irah H. Donner	1995	IEEE Computer	10.1109/2.467605	software review;personal software process;medical software;long-term support;software project management;package development process;social software engineering;software development;software design description;operating system;software engineering;software as a service;software walkthrough;software maintenance;management;law;software deployment;computer security;intellectual property;software quality;software system;software peer review	Arch	-68.0534755832	27.49628525356325	127890
d7bfa7c00d6d4dba74027bfd43207881b37370dd	measuring agility and architectural integrity		Most organizations that depend on software are pursuing more flexible architectures and more agile life-cycle processes to increase business flexibility. What does agility look like, and how do we measure it? A truly agile project or organization should experience changes that are more straightforward and more predictable. Consequently, improvements are best measured by gauging the change trends in software baselines. A well-accepted tenet of software engineering states, “The later you are in the life cycle, the more expensive things are to fix.” This iron law, an artifact of a waterfall culture, should not apply if you have transformed to agile software delivery with a well-architected system. This bold assertion is the root of the metric patterns presented in this paper.	agile software development;baseline (configuration management);benchmark (computing);best practice;continuous integration;executable;information needs;integration testing;new product development;overhead (computing);software deployment;software engineering;software industry;unit testing;waterfall model	Walker Royce	2011	Int. J. Software and Informatics		software engineering;management	SE	-68.16502395198248	23.980695482152495	127903
d277258abb553ee01daddc55ca684a7ce8addae1	software measurement - establish, extract, evaluate, execute	comprehensive introduction;hands-on presentation;industry leader;dumke detail knowledge;software measurement;hands-on experience;metrics community;relevant measurement tool;case study;large reference list	In this comprehensive introduction to software measurement, Ebert and Dumke detail knowledge and experiences about the subject in an easily understood, hands-on presentation. The book describes software measurement in theory and practice as well as provides guidance to all relevant measurement tools and online references. In addition, it presents hands-on experience from industry leaders and provides many examples and case studies from Global 100 companies. Besides the many practical hints and checklists, readers will also appreciate the large reference list, which includes links to metrics communities where project experiences are shared.	software measurement	Christof Ebert;Reiner R. Dumke	2007		10.1007/978-3-540-71649-5		OS	-66.59719279499701	25.957175962409696	127906
045f72de3f5d04160d85ba12df5bef0ecb12a504	a framework for technological research results assessment	technology transfer;innovation management;business information systems	A framework for technological research results assessment Elsa Marcelino-Jesus, João Sarraipa, Miguel Beça & Ricardo Jardim-Goncalves To cite this article: Elsa Marcelino-Jesus, João Sarraipa, Miguel Beça & Ricardo JardimGoncalves (2016): A framework for technological research results assessment, International Journal of Computer Integrated Manufacturing, DOI: 10.1080/0951192X.2016.1145806 To link to this article: http://dx.doi.org/10.1080/0951192X.2016.1145806	activity diagram;ar (unix);business analysis;computer-integrated manufacturing;enterprise life cycle;exploit (computer security);gqm;interpreter (computing);joão pavão martins;nl (complexity);openness;requirement;software deployment;software quality;universal instantiation;usability;user requirements document;verification and validation	Elsa Marcelino-Jesus;João Sarraipa;Miguel Ferro de Beca;Ricardo Jardim-Gonçalves	2017	Int. J. Computer Integrated Manufacturing	10.1080/0951192X.2016.1145806	innovation management;systems engineering;engineering;knowledge management;marketing;management science;management;mechanical engineering	Visualization	-63.81855184843119	21.16428057765846	128226
4c06567f280f319c6a820fe8d6c333bc5eb4b8a4	software development governance (sdg)	life cycle;governance;software development governance;software development;governance life cycle;decision rights	Governance in a specific organization is an iterative process that starts with the assignment of roles and decision rights as per goals that are set, continues with the establishment of a set of mechanisms to be activated on a specific scope within the organization, and ends with the assessment that leads to the refinement of the goals accordingly. This one-day workshop focuses on software development governance and deals with the issues that are special to software organizations.	iteration;refinement (computing);software development	Yael Dubinsky	2008		10.1145/1370175.1370246	corporate governance;biological life cycle;systems engineering;software development;software engineering;project governance;management	SE	-67.37711573901282	22.087400835662244	128318
9719b7c319186a5a23dccfdd5e1dfbe039f107b0	startups and technical debt: managing technical debt with visual thinking		This position paper addresses the issue of startups and technical debt. Early stage startups condition makes creating technical debt an almost mandatory decision. Not managing technical debt can be deadly for a startup as fast product iteration cycle is necessary. We here introduce a technique for managing technical debt based on Visual Thinking. The technique addresses the problem of knowing how much debt is in place and how it is affecting the development cycle.	iteration;technical debt	Marcos Chicote	2017	2017 IEEE/ACM 1st International Workshop on Software Engineeting for Startups (SoftStart)	10.1109/SoftStart.2017.6	finance;position paper;visual thinking;debt;visualization;operations management;technical debt;business	SE	-69.01081517724435	23.49355195210366	128399
6985fb1189a0623af3755d8377f83c6e37747254	developing processes to increase technical debt visibility and manageability - an action research study in industry	software process improvement;technical debt;technical debt management;action research	The knowledge on technical debt and its management has increased in recent years. The interest of academia and industry has generated many viewpoints on technical debt. Technical debt management consists of technical and organizational aspects, which make it a challenge in software development. To increase technical debt visibility and manageability, new processes must be developed and thoroughly empirically tested for their applicability. In this paper, we use the action research methodology to design processes for identification, documentation, and prioritization of technical debt. Our partner in this research is a large Nordic IT company Tieto, currently in a need for new ways to improve their technical debt management. The results include a set of processes and templates that were successfully used to identify and document technical debt. The identified technical debt items were later prioritized based on evaluation by Tieto employees. Tieto was able to create a prioritized technical debt backlog, which is now used for reduction activities to create healthy and sustainable product for future. This was considered as a success and therefore Tieto is planning to use the same process to other product lines in near future.	documentation;self-replication;software development;technical debt	Jesse Yli-Huumo;Andrey Maglyas;Kari Smolander;Johan Haller;Hannu Törnroos	2016		10.1007/978-3-319-49094-6_24	computer science;systems engineering;operations management;action research;technical debt;management	SE	-68.96949011516199	21.06227846014346	128406
92abd3f4c7e2f6e10e5434550eca95e4a97114d6	requirements engineering during global software development: some impediments to the requirements engineering process: a case study	requirement engineering;requirements engineering;software development	Requirements engineering is not straightforward for any software development team. Developing software when team members are located in widely distributed geographic locations poses many challenges for developers, particularly during the requirements engineering phase. This paper reports on a case study concerning a large software development project that was completed in just seven months between users located in the UK and software developers from an international software house based in New Zealand. The case indicates that while “true” global requirements engineering may be desirable in achieving economy of resources, a “hybrid” structure of requirements engineering processes is more realistic so that lasting relationships with clients may be formed, and requirements engineering activities achieved. The main impediment to the process of requirements engineering during global software development, as recounted by the team members in this case, is communication. Communication issues may be further described in terms of four categories: distribution of the clients and the development team, distribution of the development team, cultural differences between the clients and the development team and cultural differences among the development team	requirement;requirements engineering;software developer;software development;software house	Jo Hanisch;Brian J. Corbitt	2004				SE	-66.88176891637139	21.09650760593791	128641
52a96c2810634fbca2b52dd968d840ac49f2a673	a model of open source developer foundations		Many community open source projects are of high economic relevance. As these projects mature, their leaders face a choice of continuing the project as is, making the project join an existing foundation, or creating their own foundation for the project. This article presents a model of open source developer foundations that project leaders can use to compare existing foundations with their needs or to design their own. The model is based on a three-iteration qualitative study involving interviews and supplementary materials review. To demonstrate its usefulness, we apply the model to nine foundations and present their organizational choices in a comparative table format.	control table;iteration;open-source software;relevance	Dirk Riehle;Sebastian Berschneider	2012		10.1007/978-3-642-33442-9_2	knowledge management;computer science;qualitative research	AI	-74.44366360802661	21.249960425346774	129120
34badc0a116df17f451ffb019ea8bad1691ae6b6	a survey on reliable distributed communication		From entertainment to personal communication, and from business to safety-critical applications, the world increasingly relies on distributed systems. Despite looking simple, distributed systems hide a major source of complexity: tolerating faults and component crashes is very difficult, due to the incompleteness of (remote) knowledge. The need to overcome this problem, and provide different guarantees to applications, sparked a huge research effort and resulted in a large body of communication protocols, and middleware. Thus, it is worthwhile to survey the state of the art in distributed systems, with a particular emphasis on reliable communication. We discuss key concepts in reliable communication, such as interaction patterns (e.g., one-way vs. request-response, synchronous vs. asynchronous), reliability semantics (e.g., at-least-once, at-most-once), and reliability targets (e.g., message, conversation), and we analyze a wide set of current communication solutions, which map to the different concepts. Building on the concepts, we analyze applications that have different reliable communication needs. As a result, we observe that, in most cases, elaborate communication solutions offering superior guarantees are purely academic efforts that cannot compete with the popularity and maturity of established, albeit poorer solutions. Based on our analysis, we identify and discuss open research topics in this area.		Naghmeh Ivaki;Nuno Laranjeiro;Filipe Araújo	2018	Journal of Systems and Software	10.1016/j.jss.2017.03.028	real-time computing;simulation;computer science;engineering;operating system;software engineering;distributed computing;management	HPC	-71.29704685119863	25.64950841657522	129218
86a181f3e55858527713bdef12f36e743fd117be	software engineering considered harmful	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;software engineering;ciencias basicas y experimentales;tecnologias	In search of a resolution to the ongoing software crisis.	software crisis;software engineering	Dennis de Champeaux	2002	Commun. ACM	10.1145/581571.581608	operating system;software engineering	SE	-64.09209787420302	24.892720863637752	129327
b3c3bacdb1e73f35cfef1423c87fc6837b9bc0b4	comparing apples with oranges? the perceived differences between agile and lean software development processes	agile software development;is project management;agile methods;track 14 project management;info eu repo semantics conferenceobject;lean software development;lean thinking;outsourcing and is development;kanban		agile software development;lean software development	Xiaofeng Wang;Kieran Conboy	2011			lean project management;agile unified process;agile usability engineering;software project management;operations management;agile software development;process management;empirical process;lean software development;software development process;lean it;lean manufacturing	SE	-65.24340677252272	22.019535876246067	129631
706753cc109d32dea59055eb332d7b91a0574a27	adapting the lean enterprise self-assessment tool for the software development domain	software tools iec standards iso standards lean production software development management software houses software standards;software;standards organizations;enterprise;lean transformation;lean software development;iso standards;finland lean enterprise self assessment tool software development domain lean principles software development companies lesat lean advancement initiative lai massachusetts institute of technology mit iso iec 12207 standard life cycle processes lean amplifier ericsson r and d;maintenance engineering;lean production;companies;software engineering;software engineering lean lean software development lean transformation assessment lesat enterprise;software houses;iec standards;software standards organizations companies maintenance engineering iso standards;software standards;software tools;lean;lesat;assessment;software development management	"""Lean principles have attracted the attention of software development companies due to their potential to improve competitiveness. However, the application of such principles in the software domain is still in its infancy. This paper presents a proposal for adapting the Lean Enterprise Self-Assessment Tool (LESAT) to guide the transformation of software development companies toward Lean. LESAT, developed by the Lean Advancement Initiative (LAI) at the Massachusetts Institute of Technology (MIT), has been widely used in other domains. In this study, concepts and expressions of LESAT were analyzed and mapped to software development following the ISO/IEC 12207 standard. Seven assessment items concerning life-cycle processes were modified from the original LESAT. The modified LESAT for software was compared with a lean assessment approach called """"Lean amplifier, """" which has been developed and successfully used in practice by Ericsson R&D in Finland. The results indicated that LESAT may complement lean assessment in the software domain at enterprise level, involving the entire value stream. Moreover, they clearly emphasized the role of leadership in the transformation."""	agile software development;amplifier;iso/iec 12207;lean software development	Teemu Karvonen;Pilar Rodríguez Marín;Pasi Kuvaja;Kirsi Mikkonen;Markku Oivo	2012	2012 38th Euromicro Conference on Software Engineering and Advanced Applications	10.1109/SEAA.2012.51	lean project management;systems engineering;engineering;software engineering;lean software development;lean it;educational assessment;manufacturing engineering;lean manufacturing	SE	-69.80493559569598	18.36591706994673	129756
abe571807d7c274b9c9fda3d143c45cf68d92775	the evolution of an evaluation framework for a text mining system	serveur institutionnel;archive institutionnelle;open access;archive ouverte unige;cybertheses;institutional repository	The Parmenides project developed a text mining application applied in three different domains exemplified by case studies for the three user partners in the project. During the lifetime of the project (and in parallel with the development of the system itself) an evaluation framework was developed by the authors in conjunction with the users, and was eventually applied to the system. The object of the exercise was two-fold: firstly to develop and perform a complete user-centered evaluation of the system to assess how well it answered the users' requirements and, secondly, to develop a general framework which could be applied in the context of other users' requirements and (with some modification) to similar systems. In this paper we describe not only the framework but the process of building and parameterising the quality model for each case study and, perhaps most interestingly, the way in which the quality model and users' requirements and expectations evolved over time. UNDERWOOD, Nancy Louise, LISOWSKA, Agnès. The Evolution of an Evaluation Framework for a Text Mining System. In: Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC). p. 2486-2491	requirement;text mining;user-centered design	Nancy L. Underwood;Agnes Lisowska Masson	2006			engineering;data science;data mining;world wide web	SE	-73.2017723053816	23.361958167635844	130461
a1e2a3e588d6fe750104e2e968d804d761139494	case study on installing a porting process for embedded operating system in a small team	operating system source code;manuals;operating systems manuals organizations maintenance engineering programming;operating system material porting process embedded operating system google android microsoft windows mobile embedded linux operating system source code;operating system material;google android;software engineering embedded systems operating systems computers;maintenance engineering;software engineering;embedded system;embedded systems;microsoft windows mobile;operating system;embedded operating system;embedded linux;porting process;source code;operating system porting process embedded system;organizations;process;programming;operating systems computers;porting;operating systems	Recently as the demand of smart devices increases, the porting of embedded operating systems such as Google Android, Microsoft Windows Mobile, and Embedded Linux, becomes more important. Consequently, the importance of efficient, systematic porting is also raised. Generally, developers initiate embedded operating system porting from getting operating system source codes and materials. After they get source codes, they modify the source codes, and then they test them. To identify porting in detail, we investigated a small porting team which has fifteen members. In this team, each developer has done porting depending on his or her knowledge and experience. Therefore, we tried to find studies for efficient, systematic porting, but we couldn't find sufficient study results. This study aims to analyze porting process in a small organization. Also, we'll suggest productive a porting process and evaluate productivity of the new process through a case study.	android;code;embedded operating system;embedded system;iterative and incremental development;iterative method;linux on embedded systems;microsoft windows;process modeling;smart device;software development process;waterfall model;windows mobile	DongSeok Cho;Doo-Hwan Bae	2011	2011 Fifth International Conference on Secure Software Integration and Reliability Improvement - Companion	10.1109/SSIRI-C.2011.14	maintenance engineering;porting;embedded system;programming;embedded operating system;real-time computing;computer science;organization;operating system;process;source code	Embedded	-68.59135688683463	29.245452947090907	130466
65b7e00e642face6664243917c113f66269f3e59	the use of product measures in tracking code development to completion within small to medium sized enterprises	software development management dp industry product development project management small to medium enterprises;software;release;project management;project manager;dp industry;companies monitoring software schedules face current measurement testing;small to medium enterprises;testing;small to medium sized enterprise measures release;companies;current measurement;effort estimation;monitoring;product measures;schedules;measures;small to medium sized enterprises;face;product code development;project management product code development small to medium sized enterprises project monitoring product measures product measurement criteria;small to medium sized enterprise;software development management;product measurement criteria;project monitoring;product development	Many companies face the need to produce frequent releases of their software. Yet many do not manage to release on time and within their development schedule. The reasons for this are numerous. We suggest that an accurate insight into progress of a project towards completion would assist a project manager in balancing the various commercial decisions made through the lifetime of the release. We examine the release cycles of three local companies and find that effort estimation is the predominant means of project monitoring. As a solution to difficulties concerning ongoing project monitoring we suggest using product measures and measurement criteria which would assist a project manager when tracking change and progress within a release. We contrast these measures and measure methods to standard change data and suggest that they are more sensitive to the nature of the development activities undertaken.	cost estimation in software engineering	Melanie P. Ware;F. George Wilkie;Mary Shapcott;N. G. Lester	2008	2008 Sixth International Conference on Software Engineering Research, Management and Applications	10.1109/SERA.2008.15	face;project management;measure;schedule;systems engineering;software engineering;software testing;new product development	SE	-66.02346860109252	28.574002585075423	130478
936490fafb1c6fd954d99537fab6638ee5bcacca	tool support for disseminating and improving development practices	engineering;software;project;software process improvement;knowledge management;postmortem review;software engineering;guide;success;programvaruteknik	Knowledge management in software engineering and software process improvement activities pose challenges as initiatives are deployed. Most existing approaches are either too expensive to deploy or do not take an organization’s specific needs into consideration. There is thus a need for scalable improvement approaches that leverage knowledge already residing in the organizations. This paper presents tool support for an Experience Factory approach for disseminating and improving practices used in an organization. Experiences from using practices in development projects are captured in postmortems and provide iteratively improved decision support for identifying what practices work well and what needs improvement. An initial evaluation of using the tool for organizational improvement has been performed utilizing both academia and industry. The results from the evaluation indicate that organizational characteristics influence how practices and experiences can be used. Experiences collected in postmortems are estimated to have little effect on improvements to practices used throughout the organization. However, in organizations where different practices are used in different parts of the organization, making practices available together with experiences from use, as well as having context information, can influence decisions on what practices to use in projects.	commitment scheme;decision support system;documentation;experience;iterative method;knowledge management;scalability;software development process;software engineering;trusted operating system	Martin A Ivarsson;Tony Gorschek	2011	Software Quality Journal	10.1007/s11219-011-9139-6	project;extreme programming practices;computer science;systems engineering;engineering;knowledge management;operations management;software engineering;management science;management	SE	-68.8300870765782	20.848239144677134	130717
276b6eb949ea3fd78210a54f7947e85af2eb3d3f	biological mutualistic models applied to study open source software development	mutualistic system biological mutualistic models open source software development web evolution collaborative work open source initiative interaction level cooperation level software quality software reliability lotka volterra based biological models host parasite interaction concept mutualism social parasites github collaborative platform open source phenomena;web based collaborative work;open source software development;open source software development web based collaborative work population models;software reliability biology groupware public domain software software quality;population models	The evolution of the Web has allowed the generation of several platforms for collaborative work. One of the main contributors to these advances is the Open Source initiative, in which projects are boosted to a new level of interaction and cooperation that improves their software quality and reliability. In order to understand how the group of contributors interacts with the software under development, we propose a novel methodology that adapts Lotka-Volterra-based biological models used for host-parasite interaction. In that sense, we used the concept mutualism from social parasites. Preliminary results based on experiments on the Github collaborative platform showed that Open Source phenomena can be modeled as a mutualistic system, in terms of the evolution of the population of developers and repositories.	experiment;lotka–volterra equations;open-source software;software development;software quality;world wide web	Pablo Loyola;In-Young Ko	2012	2012 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2012.228	simulation;population model;social software engineering;software framework;software development;software analytics;resource-oriented architecture;world wide web;software development process	SE	-63.66127922198698	22.482596641292112	130909
b6812b78b1cf8799b5ae234fe275c1321bcf20b2	nlp-assisted software testing: a systematic review		Context: To reduce manual effort of extracting test cases from natural-language requirements, many approaches based on Natural Language Processing (NLP) have been proposed in the literature. Given the large number of approaches in this area, and since many practitioners are eager to utilize such techniques, it is important to synthesize and provide an overview of the state-of-the-art in this area. Objective: Our objective is to summarize the state-of-the-art in NLP-assisted software testing which could benefit practitioners to potentially utilize those NLP-based techniques, benefit researchers in providing an overview of the research landscape. Method: To address the above need, we conducted a survey in the form of a systematic literature mapping (classification) and systematic literature review. After compiling an initial pool of 57 papers, we conducted a systematic voting, and our final pool included 50 technical papers. Results: This review paper provides an overview of contribution types in the papers, types of NLP approaches used to assist software testing, types of required input requirements, and a review of tool support in this area. Among our results are the followings: (1) only 2 of the 28 tools (7%) presented in the papers are available for download; (2) a larger ratio of the papers (23 of 50) provided a shallow exposure to the NLP aspects (almost no details). Conclusion: We believe that this paper would benefit both practitioners and researchers by serving as an “index” to the body of knowledge in this area. The results could help practitioners by enabling them to utilize any of the existing NLP-based techniques to reduce cost of test-case design and decrease the amount of human resources spent on test activities. Initial insights, after sharing this review with some of our industrial collaborators, show that this review can indeed be useful and beneficial to practitioners.	compiler;download;natural language processing;requirement;software testing;systematic review;technical standard;test case	Vahid Garousi;Sara Bauer;Michael Felderer	2018	CoRR		computer science;body of knowledge;test case;systematic review;natural language processing;software;download;human resources;artificial intelligence	SE	-73.01437138276502	24.993996034839814	131036
2fa555a78d3dd185a8d2adcffe6fd4522f610eba	elicitation of communication inherent risks in distributed software development	software;distributed software development;communication strategies;software risk management software engineering cultural differences project management face companies;project management;qualitative research;distributed processing;risk management;companies;software engineering;communication recommedations risk management distributed software development communication related risks empirical research qualitative research communication strategies;dsd communication inherent risk management distributed software development distributed software projects cultural diversity frequent communication communication effectiveness distributed teams informal communication exploratory empirical qualitative research interview data collection distinct companies;communication related risks;software engineering cultural aspects distributed processing project management risk management;face;communication recommedations;cultural aspects;cultural differences;empirical research	The lack of risk management, communication and understanding of the requirements are actually the main factors related to the low rate of success in software development, more specifically in distributed projects given the characteristics of this type of development. Considering distributed software projects, the main goal of this paper is to show communication inherent risks empirically identified in such type of project, and the strategies and recommendations adopted to mitigate them. For example, we found that to solve misunderstandings that may occur due to the cultural diversity and language we must encourage frequent communication. This frequent communication does not only increases the communication effectiveness, but also develops the cohesion among the distributed teams, resulting in an improvement of the informal communication and establishment of the confidence among members of the distributed team. These findings were obtained from an exploratory empirical qualitative research that collected interview data from project leaders and managers from several software projects from distinct companies. Our findings contribute to a better understanding of the influence of communication process in DSD. It also contributes to the industrial practice so that they can use the results to improve the communication management, minimizing potential problems.	cohesion (computer science);distributed computing;document structure description;requirement;risk management;software development	Ivaldir Honório de Farias Junior;Ryan Ribeiro de Azevedo;Hermano Perrelli de Moura;Dennis S. Martins da Silva	2012	2012 IEEE Seventh International Conference on Global Software Engineering Workshops	10.1109/ICGSEW.2012.18	face;project management;team software process;economics;risk management;systems engineering;engineering;knowledge management;qualitative research;software engineering;management science;empirical research;management;cultural diversity	SE	-71.71227803836415	20.985764831388952	131076
d4dcc754ad90d93b16c35875247292cbc4376077	project failures in small companies	project manager project failures small companies small software development company project management;project management;software development management software houses project management professional aspects human resource management;project manager;software houses;professional aspects;software development;project management programming profession disaster management application software subcontracting databases nose testing contracts personnel;human resource management;software development management	The author relates his experiences in a small software development company. These experiences show that project management is challenging and if the project manager is an obstacle, the project is bound to fail. When it does, it can spell disaster for the manager and anyone who accompanies him or her on a software development journey.	failure	Mohammad Rob	2003	IEEE Software	10.1109/MS.2003.1241374	project management;extreme project management;program management;time management;earned value management;software project management;opm3;systems engineering;knowledge management;project sponsorship;resource management;software development;software engineering;functional manager;human resource management;project risk management;application lifecycle management;project management 2.0;project management triangle;management;project charter;software development process;project planning;project portfolio management	Visualization	-68.70491498707771	25.83193729478115	131252
05ed25ad470a7a3f3dea4d86f300364dba4d1855	planning the software industrial revolution	object oriented programming;software engineering;value rigidity;technology transfer;technology transfer object oriented programming software engineering;computer industry software reusability costs assembly software measurement testing software quality process planning programming profession application software;object oriented;software development;software industry;interchangeable parts technology;software industrial revolution;value rigidity software industrial revolution us history invention technology transfer software development process centered cottage industry interchangeable parts technology object oriented;invention;process centered cottage industry;us history	The author traces the US history of invention and technology transfer from the 1700s to the present and asks whether software development can stop being a process-centered cottage industry by the application of interchangeable parts technology. He maintains that a revolution is needed to accomplish this and outlines the steps of such a revolution. The author clarifies the meaning of object oriented, discusses the value rigidity trap, and provides a commercial example of the approach that he advocates.<<ETX>>	c. william gear;complexity;component-based software engineering;direct manipulation interface;enterprise system;hardware description language;high- and low-level;immutable object;interface metaphor;library (computing);morrow pivot ii;my life as a teenage robot;objective-c;robert;robustness (computer science);self-replicating machine;silk road;software crisis;software development;stepstone;superdistribution;thread (computing);tracing (software);user interface;velocity obstacle	Brad J. Cox	1990	IEEE Software	10.1109/52.60587	personal software process;verification and validation;software sizing;computer science;systems engineering;engineering;package development process;backporting;software design;social software engineering;software framework;component-based software engineering;software development;software design description;industrial engineering;software engineering;software construction;software walkthrough;programming language;object-oriented programming;resource-oriented architecture;software deployment;software development process;software quality;software system	SE	-68.80986987145597	27.144243846576018	131337
c60a4ca05d1d9174222fd3da94b890ecda976fbe	simulation-based workforce assignment in a multi-organizational social network for alliance-based software development	distributed global software development;workforce assignment;agent based simulation;multi objective optimization;software development process;software requirements;social network;open source software development;software development;task control and modeling;organizational management and networks;task management;global software development;software process	The development of alliance-based software requires the collaboration of many stakeholders. These different stakeholders across multiple organizations form a complex social network. The goal of this paper is to develop a novel modeling framework, which will help task managers devise optimal workforce assignments considering both short-term and long-term aspects of the software development process. The proposed framework is composed of an assignment module and a prediction module. For a given task, the assignment module first selects a candidate workforce mix. Based on the candidate workforce mix, the prediction module then predicts the short-term performance (productivity) as well as the long-term performance (workforce training and robustness of the organization) of the organization. Then, the assignment module selects another candidate mix, and this iteration continues until an optimal workforce mix is found. The prediction module and the assignment module are based on an agent-based simulation method and a multi-objective optimization model, respectively. The proposed modeling framework is illustrated with a software enhancement request process in Kuali, an alliance-based open source software development project involving 12 organizations. The constructed framework is executed with varying parameters to demonstrate its use and benefit in the software enhancement process.	simulation;social network;software development	Nurcin Celik;Seungho Lee;Esfandyar Mazhari;Young-Jun Son;Robin Lemaire;Keith G. Provan	2011	Simulation Modelling Practice and Theory	10.1016/j.simpat.2011.07.004	personal software process;verification and validation;team software process;simulation;software engineering process group;software sizing;software project management;systems engineering;engineering;knowledge management;package development process;software design;social software engineering;software framework;software development;software design description;iterative and incremental development;software construction;software walkthrough;software deployment;goal-driven software development process;software development process;software metric	Metrics	-66.06932300571005	20.792950738335826	131345
cdf8f53905191a3b01c33ccb7f7c90f24e43905d	the preferable test documentation using ieee 829		During software development, testing is one of the processes to find errors and aimed at evaluating a program meets its required results. In testing phase there are several testing activity involve user acceptance test, test procedure and others. If there is no documentation involve in testing the phase the difficulty happen during test with no solution. It because no reference they can refer to overcome the same problem. IEEE 829 is one of the standard to conformance the address requirements. In this standard has several documentation provided during testing including during preparing test, running the test and completion test. In this paper we used this standard as guideline to analyze which documentation our companies prefer the most. From our analytical study, most company in Malaysia they prepare document for Test Plan and Test Summary.	software test documentation	Roslina Mohd Sidek;Ahmad Noraziah;Mohd Helmy Abd Wahab	2011		10.1007/978-3-642-22203-0_10	reliability engineering;computer science;software engineering;computer security	Embedded	-66.78928915823064	26.96178060329702	131602
a2c0840629939f93140cc47ca14391239dc7556c	motivating company personnel by applying the semi-self-organized teams principle	agile methods;innovation process;software development process;software engineering;key success factor;self organization	  The only way nowadays to improve stability of software development process in the global rapidly evolving world is to be innovative  and involve professionals into projects motivating them using both material and non material factors. In this paper self-organized  teams are discussed. Unfortunately not all kind of organizations can benefit directly from agile method including applying  self-organized teams. The paper proposes semi-self-organized teams presenting it as a new and promising motivating factor  allowing deriving many positive sides of been self-organized and partly agile and been compliant to less strict conditions  for following this innovating process. The semi-self organized teams are reliable at least in the short-term perspective and  are simple to organize and support.    	self-organization;semiconductor industry	Deniss Kumlander	2009		10.1007/978-90-481-9112-3_41	innovation;personal software process;team software process;self-organization;software engineering process group;agile unified process;agile usability engineering;computer science;knowledge management;social software engineering;software development;software engineering;agile software development;management science;empirical process;lean software development;software development process	Vision	-67.2679660613392	20.448632593678752	131628
8cb42340cb2c023f67ad21e43ae3c61221f1755a	the usage of isbsg data fields in software effort estimation: a systematic mapping study	software effort estimation;systematic mapping study;isbsg data field	The International Software Benchmarking Standards Group (ISBSG) maintains a repository of data about completed software projects. A common use of the ISBSG dataset is to investigate models to estimate a software project’s size, effort, duration, and cost. The aim of this paper is to determine which and to what extent variables in the ISBSG dataset have been used in software engineering to build effort estimation models. For that purpose a systematic mapping study was applied to 107 research papers, obtained after a filtering process, that were published from 2000 until the end of 2013, and which listed the independent variables used in the effort estimation models. The usage of ISBSG variables for filtering, as dependent variables, and as independent variables is described. The 20 variables (out of 71) mostly used as independent variables for effort estimation are identified and analysed in detail, with reference to the papers and types of estimation methods that used them. We propose guidelines that can help researchers make informed decisions about which ISBSG variables to select for their effort estimation models.	cost estimation in software engineering;software development effort estimation;software project management	Fernando González-Ladrón-de-Guevara;Marta Fernández-Diego;Christopher J. Lokan	2016	Journal of Systems and Software	10.1016/j.jss.2015.11.040	computer science;data science;data mining;statistics	SE	-65.33184570691476	30.842860144714496	131649
46fd809e67fd3a34fd2320ad5ec6215349821d30	the effect of checklist in code review for inexperienced students: an empirical study	computer science education;software sensitivity software engineering testing education conferences;educational courses;teaching computer science education educational courses program debugging software quality;student teaching checklist code review inexperienced students defect removal early development stage software quality curricula software engineering student course;program debugging;software quality;teaching	Code review is believed to be an effective technique to remove defects in early development stage and improve software quality. Therefore, it is regarded as one of the basic skills of qualified software engineers. Consequently, most curricula for SE students incorporated knowledge about code review in different courses. However, how to teach students to conduct efficient code review remains challenging. Many reports claimed that using checklist during code review could increase review efficiency (percentage of defects removed in code review). Nevertheless, we found a quite different result through analyzing the data collected from a PSP course took by freshmen. Results indicate that checklist contributes more to helping beginners conduct code review than to improving review efficiency. This finding implies that educators need to properly recognize the role of checklist in code review for students and explore more approaches to help students master skills to conduct efficient code reviews.	experience;software engineer;software quality;software release life cycle	Guoping Rong;Jingyi Li;Mingjuan Xie;Tao Zheng	2012	2012 IEEE 25th Conference on Software Engineering Education and Training	10.1109/CSEET.2012.22	computer science;systems engineering;software engineering;software technical review;software walkthrough;computer engineering;software peer review	SE	-66.12348274373124	27.27286250535312	131662
70daca129bc974cc2e1d04cbf3c225c74456d1fd	problems with software complexity measurement	programming environment;software complexity;performance;parallel searching;distributed algorithm;cartesian product files	Theoretical and methodological problems in the development of program-based measures of software complexity are enumerated. Three issues are analyzed: the potential confounding influence of non-program factors; the desirable features of complexity measures, and the difficulties in validating complexity measures. The analysis suggests that researchers must find ways to control the effects of non-program factors, perhaps by restricting their focus to a well-defined programming environment. Further, both the designers and users of complexity measures must be aware of the inherent limitations of such tools.	integrated development environment;programming complexity	Robert L. Sedlmeyer;Joseph K. Kearney;William B. Thompson;Michael A. Adler;Michael A. Gray	1985		10.1145/320599.320707	distributed algorithm;complexity;performance;computer science;theoretical computer science;worst-case complexity;distributed computing;complexity management;programming complexity	SE	-67.6271260269203	31.648653844520577	131868
d7289913001cd4340455017886fcd3adafd3cd74	a strategic approach for decision making in process centered software engineering environment			software engineering	Inés Bayoudh Saâdi;Yassine Jamoussi;Henda Hajjami Ben Ghézala	2003			goal-driven software development process;systems engineering;software development;computer science;personal software process;software engineering process group;software development process;social software engineering;software design;empirical process (process control model)	SE	-64.62025993821291	21.719765775211833	131999
c9680644819a6306dbc8c77f2937ca155ae867d8	an empirical study on decision making for quality requirements		Abstract Context Quality requirements are important for product success yet often handled poorly. The problems with scope decision lead to delayed handling and an unbalanced scope. Objective This study characterizes the scope decision process to understand influencing factors and properties affecting the scope decision of quality requirements. Method We studied one companyu0027s scope decision process over a period of five years. We analyzed the decisions artifacts and interviewed experienced engineers involved in the scope decision process. Results Features addressing quality aspects explicitly are a minor part (4.41%) of all features handled. The phase of the product line seems to influence the prevalence and acceptance rate of quality features. Lastly, relying on external stakeholders and upfront analysis seems to lead to long lead-times and an insufficient quality requirements scope. Conclusions There is a need to make quality mode explicit in the scope decision process. We propose a scope decision process at a strategic level and a tactical level. The former to address long-term planning and the latter to cater for a speedy process. Furthermore, we believe it is key to balance the stakeholder input with feedback from usage and market in a more direct way than through a long plan-driven process.		Thomas Olsson;Krzystof Wnuk;Tony Gorschek	2018	CoRR	10.1016/j.jss.2018.12.002	empirical research;systems engineering;management science;stakeholder;computer science	SE	-70.8751398270834	21.32746563340533	132115
488918092169c24ebd29f6e4be742388db901148	e-commerce engineering: a short vs. long software process for the development of e-commerce applications	e commerce;software process		e-commerce	Andreas S. Andreou;Stephanos Mavromoustakos;Costas Leonidou;Chrysostomos Chrysostomou;Andreas Pitsillides;George Samaras;Christos N Schizas	2003			resource-oriented architecture;e-commerce;software engineering;software deployment;package development process;software development;personal software process;computer science;software development process;social software engineering	SE	-63.90848446841719	24.964123167214808	132231
1a51f83c978afa1e12e576719551ebabb1cd1abd	challenges in scaling up a globally distributed legacy product: a case study of a matrix organization		This paper presents our experiences with a 120-person matrixed software engineering product team, spread across three countries that successfully scaled their adoption of Scrum. The product is a legacy, mission-critical software system that conforms to stringent healthcare regulatory standards. We are practicing Obeya wall that brings solution to our large team communication challenges and OYA day that helps solving challenges in fostering innovation, and learning culture and collaboration. We also are describing our experience of defining focus areas of project manager and product manager. These roles are not defined in scrum guide, however, is relevant in our experience in scaled up distributed scrum environment. The authors bring our experiences as a Scrum Master, Product Owner and an architect who have been integral part of the journey and establishing these practices over several years. These practices have helped in scaling as well as stabilizing the team to an extent where each product version is meeting milestones on time and taking strong steps towards shorter release cycles of quarterly releases. This paper also summaries our lessons learned, and recommendations.		Rajeev Kumar Gupta;Shivani Jain;Bharat Singh	2018	2018 IEEE/ACM 13th International Conference on Global Software Engineering (ICGSE)	10.1145/3196369.3196389	systems engineering;software system;obeya;milestone (project management);scaling;project manager;engineering;scrum	SE	-67.76541862383588	20.90942601128198	132907
99c1a91b202d7b1e94de6ee042dff01c4c6a6267	exploring the potential of component-oriented software development application	software development	This article presents about a study performed to investigate the current state of COSD application amongst software developers  in Malaysia. The information required for the study was obtained through questionnaires that were distributed to the software  developers who are working at various software development companies in Malaysia. Results from the study are used to determine  the potential of COSD application in Malaysia. Outcomes of the analysis performed on the results show that the potential of  COSD application amongst the software developers in Malaysia is high.  	software development	Hazleen Aris	2009		10.1007/978-3-642-01112-2_37	personal software process;verification and validation;software project management;computer science;package development process;social software engineering;software framework;software development;software engineering;software construction;software analytics;resource-oriented architecture;management;lean software development;software deployment;software development process;software peer review	SE	-65.27860927868979	23.201082416802514	133058
acc9f20af636f8296b6f5c8cdefbea37b8fd01d5	tutorial 1: multi-year results of using an open global research and development process on three different application domains	component development open global research and development process application domain open global collaboration global competence centers component specification;unified modeling language collaboration computer architecture conferences software analytical models software engineering;software engineering object oriented methods	The paper presents three large projects that were developed using OPEN Global Research and Development Process over a 5 year span. The three projects are significantly different in the domain of applicability and scope but were all developed using the same process for OPEN Global collaboration. The OPEN Global Collaboration process is based on the identification of global competence centers staffed with domain experts that are managed by a central team responsible for high-level requirements, overall architecture and quality assurance. The key enabler for OPEN Global Collaboration process is the selection of the domain experts of the global competence centers. These domain experts are internationally recognized experts and they are responsible for the complete specification and development of the components under their responsibility. This is a key insight as it signficantly reduces the required communication between the central and remote teams. As a consequence, the communication is centered on the interface between components and not on the detailed component specifications.	high- and low-level;requirement;subject-matter expert	Alberto Avritzer	2014	2014 IEEE International Conference on Global Software Engineeering Workshops	10.1109/ICGSEW.2014.20	domain analysis;personal software process;model-driven architecture;software engineering process group;computer science;systems engineering;package development process;software design;social software engineering;component-based software engineering;software development;software engineering;domain engineering;software construction;goal-driven software development process;software development process;computer engineering;software peer review	Visualization	-63.502207513151674	20.984477048950932	133085
8d6714e931346d95ff0d426351e63ebc1e0cb438	secure development tool adoption in open-source	social factors;security tools;adoption	Although the use of secure software development tools can help developers build more secure software, many developers do not use these tools. In previous work, a colleague conducted interviews with professional developers to develop a qualitative model of factors that influence developers' decisions to use or not use security tools. In the work described in this abstract, I conducted interviews with open-source software developers to evaluate how our findings generalize outside of corporate software development populations. With the data from these interviews, I aim to gain insight into open-source software developers' behavior and values. I aim to refine, expand, and generalize our security tool adoption model so it may be used to foster wider adoption of security tools.	integrated development environment;open-source software;population;software developer;software development	Jim Witschey	2013		10.1145/2508075.2514872	knowledge management;diffusion;computer security	SE	-74.16925057052065	21.78733823177436	133153
6c232f41439101668bd9be8a9d38b088f1621566	risdm: a requirements inspection systems design methodology: perspective-based design of the pragmatic quality model and question set to srs	inspection pragmatics software design methodology standards organizations organizations;software quality formal specification;risk prediction risdm methodology requirements inspection systems design methodology perspective based design pragmatic quality model software requirements specification software development srs verification srs validation pqm pbr perspective based reading ntt data software;risk prediction requirements inspection requirements verification and validation srs pragmatic quality model question set	The quality of the SRS (Software Requirements Specification) is the key to the success of software development. The inspection for the verification and validation of SRS are widely practiced, however, the techniques of inspection are rather ad hoc, and largely depend on the knowledge and skill of the people. This article proposes RISDM (Requirements Inspection Systems Design Methodology) to design the RIS (Requirements Inspection System) to be conducted by a thirdparty inspection team. The RISDM includes a meta-model and design process of RIS, PQM (Pragmatic Quality Model) of SRS, and a technique to generate inspection question set based on the PQM and PBR (Perspective-Based Reading). We have been applying the RIS designed by the proposed RISDM to more than 140 projects of a wide variety of software systems in NTT DATA for five years. By analyzing the statistics from the experience, we discovered some key quality characteristics of SRS reveal strong correlation to the project cost and level of quality to be used for evaluating the maturity of the SRS and predicting the risk.	capability maturity model;hoc (programming language);metamodeling;pbr theorem;relational interface system;requirement;software development;software requirements specification;software system;systems design;verification and validation	Shinobu Saito;Mutsuki Takeuchi;Setsuo Yamada;Mikio Aoyama	2014	2014 IEEE 22nd International Requirements Engineering Conference (RE)	10.1109/RE.2014.6912264	reliability engineering;requirements analysis;software requirements specification;verification and validation;software verification;computer science;systems engineering;software design;software engineering;software construction;software inspection;software quality control	SE	-64.85421709239478	29.341428713548364	133165
855f108f0c0d9cd73f79e110a9a9283730aac65f	linking return on training investment with defects causal analysis.	causal analysis	In this paper, we present a process for linking organizational training efforts with defects causal analysis in software development organizations. The process is being implemented in a CMMI maturity level 3 organization. Since causal analysis is not an expected process area at maturity level three, key success factors for the implementation of the process are identified and analyzed. The conclusions were tested in this software development organization. In order to do that, a pilot project was selected and training was implemented to support the process. The training results are analyzed in order to validate the overall approach. The resulting work provides a guideline for implementing causal analysis in lower maturity organizations and establishes that the implementation is viable in the target organization.	capability maturity model integration;causal filter;causality;software development	Santiago Matalonga;Tomás San Feliu Gilabert	2008			computer science;operations research	SE	-70.26028441500895	19.619077138703773	133487
746723b6137202d38af55437420a151983aeb02c	quantifying long-term evolution of industrial meta-models - a case study	automotive engineering;software;complexity theory;measurement;metrics;software engineering;software metrics autoregressive processes computational complexity principal component analysis software development management;monitoring;unified modeling language;measurement software complexity theory couplings automotive engineering unified modeling language monitoring;package cohesion long term evolution industrial meta models software engineering software metrics meta model properties standardized meta model automotive software systems autosar meta model versions volvo car corporation principal component analysis pca software development projects planning fan in complexity;couplings	Measurement in software engineering is an important activity for successful planning and management of projects under development. However knowing what to measure and how is crucial for the correct interpretation of the measurement results. In this paper, we assess the applicability of a number of software metrics for measuring a set of meta-model properties - size, length, complexity, coupling and cohesion. The goal is to identify which of these properties are mostly affected by the evolution of industrial meta-models and also which metrics should be used for their successful monitoring. In order to assess the applicability of the chosen set of metrics, we calculate them on a set of releases of the standardized meta-model used in the development of automotive software systems - the AUTOSAR meta-model - in a case study at Volvo Car Corporation. To identify the most applicable metrics, we used Principal Component Analysis (PCA). The results of these metrics shall be used by software designers in planning software development projects based on multiple AUTOSAR meta-model versions. We concluded that the evolution of the AUTOSAR meta-model is quite even with respect to all 5 properties and that the metrics based on fan-in complexity and package cohesion quantify the evolution most accurately.	autosar;automotive software;cohesion (computer science);evolution;fan-in;metamodeling;principal component analysis;software development;software engineering;software metric;software system;unified modeling language	Darko Durisic;Miroslaw Staron;Matthias Tichy;Jörgen Hansson	2014	2014 Joint Conference of the International Workshop on Software Measurement and the International Conference on Software Process and Product Measurement	10.1109/IWSM.Mensura.2014.11	reliability engineering;personal software process;verification and validation;software engineering process group;software sizing;software verification;computer science;systems engineering;package development process;social software engineering;component-based software engineering;software development;software engineering;software construction;software analytics;software measurement;software deployment;goal-driven software development process;software development process;software metric;software system;software peer review	SE	-63.81316418471717	28.309158913772258	133556
b145e62f5f6d65cd8e312cd491d6f41ee9a8fb56	simulating software evolution with varying numbers of developers and validation using oss	analytical models;software;developer;user configurable settings software evolution oss software development memory recall open source systems;information systems;costs open source software computational modeling programming australia software engineering software performance high performance computing programmable control information systems;high performance computing;probability density function;simulation;simulation framework;programmable control;open source systems;development process;data mining;software engineering;software performance;development process simulation oss developer;evolution biology;public domain software;simulation software;computational modeling;software engineering public domain software;software evolution;user configurable settings;software development;memory recall;simulation tool;programming;object oriented modeling;australia;open source software;data models;open source;oss	An issue that has confounded the understanding of software development in the past is the role that different numbers of developers play in the construction and subsequent evolution of software. In this paper, we investigate that facet of software using a configurable simulation framework as a basis. The framework uses 'agents' to represent developers and models the costs associated with first comprehending and then applying necessary changes to a fictitious code base. It also considers agent 'memory recall' of their own code as a fundamental part of the framework and the fact that, with higher numbers of developers, maintenance of a higher proportion of other developers' code (rather than their own) is an inevitable, yet realistic aspect. Through exploration of the results and data produced by the simulation, we are able to explore 'desirable' features that are part of simulating software evolution; as a discussion of the issues raised by the framework, we provide a set of class data from four open-source systems by way of comparison and show that trends in those systems are comparable with results generated by the simulation. The paper thus provides evidence that we can use simulation tools to help model evolving systems, whether based on default settings or user-configurable settings.	emergence;open sound system;open-source software;simulation;software development;software evolution	Benjamin Stopford;Steve Counsell;Emal Nasseri	2009	2009 Australian Software Engineering Conference	10.1109/ASWEC.2009.36	data modeling;programming;probability density function;supercomputer;software performance testing;simulation software;computer science;systems engineering;software evolution;software development;software engineering;recall;programming language;computational model;public domain software;software development process;information system;computer engineering	SE	-66.61408905731419	30.59917132174875	133777
ae31546f529c1c9c7b8e999ee8312c2d299551ee	industrie 4.0 by siemens: steps made next			industry 4.0	Diana Cozmiuc;Ioan Petrisor	2018	J. Cases on Inf. Techn.	10.4018/JCIT.2018010103	software engineering;knowledge management;siemens;engineering	DB	-64.5450642937243	22.257032183707043	134049
e692a861c7087249f5b8748bf2f11b6e5400824d	structured analysis of the evaluation process for adopting open-source software		Abstract Open-source software (OSS) has been widely used in the software development process to reduce development cost and development period. However, adopting OSS requires crucial decision-making in terms of various aspects including business, technology, and intellectual property management; these may not be mutually independent and may exhibit a complex set of relationships. This research studies the structured analysis to break down the evaluation criterion axis and the contributing factors when adopting OSS and attempts to clarify the structured evaluation criterion map.		Shinji Akatsu;Yoshikatsu Fujita;Takumi Kato;Kazuhiko Tsuda	2018		10.1016/j.procs.2018.08.131	data mining;systems engineering;software;software development process;intellectual property;structured analysis;computer science	SE	-69.5659250411513	20.363277886929385	134283
8cccdb902913a120d4d63fa0c0699fd0f4c24279	staffing and organization in the engineering of systems	working group;ieee standards;systems engineering;social aspects of automation;business reengineering staffing engineering of systems model based systems engineering organization culture ieee standards ieee ecbs incose technical process management process abstractions anthropology psychology;personnel;systems engineering and theory cultural differences taxonomy lakes humans psychology business process re engineering project management automation documentation;human resource management systems engineering personnel social aspects of automation ieee standards;model based systems engineering;human resource management	The techniques of model based systems engineering are applied to the human issues of staffing, organization, and culture. This supplements IEEE standards and contributions by IEEE ECBS and INCOSE working groups on the technical process, the management process, a taxonomy for tools to automate the processes, and a mapping of the process onto tools. This paper draws on abstractions and representations from the fields of anthropology and psychology and recasts them in executable models. This results in greater rigor in expression and analysis, and the potential to automate efficient capture of data and its transformation into the notations and views wanted by other disciplines. It provides a basis for rigorous discussion of staffing, organization, and culture through review and improvement of models. The analysis connects goals, rewards and tasks to classes of cultural behavior, and to four basic organization architectures. It applies to business re-engineering.	executable;systems engineering;taxonomy (general)	David W. Oliver	1997		10.1109/ECBS.1997.581855	engineering management;working group;health systems engineering;system of systems engineering;computer science;systems engineering;engineering;knowledge management;artificial intelligence;software engineering;human resource management;management science;management	Visualization	-66.01873920992276	24.374857444259195	134296
0f347e48c6ca275e037c2d1782dba8f1143f30bc	pilot projects for object-oriented design: an empirical study	phase change materials;electrical capacitance tomography;empirical study;universities;project management;project design object oriented design object oriented techniques universities project management computing project course;design engineering;object oriented design;project manager;object oriented programming;object oriented techniques;software engineering;process design;computer science education;electrical capacitance tomography software engineering system testing documentation process design phase change materials radio access networks design engineering;pilot project;educational courses project management object oriented programming software development management computer science education teaching;object oriented;educational courses;system testing;computing project course;pilot projects;software development management;documentation;project design;teaching;radio access networks	Over the last two years (1998-2000) in the Computing Project course at the University of Tasmania in Hobart, the students have undertaken to design their projects using object oriented techniques. Our experiences have led to significant changes to our approach. It is thought that our experience may be of interest to industry and other universities who are considering changing their project management to include a significant object oriented design component.		Nicole Clark	2000		10.1109/ASWEC.2000.844571	project management;computer science;systems engineering;engineering;software engineering;programming language;object-oriented programming;computer engineering	SE	-65.61558103321896	26.580032080258714	134682
9251b2299f4f02ee12466ed2aedfc53b2cade2c4	an experience-based framework for evaluating alignment of software quality goals	software;software engineering;cluster analysis;different perspectives;quality;programvaruteknik;global software development;alignment	Efficient quality management of software projects requires knowledge of how various groups of stakeholders involved in software development prioritize the product and project goals. Agreements or disagreements among members of a team may originate from inherent groupings, depending on various professional or other characteristics. These agreements are not easily detected by conventional practices (discussions, meetings, etc.) since the natural language expressions are often obscuring, subjective, and prone to misunderstandings. It is therefore essential to have objective tools that can measure the alignment among the members of a team; especially critical for the software development is the degree of alignment with respect to the prioritization goals of the software product. The paper proposes an experience-based framework of statistical and graphical techniques for the systematic study of prioritization alignment, such as hierarchical cluster analysis, analysis of cluster composition, correlation analysis, and closest agreement-directed graph. This framework can provide a thorough and global picture of a team’s prioritization perspective and can potentially aid managerial decisions regarding team composition and leadership. The framework is applied and illustrated in a study related to global software development where 65 individuals in different roles, geographic locations and professional relationships with a company, prioritize 24 goals from individual perception of the actual situation and for an ideal situation.	cluster analysis;directed graph;global variable;graphical user interface;hierarchical clustering;holism;inferential theory of learning;list of statistical packages;natural language;population;programming tool;software development;software engineering;software quality;statistical model	Panagiota Chatzipetrou;Lefteris Angelis;Sebastian Barney;Claes Wohlin	2014	Software Quality Journal	10.1007/s11219-014-9251-5	team software process;requirement prioritization;computer science;systems engineering;knowledge management;software design;operations management;software development;software design description;software engineering;management science;cluster analysis;software walkthrough;management;software quality control;software quality;software metric;software quality analyst	SE	-70.17125738403199	22.02774150637536	134774
d0f07bc3dfcff4e1bc0d1cf21df2e2652825416a	towards guaranteed quality and dependability of information services	digital library;electronic commerce;information technology	If I had had more time, I could have written you a shorter letter. Abstract The impressive advances in global networking and information technology provide great opportunities for all kinds of ubiquitous information services, ranging from digital libraries and information discovery to virtual-enterprise workkows and electronic commerce. However, many of these services too often exhibit rather poor quality and are thus unsuitable for mission-critical applications. In this paper I would like to encourage more intensive research eeorts towards service quality guarantees, the ultimate goal being the ability to construct and deploy truly dependable systems with provable correctness, continuous availability , and predictable performance. The paper aims to sort out some of the issues towards these elusive goals, mainly by discussing a case study on work-ow management. I will point out various assets that can be leveraged, most notably, from database and TP technology and also mathematical modeling and reasoning, and I will outline some research directions that I would encourage to pursue.	continuous availability;correctness (computer science);database;dependability;digital library;e-commerce;information discovery;library (computing);mathematical model;mission critical;provable security	Gerhard Weikum	1999			reliability engineering;real-time computing;dependability;computer network	DB	-71.62685369931552	31.207424505878716	134847
0f9c99c38eb6fcbbeb46052939f318f170946721	applicability of iso/iec 9126 for the selection of floss tools		The trend towards the use of Free/Libre Open Source Software (FLOSS) tools is impacting not only how we work and how productivity can be improved when it comes to developing software, but is also promoting new work schemes and business models, specifically small and medium-size enterprises. The purpose of this paper is to present the applicability of ISO/IEC 9126 for the selection of FLOSS Tools associated with three relevant software development disciplines, such as Analysis and Design, Business Models and Software Testing. The categories considered for the evaluation of these three types of tools are Functionality, Maintainability and Usability. From the results obtained from this research-in-progress, we have been able to determine that these three categories are the most relevant and suitable to evaluate FLOSS tools, thus pushing to the background all aspects associated with Portability, Efficiency and Reliability. Our long-term purpose is to refine quality models for other types of FLOSS tools.	enterprise information system;iso/iec 9126;information systems;open-source software;software development;software testing;usability	María A. Pérez;Kenyer Domínguez;Edumilis Maria Méndez;Luis Eduardo Mendoza	2009		10.5220/0002000303670371	data mining;coating;computer science;organic chemistry;molecule;amine gas treating;aqueous solution;heterocyclic amine	SE	-63.988372017918344	23.399741449065733	135052
d9c55183e864fde79636a3f0086ab760975c4405	from the editor: best practices-who says?	best practices programming inspection nasa loudspeakers coordinate measuring machines middleware advertising;best practice;inspection;loudspeakers;best practices;middleware;coordinate measuring machines;nasa;programming;advertising	We often hear the term best practices used in software development contexts. It's easy to fall into the habit of using the term indiscriminately for any activity that looks even remotely useful. The editor in chief looks at the term's possible meanings, how it can affect computer forensics investigations, why he's restricting its use in IEEE Software, and how we might formalize a definition so that the term and concept can be useful to the community.	best practice	Warren Harrison	2004	IEEE Software	10.1109/MS.2004.1320864	real-time computing;simulation;extreme programming practices;computer science;engineering;software engineering;multimedia;programming language;management;best practice	Visualization	-71.35028693571583	28.058837019604635	135158
4ccec052c2c83aadb8d29693f9f1cf0cc8d1cf76	a tool for teaching risk	project management;software development software enterprise ibm rational jazz platform risk management risk control risk monitoring;computer aided instruction;software engineering;software engineering education;computer science education;risk management software servers decision trees monitoring project management user interfaces;software engineering education risk tools;risk;tools;teaching computer aided instruction computer science education project management software engineering;teaching	Students tend to think optimistically about the software they construct. They believe the software will be defect free, and underestimate apparent risks to the development process. In the Software Enterprise, a 4-course upper division project sequence, student team failures to predict and prevent these risks lead to various problems like schedule delays, frustration, and dissatisfaction from external customer sponsors. The Enterprise uses the IBM Rational Jazz platform, but it does not have a native risk management capability. Instead, project teams were recording risks associated with their projects on paper reports. To facilitate maintaining and managing the risks associated with their projects, we developed a risk management component in the Jazz environment. This component complements Jazz by providing features of the risk management process like risk control and monitoring. The risk management component was used and evaluated by student capstone project teams.	capstone (cryptography);decision tree;eclipse;it risk management;jazz (computer);open-source software;optimistic concurrency control;plug-in (computing);real-time clock;software bug;user interface	Santosh Rajendran;Kevin Gary;Harry Koehnemann	2012	2012 Ninth International Conference on Information Technology - New Generations	10.1109/ITNG.2012.172	project management;personal software process;verification and validation;team software process;enterprise software;software engineering process group;risk management;software project management;social software engineering;software development;software engineering;software as a service;risk;project risk management;application lifecycle management;project management triangle;management;computer-aided software engineering;risk management plan;software system;software peer review	SE	-68.49602658246391	26.338689728417588	135401
4a4e898a229dde7957d1e0aeb85afe8a6bf48afa	a new software engineering	computer and information science education	What happened to the promise of rigorous, disciplined, professional practices for software development?	software development;software engineering	Ivar Jacobson;Ed Seidewitz	2014	ACM Queue	10.1145/2685690.2693160	personal software process;software engineering process group;extreme programming practices;social software engineering;software development;software engineering;software walkthrough;software development process;software requirements;software peer review	SE	-66.04950761746188	24.509441150068174	135475
e442162e3c4b3d8e30b2ad8864c60e855a0b83b2	empirical studies as a basis for technology transfer	empirical study;software engineering;technology transfer	The ultimate goal of all software engineering research should be to have an impact on the way software is engineered. This might involve making it more dependable, more economical to produce, more easily understood, or in some way improve the production or quality of software. This should be true whether the research is theoretical in nature or more pragmatic. In the former case the timescale for impact will likely be longer than one would expect if the research involves the proposal of a new specification, development, architecture or testing technique, or a new metric or way of assessing some software artifact. Nonetheless, it should ultimately allow practitioners to build “better” systems. The primary question we consider in this note is how to effect or facilitate that impact. More specifically, how should we transfer new technology introduced in research to the practitioners who are actually involved in some stage of the development of software systems? Our experience is that empirical studies are among the best ways to demonstrate to practitioners how the technology works or is to be used, and to convince practitioners that the technology will actually be usable by their project. This, of course, assumes that the empirical studies are believable and relevant to the types of projects that the practitioners are actually building. For this to be the case, it is generally necessary to perform these studies using “real” projects. The question then becomes, how do we get projects to participate, and how do we distribute the results so that the technology eventually gets transferred? These two issues are the subject of this paper.		Elaine J. Weyuker	2006		10.1007/978-3-540-71301-2_34	empirical research;systems engineering;architecture;software;computer science	SE	-70.17535224289252	25.287909097666155	135557
241c620da9cf87518655c5ca855fb87055dab2be	managing risks in global software engineering: principles and practices	evolution methods;distributed development;software;distributed software development;innovation management global distributed software development risk management software engineering project management product development product evolution quality management supplier management process framework product life cycle management sla based escalation competence management;project management;globalisation;product life cycle management;risk management;industries;companies;team working globalisation innovation management product development project management quality management risk management software development management software quality;software engineering;production management;gse;team working;global economy;innovation management;global software engineering;schedules;supplier management;driver circuits;cost effectiveness;software companies software engineering driver circuits schedules risk management industries;software quality;software development management;field study;quality management;supplier management distributed development global software engineering gse risk management;product development	Globally distributed software development poses substantial risks to project and product management. Not all eventualities can however be buffered, because in the global economy, developing and implementing products must be fast, cost effective and adaptive to changing needs. Therefore, there is a need to utilize different techniques to effectively and efficiently mitigate risks. This article systematically introduces risk management in global software engineering (GSE) for development projects and product evolution. Methods include using basic project, supplier and quality management techniques, process frameworks (e.g., CMMI), product life-cycle management, effective communication processes, SLA based escalation, competence management, and innovation management. A longitudinal empirical field study over several years from a captive SW center of a worldwide leading ICT company in India provides practical experiences and indicates how to effectively apply GSE risk management practices.	agile software development;capability maturity model integration;captive portal;distributed computing;field research;generic stream encapsulation;privilege escalation;risk management;service-level agreement;shattered world;software engineering	Christof Ebert;Bvs Krishna Murthy;Namo Narayan Jha	2008	2008 IEEE International Conference on Global Software Engineering	10.1109/ICGSE.2008.12	project management;quality management;program management;cost-effectiveness analysis;economics;risk management;innovation management;schedule;software project management;systems engineering;knowledge management;operations management;software engineering;supplier relationship management;application lifecycle management;management;product life-cycle management;software quality;new product development	SE	-67.58084559635341	21.228572933339308	135577
23d510be6a922ee7e9cf0fe7ca41bc7d1c12d520	package formats for preserved digital material		This paper presents an investigation of the best suitable package formats for long term digital preservation. The choice of a package format for preservation is crucial for future access, thus a thorough analysis of choice is important. The investigation presented here covers setting up requirements for package formats used for long term preserved digital material, and using these requirements as the basis for analysing a range of package formats. The result of the concrete investigation is that the WARC format is the package format best suited for the listed requirements. Fulfilling the listed requirements will ensure mitigating a number of risks of information loss. Thus WARC is the best choice for a package format in cases where these same risks are judged most important. Similar analysis will need to be carried out in cases where the requirements differ from the ones described here, e.g. if there are specific forensic or direct access to files.	computer forensics;random access;requirement;web archive	Eld Zierau	2012			computer science	SE	-74.48599234103045	25.36673080258165	135744
576b7183ac4eb82a21d94284334e638235c41262	how experienced project managers assess risk	application development;project management;project manager;reviews software development management risk management project management;risk management;risk management concerns experienced project managers risk assessment software development projects survey ireland application systems developers custom built software intensive application development projects external clients customer characteristics application characteristics software project risk drivers perceptions;software project management;project management risk management dogs application software software development management lenses management information systems psychology planning;software development;system development;reviews;software development management	This survey of a homogenous group of project managers revealed a surprising diversity of risk management concerns. oftware development projects, given their diverse and abstract nature, offer unique challenges and risks. Although a substantial body of literature has been written to address project risk management, my experience in the field led me to question whether this literature accurately mirrors the concerns of real-world project managers. To confirm my suspicions, I surveyed 14 experienced application systems developers, all located in Ireland. All survey participants manage custom-built, software-intensive application development projects that originate from external clients. The survey focused on three major areas:	risk management	Tony Moynihan	1997	IEEE Software	10.1109/52.589229	project management;team software process;extreme project management;program management;project stakeholder;risk management;software project management;opm3;systems engineering;engineering;knowledge management;environmental resource management;software development;functional manager;project risk management;project management 2.0;project management triangle;rapid application development;management;project charter;risk management plan;project planning;project portfolio management	SE	-72.03314871793239	20.438171979703245	135776
d70949b0283b2d093aaa277612a853ab17a68509	wip: generating sequence diagrams for modern fortran		Fortran finds widespread use in scientific and engineering communities that embraced computing early, including weather and climate science and mechanical, nuclear, and aerospace engineering. Over its lifetime, Fortran has evolved to support multiple programming paradigms, including Object-Oriented Programming (OOP). Despite the recently burgeoning ecosystem of tools and libraries supporting modern Fortran, there remains limited support for generating common Object-Oriented Design (OOD) diagrams from Fortran source code. ForUML partially fills this need by reverse engineering Unified Modeling Language (UML) class diagrams from object-oriented (OO) Fortran programs. Class diagrams provide useful information about class structures and inter-relationships, but class diagrams do not convey the temporal information required to understand runtime class behavior and interactions. UML sequence diagrams provide such important algorithmic details. This paper proposes to extend ForUML to extract UML sequence diagrams from Fortran code and to offer this capability via a widely used open-source platform. The paper argues that the proposed capability can raise the level of abstraction at which the computational science community discusses modern Fortran.	class diagram;computational science;ecosystem;fortran;interaction;library (computing);open-source software;programming paradigm;reverse engineering;sequence diagram;unified modeling language	Anawat Leatongkam;Aziz Nanthaamornphong;Damian W. I. Rouson	2017	2017 IEEE/ACM 12th International Workshop on Software Engineering for Science (SE4Science)	10.1109/SE4Science.2017.13	theoretical computer science;unified modeling language;reverse engineering;programming paradigm;source code;sequence diagram;object-oriented programming;class diagram;fortran;computer science	SE	-64.28698216531805	29.10211507142868	135850
d6d63a45f4d834b0987823c2fe17d875a66b17f6	the naturalness of object orientation: beating a dead horse?	protocols;horses electric breakdown programming protocols business communication object oriented modeling vehicles performance evaluation information systems;information systems;performance evaluation;business communication;horses;electric breakdown;object oriented;vehicles;programming;object oriented modeling	"""I n a recent column ("""" A Story about the Creativity Involved in Software Work, """" Sept./Oct. 2001), I hinted at a research study whose goal was to compare the object-oriented, function/process, and information/data approaches to systems analysis. I called it """" a story for another time. """" This is that time. In that column, I described my boredom in looking at videotapes of graduate students analyzing an assigned information systems task. My point was that what at first appeared to be boring activity turned out to be thinking activity, and that the thinking part of the task overwhelmed the task's more clerical aspects at an 80-to-20-percent ratio. That was strong evidence, I suggested , that software development is far more complex than those who believe it is easy and automatable have led us to believe. That was that column; this is now. I want to revisit this topic to explain where those """" boring """" videotapes came from and why their original purpose was at least as important as the purpose I derived from them. Amazing benefits! The software field has been subjected, over the years, to excessive claims of benefits for almost every new technology. Fourth-generation languages were to lead to """" programming without programmers, """" CASE tools would bring about """" the automation of programming , """" and object orientation was to be a dramatic new methodological approach to systems development that would replace all the other, older, methodologies. Two phenomena have accompanied such excessive claims: I Once the concepts are more thoroughly understood, the benefits turn out to be far more modest than claimed. I That transition from excessive claims to modest benefits has seldom been accomplished with the aid of evaluative research. Researchers, I am saying here, have been of little help in sorting the technological and methodological wheat from its chaff. That's why I am so impressed by the study I hinted at in the previous column. Videotape evidence! This study was an honest-to-goodness attempt to objectively compare the benefits of the (at that time) newfangled object-oriented approaches with the more traditional func-tion/process and information/data alternatives. (That the study's lead researcher, Iris Vessey of Penn State University [and now of Indiana University], is my wife also partly accounts for my being impressed!) The claims made for object orientation, then as now, were that it is a more natural form of problem solution and that …"""	computer-aided software engineering;information system;programmer;software development process;sorting;test automation	Robert L. Glass	2002	IEEE Software	10.1109/MS.2002.1003467	communications protocol;programming;real-time computing;simulation;computer science;engineering;business communication;object-oriented programming;management;information system	SE	-70.82762340533473	27.775733071150402	135854
9837d972df41630c69adb684f64f0b2e8cae9425	architectural studies of games engines — the quake series	games engine;software;quake engine architecture;engines open source software computer architecture performance analysis software engineering application software information technology pattern analysis software architecture middleware;design and development;architectural studies;oss game engine;game engine;data mining;game development;public domain software;computer architecture;software architecture;servers;engines;games;software architecture computer games public domain software;quake series;source code;open source communities;computer games;rendering computer graphics;open source;quake engine architecture architectural studies games engine quake series open source communities oss game engine	The presented approach constitutes a useful resource for games developers who wish to contribute to the further evolution of these games engines; and it provides insights into how the Quake engine architecture has evolved in practice since it was released as an open source project.	open-source software;quake engine	James B. Munro;Cornelia Boldyreff;Andrea Capiluppi	2009	2009 International IEEE Consumer Electronics Society's Games Innovations Conference	10.1109/ICEGIC.2009.5293600	simulation;engineering;software engineering;world wide web	SE	-69.72988758171412	29.33725729340095	136029
43ac08728ea66901376bf002388938156419e9d4	achievements and challenges in state-of-the-art software traceability between test and code artifacts	t technology;systems analysis program diagnostics program testing software maintenance software reliability;software testing software reliability production debugging object oriented modeling;traceability recovery software testing software traceability test to code traceability;software traceability requirements engineering software reliability software maintenance software development code artifacts software testing	Testing is a key activity of software development and maintenance that determines the level of reliability. Traceability is the ability to describe and follow the life of software artifacts, and has been promoted as a means for supporting various activities, most importantly testing. Traceability information facilitates the testing and debugging of complex software by modeling the dependencies between code and tests. Actively supplementing traceability to testing enables rectifying defects more reliably and efficiently. Despite its importance, the development of test-to-code traceability has not been sufficiently addressed in the literature, and even worse there is currently no organized review of traceability studies in this field. In this work, we have investigated the main conferences, workshops, and journals of the requirements engineering, testing, and reliability, and identified those contributions that refer to traceability topics. From that starting point, we characterized and analyzed the chosen contributions against three research questions by utilizing a comparative framework including nine criteria. As a result, our study arrives to some interesting points, and outlines a number of potential research directions. This, in turn, can pave the way for facilitating and empowering traceability research in this domain to assist software engineers and testers in test management.	debugging;experiment;graphic art software;rectifier;requirements engineering;software development;software engineer;software testing;test management;traceability	Reza Meimandi Parizi;Sai Peck Lee;Mohammad Dabbagh	2014	IEEE Transactions on Reliability	10.1109/TR.2014.2338254	reliability engineering;development testing;personal software process;long-term support;verification and validation;software sizing;software verification;computer science;systems engineering;package development process;backporting;social software engineering;software reliability testing;software development;software engineering;software construction;software testing;software walkthrough;software measurement;software deployment;software quality;requirements traceability;software system;software peer review	SE	-63.89039906302295	29.87937863731153	136418
863a4b1c739ccac2186adb38c70500a87ab43cc1	combining of kanban and scrum means with programmable queues in designing of software intensive systems		The existing problem of the extremely low level of the success in developments of software intensive systems (SISs) is a reason for the ongoing search for innovations in software engineering. One of the promising areas of the search is a continuous improvement of agile methods of the project management the most popular of which are bound with Kanban and Scrum approaches. The paper presents the way of combining the Kanban and Scrum means with the programmable queues of project tasks that are implementing by designers in the real-time. In any queue, its elements present the states of the corresponding tasks in their conceptually-algorithmic solutions. Interactions of designers with queues provide the parallel and pseudo parallel work with tasks. Such way-of-working promotes increasing the reliability of operational planning. The specialized toolkit WIQA (Working In Questions and Answers) supports the offered version of the project management.	kanban (development);scrum (software development)	Petr Sosnin	2015		10.1007/978-3-319-22689-7_28	real-time computing;systems engineering;software engineering;kanban	EDA	-67.30619983169656	22.858933956710263	136859
0d88ccb85fa60b69e866e5e06f2244f625c5a78b	incorporating learning and expected cost of change in prioritizing features on agile projects	agile software development;developpement logiciel;optimisation;project management;guidage;optimizacion;programmation agile;guiado;by product;agile programming;extreme programming;production management;programacion extrema;sous produit;desarrollo logicial;subproducto;software development;programmation extreme;guidance;gestion projet;optimization;programacion agil;business value;gestion proyecto	Very little has been written to date on how to prioritize and sequence the development of new features and capabilities on an agile software development project. Agile product managers have been advised to prioritize based on “business value.” While this seems an appropriate goal, it is vague and provides little specific guidance. Our approach to optimizing “business value” uses tactics to minimize costs and maximize benefits through strategic learning. In order to provide specific and actionable advice to agile product managers, we present two guidelines. These guidelines are meant to provide a set of considerations and a process by which an agile product manager can achieve the goal of optimizing “business value” while recognizing that different product managers will vary in their notions of what “business value” is.	agile software development	R. Scott Harris;Mike Cohn	2006		10.1007/11774129_19	project management;agile unified process;agile usability engineering;knowledge management;agile software development;empirical process	Robotics	-70.43119472189103	22.99931422349466	136996
0aa6d05f856a34cf6b65aeefef81f8847c2a3def	stakeholders' perception of success: an empirical investigation	software;empirical study;strategic view;project management;operational view;software engineering project management;stakeholder involvement;software project;empirical study project success factors strategic view tactic view operational view;project management programming companies research and development management software development management engineering management teamwork software engineering application software australia;stakeholder perception;data mining;companies;software engineering;data analysis;software development;kommunikationssystem;software project software development stakeholder perception;success factor;schedules;datavetenskap datalogi;programvaruteknik;programming;project success factors;tactic view	Different stakeholders involved in the software development may attribute success to different indicators. Analogously they may support different factors considered the root of successful projects. The study presented in this paper explores how different stakeholders perceive project success and what they deem the effect of specific factors on the project outcome. The study highlighted both commonalities and differences among three main stakeholder classes. A substantial agreement was observed concerning the characteristics that make a project or product successful. As far as the factors that could lead to success are concerned, more bias emerged.	operational view;requirement;software development;user requirements document	Evgenia Egorova;Marco Torchiano;Maurizio Morisio;Claes Wohlin;Aybüke Aurum;Richard Berntsson-Svensson	2009	2009 35th Euromicro Conference on Software Engineering and Advanced Applications	10.1109/SEAA.2009.33	project management;programming;operational view;schedule;computer science;systems engineering;knowledge management;software development;management science;data analysis;empirical research;management	SE	-71.39079139945372	21.243348349587095	137093
7ae9202f2da90595c28c49f17d607ac90ec3ab6c	twenty-year retrospective: the nato software engineering conferences	mathematics;history;distributed computing;software systems;software engineering;hybrid analysis techniques;permission;fault detection;software engineering software systems permission history computer science hardware distributed computing machinery mathematics;computer science;static analysis;machinery;dynamic analysis;hardware		nato software engineering conferences	James E. Tomayko	1989		10.1145/74587.326030	personal software process;verification and validation;machine;computing;software verification;computer science;social software engineering;component-based software engineering;software development;software engineering;software construction;dynamic program analysis;software walkthrough;software deployment;computer-aided software engineering;static analysis;software requirements;fault detection and isolation;software system;computer engineering;software peer review	SE	-63.73721114911959	26.55390095411191	137223
d7da904065f652adcf7aca67fc2757bf3c13edd3	continuous software process improvement requires organisational learning: an australian case study	organisational memory;280112;software process improvement;software process assessment;organisational learning;journal article;information systems development methodologies;faculty of engineering and information technology;continuous improvement;learning organisation;process improvement;software quality	The study reported in this paper suggests that in order to achieve optimal benefits from implementing process improvement programs, organisations must move towards becoming what is termed “a learning organisation.” Software process assessment “leads to the identification and selection of key activities for improvement and the continuous application of improvements to match business needs” (ISO/IEC 1996). Continuous improvement requires a commitment to learning on the part of the organisation (Garvin 1993). A model to help identify evidence of learning (the Organisational Learning Evaluation Cycle [OLEC] has been developed and empirically tested in the study. We have found evidence to suggest that the case study organisation had not moved through all three of Garvin's (1993) overlapping phases of organisational learning and as a result the firm's improvement program did not achieve optimal benefits for the organisation. The paper concludes by discussing why significant improvement in performance was not achieved.	business requirements;formative context;iso/iec 42010;learning organization;situated;software development process;web application	Jennifer Gasston;Pat Halloran	1999	Software Quality Journal	10.1023/A:1008974818812	learning organization;computer science;systems engineering;engineering;knowledge management;operations management;software engineering;management science;software quality	NLP	-69.96481972303224	19.717778663085895	137490
00aed6f560c6430bc10a90c57ac28e42bbc14cd0	software component allocation in distributed development settings	000 allgemeines;wissenschaft	Outsourcing in software development projects has become a widely adopted utility model for dealing with competitive issues such as cost pressure and the lack of skilled human resources. Established outsourcing relationships in terms of captive offshoring centers or clientvendor partnerships are prone to fail due to the lack of qualified outsourcing decisions for the allocation of software components to either in-house or external/offshored development. Therefore, this design-oriented research endeavor aims at developing a methodology and a corresponding tool to inform and improve the outsourcing decision in global software development projects on the basis of software components. For that reason, the results of explorative case studies researching outsourcing decision making as well as concepts of collaborative software development are combined and form the proposed methodology for supporting project leads in decision making and in avoiding of instinctive and spontaneous decisions on the allocation of software components.	captive portal;collaborative software;component-based software engineering;decision support system;knowledge base;outsourcing;programming tool;relevance;software development;spontaneous order	Tommi Kramer	2012			computer science;systems engineering;software engineering	SE	-67.6362968415066	20.15876294405982	137499
8e9b7d08b9da39d322abd7b802da902e8988d7ad	preliminary findings on software engineering practices in civic hackathons		Civic hackathons gained momentum in the last years, mainly propelled by city halls and government agencies as a way to explore public data repositories. These initiatives became an attempt to crowdsource the development of software applications targeting government transparency and urban life, under the smart cities umbrella. Some authors have been criticizing the results of these competitions, complaining about the usefulness and quality of the software that is produced. However, academic literature has much anecdotal evidence on that, being scarce on empirical analysis of civic hackathons. Therefore, we intended to gather preliminary data not only to help verifying those claims but also to understand how teams in these competitions are tackling the different activities in their software development process, from requirements to application release and maintenance. In this work, we present preliminary results of these findings.	backup;crowdsourcing;hackathon;hacker;information privacy;relevance;requirement;smart city;software development process;software engineering;tracing (software);verification and validation	Kiev Gama	2017	2017 IEEE/ACM 4th International Workshop on CrowdSourcing in Software Engineering (CSI-SE)	10.1109/CSI-SE.2017.5	anecdotal evidence;software development process;knowledge management;software;maintenance engineering;crowdsource;transparency (graphic);government;public relations;crowdsourcing;engineering	SE	-74.20417214737904	19.616850130720714	138279
1047ceeb64ad357e9812f0f5472627bd896f96e7	midas: a design quality assessment method for industrial software	expert systems;program testing;software architecture;software performance evaluation;software quality;ct dc aa;midas;siemens corporate development center asia australia;design analysis tools;design assessment practices;design quality assessment method;expert-based method;ility-based quality model;industrial software;method for intensive design assessments;project-specific constraints;software applications;software architects;software design quality;software engineering community;software design;software design assessment method;software design quality	Siemens Corporate Development Center Asia Australia (CT DC AA) develops and maintains software applications for the Industry, Energy, Healthcare, and Infrastructure & Cities sectors of Siemens. The critical nature of these applications necessitates a high level of software design quality. A survey of software architects indicated a low level of satisfaction with existing design assessment practices in CT DC AA and highlighted several shortcomings of existing practices. To address this, we have developed a design assessment method called MIDAS (Method for Intensive Design ASsessments). MIDAS is an expert-based method wherein manual assessment of design quality by experts is directed by the systematic application of design analysis tools through the use of a three view-model consisting of design principles, project-specific constraints, and an ility-based quality model. In this paper, we describe the motivation for MIDAS, its design, and its application to three projects in CT DC AA. We believe that the insights from our MIDAS experience not only provide useful pointers to other organizations and practitioners looking to assess and improve software design quality but also suggest research questions for the software engineering community to explore.	ct scan;high-level programming language;non-functional requirement;software architect;software design;software engineering;view model	Ganesh Samarthyam;Girish Suryanarayana;Tushar Sharma;Shrinath Gupta	2013	2013 35th International Conference on Software Engineering (ICSE)		reliability engineering;software architecture;design methods;computer science;systems engineering;engineering;software design;software engineering;software construction;expert system;software quality	SE	-64.17917061780975	26.50003268671482	138315
2c94c791abaf56a93a2c3a822ca743a4b0a870bc	assessing the quality of collaborative processes	collaborative work process design collaborative software international collaboration design engineering usability information technology technology management;collaborative work;design engineering;information technology;collaborative engineering;technology management;process design;usability;collaborative software	Use of effective and efficient collaboration is important for organizations to survive and thrive in today’s competitive world. This paper presents quality constructs that can be used to evaluate the success of a collaboration process. Two types of collaboration processes are identified: 1) processes that are designed and executed by the same facilitator who designed them, and 2) processes that are designed by a collaboration engineer and executed many times by practitioners. Accordingly, the quality constructs have been divided in two categories. Constructs within the first category apply to both types of collaboration processes. This category includes constructs such as process effectiveness and efficiency, results quantity, results quality, satisfaction, and usability. The second category contains constructs that are useful from the perspective of the collaboration engineering approach: repeatable collaboration processes executed by practitioners. The three constructs important for this perspective are reusability, predictability, and transferability.	usability	Mariëlle den Hengst;Douglas L. Dean;Gwendolyn L. Kolfschoten;Anita Chakrapani	2006	Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS'06)	10.1109/HICSS.2006.64	process design;usability;computer science;knowledge management;technology management;software engineering;management science;management;information technology;collaborative software	SE	-71.76820789691884	18.764672631214214	138327
c9057c689c6b680f46934194f2bcdf9dae5514d6	requirements elicitation techniques: a systematic literature review based on the maturity of the techniques		Requirements elicitation is a critical activity that forms part of the requirements engineering process because it has to discover what the software must do through a solid understanding of the wishes and needs of the various stakeholders and to transform them into software requirements. However, in spite of its relevance, there are only a few systematic literature reviews that provide scientific evidence about the effectiveness of the techniques used to elicit software requirements. This study presents a systematic review of relevant literature on requirements elicitation techniques, from 1993 to 2015, by addressing two research questions: Which mature techniques are currently used for eliciting software requirements? and Which mature techniques improve the elicitation effectiveness? Prior literature assumes that such ‘maturity’ leads to a better-quality understanding of stakeholders’ desires and needs, and thus an increased likelihood that a resulting software will satisfy those requirements. This research paper found 140 studies to answer these questions. The findings describe which elicitation techniques are effective and in which situations they work best, taking into account the product which must be developed, the stakeholders’ characteristics, the type of information obtained, among other factors.	capability maturity model;requirement;requirements elicitation;systematic review	Carla L. Pacheco;Ivan A. Garcia;Jindi Luo	2018	IET Software	10.1049/iet-sen.2017.0144	systems engineering;requirements elicitation;requirements engineering;software;systematic review;computer science;spite;scientific evidence;software requirements	SE	-70.63044905450354	22.62610528724656	138379
6629f750c5b5ea8837a50b66f498f92caf9f44b5	the impact of systems development expertise on information systems development methodology use		Prior research on Task Technology Fit Theory (TTF) has found that task experience does not moderate perceptions of tasktechnology fit and does not directly affect technology usage. Additionally, researchers using TTF must develop new items to operationalize TTF constructs for each study. This study will reexamine the role of task experience in TTF within the context of systems development methodologies. Proposed results will indicate that task experience moderates perceptions of tasktechnology fit and influences intention to use. Furthermore, this study will assess perceptions of task-technology fit by employing a context-independent measure, thereby reducing the need to develop new task-technology fit items for each study.	experience;information system;software development process;test template framework	David Henderson	2006			reliability engineering;method engineering;information engineering;systems engineering;systems development life cycle;information system	HCI	-71.32784607077811	22.017051823418278	138453
3bc4b033a892d252d62c38b4ee28ed2f4eb1a242	simulation of the defect removal process with queuing theory	queuing theory	In this paper, we simulate the defects removal process using finite independent queues with different capacity and loading, which represent the limitation of developers and the ability differences of developers. The re-assignment strategy used in defects removal represents the cooperation between relevant developers. Experimental results based on real data show that the simulated approach can provide very useful and important information which can help project manager to estimate the duration of the whole defects removal process, the utilization of each developers and the defects remain at a specific time.	queueing theory;simulation;software bug	Fan Wang;Xiaohu Yang;Xiaochun Zhu;Lu Chen	2009		10.1145/1671248.1671310	reliability engineering;real-time computing;computer science;systems engineering;queueing theory	Logic	-63.88972333012421	31.297911807977105	138841
428d492642292f79acaf49e827e55733aee2a8eb	a non-intrusive process to software engineering decision support focused on increasing the quality of software development (s)			software development;software engineering	Everton Gomede;Rodolfo Miranda de Barros	2013			software engineering;computer science;software peer review;package development process;goal-driven software development process;systems engineering;personal software process;software engineering process group;software quality analyst;social software engineering;software development	SE	-63.02242244096694	26.24851050223374	138871
e094dc2f5249ade6bb548d95dbfd1cb26154574e	software engineering for large-scale multi-agent systems - selmas'05	verification;context aware computing;time triggered;context aware;multi agent system;automotive;automated test generation;software engineering;integration;theorem proving;large scale;model based software engineering;agent technology;model test;context aware systems	"""Software is becoming present in every aspect of our lives, pushing us inevitably towards a world of distributed, context-aware computing systems. SELMAS'05, """"Software Everywhere - Context-Aware Agents"""", was built on the success of precedent SELMAS workshops, but with a special emphasis on the impact of the agent technology in the development of large context-aware systems. SELMAS has a track record of bringing together researchers and practitioners with a variety of perspectives in order to engage in lively discussion and debate. A particular interest of this workshop was to understand those issues in the agent technology that make it difficult and/or improve the production of context-aware systems."""		Alessandro F. Garcia;Ricardo Choren;Carlos José Pereira de Lucena;Alexander Romanovsky;Tom Holvoet;Paolo Giorgini	2005	ACM SIGSOFT Software Engineering Notes	10.1145/1082983.1082962	verification;simulation;computer science;systems engineering;engineering;social software engineering;software engineering;multi-agent system;automated theorem proving;programming language;software system	SE	-65.05812743150778	24.74702914297174	139055
78990bb004643d859fd62450ff03aa095bbcdaf1	introducing automated regression testing in open source projects	long term field experiment;regression testing;introduction;testing;software engineering;innovation;junit;open source	To learn how to introduce automated regression testing to existing medium scale Open Source projects, a longterm field experiment was performed with the Open Source project FreeCol. Results indicate that (1) introducing testing is both beneficial for the project and feasible for an outside innovator, (2) testing can enhance communication between developers, (3) signaling is important for engaging the project participants to fill a newly vacant position left by a withdrawal of the innovator. Five prescriptive strategies are extracted for the innovator and two conjectures offered about the ability of an Open Source project to learn about innovations.	freecol;regression testing	Christopher Oezbek	2010	CoRR		test strategy;innovation;regression testing;simulation;systems engineering;engineering;software engineering;software testing	SE	-68.65518235944829	24.1547891547249	139143
6d305b7a147182de874e11cdd9c993a963be0a8c	minimizing risk in applying metrics on multiple projects	minimisation;software metrics;software quality q factor costs phase measurement time measurement software measurement sampling methods sensitivity analysis inspection risk management;project management;quality functions risk minimization software quality multiple projects metrics validation methodology inspection discriminative power validity criterion quality control function quality factors;quality factor;inspection;software quality dp management inspection minimisation project management quality control software metrics;dp management;quality control;software quality	Using our metrics validation methodology, which we developed previously, we show how this methodology can be used across dissimilar multiple projects. We show how to reduce the risk of using metrics on multiple projects. We also show that the choice of metrics and their values can have a significant effect on the quality of software that is achieved and on the cost and amount of inspection that is incurred on multiple projects. A multiproject example, emphasizing the discriminative power validity criterion in support of the quality control function, is presented. A metrics validation process is defined that integrates quality factors, metrics and quality functions.	extended validation certificate;software metric	Norman F. Schneidewind	1992		10.1109/ISSRE.1992.285847	project management;reliability engineering;minimisation;quality control;verification and validation;inspection;systems engineering;engineering;software engineering;q factor;management;software quality control;software quality;software metric;statistics;software quality analyst	SE	-65.45078245016384	29.568904647916256	139239
8e85a33a520e2d2a4756f0ed15dea6137424c2e7	model-driven software engineering in the openetcs project: project experiences and lessons learned	experience report;modeling;safety critical systems;open source;etcs	Model-driven software engineering in industrial practice has been the focus of different empirical studies and experience reports. Particularly, positive effects of model-driven software engineering have been reported in the domain of embedded and safety-critical systems.  We report in this paper on the experiences of the openETCS European research project whose goal was to formalize the System Requirements Specification and to develop an open source reference implementation of the European Train Control System including open source modeling tools. Furthermore, we will discuss lessons learned, e.g., about using open source modeling toolchains in safety-critical contexts and about using the SCADE Suite for the development of the safety-critical parts.	control system;embedded system;model-driven engineering;model-driven integration;open-source software;reference implementation;software engineering;system requirements specification;toolchain	Stefan Karg;Alexander Raschke;Matthias Tichy;Grischa Liebel	2016		10.1145/2976767.2976811	simulation;systems modeling;systems engineering;engineering;software engineering;life-critical system	SE	-63.01117756173327	24.250301553679968	139385
534796bec452e39a2e746cd464e4bd0e8c840e24	cost-sensitive learning for defect escalation	software defect escalation prediction;data mining;machine learning;defect escalation;cost sensitive learning	While most software defects (i.e., bugs) are corrected and tested as part of the prolonged software development cycle, enterprise software venders often have to release software products before all reported defects are corrected, due to deadlines and limited resources. A small number of these reported defects will be escalated by customers whose businesses are seriously impacted. Escalated defects must be resolved immediately and individually by the software vendors at a very high cost. The total costs can be even greater, including loss of reputation, satisfaction, loyalty, and repeat revenue. In this paper, we develop a  Software defecT Escalation Prediction  ( STEP ) system to mine historical defect report data and predict the escalation risk of current defect reports for maximum net profit. More specifically, we first describe a simple and general framework to convert the maximum net profit problem to cost-sensitive learning. We then apply and compare four well-known cost-sensitive learning approaches for STEP. Our experiments suggest that  cost-sensitive decision trees  ( CSTree ) is the best methods for producing the highest positive net profit.	privilege escalation;software bug	Victor S. Sheng;Bin Gu;Wei Fang;Jian Wu	2014	Knowl.-Based Syst.	10.1016/j.knosys.2014.04.033	simulation;computer science;machine learning;data mining	DB	-69.53021366158345	24.074633194450204	139559
e9bfb020d21a1bace59ca4c149648d49932a71ae	a risk index for software producers	software producer;risk index;indexation;risk assessment;metric	Software risk management has been receiving increasing attention lately. A key activity of software risk management is the quantification of the risk of using a software product. Previous attempts to define the risk index have taken the usersu0027 viewpoint. The loss due to a product failure is computed based on its impact on the users. Yet, the impact of a failure on the software producer is different from that of the users. A high risk module according to the users may not be treated the same by the producer. This paper presents a method to determine the producer risk index for quantifying the probability and impact of failure on the producer at the product release time. The producer can use the results to determine whether it is more economical to improve the software quality or to release the product with the achieved quality level. The index can also be used to estimate the maintenance effort. The approach makes use of two recent developments in software complexity metrics, principal component analysis and reliability growth modelling. A new classification scheme for failure impact is introduced. Results from applying the producer risk index to a telecommunication software system are presented.		Hareton K. N. Leung	1996	Journal of Software Maintenance	10.1002/(SICI)1096-908X(199609)8:5%3C281::AID-SMR137%3E3.0.CO;2-W	reliability engineering;risk assessment;metric;systems engineering;engineering	SE	-63.35740666717526	28.456453437694847	139590
e4014747f9daa58b73034036f16e8c2a4c71ca41	investigations on user preferences of the alignment of process activities, objects and roles		Numerous attempts have been made to research the variety of different influences on the understandability of process models. Common to all of these attempts is the limitation to the process model itself. Little empirical effort is spent on investigating the understandability of the alignment of process activities, objects, and roles. This paper tackles this issue and empirically studies preferences of how to visually align process activities with objects and roles. In particular, three visualization techniques are evaluated in order to support the combination of the object and organization units with their corresponding process model elements. The empirical study provides a strong support for the visualization of a process model that is disburdened from context information such as objects used and roles involved and thus is reduced to the sole visualization of process activities and its control-flow.	align (company);control flow;process modeling	Agnes Koschmider;Simone Kriglstein;Meike Ullrich	2013		10.1007/978-3-642-41030-7_5	simulation;engineering;communication;engineering drawing	HCI	-72.50335245943393	23.68153239862531	139694
b0f2dfc3ad2d65c7a3d96ece13cd5e6c677f0a68	a tree-based approach to preserve the privacy of software engineering data and predictive models	data sharing;software processes;empirical software engineering;simulated annealing;software engineering;predictor models;faster better cheaper;cocomo;prediction model	In empirical disciplines, data sharing leads to verifiable research and facilitates future research studies. Recent efforts of the PROMISE community contributed to data sharing and reproducible research in software engineering. However, an important portion of data used in empirical software engineering research still remains classified. This situation is unlikely to change because many companies, governments, and defense organizations will be always hesitant to share their project data such as, effort and defect data, due to various confidentiality, privacy, and security concerns. In this paper, we present, demonstrate, and evaluate a novel tree-based data perturbation approach. This approach does not only preserve privacy effectively, but it also preserves the predictive patterns in the original data set. Consequently, the empirical software engineering researchers will have access to another category of data sets, transformed data sets, which will increase the verifiability of research results and facilitate the future research studies in this area. Our approach can be immediately useful to many researchers and organizations who are willing to share their software engineering data but cannot do so due to privacy concerns.	computer cluster;confidentiality;experimental software engineering;formal verification;predictive modelling;privacy;software bug	Yu Fu;Akif Günes Koru;Zhiyuan Chen;Khaled El Emam	2009		10.1145/1540438.1540443	software engineering process group;simulated annealing;privacy by design;computer science;systems engineering;engineering;data science;software development;software engineering;cocomo;data mining;database;predictive modelling;software analytics	SE	-68.64015016229672	31.129276346332578	139773
003a17e73943b0d8684cc3aee37e5f0969f4316c	design of a major in software development	learning styles;student profiling;software engineering;software engineering education;introductory programming;body of knowledge;software development;diagnostic testing	"""This paper presents a curriculum consisting of a collection of subjects to prepare students for a career in """"software development"""" while remaining within the scope normal for a major in a broad liberal arts degree. We describe the principles behind the construction of the curriculum, and contrast it with the more extensive """"Software Engineering Body of Knowledge"""" appropriate in a professional Engineering degree."""	software engineering body of knowledge;software development	Alan Fekete;Bob Kummerfeld	2002		10.1145/563340.563367	personal software process;software engineering process group;computer science;software design;social software engineering;component-based software engineering;software development;body of knowledge;software engineering;software construction;software walkthrough;software analytics;software development process;software requirements;diagnostic test;software peer review	SE	-65.93391159487835	26.108650600365188	139788
ca4b974be8bff15f90b550fd4b5526004b378e33	empirical evaluation of novel approaches to software engineering	software engineering	"""It is a pleasure to present to our readers the first issue of the e-Informatica Software Engineering Journal (ISEJ). The idea to establish the e-Informatica Software Engineering Journal as a new scientific journal has been considered by Polish academic environment for several years. Finally, it appeared that we are able to start the international software engineering journal with strong support from many recognized researchers and practitioners in Europe who agreed to join the Editorial Board. We would like to express our gratitude to all those involved in many international software engineering conferences, e. for sponsoring the journal and many outstanding students involved in e-Informatyka project. The mission of the e-Informatica Software Engineering Journal is to be a prime international journal to publish research findings and IT industry experiences related to theory, practice and experimentation in software engineering. The scope of e-Informatica Software Engineering Journal includes methodologies, practices, architectures, technologies and tools used in processes along the software development lifecycle, but particular stress is laid on empirical evaluation. There is evidence that software engineering researchers undertake relatively little empirical validation of their research [1, 2, 3]. Therefore the aim of the journal is to put a strong emphasis on empirical evaluation of novel approaches to software engineering. The journal's emphasis is in line with the ENASE series of conferences started by Leszek Maciaszek and Lech Madeyski (members of the editorial board) and Zbigniew Huzar (Editor-In-Chief) in 2006. The first issue of the e-Informatica Software Engineering Journal includes five papers carefully reviewed by Editorial Board members, as well as by external reviewers, and then selected by the editors. Addressing the raised empirical validation issue, the first of the papers includes an empirical evaluation of refactoring technique. The second article explores some of the basic tenets of eXtreme Programming (XP) and agile methodologies and presents an analysis of an interview with two of the proponents and early participants in the """" Agile revolution """" , Chet Hendrickson and Ron Jeffries. The third paper analyses to what extent the CMMI process areas can be covered by XP, and where adjustments of XP have to be made. The last two papers do not fall into an agile track. The forth paper identifies a program verification problem which is caused by the loose conventional object typing/subtyping, introduces object type graphs in which object component interdepen-dencies are integrated into object types, and shows how the problem existing …"""	agile software development;capability maturity model integration;code refactoring;extreme programming;formal verification;object type (object-oriented programming);software development process;software engineering	Zbigniew Huzar;Lech Madeyski	2007	e-Informatica		feature-oriented domain analysis;software engineering;software peer review;software verification and validation;software analytics;software construction;software development;social software engineering;search-based software engineering;computer science	SE	-66.05365964332034	24.940329898813225	139828
35dcea4bc2d4ba0bac70ef0f4f9f6592ec75b140	adapting extreme programming for a core software engineering course	north carolina state university extreme programming core software engineering course agile methodologies agile processes;software engineering programming profession manufacturing industries computer science agile manufacturing computer industry product development software measurement software quality quality control;agile processes;software measurement;agile manufacturing;software development process;manufacturing industries;computer industry;software engineering;extreme programming;business environment;computer science education;agile methodologies;programming profession;educational courses;software industry;manufacturing industry;educational courses software engineering computer science education;computer science;core software engineering course;quality control;north carolina state university;software quality;north carolina;product development	Over a decade ago, the manufacturing industry determined it needed to be more agile to thrive and prosper in a changing, nonlinear, uncertain and unpredictable business environment. Recently, the software engineering community has come to the same realization. A group of software methodologists has created a set of software development processes, termed agile methodologies that have been specifically designed to respond to the demands of the turbulent software industry. Each of the processes in the set of agile processes is comprised of a set of practices. As educators, we must assess the emerging agile practices, integrate them into our courses (carefully), and share our experiences and results from doing so. This paper discusses the use of Extreme Programming, a popular agile methodology, in a senior Software Engineering course at North Carolina State University. It then provides recommendations for integrating agile principles into a core Software Engineering course.	agile software development;extreme programming;nonlinear system;software engineering;software industry;turbulence	Anuja Shukla;Laurie A. Williams	2002		10.1109/CSEE.2002.995210	feature-driven development;requirements analysis;personal software process;software engineering process group;agile unified process;extreme programming practices;agile usability engineering;systems engineering;engineering;software evolution;social software engineering;component-based software engineering;software development;requirement;software engineering;software construction;agile software development;software walkthrough;software documentation;empirical process;lean software development;software development process;best coding practices;computer engineering	SE	-65.59566127373724	26.19407947568603	140032
5c4a08a28b46fec62a0b45a26647330a0e69feb8	seven process modeling guidelines (7pmg)	model quality;computacion informatica;grupo de excelencia;business process modeling;business process model;guidelines;ciencias basicas y experimentales;process model	Business process modeling is heavily applied in practice, but important quality issues have not been addressed thoroughly by research. A notorious problem is the low level of modeling competence that many casual modelers in process documentation projects have. Existing approaches towards model quality might be of potential benefit, but they suffer from at least one of the following problems. On the one hand, frameworks like SEQUAL and the Guidelines of Modeling are either too abstract to be applicable for novices and non-experts in practice. On the other hand, there are collections of pragmatic hints that lack a sound research foundation. In this paper, we analyze existing research on relationships between model structure on the one hand and error probability and understanding on the other hand. As a synthesis we propose a set of seven process modeling guidelines (7PMG). Each of these guidelines builds on strong empirical insights, yet they are formulated to be intuitive to practitioners. Furthermore, we analyze how the guidelines are prioritized by industry experts. In this regard, the seven guidelines have the potential to serve as an important tool of knowledge transfer from academia into modeling practice.	business process;documentation;information systems research;process modeling;real life;sequal framework;systems theory;usability	Jan Mendling;Hajo A. Reijers;Wil M. P. van der Aalst	2010	Information & Software Technology	10.1016/j.infsof.2009.08.004	simulation;computer science;engineering;knowledge management;artifact-centric business process model;software engineering;database;management science;management;business process modeling	SE	-71.85562730235311	23.353015441883684	140080
a2ba334f3781751ccf53e9b6eeebe8878eb5da8a	a preliminary systematic mapping study of human competitiveness of sbse		Search Based Software Engineering (SBSE) seeks to reformulate Software Engineering complex problems as search problems to be, hereafter, optimized through the usage of artificial intelligence techniques. As pointed out by Harman in 2007, in his seminal paper about the current state and future of SBSE, it would be very attractive to have convincing examples of human competitive results in order to champion the field. A landmark effort in this direction was made by Souza and others, in the paper titled “The Human Competitiveness of Search Based Software Engineering”, published at SSBSE’2010, voted by the SBSE community as the most influential paper of the past editions in the 10th anniversary of the SSBSE, in 2018. This paper presents a preliminary systematic mapping study to provide an overview of the current state of human competitiveness of SBSE, carried out via a snowball reading of Souza’s paper. The analyses of the 29 selected papers showed a growing interest in this topic, especially since 2010. Seven of those papers presented relevant experimental results, thus demonstrating the human competitiveness of results produced by SBSE approaches.	search-based software engineering	Jerffeson Souza;Allysson Allex Araújo;Raphael Saraiva;Pamella Soares;Camila Loiola Brito Maia	2018		10.1007/978-3-319-99241-9_6	systems engineering;computer science;data science;champion;search-based software engineering	HCI	-65.84362971962929	24.28756637486321	140108
376f34c78d56b79618800384da95d746fb7735cd	transition of software maintenance teams from scrum to kanban	software management project management software maintenance;software maintenance;collaboration;maintenance engineering;companies;scrum software development;maintenance engineering software maintenance interviews companies collaboration scrum software development;interviews;software maintenance team transition finnish software companies collaboration communication team motivation software quality project visibility software companies kanban scrum;software maintenance kanban scrum agile lean	Software companies are increasingly moving to use Kanban after Scrum since Kanban claimed to offer improved project visibility, software quality, team motivation, communication and collaboration. However, empirical studies are needed to verify these effects and companies' real motivation for the transition. In particular, underlying reasons leading software companies to start using Kanban in software maintenance must be understood. A multiple-case study was conducted to investigate why two experienced Scrum maintenance teams transitioned to Kanban. We conducted 17 semi-structured interviews with two different teams from two large Finnish software companies. Thematic analysis was applied to identify the most common challenges in Scrum and their solutions in Kanban. The results showed that Scrum maintenance teams faced challenges, such as lack of work visibility, task prioritisation, communication and collaboration, over commitment of sprints, work synchronisation and changing people. We discuss how maintenance teams mitigated these challenges with Kanban and present the lessons learned.	kanban (development);scrum (software development);semiconductor industry;software industry;software maintenance;software quality	Muhammad Ovais Ahmad;Pasi Kuvaja;Markku Oivo;Jouni Markkula	2016	2016 49th Hawaii International Conference on System Sciences (HICSS)	10.1109/HICSS.2016.670	maintenance engineering;personal software process;long-term support;interview;social software engineering;software development;software engineering;scrum;empirical process;software maintenance;management;software deployment;kanban;collaboration;software peer review	SE	-68.35869089396202	22.460280408988247	140452
cc73c83a903c5d83fa4b466b739fb447dffccf4a	a quantitative analysis into the economics of correcting software bugs	software verification;model checking;software development life cycle;empirical studies	"""Using a quantitative study of in-house coding practices, we demonstrate the notion that programming needs to move from """"Lines of Code per day"""" as a productivity measure to a measure that takes debugging and documentation into account. This could be something such as """"Lines of clean, simple, correct, well-documented code per day"""", but with bugs propagating into the 6th iteration of patches, a new paradigm needs to be developed. Finding flaws in software, whether these have a security related cost or not, is an essential component of software development. When these bugs result in security vulnerabilities, the importance of testing becomes even more critical. Many studies have been conducted using the practices of large software vendors as a basis, but few studies have looked at in-house development practices. This paper uses an empirical study of in-house software coding practices in Australian companies to both demonstrate that there is an economic limit to how far testing should proceed as well as noting the deficiencies in the existing approaches."""	clean;debugging;documentation;it risk management;in-house software;iteration;money;programming paradigm;software bug;software development;software industry;source lines of code;vulnerability (computing)	Craig S. Wright;Tanveer A. Zia	2011		10.1007/978-3-642-21323-6_25	software security assurance;model checking;long-term support;verification and validation;simulation;software sizing;crowdsourcing software development;extreme programming practices;software verification;computer science;package development process;software design;software development;software design description;software rot;software construction;software testing;systems development life cycle;software walkthrough;secure coding;empirical research;computer security;best coding practices;software metric;software quality analyst	SE	-64.92443252332131	28.44928848400497	140745
cefaaa7ef764b755cb506d6737a3d6f19fbe882d	keynote 2 - past, current, and future of faster, cheaper, better	formal specification;software prototyping;reconfigurable architectures;esl method ares vallis valley sojourner rover panoramic color photos mars pathfinder development complex fpga based systems hls method superman dilemma multicore development rcc development system specification software based agile engineering technique model based engineering technique fpga development process;high level synthesis;software prototyping field programmable gate arrays formal specification high level synthesis reconfigurable architectures;field programmable gate arrays	The Mars Pathfinder landed in the Ares Vallis valley on July 4th, 1997, and after deploying the Sojourner rover and sending back detailed panoramic color photos the mission captured the world’s attention and people’s imagination. The Mars Pathfinder development was an example of doing design quickly, at less cost and having it work better than expected (give or take a few software “glitches”). So why does industry have so much trouble doing “Faster, Cheaper, Better” in larger and more complex FPGA based systems since then? This presentation takes a journey through insights gained using different tools, techniques and methods to sort through what works, where we need to go and what the future holds.	field-programmable gate array;glitch;rover (the prisoner)	Tim Gallagher	2013		10.1109/ReConFig.2013.6732254	embedded system;simulation;computer science;operating system;formal specification;high-level synthesis;field-programmable gate array	DB	-68.22059153036476	27.940140220480682	140849
f64f868fb1d801fc208c9323d69a26d68c624645	design-level metrics estimation based on code metrics	software metrics;fuzzy classification;software defect prediction;programming language;data mining;software development methodology;software process model;fault detection;software metric;approximate dependencies;source code;parameter estimation;fuzzy model	"""Fault detection based on mining code and design metrics has been an active research area for many years. Basically """"module""""-based metrics for source code and design level are calculated or obtained and data mining is used to build predictor models. However, in many projects due to organizational or software process models, design level metrics are not available and/or accurate. It has been shown that performance of these classifiers or predictors decline if only source code features are used for training them. Based on best of our know knowledge no set of rule to estimate design level metrics based on code level metrics has been presented since it is believed that design level metrics have additional information and cannot be estimated without access to design artifacts. In this study we present a fuzzy modeling system to find and present these relationships for projects presented in NASA Metrics Data Repository (MDP) datasets. Interestingly, we could find a set of empirical rules that govern all the projects regardless of size, programming language and software development methodology. Comparison of fault detectors built based on estimated design metrics with actual design metrics on various projects showed a very small difference in accuracy of classifiers and validated our hypothesis that estimation of design metrics based on source code attributes can become a practical exercise."""	data mining;fault detection and isolation;kerrison predictor;programming language;sensor;software design;software development process;software metric	Ashkan Sami;Seyed Mostafa Fakhrahmad	2010		10.1145/1774088.1774612	halstead complexity measures;computer science;theoretical computer science;data mining;programming language;software metric;static program analysis	SE	-65.3997177297315	31.42708397180737	140940
47ada3499851707a02d743030b1345fbe4e7af10	the challenge of complexity in dependable plc-based systems	software;reliability;complexity theory;industries;plc;complexity;software research complexity dependable plc based systems software engineering east asia shipbuilding;software software reliability safety complexity theory industries complex systems;dependability;safety;complex systems;reliability plc complexity dependability;software reliability;software engineering computational complexity programmable controllers shipbuilding industry	The objective of this article is to introduce researchers to the software engineering challenges of an industry that is important to many of the economies of East Asia -- shipbuilding. Research in software technologies critical to this industry has lagged that of software research in other domains.	complex system;complex systems;power-line communication;software development;software engineering	David N. Card	2015	2015 IEEE 39th Annual Computer Software and Applications Conference	10.1109/COMPSAC.2015.6	reliability engineering;complex systems;verification and validation;complexity;software engineering process group;software verification;search-based software engineering;computer science;systems engineering;engineering;social software engineering;software reliability testing;software development;software engineering;programmable logic controller;software construction;reliability;dependability;software deployment;software requirements;software quality;software system;avionics software	SE	-63.826065487955354	26.84151378587611	140973
8c4a6e9315d35fb33e8e752b3d0d47080e5d1ea3	evaluating the software test strategy for the 2000 sydney olympics	software reliability program testing;software testing;measurement techniques;odc;information technology;software systems;test analysis;software test strategy 2000 summer olympic games information technology test analysis measurement techniques orthogonal defect classification odc 2000 sydney olympics;orthogonal defect classification;program testing;software testing system testing performance evaluation history scheduling software engineering information technology software systems measurement techniques computer architecture;validation;evaluation;software reliability;measurement technique;olympic games	The 2000 summer Olympic Games event was a major information technology challenge. With a fixed deadline for completion, its inevitable dependency on software systems and immense scope, the testing and verification effort was critical to its success. One way in which success was assured was the use of innovative techniques using ODC based analysis to evaluate planned and executed test activities. These techniques were used to verify that the plan was comprehensive, yet efficient, and ensured that progress could be accurately measured. This paper describes some of these techniques and provides examples of the benefits derived. We also discuss the applicability, of the techniques to other software projects.	software testing;test strategy	Kathryn Bassin;Shriram Biyani;Padmanabhan Santhanam	2001		10.1109/ISSRE.2001.989480	orthogonal defect classification;reliability engineering;simulation;systems engineering;engineering;evaluation;operating system;software engineering;software testing;information technology;software quality;software system	SE	-63.045939138888784	30.512875067285243	141074
d12fcaf5b122d1499df2a9506b1f954b1a374017	assessing the strength of global teaming practices: a pilot study	software;pilot study;empirical study;project management;software process improvement;software engineering groupware project management;process assessment;companies;gsd;gse;global software engineering;capability maturity model;global teaming model;software companies capability maturity model conferences project management;gta global teaming practices global software engineering global development activities gse software process improvement activities global teaming assessment;global software development;conferences;software process improvement global software development global software engineering gsd gse process assessment global teaming model project management pilot study empirical study	"""After more than a decade of research in Global Software Engineering (GSE), organisations have a wealth of practices that they can draw on to support them in their global development activities. However, practitioners are now asking, """"What is the current status of my GSE practices?"""", """"How prepared is my company for GSE?"""", """"What practices need improving?"""" We aim to give practitioners the answers they need by giving them a snapshot of their current GSE process strengths and weaknesses that can act as a guide for future software process improvement activities. We do this through our lightweight Global Teaming Assessment (GTA) based on 70 recommended GSE practices which we piloted in a small company."""	generic stream encapsulation;snapshot (computer storage);software development process;software engineering	Sarah Beecham;Ita Richardson;John Noll	2015	2015 IEEE 10th International Conference on Global Software Engineering	10.1109/ICGSE.2015.14	project management;reliability engineering;economics;systems engineering;engineering;software engineering;empirical research;management;capability maturity model	SE	-68.40245886986555	21.015630647485715	141265
7cce2278c123bada9397913966a3a7112268d9a2	future software development management system prototype	management system;educational software;software development	Initial work during the last ten years for defining and prototyping software Development Management Systems has prepared the ground for presenting the concepts for the year 2000 DMS. DMS product evolution, features, 'approach, concepts and philosophy', future year 2000 concepts and current DMS prototype implementation are discussed. Finally, an offspring of the DMS project, EduSET: Educational Software Engineering Tool, is outlined.	digital multiplex system;forge (software);prototype;software development;software engineering	Ben Livson	1988		10.1145/322609.322615	personal software process;verification and validation;simulation;software project management;computer science;package development process;social software engineering;software development;software engineering;software construction;management system;educational software;software walkthrough;software deployment;software development process;software system;software peer review	SE	-63.78584643747228	24.198270604686925	141282
dde5215cdd3cab34f7a1b25085be13a2def259f2	workshop on program comprehension through dynamic analysis (pcoda &#145;05)	software maintenance;software system;program comprehension technique;program comprehension;dynamic analysis;better comprehension;dynamic analysis;program comprehension;dynamic analysis technique	Software maintenance and evolution can be made easier if program comprehension techniques are used. Understanding a software system would typically necessitate a combination of static and dynamic analysis techniques. The aim of this workshop is to gather researchers working in the area of program comprehension with an emphasis on dynamic analysis. We are interested in investigating how dynamic analysis techniques are used or can be used to enable better comprehension of a software system.	dynamic program analysis;list comprehension;program comprehension;software maintenance;software system	Orla Greevy;Abdelwahab Hamou-Lhadj;Andy Zaidman	2005	12th Working Conference on Reverse Engineering (WCRE'05)	10.1109/WCRE.2005.35	software engineering	SE	-63.92446300973607	29.614018695039274	141522
fccff102af0e7d7cbf433f7a603393943491b064	advances in software product quality measurement and its applications in software evolution	software systems;computational modeling;iec standards;university of szeged software product quality measurement software evolution software product quality modeling system level software quality models source code element level software quality models hungarian project international r d projects software engineering department;correlation software quality software systems computational modeling predictive models iec standards;source code software project management software maintenance software quality;predictive models;correlation;software quality	The main results presented in this work, a synopsis of the connected PhD dissertation, are related to software product quality modeling and measurement as well as to the application of the newly proposed methods, tools and techniques in software evolution.	software evolution	Péter Hegedüs	2015		10.1109/ICSM.2015.7332520	reliability engineering;personal software process;medical software;long-term support;verification and validation;software sizing;software project management;computer science;systems engineering;engineering;package development process;social software engineering;software development;software engineering;software construction;predictive modelling;software walkthrough;software analytics;software measurement;computational model;software deployment;software quality control;correlation;software quality;software quality analyst;software system;software peer review	SE	-64.09513699988534	27.24121728505553	141554
d0a85a7232626ab4c8fa05feb9827bc2bf7fabfc	driving software quality at a silicon valley high-tech software company	silicon;software quality silicon quality management software maintenance software tools application software costs manufacturing industries continuous improvement productivity;application software;software maintenance;manufacturing industries;continuous improvement;software tools;productivity;software quality;quality management	Tri-Partite company targets printing industry and Silicon Valley to fuel growth for Outsourcing3rd Party Applications and Testing HONG KONG (Novermber 17, 2008) – We Software Ltd (WeSoft), a leading software outsourcing company with operations in the US, Hong Kong and China, is expanding its operations in the US market with the appointment of two seasoned veterans to oversee business opportunities in two distinct market sectors. In a bid to capitalize on what it has identified as a growing need among small and medium sized enterprises (SMEs) and new startup operations for high quality, yet affordable, multi-platform 3rd party software solutions, WeSoft has appointed Cary A. Kimmel as business development director and Michael Denzel as general manager, sales to oversee the company’s expansion in the printing and imaging and the technology sectors, respectively With a strong background in the printing and imaging industry, Kimmel will focus on driving business opportunities for WeSoft in that segment while Denzel will leverage his wealth of experience to build business opportunities among emerging technology companies in Silicon Valley Prior to joining WeSoft, Kimmel spent 13 years with Peerless Systems Corporation, most recently as vice president for business development where he was responsible for pricing of proposals, contracts and intellectual property license development projects. Previously, Kimmel was a business development manager with Xerox for Desktop Printer Products and has also served with Grumman Aircraft Corporation, the U.S. Department of Defense and the U.S. Department of State Consular Service New York. He has a B.A. in Political Science from Queens College, City University of New York, and attended graduate studies at the University of Maryland and the Air Force Institute of Technology. For his part, Denzel, was most recently a general partner at McKenna Ventures, an early stage investment company, where he reviewed thousands of business plans, invested in several startups and has consulted for many companies. He was instrumental in the development of many successes, including serving on the board of directors of Broadware, which was acquired by Cisco in 2007. ...2 WeSoft Previously Denzel held a variety of roles with increasing accountability in the Sales and Marketing divisions at Quantum Corporation and Maxtor Corporation. He holds a Bachelor of Science Degree in Industrial Engineering at the State University of New York at Buffalo and his MBA at Santa Clara University. WeSoft specializes in a range of outsourcing services including software development, localization and globalization, software quality assurance and testing, application customization and cross-platform development and porting.	buffalo airstation;desktop computer;device driver;display resolution;industrial engineering;outsourcing;printer (computing);printing;quantum;software development;software house;software quality assurance;third-party software component	Giora Ben-Yaacov	2002		10.1109/ICSM.2002.1167819	reliability engineering;personal software process;long-term support;quality management;verification and validation;productivity;application software;software project management;computer science;systems engineering;engineering;package development process;social software engineering;software development;software engineering;software construction;process management;manufacturing;silicon;software maintenance;software deployment;software quality control;software quality;software quality analyst	SE	-66.41097710866106	20.988666904692476	141578
46ee13d83206f2422bc503d0eb252db3d2c48706	fun with software developers and biometrics: invited talk		The use of low-cost, widely available, biometric sensors has skyrocketed over the past few years, enabling anyone to measure how their physiological signals change as they go about their daily lives. We use these sensors to understand software development activities, however, their use is not straightforward, nor is it easy. In this paper, we introduce some common sensors, along with some difficulties we encountered in using them in our experiments as well as how we worked past them. We call on everyone in our community to share best practices in sensor application and analysis in order to enable our field to grow as quickly as possible while producing robust, reliable results.	biometrics;software developer	Andrew Begel	2016		10.1109/SEmotion.2016.009	simulation;engineering;data mining;computer security	SE	-67.43973229680711	28.444527311512974	142324
0ac8abb2264944e3f7fae38f6f6f3862de274e13	reliability of feedback fechanism based on root cause defect analysis - case study	feedback fechanism;defect prevention activity;rca data collection process;rca assessment;measurement system;gauge r;r study;root cause defect analysis-case;common pitfall;case study;root cause defect analysis;data consistency	The case study presented in this article focuses on the common pitfall in which many defect prevention activities fall, caused by inconsistency of data. Before any collected Root Cause Defect Analysis (RCA) data can be used reliably, an analysis of the variation due to the measurement system itself such as a Gauge R&R study, should be performed. This allows to understand of the integrity of the data in terms of data consistency and validity. The RCA data collection process chosen for this case study concentrates on the RCA assessment performed by engineers independently.	categorization;data recovery;feedback;software bug;software engineering;synergy;system of measurement	Marek Grzegorz Stochel	2011	Annales UMCS, Informatica	10.2478/v10065-011-0037-0	data mining	SE	-64.84836726134024	32.21335041703985	142590
63bf8c7bd40dba71c59834c47bad023b5dd87ec1	flight software engineering lessons	software process improvement;software engineering	This paper summarizes the findings of several studies and mishap investigations that explored the causes of flight software problems. From these studies and mishap investigations the author identifies several lessons from which others can learn. A key lesson that the author proposes is that software engineering in the real world is largely one of managing risk.	design rationale;embedded software;jones calculus;requirement;schedule (computer science);software development;software engineering	Ronald Kirk Kandt	2009			personal software process;verification and validation;software engineering process group;software verification;systems engineering;package development process;social software engineering;component-based software engineering;software development;software engineering;software construction;software walkthrough;resource-oriented architecture;software deployment;software requirements;software system;computer engineering;software peer review	SE	-65.0642292067152	25.4677083260759	142696
0aa978e11f9ce3caafe3914e908a748d246fd0ee	fantasy, farms, and freemium: what game data mining teaches us about retention, conversion, and virality (keynote abstract)	generics;post mortem analysis;data mining;software engineering;business model;social network;user experience;word of mouth;languages;java language;java	In December of 2010, the new game CityVille achieved 6 million daily active users in just 8 days. Clearly the success of CityVille owes something to the fun gameplay experience it provides. That said, it was far from the best game released in 2010. Why did it grow so fast? In this talk the key factors behind the dramatic success of social network games are explained. Social network games build word-of-mouth player acquisition directly into the gameplay experience via friend invitations and game mechanics that require contributions by friends to succeed. Software analytics (mined data about player sessions) yield detailed models of factors that affect player retention and engagement. Player engagement is directly related to conversion, shifting a free player into a paying player, the critical move in a freemium business model. Analytics also permit tracking of player virality, the degree to which one player invites other players into the game. Social network games offer multiple lessons for software engineers in general, and software mining researchers in particular. Since software is in competition for people's attention along with a wide range of other media and software, it is important to design software for high engagement and retention. Retention engineering requires constant attention to mined user experience data, and this data is easiest to acquire with web-based software. Building user acquisition directly into software provides powerful benefits, especially when it is integrated deeply into the experience delivered by the software. Since retention engineering and viral user acquisition are much easier with web-based software, the trend of software applications migrating to the web will accelerate.	daily active users;data mining;game mechanics;mined;social network;software analytics;software engineer;software mining;user experience;web application	E. James Whitehead	2011		10.1145/1985441.1985443	business model;word of mouth;user experience design;simulation;computer science;engineering;operating system;software engineering;machine learning;software as a service;data mining;multimedia;software walkthrough;programming language;generic programming;java;management;world wide web;social network	HCI	-70.94463627661956	26.30700613810548	143271
681459bfd2bd7a4d529ac7cae8ae411c5f5c4945	a mathematical modeling framework for software reliability testing	continuous time;software testing;generic model;discrete time;markov usage model based testing;action selection;reliability assessment;mathematical model;model based testing;software reliability;software testing stability	Software reliability testing refers to various software testing activities that are driven to achieve a quantitative reliability goal given a priori or lead to a quantitative reliability assessment for the software under test. In this paper we develop a modeling framework for the software reliability testing process, comprising a simplifying model and a generalized model. In both models the software testing action selection process and the defect removal mechanism are explicitly described. Both the discrete-time domain and the continuous-time domain are involved. The generalized model is more accurate or realistic than the simplifying model since the former avoids the assumption that defects are equally detectable and the assumption that defects are removed upon being detected. However simulation examples show that the simplifying model really captures some of essential features of the software testing process after a short initial testing stage. The modeling framework is practically realistic, mathematically rigorous, and quantitatively precise. It demonstrates that the relationship between software testing and delivered software reliability, which was poor understood, can well be formulated and quantified. Rigorous examinations show that several common assumptions adopted in software reliability modeling, including the independence assumption, the exponentiality assumption, and the NHPP assumption, are theoretically false in general. This paper sets a good starting point to further formalize and quantify the software testing process and its relation to delivered software reliability.	action selection;mathematical model;reliability engineering;simulation;software bug;software reliability testing;software testing	Kai-Yuan Cai;Zhao Dong;Ke Liu;Chenggang Bai	2007	Int. J. General Systems	10.1080/03081070600957939	non-regression testing;development testing;discrete time and continuous time;verification and validation;regression testing;model-based testing;simulation;action selection;orthogonal array testing;software performance testing;white-box testing;manual testing;system integration testing;computer science;software reliability testing;software construction;mathematical model;mathematics;risk-based testing;software testing;software quality;stress testing	SE	-62.900962337540086	31.719065583912386	143507
54b0c3734b4fb61a48a9e69aed54962f4b8c2f2b	using metrics to manage software projects	software metrics;project management;software process improvement;inspection data software projects management software process project management quality productivity phoenix operation;software project management;software metrics dp management project management;project management programming knee system testing capability maturity model feedback size measurement software engineering data analysis engineering management;dp management;historical data	Five years ago, Bull's Enterprise Servers Operation in Phoenix, Arizona, used a software process that, although understandable, was unpredictable in terms of product quality and delivery schedule. The process generated products with unsatisfactory quality levels and required significant extra effort to avoid major schedule slips. All but the smallest software projects require metrics for effective project management. Hence, as part of a program designed to improve the quality, productivity, and predictability of software development projects, the Phoenix operation launched a series of improvements in 1989. One improvement based software project management on additional software measures. Another introduced an inspection program, since inspection data was essential to project management improvements. Project sizes varied from several thousand lines of code (KLOC) to more than 300 KLOC. The improvement projects enhanced quality and productivity. In essence, Bull now has a process that is repeatable and manageable, and that delivers higher quality products at lower cost. We describe the metrics we selected and implemented, illustrating with examples drawn from several development projects.<<ETX>>	software development process;software project management;source lines of code	Edward F. Weller	1994	Computer	10.1109/2.312035	project management;personal software process;long-term support;verification and validation;team software process;software quality management;software engineering process group;software sizing;software project management;package development process;software development;software engineering;software construction;application lifecycle management;project management triangle;management;software quality control;software development process;software quality;project planning;software metric;software quality analyst;software peer review	SE	-67.46937402638085	26.739237137432948	143706
e0ed52e57f34ac530e6f81d20e2ae034765deaa8	editor’s note		"""Internet has now become the main place of IT technology and business innovations, from Web 2.0, social network, mobile Internet, cloud computing, to Internet of Things and big data. To embrace these innovations as well as to cope with the extremely open and dynamic natures of Internet, software systems have to be autonomous, cooperative, situational, evolvable, emergent, and trustworthy. To systematically support the development and deployment of software systems with these characteristics, a new generation of software paradigm, known as """" Internetware """" , is needed. A software paradigm (also called a programming paradigm) describes a software model and its construction from the perspective of software engineers or programmers, usually including four main concerns, namely What-to-Be, How-to-Do, How-to-Run and How-Well. Encouraging results are emerging in this active research filed and the general software engineering community's interest in Internetware is ever increasing. This special focus includes 11 papers, each having been rigorously reviewed by leading experts in the Internetware field, and having gone through minor or major revisions based on the reviewers' comments. It covers the state-of-the-art theory and practice of the Internetware paradigm, from runtime adaptation and evolution with the help of requirement models, architecture models, configuration models, context models, correlation models and propagation models, to collaborative requirements modeling, automated service composition and open source development with various socio-technical considerations. We hope that the reader may benefit from this special focus and find it useful in gaining the latest progress of Internetware. Finally, we thank all authors for submitting and revising their interesting and valuable papers, and all reviewers for evaluating the submitted and revised papers timely and insightfully."""	autonomous robot;big data;cloud computing;emergence;internet of things;open-source software;programmer;programming paradigm;requirement;requirements analysis;service composability principle;social network;sociotechnical system;software deployment;software engineer;software engineering;software propagation;software system;web 2.0	Gang Huang;Xiaoxing Ma;Weitek Tsai	2013	Science China Information Sciences	10.1007/s11432-013-4926-2		SE	-64.96581281321117	24.22022653709354	144089
32c39c659888cb955568b38de87ab4b2f1ca05a1	building or buying a scalable software system - a handbook	software systems		handbook;software system	Craig D. Hanson;Pat V. Crain	2000			backporting;software deployment;software peer review;software system;software design description;software engineering;resource-oriented architecture;package development process;social software engineering;computer science	SE	-63.59243118899856	25.33630729326388	144113
4324fbaf89774b4a71540015e852c31e96d91dc8	influence of software product management maturity on usage of artefacts in agile software development		Context: Agile software development (ASD) uses ‘agile’ artefacts such as user stories and product backlogs as well as ‘non-agile’ artefacts, for instance designs and test plans. Rationales for incorporating especially non-agile artefacts by an agile team mainly remain unknown territory. Goal: We start off to explore influences on artefacts usage, and state our research question as: To what extent does maturity relate to the usage of artefacts in ASD in software product organizations? Method: In our multiple case study 14 software product organizations were visited where software product management maturity was rated and their artefacts usage listed. Results: We found maturity to be negatively correlated with the non-agile/all artefacts ratio. In other words, the more mature software product management is, the fewer non-agile artefacts are used in ASD. Conclusions: This suggests that an organizational factor influences an agile team in its artefacts usage, contradictory to the concept of self-organizing	agile software development;capability maturity model;organizing (structure);scrum (software development);self-organization;software product management;test plan;user story	Gerard Wagenaar;S. J. Overbeek;Garm Lucassen;Sjaak Brinkkemper;Kurt Schneider	2017		10.1007/978-3-319-69926-4_2	engineering;systems engineering;agile software development;empirical process (process control model);package development process;process management;personal software process;agile usability engineering;social software engineering;lean software development;software product management	SE	-68.91606884128257	21.67606762906775	144354
36f9bb788d2fafe03b60396dd767640d84d938cb	impact of plm system in the new food development process performances: an empirical research		Over the last few years, the food industry has become increasingly more relevant since it represents excellence not only at the European level, but also for the worldwide economy. Starting with this consideration, the main objective of this paper is to provide some elements that could support food companies to be successful in the market. In 2016, during the last PLM conference, the first results of a wider research were presented with the aim to understand how the PLM solution has been adopted into the food industry, and its limits and challenges of the deployment in this sector. This paper presents how the study has evolved through this year. Starting from this point, the impacts and effects from the use of the PLM solution on the New Food Development (NFD) process performances have been described. To identify these effects, a questionnaire was developed and used as a framework to support the data gathering process; each section of the questionnaire is described in the paper. Furthermore, the results of a preliminary empirical research based on a case study are shown. The results of this work will help both food companies and PLM vendors. Indeed, it will support PLM vendors to understand the food industry vision about their NFD process and performances. On the other hand, food companies will be able to better understand their NFD process, their NFD process performances and how they can use the PLM solution to affect their performances.	performance	Claudia Pinna;Laureline Plo;Monica Rossi;Vincent Robin;Sergio Terzi	2017		10.1007/978-3-319-72905-3_47	empirical research;data collection;process management;software deployment;food industry;business;excellence	HCI	-69.09419767548364	19.15132962633879	144453
4f59ea7fba55bea5b5f616fc9b2e3a31b9a32ec4	knowledge sharing in traditional and agile software processes	conference paper;knowledge sharing;software process	The software development community has a wide spectrum of methodologies to implement a software project. In one side of the spectrum we have the more Traditional deterministic software development derived from Tayloristic management practices, and in the other side, are the Agile software development approaches. The Agile processes are people oriented rather than process oriented, unlike the Traditional processes they are adaptive and not predictive. Software development is a knowledge intensive activity and the Knowledge Creation and Sharing are crucial parts of the software development processes. This paper presents a comparison between Knowledge Sharing approaches of Agile and Tayloristic software development teams.	agile software development;blueprint;iteration;iterative and incremental development;knowledge management;linear model;pair programming;software engineering;software project management;turbulence	Broderick Crawford;Claudio León de la Barra;José Miguel Rubio León	2008			personal software process;verification and validation;agile unified process;extreme programming practices;agile usability engineering;software project management;computer science;systems engineering;engineering;knowledge management;package development process;social software engineering;software development;software engineering;release management;software construction;agile software development;software documentation;empirical process;software analytics;lean software development;software deployment;software development process;software peer review	SE	-66.05866912417453	22.35957100415261	144810
c0b3716bb692d8d6949bd390b804687c7ccb24ac	high voltage insulation system monitoring and diagnostics: generators, power transformers	generators;power transformers;diagnosis	During last decades a variety of different practices having the main intention to assess the expected reliability and remaining life span of large units in the power system have been introduced and implemented. During the first period a so called Timely Based Diagnostics (TBD) with a defined periodicity was practiced. Further on the development and introduction of improved testing and measuring methods and tools brought on the Condition Based Diagnostics (CBD). Finally, the Reliability Oriented Diagnostics (ROD) fostered by appropriate methods and tools is practiced by many utilities. The article depicts the most important testing and measuring procedures reported during the last years and particularly those which were long-term practiced in the Milan Vidmar Electric Power Research Institute contributing to an appropriate and efficient asset management.	system monitor;transformers	Maks Babuder;Boris Zitnik;Maja Koncan-Gradnik;Ivo Kobal;Tim Gradnik	2012	Elektrotechnik und Informationstechnik	10.1007/s00502-012-0018-z	engineering;electrical engineering;medical diagnosis;forensic engineering;transformer	Arch	-70.88779616576954	29.623143692568508	145014
dddcd80b5440106294a8a17e4da7f5825f2797ee	how to improve performance of software systems: a methodology and a case study for tuning performance	performance measure;experimental design;software systems;design optimization;system performance;accelerated life testing;association analysis;process scheduling;performance optimization;performance tuning	Before software systems are shipped, they are tuned to optimize their field performance. This process is called performance tuning. Performance tuning is used to find the best settings for a set of tunable, or changeable, parameters like buffer space, disk file allocation, main memory partition, I/O priority, process scheduling quantum, etc. Examples of performance measures to be optimized are: query or transaction loss, throughput rate, response time, etc. Improperly tuned systems can create field problems even if there are no software faults in the product. Hence, it is important that software systems be tuned for optimal performance before they are delivered. However, optimal performance tuning is quite complex because of: exponentially many alternatives, unknown functional relationships between parameters and performance measures, stochastically fluctuating system performance, and expensive empirical experiments. For these reasons, tuning is typically practiced as an art and depends heavily on the intuitions of experts. In this paper, we examine a method for tuning which is repeatable and produces consistently superior results across many different applications. This method, based upon Robust Experimental Design, has revolutionized design optimization in hardware systems. The methodology consists of conducting a few carefully chosen experiments and using the associated analysis technology to help extract the maximum possible information for performance optimization. Specifically we give some background on statistical experimental design and demonstrate it on an actual software system that provides network database services which had experienced occasional query losses. Focusing on nine carefully chosen parameters, 12 experiments were conducted. This number of experiments is far fewer and consequently far less costly in time and effort than what would be required for collecting the same amount of information by traditional methods. The selection of the experiments took into account ideas from accelerated life testing and ideas from the Robust Experimental Design. Based on the analysis of this data, new settings for the parameters in software system were implemented. All tests done with the new settings have shown that the query loss problem has been totally controlled.	software system	Siddhartha R. Dalal;Michael S. Hamada;Tzyh-Jong Wang	1999	Ann. Software Eng.	10.1023/A:1018910926921	real-time computing;multidisciplinary design optimization;simulation;accelerated life testing;performance engineering;computer science;engineering;genetic association;operations management;software engineering;computer performance;design of experiments;scheduling;software system	SE	-63.56607874504982	31.759142052862696	145085
3c1a3a83a9df43ef919eeb454aa0ec8c36eb7e2c	the 'tag team' : tools, tasks and roles in collaborative software development			chunking (computing);collaborative software;device driver;pair programming;principle of abstraction;programmer;software development	Sallyann Freudenberg	2006				HCI	-64.13442995093935	22.67637989375135	145343
acdfc0932fb06893d6ead7a82c807cb33982440c	a statistical examination of the evolution and properties of libre software	informatica;statistical approach;software;empirical study;history;software system;software maintenance;statistical examination;software systems;3304 06 arquitectura de ordenadores;size measurement;data mining;libre software development;software engineering;large scale;statistical distributions;statistical distributions software development management;shape;software evolution;time series analysis;estadistica y demografia;short range correlation;software development;open source software programming software systems software maintenance software safety large scale systems communication system software internet natural languages quality management;predictive models;empirical studies;free open source software;software system statistical examination software evolution libre software development;software development management;libre software	How and why does software evolve? This question has been under study since almost 40 years ago, and it is still a subject of controversy. In the seventies, Meir M. Lehman formulated the laws of software evolution, a first attempt to characterize the dynamics of the evolution of software. With the raise of the libre (free / open source) software development phenomenon, some cases that do not fulfill those laws have appeared. Are Lehman's laws valid in the case of libre software development? Is it possible to design an universal theory for software evolution? And if it is, how? This thesis is a large-scale empirical and statistical approach to analyze the properties and evolution of libre software, using publicly available data sources, hence enabling repeatability of the results and third parties verification, fundamental aspects of any empirical study. The main results are that a small subset of basic size metrics are enough to characterize a software system, software systems are self-similar, and software evolution is a short range correlated (short memory) process.	open-source software;repeatability;self-similarity;software development;software evolution;software system	Israel Herraiz	2009	2009 IEEE International Conference on Software Maintenance	10.1109/ICSM.2009.5306299	reliability engineering;computer science;systems engineering;engineering;software engineering;empirical research;programming complexity;software system	SE	-66.80443278333244	30.31729819117014	145650
5c4c66ec5768063107990e7c7af5a2b8ee65326f	orchestrator conversation: distributed management of cloud applications		Managing cloud applications is complex, and the current state of the art is not addressing this issue. The ever-growing software ecosystem continues to increase the knowledge required to manage cloud applications at a time when there is already an IT skills shortage. Solving this issue requires capturing IT operation knowledge in software so that this knowledge can be reused by system administrators who do not have it. The presented research tackles this issue by introducing a new and fundamentally different way to approach cloud application management: a hierarchical collection of independent software agents, collectively managing the cloud application. Each agent encapsulates knowledge of how to manage specific parts of the cloud application, is driven by sending and receiving cloud models, and collaborates with other agents by communicating using conversations. The entirety of communication and collaboration in this collection is called the orchestrator conversation. A thorough evaluation shows the orchestrator conversation makes it possible to encapsulate IT operations knowledge that current solutions cannot, reduces the complexity of managing a cloud application, and happens inherently concurrent. The evaluation also shows that the conversation figures out how to deploy a single big data cluster in less than 100 milliseconds, which scales linearly to less than 10 seconds for 100 clusters, resulting in a minimal overhead compared with the deployment time of at least 20 minutes with the state of the art.	cloud computing	Merlijn Sebrechts;Gregory van Seghbroeck;Tim Wauters;Bruno Volckaert;Filip De Turck	2018	Int. Journal of Network Management	10.1002/nem.2036	computer science;cloud computing;distributed computing;software engineering;information technology operations;big data;software deployment;software ecosystem;distributed management;application lifecycle management;software agent	Networks	-65.33478025007228	19.436348170033817	145928
7c7e6ae0dd4a264543548c46316ccde43ad978d0	the role of experience in software testing practice	software;software testing;banking;rail transportation;siemens austria;experience;requirements based testing software testing practice siemens austria safety critical railway systems experience based testing;software systems;case study experience testing practice experience based testing;testing;companies;experience based testing;program testing;multiple case study;software testing practice;requirements based testing;software testing system testing application software software engineering insurance banking rail transportation software systems performance evaluation nose;experience base;perceived value;testing practice;safety critical railway systems;insurance	Practitioners report that experience plays an important role in effective software testing. We investigate the role of experience in a multiple case study about three successful projects conducted at Siemens Austria and document the state of practice in testing software systems. The studied projects were employed from the domains telecommunications, insurance and banking, as well as safety-critical railway systems. The study shows that test design is to a considerable extent based on experience in all three projects and that experience-based testing is an important supplementary approach to requirements-based testing. The study further analyzes the different sources of experience, the perceived value of experience for testing, and the measures taken to manage and evolve this experience.	requirement;software system;software testing;test design	Armin Beer;Rudolf Ramler	2008	2008 34th Euromicro Conference Software Engineering and Advanced Applications	10.1109/SEAA.2008.28	test strategy;reliability engineering;systems engineering;engineering;acceptance testing;software engineering;software testing	SE	-64.68473043347507	27.767862264385442	145958
767e711f8207ba08a3d7d941c5c769218da27721	evolution of software quality models in context of the standard iso 25010		Evolutionary analysis of software (SW) quality models (QM) over the past forty years, from one of the first software QM by McCall to the model presented in the standard ISO 25010 is performed. 9 models were chosen for the analysis and divided into sets of basic and corporate QMs according to the completeness, detailing and significance. The choice of basic models McCall (1977), IEEE 1219 (1993), ISO9126-1 (2001), ISO 25010 (2010) is grounded. QM structure is described by hierarchy whose elements are sets of characteris- tics (subcharacteristics) and relations of subordination between them. To assess the complexity and completeness of SW QM and to compare them with the lat- est ISO 25010 model special particular and general metrics are introduced. Analytic dependence of the growth of model complexity represented by a linear function is obtained. Analysis of some characteristics evolution (operational suitability, effectiveness, reliability, usability, safety, etc) is performed.	software quality	Oleksandr Gordieiev;Vyacheslav S. Kharchenko;Nataliia Fominykh;Vladimir V. Sklyar	2014		10.1007/978-3-319-07013-1_21	computer science;systems engineering;algorithm	SE	-63.07989868559462	28.36136707595708	146006
cc05785b29d80e12c39a702a6debf5747ec2b2a5	tool support for the effective distribution of agile practice (extended abstract)	agile methods;tool support;software engineering;software development;software engineering practices	Agile methods are quickly gaining notoriety amongst software engineers. Having been developed over the past decade, they now present a mature, lightweight alternative to the “classic” approaches to software engineering. Although agile methods have solved some of the problems of established software engineering practice, they have created some problems of their own. Most importantly, we can infer a, potentially problematic, requirement of collocation. The usefulness of the agile methods is restricted by this requirement of collocation and by the requirement of small development teams. If these requirements can be loosened then it would be possible to apply agile methods to a larger arena of software development. This research intends to extend the usefulness of agile methods by defining a new paradigm for software engineering practice, the “Liberal” paradigm and providing tool support for processes within this paradigm.	agile software development;collocation;programming paradigm;requirement;software engineer;software engineering	Paul J. Adams;Cornelia Boldyreff	2005		10.1007/11499053_67	feature-driven development;requirements analysis;personal software process;verification and validation;software engineering process group;agile unified process;extreme programming practices;agile usability engineering;systems engineering;engineering;social software engineering;software development;requirement;software engineering;software construction;agile software development;management science;software walkthrough;software documentation;empirical process;lean software development;software development process;software requirements	SE	-65.11234968930697	23.86134433362757	146090
94d121e185ddad693e91022b7282b1d1ac25410d	reducing complexity using an interaction room: an experience report	heterogeneous teams;software evolution;complexity reduction;cognitive load of methods;interaction room	"""Large-scale information system evolution projects often place high demands on both business and technical stakeholders' cognitive and communication skills. Especially if the need for evolution is not confined to a particular feature, but affects the whole value chain, finding dependencies and interrelationships between processes and components is challenging as it requires cross-departmental understanding. These issues can be even more challenging for management stakeholders who need to make high-level and far-reaching decisions on implementation strategies despite not being deeply involved in the technical details. One of the main problems in such projects is that the stakeholders who have expert knowledge typically have only little methodical experience, while the method experts lack the business experience. In this paper, we report on experiences and lessons from a large systems evolution project in a German insurance company, where we applied a new approach -- the so-called """"Interaction Room"""" -- to improve stakeholders' understanding of the project's risks and dependencies in a pragmatic way, without overwhelming them with a heavyweight analysis method."""	business process;experience;high- and low-level;information system;mission critical;problem domain;requirement;ripple effect;value (ethics)	Simon Grapenthin;Matthias Book;Volker Gruhn;Christian Schneider;Kai Völker	2013		10.1145/2507065.2507087	human–computer interaction;computer science;knowledge management;software evolution;software engineering;management science;management;reduction	SE	-71.18134509178114	20.280892137739823	146293
13577801e69d868ab6e08542bd8bcf58c5d503ab	monitoring our requirements	project management;formal specification;satisfaction arguments requirements compliance;satisfaction arguments;contracts;systems engineering and theory;project design project management contracts systems engineering and theory;requirements;conformance testing;program testing;compliance;software based systems test compliance system requirements software monitor specification requirements compliance;project design;program testing conformance testing formal specification	Most people think of requirements as things to manipulate at the start of a project. Others, more enlightened, recognize that requirements also have a role toward the end of projects to test compliance. But few people have recognized an active role for requirements during their system's use - to monitor whether the system continues to comply with its requirements during its lifetime. This important new role for requirements - which necessitates the specification of software monitors to test for requirements compliance - has implications for how such requirements are structured and exposed, especially for the increasing numbers of software-based systems that use monitors to adapt to their environments.	algorithm;requirement	Neil A. M. Maiden	2013	IEEE Software	10.1109/MS.2013.10	project management;reliability engineering;requirements analysis;software requirements specification;requirements management;market requirements document;requirement prioritization;business requirements;software project management;computer science;systems engineering;engineering;requirement;software engineering;needs analysis;system requirements specification;requirements elicitation;conformance testing;formal specification;functional specification;requirements engineering;non-functional testing;management;system testing;non-functional requirement;software requirements;requirements traceability	SE	-71.09256795299476	27.042021694938686	146347
eea1e38d0ca5ab8c09cd6e8be915623d3dfadf08	growing bloom: design of a visualization of project evolution	data gathering;large scale;visualization;software evolution;software development;collaborative software development;open source software;open source	In this paper we describe the design behind the Bloom Diagram, a tool to visualize the evolution of individual participants' code and comment contributions to open source software projects. The design blends techniques such as concentric pie charts, animation, motion trails, and social proxies to produce a compact presentation of the large scale dynamics around software development. We also briefly present some preliminary findings using data gathered from SourceForge, a popular open source project hosting site, and discuss future directions for this work.	chart;diagram;open-source software;shared web hosting service;software development;sourceforge	Bernard Kerr;Li-Te Cheng;Timothy Sweeney	2006		10.1145/1125451.1125476	software visualization;simulation;visualization;human–computer interaction;software project management;computer science;package development process;software evolution;software design;social software engineering;software framework;software development;software design description;operating system;software construction;database;software walkthrough;software analytics;software deployment;world wide web;software development process;software quality;data collection;software peer review	HCI	-64.18577238649718	23.287593716475254	146582
62b698027d8f87c8b0b4776f0ceb684073fed972	evaluation of the improved xp software development model		M. R. J. Qureshi Dept. of Computer Science, COMSATS Institute of Information Technology Lahore Pakistan Defence Road, Off Raiwind Road Lahore Pakistan rjamil@ciitlahore.edu.pk Ph # (92-42-5431602) Cell # (03334492203) Abstract: The concept of agile process models has attained great popularity in software (SW) development community in last few years. Agile models promote fast development. Fast development has certain drawbacks, such as weak documentation and performance for medium and large development projects. Fast development also promotes use of agile process models in small-scale projects. This paper modifies and evaluates Extreme Programming (XP) process model and proposes a novel process model based on these modifications.	agile software development;computer science;documentation;extreme programming;process modeling;requirement;shattered world;software development process;software project management	M. Rizwan Jameel Qureshi	2009	CoRR		simulation;agile unified process;extreme programming practices;agile usability engineering;systems engineering;engineering;iterative and incremental development;agile software development;empirical process;lean software development;goal-driven software development process;software development process	SE	-69.45372312408051	18.34667991736132	146858
c49860b801738f1f98ffb60fc694eaf608f75343	cognitive influences in prioritizing software requirements	software requirements	In software development, the elicitation process and particularly the acquisition of software requirements are critical success factors. Elicitation is about learning the needs of users, and communicating those needs to system builders. Prioritizing requirements includes negotiation as an important issue, which becomes extremely difficult, as clients often do not know exactly what they need. To overcome this situation, aiming at improving stakeholder’s negotiation, we propose reducing the gap of misunderstanding between them by the use of cognitive science. Particularly, we suggest using cognitive styles to characterize people from the way their process information. In this paper, we introduce a case study showing that cognitive profiles may affect requirement understanding and prioritization. Our controlled experiment shows that considering cognitive profiles when performing elicitation might increase stakeholders’ satisfaction and prioritization	cognitive science;orientation (graph theory);requirement;software build;software development;software requirements	Nadina Martinez Carod;Alejandra Cechich	2010			requirements analysis;software requirements specification;verification and validation;requirements management;requirement prioritization;business requirements;software project management;computer science;software design;social software engineering;software development;requirement;software engineering;software construction;requirements engineering;non-functional testing;software deployment;software requirements;software peer review	HCI	-70.30772529409678	23.22461643949873	146996
932538d5085aa6db0d0d4000a3191f6b7792e4c8	the collaboratory for the study of earthquake predictability perspective on computational earthquake science	csep testing center;different testing region;hypothesis testing;rigorous testing;testing center concept;csep fosters collaboration;computational earthquake science;earthquake forecast hypothesis;earthquake forecast model;earthquake research;earthquake predictability perspective	The Collaboratory for the Study of Earthquake Predictability (CSEP) aims to advance earthquake research by rigorous testing of earthquake forecast hypotheses. As in other disciplines, such hypothesis testing requires carefully designed experiments that meet certain requirements: they should be reproducible, fully transparent, and conducted within a controlled environment. CSEP has begun building infrastructure for conducting such rigorous earthquake forecasting experiments. Because past earthquake prediction experiments often have been controversial, CSEP testing centers—the secure, controlled computational environments within which experiments are conducted—have been designed to address particular issues related to transparency and exact reproducibility. Moreover, CSEP fosters collaboration among scientists developing earthquake forecast models, and the testing center concept allows multiple concurrent predictability experiments. In this paper, we share our perspective on computational earthquake science by presenting the design principles, organizational structure, and implementation details of CSEP testing centers. We describe ongoing forecast experiments in different testing regions and some of the	experiment;requirement	J. Douglas Zechar;Danijel Schorlemmer;Maria Liukis;John Yu;Fabian Euchner;Philip Maechling;Thomas H. Jordan	2010	Concurrency and Computation: Practice and Experience	10.1002/cpe.1519	organizational structure;statistical hypothesis testing;simulation;computer science;reproducibility;transparency;operations research;earthquake prediction;statistics	SE	-74.96280970916366	28.124832339426302	147122
2bbbee329a0b0cd726a528cd5895bd1ccbca7c68	assessing project success using subjective evaluation factors	software engineering;project success;number of factors;project assessment;subjective measures;programvaruteknik;project evaluation;subjective evaluation	Project evaluation is essential to understand and assess the key aspects of a project that make it either a success or failure. The latter is influenced by a large number of factors, and many times it is hard to measure them objectively. This paper addresses this by introducing a new method for identifying and assessing key project characteristics, which are crucial for a project's success. The method consists of a number of well-defined steps, which are described in detail. The method is applied to two case studies from different application domains and continents. It is concluded that patterns are possible to detect from the data sets. Further, the analysis of the two data sets shows that the proposed method using subjective factors is useful, since it provides an increased understanding, insight and assessment of which project factors might affect project success.	application domain;inter-rater reliability;no silver bullet;reliability engineering;software project management;subject (philosophy)	Claes Wohlin;Anneliese Amschler Andrews	2001	Software Quality Journal	10.1023/A:1016673203332	reliability engineering;program evaluation;systems engineering;engineering;estimation;software engineering;management science;project management triangle	SE	-70.56905111952273	22.459347608201675	147316
b4a5b3ba3c8210abcf01ac680d46e3ea0757ee2d	classes of distributed agile development problems	trust;time zone;annan data och informationsvetenskap;electronic mail;customer collaboration;software prototyping;distributed processing;training;collaboration;computer and information science;distributed agile development;companies;agile development;time zones culture communication trust customer availability;natural sciences;companies documentation collaboration electronic mail productivity context training;time zones;culture;software prototyping distributed processing;productivity;time zone distributed agile development customer collaboration technical issue;communication;context;customer availability;documentation;technical issue;other computer and information science	Little is known about problems encountered in distributed Agile development environments. There have been some case studies reporting on them. However, these studies have been mainly limited to the scope and context of only one or a few companies. As a result, we do not possess an overall picture of what types of problems and challenges the companies may encounter in distributed Agile environments. In this paper, we analyze twelve case studies from the existing literature, identify thirteen problems reported in them and their solutions, and we group the problems into six classes: Culture, Time Zone, Communication, Customer Collaboration, Trust, Training and Technical Issues.	agile software development	Mira Kajko-Mattsson;Gayane Azizyan;Miganoush Katrin Magarian	2010	2010 Agile Conference	10.1109/AGILE.2010.14	systems engineering;engineering;knowledge management;software engineering	SE	-67.5371629634409	20.857482341813217	147386
947839dbbe8ae96a75ecadb71e44b5ae76464509	high assurance software testing in business and dod	empirical bayesian stopping rule;software testing;project management;information science;application software;stopping rule;bayes methods;department of defense;bayesian methods;earned value management paradigm;bayes methods program testing military computing;software testing us department of defense information science software development management programming bayesian methods project management life testing application software scanning probe microscopy;program testing;life testing;us department of defense;business;software development;test methods;department of defense high assurance software testing business software development life cycle earned value management paradigm empirical bayesian stopping rule;software development life cycle;scanning probe microscopy;programming;earned value management;high assurance software testing;software development management;military computing	This paper argues that software testing can be less thorough yet more efficient if applied in a well-managed, empirical manner across the entire Software Development Life Cycle (SDLC). To ensure success, testing must be planned and executed within an Earned Value Management (EVM) paradigm. A specific example of empirical software testing is given: the Empirical Bayesian Stopping Rule (EBSR). The Stopping Rule is applied to an actual Department of Defense (DoD) software development to show potential gains with respect to archaic testing methods that were used. The result is that a considerable percentage of the particular testing effort could have been saved under usual circumstances, had the testing been planned and executed under EVM with the Empirical Bayesian Stopping Rule algorithm.	algorithm;programming paradigm;software development process;software testing;synchronous data link control	Coskun Bayrak;Mehmet Sahinoglu;Timothy Cummings	2000	Transactions of the SDPS	10.1109/HASE.2000.895463	non-regression testing;test strategy;project management;reliability engineering;programming;black-box testing;application software;scanning probe microscopy;earned value management;software performance testing;white-box testing;manual testing;system integration testing;information science;bayesian probability;systems engineering;engineering;acceptance testing;software reliability testing;software development;software engineering;functional testing;risk-based testing;software testing;systems development life cycle;test method;management;system testing;computer security;stress testing;software quality analyst	SE	-65.19557256927652	28.756621081971307	147408
d7c61551f74bad657f927b328426ea37e7540235	supporting software development as knowledge-intensive and collaborative activity	knowledge collaboration;distributed cognition;software development support	Starting from the belief that software development is a human activity, this paper tries to conceptualize software development as a knowledge-intensive design and distributed cognitive activity. This conceptualization leads to the argument that providing support for software developers to engage in knowledge collaboration with external knowledge repositories and peers is essential for software development environments. Technical and social challenges in providing such support are identified, and an illustrative system support that we have been developing is briefly described.	agile software development;conceptualization (information science);information repository;software developer	Yunwen Ye	2006		10.1145/1137661.1137666	personal software process;software engineering process group;crowdsourcing software development;human–computer interaction;computer science;systems engineering;knowledge management;social software engineering;software framework;software development;software walkthrough;software analytics;resource-oriented architecture;software development process;software peer review	HCI	-64.34326735664209	18.73680546570802	147607
a01caa3e664d9d0e354eecdecbb58554c0f8a13e	understanding the causes of architecture changes using oss mailing lists	architecture change;communication;mailing list;cause of change;open source software	The causes of architecture changes can tell about why architecture changes, and this knowledge can be captured to prevent architecture knowledge vaporization and architecture degeneration. But the causes are not always known, especially in open source software (OSS) development. This makes it very hard to understand the underlying reasons for the architecture changes and design appropriate modifications. Architecture information is communicated in development mailing lists of OSS projects. To explore the possibility of identifying and understanding the causes of architecture changes, we conducted an empirical study to analyze architecture information (i.e., architectural threads) communicated in the development mailing lists of two popular OSS projects: Hibernate and ArgoUML, verified architecture changes with source code, and identified the causes of architecture changes from the communicated architecture information. The main findings of this study are: (1) architecture information communicated in OSS mailing lists does lead to architecture changes in code; (2) the major cause for architecture changes in both Hibernate and ArgoUML is preventative changes, and the causes of architecture changes are further classified to functional requirement, external quality requirement, and internal quality requirement using the coding techniques of grounded theory; (3) more than 45% of architecture changes in both projects happened before the first stable version was released.		Wei Ding;Peng Liang;Antony Tang;Hans van Vliet	2015	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194015400367	website architecture;database-centric architecture;systems engineering;engineering;software engineering;service;world wide web	SE	-66.73629449871639	29.5757535596089	147648
4a2d16e479dff002f77de065b4c0b304bf63e185	invited talk: asm formalware in the software engineering cycle	abstract state machine;software engineering;product cycle;error correction	Software is becoming more and more complex. As you move down the product cycle - from market requirements to product definition, specification, design, implementation, documentation, testing, and support -- the cost of error correction escalates dramatically. We aim to improve on the various stages by means of high-level yet executable models. This is based on the abstract state machine approach http://www.eecs.umich.edu/gasm/.	software engineering	Yuri Gurevich	2000		10.1007/3-540-45499-3_15	real-time computing;error detection and correction;computer science;product lifecycle;product engineering;abstract state machines	SE	-63.06139413176469	25.71198811840363	147926
1b2fde7641bee3a7a5ca6f8d67445966e6bb67f7	lmes: a localized multi-estimator model to estimate software development effort	software project;localization;classification;estimator;effort estimation	Accurate estimation of software development effort is strongly associated with the success or failure of software projects. The clear lack of convincing accuracy and flexibility in this area has attracted the attention of researchers over the past few years. Despite improvements achieved in effort estimating, there is no strong agreement as to which individual model is the best. Recent studies have found that an accurate estimation of development effort in software projects is unreachable in global space, meaning that proposing a high performance estimation model for use in different types of software projects is likely impossible. In this paper, a localized multi-estimator model, called LMES, is proposed in which software projects are classified based on underlying attributes. Different clusters of projects are then locally investigated so that the most accurate estimators are selected for each cluster. Unlike prior models, LMES does not rely on only one individual estimator in a cluster of projects. Rather, an exhaustive investigation is conducted to find the best combination of estimators to assign to each cluster. The investigation domain includes 10 estimators combined using four combination methods, which results in 4017 different combinations. ISBSG, Maxwell and COCOMO datasets are utilized for evaluation purposes, which include a total of 573 real software projects. The promising results show that the estimate accuracy is improved through localization of estimation process and allocation of appropriate estimators. Besides increased accuracy, the significant contribution of LMES is its adaptability and flexibility to deal with the complexity and uncertainty that exist in the field of software development	4000 series;cocomo;internationalization and localization;maxwell (microarchitecture);software development;unreachable memory;xojo	Vahid Khatibi Bardsiri;Dayang N. A. Jawawi;Amid Khatibi Bardsiri;Elham Khatibi	2013	Eng. Appl. of AI	10.1016/j.engappai.2013.08.005	estimator;internationalization and localization;software sizing;biological classification;computer science;analysis effort method;data mining;software metric;statistics	SE	-66.84134462966293	31.016731355453256	148398
64acfb635d1ccd11678a5208ff14dd94522e906d	gamification at work: designing engaging business software	user experience design;engagement;gamification of business software;enterprise software;business software;motivation;design;enterprise gamification;gamification;ux	"""Gamification is a buzz word in business these days. In its November 2012 press release, Gartner predicts that """"by 2015, 40% of Global 1000 organizations will use gamification as the primary mechanism to transform business operations"""". In the same report, they also predict that """"by 2014, 80% of current gamified applications will fail to meet business objectives, primarily due to poor design"""".#R##N##R##N#What is gamification? Does it belong in the workplace? Are there design best practices that can increase the chance of success of enterprise gamification efforts?#R##N##R##N#Janaki Kumar answers these questions and more in this paper Gamification @ Work. She cautions against taking a """"chocolate covered broccoli"""" approach of simply adding points and badges to business applications and calling them gamified. She outlines a methodology called Player Centered Design which is a practical guide for user experience designers, product managers and developers to incorporate the principles of gamification into their software."""	business software;gamification	Janaki Kumar	2013		10.1007/978-3-642-39241-2_58	simulation;systems engineering;engineering;knowledge management	HCI	-68.5374002147397	24.63623260483654	148573
f57d78bea0ddbd05ce3c84913488caf576247d79	combining empirical results in software engineering	empirical study;vote counting;computacion informatica;empirical software engineering;grupo de excelencia;meta analysis;software engineering;ciencias basicas y experimentales;empirical studies;correlation coefficient	In this paper we investigate the techniques used in medical research to combine results from independent empirical studies of a particular phenomenon: meta-analysis and vote-counting.#R##N##R##N#We use an example to illustrate the benefits and limitations of each technique and to indicate the criteria that should be used to guide your choice of technique. Meta-analysis is appropriate for homogeneous studies when raw data or quantitative summary information, e.g. correlation coefficient, are available. It can also be used for heterogeneous studies where the cause of the heterogeneity is due to well-understood partitions in the subject population. In other circumstances, meta-analysis is usually invalid. Although intuitively appealing, vote-counting has a number of serious limitations and should usually be avoided.#R##N##R##N#We suggest that combining study results is unlikely to solve all the problems encountered in empirical software engineering studies, but some of the infrastructure and controls used by medical researchers to improve the quality of their empirical studies would be useful in the field of software engineering.		Lesley Pickard;Barbara A. Kitchenham;Peter Jones	1998	Information & Software Technology	10.1016/S0950-5849(98)00101-3	computer science;engineering;data mining;empirical research	SE	-67.97998377046245	31.040806910456837	148642
c6fa95f4ca90ed696f682c103c86056c820c952b	teaching team software process in graduate courses to increase productivity and improve software quality	team software process;software;productivity training team software process estimations;tspi teaching team software process teaching graduate courses software quality;teaching computer science education continuing education software quality;training;defect density;continuing education;accuracy;computer science education;estimation;estimations;upm;productivity;production cost;graduate courses;programming;software training estimation productivity education accuracy programming;team software process teaching;software quality;teaching;tspi teaching	This paper presents a case study that describes TSPi teaching (introduction to the team software process) to 4th year students, grouped by teams, at the Computer Science School, Polytechnic University of Madrid (UPM). The achievements of the teams, due to training and the use of TSPi, were analyzed and discussed. This paper briefly discusses the approach to the teaching and some of the issues that were identified. The teams collected data on the projects developed. They reviewed the schedule and quality status weekly. The metrics selected to analyze the impact on the students were: size, effort, productivity, costs and defects density. These metrics were chosen to analyze teams 'performance evolution through project development. This paper also presents a study related to the evolution of estimation, quality and productivity improvements these teams obtained. This study will prove that training in TSPi has a positive impact on getting better estimations, reducing costs, improving productivity, and decreasing defect density. Finally, the teams 'performance are analyzed.	computer science;software bug;software development process;software quality;team software process	Sussy Bayona Oré;José Antonio Calvo-Manzano;Gonzalo Cuevas Agustín;Tomás San Feliu Gilabert	2008	2008 32nd Annual IEEE International Computer Software and Applications Conference	10.1109/COMPSAC.2008.135	engineering management;education;programming;estimation;team software process;productivity;systems engineering;engineering;knowledge management;software engineering;accuracy and precision;software quality;statistics	SE	-66.27124254825178	27.462411465483147	148699
51ed0240b55c3795e374bdaad3c5d4580ebccaf6	who tested my software? testing as an organizationally cross-cutting activity	values;industrial case study;defect data analysis;defect fix rate;testing;datavetenskap datalogi;interviews;testers;roles;defect reporters	There is a recognized disconnect between testing research and industry practice, and more studies are needed on understanding how testing is conducted in real-world circumstances instead of demonstrating the superiority of specific methods. Recent literature indicates that testing is a cross-cutting activity that involves various organizational roles rather than the sole involvement of specialized testers. This research empirically investigates how testing involves employees in varying organizational roles in software product companies. We studied the organization and values of testing using an exploratory case study methodology through interviews, defect database analysis, workshops, analyses of documentation, and informal communications at three software product companies. We analyzed which employee groups test software in the case companies, and how many defects they find. Two companies organized testing as a team effort, and one company had a specialized testing group because of its different development model. We found evidence that testing was not an action conducted only by testing specialists. Testing by individuals with customer contact and domain expertise was an important validation method. We discovered that defects found by developers had the highest fix rates while those revealed by specialized testers had the lowest. The defect importance was susceptible to organizational competition of resources (i.e., overvaluing defects of reporter’s own products or projects). We conclude that it is important to understand the diversity of individuals participating in software testing and the relevance of validation from the end users’ viewpoint. Future research is required to evaluate testing approaches for diverse organizational roles. Finally, to improve defect information, we suggest increasing automation in defect data collection.	documentation;domain-specific language;relevance;software bug;software development;software quality assurance;software testing;user interface	Mika Viking Mäntylä;Juha Itkonen;Joonas Iivonen	2011	Software Quality Journal	10.1007/s11219-011-9157-4	test strategy;simulation;interview;systems engineering;engineering;values;operations management;role;software engineering;software testing;management	SE	-69.5579442011057	23.011058757791346	148736
a14f69985e19456681bc874310e7166528637bed	feature-oriented software product lines	information systems;software engineering	Inevitably, reading is one of the requirements to be undergone. To improve the performance and quality, someone needs to have something new every day. It will suggest you to have more inspirations, then. However, the needs of inspirations will make you searching for some sources. Even from the other people experience, internet, and many books. Books and internet are the recommended media to help you improving your quality and performance.	software product line	Sven Apel;Don S. Batory;Christian Kästner;Gunter Saake	2013		10.1007/978-3-642-37521-7	personal software process;verification and validation;computing;software sizing;information engineering;software verification;systems engineering;package development process;social software engineering;component-based software engineering;software development;software engineering;software construction;software walkthrough;software analytics;resource-oriented architecture;software measurement;software deployment;software requirements;software system	Networks	-64.5009021651265	25.803239889388824	148850
22e8b37ea3d64e4fead4a244a70725576b188782	using the it capability maturity framework to improve it capability and value creation: an intel it case study	competitive intelligence capability maturity model;planning organizations context standards organizations electronic mail navigation;electronic mail;performance indicator;standards organizations;design science information technology it cmf business value design pattern it capability maturity framework intel corporation;information technology;it cmf;navigation;capability maturity model;design pattern;it capability maturity framework;competitive intelligence;intel corporation;planning;value creation;business intelligence;organizations;business value;context;design science;business value improvement it capability maturity framework value creation intel it case study it organization it cmf capability improvement measurement business intelligence information	This paper gives a short overview of the IT Capability Maturity Framework (IT-CMF) and describes how it was used between 2007-2009 to help Intel IT navigate and track progress on IT capability improvement and value contribution from IT, whilst negotiating a strategic transition for the IT organization which involved significant downsizing and budget reduction. The case study illustrates how the IT-CMF was used to measure capability improvements, provide business intelligence information and prioritized improvement recommendations. The paper also discusses how practices contained within the IT-CMF helped articulate a business value improvement whilst more traditional metrics of IT performance indicated a degradation in performance.	capability maturity model;elegant degradation;list of content management frameworks;while	Martin Curley;Jim Kenneally	2011	2011 IEEE 15th International Enterprise Distributed Object Computing Conference	10.1109/EDOC.2011.32	planning;navigation;competitive intelligence;computer science;systems engineering;organization;engineering;business value;performance indicator;software engineering;design pattern;business intelligence;management;information technology;computer security;capability maturity model;capability immaturity model	Visualization	-69.69615418304528	19.465725918944788	148904
7d1fc49facf3cd3aaa83e3c90f3ffb8c2275fc53	a roadmap and plan of action for community-supported empirical evaluation in computer architecture	repository;computer architecture;repeatability	A framework of open interoperable simulators for computer architecture is long overdue. Today there are many separate, uncoordinated efforts to develop simulation and modeling artifacts (tools) for computer architecture research. The artifacts are used to empirically evaluate new computer architecture innovations and compare them with the state of the art. The artifacts are usually developed by individual groups, often for a specific purpose, and may not be publicly released. Consequently, it is difficult to leverage investment in artifact development and to repeat or reproduce experiments. In this position paper, we present recommendations and a roadmap for sharing and building open-source, interoperable simulation and modeling artifacts. The recommendations are the outcome of a community workshop involving industry, government and academia to determine how to coordinate effort, share tools and improve methodology.	computer architecture;experiment;interoperability;open-source software;simulation	Bruce R. Childers;Alex K. Jones;Daniel Mossé	2015	Operating Systems Review	10.1145/2723872.2723886	repeatability;simulation;computer science;data mining;computer security	Arch	-67.87167499478156	19.37061299543306	148909
48be6d3721cb2b8658fd1b55ca092962f5756728	estimating the impact of enterprise resource planning project management decisions on post-implementation maintenance costs: a case study using simulation modelling	cost estimation model;project management;policy analysis;software maintenance;system dynamics;cost saving;enterprise systems;project manager;total cost of ownership;maintenance cost;erp system;model evaluation;erp;enterprise resource planning;dynamic simulation;enterprise system;erp implementation;cost estimation;simulation model;simulation modelling;model simulation	Organisations often make implementation decisions with little consideration for the maintenance phase of an enterprise resource planning (ERP) system, resulting in significant recurring maintenance costs. Poor cost estimations are likely related to the lack of an appropriate framework for enterprise-wide pre-packaged software maintenance, which requires an ongoing relationship with the software vendor (Markus, M.L., Tanis, C., and Fenema, P.C., 2000. Multisite ERP implementation. CACM, 43 (4), 42-46). The end result is that critical project decisions are made with little empirical data, resulting in substantial long-term cost impacts. The product of this research is a formal dynamic simulation model that enables theory testing, scenario exploration and policy analysis. The simulation model ERPMAINT1 was developed by combining and extending existing frameworks in several research domains, and by incorporating quantitative and qualitative case study data. The ERPMAINT1 model evaluates tradeoffs between different ERP project management decisions and their impact on post-implementation total cost of ownership (TCO). Through model simulations a variety of dynamic insights were revealed that could assist ERP project managers. Major findings from the simulation show that upfront investments in mentoring and system exposure translate to long-term cost savings. The findings also indicate that in addition to customisations, add-ons have a significant impact on TCO.	enterprise resource planning;simulation	Meg Fryling	2010	Enterprise IS	10.1080/17517575.2010.519785	project management;dynamic simulation;enterprise system;simulation;computer science;systems engineering;policy analysis;operations management;database	AI	-70.72674203194877	20.343992850616488	148982
a556e0417d38c326b4d9b5f430adac933d5b5f78	an early software effort estimation method based on use cases and conceptual classes	use cases;effort estimation;use case point;conceptual classes	It is an important issue in the software industry to predict how much effort will be required for a software project as early as possible. Software size is one of the commonly used attributes in effort estimation. In this paper, we propose an early software size and effort estimation method based on conceptual model of the problem domain. Our method utilizes the noteworthy domain concepts identified mainly from the use cases written in the requirements phase of the software development lifecycle. In order to develop the model and evaluate its prediction quality, the use cases written and the effort data collected for 14 industrial software development projects of a CMMI level 3 certified defense industry company have been used. Evaluation results reveal a high correlation between the number of conceptual classes identified (i.e., domain objects) during the requirements analysis, the number of classes constituting the resulting software and the actual effort spent. Moreover, we have used the use case point (UCP) method to estimate the effort needed for each project and compared the results of UCP analysis with the results obtained with our method. The comparisons have shown that, for the projects considered, our method gives a better effort estimation compared to the effort estimated by using the UCP method.	business object;capability maturity model integration;cost estimation in software engineering;domain-driven design;emi (protocol);estimation theory;newton's method;problem domain;requirement;requirements analysis;software development effort estimation;software development process;software industry;software project management;software sizing	Tülin Erçelebi Ayyildiz;Altan Koçyigit	2014	JSW	10.4304/jsw.9.8.2169-2173	use case;putnam model;verification and validation;simulation;software sizing;analysis effort method;software construction;use case points;software metric	SE	-65.18575753525072	29.850535284701348	149005
23e80ce89318c6f764dfd625e65b181366c5e0ad	startup methodology for production flow simulation projects assessing environmental sustainability	automobile industry;environmental factors;product life cycle management;production management;sustainable development;environmental impact reduction;automotive industry;environmental impact assessments;environmental sustainability;production flow simulation projects;project startup phase	Environmental impact assessments for companies and products are important to increase sales and reduce environmental impact. To support improvements and detailed analyses, researchers have extended the use of simulation of production flows to include sustainability performance indicators. The research cases performed until recently lack standardized methodology and thus have comparability issues and an increase number of common faults. By using a common methodology and gathering best practice, future cases can gain a lot. Especially noted by the authors is that the project startup phase is critical for success. This paper proposes a methodology to support the startup phases of simulation projects with sustainability aspects in production flows. The methodology is developed and applied in an automotive industry study presented in this paper. Using a rigid project startup, such as the proposed methodology, reduces iterations during modeling and data collection and decreases time spent on modeling.	best practice;iteration;requirement;simulation	Tobias Dettmann;Clas Andersson;Jon Andersson;Anders Skoogh;Björn Johansson;Per-Olof Forsbom	2013	2013 Winter Simulations Conference (WSC)		simulation;computer science;systems engineering;engineering;discrete event simulation;sustainable development;product life-cycle management	HPC	-69.53230795931226	19.180280101330474	149011
e8a92c1d1c0b1452b69b12ffd80bcfbc665eabc0	a scrum-based process to distributed projects in multidisciplinary teams: a case study		It is a usual practice for software companies to develop their products using Distributed Software Development (DSD). Moreover, many times the software companies work with multidisciplinary teams to satisfy their customer demands. These multidisciplinary teams are composed of IT professionals and professionals from multiple areas not related to software development or IT. There are several problems associated with communication and information dissemination that severely compromise the software product development. This work presents a case study of a company that uses DSD. The Scrum-based process shown in this work promotes a communication improvement between the client company functional areas.		Leonardo Sanches dos Santos;Alexandre L'Erário;Tiago Pagotto;Joao Ricardo Moreno Camilo;Fabricio Sousa Oliveira;José Augusto Fabri	2018	2018 IEEE/ACM 13th International Conference on Global Software Engineering (ICGSE)	10.1145/3196369.3196380	engineering;new product development;systems engineering;software development;multidisciplinary approach;software;compromise;information dissemination;scrum	SE	-66.85238444549546	20.732961360551293	149110
916f815ed53b5f6bf2a70bebf26f28faa9ede9f9	evaluating the xp customer model and design by contract	dp industry;contracts;customer satisfaction;formal verification;interactive programming;object-oriented languages;program testing;project management;software development management;software prototyping;software quality;gaudi software factory;xp customer model;customer satisfaction;design by contract;extreme programming;formal methods;object-oriented languages;onsite customer;software development;software quality;software testing	We describe one of the series of experiments with extreme programming, carried out as a summer project. The focus in this experiment was to try out the XP customer model and design by contract. The experiment indicates that the extreme programming emphasis on having an onsite customer available during the project improves the communication between customers and the programming team, and markedly decreases the number of false features and feature misses. It also indicates that the systematic use of design by contract leads to a low post-release defect rate for the software system built.	customer relationship management;design by contract;experience;experiment;extreme programming;formal methods;programmer;programming team;software bug;software development;software system;type system	Ralph-Johan Back;Piia Hirkman;Luka Milovanov	2004	Proceedings. 30th Euromicro Conference, 2004.	10.1109/EURMIC.2004.1333386	reliability engineering;computer science;systems engineering;software engineering	SE	-64.81876758415842	28.114931947365687	149117
36c7d650726916ea4cf070577437afee0c4ccb9e	a heuristic approach for supporting innovation in requirements engineering		The first activity that most software development projects take is to elicit and document the project’s requirements. Requirement elicitation is one of the most critical activities in the software development process. The ability to do it well is crucial to the project’s success. The experience has shown that poor requirements frequently lead to rework, cost overruns and even project failure. Although several tools, processes, models, methods and frameworks have been developed to help with requirement elicitation, there is much less support for innovation through Requirement Engineering in software product development process. In this paper, we describe an approach to design innovative software. Innovative softwares are products that differ of the existing products and that aggregate value for customers or end users.	aggregate data;heuristic;new product development;requirement;requirements engineering;rework (electronics);software development process	Ricardo André Cavalcante De Souza;Gilberto Amado de Azevedo Cysneiros Filho;Glauber Henrique Camelo Batista	2015			systems engineering;requirements engineering;management science;heuristic;computer science	SE	-68.85462824175575	21.885216991035975	149399
c24532ed383be93f4c10684468adcdb317943323	global software development for the enterprise	globalisation;information technology;software engineering;software engineering computer science education globalisation personnel;computer science education;programming global communication outsourcing product development application software embedded software globalization computer science information technology stress;personnel;it workforce global software development enterprise information technology;global software development;enterprise information technology;it workforce	In this position paper, we present certain observed characteristics of global software development for the enterprise, as well as trends in enterprise information technology needs for a global enterprise. We then identify IT workforce needs and the consequent curriculum	software development	Rajiv Ramnath	2006		10.1109/COMPSAC.2006.49	functional software architecture;personal software process;computing;enterprise system;global information system;enterprise systems engineering;enterprise software;crowdsourcing software development;computer science;systems engineering;engineering;knowledge management;social software engineering;software development;software engineering;globalization;software as a service;enterprise integration;information technology;software deployment;enterprise information security architecture;enterprise information system;enterprise life cycle;software peer review	OS	-67.59428472345631	21.327797242048373	149409
656f01e09bb5174a17aa79ff4d82be9188d522f3	user evaluations of virtually experiencing mount everest		In software development it is hard to know both whether the team has developed a product that fits the users’ needs, and is easy to use. One way of gathering feedback from users on both these issues is to conduct formal user testing, which has been rated by IT professionals as one of the best methods for user involvement in software development. In this paper, we present a formal evaluation of a running prototype for a virtual reality experience that was scheduled to be launched 3 months later. We conducted formal user testing with five users, and recorded the problems that the users experienced while they used the VR prototype. We also collected data concerning each user’s impressions of their experience immediately after it was complete. The results show that many serious problems were identified, and that the developers found several of them to be very useful. In some cases, the user testing was regarded as having been essential to discovering these problems.		Marta Kristín Lárusdóttir;David Thue;Hannes Högni Vilhjálmsson	2018		10.1007/978-3-030-05909-5_18	launched;world wide web;mount;agile software development;virtual reality;software development;computer science	NLP	-69.44744880743181	25.289667121158804	149453
be1cf228bd1df98530b107b28cda57ccea1b7358	proceedings on the 1st workshop on agile methods applied to development and certification of safety-critical software	agile software development;safety critical software	The first international workshop on agile methods applied to development and certification of safety-critical software (ASCS) was organized as part of the XP 2015 conference on May 25th 2015. The workshop gathered 17 experts from industry and academia to share recent industrial experience and research on applications of agile methods in the safety critical software domain. The workshop was organized as a series of talks and discussions to share experience and ideas. The workshop audience also provided guidelines for future research needed to advance the field.	agile software development	Geir Kjetil Hanssen;Thor Myklebust;Tor Stålhane	2016	ACM SIGSOFT Software Engineering Notes	10.1145/2894784.2894799	engineering ethics;personal software process;agile usability engineering;computer science;systems engineering;engineering;software development;software engineering;agile software development;empirical process;lean software development;software development process	SE	-65.98351278184481	24.070036486532135	149513
8ca6e2dd76dc2772805df136284e20216168eb39	using pure: variants across the product line lifecycle				Danilo Beuche	2016		10.1145/2934466.2962729		ML	-63.030345104772714	22.713464557908367	149565
224411b5e4028aac46241eae71b5b73d6c29d54f	towards a conceptual framework for open systems developments	wikipedia;iterative development;open innovation;conceptual framework;development governance;systems engineering management;collaborative community;open systems;open software;systems development	The systems engineering discipline has made great strides in developing a manageable approach to system development. This is predicated on thoroughly articulating the stakeholder requirements. However, in some engineering environments, requirements are changing faster than they can be captured and realized, making this ‘traditional’ form of systems engineering less tenable. An iterative system refinement approach, characterized by open systems developments, may be a more appropriate and timely response for fast-changing needs. The open systems development approach has been utilized in a number of domains including open source software, Wikipedia®, and open innovation in manufacturing. However, open systems development appears difficult to recreate successfully, and while domain tradecraft advice is often available, no engineering management methodology has emerged to improve the likelihood of success. The authors discuss the essential features of openness in these three domains and use them to propose a conceptual framework for the further exploration of the effect of governance in determining success in such open endeavors. It is the authors’ hope that further research to apply this conceptual framework to open source software projects may reveal some rudimentary elements of a management methodology for environments where requirements are highly uncertain, volatile, or ‘traditional’ systems engineering is otherwise sub-optimal. James A. Cowling School of Systems and Enterprises, Stevens Institute of Technology, USA Christopher V. Morgan PA Consulting Group, UK Robert Cloutier School of Systems and Enterprises, Stevens Institute of Technology, USA	iterative method;morgan;open innovation;open-source software;openness;refinement (computing);requirement;software development process;systems engineering;volatile memory;wikipedia	James A. Cowling;Christopher V. Morgan;Robert J. Cloutier	2014	IJITSA	10.4018/ijitsa.2014010103	system of systems;system of systems engineering;computer science;systems engineering;engineering;knowledge management;software engineering;iterative and incremental development;conceptual framework;brand;management science;systems development life cycle;open system;open innovation;management;systems design	SE	-66.91155545602415	19.066953991629585	149755
08a62c8b26179c554451b3822fd7c5afa3003434	towards an engineering process for developing accessible software in small software enterprises		This study presents the results of a web accessibility evaluation performed on a sample of six software products developed by small software enterprises of two countries. According to the International Standard Organization (ISO), an enterprise, organization, department or project with up to 25 people is considered small. All the products evaluated presented accessibility issues, mainly lack of HTML labels, alternative texts, and color contrast errors. These results showed there is a need in small software enterprises of an engineering development process that, taking into account their constraints of staff and budget, includes activities for improving the accessibility of their software. We present the current state of an ongoing work to define such process based on ISO/IEC 29110 that includes accessibility-related task in each of the following activities: initiation, analysis, design, construction, integration and test, and delivery.	exception handling;html;iso/iec 42010;interaction;web accessibility;web page;world wide web	Sandra Sanchez-Gordon;Mary-Luz Sánchez-Gordón;Sergio Luján-Mora	2016		10.5220/0005900702410246	personal software process;team software process;software engineering process group;systems engineering;package development process;social software engineering;software development;software engineering;software analytics;resource-oriented architecture;software deployment;software development process;software requirements;computer engineering	SE	-73.25167317891615	23.418751786183886	149837
fdf7968c50853d5dbd4a8be1a71a54cb37891f88	empirical software engineering, predictive models, and product lines		THIS ISSUE’S COLUMN reports on papers presented at the 11th Inter national Symposium on Empirical Software Engineering and Measurement (ESEM 17), 13th International Conference on Predictive Models and Data Analytics in Software Engineering (PROMISE 17), and 21st International Systems and Software Product Line Conference (SPLC 17). Feedback and suggestions are welcome. In addition, if you try or adopt any of the practices included in the column, please send Jeffrey Carver and the paper authors a note about your experiences.	experience;experimental software engineering;software product line	Jeffrey C. Carver;Eduardo Santana de Almeida;Rafael Capilla;Leandro L. Minku;Marco Torchiano;Alejandro Valdezate	2018	IEEE Software	10.1109/MS.2018.2141018	computer science;microservices;software engineering;systems engineering;domain engineering;empirical process (process control model);software development;agile software development;software product line;data analysis	SE	-65.94227186670528	24.075171501331532	149969
7b1e61cb1bbb9f76bf37069ccdc8f9295dd70e60	summary of the international conference on software and system processes (icssp 2016): [co-located with icse 2016]	project management;process description;control structures;tooling;process improvement;process simulation;software process	"""The International Conference on Software and Systems Process (ICSSP), continuing the success of Software Process Workshop (SPW), the Software Process Modeling and Simulation Workshop (ProSim) and the International Conference on Software Process (ICSP) conference series, has become the established premier event in the field of software and systems engineering processes. It provides a leading forum for the exchange of research outcomes and industrial best-practices in process development from software and systems disciplines. ICSSP 2016 was held in Austin, Texas, from 14-15 May 2016, co-located with the 38th International Conference on Software Engineering (ICSE). The theme of mICSSP 2016 was studying \Process(es) in Action"""" by recognizing that the AS-Planned and AS-Practiced processes can be quite different in many ways including their ows, their complexity and the evolving needs of stakeholders. Papers presented at ICSSP discussed this issue addressing different domains, providing concepts, evidence, and experiences."""	experience;icse;in-system programming;process modeling;simulation;software engineering;systems engineering	Marco Kuhrmann;Rory O'Connor;Dewayne E. Perry;David Raffo	2016	ACM SIGSOFT Software Engineering Notes	10.1145/2994205.2994215	project management;engineering management;personal software process;process simulation;software engineering process group;computer science;systems engineering;engineering;software design;social software engineering;software development;software engineering;software walkthrough;empirical process;management;software development process;software peer review	SE	-65.94495397913536	23.723224500555702	150225
ba60c335646f8002c9d5b6dca7d2f10e58ce2ea2	guest editorial for special section on success and failure in software engineering		Many papers investigate success and failure of software projects from diverse perspectives, leading to a myriad of antecedents, causes, correlates, factors and predictors of success and failure. This body of research has not yet produced a solid, empirically grounded body of evidence enabling actionable practices for increasing success and avoiding failure in software projects. The need for more evidence motivates this special issue, which includes four articles that contribute to our understanding of how software project success and failure relate to topics such as: requirements engineering, user satisfaction, start-up pivots and retrospective discussions. We moreover present a brief systematic review to both situate the accepted articles in existing literature and to explore enduring methodological and conceptual challenges in this area, including developing sound instruments for measuring success, representative sampling without population lists and creating both empirically sound and practically actionable taxonomies of success antecedents.	agile software development;computer user satisfaction;digital single-lens reflex camera;erp;inductive reasoning;information system;key (cryptography);open-source software;requirement;requirements engineering;sampling (signal processing);situated cognition;software engineering;software project management;systematic review;taxonomy (general)	Mika Viking Mäntylä;Magne Jørgensen;Paul Ralph;Hakan Erdogmus	2017	Empirical Software Engineering	10.1007/s10664-017-9505-5	systems engineering;project management;software;computer science;requirements engineering;population;knowledge management	SE	-71.36433308978539	21.95449089868318	150328
93fc02232ba6ccaf9038ec212f3ddf6609b7e972	validation of outsourcing teams work on agile projects of samsung r&d institute brazil		Samsung R&D Institute Brazil (SRBR) is one of Samsung's research centers in the world in which there is research focused on software areas. SRBR teams have worked in collaboration with Samsung headquarter and outsourcing partners for producing software that aggregates value on Samsung products. SRBR has different partners with different levels of skill, maturity and that work in different contexts. For this reason, managing software development projects and guaranteeing the quality of resulting products have been challenging for SRBR. This experience report describes the process created to improve partners' management and proposes methods for tracking and improving the methods applied for validating the work delivered by outsourcing partners in order to guarantee that it meets Samsung quality requirements.	acceptance testing;agile software development;capability maturity model;http 404;open-source software;outsourcing;pmr446;requirement;software project management	Gizelle S. Lemos;Marcia Cristina de C. Costa;Tatiana D. Borghi;Paula G. Povoas	2018		10.1145/3196369.3196392	engineering;acceptance testing;systems engineering;software;software development;outsourcing;agile software development	SE	-67.82372267908936	20.880175691456433	150589
9d1bee3bc0044ca20295cfefa14a99bd6a6047b0	planning for resilient lean programs	planning	What would happen if the key program stakeholders are included in the up-front planning? What if the stakeholders developed the schedule? What if they identified risks, opportunities, critical actions, and key assumptions, prior to program kickoff? What if all of this planning only took one to four days? Rockwell Collins has developed a method called Lean Enabled Accelerated Planning (LEAP) that directly addresses these items. In this paper, you will learn how LEAP is used to increase customer satisfaction, reduce program risk and increase program performance. This paper contains excerpts, experiences and benefits of over two hundred LEAP workshops conducted at Rockwell Collins over the past three years. It also shows how LEAP promotes the new Lean Enablers for Managing Engineering Programs. © 2014 The Authors. Published by Elsevier B.V. Selection and peer-review under responsibility of the University of Southern California.	allan m. collins;customer relationship management;experience;schedule (computer science)	Deborah A. Secor;Sebastian Lucae;Eric Rebentisch	2014		10.1016/j.procs.2014.03.018	simulation;artificial intelligence;data mining	SE	-69.73527021020413	24.120349734657385	151108
be6c62fb42278233588a1c4bc7b3c910adee5c71	obtaining value from the customization of packaged business software: a model and simulation	customization;package business software;erp;software development;modification	Businesses that purchase packaged application software – for example, an Enterprise Resource Planning system – must make choices about customization. Packaged software vendors, anecdotal evidence, and practitioner-oriented research all recommend that businesses should customize software as little as possible, and instead adapt their processes to meet the “best practices” of the software. However, businesses continue to outspend their budgets on implementing and maintaining customized software, often to a significant extent. This suggests that either these businesses are making poor decisions, or that the conventional wisdom about customization is incorrect. In this paper the authors model the primary factors in the customization decision: “fit” between the desired business process and the packaged software; costs related to development, maintenance, integration, and performance; and benefits related to increased fit, integration, performance, and user acceptance. They use simulation techniques to illustrate the conditions under which customization is likely to provide value to the organization, as well as conditions under which customization should be avoided. Obtaining Value from the Customization of Packaged Business Software: A Model and Simulation	best practice;business process;business software;enterprise resource planning;simulation	Bryon Balint	2015	IJEIS	10.4018/ijeis.2015010103	mass customization;computer science;systems engineering;engineering;knowledge management;package development process;marketing;operations management;software development;software walkthrough;management	SE	-70.47144758303064	22.044630860741417	151147
d20fa6edcb149996f6968420a8ebf54ca487d919	what happened to my application? helping end users comprehend evolution through variation management		Abstract Context: Millions of end users are creating software applications. These end users typically do not have clear requirements in mind; instead, they debug their programs into existence and reuse their own or other persons’ code. These behaviors often result in the creation of numerous variants of programs. Current end-user programming environments do not provide support for managing such variants. Objective: We wish to understand the variant creation behavior of end user programmers. Based on this understanding we wish to develop an automated system to help end user programmers efficiently manage variants. Method: We conducted an on-line survey to understand when and how end-user programmers create program variants and how they manage them. Our 124 survey respondents were recruited via email from among non-computer science majors who had taken at least one course in the computer science department at our university; the respondents were involved in the Engineering, Sciences, Arts, and Management fields. Based on the results of this survey we identified a set of design requirements for providing variation management support for end users. We implemented variation management support in App Inventor – a drag and drop programming environment for creating mobile applications. Our support, AppInventorHelper, is meant to help end-user programmers visualize the provenance of and relationships among variants. We conducted a think-aloud study with 10 participants to evaluate the usability of AppInventorHelper. The participants were selected on a first-come, first-served basis from those who responded to our recruitment email sent to list-servers. They were all end users majoring in electrical engineering, mechanical engineering, or physics. None had formal training in software engineering methods, but all had some experience with visual programming languages. Results: Our (user study) results indicate that AppInventorHelper can help end users navigate through variants and find variants that could be utilized cost-effectively as examples or actual code upon which to build new applications. For example, in one of our empirical studies end users explored variants of a paint application in order to find a variant that could easily be extended to incorporate a new feature. Conclusions: Our survey results show that end users do indeed reuse program variants and suggest that understanding the differences between variants is important. Further, end users prefer running code and looking at outputs, accessing source code and meta information such as filenames, referring to the creation and update dates of programs, and having information on the authors of code. When selecting variants users prefer to look at their major features such as correctness, similarity and authorship information. End users rely primarily on memory to track changes. They seldom make use of online or configuration management tools. Hence, integrated domain-specific variation management tools like AppInventorHelper can significantly help improve users’ interactions with the system. A key contribution of our work is a set of design requirements for end-user programming environments that facilitate the management and understanding of the provenance of program variants.		Sandeep Kaur Kuttal;Anita Sarma;Gregg Rothermel;Zhendong Wang	2018	Information & Software Technology	10.1016/j.infsof.2018.06.008	data mining;end user;source code;software;visual programming language;debugging;configuration management;computer science;drag and drop;usability	HCI	-73.33486775247283	24.16311326582645	151234
a768d510750c9a67afb2fde4d11a4a70e93af57b	standard based software process assessments in small companies	software process improvement;software process assessment;iso iec 15504;small organizations	Abstract#R##N##R##N#Small software companies face similar issues regarding software quality improvement and process assessments as larger companies. The main difference is that smaller companies seldom have specialized or competent resources to solve the problems. Therefore, the development of assessment methods from the viewpoint of small companies can also support the software industry. Based on experiences applying ISO/IEC 15504 in small software companies in Finland and Brazil, we present a flexible approach to efficient process assessments. Flexibility requires a continuous assessment model, so that the scope of process improvement and assessment can be defined on the basis of the prioritized needs of an organization. Our experiences show that 15504 can also be applied with success in small software organizations. This paper presents how the assessments were run and lessons learned on applying 15504 in this kind of organization. Copyright © 2006 John Wiley & Sons, Ltd.	software development process	Christiane Gresse von Wangenheim;Timo Varkoi;Clenio F. Salviano	2006	Software Process: Improvement and Practice	10.1002/spip.276	iso/iec 9126;personal software process;verification and validation;team software process;software engineering process group;iso/iec 12207;systems engineering;engineering;package development process;social software engineering;operations management;software development;software engineering;software construction;iso/iec 15504;software walkthrough;empirical process;management;software deployment;software quality control;goal-driven software development process;software quality;software quality analyst;software peer review	SE	-69.2044910224927	19.678658152288364	151593
b1cd9a254a50dc46d74f7974a84e5fd51018fc3e	how internationalization of a product changes requirements engineering activities: an exploratory study	human interaction;information technology;portfolios;packaging;stability;job production systems;requirement engineering;programming product development job production systems software packages packaging information technology humans marketing and sales portfolios stability;humans;exploratory study;programming;software packages;marketing and sales;product development	This paper explores the Requirement Engineering (RE) activities in two software product development organizations. Both companies have in recent years extended their product offering outside of their home market. In this paper, we wish to answer what RErelated challenges companies have faced in their journey of introducing their software products in new market areas and what have the companies done in their response to their new RE-related challenges. We believe that the results of this paper are important for practitioners and researchers alike. While increasing the academic understanding on the role of internationalization in market-driven requirements engineering, the paper also helps practitioners to anticipate some of the challenges that they may meet in their internationalization efforts. We have discovered that there may be inconsistencies between the nature of the challenges companies are facing and the strategies companies have taken to respond to the challenges. In addition, many of our findings are human interaction related indicating that the social aspects may still be an undervalued topic in RE research.	exploratory testing;new product development;requirements engineering	Sami Jantunen;Kari Smolander;Donald C. Gause	2007	15th IEEE International Requirements Engineering Conference (RE 2007)	10.1109/RE.2007.44	programming;packaging and labeling;interpersonal relationship;stability;economics;systems engineering;engineering;marketing;operations management;software engineering;requirements engineering;management;information technology;exploratory research;new product development	SE	-69.0317929851181	23.4138304889011	151705
5e9d17f5728b509a1b9bf557716a9b3ed642dcf4	approximations for the halstead software science software error rate and project effort estimators	developpement logiciel;taux erreur;ingenieria logiciel;software engineering;estimator;estimador;effort estimation;desarrollo logicial;software development;genie logiciel;error rate;indice error;naval research laboratory;estimateur	Experimental estimators are presented relating the expected number of software errors (B) in a software development project to* the overal1 reported months of programmer effort for the project (E)* the number of subprograms (n)* the count of thousands of coded source statements (s)These estimators are [EQUATION]These estimators are shown to be consistent with data obtained from, the air force Rome air developement center, the naval research laboratory, and Fujitsu corporation. It is suggested here that more data is needed to refine these estimators further.	approximation;programmer;software development;subroutine	Victor B. Schneider	1989	SIGMETRICS Performance Evaluation Review	10.1145/1041911.1041915	estimator;simulation;word error rate;computer science;software development;operations research;statistics	SE	-66.4378001937296	32.077931737638814	151763
53279e0c83227df62589a9d3e7e45c16eae6478f	industrial experiences with runtime verification of financial transaction systems: lessons learnt and standing challenges		The chapter will focus on experiences the authors had in applying runtime verification in industrial settings, in particular on financial transaction systems. We discuss how runtime verification can be introduced in the software development lifecycle and who are the people to be involved and when. Furthermore, we investigate what kind of properties have been found useful in practise and how these were monitored to keep intrusion to a minimum. Next, we describe two significant case studies which have been successfully carried out in the past, and conclude by outlining a number of challenges which we believe still need to be addressed for runtime verification to become more mainstream in industrial settings.	extrapolation;online and offline;requirement;runtime verification;software development process;software engineering	Christian Colombo;Gordon J. Pace	2018		10.1007/978-3-319-75632-5_7	software development process;real-time computing;systems engineering;intrusion;runtime verification;computer science;financial transaction	Logic	-66.94550047095707	25.125536352680154	151964
cba36171c42464c0a92d3b8237a7d54d0a35a433	an empirical evaluation of the impact of case on developer productivity and software quality	information management system;software;information systems security;mis systems;information systems research;journal of it;jit;teaching cases;logiciel;information security;case studies;information science;information security systems;information technology;business information technology;security information systems;it journals;information systems management;it teaching cases;operational research society;business model;journal of information technology teaching cases;enquete;computer information systems;jit journal;geographic information systems;information technology journal;information management;information systems journals;information systems technology;managing information systems;accounting information systems;information and management;management information systems;logicial;define information systems;evaluation;strategic information systems;business information management;encuesta;soft system methodology;information system;evaluacion;health information systems;computer information technology;journal of information technology;business information systems;business systems analyst;survey;empirical evaluation;case computer aided software engineering;systeme information;software quality;journal information technology;it journal;management science;journal of information systems;sistema informacion;information technology journals	This paper presents the findings of research into the impact of computer aided software engineering (CASE) tools. It is based on a questionnaire survey of software developers in UK organizations. CASE had a positive effect on developer productivity and the quality of applications software. It particularly improved the reliability and accuracy of applications software, though this was sometimes offset by a deterioration in software efficiency. There was little evidence of productivity being ‘traded’ for quality, since developers citing productivity gains also tended to report quality improvements. The extent to which organizations were able to realize the benefits of CASE depended on the experience, competence and training of individual developers. This has significant implications for the selection and training of personnel and the use of consultants. Methodologically, the findings also serve to underline the importance of explicitly taking account of prior development environments, when using retrospective methods to evaluate different software technologies.	software quality	R. T. Coupe;N. M. Onodu	1996	JIT	10.1080/026839696345379	personal software process;team software process;software quality management;software engineering process group;computer science;systems engineering;engineering;knowledge management;electrical engineering;management information systems;management science;software walkthrough;information technology;software quality control;information system;software metric;software quality analyst	SE	-70.84392340453364	20.85141054238374	152064
4727bad7521edf4ea02ea767439ab5e90121b91e	evolving a method framework for engineering process assessment models		In 2009 a research team analyzed how Process Assessment Models (PAM) had been produced. As a consequence, MFMOD was developed as a Method Framework for engineering Process Assessment Models (MFMOD). Producing PAMs using an engineering approach is a desirable research topic in Software Process Improvement due to the need for distinct and more specialized PAMs and the publication of ISO/IEC 15504 International Standard that includes requirements for PAMs. Lately MFMOD has been used as reference for defining processes for engineering three different PAMs and for defining a specific method for customizing PAMs. An analysis of how MFMOD was used confirmed its usefulness and indicated improvement opportunities for evolving it. This article introduces a work in progress to evolve it towards an improved version.		Adriana Maria C. M. Figueiredo;Clenio F. Salviano	2014		10.1007/978-3-319-13036-1_2	systems engineering	SE	-64.45831239766108	19.69684325387235	152266
532d407ea4f0b31ace65326f8e3a830b75fbdc6a	a survey on software test maturity in korean defense industry	software testing;test process improvement;software development;process improvement;survey	In this paper, we present findings of the survey on software test maturity, which has a total of 38 respondents answered to the questionnaire. The objectives of the survey were to identify approximate test maturity, testing practices, and characteristics of software development in Korean defense industry. The result of the survey reveals the strengths and weaknesses and several concerns the defense software organizations face.	approximation algorithm;capability maturity model;software development;software testing	Junyoung Park;Hoyeon Ryu;Ho-Jin Choi;Dong-Kuk Ryu	2008		10.1145/1342211.1342247	reliability engineering;systems engineering;engineering;software development;software engineering;software testing	SE	-65.84792955044138	28.367063186193633	152472
adc91c83c0e044aed7e0a8249ef0a3ad86e9123c	an experience report of the api evolution and maintenance for software platforms		Development and maintenance of software plat-form APIs are challenging because new APIs are constantly added in new software platforms. Furthermore, software plat-form API development requires a lot of stakeholders to work together on tight release schedules. Application developers use platform's APIs to create their applications and therefore providing a well-defined and comprehensive set of platform APIs may be the most basic requirement for software platforms. To provide such APIs, API usability should be secured and API backward compatibility should be guaranteed in subsequent platform re-leases. In these circumstances, sharing lessons learned from multiple years of experience of platform API development, mainte-nance, and releases using an integrated API development process can benefit API researchers and practitioners who have similar needs to create or adopt API development process for their projects. In this paper we share an API development and mainte-nance process for multi-device Tizen software platform, which we call the Tizen API Change Request (ACR) process. The process has been used among various Tizen API stakeholders for several years of Tizen platform and SDK releases to keep API usability and compatibility high. We believe the process can be further applied to various software platforms and projects to systematically develop and maintain their APIs.	application programming interface;backward compatibility;change request;software development kit;software maintenance;tizen;usability	H J Kwon;Juwon Ahn;Sunggyu Choi;Jakub Siewierski;Piotr Kosko;Piotr Szydelko	2018	2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)	10.1109/ICSME.2018.00034	backward compatibility;systems engineering;computer science;maintenance engineering;software;usability;schedule;change request	SE	-66.57027464247395	22.58289856919398	152574
5292ac1c5e01a6fa40fb7f5e43c9437f2d51b20b	an integrated multi-agent-based simulation approach to support software project management		Software projects often do not accomplish what is expected. They fail to comply with the planned schedule, cost more than predicted, or are simply not completed at all owing to issues such as bad planning, a poorly chosen team or an incorrect definition of the tasks to be performed. Although simulation methods and tools have been introduced to alleviate these problems, there is a lack of simulation approaches that integrate software project knowledge, software development processes, project-related situation-awareness, and learning techniques to help project managers to make more informed decisions and hence reach successful conclusions with software projects. In addition, in order to be more proactive, such approaches need to provide simulations based on both static and dynamic situation-awareness data, support (self-)adaptive project planning and execution, and recommend remedial courses of action when real-time project anomalies occur. In this context, this PhD research aims to create an integrated multi-agent-based simulation to support software project management in a more comprehensive way.	agent-based model;multi-agent system;real-time transcription;simulation;software development process;software project management	Davy de Medeiros Baia	2015	2015 IEEE/ACM 37th IEEE International Conference on Software Engineering		project management;verification and validation;team software process;extreme project management;software project management;computer science;systems engineering;engineering;knowledge management;software development;software design description;estimation;software engineering;software construction;management science;project management 2.0;project management triangle;schedule;software development process;project planning;project portfolio management	SE	-69.64170132866312	23.841671098220775	152590
f375245b85dee56df663ba58214570778d40abe1	collaboration in global software projects at siemens: an experience report	software development global software project collaboration siemens software initiative;software engineering;experience report;collaborative software international collaboration programming best practices project management engineering management management training collaborative tools computer architecture environmental management;siemens;global software project collaboration;software development;software initiative;software development management;geographic distribution	As a globally operating company with about 30,000 software engineers worldwide, Siemens has accumulated a wide variety of experiences in global development. Many individuals and organizations have adjusted their practices to deal with the challenges related to the geographic distribution of the development effort. From a corporate perspective, Siemens has accumulated a rich base of knowledge about global development and how to approach it successfully. The Siemens software initiative - a company-wide improvement program for software development at Siemens - has worked on collecting this widely-distributed knowledge and synthesizing it in a form accessible to the wider software development community. In this paper, the approach as well as key learnings in people and communication-related aspects of collaboration are summarized.	experience;software development;software engineer	Matthew Bass;James D. Herbsleb;Christian Lescher	2007	International Conference on Global Software Engineering (ICGSE 2007)	10.1109/ICGSE.2007.16	personal software process;long-term support;verification and validation;team software process;software engineering process group;software project management;systems engineering;engineering;knowledge management;social software engineering;siemens;software development;software engineering;software construction;software as a service;software walkthrough;software analytics;software deployment;software development process;software system;software peer review	SE	-67.43553873771859	21.416690743684377	152603
197190eb6cb1d5b2c94271d2ce60247939e3cbec	natures and perspectives	product line;software engineering;software development;software product line	“Nature” and “Perspective” have similar meaning for Eclipse developers and for personnel in a software product line organization. The nature of product line work differs from one part of the organization to another. A developer using Eclipse switches among perspectives to have ready access to the specific tools needed for the nature of the current work such as testing, modeling, or plug-in development. The product line developer has many reasons to switch among different perspectives on the product line. In this issue of Strategic Software Engineering I will explore the fundamental natures in a product line organization and the perspectives required for the success of a software development organization.	eclipse;network switch;plug-in (computing);software development;software engineering;software product line;vector graphics	John D. McGregor	2006	Journal of Object Technology	10.5381/jot.2006.5.8.c1	personal software process;verification and validation;software quality management;systems engineering;engineering;social software engineering;software development;software engineering;software construction;software walkthrough;product management;software quality control;product engineering;software peer review	SE	-66.76444283670698	23.60107025110095	152960
f267cb014f761a30dbe0ee15cf1d0b5ff74c7d30	third-party testing and the quality of software components	underwriters laboratories standard for safety related software third party testing software component quality professional disciplines governmental actions court decisions third party standards legislative processes regulatory processes software engineering standards;legislation;software engineering;software quality program testing legislation software standards government policies software reusability;program testing;software reusability;government policies;software component;software testing software quality software engineering business capability maturity model standards development software standards laboratories coordinate measuring machines software safety;software standards;software quality	One of the greatest fears of emerging professional disciplines is that governmental actions— court decisions and third-party standards—will preempt the profession’s active participation in legislative and regulatory processes. Indeed, software engineering standards, such as the Underwriters Laboratories’ Standard for Safety-Related Software (UL 1998, first and second editions), have preceded the development of practices, legislation, and regulation.1,2	component-based software engineering;software quality;third-party software component	William T. Councill	1999	IEEE Software	10.1109/52.776949	public policy;reliability engineering;personal software process;medical software;long-term support;verification and validation;software engineering process group;computer science;systems engineering;engineering;package development process;social software engineering;component-based software engineering;software development;software engineering;software construction;software testing;software walkthrough;software deployment;software quality control;software requirements;software quality;software quality analyst;software peer review	SE	-67.20926077041	27.623378643353657	152966
34747ab0f808f0b97618041c74e168ff8e4ab57b	the software engineering laboratory - an operational software experience factory	online resources;space flight;information resources;scholarly research;national aeronautics and space administration;programming environments;information sources;academic research;software measurement;ada programming language;particle measurements;online databases;education resources;goddard space flight center;publishing;research databases;packaging;software engineering;computer programs;computer programming;feedback;australasian research information;software engineering laboratories production facilities packaging feedback particle measurements software measurement software quality character recognition process planning;software engineering laboratory;software development environment;south east asian information;production facilities;information databases;full content;education databases;australian databases;software development tools;experience factory;organizations;process planning;commissioning;electronic publisher;software reliability;character recognition;online;software quality;software process;e titles;library resources	For 15 years, the Software Engineering Laboratory (SEL) has been carrying out studies and experiments for the purpose of understand- ing, assessing, and improving software and software processes within a production software development environment at the National Aeronautics and Space Administration/Goddard Space Flight Center (NASA/GSFC). The SEL comprises three major organizations: NASA/GSFC, Flight Dynamics Division University of Maryland, Department of Computer Science Computer Sciences Corporation, Flight Dynamics Technology Group - These organizations have jointly carried out several hundred software studies, producing hundreds of reports, papers, and documents, all of which de scribe some aspect of the software engineering technology that has been analyzed in the flight dynamics environment at NASA. The studies range from small, controlled experiments (such as analyzing the effectiveness of code readingversus that of functional testing) tolarge, multiple- project studies (such as assessing the impacts of Ada on a production environment). The organization's driving goal is to improve the software process continually, so that sustained improvement may be observed in the resulting products. This paper discusses the SEL as a functioning example of an operational software experience factory and summarizes the characteristics of and major lessons learned from 15 years of SEL operations.	ada;computer science;deployment environment;document;experiment;functional testing;integrated development environment;qr code;software development process;software engineering;software studies;systems engineering laboratories	Victor R. Basili;Gianluigi Caldiera;Frank E. McGarry;Rose Pajerski;Gerald T. Page;Sharon Waligora	1992	International Conference on Software Engineering	10.1145/143062.143154	personal software process;long-term support;verification and validation;team software process;simulation;software engineering process group;software project management;computer science;systems engineering;engineering;social software engineering;software development;operating system;software engineering;software construction;programming language;management;software deployment;software quality;software system;software peer review	SE	-65.61486711790987	27.28010347120932	153264
a2d64ff18b3b383bf2dc5b3c4b6659eb851e5dea	people-centered software development: an overview of agile methodologies		This chapter gives an overview of agile software development processes and techniques. The first part of the chapter covers the major agile project management techniques with a focus on project planning. Iteration planning and interaction design approaches are given special focus. The second part of the chapter covers agile quality assurance with a focus on test-driven development and the state space of testing. Current problems in agile testing, including measuring test quality and testing applications with large state spaces, are	agile software development;agile testing;consortium;dynamic systems development method;extreme programming practices;fault coverage;feature-driven development;feedback;interaction design;iteration;iterative and incremental development;lean software development;map;no silver bullet;prentice hall international series in computer science;software development process;stand-up meeting;state space;test-driven development;user story;xfig	Frank Maurer;Theodore D. Hellmann	2011		10.1007/978-3-642-36054-1_7	agile unified process;extreme programming practices;agile usability engineering;software development;empirical process;lean software development;software development process	SE	-63.87996442068836	24.628695578518897	153486
5986df0459c8545b89b39b1e76f4356e93ec6709	an agile knowledge discovery in databases software process		In a knowledge society, transforming data into information and knowledge to support the decision-making process is a crucial success factor for all organizations. In this sense, the mission of Software Engineering is to build systems able to process large volumes of data, transform them into relevant knowledge and deliver them to customers, so they can make the right decisions at the right time. However, companies still fail in determining the process model used in their Knowledge Discovery in Databases projects. This article introduces the AgileKDD, an agile and disciplined software process for developing systems capable of discovering the knowledge hidden in databases, which was built on top of the Open Unified Process. A case study shows that AgileKDD can increase the success factor of projects whose goal is to develop Knowledge Discovery in Databases applications.	agile software development;continuous delivery;data mining;database;iterative method;knowledge society;openup;process modeling;software development process;software engineering;unified process	Givanildo Santana do Nascimento;Adicinéia Aparecida de Oliveira	2012		10.1007/978-3-642-34679-8_6	knowledge base;organizational learning;software mining;knowledge economy;knowledge management;mathematical knowledge management;knowledge-based systems;knowledge engineering;open knowledge base connectivity;data mining;database;knowledge extraction;personal knowledge management;knowledge value chain;domain knowledge	ML	-66.8134817381725	19.831053859881063	153759
619e02e528ecad6c0297f90dde3acef23f594447	pathways to technology transfer and adoption: achievements and challenges (mini-tutorial)	software analytics;research and development;program testing;particular research area;industrial practice;industrial researcher;technology adoption;industrial researchers;technology transfer;research achievement;research result;research area;academic researchers;software analysis;software testing;producing industrial impact;industrial impact;software engineering;speech;cloning;collaboration;testing	Producing industrial impact has often been one of the important goals of academic or industrial researchers when conducting research. However, it is generally challenging to transfer research results into industrial practices. There are some common challenges faced when pursuing technology transfer and adoption while particular challenges for some particular research areas. At the same time, various opportunities also exist for technology transfer and adoption. This mini-tutorial presents achievements and challenges of technology transfer and adoption in various areas in software engineering, with examples drawn from research areas such as software analytics along with software testing and analysis. This mini-tutorial highlights success stories in industry, research achievements that are transferred to industrial practice, and challenges and lessons learned in technology transfer and adoption.	software analytics;software engineering;software testing	Dongmei Zhang;Tao Xie	2013	2013 35th International Conference on Software Engineering (ICSE)		engineering management;personal software process;software engineering process group;systems engineering;engineering;social software engineering;software development;software engineering;software walkthrough;software analytics;software deployment;software peer review	SE	-66.84848632367617	23.892733449176312	153814
e1780fbff04d79a09fe95f48df52883efdeafa33	assessing attribute grammars' quality: metrics and a tool		The definition of metrics and their evaluation process is an activity intrinsic to each engineering branch and it has to do with the need to reason quantitatively about the quality of the developed prod- ucts. Years ago software engineers working on the field of formal lan- guages and grammars came out with the idea of measuring grammars. However no much progress was done in this trend; there is a clear lack for tools to automatize the computation of some grammar metrics gram- mars. In this paper we will introduce a tool, GQE, aimed at evaluating a new set of simple metrics for attribute grammars (AG) in order to help on the assessment of AGs quality.	attribute grammar	João Cruz;Pedro Rangel Henriques;Daniela Carneiro da Cruz	2015		10.1007/978-3-319-27653-3_13	natural language processing;computer science;artificial intelligence;theoretical computer science;data mining;programming language	Logic	-67.05337582484466	31.597330841273163	153970
8fe30b5422a568a7b847b2545152770c75e4cd2f	processpair: a tool for automated performance analysis and improvement recommendation in software development	software;calibration unified modeling language sensitivity software performance analysis statistical distributions estimation;psp processpair software tool performance analysis improvement recommendation software development data analysis personal software process;sensitivity;statistical distributions;estimation;unified modeling language;performance analysis;software tools data analysis software performance evaluation software process improvement;improvement recommendation;improvement recommendation software process performance analysis;calibration;software process	High-maturity software development processes can generate significant amounts of data that can be periodically analyzed to identify performance problems, determine their root causes and devise improvement actions. However, conducting that analysis manually is challenging because of the potentially large amount of data to analyze and the effort and expertise required. In this paper, we present ProcessPAIR, a novel tool designed to help developers analyze their performance data with less effort, by automatically identifying and ranking performance problems and potential root causes, so that subsequent manual analysis for the identification of deeper causes and improvement actions can be properly focused. The analysis is based on performance models defined manually by process experts and calibrated automatically from the performance data of many developers. We also show how ProcessPAIR was successfully applied for the Personal Software Process (PSP). A video about ProcessPAIR is available in https://youtu.be/dEk3fhhkduo.	capability maturity model;personal software process;profiling (computer programming);software development process	Mushtaq Raza;João Pascoal Faria	2016	2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)	10.1145/2970276.2970284	probability distribution;unified modeling language;personal software process;estimation;verification and validation;team software process;calibration;software engineering process group;software sizing;sensitivity;computer science;systems engineering;package development process;software design;software reliability testing;software development;software engineering;software construction;data mining;software walkthrough;empirical process;software analytics;software measurement;software deployment;goal-driven software development process;software development process;software metric	SE	-64.65487516636601	31.454955285828863	154038
39ff7fa953124e1e4443396803de25f67c082779	rethinking coordination in large-scale software development		Coordination was early identified as a key challenge in software development, and in particular in large development projects. With the arrival of agile methods and their increasing use also in large-scale projects, this calls for rethinking how the software engineering community addresses coordination. We argue for increasing the focus on coordination in software engineering and describe four directions for research. Focus on these areas can supplement advice given in current development methods with relevant research-based advice.	advice (programming);agile software development;software engineering	Torgeir Dingsøyr;Finn Olav Bjørnson;Nils Brede Moe;Knut H. Rolland;Eva Amdahl Seim	2018	2018 IEEE/ACM 11th International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE)	10.1145/3195836.3195850	systems engineering;task analysis;computer science;software;software development;agile software development	SE	-66.33508419957217	23.668739932592185	154831
0e10a1af12a06a1cee730e3c72d3f51ec3a735ee	deploying and provisioning green software	energy efficiency;software green products hardware energy efficiency benchmark testing electricity educational institutions;industry;industry green software green it energy efficiency;green software;green it	To learn more about how software developers can integrate green software practices, the guest editors spoke with Steve Raspudic, manager and deployment and provisioning architect at IBM Toronto's Software Lab.	provisioning	Ayse Basar Bener;Andriy V. Miranskyy;Steve Raspudic	2014	IEEE Software	10.1109/MS.2014.59	green computing;personal software process;simulation;computer science;engineering;social software engineering;operations management;operating system;software engineering;software as a service;efficient energy use;resource-oriented architecture;software deployment	SE	-69.89086808959041	27.516135238822724	154835
68f67e9cb03e3c505c349c877ac6a6a1fde270de	enterprise-level packaged software acquisition: a structured literature review through the lens of it governance		Enterprise-level packaged software is gaining in importance across organizations. Increasingly, organizations decide to purchase packaged software solutions. However, the acquisition of these software packages is carried out in risky and complex acquisition projects. Implementing the right governance structures and procedures can help to avoid errors and problems in this phase, which could severely impact implementation and usage of the procured systems in the future. The current body of knowledge on software acquisition governance is scarce, scattered, and in need of integration. Therefore, this study endeavors to perform a structured literature review which assesses the current state-of-the-art in software acquisition, focusing on IT governance-related aspects. Three main topics are identified and elaborated: the selection of software, the software acquisition process, and influencing factors. Based on these extant findings, this study integrates and synthesizes the separate research streams through the conceptual lens of IT governance. This literature review can help decision makers in organizations with optimizing their software procurement processes, governance, and behaviors and builds a foundation for further research on this increasingly relevant topic.	benchmark (computing);best practice;business process;cluster analysis;enterprise software;european conference on information systems;holism;procurement;purchasing;relevance;software as a service;systematic review;thomas j. watson research center	Stefan Harnisch	2014			team software process;software engineering process group;systems engineering;engineering;knowledge management;social software engineering;software development;software design description;management science;software technical review;software walkthrough;software analytics;software deployment;software quality control;software peer review	SE	-70.59699416702422	19.81594670143824	154865
82162d1ec16f2567ba6af210538037c16a684793	verdicts: visual exploratory requirements discovery and injection for comprehension and testing of software	debugging;mutation testing;software testing;computer science verdicts visual exploratory requirements discovery and injection for comprehension and testing of software syracuse university james w fawcett bolazar;requirements discovery;design by contract;sefik kanat;software visualization	We introduce a methodology and research tools for visual exploratory software analysis. VERDICTS combines exploratory testing, tracing, visualization, dynamic discovery and injection of requirements speci cations into a live quick-feedback cycle, without recompilation or restart of the system under test. This supports discovery and veri cation of software dynamic behavior, software comprehension, testing, and locating the defect origin. At its core, VERDICTS allows dynamic evolution and testing of hypotheses about requirements and behavior, by using contracts as automated component veri ers. We introduce Semantic Mutation Testing as an approach to evaluate concordance of automated veri ers and the functional speci cations they represent with respect to existing implementation. Mutation testing has promise, but also has many known issues. In our tests, both black-box and white-box variants of our Semantic Mutation Testing approach performed better than traditional mutation testing as a measure of quality of automated veri ers. VERDICTS: Visual Exploratory Requirements Discovery and Injection for Comprehension and Testing of Software By e k Kanat Bolazar B.S. Middle East Technical University, 1990 M.S. Syracuse University, 1993	black box;concordance (publishing);exploratory testing;list comprehension;mutation testing;requirement;software bug;system under test	S. Kanat Bolazar;James W. Fawcett	2010			exploratory testing;verification and validation;computer science;software engineering;software construction;session-based testing;software testing;programming language;world wide web	SE	-63.24603063872387	29.870274838300304	155270
68216a89952d34c30f5bca23a4e0b495b8be9795	a follow up study of the effect of personality on the performance of software engineering teams	jungian personality types;software engineering;personality type;team work;group work in software engineering;ethnographic observations;myers briggs type indicator;group work;follow up study	This paper describes ethnographic observations and analysis of the performance of student teams working on year-long software projects (2004-2005 UK academic year) for industrial clients. Personality types were measured using an online version of the Myers Briggs Type Indicator (MBTI), as a basis for studying how individuals interacted within the teams, and the effects of disruptive issues on the quality of work produced by the team. The behavior of the observed teams is analyzed and the results compared with those from the previous year's (2003-2004) research, also carried out on student teams. A significant finding in 2003-2004 was that issues which teams did not discuss adequately caused more problems for the quality of work than issues which produced actual disruption within the team; the results from 2004-2005 differ in that actual disruptions proved most damaging to the teams involved.	denial-of-service attack;software engineering	John Karn;Anthony J. Cowling	2006		10.1145/1159733.1159769	psychology;knowledge management;management;social psychology	SE	-72.29819942276403	21.993269299694948	155331
9549d6d719302d6520afe7c4e6b1dd686a011c95	naming the pain in requirements engineering: design of a global family of surveys and first results from germany	software;family of surveys;anforderungsanalyse;survey research;family of studies;software engineering;requirements engineering;anforderung;conferenceobject;umfrage;umfragefamilie;umfrage forschung;preprint	Context: For many years, we have observed industry struggling in defining a high quality requirements engineering (RE) and researchers trying to understand industrial expectations and problems. Although we are investigating the discipline with a plethora of empirical studies, those studies either concentrate on validating specific methods or on single companies or countries. Therefore, they allow only for limited empirical generalisations. Objective: To lay an empirical and generalisable foundation about the state of the practice in RE, we aim at a series of open and reproducible surveys that allow us to steer future research in a problem-driven manner. Method: We designed a globally distributed family of surveys in joint collaborations with different researchers from different countries. The instrument is based on an initial theory inferred from available studies. As a long-term goal, the survey will be regularly replicated to manifest a clear understanding on the status quo and practical needs in RE. In this paper, we present the design of the family of surveys and first results of its start in Germany. Results: Our first results contain responses from 30 German companies. The results are not yet generalisable, but already indicate several trends and problems. For instance, a commonly stated problem respondents see in their company standards are artefacts being underrepresented, and important problems they experience in their projects are incomplete and inconsistent requirements. Conclusion: The results suggest that the survey design and instrument are well-suited to be replicated and, thereby, to create a generalisable empirical basis of RE in practice.	display resolution;replication (computing);requirement;requirements engineering	Daniel Méndez Fernández;Stefan Wagner	2013		10.1145/2460999.2461027	survey research;computer science;engineering;software engineering;management science;requirements engineering;management;operations research;preprint	SE	-69.68589641886182	21.54913965423584	155405
5d76415987bd685bd9d289a6642ec74c3ac9f5bc	content-based multi-platform app forge	digital assets management;software generation;hybrid development;publishing;incremental update content based multiplatform application forge mobile application development device platform device equipment solution projects solution maintenance sustainability cultural heritage video guide digital editorial artifacts open source cms system software package mobile platforms client side application phonegap cordova framework javascript framework selection javascript framework optimization digital mobile publishing product life cycle digital asset management web application mobile application in application purchase content;software packages client server systems content management java mobile computing;software engineering;javascript software engineering hybrid development digital assets management software generation;mobile communication software engineering publishing multimedia communication operating systems open source software;multimedia communication;mobile communication;javascript software engineering;open source software;operating systems	Mobile App development arises new dynamism for both device platform and device equipment. New solution projects and solution maintenance sustainability is at risk due to this variability. Some entry-level and build-by-template solutions are emerging. This experience demonstrates the solution we found when working together with market leaders in cultural-heritage video-guide: new digital editorial artifacts. We used an open-source CMS system to manage different type of contents and to generate complete software package for various mobile platforms. The client-side App is based on PhoneGap/Cordova framework and javascript frameworks selection and optimization. This system completely covers digital mobile publishing product life-cycle from digital asset management to App (web or mobile) deploy or updates management systems, including in-App purchase content and incremental update.	apache cordova;client-side;digital asset;forge;heart rate variability;incremental backup;javascript;mathematical optimization;mobile app;mobile device;open-source software	Davide Rogai;Claudio Bisconti;Salif Omar Faye	2015	2015 2nd ACM International Conference on Mobile Software Engineering and Systems	10.1109/MobileSoft.2015.47	web application;mobile search;digital asset management;content management;computer science;package development process;social software engineering;software framework;software development;software engineering;mobile technology;software construction;software as a service;database;mobile computing;world wide web;software development process;software system	SE	-71.83474022230025	29.355480615156917	155613
ff4ef066a8da46c723eb89ddc306e8b35387c882	why lehman matters: mediocracy	lehman matter	"""Developers of software should be familiar with software processes, but what is a process? Is a process a set of rules or is it a set of guidelines? The difference is important as rules are mandatory, things that have to be done, while guidelines are looser, allowing for some measure of human judgment. According to Lehman the purpose of having a software process is to reduce the amount of thinking that needs to be done-although thinking may be reduced it can never be fully eliminated. Rules-following is easy, but predicting the consequence of rules-following may be less so. One should look at process from a perspective of context-if a process contains good things then by following a process one can do good things. But if a rule becomes wrong in a changing environment, then blindly following that rule can lead to bad consequences. Rules, like lines of code, should be weighed not just counted. Lehman says that real world software processes constitute """" multi-level, multi-loop, multi-agent feedback systems """" where the reaction to a consequence provides the feedback. That is, the consequence of following a rule that did not end up doing what you wanted can affect the assumptions that led to the rule, leading to changing the rule to get a better outcome. So Lehman also says that processes should be treated as provisional and open-ended for any other than primitive (i.e. very simple) processes. What about multi-agent? The person who creates the rule, the person who applies the rule, and the person who evaluates the consequence may not be the same person. When there is separation between observation, action and consequence, gaps can occur that prevent determining an accurate relationship between cause and effect, which in turn can negatively affect generating accurate feedback. This is true not just for developing software, but also true for developing software developers. The observer's role is especially difficult. If a rule doesn't work, was the rule incorrect (which points to the rule or the context), not applied correctly (which points to training or ability), or did the rule-follower simply not try hard enough (which points to time or motivation)? Perhaps the observation itself was incorrect (what did I see?) Or the judgment on the observation (what should I believe?), or the judgment on the consequence (how should I interpret what happened?) The consequence might even be out of the hands of those …"""	causality;loose coupling;multi-agent system;nonlinear gameplay;process (computing);software developer;software development process;source lines of code	Robert Schaefer	2013	ACM SIGSOFT Software Engineering Notes	10.1145/2532780.2532786	systems engineering;software engineering;computer science	SE	-71.06303296568596	24.93936938485995	155660
6ea36d7da665a735c441a243868fc87729f740e7	leveraging resources in global software development	project management;cellular system;risk factors;software development;programming maintenance engineering software tools teamwork australia contracts electric breakdown cultural differences computer architecture;project risk factors global software development global resources global engineering team motorola risk factors;global software development;software development management;project management software development management	Leveraging global resources for software development is rapidly becoming the norm at Motorola, which has over 25 software development centers worldwide. Our project, called the 3G Trial (Third Generation Cellular System), was the first of its scope and significance developed by a global engineering team at Motorola. Staffing was the most significant issue we encountered in the 3G Trial. We had only about 20 percent of the required staff available at our division headquarters in Burlington Heights, Ill., US, and needed to find the other 80 percent to successfully complete the project. Early on, we concluded that our only means to staff the project was to rely on software development engineers from Motorola's worldwide software centers. We developed the system with staffing from six different countries. Next, we had to integrate the people into a team. While addressing this challenge, we identified key risk factors and developed approaches to reduce them. We separated the project risk factors into the five categories Carmel (1999) describes as the centrifugal forces that pull global projects apart. To pass on the lessons we learned from this project, this article sets out the global development issues we faced, our approaches to resolving them, and our findings compared to other research.	software development	Robert D. Battin;Ron Crocker;Joe Kreidler;K. Subramanian	2001	IEEE Software	10.1109/52.914750	project management;personal software process;long-term support;team software process;software project management;systems engineering;engineering;knowledge management;package development process;social software engineering;operations management;software development;software engineering;software as a service;software walkthrough;software analytics;project management triangle;management;lean software development;software deployment;risk factor;software development process;software peer review	SE	-67.48979063155976	21.336716066416162	155834
39c7c5897a9b5edafccf98e2cdaf9c41f807e32c	automatic software summarization: the state of the art		While automatic text summarization has been widely studied for more than fifty years, in software engineering, automatic summarization is an emerging area that shows great potential and poses new and exciting research challenges. This technical briefing provides an introduction to the state of the art and maps future research directions in automatic software summarization. A first version was presented at ICSE'17 and now it is updated and enhanced, based on feedback from the audience.	automatic summarization;map;software engineering	Laura Moreno;Andrian Marcus	2017	2018 IEEE/ACM 40th International Conference on Software Engineering: Companion (ICSE-Companion)		data mining;automatic summarization;computer science;software peer review;software system;software construction;software development;software verification and validation;social software engineering;software release life cycle	SE	-65.82392504842437	24.33072551010925	156058
e7d40892a114a9390dc2db9e582b9d124a90099a	benefits and limitations of job rotation in software organizations: a systematic literature review	software engineering;job rotation;slr	Context. Job Rotation is an organizational practice whereby individuals are regularly moved among jobs or projects in the same organization. Goal: To identify and discuss evidence about job rotation, in order to understand the use, the benefits, and the limitations of this practice in software organizations. Method: A systematic literature review protocol was used to identify and select empirical studies previously published in the software engineering literature, and then coding techniques were used to analyse and synthesize their findings. Results: This review identified 18 empirical papers presenting evidence of 17 distinct studies about job rotation in software engineering. These studies revealed that in software organizations job rotation has been used to enhance communication, organizational understanding, knowledge exchange, and task variety. However, its use also requires extra effort and sometimes complex planning. Conclusion: The research about job rotation in software engineering is restricted, with only one study focusing on this topic and 16 presenting non-intentional evidence about the theme. Our review synthesized evidence that could inform research and practice. However, due to the specific nature of software development tasks and jobs, empirical evidence is still needed to guide the effective application of job rotation in practice.	data compression;job stream;software development;software engineering;systematic review	Ronnie E. S. Santos;Fabio Q. B. da Silva;Cleyton V. C. de Magalhães	2016		10.1145/2915970.2915988	software engineering process group;engineering;knowledge management;operations management;management science;job analysis	SE	-71.2803425754467	21.86181565939646	156472
0422f86e27a31b90d6a37a9ec7e601757c48ada2	collaboration change in enterprise software development		Enterprise software development is a complex effort that may last years. Enterprise software is often developed by a systems integrator that makes modifications to a pre-made package or builds tailored software for the specific purpose. The development may include many developer organizations, the user organization, and their different departments and sub-units. Their collaboration evolves through project incidents, phases and even crises. The practices of project management, communication, contracts, and ultimately personal relationships change intentionally or unintentionally. These changes may cause uncertainties and discontinuities for the development. This study observes changes during enterprise software development and their influence on collaboration practices in different situations. During twenty years of development both internal and external crises and changes in the business environment triggered changes in collaboration. The collaboration practices are classified with four modes of collaboration (contract, cooperation, personified, and process) that illustrate emphasis in collaboration in different circumstances. CCS Concepts Software and its engineering  Software creation and management  Collaboration in software development Information systems  Information systems application  Enterprise information systems		Kari Smolander;Matti Rossi;Samuli Pekkola	2016		10.1109/CHASE.2016.023	functional software architecture;project management;enterprise system;enterprise software;software project management;computer science;systems engineering;engineering;knowledge management;software engineering;software as a service;management;collaboration	SE	-67.74144908471105	20.99557207889145	156887
ff61e90927f62da3a226ddf31ec7381ef92b42da	is it possible to disregard obsolete requirements? an initial experiment on a potentially new bias in software effort estimation		Effort estimation is a complex area in decision-making, and is influenced by a diversity of factors that could increase the estimation error. The effects on effort estimation accuracy of having obsolete requirements in specifications have not yet been studied. This study aims at filling that gap. A total of 150 students were asked to provide effort estimates for different amounts of requirements, and one group was explicitly told to disregard some of the given requirements. The results show that even the extra text instructing participants to exclude requirements in the estimation task, had the subjects give higher estimates. The effect of having obsolete requirements in requirements specifications and backlogs in software effort estimation is not taken into account enough today, and this study provides empirical evidence that it possibly should. We also suggest different psychological explanations to the found effect.	cost estimation in software engineering;error message;futures studies;requirement;software development effort estimation	Lucas Gren;Richard Berntsson-Svensson;Michael Unterkalmsteiner	2017	2017 IEEE/ACM 10th International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE)	10.1109/CHASE.2017.10		SE	-70.78706639699851	23.65460256789989	157109
d7d5260d4b9413a63f6c2b20f58b89d3a68567ca	preliminary results of a systematic review on requirements evolution	systematic literature review requirements evolution requirements change management process measurement;measurement goals software systems stakeholder needs business environment society regulations software project cost software project scheduling software project defect density requirements evolution management requirements engineering;software management formal verification software engineering	Background: Software systems must evolve in order to adapt in a timely fashion to the rapid changes of stakeholder needs, technologies, business environment and society regulations. Numerous studies have shown that cost, schedule or defect density of a software project may escalate as the requirements evolve. Requirements evolution management has become one important topic in requirements engineering research. Aim: To depict a holistic state-of-the-art of requirement evolution management. Method: We undertook a systematic review on requirements evolution management. Results: 125 relevant studies were identified and reviewed. This paper reports the preliminary results from this review: (1) the terminology and definition of requirements evolution; (2) fourteen key activities in requirements evolution management; (3) twenty-eight metrics of requirements evolution for three measurement goals. Conclusions: Requirements evolution is a process of continuous change of requirements in a certain direction. Most existing studies focus on how to deal with evolution after it happens. In the future, more research attention on exploring the evolution laws and predicting evolution is encouraged. Keywordsrequirements evolution, requirements change, management process, measurement, systematic literature review	change management (engineering);holism;requirement;requirements engineering;schedule (computer science);software bug;software evolution;software project management;software system;systematic review	Juan Li;He Zhang;Liming Zhu;D. Ross Jeffery;Qing Wang;Mingshu Li	2012		10.1049/ic.2012.0002	requirements analysis;software requirements specification;requirements management;market requirements document;requirement prioritization;business requirements;software project management;systems engineering;engineering;software design;requirement;software engineering;needs analysis;system requirements specification;requirements elicitation;management science;requirements engineering;application lifecycle management;functional requirement;non-functional requirement;software requirements;requirements traceability	SE	-68.1617332090318	22.371344741351532	157320
08f29338cb6236ca0c97181e3d83a2859fc8d3a0	complementor embeddedness in platform ecosystems: the case of google apps	ecosystems google companies measurement industries software collaboration;nyenrode publications;web sites statistical analysis;statistical analysis;web sites;google apps ecosystem complementor embeddedness software industry network analysis statistical analysis	Platforms and their marketplaces with complementarities are prominent in the software industry. As the proprietary platform itself exhibits elementary or generic functionality, platform owners depend on a complementor ecosystem populated by third-parties. At present, little is known about mechanisms at play in proprietary ecosystems. Addressing this deficiency, this paper investigates the Google Apps ecosystem through statistical and network analysis. Results show that the Google Apps ecosystem is sparsely connected, the majority of complementors develops one application (83%) and does not have visible relationships (73%). Furthermore, there is a positive relationship between the number of applications a complementor develops and the number of relationships it establishes. The research method and results presented can be used by practitioners as a reference to evaluate their structural position in the ecosystem, while it provides researchers with a quantification of ecosystem characteristics.	angular defect;app store;complementarity theory;computer cluster;elementary;ecosystem;emergence;g suite;network topology;population;software industry;techcrunch;traffic shaping	Joey van Angeren;Vincent Blijleven;Slinger Jansen;Sjaak Brinkkemper	2013	2013 7th IEEE International Conference on Digital Ecosystems and Technologies (DEST)	10.1109/DEST.2013.6611326	simulation;engineering;data mining;world wide web	Visualization	-75.91444501801182	21.54618076746192	157978
cd31768c2d5c82beced29c5f7d054bce6259dbd7	software process landscaping	software process	Software processes usually cover software development activities, configuration management, quality management and project management issues. Models of these processes tend to become rather complex. Mechanisms to structure these models are needed. The process landscaping approach allows us to model processes on different abstraction levels without losing the overview about the whole framework of processes and their interfaces. It also ensures that key decisions about processes are not burdened by an overwhelming amount of detail. In this article we discuss the method of process landscaping in the light of a real-world software process. Copyright © 2000 John Wiley u0026 Sons Ltd		Volker Gruhn	2000	Software Process: Improvement and Practice	10.1002/1099-1670(200006/09)5:2/3%3C111::AID-SPIP118%3E3.0.CO;2-R	team software process;software engineering process group;computer science;systems engineering;engineering;operations management;software framework;software development;software engineering;process management;empirical process;management;business process modeling;goal-driven software development process;software development process	SE	-66.59163158742153	22.46527115735696	158141
10fe1adf25ee4bfc6acd93d1f978a57ceade86bc	a requirements monitoring framework for enterprise systems	electronic commerce;real time;web service;satisfiability;requirement analysis;software requirements;monitoring system;requirements monitoring;enterprise information system;web services;enterprise system;case	Requirements compliant software is becoming a necessity. Fewer and fewer organizations will run their critical transactions on software that has no visible relationship to its requirements. Businesses wish to see their software being consistent with their policies. Moreover, partnership agreements are pressuring less mature organizations to improve their systems. Businesses that rely on web services, for example, are vulnerable to the problems of their web service providers. While electronic commerce has increased the speed of on-line transactions, the technology for monitoring requirements compliance—especially for transactions—has lagged behind. To address the requirements monitoring problem for enterprise information systems, we integrate techniques for requirements analysis and software execution monitoring. Our framework assists analysts in the development of requirements monitors for enterprise services. The deployed system raises alerts when services succeed or fail to satisfy their specified requirements, thereby making software requirements visible. The framework usage is demonstrated with an analysis of ebXML marketplace specifications. An analyst applies goal analysis to discover potential service obstacles, and then derives requirements monitors and a distributed monitoring system. Once deployed, the monitoring system provides alerts when obstacles occur. A summary of the framework implementation is presented, along with analysis of two monitor component implementations. We conclude that the approach implemented in the framework, called ReqMon, provides real-time feedback on requirements satisfaction, and thereby provides visibility into requirements compliance of enterprise information systems.	automated planning and scheduling;distributed computing;e-commerce;ebxml;enterprise information system;enterprise integration;enterprise system;goto;high- and low-level;international federation for information processing;martin kay;online and offline;real-time clock;requirement;requirements analysis;requirements engineering;software requirements;system requirements;traceability;trust (emotion);velocity obstacle;web service	William N. Robinson	2005	Requirements Engineering	10.1007/s00766-005-0016-3	web service;requirements analysis;software requirements specification;requirements management;requirement prioritization;system requirements;enterprise software;business requirements;computer science;systems engineering;requirement;software engineering;needs analysis;system requirements specification;requirements elicitation;database;requirements engineering;non-functional testing;computer security;non-functional requirement;software requirements;requirements traceability;enterprise information system	SE	-71.15522223348542	27.025024424580018	158158
9c27e1347a260e823655e86f530ab9f249d32b31	a situational assessment method for software product management	a situational assessment method for software product management	There is very little literature supporting software product managers in their work, even though they play a crucial role within software product management organizations. There are large solutions for the improvement of software product management practices, but these are not applicable to most small and medium sized organizations. This research-in-progress paper presents a general incremental assessment method that takes the organization’s situational context into account: the Situational Assessment Method (SAM). We applied this scientific method to the field of software product management to solve the aforementioned problem. Our method presents organizations with an assessment of their current maturity level, and suggests steps to incrementally improve their processes. SAM is a focus area oriented instrument with a different set of capabilities for each area. The context of an organization is taken into account by examining various situational factors that describe the context of the organization, and the organization itself. This context is then used to determine which capabilities apply to the organization being assessed. A situation specific advice indicating how software product management practices can be improved upon is then created based on a gap analysis of the currently implemented capabilities, and the capabilities that should be implemented.	capability maturity model;gap analysis;software product management	Willem Bekkers;Marco R. Spruit;Inge van de Weerd;Rob van Vliet;Alain Mahieu	2010			verification and validation;computer science;knowledge management;application lifecycle management	SE	-69.48350527168172	19.93383833766151	158215
7c2e291e769b24985cf499a9bb1b278a44af30d6	aspic: awareness-based support project for interpersonal collaboration in software engineering	interpersonal collaboration;groupware;awareness based support project;collaborative work;collaboration;presses;contextual information;software engineering groupware;software engineering;gse;technological support;awareness;gse aspic awareness based support project interpersonal collaboration software engineering;context software engineering ieee computer society press collaborative work programming collaborative software presses;ieee computer society press;aspic;programming;context;collaboration aspic awareness technological support contextual information gse;collaborative software	Research the problems caused by the difficulties in GSE with acquiring and maintaining awareness: sufficient contextual information to be able to properly cooperate with others.	generic stream encapsulation;software engineering	Kevin Dullemond;Ben van Gameren;Rini van Solingen	2010	2010 5th IEEE International Conference on Global Software Engineering	10.1109/ICGSE.2010.50	economics;systems engineering;engineering;knowledge management;software engineering;management;collaborative software	SE	-67.2980175831672	19.819176491663402	158319
28de893ca2d708ecebda2cac7c401a210f275623	supporting scientific se process improvement		The increasing complexity of scientific software can result in significant impacts on the research itself. In traditional software development projects, teams adopt historical best practices into their development processes to mitigate the risk of such problems. In contrast, the gap that has formed between the traditional and scientific software communities leaves scientists to rely on only their own experience when facing software process improvement (SPI) decisions. Rather than expect scientists to become software engineering (SE) experts or the SE community to learn all of the intricacies involved in scientific software development projects, we seek a middle ground. The Scientific Software Process Improvement Framework (SciSPIF) will allow scientists to self-drive their own SPI efforts while leveraging the collective experiences of their peers and linking their concerns to established SE best practices. This proposal outlines the known challenges of scientific software development, relevant concepts from traditional SE research, and our planned methodology for collecting the data required to construct SciSPIF while staying grounded in the actual goals and concerns of the scientists.	best practice;experience;software development process;software engineering	Erika S. Mesh	2015	2015 IEEE/ACM 37th IEEE International Conference on Software Engineering		personal software process;long-term support;verification and validation;team software process;software engineering process group;software project management;computer science;systems engineering;engineering;knowledge management;package development process;social software engineering;software development;software engineering;software construction;software walkthrough;empirical process;software analytics;software deployment;goal-driven software development process;software development process;software peer review	SE	-68.74366294971705	20.780084167932618	158652
0737b5d249a7340cbb29282531ddcdeb679bf759	flossmole: a collaborative repository for floss research data and analyses	data mining;software engineering;data storage;methodologies;free and open source software;open source software;open source	This paper introduces and expands on previous work on a collaborative project, called FLOSSmole (formerly OSSmole), designed to gather, share and store comparable data and analyses of free, libre, and open source software (FLOSS) development for academic research. The project draws on the ongoing collection and analysis efforts of many research groups, reducing duplication, and promoting compatibility both across sources of FLOSS data and across research groups and analyses. The paper outlines current difficulties with the current typical quantitative FLOSS research process and uses these to develop requirements and presents the design of the system.	open-source software;requirement	James Howison;Megan Conklin;Kevin Crowston	2006	IJITWE	10.4018/jitwe.2006070102	computer science;package development process;software development;operating system;software construction;computer data storage;methodology;data mining;database;software analytics;software deployment;world wide web;software system	SE	-64.81413901379509	23.479406018460345	158720
fb9532dcce130635e439db1ff8ad96644f1f766f	development of a metric for assessing full-stack developers' expertise				Jordan Shropshire;Jeffrey P. Landry;Steven J Presley	2018				SE	-76.0561733129144	23.534674646653954	158975
3fb76be4635654c396a6c352d53fc20315751602	are developers complying with the process: an xp study	project manager;data capture;process conformance;extreme programming;version control system;xp programming;process model;process improvement;product quality;software process	Adapting new software processes and practices in organizational and academic environments requires training the developers and validating the applicability of the newly introduced activities. Investigating process conformance during training and understanding if programmers are able and willing to follow the specific steps are crucial to evaluating whether the process improves various software product quality factors. In this paper we present a process model independent approach to detect process non-conformance. Our approach is based on non-intrusively collected data captured by a version control system and provides the project manager with timely updates. Further, we provide evidence of the applicability of our approach by investigating process conformance in a five day training class on eXtreme Programming (XP) practices at the Leibniz Universität Hannover. Our results show that the approach enabled researchers to formulate minimal intrusive methods to check for conformance and that for the majority of the investigated XP practices violations could be detected.	conformance testing;control system;extreme programming;ibm notes;iteration;microsoft customer care framework;process modeling;programmer;technical debt;version control	Nico Zazworka;Kai Stapel;Eric Knauss;Forrest Shull;Victor R. Basili;Kurt Schneider	2010		10.1145/1852786.1852805	reliability engineering;extreme programming;computer science;systems engineering;engineering;software engineering;management	SE	-69.22253555241741	23.686416327693383	159013
049a7e1f409182f396c4c3b7cb080e8cfc15a628	knowledge management and reflective practice in daily stand-up and retrospective meetings		Knowledge management and reflection are important aspects in daily stand-up and retrospective meetings, which contribute to agile teams continuous improvement. Research in knowledge management in agile software develop‐ ment has shown knowledge classifications which do not seem closely related with agile practitioners and current research has not treated agile reflective practice in detail. This research, which will focus on daily stand-up and retrospective meet‐ ings, addresses two objectives: (i) to investigate specific knowledge types (i.e. product, project and process knowledge) in everyday agile practice and knowl‐ edge management strategies applied by agile teams; (ii) to explore the actual knowledge involved in the meetings, which helps agile teams to perform reflec‐ tion and use that knowledge for reflection. Case studies will be applied for this research to analyse both meeting practices. It is expected that the research results will provide a framework for agile teams to manage knowledge and perform reflection, which would be useful for team and process improvement.	agile software development;knowledge management;reflection (computer programming);stand-up meeting	Yanti Andriyani	2017		10.1007/978-3-319-57633-6_21	medicine;knowledge management;nursing;management science	HCI	-71.33740668041702	18.735197843810585	159128
ee280d2a9acbc66cfbe1bb82d122c4e9a4365155	is scrum fit for global software engineering?		Distributed software engineering and agility are strongly pushing on today's software industry. Due to inherent incompatibilities, for years, studying Scrum and its application in distributed setups has been subject to theoretical and applied research, and an increasing body of knowledge reports insights into this combination. Through a systematic literature review, this paper contributes a collection of experiences on the application of Scrum to global software engineering (GSE). In total, we identified 40 challenges in 19 categories practitioners face when using Scrum in GSE. Among the challenges, scaling Scrum to GSE and adopting practices accordingly are the most frequently named. Our findings also show that most solution proposals aim at modifying elements of the Scrum core processes. We thus conclude that, even though Scrum allows for extensive modification, Scrum itself represents a barrier for global software engineering, and development teams have to customize Scrum properly to benefit from agile software development in GSE.	agile software development;generic stream encapsulation;image scaling;scrum (software development);software engineering;software industry;systematic review	Pernille Lous;Marco Kuhrmann;Paolo Tell	2017	2017 IEEE 12th International Conference on Global Software Engineering (ICGSE)	10.1109/ICGSE.2017.13		SE	-68.95812447112648	21.930001743198698	159543
fe77a2730aafcb45ea2ce433da64b4122ef0b7ed	collaboration engineering methodology: horizontal extension to accommodate project and program concerns		A Collaboration Engineering Methodology (CEM) comprises a set of defined, standardized, docu-mented, and discoverable objectives, deliverables, key actions, tools/templates, principles and policies for establishing effective, efficient, satisfying col-laborative work practices for highvalue organi-zational tasks. First-generation CEMs address design and development CE solutions. Existing CEMs, though, focus on the design/build phase, but lack the pre-design and post-build elements that are common to methodologies for adjacent disciplines. We use Design Science Research to situate existing design/build CEMs in the larger context of CE programs and projects. We develop and validate an extended CEM in four phases: 1) Opportunity Assessment, 2) Development, 3) Deployment, and 4) Improvement (ODDI). Phase 1 concerns CE portfolio management and CE project planning; Phase 2 encapsulates existing design/build CEMs; Phase 3 concerns roll-out planning, change management, and implementation; Phase 4 concerns continuous optimization of a deployed work practice. The ODDI model advances CE another step towards becoming a fully realized professional practice, but more research is still required to derive a complete a design theory for CE.	continuous optimization;discoverability;mathematical optimization;software deployment	Nils L. Randrup;Robert O. Briggs	2017			human–computer interaction;computer science;software engineering;methodology;management;process;collaboration	SE	-65.13616541618659	19.78287321551379	159953
9f93533b3d9690128c41c97b150abbb4458265a9	y2k: don't play it again, sam	y2k hype year 2000 press releases y2k compliant software developers engineering discipline profession;software maintenance;glass databases application software companies computer industry time measurement costs read write memory hard disks programming;professional aspects software development management software maintenance;professional aspects;software development;software development management	Judging by how many Year 2000 press releases cross my desk each month, making software Y2K compliant is a booming business. Warnings of calamity mixed with promises of an easy fix—it’s the same old tune over and over again, one I find disturbing. How much faith would you have in the legal profession, for example, if legions of attorneys aggressively sought to take on cases that involved suing their fellow lawyers for malpractice? Yet this is uncomfortably like what many in our industry do today: bill clients to fix problems caused by other software developers. If we are ever to be taken seriously as a profession or engineering discipline, we must look past the Y2K hype and hysteria to determine how the problem emerged, why it emerged, and what we can do to avoid similar situations in the future.	software developer;year 2000 problem	James Sanders	1998	IEEE Software	10.1109/52.676971	software quality management;software configuration management;computer science;engineering;operations management;software development;software engineering;software asset management;software walkthrough;software maintenance;management	SE	-68.99045897883731	26.918282412125734	159956
f6255b6eb9dcb07a203a59a92e8f0329cf841ea8	a perspective on software science	practical significance;software science;programming language barrier;new approach;additional research;measurement methodology	Measurement of programs is still a fairly subjective process. We can measure size, based on line ofcode or number ofstatements, but acceptance of these measures is not universal. Acceptance of lines of code, as an example, seems to be based on the view that although lines of code may be an imprecise measure, it is something that can be enumerated, and until something better is discovered we will continue to use it. There is a veiled invitation here to find something better.	source lines of code	Kenneth J. Christensen;George P. Fitsos;Charles P. Smith	1981	IBM Systems Journal	10.1147/sj.204.0372	computer science;systems engineering;software development;software engineering	SE	-66.58755530228503	31.410957860285876	160060
93617e0f634fb68313c13df58c452442d026b243	object-oriented software evolution and reengineering - editorial			code refactoring;software evolution	Eduardo Casais;Antero Taivalsaari	1997	TAPOS		database;resource-oriented architecture;software design description;systems engineering;component-based software engineering;software construction;software development;software analytics;social software engineering;software evolution;computer science	SE	-63.2995061632909	25.14484368003117	160092
088a40ddacf2171c65c21c3ffde0b77eaf76f973	testing: a roadmap	quality assurance;program understanding;software analysis;software testing;software maintenance;program comprehension;software engineering;software evolution;software development;software migration;software tools;software reengineering;tool adoption;tool evaluation;data reverse engineering;reverse engineering	Testing is an important process that is performed to support quality assurance. Testing activities support quality assurance by gathering information about the nature of the software being studied. These activities consist of designing test cases, executing the software with those test cases, and examining the results produced by those executions. Studies indicate that more than fifty percent of the cost of software development is devoted to testing, with the percentage for testing critical software being even higher. As software becomes more pervasive and is used more often to perform critical tasks, it will be required to be of higher quality. Unless we can find efficient ways to perform effective testing, the percentage of development costs devoted to testing will increase significantly. This report briefly assesses the state of the art in software testing, outlines some future directions in software testing, and gives some pointers to software testing resources.	pervasive informatics;software development;software testing;test case	Mary Jean Harrold	2000		10.1145/336512.336532	test strategy;reliability engineering;quality assurance;black-box testing;software modernization;verification and validation;regression testing;software performance testing;white-box testing;manual testing;system integration testing;computer science;systems engineering;engineering;acceptance testing;software evolution;software reliability testing;software development;software analysis pattern;software engineering;risk-based testing;operational acceptance testing;software testing;software maintenance;stress testing;reverse engineering;software quality analyst	SE	-63.24520287998205	30.138883888631202	160395
10faf34d1fbe170b3b0bc7d141161c03b5fce445	interaction design in free/libre/open source software development: a systematic mapping		Approaches for integrating interaction design into software development processes do not consider the specific development characteristics of free/libre/open source software (FLOSS). Researchers know the importance of integrating good practices of interaction design into the software development process. This paper aims to present a summary and analysis of methods, techniques, tools, strategies and approaches (MTTSA) to interaction design that have been proposed/used in the context of FLOSS development. A systematic mapping was performed to identify MTTSAs of interaction design proposed or used for/in the development of FLOSS. The results show that few studies have used MTTSA of interaction design in FLOSS context. No methods or techniques of interaction design proposed specifically for the development of FLOSS have found, and the majority of the selected papers do not present any type of validation through empirical studies. We hope that this paper provides an overview of studies that have used MTTSA of interaction design in FLOSS context, and becomes an initial effort to conduct new research proposals involving interaction design MTTSA and FLOSS development.	interaction design;open-source software;software development process	Daniel Domingos Alves;Ecivaldo de Souza Matos	2017		10.1145/3160504.3160515	empirical research;software development process;human–computer interaction;software;open-source software development;interaction design;computer science	HCI	-64.95868812975013	23.804230531263094	160490
cd83a93e876187a58d82d533895bf58b57045aea	multistage growth model for code change events in open source software development: an example using development of nagios	data models market research software mathematical model logistics computational modeling switches;source code software public domain software software quality;development period multistage growth model code change events open source software products open source software development information technology business it business oss development status product quality distributed contributors developmental structure source code change events growth curve complex evolutionary behavior	In recent years, many open source software (OSS) products have become popular and widely used in the information technology (IT) business. To successfully run IT business, it is important to properly understand the OSS development status. Having a proper understanding of development status is necessary to evaluate and predict the product quality. However, the OSS development status is not easy to understand, because it is often concurrently developed by many distributed contributors, and its developmental structure is complicated. To aid the understanding of the development status, there is an approach that models the trend of source code change events (evolution) with a growth curve. Although an application of growth curves seems to be a promising approach, there has been a big issue that a single growth curve is often unsuitable for modeling the whole evolution because of its complex evolutionary behavior. This paper proposes a multistage model that divides the whole development period into some stages, and applies a different growth curve to a different stage. The empirical investigation in this paper shows that the switching points of stages have meaningful associations with the release dates.	capability maturity model;firefox;multistage amplifier;nagios core;open sound system;open-source software;population dynamics;software development;software evolution;temporal logic	Hirohisa Aman;Akiko Yamashita;Takashi Sasaki;Minoru Kawahara	2014	2014 40th EUROMICRO Conference on Software Engineering and Advanced Applications	10.1109/SEAA.2014.47	kpi-driven code analysis;simulation;computer science;systems engineering;engineering;package development process;software development;software engineering;software construction;management;software development process;software quality	SE	-69.1557360131557	30.084320701686362	160546
da2a3de23788e1f0b4edc205f38ead22dfd0f5d3	the accidental agilists: one team's journey from waterfall to agile	agile software development;application development;software;waterfall methodology;testing;software engineering;web advising system project;software engineering internet;internet;custom application development;programming documentation business testing schedules education software;organizational change agile software development;organizational change;business;schedules;mission critical application;web application development;accidental agilists;programming;documentation;mission critical application accidental agilists waterfall methodology web application development custom application development web advising system project	This case study outlines one team's shift from the traditional waterfall methodology to an agile approach for Web and custom application development. The transformation occurred by accident over the course of a Web advising system project at The Ohio State University. Using the five stages of grieving as a metaphor, we will describe how the team moved from denial that the waterfall approach was failing to acceptance that agile practices would be the best way to deliver the mission-critical application. In the end, the entire team re-envisioned itself, transformed its business practices, and has evolved into a significantly more agile organization.	accident (philosophy);agile software development;awareness;failure;mission critical;waterfall model;whole earth 'lectronic link	Mary Beth Snapp;Diane Dagefoerde	2008	Agile 2008 Conference	10.1109/Agile.2008.68	simulation;agile usability engineering;systems engineering;engineering;software engineering;agile software development	Robotics	-68.3901309610198	25.064894922662404	160624
ee509067a4c74429b2c8560d8b6f4661f5759aba	position paper: how to solve the reuse problem	electrical capacitance tomography;computer languages;history;software systems;runtime;telephony;shape;writing;software tools;writing software tools electrical capacitance tomography software quality telephony computer languages history shape software systems runtime;software quality	We need to radically rethink the way that we approach software production. Much of the focus in the industry is on programming languages and tools. However, we keep on writing the same pi ces of software over and over, and the tools are not making a difference. The tools allow us to write the software more quickly, and sometimes with higher quality, but they simply do not help with reuse, which would allow us not to write that software at all. Early in the history of the telephone service, there were a large number of people employed as plugboard operators. One might have predicted that this would eventually become the world’s most labor-intensive industry. The solution was not to improve productivity of these operators, but to change the way that telephone switching worked. We need a similar change to the way that software is constructed.	plugboard;programming language;telephone exchange	Tony Williams	1998		10.1109/ICSR.1998.685770	software visualization;verification and validation;computing;software sizing;computer science;package development process;backporting;social software engineering;theoretical computer science;software framework;component-based software engineering;software development;software design description;software engineering;software construction;software walkthrough;resource-oriented architecture;software deployment;software quality;software system;computer engineering	SE	-68.67159355144834	27.95149357072176	160836
171e0993af8432cb3b4325f8429bb6c525b5529a	ada: a promising beginning	computer languages;application software;government;natural languages;computer industry;application software standards development government natural languages computer languages real time systems documentation program processors computer industry software standards;standards development;software standards;program processors;documentation;real time systems	DoDu0027s standardization on Ada will encourage development of Ada-based products benefitting nonmilitary as well as military users.	ada	William E. Carlson	1981	Computer	10.1109/C-M.1981.220486	computing;application software;documentation;computer science;operating system;software engineering;programming language;government;software system	HCI	-68.45000606943705	27.969268992309953	160925
1f11325b1bef4fb21085e2b66309cbc0735eac5b	the evolution of a system test process [for motorola gsm products]	system test organisation;system reliability;reliability;telecommunication network reliability;hardware evolution;system test process evolution;cellular radio;communication complexity;system testing gsm telephony mobile handsets cellular networks computer architecture computer networks reliability hardware couplings;cellular networks;telecommunication computing;complexity;telephony;telecommunication equipment testing cellular radio digital radio software reliability telecommunication network reliability telecommunication computing communication complexity;computer networks;computer architecture;telecommunication equipment testing;software evolution;digital cellular telephone system;complex system;digital radio;test coverage;mobile handsets;system testing;future challenges;test coverage system test process evolution system reliability system test organisation future challenges digital cellular telephone system feature test complexity motorola gsm products hardware evolution software evolution;couplings;gsm;software reliability;feature test;motorola gsm products;hardware	Test organisations are now widely recognised as being central in the creation and successful arrival to market of complex systems. As such it is critical that they constantly evolve and mature. A mature test organisation will typically have evolved from testing quality into the product to concentrating largely on analysing and verifying system reliability. During this evolution, the organisation moves from being perceived as at best a necessary part of the process to being recognised by both customers and other internal organisations as being a highly effective and valued operation. This paper will describe the evolution of the system test organisations for Motorola's GSM Systems Division (GSD). It will show how Motorola's GSD test organisations are organised, the methodologies and processes employed, how these organisations have matured over the past nine years and how they will evolve to meet the challenges in the future.	system testing	Simon H Martin;Robert Bleck;Chryssa Dislis;Des Farren	1999		10.1109/TEST.1999.805796	gsm;reliability engineering;embedded system;cellular network;digital radio;complex systems;electronic engineering;complexity;real-time computing;telecommunications;computer science;engineering;software evolution;software engineering;reliability;communication complexity;coupling;code coverage;telephony;system testing;software quality;computer network;computer engineering	Logic	-68.14702821885412	28.399582429508683	160995
95ae7066eb53af5b533208f43cdc8d72edd28038	an empirical study of the software development process, including its requirements engineering, at very large organization: how to use data mining in such a study		Very Large Organization (VLO) develops and manufacturers hardware and software products, with each product being developed in its own project. Each project, from its inception, maintains a database that contains a wealth of data pertaining to its software development lifecycle. To empirically study VLO’s software development process, the authors mined the data from seven consecutive VLO projects to determine whether the data exhibit any anomalies and whether these anomalies can help assess a project’s level of success. Some anomalies provide evidence of what VLO does well, while other anomalies highlight possible areas of improvement. Through the anomalies in the mined data, the organization can direct additional focus and research to specific areas of the development process, particularly its requirements engineering, to improve the likelihood of success for future projects. While describing the results of the empirical study, the paper also shows how such a study can be conducted even when the mined data are not very detailed.	data mining;database;mined;requirements engineering;software development process	Colin M. Werner;Daniel M. Berry	2017		10.1007/978-981-10-7796-8_2	systems engineering;empirical research;software development process;requirements engineering;software;project management;engineering	SE	-69.03640208802226	22.067204698948817	161140
9c0bfc268e93f56b862deb03f2d8fe04ac5a62bd	application of multi attribute utility theory in multiple releases of software		One of the important applications of software reliability models is the determination of software release time. Most of the existing studies on this topic use models based on non homogeneous Poisson process with a bounded mean value function. Multi up gradation based software reliability growth model is developed for successive release modelling and analysis. Based on this model, maximum fault removal for upgraded software and optimal release time of upgraded software are investigated as well. This paper proposes a new practical method for determining when to stop software testing considering failure intensity and cost as two factors simultaneously. This issue has been widely known as the optimal release problem of software product. The proposed new decision model based on multi-attribute utility analysis is tested on the real world data sets. In addition, the proposed decision model can help companies to make a rational decision on the optimal timing of the software.	utility	P. K. Kapur;Jyotish N. P. Singh;Ompal Singh	2015	Int. J. Systems Assurance Engineering and Management	10.1007/s13198-014-0243-4	reliability engineering;software sizing;computer science;software reliability testing;operations management;data mining;software testing;goal-driven software development process;software metric;statistics	SE	-63.093916435391684	31.363344876629615	161235
0519d73c2dfc11a6a785dc360c050f7774ec476d	characterizing software developers by perceptions of productivity		Understanding developer productivity is important to deliver software on time and at reasonable cost. Yet, there are numerous definitions of productivity and, as previous research found, productivity means different things to different developers. In this paper, we analyze the variation in productivity perceptions based on an online survey with 413 professional software devel-opers at Microsoft. Through a cluster analysis, we identify and describe six groups of developers with similar perceptions of productivity: social, lone, focused, balanced, leading, and goal-oriented developers. We argue why personalized recommendations for improving software developers' work is important and discuss design implications of these clusters for tools to support developers' productivity.	cluster analysis;personalization;software developer	André N. Meyer;Thomas Zimmermann;Thomas Fritz	2017	2017 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)	10.1109/ESEM.2017.17	computer science;systems engineering;software	SE	-75.08369171134011	21.688328635013008	161339
80d611648fd40cd90eb3dc2b549d1699015d586a	the unnecessary tension between process and programmer - some of my best friends use an agile software process	software process	"""Today all organizations are required to achieve process compliance, be it ISO 9000, Six Sigma, CMM, Sarbanes-Oxley, Balanced Score Cards etc. Each of these compliance activities seeks to ensure that the company has the appropriate processes in place to ensure that the company can serve the needs of their customers and shareholders. Most mandate some form of continuous improvement measurement, dare I say metrics, so that the organization can monitor its improvement. Many of these efforts were originally targeted at improving manufacturing, operations or finance, but they are having an increasing impact on the IT and SE. Also, while these efforts were initially applied to larger companies, they have trickled down to the smaller ones who supply these larger firms. Having a documented process has therefore become a mandatory requirement for software development. It isn't sufficient to say """" we are doing Waterfall, Iterative or Agile; go away and let us get our work done """". Like it or not, everyone needs to be able to articulate the process they use for software development. It is time for developers to take ownership of the process side of things so that they can stop fighting it. Process is like democracy: if you don't participate, you get the process you deserve. However, there is no need for process tension to obstruct productive development! Ask any software developer and they will tell you if they feel they are working in a good software culture, and most who answer no will say that they would like to be. However, ask most developers how they feel about their company's software process and they will complain bitterly. Yet the best software cultures always have very disciplined processes which developers follow almost to a fault. Indeed the culture is defined by a unique combination of people and process. The open source Apache foundation is an example of"""	agile software development;capability maturity model;embrace, extend and extinguish;iterative method;open-source software;programmer;software developer;software development process;vocabulary;waterfall model	Dave Thomas	2006	Journal of Object Technology	10.5381/jot.2006.5.1.c1	team software process;real-time computing;computer science;systems engineering;package development process;software development;software engineering;software walkthrough;software development process	SE	-69.39521048182303	25.094750176260312	161434
1d134fe57b997a7f16f8f4f32fb03c85d23fc89d	towards a practical maintainability quality model for service-and microservice-based systems		Although current literature mentions a lot of different metrics related to the maintainability of Service-based Systems (SBSs), there is no comprehensive quality model (QM) with automatic evaluation and practical focus. To fill this gap, we propose a Maintainability Model for Services (MM4S), a layered maintainability QM consisting of Service Properties (SPs) related with automatically collectable Service Metrics (SMs). This research artifact created within an ongoing Design Science Research (DSR) project is the first version ready for detailed evaluation and critical feedback. The goal of MM4S is to serve as a simple and practical tool for basic maintainability estimation and control in the context of SBSs and their specialization Microservice-based Systems (μSBSs).	ansi escape code;microservices;partial template specialization	Justus Bogner;Stefan Wagner;Alfred Zimmermann	2017		10.1145/3129790.3129816	maintainability;computer science;microservices;collectable;systems engineering;design science research;reliability engineering	SE	-64.32917116571423	19.90064621424343	161452
77077e5d5faaeef25432771906df1987b41c052d	formal methods versus software engineering: is there a conflict?	software engineering;formal method	There has been a sigfilcant amount of controversy over the years, sparked lmgely by the publication of two papers [1,2] arguing that formal methods are either totally impractical as a means of gaining enhanced assurance or that the entire notion of mathematically establishing the correctness of a program is theoretically ill-founded. The result has been a sometimes vitriolic debate seeming to pose the fortnaf methods community against the rest of software engineering.	correctness (computer science);formal methods;software engineering	William D. Young	1991		10.1145/120807.120824	reliability engineering;personal software process;verification and validation;formal methods;software engineering process group;software verification;computer science;systems engineering;social software engineering;component-based software engineering;software development;software engineering;software construction;formal specification;software walkthrough;programming language;software development process;software requirements;software peer review	SE	-65.76996191736649	24.889006137922532	161677
f7c7ce5903ec40ff9ffbe198c54cabf38eb524b3	case studies in just-in-time requirements analysis	agile;project management;formal specification;agile requirements analysis;software organizations best practices computer architecture internet browsers communities;requirements engineering just in time requirements analysis project inception requirements practices open source software projects project management;requirements;public domain software;systems analysis;just in time;analysis;systems analysis formal specification just in time project management public domain software software development management;software development management	Many successful software projects do not follow the commonly assumed best practice of engineering well-formed requirements at project inception. Instead, the requirements are captured less formally, and only fully elaborated once the implementation begins, known as `just-in-time' requirements. Given the apparent disparity between best practices and actual practices, several questions arise. One concerns the nature of requirements engineering in non-traditional forms. What types of tools and practices are used? Another is formative: what types of problems are encountered in just-intime requirements, and how might we support organizations in solving those problems? In this paper we conduct separate case studies on the requirements practices of three open-source software projects. Using an individual task as the unit of analysis, we study how the project proceeds from requirement to implementation, in order to understand how each project manages requirements. We then comment on the benefits and problems of just-in-time requirements analysis. This allows us to propose research directions about requirements engineering in just-in-time settings. In particular, we see the need to better understand the context of practice, and the need to properly evaluate the cost of decisions. We propose a taxonomy to describe the requirements practices spectrum from fully formal to just-in-time.	best practice;binocular disparity;intime rtos / intime for windows;just-in-time compilation;mathematical optimization;open-source software;requirement;requirements analysis;requirements engineering;requirements management;software development;taxonomy (general);well-formed element	Neil A. Ernst;Gail C. Murphy	2012	2012 Second IEEE International Workshop on Empirical Requirements Engineering (EmpiRE)	10.1109/EmpiRE.2012.6347678	requirements analysis;software requirements specification;requirements management;market requirements document;requirement prioritization;extreme programming practices;business requirements;software project management;systems engineering;engineering;knowledge management;software design;requirement;software engineering;needs analysis;system requirements specification;requirements elicitation;functional specification;requirements engineering;non-functional testing;non-functional requirement;software requirements;requirements traceability	SE	-67.2785547368774	22.60350626653844	162035
f0e5c137a9cc0583ef4a5bcfb4366da9c596d262	prototype tasks: improving crowdsourcing results through rapid, iterative task design		Low-quality results have been a long-standing problem on microtask crowdsourcing platforms, driving away requesters and justifying low wages for workers. To date, workers have been blamed for low-quality results: they are said to make as little effort as possible, do not pay attention to detail, and lack expertise. In this paper, we hypothesize that requesters may also be responsible for low-quality work: they launch unclear task designs that confuse even earnest workers, under-specify edge cases, and neglect to include examples. We introduce prototype tasks, a crowdsourcing strategy requiring all new task designs to launch a small number of sample tasks. Workers attempt these tasks and leave feedback, enabling the requester to iterate on the design before publishing it. We report a field experiment in which tasks that underwent prototype task iteration produced higher-quality work results than the original task designs. With this research, we suggest that a simple and rapid iteration cycle can improve crowd work, and we provide empirical evidence that requester “quality” directly impacts result quality.	agile software development;crowdsourcing;downstream (software development);edge case;iteration;prototype	Snehalkumar S. Gaikwad;Nalin Chhibber;Vibhor Sehgal;Alipta Ballav;Catherine A. Mullings;Ahmed Nasser;Angela Richmond-Fuller;Aaron Gilbee;Dilrukshi Gamage;Mark E. Whiting;Sharon Zhou;Sekandar Matin;Senadhipathige S. Niranga;Shirish Goyal;Dinesh Majeti;Preethi Srinivas;Adam Ginzberg;Kamila Mananova	2017	CoRR		neglect;computer science;simulation;empirical evidence;job design;small number;field experiment;crowdsourcing	HCI	-71.08196985642466	25.50110172367415	162041
b68d63d0ba1d18953296c00b497e1b4bae6b196c	an approach to erp testing using services	automated testing;quality assurance;software testing;application software;software complexity;automatic testing;erp testing;packaging;business;enterprise resource planning;test methods;software standards;erp implementation;enterprise resource planning packaging software testing software packages automatic testing application software floors software standards business software quality;automated testing software testing erp testing software quality;software quality;business process;floors;software packages	Enterprise packages software solutions are becoming an increasingly popular choice for organizations aiming to streamline their business processes. However, as the software complexity reaches new heights, package vendors are faced with critical concerns regarding quality assurance. Traditional testing methods are not designed to meet all the challenges posed by ERP implementation. This paper will try to suggest a novel approach to dealing with the complexity aspects of testing. We will try and demonstrate how the technical advancements introduced by SOA enable the adoption of such approach by many package vendors.	adobe streamline;business process;erp;programming complexity;service-oriented architecture	Sagi Schliesser	2007	IEEE International Conference on Software-Science, Technology & Engineering (SwSTE'07)	10.1109/SwSTE.2007.17	reliability engineering;quality assurance;packaging and labeling;application software;computer science;systems engineering;software engineering;software testing;business process;test method;software quality;programming complexity	SE	-65.21114264072256	27.881627542439894	162211
113678a92fc971ef4872b081f159a8f223135dcd	the state of metrics in software industry	databases;software metrics;software measurement;job shop scheduling;metrics in software industry;computer industry software quality software metrics costs job shop scheduling software measurement databases information technology computer science size measurement;dp industry;information technology;size measurement;software reliability dp industry software houses software metrics software quality;computer industry;state of metrics;software houses;product metrics;software reliability software industry software quality software metrics product metrics;software industry;software metric;metrics in software industry software metrics cost of defects state of metrics;cost of defects;computer science;software reliability;software quality	The role of metrics in software quality is well recognized. However, software metrics are yet to be standardized and integrated into development practices across software industry. While process, project, and product metrics share a common goal of contributing to software quality and reliability, utilization of metrics has been at minimum. This work is an effort to bring more attention to software metrics. It examines the practices of metrics in software industry and the experiences of some organizations that have developed, promoted, and utilized variety of software metrics. As various types of metrics are being developed and used, these experiences show evidence of benefits and improvements in quality and reliability.	experience;software industry;software metric;software quality	Mauricio John Ordoñez;Hisham M. Haddad	2008	Fifth International Conference on Information Technology: New Generations (itng 2008)	10.1109/ITNG.2008.106	job shop scheduling;personal software process;verification and validation;software quality management;software sizing;computer science;social software engineering;software development;software engineering;software construction;software walkthrough;information technology;software deployment;software quality control;software quality;software metric;green chemistry metrics;software quality analyst;software peer review	SE	-64.80101732798919	28.232528640038833	162238
b361e8aa105570d1a50e2e2ba0d400b296c5dbd7	nine things you can do with old software	software architecture economics;software;technological innovation;software measurement;software maintenance;software systems;presses;aging;assembly;computer architecture;software architecture;lines of code;casting;software maintenance costs power generation economics assembly software systems casting aging programming software measurement technological innovation;business;software development life cycle;organizations;economics;software development life cycle software architecture software architecture economics;programming;power generation economics;solids	Every new line of code quickly becomes legacy. When that legacy mounts, it forms a significantly massive pile of software, which cannot be ignored. This article discusses what we can do intentionally with such piles, from abandonment to evolution and many things in between.	source lines of code	Grady Booch	2008	IEEE Software	10.1109/MS.2008.139	software architecture;programming;casting;systems engineering;organization;engineering;software engineering;solid;assembly;systems development life cycle;software maintenance;software measurement;source lines of code;software system;computer engineering	SE	-68.97551356156683	26.99647427338437	162546
8a90d0159b2a6984c678139f1a0b6fa604238af7	on the need for a new generation of code review tools		Tool support for change-based code review is gaining widespread acceptance in the industry. This indicates that the current generation of tools is well-aligned to current code review practices. Nevertheless, we believe that further improvements in code review tooling can lead to increased review efficiency and effectiveness. In this paper, we combine results from a qualitative study and results from the literature to substantiate this claim. We derive promising improvement areas and provide an overview of existing research in these areas. A common attribute of these improvements is that they trade flexibility for reviewer support. As flexibility is one of the main characteristics of the current generation of code review tools in Hedberg’s classification of review tool generations, we regard these coming tools as part of a new generation of code review tools.		Tobias Baum;Kurt Schneider	2016		10.1007/978-3-319-49094-6_19	code review	HPC	-72.49319417912434	24.466211710529425	162935
326a2f3705dc7e761e1753aadf95259d7e0e0596	construct validity in software engineering research and software metrics		Construct validity is essentially the degree to which our scales, metrics and instruments actually measure the properties they are supposed to measure. Although construct validity is widely considered an important quality criterion for most empirical research, many software engineering studies simply assume that proposed measures are valid and make no attempt to assess construct validity. Researchers may ignore construct validity because evaluating it is intrinsically difficult, or due to lack of specific guidance for addressing it. In any case, some research inevitably produces erroneous conclusions, because due to invalid measures. This article therefore attempts to address these problems by explaining the theoretical basis of construct validity, presenting a framework for understanding it, and developing specific guidelines for assessing it. The paper draws on a detailed example involving 15 software metrics, which ostensibly measure the size, coupling and cohesion of Java classes.	cohesion (computer science);java;software engineering;software metric	Paul Ralph;Ewan D. Tempero	2018		10.1145/3210459.3210461	systems engineering;software engineering;empirical research;management science;software metric;java;construct validity;computer science	SE	-66.73311208095096	31.22380564436411	163341
fd153d2239c49e59c69db0b1fdb43664be56f843	is project management: size, complexity, practices and the project management office	performance measure;project management office;project management;application software;project manager;size measurement;project management size measurement industrial relations performance analysis testing management information systems humans application software cultural differences costs;testing;performance analysis;industrial relations;management information systems;survey data;humans;cultural differences	The current research is an exploratory investigation into current IS project management practices related to projects of varying size and complexity across diverse industries Survey data on a broad range of project management issues was collected from 129 IS project managers. The relationships between project size and complexity with 13 project management practices and 3 project performance measures were analyzed. In addition, the influence of a PMO on the use of standardized project management practices and project performance was empirically tested. Our findings suggest that IS project size influences budget and project quality, while project complexity influences the use of specific project management practices. The PMO is empirically linked to project budget.	complexity	Nancy L. Martin;John Michael Pearson;Kimberly A. Furumo	2005	Proceedings of the 38th Annual Hawaii International Conference on System Sciences	10.1109/HICSS.2005.359	basis of estimate;project management;application software;extreme project management;program management;work breakdown structure;earned value management;software project management;opm3;computer science;knowledge management;survey data collection;management science;software testing;industrial relations;project management triangle;management;project charter;schedule;cultural diversity;project planning;project portfolio management	SE	-72.5025623705804	19.808669698002742	163444
14752df3f86ae27d4446a19390ec4809cb65fd4a	assuring data trustworthiness - concepts and research challenges	data trustworthiness;data sharing;data integrity;policy;data integrity and quality;decision maker;data quality;security;security policy;situation assessment	Today, more than ever, there is a critical need to share data within and across organizations so that analysts and decision makers can analyze and mine the data, and make effective decisions. However, in order for analysts and decision makers to produce accurate analysis and make effective decisions and take actions, data must be trustworthy. Therefore, it is critical that data trustworthiness issues, which also include data quality, provenance and lineage, be investigated for organizational data sharing, situation assessment, multi-sensor data integration and numerous other functions to support decision makers and analysts. The problem of providing trustworthy data to users is an inherently difficult problem that requires articulated solutions combining different methods and techniques. In the paper we first elaborate on the data trustworthiness challenge and discuss a framework to address this challenge. We then present an initial approach for assess the trustworthiness of streaming data and discuss open research directions.	trust (emotion)	Elisa Bertino;Hyo-Sang Lim	2010		10.1007/978-3-642-15546-8_1	data governance;decision-making;data quality;computer science;knowledge management;security policy;information security;data integrity;data mining;database;situation analysis	DB	-76.87035441577848	19.45367632183964	163807
91e53cc30f5794a2da0f59997de38e632ec7f682	on the relationship between newcomer motivations and contribution barriers in open source projects		There has been extensive research on the the factors that motivate software developers to contribute to an Open Source Software (OSS) project. Contribution barriers are the counter-side to motivations and prevent newcomers from joining the OSS project. This study searches for relations between motivations and contribution barriers with a web-based survey of 117 developers who had recently contributed their first patch to either Mozilla or GNOME.  The results substantiate the hypothesis that newcomers' motivations mirror their mental models of the OSS project they are going to contribute to, and that the mental model determines the impact of contribution barriers. More generally, we propose a new model for the joining process to an OSS project that takes social properties, motivations, and contribution barriers into account.	gnome;mental model;open sound system;open-source software;software developer;web application	Christoph Hannebauer;Volker Gruhn	2017		10.1145/3125433.3125446	software;systems engineering;knowledge management;engineering	SE	-74.42378258667672	21.43292950723874	163895
abe269076b072e14918921a25f10757747fa3493	"""responsible data science: using event data in a """"people friendly"""" manner"""		The omnipresence of event data and powerful process mining techniques make it possible to quickly learn process models describing what people and organizations really do. Recent breakthroughs in process mining resulted in powerful techniques to discover the real processes, to detect deviations from normative process models, and to analyze bottlenecks and waste. Process mining and other data science techniques can be used to improve processes within any organization. However, there are also great concerns about the use of data for such purposes. Increasingly, customers, patients, and other stakeholders worry about “irresponsible” forms of data science. Automated data decisions may be unfair or nontransparent. Confidential data may be shared unintentionally or abused by third parties. Each step in the “data science pipeline” (from raw data to decisions) may create inaccuracies, e.g., if the data used to learn a model reflects existing social biases, the algorithm is likely to incorporate these biases. These concerns could lead to resistance against the large-scale use of data and make it impossible to reap the benefits of process mining and other data science approaches. This paper discusses Responsible Process Mining (RPM) as a new challenge in the broader field of Responsible Data Science (RDS). Rather than avoiding the use of (event) data altogether, we strongly believe that techniques, infrastructures and approaches can be made responsible by design. Not addressing the challenges related to RPM/RDS may lead to a society where (event) data are misused or analysis results are deeply mistrusted.	algorithm;bottleneck (software);confidentiality;data science	Wil M. P. van der Aalst	2016		10.1007/978-3-319-62386-3_1		ML	-76.15773932455878	25.766340584698863	164021
e7dfeb236faeb3bcaf5556228332caab3bc1f810	a comparison of three modes of collaboration for software development	software development;risk management;supply chain management	In the current environment of global collaboration, multiple models for collaborative ventures have be n introduced. We consider traditional, contractual interactions a well as three modes of collaboration—supply-chain management, a standard virtual organization, and in ter-organizational collaborative software developme nt (ICSD). After outlining multiple characteristics of these m odes, and their strengths and weaknesses, we examin e how to select an approach for a software project, and char a terize non-software-development applications for which an ICSD approach may be appropriate. Each of these ca n then be used as input in selecting an optimal mod e and practices for the project.	collaborative software;information flow (information theory);inorganic crystal structure database;interaction;knowledge management;predispositioning theory;risk management;scm;software development;software project management;virtual organization (grid computing)	Mojgan Mohtashami;Vassilka D. Kirova;Thomas J. Marlowe;Fadi P. Deek	2009			virtual organization;supply chain management;knowledge management;computer science;collaborative software;management science;software;software development;software engineering process group;social software engineering;lean software development	SE	-64.59953089995697	22.00258423231216	164317
06d8706d92f29d6cdd462fd9930dc13253b7407c	teaching enterprise software development in undergraduate curriculum	experiential learning;distributed system;enterprise systems;software development process;agile development;software development;system development;enterprise system;object oriented analysis;systems development;teaching	This paper presents a model upper-division capstone computer science course that teaches the fundamentals and develops skills for enterprise software development. The course assumes strong fundamentals in computer science and experience in systems-analysis and object-oriented analysis. The software is developed for a business client and the client is involved during the software development process. Fundamentals of distributed systems development, Internet and Web architecture is presented together with the facets of J2EE as a representative platform for such development.  This approach facilitates experiential learning and moves away from the classic learning-through-academic-exercise. The class works as a software team and through meetings, assignments, and discussion an agile development process is followed to deliver product for the customer.	agile software development;capstone (cryptography);computer science;distributed computing;enterprise software;internet;java platform, enterprise edition;software development process	Sudharsan R. Iyengar	2009		10.1145/1631728.1631739	functional software architecture;education;personal software process;enterprise system;enterprise software;crowdsourcing software development;computer science;systems engineering;engineering;knowledge management;package development process;social software engineering;component-based software engineering;software development;software engineering;iterative and incremental development;software as a service;systems development life cycle;software walkthrough;empirical process;software analytics;management;lean software development;software deployment;goal-driven software development process;software development process;software system;software peer review	SE	-65.39138277719378	25.202519775800287	164536
002b3bc35200539405ac14295d3c2c4bdd5ceb7a	requirements researchers: are we really doing research?	requirements researcher	A few years ago, Davis and Hickey (2002) suggested that a reason why the results of requirements engineering research are not used in practice is that requirements engineering researchers do not practice what they preach: they do not analyze the problems of requirements engineering practice, and therefore their solutions do not address these problems. Although I agree with this diagnosis, I think it must be taken one step further in order to achieve a vision of a solution. The additional step that I propose here is to realize that currently, most requirements engineering researchers do not do research. Many of us create unvalidated designs, and move on from one unvalidated design to the other. The remedy that I propose is that we should learn to distinguish design from research, and start doing research. What we should do research about is the engineering process, so let me first explain what I mean by ‘‘engineering’’.	requirement;requirements engineering	Roel Wieringa	2005	Requirements Engineering	10.1007/s00766-005-0013-6	systems engineering;requirements engineering;computer science	SE	-65.06739689757053	18.794632511707867	164619
c16761bfc6e29830a7eb40545e4ef6b27fdf8a83	guiding requirements scoping using roi: towards agility, openness and waste reduction	software;waste reduction data visualisation formal specification formal verification software cost estimation systems analysis;investments;software cost estimation;formal specification;efficiency;economic efficiency;biological system modeling;scoping decision making;cost estimation waste reduction roi disproportionate wasted investment requirements visualization scoping decision making;data visualisation;waste reduction;formal verification;systems analysis;datavetenskap datalogi;production;requirements visualization;computer science;economics;economics requirements visualization process evaluation scope efficiency cost estimation;cost estimation;disproportionate wasted investment;roi;process evaluation;scope;data models;biological system modeling investments data models production software computer science economics	We present a model for supporting scoping decisions that is based on an analysis of the ROI for a given feature. Employing a ROI threshold value for making scoping decisions, the utility of the model was investigated using data from a single large project and identified a group of outlying features responsible for a disproportionate wasted investment. These initial results are promising and indicate that further investigation and validation efforts are warranted.	openness;region of interest;requirement;scope (computer science)	Krzysztof Wnuk;David Callele;Björn Regnell	2010	2010 18th IEEE International Requirements Engineering Conference	10.1109/RE.2010.62	data modeling;systems analysis;return on investment;program evaluation;formal verification;computer science;systems engineering;engineering;operations management;formal specification;management science;efficiency;programming language;management;economic efficiency;data visualization;cost estimate	SE	-70.94326887288366	20.24579243235189	164954
3b3229e39494e0392ddc92b2199f3a8cba00eed1	magnet or sticky? an oss project-by-project typology	magnet;sticky;developer migration;open source	For Open Source Software (OSS) projects, retaining existing contributors and attracting new ones is a major concern. In this paper, we expand and adapt a pair of population migration metrics to analyze migration trends in a collection of open source projects. Namely, we study: (1) project stickiness, i.e., its tendency to retain existing contributors and (2) project magnetism, i.e., its tendency to attract new contributors. Using quadrant plots, we classify projects as attractive (highly magnetic and sticky), stagnant (highly sticky, weakly magnetic), fluctuating (highly magnetic, weakly sticky), or terminal (weakly magnetic and sticky). Through analysis of the MSR challenge dataset, we find that: (1) quadrant plots can effectively identify at-risk projects, (2) stickiness is often motivated by professional activity and (3) transitions among quadrants as a project ages often coincides with interesting events in the evolution history of a project.	biological anthropology;django;open sound system;open-source software;software engineer;sticky bit	Kazuhiro Yamashita;Shane McIntosh;Yasutaka Kamei;Naoyasu Ubayashi	2014		10.1145/2597073.2597116	magnet;simulation;engineering	SE	-69.40247796382002	30.464067802029806	165194
89baa357c2889dd7ae20dc77363b0e05ccad719c	evolutionary coupling measurement: making sense of the current chaos	measurement;evolutionary coupling;measurement theory	Objective: The aim of this research is to evaluate the measurement of evolutionary coupling (EC) in software artefacts from a measurement theory perspective.#R##N##R##N#Background: Evolutionary coupling (EC) can be defined as the implicit relationship between two or more software artefacts which are frequently changed together. Previous studies on EC show that EC measures which are based on software change history information play an important role in measuring software quality and predicting defects. The many previous EC measures published are disparate and no comprehensive evaluation of the current EC measures exists. Therefore it is hard for researchers and practitioners to compare, choose and use EC measures.#R##N##R##N#Methods: We define 19 evaluation criteria based on the principles of measurement theory and metrology. We evaluate previously published EC measures by applying these criteria.#R##N##R##N#Results: Our evaluation results revealed that current EC measurement has the particular weaknesses around establishing sound empirical relation systems, defining detailed and standardised measurement procedures as well as scale type and mathematical validation.#R##N##R##N#Conclusions: We provide information about the quality of existing EC measures and measurement methods. The results suggest that there is more work to be done to put EC measurement on a firm footing that will enable the reliable measurement of EC and the accurate replication of EC measurement.		Serkan Kirbas;Tracy Hall;Alper Sen	2017	Sci. Comput. Program.	10.1016/j.scico.2016.10.003	management science;operations research;measurement	Theory	-70.03144240233324	30.725721417341084	165358
0c0950f7db34dc86e705c79ef743b74cfb14c3c4	performance measurement systems must be engineered	process model;performance measurement systems;performance measurement;design and maintenance;requirements;life cycle;empirical study	The aim of this paper, which puts special emphasis on IT-related aspects, is threefold. • First, it defines requirements a modern Performance Measurements System (PMS) should meet. The list of requirements generated can be used both to assess a current PMS, and to identify ways to improve an existing PMS. • Second, it reports the findings of an empirical study, which seeks to identify the shortcomings of existing PMSs. • Third, a life cycle for PMSs is suggested.	requirement;system of measurement	Peter Kueng;Andreas Meier;Thomas Wettstein	2001	CAIS		engineering;empirical research;performance measurement;reliability engineering;systems engineering	SE	-68.88024219443916	19.06226317664335	165443
e9f0648c9243a5d9a9c6835b53f1e3420e104f71	risk assessment for enterprise resource planning (erp) system implementations: a fault tree analysis approach	risk management;erp system;system usage failure;probabilistic risk assessment;risk factors;enterprise resource planning;risk assessment;erp implementation;fault tree analysis;high risk	Enterprise resource planning ERP system implementations are often characterised with large capital outlay, long implementation duration, and high risk of failure. In order to avoid ERP implementation failure and realise the benefits of the system, sound risk management is the key. This paper proposes a probabilistic risk assessment approach for ERP system implementation projects based on fault tree analysis, which models the relationship between ERP system components and specific risk factors. Unlike traditional risk management approaches that have been mostly focused on meeting project budget and schedule objectives, the proposed approach intends to address the risks that may cause ERP system usage failure. The approach can be used to identify the root causes of ERP system implementation usage failure and quantify the impact of critical component failures or critical risk events in the implementation process.	erp;enterprise resource planning;fault tree analysis;risk assessment	Yajun Zeng;Miroslaw J. Skibniewski	2013	Enterprise IS	10.1080/17517575.2012.690049	reliability engineering;risk assessment;fault tree analysis;risk analysis;it risk management;risk management;systems engineering;engineering;operations management;probabilistic risk assessment;risk factor	SE	-69.88067454171053	21.485600700684387	165744
ab845d60258c626bb91c0f56ae8f742954fccde7	the documentation of quality engineering: applying use cases to drive change in software engineering models	specifications;text analysis;use cases;financial services;software engineering;requirements engineering;iterative methods;design method;requirement engineering;software development;rhetorical genre theory;waterfall methods;software design;iteration method;use case;software engineering practices	"""This paper examines how documentation is used to create """"quality"""" engineering processes in software development, focusing on recent industry trends of adopting use case driven software engineering models, to investigate a phenomenon that in this paper I call """"genre dumping."""" The paper aims to address questions about how software development methods change under a use-case driven model. For example, is it really that easy to adopt the use case methodology? The paper draws from a 24-month case study of a small cross-disciplinary team of software designers, developers, testers, and managers who are helping build a large in-house application for a multinational financial services corporation called """"Financial Capital"""" (pseudonym). This project was selected for study because a use case driven model was being applied to explicitly change software engineering practices: use cases were newly adopted and thus unfamiliar to those involved in the software development project.  Presented are selected results of qualitative and quantitative analyses of textual and interview data. The findings are interpreted using rhetorical genre theory, which features a large and growing body of workplace research about the ways documents enable (and constrain) people to get work done. The results show that textual features of the documents of the older design methods persist in the newly adopted use cases and that readers' approaches to text-related meaning making also persist, indicating generic recurrence. The findings also show that conflict occurs at the same sites where recurrence occurs. The paper concludes with discussions of implications for technical communicators and genre theorists interested in technical communication."""	documentation;quality engineering;software development;software engineering	Ashley Williams	2004		10.1145/1026533.1026538	use case;human–computer interaction;computer science;knowledge management;software design;software development;software engineering;iterative method;software technical review;requirements engineering;software walkthrough;management;world wide web	SE	-72.59878190067828	22.860218202523136	165746
0c6df0d8a6b6d927a9880488f3a6c019c21b7c9f	identifying usability issues with an erp implementation	first year;cost saving;erp system;large scale;enterprise resource planning;enterprise system;erp implementation;business process	Enterprise Resource Planning (ERP) systems hold great promise for integrating business processes and have proven their worth in a variety of organizations. Yet the gains that they have enabled in terms of increased productivity and cost savings are often achieved in the face of daunting usability problems. While one frequently hears anecdotes about the difficulties involved in using ERP systems, there is little documentation of the types of problems typically faced by users. The purpose of this study is to begin addressing this gap by categorizing and describing the usability issues encountered by one division of a Fortune 500 company in the first years of its large-scale ERP implementation. This study also demonstrates the promise of using collaboration theory to evaluate usability characteristics of existing systems and to design new systems. Given the impressive results already achieved by some corporations with these systems, imagine how much more would be possible if understanding how to use them weren’t such an	business process;categorization;documentation;erp;field research;money;ramp simulation software for modelling reliability, availability and maintainability;usability	Heikki Topi;Wendy T. Lucas;Tamara Babaian	2005			enterprise system;enterprise software;computer science;knowledge management;database;business process;enterprise integration;management;enterprise planning system;enterprise information system;enterprise life cycle	HCI	-69.84742832224828	25.991166834432477	165818
f011e47a2349f03d76f080acd1cd4647d4965ba7	platonic schizophrenia: a pattern about mistaking the idea for the real thing ... and mistaking a thing for what you actually need.		Focus on the core business! Following this imperative, companies and projects try to take advantage from globalization and environment. Software parts or entire systems are being contracted out to companies that understand better how to engineer software systems. In the automobile industry, a long tradition of combining complex ingredients has changed the focus from building automobiles towards the process of supplier management. Organizations rely on external knowledge to do the payroll system or the entire IT support.	imperative programming;software system	Klaus Marquardt	2004				DB	-67.83512944466595	24.401994413291206	165868
c4976070b483aac44a566fc6eb95be73bfccd1d2	an approach to measure value-based productivity in software projects	software metrics;software;software measurement productivity programming software quality area measurement software engineering statistical analysis gain measurement business communication production;measurement;software measurement;software productivity metric value based productivity measurement software projects software engineering area;software engineering area;software engineering;software productivity metric;value based productivity measurement;software projects;mathematical model;organizations;process;productivity;programming;process productivity measurement	Nowadays, after a lot of evolution in software engineering area, there is not yet a simple and direct answer to the question: What is the best software productivity metric? The simplest and most commonly used metric is the SLOC and its derivations, but these are admittedly problematic for this purpose. In another way, there are some indications of maturation in this topic, the new studies point to the use of more labored models, which are based on multiple dimensions and in the idea of produced value. Based in this tendency and on the evidence that each organization must define its own way to assess their productivity, we defined a process to support the definition of productivity measurement models in software organizations. We also discuss, in this paper, some issues about the difficulties related with the process adoption in real software organizations.	basis (linear algebra);best practice;software engineering;source lines of code;xojo	Gibeon Soares de Aquino Junior;Silvio Romero de Lemos Meira	2009	2009 Ninth International Conference on Quality Software	10.1109/QSIC.2009.57	reliability engineering;programming;productivity;computer science;systems engineering;organization;software engineering;mathematical model;software measurement;software metric;measurement;process	SE	-66.54699369590251	30.404867385446295	165915
060510b633a5e31d413a0bf4e1d02093c0d71324	welcome from the tool demonstration chairs		The Tool Demonstration Track at CSMR 2012 provides an opportunity for researchers to present novel research tools for software maintenance and reengineering. Eight tools which aim to aid software developers and maintainers in their work have been selected for presentation and demonstration. The tools are meant to be explored and applied by interested users and to inspire fellow researchers. Tool developers can thus get feedback on how to further improve upon their tools. This track also provides an outlet to publish about research embodied in tools. This was recognized by the track’s call: Since tools are central to research in software maintenance and reengineering, tool demonstrations will have a prominent role within the conference and will add to the visibility of the associated research. Whereas a scientific paper is intended to give the background information and point out the scientific contribution of a new software engineering approach, the tool demonstration provides a good opportunity to show how the scientific approach has been transferred into a running tool prototype. To further increase the visibility of the presented tools, developers were encouraged to provide a screencast and make it available on the web.	code refactoring;prototype;scientific literature;screencast;software developer;software engineering;software maintenance	Holger M. Kienle;Mircea Lungu	2012		10.1109/CSMR.2012.87		SE	-64.73618959701456	23.92161767069908	165962
c2d64eb24d4183a90b2301a707369a7e8c91920f	green software engineering: the curse of methodology		Computer Science often seems distant from its natural science cousins, especially software engineering which feels closer to sociology and psychology than to physics. Physical measurements are often rare in software engineering, except in a few niches. One such important niche is that of software energy consumption, green mining, green IT, and sustainable computing, which all fall under the umbrella of green software engineering. With the physical measurement of energy consumption comes all of the limitations of measurement and experimentation that exist in the natural sciences and engineering. Issues abound, from attribution of energy use, isolation of components, to replicable experiments. These get further complicated by cloud computing whereby systems are virtualized and attribution of resource usage is a serious issue. Thus in this work we discuss the current state of software energy consumption, and where will it go.	cloud computing;computer engineering;computer science;electrical engineering;experiment;fork (software development);holism;list of code lyoko episodes;niche blogging;operating system;operating-system-level virtualization;programmer;software engineer;software engineering;threat (computer)	Abram Hindle	2015	PeerJ PrePrints	10.7287/peerj.preprints.1470v1	software deployment;software development;green computing;resource-oriented architecture;software engineering;software;cloud computing;energy consumption;social software engineering;systems engineering;engineering	SE	-69.75817400898448	27.316814913263865	166525
427db777575b17ef1b5b5911144294694fe48f0b	the impact of model driven development on the software architecture process	specification languages software architecture;software;large scale industrial software development project;industrial case study;software architecture process;dsl;code generation;model driven development mdd;development process;model driven development;large scale;software architecture;specification languages;lead;business;software development;unified modeling language;domain specific language;code generator model driven development software architecture process large scale industrial software development project domain specific language;grounded theory;code generator;interviews;industrial case study software architecture model driven development mdd;software architecture design;unified modeling language software business programming dsl lead interviews;programming;meta model	While Model-Driven Development (MDD) is an increasingly popular software development approach, its impact on the development process in large-scale, industrial practice is not yet clear. For this study the application of MDD in a large-scale industrial software development project is analyzed over a period of two years. Applying a grounded theory approach we identified 14 factors which impact the architectural process. We found that scope creep is more likely to occur, late changes can imply more extensive rework and that business engineers need to be more aware of the technical impact of their decisions. In addition, the introduced Domain-Specific Language (DSL) provides a new common idiom that can be used by more team members and will ease communication among team members and with clients. Also, modelers need to be much more explicit and complete in their descriptions. Parallel development of a code generator and defining a proper meta-model require additional time investments. Lastly, the more central role of software architecture design documentation requires more structured, detailed and complete architectural information and consequently, more frequent reviews.	artifact (software development);code generation (compiler);computer-aided software engineering;digital subscriber line;documentation;domain-specific language;instruction creep;metamodeling;model-driven engineering;model-driven integration;requirement;rework (electronics);software architect;software architecture;software development	Werner Heijstek;Michel R. V. Chaudron	2010	2010 36th EUROMICRO Conference on Software Engineering and Advanced Applications	10.1109/SEAA.2010.63	software architecture;team software process;computer science;systems engineering;package development process;software engineering;programming language;software development process;code generation	SE	-66.52460830469715	22.857611566524923	166610
607ba1865a575cbb6c2ca822a47a5e8a7e07f1b9	quantifying design quality through design experiments	probability quality control;design process;probability;verification procedure design quality metrics design experiments error data extraction electronic products probability error free design synthesis process;design quality;costs testing process design dictionaries fasteners handicapped aids telecommunications data mining data analysis energy consumption;data extraction;quality control	The authors present a model for design quality metrics, discuss its relevance, and give some examples of use. Design experiments demonstrate error data extraction and analysis. Using a model of the design process for electronic products that emphasizes the resulting quality of the design, the authors demonstrated that they can quantify design quality. They can best express the probability of an error-free design in terms of the quality of the synthesis process and the quality of the verification procedure.<<ETX>>	experiment;relevance	Einar J. Aas;Tore Steen;Karl Klingsheim	1994	IEEE Design & Test of Computers	10.1109/54.262320	iterative design;reliability engineering;quality control;probabilistic design;design process;data quality;computer science;systems engineering;probability;data mining;statistics	EDA	-64.59646156843661	29.625619187792168	166769
b7611141998ca33c290cb7b6445251dc3bd0bd09	can function points be mapped to object points	function point	Object points is a new software size metric that has emerged to cope with recent developments in software engineering, and to overcome the deficiencies of the traditional lines of code and function points size metrics. Moreover, object points has been utilized as the basis for several software cost estimation models with promising improvements in the accuracy of estimates. However, the infancy of the object points size metric means that there is a shortage of object points based software historical projects, on which to base the empirical validation of the new object points based software cost estimation models. Hence, the relationship between the extensively used function points and newly invented object points size metrics have been conceptualized and utilized in a novel forward approach to convert the function points projects data into their equivalent object points data. Empirical investigations of 66 function points projects have shown high correlation and significance, 88% and 0.33, respectively, between the resulting object points effort estimates and the actual function points effort. Furthermore, the resulting object points data have been utilized to model the embodied function points-object points relationship in two specialized productivity factors and function points type dependent linear models. The resulting models have shown high fitness, R, values of 0.95, for both models.	function point;linear model;software development effort estimation;software engineering;software sizing;source lines of code	Ayman Issa;Mohammed Odeh;David Coward	2007	Int. Arab J. Inf. Technol.		computer science;function point;function representation	SE	-66.95531941917838	30.42908212415817	167174
ffa928b68d3fc02d213e6ccd2bc8fe019d3ded0d	towards automatic analysis of software requirement stability	software requirements	Requirement eliciting, organizing, developing and managing are most important activities in the implementation of software systems. Changes of requirements are inevitable. But, too many changes of requirements might fail software projects. Thus, the stability of the software requirements of a project is critical to the software development success. However, there are no published studies on software requirement stability yet. This paper proposes an approach to analyze the software requirement stability based on the regression analysis and control chart analysis of the function point changes. It can help the organizations to predict the future trend of the projects.	function point;futures studies;organizing (structure);requirement;software development;software requirements;software system	Jiang Guo	2010	AISS	10.4156/aiss.vol2.issue4.4	requirements analysis;software requirements specification;verification and validation;requirement prioritization;software sizing;software verification;computer science;package development process;backporting;software design;software development;requirement;software construction;software measurement;software deployment;functional requirement;software requirements;software system	SE	-63.73121631334319	28.997824424657647	167367
208a23b643ed91ed6603a6e4c3f89856e0fc34f1	web development effort estimation using analogy	automatic collection;information resources;gold bismuth;novice developers;software cost estimation;project management;tool support;software development work;analogy based estimation;bismuth;function point;measurement environment;datasets;web applications;development effort;analogous projects web development effort estimation web applications development effort web development projects software development work algorithmic cost models calibration measurement environment variable accuracy levels analogy based estimation datasets empirical web development data novice developers angel tool automatic collection;gold;effort estimation;web development projects;distributed programming;software development;variable accuracy levels;algorithmic cost models;software cost estimation information resources distributed programming project management software development management;angel tool;analogous projects;web development effort estimation;prediction;calibration;empirical web development data;cost model;software development management;web development	Although estimating the effort required in developing Web applications is a difficult task, accurate estimates of development effort have an important role to play in the successful management of Web development projects. In software development work to date, emphasis has focused on algorithmic cost models such as COCOMO and function points. Two disadvantages of these models are firstly, the need for calibration of a model for each individual measurement environment and, secondly, the variable accuracy levels achieved even after calibration. The paper describes the use of estimation by analogy to calculate the development effort of Web applications. Two datasets containing empirical Web development data were used in the case study. One set contained data relating to forty-one novice developers, the other to twenty-nine experienced developers. The ANGEL tool supporting the automatic collection, storage and identification of the most analogous projects was used as a basis for estimating effort required for a new project. Results show estimation by analogy to be a promising alternative to algorithmic techniques.	web development	Emilia Mendes;Steve Counsell	2000		10.1109/ASWEC.2000.844577	gold;project management;web development;web application;web modeling;calibration;simulation;prediction;computer science;systems engineering;software development;function point;software engineering;bismuth;data mining;management	HCI	-65.52025322627712	30.78584377343518	167379
2d7c7813da3fad4c6e08f9b24d93b1ed68a5a90e	enhancing customer partnership through requirements framework	software;customer partnership;integrated approach;igate;formal specification;training;barium;best practice;customer value chain;customer satisfaction;requirements;formal verification;systems analysis;value chain;framework customer partnership requirements;root cause analysis;organizations;first integral;project execution;organizations training customer satisfaction software barium conferences;customer portfolio;conferences;framework;customer satisfaction igate customer partnership integrated technology and operation customer value chain customer portfolio root cause analysis project execution;systems analysis customer satisfaction formal specification formal verification organisational aspects;organisational aspects;integrated technology and operation	iGATE, the first integrated Technology & Operations (iTOPS) organization in India had a steady climb in the customer’s value chain in terms of penetrating deeper (instead of wider) into customer portfolio. More and more customers were proposing ‘partnership’ model. One of the focus areas in partnership was ‘requirements engineering’ as the challenges faced in this area were affecting both iGATE and its customers. In spite of iGATE having established process and tools, some of the critical projects experienced cost and schedule overruns due to missed requirements. While the conventional Root Cause Analysis (RCA) approach resulted in incremental benefits, an integrated approach to tackle the challenge was the need of the hour. The paper portrays how a robust Requirements Framework was evolved over a period of one and half years crossing several milestones on its journey such as integration of training and technology, project execution and facilitation. The results of implementation was (i) increase in completely owned development projects from 2% to 12%, (ii) increase in resources engaged in requirements phase of project from 8% to 24% and (iii) improved annual organization level customer satisfaction results. Growing by its strength, the organization at present is not only leveraging the requirements framework for successful execution of projects within iGATE. Best practices of the framework are adopted by our customers and the framework is customized as “customer-iGATE specific joint requirements framework”.	best practice;requirement;requirements elicitation;requirements engineering;software bug;structured analysis	Deepa K. Vijayamma;Nora Yamini David	2010	2010 18th IEEE International Requirements Engineering Conference	10.1109/RE.2010.48	systems analysis;requirements analysis;root cause analysis;formal verification;value chain;computer science;systems engineering;organization;marketing;operations management;software framework;software engineering;formal specification;barium;programming language;customer satisfaction;management;best practice	SE	-66.98865636053306	21.431711702943147	167592
2152813357c19dff1341056a6cf0b86ed49aadd1	surfing the net for software engineering notes		We last covered the topic of software testing way back in 2007. Since that time, many of the URLs in the 2007 article have been moved, deleted or updated. In addition to the updated sites, here are some new web sites that discuss new approaches to software testing, including advice for folding your testing process into an overarching agile development process. Finally, there are new test tools that offer new opportunities for improved testing methods. For those reasons, I thought it was time to re-visit the topic of software testing. Needless to say, testing is critical to developing high quality software. While everyone agrees that you can’t “test in” quality, testing still plays an important role in verifying the correctness and reliability of your software. One of the key issues in testing is “how much testing is enough?” You want to establish and effective yet efficient testing program where your testing finds the bugs prior to deployment, yet doesn’t go overboard with excessive testing. Yes, there is such a thing as excessive testing. The goal is to raise your Defect Removal Efficiency (DRE). If you are not tracking DRE as a development program metric, check out some of the articles by Capers Jones at the Namcook Analytics article below. I think you’ll find this surfing expedition interesting as we investigate some web sites with agile testing techniques. As I am sure you are aware, agile methods such as Scrum emphasize short development times and frequent delivery of working code. There is little room for lengthy, “wall-to-wall” testing processes in the overall agile approach. We’ll investigate some newer methodologies such as exploratory testing, context-driven testing, and Rapid Software TestingTM that provide approaches for dealing with software test in an agile environment. We will also visit some sites discussing Test Driven Development (TDD). This agile development approach centers on testing as an integrated development activity. TDD is not particularly new, but has been gaining in popularity since we last discussed software testing in this column. In addition to the web sites discussing the various testing techniques, there are scores of web sites that provide practical advice on how to integrate these techniques into your development methodology. While there is no single site that provides an authoritative list of testing best practices, you can find case studies and examples of what has worked for others in the past. Let’s start at the beginning with a Beginner’s Guide to unit testing.	agile software development;agile testing;best practice;correctness (computer science);display resolution;exploratory testing;jones calculus;mind;programmer;scrum (software development);software engineering notes;software bug;software deployment;software testing controversies;test-driven development;unit testing;verification and validation	Mark Doernhoefer	2015	ACM SIGSOFT Software Engineering Notes	10.1145/2830719.2830724		SE	-67.96116540176881	25.328980751720632	167656
0e5a65f2c305eef3fcbcfeb00c768cfb1b087b66	a summary of progress toward proving program correctness	computer program;software systems;computer application;program correctness	Interest in proving the correctness of programs has grown explosively within the last two or three years. There are now over a hundred people pursuing research on this general topic; most of them are relative newcomers to the field. At least three reasons can be cited for this rapid growth:  (1) The inability to design and implement software systems which can be guaranteed correct is severely restricting computer applications in many important areas.  (2) Debugging and maintaining large computer programs is now well recognized as one of the most serious and costly problems facing the computer industry.  (3) A large number of mathematicians, especially logicians, are interested in applications where their talents can be used.	computer program;correctness (computer science);debugging;software system	Theodore A. Linden	1972		10.1145/1479992.1480019	program analysis;computer science;theoretical computer science;algorithm	Arch	-71.43693776513811	31.134940174618063	167794
bbb171c862b66f4e44fb946c5dd10e3206ceb302	metrics to assess the likelihood of project success based on architecture reviews	discovery review;empirical study;data collection;architecture audit;software development;risk metric;architecture review;high risk	Architecture audits are performed very early in the software development lifecycle, typically before low level design or code implementation has begun. An empirical study was performed to assess metrics developed to predict the likelihood of risk of failure of a project. The study used data collected during 50 architecture audits performed over a period of two years for large industrial telecommunications systems. The purpose of such a predictor was to identify at a very early stage, projects that were likely to be at high risk of failure. This would enable the project to take corrective action before significant resources had been expended using a problematic architecture. Detailed information about seven of the 50 projects is presented, and a discussion of how the proposed metric rated each of these projects is presented., A comparison is made of the metric's evaluation and the assessment of the project made by reviewers during the review process.	kerrison predictor;level design;low-level design;software development process	Alberto Avritzer;Elaine J. Weyuker	1999	Empirical Software Engineering	10.1023/A:1009826509846	reliability engineering;systems engineering;engineering;software development;software engineering;data mining;empirical research;management;statistics;data collection	SE	-64.86881349746139	32.17134227629664	167827
0cf11aadd6e51b88109cb61744dfdb0647b540ea	woda 2008: the sixth international workshop on dynamic analysis	software testing;statistical reasoning techniques;synergies between static and dynamic analysis techniques;optimization technique;program evolution;software systems;fault detection and debugging;efficient instrumentation techniques;optimization techniques;runtime monitoring;static and dynamic analysis;remote analysis and measurement of software systems;visualization and classification of program behavior;development of dynamic analysis tools and frameworks;dynamic analysis	Dynamic analysis techniques reason over program executions and deal with data produced at program execution time. At WODA 2008, we bring together researchers and practitioners working in all areas of dynamic analysis to discuss new issues, share results and ongoing work, and foster collaborations.	run time (program lifecycle phase)	Ben Liblit;Atanas Rountev	2008		10.1145/1390630.1390671	real-time computing;computer science;systems engineering;software engineering;dynamic program analysis;software testing;software system	SE	-63.41657460422107	29.65970743909474	168344
7f89c6ec7bdd9356000520d4ea8571bb49b007ab	teaching formal methods in the context of software engineering	formal methods;software engineering;formal method;software development;teaching methods;formal engineering methods;graduate student	Formal methods were developed to provide systematic and rigorous techniques for software development, and they must be taught in the context of software engineering. In this paper, we discuss the importance of such a teaching paradigm and describe several specific techniques for teaching formal methods. These techniques have been tested over the last fifteen years in our formal methods education programs for undergraduate and graduate students at universities as well as practitioners at companies. We also present a curriculum to systematically introduce formal methods to students at university and a successful program of teaching formal methods to industry. Our experience shows that students can gain confidence in formal methods only when they learn their clear benefits in the context of software engineering.	experience;formal methods;programming paradigm;software development;software engineering	Shaoying Liu;Kazuhiro Takahashi;Toshinori Hayashi;Toshihiro Nakayama	2009	SIGCSE Bulletin	10.1145/1595453.1595457	formal methods;computer science;social software engineering;software development;software engineering;teaching method;formal specification;programming language	SE	-65.68374117731113	25.864748199525188	168527
b8d0767645968e97c141e4550c5a2e58ff701978	the critical issues of software metrics part 0: perspectives on software measurements	software measurement;software metric	Software metrics is the science of measurements of software productivity for the purposes of comparison, cost estimation an d forecasting . Practically, the quintessence of measurement is th e confidence gained through numerical control of productivity i n terms of how much, how far, and how well . Basically, measuremen t is the assignment of numbers to represent the observed behaviora l properties of objects and empirical phenomena . For instance, i n software technology, there is a strong affinity between softwar e metrics and structured programming . The structured revolutio n posed on us TWO PARADOXES :	affinity analysis;emoticon;numerical analysis;software metric;structured programming	Lem O. Ejiogu	1987	SIGPLAN Notices	10.1145/24697.24702	personal software process;verification and validation;software sizing;software verification;computer science;package development process;backporting;social software engineering;software development;software design description;software construction;software walkthrough;software analytics;software measurement;software deployment;software quality;software metric;software system;software peer review	Logic	-66.63605520165943	30.918029230742317	168667
073c7c7d8ed1fdb5dcebcc4602099ea128f976c6	security and software quality: an interview with frank perry	interviews software quality programming security cryptography certification linux internet capability maturity model software libraries;system security;network technologies and applications;network technologies and applications security software quality;security;software quality	The ramifications of failing to completely and correctly address security can devastate an organization, not only in compromised data and financial cost but also in the time and energy spent to recover. One of us, Jane Hayes, sat down with an expert in the field, Frank Perry, to discuss the state of the art and future directions of system security and particularly how it interacts with software quality. Perry is chief engineer of the System and Network Solutions Group at SAIC. The group of almost 10,000 people focuses on network technologies and applications, primarily in the US federal market.	computer security;failure;hayes microcomputer products;jane (software);software quality	Jane Huffman Hayes;Nancy S. Eickelmann;Elizabeth Ashlee Holbrook	2006	IEEE Software	10.1109/MS.2006.83	software security assurance;computer security model;cloud computing security;verification and validation;security through obscurity;software quality management;security information and event management;asset;computer science;engineering;information security;backporting;software development;logical security;software engineering;security service;management;network access control;world wide web;software quality control;computer security;software quality	Arch	-67.46945689947137	27.60986690662944	168862
994c600f3f0284ff0b8289620aa005761a8685ee	self-organizing roles on agile software development teams	team working knowledge management software management software prototyping;agile software development;software;champion role;senior management support sustainability self organizing roles agile software development teams self organizing teams autonomous groups socio technical systems organizational theories enablers knowledge management agents complex adaptive system examples software engineering grounded theory research new zealand india mentor role coordinator role translator role champion role promoter role terminator role customer expectation management customer collaboration coordination senior management support security;software prototyping;autonomous groups;socio technical systems;software management;knowledge management;collaboration;terminator role;software engineering;team working;mentor role;self organizing roles;promoter role;senior management support security;team roles;agile software development teams;complex adaptive system examples;coordinator role;organizing;self organizing teams;grounded theory research;programming organizations collaboration software organizing software engineering;grounded theory;organizational theories enablers;organizations;grounded theory self organizing team roles software engineering agile software development;senior management support sustainability;new zealand;programming;knowledge management agents;india;customer collaboration coordination;self organizing;translator role;customer expectation management	Self-organizing teams have been recognized and studied in various forms-as autonomous groups in socio-technical systems, enablers of organizational theories, agents of knowledge management, and as examples of complex-adaptive systems. Over the last decade, self-organizing teams have taken center stage in software engineering when they were incorporated as a hallmark of Agile methods. Despite the long and rich history of self-organizing teams and their recent popularity with Agile methods, there has been little research on the topic within software wngineering. Particularly, there is a dearth of research on how Agile teams organize themselves in practice. Through a Grounded Theory research involving 58 Agile practitioners from 23 software organizations in New Zealand and India over a period of four years, we identified informal, implicit, transient, and spontaneous roles that make Agile teams self-organizing. These roles-Mentor, Coordinator, Translator, Champion, Promoter, and Terminator-are focused toward providing initial guidance and encouraging continued adherence to Agile methods, effectively managing customer expectations and coordinating customer collaboration, securing and sustaining senior management support, and identifying and removing team members threatening the self-organizing ability of the team. Understanding these roles will help software development teams and their managers better comprehend and execute their roles and responsibilities as a self-organizing team.	agile software development;autonomous robot;complex adaptive system;knowledge management;organizing (structure);self-organization;self-organizing map;sociotechnical system;software engineering;spontaneous order;the terminator;theory	Rashina Hoda;James W Noble;Stuart Marshall	2013	IEEE Transactions on Software Engineering	10.1109/TSE.2012.30	systems engineering;engineering;knowledge management;grounded theory;management;lean software development	SE	-67.56461431946876	21.225959584324336	168981
c7200fed52809c5ce5bede4c8e010bc2c1e4662b	beyond programming-in-the-large: the next challenges for software engineering	solutions general;systems engineering;computations;software development process;satisfiability;software engineering;computer programs;computer programming;complex system;software development;high costs	Abstract : As society's dependence on computing broadens, software engineering is being called upon to address new problems that raise new technical and non-technical concerns. Aspirations and expectations for the applications of computers appear to be unbounded, but present software development and support techniques will not be adequate to build computational systems that satisfy our expectations, even at very high cost. Each order-of-magnitude increase in the scale of the problems being solved leads to a new set of critical problems that require essentially new solutions. The next challenges for software engineering will deal with software as one of many elements in complex systems, which we call program-as-component, and with the role of software as an active participant in the software development process, which we call program-as-deputy.		Mary Shaw	1986		10.1007/3-540-17189-4_118	personal software process;verification and validation;computing;software engineering process group;software sizing;search-based software engineering;computer science;systems engineering;package development process;social software engineering;software framework;component-based software engineering;software development;software engineering;software construction;software walkthrough;software deployment;software development process;software requirements;software metric;software system;computer engineering	SE	-65.72129443207139	24.838346133057357	169029
46d65197bc4d3a1178d50cec2f9eee93567dde4e	fundamental principles of software engineering - a journey	software engineering;technical presentations;computer software;computer science;quality control	A set of fundamental principles can act as an enabler in the establishment of a discipline; however, software engineering still lacks a set of universally recognized fundamental principles. This article presents a progress report on an attempt to identify and develop a consensus on a set of candidate fundamental principles. A fundamental principle is less specific and more enduring than methodologies and techniques. It should be phrased to withstand the test of time. It should not contradict a more general engineering principle and should have some correspondence with ‘‘best practice’’. It should be precise enough to be capable of support and contradiction and should not conceal a tradeoff. It should also relate to one or more computer science or engineering concepts. The proposed candidate set consists of fundamental principles which were identified through two workshops, two Delphi studies and a web-based survey. 2001 Elsevier Science Inc. All rights reserved.	best practice;computer science;embarcadero delphi;software engineering;web application	Pierre Bourque;Robert Dupuis;Alain Abran;James W. Moore;Leonard L. Tripp;Sybille Wolff	2002	Journal of Systems and Software	10.1016/S0164-1212(01)00136-4	quality control;computer science;systems engineering;engineering;software engineering;management	SE	-65.75851046052699	18.344490497351142	169041
2fef4de02abab03c8ab1424e94bbf1b76540e9f7	a readiness model for software development outsourcing vendors	analytical models;software;software development management outsourcing;outsourcing;software measurement;readiness model for software outsourcing vendors software outsourcing vendors criteria for vendors selection;readiness model for software outsourcing vendors;companies;software practitioners readiness model software development outsourcing vendors outsourcing business;criteria for vendors selection;business;software development;failure rate;outsourcing software programming companies business software measurement analytical models;programming;software development management;software outsourcing vendors	Software development outsourcing has been growing steadily. However significant outsourcing failure rates have also been reported. One of the major issues in outsourcing business is that many organisations undertake software outsourcing initiatives without knowing whether or not they are ready to undertake them. The objective of this project is to develop a readiness model in order to measure the organisationpsilas (vendor) readiness for software development outsourcing. Two types of data will be collected in this research project: firstly, factors that can have a positive or negative impact on software outsourcing clients in the selection of software development outsourcing vendors; and secondly, how one can implement these factors. The anticipated outcome of this project will be a software outsourcing readiness model to assist software practitioners in the design of effective software outsourcing strategies. This model should assist outsourcing vendors in measuring the strength or weakness of software outsourcing activities.	agile software development;outsourcing	Siffat Ullah Khan;Mahmood Niazi;Rashid Ahmad	2008	2008 IEEE International Conference on Global Software Engineering	10.1109/ICGSE.2008.37	programming;economics;systems engineering;engineering;software development;failure rate;knowledge process outsourcing;process management;software measurement;management;commerce;outsourcing	SE	-69.27747026930213	20.774142708736836	169167
d8d1111ae571dc9f52faf013690f727ecad4348d	improving effort estimation by voting software estimation models	effort estimation	Estimating software development effort is an important task in the management of large software projects. The task is challenging, and it has been receiving the attentions of researchers ever since software was developed for commercial purpose. A number of estimation models exist for effort prediction. However, there is a need for novel models to obtain more accurate estimations. The primary purpose of this study is to propose a precise method of estimation by selecting the most popular models in order to improve accuracy. Consequently, the final results are very precise and reliable when they are applied to a real dataset in a software project. Empirical validation of this approach uses the International Software Benchmarking Standards Group (ISBSG) Data Repository Version 10 to demonstrate the improvement in software estimation accuracy.		Luiz Fernando Capretz;Venus Marza	2009	Adv. Software Engineering	10.1155/2009/829725	reliability engineering;software sizing;computer science;data science;software reliability testing;analysis effort method;data mining;cosmic software sizing;goal-driven software development process;use case points;software metric	SE	-65.18621609680153	30.83888947367853	169171
76f1c58bae1c0d57b7c68831a9432e87ca5ee392	getting what you measure	project management;software metrics;common pitfall;software metric	Four common pitfalls in using software metrics for project management.	software metric	Eric Bouwers;Joost Visser;Arie van Deursen	2012	Commun. ACM	10.1145/2209249.2209266	computer science;data science;software engineering;data mining;software metric	SE	-65.66080383086268	30.541661767789634	169618
9d5ecc93e4902ee4af5fd0bb66ff40fd4e633c06	model checking	computational thinking;engagement;computer science education;motivation;context	IN AN EARLIER Math CountS column I mentioned that the 2007 Turing Award Winners are Edmund M. Clarke, E. Allen Emerson, and Joseph Sifakis for their seminal work on model checking. This column led to an email exchange with Mordechai (Moti) Ben-Ari, Weizmann Institute of Science, regarding the educational aspects of model checking, in particular, how and when to introduce model checking to students. The result of this exchange is an article “A Primer on Model Checking” in this issue of ACM Inroads. In addition, the 2009 June issue of inroads was devoted to Formal Methods in Education and Training. In this issue of ACM Inroads, Moti and I hope to invigorate further an educational interest in emerging rigorous techniques for the development of software systems, as we both believe these will become more widely used and practical in the future. Model checking is a formal, logic-based approach to ensuring that a model of the software system (requirements or design) is consistent with the system specifi cation. Ensuring the system requirements are accurate is one of the fi rst stages in the engineering of a correct software system. In traditional engineering disciplines developing and checking a mathematical model of the system to be developed, be it an automobile suspension component or a space shuttle thruster, it is extremely important to ensure the system works correctly. With such physical systems, checking the mathematical model is often achieved by constructing a physical model whose behavioral characteristics are then compared against the mathematical model. After a series of refi nements, the mathematical model is brought into alignment with the physical model helping to improve ones confi dence that the fi nal system is correct. For software systems, this approach is very important for the development of verifi ably correct systems and used for developing requirements and specifi cations as better model checking tools and techniques are discovered and applied. One goal of this column and Moti’s article is to encourage educators to introduce these concepts and tools to the next generation of software practitioners. As Peter Neuman’s SIGSOFT Software Engineering Notes column “Risks to the Public” and his Communications of the ACM “Inside Risks” contributions illustrate software systems are subject to faults and failures. Luckily, there have not been signifi cant catastrophic software failures resulting in a major loss of life such as the ones we hear about in other engineering disciplines – for example, structural collapses. Many situations exist in which software must function correctly such as medical machines, transportation systems, and fi nancial software. A model-checking tool takes a model in the form of system requirements or a design and specifi cations the system must satisfy, and determines if these are consistent. If not, then the tool generates a counterexample that identifi es the inconsistency. This can be used to correct either the model or the specifi cation, whichever led to the inconsistency. This process is iterated until the model and it specifi cation are brought into alignment. As detailed in Moti’s article, formal languages have been developed for defi ning models and their specifi cations. To clarify this idea, consider a software component that takes some inputs and outputs a single integer value. Let’s say that one of many possible specifi cation constraints of the output is that the integer value must be even. A model of this software component is created using a modeling language. This model and the claim that the output must be even are fed to the model checking tool. If the model checker fi nds a counterexample (a non-even output) and the specifi cation of ‘evenness’ is correct, then the model must be wrong, requiring revision. As with traditional engineering practice, building and checking a model servers several purposes. First, this process helps to clarify the problem being solved. Second, insight gained from constructing and checking the model can be used in the design/development of the system. Third, in some cases another tool can be used to accurately translate the formal model to an effi cient implementation. Finally, the model might be used as an executable specifi cation to verify the implementation. Students who learn this methodology and these emerging tools will be far ahead of their peers since a signifi cant aspect of the software engineering process is the development of rigorously accurate system requirements. For many software projects, the “infi nite” cycle of coding and testing is too time consuming (often akin to playing golf blindfolded) and error prone. And of course one must keep in mind that famous Dijkstra’s saying, “Program testing can be used to show the presence of bugs, but never to show their absence!”. Please read Moti’s article and begin the journey toward changing the way future students develop software. Ir	acm turing award;cognitive dimensions of notations;communications of the acm;component-based software engineering;edmund m. clarke;effi;email;executable;formal language;formal methods;hall-effect thruster;iteration;mathematical model;model checking;modeling language;primer;requirement;software engineering notes;software bug;software development process;software system;system requirements	Peter B. Henderson	2010	Inroads	10.1145/1721933.1721947	mathematics education;applied mathematics;computer science;pedagogy	SE	-65.2228783150975	18.900697563614262	169800
5288e38bbb30766d461f17c308f43258706223e1	demarcating risk management responsibilities of a project manager	requirement planning project managers risk management responsibility software companies task planning project planning;annan data och informationsvetenskap;project management;risk management project management conference management technology management portfolios programming information technology communications technology communication standards financial management;task planning project planning requirements planning;project manager;risk management;software companies;companies;requirements planning;risk management responsibility;project managers;requirement planning;monitoring;software development management project management risk management;task planning;interviews;planning;process model;software development management;project planning;other computer and information science	Most of the standards and process models are not explicit enough about demarcating risk management responsibilities of project managers. Usually, they place them entirely on a project level. In this paper, we study the risk management responsibilities of project managers within 53 software companies. Our goal is to find out what exactly project managers do within pre-project and project activities such as requirements, project and task planning and what risk management responsibilities they have within these activities. Our results show that the responsibility portfolio of project managers varies depending on the degree of their engagement within pre-project and project phases; the broader the project managers’ responsibility portfolio, the broader their risk management responsibility portfolio.	requirement;risk management;software industry	Mira Kajko-Mattsson	2010	2010 Seventh International Conference on Information Technology: New Generations	10.1109/ITNG.2010.218	level of effort;planning;basis of estimate;project management;extreme project management;project stakeholder;interview;risk management;opm3;knowledge management;project sponsorship;functional manager;process modeling;project risk management;project governance;project management triangle;management;project charter;schedule;risk management plan;project planning;project portfolio management	SE	-67.67543397533254	21.279651695411406	169943
2744f9b3dc7c8c587811ffd39dd1ce7015a72e82	continuous software engineering - a microservices architecture perspective		From its earliest days, software development has been beset with challenges in relation to timely delivery, appropriateness of features and quality of deliverables. Many advances in software development processes have helped to address these concerns. For example, agile software development has helped to deliver working software more frequently and capability maturity frameworks have brought about improved consistency in quality levels. However, the age-old challenge of better, cheaper, faster software has continued to beguile developers. In this paper, we discuss an emerging approach to software development, continuous software engineering (CSE), wherein software of operational quality may be delivered on a very frequent basis, up to many times in a given day. This approach employs a complex set of independent tools that together reduce the lead time in delivering commercial-grade software. Having examined the situational context of one industrial organisation applying CSE, we conclude that the approach may not presently be appropriate to all manners of software development. Nonetheless, the authors are of the view that CSE represents a significant progression in software engineering and that software development settings of all types stand to gain from aspects of the CSE approach.	agile software development;capability maturity model;color gradient;microservices;norm (social);software development process;software engineering	Rory O'Connor;Peter Elger;Paul M. Clarke	2017	Journal of Software: Evolution and Process	10.1002/smr.1866		SE	-68.36123751740266	23.02926885543906	170103
6752449bc351b883c0240f0b6236870b44c42819	e-mentoring for software engineering: a socio-technical perspective		Mentoring is one of the most effective pedagogical tools, holding great promise for software engineering education. When done badly, however, it can lead to dysfunctional interpersonal relationships and may turn off mentees from careers in software engineering. In this qualitative interview-based study we examine how socio-technical dimensions of software impact the formation of social ties important for satisfying two goals of mentorship, building technical skill and interpersonal development. We find that mentees working on user facing, interdependent software form a balance of ties that facilitate both goals, while mentees working on non-user facing software mostly form ties important for building technical skill. Work practices that create opportunities for unstructured contact between mentees and community members, such as code review in a mentee cohort, can help to overcome this imbalance. Our findings have important implications for task definition in software engineering e-mentoring program schemes.	interaction;interdependence;social network;sociotechnical system;software engineering	Erik H. Trainer;Arun Kalyanasundaram;James D. Herbsleb	2017	2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering Education and Training Track (ICSE-SEET)	10.1109/ICSE-SEET.2017.19	personal software process;verification and validation;software engineering process group;software evolution;social software engineering;component-based software engineering;software development;civil engineering software;software engineering;software construction;software walkthrough;resource-oriented architecture;software deployment;software requirements;software system;software peer review	SE	-73.35781286822032	21.9283702946896	170615
37fb0c212474e4941dbcd3b0ee9887f53bc0cc13	software reliability engineering: a roadmap	software measurement;programming;software reliability;reliability analysis;software systems;software development;reliability engineering;predictive models;software maintenance;maintenance engineering;software architecture	Software reliability engineering is focused on engineering techniques for developing and maintaining software systems whose reliability can be quantitatively evaluated. In order to estimate as well as to predict the reliability of software systems, failure data need to be properly measured by various means during software development and operational phases. Moreover, credible software reliability models are required to track underlying software failure processes for accurate reliability analysis and forecasting. Although software reliability has remained an active research subject over the past 35 years, challenges and open questions still exist. In particular, vital future goals include the development of new software reliability engineering paradigms that take software architectures, testing techniques, and software failure manifestation mechanisms into consideration. In this paper, we review the history of software reliability engineering, the current trends and existing problems, and specific difficulties. Possible future directions and promising research subjects in software reliability engineering are also addressed.	history of software;list of software reliability models;reliability engineering;software architecture;software bug;software development;software quality;software reliability testing;software system	Michael R. Lyu	2007	Future of Software Engineering (FOSE '07)		reliability engineering;software architecture;personal software process;long-term support;verification and validation;software engineering process group;software sizing;software verification;computer science;systems engineering;engineering;package development process;social software engineering;software reliability testing;software development;software engineering;software construction;software walkthrough;software maintenance;software deployment;software requirements;software quality;software system;avionics software;software peer review	SE	-63.107780485391345	30.87464903257248	170692
9aaf04d3b0f68e3e36fef90c5064bc36771e5870	effort estimation in agile software development: a systematic literature review	agile software development;computer and information science;software engineering;natural sciences;effort estimation;systematic literature review;programvaruteknik	Context: Ever since the emergence of agile methodologies in 2001, many software companies have shifted to Agile Software Development (ASD), and since then many studies have been conducted to investigate effort estimation within such context; however to date there is no single study that presents a detailed overview of the state of the art in effort estimation for ASD. Objectives: The aim of this study is to provide a detailed overview of the state of the art in the area of effort estimation in ASD. Method: To report the state of the art, we conducted a systematic literature review in accordance with the guidelines proposed in the evidence-based software engineering literature. Results: A total of 25 primary studies were selected; the main findings are: i) Subjective estimation techniques (e.g. expert judgment, planning poker, use case points estimation method) are the most frequently applied in an agile context; ii) Use case points and story points are the most frequently used size metrics respectively; iii) MMRE (Mean Magnitude of Relative Error) and MRE (Magnitude of Relative Error) are the most frequently used accuracy metrics; iv) team skills, prior experience and task size are cited as the three important cost drivers for effort estimation in ASD; and v) Extreme Programming (XP) and SCRUM are the only two agile methods that are identified in the primary studies. Conclusion: Subjective estimation techniques, e.g. expert judgment-based techniques, planning poker or the use case points method, are the one used the most in agile effort estimation studies. As for the size metrics, the ones that were used the most in the primary studies were story points and use case points. Several research gaps were identified, relating to the agile methods, size metrics and cost drivers, thus suggesting numerous possible avenues for future work.	agile software development;approximation error;cost estimation in software engineering;emergence;emoticon;extreme programming;mean squared error;planning poker;scrum (software development);software development effort estimation;systematic review;use case points	Muhammad Usman;Emilia Mendes;Francila Weidt;Ricardo Britto	2014		10.1145/2639490.2639503	simulation;systematic review;systems engineering;engineering;software engineering;agile software development;management science;empirical process;statistics	SE	-71.05283129535562	22.677603352546157	171069
2b08aa2fb0a85201b05fa4f101397eaeab6afbe2	exploiting hardware monitoring in software engineering	software testing;performance monitoring;path profiling;hardware monitoring;software engineering;dynamic optimization	Program monitoring is a key component of many software engineering tasks. Traditionally, instrumentation is used to complete such tasks. However, instrumentation can prohibitively increase the time and especially the memory overhead of an application. As an alternative to instrumentation, hardware monitoring has been shown to aid in developing more efficient techniques.#R##N##R##N#In this chapter, we examine efforts in applying hardware monitoring to a number of software engineering tasks including profiling, dynamic optimization, and software testing. We discuss improvements in using instrumentation for monitoring, how hardware mechanisms can provide an alternative, and the success that has been revealed in software engineering research when applying hardware monitoring approaches.	software engineering;system monitor	Kristen Walcott-Justice	2014	Advances in Computers	10.1016/B978-0-12-800162-2.00002-6	hardware compatibility list;embedded system;verification and validation;computing;real-time computing;software engineering process group;software sizing;software verification;search-based software engineering;computer science;software reliability testing;software development;software construction;hardware architecture;computer-aided engineering;software testing;software deployment;software requirements;software system;computer engineering	SE	-63.19207839236598	30.389889178507286	171117
4c777c62f0b3723f4cfb7cdf545dfa264fab7ce8	a method for defining the implementation order of software projects under uncertainty	minimum marketable feature and project management;project manager;information technology	This article proposes a method for obtaining the optimal implementation order of software units in an information technology development project.		Eber A. Schmitz;Antonio J. Alencar;Carlos Mendes de Azevedo	2008		10.1145/1363686.1363879	project management;extreme project management;change order;software project management;computer science;knowledge management;software engineering;project management triangle;information technology;project charter;project planning;project portfolio management	SE	-64.83506319458911	21.34285274755589	171177
b412068abc397b3885a9ff6a330dcaaf848a33f4	towards a verbal decision analysis on the selecting practices of framework scrum	agile;scrum;elicitation of preferences;zapros lm;verbal decision analysis;framework	Considering that agile methodologies, in focus Framework SCRUM, are always more popular for Development Software Companies, and noticing that the mentioned companies cannot always apply every characteristics of the framework, this paper presents an application of methodologies from the Verbal Decision Analysis (VDA) framework to generate a rank of the SCRUM characteristics to be applied in a company. The paper consists on an application of a questionnaire for a group of experienced ScrumMasters and considers the elicitation of preferences of a decision maker for creating the final rank of alternative. The methodology from VDA framework selected to be applied for ranking the alternatives was ZAPROS-LM. The final rank of alternatives indicates a list of SCRUM practices, from the more preferable to less preferable one, according to the decision maker responses.	decision analysis;scrum (software development)	Thais Cristina Sampaio Machado;Plácido Rogério Pinheiro;Marcelo Marcony Leal de Lima;Henrique Farias Landim	2011		10.1007/978-3-642-25255-6_74	systems engineering;engineering;knowledge management;operations management	NLP	-74.06699611465196	23.633553521373003	171366
b77138d322edf016a969803f69cd26e78c49c78e	"""corrigendum to """"reverse engineering applications for recovery of broken or worn parts and re-manufacturing: three case studies""""[advances in software engineering 40/6 (2009) 407-418]"""	software engineering;reverse engineering		reverse engineering;software engineering	Eyup Bagci	2011	Advances in Engineering Software	10.1016/j.advengsoft.2010.10.013	computer science;engineering;industrial engineering;reverse engineering;mechanical engineering	SE	-63.60613706346263	25.55378626081286	171446
baec4bdeb15591b48223d73b003b74d28edec47f	"""international workshop on empirical evaluation of agile methods (""""the data workshop"""")"""	agile methods;tratamiento palabra;procesamiento imagen;programmation agile;agile programming;software requirements;customer value;reconocimiento patron;empirical evaluation;empirical research	  Imagine the benefits of knowing that an XP project expends more effort understanding software requirements than does a team  using a typical traditional, or waterfall approach. Imagine the benefits of being able to predict that for this particular  combination of customer, product, and project team, agile modeling is going to benefit the team more than a strict XP implementation.      As compared to last year, agile methods are increasingly closer to the mainstream. This means that more organizations require  support and more detailed understanding of how agile methods will affect their development teams. In addition, these organizations  want to assess the customer value that the teams deliver through agile practices. This workshop builds on the success of the  1st Workshop on Empirical Evaluation of Agile Methods at XP/Agile Universe 2002 in Chicago.      	agile software development	Grigori Melnik;Laurie A. Williams;Adam Geras	2003		10.1007/978-3-540-45122-8_26	agile usability engineering;agile software development;empirical process	NLP	-67.79597532006419	23.468467900566598	171831
59de1345496bb84c5ac5fe9056eabc1bab856299	test-driven development - an empirical evaluation of agile practice			agile software development;test-driven development	Lech Madeyski	2010		10.1007/978-3-642-04288-1		SE	-65.08182629297606	22.971728030435806	171879
052b3c01237441f9c9072d4b07d81f82dfcc7278	delivering requirements research into practice: a keynote to the refsq'2011 conference	numerical method;software engineering;industrial practice;requirements engineering;exploitation and dissemination;large scale;requirement engineering;applied research	Requirements research over the last 25 years has delivered numerous methods, techniques and tools. These methods, techniques and tools have been reported in requirements and software engineering journals and conferences, often with small-scale evaluations based on experiments and controlled studies. Alas few of these methods, techniques and tools have been applied to largescale requirements problems or transferred to widespread requirements practice. This keynote reviews the challenges that researchers face to apply research solutions to requirements practices. It demonstrates how some of these challenges have been overcome with presentations of cases that show the application of requirements research on large-scale industrial projects, and reflect on how these successes were achieved. The keynote ends with proposals to deliver more requirements research into practice.	experiment;requirement;software engineering	Neil A. M. Maiden	2011		10.1007/978-3-642-19858-8_1	requirements analysis;requirements management;economics;business requirements;numerical analysis;computer science;systems engineering;engineering;requirement;software engineering;requirements elicitation;management science;requirements engineering;management;software requirements	SE	-66.44779669315531	23.41502426329174	171902
8039aff2acaa546fb51ad6084f16d60c34cf92f9	unifying documentation teams	documentation standards;distributed teams;distributed team;software development methodology;lessons learned;organizational development	This paper describes how a set of geographically and organizationally distributed documentation teams created the Rational Suite 1.0 documentation set. The paper covers the business operations of Rational Software, details the documentation tools and technologies used in the project and describes the evolution of the larger team as it learned how to work with a new software development methodology. The paper concludes with a summary of lessons learned and next steps.	coherence (physics);documentation;email;iteration;iterative and incremental development;new product development;software development process;web server	Karl A. Hakkarainen	1999		10.1145/318372.318591	knowledge management;software engineering;software documentation;management;organization development;software development process;software system	SE	-64.19512458674957	22.833614318974433	172053
403f14fee60834f69820b4d4b1a6bb527fce7580	the integration of software engineering into a computer science curriculum	integrated approach;software development process;computer science curriculum;software engineering;software engineering education;introductory computer science;software quality;software engineering practices	This paper discusses ideas and techniques for integrating software engineering concepts and practices into an undergraduate computer science curriculum. Discussion is focused on concepts that are related to the following aspects of software engineering: the need for software engineering, characteristics of good software, the software development process, estimation and planning, working in teams, specification of requirements, software design, and software quality issues.  The computer science curriculum at Embry-Riddle Aeronautical University is used as an illustrative example of how these concepts can be integrated into an undergraduate computer science program, from introductory computer science courses to a senior project course. The paper starts with a description of the current state of software engineering education. After a discussion of Emory-Riddle's computer science curriculum structure, the authors propose a set of software engineering concepts that should be included in an undergraduate program. Finally, guidelines for incorporating these concepts into a computer science curriculum are presented, and there is a discussion of the benefits of the integrated approach: the relevance of the curriculum to software engineering practices, the experience that students gain through collaboration and teamwork, and the satisfaction that employers show with graduates of such a program.    		Thomas B. Hilburn;Iraj Hirmanpour;Andrew J. Kornecki	1995		10.1007/3-540-58951-1_94	personal software process;verification and validation;computing;software engineering process group;computer science;systems engineering;package development process;social software engineering;component-based software engineering;software development;software engineering;software construction;software walkthrough;resource-oriented architecture;software deployment;software requirements;software system;computer engineering;software peer review	SE	-65.91618590026773	25.417118607215766	172298
05188ab88afa0c1e7aa4d51e99e804284651885b	quantification of non-functional requirements	software;bayesian network;bayesian network nonfunctional requirement quantification requirement analysis quality software development design phase implementation phase software project software reliability fuzzy sets;bayes methods;fuzzy sets;probability distribution;systems analysis bayes methods fuzzy set theory software quality software reliability;bayes methods software probability distribution software reliability mathematical model equations;mathematical model;bayesian network non functional requirements nfrs software reliability fuzzy sets;software reliability;non functional requirements nfrs	Requirements Analysis is considered as the most important phase for the development of quality software because errors caused by poor and inadequate requirement analysis are likely to creep in design and implementation phase. These errors are observed as time-consuming and most expensive to repair. Thus, Requirement Analysis is the phase, which determines the success or failure of a software project. Poor requirement analysis increases the cost of development by 70-85%, which requires reworking on all phases of software project. It is observed that non-functional properties are often ignored while focusing on the functionality of the software. Many software systems have failed because of negligence of non-functional requirements. Therefore, it is necessary to measure the satisfaction level of non-functional requirement during software development process.	algorithm;bayesian network;feature creep;functional requirement;fuzzy concept;fuzzy set;non-functional requirement;problem domain;randomness;requirements analysis;set theory;software development process;software project management;software reliability testing;software system	Kiran Khatter;Arvind Kalia	2014	2014 Seventh International Conference on Contemporary Computing (IC3)	10.1109/IC3.2014.6897177	probability distribution;software requirements specification;verification and validation;requirement prioritization;software sizing;software verification;computer science;software design;software reliability testing;machine learning;software construction;bayesian network;mathematical model;data mining;fuzzy set;functional requirement;goal-driven software development process;software quality;software metric;statistics;software quality analyst	SE	-62.915089852389286	31.692562878120693	172302
a130abbb4b21b35bf1537db727b631a80530f8ba	the algorithmic autoregulation software development methodology	distributed development;hacking;gsd;aa;global software development;free software	We present a new self-regulating methodology for coordinating distributed team work called Algorithmic Autoregulation (AA), based on recent social networking concepts and individual merit. Team members take on an egalitarian role, and stay voluntarily logged into so-called AA sessions for part of their time (e.g. 2 hours per day), during which they create periodical logs — short text sentences — they wish to share about their activity with the team. These logs are publicly aggregated in a Website and are peer-validated after the end of a session, as in code review. A short screencast is ideally recorded at the end of each session to make AA logs more understandable. This methodology has shown to be well-suited for increasing the efficiency of distributed teams working on what is called Global Software Development (GSD), as observed in our experience in actual realworld situations. This efficiency boost is mainly achieved through 1) built-in asynchronous on-demand communication in conjunction with documentation of work products and processes, and 2) reduced need for central management, meetings or time-consuming reports. Hence, the AA methodology legitimizes and facilitates the activities of a distributed software team. It thus enables other entities to have a solid means to fund these activities, allowing for new and concrete business models to emerge for very distributed software development. AA has been proposed, at its core, as a way of sustaining self-replicating hacker initiatives. These claims are discussed in a real casestudy of running a distributed free software hacker team called Lab Macambira. Key-words: global software development; distributed development; hacking; free software.	distributed computing;documentation;entity;screencast;self-replication;software development	Renato Moraes Alves Fabbri;Ricardo Fabbri;Vilson Vieira da Silva Junior;Daniel A Peñalva;Danilo Shiga;Marcos Mendonca;Alexandre Negrao;Lucas Zambianchi;Gabriela Thume	2015	CoRR	10.5329/RESI.2014.130200	hacker;personal software process;team software process;simulation;computer science;engineering;software engineering;management;world wide web	SE	-73.55010896502739	18.588451226493014	172457
2ce81339be79bfc3d0c3ed2e2e552f84adcc804b	requirements engineering in rail transit production: an experience report	railway engineering;embedded systems;safety;control engineering computing;software quality	Software is an increasing part of train control systems, calling for the integration of sound software design techniques into consolidated industrial systems' engineering processes. Although requirements engineering is a traditional software engineering area, its relevance for critical embedded systems is underestimated. We present the experience of a public-private collaboration between University of Naples and Ansaldo Breda, a leading company in the field of rail transit systems. The experience is focused on requirements engineering as a driver to improve the development process in order to better support, in the long term, software quality and safety assurance activities, at the same time with a proper cost/quality trade-off (higher quality costs are compensated through reuse over a product line).	control system;embedded system;industrial engineering;relevance;requirements engineering;software design;software engineering;software quality	Fernanda Buonanno;Domenico Di Leo;Paolo di Paolo;Roberto Pietrantuono;Stefano Russo	2013	2013 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)	10.1109/ISSREW.2013.6688919	reliability engineering;requirements analysis;verification and validation;software engineering process group;information engineering;system of systems engineering;systems engineering;engineering;social software engineering;software development;requirement;railway engineering;software engineering;domain engineering;applied engineering;software construction;transport engineering;requirements engineering;systems development life cycle;software quality control;software requirements;software quality;software quality analyst;software system;computer engineering;mechanical engineering	SE	-63.115581176272	25.87257204825964	172840
34212f1de526376ffb395ec7da9d1f983434ad48	utilizing online serious games to facilitate distributed requirements elicitation	serious games;innovative requirements elicitation;global software development;article	Requirements elicitation is one of the most important and challenging activities in software development projects. A variety of challenges related to requirements elicitation are reported in the literature, of which the lack of proper communication and knowledge transfer between software stakeholders are among the most important. Communication and knowledge transfer are becoming even bigger challenges with the current increase in globally distributed software development projects due to the temporal, geographic, and sociocultural diversity among software stakeholders. In this study, we propose a new approach to requirements elicitation, which employs online serious games for gathering requirements from distributed software stakeholders. The feasibility and effectiveness of the proposed approach were evaluated in an empirical study with encouraging results. These results especially reveal that our suggested approach enables less-experienced individuals to identify a higher number of requirements. Our results also reveal that for the majority of subjects, especially individuals with less technical experience, this approach was a pleasant and easy way of participating in requirements elicitation. Based on these results we suggest that using online serious games not only enhances innovation and creativity among end-users but also facilitates collaboration and communication among software stakeholders. Implications for both research and practice are considered. 1 Corresponding author. Present address: University of Jyvaskyla, Department of Computer Science and Information Systems, P.O.Box 35, FI40014, University of Jyvaskyla, Finland	computer science;distributed computing;effective method;experience;experiment;information systems;plan;pro tools;requirement;requirements elicitation;software development;user requirements document	Hadi Ghanbari;Jouni Similä;Jouni Markkula	2015	Journal of Systems and Software	10.1016/j.jss.2015.07.017	requirements analysis;requirements management;simulation;business requirements;systems engineering;engineering;knowledge management;requirement;requirements elicitation	SE	-71.76584830584785	20.804826280885763	172857
7f4461db71f2cd139cf96a941797e6b1660af0ed	the second international workshop on automated program analysis, testing and verification	software system;total development cost;reduced cost;program analysis;international workshop;automated program analysis;successful workshop;key technique;software complexity;current start-of-the-art;thorough analysis;software systems	Program analysis, testing and verification are key techniques for building confidence in and increasing the quality of software systems. Such activities typically cost upwards of 50% of total development costs. Automation aims to allow both reduced costs and more thorough analysis, testing and verification and is vital to keep pace with increasing software complexity. This workshop follows on from the successful workshop held as part of ICSE 2000 in Ireland to further discuss these issues and the current start-of-the-art.	automation;icse;program analysis;programming complexity;software system	Nigel Tracey;John Penix;Willem Visser	2001		10.1109/ICSE.2001.919162	program analysis;personal software process;verification and validation;software engineering process group;system integration testing;software verification;computer science;systems engineering;engineering;package development process;backporting;social software engineering;software reliability testing;software development;software engineering;software construction;process modeling;software testing;software walkthrough;software deployment;software quality control;software quality;programming complexity;software quality analyst;software system;computer engineering;software peer review	SE	-62.92724445859	29.944195308980074	172925
11e7b39fe22ffa4353582089237281de989b13db	cost model based on software-process and process oriented cost system	cost control;cost estimation;cost model;software prosess	The paper attempted to establish a software process oriented cost system depend upon cost model based on software process. It considers that it is impossible to realize the cost oriented process control and process improvement in view of software artifact is a complete unit. Firstly, cost model based on software process is introduced, different from the cost model based on product unit; the paper defines the reusable software process as the object of cost-metric. And then the paper provides ontology of software process and cost-metric in order to give a semantic background of cost-metric object and metric data. The research of this paper emphasizes on establishing cost management system oriented to software process, realizing the software process related cost measure, data record, and thereafter realizing cost control during the project execution and cost estimation in the phase of software process modeling. At last the paper expounds the method of integrating cost systems into PSEEs.	analysis of algorithms;artifact (software development);process modeling;row (database);software development process	HongTao Chen;Jun Liu;ShengMing Gu	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.426	goal-driven software development process;systems engineering;software metric;software engineering process group;distributed computing;package development process;software development;team software process;empirical process (process control model);computer science;software sizing	SE	-63.70487209259874	20.865174929062746	172990
76192e4891ba99bc705ff7df04545fe6ceed24a4	predicting readability of data processing written materials	linguistic variable;cobol;data processing;maintenance management	Poorly written documentation adversely affects the acquisition, development, use, maintenance, management and control of application software. Readability formulas, comprised of certain linguistic variables, provide rough estimates of the potential difficulty of reading material. This paper illustrates the application of well-known readability formulas in a readability assessment of the 1985 ANSI COBOL Standard. The paper summarizes certain limitations of readability formulas and concludes with suggestions concerning the use of readability formulas in the evaluation of computer-related material.	cobol;documentation	Ronald A. Guillemette	1987	DATA BASE	10.1145/1017816.1017820	data processing;computer science;data mining;cobol;programming language;engineering drawing	AI	-69.62422729240532	31.904546605631754	173209
c4a8e30fb3529785bf2934a24a73079f65d54e65	evaluate the quality of foundational software platform by bayesian network	bayesian network;deficiency of data;software platform;metric;foundational software platform;quality evaluation;software quality;bayesian networks	The software quality model and software quality measurement model are the basis of evaluating the quality of the Foundational Software Platform (FSP), but it is quite difficult or even impossible to collect the whole metric data required in the process of the software quality measurement, which is the problem of the FSP quality evaluating. Bayesian networks are the suitable model of resolving the problem including uncertainty and complexity. By analyzing the problem domain of foundational software platform quality evaluation and comparing it with the characteristic domain of Bayesian networks, this paper proposed a method of evaluating the quality of the FSP by Bayesian network. The method includes three parts: node choosing, Bayesian network learning and Bayesian network inference. The results of the experiments indicate a Bayesian network for every quality characteristic should be built in practical quality evaluation of the FSP by the proposed method.	bayesian network	Yuqing Lan;Yanfang Liu;Mingxia Kuang	2010		10.1007/978-3-642-16527-6_43	verification and validation;variable-order bayesian network;computer science;machine learning;software construction;bayesian network;data mining;software quality;software metric	Robotics	-63.252060378562234	31.491918481777578	173502
777302047fa20df288aec1d2a72fef296deae4f2	knowledge management in software testing: a systematic snowball literature review		Background: Software testing benefits from the usage of Knowledge Management (KM) methods and principles. Thus, there is a need to adopt KM to the software testing core processes and attain the benefits that it provides in terms of cost, quality, etc. Aim: To investigate the usage and implementation of KM for software testing. The major objectives include 1. To identify various software testing aspects that receive more attention while applying KM. 2. To analyse multiple software testing techniques, i.e. test design, test execution and test result analysis and highlight KM involvement in these. 3. To gather challenges faced by industry due to the lack of KM initiatives in software testing. Method: A Systematic Literature Review (SLR) was conducted utilizing the guidelines for snowballing reviews by Wohlin. The identified studies were analysed in relation to their rigor and relevance to assess the quality of the results. Results: The initial resulting set provided 4832 studies. From these, 35 peer-reviewed papers were chosen among which 31 are primary, and 4 are secondary studies. The literature review results indicated nine testing aspects being in focus when applying KM within various adaptation contexts and some benefits from KM application. Several challenges were identified, e.g., improper selection and application of better-suited techniques, a low reuse rate of software testing knowledge, barriers in software testing knowledge transfer, no possibility to quickly achieve the most optimum distribution of human resources during testing, etc. Conclusions: The study brings supporting evidence that the application of KM in software testing is necessary, e.g., to increase test effectiveness, select and apply testing techniques. The study outlines the testing aspects and testing techniques that benefit their users.		Krzysztof Wnuk;Thrinay Garrepalli	2018	e-Informatica	10.5277/e-Inf180103	systems engineering;software;systematic review;reuse;computer science;test design;knowledge management;knowledge transfer	SE	-70.09323330164915	21.828669564523015	173508
2586d96bc23b89b6e5cc1da9da6bde07d415d9e8	formal methods software engineering for the cara system	formal specification;formal methods software engineering;statistical test;satisfiability;software engineering;formal method;software development;sequence enumeration;medical device;cleanroom	This paper discusses the application of formal methods software engineering (FMSE) to the development of the Computer Automated Resuscitation A (CARA) medical device at Walter Reed Army Institute of Research. Because this system is potentially life critical, a high level of quality was required. A formal engineering approach to the software development activities was chosen to satisfy this need. Specifically, a technique called sequence enumeration was applied to elicit and refine requirements while deriving a formal specification. The fundamentals of the specification process that was used on the project are described along with a brief summary of the project experience in the development and testing phases. The project employed recent advances in Cleanroom software engineering methods along with older box-structured development and usage-model-based statistical testing techniques.	cleanroom software engineering;display resolution;executable;formal methods;formal specification;high-level programming language;natural language;requirement;software development;software documentation;software system	John C. Martin	2003	International Journal on Software Tools for Technology Transfer	10.1007/s10009-003-0113-x	statistical hypothesis testing;personal software process;software requirements specification;verification and validation;formal methods;software engineering process group;cleanroom;formal verification;software verification;search-based software engineering;computer science;package development process;software design;social software engineering;software development;requirement;software engineering;software construction;formal specification;software testing;systems development life cycle;programming language;software development process;software requirements;algorithm;software system;satisfiability	SE	-63.04506270687579	26.044165135257035	173537
0ab789cf9dc7eb1bfa8b5c4db95ae165c8507dcc	comparative case studies of open source software peer review practices	virtual community;software peer review;design;open source software	Context: The power of open source software peer review lies in the involvement of virtual communities, especially users who typically do not have a formal role in the development process. As communities grow to a certain extent, how to organize and support the peer review process becomes increasingly challenging. A universal solution is likely to fail for communities with varying characteristics. Objective: This paper investigates differences of peer review practices across different open source software communities, especially the ones engage distinct types of users, in order to offer contextualized guidance for developing open source software projects. Method: Comparative case studies were conducted in two well-established large open source communities, Mozilla and Python, which engage extremely different types of users. Bug reports from their bug tracking systems were examined primarily, complemented by secondary sources such as meeting notes, blog posts, messages from mailing lists, and online documentations. Results: The two communities differ in the key activities of peer review processes, including different characteristics with respect to bug reporting, design decision making, to patch development and review. Their variances also involve the designs of supporting technology. The results highlight the emerging role of triagers, who bridge the core and peripheral contributors and facilitate the peer review process. The two communities demonstrate alternative designs of open source software peer review and their tradeoffs were discussed. Conclusion: It is concluded that contextualized designs of social and technological solutions to open source software peer review practices are important. The two cases can serve as learning resources for open source software projects, or other types of large software projects in general, to cope with challenges of leveraging enormous contributions and coordinating core developers. It is also important to improve support for triagers, who have not received much research effort yet. 2015 Elsevier B.V. All rights reserved.	biconnected component;blog;bug tracking system;design rationale;documentation;emergence;focus group;hoc (programming language);knowledge management;online community;open sound system;open-source software;peer-to-patent;peripheral;python;secondary source;software bug;software peer review;virtual community	Jing Wang;Patrick C. Shih;Yu Wu;John M. Carroll	2015	Information & Software Technology	10.1016/j.infsof.2015.06.002	software review;design;technical peer review;peer review;computer science;engineering;knowledge management;software engineering;database;software technical review;software walkthrough;world wide web;software peer review	SE	-74.60816218008017	21.486281586057128	173861
594f7415000665972afe3128b439e55410d28d75	computer software and applications	computer software	computer software		Xiaoqing Frank Liu;Carl K. Chang;Tsang Ming Jiang	2010	Journal of Systems and Software	10.1016/j.jss.2009.09.044	computing;software engineering;software construction;software walkthrough;computer-aided software engineering;software system;software peer review	SE	-63.48175137919177	25.778463546401998	174070
f8206eafb753b932502eedfee3c4a17481ecb4bb	software crowdsourcing platforms	outsourcing;software engineering;crowdtest crowdsourcing software development software engineering outsourcing software development phases;software development;software crowdsourcing testing computer bugs recruitment software engineering;crowdtest;software development phases;crowdsourcing	Software crowdsourcing is mediated by platforms that connect requesters (buyers) with online workers--the crowd. Thus, these platforms have emerged as an important stakeholder in software development. This article introduces them and groups them by development phase.	crowdsourcing;software development	Alexandre Lazaretti Zanatta;Leticia Machado;Graziela Pereira;Rafael Prikladnicki;Erran Carmel	2016	IEEE Software	10.1109/MS.2016.151	personal software process;long-term support;verification and validation;software engineering process group;crowdsourcing software development;computer science;systems engineering;engineering;package development process;social software engineering;software development;software engineering;software construction;software release life cycle;software walkthrough;software analytics;resource-oriented architecture;software deployment;world wide web;crowdsourcing;software development process;outsourcing;software system;software peer review	SE	-64.66939982626803	22.9063255533256	174181
c42182e23a36893ffbe2033dc7f494ffc4d46e75	a meta-model for software development resource expenditures	model generation;data collection;resources;goddard space flight center;data bases;software engineering;systemeering;development strategies;statistical analysis;cost estimates;lifecycle;software engineering laboratory;software development;model development;organizations;models;meta model;environmental factor	One of the basic goals of software engineering is the establishment of useful models and equations to predict the cost of any given programming project. Many models have been proposed over the last several years, but, because of differences in the data collected, types of projects and environmental factors among software development sites, these models are not transportable and are only valid within the organization where they were developed. This result seems reasonable when one considers that a model developed at a certain environment will only be able to capture the impact of the factors which have a variable effect within that environment. Those factors which are constant at that environment, and therefore do not cause variations in the productivity among projects produced there, may have different or variable effects at another environment.  This paper presents a model-generation process which permits the development of a resource estimation model for any particular organization. The model is based on data collected by that organization which captures its particular environmental factors and the differences among its particular projects. The process provides the capability of producing a model tailored to the organization which can be expected to be more effective than any model originally developed for another environment. It is demonstrated here using data collected from the Software Engineering Laboratory at the NASA/Goddard Space Flight Center.	coefficient of determination;mac os x 10.3 panther;metamodeling;nonlinear system;software development;software engineering;univac	J. W. Bailey;Victor R. Basili	1981			metamodeling;simulation;systems engineering;organization;engineering;software development;software engineering;cost estimate;resource;data collection	SE	-66.61198108824128	31.78081719552945	174318
915967fda30522367b67d93ac17807e64a207e60	an agile perspective on open source software engineering	agile software development;open source software oss;implementation;development processes;software engineering principles	Open source software (OSS) development has been a trend parallel to that of agile software development, which is the highly iterative development model following conventional software engineering principles. Striking similarities exist between the two development processes as they seem to follow the same generic phases of software development. Both modes of development have less emphasis on planning and design and a more prominent role for implementation during the software engineering process. This chapter expounds on this connection by adopting an agile perspective on OSS development to emphasize the similarities and dissimilarities between the two models. An attempt is fi rst made to show how OSS development fi ts into the generic agile development framework. Then, the chapter demonstrates how the development process of Mozilla and Apache as two of the most famous OSS projects can be recast within this framework. The similarity discussed and illustrated between agile and OSS development modes is rather limited to the mechanics of the development processes and do not include the philosophies and motivations behind development.	fits;iterative and incremental development;iterative method;open sound system;software development process;software engineering	Sofiane Sahraoui;Noor Al-Nahas;Rania Suleiman	2012	IJOSSP	10.4018/ijossp.2012070105	feature-driven development;reliability engineering;personal software process;agile unified process;extreme programming practices;agile usability engineering;computer science;systems engineering;engineering;software evolution;social software engineering;software development;requirement;software engineering;iterative and incremental development;software construction;agile software development;systems development life cycle;programming language;empirical process;implementation;management;lean software development;goal-driven software development process;software development process;best coding practices	SE	-64.21843475017566	23.90920167544138	174538
c470df485c480b9521f49dff1c5b9f0a71cf4ff2	an sei process improvement path to software quality	software quality programming business software maintenance software systems software engineering management training communications technology history assembly systems;design model;software systems;design models;functional equivalence;formal quantification approach paradigm independent software assessment paradigm shifts software assets software products source code design models;ciencia;paradigm shift;software products;software assets;projetos;formal quantification approach;software development;paradigm shifts;investigacao;publicacoes;source code;iscte iul;software development management;paradigm independent software assessment	"""Software quality is growing in importance: we are increasingly dependent on software for everything from transportation to public safety. The Carnegie Mellonreg Software Engineering Institute has pioneered excellent methods for software process improvement, namely its capability maturity model integration (CMMIreg) and Team Software Processtrade (TSPtrade). This paper provides a brief overview of software quality and its history, a short treatment of CMMI, and an introduction to the TSPtrade , the SEI's """"how to"""" guide to achieving process maturity. Empirical results are presented."""	capability maturity model integration;software engineering institute;software development process;software quality	Philip Miller	2007	6th International Conference on the Quality of Information and Communications Technology (QUATIC 2007)	10.1109/QUATIC.2007.30	paradigm shift;reliability engineering;model-driven architecture;verification and validation;software sizing;software mining;computer science;systems engineering;engineering;package development process;software framework;component-based software engineering;software development;software design description;software engineering;software construction;software walkthrough;software analytics;resource-oriented architecture;software system	SE	-64.16731842238421	27.02437115602492	174559
bfb08d770860fb1b2320fc365e5a15705a36b675	improving software process improvement	standards;software process improvement;coordinate measuring machines productivity programming technological innovation software maintenance software quality manufacturing processes humans total quality management quality management;process improvement;empirical studies;organizational behavior;user satisfaction;procurer risks software process improvement disciplined work creative work user satisfaction;software process	0 7 4 0 7 4 5 9 / 0 2 / $ 1 7 . 0 0 © 2 0 0 2 I E E E ISO 9000, the Capability Maturity Model,1,2 Spice (Software Process Improvement and Capability Determination, also known as ISO/IEC 15504), and Bootstrap to promote mature software development practices. The CMM has been supplemented with the Ideal improvement model, the Personal Software Process, and Team CMM. Most of these frameworks have become well known among practitioners and researchers. In the US, more than 1,000 CMM-based assessments have been carried out. From 1994 to 2000, the Commission of the European Union funded more than 450 so-called process improvement experiments (PIEs) through its European Systems and Software Initiative (ESSI). Despite the amount of resources spent on these improvement efforts, several critical issues are still open, as the many ongoing initiatives, projects, and standardization efforts testify. In particular, evaluating whether an assessment and consequent improvement plan have had a causal, significant, and positive impact on company success is difficult. Certainly, some studies show that process assessment techniques benefit software development organizations.3 In reality, these positive effects are not so evident. Some researchers claim that most improvement initiatives have had limited success.4 Further, companies such as Microsoft have developed successful commercial software without adhering to external process standards or pursuing ambitious improvement initiatives. The problems go deeper than just needing to downsize and tailor SPI frameworks. As the Spice and CMM experience has shown, rather than just repair and adjust the process (model), we should also question some underlying assumptions and refocus SPI to be more companyand user-oriented. Indeed, one of the basic SPI-QA (quality assurance) assumptions is that “the quality of a softfocus	capability maturity model;causal filter;commercial software;experiment;iso/iec 15504;personal software process;spice;semantic web service;software development;software quality assurance	Reidar Conradi;Alfonso Fuggetta	2002	IEEE Software	10.1109/MS.2002.1020295	personal software process;verification and validation;team software process;software quality management;software engineering process group;software project management;systems engineering;engineering;knowledge management;package development process;software design;social software engineering;software development;software engineering;software construction;process management;software walkthrough;empirical process;empirical research;management;software deployment;software quality control;goal-driven software development process;software development process;software quality;software quality analyst;organizational behavior;software peer review	SE	-69.76432710309817	18.42033153668689	174575
e0874bcc67280a101ba0dc12db6f34c84a8779b8	work breakdown structure: a tool for software project scope verification		Software project scope verification is a very important process in project scope management and it needs to be performed properly and thoroughly so as to avoid project rework and scope creep. Moreover, software scope verification is crucial in the process of delivering exactly what the customer requested and minimizing project scope changes. Well defined software scope eases the process of scope verification and contributes to project success. Furthermore, a deliverable-oriented WBS provides a road map to a well defined software scope of work. It is on the basis of this that this paper extends the use of deliverable-oriented WBS to that of scope verification process. This paper argues that a deliverable-oriented WBS is a tool for software scope verification	instruction creep;rework (electronics);software project management;work breakdown structure	Robert T. Hans	2013	CoRR	10.5121/ijsea.2013.4402	reliability engineering;verification and validation;work breakdown structure;software verification;software project management;computer science;systems engineering;software engineering	SE	-66.77525013180862	22.83495109789555	175123
72839ae2e869b6368934811871c1a835cc0c9e12	maturity status within front-end support organisations	front end;disaster management;virtual enterprises;information science;software maintenance;collaboration;testing;systemvetenskap;portfolios;computer industry;front end problem management;software engineering;concolic testing;directed random testing;front end support organisations;problem management process model maturity status front end support organisations front end problem management;maturity status;process model;management training;educational products;problem management process model;disaster management management training software maintenance collaboration testing computer industry educational products portfolios virtual enterprises software engineering;software development management	It may not be enough to develop mature processes at the back-end support level. Other strongly collaborating front-end support processes may substantially undermine them. For this reason, we have created CM3: Front-End Problem Management - a detailed problem management process model to be utilised at the front-end support level. In this paper, we present the CM3 maturity levels at the front-end support and match them against the industrial state of practice within 15 software organisations. Our goal is to establish the current status of support maturity using CM3: Front-End Problem Management. Our results show that the industrial processes studied suffice to provide basic problem management support at the front-end support level. However, only two out of 15 organisations studied have almost achieved the highest maturity level.	capability maturity model;problem solving;process modeling	Mira Kajko-Mattsson	2007	29th International Conference on Software Engineering (ICSE'07)	10.1109/ICSE.2007.51	information science;systems engineering;engineering;knowledge management;front and back ends;software engineering;process modeling;software testing;software maintenance;management;concolic testing;emergency management;collaboration	SE	-68.66542927566832	19.79224082877271	175185
53fa48a35a61de3c6c1e72b925800bd03749ff35	software process model for total factor productivity of agriculture				Rajni Jain;M. Alam A. K. SamimulAlamA.K.;Alka Arora	2011			agricultural economics;machine learning;artificial intelligence;computer science;software development process;total factor productivity;productivity;agriculture;productivity model;agricultural productivity	Theory	-64.17040066152225	22.107073976590314	175215
6766a4fc3121e8c38a06f08bb1b8b66fdf1834f0	agile user-centered design applied to a mobile multimedia streaming application	agile methods;mobile multimedia;mobile device;social values;usability study;multimedia streaming;mobile computer;user centered design;development process;extreme programming;mobile phone;software development;usability;mobile application;user acceptance	Mobile computing is leading a revolution. Multimedia consumption on mobile devices is increasing day by day. The most important factor for the success of such applications is user acceptance. Additionally, the success of a software development project is associated not only with tools and technologies but also depends on how much the development process is both user-centered and developer-oriented. We are working on a project to develop a multimedia streaming application for mobile phones. The paper describes our adopted development process: the integration of Extreme Programming (XP) --- one of the popular agile methods --- with User-Centered Design (UCD) and shows how the integrated process facilitates user-orientation and at the same time preserves the social values of the development team. The paper also presents a summary of a recently carried out usability study.	agile software development;user-centered design	Zahid Hussain;Martin Lechner;Harald Milchrahm;Sara Shahzad;Wolfgang Slany;Martin Umgeher;Peter Wolkerstorfer	2008		10.1007/978-3-540-89350-9_22	mobile search;simulation;mobile web;human–computer interaction;agile usability engineering;computer science;mobile technology;multimedia;mobile computing	EDA	-75.37144089597416	19.3956754083371	175395
f73ff5ff47518e577c34cd9fb0bee464438e82a3	a platform for empirical research on information system evolution		Software-intensive systems are subject to continuous change due to modification of the systems themselves and their environment. Methods for supporting evolution are a competitive edge in software engineering as software is operated over decades. Empirical research is useful to validate the effectiveness of these methods. However, empirical studies on software evolution are rarely comprehensive and hardly replicable. Collaboration in empirical studies may prevent these shortcomings. We analyzed the support for such collaboration and examined existing studies in a literature review. Based on our findings, we designed CoCoMEP– a platform for supporting collaboration in empirical research on software evolution by shared knowledge. We report lessons learned from the application of the platform in a large research programme.	information system;requirement;software engineering;software evolution	Robert Heinrich;Stefan Gärtner;Tom-Michael Hesse;Thomas Ruhroth;Ralf H. Reussner;Kurt Schneider;Barbara Paech;Jan Jürjens	2015		10.18293/SEKE2015-66	simulation;systems engineering;engineering;knowledge management;empirical process	SE	-68.26710359678708	21.079042146576537	175580
dabd442feb95264a6dc3d57ab1c40c3bd95ffacc	a software size measurement model for large-scale business applications	software;function likeness weights;empirical study;size measurement large scale systems application software management information systems programming software measurement project management computer science software engineering economic forecasting;requirement analysis software size measurement model large scale business applications software development lifecycle information systems function point analysis method rapid function point model telecommunication industry data complexity likeness weights function likeness weights;software cost estimation;complexity theory;information systems;telecommunication industry;software measurement;function point;biological system modeling;size measurement;rapid function point model function point analysis analogous approach;function point analysis;large scale business applications;requirement analysis;large scale;systems analysis software cost estimation;estimation;systems analysis;business;software development;system development;function point analysis method;information system;analogous approach;rapid function point model;software development lifecycle;data complexity likeness weights;software size measurement model	Software size measurement at the very early stages of the software development lifecycle has been one of the critical issues in the information system field. In order to plan and develop information systems successfully, it is necessary to obtain an initial estimate of the size of the system being undertaken. Based on Albrecht's function point analysis (FPA) method and using analogous approach, this paper develops a methodology that gives a more reliable and accurate predictor of software size at an early stage of the systems development process. The proposed model called rapid function point model (RFPA) mainly applies to large-scale business applications. In addition, an empirical investigation was conducted for validating this model using 20 large software projects data from telecommunication industry. The results of the empirical study confirm that the function likeness weights and data complexity likeness weights in the model are robust enough to be used when little data is available during the early stage of requirement analysis.	function point;information system;kerrison predictor;requirements analysis;software development process;software sizing	Jun Wu;Xi Cai	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.1413	software sizing;computer science;function point;software engineering;cosmic software sizing;information system	SE	-65.87395883101499	28.7052188786858	175863
facc96c47571ea30966621d2439660f54bae4feb	encouraging privacy by design concepts with privacy policy auto-generation in eclipse (page)	eclipse plug in;software development;privacy policies	Many novice software developers do not have the training, experience or appropriate resources in developing privacy policies for their applications. Anecdotal evidence suggests that some new software developers create original, natural language privacy policies, use existing privacy policies as templates or an external agency (i.e., a legal counsel). This paper presents an overview of the privacy Policy Auto-Generation in Eclipse (PAGE), a work-in-progress that seeks to integrate privacy planning capabilities into the Eclipse integrated development environment (IDE), enabling application developers to create privacy policies as development occurs. This should support privacy by design concepts, enhance team communication through reusability, as well as reduce costs due to errors or extra time in external activities.	eclipse;integrated development environment;natural language;privacy by design;privacy policy;software developer	Mark Rowan;Josh Dehlinger	2014		10.1145/2688130.2688134	privacy software;privacy policy;information privacy;privacy by design;computer science;software development;operating system;software engineering;internet privacy;world wide web;computer security	SE	-72.3751802283091	30.181463664689932	176008
c3fbc4134562b75c841da8a7fb44cfb9e5968e66	the first decade of an undergraduate degree programme in software engineering	software engineering	This paper describes the development of an undergraduate degree programme in software engineering over the ten year period from 1988 to 1998. Particular emphasis is given to the fundamental principles that have been established to guide the creation and evolution of this programme during this period, and to ensure that it has been distinctively a course in software engineering rather than in any other branch of computing. To this end, the fundamental engineering characteristics of the programme are compared with those of undergraduate courses in other branches of engineering. Desirable future developments in this programme are then discussed, and finally the different principles identified in the paper are evaluated.	software engineering	Anthony J. Cowling	1998	Ann. Software Eng.	10.1023/A:1018940911475	software engineering process group;computer science;systems engineering;engineering;social software engineering;software engineering;mechanical engineering	SE	-66.10333735597484	25.87727919643156	176009
25976348d7ff1e19bad9aec173323d4fe2f7ae77	identification of more risks can lead to increased over-optimism of and over-confidence in software development effort estimates	cognitive science;computacion informatica;human judgment;grupo de excelencia;effort estimation;ciencias basicas y experimentales;software development;risk assessment	Software professionals are, on average, over-optimistic about the required effort usage and over-confident about the accuracy of their effort estimates. A better understanding of the mechanisms leading to the over-optimism and over-confidence may enable better estimation processes and, as a consequence, better managed software development projects. We hypothesize that there are situations where more work on risk identification leads to increased over-optimism and over-confidence in software development effort estimates, instead of the intended improvement of realism. Four experiments with software professionals are conducted to test the hypothesis. All four experiments provide results in support of the hypothesis. Possible explanations of the counter-intuitive finding relate to results from cognitive science on ''illusion-of-control'', ''cognitive accessibility'', ''the peak-end rule'' and ''risk as feeling.'' Thorough work on risk identification is essential for many purposes and our results should not lead to less emphasis on this activity. Our results do, however, suggest that it matters how risk identification and judgment-based effort estimation processes are combined. A simple approach for better combination of risk identification work and effort estimation is suggested.	software development	Magne Jørgensen	2010	Information & Software Technology	10.1016/j.infsof.2009.12.002	reliability engineering;risk assessment;simulation;engineering;software development;management	SE	-70.9117438220496	23.685714764968154	176138
f4b97bc8b9dc90ecd596a35c42c25bb3f3156f1f	an improved strategic information management plan for medical institutes	strategic information management plan;knowledge engineering and management;software development;electronic medical record;software quality engineering	In recent years the driving force behind software development of the Electronic Medical Record (EMR) has been gradually changing. Heterogeneous software requirements have emerged, so how to correctly carry out development project has become a complex task. This paper adopts the knowledge engineering and management mechanism, i.e. CommonKADS, to improve existing strategic information management (SIM) plan as a design methodology to assist in software implementation for medical institutes. Moreover, the concept of software quality engineering is integrated into the proposed plan. We evaluate the adopting performance by a real case. After describing the adopting details, this study further examines the maturity level of the architecture alignment between the target solution analyzed in the proposed plan and the built medical system.	capability maturity model;channel (communications);component-based software engineering;display resolution;excalibur: morgana's revenge;expectation propagation;experience;information management;knowledge acquisition and documentation structuring;knowledge engineering;quality engineering;requirement;software architecture;software development process;software quality;software requirements;test engineer	Tsung-Han Yang;Cheng-Yuan Ku;David C. Yen;Wen-Huai Hsieh	2016	Computer Standards & Interfaces	10.1016/j.csi.2015.11.001	personal software process;medical software;verification and validation;software engineering process group;software configuration management;software project management;knowledge management;package development process;social software engineering;software development;software design description;software engineering;software construction;database;software walkthrough;resource-oriented architecture;management;software deployment;software development process;software requirements;software quality;software system;software peer review	SE	-66.54403670204154	19.249106328973852	176450
f9dbba4277f66dc01a40b9b4455f375d676ff83a	using simulation to facilitate the study of software product line evolution	discrete event simulation;design model;strategic reuse;strategic management;software product line development;software product line engineering;software product line evolution;product line approach;aforementioned artifact;software process simulation modeling;software architecture;software maintenance;source code;software architecture design	A product line approach is a disciplined methodology for strategic reuse of source code, requirement specifications, software architectures, design models, components, test cases, and the processes for using the aforementioned artifacts. Software process simulation modeling is a valuable tool for enabling decision making for a wide variety of purposes, ranging from adoption and strategic management to process improvement and planning. In this paper, discrete event simulation is used to provide a framework for the simulation of software product line engineering. We have created an environment that facilitates strategic management and long-term forecasting with respect to software product line development and evolution.	automated planning and scheduling;bang file;concurrency (computer science);evolution strategy;level of detail;mathematical optimization;reduced cost;simulation;software architecture;software development process;software product line;stepping level;strategic management;test case	Yu Chen;Gerald C. Gannod;James S. Collofello;Hessam S. Sarjoughian	2004	Proceedings. 7th International Workshop on Principles of Software Evolution, 2004.	10.1109/IWPSE.2004.1334774	domain analysis;reliability engineering;software architecture;personal software process;verification and validation;software engineering process group;software sizing;computer science;systems engineering;engineering;package development process;software design;software framework;software development;discrete event simulation;software design description;software engineering;software construction;software walkthrough;software maintenance;software deployment;goal-driven software development process;software development process;software metric;strategic management;product engineering;source code	SE	-63.20274810495423	22.65669388739392	176820
ecd78528aff461a16b01a74e3d6ce8b804c56869	to agile or not to agile students (with a twist): experience report from a student project course		"""Agile software development and formal methods are seemingly on the opposite ends of the rigorousness scale. If carefully used, the can efficiently function in synergy to provide an evolutionary, iterative and tailorable process for a correct-by-construction system. In this work, we present the use of agile and formal methods in the academic context at the project course. We describe the development of the meeting scheduler – a web application, which utilised the Event-B formal method and the Vaadin framework within the Scrum development process. Our contribution includes remarks and advice for student projects regarding (i) the use of Scrum and (ii) the application of formal methods in """"traditional"""" software development. We believe that results can be to some extent transferred to an industrial setting, where learning new technologies is involved within agile development processes."""	academy;agile software development;b-method;curve fitting;formal methods;iteration;peopleware;relevance;requirement;scheduling (computing);scrum (software development);synergy;vaadin;web application	Marta Olszewska;Sergey Ostroumov;Mikolaj Olszewski	2017	2017 43rd Euromicro Conference on Software Engineering and Advanced Applications (SEAA)	10.1109/SEAA.2017.54	agile unified process;software development process;requirement;computer science;systems engineering;empirical process (process control model);agile software development;knowledge management;agile usability engineering;scrum;lean software development	SE	-65.96591149559318	22.500620145620285	176872
74e2a85d93b73249d804aa735a264546df8a7df6	defects, scientific computation and the scientific method	computer science and informatics	Computation has rapidly grown in the last 50 years so that in many scientific areas it is the dominant partner in the practice of science. Unfortunately, unlike the experimental sciences, it does not adhere well to the principles of the scientific method as espoused by for example, the philosopher Karl Popper. Such principles are built around the notions of deniability and reproducibility. Although much research effort has been spent on measuring the density of software defects, much less has been spent on the more difficult problem of measuring their effect on the output of a program. This paper explores these issues with numerous examples suggesting how this situation might be improved to match the demands of modern science. Finally it develops a theoretical model based on Shannon information which suggests that software systems have strong implementation independent behaviour and presents supporting evidence.	computation;computational science;entropy (information theory);experiment;open-source software;shannon (unit);software bug;software system;theory	Les Hatton	2011		10.1007/978-3-642-32677-6_8	computational science;engineering informatics;computer science;informatics engineering;theoretical computer science;informatics;materials informatics;information and computer science	PL	-67.61297308057102	29.11698518624455	177073
43111240f583bb25a45bcab97efac82efea76097	trust and vulnerability in open source software	trust;security of data public domain software;users;critical infrastructures;cyber criminal;vulnerability;software components;pitac;community of software developers;predictably secure systems;presidents information technology advisory committee;predictably reliable systems;closed source software;open source software;closed source software trust vulnerability open source software critical infrastructures presidents information technology advisory committee pitac software components predictably reliable systems predictably secure systems cyber criminal community of software developers users	Software plays an ever increasing role in the critical infrastructures that run our cities, manage our economies, and defend our nations. In 1999, the Presidents Information Technology Advisory Committee (PITAC) reported to the United States President the need for software components that are reliable, tested, modelled and secure supporting the development of predictably reliable and secure systems that underscore our critical infrastructures. Open source software (OSS) constitutes a viable source for software components. Some believe that OSS is more reliable and more secure than closed source software (CSS)—due to a phenomenon dubbed `many eyeballs'—but is this truly the case? Or does OSS give the cyber criminal an edge that he would likewise not have? In this paper, we explore OSS from the perspective of the cyber criminal and discuss what the community of software developers and users alike can do to increase their trust in both open source software and closed source software.	open-source software	Scott A. Hissam;Daniel Plakosh;Charles B. Weinstock	2002	IEE Proceedings - Software	10.1049/ip-sen:20020208	software security assurance;software review;long-term support;crowdsourcing software development;vulnerability;computer science;engineering;social software engineering;component-based software engineering;software development;operating system;software engineering;software as a service;database;software walkthrough;programming language;trustworthy computing;software analytics;software deployment;world wide web;computer security;software quality;software peer review	SE	-71.38540878330943	30.053807296097638	177133
d8fb7faee8f3b29f4c32bac396776e60c5fd9925	do review feedbacks influence to a contributor's time spent on oss projects?		Open Source Software (OSS) does not work without contributions from the community. In particular, long-term contributors (LTCs) (e.g., committer), defined as contributors who spend at least one year on OSS projects, play a crucial role in a project success because they would have permission to add (commit) code changes to a project’s version control system, and to become a mentor for a beginner in OSS projects. However, contributors often leave a project before becoming a LTC because most contributors are volunteers. If contributors are motivated in their work in OSS projects, they might not leave the projects. In this study, we examine the phenomena involved in becoming a LTC in terms of motivation to continue in OSS projects. In particular, our target motivation is to understand what is involved in long-term contribution with other expert contributors. We study classifier to identify a LTC who will contribute patch submissions for more than one year based on collaboration in terms of the code review process. In detail, we analyze what review feedbacks encourage a contributor to continue with OSS project. Using a Qt project dataset, we build a prediction model to identify a LTC. We find that not only contributor’s activities, but also a reviewer feedbacks, useful in identifying LTCs.	committer;control system;litecoin;open sound system;open-source software;statistical classification;version control	Takuto Norikane;Akinori Ihara;Kenichi Matsumoto	2018	2018 IEEE International Conference on Big Data, Cloud Computing, Data Science & Engineering (BCD)	10.1109/BCD2018.2018.00028	data mining;computer science;revision control;knowledge management;software;permission;commit;information science;code review	SE	-73.33982006697416	26.864494659768035	177228
a9957d210d19b3136207995f19177ea6526ddc45	the relationship between software development environments and the software process (panel session introduction)	program committee;software development environment;software process	The program committee originally planned for this panel session (and this introduction) to provide a summary of the 4th International Workshop on the Software Process. I have taken the liberty of covering a slightly more general view of the relationship between software development environments and the software process.	integrated development environment;software development process	David Notkin	1988		10.1145/64135.65013	personal software process;long-term support;verification and validation;team software process;software engineering process group;software project management;computer science;package development process;backporting;social software engineering;software development;software construction;development environment;software walkthrough;empirical process;software deployment;software development process;software system;software peer review	SE	-64.11322686005352	24.848932393498664	177463
74bf6925e92a75f0be87c32369efb8a50e1e2afc	a participant recruitment framework for crowdsourcing based software requirement acquisition	software engineering information retrieval;crowdsourcing based software requirement acquisition real world mobility model opportunistic participant recruitment framework spatiotemporal space domain knowledge requirements acquisition task;crowdsourcing software recruitment peer to peer computing spatiotemporal phenomena educational institutions analytical models;opportunistic network crowdsourcing;opportunistic network;crowdsourcing	The opportunity to leverage crowd sourcing-based model to facilitate software requirements acquisition has been recognized to maximize the advantages of the diversity of talents and expertise available within the crowd. Identifying well-suited participants is a common issue in crowd sourcing system. Requirements acquisition tasks call for participants with particular kind of domain knowledge. However, current crowd sourcing system failed to provide such kind of identification among participants. We observed that participants with a particular kind of domain knowledge often have the opportunity to cluster in particular spatiotemporal spaces. Based on this observation, we propose a novel opportunistic participant recruitment framework to enable organizers to recruit participants with desired kind of domain knowledge in a more efficient way. We analyzed the feasibility of our opportunistic approach through both theoretic study on analytical model and simulated experiment on real world mobility model. The results showed the feasibility of our approach.	crowdsourcing;experiment;requirement;simulation;software requirements;software testing;theory;whole earth 'lectronic link	Hao Wang;Yasha Wang;Jiangtao Wang	2014	2014 IEEE 9th International Conference on Global Software Engineering	10.1109/ICGSE.2014.26	simulation;crowdsourcing software development;computer science;engineering;data mining;world wide web;crowdsourcing	SE	-76.75324359317649	19.774346601540255	177783
5550969f990cd92105be7924e37d62e62a7445ea	helena stage 2 - danish overview		Since the early days of software engineering, a number of methods, processes, and practices to design and develop software systems have been proposed and applied in industry, e.g., the Rational Unified Process, Agile Software Development, etc. However, since no silver bullet exists, organizations use rich combinations of agile and/or traditional methods and practices, rather than following a single process by the book. To investigate this reality, an international exploratory multistage research project named HELENA (Hybrid DEveLopmENt Approaches in software systems development) was initiated. Currently, the HELENA survey is conducted globally (second stage of HELENA project). This short paper presents and discusses the results of the survey in Danmark compared to the global results based on the data from August 15, 2017.	agile software development;multistage amplifier;no silver bullet;rational unified process;software development process;software engineering;software system	Paolo Tell;Rolf-Helge Pfeiffer;Ulrik Pagh Schultz	2017		10.1007/978-3-319-69926-4_31		SE	-66.38155019098288	23.479981195278132	177810
d483c767afd12541debb2efe6b2be5f1a72882b0	iamps: an process to support the mps.br implementation together with agile methods	mps br agile method maturity model;public sector iamps mps br agile methods software development small and medium sized organizations mses micro and small sized enterprises software process improvement deployment;software prototyping dp industry small to medium enterprises software process improvement;software adaptation models capability maturity model process control context modeling computational modeling abstracts	The MPS.BR is a program to help improve the processes of software development mainly in small and medium-sized organizations, however it does not determine how processes should be defined to reach a certain degree of maturity. From another perspective, there is growing acceptance and records of success in the use of agile methods, mainly in MSEs (micro and small-sized enterprises of software development). Thus, it can be considered that both approaches can be used together to enable the implementation of lightweight processes and easily managed. In this context, this paper presents a process to support the implementation of MPS.BR together with agile practices in MSEs, called IAMPS, and discusses the main results obtained with its application in an initial project of software process improvement deployment in the public sector.	agile software development;capability maturity model;software deployment;software development process	Marcelo Benites Gonçalves;Maria Istela Cagnin;Débora Maria Barroso Paiva	2014	2014 XL Latin American Computing Conference (CLEI)	10.1109/CLEI.2014.6965151	team software process;software engineering process group;agile unified process;leancmmi;systems engineering;engineering;operations management;software development;process management;empirical process;lean software development;software deployment;software development process	SE	-68.6933417917875	20.189578589135735	178059
26d50ebcc9a02e43e1b135e4d3a517470014f392	repeated use of process models: the impact of artifact, technological and individual factors (extended abstract)		Business process modeling has received a lot of attention from practitioners and researchers alike. Organizations make significant investments into process modeling in terms of training, tools and resources. Yet, having invested into creating large process model collections, process models often fall into disuse, provoking the impression that the initial investment has been lost. In this paper we present a summary of a study on factors that facilitate or hinder the repeated use of process models by individual users. Results from that study indicate the importance of quality and ease of understanding of process models to repeated use, alongside individual factors, such as motivation and individual expertise. We also identified means that support organizations in promoting repeated process model use. The work summarized in this extended abstract has been published in [No16].	accessibility;business process;process modeling	Alexander Nolte;Eike Bernhard;Jan Recker;Fabian Pittke;Jan Mendling	2016			systems engineering;management science;process modeling;engineering	HCI	-71.80652971002553	22.987697080783015	178139
37dd5789e42fb2f027ff1fa101a1c4913e7ae0c2	handling the knowledge acquired during the requirements engineering process: a case study	quality attributes;management system;requirements engineering;agents;process modeling;requirement engineering;soft and hard goals;process model;quality model;software quality;quality modeling	Performing the requirements engineering process for software-intensive systems, characterized by a high organizational impact, requires the analysts to handle a large amount of information, related to desires, needs, and constraints of a vast number of completely different stakeholders. The paper presents an organization modeling-based requirements engineering framework, where advanced requirements engineering techniques are combined with software quality modelling approaches to support the analysts in capturing, and formalising the knowledge embedded in the organisation, from which the sought system functionality and quality attributes may be derived. The collected knowledge will not only support the specific project but will represent an organizational assetto be exploited for future systems/organization evolution. As a case study, the paper reports on an on-going project concerned with the development and introduction, within the Italian Office of the Prime Minister, of a Electronic Record Management System, as a first step towards a paperless knowledge workplace.	embedded system;list of system quality attributes;record management system;requirement;requirements engineering;software quality	Paolo Donzelli;Roberto Setola	2002		10.1145/568760.568876	requirements analysis;requirements management;software engineering process group;business requirements;systems engineering;engineering;knowledge management;requirement;software engineering;process modeling;management science;requirements engineering;management;functional requirement;non-functional requirement	SE	-63.74191275046326	20.06347006508844	178154
0cdc3764d7be152902f7e6dc2841d01cd14c870d	security fuzzing toolset	control systems;software testing;testing;software engineering;fuzzing;control system;research and development;software development;input validation;security testing;security	Although there has been a significant increase in security awareness among software developers during the past few years, there are still many developers who do not have the necessary expertise in developing secure programs. This concern has motivated the creation of a new set of automated tools, called fuzzers, which can provide security testing. This paper presents an on-going research and development of a security fuzzing toolset.	security awareness;security testing;software developer	Christopher Smith;Guillermo A. Francia	2012		10.1145/2184512.2184589	software security assurance;reliability engineering;security through obscurity;fuzz testing;security information and event management;security bug;engineering;software reliability testing;software engineering;software construction;software testing;security testing;computer security	Security	-63.3760747368976	29.76156496511379	178282
7f8ee460daa25d8ccf333eda205cf3434b2962b3	assessment of the requirements management process using a two-stage questionnaire	bad management;two-stage questionnaire;requirements management practice;requirements management process;assessment methodology;requirements management;industrial case study;formal specification	This research advocates the idea that although requirements management process is not carried out in many organizations, there are some people within the organization that perform some requirements management practices. However, these practices are usually not documented and as consequence are not spread across the organization. This paper proposes an assessment methodology based on a two-stage questionnaire to identify which practices of the requirements management process are performed but not documented, which practices require to be prioritized and which are not implemented due to bad management or unawareness. In order to validate the assessment methodology, the questionnaire was applied to an industrial case study.	requirement;requirements management	Gonzalo Cuevas Agustín;Alan Serrano;Ariel Serrano	2004	Fourth International Conference onQuality Software, 2004. QSIC 2004. Proceedings.	10.1109/QSIC.2004.1357951	reliability engineering;requirements analysis;personal software process;software requirements specification;verification and validation;requirements management;requirement prioritization;program management;extreme programming practices;software configuration management;software project management;computer science;systems engineering;engineering;software development;requirement;software engineering;formal specification;requirements engineering;application lifecycle management;software development process;software requirements;software peer review	SE	-69.43230205482635	21.77658875176669	178870
5cea331bdb0c5430c8897876430f3e9f41b74778	a strategy based on multiple decision criteria to support technical debt management		Technical debt (TD) refers to likely long-term costs associated with software development shortcuts taken by programmers to achieve short-term business benefits. If a development team does not manage TD, it can cause significant long-term problems such as high maintenance costs. Management strategies monitor debt items and evaluate when and if they should be paid. In order to effectively support this task, the systematic use of decision criteria can be decisive. In this context, this paper presents a strategy for TD management that uses multiple decision criteria to decide when to pay debt items off. In addition, it presents a case study that assessed the feasibility of the proposed strategy regarding its usefulness, ease of use and self-predicted future use. The results provided positive evidence on the use of the proposed strategy, indicating (i) that it can be useful in supporting TD management activities and (ii) that it can bring gains in terms of productivity, performance, and efficacy when evaluating the desirable time to pay debt items off.	decision problem;programmer;self-replicating machine;software development process;technical debt;toad data modeler;usability	Leilane Ferreira Ribeiro;Nicolli Souza Rios Alves;Manoel G. Mendonça;Rodrigo O. Spínola	2017	2017 43rd Euromicro Conference on Software Engineering and Advanced Applications (SEAA)	10.1109/SEAA.2017.37	multiple-criteria decision analysis;debt;computer science;management science;software development;maintenance engineering;software;usability;technical debt;reliability engineering	SE	-70.55926254928768	21.63889786859062	178873
cc4bbf90462354b5abfc7035732b0225f826f89e	scrum and plan-driven process integration and its impact on effort estimation	process integration		scrum (software development);software development effort estimation	Nelio Alves;William Carvalho;Edgard Lamounier	2010			systems engineering;process integration;computer science;scrum	AI	-64.65607524188647	22.691339778895248	178972
133e803febcf7c4366a781810145f4fce55e76d6	measurement, prediction and risk analysis for web applications	risk management world wide web development project management development effort risk analysis application quality measurement feedback authoring prediction model web design model case study evaluation software effort metrics software structure metrics software complexity metrics software reuse metrics software size metrics generalised linear model predictive power assessment;software metrics;information resources;complexity metrics;risk analysis;risk management;development process;authoring systems;risk analysis predictive models project management web design risk management resource management costs statistics feedback power generation;internet;web design;forecasting theory;prediction model;authoring systems information resources internet software metrics risk management software development management forecasting theory;generalised linear model;software development management;web development	Accurate estimates of development effort play an important role in the successful management of larger Web development projects. By applying measurement principles to measure qualities of the applications and their development processes, feedback can be obtained to help understand, control and improve products and processes. The objective of this paper is to present a Web design and authoring prediction model based on a set of metrics which were collected using a case study evaluation. The paper is organised into three parts: part I describes the case study evaluation (CSE) in which the metrics used in the prediction model were collected. These metrics were organised into five categories: effort metrics, structure metrics, complexity metrics, reuse metrics and size metrics. Part II presents the prediction model proposed, which was generated using a Generalised Linear Model (GLM), and assesses its prediction power. Finally, part III investigates the use of the GLM as a framework for risk management.	feedback;generalized linear model;reuse metrics;risk management;web application;web design;web development	Rachel M. Fewster;Emilia Mendes	2001		10.1109/METRIC.2001.915541	reliability engineering;web development;the internet;risk analysis;web design;risk management;computer science;systems engineering;data mining;predictive modelling;management;software development process;software metric	SE	-64.27071791089517	30.117385468052678	179043
caf9f91333c00c96985fd0bb02f1be4bb02b1cc1	information and software technologies		The paper propose methodology for benchmark modelling of adequate costs of utilities services, which is based on the data analysis of the factual cases (key performance indicators of utilities as the predictors). The proposed methodology was tested by modelling of Latvian water utilities with three tools: (1) a classical version of the multi-layer perceptron with error back-propagation training algorithm was sharpened up with task-specific monotony tests, (2) the fitting of the generalized additive model using the programming language R ensured the opportunity to evaluate the statistical significance and confidence bands of predictors, (3) the sequential iterative nonlinear regression process with minimizing mean squared error provided the notion of the impact of each predictor on the searched regularity. The quality of models is high: the adjusted determination coefficient is greater than 0.75, explained deviance exceeds 0.80, while the correlation between the respective modelled values exceeds even 0.95.	algorithm;backpropagation;benchmark (computing);coefficient;generalized additive model;iterative method;kerrison predictor;layer (electronics);mean squared error;multilayer perceptron;nonlinear system;programming language;sequal framework;software propagation	Giedre Dregvaite;Robertas Damaševičius;Alfredo Cuzzocrea;Dominik Slezak;Xiaokang Yang;Simone D. J. Barbosa	2016		10.1007/978-3-319-46254-7	personal software process;long-term support;computing;package development process;social software engineering;software development;software construction;software as a service;software analytics;resource-oriented architecture;software deployment;software quality;computer-aided technologies;software system;software peer review	AI	-72.08100454707902	25.093663795680015	179137
4370a4083cd2fcb3c1af5de6f0b07fa6ed5b6038	software process improvement motivators: an analysis using multidimensional scaling	empirical study;software process improvement;focus group;social science;multidimensional scaling;motivators;data analysis techniques;article;software practitioners;ssa	In this paper we present an analysis of software practitioners' motivations for software process improvement (SPI). Our findings are based on an empirical study of SPI in 13 software companies where we conducted focus groups with nearly 200 software practitioners. Our aim is to better understand how companies can maximise practitioner support for SPI. This insight should help SPI managers establish more effective SPI implementation strategies. In this paper we introduce the use of multidimensional scaling (MDS) in SPI research. MDS is a social science data analysis technique designed to generate a rich visual understanding of human issues. By using MDS we found evidence to suggest distinct clusters of punitive and rewarding SPI motivators. Furthermore our analysis also suggests that different clusters of motivations exist for different staff groups.	focus group;image scaling;multidimensional scaling;scalability;software development process;software industry	Nathan Baddoo;Tracy Hall	2002	Empirical Software Engineering	10.1023/A:1015203013834	social science;multidimensional scaling;computer science;systems engineering;knowledge management;focus group;management science;data analysis;empirical research;management	SE	-72.11525548871313	21.74841614085295	179310
f534093403f27532e7d26ceca9d45910e5a4197b	supporting scope tracking and visualization for very large-scale requirements engineering-utilizing fsc+, decision patterns, and atomic decision visualizations	software;requirements specifications;electronic mail;elektroteknik och elektronik;electrical engineering electronic engineering information engineering;power capacitors;companies;software engineering;change tolerant release scope management process scope tracking very large scale requirements engineering visualization fsc decision patterns atomic decision visualizations feature survival charts requirements scoping process very large scale requirements engineering vlsre;visualization;initiation and scope definition;d 2 1requirements specifications d 2 9 d initiation and scope definition d 2 9 management;planning;programvaruteknik;power capacitors companies planning visualization software software engineering electronic mail;management;formal specification data visualisation	Deciding the optimal project scope that fulfills the needs of the most important stakeholders is challenging due to a plethora of aspects that may impact decisions. Large companies that operate in rapidly changing environments experience frequently changing customer needs which force decision makers to continuously adjust the scope of their projects. Change intensity is further fueled by fierce market competition and hard time-to-market deadlines. Staying in control of the changes in thousands of features becomes a major issue as information overload hinders decision makers from rapidly extracting relevant information. This paper presents a visual technique, called Feature Survival Charts+ (FSC+), designed to give a quick and effective overview of the requirements scoping process for Very Large-Scale Requirements Engineering (VLSRE). FSC+ were applied at a large company with thousands of features in the database and supported the transition from plan-driven to a more dynamic and change-tolerant release scope management process. FSC+ provides multiple views, filtering, zooming, state-change intensity views, and support for variable time spans. Moreover, this paper introduces five decision archetypes deduced from the dataset and subsequently analyzed and the atomic decision visualization that shows the frequency of various decisions in the process. The capabilities and usefulness of FSC+, decision patterns (state changes that features undergo) and atomic decision visualizations are evaluated through interviews with practitioners who found utility in all techniques and indicated that their inherent flexibility was necessary to meet the varying needs of the stakeholders.	content-control software;hard time;information overload;requirement;requirements engineering;scope (computer science);zooming user interface	Krzysztof Wnuk;Tony Gorschek;David Callele;Even-André Karlsson;Eskil Ahlin;Björn Regnell	2016	IEEE Transactions on Software Engineering	10.1109/TSE.2015.2445347	planning;visualization;decision analysis;computer science;systems engineering;engineering;operating system;software engineering;data mining;management	SE	-68.7669178202017	23.703169915816616	179379
367339d7773bf246574578057177cefd1b3ccb73	managing software productivity and reuse	software process improvement software reusability software development management;investments;software process improvement;computer aided instruction;department of defense;differentiated service;software productivity management;software reuse management;non value adding tasks;software artifacts;internet;marine vehicles;airplanes;work avoidance;process improvements;workstations;software reusability;lab on a chip;productivity costs lab on a chip investments hardware internet marine vehicles airplanes workstations computer aided instruction;process improvement;productivity;software reuse management software productivity management process improvements non value adding tasks software artifacts work avoidance;software reuse;software development management;value added;hardware	Your organization can choose from three main strategies for improving its software productivity. You can work faster, using tools that automate or speed up previously labor-intensive tasks. You can work smarter, primarily through process improvements that avoid or reduce non-value-adding tasks. Or you can avoid unnecessary work by reusing software artifacts instead of custom developing each project. Which strategy will produce the highest payoff?		Barry W. Boehm	1999	IEEE Computer	10.1109/2.789755	personal software process;team software process;productivity;the internet;workstation;lab-on-a-chip;differentiated service;software project management;computer science;value added;package development process;software development;operating system;software engineering;domain engineering;software walkthrough;software deployment	SE	-67.82784833492221	26.133784765221076	179677
1da29c2a1dda2e74866529333a47cdf869fbed98	characterization of autonomy and interdependence in software engineering		Context: Autonomy and interdependence are work characteristics related to motivation that each individual has to complete her task. Objective: Verify if there is a correlation between autonomy and interdependence. Method: We made a survey of 185 Brazilian professionals of diverse areas, most of them belonging to Pernambuco State. The professionals were divided into two main groups, one of software engineers and another of other professions. We investigate five different constructors, three of them grouped as autonomy and remaining constructors as interdependence. Results: The comparison between samples showed that there are distinct characteristics between autonomy and interdependence. In addition, our sample and sub-samples showed different behaviors between both initiated and received interdependence. Conclusion: We were able to support some of the predicted hypotheses and identify areas for further research.	autonomy;engineering sample;interdependence;job design;software engineer	Itanaua F. Barbosa;Karla M. B. Silva;Marcela P. Oliveira;Priscila B. S. Reis;Fabio Q. B. da Silva	2017	2017 IEEE/ACM 10th International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE)	10.1109/CHASE.2017.15	computer science;job design;software;autonomy;knowledge management	SE	-72.51717053576414	21.119391000569223	179774
7ad4b43d402298135a63938b1d2d4b5942753361	the effects of time pressure on quality in software development: an agency model	software measurement;principal agent;time pressure;software development;agency theory;product quality;software estimating;software quality	Anagency framework is used to model the behavior of software developers as they weigh concerns about product quality against concerns about missing individual task deadlines. Developers who care about quality but fear the career impact of missed deadlines may take “shortcuts.” Managers sometimes attempt to reduce this risk via their deadline-setting policies; a common method involves adding slack to best estimates when setting deadlines to partially alleviate the time pressures believed to encourage shortcut-taking. This paper derives a formal relationship between deadline-setting policies and software product quality. It shows that: (1) adding slack does not always preserve quality, thus, systematically adding slack is an incomplete policy for minimizing costs; (2) costs can be minimized by adopting policies that permit estimates of completion dates and deadlines that are different and; (3) contrary to casual intuition, shortcut-taking can be eliminated by setting deadlines aggressively, thereby maintaining or even increasing the time pressures under which developers work. (Agency Theory; Principal-Agent; Software Quality; Software Measurement; Software Estimating)	.net framework;keyboard shortcut;slack variable;software developer;software development;software measurement;software quality	Robert D. Austin	2001	Information Systems Research	10.1287/isre.12.2.195.9699	principal–agent problem;real-time computing;simulation;software quality management;economics;marketing;operations management;software development;software measurement;management;social psychology;software quality control;computer security;software quality;software quality analyst	SE	-70.43936555621168	24.41665097435996	179978
a9a474dda3f10e5943cd050458ff51d09a124e78	metagile: an agile domain-specific modeling environment	agile domain-specific modeling environment;management information systems;outsourcing;computer networks;programming;project management;information technology;computer science;dsl;productivity	The outsourcing of building Management Information System (MIS) has been a mainstream in recent years. Providing efficient project management to these outsourcing projects has become an urgent issue. As the world biggest Information Technology (IT) consulting service provider, IBM Global Business Service (GBS) has successfully build numerous Management Information System for its customers. Such systems range from to, covering all aspects of MIS. During building these systems, IBM GBS has accumulated lots of experiences on project management. The poster provides some important elements of these elements. Besides, we also provide some key information on training project management staffs.	agile software development;domain-specific modeling;ibm notes;management information system;outsourcing	Yi Wang;Huihui Shi	2007	14th Asia-Pacific Software Engineering Conference (APSEC'07)	10.1109/APSEC.2007.68	project management;programming;computing;productivity;systems management;program management;information technology management;digital subscriber line;data management;systems engineering;engineering;knowledge management;technology management;software engineering;management information systems;information management;application lifecycle management;project management triangle;management;information technology;information system;information technology consulting;outsourcing	SE	-65.93272814211436	21.367121054643313	180305
e7d6326051bcc543c590305c7ed83bbf389af45d	understanding email interaction increases organizational productivity	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;ciencias basicas y experimentales;code compaction;tecnologias;article;code size reduction	To minimize the effect of email interruption on employee productivity, limit the frequency of new-email alerts (silence them, too), make it easier to assess each message's importance, and remove the reply-to-all facility.	email;interrupt	Thomas W. Jackson;Ray Dawson;Darren Wilson	2003	Commun. ACM	10.1145/859670.859673	real-time computing;simulation;world wide web	HCI	-74.37011133312326	29.66257689578693	180907
abda706ffa7f80dc4e5f86b90e1a4baf70b59765	lessons learned from evaluating mde abstractions in an industry case study		In a recent empirical study we found that evaluating abstractions of model-driven engineering (MDE) is not as straight forward as it might seem. In this paper, we report on the challenges that we as researchers faced when we conducted the aforementioned field study. In our study we found that modeling happens within a complex ecosystem of different people working in different roles. An empirical evaluation should thus mind the ecosystem, that is, focus on both technical and human factors. In the following, we present and discuss five lessons learnt from our recent work.	ecosystem;field research;human factors and ergonomics;mind;model-driven architecture;model-driven engineering	Adrian Kuhn;Gail C. Murphy	2012	CoRR			HCI	-65.62448131381447	23.672839561486317	181178
1a7af7bbe574e3f5eed242f727fd269158c04ed1	documenting evolutionary process improvements with method increment case descriptions		Evolutionary process improvement is a common approach to manage the complexity and risk of large software process improvement efforts. Performing SPI through a sequence of small steps allows organizations to reflect and steer the effort often and avoid failed improvements. However, few methods currently exist to structure improvement paths in a clear and concise manner. In this paper, we present a template for such a structuring method, based on Use Case Descriptions and method engineering techniques. A concise description of improvement paths allow organizations to reflect on their implementation and to guide similar improvement efforts. A case study of two large improvements within a small Dutch software company is used for evaluation.	increment and decrement operators;software documentation	Peter van Stijn;Kevin Vlaanderen;Sjaak Brinkkemper;Inge van de Weerd	2012		10.1007/978-3-642-31199-4_17	reliability engineering;systems engineering;database	NLP	-69.98909120540137	19.480535331174917	181204
0b1239170aa1f158306a1ba09727780007cb73ab	"""review of """"interpreting the cmmi: a process improvement approach by margaret k. kulpa and kent a. johnson"""". auerbach publications 2003"""	regression testing;usability testing;performance testing;web application;process improvement;testing model	Web services have the potential to dramatically reduce the complexities and costs of software integration projects. The most obvious and perhaps most significant difference between Web services and traditional applications is that Web services use a common communication infrastructure, XML and SOAP, to communicate through the Internet. The method of communication introduces complexities to the problems of verifying and validating Web services that do not exist in traditional software. This paper presents a new approach to testing Web services based on data perturbation. Existing XML messages are modified based on rules defined on the message grammars, and then used as tests. Data perturbation uses two methods to test Web services: data value perturbation and interaction perturbation. Data value perturbation modifies values according to the data type. Interaction perturbation classifies the communication messages into two categories: RPC communication and data communication. At present, this method is restricted to peer-to-peer interactions. The paper presents preliminary empirical evidence of its usefulness.	capability maturity model integration;interaction;internet;peer-to-peer;remote procedure call;soap;system integration;verification and validation;web service;xml;zenon kulpa	Mordechai Ben-Menachem	2005	ACM SIGSOFT Software Engineering Notes	10.1145/1039174.1039202	regression testing;web application;software performance testing;computer science;software engineering;programming language	SE	-75.08417149414952	24.634005424113678	181270
249085e0927bcaee65713c0829783ba62c91383c	software for everyone by everyone	web based applications;software engineering;model driven development;automated verification;mobile applications;tools and techniques;modularity;mobile application;end user programming	Given the dizzying pace of change in computer science, trying to look too far into the future of software engineering is hard. However, it might be possible to predict the future of software for the next decade based on the current trends. And based on the predictions on future of software, it might be possible to speculate about the future of software engineering. I try to do such a prediction in this position paper. I predict that the future of software will be applications that will be accessible everywhere, such as web applications and mobile applications. I also predict that increasingly more applications will be developed by non-computer-scientists. The challenges and the opportunities for software engineering research will be in providing tools and techniques that will enable non-programmers to become programmers for everywhere-accessible-software.	computer science;mobile app;programmer;software engineering;web application	Tevfik Bultan	2010		10.1145/1882362.1882377	personal software process;computing;web application;software engineering process group;computer science;systems engineering;package development process;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;middleware;software construction;modularity;software walkthrough;programming language;software analytics;resource-oriented architecture;software deployment;software requirements;software system;computer engineering	SE	-64.72403284993074	25.88425164477829	181685
7817756dd0c57b1ec4864ba438bef9b3c80c021c	empirically evolving software techniques: the high dependability computing project	computer society;software measurement;software engineering;computer science educational institutions software engineering laboratories nasa software measurement milling machines computer society;milling machines;computer science;nasa		dependability	Victor R. Basili	2004		10.1109/ICSM.2004.1357784	personal software process;verification and validation;computing;software engineering process group;software verification;software project management;computer science;systems engineering;engineering;social software engineering;component-based software engineering;software development;software engineering;software construction;software measurement;software deployment;software requirements;software system;computer engineering;software peer review	SE	-64.37928397422179	27.317339336413053	181844
2638f537cf18e62e1c00ad7b3ac6a99bed5a9bbb	testing the theory of relative defect proneness for closed-source software	software science;size defect relationship;software metrics;software reviews;software testing;software quality assurance;software inspections;software metric;planning for software quality assurance;closed source software;software inspection;defect detection;open source software	Recent studies on open-source software (OSS) products report that smaller modules are proportionally more defect prone compared to larger ones. This phenomenon, referred to as the Theory of Relative Defect Proneness (RDP), challenges the traditional QA approaches that give a higher priority to larger modules, and it attracts growing interest from closed-source software (CSS) practitioners. In this paper, we report the findings of a study where we tested the theory of RDP using ten CSS products. The results clearly confirm the theory of RDP. We also demonstrate the useful practical implications of this theory in terms of defect-detection effectiveness. Therefore, this study does not only make research contributions by rigorously testing a scientific theory for a different category of software products, but also provides useful insights and evidence to practitioners for revising their existing QA practices.	cascading style sheets;futures studies;justin (robot);open sound system;open-source software;remote desktop protocol;software bug;software quality assurance;software testing	Günes Koru;Hongfang Liu;Dongsong Zhang;Khaled El Emam	2010	Empirical Software Engineering	10.1007/s10664-010-9132-x	reliability engineering;personal software process;medical software;verification and validation;software sizing;computer science;systems engineering;engineering;package development process;backporting;social software engineering;software reliability testing;software development;software design description;software engineering;software construction;software testing;software walkthrough;software measurement;software deployment;software quality control;software quality;software metric;software quality analyst;software peer review	SE	-63.948496044817844	30.344875838005454	182013
0427b94404d92e1dc5d8efa0d6c4e4d0f15912dd	estimating the effort to develop screen mockups	agile software development;estimation software predictive models accuracy benchmark testing educational institutions atmospheric measurements;software;systems analysis cost benefit analysis formal specification regression analysis;requirements engineering empirical studies use cases screen mockups;formal specification;atmospheric measurements;customer specific teams;screen mockups;technology;large scale software development;use cases;teknikvetenskap;leave one out cross validation screen mockups cost benefit analysis stepwise linear regression effort estimation model use case size measures;requirements engineering;accuracy;software evolution;estimation;systems analysis;conference paper peer reviewed;predictive models;regression analysis;empirical studies;cost benefit analysis;benchmark testing	There is empirical evidence supporting the usefulness of screen mockups in improving the comprehension of use cases. Though a cost-benefit analysis would require an estimate of the effort required to produce them. In this paper, we present an empirical study with students and professionals to estimate the effort to develop mockups starting from use cases. We adopted Step Wise Linear Regression to build estimation models based on use case size measures (e.g., the number of steps and the number of characters). The leave-one-out cross validation has been adopted to assess the accuracy of our models against a baseline benchmark. The results of our empirical study show that the estimates obtained with our models are significantly better than those achieved by using the chosen baseline benchmark.	accessibility;baseline (configuration management);benchmark (computing);cosmic;cross-validation (statistics);machine learning;problem domain;self-replicating machine;software system	Giuseppe Scanniello;Filippo Ricca;Marco Torchiano;Carmine Gravino;Gianna Reggio	2013	2013 39th Euromicro Conference on Software Engineering and Advanced Applications	10.1109/SEAA.2013.52	reliability engineering;systems analysis;estimation;computer science;engineering;software evolution;software engineering;data mining;formal specification;agile software development;requirements engineering;regression analysis;technology	SE	-65.1621032132286	30.860542613805517	182317
af0cea1e8371448fdde99ad8bb0f13d97dfeb7ee	what do developers want? an advisor approach for developer priorities		On a typical work day, a software developer is swamped to know answers to a multitude of questions to gain diverse insights into the project environment, spanning multiple categories including code, quality and guidance. Due to client mandates, the project environment employs a lot of heterogeneous tools, thus making the relevant information retrieval process fairly complex and therefore it is important to know which insights are most important to the developer. In this paper, we present results from a survey we conducted on a pool of 27 developers from the development team in the delivery center, by asking them to rate a set of 25 Questions, prioritising them as most, moderate and least important to be answered automatically during the software evolution process. We also introduce the concept of Smart Advisor for developers, an intelligence augmentation framework that employs domain and knowledge modelling and in-process analytics to automatically provide important insights and answer developer queries, using a conversational and interactive user interface.	file spanning;information retrieval;intelligence amplification;software developer;software evolution;user interface	Vibhu Saujanya Sharma;Rohit Mehra;Vikrant Kaulgud	2017	2017 IEEE/ACM 10th International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE)	10.1109/CHASE.2017.14		SE	-72.84012949244239	20.02639507580704	182357
d41cc863ab30d343a1536b9e7239c8a66f61bdba	model size matters	measurement;uml;gqm;metrics;size;prediction;models	Size is an important attribute of software artefacts; for most artefact types exists a body of measurement knowledge. As software engineering is becoming more and more model-centric, it is surprising that there exists only little work on model size metrics (MoSMe). In this position paper we identify the goals justifying the need for MoSMe, such as prediction, description and progress measurement. Additionally, we identify challenges that make it difficult to measure the size of UML models and that MoSMe have to deal with. Finally, we propose a classification of MoSMe and concrete examples of metrics for the size of UML models.	software engineering;unified modeling language	Christian Lange	2006		10.1007/978-3-540-69489-2_26	reliability engineering;unified modeling language;prediction;systems engineering;gqm;data mining;size;metrics;measurement	SE	-66.05759561746149	31.17970716325677	182551
4c6fd464dc4989f8ea89857caad282dcc431463f	system architecture metrics : an evaluation		The research described in this dissertation is a study of the application of measurement, or metrics for software engineering. This is not in itself a new idea; the concept of measuring software was first mooted close on twenty years ago. However, examination of what is a considerable body of metrics work, reveals that incorporating measurement into software engineering is rather less straightforward than one might pre-suppose and despite the advancing years, there is still a lack of maturity. The thesis commences with a dissection of three of the most popular metrics, namely Haistead's software science, McCabe's cyclomatic complexity and Henry and Kafura's information flow all of which might be regarded as having achieved classic status. Despite their popularity these metrics are all flawed in at least three respects. First and foremost, in each case it is unclear exactly what is being measured: instead there being a preponderance of such metaphysical terms as complexIty and qualIty. Second, each metric is theoretically doubtful in that it exhibits anomalous behaviour. Third, much of the claimed empirical support for each metric is spurious arising from poor experimental design, and inappropriate statistical analysis. It is argued that these problems are not misfortune but the inevitable consequence of the ad hoc and unstructured approach of much metrics research: in particular the scant regard paid to the role of underlying models. This research seeks to address these problems by proposing a systematic method for the development and evaluation of software metrics. The method is a goal directed, combination of formal modelling techniques, and empirical ealiat%or. The met\io s applied to the problem of developing metrics to evaluate software designs from the perspective of a software engineer wishing to minimise implementation difficulties, faults and future maintenance problems. It highlights a number of weaknesses within the original model. These are tackled in a second, more sophisticated model which is multidimensional, that is it combines, in this case, two metrics. Both the theoretical and empirical analysis show this model to have utility in its ability to identify hardto-implement and unreliable aspects of software designs. It is concluded that this method goes some way towards the problem of introducing a little more rigour into the development, evaluation and evolution of metrics for the software engineer.	capability maturity model;cyclomatic complexity;design of experiments;directed graph;foremost;hoc (programming language);software engineer;software engineering;software metric;systems architecture	Martin J. Shepperd	1991				SE	-67.37742715798744	31.315029670807338	182746
c6e59ecec06d30fbc01bf898e57fc699b6c1b6a3	using a semiotic framework to evaluate uml for the development of models of high quality	high quality;semiotic framework	Many researchers have evaluated different parts of UML and have come up with suggestions for improvements to different parts of the language. This chapter looks at UML (version 1.3) as a whole, and contains an overview evaluation of UML and how it is supported in the modeling tool Rational Rose as a basis for creating models of high quality. The evaluation is done using a general framework for understanding quality of models and modeling languages in the information systems field. The evaluation is based on both practical experiences and evaluations of UML and Rational Rose made by others. Based on the evaluation, we conclude that, although being an improvement over its predecessors, UML still has many limitations and deficiencies. Also Rational Rose only partly supports the development of information system models of high quality, and provides too limited support for using different modeling techniques in concert within a larger methodological framework. INTRODUCTION According to Booch, Rumbaugh & Jacobson (1999), developing a model for an industrial strength software system before its construction is regarded increasingly as a necessary activity in information systems development. Good models are essential for communication among the members of project teams and to assure that it is possible to implement the system.		John Krogstie	2001			uml tool;applications of uml	SE	-63.789338160070045	19.059192543787976	182865
adfc166ad62333465ae157f16b414b3144a1b8d9	experimental software engineering (stese)	application software;testing;computer industry;software engineering;software performance;software engineering computer industry software performance application software testing object oriented modeling multidimensional systems data models performance analysis usability;experimental software engineering;performance analysis;usability;object oriented modeling;multidimensional systems;data models	Software engineering theory and practice is still to a large extent based more on faith than on science. Only by contributing to the scientific and empirically grounded body of knowledge within a specific area of application, theory and practice can develop. Experimentation is an important scientific approach to collect empirical data and to test theories as well as to bring light to new phenomena so that theories can be formulated and corrected. This is the background for the emerging field of experimental software engineering.	experimental software engineering;theory	Karlheinz Kautz;Pekka Abrahamsson	2003		10.1109/HICSS.2003.1174894	data modeling;personal software process;verification and validation;application software;software engineering process group;software sizing;usability;software performance testing;multidimensional systems;human–computer interaction;computer science;artificial intelligence;marketing;social software engineering;component-based software engineering;software development;software design description;operating system;software engineering;software construction;database;software testing;software walkthrough;management;world wide web;software development process;software requirements;software quality;software metric;software system;software peer review	SE	-66.61390562190245	30.373711240326536	183049
709673f7b710bb8aeae3a380eb7a4d6175706f93	icis 2011 panel report: are we on the wrong track and do mis curricula need to be reengineered?	bepress selected works;mis curriculum		icis	David Gefen;Arik Ragowsky;Ephraim R. McLean;M. Lynne Markus;Suzanne Rivard;Matti Rossi	2012	CAIS		simulation;computer science;engineering;mechanical engineering	Vision	-66.92603843272774	25.058826239140547	183140
68ce1cdb6711c3176de3fce90516eebb23e4bc8a	open source hardware through volunteer community: a case study of ecars - now!	community;volunteer;open source hardware;community analysis;open source software;open source;motivations	The development model of Open Source Software (OSS) has been widely recognized as resilient and productive. Consequently, high hopes have been placed on projects that try to adapt the OSS model into material production, in projects that can be called Open Source Hardware (OSH). While OSS development has received increasing scholarly attention, the research on OSH is still in its early stages. Here, based on a survey done in 2010, we describe the demographic and motivational structure of one OSH community and compare it to OSS communities. The community analysis will be accompanied with a short discussion of what we see as bottlenecks in OSH development, i.e., features that may disable some of the beneficial dynamics of OSS development, and consequently merit further study.	open sound system;open-source hardware;open-source software	Tiina Malinen;Teemu Mikkonen;Vesa Tienvieri;Tere Vadén	2010		10.1145/1930488.1930502	simulation;systems engineering;engineering;software engineering	SE	-71.50529740792848	25.412227401376107	183555
906e40940698fd3e01ee25f66d8576c50cfefa8b	the application of a new process quality measurement model for software process improvement initiatives	software;quality attributes;process quality measurement model;software software measurement organizations current measurement iso standards iec standards complexity theory;complexity theory;software process improvement;software measurement;process quality;iso standards;iec standards;current measurement;cost attribute;software organization;software standards iec standards iso standards software process improvement software quality;iso iec 9126;software standards;organizations;quality measures;product quality;software product quality standard;process analysis;software product quality standard process quality measurement model software process improvement process analysis cost attribute time attribute product quality software organization iso iec 9126;process quality attribute;software process improvement process quality process quality attribute software quality;software quality;quantitative evaluation;time attribute	Conventionally, process analysis is performed by following the traces of processes on the attributes of cost, time and product quality. Although process quality is a significant aspect it is frequently ignored in process analysis. In this paper, we present the results of the applications of the Process Quality Measurement Model (PQMM) and demonstrate the added value that can be acquired by analyzing the process quality for software organizations. The PQMM is a comprehensive and proactive quality measurement model based on the ISO/IEC 9126 Software Product Quality Standard [1]. The basis of the PQMM is the measurement of process definitions. As process definitions can be established before their execution, the PQMM can measure processes before they are put into practice. The model was applied to three different software organizations as part of a software process improvement initiative. The applications of the PQMM provided guidance for the analysis and explanation of the deficiencies or problems identified in the processes. The PQMM was also applied to the improved versions of the processes and facilitated a quantitative evaluation of the improvements accomplished in the processes.		A. Selçuk Güceglioglu;Onur Demirörs	2011		10.1109/QSIC.2011.29	iso/iec 9126;reliability engineering;quality assurance;qa/qc;verification and validation;team software process;design process;software quality management;software engineering process group;process analytical technology;computer science;systems engineering;organization;engineering;business process management;software engineering;empirical process;software measurement;software quality control;business process modeling;goal-driven software development process;software quality;software quality analyst	SE	-69.21133473224998	20.739246651122414	184042
bb1cffd8b350688ac3e32ecc4e50c60264720d56	the platform of corporate development and management cat software on the web			world wide web	Jia Zhuosheng;Wei Huoqing	1996			world wide web;web development;software engineering;software;software as a service;engineering	SE	-63.554047302577786	21.902073192190734	184123
51c1d73b55d29f4a7e95a624ed81a014e6c8bc23	a portal-based tool for developing, delivering and working with guidelines	working group;portals;standards;working with guidelines;guidelines	Guidelines and standards are gaining increasing importance worldwide. However, their process of development is still in a state of flux. The same stands regarding the means for spreading, retrieving and utilising such knowledge. A portal-based approach is proposed here for supporting all lifecycle phases of guidelines and standards. The proposed approach has significant advantages: (a) it allows contributors from all over the globe to form working groups, share virtual working spaces and, thereby, collaborate for the development of guidelines and standards; (b) it facilitates the rapidly spread and effective use of produced knowledge; and (c) it tackles the demand-supply gap by bridging developers and consumers of knowledge.		Nikolaos Partarakis;Alexandros Mourouzis;Constantina Doulgeraki;Constantine Stephanidis	2007		10.1007/978-3-540-73279-2_57	systems engineering;engineering;knowledge management;data mining	HCI	-73.56443640434371	18.91522439584283	184219
e667e1c05e43a7bae9bb531768fba94b5becc1db	division among the ranks: the social implications of case tools for systems developers	case tool;system development;working paper	This paper explores how the introduction of CASE tools in systems development changes the social relations among project team members. An investigation into the role of CASE tools on projects found structural changes due to modification of the systems development division of labor and shifts in patterns of dependency among project team coalitions. These changes triggered a polarization among the system developers which was evinced in acts of coercion and rebellion, the display of territorialism, resentment, and stereotyping, as well as the enactment of subcultures. These findings are interpreted within a broader social theoretic framework, and their implications for research and practice are discussed.	computer-aided software engineering;denial-of-service attack;interdependence;organizational unit (computing);polarization (waves);software deployment;software developer;software development process;stereotype (uml);theory	Wanda J. Orlikowski	1989		10.1145/75034.75052	computer science;operations management;computer-aided software engineering	SE	-75.77193231922215	20.67000637868804	184264
98be731643a726c27e8d1f3be96e191525a3dcf0	project valorisation through agility and catering for stakeholder expectations		Project valorisation is paramount for gaining value in an increasingly competitive world. There is evidence that the majority of projects even when they are completed within budget and time fail to valorise (disseminate and exploit) their results so that they can deliver value to the organisation. Projects often have many stakeholders with different requirements and expectations. Identifying and understanding synergies, conflicts and changing requirements hold the key to project success. In this paper we discuss the challenges and failures of lack of valorisation from industry, government, academia and the European Union. Using the VALO project we demonstrate how the integration of the project plan, the quality plan and the sustainability plan started delivering value to a multiplicity of stakeholders throughout the project lifetime and beyond its completion. We propose a meta-framework for this integration taking into account the process maturity of an organisation for successful valorisation of projects.		Elli Georgiadou;Kerstin V. Siakas;Richard Messnarz	2014		10.1007/978-3-662-43896-1_19	systems engineering;operations management;management science;business	Crypto	-68.99209975737163	18.48375760565329	184491
2c3e89127db6fcb5018985916e12f62038da2d99	comments on “researcher bias: the use of machine learning in software defect prediction”	analytical models;software defect prediction;measurement;software quality assurance;collinearity;researcher bias;defect prediction;interference;software engineering;machine learning;analysis of variance;predictive models;multi collinearity;nasa;data models	Shepperd et al. find that the reported performance of a defect prediction model shares a strong relationship with the group of researchers who construct the models. In this paper, we perform an alternative investigation of Shepperd et al.’s data. We observe that (a) research group shares a strong association with other explanatory variables (i.e., the dataset and metric families that are used to build a model); (b) the strong association among these explanatory variables makes it difficult to discern the impact of the research group on model performance; and (c) after mitigating the impact of this strong association, we find that the research group has a smaller impact than the metric family. These observations lead us to conclude that the relationship between the researcher group and the performance of a defect prediction model are more likely due to the tendency of researchers to reuse experimental components (e.g., datasets and metrics). We recommend that researchers experiment with a broader selection of datasets and metrics to combat any potential bias in their results.	emoticon;machine learning;software bug	Chakkrit Tantithamthavorn;Shane McIntosh;Ahmed E. Hassan;Kenichi Matsumoto	2016	IEEE Trans. Software Eng.	10.1109/TSE.2016.2553030	collinearity;data modeling;multicollinearity;analysis of variance;computer science;engineering;data science;machine learning;data mining;interference;predictive modelling;measurement;statistics	SE	-66.54993516291805	30.518202845144785	184756
3f2a3fa0a27f2da60da28b96563aa2fb785efbe9	an empirical study examining the usage and perceived importance of xp practices	agile methods;empirical study;extreme programming;software development	Extreme Programming (XP) is a well known agile software development methodology which is ideal for projects featured as highly unpredictable in tasks with limited resources. The continuous discussion on the usage and importance of each XP practice lead us to explore what are the most important XP practices to be applied in certain projects. This study examined the actual usage amount and perceived importance of each XP practice by means of a cross-sectional anonymous survey conducted in local organizations which have implemented XP in their projects. Results indicate that Continuous Integration and Collective Ownership as the most important. Collective Ownership, Continuous Integration, Pair Programming, Planning Game and Sustainable Pace are used the most. Both practitioners and researchers can build upon these findings.	agile software development;collective intelligence;continuous integration;cross-sectional data;extreme programming practices;pair programming;software development process	Ann L. Fruhling;Jessica Zhang	2007			extreme programming;extreme programming practices;knowledge management;software development;agile software development;empirical process;empirical research;management	HCI	-72.01061041140194	21.948814343880812	184903
e2f6134eeecfaac7654a9f4dc1560193a3e6305a	creating an accreditable software engineering bachelor's program	developpement logiciel;modelizacion;guide programme etude;software engineering accreditation computer science education educational administrative data processing;software engineering accreditation maintenance engineering design engineering australia councils software standards standards development curriculum development process design;proceso concepcion;universite;design process;international standards accreditable software engineering bachelor program design undergraduate engineering program accreditation accreditation standards national standards;educational program;bsse program development abet accreditation software engineering;software engineering;undergraduate engineering program accreditation;preparacion serie fabricacion;accreditable software engineering bachelor program design;modelisation;international standards;computer science education;bsse program development;educational administrative data processing;desarrollo logicial;programme enseignement;abet;software development;national standards;curriculum guides;genie logiciel;accreditation;university;accreditation standards;process planning;preparation gamme fabrication;modeling;universidad;programa ensenanza;ingenieria informatica;program development;processus conception;internal standard	Since 1936, the accreditation of undergraduate engineering programs has been a cornerstone of modern engineering practice. Accreditation validates that an engineering program serves its constituents and the public well. In an emerging discipline such as software engineering, accreditation standards also serve as a target - a source of requirements for validating an SE program's design. Accreditation standards also help ensure that a program's graduates will meet or exceed national and international standards expected of the Bachelor of Science graduate. A small university's BSSE program grew out of several requirements sources and accreditation expectations. The planners developed effective design processes and a model curriculum	requirement;software engineering	Stephen T. Frezza;Mei-Huei Tang;Barry J. Brinkman	2006	IEEE Software	10.1109/MS.2006.156	engineering management;systems modeling;design process;systems engineering;engineering;software development;software engineering;internal standard;accreditation;certification and accreditation	SE	-66.70456991928657	26.417457782707864	184984
986905e31033e606b121c1de9d378c8cd290a97e	progress on approaches to software defect prediction		Software defect prediction is one of the most popular research topics in software engineering. It aims to predict defect-prone software modules before defects are discovered, therefore it can be used to better prioritise software quality assurance effort. In recent years, especially for recent 3 years, many new defect prediction studies have been proposed. The goal of this study is to comprehensively review, analyse and discuss the state-of-the-art of defect prediction. The authors survey almost 70 representative defect prediction papers in recent years (January 2014–April 2017), most of which are published in the prominent software engineering journals and top conferences. The selected defect prediction papers are summarised to four aspects: machine learning-based prediction algorithms, manipulating the data, effort-aware prediction and empirical studies. The research community is still facing a number of challenges for building methods and many research opportunities exist. The identified challenges can give some practical guidelines for both software engineering researchers and practitioners in future software defect prediction.	software bug	Zhiqiang Li;Xiao-Yuan Jing;Xiaoke Zhu	2018	IET Software	10.1049/iet-sen.2017.0148	empirical research;systems engineering;software bug;computer science;data manipulation language;software quality assurance;software	SE	-65.8366809744468	25.558030785494992	185066
d04902bcfe40b0c03a0dab2b6ffdc0585d867f35	lessons learned from an initiative for improving software process, quality, and reliability in a semiconductor equipment company	software process improvement;quality improvement;production engineering computing semiconductor device manufacture electronic equipment manufacture software development management software quality software reliability electronic engineering computing;production engineering computing;applied materials co software process improvement software quality software reliability semiconductor equipment company semiconductor manufacturing equipment sematech spi project;lessons learned;semiconductor device manufacture;electronic engineering computing;software quality electronics industry semiconductor materials embedded software semiconductor device manufacture software maintenance semiconductor device reliability manufacturing processes marketing and sales fabrication;electronic equipment manufacture;software reliability;software quality;software development management;software process;semiconductor manufacturing	Improving software in semiconductor manufacturing equipment was targeted by SEMATECH in the early ‘90s due to numerous reports of problems, failures, complexities and growing needs. The SEMATECH SPI Project has been working with equipment supplier companies on focused software improvement initiatives. This report will describe the key accomplishments and lessons learned from the software process and quality improvement initiative that has been going on in Applied Materials for the last 2 years. Conclusions and recommendations for companies preparing to embark on such an improvement program are described, as well as, the plans and challenges for Applied Materials in 1995 and beyond.	semiconductor device fabrication;software development process	Herb Krasner;Gregory Scott	1996		10.1109/HICSS.1996.495523	personal software process;long-term support;quality management;verification and validation;software engineering process group;software project management;package development process;social software engineering;software development;software engineering;software construction;software deployment;software quality control;software quality;software system	SE	-66.3699772633365	21.166099253609147	185354
927cee103147d98705265937bcda9d531d039565	reliability of function points productivity model for enhancement projects (a field study)	software cost estimation software maintenance;mean relative error model reliability software maintenance function points productivity model enhancement projects function points based models canadian financial institution software engineering;software cost estimation;software maintenance;function point;productivity application software software engineering software maintenance project management predictive models costs uncertainty equations computer industry;product model;relative error;field study	The use of productivity models for enhancement projects is illustrated, and the reliability of function points-based models is reported. The results of a field study at a major Canadian financial institution indicate that function points-based productivity models are within the range of the recommended criteria for good models in software engineering: a mean relative error of /spl plusmn/25% in 75% of cases. >	function point	Alain Abran;Pierre N. Robillard	1993		10.1109/ICSM.1993.366953	reliability engineering;approximation error;verification and validation;software sizing;systems engineering;engineering;software reliability testing;function point;software engineering;software maintenance;use case points;software metric;field research	SE	-65.68837845750451	29.526138753814475	185406
596f23540148120e79f751d83fbe7ad3bda9bc1a	characterization of risky projects based on project managers' evaluation	project management;risky projects;project managers evaluation;logistic regression analysis risky projects project managers evaluation software development requirements team organization planning capability project management;project manager;risk management;logistic model;logistic regression;software engineering;planning capability;project management risk management programming logistics permission software development management engineering management concrete regression analysis software engineering;requirements;risk management software development management project management;team organization;logistics;permission;engineering management;software development;regression analysis;questionnire;programming;software development management;software risk management;concrete;logistic regression analysis;risky project	During the process of software development, senior managers often find indications that projects are risky and take appropriate actions to recover them from this dangerous status. If senior managers fail to detect such risks, it is possible that such projects may collapse completely. In this paper, we propose a new scheme for the characterization of risky projects based on an evaluation by the project manager. In order to acquire the relevant data to make such an assessment, we first designed a questionnaire from five viewpoints within the projects: requirements, estimations, team organization, planning capability and project management activities. Each of these viewpoints consisted of a number of concrete questions. We then analyzed the responses to the questionnaires as provided by project managers by applying a logistic regression analysis. That is, we determined the coefficients of the logistic model from a set of the questionnaire responses. The experimental results using actual project data in Company A showed that 27 projects out of 32 were predicted correctly. Thus we would expect that the proposed characterizing scheme is the first step toward predicting which projects are risky at an early phase of the development.	coefficient;digital monster (virtual pet);logistic regression;requirement;risk assessment;software development	Osamu Mizuno;Tohru Kikuno;Yasunari Takagi;Keishi Sakamoto	2000		10.1145/337180.337226	project management;risk management;systems engineering;engineering;knowledge management;management science;logistic regression;management;project portfolio management	SE	-72.09211318006281	25.78409864570307	185960
9cddcaa2eb6bf03eb773c34bb4bd7f09166b4b17	the neglected management activity: software risk management	developpement logiciel;gestion risque;risk management;software engineering;desarrollo logicial;software development;genie logiciel;gestion riesgo;ingenieria informatica	Software risk management is a crucial part of successful project management, yet it is often neglected. Why is it important? Why is it neglected? This letter discusses barriers to implementing risk management and provides examples of good (i.e., successful) risk management. © 2003 Lucent Technologies Inc.	risk management	F. Michael Dedolph	2003	Bell Labs Technical Journal	10.1002/bltj.10077	risk management;systems engineering;engineering;software development;operations research	SE	-69.09211410736546	18.649904679555526	186033
c76b2c3b80a232c2c58e02640c3a2e247f010a17	modeling and scenario simulation for decision support in management of requirements activities in software projects	decision support;risk evaluation;software engineering;requirements;software process	There are many tools and techniques readily available to support the work in requirements activities of software development processes. As a consequence, the high frequency of errors still occurring in requirements activities suggests that the misunderstanding of the relationships among key decisions is the probable reason for this. The present work presents a system dynamics model constructed to make it possible for users to better understand the relations among key decision variables in requirements activities. The model was parameterized with data taken from previous studies and from a software development company so as to run two sets of simulations with three scenarios each. Optimistic, baseline and pessimistic scenarios are created on the basis of different assumptions regarding risk factors related to requirements volatility and people turnover. We used our simulation results to foresee the effects of these risk factors on the quality and cost of work in requirements activities. Up-to-date results from the software engineering literature strongly support the simulation outcomes obtained in our research. Copyright © 2010 John Wiley & Sons, Ltd.	decision support system;requirement;requirements management;simulation	Bernardo Giori Ambrósio;José Luís Braga;Moisés A. Resende-Filho	2011	Journal of Software Maintenance	10.1002/smr.469	reliability engineering;requirements analysis;software requirements specification;requirements management;requirement prioritization;software engineering process group;decision support system;business requirements;computer science;systems engineering;engineering;software design;software development;requirement;software engineering;requirements elicitation;management science;non-functional testing;software deployment;software development process	SE	-70.37804112847512	22.48134820462416	186065
74f33512eec5d9781463d65c8a84de8f4c04fbae	a tool support for secure software integration	security properties;compositional contracts;software integration;tool support;software services;software components;characterization	"""This paper presents a tool for the integration of security-aware services based applications that is constructed on the principles of security characterization of individual software services. The tool uses the technique of reasoning between the ensured security properties of the services and the security requirements of the user’s system. Rather than reporting the research outcomes, in this paper the authors describe the architecture and capabilities of the tool for secure software integration. The main objective of this paper is to show that an automatic tool support could assist the process of security-aware service based software integration. In a service oriented system a service providing software component is usually developed, owned, and managed by third parties. However, the conformity between service consumers’ security requirements and security assurances of services over the Internet has become an important issue. In a highly open Internet environment, service consumers are virtually forced to consume services of which they have only partial or no knowledge about their underlying security properties (Khan & Han, 2003). When services are discovered from the Internet and composed with the application system of the consumer, it is not always possible to verify the conformity of security properties between the application system and the third part services. A service is actually offered by a software component or an entity. For simplicity, in this paper we use component to refer to a service providing software entity. DOI: 10.4018/jsse.2010040103 36 International Journal of Secure Software Engineering, 1(2), 35-56, April-June 2010 Copyright © 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. In a service oriented system, we need tools and techniques that assist us to check the security compatibility between the selected services and the security requirements of the consumers’ application system. To illustrate the main focus of this paper, let us consider a fictitious distributed healthcare scenario. A number of individual healthcare components provide independent services. Assume a consumer’s system y running on a machine at a general practitioner’s (GP) office connects with a component s that provides specialist prescription based on diagnosis report. The service s is selected from many such services running at various service providers machines. Component y provides a patient’s diagnosis report to s to get a prescription. After receiving the prescription from s, y sends it electronically to another component p residing on a pharmacist’s system for a price quotation. In this case developers would independently develop many such p and s, and make them available from their various distributed sources which are potentially able to deliver the services that y wants. However, component y is not only interested in specific services but also wants to know upfront the security properties that the components s and p could provide with the services. In this scenario, two issues need to be addressed: (i) how to know the security assurances provided by a service; and (ii) how to verify that the required security properties of the client of a service are complied with the ensured security provided by the services. For example, a component offering pathological services may ensure confidentiality through secure storage and transmission of diagnosis reports. The component y (GP) may require confidentiality provided with specific encryption schemes with specific key size. The pathology component may or may not satisfy the general practitioner’s (GP) security requirements, depending on how the confidentiality is realized by the service providing component. The current practices and research provide limited supports for software components and systems security at the composition level. While the existing security technologies have made some progresses in addressing security issues of services, however, they have primarily been focusing on system security at the software infrastructure level. A key consideration missing from all these is how to reason about the security compatibility between a service and an application system. No matter how advanced the security techniques used at the individual service level, these would remain useless if the security properties are inconsistent with the required security of the client’s system. In order to facilitate the security-aware service composition, an automatic tool support is required. The tool could be used by the software engineers to identify the suitable services along with the security profiles of the providing software components, and reason about their compatibility with the service consumer’s application system. Based on our approaches reported in (Khan & Han, 2003; Khan & Han, 2005), we have developed a simple tool to characterize the security properties of the services, and verify the security compliance between the service and the consumer’s application system. This paper reports the architecture, capabilities, and limitations of the security characterization tool. This paper is organized as follows. Next section outlines the requirements for an automatic tool to check the conformity of security properties of services. The section also outlines our earlier work on the security characterization which is used in the tool. Then we discuss the architecture of the tool along with a demonstration of its capabilities with an example. We briefly cite the current practices in security-aware component composition. Finally, we conclude with some outlines of future works. rEqUIrEMENTS For aUToMaTIC Tool SUPPorT An architecture of a complete system for service composition is shown in Figure 1. The figure shows that the tool has six requirements represented as modules. Some of the requirements focus on the functional issue of the tool, whereas 20 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/tool-support-secure-softwareintegration/43925?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Computer Science, Security, and Information Technology, InfoSci-Computer Systems and Software Engineering eJournal Collection, InfoSci-Knowledge Discovery, Information Management, and Storage eJournal Collection, InfoSci-Physical Sciences, Biological Sciences, and Engineering eJournal Collection, InfoSci-Surveillance, Security, and Defense eJournal Collection, InfoSci-Journal Disciplines Engineering, Natural, and Physical Science, InfoSci-Select. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2"""	requirement;system integration	Khaled M. Khan;Jun Han	2010	IJSSE	10.4018/jsse.2010040103	software security assurance;personal software process;long-term support;software requirements specification;verification and validation;software sizing;computer science;package development process;backporting;social software engineering;software framework;component-based software engineering;software development;software design description;middleware;software construction;software testing;resource-oriented architecture;software deployment;software system;system integration;software peer review	Security	-67.45899327547718	27.874135943078088	186235
28730b5f2a6484f38b2b4379eded2124492f1021	process simulation: a tool for software project managers?		Process simulation has been introduced as a tool in support of software project management more than 25 years ago. Since then, it has been considered an approach with high potential for making software project managers' work more effective and successful. Unfortunately, despite high expectations and many reports on prototypical process simulation applications in industrial contexts, little evi- dence exists that process simulation has become an accepted and regularly used tool of software project managers. This chapter investigates the reasons for lacking impact of process simulation in the software industry. This is done with the help of an in-depth description of a software process simulation application example. The application example focuses on the effects of various workforce allocation strate- gies on project performance, expressed in terms of project duration, effort con- sumption, and product quality. With the help of the application example and based on existing literature, the gap between the current state of the art of software process simulation and the actual state of practice is described and its root-causes are discussed. The chapter concludes with a list of issues that need to be addressed in order to close the gap between the state of the art and the state of practice. Most of the issues relate to the difficulty of demonstrating a positive cost-benefit ratio when applying process simulation as a tool in support of software project management tasks.	simulation;software project management	Dietmar Pfahl	2014		10.1007/978-3-642-55035-5_17	personal software process;verification and validation;team software process;software quality management;software engineering process group;software project management;systems engineering;engineering;knowledge management;package development process;software development;software design description;software construction;management science;empirical process;project management triangle;goal-driven software development process;software development process;software metric;software peer review	Logic	-68.85333642750008	22.700504895326105	186392
cdbcd7acd891ee01c4398ee02d76225d981ca3a4	tutorial: agent-oriented software engineering.	agent oriented software engineering	OUTLINE g Part I: Intelligent agents and Multi-agent systems – a brief introduction g Part II: Concepts and abstractions in agent-oriented software engineering (AOSE) g Part III: Methodologies for agent-based software development g Part IV: Tools and infrastructures for AOSE g Part V: Current and future research directions in AOSE 5 M. Oprea AOSE tutorial IASTED AIA 2006 & SE 2006 February 2006, Innsbruck PART I:	agent-based model;agent-oriented software engineering;intelligent agent;multi-agent system;software development	Mihaela Oprea	2006			personal software process;verification and validation;systems engineering;social software engineering;component-based software engineering;software development;feature-oriented domain analysis;software engineering;software construction;software walkthrough;resource-oriented architecture;software deployment;software requirements;software system;computer engineering	SE	-63.19565341298417	24.17878089881168	186395
3d7e7c64cad4bba7f8e11962f2e358f4db14ca33	software evolution and integration	software evolution		software evolution	Jens Palsberg	1996	ACM Comput. Surv.	10.1145/242224.242480	computer science;software evolution;social software engineering;software development;software construction;resource-oriented architecture	Theory	-63.387300638118035	24.902917383585606	186424
799169e956f803c4f26c923107abcc9453835bff	evolving software systems	software maintenance;software system;software practitioner;evolving software systems;software ecosystem;software evolution topic;inter-dependent software project;software evolution research;software evolution;software engineering;model-driven software development	During the last few years, software evolution research has explored new domains such as the study of socio-technical aspects and collaboration between different individuals contributing to a software system, the use of search-based techniques and meta-heuristics, the mining of unstructured software repositories, the evolution of software requirements, and the dynamic adaptation of software systems at runtime. Also more and more attention is being paid to the evolution of collections of inter-related and inter-dependent software projects, be it in the form of web systems, software product families, software ecosystems or systems of systems. With this book, the editors present insightful contributions on these and other domains currently being intensively explored, written by renowned researchers in the respective fields of software evolution. Each chapter presents the state of the art in a particular topic, as well as the current research, available tool support and remaining challenges. The book is complemented by a glossary of important terms used in the community, a reference list of nearly 1,000 papers and books and tips on additional resources that may be useful to the reader (reference books, journals, standards and major scientific events in the domain of software evolution and datasets). This book is intended for all those interested in software engineering, and more particularly, software maintenance and evolution. Researchers and software practitioners alike will find in the contributed chapters an overview of the most recent findings, covering a broad spectrum of software evolution topics. In addition, it can also serve as the basis of graduate or postgraduate courses on e.g., software evolution, requirements engineering, model-driven software development or social informatics.	adaptive system;agile software development;cpu cache;evolution;evolutionary systems;genetic algorithm;humans;inference engine;linkage (software);mathematical optimization;mind;parallel computing;rational doors;requirement;requirements engineering;responsiveness;search-based software engineering;semantics (computer science);software system;spatial variability;statistical classification;time complexity	Tom Mens;Alexander Serebrenik;Anthony Cleve	2014		10.1007/978-3-642-45398-4	personal software process;software engineering process group;computer science;systems engineering;social software engineering;software framework;software development;software design description;software engineering;software walkthrough;software analytics;software requirements;software peer review	SE	-64.92340938307123	24.12902320946418	186612
245b34f522e6af4fb280425fea097373d5852365	correlations of software code metrics: an empirical study		Background: The increasing up-trend of software size brings about challenges related to release planning and maintainability. Foreseeing the growth of software metrics can assist in taking proactive decisions regarding different areas where software metrics play vital roles. For example, source code metrics are used to automatically calculate technical debt related to code quality which may indicate how maintainable a software is. Thus, predicting such metrics can give us an indication of technical debt in the future releases of software. Objective: Estimation or prediction of software metrics can be performed more meaningfully if the relationships between different domains of metrics and relationships between the metrics and different domains are well understood. To understand such relationships, this empirical study has collected 25 metrics classified into four domains from 9572 software revisions of 20 open source projects from 8 well-known companies. Results: We found software size related metrics are most correlated among themselves and with metrics from other domains. Complexity and documentation related metrics are more correlated with size metrics than themselves. Metrics in the duplications domain are observed to be more correlated to themselves on a domain-level. However, a metric to domain level relationship exploration reveals that metrics with most strong correlations are in fact connected to size metrics. The Overall correlation ranking of duplication metrics are least among all domains and metrics. Contribution: Knowledge earned from this research will help to understand inherent relationships between metrics and domains. This knowledge together with metric-level relationships will allow building better predictive models for software code metrics.	coefficient;complexity;internal code;java;open-source software;predictive modelling;software documentation;software metric;software quality;software sizing;statement (computer science);technical debt	Md. Abdullah Al Mamun;Christian Berger;Jörgen Hansson	2017		10.1145/3143434.3143445	software quality;documentation;data mining;maintainability;empirical research;software metric;source code;software;technical debt;computer science	SE	-65.21740197332701	31.309642755058142	186663
e26641e19c8fc2e6a8128fa2266ca8ca957efbd0	detecting and classifying patterns of requirements clarifications	rtc project project environments distributed teams project managers online requirement communication clarification event classification clarification event detection requirement clarification pattern ibm rational team concert project;project management;systems analysis distributed processing formal verification pattern classification project management;distributed processing;formal verification;systems analysis;visualization trajectory software manuals natural languages message systems context;pattern classification;communication of requirements requirements clarification patterns distributed requirements engineering;distributed requirements engineering;requirements clarification patterns;communication of requirements	In current project environments, requirements often evolve throughout the project and are worked on by stakeholders in large and distributed teams. Such teams often use online tools such as mailing lists, bug tracking systems or online discussion forums to communicate, clarify or coordinate work on requirements. In this kind of environment, the expected evolution from initial idea, through clarification, to a stable requirement, often stagnates. When project managers are not aware of underlying problems, development may proceed before requirements are fully understood and stabilized, leading to numerous implementation issues and often resulting in the need for early redesign and modification. In this paper, we present an approach to analyzing online requirements communication and a method for the detection and classification of clarification events in requirement discussions. We used our approach to analyze online requirements communication in the IBM® Rational Team Concert® (RTC) project and identified a set of six clarification patterns. Since a predominant amount of clarifications through the lifetime of a requirement is often indicative of problematic requirements, our approach lends support to project managers to assess, in real-time, the state of discussions around a requirement and promptly react to requirements problems.	bug tracking system;computer-mediated communication;rational team concert;real-time transcription;requirement;sensor;user story	Eric Knauss;Daniela E. Damian;Germán Poo-Caamaño;Jane Cleland-Huang	2012	2012 20th IEEE International Requirements Engineering Conference (RE)	10.1109/RE.2012.6345811	project management;systems analysis;requirements analysis;requirements management;requirement prioritization;business requirements;formal verification;computer science;systems engineering;knowledge management;requirement;software engineering;requirements elicitation;data mining;requirements engineering;programming language;non-functional requirement;requirements traceability	SE	-67.93109356255961	21.841284903050727	186799
30def4020c8ff3b9ca10ce675285ad1f895f9c39	evaluation of software quality	development process;quality assessment;software quality	The paper describes a method, which we used to eva luate the expected quality of software that was developed for a huge governmental system. The evaluation lasted nearly two years and was perf ormed along with the software development process. The output that was expec ted by our customer consisted of a quality assessment accompanied by a set of r commendations on what to do in order to enhance the quality of the p roduct.	human-readable medium;iso/iec 9126;perf (linux);relay;software development process;software quality;waterfall model	Krzysztof Sacha	2005			reliability engineering;quality assurance;quality function deployment;personal software process;quality control;verification and validation;team software process;quality policy;software quality management;software sizing;systems engineering;engineering;operations management;quality audit;software quality control;software metric;software quality analyst	SE	-63.51106303042357	27.583277776207805	186868
7dd80f3bf41127d382da5f1e6f7fcdb63537d428	article summaries		How Standards Enable Adoption of Project Management Practice by Suzanne Garcia, pp. 22–29. Appropriate standards are a powerful transition mechanism to support implementation of new technologies, including practice-based technologies such as project management practices. Standards affect the adoption of project management practices in three areas: deployment of practices in an organization, customer-supplier relationships, and the community of project management practitioners.	blender (software);software deployment;software project management	J. Fernando Naveda;Stephen B. Seidman	2005	IEEE Software	10.1109/MS.2005.115		HCI	-68.13802970580367	19.536540489068454	187681
06d39dacc497d1439a165966628d94cff50960b3	experiment-driven approach to building support for distributed agile teams	architectural design;tool support;programming profession video sharing collaboration meeting planning navigation software engineering computer science iterative methods globalization computer industry;program verification;support system;software architecture;agile methodologies;distributed programming;agile programming distributed agile teams supporting system agile studio agile server distributed pair programmers editor;software architecture distributed programming program verification	Supporting agile methodologies in distributed setting requires a suitable tool support, which, at the moment, does not meet the expectations. Presented paper proposes an iterative and experimental approach to developing discussed support aimed at continuous enhancement of the supporting system and tailoring it to the needs. As a verification of these assumptions a dedicated environment called Agile Studio is developed. The paper gives an overview over its two implemented elements: agile server and distributed pair programmers editor. This includes a presentation of architectural design and provided features with reference to iteratively elaborated requirements. In addition, the results of conducted evaluating experiment are reported.	agile software development;experiment;feedback;iterative method;pair programming;programmer;requirement;server (computing);software design pattern;synergy;test-driven development;usability	Jacek Dajda;Grzegorz Dobrowolski	2007	14th Asia-Pacific Software Engineering Conference (APSEC'07)	10.1109/APSEC.2007.52	software architecture;pair programming;agile unified process;extreme programming practices;agile usability engineering;computer science;systems engineering;engineering;software engineering;agile software development;empirical process;lean software development;computer engineering	SE	-67.11805858278238	25.95220258897118	187830
4cde06635d9a7d429deb1fbecffb8d7a55777c64	optimizing investments in security countermeasures: a practical tool for fixed budgets	decision support;security countermeasures;software cost estimation;economic reality;fixed budgets;policy recommendation;risk management;software engineering;software engineers;investment;system security;requirements engineering;temporal constraints;budgeting;it security;software security;investments security costs frequency estimation optimization methods hardware software engineering financial management project management engineering management;software security mitigation;integer programming;requirement engineering;optimal system security;fixed budgets investment security countermeasures policy recommendation architectural recommendation security vulnerabilities postproduction software engineers economic reality optimal system security software security mitigation;integer programming software engineering requirements engineering risk management;optimal investment;integer program;architectural recommendation;security vulnerabilities postproduction;software cost estimation budgeting investment	As a software engineer or client, how much of your budget should you spend on software security mitigation for the applications and networks on which you depend? The authors introduce a novel way to optimize a combination of security countermeasures under fixed resources. Software engineers and their customers continuously face a complex and frustrating decision: given a fixed budget, which combination of vulnerability mitigation actions produces optimal system security? In a world without budgetary or temporal constraints, engineers could invest in whatever tools or training they deemed necessary to safeguard applications and networks. Or they could spend arbitrary amounts of time and money patching existing code and take painstaking precaution in writing new software to ensure its security. Of course, the economic reality is that software engineers are pushed to get their product to market as fast as possible, and security is often a distant priority in the face of budgetary constraints. However, fixing any remaining security vulnerabilities postproduction can be both costly and wasteful. In this article, we describe a novel methodology for quantitatively optimizing the blend of architectural and policy recommendations that engineers can apply to their products to maximize security under a fixed budget. The results of our optimization are sometimes surprising and even counterintuitive: bigger budgets don't always produce greater security, and the optimal combination of corrective actions changes nonlinearly with increasing expenditures. These findings suggest that some form of formal decision support could augment traditional methods.	application security;decision support system;mathematical optimization;nonlinear system;optimizing compiler;software engineer;vulnerability (computing);vulnerability management	Jonathan P. Caulkins;Eric D. Hough;Nancy R. Mead;Hassan Osman	2007	IEEE Security & Privacy	10.1109/MSP.2007.117	security through obscurity;investment;computer science;requirements engineering;security testing;computer security	Security	-69.73282835410048	26.268602684307304	187933
64d2ccf22e9219fb67df63b07557d3758b6ac7c3	the impending changes in software education	computer industry software safety software quality software performance software engineering manufacturing industries protection law health and safety government;government;manufacturing industries;computer industry;software engineering;law;software performance;protection;software safety;health and safety;software quality	Software’s critical nature Software is increasingly used in businesscritical and even life-critical situations. We are moving from a benign environment with typically friendly and honest users to an environment in which criminals, malcontents, and even terrorists use our systems. Safety and security are growing concerns. However, although the public’s health, safety, and welfare increasingly depend on software, approximately 75 percent of all software projects are either late or cancelled.1 A staggering 78 percent of IT organizations have been involved in disputes guest editors’ introduction		Thomas B. Hilburn;Watts S. Humphrey	2002	IEEE Software	10.1109/MS.2002.1032848	personal software process;long-term support;verification and validation;software engineering process group;systems engineering;engineering;package development process;social software engineering;software development;software engineering;occupational safety and health;software walkthrough;management;software deployment;software quality control;software requirements;government;software quality;software quality analyst;computer engineering;software peer review	SE	-68.95135795660842	26.848507350939165	188040
07369e4c1a228a69976da5d236dbdd3d7c39c927	ten strategies for successful distributed development	distributed software development;distributed development framework;info eu repo semantics conferenceobject;technology;strategies case studies;computer and information science;teknik;data och informationsvetenskap;global software development	This paper presents an overview of the field of distributed development of software systems and applications (DD). Based on an analysis of the published literature, including its use in different industrial contexts, we provide a preliminary analysis that structures existing DD knowledge, indicating opportunities but identifying threats to communication, coordination, and control caused by temporal distance, geographical distance, and sociocultural distance. An analysis of the case and field study literature has been used to identify strategies considered effective for countering the identified threats. The paper synthesizes from these a set of 10 general strategies for successful DD which, if adopted, should lead to increased company resilience.	field research;geographical distance;software system	Brian Lings;Björn Lundell;Pär J. Ågerfalk;Bob Fitzgerald	2006		10.1007/0-387-34410-1_9	systems engineering;engineering;knowledge management;data mining	SE	-72.00000288682392	20.719039021823754	188114
41067d89336b412d3e8f2a0fa2f4e0a9b62721cf	understanding and improving technology transfer in software engineering	software engineering;technology transfer	Software engineering has come a long way since 1968, when the term was first introduced at a NATO conference. Today, software pervades almost all aspects of our lives, from controlling our appliances to transporting us around the world. However, the transfer of new software engineering techniques and tools to common practice has had much more limited success; sometimes new ideas take hold immediately, but more often a new, proven idea takes many years to become accepted as standard practice. As practitioners, we are faced regularly with technology decisions: which to keep and which to replace, and how to adapt new technologies to our particular situations so that they are most efficient and effective. As researchers, we must evaluate the effects of a technology, and build a body of evidence to help in the decision-making process. This paper summarizes the history of software engineering technology transfer and suggests ways to help both practitioners and researchers understand how to shorten the time between innovation and effective practice.	history of software engineering	Shari Lawrence Pfleeger	1999	Journal of Systems and Software	10.1016/S0164-1212(99)00031-X	computer science;systems engineering;engineering;knowledge management;social software engineering;software engineering;technology education	SE	-70.00050910681205	25.542662982559772	188472
24e169f2df07090463f2d803e038616cc9bd3162	towards better software management through careful analysis of current application systems	software management	Results are reported of empirical investigations into EDP applications in use. A model for connecting terms of the users of the applications to the consumed hardware resources is proposed. The properties of so-called “application profiling” are studied. Discussions are based on through analyses of a few EDP applications and one of them is abridged as a case study.	software project management	Ari Heiskanen;Jaana Helanterä	1982	Information & Management	10.1016/0378-7206(82)90024-6	computer science;systems engineering;software engineering;data mining	OS	-66.22901565578708	18.907926632456558	188560
1bc0c1e8a182b0e9ecdc7259e3622ec5d23ac2bb	special section on empirical studies of programming	empirical study			Elliot Soloway	1987	Journal of Systems and Software	10.1016/0164-1212(87)90031-8	computer science;empirical research	SE	-65.87053009275603	23.991271516404552	188669
b43ca2ec0a45136f79ed981341601deb7aa2e05e	software engineering and computer systems - second international conference, icsecs 2011, kuantan, pahang, malaysia, june 27-29, 2011, proceedings, part i			software engineering		2011		10.1007/978-3-642-22170-5	verification and validation;computing;software engineering process group;information engineering;software verification;search-based software engineering;systems engineering;social software engineering;informatics engineering;component-based software engineering;software development;software engineering;software construction;computer-aided engineering;systems development life cycle;computer-aided software engineering;software requirements;software system;computer engineering	Robotics	-63.271744284076206	25.529441937489562	188691
867f3f32f675094398cea00ad287723662933a1a	effort estimation for erp projects - a systematic review		Enterprise Resource Planning (ERP) systems are large scale integrated systems covering most of the business processes of an enterprise. ERP projects differ from software projects with customization, modification, integration and data conversion phases. Most of the time effort and time estimations are performed in an ad-hoc fashion in ERP projects and as a result they frequently suffer from time and budget overruns. Although there is no consensus on a methodology to estimate size, effort and cost of ERP projects there are various research studies in the field. The purpose of this paper is to review the literature on effort estimation methods for ERP projects, their validations and limitations. The systematic literature review used online journal indexes between January 2000 and December 2016. Studies focusing on effort estimation for ERP projects were selected. Two reviewers assessed all studies and 41 were shortlisted. In most of the studies, cost factors for ERP projects were investigated and validated. Our findings showed that effort estimation methods have mostly used function points as an input. Validations of these methods were mostly done by using history-based validation approaches.	erp;systematic review	Neslihan Küçükates Ömüral;Onur Demirörs	2017		10.1109/SEAA.2017.68	computer science;software;personalization;function point;systems engineering;data modeling;business process;enterprise resource planning;factor cost;systematic review	SE	-68.9537161525087	20.62142151717085	188897
0f8f951da2f680876a62e4102375085b0a84c914	using a web-based repository to integrate testing tools into programming courses	software testing;integration testing;unit testing;learning resource;software engineering;computer science education;software development;software industry;programming courses	Improving the quality of software developed in the 21st century is one of the major challenges in the software industry. Addressing this problem will require that academic institutions play a key role in training developers to produce high quality software. Unfortunately, students and instructors continue to be frustrated by the lack of support provided when selecting appropriate testing tools and program analyzers to verify programs under development.  In this paper we present an approach that integrates the use of software testing tools into programming and software engineering courses. The approach consists of three phases, developing an online repository with learning resources, training instructors in the area of testing techniques and tools, and integrating the use of testing tools into various programming courses. We also present the results of the first instructors' workshop and studies on integrating testing tools into two courses, CS2 and Software Engineering (SE).	display resolution;software engineering;software industry;software testing;web application	Peter J. Clarke;Andrew A. Allen;Tariq M. King;Edward L. Jones;Prathiba Natesan	2010		10.1145/1869542.1869573	test strategy;verification and validation;software performance testing;system integration testing;integration testing;computer science;acceptance testing;package development process;social software engineering;software reliability testing;software framework;component-based software engineering;software development;software construction;software testing;unit testing;resource-oriented architecture;software quality;software quality analyst;software system;software peer review	SE	-65.64077618926855	26.946579780958857	189096
e7333570203ebd6138efb9d85ffcb2f620dd3617	a process model design and tool development for supplier agreement management of cmmi: capability level 2	software engineering software development management;level 2;software tool;supplier agreement management tool process model design tool development supplier agreement management cmmi software product acquisition business workflow process model contextual layer elaboration layer definition layer;process design capability maturity model software tools software engineering subcontracting software development management design engineering business costs best practices;software engineering;management tool;process model;software development management	Acquired software products from suppliers are being increasing tremendously because of insufficiency of resources and capable employees. To manage and monitor the product acquisition process effectively according to a signed contract with a supplier, an organization has to define the standard of workflow, deliverable products in each step and staff roles and responsibilities, etc. Thus, there is a need to incorporate these diversified processes into a single process model that could helps to reach the software product acquisition goal. CMMI defines supplier agreement management process area (SAM) that relates to product acquisition but it does not describe how the organization should do to achieve its expectation. This research presents a business workflow process model for SAM process area of CMMI: capability level 2. It consists of three layers: contextual layer, elaboration layer, and definition layer. A software tool called supplier agreement management tool (SAMT) is also developed to help integrate the details of our approach and can be used for the proposed process model.	cpu cache;capability maturity model integration;convergence insufficiency;process modeling;programming tool	Chakkanart Vivatanavorasin;Nakornthip Prompoon;Athasit Surarerks	2006	2006 13th Asia Pacific Software Engineering Conference (APSEC'06)	10.1109/APSEC.2006.12	standard cmmi appraisal method for process improvement;reliability engineering;personal software process;verification and validation;team software process;software quality management;software engineering process group;software sizing;leancmmi;software project management;systems engineering;engineering;knowledge management;business process management;capability maturity model integration;package development process;social software engineering;software development;software engineering;software construction;process modeling;empirical process;software measurement;business process modeling;goal-driven software development process;software development process	SE	-67.54494100751886	20.592264310293213	189329
433a83d9ebe6ceacca364e235fd35dd74fc61ac6	semiotic inspection method in the context of educational simulation games	scientific application;software process simulation;software process improvement;simulation;evaluation method;simulation game;communicability;software engineering;semiotic inspection method;game;simulation tool;semiotic engineering;software process	Software process simulation is increasingly being used as an approach for analyzing complex business, for supporting management planning, for helping with software process training and learning and for supporting the software process improvement. In addition to providing to users a simulation tool that supports all these aspects, it is also important to consider some other requirements during the tool's design, such as efficient and effective communication of the designer's message to the user. In this way, we show how semiotic concepts can be used in the analysis and generation of knowledge through the application of the Semiotic Inspection Method (SIM), a semiotic engineering evaluation method. In this paper we present a scientific application of SIM to a Software Engineering simulation game focusing the analysis on feedback aspects and issues. The results go beyond the system analyzed and point to considerations regarding simulation games used in educational contexts.	requirement;semiotic engineering;semiotics;simulation;software development process;software engineering	Daniela Cristina Cascini Peixoto;Raquel Oliveira Prates;Rodolfo F. Resende	2010		10.1145/1774088.1774342	games;personal software process;verification and validation;simulation;software engineering process group;software sizing;computer science;package development process;software design;social software engineering;software development;software engineering;software construction;multimedia;software walkthrough;goal-driven software development process;software development process;software requirements;software system	SE	-65.54567863685548	26.28279281227023	189469
011ff98b79f8d82f01e7de25e90a2f9d7742120c	ten steps of integrating user feedback into the product definition process: a closed loop approach	best practice;user feedback;user centered design;product definition process;user centered design process;time integration	An appropriate and timely integration of results from user feedback studies into product definition and development efforts is an important but challenging goal. In this paper we describe some best practices and processes at SAP which are facilitating this integration. They are based on several years of experience of applying user centered design principles to SAP Business ByDesign Software.	best practice;closed-loop transfer function;sap business bydesign;user-centered design	Jens Bombolowsky;Edmund Eberleh	2009		10.1145/1520340.1520390	user interface design;user experience design;user-centered design;computer user satisfaction;human–computer interaction;computer science;knowledge management;management	DB	-64.56710407498772	22.009223494762036	189558
3c6b7cc1fec6df9554b5ac65507867fe4fcc2b7c	a methodology to use market simulation software in the teaching of business management		This work aims at presenting and analyzing the use of Enterprise Resource Planning Simulation Game software as a success case of the application of the Problem-Based Learning strategy classes in business management. Problem-Based Learning is a strategy focused on the process of self - learning through problem solving. The ERP Simulation Game is a simulation software market, developed by HEC Montreal. To achieve the desired educational goals, it was necessary to define a methodology for me - use software, which include all the essential characteristics of Problem-Based Learning. It was observed during the application of the methodology to use software that increases the level of involvement and pursuit of knowledge by students, motivated by competition that the software provides.	simulation software	Fabio Correa Xavier;Beatriz Camasmie Curiati Salione;Solange N. Alves de Souza	2015		10.1007/978-3-319-16486-1_119	business rule management system;verification and validation;business requirements;software project management;systems engineering;business process management;package development process;social software engineering;software development;software asset management;software as a service;management science;process management;business;business software;software deployment;business process modeling;software development process;software quality;business activity monitoring	ECom	-65.79611856596046	21.621014420042705	189794
a78431f127b303d3804e11c35caf5a07410fbc0a	agile software assurance	agile methods;software quality	1. What is the quality of Agile Software, importantly, how we can evaluate the quality of Agile Software? 2. Can Agile assure the quality under time pressure and with unstable requirements? 3. What are the best ways to assure the quality of Agile Software? 4. Different organizations interpret words like Agile and iterative in different ways. Therefore, another question is how do organizations understand these terms?	agile software development;control theory;iteration;microsoft software assurance;requirement	Noura Abbas;Andrew M. Gravell;Gary B. Wills	2007		10.1007/978-3-540-73101-6_26	software security assurance;p-modeling framework;personal software process;verification and validation;agile unified process;extreme programming practices;agile usability engineering;software development;release management;software construction;agile software development;software testing;empirical process;lean software development;software quality control;software development process;software quality;software quality analyst	SE	-67.73169002033049	23.785171052974526	189972
948698cc36943f4d3c9df518e1b2ba00c96cebe1	process oriented software quality assurance - an experience report in process improvement - oem perspective [automotive applications]	software management processes;safety critical software systems;automotive engineering;quality assurance;human factors automotive engineering software process improvement software quality quality assurance software development management software standards safety critical software;oem;construction process;software process improvement;software quality assurance;software systems;automotive software development;software engineering;experience report;wireless sensor network;software quality automotive applications automotive engineering software safety software standards software engineering buildings software systems knowledge engineering costs;standardisation;human factors;automotive applications;software safety;software key component standards;safety critical software;safety critical system;software construction process;cost effectiveness;process oriented software quality assurance;software standards;coverage;process improvement;human factors process oriented software quality assurance process improvement oem automotive software development software construction process software key component standards software engineering safety critical software systems standardisation software management processes;set cover;software quality;buildings;software development management;knowledge engineering	This paper proposes that a well defined software construction process, and standards for key components, is a successful way for future software engineering. One of the main topics of building complex and safety critical software systems is the establishing of constructing quality as key knowledge for automotive engineers. It suggests that a high technology product can only be cost effectively produced by standardisation, effective engineering and management processes and considering the human factor. The software construction of complex, safety critical systems can no longer be a job for individual artists, it has to be the job of trained and motivated engineers, even in a classical industry such as automotive.	human factors and ergonomics;software construction;software engineering;software quality assurance;software system	Thomas Illgen;Stefan Ortmann	2005	Design, Automation and Test in Europe	10.1109/DATE.2005.245	reliability engineering;quality assurance;personal software process;verification and validation;team software process;wireless sensor network;cost-effectiveness analysis;software quality management;software engineering process group;software sizing;computer science;systems engineering;engineering;package development process;social software engineering;software development;original equipment manufacturer;software engineering;knowledge engineering;software construction;set cover problem;software walkthrough;software deployment;software quality control;software requirements;standardization;software quality;software metric;software quality analyst;software system;avionics software	SE	-63.31178406448929	27.630923947873345	189980
e36de1206eeef84a44e755cf42dd90b4afe48106	determining defect trends and identifying critical discriminators: a case study			software bug	John D. Powell	2004			reliability engineering;systems engineering;computer science	SE	-62.93257798695392	26.285190791007658	190047
6c64ca4a8992286bd48b80718ed61ab8738d42c1	devops enhancement with continuous test optimization			devops;program optimization	Dusica Marijan;Sagar Sen	2018		10.18293/SEKE2018-168	systems engineering;computer science;devops	EDA	-63.591426500877304	23.427543860804334	190467
6cfec069b01c65efec756bc234bf64cbcbefd547	software architecture and agile software development: a clash of two cultures?	agile software development;software;computer architecture software architecture programming software tutorials documentation;software prototyping;lean software development;system documentation;architectural issue;computer architecture;system documentation software architecture software development management software prototyping;software architecture;tutorials;agile process;software architecture agile process;project architecture;software development;architectural effort agile software architecture agile software development lean software development bufd big up front design architectural issue project architecture;agile software architecture;programming;bufd big up front design;software development management;documentation;architectural effort	"""Software architecture is taking a bad rap with the agilists---proponents of agile and lean software development approaches: """"BUFD big up-front design"""", """"YAGNI You Ain't Gonna Need It"""", """"massive documentation"""", """"smells of waterfall"""", it is pictured as a typical non-agile practice. However, certain classes of system, ignoring architectural issues too long """"hit a wall"""" and collapse by lack of an architectural focus. 'Agile architecture': a paradox, an oxymoron, two totally incompatible approaches? In this tutorial, we examine the real issues at stake, beyond the rhetoric and posturing, and show that the two cultures can coexist and support each other, where appropriate. We define heuristics to scope how much architecture a project really needs, to assign actual value to an otherwise invisible architecture; and we review management and development practices that do work in the circumstances where some significant architectural effort is needed, when you are actually going to need it."""	agile architecture;agile software development;big design up front;coexist (image);documentation;gon;heuristic (computer science);lean software development;numerical aperture;software architecture;you aren't gonna need it	Philippe Kruchten	2010	2010 ACM/IEEE 32nd International Conference on Software Engineering	10.1145/1810295.1810448	database-centric architecture;computer science;systems engineering;engineering;software engineering;agile software development;you aren't gonna need it;computer engineering	SE	-69.29189920410253	26.609011586671407	190628
241161cee4ca3c2d59ef981c3ca49edfe0708d4f	the effect of task and tool experience on maintenance case tool usage	utilization model;computer aided software engineering;case tool;baseline maintenance tool;case	Computer-Aided Software Engineering (CASE) tools have been advocated for improving maintainer productivity and the quality of maintained software. While there is evidence that such benefits can accrue to organizations adopting maintenance-oriented CASE tools, a key problem in achieving the desired benefits from CASE tools is low usage of these tools by programmers. The previously tested Maintenance Tool Utilization Model was a first step in investigating the factors that affect whether maintainers choose to use CASE tools during maintenance projects. We test the addition of experience with software maintenance tools and with the software maintenance task to the Maintenance Tool Utilization Model. The role of experience is important because managers can provide training to increase experience and they can ensure that project teams have some members experienced with the tools This chapter appears in the book, Advanced Topics in Information Resources Management, Volume 3, edited by Mehdi Khosrow-Pour. Copyright © 2004, Idea Group Inc. Copying or distributing in print or electronic forms without written permission of Idea Group Inc. is prohibited. 701 E. Chocolate Avenue, Suite 200, Hershey PA 17033-1240, USA Tel: 717/533-8845; Fax 717/533-8661; URL-http://www.idea-group.com IDEA GROUP PUBLISHING	computer-aided software engineering;fax;pa-risc;programmer;software maintenance;uniform resource identifier	Mark T. Dishaw;Diane M. Strong	2003	IRMJ	10.4018/irmj.2003070101	reliability engineering;systems engineering;engineering;knowledge management;computer-aided software engineering	SE	-70.02611000592344	24.51013743786806	190783
0b5d04220ec2a3502b09e9973e0c2defc45a0b1d	management of softwrare product development, innovation and adaptability	innovation	This inductive study develops a model of innovation and adaptability in software product development. It is based on a case study of a company that is transitioning from a custom development approach to a product-based solution. The emergent model represents a synthesis of the case study findings and the enfolding literature from traditional product development and software development. The goal of the emergent software product development model is to guide organizations in their selection of development processes.	emergence;new product development;software development	Michael L. Harris;Alan R. Hevner;Rosann Webb Collins	2009			new product development;product engineering;knowledge management;product design specification;product management;software development process;innovation management;computer science;lean software development;scrum	SE	-66.7227430021023	18.454289783873673	190818
df4f3a6af2de107130b848a2ad46137760d1bc58	lessons learned in an industrial software lab (software development)	industrial software lab;project management;software developer;software engineering project management;implementation;development process models;formal methods;development process;software engineering;reuse;formal method;development process models industrial software lab software development software developer formal methods reuse implementation;lessons learned;software development;computer industry programming design methodology error analysis testing laboratories job shop scheduling specification languages assembly documentation	The author offers a personal account of the issues and challenges that have confronted the software developer over the last few decades. The failures and successes associated with formal methods, the realities of reuse, and the implementation of development process models and goals are discussed.<<ETX>>	formal methods;reuse (action);software developer;software development	Albert Endres	1993	IEEE Software	10.1109/52.232401	personal software process;verification and validation;formal methods;software engineering process group;software project management;computer science;systems engineering;package development process;backporting;software design;social software engineering;software framework;component-based software engineering;software development;software engineering;software construction;reuse;software walkthrough;software analytics;resource-oriented architecture;implementation;software deployment;goal-driven software development process;software development process;software system;computer engineering;software peer review	SE	-63.467373294808894	26.637489646222694	191114
04c2a3a14c284b19b8c6547be831958924dc733b	simulating cities: a software engineering perspective	systems design;simulation;software architecture;programming	Despite all the reasons why complex simulations are desirable for decision and policy making, and despite advances in computing power, large distributed simulations are still rarely used. The reality is that developing distributed simulations is much harder than developing nondistributed, specialized ones, and requires a much higher level of software engineering expertise. Prof. Cristina Lopes and her students have been working on a software architecture, and a corresponding software framework, which have the goal of lowering the barriers for the simulation of large, complex systems, such as entire cities.	complex systems;simulation;software architecture;software engineering;software framework	Cristina V. Lopes	2016		10.1007/978-3-662-49498-1_1	software architecture;programming;simulation;software engineering process group;computer science;social software engineering;component-based software engineering;software development;management science;systems design	SE	-64.81891229783022	20.453174525700753	191664
523b56b27da0eed58c99583d5c93a02b2f7bbb0d	usability issues in spoken dialogue systems	spoken dialogue system	Whilst Spoken Language Dialogue Systems (SLDSs) technology has made good progress in recent years, the issue of SLDS usability is still lagging behind both theoretically and in actual SLDS development and evaluation. However, as more products reach the market and competition intensifies, there is growing recognition of the importance of systematically understanding the factors which must be taken into account in order to optimise SLDS usability. Ideally, this understanding should be comprehensive (i.e. include all major human factors perspectives on SLDSs), and exhaustive (i.e. describe each perspective as it pertains to the detailed development and evaluation of any possible SLDS). This paper addresses the requirement of comprehensiveness by decomposing the complex space of SLDS usability best practice into eleven issues which should be considered by developers during specification, design, development and evaluation. The discussion of each issue is aimed to support the developer in building SLDSs which are likely to generate user satisfaction, which are perceived to be easy to understand and control, and which enable smooth user- system interaction. Based on the best practice issues discussed, criteria for evaluating SLDS usability are proposed. Several limits to our current understanding of SLDS usability are highlighted.	dialog system;usability	Laila Dybkjær;Niels Ole Bernsen	2000	Natural Language Engineering	10.1017/S1351324900002461	natural language processing;usability goals;computer science;knowledge management;usability engineering	NLP	-71.86753811739072	24.01576213340717	191900
20db0c79a11a4bcd4611b3f7d1c1ec0c8fd936d1	how many story points for diversity?: estimation as a chance for diversity reflexion		This paper presents the tool of estimation in the scrum framework as a potential step to reflect in the team on differences of diversity dimensions. The research is based on constructing grounded theory of Charmaz.	scrum (software development);solution of schrödinger equation for a step potential	Helena Barke	2018		10.1145/3196839.3196872	management science;solution of schrödinger equation for a step potential;grounded theory;reflection (mathematics);scrum;mathematics	HCI	-70.98576055096672	20.80025399768243	192070
993a9a1c82f9792e8d14bfbb9418db188ba874dd	network analysis of scientific workflows: a gateway to reuse	social network services;case framework;groupware;reseau social;online workflow repositories;services computing;software reusability social networking online;selected works;reutilizacion;scientific workflow;social network analysis network analysis scientific workflows online workflow repositories;reuse;network analysis;scientific workflows;social network;workflow reuse;research and development;biocatalogue scientific computing services computing scientific workflows workflow reuse case framework myexperiment;biocatalogue;workflow management software scientific computing best practices social network services research and development;best practices;software reusability;social networking online;scientific computing;workflow management software;social network analysis;workflow;bepress;information gateway;pasarela informacion;passerelle d information;analyse circuit;collecticiel;myexperiment;red social;analisis circuito;reutilisation	Online workflow repositories let scientists share successful experimental routines and compose new workflows from best practices and existing service components. The authors share the results of a social network analysis of the myExperiment workflow repository to assess the state of scientific workflow reuse and propose the CASE framework to facilitate such reuse.	best practice;social network analysis;myexperiment	Wei Tan;Jia Zhang;Ian T. Foster	2010	Computer	10.1109/MC.2010.262	workflow;social network analysis;network analysis;computer science;knowledge management;reuse;database;services computing;windows workflow foundation;world wide web;workflow management system;workflow engine;best practice;social network;workflow technology	HPC	-75.66378144715367	22.027310660269073	192129
de270dcf3a03059af50f6da3a89ff1ba5631eb04	does the technology acceptance model predict actual use? a systematic literature review	computacion informatica;technology acceptance model;grupo de excelencia;actual usage;software engineering;technology acceptance model tam;ciencias basicas y experimentales;evidence based software engineering;systematic literature review;literature review	0950-5849/$ see front matter 2009 Elsevier B.V. A doi:10.1016/j.infsof.2009.11.005 * Corresponding author. Tel.: +44 (0) 1782 734090; E-mail address: m.turner@cs.keele.ac.uk (M. Turne Context: The technology acceptance model (TAM) was proposed in 1989 as a means of predicting technology usage. However, it is usually validated by using a measure of behavioural intention to use (BI) rather than actual usage. Objective: This review examines the evidence that the TAM predicts actual usage using both subjective and objective measures of actual usage. Method: We performed a systematic literature review based on a search of six digital libraries, along with vote-counting meta-analysis to analyse the overall results. Results: The search identified 79 relevant empirical studies in 73 articles. The results show that BI is likely to be correlated with actual usage. However, the TAM variables perceived ease of use (PEU) and perceived usefulness (PU) are less likely to be correlated with actual usage. Conclusion: Care should be taken using the TAM outside the context in which it has been validated. 2009 Elsevier B.V. All rights reserved.	digital library;ibm tivoli access manager;library (computing);one-class classification;systematic review;usability	Mark Turner;Barbara A. Kitchenham;Pearl Brereton;Stuart M. Charters;David Budgen	2010	Information & Software Technology	10.1016/j.infsof.2009.11.005	systematic review;systems engineering;engineering;software engineering;data mining;world wide web	HCI	-73.01210851952032	24.534755340783303	192472
f2b01e6f628397738ae2c00e19f0affcd98a77c6	pair programming on the c3 project	concurrent computing;software libraries;extreme programming precepts pair programming c3 project chrysler s comprehensive compensation project it projects;it projects;testing;software engineering;extreme programming precepts;extreme programming;runtime library;pair programming;large scale;registers;programming profession;c3 project;chrysler s comprehensive compensation project;statistics;runtime library testing concurrent computing relational databases user interfaces statistics programming profession software libraries registers writing;writing;relational databases;programming;user interfaces;performance tuning;software engineering programming	"""Chrysler's Comprehensive Compensation (C3) project was one of the first large-scale IT projects on which Extreme Programming (XP) precepts were attempted. As XP was being invented, we didn't really think of it as a theoretical or methodological breakthrough; it was simply an opportunity to get the job done. The """"theory"""" came about later because of the practice's success. In my opinion, XP is not a theory, but a cogent descriptive body of successful praxis. Some people consider pair programming, an XP technique, to be difficult, unworkable, or downright weird. After all, what does the workstation represent, if not finally having your own computer? The idea of sharing your machine with someone seems like a lot of bother without much reward. How can you talk if you're trying to think? And how can you think if you first have to explain what you're thinking about? Having participated on the C3 project as a performance-tuning consultant beginning in 1996, I can attest to the success of pair programming. At the same time, I can show instances where it did not work or was not emphasized in this early XP project. In a sense, this pragmatism is the strength of XP: Use a technique where it works, ignore it where it doesn't. XP has never been prescribed as a panacea. XP's pair programming helps programmers synthesize their individual expertise into an effective combination."""	pair programming	Jim Haungs	2001	IEEE Computer	10.1109/2.901173	programming;extreme programming;concurrent computing;pair programming;relational database;computer science;artificial intelligence;operating system;software engineering;software testing;processor register;programming language;user interface;management;writing;you aren't gonna need it	Visualization	-70.49985513098498	27.66129005637015	192604
7a4e3a08aae25a0d27b285a498ad23ca7045b164	improving tool support for software reverse engineering in a security context		Illegal cyberspace activities are increasing rapidly and many software engineers are using reverse engineering methods to respond to attacks. The security-sensitive nature of these tasks, such as the understanding of malware or the decryption of encrypted content, brings unique challenges to reverse engineering: work has to be done offline, files can rarely be shared, time pressure is immense, and there is a lack of tool and process support for capturing and sharing the knowledge obtained while trying to understand assembly code. To help us gain an understanding of this reverse engineering work, we conducted an exploratory study at a government research and development organization to explore their work processes, tools, and artifacts [1]. We have been using these findings to improve visualization and collaboration features in assembly reverse engineering tools. In this talk, we will present a review of the findings from our study, and present prototypes we have developed to improve capturing and sharing knowledge while analyzing security concerns.	reverse engineering	Brendan Cleary;Christoph Treude;Fernando Marques Figueira Filho;Margaret-Anne D. Storey;Martin Salois	2013		10.1007/978-3-642-39454-6_12	software security assurance;reliability engineering;software engineering process group;security engineering;systems engineering;social software engineering;software construction;computer engineering	SE	-67.36407291973514	28.179266394287986	192758
c40e19097353155cc870117df9e5963e91a18423	sharing the wealth: accumulating and sharing lessons learned in empirical software engineering research	empirical software engineering;lessons learned		experimental software engineering	Warren Harrison	1998	Empirical Software Engineering	10.1023/A:1009731704468	construction engineering;computer science;systems engineering;engineering;knowledge management;empirical process	SE	-66.09842617373894	23.702492220676067	192850
0973da4f366a26c84929a3bc2206d8c22d4de442	on the adaptation of an agile information systems development method	method engineering;information systems development;method adaptation;agile method;agile information systems;is;information system development	Little specific research has been conducted to date on the adaptation of agile information systems development (ISD) methods. This article presents the work practice in dealing with the adaptation of such a method in the ISD department of one of the leading financial institutes in Europe. Two forms of method adaptation, static adaptation and dynamic adaptation, are introduced and discussed in detail. We provide some insights plus an instrument that the ISD department studied uses to deal with the dynamic method adaptation. To enhance our understanding of the observed practice, we take into account two complementary perspectives: the engineering perspective and the socio-organizational perspective. Practical and theoretical implications of this study are discussed.	agile software development;information system;software development process;static variable	Mehmet N. Aydin;Frank Harmsen;Kees van Slooten;R. A. Stagwee	2005	J. Database Manag.	10.4018/jdm.2005100102	method engineering;agile unified process;agile usability engineering;computer science;knowledge management;software engineering;agile software development;management science;is	SE	-69.6090154925249	20.60340655369861	192928
bc6ea03a111a6d30c34c09542e43611b6f98691c	a novel quantitative evaluation approach for software project schedules using statistical model checking	statistical model checking;project schedule;swinburne;会议论文;quantitative evaluation	Project schedules are essential for successfully carrying out software projects. To support manager’s decision making, many project scheduling algorithms have been developed in recent years for generating candidate project schedules. However, these project schedules may not be able to be used directly because the uncertainty and complexity of real-world software development environments which have been overlooked or simplified in the project scheduling algorithms. Therefore, significant human efforts are still required to evaluate and compare these project schedules. To address such a problem, we propose a quantitative analysis approach based on statistical model checking technique which serves as a novel evaluation method for project schedules. By using the UPPAAL-SMC, we can systematically evaluate the performance of a project schedule and answer complex questions which are vital for manager’s decision making but cannot be efficiently addressed by any existing tools. The preliminary results show that our approach can efficiently filter out unsatisfactory candidates by answering simple “yes or no” questions first and then help effectively compare the rest by answering complicated user specified questions. Therefore, the human efforts in planning project schedules can be significantly reduced.	algorithm;model checking;schedule (computer science);scheduling (computing);software development;software project management;statistical model;uppaal	Dehui Du;Mingsong Chen;Xiao Qiao Liu;Yun Yang	2014		10.1145/2591062.2591132	computer science;systems engineering;engineering;estimation;data mining;management science;project management triangle;schedule	SE	-69.86195799969049	23.96172588339074	193012
a16ce0aeb2f06c0917afaf6e17d2a0280bdea4fc	mining the ground truth of enterprise toolchains		Data on organizations’ use of agile and DevOps tools provides the ground truth of enterprise software delivery.	agile software development;devops;enterprise software;ground truth;software deployment;toolchain	Mik Kersten	2018	IEEE Software	10.1109/MS.2018.2141029	systems engineering;computer science;software engineering;task analysis;software;devops;agile software development;enterprise software;ground truth	Visualization	-64.907466732737	22.668123197224265	193059
f68643e50fa541e7b9ac447065cd13a433bba165	organizing for agility: a complex adaptive systems perspective on agile software development process	agile software development;info eu repo semantics conferenceobject;software development process;complex adaptive systems;conference paper;enterprise agility	Agile software development has caught the attention of both practitioners and academics in recent years. In spite of many anecdotes and papers describing lessons learnt the theoretical foundation of agile software development has not been systematically articulated. This paper proposes a conceptual framework to study agile software development based on the theory of complex adaptive systems. The framework is illustrated by a case study of an agile software development team. Several agile practices are identified and reflected on from the perspective of complex adaptive systems.	agile software development;complex adaptive system;organizing (structure);software development process	Richard T. Vidgen;Xiaofeng Wang	2006			feature-driven development;complex adaptive system;p-modeling framework;requirements analysis;personal software process;agile unified process;extreme programming practices;agile usability engineering;computer science;knowledge management;software evolution;software development;requirement;software engineering;iterative and incremental development;agile software development;systems development life cycle;software documentation;empirical process;management;lean software development;goal-driven software development process;software development process;best coding practices	SE	-67.90334627403566	21.028837027134454	193095
21e9f682a867a18ced6de467b7dec466b400b2e2	simulation of adaptive project management analytics	enabling project manager;common project management practice;optimization algorithm;it project;better outcome;risk factor;alternative approach;better alternative;project plan;adaptive project management analytics;budget project completion;project planning;information technology;risk factors;manufacturing industries;project management;optimization;resource allocation	Typically, IT projects are delivered over-budget and behind schedule. In this paper, we explore the effects of common project management practices that contribute to these problems and suggest a better alternative that can utilize resources more effectively. Our alternative approach uses (a) a thorough analysis of risks affecting activities in a project plan (i.e., the root factors leading to cost and time overruns), and (b) an optimization of the resources allocated to each activity in the project plan to maximize the probability of on time and within budget project completion. One key feature of our method is its capability to adapt and learn the risk factors affecting activities during the course of the project, enabling project managers to reallocate resources dynamically to ensure a better outcome given the updated risk profile. We use simulations to test the performance of our optimization algorithm and to gain insights into the benefits of adaptive re-planning.	algorithm;emoticon;mathematical optimization;simulation	Léa A. Deleris;Sugato Bagchi;Shubir Kapoor;Kaan Katircioglu;Richard Lam;Stephen J. Buckley	2007	2007 Winter Simulation Conference		level of effort;basis of estimate;project management;resource;resource allocation;systems engineering;engineering;knowledge management;manufacturing;project management triangle;information technology;schedule;risk factor;risk management plan;project planning;project portfolio management	SE	-71.11180154095038	19.620383822634395	193386
21d4ecfe689449febd1bd5c1190ea3b81d079e40	software quality improvement	software quality costs humans man machine systems user interfaces software maintenance application software telephony software systems natural languages;application software;software maintenance;software systems;natural languages;telephony;humans;user interfaces;man machine systems;software quality	"""Similarly, """"superior communication"""" in the manmachine interface refers to an approximation of human communication. Users want software that allows input and otput in less esoteric formats. The operator should have to descend to the level of the machine and Agage in dialog at each and every step. Voice I/O and dati processing in natural languages are sterling examples of superior communication. The rapid growth of software"""	approximation;input/output;natural language;software quality;dialog	Yukio Mizuno	1983	Computer	10.1109/MC.1983.1654331	medical software;long-term support;verification and validation;application software;software sizing;computer science;package development process;backporting;social software engineering;software framework;component-based software engineering;software development;software engineering;software construction;software walkthrough;natural language;telephony;user interface;software analytics;resource-oriented architecture;software maintenance;software deployment;software quality;software system;software peer review	ML	-69.26008139514275	28.80775120665919	193717
bffb13517a09fc7af9d07070694727b5e6137b87	decision-making framework for refactoring	software;code quality decision making framework refactoring;stakeholders;companies;decision making software interviews companies context stakeholders;interviews;context;software maintenance decision making	Refactoring has been defined as improving code quality without affecting its functionality. When refactoring is overlooked in daily development, the likelihood of larger refactorings increases with time. Disadvantages of larger refactorings include that they disrupt the daily work, require additional planning effort, and often they need to be justified to stakeholders. In this paper, we investigate with interviews how professionals make refactoring decisions. As a result, we present a framework for decision making for larger refactoring operations describing the key stages in a refactoring workflow. Furthermore, one actual industry case of refactoring decision making is presented in detail.	code refactoring;software industry;software quality;user-subjective approach	Marko Leppänen;Samuel Lahtinen;Kati Kuusinen;Simo Mäkinen;Tomi Männistö;Juha Itkonen;Jesse Yli-Huumo;Timo Lehtonen	2015	2015 IEEE 7th International Workshop on Managing Technical Debt (MTD)	10.1109/MTD.2015.7332627	reliability engineering;computer science;systems engineering;knowledge management	SE	-69.50153925530006	21.813280638948232	193955
89c5ea8aa0f208a12dba3a0b4ceb8873ad45e0f3	evolution in open source software: a case study	development model open source software case study software evolution large software systems evolutionary narratives commercially developed systems linux operating system kernel;software prototyping;software maintenance;open source development;operating system kernels software prototyping software maintenance unix;software systems;lines of code;software evolution;operating system;system development;operating system kernels;unix;software process;open source software;open source	Most studies of software evolution have been performed on systems developed within a single company using traditional management techniques. With the widespread availability of several large software systems that have been developed using an “open source” development approach, we now have a chance to examine these systems in detail, and see if their evolutionary narratives are significantly different from commercially developed systems. This paper summarizes our preliminary investigations into the evolution of the best known open source system: the Linux operating system kernel. Because Linux is large (over two million lines of code in the most recent version) and because its development model is not as tightly planned and managed as most industrial software processes, we had expected to find that Linux was growing more slowly as it got bigger and more complex. Instead, we have found that Linux has been growing at a super-linear rate for several years. In this paper, we explore the evolution of the Linux kernel both at the system level and within the major subsystems, and we discuss why we think Linux continues to exhibit such strong growth.	flat rate;kernel (operating system);linux;open-source software;operating system;software evolution;software system;source lines of code	Michael W. Godfrey;Qiang Tu	2000		10.1109/ICSM.2000.883030	embedded system;long-term support;verification and validation;real-time computing;software sizing;computer science;engineering;package development process;backporting;software evolution;social software engineering;software framework;component-based software engineering;software development;operating system;software engineering;software construction;open system;unix;software analytics;software maintenance;source lines of code;software deployment;software development process;linux kernel;software system	SE	-68.93960432655186	28.764435267623817	194454
d18241874b4b3d845a79971420ad76a40b53fe71	simple software processes and tests improve the reliability and usefulness of a model	automated testing;agricultural production;modeling and simulation;simulation;testing;sensibility tests;apsim;water use efficiency;software development;model development;model test;farming system;version control;system simulation;simulation modelling;software process;agriculture and the environment	Models are abstractions of reality that have predetermined limits (often not consciously thought through) on what problem domains the models can be used to explore. These limits are determined by the range of observed data used to construct and validate the model. However, it is important to remember that operating the model beyond these limits, one of the reasons for building the model in the first place, potentially brings unwanted behaviour and thus reduces the usefulness of the model. Our experience with the Agricultural Production Systems Simulator (APSIM), a farming systems model, has led us to adapt techniques from the disciplines of modelling and software development to create a model development process. This process is simple, easy to follow, and brings a much higher level of stability to the development effort, which then delivers a much more useful model.A major part of the process relies on having a range of detailed model tests (unit, simulation, sensibility, validation) that exercise a model at various levels (sub-model, model and simulation). To underline the usefulness of testing, we examine several case studies where simulated output can be compared with simple relationships. For example, output is compared with crop water use efficiency relationships gleaned from the literature to check that the model reproduces the expected function. Similarly, another case study attempts to reproduce generalised hydrological relationships found in the literature.This paper then describes a simple model development process (using version control, automated testing and differencing tools), that will enhance the reliability and usefulness of a model.		Dean P. Holzworth;Neil I. Huth;Peter G. de Voil	2011	Environmental Modelling and Software	10.1016/j.envsoft.2010.10.014	simulation;computer science;revision control;systems engineering;engineering;operations management;software development;modeling and simulation;software testing;agricultural productivity;software development process	SE	-70.58513647846955	24.00225371878668	194586
8ef1cc61a11f0bfe5bfc854ae59aa5bb0dbde508	business process management		As part of process redesign initiatives, substantial time is spent on the systematic description and analysis of the as-is process. By contrast, to-be scenarios are often generated in a less rigorous way. Only one or a few workshops are organized for this purpose, which rely on the use of techniques that are susceptible to bias and incompleteness, e.g. brainstorming. In this paper, we evaluate a new technique for generating process improvement ideas: the RePro (Rethinking of Processes) technique. Its backbone is formed by process improvement principles that guide practitioners in a systematic and comprehensive exploration of the solution space. An experiment was conducted to compare the performance of the RePro technique with traditional brainstorming. Results confirm the potential for using a more advanced technique during process redesign workshops, but also show that the way such a technique is used strongly affects its performance.	business process;computer performance;feasible region;internet backbone	Josef Kittler;Moni Naor	2015		10.1007/978-3-319-23063-4		SE	-70.11223493922974	21.052818854181155	194738
152972c2704833838c105dc9190cbbd1a4eaba3f	"""requirements engineering for cyber-physical systems - challenges in the context of """"industrie 4.0"""""""			cyber-physical system;industry 4.0;requirements engineering	Stefan Wiesner;Christian Gorldt;Mathias Soeken;Klaus-Dieter Thoben;Rolf Drechsler	2014		10.1007/978-3-662-44739-0_35	requirements analysis;electrical engineering technology;mechatronics;performance engineering;system of systems engineering;systems engineering;requirement;requirements engineering;functional requirement;non-functional requirement;requirements traceability;systems design	EDA	-62.909502842300505	24.457117168080075	194768
8024f82a8a4c605dc39b633033b127c632ff41f6	a systematic review of requirements change management		ContextSoftware requirements are often not set in concrete at the start of a software development project; and requirements changes become necessary and sometimes inevitable due to changes in customer requirements and changes in business rules and operating environments; hence, requirements development, which includes requirements changes, is a part of a software process. Previous work has shown that failing to manage software requirements changes well is a main contributor to project failure. Given the importance of the subject, thereu0027s a plethora of research work that discuss the management of requirements change in various directions, ways and means. An examination of these works suggests that thereu0027s a room for improvement. ObjectiveIn this paper, we present a systematic review of research in Requirements Change Management (RCM) as reported in the literature. MethodWe use a systematic review method to answer four key research questions related to requirements change management. The questions are: (1) What are the causes of requirements changes? (2) What processes are used for requirements change management? (3) What techniques are used for requirements change management? and (4) How do organizations make decisions regarding requirements changes? These questions are aimed at studying the various directions in the field of requirements change management and at providing suggestions for future research work. ResultsThe four questions were answered; and the strengths and weaknesses of existing techniques for RCM were identified. ConclusionsThis paper has provided information about the current state-of-the-art techniques and practices for RCM and the research gaps in existing work. Benefits, risks and difficulties associated with RCM are also made available to software practitioners who will be in a position of making better decisions on activities related to RCM. Better decisions will lead to better planning which will increase the chance of project success.	change management (engineering);requirement;systematic review	Shalinka Jayatilleke;Richard Lai	2018	Information & Software Technology	10.1016/j.infsof.2017.09.004	systems engineering;requirements management;market requirements document;requirements elicitation;requirement prioritization;software requirements specification;business requirements;vision document;management science;requirements analysis;engineering	SE	-69.56033903532055	22.19837020093392	195085
591f0fce133f4a0b2f01170d7cd4cd70f09bf989	automated game testing with icarus: intelligent completion of adventure riddles via unsupervised solving		With ICARUS, we introduce a framework for autonomous video game playing, testing, and bug reporting. We report on the design rationale, the practical implementation, and its use in game development industry projects. The underlying solving mechanic is based on discrete reinforcement learning in a dualistic fashion, encompassing volatile short-term memory as well as persistent long-term memory that spans across distinct game iterations. In combination with heuristics that reduce the search space and the possibility to employ pre-defined situation-dependent action choices, the system manages to traverse complete playthrough iterations in roughly the same amount of time that a professional game tester requires for a speedrun. The ICARUS project was developed at Daedalic Entertainment. The software can be used to generically run all adventure games built with the popular Visionaire Engine and is currently used for evaluating daily builds, for large-scale hardware compatibility and performance tests, as well as for semi-supervised quality assurance playthroughs. The supplementary video depicts real-time solving with active control and observation via a web control panel.	autonomous robot;design rationale;game testing;heuristic (computer science);iteration;persistent data structure;plugboard;real-time computing;real-time transcription;reinforcement learning;semiconductor industry;software bug;software quality assurance;solver;speedrun;traverse;video game development	Johannes Pfau;Jan Smeddinck;Rainer Malaka	2017		10.1145/3130859.3131439	game testing;multimedia;simulation;computer science;human–computer interaction;design rationale;video game development;game design;reinforcement learning;heuristics;adventure;game design document	AI	-65.2142748158869	22.221295876611563	195315
4d9a45cbb868a5221dbc962c1dd4312f3602dc1b	a study on agility and testing processes in software organizations	agile methods;empirical study;agile development;grounded theory;test process	In this paper, we studied the differences in testing activities between software organizations which apply agile development methods and organizations which take the traditional plan-driven approach. Our focus was on the concepts which allow the software organization to successfully apply agile development methods or plan-driven methods. We also observed the test process enhancements and hindrances, which originate in the selected development method. We interviewed 12 organizations, which were selected to represent different polar types of software production. The interviews were tape-recorded and transcribed for further analysis. The study yielded hypotheses which were derived by applying the qualitative grounded theory method. The results indicated that in practice, agile methods can improve the position of testing through the early involvement of testing activities in development, and also have a positive influence on end-product satisfaction. By applying these results, organizations can improve their processes and avoid pitfalls when transitioning to agile methods.	agile software development	Vesa Kettunen;Jussi Kasurinen;Ossi Taipale;Kari Smolander	2010		10.1145/1831708.1831737	agile unified process;agile usability engineering;systems engineering;engineering;agile software development;management science;empirical process;lean software development	SE	-69.66559583923105	21.587689852412254	195444
b167f72118994b516010d1bce24189c540da822e	a preliminary survey on subjective measurements and personal insights into factors of perceived future project success	software;collaborative work;software development management internet;collaboration;internet of things;large scale;research and development;internet;current measurement;collaboration correlation software business current measurement mathematical model context;path analysis;business;mathematical model;correlation;context;software development management;internet of things subjective measurements personal insights perceived future project success path analysis	Within the framework of a project, a variety of known and unknown problems and difficulties in collaboration may occur, which affect how the success of a project is perceived. The goal of our research is to identify factors that influence the perceived success of a project in order to be able to take early countermeasures if project success is threatened. In this paper, we present preliminary results of a study for perceived project success. The study measures perceived project success quantitatively and qualitatively; in addition, our goal was to analyze correlations between perceived project success and aspects of collaboration, communication and individual experiences by using path analysis. The study was conducted in the context of a large-scale research and development project, where multiple partners from research and industry with a heterogeneous background work together to develop new methods and technologies in the field of “internet of things”. After the first half of the project, we conducted an explorative survey with 45 persons to evaluate how the current status and project success are perceived by the partners after 1.5 years of collaborative work. As key result, we identified factors that significantly influence the perceived future project success. Keywordssubjective measurement; project success; quantitative data; qualitative data; path analysis	countermeasure (computer);internet of things;level of measurement;path analysis (statistics);requirement;user requirements document	Sabine Nunnenmacher;Jessica Jung;Golriz Chehrazi;Alexander Klaus;Constanza Lampasona;Christian Webel;Marcus Ciolkowski	2011	2011 International Symposium on Empirical Software Engineering and Measurement	10.1109/ESEM.2011.57	path analysis;the internet;computer science;systems engineering;engineering;knowledge management;mathematical model;management science;project management triangle;internet of things;correlation;statistics;collaboration	SE	-72.86165859370128	20.70632450343469	195564
e7cf62ad0696507d3534429e37b20966062b01a6	software process improvement barriers: a cross-cultural comparison	empirical study;computacion informatica;software process improvement;cmmi;software process improvement barriers;cross cultural comparison;grupo de excelencia;ciencias basicas y experimentales;cross cultural;software development;process improvement	Context: Software Process Improvement initiatives have been around for many years with the growing globalisation of software development is making them increasingly important. Objective: The objective of this exploratory research is to gain an in-depth understanding of barriers that can undermine SPI, in the context of Global Software Development, from the perspective of software development practitioners; this will enable SPI managers to better manage SPI initiatives. We intend to discover if the barriers to SPI initiatives in a developed country are different to those in a developing country. Method: In an empirical study, Vietnamese software practitioners’ experiences of SPI barriers are compared with barriers identified by Australian practitioners. Face-to-face questionnaire-based survey sessions with 23 Vietnamese SPI practitioners were conducted. Our survey included barriers to SPI improvement initiatives identified in previous research. We asked the participants to rank each SPI barrier on a three-point scale (high, medium, low) to determine the importance of each barrier. We then compare our results, with results (identified in previous work), from 34 Australian software development practitioners. Results: We identify (1) lack of project management, (2) lack of resources, (3) lack of sponsorship, (4) inexperienced staff/lack of knowledge, and (5) lack of SPI awareness as ‘high’ value SPI barriers in Vietnam. The results also reveal similarities and differences between the experiences of Australian and Vietnamese practitioners regarding the importance of the SPI barriers identified. While the Australian practitioners were also concerned with (1) lack of SPI awareness, they were even more concerned with (2) organisational politics, and (3) lack of support. Conclusions: Practitioners identify SPI barriers based on previous SPI implementation experience. Their role(s) in their different organisations have helped them to understand the importance of that barrier. Vietnamese software practitioners cited more SPI barriers than their counterparts in Australia. The Vietnamese SPI barriers relate to project management, resources, and sponsorship while the Australian barriers are concerned with organisational politics and lack of support. 2010 Elsevier B.V. All rights reserved.	experience;software development;the australian	Mahmood Niazi;Muhammad Ali Babar;June M. Verner	2010	Information & Software Technology	10.1016/j.infsof.2010.06.005	systems engineering;engineering;knowledge management;capability maturity model integration;software development;software engineering;empirical research;management;cross-cultural studies;cross-cultural	SE	-71.78494372651883	21.247958888445172	195597
03c6abcce3077c0d26abf3deed74bc1b30be2d93	the reliability of iso/iec pdtr 15504 assessments	internal standard	During phase two of the SPICE trials, the Proposed Draft Technical Report version of ISO/IEC 15504 is being empirically evaluated. This document set is intended to become an international standard for Software Process Assessment. One thread of evaluations being conducted during these trials is the extent of reliability of assessments based on ISO/IEC PDTR 15504. In this paper we present the first evaluation of the reliability of assessments based on the PDTR version of the emerging international standard. In particular, we evaluate the interrater agreement of assessments. Our results indicate that interrater agreement is considerably high, both for individual ratings at the capability attribute level, and for the aggregated capability levels. In general, these results are consistent with those obtained using the previous version of the Software Process Assessment document set (known as SPICE version 1.0), where capability ratings were also found to have generally high interrater agreement. Furthermore, it was found that the current 4-point scale cannot be improved substantially by reducing it to a 3-point or to a 2-point scale.	iso/iec 15504;inter-rater reliability;spice	Jean-Martin Simon;Khaled El Emam;Sonia Rousseau;Eric Jacquet;Frederic Babey	1997	Software Process: Improvement and Practice	10.1002/(SICI)1099-1670(199709)3:3%3C177::AID-SPIP80%3E3.0.CO;2-P	reliability engineering;engineering;data mining;internal standard;engineering drawing	SE	-71.66952274354344	22.273870438287897	195877
d7649a1770ae969dd7e4c345bc100fbb420f5196	performance evaluation for process refinement stage of swa system	measurement;risk management;mathematical model;data fusion perspective performance evaluation process refinement stage swa system situational awareness risk assessment model dynamic environment missing information situational assessment capability performance metrics quality based evaluation;context modeling;data integration;sensor fusion performance evaluation risk analysis;data models;measurement data integration mathematical model risk management data models real time systems context modeling;real time systems	"""In periodic manner the analysts teams are in the process of designing, updating and verifying the situational awareness SWA system. Initially, at the designing stage the risk assessment model has little information about the dynamic environment. Hence, any missing information can directly impact the situational assessment capabilities. With this in mind, researchers relied on various performance metrics in order to verify how well they were doing in assessing different situations. In fact, before measuring the ranking capabilities of the SWA system, the underlying performance metrics should be examined against its intended purpose. In this paper, we have conducted quality based evaluations for the performance metrics, namely """"The Ranking Capability Score"""". The results obtained showed that the proposed performance metrics have scaled well over a number of scenarios. Indeed, from the data fusion perspectives the underlying metrics have adequately satisfied different SWA system needs and configurations."""	performance evaluation;refinement (computing);risk assessment;soap with attachments;situational application;software performance testing;verification and validation	Orabi Shurrab;Irfan-Ullah Awan	2015	2015 3rd International Conference on Future Internet of Things and Cloud	10.1109/FiCloud.2015.99	data modeling;risk management;computer science;data integration;mathematical model;data mining;context model;measurement;statistics	HPC	-76.80420734092885	19.60743969823624	195924
aee2ab8de7a72a47844e3536e7d37dc3811e7b0c	assessing the management of innovation with software tools: an application of innovationenterprizer	managerial decision making;software tool;measurement;germany;innovation management;automotive parts suppliers;software tools;npd;new product development;automobile industry;toolkit	This paper presents an NPD managerial decision-making software system: innovationEnterprizer. Furthermore, the paper reports on the application of the system at a major European parts supplier to the German automotive industry which was carried out during September 2004. Ten facilitated sessions were conducted with managers. The main results indicated that the project team (human and integration factors) were extremely weak when compared with the formal side of innovation, for which the company had formal processes and scored very strongly. Furthermore, the consistency between units was very high, indicating that general innovation policy, which was formulated at corporate board level, was not adapted to the unit-specific level. This was despite the board’s recognition that each unit has a need for its own uniquely combined set of success factors.	new product development;software system	Steffen Conn;Marko Torkkeli;Iain Bitran	2009	IJTM	10.1504/IJTM.2009.022656	economics;innovation management;marketing;operations management;management;new product development;measurement	SE	-70.51796386247922	18.607742108090285	195984
f7107e0fbac9f606d1dc538edf0f4ab5200ddea6	project management in is: fit matters	selected works;project manager;bepress	Information systems (IS) projects are ubiquitous in today’s business environment. IS projects vary in size, scope, difficulty and risk-level and combined, these attributes represent a project’s complexity. Previous research has found that most IS projects do not meet budget, schedule and/or quality expectations. In the past, organizations have utilized a variety of project management practices in attempts to better control IS projects. This research-in-progress explores project complexity and project management practices and their fit related to IS project performance. A web-based survey of professional IS project managers is underway and it is anticipated that the respondent data will provide insights into current successful and unsuccessful IS project management practices. It is expected that a framework will be established to identify successful project management techniques for projects of varying complexity.	americas conference on information systems;complex systems;complexity;curve fitting;information systems;taxonomy (general);web application	Nancy L. Martin;Kimberly A. Furumo;John Michael Pearson	2004			level of effort;basis of estimate;project management;extreme project management;program management;project stakeholder;work breakdown structure;earned value management;software project management;opm3;systems engineering;engineering;knowledge management;project sponsorship;project risk management;management science;project management 2.0;project management triangle;project charter;schedule;project planning;project portfolio management	SE	-72.54009298394968	19.422479330176746	196316
5ac078d55a60562fed8eb7b3a6543e1535a119cb	adapting scrum for third party services and network organizations	software;reliability;project management;planning programming reliability testing software companies;software prototyping;software prototyping business communication organisational aspects project management;scrum software development third party services network organizations scientific publications press releases;testing;business communication;companies;planning;programming;organisational aspects	Large number of scientific publications and press releases demonstrate that organizations are adopting the Scrum software development method with success in almost all areas. Nevertheless, traditional Scrum method is not sufficient for managing work in Network Organizations where Third Party Service providers may know nothing about the Scrum. This paper describes the findings of a field study that explores the Scrum in Network Organizations. We extended Scrum core roles and proposed changes in Scrum artifacts that help in adapting the Scrum method to work in Network Organization where changes and high competition are the cornerstone of the entire process.	field research;holon (philosophy);network governance;scientific literature;scrum (software development);service layer;software development	Lukasz D. Sienkiewicz;Leszek A. Maciaszek	2011	2011 Federated Conference on Computer Science and Information Systems (FedCSIS)		planning;project management;programming;knowledge management;scrum;reliability;software testing;business communication;empirical process;management	Vision	-67.43338005682594	21.656034892678555	196334
88d6d0a4b64c00f93fc1a73061d268921f5ccc56	a framework for empirical evaluation of belief change operators	multiple scenario;empirical testing;different operator;belief change operator;theoretical point;kernel contraction operator;thirty year;belief revision;case study;empirical evaluation;available api	Belief revision has been extensively studied in the last thirty years. While there are many results in the literature comparing different operators from a theoretical point of view, there is no study of how the different operators perform in practice. In this paper, we propose a framework for empirical testing of belief change operators. The idea is that any operator can be quickly implemented making use of the available API and then tested for multiple scenarios. We illustrate the use of the framework with a case study comparing partial meet and kernel contraction operators.		Renato U. Lundberg;Márcio Moretto Ribeiro;Renata Wassermann	2012		10.1007/978-3-642-34459-6_2	knowledge management;data mining;management science	AI	-74.07871758145907	25.936056861771924	196507
c12a9fdc3d06b5fa8590179b021ea18d9d8bc983	evospaces: multi-dimensional navigation spaces for software evolution	navigation;shape;visualization;software systems;data visualisation;reverse engineering;software visualization;software maintenance;informatics;software evolution;data visualization	EvoSpaces is a Swiss-wide research project sponsored by the Hasler foundation. It involves three partners: University of Zurich, University of Lugano and the University of Applied Sciences in Geneva. The overall goal of the project is to explore novel ways to visualize and navigate evolving software systems in a 3D environment. In this paper we briefly describe the particularities of the project and the results obtained so far.	software evolution;software system;spaces;switzerland	Michele Lanza;Harald C. Gall;Philippe Dugerdil	2009	2009 13th European Conference on Software Maintenance and Reengineering	10.1109/CSMR.2009.14	software visualization;navigation;visualization;human–computer interaction;shape;computer science;systems engineering;engineering;software evolution;software engineering;software maintenance;informatics;data visualization;reverse engineering;software system	SE	-63.86718454686891	23.31871565376874	196526
6e45c73a67fb3b822ff56a0f93eb0925bf605291	prototype dependability model in software: an application using bocr models	anp;ahp;defects;bocr;prototype	Abstract Actual software project feasibility assessment is one of the foremost challenging and vital activities in estimating economics of software before its actual development. Therefore, prototyping in recent years, gradually become an approach to decide various options and possible outcomes before its real implementation and success of the projects. Most of the prototype studies in software engineering acts as a good pointer to envision and reflect upon the final product prediction. However, there has been dearth so far for a detailed economic analysis accountable for benefits, opportunities, risks and costs (BOCR) merits arising from various influencing factors (criteria and sub-criteria…). Further to determine the final possible outcomes (alternatives) through the trade-offs between the BOCR models. The present work attempts to close this gap. The modeling is performed in association with two types of models: analytic network process (ANP) and analytic hierarchy process (AHP) with complex relations between influencing factors. The former is illustrated as BOCR-ANP in the form of a control network and analysed through questionnaire based on expert judgement and historic data. The latter BOCR-AHP as a strategic hierarchy via real time data collected from the defect consolidation log data sets through linguistic variables proposed by same authors in our previous work. Thus we propose to investigate prototype dependability model through the inputs arising from expert judgement and real time data. More importantly our proposed model is realized without constructing actual working model. It is an analytical model based on inputs from past experience. The model can be a replacement for a working model for smaller/medium projects or additional inputs to strengthen working model for larger complex software systems. Thus our paper proposes a holistic model to assess the prototype dependability in software at prototype level in early in the software life cycle process. We carried over a case study to examine the proposed approach and to evaluate the economic feasibility of projects in I.T. industry.	dependability;prototype	Kovur Krishna Mohan;Ajit Srividya;Ajit Kumar Verma	2016	Int. J. Systems Assurance Engineering and Management	10.1007/s13198-016-0427-1	reliability engineering;analytic hierarchy process;computer science;systems engineering;engineering;operations management;software engineering;machine learning;prototype;management	SE	-70.55459007825984	21.494440381913122	196555
1943a0e210b4f57d1bc5c7dc5a60b764c753499f	leadership in kanban software development projects: a quasi-controlled experiment	empirical analysis;software process improvement;controlled experiment;software development;self organization	Useless actions and work in software development projects do not increase the value for the customer. While getting rid of such waste may sound simple, even recognizing the waste is considered a challenging issue. Once recognized with its causes, projects are more aware of the signs of waste: the pitfalls are avoidable by knowing their reasons. On the other hand, self-organization and empowering the teams emerge in a modern Kanban-driven software development project. This makes it relevant to ask whether sacrificing project resources for leadership adds any value. Hence, this paper conducts a quasi-controlled experiment with two leadership settings in order to find out differences between waste, its causes and effects. The results from the empirical analysis show that waste is present in each project but the amount and significance of waste can be reduced with the right leadership even in self-organized teams of	agile software development;kanban (development);self-organization;software development	Marko Ikonen	2010		10.1007/978-3-642-16416-3_13	team software process;software project management;systems engineering;engineering;operations management;management science	SE	-69.85496527845196	24.59379746000437	196630
5e45980bff9ff8d341263eee053091e648b6026a	what are the dominant projects in the github python ecosystem?	popularity;inter dependencies;github python ecosystem;centrality and influence	GitHub, a popular social-software-development platform, has fostered a variety of software ecosystems where projects depend on one another and co-evolve together. The projects located in the central hub of the ecosystem are supposed to be important and could affect a number of other projects. However, few researches have investigated the dominant projects in a software ecosystem. In this study, we aim to identify the most influential projects in the GitHub Python ecosystem. We first construct the GitHub Python ecosystem with 19797 projects by identifying their inter-dependencies. Then, we calculate the four kinds of centrality metrics to measure the centrality and influence of each project in the ecosystem. Finally, we evaluate the project's popularity using GitHub social methods and compare the consistency of the two measurements. Our results indicate that 1) the most influential projects are mostly custom libraries; 2) only a small number of projects have large values of the centrality metrics; 3) the dominant projects are not always popular among the GitHub users. Our results help the researchers and practitioners gain a better understanding of the GitHub Python ecosystem.	centrality;library (computing);parsing;python;software ecosystem;usb hub	Wanwangying Ma;Lin Chen;Yuming Zhou;Baowen Xu	2016	2016 Third International Conference on Trustworthy Systems and their Applications (TSA)	10.1109/TSA.2016.23	simulation;computer science;data mining;world wide web	SE	-75.5691101147867	21.59719279609436	196687
50fcb25f8fb82d3d41cb2423596ede2965fa424c	an experiment to evaluate software development teams by using object-oriented metrics		Managing a software project is a task that becomes increasingly difficult as software complexity increases. Gathering and interpreting software metrics is a mean to help the project team to achieve its goals. The objective of this work is to use software metrics to evaluate teams and individuals by analyzing current performance of developers. An experiment was realized in four organizations, two universities and two companies. Information about participants was collected and the object-oriented metrics of software produced by them were calculated. As a result, evidence was found that gathering software metrics is useful in activities of project management and to evaluate software development team members. In this way, software metrics can contribute during activities of software development, and also can advise managers with decisions that cause changes in the team.	software development	Jamille S. Madureira;Anderson S. Barroso;Rogerio P. C. do Nascimento;Michel S. Soares	2017		10.1007/978-3-319-62407-5_9	software development;computer science;systems engineering;computer network;programming complexity;software;project management;software metric;team software process;object-oriented programming;project team	SE	-65.75933942258767	30.02815360289688	196716
210d6e9fd09ce2148bf790b8bc875e4dbc906303	towards quality-driven software migration		Long-running software systems suffer from software erosion, due to their constant evolution to meet new or changing requirements, severely limiting their maintainability. Migrating software systems, i.e. transferring legacy systems into modern environments and technologies without changing functionality [FWE12], is a key technique of software evolution, and serves to keep existing software systems operational. Structured migrations allow for transferring established software solutions to cutting edge technology, without having to consider the significantly higher risks of developing a new system from scratch.	legacy system;requirement;software evolution;software modernization;software rot;software system	Jan Jelschen;Gaurav Pandey;Andreas Winter	2014			software system;software;computer engineering;maintainability;software evolution;legacy system;scratch;software rot;software modernization;computer science	SE	-64.20467145916814	29.214614060347518	197089
9afe34c31a534bdc4bfc68bff0736e2469628be9	the quality control of software reliability based on functionality, reliability and usability	reliability;iso iec 25000;international standards;quality evaluation;iso iec 9126 2;functionality;usability	Software quality control is very important. We have concern about software reliability deeply. Many research workers study about software reliability. We want to evaluate software quality as quantity. Especially, we worry about software failure data. We have to find the method software reliability by using software failure data. We propose that software test cases for evaluating of software functionality and usability. We propose that the evaluating of software reliability. We introduce the international standards of software quality control. Also, in this paper, we propose the quality testing metric for those criteria. Our evaluation method of software quality is based on the international standards ISO/IEC 9126-2 and ISO/IEC 25000 series.	software quality;software reliability testing;usability	Hye-Jung Jung;Suck-Joo Hong	2012		10.1007/978-3-642-35585-1_15	iso/iec 9126;reliability engineering;medical software;verification and validation;software sizing;iso/iec 12207;systems engineering;engineering;software reliability testing;software engineering;software construction;iec 62304;software testing;software measurement;software deployment;software quality control;software quality;software metric;software quality analyst;software peer review	SE	-63.057324688123046	27.969395609749398	197142
543f534e5f97094da3f43d5b59fa5900ddc3bd9b	software testing and iec 61508 - project case study and further thoughts	software testing;lines of code		software testing	Wayne Flint;Ian Gilchr ist	2009		10.1007/978-1-84882-349-5_14	test strategy;reliability engineering;verification and validation;iso/iec 12207;system integration testing;computer science;systems engineering;acceptance testing;software engineering;software construction;software testing	SE	-63.57544741379772	26.65816186395337	197442
88f519c64382e4ee01c37d34fc581bede7e3e268	exemplar: an experimental information repository for sbse research		The number and variety of experiments carried out in software engineering research is growing, leading to an increasing need of replication and review. In order to support such needs the information about experiments should be provided as lab-packs. However, this information is often scattered, poorly structured, and even unavailable, implying a tedious process of search and gathering. EXEMPLAR is an online platform for managing experimental information, which allows the uploading and publication of experimental lab packs, and an efficient search. The platform also supports the use of formal languages for providing experimental descriptions (e.g. SEDL and MOEDL). In so doing, EXEMPLAR enables the automated analysis of lab-packs, in order to detect common validity threats and missing information which could hinder replicability.	experiment;formal language;information repository;search-based software engineering;upload	José Antonio Parejo;Sergio Segura;Pablo Fernandez;Antonio Ruiz Cortés	2014			computer science;information retrieval;data mining;information repository	SE	-68.27754921998469	31.162257947456848	197531
0cd02c1449eaec275592bd709d8d24072617204f	architecting with just enough information	incremental development;architectural knowledge;lean software development;knowledge management;software development process;software development;agility;architecture centric engineering	We learned an important lesson recently about breaking down barriers among architects, developers, and other stakeholders when we were engaged on a project and were challenged to deliver the architecture in smaller increments and shorter iterations. We learned how information was used and exchanged among key players participating in the software development process and are seeking to formalize our understanding through principles of workflow from lean software development and how architecture knowledge management can influence defining an appropriate architecture batch size for effective incremental development.	iteration;iterative and incremental development;knowledge management;lean software development;software development process	Robert L. Nord;Nanette Brown;Ipek Ozkaya	2011		10.1145/1988676.1988680	reference architecture;software architecture;personal software process;software project management;systems engineering;engineering;knowledge management;package development process;social software engineering;software development;software design description;software engineering;iterative and incremental development;software architecture description;systems development life cycle;resource-oriented architecture;lean software development;goal-driven software development process;software development process;software peer review	SE	-66.23051332184693	22.196131747554922	197657
2f4770421f3650bfb068635d8d2cca5964d8309d	offshoring test automation: observations and lessons learned	business centric projects;software;software centric projects;software testing;outsourcing;project management;offshore outsourcing;test automation;maintenance work test automation offshoring offshore outsourcing software centric projects software project development onsite local staff remote offshore staff business centric projects business consulting requirements elicitation software testing team organization charter definition offshore personnel skills nokia oyj subcontractors;test automation offshoring;contracts;testing;charter definition;software project development;requirements elicitation;companies;offshoring;software development management outsourcing program testing project management;team organization;nokia oyj;offshore personnel skills;program testing;lessons learned;risk;remote offshore staff;risk offshoring test automation;subcontractors;onsite local staff;business consulting;maintenance work;software development management;automatic testing automation outsourcing software testing subcontracting companies programming business communication system testing software engineering;automation	Offshoring (offshore outsourcing) is increasingly used in software-centric projects, specifically in the development phases of software projects. Using a mixture of onsite local staff and remote offshore staff in business-centric projects, such as business consulting, requirements elicitation and software testing, put many challenges to team organizing, charter definition and offshore personnel skills. This study considers challenges of test automation in a company which has been doing offshoring before. The challenges were studied with three test automation offshoring cases that were carried out by Nokia Oyj. Although the subcontractors fulfilled the expectations set by the customer in all cases, subcontractors’ unfamiliarity with test tools to be used and with software to be tested caused extra meetings and training sessions. Lack of resources in the customer’s side also caused additional maintenance work onshore.	information system;organizing (structure);outsourcing;requirement;requirements elicitation;software testing;supervised learning;test automation;while	Ilkka Tervonen;Timo Mustonen	2009	2009 Fourth IEEE International Conference on Global Software Engineering	10.1109/ICGSE.2009.30	project management;economics;systems engineering;knowledge management;operations management;software engineering;software testing;management	SE	-67.58573409247373	21.337810308330113	198028
fdb8a8f8a941a580e13bcf3e8d1a6020be364a3b	guest editorial: an industrial viewpoint		A curious facet of software development is the poor uptake of many of the principles of software testing in industrial environments. In some industries, notably the avionics and nuclear sectors, software producers have no choice but to demonstrate thorough testing of their software. Interestingly, parts of the telecommunications industry, although answerable to no certification body, have also always had a tradition of rigorously testing their software, probably as a result of pioneering research at Bell Labs in New Jersey back in the 1960s. From an industry viewpoint, there is often a fear that bad news, brought to light by a rigorous testing process, will extend the time-to-market and result in a loss of market share. However, part of the problem of poor uptake must be borne by academic researchers because industry still lacks answers to key motivating factors such as:	avionics;software development;software testing	Michael A. Hennell	2004	Softw. Test., Verif. Reliab.	10.1002/stvr.311	software engineering;theoretical computer science;computer science	SE	-70.90687282566981	26.137421360591553	198342
da6cdbb6e6602555964680f8f94f74ec2686c1f1	pair programming for software engineering education: an empirical study			pair programming;software engineering	Kavitha Karthiekheyan;Irfan Ahmed;Jalaja Jayalakshmi	2018	Int. Arab J. Inf. Technol.		empirical research;pair programming;machine learning;artificial intelligence;computer science	SE	-65.27748887652822	25.31509558873617	198361
70f27019530da711a3e75259e6c5ef4529544bde	the definiton of a testing process to small-sized companies: the brazilian scenario	quality assurance;software;software testing;software process improvement;software planning companies software testing adaptation model programming;small sized software organizations high quality software development market quality assurance software testing process;companies;software testing process;adaptation model;development market;small sized software organizations;program testing;testing process;high quality software;planning;programming;software quality;software quality program testing quality assurance software process improvement;software quality testing process software process improvement	Producing high-quality software has been one of the greatest challenges of the development market in the last few years. The software testing is the essence of the quality assurance, but the implementation of this activity is still difficult due to many factors. This paper presents some factors that influence on the adoption of a testing process. Some of these factors were outlined in the literature, and others were selected empirically based on the work experience obtained in a large company. Besides, this paper presents the results of a survey carried out to identify factors that make difficult the implementation of software testing process in small-sized software organizations and a proposed approach of a testing process to them.	relevance;software testing	Andreia Rodrigues;Plácido Rogério Pinheiro;Adriano Bessa Albuquerque	2010	2010 Seventh International Conference on the Quality of Information and Communications Technology	10.1109/QUATIC.2010.56	test strategy;planning;reliability engineering;quality assurance;programming;team software process;software engineering process group;systems engineering;engineering;software engineering;operational acceptance testing;software testing;management;software quality;software quality analyst	SE	-65.65509534980907	27.984967821197973	198650
6301456d36a734ecbb25c35769118bc04b006e4c	coven: brewing better collaboration through software configuration management	programming environment;software configuration management;collaborative programming;collaborative software development	Our work focuses on building tools to support collaborative software development. We are building a new programming environment with integrated software configuration management which provides a variety of features to help programming teams coordinate their work. In this paper, we detail a hierachy-based software configuration management system called Coven, which acts as a collaborative medium for allowing teams of programmers to cooperate. By providing a family of inter-related mechanisms, our system provides powerful support for cooperation and coordination in a manner which matches the structure of development teams.	bitkeeper;collaborative software;computer science;concurrent versions system;dart (programming language);decibel;experience;federated identity;hypertext transfer protocol;icse;integrated development environment;integrated software;jensen's inequality;john d. wiley;kaplan–meier estimator;kramer graph;local interconnect network;lock (computer science);peer-to-peer;policy-based design;programmer;rational clearcase;rational synergy;revision control system;semiconductor research corporation;separation of concerns;six degrees of separation;software engineering institute;software configuration management;software development process;springer (tank);sun workshop teamware;tip (unix utility);user interface;version control;vesta (software configuration management);visualworks;web page;webdav	Mark Chu-Carroll;Sara Sprenkle	2000		10.1145/355045.355058	personal software process;simulation;software configuration management;software project management;computer science;systems engineering;engineering;knowledge management;package development process;software framework;component-based software engineering;software development;software engineering;software construction;software as a service;resource-oriented architecture;software deployment;software development process;collaborative software;software system	SE	-63.55423163812076	23.21860100618652	198718
a63db3d65b25a66b4a75d780c85d9a1ad62cc644	empirical investigation of the challenges of the existing tools used in global software development projects	weak negative correlation;software quality project management;systematic literature review approach;weak negative correlation empirical investigation tool challenge global software development projects gsd projects systematic literature review approach slr approach survey based empirical study approach questionnaire based empirical study five point scale synchronous communication tools asynchronous communication tools;global software development projects;questionnaire based empirical study;gsd projects;asynchronous communication tools;five point scale;slr approach;empirical investigation;tool challenge;survey based empirical study approach;synchronous communication tools	Global software development (GSD) is continuously increasing because of many factors such as high quality software production in offshore destinations with significant cost-savings. Objective – The objective of this study is to identify the challenges of the existing tools used in GSD projects. Method – The authors applied the systematic literature review (SLR) approach and a survey-based empirical study approach to address the research objective. Results – From both data sets, the authors identified eight challenges of the existing tools used in GSD projects. The top-ranked challenges in the SLR are the ‘inappropriate use of synchronous and asynchronous communication tools’ and ‘difficulties in adopting and learning to use the existing tools’. The top-ranked challenges in the questionnaire-based empirical study are the ‘lack of awareness of existing tools used in GSD projects’ and the ‘lack of support for collaboration and group decision making'. The results show a weak negative correlation between the ranks obtained from the SLR and the questionnaire-based empirical study ((rs(8) = −0.313), p = 0.450) Conclusion: GSD organisations should address the challenges of the existing tools used in GSD projects, especially the most common ones.	software development	Mahmood Niazi;Sajjad Mahmood;Mohammad Alshayeb;Ayman Hroub	2015	IET Software	10.1049/iet-sen.2014.0130	reliability engineering;systems engineering;engineering;management science	SE	-71.65347807371211	21.172967803812803	198777
6daa377303fd5ec40e72898d3822abd42052db3f	dimensions of software engineering course design	architectural design;course design;course design framework;outcome case studies;software engineering;software engineering education;course design evaluation	A vast variety of topics relate to the field of Software Engineering. Some universities implement curricula covering all aspects of Software Engineering. A number of other courses cover detailed aspects, e.g. programming, usability and security issues, analysis, architecture, design, and quality. Other universities offer general curricula considering Software Engineering in few or single course only. In each case, a course set has to be defined which directly relates to a specific student outcome. This work provides a method for categorizing and analyzing a course set within abstract dimensions for course design. We subsequently show the results of applying the dimensions to the course degree scheme in use. The course design dimensions can also be related to the student outcomes defined in SE2004 CC Section 3.2 [10].	categorization;software engineering 2004;usability	Mario Bernhart;Thomas Grechenig;Jennifer Hetzl;Wolfgang Zuser	2006		10.1145/1134285.1134387	software engineering process group;architectural pattern;computer science;systems engineering;engineering;software design;social software engineering;component-based software engineering;software development;software design description;software engineering;software construction;resource-oriented architecture;software requirements;computer engineering	SE	-65.88305037230799	25.589286635291742	198800
4627fc69ace571b955c1d74fbb5597c59d72b688	impact of requirements discovery pattern on software project outcome: preliminary results	software management;software project;project outcome;change impact software project;project development;requirements discovery;different way;discovery pattern;preliminary results;software development;software process;project management;requirements discovery pattern;workforce deployment patterns;workforce augmentation plan;software engineering;software project outcome;different pattern;risk mitigation	Requirements discovery during project development is known to be the most critical risk in any software project, and managing this is paramount to success in software development. Requirements can change in various ways during the course of a project, and the effect of change on the outcome can differ widely. In this paper we study the effect of different patterns of requirements discovery on a software project. Using a validated model of software process we show that the effect on the total effort, the completion time and the workforce deployment patterns can be counter intuitive as different patterns of change impact software project dynamics in different ways. The insight into the relationship between requirements discovery pattern and project outcome can help managers decide appropriate risk mitigation policy and workforce augmentation plan.	requirement;software deployment;software development process;software project management	Rahul Thakurta;Rahul Roy;Subir Bhattacharya	2009	2009 42nd Hawaii International Conference on System Sciences	10.1109/HICSS.2009.760	project management;personal software process;long-term support;verification and validation;team software process;software engineering process group;risk management;software project management;knowledge management;package development process;social software engineering;software development;software construction;management science;software walkthrough;application lifecycle management;project management triangle;management;software deployment;software development process;software requirements;project planning;software peer review	SE	-69.24048300712035	21.714739086997678	198844
750aa9349b42a524f963ecd3cd79d47b5336ee8b	the impact of person-organization fit and psychological ownership on turnover in open source software projects		Open source software (OSS) projects represent an alternate form of software production by relying primarily on voluntary contributions. Despite the immense success of several mainstream OSS projects such as Mozilla, Linux, and Apache, a vast majority of such projects fail to sustain their development due to high levels of developer turnover. While existing research in the area has offered a rich foundation, we know little about how developers’ perceptions of fit with the project environment may be moderated by the sense of ownership they have toward the project and how it may impact their turnover intentions. Using survey data from 574 GitHub developers, we tested a model to examine the impact of Person-Organization fit and psychological ownership on developers’ turnover intentions. Our results suggest that two relevant dimensions of fit, namely, value and demands-abilities fit, negatively impact turnover intentions and that their sense of ownership moderates these effects.	linux;open sound system;open-source software	Tingting Rachel Chung;Pratyush Nidhi Sharma;Sherae L. Daniel	2015			knowledge management;computer science;survey data collection;turnover;software	SE	-74.80766158751314	20.710491770491743	199239
66077b4bd689cea543dfe49f86acca176ad69aa7	a case study in estimating avionics availability from field reliability data	avionics;field reliability;availability;statistical data analysis;article	Under incentivized contractual mechanisms such as availability-based contracts the support service provider and its customer must share a common understanding of equipment reliability baselines. Emphasis is typically placed on the Information Technology-related solutions for capturing, processing and sharing vast amounts of data. In the case of repairable fielded items scant attention is paid to the pitfalls within the modelling assumptions that are often endorsed uncritically, and seldom made explicit during field reliability data analysis. This paper presents a case study in which good practices in reliability data analysis are identified and applied to real-world data with the aim of supporting the effective execution of a defence avionics availability-based contract. The work provides practical guidance on how to make a reasoned choice between available models and methods based on the intelligent exploration of the data available in practical industrial applications.		Ettore Settanni;Linda B. Newnes;Nils E. Thenent;Daniel Bumblauskas;Glenn C. Parry;Yee Mey Goh	2016	Quality and Reliability Eng. Int.	10.1002/qre.1854	avionics;reliability engineering;availability;computer science;engineering;operations management;computer security	SE	-68.17802392693697	29.468496855023183	199285
23393bdaea4de56302836575327bf995aac8696e	wait for it: determinants of pull request evaluation latency on github		The pull-based development model, enabled by git and popularised by collaborative coding platforms like BitBucket, Gitorius, and GitHub, is widely used in distributed software teams. While this model lowers the barrier to entry for potential contributors (since anyone can submit pull requests to any repository), it also increases the burden on integrators (i.e., members of a project's core team, responsible for evaluating the proposed changes and integrating them into the main development line), who struggle to keep up with the volume of incoming pull requests. In this paper we report on a quantitative study that tries to resolve which factors affect pull request evaluation latency in GitHub. Using regression modeling on data extracted from a sample of GitHub projects using the Travis-CI continuous integration service, we find that latency is a complex issue, requiring many independent variables to explain adequately.	bitbucket;continuous integration;distributed computing;distributed version control;interrupt latency;travis ci	Yue Yu;Huaimin Wang;Vladimir Filkov;Premkumar T. Devanbu;Bogdan Vasilescu	2015	2015 IEEE/ACM 12th Working Conference on Mining Software Repositories		verification and validation;real-time computing;simulation;computer science;systems engineering;engineering;qualitative research;operating system;software engineering;machine learning;software construction;data mining;systems development life cycle;process mining;programming language;computational model;software quality	SE	-67.58754258277307	22.238810636734904	199396
484fdd8a0acaaaae0750eedaa2a9b7cd9664ce94	bizdevops and the role of s-bpm		"""Recently discussed software development approaches are characterized by agility. New increments of software are developed in relatively short cycles. While previously new versions of software were delivered after several months, nowadays this happens sometimes daily. Tool chains that ensure quality attributes are needed for this purpose. They are classified as DevOps tools. The paper discusses an even broader approach that includes business process modelling activities. It can be characterized with the term BizDevOps. It has a lot of similarities with the idea of """"Continuous Software Engineering"""". Additionally, it is discussed how subject-oriented modelling by S-BPM or task models can be used in this context. The domain specific language DSL-CoTaL is demonstrated as candidate for communications with domain experts."""	beam propagation method;business process;devops;digital subscriber line;domain-specific language;list of system quality attributes;markov chain;process modeling;software development;software engineering	Peter Forbrig	2018		10.1145/3178248.3178250	systems engineering;process management;business process modeling;software;devops;software development;domain-specific language;computer science	SE	-66.44298335377484	20.106790746718715	199523
fa7d4a95e40e73b088077cfe3bb90ecd5311c8fe	the establishment and application of effort regression equation	software;software project estimation;software size;regression equation;reliability;confidence level;linear regression;software reliability regression analysis;reliability interval;statistical analysis;equations linear regression costs scheduling application software linearity project management software engineering usability statistical analysis;effort estimation;estimation;schedules;forecast and control software size effort regression relationship validation reliability;mathematical model;statistics analysis method;validation;regression analysis;regression relationship;forecast and control;effort;software reliability;programming;software project estimation regression equation software size statistics analysis method reliability interval	To define the reliability and usability of the linearity regression relationship between software size and effort, statistics analysis method was used to validate the regression result and seek for the reliability interval of coefficient b. The application method of the regression result was discussed under the situation that the regression result is usable. By analysis, it shows the result of the linearity regression relationship is ideal and has a high confidence level. The application of the linearity regression equation also proves that this regression relationship is effective and it could be applied in actual software projects. Therefore the equation could be used exactly during effort estimation of software projects.	coefficient;cost estimation in software engineering;regression testing;software sizing;usability	Junguang Zhang	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.726	econometrics;proper linear model;computer science;regression diagnostic;path coefficient;nonparametric regression;regression analysis;statistics	SE	-65.73559481341893	30.66655461815588	199543
36c7edec08c823aa52475fe9153ac22d7f42b284	software engineering of safety-critical systems: themes from practitioners		This study addresses two important questions related to engineering of safety-critical software and software-intensive systems. The first question is: which software and software-intensive systems should be considered safety critical? The second question is: what processes, design practices, and tools have practitioners been using for building these systems? We answer these questions through an analysis of unstructured interviews with experienced engineers who self-describe as working on safety-critical systems. Then, a thematic analysis of these responses was conducted. The results of this study are intended to provide guidance to those building safety-critical systems and have implications on state engineering licensure boards, in the determination of legal liability, and in risk assessment for policymakers, corporate governors, and insurance executives.	process (computing);risk assessment;software engineering;type safety	Phillip A. Laplante;Joanna F. DeFranco	2017	IEEE Transactions on Reliability	10.1109/TR.2017.2731953	reliability engineering;software system;thematic analysis;software engineering process group;personal software process;information engineering;software walkthrough;systems engineering;social software engineering;government;engineering	SE	-66.5244708070381	24.746264259513854	199659
366070649bbbc72831386b0ad6d26519243286de	toward meaningful industrial-academic partnerships	archie technology transfer requirements engineering software engineering ready set transfer flexisketch collaborative creativity canvas;technology transfer requirements engineering software engineering interviews;software engineering;requirements engineering;technology transfer	OVER THE PAST few years, there has been much discussion in the requirements engineering (RE) research community about researchers’ responsibility to deliver practical, usable solutions to industry. Practitioners complain that researchers often work on theoretical problems that never seem to see the light of day, while the day-to-day problems remain unsolved. Nevertheless, many researchers collaborate closely with industrial partners and care	requirements engineering	Jane Cleland-Huang	2015	IEEE Software	10.1109/MS.2015.20	requirements analysis;business requirements;computer science;systems engineering;engineering;social software engineering;requirement;software engineering;requirements elicitation;requirements engineering;management;software requirements	Visualization	-67.00862708187394	23.928385585782767	199738
cc32ad081d12ef9bb5940e7a273b44228a912b78	the adoption of software measures: a technology acceptance model (tam) perspective	software measurement;technology acceptance model;structural equation modeling	The use of software measures for project management and software process improvement has been encouraged for many years. However, the low level of acceptance and use of software measures in practice has been a constant concern. In this paper we propose and test a model which explains and predicts the use of software measures. The model is based on the technology acceptance model (TAM) and operationalizes the perceived usefulness construct according to the ''desirable properties of software measures.'' Our research provides guidance for software engineers in selecting among different software measures and for software metrics coordinators who are planning measurement programs.	ibm tivoli access manager	Linda G. Wallace;Steven D. Sheetz	2014	Information & Management	10.1016/j.im.2013.12.003	reliability engineering;structural equation modeling;personal software process;verification and validation;software engineering process group;systems engineering;engineering;knowledge management;social software engineering;software reliability testing;software development;software construction;software testing;software walkthrough;software measurement;software deployment;software quality;software metric;software peer review	SE	-65.8202651038073	29.13291985179491	199957
