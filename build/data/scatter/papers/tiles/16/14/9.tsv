id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
89456d3fdec9522521790ee6c2c0e30cee916c87	air tools - a matlab package of algebraic iterative reconstruction methods	computacion informatica;sirt methods;stopping rules;65y15;semi convergence;ciencias basicas y experimentales;art methods;matematicas;65f22;relaxation parameters;tomographic imaging;grupo a	"""(Convergence analysis, stopping criteria, and good advice) Goal: use measured data to compute """" hidden """" information. The forward problem is formulated as a certain transform  formulate a stable way to compute the inverse transform. Example: the inverse Radon transform for tomography. Use the forward model to produce a Krylov subspace  inversion amounts to projecting on this """" signal subspace """" & using prior information. Algebraic Iterative Methods Formulate the forward problem as a discretized problem  inversion amounts to solving A x = b using algebraic properties of A & using prior information. Each measured data b i is the loss of intensity of a ray sent through the domain, i.e., a line integral of the absorption coefficient f(t) along ray i through the domain. Algebraic approach: discretize f(t) into a 2D or 3D array X, and set up the linear system A x = b where A is large, sparse, and ill conditioned, x = vec(X), and b is the measured data. Each ray intersects only a few cells, hence A is very sparse. Many rows are structurally orthogonal. Provides the user with:  the most important algebraic iterative reconstruction methods  presented in a common framework  using identical functions calls  with easy access to o strategies for choosing the relaxation parameter, o strategies for stopping the iterations. The package allows the user to easily test and compare different methods and strategies on test problems. Also: templates or """" model implementations """" for dedicated software"""	accessibility;advice (programming);ccir system a;coefficient;condition number;discretization;iteration;iterative method;iterative reconstruction;krylov subspace;linear algebra;linear programming relaxation;linear system;matlab;signal subspace;sparse matrix;tomography;turing test	Per Christian Hansen;Maria Saxild-Hansen	2012	J. Computational Applied Mathematics	10.1016/j.cam.2011.09.039	mathematical optimization;mathematical analysis;theoretical computer science;calculus;mathematics;tomographic reconstruction;algorithm;statistics	ML	84.07165687372621	20.425157716474	109187
0e70ad72a04a2079ec22fef294389f19cab59faa	the multishift qr algorithm. part i: maintaining well-focused shifts and level 3 performance	linear algebra;15a18;non symmetric matrix;deflation;convergence;factorisation qr;matrice non symetrique;implicit shifts;convergence rate;matrix algebra;qr factorization;eigenvalues;eigenvector;qr algorithm;eigenvalue;algorithme;basic linear algebra subprogram;vector propio;algorithm;factorizacion qr;adverse effect;convergencia;algebre lineaire;valor propio;algebra lineal;level 3 blas;valeur propre;algebre matricielle;65f15;vecteur propre;blas;eigenvectors;algoritmo	This paper presents a small-bulge multishift variation of the multishift QR algorithm that avoids the phenomenon of shift blurring, which retards convergence and limits the number of simultaneous shifts. It replaces the large diagonal bulge in the multishift QR sweep with a chain of many small bulges. The small-bulge multishift QR sweep admits nearly any number of simultaneous shifts—even hundreds—without adverse effects on the convergence rate. With enough simultaneous shifts, the small-bulge multishift QR algorithm takes advantage of the level 3 BLAS, which is a special advantage for computers with advanced architectures.	blas;computer;earth bulge;qr algorithm;qr code;rate of convergence;selective calling;speedup;the matrix	Karen Braman;Ralph Byers;Roy Mathias	2002	SIAM J. Matrix Analysis Applications	10.1137/S0895479801384573	eigenvalues and eigenvectors;linear algebra;calculus;pure mathematics;mathematics;algebra	Theory	83.51227361962553	22.01947573796013	109532
2eb4d3b9f80f7b6f081feb5c27ba94826a581c53	a fast direct solver for a class of elliptic partial differential equations	iterative solver;discrete laplace operator;laplace operator;low frequency;fast solver;matrix algebra;matrix inversion;linear system;fast matrix algebra;robust method;helmholtz equation;elliptic partial differential equation;fast matrix inversion;hierarchically semi separable matrix;sparse linear system;direct method;h matrix	We describe a fast and robust method for solving the large sparse linear systems that arise upon the discretization of elliptic partial differential equations such as Laplace’s equation and the Helmholtz equation at low frequencies. While most existing fast schemes for this task rely on so called “iterative” solvers, the method described here solves the linear system directly (to within an arbitrary predefined accuracy). The method is described for the particular case of an operator defined on a square uniform grid, but can be generalized other geometries. For a grid containing N points, a single solve requires O(N log N) arithmetic operations and O( √ N logN) storage. Storing the information required to perform additional solves rapidly requires O(N logN) storage. The scheme is particularly efficient in situations involving domains that are loaded on the boundary only and where the solution is sought only on the boundary. In this environment, subsequent solves (after the first) can be performed in O( √ N logN) operations. The efficiency of the scheme is illustrated with numerical examples. For instance, a system of size 106 × 106 is directly solved to seven digits accuracy in four minutes on a 2.8 GHz P4 desktop PC.	desktop computer;discretization;iterative method;linear system;numerical analysis;solver;sparse matrix	Per-Gunnar Martinsson	2009	J. Sci. Comput.	10.1007/s10915-008-9240-6	direct method;mathematical optimization;laplace operator;mathematical analysis;discrete mathematics;calculus;mathematics;low frequency;linear system;helmholtz equation;elliptic partial differential equation;physics;quantum mechanics	HPC	86.08523406387002	20.7676006286103	109675
9b5420605a6cccc1a5777ec4c56489dde0e13745	the nine neighbor extrapolated diffusion method for weighted torus graphs	iterative diffusion;laplacian matrix;weighted torus;load balancing;fourier analysis	The convergence analysis of the Extrapolated Diffusion (EDF) was developed in [7] and [8] for the weighted torus and mesh graphs, respectively using the set $\mathcal{N}_1(i)$ of nearest neighbors of a node i in the graph. In the present work we propose a Diffusion scheme which employs the set $\mathcal{N} _1(i)\cup \mathcal{N}_2(i)$, where $\mathcal{N}_2(i)$ denotes the four neighbors of node i with path length two (see Figure 1) in order to increase the convergence rate. We study the convergence analysis of the new Diffusion scheme with nine neighbors (NEDF) for weighted torus graphs. In particular, we find closed form formulae for the optimum values of the edge weights and the extrapolation parameter. A 60% increase in the convergence rate of NEDF compared to the conventional EDF method is shown analytically and numerically.	extrapolation	Katerina A. Dimitrakopoulou;Michail N. Misyrlis	2011		10.1007/978-3-642-31464-3_42	combinatorics;discrete mathematics;topology;laplacian matrix;computer science;load balancing;mathematics;fourier analysis	Vision	86.79426994509761	25.62386953901985	109969
870f894b13287b10b3fa6b921fea632e6a0e4ef6	the convergence of asynchronous monotone newton iterations on distributed computer	convergence;newton iteration;distributed computing;algorithms;newton method;parallel processing;mathematics computers information science management law miscellaneous	In this paper, according to the asynchronous iteration model presented by Baudet and Bertsekas, we present an asynchronous parallel algorithm for the non-linear system of equations F(x) = 0. In order to describe this algorithm, we need to give some notations. If x is an element of R{sup n}, we write x = (x{sub 1}, ... x{sub n}). To avoid confusion, a sequence of elements of R{sup n} will be denoted by x(t),t = 0,1,2, ... Let F: R{sup n} {r_arrow} Rn be the function defined by F(x) = (F{sub 1}(x), ... Fn(x)), for any x. Let x{sub i}(t)=value of i-th component at time t. We assume that there is a set of times T = 0, 1, 2, {hor_ellipsis} at which one or more components x{sub i} of x are updated by some processors of a distributed computing system. Let T{sub i} = set of times at which x{sub i} is updated.	iteration;newton;monotone	Jie Hu;Tadao Nakamura;Lei Li	1995			mathematical optimization;computer science;theoretical computer science;algorithm	EDA	84.31204311874765	22.025362725862976	112408
b4895922db6dc0e348e252da2d0b6fc881284ff6	iterative algorithms for solution of large sparse systems of linear equations on hypercubes	equation derivee partielle;linear algebra;distributed memory;algoritmo paralelo;hypercube;partial differential equation;ecuacion derivada parcial;parallel algorithm;methode element fini;metodo elemento finito;iterative algorithms;multiprocessor;numerical technique;gradient method;boundary value problem;metal forming;hypercube topology;ecuacion lineal;conjugate gradient method parallel algorithms iterative algorithms large sparse systems linear equations hypercubes distributed memory message passing multiprocessors hypercube topology;finite element method;message passing multiprocessors;indexing terms;conjugate gradient method;iterative algorithm;finite element;algorithme parallele;iterative methods;resolucion sistema ecuacion;resolution systeme equation;heat flow;finite element mesh;iterative algorithms hypercubes finite element methods equations topology gradient methods algorithm design and analysis;message passing;hypercubes;equation system solving;finite element analysis;parallel algorithms finite element analysis iterative methods linear algebra;linear equations;coarse grained;multiprocesador;linear equation;probleme valeur limite;large sparse systems;equation lineaire;problema valor ĺimite;parallel algorithms;multiprocesseur;hipercubo	Solution of many scientific and engineering problems requires large amounts of computing power. The finite element method [l] is a powerful numerical technique for solving boundary value problems involving partial differential equations in engineering fields such as heat flow analysis, metal forming, and others. As a result of finite element discretization, linear equations in the form A x = b are obtained where A is large, sparse, and banded with proper ordering of the variables x. In this paper, solution of such equations on distributed-memory message-passing multiprocessors implementing the hypercube [2] topology is addressed. Iterative algorithms based on the Conjugate Gradient method are developed for hypercubes designed for coarse grain parallelism. Communication requirements of different schemes for mapping finite element meshes onto the processors of a hypercube are analyzed with respect to the effect of communication parameters of the architecture. Experimental results on a 16-node Intel 386-based iPSC/2 hypercube are presented and discussed in Section V.	algorithm;central processing unit;conjugate gradient method;data-flow analysis;discretization;distributed memory;finite element method;grid network;iterative method;linear equation;message passing;numerical analysis;parallel computing;requirement;sparse matrix;system of linear equations	Cevdet Aykanat;Füsun Özgüner;Fikret Erçal;P. Sadayappan	1988	IEEE Trans. Computers	10.1109/12.9733	mathematical optimization;combinatorics;parallel computing;computer science;theoretical computer science;linear algebra;finite element method;mathematics;algebra	HPC	85.45861577804683	21.694892241377158	113724
4f2740f438982030f59c204bade3230828fe14ad	a numerical method for mass spectral data analysis	tratamiento datos;metodo espectral;mass spectrometer;matematicas aplicadas;algorithm performance;mathematiques appliquees;analisis datos;gollete estrangulamiento;numerical method;mass spectra;mass spectrometry;error sistematico;data processing;traitement donnee;analyse temporelle;analisis temporal;algorithme numerique;time analysis;data analysis;goulot etranglement;espectrometria masa;extremite;end;bias;resultado algoritmo;numerical algorithm;extremidad;analyse spectrale;spectral method;performance algorithme;algoritmo numerico;analyse donnee;analisis espectral;methode spectrale;spectrometrie masse;spectral analysis;applied mathematics;bottleneck;erreur systematique	The new generation of mass spectrometers produces an astonishing amount of high-quality data in a brief periodof time, leading to inevitable data analysis bottlenecks. Automated data analysis algorithms are required for rapid and repeatable processing of mass spectra containing hundreds of peaks, the part of the spectra containing information. New data processing algorithms must work with minimal user input, both to save operator time and to eliminate inevitable operator bias. Toward th is end an accurate mathema tic l algorithm is presented that automatically locates an d calculates the area beneath peaks. The p romising numerical performance of this algorithm applied to raw data is presented. Published by Elsevier Ltd	algorithm;bottleneck (software);mass effect trilogy;numerical method;rca spectra 70;smoothing	Anthony J. Kearsley;William E. Wallace;Javier Bernal;Charles M. Guttman	2005	Appl. Math. Lett.	10.1016/j.aml.2005.02.033	end;mass spectrum;applied mathematics;mass spectrometry;numerical analysis;bias;calculus;mathematics;data analysis;algorithm;spectral method	ML	89.83805040821954	21.731888662669736	113782
80794a09ff1c87852f0286c8218b71a9126fd38d	solving negative order equations by the multigrid method via variable substitution		Variable substitutions are introduced to the single layer potential equations such that the order of pseudo-differential operator is changed from minus one to plus one. Though the condition number remains the same order after such a variable substitution, the frequencies of higher and lower eigenfunctions are switched. The multigrid iteration is shown to be an optimal order solver for the resulting linear systems of boundary element equations. Two types of variable substitutions are suggested. Numerical tests are presented showing efficiency of both methods, and supporting the theory.	boundary element method;condition number;iteration;linear system;multigrid method;numerical linear algebra;numerical method;solver	George C. Hsiao;Liwei Xu;Shangyou Zhang	2014	J. Sci. Comput.	10.1007/s10915-013-9762-4	mathematical optimization;combinatorics;mathematical analysis;mathematics;multigrid method	HPC	84.13038242284303	20.381000694015647	114368
8a02da159e003a971181f856f05a58e6a9edd0e4	fast numerical algorithms for wiener systems identification	system identification	A Wiener system consists of a linear dynamic block followed by a static nonlinearity. The identification of a Wiener system means finding a mathematical model using the input and output data. The approach chosen for identification uses a state space representation for the linear part and a single layer neural network to model the static nonlinearity. Fast subspace identification algorithms are used for estimating the linear part, based on the available input-output data. Using the resulted state-space model, an approximate model of the nonlinear part is found by an improved Levenberg-Marquardt (LM) algorithm. Finally, the whole model is refined using a specialized, MINPACK-like, but structure-exploiting LAPACK-based LM algorithm. The output normal form is used to parameterize the linear part. With a suitable ordering of the variables, the Jacobian matrices have a block diagonal form, with an additional block column at the right. This structure is preserved in a QR factorization with column pivoting restricted to each block column. The implementation is memory conserving and about one order of magnitude faster than standard LM algorithms or specialized LM calculations based on conjugate gradients for solving linear systems.	algorithm;numerical analysis	Vasile Sima	2002			mathematical optimization;combinatorics;discrete mathematics;mathematics	EDA	88.0767038654144	21.098228779848522	115887
067072add869890e270de348377efbc8150177e9	a space-time adaptive finite element algorithm based on dual weighted residual methodology for parabolic equations	65n30;equation derivee partielle;calcul scientifique;erreur troncature;partial differential equation;ecuacion derivada parcial;analisis numerico;adaptive finite elements;dwr method;methode element fini;metodo elemento finito;algoritmo adaptativo;parabolic equation;65n50;finite element method;maillage;integration;ecuacion parabolica;analyse numerique;unstructured triangular meshes;adaptive algorithm;computacion cientifica;equation parabolique;numerical analysis;estimation erreur;algorithme adaptatif;parabolic problems;celdarada;35kxx;error estimation;integracion;estimacion error;finite elements;truncation error;65n15;grid pattern;scientific computation;time space goal oriented adaptivity;error truncamiento;28xx	We propose in this paper a space-time adaptive algorithm based on the dual weighted residual (DWR) idea in the framework of a finite element method. Our algorithm consists of applying the DWR technique locally in each time interval In := (tn−1, tn], and thus, we control the local or truncation error for a functional of the solution J(u). The disadvantage of our method compared to the traditional DWR method is that having a good local error control does not guarantee that the global error will be bounded. However, the main advantage of our method is that we avoid solving backward in the whole time interval I := (0, T ] the associated linear dual problem so that the storage requirements are smaller. This means that we can define a self-sufficient criterion that allows us to have control of the time step Δt and the mesh size h as time of integration progresses. Another good feature of our algorithm is the extension of the spatial postprocessing procedure of the traditional DWR method to unstructured meshes made of simplices.	adaptive algorithm;direct web remoting;duality (optimization);error detection and correction;finite element method;parabolic antenna;requirement;truncation error	Rodolfo Bermejo;Jaime Carpio	2009	SIAM J. Scientific Computing	10.1137/070698853	mathematical optimization;finite element method;calculus;mathematics;algorithm;algebra	Visualization	87.39326249482362	19.917458390640057	116000
74af50715b3c654719df42982b096e2603bfdb99	a preconditioned conjugate gradient method for nonselfadjoint or indefinite orthogonal spline collocation problems	preconditionnement;orthogonal spline collocation;65b99;systeme equation;problema valor limite;nonselfadjoint or indefinite elliptic boundary value problem;analisis numerico;elliptic boundary value problem;preconditioned conjugate gradient method;approximation numerique;65n35;gradient method;metodo descomposicion;relacion convergencia;boundary value problem;convergence of numerical methods;methode decomposition;65n99;dirichlet problem;ecuacion lineal;preconditioning;taux convergence;convergence rate;conjugate gradient method;probleme dirichlet;aproximacion numerica;analyse numerique;algorithme;methode gradient;convergence methode numerique;algorithm;decomposition method;descomposicion matricial;aproximacion esplin;sistema ecuacion;numerical analysis;matrix decomposition algorithm;preconditioner;particion;65d07;decomposition matricielle;spline orthogonale;metodo gradiente;matrix decomposition;metodo gradiente conjugado;spline approximation;approximation spline;problema dirichlet;equation system;65nxx;partition;precondicionamiento;numerical approximation;methode gradient conjugue;linear equation;probleme valeur limite;orthogonal spline;65f10;equation lineaire;algoritmo;65n22	We study the computation of the orthogonal spline collocation solution of a linear Dirichlet boundary value problem with a nonselfadjoint or an indefinite operator of the form Lu = ∑ aij(x)uxixj + ∑ bi(x)uxi + c(x)u. We apply a preconditioned conjugate gradient method to the normal system of collocation equations with a preconditioner associated with a separable operator, and prove that the resulting algorithm has a convergence rate independent of the partition step size. We solve a problem with the preconditioner using an efficient direct matrix decomposition algorithm. On a uniform N×N partition, the cost of the algorithm for computing the collocation solution within a tolerance is O(N2 lnN | ln |).	algorithm;collocation;computation;conjugate gradient method;lu decomposition;navier–stokes equations;preconditioner;rate of convergence;spline (mathematics)	Rakhim Aitbayev;Bernard Bialecki	2003	SIAM J. Numerical Analysis	10.1137/S0036142901391396	mathematical optimization;orthogonal collocation;mathematical analysis;calculus;mathematics;preconditioner;algorithm;algebra	Theory	83.26273641579843	20.618683191453922	117102
2d37dc8f28a04081fb5f5bb1ad121ca8c8a26c13	rigorously computed orbits of dynamical systems without the wrapping effect	algoritmo paralelo;wrapping;discrete dynamical system;parallel algorithm;algorithm performance;calcul formel;heuristic method;wrapping effect;metodo heuristico;dynamic system;matrix algebra;envolvimiento;parallel computation;calculo formal;algorithme parallele;dynamical system;systeme dynamique;calculo paralelo;resultado algoritmo;performance algorithme;parallel computer;enveloppage;dynamical systems;methode heuristique;sistema dinamico;computer algebra;calcul parallele;zonotopes	A new method for rigorously computing orbits of discrete dynamical systems is introduced. High order zonotope enclosures of the orbit are computed, using only matrix algebra. The wrapping effect can be made arbitrarily small by choosing the order high enough. The method is easy to implement and especially suited for parallel computing. It is compared to other well known strategies, and several examples are given.	dynamical system;parallel computing;wrapping (graphics);zonohedron	Wolfgang Kuehn	1998	Computing	10.1007/BF02684450	orbit;symbolic computation;dynamical system;mathematics;geometry;algorithm	DB	87.37746592352089	20.22548766158676	118780
045356c044ea52c0a42db2d6877b1d22b3281c78	a tensor-train accelerated solver for integral equations in complex geometries	integral equations;hierarchical matrix compression and inversion;tensor train decomposition;fast multipole methods;complex geometries;preconditioned iterative solver	We present a framework using the Quantized Tensor Train (QTT) decomposition to accurately and efficiently solve volume and boundary integral equations in three dimensions. We describe how the QTT decomposition can be used as a hierarchical compression and inversion scheme for matrices arising from the discretization of integral equations. For a broad range of problems, computational and storage costs of the inversion scheme are extremely modest O log N and once the inverse is computed, it can be applied in O N log N . We analyze the QTT ranks for hierarchically low rank matrices and discuss its relationship to commonly used hierarchical compression techniques such as FMM and HSS. We prove that the QTT ranks are bounded for translation-invariant systems and argue that this behavior extends to nontranslation invariant volume and boundary integrals. For volume integrals, the QTT decomposition provides an efficient direct solver requiring significantly less memory compared to other fast direct solvers. We present results demonstrating the remarkable performance of the QTT-based solver when applied to both translation and non-translation invariant volume integrals in 3D. For boundary integral equations, we demonstrate that using a QTT decomposition to construct preconditioners for a Krylov subspace method leads to an efficient and robust solver with a small memory footprint. We test the QTT preconditioners in the iterative solution of an exterior elliptic boundary value problem (Laplace) formulated as a boundary integral equation in complex, multiply connected geometries.	approximation algorithm;cholesky decomposition;computation;discretization;fast multipole method;flip-flop (electronics);generalized minimal residual method;high-speed serial interface;image scaling;iterative method;krylov subspace;machine translation;memory footprint;multigrid method;preconditioner;requirement;solver;time complexity	Eduardo Corona;Abtin Rahimian;Denis Zorin	2017	J. Comput. Physics	10.1016/j.jcp.2016.12.051	mathematical optimization;mathematical analysis;mathematics;geometry;integral equation	Robotics	87.95392053779392	21.572090740564313	118819
6f782d55cccced1b880db8b27f4e021ede8eb558	propagating dense systems of integer linear equations	constraint propagation;finite domain;constraint programming;gaussian elimination;linear equations;interval arithmetic;gauss seidel;artificial intelligence and image processing;conference proceeding	In interval propagation approaches to solving non-linear constraints over reals it is common to build stronger propagators from systems of linear equations. This, as far as we are aware, is not pursued for integer finite domain propagation. In this paper we show how we can add preconditioning Gauss-Seidel based propagators to an integer propagation solver. The Gauss-Seidel based propagators make use of interval arithmetic which is substantially slower than integer arithmetic. We show how we can build new integer propagators from the result of preconditioning that no longer require interval arithmetic to be performed. Although the resulting propagators may be slightly weaker than the original Gauss-Seidel propagation, they are substantially faster. We show on standard integer benchmarks how these new propagators can substantially improve propagation performance, in terms of strength of propagation and speed.	gauss–seidel method;interval arithmetic;interval propagation;linear equation;nonlinear system;preconditioner;propagator;software propagation;solver;system of linear equations	Thibaut Feydy;Peter J. Stuckey	2007		10.1145/1244002.1244075	mathematical optimization;constraint programming;gaussian elimination;linear equation;interval arithmetic;local consistency;gauss–seidel method	NLP	83.03849893633951	23.696087830759154	119579
55f878cdbf771f8d0d93a1bb4971a2b719705050	reducing the deteriorating effect of old history in asynchronous iterations	metodo cuadrado menor;parallelisme;methode moindre carre;least squares method;numerical method;linear least square;synchronisation;parallelism;asynchronous algorithm;paralelismo;metodo numerico;synchronization;sincronizacion;numerical experiment;methode numerique	The deteriorating effect of old history in asynchronous iterations is investigated on an application based on the specialization of parallel variable distribution approach of Ferris and Mangasarian [4] to linear least squares problem. A partially asynchronous algorithm is developed which employs a combination of synchronization, a relaxation parameter and a certain form of overlap between subproblems. It is shown by numerical experiments that this combined effort to decrease the effect of old history is more effective than the single attempts considered in [9, 11].	iteration	Yasemin Yalçinkaya;Trond Steihaug	2004		10.1007/978-3-540-27866-5_92	synchronization;combinatorics;computer science;calculus;mathematics;algorithm	HCI	85.32054601869194	25.71429043689693	119845
0cb5bacbc318c6c7d3f784092d7d01d4e9b04cce	improvement of the recursive projection method for linear iterative scheme stabilization based on an approximate eigenvalue problem	linear systems;optimisation;advection diffusion equation;eigenvalue problem;eigenvalue problems;krylov subspace method;performance;stabilization;projection method;calculation;ecuacion adveccion difusion;probleme valeur propre;linear system;methode calcul;algorithme;transonic flow;shape optimization;technique calcul;sensitivity analysis;simulation numerique;numerical algorithm;calculation methods;analyse sensibilite;algorithms;optimization;stabilisation;turbulent flow;numerical experiment;systeme lineaire;ecoulement turbulent;equation advection diffusion;digital simulation;problema valor propio;recursive projection method	An algorithm for stabilizing linear iterative schemes is developed in this study. The recursive projection method is applied in order to stabilize divergent numerical algorithms. A criterion for selecting the divergent subspace of the iteration matrix with an approximate eigenvalue problem is introduced. The performance of the present algorithm is investigated in terms of storage requirements and CPU costs and is compared to the original Krylov criterion. Theoretical results on the divergent subspace selection accuracy are established. The method is then applied to the resolution of the linear advection–diffusion equation and to a sensitivity analysis for a turbulent transonic flow in the context of aerodynamic shape optimization. Numerical experiments demonstrate better robustness and faster convergence properties of the stabilization algorithm with the new criterion based on the approximate eigenvalue problem. This criterion requires only slight additional operations and memory which vanish in the limit of large linear systems. 2011 Elsevier Inc. All rights reserved.	approximation algorithm;central processing unit;experiment;iteration;krylov–bogolyubov theorem;linear system;mathematical optimization;numerical analysis;numerical method;projection method (fluid dynamics);recursion;requirement;shape optimization;turbulence;vanish (computer science)	Florent Renac	2011	J. Comput. Physics	10.1016/j.jcp.2011.03.057	mathematical optimization;combinatorics;calculus;inverse iteration;mathematics;linear system;thermodynamics;physics;algorithm	Vision	85.31960473814749	21.231666543940282	122529
14c5b98af4ae6b1acd8ffa72a589a8ee8023ba6a	condition number estimates and weak scaling for 2-level 2-lagrange multiplier methods for general domains and cross points	partial differential equation;parallel preconditioner;domain decomposition;schwarz method;krylov space;2 lagrange multiplier;65n55;multigrid;65f08;coarse grid;feti;35j15	The 2-Lagrange multiplier method is a domain decomposition method which can be used to parallelize the solution of linear problems arising from partial differential equations. In order to scale to large numbers of subdomains and processors, domain decomposition methods require a coarse grid correction to transport low frequency information more rapidly between subdomains that are far apart. We introduce two new 2-level methods by adding a coarse grid correction to 2-Lagrange multiplier methods. We prove that if we shrink h (the grid parameter) while maintaining bounded the ratio H h (where H is the size of the subdomains), the condition number of the method remains bounded. We confirm our analysis with experiments on the HECToR (High-End Computing Terascale Resource) supercomputer. This proves that the new methods scale weakly, opening the door to massively parallel implementations.	central processing unit;condition number;domain decomposition methods;experiment;hector;linear algebra;parallel computing;scalability;supercomputer;terascale (microarchitecture);weak value	Anastasios Karangelis;Sébastien Loisel	2015	SIAM J. Scientific Computing	10.1137/140965491	computational science;mathematical optimization;mathematical analysis;discrete mathematics;mathematics;domain decomposition methods;feti;mortar methods;partial differential equation;multigrid method	HPC	84.00861316146808	23.174061901778174	122549
54cdb2a83b71410967448f11a92ca3dc6a9e734e	concepts and application of time-limiters to high resolution schemes	equation derivee partielle;metodo directo;methode discretisation;systeme equation;equation differentielle;solution oscillatoire;partial differential equation;solucion oscilatoria;ecuacion derivada parcial;time dependent;equation burgers;high resolution;numerical solution;schema implicite;integracion numerica;numerical method;adveccion;implementation;ecuacion burgers;temps lineaire;differential equation;non linear time integration;tiempo lineal;satisfiability;methode runge kutta;metodo runge kutta;integration;monotonie;ecuacion diferencial;algorithme;stabilite non lineaire;algorithm;metodo discretizacion;methode lignes;total variation diminishing scheme;haute resolution;stabilite lineaire;sistema ecuacion;dependance du temps;time dependence;metodo numerico;numerical integration;integracion;equation system;monotonicity;linear time;systeme non lineaire;time limiting;alta resolucion;advection;non linear stability;burgers equation;high resolution schemes;estabilidad no lineal;discretization method;method of lines;tvd scheme;monotonia;high resolution scheme;linear stability;implementacion;sistema no lineal;estabilidad lineal;integration numerique;oscillatory solution;methode directe;dependencia del tiempo;non linear system;solution numerique;methode numerique;direct method;runge kutta method;implicit scheme;metodo lineas;algoritmo;time integration	1 Graduate Research Student, Department of Aerospace Engineering, University of Maryland, College Park, Maryland 20742. 2 Associate Professor, Department of Aerospace Engineering, University of Maryland, College Park, Maryland 20742. 3 Professor, Institute of Physical Science and Technology and Department of Mathematics, University of Maryland, College Park, Maryland 20742. E-mail: jliu@math.umd.edu Received May 1, 2002; accepted (in revised form) October 20, 2002	bandlimiting	Karthikeyan Duraisamy;James D. Baeder;Jian-Guo Liu	2003	J. Sci. Comput.	10.1023/A:1025395707090	direct method;linear stability;mathematical analysis;advection;numerical integration;calculus;mathematics;geometry;flux limiter;implementation;method of lines;differential equation;partial differential equation;algorithm;satisfiability	DB	87.77031192747526	18.80790551810174	122654
8eab7af2b779bdbafe996ae28a58b31364e63e31	iterated tikhonov regularization with a general penalty term		Tikhonov regularization is one of the most popular approaches to solving linear discrete ill-posed problems. The choice of regularization matrix may significantly affect the quality of the computed solution. When the regularization matrix is the identity, iterated Tikhonov regularization can yield computed approximate solutions of higher quality than (standard) Tikhonov regularization. This paper provides an analysis of iterated Tikhonov regularization with a regularization matrix different from the identity. Computed examples illustrate the performance this method. Copyright c © John Wiley & Sons, Ltd.	approximation algorithm;iterated function;iteration;john d. wiley;matrix regularization;numerical analysis;stationary process;well-posed problem;whole earth 'lectronic link	Alessandro Buccini;Marco Donatelli;Lothar Reichel	2017	Numerical Lin. Alg. with Applic.	10.1002/nla.2089	regularization perspectives on support vector machines;backus–gilbert method;regularization;mathematical optimization;mathematical analysis;calculus;tikhonov regularization	AI	84.47071851150976	19.15503417043119	122724
4f2cd62067b4c52ff438e9291a6856ca6344e1f8	variational and pde level set methods	equation derivee partielle;calcul scientifique;partial differential equation;ecuacion derivada parcial;analisis numerico;35xx;level set;ensembe niveau;analyse numerique;algorithme;algorithm;computacion cientifica;numerical analysis;49r50;scientific computation;level set method;algoritmo	– M. Bertalmı́o, Universitat Pompeu Fabra, Barcelona – M. Burger, Johannes Kepler University, Linz – G. Dziuk, Albert Ludwig University, Freiburg – M. Hintermüller, TU Graz – M. Nikolova, ENS de Cachan, Paris – M. Rumpf, Rheinische Friedrich-Wilhelms University, Bonn – C. Schnoerr, University of Mannheim – F. Sgallari, University of Bologna – G. Steidl, University of Mannheim – J. Weickert, Saarland University – J. P. Zolesio, INRIA, Nice.	kepler;variational principle	Bert Jüttler;Helmut Pottmann;Otmar Scherzer	2007	Computing	10.1007/s00607-007-0244-0	numerical analysis;level set;calculus;mathematics;geometry;partial differential equation;level set method;algorithm	DB	87.87562923499449	18.929481079048838	122739
682d091bed26a9a8af017b87608b39e4843dc9e3	a fast randomized eigensolver with structured ldl factorization update	15a18;matrix free hss construction;65f05;eigensolver;hss matrix;aggressive low rank inertia evaluation;inertia ldl update for varying shifts;adaptive randomized sampling;65f30;65f15	In this paper, we propose a structured bisection method with adaptive randomized sampling for finding selected or all of the eigenvalues of certain real symmetric matrices A. For A with a low-rank property, we construct a hierarchically semiseparable (HSS) approximation and show how to quickly evaluate and update its inertia in the bisection method. Unlike some existing randomized HSS constructions, the methods here do not require the knowledge of the off-diagonal (numerical) ranks in advance. Moreover, for A with a weak rank property or slowly decaying offdiagonal singular values, we show an idea of aggressive low-rank inertia evaluation, which means that a compact HSS approximation can preserve the inertia for certain shifts. This is analytically justified for a special case, and numerically shown for more general ones. A generalized LDL factorization of the HSS approximation is then designed for the fast evaluation of the inertia. A significant advantage over standard LDL factorizations is that the HSS LDL factorization (and thus the inertia) of A − sI can be quickly updated with multiple shifts s in bisection. The factorization with each new shift can reuse about 60% of the work. As an important application, the structured eigensolver can be applied to symmetric Toeplitz matrices, and the cost to find one eigenvalue is nearly linear in the order of the matrix. The numerical examples demonstrate the efficiency and the accuracy of our methods, especially the benefit of low-rank inertia evaluations. The ideas and methods can be potentially adapted to other HSS computations where shifts are involved and to more problems without a significant low-rank property.	approximation error;binary logarithm;bisection method;computation;eigenvalue algorithm;flops;fast multipole method;high-speed serial interface;low-rank approximation;numerical analysis;randomized algorithm;sampling (signal processing);the matrix;time complexity;toeplitz hash algorithm;uml state machine;weak value	Yuanzhe Xi;Jianlin Xia;Raymond H. Chan	2014	SIAM J. Matrix Analysis Applications	10.1137/130914966	mathematical optimization;combinatorics;discrete mathematics;mathematics	Web+IR	82.99414948457247	24.23963797596756	123368
b1e3571d3bb150192ae4ffe5386337aea31ecc6b	multiple search direction conjugate gradient method i: methods and their propositions	linear systems;global communication;inner product;conjugate gradient method;massively parallel computing;conjugate gradient type method	Multiple search direction conjugate gradient method I: methods and their propositions Tongxiang Gu a b , Xingping Liu a , Zeyao Mo a & Xuebin Chi b a Laboratory of Computational Physics , Institute of Applied Physics and Computational Mathematics , P.O. Box 8009, Beijing, 100088, P.R. China b Supercomputing Center of Computer Network Information Center , Chinese Academy of Science , P.O. Box 349, Beijing, 100080, P.R. China Published online: 25 Jan 2007.	acm/ieee supercomputing conference;academy;chi;computation;computational mathematics;computational physics;conjugate gradient method	Tongxiang Gu;Xingping Liu;Zeyao Mo;Xuebin Chi	2004	Int. J. Comput. Math.	10.1080/00207160410001712305	gradient descent;mathematical optimization;discrete mathematics;conjugate residual method;dot product;gradient method;massively parallel;derivation of the conjugate gradient method;descent direction;mathematics;domain decomposition methods;conjugate gradient method;biconjugate gradient stabilized method;nonlinear conjugate gradient method;linear system;biconjugate gradient method;algorithm;algebra	ML	85.18427686882632	24.10170606664442	123779
20d3df24f102e3f7b280c6eb51e42c9cbd81092f	damped jacobi preconditioning and coarse grid deflation for conjugate gradient iteration on parallel computers	equation derivee partielle;sistema lineal;iterative method;partial differential equation;ecuacion derivada parcial;methode element fini;metodo elemento finito;multiprocessor;finite element method;conjugate gradient method;linear system;metodo iterativo;65n20;conjugate gradient;metodo gradiente conjugado;methode iterative;parallel;parallel computer;methode gradient conjugue;systeme lineaire;multiprocesador;preconditioned conjugate gradient;65f10;preconditioned conjugate;multiprocesseur	A combination of damped Jacobi preconditioning and deflation is given as a way to improve the convergence of conjugate gradient iteration on local memory multiprocessor computers such as the hypercube. Experimental results are given for the linear system associated with the elastic bending of a cantilever beam on the iPSC/2 with both 4 and 16 processors.	conjugate gradient method;iteration;jacobi method;parallel computing;preconditioner;stochastic gradient descent	Lois Mansfield	1991	SIAM J. Scientific Computing	10.1137/0912071	mathematical optimization;calculus;mathematics;geometry;conjugate gradient method;algebra	HPC	84.23929481147287	21.407217072250997	123780
d60f1f925125049ef1ec94f444d59bb743b093e6	sweeping preconditioner for the helmholtz equation: moving perfectly matched layers	iterative solver;layer by layer;mathematics;three dimensions;green s function;perfectly matched layers;schur complement;multifrontal methods;preconditioners;optimal ordering;numerical analysis;boundary condition;65f08;65n80;ldl factorization;helmholtz equation;high frequency waves;ldlt factorization;iterative solution;matematik;perfectly matched layer;lu factorization;65n22	This paper introduces a new sweeping preconditioner for the iterative solution of the variable coefficient Helmholtz equation in two and three dimensions. The algorithms follow the general structure of constructing an approximate LDLt factorization by eliminating the unknowns layer by layer starting from an absorbing layer or boundary condition. The central idea of this paper is to approximate the Schur complement matrices of the factorization using moving perfectly matched layers (PMLs) introduced in the interior of the domain. Applying each Schur complement matrix is equivalent to solving a quasi-1D problem with a banded LU factorization in the 2D case and to solving a quasi-2D problem with a multifrontal method in the 3D case. The resulting preconditioner has linear application cost, and the preconditioned iterative solver converges in a number of iterations that is essentially independent of the number of unknowns or the frequency. Numerical results are presented in both two and three dimensions to demonstrate the efficiency of this new preconditioner.	adaptive mesh refinement;approximation algorithm;authorization;coefficient;computation;domain decomposition methods;finite difference;finite element method;frontal solver;galerkin method;generalized minimal residual method;iteration;iterative method;lu decomposition;matrix representation;numerical analysis;parallel computing;parallel processing (dsp implementation);parallel programming model;preconditioner;qr decomposition	Björn Engquist;Lexing Ying	2011	Multiscale Modeling & Simulation	10.1137/100804644	layer by layer;three-dimensional space;mathematical optimization;mathematical analysis;perfectly matched layer;lu decomposition;numerical analysis;boundary value problem;calculus;mathematics;schur complement;green's function;helmholtz equation;quantum mechanics	Vision	84.97643930968168	21.119257617547444	125172
446bc33d21c79b1e4283bf853829eeb46a1e5a3c	strategies for nonobtuse boundary delaunay triangulations	partial differential equation;delaunay triangulation;numerical solution;informing science;satisfiability;quality requirement;matrices;partial differential equations;algorithms;99 mathematics computers information science management law miscellaneous;mesh generation;mathematics computers information science management law miscellaneous	Delaunay Triangulations with nonobtuse triangles at the boundaries satisfy a minimal requirement for Control Volume meshes. We motivate this quality requirement, discuss it in context with others that have been proposed, and give point placement strategies that generate the fewest or close to the fewest number of Steiner points needed to satisfy it for a particular problem instance. The advantage is that this strategy places a number of Steiner points proportional to the combinatorial size of the input rather than the local feature size, resulting in far fewer points in many cases.	delaunay triangulation;local feature size;steiner tree problem	Michael P Murphy;Carl W. Gable	1998			mathematical optimization;combinatorics;discrete mathematics;mathematics;constrained delaunay triangulation	Theory	92.78746670648036	20.111253230119072	125712
2c373366e31b3dc9a8e44a3dce637c677326111c	complexity of hierarchical refinement for a class of admissible mesh configurations		An adaptive isogeometric method based on d-variate hierarchical spline constructions can be derived by considering a refine module that preserves a certain class of admissibility between two consecutive steps of the adaptive loop [6]. In this paper we provide a complexity estimate, i.e., an estimate on how the number of mesh elements grows with respect to the number of elements that are marked for refinement by the adaptive strategy. Our estimate is in the line of the similar ones proved in the finite element context, [3, 24].	admissible heuristic;discretization;dreams;finite element method;finite impulse response;isogeometric analysis;refinement (computing);simulation;spline (mathematics)	Annalisa Buffa;Carlotta Giannelli;Philipp Morgenstern;Daniel Peterseim	2016	Computer Aided Geometric Design	10.1016/j.cagd.2016.04.003	mathematical optimization;combinatorics;discrete mathematics;mathematics	EDA	92.01508749408336	18.770982811318465	127280
0f316d883253befe8252dce235ac2cd1746f0372	fast wave computation via fourier integral operators	separated approximation;multiscale computations;random sampling;wave equations;fourier integral operators;discrete symbol calculus	This paper presents a numerical method for “time upscaling” wave equations, i.e., performing time steps not limited by the Courant-FriedrichsLewy (CFL) condition. The proposed method leverages recent work on fast algorithms for pseudodifferential and Fourier integral operators (FIO). This algorithmic approach is not asymptotic: it is shown how to construct an exact FIO propagator by 1) solving Hamilton-Jacobi equations for the phases, and 2) sampling rows and columns of low-rank matrices at random for the amplitudes. The setting of interest is that of scalar waves in two-dimensional smooth periodic media (of class C∞ over the torus), where the bandlimit N of the waves goes to infinity. In this setting, it is demonstrated that the algorithmic complexity for solving the wave equation to fixed time T 1 can be as low as O(N2 logN) with controlled accuracy. Numerical experiments show that the time complexity can be lower than that of a spectral method in certain situations of physical interest.	algorithm;analysis of algorithms;bandlimiting;column (database);computation;computational complexity theory;courant–friedrichs–lewy condition;experiment;jacobi method;numerical method;propagator;sampling (signal processing);spectral method;time complexity	Laurent Demanet;Lexing Ying	2012	Math. Comput.	10.1090/S0025-5718-2012-02557-9	sampling;mathematical optimization;combinatorics;wave equation;mathematical analysis;mathematics;geometry;fourier integral operator;algorithm;quantum mechanics;algebra	Theory	86.26833383781712	19.731560705449187	128249
4206e1a7c058bf2fd41de12d53d9f2a72f60cb49	the highly parallel incomplete gram-schmidt preconditioner	sistema lineal;modelizacion;distributed memory;analisis estadistico;inner product;linear system;parallel computation;modelisation;calculo paralelo;statistical analysis;analyse statistique;least square;systeme lineaire;modeling;calcul parallele	In this paper we study the parallel aspects of IMGS, Incomplete Modiied Gram-Schmidt preconditioner which can be used for ef-ciently solving sparse and large linear systems and least squares problems on massively parallel distributed memory computers. The performance of this preconditioning technique on this kind of architecture is always limited because of the global communication required for the inner products, even for ParIMGS, a parallel version of IMGS where we create some possibilities such that the computation can be overlapped with the communication. We will describe a more eecient alternative, namely Improved ParIMGS (IParIMGS) which avoids the global communication of inner products and only requires local communications. Therefore, the cost of communication can be signiicantly reduced. Several numerical experiments carried out on Parsytec GC/PowerPlus are presented as well.	computation;computer;distributed memory;experiment;least squares;linear system;numerical analysis;preconditioner;schmidt decomposition;sparse matrix	Laurence Tianruo Yang;Hai-Xiang Lin	1997		10.1007/3-540-63371-5_50	combinatorics;parallel computing;systems modeling;distributed memory;dot product;computer science;theoretical computer science;linear system;least squares;algorithm;statistics	HPC	83.48558117011419	21.695882054375264	131694
beb6eb5a98f9776f0f8e6d687b8d672f4a7a66ff	a new iterative method for solving large-scale lyapunov matrix equations	calcul scientifique;iterative method;continuous time;analisis numerico;metodo subespacio krylov;krylov subspace method;matrix equations;aproximacion;methode sousespace krylov;equation matricielle;projection method;temps continu;tiempo continuo;analyse numerique;approximation;metodo iterativo;large scale equations;iterative methods;15a06;large scale;computacion cientifica;iteraccion;numerical analysis;matrix equation;methode projection;methode iterative;metodo proyeccion;39b42;ecuacion matricial;iteration;krylov subspace;scientific computation;low rank approximation;iteration method;65f30;model order reduction;65f10;15a24	In this paper we propose a new projection method to solve large-scale continuous-time Lyapunov matrix equations. The new method projects the problem onto a much smaller approximation space, generated as a combination of Krylov subspaces in A and A. The reduced problem is then solved by means of a direct Lyapunov scheme based on matrix factorizations. The reported numerical results show the competitiveness of the new method, compared to a state-of-the-art approach based on the factorized Alternating Direction Implicit (ADI) iteration.	algebraic equation;alternating direction implicit method;approximation algorithm;coefficient;compactflash;computable function;computation;estimation theory;experiment;iterative method;krylov subspace;linear algebra;linear equation;lyapunov fractal;numerical analysis;projection method (fluid dynamics);semiconductor industry;solver;stationary process;system of linear equations;truncation	Valeria Simoncini	2007	SIAM J. Scientific Computing	10.1137/06066120X	mathematical optimization;mathematical analysis;calculus;lyapunov equation;mathematics;iterative method;lyapunov exponent;algebra	HPC	83.06496311194306	19.089215318672125	132308
d01d79c0ba95b962db7633760722d44826e5870e	novel numerical methods for solving the time-space fractional diffusion equation in two dimensions	caputo fractional derivative;numerical method;two dimensions;finite element method;finite difference method;matrix transfer technique;lanczos method;80m10;fractional calculus;matrix function;65m06;26a33;fractional diffusion equation;mathbf m lanczos method;65f60;m lanczos method;35r11;34l10;fractional laplacian	In this paper, a time-space fractional diffusion equation in two dimensions (TSFDE2D) with homogeneous Dirichlet boundary conditions is considered. The TSFDE-2D is obtained from the standard diffusion equation by replacing the first-order time derivative with the Caputo fractional derivative tD γ ∗ , γ ∈ (0, 1), and the second-order space derivatives with the fractional Laplacian −(−Δ)α/2, α ∈ (1, 2]. Using the matrix transfer technique proposed by Ilić et al. [M. Ilić, F. Liu, I. Turner, and V. Anh, Fract. Calc. Appl. Anal., 9 (2006), pp. 333–349], the TSFDE-2D is transformed into a time fractional differential system as tD γ ∗u = −KαAα/2u, where A is the approximate matrix representation of (−Δ). Traditional approximation of Aα/2 requires diagonalization of A, which is very time-consuming for large sparse matrices. The novelty of our proposed numerical schemes is that, using either the finite difference method or the Laplace transform to handle the Caputo time fractional derivative, the solution of the TSFDE-2D is written in terms of a matrix function vector product f(A)b at each time step, where b is a suitably defined vector. Depending on the method used to generate the matrix A, the product f(A)b can be approximated using either the preconditioned Lanczos method when A is symmetric or the M-Lanzcos method when A is nonsymmetric, which are powerful techniques for solving large linear systems. We give error bounds for the new methods and illustrate their roles in solving the TSFDE-2D. We also derive the analytical solution of the TSFDE-2D in terms of the Mittag–Leffler function. Finally, numerical results are presented to verify the proposed numerical solution strategies.	approximation algorithm;comstock–needham system;discretization;finite difference method;finite element method;first-order reduction;h2 database engine;krylov subspace;lanczos algorithm;lanczos resampling;laplacian matrix;libreoffice calc;linear system;matrix representation;numerical analysis;numerical method;numerical methods for ordinary differential equations;numerical partial differential equations;preconditioner;samuel j leffler;scheme;sparse matrix;terminate (software);the matrix	Qianqian Yang;Ian W. Turner;Fawang Liu;Milos Ilic	2011	SIAM J. Scientific Computing	10.1137/100800634	matrix function;mathematical optimization;mathematical analysis;two-dimensional space;fractional calculus;numerical analysis;finite difference method;finite element method;calculus;mathematics;algebra	HPC	84.69482453673187	20.48468626527282	134419
57ebcf1cf2f9bee688844238b442dad5197a7738	a novel symmetric skew-hamiltonian isotropic lanczos algorithm for spectral conformal parameterizations	15b57;null space free;65d18;nonequivalence deflation;isotropic lanczos;conformal parameterization;68u05;article;65f15;symmetric skew hamiltonian	In the past decades, many methods for computing conformal mesh parameterizations have been developed in response to demand of numerous applications in the field of geometry processing. Spectral conformal parameterization (SCP) (Mullen et al. in Proceedings of the symposium on geometry processing, SGP '08. Eurographics Association, Aire-la-Ville, Switzerland, pp 1487---1494, 2008) is one of these methods used to compute a quality conformal parameterization based on the spectral techniques. SCP focuses on a generalized eigenvalue problem (GEP) $$L_{C}{\mathbf {f}} = \lambda B{\mathbf {f}}$$ L C f = ? B f whose eigenvector(s) associated with the smallest positive eigenvalue(s) provide the conformal parameterization result. This paper is devoted to studying a novel eigensolver for this GEP. Based on structures of the matrix pair $$(L_{C},B)$$ ( L C , B ) , we show that this GEP can be transformed into a small-scale compressed and deflated standard eigenvalue problem with a symmetric positive definite skew-Hamiltonian operator. We then propose a symmetric skew-Hamiltonian isotropic Lanczos algorithm ( $${\mathbb {S}}$$ S HILA) to solve the reduced problem. Numerical experiments show that our compressed deflating technique can exclude the impact of convergence from the kernel of $$L_{C}$$ L C and transform the original problem to a more robust system. The novel $${\mathbb {S}}$$ S HILA method can effectively avoid the disturbance of duplicate eigenvalues. As a result, based on the spectral model of SCP, our numerical eigensolver can compute the conformal parameterization accurately and efficiently.	hamiltonian (quantum mechanics);lanczos algorithm;stellar classification	Wei-Qiang Huang;Xianfeng Gu;Wen-Wei Lin;Shing-Tung Yau	2014	J. Sci. Comput.	10.1007/s10915-014-9840-2	mathematical optimization;combinatorics;mathematical analysis;calculus;mathematics;algorithm;algebra	Theory	83.58879537234533	23.360037244316235	135340
145bc841357fb1f506eb0d622c1dccda217b85b9	stability of block algorithms with fast level-3 blas	calcul matriciel;linear algebra;numerical stability;iterative refinement;65 numerical analysis;matriz bloque;analisis numerico;block algorithm;lapack;estabilidad numerica;sistema informatico;matrix theory;calcul erreur;computer system;qr factorization;transformation orthogonale;analyse numerique;transformacion ortogonal;error analysis;factorization;matrix computation;numerical analysis;backward error analysis;15 linear and multilinear algebra;factorizacion;mathematical programming;matrice bloc;algebre lineaire;high performance computer;factorisation;calculo error;algebra lineal;block matrix;level 3 blas;matrix multiplication;systeme informatique;stabilite numerique;orthogonal transformation;backward error;matrix calculus;error bound;linear equations;programmation mathematique;programacion matematica;lu factorization;calculo de matrices	Block algorithms are becoming increasingly popular in matrix computations. Since their basic unit of data is a submatrix rather than a scalar, they have a higher level of granularity than point algorithms, and this makes them well suited to high-performance computers. The numerical stability of the block algorithms in the new linear algebra program library LAPACK is investigated here. It is shown that these algorithms have backward error analyses in which the backward error bounds are commensurate with the error bounds for the underlying level-3 BLAS (BLAS3). One implication is that the block algorithms are as stable as the corresponding point algorithms when conventional BLAS3 are used. A second implication is that the use of BLAS3 based on fast matrix multiplication techniques affects the stability only insofar as it increases the constant terms in the normwise backward error bounds. For linear equation solvers employing LU factorization, it is shown that fixed precision iterative refinement helps to mitigate the effect of the larger error constants. Despite the positive results presented here, not all plausible block algorithms are stable; we illustrate this with the example of LU factorization with block triangular factors and describe how to check a block algorithm for stability without doing a full error analysis.	algorithm;blas;computation;computer;error analysis (mathematics);fixed-point arithmetic;iterative method;iterative refinement;lapack;lu decomposition;library (computing);linear algebra;linear equation;matrix multiplication;numerical stability;qr decomposition;refinement (computing);supercomputer	James Demmel;Nicholas J. Higham	1992	ACM Trans. Math. Softw.	10.1145/131766.131769	combinatorics;linear algebra;calculus;mathematics;factorization;algorithm;algebra	HPC	83.03933776342201	21.546228594245026	136067
1b4fd06d0458461140fbcae47a5b8f16f3ad6b24	hierarchical-matrix preconditioners for parabolic optimal control problems	time complexity;parabolic partial differential equation;hierarchical data;hierarchical matrices;control problem;parabolic optimal control problems;iteration method;multilevel methods;multilevel method;lu factorization;sparse matrices;optimal control problem;saddle point	Hierarchical (H)-matrices approximate full or sparse matrices using a hierarchical data sparse format. The corresponding H-matrix arithmetic reduces the time complexity of the approximate H-matrix operators to almost optimal while maintains certain accuracy. In this paper, we represent a scheme to solve the saddle point system arising from the control of parabolic partial differential equations by using H-matrix LUfactors as preconditioners in iterative methods. The experiment shows that the H-matrix preconditioners are effective and speed up the convergence of iterative methods.	approximation algorithm;hierarchical database model;iterative method;optimal control;parabolic antenna;preconditioner;sparse matrix;time complexity	Suely Oliveira;Fang Yang	2007		10.1007/978-3-540-72584-8_29	time complexity;mathematical optimization;combinatorics;discrete mathematics;sparse matrix;lu decomposition;computer science;parabolic partial differential equation;mathematics;iterative method;saddle point;hierarchical database model	AI	84.74124045129423	22.004988411662623	136725
a7164ee12d56d7fb7bf8b9ae1cae0e11d1be0e15	a mixed finite volume scheme for anisotropic diffusion problems on any grid	finite volume scheme;finite volume method;analisis numerico;efficiency;diffusion anisotrope;solucion aproximada;metodo mixto;anisotropic diffusion;analyse numerique;probleme diffusion;methode mixte;eficacia;numerical analysis;estimation erreur;methode volume fini;irregular grid;unstructured grid;difusion anisotropica;mixed method;error estimation;solution approchee;approximate solution;irregular grids;estimacion error;efficacite;anisotropic scattering;metodo volumen finito;error estimate;unstructured grids;anisotropic heterogeneous diffusion problems	HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. A mixed finite volume scheme for anisotropic diffusion problems on any grid J. Droniou, Robert Eymard	anisotropic diffusion;approximation algorithm;converge;finite volume method;gradient	Jérôme Droniou;Robert Eymard	2006	Numerische Mathematik	10.1007/s00211-006-0034-1	mathematical optimization;unstructured grid;numerical analysis;calculus;mathematics;geometry;efficiency;anisotropic diffusion;finite volume method;algorithm;regular grid	ML	88.03576804279903	19.261752594648808	139157
1f25689e099e603f3b458b112861a7230f2d7540	inverse source identification by the modified regularization method on poisson equation		This paper deals with an inverse problem for identifying an unknown source which depends only on one variable in two-dimensional Poisson equation, with the aid of an extra measurement at an internal point. Since this problem is illposed, we obtain the regularization solution by the modified regularization method. Furthermore, we obtain the Hölder-type error estimate between the regularization solution and the exact solution. The numerical results show that the proposed method is stable and the unknown source is recovered very well.		Xiao-Xiao Li;HengZhen Guo;Shi-Min Wan;Fan Yang	2012	J. Applied Mathematics	10.1155/2012/971952	regularization perspectives on support vector machines;backus–gilbert method;regularization;mathematical optimization;mathematical analysis;calculus;mathematics	ML	84.2039098974795	18.535545817538857	139619
9f364e33eb4899173d52ccbe038ece35201ef3a0	local polynomial chaos expansion for linear differential equations with high dimensional random inputs	65d05;uncertainty quantification;domain decomposition;stochastic differential equation;42c05;mathematics and computing generalized ploynomial chaos;41a10;generalized polynomial chaos	In this paper we present a localized polynomial chaos expansion for partial differential equations (PDE) with random inputs. In particular, we focus on time independent linear stochastic problems with high dimensional random inputs, where the traditional polynomial chaos methods, and most of the existing methods, incur prohibitively high simulation cost. The local polynomial chaos method employs a domain decomposition technique to approximate the stochastic solution locally. In each subdomain, a subdomain problem is solved independently and, more importantly, in a much lower dimensional random space. In a postprocesing stage, accurate samples of the original stochastic problems are obtained from the samples of the local solutions by enforcing the correct stochastic structure of the random inputs and the coupling conditions at the interfaces of the subdomains. Overall, the method is able to solve stochastic PDEs in very large dimensions by solving a collection of low dimensional local problems and can be h...	polynomial	Yi Chen;John D. Jakeman;Claude Jeffrey Gittelson;Dongbin Xiu	2015	SIAM J. Scientific Computing	10.1137/140970100	mathematical optimization;mathematical analysis;uncertainty quantification;discrete mathematics;stochastic differential equation;polynomial chaos;stochastic optimization;stochastic partial differential equation;mathematics;domain decomposition methods;statistics	Theory	90.25110729164668	18.679982623584824	139875
e1bb5254c24bd0483a47f31f9c96e4ab3d4027f1	lanczos-type variants of the cocr method for complex nonsymmetric linear systems	physical problems;linear systems;electromagnetic scattering;cocr;complex;complex matrix;calculation;complex nonsymmetric matrices;problems;sistema complejo;linear system;journal;three dimensional;methode calcul;algorithme;conjugate residual;methode gradient;matrice complexe;conjugate gradient;matrice creuse;matrices;systeme complexe;technique calcul;complex system;lanczos type;simulation numerique;nonsymmetric;calculation methods;nonsymmetric linear systems;gradient methods;algorithms;variants;sparse matrix;numerical experiment;systeme lineaire;sparse matrices;65f10;cbicg;digital simulation;physical;matriz compleja;lanczos type variants	Motivated by the celebrated extending applications of the well-established complex Biconjugate Gradient (CBiCG) method to deal with large three-dimensional electromagnetic scattering problems by Pocock and Walker [M.D. Pocock, S.P. Walker, The complex Bi-conjugate Gradient solver applied to large electromagnetic scattering problems, computational costs, and cost scalings, IEEE Trans. Antennas Propagat. 45 (1997) 140-146], three Lanczos-type variants of the recent Conjugate A-Orthogonal Conjugate Residual (COCR) method of Sogabe and Zhang [T. Sogabe, S.-L. Zhang, A COCR method for solving complex symmetric linear systems, J. Comput. Appl. Math. 199 (2007) 297-303] are explored for the solution of complex nonsymmetric linear systems. The first two can be respectively considered as mathematically equivalent but numerically improved popularizing versions of the BiCR and CRS methods for complex systems presented in Sogabeu0027s Ph.D. Dissertation. And the last one is somewhat new and is a stabilized and more smoothly converging variant of the first two in some circumstances. The presented algorithms are with the hope of obtaining smoother and, hopefully, faster convergence behavior in comparison with the CBiCG method as well as its two corresponding variants. This motivation is demonstrated by numerical experiments performed on some selective matrices borrowed from The University of Florida Sparse Matrix Collection by Davis.	lanczos resampling;linear system	Yan-Fei Jing;Ting-Zhu Huang;Yong Zhang;Liang Li;Guang-hui Cheng;Zhi-Gang Ren;Yong Duan;Tomohiro Sogabe;Bruno Carpentieri	2009	J. Comput. Physics	10.1016/j.jcp.2009.05.022	complex systems;combinatorics;sparse matrix;calculus;mathematics;biconjugate gradient stabilized method;linear system;algorithm;algebra	Logic	83.03965085559176	21.313125433852086	140331
2483c58592a7651e8f82db540cf19e9ce219f9f2	reducing floating point error in dot product using the superblock family of algorithms	calcul scientifique;linear algebra;analyse erreur;15xx;analisis numerico;51e24;46cxx;calcul erreur;inner product;65gxx;65k10;68 04;analyse numerique;algorithme;algorithm;error analysis;computacion cientifica;65k05;65g50;numerical analysis;dot product;estimation erreur;error estimation;algebre lineaire;estimacion error;borne inferieure;atlas;calculo error;algebra lineal;floating point;coma flotante;scientific computation;65y20;blas;lower bound;cota inferior;virgule flottante;algoritmo	This paper discusses both the theoretical and statistical errors obtained by various well-known dot products, from the canonical to pairwise algorithms, and introduces a new and more general framework that we have named superblock which subsumes them and permits a practitioner to make trade-offs between computational performance, memory usage, and error behavior. We show that algorithms with lower error bounds tend to behave noticeably better in practice. Unlike many such error-reducing algorithms, superblock requires no additional floating point operations and should be implementable with little to no performance loss, making it suitable for use as a performance-critical building block of a linear algebra kernel.	atlas;algorithm;analysis of algorithms;best, worst and average case;block size (cryptography);blocking (computing);decision problem;library (computing);linear algebra;sorting	Anthony M. Castaldo;R. Clint Whaley;Anthony T. Chronopoulos	2008	SIAM J. Scientific Computing	10.1137/070679946	dot product;linear algebra;calculus;mathematics;algorithm;algebra	Theory	83.38626948449337	26.197556911440905	141332
575b925ae3cbe99f92c1eadaebfb403766aa58c8	adaptive arnoldi-tikhonov regularization for image restoration	linear discrete ill-posed problem;image restoration;tikhonov regularization;arnoldi algorithm;krylov methods	In the framework of the numerical solution of linear systems arising from image restoration, in this paper we present an adaptive approach based on the reordering of the image approximations obtained with the Arnoldi-Tikhonov method. The reordering results in a modified regularization operator, so that the corresponding regularization can be interpreted as problem dependent. Numerical experiments are presented.	algorithmic efficiency;approximation algorithm;arnoldi iteration;circuit restoration;computation;experiment;image restoration;linear system;manifold regularization;matrix regularization;newton's method;numerical method;numerical partial differential equations	Paolo Novati;Maria Rosaria Russo	2013	Numerical Algorithms	10.1007/s11075-013-9712-0	regularization perspectives on support vector machines;backus–gilbert method;mathematical optimization;mathematical analysis;calculus;mathematics	ML	84.08852475885986	19.49863520698238	142099
8d1c951e954550340fcac88c9bec01f39b447724	parameter optimization and reduction of round off error for the gegenbauer reconstruction method	high resolution;piecewise smooth functions;piecewise smooth;round off error;gegenbauer polynomials;gegenbauer reconstruction;parameter optimization;gibbs phenomenon	The Gegenbauer reconstruction method has been successfully implemented to reconstruct piecewise smooth functions by both reducing the effects of the Gibbs phenomenon and maintaining high resolution in its approximation. However, it has been noticed in some applications that the method fails to converge. This paper shows that the lack of convergence results from both poor choices of the parameters associated with the method, as well as numerical round off error. The Gegenbauer polynomials can have very large amplitudes, particularly near the endpoints xe±1, and hence the approximation requires that the corresponding computed Gegenbauer coefficients be extremely small to obtain spectral convergence. As is demonstrated here, numerical round off error interferes with the ability of the computed coefficients to decay properly, and hence affects the method's overall convergence. This paper addresses both parameter optimization and reduction of the round off error for the Gegenbauer reconstruction method, and constructs a viable “black box” method for choosing parameters that guarantee both theoretical and numerical convergence, even at the jump discontinuities. Validation of the Gegenbauer reconstruction method through a-posteriori estimates is also provided.	shadow volume	Anne Gelb	2004	J. Sci. Comput.	10.1023/B:JOMP.0000025933.39334.17	gegenbauer polynomials;gibbs phenomenon;mathematical optimization;mathematical analysis;image resolution;round-off error;calculus;mathematics;quantum mechanics;statistics	Theory	88.92480678777062	18.565348660907105	142453
73a065fee00cfad51102b4d6e18581791750e833	stability of the partitioned inverse method for parallel solution of sparse triangular systems	65 numerical analysis;matrix inverse;general and miscellaneous mathematics computing and information science;parallel algorithm;65f05;right hand side;matrix theory;matrix inversion;mathematical logic;65g05;rounding error analysis;computer architecture;factorization;matrices;15 linear and multilinear algebra;triangular system;inverse method;substitution algorithm;programming 990200 mathematics computers;algorithms;backward error;sparse matrix;logic programs;65f50;parallel processing	Several authors have recently considered a parallel method for solving sparse triangular systems with many right-hand sides. The method employs a partition into sparse factors of the product form of the inverse of the coefficient matrix. It is shown here that while the method can be unstable, stability is guaranteed if a certain scalar that depends on the matrix and the partition is small and that this scalar is small when the matrix is well conditioned. Moreover, when the partition is chosen so that the factors have the same sparsity structure as the coefficient matrix, the backward error matrix can be taken to be sparse. Key words, sparse matrix, triangular system, substitution algorithm, parallel algorithm, rounding error analysis, matrix inverse AMS subject classifications, primary 65F05, 65F50, 65G05	coefficient;control theory;error analysis (mathematics);parallel algorithm;round-off error;rounding;sparse matrix;the matrix;vhdl-ams	Nicholas J. Higham;Alex Pothen	1994	SIAM J. Scientific Computing	10.1137/0915009	cuthill–mckee algorithm;parallel processing;mathematical optimization;hollow matrix;combinatorics;mathematical analysis;discrete mathematics;sparse matrix;lu decomposition;single-entry matrix;band matrix;sparse approximation;mathematics;state-transition matrix;matrix-free methods;block matrix;matrix;algebra	HPC	83.0859565265771	22.589232519125762	143281
1210f54011a3aa7358b474d61ac6cf4e4fdc2706	efficient chebyshev-petrov-galerkin method for solving second-order equations	galerkin method;second order equation;chebyshev polynomial;elliptic equation;chebyshev polynomials;petrov galerkin method;second order elliptic equations;neumann boundary condition;direct solvers;second order elliptic problem;sparse matrices	A new efficient Chebyshev---Petrov---Galerkin (CPG) direct solver is presented for the second order elliptic problems in square domain where the Dirichlet and Neumann boundary conditions are considered. The CPG method is based on the orthogonality property of the kth-derivative of the Chebyshev polynomials. The algorithm differs from other spectral solvers by the high sparsity of the coefficient matrices: the stiffness and mass matrices are reduced to special banded matrices with two and four nonzero diagonals respectively. The efficiency and the spectral accuracy of CPG method have been validated.	galerkin method	Elsayed M. E. Elbarbary	2008	J. Sci. Comput.	10.1007/s10915-007-9161-9	chebyshev polynomials;mathematical optimization;mathematical analysis;chebyshev equation;elliptic rational functions;calculus;mathematics;algebra	Logic	84.24307951084286	20.43542268668373	145219
d9cec9a6cd4a499a8ae45cac64f8bcd5142663e1	preconditioned continuation model predictive control		Model predictive control (MPC) anticipates future events to take appropriate control actions. Nonlinear MPC (NMPC) describes systems with nonlinear models and/or constraints. A Continuation/GMRES Method for NMPC, suggested by T. Ohtsuka in 2004, uses the GMRES iterative algorithm to solve a forward difference approximation Ax = b of the Continuation NMPC (CNMPC) equations on every time step. The coefficient matrix A of the linear system is often illconditioned, resulting in poor GMRES convergence, slowing down the online computation of the control by CNMPC, and reducing control quality. We adopt CNMPC for challenging minimum-time problems, and improve performance by introducing efficient preconditioning, utilizing parallel computing, and substituting MINRES for GMRES. 2015 SIAM Conference on Control and Its Applications This work may not be copied or reproduced in whole or in part for any commercial purpose. Permission to copy in whole or in part without payment of fee is granted for nonprofit educational and research purposes provided that all such whole or partial copies include the following: a notice that such copying is by permission of Mitsubishi Electric Research Laboratories, Inc.; an acknowledgment of the authors and individual contributions to the work; and all applicable portions of the copyright notice. Copying, reproduction, or republishing for any other purpose shall require a license with payment of fee to Mitsubishi Electric Research Laboratories, Inc. All rights reserved. Copyright c © Mitsubishi Electric Research Laboratories, Inc., 2015 201 Broadway, Cambridge, Massachusetts 02139 Preconditioned Continuation Model Predictive Control Andrew Knyazev∗ Yuta Fujii† Alexander Malyshev‡	acknowledgment index;algorithm;approximation;broadway (microprocessor);coefficient;computation;computer graphics;continuation;control system;experiment;finite difference;generalized minimal residual method;graphics processing unit;guidance, navigation, and control;iteration;iterative method;linear system;multi-core processor;multiprocessing;nonlinear programming;nonlinear system;numerical analysis;online and offline;parallel computing;preconditioner;rate of convergence;real-time clock;requirement;series acceleration;solver	Andrew V. Knyazev;Yuta Fujii;Alexander Malyshev	2015		10.1137/1.9781611974072.15	mathematical optimization;control theory;mathematics	AI	85.29191666967964	23.987794556965845	145304
c9e34812bbc2c87967ec1a50fb9c9f1715b50f24	domain decomposition in time for pde-constrained optimization	parallel computing;mathematics computing and information science pde constrained optimization;domain decomposition;preconditioning;pde constrained optimization;mathematics computing and information science;space time methods	PDE-constrained optimization problems have a wide range of applications, but they lead to very large and ill-conditioned linear systems, especially if the problems are time dependent. In this paper we outline an approach for dealing with such problems by decomposing them in time and applying an additive Schwarz preconditioner in time, so that we can take advantage of parallel computers to deal with the very large linear systems. We then illustrate the performance of our method on a variety of problems.	additive schwarz method;central processing unit;computer;condition number;constrained optimization;domain decomposition methods;image scaling;langrisser schwarz;linear system;mathematical optimization;navier–stokes equations;nonlinear system;numerical analysis;parallel computing;preconditioner;scalability;utility functions on indivisible goods	Andrew T. Barker;Martin Stoll	2015	Computer Physics Communications	10.1016/j.cpc.2015.08.025	mathematical optimization;combinatorics;computer science;theoretical computer science;mathematics;preconditioner;domain decomposition methods	HPC	85.33918540968376	22.099357674199503	145460
f6771d09ff8a7173d9725ee2942906293ae9c2e2	adjoint-based iterative method for robust control problems in fluid mechanics	iterative method;65b99;analisis numerico;numerical solution;76;probleme non lineaire;relacion convergencia;navier stokes;taux convergence;robust control;convergence rate;fluid mechanics;nonlinear problems;mecanique fluide;65;analyse numerique;metodo iterativo;iterative methods;numerical analysis;methode iterative;equation navier stokes;control robusta;49;iteration method;commande robuste;mecanica fluido;solution numerique;35;navier stokes equation;ecuacion navier stokes	In this article we study the convergence of an adjoint-based iterative method recently proposed in [T. R. Bewley, R. Temam, and M. Ziane, Phys. D, 138 (2000), pp. 360--392] for the numerical solution of a class of nonlinear robust control problems in fluid mechanics. Under weaker assumptions than those of [T. Tachim Medjo, Numer. Funct. Anal. Optim., 23 (2002), pp. 849--873}], we prove the convergence of the algorithm, and we obtain an estimate of the convergence rate. Numerical solutions of a robust control problem related to data assimilation in oceanography are presented to illustrate the method.	iterative method;robust control	T. Tachim Medjo;Louis Roder Tcheugoué Tébou	2004	SIAM J. Numerical Analysis	10.1137/S0036142902416231	mathematical optimization;mathematical analysis;calculus;mathematics;iterative method;algorithm;algebra;fluid mechanics	Theory	82.91709980480148	18.658219837166687	145658
bc37074914644f2b2da8eaa7d21846b63a3c0f53	spherical harmonic transforms using quadratures and least squares	metodo cuadrado menor;numerical stability;algoritmo paralelo;discretisation;methode moindre carre;quadrature;parallel algorithm;least squares method;fourier transform;spherical harmonic;estabilidad numerica;isometrie;discretization;discretizacion;cuadratura;harmonique spherique;satelite;parallel computation;algorithme parallele;sphere;grid;calculo paralelo;isometria;fourier transformation;satellite;rejilla;least square;transformation fourier;least squares estimate;grille;armonica esferica;esfera;stabilite numerique;isometry;grid computing;calcul parallele;transformacion fourier	Spherical Harmonic Transforms (SHTs) which are essentially Fourier transforms on the sphere are critical in global geopotential and related applications. For analysis purposes, discrete SHTs are difficult to formulate for an optimal discretization of the sphere, especially for applications with requirements in terms of near-isometric grids and special considerations in the polar regions. With the enormous global datasets becoming available from satellite systems, very high degrees and orders are required and the implied computational efforts are very challenging. Among the best known strategies for discrete SHTs are quadratures and least squares. The computational aspects of SHTs and their inverses using both quadrature and least-squares estimation methods are discussed with special emphasis on information conservation and numerical stability. Parallel and grid computations are imperative for a number of geodetic, geophysical and related applications, and these are currently under investigation.	computation;discretization;geodetic datum;imperative programming;isometric projection;least squares;numerical stability;requirement	J. A. Rod Blais;M. A. Soofi	2006		10.1007/11758532_8	fourier transform;mathematical optimization;calculus;discretization;mathematics;geometry;least squares;satellite	HPC	86.09130762066233	19.285784848342505	145851
1ca4e8a86f22c79fda2233dd07785c60d0db0e2e	parallelisation of sparse grids for large scale data analysis	iterative refinement;sparse grids;high dimensionality;keywords numerical linear algebra;predictive modelling;function space;conference paper;data analysis;large scale;parallelism;numerical linear algebra	Sparse Grids (SG), due to Zenger, are the basis for efficient high dimensional approximation and have recently been applied successfully to predictive modelling. They are spanned by a collection of simpler function spaces represented by regular grids. The combination technique prescribes how approximations on simple grids can be combined to approximate the high dimensional functions. It can be improved by iterative refinement. Fitting sparse grids admits the exploitation of parallelism at various stages. The fit can be done entirely by fitting partial models on regular grids. This allows parallelism over the partial grids. In addition, each of the partial grid fits can be parallelised as well, both in the assembly phase where parallelism is done over the data and in the solution stage using traditional parallel solvers for the resulting PDEs. A simple timing model confirms that the most effective methods are obtained when both types of parallelism are used. AMS subject classification. 62H30, 65D10, 68Q22	approximation algorithm;coefficient;curve fitting;extrapolation;fits;finite element method;iteration;iterative method;iterative refinement;multiprocessing;parallel computing;predictive modelling;refinement (computing);sparse grid;sparse matrix;speedup;suicidegirls;vhdl-ams	Jochen Garcke;Markus Hegland;Ole Møller Nielsen	2003		10.1007/3-540-44863-2_67	mathematical optimization;combinatorics;function space;computer science;theoretical computer science;predictive modelling;numerical linear algebra;data analysis	HPC	85.6613523595853	22.904360074361875	145924
d876d22f28316a4c2d60eae94b2c066bc1e2a02a	carp-cg: a robust and efficient parallel solver for linear systems, applied to strongly convection dominated pdes	linear systems;elliptic equations;partial differential equation;kaczmarz;linear system;elliptic equation;conjugate gradient;partial differential equations;convection dominated;elliptic partial differential equation;carp;sparse linear system;carp cg;parallel processing;cgmn;sparse systems	CARP-CG is a conjugate gradient (CG) acceleration of CARP, which was introduced by Gordon and Gordon as a robust block-parallel scheme for sparse linear systems. CARP performs Kaczmarz (KACZ) row projections within the blocks, and the results from the separate blocks are merged by averaging, for each component, its updated values from the different blocks. The averaging operations are equivalent to a sequence of certain KACZ row projections in some superspace (the ‘‘averaging projections”), and so CARP is equivalent to KACZ with cyclic relaxation parameters in that superspace. The CG-acceleration of CARP is based on a generalization of the (sequential) CGMN algorithm of Björck and Elfving, which accelerates KACZ by running it in a double sweep on the equations of a linear system, using a fixed relaxation parameter. CGMN is generalized to allow cyclic relaxation parameters, so the resulting method, called CGMNC, can be applied in the superspace. The averaging projections in the superspace can be done in any order, so CGMNC in the superspace can be implemented in the regular space by using CARP in a double sweep. The resulting algorithm, CARP-CG, is as robust as CARP but converges significantly faster. CARP-CG is compared with restarted GMRES, Bi-CGSTAB and CGS, with and without various preconditioners, on some stiff linear systems derived from convection dominated elliptic partial differential equations. The results indicate that CARP-CG is very robust and its runtime is very competitive with the other methods. A scaled version of CGNR was also tested, and it was as robust as CARP-CG, but slower. 2010 Elsevier B.V. All rights reserved.	algorithm;cg (programming language);common address redundancy protocol;conjugate gradient method;generalized minimal residual method;linear programming relaxation;linear system;preconditioner;solver;sparse matrix	Dan Gordon;Rachel Gordon	2010	Parallel Computing	10.1016/j.parco.2010.05.004	parallel processing;mathematical optimization;mathematical analysis;discrete mathematics;mathematics;linear system;partial differential equation	ML	83.57660119234934	22.782749969109886	146671
6c94d928ce53cd554f05c59e0fd44cdf2fb97709	simulation of a free boundary problem using boundary element method and restarted re-analysis technique	sistema lineal;metodo directo;methode element frontiere;iterative method;analisis numerico;restarted re analysis;probleme frontiere libre;design process;limite libre;optimal design statistics;matematicas aplicadas;boundary element method;mathematiques appliquees;approximation numerique;metodo elemento frontera;free boundary;free boundary problem;optimization method;optimisation forme;matrix inversion;inversion matriz;metodo optimizacion;cost analysis;linear system;aproximacion numerica;analyse numerique;analisis costo;metodo iterativo;analyse cout;large scale;shape optimization;numerical analysis;mathematical programming;methode iterative;algebra lineal numerica;algebre lineaire numerique;methode optimisation;problema frontera libre;plan optimal;inversion matrice;numerical linear algebra;numerical approximation;optimal shape design;escala grande;systeme lineaire;iteration method;applied mathematics;methode directe;programmation mathematique;programacion matematica;large scale problem;direct method;echelle grande	In this work, we deal with the numerical approximation of a free boundary problem reformulated as an optimal shape design one. The boundary element method is used for the approximation of this problem. The iterative method used to solve the discrete problem requires the resolution of intermediate linear systems associated with the successive modification in the design process. In many cases one of the main obstacles is the high computational cost involved in the solution of large-scale problems. To reduce the computational cost, a restarted re-analysis technique is introduced to solve these systems. Numerical examples including comparison results are presented to show the efficiency of the proposed approach. 2005 Elsevier Inc. All rights reserved.	algorithmic efficiency;approximation;boundary element method;computation;constant function;direct method in the calculus of variations;discretization;iteration;iterative method;linear system;mathematical optimization;numerical analysis;numerical method;optimal design;optimization problem;polynomial interpolation;sequential quadratic programming;shape optimization;simulation;succession	A. Chakib;A. Nachaoui	2006	Applied Mathematics and Computation	10.1016/j.amc.2005.11.040	mathematical optimization;method of fundamental solutions;boundary knot method;calculus;mathematics;geometry;iterative method;singular boundary method;algorithm;algebra	Robotics	84.99422440249181	19.699467366333945	147035
9af2d162a0030fb4e56b805f4f717954726e65db	on some versions of the element agglomeration amge method	topology;targets;interpolation;eigenvalue problem;nested cg cycle mg;linear system of equations;element agglomeration;implementation;degree of freedom;general and miscellaneous;eigenvalues;99 general and miscellaneous;finite element;degrees of freedom;adaptive amg;conjugate gradient;agglomeration;matrices;elliptic pde;algorithms;algebraic multigrid;experience base	The present paper deals with element-based algebraic multigrid (AMGe) methods that target linear systems of equations coming from finite element discretizations of elliptic partial differential equations. The individual element information (element matrices and element topology) is the main input to construct the AMG hierarchy. We study a number of variants of the spectral agglomerate AMGe method. The core of the algorithms relies on element agglomeration utilizing the element topology (built recursively from fine to coarse levels). The actual selection of the coarse degrees of freedom is based on solving a large number of local eigenvalue problems. Additionally, we investigate strategies for adaptive AMG as well as multigrid cycles that are more expensive than the V -cycle utilizing simple interpolation matrices and nested conjugate gradient (CG)-based recursive calls between the levels. The presented algorithms are illustrated with an extensive set of experiments based on a matlab implementation of the methods. Copyright q 2008 John Wiley & Sons, Ltd.	algorithm;anisotropic diffusion;chomsky hierarchy;computation;conjugate gradient method;discrete laplace operator;experiment;finite element method;interpolation;john d. wiley;linear algebra;linear system;matlab;mg (editor);multigrid method;nonlinear system;normal mode;numerical analysis;preconditioner;rate of convergence;recursion (computer science);roland gs;stellar classification;unstructured grid	Ilya Lashuk;Panayot S. Vassilevski	2008	Numerical Lin. Alg. with Applic.	10.1002/nla.585	mathematical optimization;discrete mathematics;calculus;mathematics;degrees of freedom;mixed finite element method;algebra	HPC	84.110101663955	22.94357112125889	147608
e2073c679d9a1b0ff56f91732657f2f269b6256f	algebraic multilevel preconditioner for the helmholtz equation in heterogeneous media	calcul scientifique;numerical stability;preconditionnement;systeme commande;sistema control;analisis numerico;heterogeneous media;symmetric indefinite matrix;78a45;metodo subespacio krylov;factorisation incomplete;krylov subspace method;estabilidad numerica;methode sousespace krylov;preconditioning;35j05;matriz simetrica;inverse based pivoting;methode algebrique;analyse numerique;symmetric matrix;computacion cientifica;control system;65n55;numerical analysis;algebraic multilevel preconditioning;algebraic method;three dimensional calculations;65f08;ecuacion helmholtz;86a15;helmholtz equation;equation helmholtz;matrice symetrique;precondicionamiento;stabilite numerique;metodo algebraico;inhomogeneous media;scientific computation;calcul 3 dimensions;calcul 2 dimensions;65f10;graph pivoting;methode multigrille;two dimensional calculations;65n22	An algebraic multilevel (Ml) preconditioner is presented for the Helmholtz equation in heterogeneous media. It is based on a multi-level incomplete LDL factorization and preserves the inherent (complex) symmetry of the Helmholtz equation. The Ml preconditioner incorporates two key components for efficiency and numerical stability: symmetric maximum weight matchings and an inverse–based pivoting strategy. The former increases the block diagonal dominance of the system, whereas the latter controls ‖L−1‖ for numerical stability. When applied recursively, their combined effect yields an algebraic coarsening strategy, similarly to algebraic multigrid methods, even for highly indefinite matrices. The Ml preconditioner is combined with a Krylov subspace method and applied as a “black-box” solver to a series of challenging two and three-dimensional test problems, mainly from geophysical seismic imaging. The numerical results demonstrate the robustness and efficiency of the Ml preconditioner, even at higher frequency regimes.	black box;diagonally dominant matrix;iterative method;krylov subspace;linear algebra;matching (graph theory);multigrid method;multilevel model;numerical analysis;numerical stability;preconditioner;recursion;solver	Matthias Bollhöfer;Marcus J. Grote;Olaf Schenk	2009	SIAM J. Scientific Computing	10.1137/080725702	mathematical optimization;numerical analysis;control system;calculus;mathematics;preconditioner;geometry;helmholtz equation;numerical stability;symmetric matrix;algebra	HPC	83.99206825903258	21.004858065523337	148044
6ceff8a34fb1b4f3a021051bc32e988fab64e53b	constraint-preconditioned inexact newton method for hydraulic simulation of large-scale water distribution networks	journal article;constraint preconditioners water distribution networks hydraulic analysis inexact newton method preconditioned conjugate gradient null space algorithm;mathematical model newton method linear systems null space jacobian matrices convergence optimization	Many sequential mathematical optimization methods and simulation-based heuristics for optimal control and design of water distribution networks rely on a large number of hydraulic simulations. In this paper, we propose an efficient inexact subspace Newton method for hydraulic analysis of water distribution networks. By using sparse and well-conditioned fundamental null space bases, we solve the nonlinear system of hydraulic equations in a lower-dimensional kernel space of the network incidence matrix. In the inexact framework, the Newton steps are determined by solving the Newton equations only approximately using an iterative linear solver. Since large water network models are inherently badly scaled, Jacobian regularization is employed to improve the condition number of these linear systems and guarantee positive definiteness. After presenting a convergence analysis of the regularized inexact Newton method, we use the conjugate-gradient (CG) method to solve the sparse reduced Newton linear systems. Since CG is not effective without good preconditioners, we propose tailored constraint preconditioners that are computationally cheap because they are based only on invariant properties of the null-space linear systems and do not change with flows and pressures. The preconditioners are shown to improve the distribution of eigenvalues of the linear systems and so enable a more efficient use of the CG solver. Since contiguous Newton iterates can have similar solutions, each CG call is warm-started with the solution for a previous Newton iterate to accelerate its convergence rate. Operational network models are used to show the efficacy of the proposed preconditioners and the warm-starting strategy in reducing computational effort.	algorithm;algorithmic efficiency;central processing unit;cluster analysis;computation;computational resource;condition number;conjugate gradient method;convex conjugate;experiment;heuristic (computer science);incidence matrix;iteration;iterative method;jacobian matrix and determinant;kernel (linear algebra);linear logic;linear system;mathematical optimization;network model;newton;newton's method;nonlinear system;numerical linear algebra;numerical method;optimal control;preconditioner;rate of convergence;roughness length;scott continuity;simulation;solver;sparse matrix;user space	Edo Abraham;Ivan Stoianov	2017	IEEE Transactions on Control of Network Systems	10.1109/TCNS.2016.2548418	mathematical optimization;mathematical analysis;calculus;newton's method in optimization;mathematics	ML	85.88826220253611	21.270312041396792	148506
110601cd01f6438cd5f0760f751533d004a7a401	an overlapping additive schwarz preconditioner for interpolation on the unit sphere with spherical radial basis functions	satellite data;interpolation;unit sphere;linear system;scattered data;radial basis function;additive schwarz preconditioner;condition number;numerical experiment	The problem of interpolation of scattered data on the unit sphere has many applications in geodesy and earth science in which the sphere is taken as a model for the earth. Spherical radial basis functions provide a convenient tool to construct the interpolant. However, the underlying linear systems tend to be ill-conditioned. In this paper, we present an additive Schwarz preconditioner to accelerate the solution process. An estimate for the condition number of the preconditioned system will be discussed. Numerical experiments using MAGSAT satellite data will be presented.	additive schwarz method;condition number;experiment;interpolation;langrisser schwarz;linear system;numerical linear algebra;preconditioner;radial (radio);radial basis function;utility functions on indivisible goods	Quoc Thong Le Gia;Thanh Tran	2010	J. Complexity	10.1016/j.jco.2010.06.003	mathematical optimization;radial basis function;mathematical analysis;interpolation;additive schwarz method;machine learning;condition number;control theory;mathematics;geometry;linear system;unit sphere;algorithm;schwarz alternating method;algebra	Robotics	86.06261617226247	19.352218292963542	149248
9d590223f4eed604fb0566227b0974d2ac1297e1	comparison of preconditioned krylov subspace iteration methods for pde-constrained optimization problems	berakningsmatematik;computational mathematics	Saddle point matrices of a special structure arise in optimal control problems. In this paper we consider distributed optimal control for various types of scalar stationary partial differential equations and compare the efficiency of several numerical solution methods. We test the particular case when the arising linear system can be compressed after eliminating the control function. In that case, a system arises in a form which enables application of an efficient block matrix preconditioner that previously has been applied to solve complex-valued systems in real arithmetic. Under certain assumptions the condition number of the so preconditioned matrix is bounded by 2. The numerical and computational efficiency of the method in terms of number of iterations and elapsed time is favourably compared with other published methods.	computation;condition number;constrained optimization;iteration;iterative method;krylov subspace;linear system;mathematical optimization;numerical analysis;numerical partial differential equations;optimal control;preconditioner;stationary process	Owe Axelsson;Shiraz Farouq;Maya Neytcheva	2016	Numerical Algorithms	10.1007/s11075-016-0111-1	computational science;mathematical optimization;discrete mathematics;power iteration;numerical analysis;krylov subspace;generalized minimal residual method;mathematics;algebra	ML	83.64765685507379	22.09163920922571	149568
6cdd2985bf6bf7af831fbb0f60eb4f4034984df2	a multilevel approach for learning from labeled and unlabeled data on graphs	unlabeled data;tratamiento datos;iterative method;evaluation performance;methode empirique;systeme grande taille;performance evaluation;linear system of equations;supervised learning;complexite calcul;metodo descenso;evaluacion prestacion;metodo empirico;empirical method;multigrille;data processing;ecuacion lineal;traitement donnee;sistema n niveles;large scale system;conjugate gradient method;methode algebrique;semi supervised learning;metodo lanczos;similitude;metodo iterativo;transduction;large scale;conjugate gradient;complejidad computacion;lanczos method;systeme n niveaux;computational complexity;metodo gradiente conjugado;methode iterative;graph;algebraic method;methode lanczos;multigrid;similarity;multilevel system;multigrilla;algebraic multigrid;metodo algebraico;similitud;apprentissage supervise;methode gradient conjugue;descent method;linear equation;multilevel;aprendizaje supervisado;equation lineaire;sistema gran escala;methode descente	The recent years have witnessed a surge of interest in graph-based semi-supervised learning methods. The common denominator of these methods is that the data are represented by the nodes of a graph, the edges of which encode the pairwise similarities of the data. Despite the theoretical and empirical success, these methods have one major bottleneck which is the high computational complexity (since they usually need to solve a large-scale linear system of equations). In this paper, we propose a multilevel scheme for speeding up the traditional graph based semi-supervised learning methods. Unlike other accelerating approaches based on pure mathematical derivations (like conjugate gradient descent and Lanczos iteration) or intuitions, our method (1) has explicit physical meanings with some graph intuitions; (2) has guaranteed performance since it is closely related to the algebraic multigrid methods. Finally experimental results are presented to show the effectiveness of our method.		Changshui Zhang;Fei Wang	2010	Pattern Recognition	10.1016/j.patcog.2009.12.025	data processing;computer science;calculus;mathematics;graph;conjugate gradient method;supervised learning;algorithm;multigrid method	Vision	83.52397807694884	21.614612441665766	150755
a6de3d32f453a694cb410424f3adecb4e3aaa7f8	approximate continuation of harmonic functions in geodesy: a spline based least squares approach with regularization	approximate continuation;computacion informatica;b;harmonic functions;regularization;least squares;ciencias basicas y experimentales;earth s potential field;matematicas;b splines;grupo a	This paper is concerned with the approximate reconstruction of the earth’s potential field from geometric and gravimetric data. This is an ill-posed problem involving typically large amounts of data which are to be continued by a harmonic function. The standard approach in geodesy is based on spherical harmonics which are globally supported. Thus, a least squares approach for the data fitting yields a linear system of equations with a fully populated system matrix. This becomes computationally prohibitive for large amounts of data and, therefore, presents the biggest bottleneck for fast and efficient computations. Motivated by the early work [30], we propose in this paper an alternative and pose the harmonicity requirement on the continuation together with the data fitting as a minimization problem for a least squares functional with regularization involving the Laplacian. This approach enables the use of locally supported functions in the reconstruction for which we employ tensor products of cubic splines. The linear system resulting from the weighted least squares approach is therefore sparsely populated which allows for iterative solvers of complexity proportional to the total number of unknowns. We extensively study the choice of the regularization parameter balancing the data fit and the harmonicity requirement for both synthetic as well as earth potential data. We compare the results with discretizations using finite differences and finite elements for solving Laplace’s equation.	airborne ranger;approximation algorithm;b-spline;coefficient;computation;continuation;cubic function;cuboid;curve fitting;discretization;experiment;finite difference;finite element method;geodetic datum;iterative method;least squares;linear least squares (mathematics);linear system;lithosphere;matrix regularization;microsoft outlook for mac;numerical analysis;population;requirement;simulation;spline (mathematics);synthetic data;synthetic intelligence;system of linear equations;undulation of the geoid;wavelet;weight function;well-posed problem	Gabriela Jager;Angela Kunoth;Wolf-Dieter Schuh	2013	J. Computational Applied Mathematics	10.1016/j.cam.2012.07.007	b-spline;regularization;mathematical optimization;harmonic function;mathematical analysis;calculus;mathematics;geometry;non-linear least squares;least squares;statistics	ML	86.1140150800375	19.19374138141716	151468
889182f32c2be4a8630713530a1a4cd4fa8df88f	a practical factorization of a schur complement for pde-constrained distributed optimal control	full space method;poisson operator;range space method;schur complement;pde constrained optimization;65n55;distributed optimal control;feti;65f50;65f10;65n22	A distributed optimal control problem with the constraint of a linear elliptic partial differential equation is considered. A necessary optimality condition for this problem forms a saddle point system, the efficient and accurate solution of which is crucial. A new factorization of the Schur complement for such a system is proposed and its characteristics discussed. The factorization introduces two complex factors that are complex conjugate to each other. The proposed solution methodology involves the application of a parallel linear domain decomposition solver—FETI-DPH— for the solution of the subproblems with the complex factors. Numerical properties of FETI-DPH in this context are demonstrated, including numerical and parallel scalability and regularization dependence. The new factorization can be used to solve Schur complement systems arising in both range-space and full-space formulations. In both cases, numerical results indicate that the complex factorization is promising. Especially, in the full-space method with the new factorization, the number of iterations required for convergence is independent of regularization parameter values.	3d printing;approximation algorithm;condition number;digital planar holography;domain decomposition methods;extensibility;feti;iteration;iterative method;krylov subspace;matrix regularization;numerical analysis;numerical linear algebra;optimal control;preconditioner;scalability;solver	Youngsoo Choi;Charbel Farhat;Walter Murray;Michael A. Saunders	2015	J. Sci. Comput.	10.1007/s10915-014-9976-0	dixon's factorization method;mathematical optimization;combinatorics;mathematical analysis;schur complement method;quadratic sieve;incomplete lu factorization;mathematics;factorization of polynomials;schur complement;feti;algebra	HPC	85.30686866578112	22.06454669652466	151499
5b65aacd7e16a016572b649c6cbc44deb2c032a3	newton's iteration for inversion of cauchy-like and other structured matrices	efficiency;structured matrices;input output;iterative methods;computer calculations;algorithms;cauchy problem;mathematics computers information science management law miscellaneous	We specify some initial assumptions that guarantee rapid refinement of a rough initial approximation to the inverse of a Cauchy-like matrix, by means of our new modification of Newton's iteration, where the input, output, and all the auxiliary matrices are represented with their short generators defined by the associated scaling operators. The computations are performed fast since they are confined to operations with short generators of the given and computed matrices. Because of the known correlations among various structured matrices, the algorithm is immediately extended to rapid refinement of rough initial approximations to the inverses of Vandermonde-like, Chebyshev?Vandermonde-like, and Toeplitz-like matrices, where again the computations are confined to operations with short generators of the involved matrices.	iteration;newton;newton's method	Victor Y. Pan;Ailong Zheng;Xiaohan Huang;Olen Dias	1997	J. Complexity	10.1006/jcom.1997.0431	matrix analysis;input/output;cauchy problem;mathematical optimization;mathematical analysis;discrete mathematics;theoretical computer science;mathematics;iterative method;efficiency;algorithm;algebra	ML	84.64774396622153	20.5994803319304	152726
717627e40963bbdb2dad8542b61c33ace60b09ee	fast sweeping methods for eikonal equations on triangular meshes	ecuacion hamilton jacobi;iterative method;analisis numerico;convergence;46e25;complexite calcul;sorting;14e20;hamilton jacobi equation;relacion orden;primary;temps lineaire;20c20;ordering;triangular mesh;tria;tiempo lineal;maillage;satisfiability;reference point;analyse numerique;metodo iterativo;algorithme;algorithm;viscosity solution;relation ordre;convergencia;complejidad computacion;eikonal equation;iteraccion;numerical analysis;celdarada;computational complexity;methode iterative;equation hamilton jacobi;54c40;secondary;linear time;triage;hamilton jacobi;iteration;unstructured mesh;grid pattern;fast sweeping;iteration method;viscosity solution primary;eikonal equations;algoritmo	The original fast sweeping method, which is an efficient iterative method for stationary Hamilton–Jacobi equations, relies on natural ordering provided by a rectangular mesh. We propose novel ordering strategies so that the fast sweeping method can be extended efficiently and easily to any unstructured mesh. To that end we introduce multiple reference points and order all the nodes according to their lp-metrics to those reference points. We show that these orderings satisfy the two most important properties underlying the fast sweeping method: (1) these orderings can cover all directions of information propagating efficiently; (2) any characteristic can be decomposed into a finite number of pieces and each piece can be covered by one of the orderings. We prove the convergence of the new algorithm. The computational complexity of the algorithm is nearly optimal in the sense that the total computational cost consists of O(M) flops for iteration steps and O(M logM) flops for sorting at the predetermined initialization step which can be efficiently optimized by adopting a linear time sorting method, where M is the total number of mesh points. Extensive numerical examples demonstrate that the new algorithm converges in a finite number of iterations independent of mesh size.	algorithm;algorithmic efficiency;computation;computational complexity theory;flops;fast sweeping method;iteration;iterative method;jacobi method;numerical analysis;sorting;stationary process;time complexity;triangular matrix;triangulated irregular network;unstructured grid	Jianliang Qian;Yong-Tao Zhang;Hongkai Zhao	2007	SIAM J. Numerical Analysis	10.1137/050627083	mathematical optimization;combinatorics;mathematical analysis;calculus;mathematics;geometry;iterative method;algorithm	Theory	85.57604469704752	19.985120160917493	153324
da7c786a67b558b9265e3356b54a19faff395e3f	a class of asynchronous block methods for nonlinear systems of equations	numerical solution;efficiency;nonlinear problems;factorization;matrices;algorithms;block method;nonlinear system;parallel processing;mathematics computers information science management law miscellaneous	The authors investigate nonlinear systems of equation represented by F(X) = 0 (1.1) where F = (f{sub 1}, ..., f{sub n}){sup T}, is a nonlinear operator from R{sup n} into itself, and X = (x{sub 1},...,x{sub n}){sup T}. To design a parallel algorithm for (1.1), we partition F and x as follows: F = (F{sup T}{sub 1},...,F{sup T}{sub 1}){sup T}, X = (X{sup T}{sub 1},...,X{sup T}{sub 1}){sup T} where F{sub 1} = (f{sub il},...,f{sub ini}){sup T}, X{sub i} = (x{sub il},...,x{sub ini}){sup T}, i = 1,...,l. Let S{sub i} = (il,...,in{sub i}), then US{sub i} = (1,...,n), Si {intersection} S{sub j} + {var_phi}, i = j, i, j = 1,...,l.		Jianjun Xu;Houghui Wan	1995			mathematical optimization;theoretical computer science;mathematics;algorithm	EDA	84.24776572985134	21.9048077298131	153607
37af64acc6eee6b5572173ce183da06b2473a3fb	software for nonlinear partial differential equations	computer program;partial differential equation;time dependent;general and miscellaneous mathematics computing and information science;numerical solution;ordinary differential equation;p codes;efficiency;nonlinear partial differential equation;differential equation;nonlinear pde;nonlinear problems;mathematical logic 990200 mathematics computers;finite difference method;spatial variability;iterative methods;time dependence;computer calculations;nonlinear problem;computer codes;nonlinear equation;algol;algorithms;n80600 mathematics computers;method of lines;fortran;differential equations;iteration method;programming;differential equations numerical solution;time integration	The numerical solution of physically realistic nonlinear partial differential equations (PDEs) is a complicated and highly problem dependent process which usually requires the scientist to undertake the difficult and time consuming task of developing his own computer program to solve his problem. This paper presents a useful and reliable software interface which can ehminate much of the expensive and time consuming effort involved in the solution of nonlinear PDEs. The software interface provides centered differencing in the spatial variable for time dependent nonlinear PDEs, giving a semidlscrete system of nonhnear ordinary differential equations (ODEs) which are then solved using one of the recently developed robust ODE integrators. Besides being portable, efficient, and easy to use, the software interface along with an ODE integrator will discretize the problem, select the time step and order, solve the nonlinear equations (checking for convergence, etc.), and maintain a user specified time integration accuracy, all automatically and reliably. Physically realistic examples are given to illustrate the use and capability of the software.	autoregressive integrated moving average;computer program;discretization;nonlinear system;numerical methods for ordinary differential equations;numerical partial differential equations	Richard F. Sincovec;Niel K. Madsen	1975	ACM Trans. Math. Softw.	10.1145/355644.355649	mathematical optimization;mathematical analysis;nonlinear system;theoretical computer science;mathematics;iterative method;differential equation	Graphics	89.70807485855033	21.76952855591534	153807
0ca7c9bbc3775e1f981b67fb85798fc8d67b1586	a fast algorithm based on partial basic solution vectors domain decomposition method for scattering analysis of electrically large cylinders	complexite;electromagnetic scattering;metodo vectorial;partial basic solution vectors;metodo descomposicion;complejidad;methode decomposition;calculation;complexity;methode calcul;cylinders;algorithme;iterative methods;decomposition method;technique calcul;computational complexity;methode iterative;fast algorithm;domain decomposition method;vector method;calculation methods;parallel computer;algorithms;methode vectorielle;iteration method;cylindre	An efficient domain decomposition method (DDM) based on the partial basic solution vectors (PBSV) is presented for the electromagnetic scattering analysis of electrically large two-dimensional objects. The original computation domain is partitioned into nonoverlapping subdomains. The PBSV of each subdomain are evaluated independently. Then the field on the interfaces between subdomains can easily be obtained by an iterative vector summation procedure, and the final solution on each subdomain is solved independently and efficiently. To improve the algorithm further, two techniques, expanding the PBSV by roof-top basis functions and an under relaxed iteration method, are also studied. Compared with the traditional DDM, the proposed method can greatly reduce the computational complexity and the memory requirement; moreover, it can be implemented totally independently on both sequential and parallel computational platform, which is distinct from the others. The validity of this algorithm is verified by numerical examples. 2006 Elsevier Inc. All rights reserved.	algorithm;basis function;computation;computational complexity theory;distributed data management architecture;domain decomposition methods;iteration;numerical analysis;scheme	Xiang An;Zhi-Qing Lü	2006	J. Comput. Physics	10.1016/j.jcp.2006.07.002	mathematical optimization;calculus;mathematics;domain decomposition methods;iterative method;algorithm	EDA	84.63032796947097	21.540717520175313	153824
4108bd016b96adb7ef494ab6f0ba3cff584b4412	descent methods for elastic body simulation on the gpu	hyperelasticity;gpu acceleration;the chebyshev method;nonlinear optimization;jacobi preconditioning	We show that many existing elastic body simulation approaches can be interpreted as descent methods, under a nonlinear optimization framework derived from implicit time integration. The key question is how to find an effective descent direction with a low computational cost. Based on this concept, we propose a new gradient descent method using Jacobi preconditioning and Chebyshev acceleration. The convergence rate of this method is comparable to that of L-BFGS or nonlinear conjugate gradient. But unlike other methods, it requires no dot product operation, making it suitable for GPU implementation. To further improve its convergence and performance, we develop a series of step length adjustment, initialization, and invertible model conversion techniques, all of which are compatible with GPU acceleration. Our experiment shows that the resulting simulator is simple, fast, scalable, memory-efficient, and robust against very large time steps and deformations. It can correctly simulate the deformation behaviors of many elastic materials, as long as their energy functions are second-order differentiable and their Hessian matrices can be quickly evaluated. For additional speedups, the method can also serve as a complement to other techniques, such as multi-grid.	algorithmic efficiency;broyden–fletcher–goldfarb–shanno algorithm;computation;descent direction;gauss–seidel method;gradient descent;graphics processing unit;grid computing;hessian;jacobi method;mathematical optimization;nonlinear conjugate gradient method;nonlinear programming;nonlinear system;numerical methods for ordinary differential equations;optimization problem;preconditioner;rate of convergence;scalability;series acceleration;simulation;singular value decomposition	Huamin Wang;Yin Yang	2016	ACM Trans. Graph.	10.1145/2980179.2980236	gradient descent;mathematical optimization;nonlinear programming;theoretical computer science;hyperelastic material;mathematics;algorithm	Graphics	87.01894501555965	20.91531793850072	154490
5c8c55ecfa5850f18ef3637c6070a23c862d27f0	"""correction to """"extended array manifolds: functions of array manifolds"""""""	manifolds;geometry;manifolds geometry direction of arrival estimation parallel processing;parallel processing;direction of arrival estimation	The author presents revisions to various equations and formulas from the above-named article.		Athanassios Manikas	2011	IEEE Trans. Signal Processing	10.1109/TSP.2011.2162152	riemannian geometry;parallel processing;mathematical optimization;combinatorics;manifold;computer science;mathematics;geometry	Embedded	85.29009556067702	23.13721263586324	154986
ab543fac0fa06261a1a0b763f23b0e8e58b2bf10	block gram--schmidt orthogonalization	calcul scientifique;analisis numerico;orthogonal matrix;producto matriz;matriz ortogonal;qr factorization;analyse numerique;blocked algorithm;experimental result;algorithme;algorithm;computacion cientifica;65g50;numerical analysis;matrice orthogonale;algebra lineal numerica;65f25;algebre lineaire numerique;orthogonalization;resultado experimental;numerical linear algebra;scientific computation;58a25;resultat experimental;produit matrice;65y20;gram schmidt algorithm;matrix product;algoritmo	The classical Gram-Schmidt algorithm for computing the QR factorization of a matrix $X$ requires at least one pass over the current orthogonalized matrix $Q$ as each column of $X$ is added to the factorization. When $Q$ becomes so large that it must be maintained on a backing store, each pass involves the costly transfer of data from the backing store to main memory. However, if one orthogonalizes the columns of $X$ in blocks of $m$ columns, the number of passes is reduced by a factor of $1/m$. Moreover, matrix-vector products are converted into matrix-matrix products, allowing level-3 BLAS cache performance. In this paper we derive such a block algorithm and give some experimental results that suggest it can be quite effective for large scale problems, even when the matrix $X$ is rank degenerate.	schmidt decomposition	G. W. Stewart	2008	SIAM J. Scientific Computing	10.1137/070682563	orthogonalization;orthogonal matrix;numerical analysis;matrix multiplication;calculus;mathematics;numerical linear algebra;qr decomposition;algorithm;algebra	HPC	83.94450699813027	23.992747899721504	155585
27150f3360fe44bd23382f25497c55044c1154da	a fast spectral method for the boltzmann collision operator with general collision kernels		We propose a simple fast spectral method for the Boltzmann collision operator with general collision kernels. In contrast to the direct spectral method [17, 28] which requires O(N) memory to store precomputed weights and has O(N) numerical complexity, the new method has complexity O(MN logN), where N is the number of discretization points in each of the three velocity dimensions and M is the total number of discretization points on the sphere and M N. Furthermore, it requires no precomputation for the variable hard sphere (VHS) model and only O(MN) memory to store precomputed functions for more general collision kernels. Although a faster spectral method is available [23] (with complexity O(MN logN)), it works only for hard sphere molecules, thus limiting its use for practical problems. Our new method, on the other hand, can apply to arbitrary collision kernels. A series of numerical tests is performed to illustrate the efficiency and accuracy of the proposed method.	adaptive quadrature;algorithm;angularjs;benchmark (computing);computational engineering;direct method in the calculus of variations;direct simulation monte carlo;discretization;experiment;holographic principle;kernel (operating system);numerical analysis;precomputation;spectral method;velocity (software development);von neumann architecture	Irene M. Gamba;Jeffrey R. Haack;Cory D. Hauck;Jingwei Hu	2017	SIAM J. Scientific Computing	10.1137/16M1096001	mathematical optimization;mathematical analysis;discrete mathematics;theoretical computer science;mathematics	Robotics	84.09858545697936	24.65320292701927	157867
30cf4189b82db48ca1f1bd812015564ff0a87a62	a projection-regularized newton method for nonlinear ill-posed problems and its application to parameter identification problems with finite element discretization	equation derivee partielle;equation non lineaire;iterative method;discretisation;ecuacion no lineal;partial differential equation;ecuacion derivada parcial;problema mal planteado;regularisation;convergence;nonlinear ill posed problems;methode element fini;65j15;metodo elemento finito;identification parametre;methode newton;convergence rates;stopping rule;parametre;probleme mal pose;discretization;discretizacion;finite element method;parameter identification;finite element;nonlinear ill posed problem;65j20;regularization;regla parada;metodo iterativo;47h17;parametro;parameter;convergencia;35r30;estimation erreur;linearisation;linearizacion;error estimation;methode iterative;identification;ill posed problem;estimacion error;well posed problem;non linearite;projection error;no linealidad;identificacion;linearization;nonlinearity;metodo newton;newton method;regularizacion;iterative regularization methods;non linear equation;erreur projection;problema bien planteado;probleme bien pose;regle arret	This paper is concerned with nonlinear ill-posed operator equations F(a)=y (e.g., parameter identification problems) and their approximate solution by a Newton-type method that is regularized by projecting the linearized equation in each Newton step onto a finite-dimensional space (e.g., a finite element space) and by stopping the Newton iteration at an appropriate index. We prove convergence as the iteration index n goes to infinity in the noise-free case and convergence as the data noise level $\delta$ goes to zero in the case of noisy data, as well as convergence rates under certain additional conditions.	discretization;newton's method;nonlinear programming	Barbara Kaltenbacher	2000	SIAM J. Numerical Analysis	10.1137/S0036142998347322	mathematical optimization;mathematical analysis;nonlinear system;finite element method;calculus;discretization;mathematics;parameter;statistics	Theory	83.84793413134541	19.018520079645608	159076
1cc8b3a2609f7ebc31d0407cedd1ee77c5a8f0b7	reducing the effects of noise in image reconstruction	metodo espectral;ruido aleatorio;gegenbauer polynomial;high resolution;fourier reconstruction;polinomio gegenbauer;numerical method;bruit aleatoire;edge detection;fonction reguliere;spectral data;image bruitee;phenomene gibbs;deteccion contorno;imagen sonora;detection contour;reconstruction image;random noise;haute resolution;caracteristica espectral;metodo numerico;reconstruccion imagen;polynome gegenbauer;fourier transformation;image reconstruction;noisy image;transformation fourier;alta resolucion;spectral method;gegenbauer polynomials;methode spectrale;funcion regular;caracteristique spectrale;methode numerique;gibbs phenomenon;smooth function;noise;transformacion fourier	Fourier spectral methods have proven to be powerful tools that are frequently employed in image reconstruction. However, since images can be typically viewed as piecewise smooth functions, the Gibbs phenomenon often hinders accurate reconstruction. Recently, numerical edge detection and reconstruction methods have been developed that effectively reduce the Gibbs oscillations while maintaining high resolution accuracy at the edges.While the Gibbs phenomenon is a standard obstacle for the recovery of all piecewise smooth functions, in many image reconstruction problems there is the additional impediment of random noise existing within the spectral data. This paper addresses the issue of noise in image reconstruction and its effects on the ability to locate the edges and recover the image. The resulting numerical method not only recovers piecewise smooth functions with very high accuracy, but it is also robust in the presence of noise.	edge detection;high-resolution scheme;iterative reconstruction;neural oscillation;noise (electronics);numerical method;spectral method	Rick Archibald;Anne Gelb	2002	J. Sci. Comput.	10.1023/A:1015148530452	gegenbauer polynomials;iterative reconstruction;gibbs phenomenon;fourier transform;smoothness;mathematical analysis;edge detection;image resolution;numerical analysis;noise;calculus;mathematics;geometry;spectral method	Vision	89.15267535278828	18.713397602613533	159090
b05230409e915043f32f3c2cc3a11313bf602d65	reconstruction of piecewise smooth functions from non-uniform grid point data	oscillations;non uniform grid point approximation;65t40;piecewise smooth functions;series expansion;piecewise smooth;orthogonal polynomial;inner product;42c20;65d15;function approximation;orthogonal polynomials;classical orthogonal polynomials;gegenbauer reconstruction;reprojection;exponential convergence;gibbs phenomenon;33c45	Spectral series expansions of piecewise smooth functions are known to yield poor results, with spurious oscillations forming near the jump discontinuities and reduced convergence throughout the interval of approximation. The spectral reprojection method, most notably the Gegenbauer reconstruction method, can restore exponential convergence to piecewise smooth function approximations from their (pseudo-)spectral coefficients. Difficulties may arise due to numerical robustness and ill-conditioning of the reprojection basis polynomials, however. This paper considers non-classical orthogonal polynomials as reprojection bases for a general order (finite or spectral) reconstruction of piecewise smooth functions. Furthermore, when the given data are discrete grid point values, the reprojection polynomials are constructed to be orthogonal in the discrete sense, rather than by the usual continuous inner product. No calculation of optimal quadrature points is therefore needed. This adaptation suggests a method to approximate piecewise smooth functions from discrete non-uniform data, and results in a one-dimensional approximation that is accurate and numerically robust.	approximation algorithm;coefficient;condition number;control theory;converge;domain decomposition methods;map projection;neural oscillation;numerical analysis;numerical method;penalty method;pixel;polynomial;polynomial expansion;rate of convergence;requirement;robustness (computer science);runge's phenomenon;runge–kutta methods;spectral method;time complexity;trapezoidal rule;virtual reality headset	Anne Gelb	2007	J. Sci. Comput.	10.1007/s10915-006-9099-3	mathematical optimization;mathematical analysis;discrete mathematics;mathematics;orthogonal polynomials;spectral element method	Theory	88.79869557425971	18.473705397891752	159305
dcf20428a6105b69628ce83e9e060121a91a1c5f	scattered data modelling using radial basis functions	scattered data;radial basis function	Radial basis functions are traditional and powerful tools for multivariate interpolation from scattered data. This self-contained talk surveys both theoretical and practical aspects of scattered data fitting by radial basis functions. To this end, basic features of the radial basis function interpolation scheme are first reviewed, such as well-posedness, numerical stability and approximation orders, before selected computational aspects are addressed. Special attention is placed on multiresolution modelling. The utility of radial basis functions is finally supported by using real-world examples from terrain modelling and hierarchical surface visualization.	approximation;computation;curve fitting;data modeling;multiresolution analysis;multivariate interpolation;numerical analysis;numerical stability;radial (radio);radial basis function;well-posed problem	Armin Iske	2002		10.1007/978-3-662-04388-2_9	voronoi diagram;meshfree methods;mathematical optimization;interpolation;multivariate interpolation;thin plate spline;least squares;remainder;delaunay triangulation;mathematics	Visualization	86.40879703230468	18.762259193014792	159678
b2aa2b8934893c56f7faa216f7470a1c6b74905d	a fast contour-integral eigensolver for non-hermitian matrices		We present a fast contour-integral eigensolver for finding selected or all the eigenpairs of a non-Hermitian matrix based on a series of analytical and computational techniques, such as the analysis of filter functions, quick and reliable eigenvalue count via low-accuracy matrix approximations, and fast shifted factorization update. The quality of some quadrature rules for approximating a relevant contour integral is analyzed. We show that a filter function based on the Trapezoidal rule has nearly optimal decay in the complex plane away from the unit circle (as the mapped contour), and is superior to the Gauss-Legendre rule. The eigensolver needs to count the eigenvalues inside a contour. We justify the feasibility of using low-accuracy matrix approximations for the quick and reliable count. Both deterministic and probabilistic studies are given. With high probabilities, the matrix approximations give counts very close to the exact one. Our eigensolver is built upon an accelerated FEAST algorithm. Both the eigenvalue count and the FEAST eigenvalue solution need to solve linear systems with multiple shifts and right-hand sides. For this purpose and also to conveniently control the approximation accuracy, we use a type of rank structured approximations and show how to update the factorization for varying shifts. The eigensolver may be used to find a large number of eigenvalues, where a search region is then partitioned into subregions. We give an optimal threshold for the number of eigenvalues inside each bottom level subregion so as to minimize the complexity, which is O(rn2)+O(r2n) to find all the eigenpairs of an order-n matrix with maximum off-diagonal rank or numerical rank r. Numerical tests demonstrate the efficiency and accuracy and confirm the benefit of our acceleration techniques.	computation;contour line;density matrix;eigenvalue algorithm;gauss–legendre algorithm;high-speed serial interface;linear system;low-rank approximation;numerical analysis;numerical integration;parallel programming model;scalability;the matrix;trapezoidal rule	Xin Ye;Jianlin Xia;Raymond H. Chan;Stephen Cauley;Venkataramanan Balakrishnan	2017	SIAM J. Matrix Analysis Applications	10.1137/16M1086601	mathematical optimization;eigenvalues and eigenvectors;complex plane;hermitian matrix;methods of contour integration;mathematics;matrix (mathematics);unit circle;trapezoidal rule;gaussian quadrature	ML	83.72526748194612	24.479405902976772	159977
82b4fc3b1adda464b11f7ba515656dcdbde068a3	simple and efficient algorithms to get a finer resolution in a stochastic discrete time agent-based simulation		A conceptually simple approach on adjusting the time step to a finer one is proposed and an efficient two-level sampling algorithm for it is presented. Our approach enables the modelers to divide each original time step into any integral number of equally spaced sub-steps, and the original model and the finer one can be formally shown to be equivalent with some basic assumptions.		Chia-Tung Kuo;Da-Wei Wang;Tsan-sheng Hsu	2012		10.1007/978-3-319-03581-9_7	mathematical optimization;simulation;computer science;theoretical computer science	Theory	92.22216236652827	18.983379650137824	160193
fe9b31f959dc81efd09281cce9901174a78f620a	symplectic method based on generating function for receding horizon control of linear time-varying systems	symplectic method;hamiltonian systems;receding horizon control;linear time varying systems;generating functions	A novel method for solving the linear receding-horizon control (RHC) problem with time-varying coefficients is proposed based on a generating function and the standard symplectic form of Hamiltonian systems. In contrast to other methods used to solve the linear RHC problem, the generating function is utilized to avoid directly online integrating the differential Riccati equation (DRE). Solutions to the DRE at discrete time points have been obtained by applying the generating function at each computation step. The derivation of the coefficient includes calculating the state transition matrices of the linear Hamiltonian system using the Magnus method, which preserves the symplectic structure of the Hamiltonian system. Numerical simulations of spacecraft rendezvous demonstrate that the proposed symplectic method obtains highly precise results for relatively long discretization sizes, and then yields computational efficiency improvements of one to two orders of magnitude compared with conventional backward sweep methods and the Legendre pseudospectral methods.	symplectic integrator;time complexity	Haijun Peng;Shujun Tan;Qiang Gao;Zhi-Gang Wu	2017	Eur. J. Control	10.1016/j.ejcon.2016.08.002	hamiltonian system;generating function;mathematical optimization;generating function;mathematical analysis;control theory;mathematics;symplectic integrator	Robotics	87.87906969805822	20.98483963844012	161107
833d2e3bd6a40d97029616ae84b9e73b05fe2976	computation of control for linear approximately controllable system using weighted tikhonov regularization		Computing steering control for an approximately controllable linear system for a given target state is an ill-posed problem. We use a weighted Tikhonov regularization method and compute the regularized control. It is proved that the target state corresponding to the regularized control is close to the actual state to be attained. We also obtained error estimates and convergence rates involved in the regularization procedure using both the a priori and a posteriori parameter choice rule. Theory is substantiated with numerical experiments. © 2017 Elsevier Inc. All rights reserved.	computation;experiment;linear system;matrix regularization;mean squared error;newton's method;numerical analysis;well-posed problem	Ravinder Katta;G. D. Reddy;Nagarajan Sukavanam	2018	Applied Mathematics and Computation	10.1016/j.amc.2017.08.012	mathematics;mathematical analysis;mathematical optimization;regularization perspectives on support vector machines;computation;tikhonov regularization;regularization (mathematics);linear system;backus–gilbert method	ML	83.83317892698079	19.096358757661616	161353
2eeb62a6d8274fa148a4cd3aa1e89d405b12d517	modular arithmetic for linear algebra computations in the real field	linear algebra;computacion informatica;ciencias basicas y experimentales;modular arithmetic;numerical computation;space complexity;grupo a;computer algebra	The aim of this work is to decrease the bit precision required in computations without a ecting the precision of the answer whether this is computed exactly or within some tolerance By precision we understand the number of bits in the binary representation of the values involved in the computation hence a smaller precision requirement leads to a smaller complexity We achieve this by combining the customary numerical techniques of rounding the least signi cant bits with the algebraic technique of reduction modulo an integer which we extend to the reduction modulo a positive number In particular we show that if the sum of several numbers has small magnitude relative to the magnitude of the summands then the precision used in the computation of this sum can be decreased without a ecting the precision of the answer Furthermore if the magnitude of the inner product of two vectors is small and if one of them is lled with short binary numbers then again we may decrease the precision of the computation The method is applied to the iterative improvement algorithm for a linear system of equations whose coe cients are represented by short binary numbers as well as to the solution of PDEs by means of multigrid methods Some results of numerical experiments are presented to demonstrate the power of the method	algorithm;binary number;computation;experiment;iterative method;linear algebra;linear system;modulo operation;multigrid method;numerical analysis;rounding;system of linear equations	Ioannis Z. Emiris;Victor Y. Pan;Yanqiang Yu	1998	J. Symb. Comput.	10.1006/jsco.1998.0201	modular arithmetic;combinatorics;discrete mathematics;linear algebra;mathematics;extended precision;dspace;algebra	Logic	83.47916883920598	26.137381064330768	162079
8d0d1671e4d805bb12d7013e0e79024dd0348264	a fast method for a generalized nonlocal elastic model	riesz potential operator;fast fourier transform;circulant preconditioners;期刊论文;toeplitz systems;fractional differential equation	We develop a numerical method for a generalized nonlocal elastic model, which is expressed as a composition of a Riesz potential operator with a fractional differential operator, by composing a collocation method with a finite difference discretization.By carefully exploring the structure of the coefficient matrix of the numerical method, we develop a preconditioned fast Krylov subspace method, which reduces the computations to ( N log ? N ) per iteration and the memory to O ( N ) . The use of the preconditioner significantly reduces the number of iterations, and the preconditioner can be inverted in O ( N log ? N ) computations. Numerical results show the utility of the method.	aharonov–bohm effect	Ning Du;Hong Wang;Che Wang	2015	J. Comput. Physics	10.1016/j.jcp.2015.05.008	fast fourier transform;mathematical optimization;mathematical analysis;discrete mathematics;mathematics;algorithm	Theory	85.06852998099998	20.372517712969316	162168
9551dca71ecfde9932525528f4d7f2b5d8e7ea72	transient circuit simulation for differential algebraic systems using matrix exponential		Transient simulation becomes a bottleneck for modern IC designs due to large numbers of transistors, interconnects and tight design margins. For modified nodal analysis (MNA) formulation, we could have differential algebraic equations (DAEs) which consist ordinary differential equations (ODEs) and algebraic equations. Study of solving DAEs with conventional multi-step integration methods has been a research topic in the last few decades. We adopt matrix exponential based integration method for circuit transient analysis, its stability and accuracy with DAEs remain an open problem. We identify that potential stability issues in the calculation of matrix exponential and vector product (MEVP) with rational Krylov method are originated from the singular system matrix in DAEs. We then devise a robust algorithm to implicitly regularize the system matrix while maintaining its sparsity. With the new approach, &phis; functions are applied for MEVP to improve the accuracy of results. Moreover our framework no longer suffers from the limitation on step sizes thus a large leap step is adopted to skip many simulation steps in between. Features of the algorithm are validated on large-scale power delivery networks which achieve high efficiency and accuracy.		Pengwen Chen;Chung-Kuan Cheng;Dongwon Park;Xinyuan Wang	2018	2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	10.1145/3240765.3264636	applied mathematics;electronic engineering;algebraic number;matrix exponential;computer science;ordinary differential equation;differential algebraic equation;algebraic equation;numerical stability;modified nodal analysis;matrix (mathematics)	EDA	88.25110400188501	21.07672069489618	163346
80b4007af719dcc3f5db7e94952f5504158c19bc	parallel image restoration with domain decomposition	algoritmo paralelo;vision ordenador;decomposition domaine;parallel algorithm;restauration image;domain decomposition;image processing;numerical method;metodo descomposicion;methode decomposition;procesamiento imagen;descomposicion dominio;image restoration;traitement image;algorithme parallele;computer vision;parallel imaging;restauracion imagen;decomposition method;metodo numerico;computational complexity;point spread function;vision ordinateur;methode numerique	In this paper we present parallel algorithms to solve the problem of image restoration when the Point Spread Function is Space Variant. The problem has a very high computational complexity and it is very hard to solve it on scalar computers. The algorithms are based on the decomposition of the image spatial domain and on the solution of both constrained and uncostrained restoration subproblems of size smaller than the original. The main results can be summarized as follows: (a) the quality of restorations do not depend on the number of subdomains; (b) the uncos-trained restoration is scalable and eecient even with a large number of processors while the constrained restoration is eecient for subdomains of more than 50 50 pixels. The numerical tests have been executed on a Cray T3E with 128 processors.	central processing unit;circuit restoration;computational complexity theory;cray t3e;domain decomposition methods;emoticon;image restoration;numerical analysis;parallel algorithm;personal computer;pixel;scalability	E. Loli Piccolomini;Fabiana Zama	2001	Real-Time Imaging	10.1006/rtim.2000.0219	image restoration;computer vision;mathematical optimization;decomposition method;image processing;numerical analysis;computer science;point spread function;domain decomposition methods;parallel algorithm;computational complexity theory;algorithm	Vision	86.47232527599685	22.46845902714355	163723
f5608d1458c8a86c6e6c55ce4e21e3f1f7f24d2e	fast multiplication of matrices with decay	sparse approximation;numerical analysis;rank reduction;fast algorithm;materials science;mathematical software;floating point;product space;high performance;data structure	A fast algorithm for the approximate multiplication of matrices with decay is introduced; the Sparse Approximate Matrix Multiply (SpAMM) reduces complexity in the product space, a different approach from current methods that economize within the matrix space through truncation or rank reduction. Matrix truncation (element dropping) is compared to SpAMM for quantum chemical matrices with approximate exponential and algebraic decay. For matched errors in the electronic total energy, SpAMM is found to require fewer to far fewer floating point operations relative to dropping. The challenges and opportunities afforded by this new approach are discussed, including the potential for high performance implementations.	approximation algorithm;fast fourier transform;linear algebra;matrix multiplication;sparse;the matrix;time complexity;truncation	Matt Challacombe;Nicolas Bock	2010	CoRR		mathematical optimization;combinatorics;data structure;product topology;numerical analysis;computer science;floating point;theoretical computer science;sparse approximation;mathematics;programming language	HPC	83.39044809339794	24.10416796425548	164809
6ed81dc29920dd6bb270bb24eea0b7d4f1f330de	krylov and polynomial iterative solvers combined with partial spectral factorization for spd linear systems	modelizacion;preconditionnement;iterative method;iterative solver;filtering;symmetric positive definite;haute performance;deflation;eigenvalue problem;mise a jour;sous espace invariant;spectral preconditioning;metodo subespacio krylov;complexite calcul;krylov subspace method;relacion convergencia;methode sousespace krylov;distributed computing;probleme valeur propre;preconditioning;taux convergence;convergence rate;conjugate gradient method;eigenvalues;linear system;metodo iterativo;actualizacion;modelisation;iterative methods;conjugate gradient;complejidad computacion;matrice definie positive;lanczos method;positive definite matrix;computational complexity;chebyshev polynomials;metodo gradiente conjugado;methode iterative;invariant subspace;alto rendimiento;calculo repartido;precondicionamiento;subespacio invariante;spectral factorization;methode gradient conjugue;matriz definida positiva;modeling;high performance;calcul reparti;updating;problema valor propio	When solving the Symmetric Positive Definite (SPD) linear system Ax = b with the conjugate gradient method, the smallest eigenvalues in the matrix A often slow down the convergence. Consequently if the smallest eigenvalues in A could be somehow “removed”, the convergence may be improved. This observation is of importance even when a preconditioner is used, and some extra techniques might be investigated to improve furthermore the convergence rate of the conjugate gradient on the given preconditioned system. Several techniques have been proposed in the literature that either consist of updating the preconditioner or enforcing the conjugate gradient to work in the orthogonal complement of an invariant subspace associated with small eigenvalues. In this work, we compare the numerical efficiency, computational complexity, and sensitivity to the accuracy of the spectral information of the techniques presented in [1], [2] and [3]. A more detailed description of these approaches as well as other comparable techniques on a range of standard test problems is available in [4].	computational complexity theory;conjugate gradient method;iterative method;krylov subspace;linear system;numerical analysis;polynomial;preconditioner;rate of convergence;the matrix	Luc Giraud;Daniel Ruiz;Ahmed Touhami	2004		10.1007/11403937_48	mathematical optimization;conjugate residual method;calculus;derivation of the conjugate gradient method;mathematics;geometry;iterative method;conjugate gradient method;algebra	Theory	82.9873317172772	21.29364140945595	165105
79ba5ab5e0b71e8493601ec1d85ec15a3fc625e5	a polyalgorithm with diagonal storing for the solution of very large indefinite linear banded systems on a vector computer	parallel processing;conjugate gradient	The efficient iterative solution of extremely large linear band matrix systems, resulting from the combination of a variable step size/variable order difference method and Newtonu0027s method is discussed. The natural storing by diagonals requires algorithms which go sequentially through diagonals. Jacobi-type and conjugate gradient type methods which can be easily formulated in diagonal form are combined to a polyalgorithm. The choice of the best method by the program itself is discussed. 8 references.	vector processor	Willi Schönauer;Karlheinz Raith	1982			discrete mathematics;derivation of the conjugate gradient method;iterative method;diagonal form;mathematical logic;band matrix;diagonal;matrix (mathematics);mathematical optimization;conjugate gradient method;mathematics	EDA	83.71389356064309	22.400885738343554	166292
71e995eb3a96ebb30d03491a924a0c537ad73265	a multigrid method for eigenvalue problem	eigenvalue problem;finite element method;multilevel correction;multigrid	A multigrid method is proposed to solve the eigenvalue problem by the finite element method based on the combination of the multilevel correction scheme for the eigenvalue problem and the multigrid method for the boundary value problem. In this scheme, solving eigenvalue problem is transformed to a series of solutions of boundary value problems by the multigrid method on multilevel meshes and a series of solutions of eigenvalue problems on the coarsest finite element space. Besides the multigrid scheme, all other efficient iteration methods can also serve as the linear algebraic solver for the associated boundary value problems. The total computational work of this scheme can reach the optimal order as same as solving the corresponding boundary value problem. Therefore, this type of iteration scheme improves the overall efficiency of the eigenvalue problem solving. Some numerical experiments are presented to validate the efficiency of the method.	multigrid method	Hehu Xie	2014	J. Comput. Physics	10.1016/j.jcp.2014.06.030	divide-and-conquer eigenvalue algorithm;mathematical optimization;combinatorics;mathematical analysis;finite element method;inverse iteration;mathematics;algorithm;multigrid method	AI	84.81087814862666	21.52088006360496	167607
aa58df51ea3541a9fc207fe593289a29432a2072	full waveform inversion and the truncated newton method	full waveform inversion;90c06;seismic imaging;numerical optimization;86 08;49m15;35r30;large scale inverse problems	Full waveform inversion (FWI) is a powerful method for reconstructing subsurface parameters from local measurements of the seismic wavefield. This method consists in minimizing the distance between predicted and recorded data. The predicted data are computed as the solution of a wave-propagation problem. Conventional numerical methods for the resolution of FWI problems are gradient-based methods, such as the preconditioned steepest descent, or more recently the $l$-BFGS quasi-Newton algorithm. In this study, we investigate the desirability of applying a truncated Newton method to FWI. The inverse Hessian operator plays a crucial role in the parameter reconstruction. The truncated Newton method allows one to better account for this operator. This method is based on the computation of the Newton descent direction by solving the corresponding linear system through an iterative procedure such as the conjugate gradient method. The large-scale nature of FWI problems requires us, however, to carefully implement ...	newton's method;truncated newton method;waveform	Ludovic Métivier;R. Brossier;Jean Virieux;Stéphane Operto	2013	SIAM J. Scientific Computing	10.1137/120877854	mathematical optimization;mathematical analysis;geophysical imaging;calculus;newton's method in optimization;mathematics	HPC	89.14546078835588	19.07513932563685	168004
5cd79cd2cc08dc10d5a19c80c84488d3ae188bf5	a riemannian fletcher-reeves conjugate gradient method for doubly stochastic inverse eigenvalue problems	15a18;riemannian isospectral flow;90c26;riemannian fletcher reeves conjugate gradient method;65k05;65f18;inverse eigenvalue problem;65f15;90c48;doubly stochastic matrix	We consider the inverse eigenvalue problem of reconstructing a doubly stochastic matrix from the given spectrum data. We reformulate this inverse problem as a constrained nonlinear least squares problem over several matrix manifolds, which minimizes the distance between isospectral matrices and doubly stochastic matrices. Then a Riemannian Fletcher–Reeves conjugate gradient method is proposed for solving the constrained nonlinear least squares problem, and its global convergence is established. An extra gain is that a new Riemannian isospectral flow method is obtained. Our method is also extended to the case of prescribed entries. Finally, some numerical tests are reported to illustrate the efficiency of the proposed method.	broyden–fletcher–goldfarb–shanno algorithm;conjugate gradient method;davidon–fletcher–powell formula;doubly stochastic model;fletcher's checksum;local convergence;non-linear least squares;nonlinear system;numerical analysis;numerical method;stochastic gradient descent;stochastic matrix	Teng-Teng Yao;Zheng-Jian Bai;Zhi Zhao;Wai-Ki Ching	2016	SIAM J. Matrix Analysis Applications	10.1137/15M1023051	mathematical optimization;combinatorics;mathematical analysis;doubly stochastic matrix;mathematics;algebra	ML	84.1485133787875	18.807660884427463	168538
7cfb25a4e96440ed9af05a997af5131456d93592	an optimal regularization method for space-fractional backward diffusion problem	discrepancy principle;optimal error estimate;space fractional backward diffusion problem;regularization;ill posed problem	In this paper, a space-fractional backward diffusion problem (SFBDP) in a strip is considered. By the Fourier transform, we proposed an optimal modified method to solve this problem in the presence of noisy data. The convergence estimates for the approximate solutions with the regularization parameter selected by an a priori and an a posteriori strategy are provided, respectively. Numerical experiments show that the proposed methods are effective and stable.	matrix regularization	Z. Q. Zhang;T. Wei	2013	Mathematics and Computers in Simulation	10.1016/j.matcom.2013.04.008	regularization;mathematical optimization;mathematical analysis;machine learning;calculus;mathematics	ML	84.35796044947486	19.077636506132283	168959
e7abc8942f051b6d1ff048e445e38a29602f8e66	quadpack computation of feynman loop integrals	65d30;numerical calculations;30e15;singularity infrared;41a55;extrapolation;asymptotic expansion;41a58;68n30;adaptive strategy;65d20;41a60;numerical iterated integration;loop integral;regularization dimensional;infrared divergence;65b15;singularities;65z05;65b05;feynman graph;68w01;programming;feynman loop integrals;65d32;convergence acceleration;asymptotic expansions	The paper addresses a numerical computation of Feynman loop integrals, which are computed by an extrapolation to the limit as a parameter in the integrand tends to zero. An important objective is to achieve an automatic computation which is effective for a wide range of instances. Singular or near singular integrand behavior is handled via an adaptive partitioning of the domain, implemented in an iterated/repeated multivariate integration method. Integrand singularities possibly introduced via infrared (IR) divergence at the boundaries of the integration domain are addressed using a version of the Dqags algorithm from the integration package Quadpack, which uses an adaptive strategy combined with extrapolation. The latter is justified for a large class of problems by the underlying asymptotic expansions of the integration error. For IR divergent problems, an extrapolation scheme is presented based on dimensional regularization. © 2011 Elsevier B.V. All rights reserved. umerical iterated integration daptive strategy xtrapolation onvergence acceleration symptotic expansions ingularities nfrared divergence	algorithm;computation;extrapolation;iteration;numerical analysis;quadpack	Elise de Doncker;Junpei Fujimoto;Nobuyuki Hamaguchi;Tadashi Ishikawa;Yoshimasa Kurihara;Yoshimitsu Shimizu;Fukuko Yuasa	2012	J. Comput. Science	10.1016/j.jocs.2011.06.003	gravitational singularity;programming;mathematical optimization;mathematical analysis;adaptive strategies;mathematics;geometry;extrapolation;asymptotic expansion	AI	85.52449456005101	18.584030257591728	169289
dd8da50aca680cac2a587cc692d9df489e55e7b2	a weakened form of fictitious play in two-person zero-sum games	convergence;two person zero sum games;fictitious play;zero sum game	Fictitious play can be seen as a numeric iteration procedure for determining the value of a game and corresponding optimal strategies. Although convergence is slow, it needs only a modest computer storage. Therefore it seems to be a good way out for analyzing large games. In this paper we consider a weakened form of ...ctitious play, which can be interpreted that players at each stage do not have to make the best choice against the total of past choices of the other player but only an increasingly better one. Theoretical bounds for convergence are derived. Furthermore it is shown that this new form can speed up convergence considerably in practice. The method is related to generalizations in which the game matrix itself becomes better known as the number of stages increases. Finally, the convergence of the strategies themselves is discussed. AMS 1991 subject classi...cation. Primary 90D05, 90D10.	computer data storage;converge;iteration;numerical analysis;vhdl-ams;zero	Ben van der Genugten	2000	IGTR	10.1142/S0219198900000202	mathematical optimization;convergence;economics;repeated game;mathematics;zero-sum game;mathematical economics;fictitious play	ML	83.56126554401312	27.420276718353723	169848
eddd9fbf289b057d716585758c36bb5962fe179d	sparse matrix representations in a functional language	sparse matrix;functional language	This paper investigates several sparse matrix representation schemes and associated algorithms in Haskell for solving linear systems of equations arising from solving realistic computational fluid dynamics problems using a finite element algorithm. This work complements that of Wainwright and Sexton (1992) in that a Choleski direct solver (with an emphasis on its forward/backward substitution steps) is examined. Experimental evidence comparing time and space efficiency of these matrix representation schemes is reported, together with associated forward/backward substitution implementations. Our results are in general agreement with Wainwright and Sexton's.	algorithm;computation;computational fluid dynamics;finite element method;functional programming;haskell;linear system;matrix representation;solver;sparse matrix	Phil W. Grant;J. A. Sharp;Michael F. Webster;Xiangrong Zhang	1996	J. Funct. Program.	10.1017/S095679680000160X	sparse matrix;computer science;programming language;functional programming	PL	84.91319129589724	22.5391172744693	170133
49f3037b47c773351d1abe61755e204728b2091c	a proof of the consistency of the finite difference technique on sparse grids	operador lineal;finite differences;interpolation;sparse grids;metodo diferencia finita;methode collocation;ondelette;interpolacion;weighting;extrapolation;differential operators;metodo colocacion;holder space;finite difference;ponderacion;consistencia;finite difference method;grid;methode difference finie;estimation erreur;linear operator;erreur interpolation;error estimation;modelo 2 dimensiones;rejilla;espace holder;interpolation error;consistance;estimacion error;modele 2 dimensions;grille;ponderation;extrapolacion;interpolets;collocation method;operateur lineaire;combination technique;wavelets;consistency;two dimensional model	In this paper, we give a proof of the consistency of the finite difference technique on regular sparse grids [7, 18]. We introduce an extrapolation-type discretization of differential operators on sparse grids based on the idea of the combination technique and we show the consistency of this discretization. The equivalence of the new method with that of [7, 18] is established.	discretization;extrapolation;finite difference;sparse grid;sparse matrix;turing completeness	Frank Koster	2000	Computing	10.1007/s006070070009	mathematical optimization;finite difference;mathematical analysis;interpolation;calculus;sparse approximation;mathematics;regular grid	HPC	83.27877439163532	19.869281086914324	170958
61bb9d2f3a9e00aa965bea659cb40367f225b315	tikhonov regularization by a reproducing kernel hilbert space for the cauchy problem for an elliptic equation	equation derivee partielle;calcul scientifique;espace hilbert;partial differential equation;ecuacion derivada parcial;analisis numerico;regularizacion tikhonov;35q15;convergence;espacio hilbert;stochastic method;05bxx;46e22;numerical method;probleme cauchy;46cxx;primary;exact solution;35jxx;regularisation tikhonov;65k15;solucion exacta;analyse numerique;65c20;equation elliptique;elliptic equation;hilbert space;problema cauchy;convergencia;computacion cientifica;numerical analysis;metodo numerico;reproducing kernel hilbert space;methode stochastique;tikhonov regularization;solution exacte;scientific computation;ecuacion eliptica;cauchy problem;methode numerique;65n21;metodo estocastico	We propose a discretized Tikhonov regularization for a Cauchy problem for an elliptic equation by a reproducing kernel Hilbert space. We prove the convergence of discretized regularized solutions to an exact solution. Our numerical results demonstrate that our method can stably reconstruct solutions to the Cauchy problems even in severe cases of geometric configurations.	discretization;hilbert space;matrix regularization;numerical analysis	Tomoya Takeuchi;Masahiro Yamamoto	2008	SIAM J. Scientific Computing	10.1137/070684793	regularization perspectives on support vector machines;cauchy problem;regularization;mathematical optimization;mathematical analysis;numerical analysis;calculus;cauchy's convergence test;mathematics;tikhonov regularization;algebra	ML	84.29413927966527	18.580274075480705	171283
e3c0f9944e081c3e71cf5400ef33f510c0f5bd03	a fast decomposition of banded symmetric toeplitz matrices for parallel processing	symmetric matrices;decomposition algorithm;rank one update decomposition banded symmetric toeplitz matrices parallel processing regularized signal restoration fft;fast fourier transforms;signal restoration;fast fourier transforms toeplitz matrices parallel processing signal restoration;matrix decomposition symmetric matrices parallel processing signal restoration eigenvalues and eigenfunctions image processing pattern recognition computer science costs concurrent computing;parallel processing;toeplitz matrices	The eigendecomposition of banded symmetric matrices is important in regularized signal restoration. In this paper a new fast decomposition algorithm is developed by using FFT and rank-one update. In this way the split of the matrix beco-mes more direct and the cost of the initial decomposition decreases. The algorithm is especially useful for parallel processing. Two numerical examples are given, which show that the new method can achieve comparable results to the classical methods.	circuit restoration;fast fourier transform;manufacturing execution system;numerical analysis;numerical method;parallel computing;the matrix;toeplitz hash algorithm	W. Xiong;Jincheng Li;Richard M. M. Chen;S. Qian	1999		10.1109/ISCAS.1999.778834	multidimensional signal processing;parallel processing;fast fourier transform;mathematical optimization;computer science;theoretical computer science;mathematics;symmetric matrix;algebra	ML	82.91398094241114	22.59360135945459	171423
6b17be50c2ccb9204629bfd63ddaa6efb888b61d	parallelization of mesh contraction and fairing using opencl	paper;laplace operator;computational geometry;ati;ati radeon hd 6630 m;parallelization;mesh fairing;triangular meshes;computer science;mesh contraction;opencl	We propose a parallel method for computing local Laplacian curvature flows for triangular meshes. Laplace operator is widely used in mesh processing for mesh fairing, noise removal or curvature estimation. If the Laplacian flow is used in global sense constraining a whole mesh with an iterative weighted linear system, it can be used even for mesh contraction. However, numerical solution of such a global linear system is computationally expensive. Therefore, we have developed a method to compute such an iterative linear system using only local neighbourhoods of each vertex in parallel. Parallel computation of local linear systems is performed on GPU using OpenCL. We have evaluated speedups of the parallelization using both local and global Laplacian flows. We show test cases, where the parallel local method can be used for mesh fairing. In contrary, we also investigate and outline a fail case, where the local Laplacian flow cannot be used. When the local Laplacian flow has problems with global convergence, we offer a global parallelization of the linear system solving as an alternative.	analysis of algorithms;automatic parallelization;computation;geometry processing;graphics processing unit;iterative method;laplacian smoothing;linear system;local convergence;numerical partial differential equations;opencl api;parallel computing;test case;triangle mesh;triangulated irregular network	Martin Madaras;Roman Durikovic	2013		10.1145/2508244.2508250	mathematical optimization;laplace operator;parallel computing;computational geometry;computer science;theoretical computer science;mathematics;geometry;laplacian smoothing	HPC	86.28740075016823	22.00638106879831	171688
c45e32c5c994ddcaa1cba9a18fd1dd22f46539e3	optimal error bound and a quasi-boundary value regularization method for a cauchy problem of the modified helmholtz equation	ill posed;stability estimate;the cauchy problem of modified helmholtz equation;regularization;35r40;quasi boundary value method;error estimate	In this paper, the Cauchy problem for the modified Helmholtz equation is investigated in a rectangle, where the Cauchy data is given for y=0 and boundary data for x=0 and x=π. The solution is sought in the interval 0<y≤1. We propose a quasi-boundary value regularization method to formulate regularized solutions which are stably convergent to the exact one with explicit error estimates. In addition, we also carry out numerical experiments and compare numerical results of our method with Qin's methods [Quasi-reversibility and truncation methods to solve a Cauchy problem for the modified Helmholtz equation, Math. Comput. Simulation 80 (2009), pp. 352–366] and Tuan's methods [Regularization and new error estimates for a modified Helmholtz equation, An. Stiint Univ. ‘Ovidius' Constanta Ser. Mat. 18(2) (2010), pp. 267–280]. It shows that our quasi-boundary value method give a better results than quasi-reversibility method of Qin and modified regularization method of Tuan.	matrix regularization	Ailin Qian;Xiaomei Yang;Yousheng Wu	2016	Int. J. Comput. Math.	10.1080/00207160.2015.1083555	well-posed problem;cauchy problem;regularization;mathematical optimization;mathematical analysis;calculus;mathematics	Theory	83.97683468076346	18.758766203755478	171772
8c725d04f4618977d67c233b630569346281ce7f	hierarchical matrices - a means to efficiently solve elliptic boundary value problems	510 mathematik	Hierarchical matrices are an efficient framework for large-scale fully populated matrices arising, e.g., from the finite element discretization of solution operators of elliptic boundary value problems. In addition to storing such matrices, approximations of the usual matrix operations can be computed with logarithmic-linear complexity, which can be exploited to setup approximate preconditioners in an efficient and convenient way. Besides the algorithmic aspects of hierarchical matrices, the main aim of this book is to present their theoretical background. The book contains the existing approximation theory for elliptic problems including partial differential operators with nonsmooth coefficients. Furthermore, it presents in full detail the adaptive cross approximation method for the efficient treatment of integral operators with non-local kernel functions. The theory is supported by many numerical experiments from real applications.		Mario Bebendorf	2008		10.1007/978-3-540-77147-0	mathematical optimization;mathematical analysis;discrete mathematics;mathematics	Theory	86.42073991871335	20.63327492674125	173120
859d2571063a1dcdb4c4cbec27cfd406ecfbbfad	block krylov-type complex moment-based eigensolvers for solving generalized eigenvalue problems	complex moment-based eigensolver;generalized eigenvalue problem;block krylov subspace method;65f15;65f25;65f30;65d30	Complex moment-based eigensolvers for solving interior eigenvalue problems have been studied because of their high parallel efficiency. Recently, we proposed the block Arnoldi-type complex moment-based eigensolver without a low-rank approximation. A low-rank approximation plays a very important role in reducing computational cost and stabilizing accuracy in complex moment-based eigensolvers. In this paper, we develop the method and propose block Krylov-type complex moment-based eigensolvers with a low-rank approximation. Numerical experiments indicate that the proposed methods have higher performance than the block SS–RR method, which is one of the most typical complex moment-based eigensolvers.	algorithmic efficiency;arnoldi iteration;computation;dns certification authority authorization;eigenvalue algorithm;experiment;krylov subspace;krylov–bogolyubov theorem;lanczos algorithm;low-rank approximation;monte carlo method;nonlinear system;numerical analysis;numerical linear algebra;rr (debugging);rapid refresh;rayleigh–ritz method;round-robin scheduling;sparse matrix;speedup;symantec endpoint protection;time complexity	Akira Imakura;Tetsuya Sakurai	2016	Numerical Algorithms	10.1007/s11075-016-0241-5	mathematical optimization;combinatorics;mathematical analysis;mathematics	ML	83.19516172224982	23.22513025371495	173346
4c23e3ea4a270f628617da58926837b7e5b141ae	unifying approach and interface for spline-based snakes	interfaces	In this paper, we present di erent solutions for improving spline-based snakes. First, we demonstrate their minimum curvature interpolation property, and use it as an argument to get rid of the explicit smoothness constraint. We also propose a new external energy obtained by integrating a non-linearly pre-processed image in the closed region bounded by the curve. We show that this energy, besides being eÆciently computable, is suÆciently general to include the widely used gradient-based schemes, Bayesian schemes, their combinations and discriminant-based approaches. We also introduce two initialization modes and the appropriate constraint energies. We use these ideas to develop a general snake algorithm to track boundaries of closed objects, with a user-friendly interface.	algorithm;computable function;discriminant;gradient;interpolation;master boot record;spline (mathematics);usability	Mathews Jacob;Thierry Blu;Michael A. Unser	2001		10.1117/12.431105	mathematical optimization;discrete mathematics;mathematics;geometry	Vision	92.58283540675545	20.994961745162094	173455
a4f548a3bc247472b61a34dc432984b11e4b39bc	h2-matrix-based finite element linear solver for fast transient thermal analysis of high-performance ics	thermal analysis;h2 matrix;finite element method;期刊论文;integrated circuits	SUMMARYrnrnIn this article, we propose 2-based finite element (FE) solver for transient thermal analysis of high-performance integrated circuits (ICs). 2-matrix is a special subclass of hierarchical matrix or -matrix, which was shown to provide a data-sparse way to approximate the matrices and their inverses with almost linear space and time complexities. In this work, we show that 2-based mathematical framework can also be applied to FE-based transient analysis of thermal parabolic partial differential equations. We show how the thermal matrix can be approximated by 2-representations with controlled error. Then, we demonstrate that both storage and time complexities of the new solver are bounded by , where N is the matrix size. The method can be applied to any thermal structures for both steady and transient analysis. The numerical results from 3D ICs demonstrate the linear scalability of the proposed method in terms of both memory footprint and CPU time. The comparison with existing product-quality LU solvers, CSPARSE and UMFPACK, on a number of 3D IC thermal matrices, shows that the new method is much more memory efficient than these methods, which however prevents the demonstration of the potential speedup of the proposed method over those methods. Copyright © 2014 John Wiley u0026 Sons, Ltd.	finite element method;numerical linear algebra;solver	Hai-Bao Chen;Sheldon X.-D. Tan;David H. Shin;Xin Huang;Hai Wang;Guoyong Shi	2015	I. J. Circuit Theory and Applications	10.1002/cta.2051	electronic engineering;extended finite element method;computer science;theoretical computer science;finite element method;engineering drawing;thermal analysis	HPC	88.6040988461641	20.927993412937585	174822
3dae37b17979f4a4b25826fc1dbc6fc527fd6ca0	limits of parallelism in explicit ode methods	numerical method;g 1 0;ams mos 65l05;initial value problem;cr g 1 7;algebraic function;nonlinear problem	Numerical methods for ordinary initial value problems that do not depend on special properties of the system are usually found in the class of linear multistage multivalue methods, first formulated by J.C. Butcher. Among these the explicit methods are easiest to implement. For these reasons there has been considerable research activity devoted to generating methods of this class which utilize independent function evaluations that can be performed in parallel. Each such group of concurrent function evaluations can be regarded as a stage of the method. However, it turns out that parallelism affords only limited opportunity for reducing the computing time with such methods. This is most evident for the simple linear homogeneous constant-coefficient test problem, whose solution is essentially a matter of approximating the exponential by an algebraic function. For a given number of stages and a given number of saved values, parallelism offers a somewhat enlarged set of algebraic functions from which to choose. However, there is absolutely no benefit in having the degree of parallelism (number of processors) exceed the number of saved values of the method. Thus, in particular, parallel one-step methods offer no speedup over serial one-step methods for the standard linear test problem. Although the implication of this result for general nonlinear problems is unclear, there are indications that dramatic speedups are not possible in general. Also given are some results relevant to the construction of methods.	central processing unit;coefficient;degree of parallelism;linear algebra;multivalue;multistage amplifier;nonlinear system;numerical methods for ordinary differential equations;parallel computing;speedup;time complexity	Robert D. Skeel;Hon-Wah Tam	1992	Numerical Algorithms	10.1007/BF02139473	mathematical optimization;mathematical analysis;numerical analysis;calculus;mathematics;algebraic function;initial value problem;algorithm;statistics;algebra	Theory	83.73208230816047	26.949845327803743	175081
b41abcfc1387afa6d7ece33f9f6562432f49129e	parallel conjugate gradient method with circulant block-factorization preconditioners for 3d elliptic problems	conjugate gradient method	AbstractParallel performance of a new solver for 3D elliptic problems based on a circulantblock-factorization preconditioner is investigated. Experimental data collected on anumber of parallel computers is reported and discussed. 1 Introduction Let us consider the numerical solution of a self-adjoint second order 3D linear boundaryvalue problem of elliptic type. After discretization, such a problem results in a linearsystem Ax = b , where A is a structured sparse symmetric positive de nite matrix. Inthe computational practice, large-scale problems of this class are most often solved by theKrylov subspace based iterative methods (e.g. conjugate gradient method). Each step ofsuch a method requires only a product of A with a given vector v allowing one to exploit thesparsity of A . The rate of convergence of these methods depends on the condition number u0014 of the coeu000ecient matrix A : smaller u0014 ( A ) leads to faster convergence. Unfortunately, forthe second order 3D elliptic problems, typically	circulant matrix;conjugate gradient method;preconditioner	Ivan Lirkov;Svetozar Margenov;Marcin Paprzycki;John McLaughlin	1999			iterative method;mathematical optimization;derivation of the conjugate gradient method;biconjugate gradient stabilized method;conjugate gradient method;nonlinear conjugate gradient method;biconjugate gradient method;preconditioner;conjugate residual method;mathematics	Theory	83.21211512853975	22.349804109229233	175305
252798f78443c819d4d61092cf36ffefb84ad918	regularization of a volterra integral equation by linear inequalities	integral equation;problema mal planteado;regularisation;metodo monte carlo;numerical solution;numerical method;fonction monotone;efficiency;probleme mal pose;simulation;equation volterra;methode monte carlo;ecuacion volterra;volterra integral equation;simulacion;volterra equation;funcion monotona;regularization;eficacia;response function;metodo numerico;constrained least square;convex function;monte carlo method;inegalite lineaire;ill posed problem;equation integrale;monotonic function;efficacite;simulation study;ecuacion integral;regularizacion;probleme moindre carre contraint;point of view;funcion respuesta;fonction convexe;methode numerique;fonction reponse;funcion convexa	The determination of a monotone nonincreasing and convex response function arising in reservoir mechanics is investigated from the computational point of view. Regularization by linear inequalities yields the means for overcoming the ill-posedness of the considered convolution type integral equation. In order to find efficient numerical solutions and adapted approach for solving the associated constrained least squares problems is developed. Some simulation studies complete the paper. In der Arbeit wird aus numerischer Sicht die Bestimmung einer monoton nichtwachsenden konvexen Responsefunktion untersucht, die in der Reservoirmechanik Anwendung findet. Regularisierung durch lineare Ungleichungen erlaubt die Überwindung der Nichtkorrektheit der betrachteten Faltungs-integralgleichung. Im Sinne effizienter numerischer Lösungen wird ein angepaßter Zugang zur Lösung der entsprechenden restringierten Kleinste-Quadrate-Probleme entwickelt. Einige Simulationsstudien runden die Arbeit ab.	convolution;frequency response;linear inequality;linear least squares (mathematics);matrix regularization;monotone polygon;numerical analysis;simulation;well-posed problem	Bernd Hofmann;R. Hausding;Ralf Wolke	1990	Computing	10.1007/BF02241655	convex function;regularization;mathematical optimization;mathematical analysis;monotonic function;numerical analysis;calculus;volterra integral equation;mathematics;efficiency;integral equation;statistics;monte carlo method	Vision	88.13658178677545	20.220163862317495	176512
5dd4c5193ded61a54cadeea5a218f12df53546e0	graph grammar based direct solver for hp-adaptive finite element method with point singularities	finite element method	In this paper we present a graph grammar based direct solver algorithm for hp-adaptive finite element method simulations with point singularities. The solver algorithm is obtained by representing computational mesh as a graph and prescribing the solver algorithm by graph grammar productions. Classical direct solvers deliver O(Np+N) computational cost for regular 2D grids, and O(Np+N) for regular 3D grids, where N denotes number of degrees of freedom and p denotes the polynomial order of approximation. The solver presented in this paper delivers linear computational cost for uniform polynomial order of approximation p. For non-uniform polynomial order the computational cost is almost linear.	algorithm;algorithmic efficiency;computation;computational complexity theory;finite element method;graph rewriting;order of approximation;polynomial;simulation;solver	Arkadiusz Szymczak;Anna Paszynska;Piotr Gurgul;Maciej Paszynski	2013		10.1016/j.procs.2013.05.327	mathematical optimization;combinatorics;discrete mathematics;mathematics	Graphics	91.3689360896114	18.276047728123967	176583
0c5376e0d345a73dd2cc8df5c36256f43d443769	lsmr: an iterative algorithm for sparse least-squares problems	discrete ordinate method;three dimensional temperature distribution;least squares minimum residual method;discrete transfer method;inverse radiation problem	An iterative method LSMR is presented for solving linear systems Ax = b and leastsquares problems min ‖Ax−b‖2, with A being sparse or a fast linear operator. LSMR is based on the Golub-Kahan bidiagonalization process. It is analytically equivalent to the MINRES method applied to the normal equation ATAx = ATb, so that the quantities ‖Ark‖ are monotonically decreasing (where rk = b−Axk is the residual for the current iterate xk). We observe in practice that ‖rk‖ also decreases monotonically, so that compared to LSQR (for which only ‖rk‖ is monotonic) it is safer to terminate LSMR early. We also report some experiments with reorthogonalization.	algorithm;bidiagonalization;computation;experiment;iteration;iterative method;linear system;matlab;maxima and minima;non-monotonic logic;ordinary least squares;sparse matrix;terminate (software)	David Chin-Lung Fong;Michael A. Saunders	2010	CoRR	10.1016/j.ijheatmasstransfer.2011.12.029	mathematical optimization;combinatorics;discrete mathematics;mathematics;iterative method;algebra	Vision	83.93934431571773	19.779734748441122	177043
a71086ea5221b16815e417891ca6dd3ba4ca3d46	gpu accelerated algorithms for computing matrix function vector products with applications to exponential integrators and fractional diffusion	contour integral method;preconditioning;krylov subspace methods;fractional reaction diffusion equation;matrix functions;65f08;exponential euler method;65f60;35r11;fractional laplacian	The efficient computation of matrix function vector products has recently become an important area of research, driven in particular by two important applications: the numerical solution of fractional partial differential equations and the integration of large systems of ordinary differential equations. In this work we consider a problem that combines these two applications in the form of a numerical solution algorithm for fractional reaction-diffusion equations that, after spatial discretization, is advanced in time using the exponential Euler method. We focus on the efficient implementation of the algorithm on graphics processing units (GPUs), as we wish to make use of the increased computational power available with this hardware. We compute the matrix function vector products using the contour integration method in [N. Hale, N. J. Higham, and L. N. Trefethen, SIAM J. Numer. Anal., 46 (2008), pp. 2505--2523]. Multiple levels of preconditioning are applied to reduce the GPU memory footprint and to furth...	exponential integrator;graphics processing unit	Megan E. Farquhar;Timothy J. Moroney;Qianqian Yang;Ian W. Turner	2016	SIAM J. Scientific Computing	10.1137/15M1021672	matrix function;mathematical optimization;mathematical analysis;exponential integrator;fractional calculus;calculus;mathematics;preconditioner;algebra	HPC	84.98603339985124	20.43386697367444	177142
70ca1b1e90ebd991130c5ba16553ca641b9db887	a new class of asynchronous iterative algorithms with order intervals	equation derivee partielle;schwarz alternating method;systeme equation;nonlinear boundary value problem;boundary value problem;convergence of numerical methods;domain decomposition methods;iterative algorithm;algorithme parallele;fixed point;convergence methode numerique;nonlinear systems;sistema ecuacion;partial differential equations;asynchronous iterations;equation system;domain decomposition method;xed point;numerical methods;systeme non lineaire;parallel iterative methods;boundary value problems;network flow;nonlinear system;iteration method;probleme valeur limite;methode numerique;shared memory multiprocessor;parallel algorithms	This paper deals with a new class of parallel asynchronous iterative algorithms for the solution of nonlinear systems of equations. The main feature of the new class of methods presented here is the possibility of flexible communication between processors. In particular partial updates can be exchanged. Approximation of the associated fixed point mapping is also considered. A detailed convergence study is presented. A connection with the Schwarz alternating method is made for the solution of nonlinear boundary value problems. Computational results on a shared memory multiprocessor IBM 3090 are briefly presented.	algorithm;approximation;central processing unit;computation;fixed point (mathematics);ibm 3090;iteration;iterative method;multiprocessing;nonlinear system;schwarz alternating method;shared memory	Jean Claude Miellou;Didier El Baz;Pierre Spitéri	1998	Math. Comput.	10.1090/S0025-5718-98-00885-0	mathematical optimization;combinatorics;nonlinear system;boundary value problem;calculus;mathematics;iterative method;algebra	Theory	84.34031592916133	21.66770073791129	177648
9fb6dd39a1ac7a8862ba3fc7523d323e2a9930e6	local regularization for the nonlinear inverse autoconvolution problem	metodo regularizacion;65b99;65r20;analisis numerico;regularizacion tikhonov;problema mal planteado;65r32;convergence;numerical solution;inverse autoconvolution problem;numerical method;probleme non lineaire;relacion convergencia;regularization method;probleme mal pose;regularisation tikhonov;methode regularisation;taux convergence;metodo secuencial;convergence rate;problema inverso;sequential method;nonlinear problems;analyse numerique;acceleration convergence;convergencia;numerical analysis;inverse problem;ill posed problem;numerical methods;algebra lineal numerica;algebre lineaire numerique;local regularization of inverse problems;nonlinear problem;aceleracion convergencia;methode sequentielle;65f22;total variation;numerical linear algebra;tikhonov regularization;probleme inverse;65r30;solution numerique;45q05;nonlinear volterra problem;convergence acceleration	We develop a local regularization theory for the nonlinear inverse autoconvolution problem. Unlike classical regularization techniques such as Tikhonov regularization, this theory provides regularization methods that preserve the causal nature of the autoconvolution problem, allowing for fast sequential numerical solution (O(rN2 − r2N) flops where r ¿ N for the method discussed in this paper as applied to the nonlinear problem; in comparison, the cost for Tikhonov regularization applied to a general linear problem is O(N3) flops). We prove the convergence of the regularized solutions to the true solution as the noise level in the data shrinks to zero and supply convergence rates for the case of both L2 and continuous data. We propose several regularization methods and provide a theoretical basis for their convergence; of note is that this class of methods does not require an initial guess of the unknown solution. Our numerical results confirm effectiveness of the methods, with results comparing favorably to numerical examples found in the literature for the autoconvolution problem (e.g., [13] for examples using Tikhonov regularization with total variation constraints, and [16] for examples using the method of Lavrent’ev); this especially seems to be true when it comes to the recovery of sharp features in the unknown solution. We also show the effectiveness of our method in cases not covered by the theory.	algebraic riccati equation;approximation algorithm;causal filter;causal system;discrepancy function;discretization;flops;flip-flop (electronics);linear programming;manifold regularization;matrix regularization;noise (electronics);nonlinear system;numerical analysis;numerical method;numerical partial differential equations;rate of convergence;signal-to-noise ratio;total variation diminishing;well-posed problem	Zhewei Dai;Patricia K. Lamm	2008	SIAM J. Numerical Analysis	10.1137/070679247	regularization perspectives on support vector machines;backus–gilbert method;regularization;mathematical optimization;mathematical analysis;numerical analysis;calculus;mathematics;tikhonov regularization;algorithm	AI	83.9126584569741	19.080736684062163	178743
fdb2ea64b6179ead294b30a0314d52283b47ffde	evaluation of linear solvers for astrophysics transfer problems	radiative transfer equation;projection approximation;numerical solution;numerical method;high performance computing;banach space;weakly singular kernel;numerical methods;high performance computer;open source;fredholm integral equation	In this work we consider the numerical solution of a radiative transfer equation for modeling the emission of photons in stellar atmospheres. Mathematically, the problem is formulated in terms of a weakly singular Fredholm integral equation defined on a Banach space. Computational approaches to solve the problem are discussed, using direct and iterative strategies that are implemented in open source packages.	computation;iterative method;numerical partial differential equations;open-source software;singular value decomposition;stellar (payment network)	Osni Marques;Paulo Batista de Vasconcelos	2006		10.1007/978-3-540-71351-7_36	radiative transfer;mathematical optimization;supercomputer;fredholm theory;numerical analysis;fredholm integral equation;integral equation;algebra	Robotics	86.42023861138675	21.52399444427687	179796
44ab7f815341704458fa281f3e0d28bcd7df8f16	calculation of generalized polynomial-chaos basis functions and gauss quadrature rules in hierarchical uncertainty quantification	interpolation;chaos;stochastic processes chaos circuit simulation integrated circuits interpolation network analysis polynomials statistical analysis;polynomials;network analysis;circuit simulation;statistical analysis;stochastic processes;generalized polynomial chaos basis functions stochastic circuit simulation monotone interpolation schemes closed form density functions random input a priori density function numerical quadrature rule orthonormal polynomials integrated circuits statistical analysis stochastic spectral methods hierarchical uncertainty quantification gauss quadrature rules;density functional theory stochastic processes polynomials probability density function interpolation integrated circuit modeling uncertainty;article;integrated circuits	Stochastic spectral methods are efficient techniques for uncertainty quantification. Recently they have shown excellent performance in the statistical analysis of integrated circuits. In stochastic spectral methods, one needs to determine a set of orthonormal polynomials and a proper numerical quadrature rule. The former are used as the basis functions in a generalized polynomial chaos expansion. The latter is used to compute the integrals involved in stochastic spectral methods. Obtaining such information requires knowing the density function of the random input a-priori. However, individual system components are often described by surrogate models rather than density functions. In order to apply stochastic spectral methods in hierarchical uncertainty quantification, we first propose to construct physically consistent closed-form density functions by two monotone interpolation schemes. Then, by exploiting the special forms of the obtained density functions, we determine the generalized polynomial-chaos basis functions and the Gauss quadrature rules that are required by a stochastic spectral simulator. The effectiveness of our proposed algorithm is verified by both synthetic and practical circuit examples.	algorithm;basis function;gaussian quadrature;gauss–hermite quadrature;integrated circuit;interpolation;numerical analysis;numerical integration;polynomial;spectral method;surrogate model;synthetic intelligence;uncertainty quantification;monotone	Zheng Zhang;Tarek A. El-Moselhy;Ibrahim M. Elfadel;Luca Daniel	2014	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2013.2295818	stochastic process;mathematical optimization;discrete mathematics;network analysis;interpolation;stochastic optimization;gaussian quadrature;mathematics;statistics;polynomial	EDA	90.65041307458817	19.751568050655425	180808
0ffadf97c137c69fccbc77bdc859bb39d58b5f36	a 2-level domain decomposition algorithm for inverse diffuse optical tomography	diffuse optical tomography;decomposition domaine;accelerateur;algoritmo busqueda;domain decomposition;tomography partitioning algorithms image reconstruction us department of transportation computational complexity acceleration convergence computational modeling imaging phantoms testing;image processing;complexite calcul;algorithme recherche;optical measurement;localization;optical tomography;search algorithm;gradiente;multigrille;procesamiento imagen;descomposicion dominio;image optique;accelerator;localizacion;gradient;conjugate gradient method;problema inverso;traitement image;grid;reconstruction image;conjugate gradient;complejidad computacion;optical imaging;localisation;coarse grid 2 level domain decomposition algorithm inverse diffuse optical tomography computational complexity optical image reconstruction two level multigrid algorithm modified multiplicative schwarz algorithm conjugate gradient simulated phantom configuration;inverse problem;reconstruccion imagen;mesure optique;computational complexity;metodo gradiente conjugado;rejilla;image reconstruction;medical image processing;multigrid;medida optica;multigrilla;grille;imagen optica;a priori information;methode gradient conjugue;acelerador;conjugate gradient methods;optical image;probleme inverse;medical image processing optical tomography computational complexity image reconstruction conjugate gradient methods	In this paper, we explore domain decomposition algorithms for the inverse DOT problem in order to reduce the computational complexity and accelerate the convergence of the optical image reconstruction. We propose a combination of a two-level multigrid algorithm with a modified multiplicative Schwarz algorithm, where a conjugate gradient is used as an accelerator to solve each sub-problem formulated on each of the partitioned sub-domains. For our experiments, simulated phantom configuration with two rectangular inclusions is used as a testbed to measure the computational efficiency of our algorithms. No a priori information about the configuration is assumed except for the source and detector locations. For the application of our modified Schwarz algorithm alone, we observe an increase in efficiency of 100% as compared to the conjugate gradient solution obtained for the full domain. With the addition of the coarse grid, this efficiency rises to 400%. The coarse grid also serves to improve the overall appearance of the reconstructed image at the boundaries of the inclusions.	additive schwarz method;algorithm;computation;computational complexity theory;conjugate gradient method;diffuse optical imaging;domain decomposition methods;error detection and correction;experiment;gauss–newton algorithm;image;interpolation;iteration;iterative reconstruction;langrisser schwarz;least squares;multigrid method;parallel computing;phantom reference;real-time clock;series acceleration;smoothing;testbed;tomography	Il-Young Son;Murat Guven;Xavier Intes;Birsen Yazici	2004	2004 International Conference on Image Processing, 2004. ICIP '04.	10.1109/ICIP.2004.1421823	mathematical optimization;image processing;computer science;calculus;mathematics;geometry;conjugate gradient method	Robotics	87.88555282197233	23.00213107573392	181954
6f38dc3f115996789b17135b2162634169e2f460	generalized stochastic collocation method for variation-aware capacitance extraction of interconnects considering arbitrary random probability	generalized polynomial chaos;geometric variations;variation-aware capacitance extraction;collocation method;sparse grids;minimum spanning tree;chip	For variation-aware capacitance extraction, stochastic collocation method (SCM) based on Homogeneous Chaos expansion has the exponential convergence rate for Gaussian geometric variations, and is considered as the optimal solution using a quadratic model to model the parasitic capacitances. However, when geometric variations are measured from the real test chip, they are not necessarily Gaussian, which will significantly compromise the exponential convergence property of SCM. In order to pursue the exponential convergence, in this paper, a generalized stochastic collocation method (gSCM) based on generalized Polynomial Chaos (gPC) expansion and generalized Sparse Grid quadrature is proposed for variation-aware capacitance extraction that further considers the arbitrary random probability of real geometric variations. Additionally, a recycling technique based on Minimum Spanning Tree (MST) structure is proposed to reduce the computation cost at each collocation point, for not only “recycling” the initial value, but also “recycling” the preconditioning matrix. The exponential convergence of the proposed gSCM is clearly shown in the numerical results for the geometric variations with arbitrary random probability. key words: variation-aware capacitance extraction, geometric variations, generalized polynomial chaos	collocation method;computation;electrical connection;minimum spanning tree;numerical analysis;polynomial;preconditioner;quadratic equation;rate of convergence;sparse grid;stochastic process;time complexity	Hengliang Zhu;Xuan Zeng;Xu Luo;Wei Cai	2009	IEICE Transactions		chip;mathematical optimization;spanning tree;telecommunications;computer science;minimum spanning tree;integrated circuit;interconnection;collocation method;preconditioner;capacitance;tree structure;rate of convergence;recycling	EDA	90.58423966581474	19.752997494478247	182995
d16c0cc674f823a01dc50b1275878d79b0b42696	fast fluid registration with dirichlet boundary conditions: a transform-based approach	dirichlet boundary condition;linear systems;fluid registration;linear pde systems;technological innovation;boundary conditions;biological organs;biomedical imaging;deformation field;deformable models;biological fluid dynamics;satisfiability;breast;fixed point iteration;velocity field;medical image processing biological fluid dynamics biological organs boundary value problems deformation discrete fourier transforms flow simulation image registration iterative methods mammography;dirichlet boundary conditions;transform based approach;iterative methods;image transformation;navier lame equations;deformation;boundary condition;partial differential equations;medical image processing;image registration;discrete fourier transform;nonrigid image registration;discrete sine transform;boundary value problems;differential equations;flow simulation;mammography;discrete fourier transforms;breast fluid registration dirichlet boundary conditions transform based approach nonrigid image registration deformation field image transformation navier lame equations fixed point iteration linear pde systems discrete fourier transform discrete sine transform mammograms;boundary conditions image registration partial differential equations biomedical imaging discrete fourier transforms deformable models linear systems differential equations technological innovation laboratories;mammograms	Fluid registration is an example of a nonrigid image registration algorithm that uses a deformation field to define the transformation between two images. The velocity of the deformation field is governed by the Navier-Lame equations, which can be discretized and solved numerically via fixed-point iteration. The fixed-point iteration generates a succession of linear PDE systems, which can be solved quickly via discrete Fourier transform (DFT) techniques, as shown in the prior art. The major drawback of this approach is that it is only applicable when the boundary conditions of the velocity field are assumed to be periodic. This paper shows that by considering the adjoint of the Navier-Lame operator, the succession of linear PDE systems can be solved quickly via discrete sine transform (DST) techniques, generating velocity fields that satisfy Dirichlet boundary conditions (where the velocities are zero on the boundaries)	algorithm;boundary case;discrete fourier transform;discrete sine transform;discretization;fixed-point iteration;image registration;numerical analysis;succession;velocity (software development)	Nathan D. Cahill;J. Alison Noble;David J. Hawkes;Lawrence A. Ray	2007	2007 4th IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2007.356951	medical imaging;dirichlet boundary condition;mathematical optimization;mathematical analysis;boundary value problem;mathematics;geometry	Vision	89.64540369869886	20.236524796261886	183416
290a7ae802581ba2da73207e657d793d9494a70d	algorithm 135: crout with equilibration and iteration			algorithm;iteration	William M. McKeeman	1962	Commun. ACM	10.1145/368996.369009	theoretical computer science;computer science	Graphics	87.98066274729734	23.934192699595023	185506
66a949a938d6c6bd0f75e13f373ab812994617b7	an index-aware parametric model order reduction method for parameterized quadratic differential-algebraic equations		Modeling of sophisticated applications, such as coupled problems arising from nanoelectronics can lead to quadratic differential algebraic equations (DAEs). The quadratic DAEs may also be parameterized, due to variations in material properties, system configurations, etc., and they are usually subject to multi-query tasks, such as optimization, or uncertainty quantification. Model order reduction (MOR), specifically parametric model order reduction (pMOR), is known as a useful tool for accelerating the simulations in a multi-query context. However, pMOR dedicated to this particular structure, has not yet been systematically studied. Directly applying the existing pMOR methods may produce parametric reducedorder models (pROMs) which are less accurate, or may be very difficult to simulate. The same problem was already observed for linear DAEs, and could be eliminated by introducing splitting MOR techniques such as the index-aware MOR (IMOR) methods. We extend the IMOR methods to parameterized quadratic DAEs, thereby producing accurate and easy to simulate index-aware parametric reduced-order models (IpROMs). The proposed approach is so far limited to index-1 one-way coupled problems, but these often appear in computational nanoelectronics. We illustrate the performance of the new approach using industrial models for nanoelectronic structures. © 2017 Elsevier Inc. All rights reserved.	computation;coupling (computer programming);differential algebraic equation;linear algebra;mathematical optimization;mathematics of operations research;model order reduction;nonlinear system;numerical analysis;one-way function;parametric model;parametric polymorphism;simulation;uncertainty quantification	Nicodemus Banagaaya;Peter Benner;Lihong Feng;Peter Meuris;Wim Schoenmaker	2018	Applied Mathematics and Computation	10.1016/j.amc.2017.04.024	mathematical optimization;discrete mathematics;theoretical computer science;mathematics	Logic	88.63507194798622	20.91986441048906	186483
cfaf0960f3beba833b8261eb2e0991f0ebd45966	merging jacobi and gauss-seidel methods for solving markov chains on computer clusters	merging jacobian matrices gaussian processes iterative methods concurrent computing equations state space methods clustering algorithms iterative algorithms mathematics;markov processes iterative methods;iterative methods;congestion control;mathematical model;clustering algorithms;congestion control mechanism merging jacobi methods gauss seidel methods markov chains computer clusters sparse linear equation systems;markov processes;linear equations;iteration method;gauss seidel;jacobian matrices;sparse matrices;algorithm design and analysis;markov chain	The authors consider the use of the parallel iterative methods for solving large sparse linear equation systems resulting from Markov chains-on a computer cluster. A combination of Jacobi and Gauss-Seidel iterative methods is examined in a parallel version. Some results of experiments for sparse systems with over 3 times 107 equations and about 2 times 108 nonzeros which we obtained from a Markovian model of a congestion control mechanism are reported.	computer cluster;experiment;gauss–seidel method;iterative method;jacobi method;linear equation;markov chain;network congestion;sparse matrix	Jaroslaw Bylina;Beata Bylina	2008	2008 International Multiconference on Computer Science and Information Technology	10.1109/IMCSIT.2008.4747250	markov chain;mathematical optimization;iterative method;markov model;matrix-free methods;relaxation;statistics;variable-order markov model	HPC	85.1025489170677	22.66016116654363	186820
64eb2d230b5afdfd70e25a3a39d2ce2a80630391	preconditioning nonsymmetric and indefinite capacitance matrix problems in domain imbedding	65n30;equation derivee partielle;preconditionnement;methode discretisation;partial differential equation;ecuacion derivada parcial;decomposition domaine;capacitance matrix;capacitancia;domain decomposition;methode element fini;metodo elemento finito;equation ordre 2;duality;descomposicion dominio;preconditioning;second order equation;finite element method;maillage;interfase;equation elliptique;elliptic equation;metodo discretizacion;fast elliptic solvers;dualite;celdarada;interface;finite elements;grid pattern;precondicionamiento;discretization method;dualidad;capacitance;ecuacion orden 2;domain imbedding;hierarchical basis;nonsymmetric and indefinite problems;ecuacion eliptica;65f10;second order elliptic equation;capacite electrique	Based on the duality between the interface domain decomposition (or DD) methods and the capacitance matrix (or CM) methods in domain imbedding, and on the existing results for preconditioning nonsymmetric and indefinite finite element elliptic problems, preconditioners of optimal order for the CM problems are constructed. The preconditioning technique explores two-level hierarchical discretization of the imbedded problem on a coarse grid (of fixed size) and on a fine grid. The major part of the preconditioning then is reduced to solving systems with preconditioners for the capacitance matrix that corresponds to the principal symmetric and coercive part of the elliptic operator. The theory is illustrated with numerical experiments. Key words, capacitance matrix, domain imbedding, fast elliptic solvers, domain decomposition, hierarchical basis, nonsymmetric and indefinite problems, second order elliptic equation, finite elements AMS subject classifications, primary 65N30; secondary 65F10	discretization;domain decomposition methods;experiment;finite element method;numerical analysis;preconditioner;vhdl-ams	Wlodzimierz Proskurowski;Panayot S. Vassilevski	1995	SIAM J. Scientific Computing	10.1137/0916026	mathematical optimization;mathematical analysis;finite element method;calculus;mathematics;algebra	HPC	84.57491776055413	20.430841697236072	187315
380f775da9b0440e79bf1d90e909561873a0d250	reducing ranking effects in parallel adaptive quadrature	numerical solution;efficiency;quadratures;matrices;algorithms;error estimate;parallel processing;mathematics computers information science management law miscellaneous	We develop parallel one-dimensional globally adaptive quadrature algorithms, building on NAG code D01AKF. Our most eeective strategy replaces D01AKF's error estimate ranking strategy by a tabulation approach. D01AKF uses 61-point Gauss-Kronrod (GK) quadrature. We also use the 21-point GK rule. A fuller discussion, with expanded results, is given in 7].	adaptive quadrature;algorithm;gauss–kronrod quadrature formula;table (information)	Malgorzata A. Napierala;Ian Gladwell	1995			mathematical optimization;tanh-sinh quadrature;theoretical computer science;gauss–kronrod quadrature formula;mathematics;algorithm;clenshaw–curtis quadrature	Web+IR	84.59182040453784	21.634032858169327	187521
980d4348cf58ea74de1ef4fe0bca1549a4e1c491	a note on skewcirculant preconditioners for elliptic problems	circulant matrix;65n06;elliptic problem;finite difference method;fast fourier transform;ams mos 65f10;elliptic differential equations;condition number;preconditioned conjugate gradient	In a recent paper Chan and Chan study the use of circulant preconditioners for the solution of elliptic problems. They prove that circulant preconditioners can be chosen so that the condition number of the preconditioned system can be reduced fromO(n 2 ) toO(n). In addition, using the Fast Fourier Transform, the computation of the preconditioner is highly parallelizable. To obtain their result, Chan and Chan introduce a shift ρ/p/n 2 for some ρ>0. The aim of this paper is to consider skewcirculant preconditioners, and to show that in this case the condition number ofO(n) can easily be shown without using the somewhat unsatisfactory shift ρ/p/n 2. Furthermore, our estimates are more precise.	circulant matrix;computation;condition number;fast fourier transform;merge sort;preconditioner;timothy m. chan	Thomas Huckle	1992	Numerical Algorithms	10.1007/BF02139468	fast fourier transform;mathematical optimization;mathematical analysis;finite difference method;condition number;circulant matrix;mathematics;algorithm;algebra	Theory	83.27489254440495	22.24693390901749	188392
759087e9d210c7618d01f7d51a7280afb579b5ac	verified computations using taylor models and their applications		Numerical methods assuring confidence involve the treatment of entire sets instead of mere point evaluations. We briefly review the method of interval arithmetic that is long known for rigorous, verified computations, and all operations are conducted on intervals instead of numbers. However, interval computations suffer from overestimation, the dependency problem, the dimensionality curse, and the wrapping effect, to name a few, and those difficulties often make conventional interval based verified computational methods useless for practical challenging problems.	computation;verifiable computing	Kyoko Makino;Martin Berz	2017		10.1007/978-3-319-63501-9_1	theoretical computer science;curse of dimensionality;numerical analysis;computation;interval arithmetic;mathematical optimization;mathematics	NLP	83.59070860775037	25.23552355845253	189121
95553aa1d6646411c91d89d7bfab37720afbaa24	a class of nonsymmetric preconditioners for saddle point problems	sistema lineal;preconditionnement;iterative method;punto silla;matriz bloque;iterative process;ssor;saddle point problem;numerical solution;efficiency;navier stokes equations;complemento schur;point col;systeme indefini;ecuacion linearizada;schur complement;preconditioning;65k10;linear system;skew symmetric preconditioners;metodo iterativo;inner outer iterations;iterative methods;nonsymmetric indefinite linear systems;proceso iterativo;processus iteratif;eficacia;iteraccion;matrice bloc;methode iterative;equation navier stokes;equation linearisee;constraint preconditioners;saddle point problems;linearized equation;65f35;efficacite;iteration;65f22;block matrix;precondicionamiento;numerical experiment;iterative solution;systeme lineaire;systeme non symetrique;iteration method;complement schur;65f10;solution numerique;navier stokes equation;preconditioning methods;ecuacion navier stokes;65n22;saddle point	For iterative solution of saddle point problems, a nonsymmetric preconditioning is studied which, with respect to the upper-left block of the system matrix, can be seen as a variant of SSOR. An idealized situation where the SSOR is taken with respect to the skew-symmetric part plus the diagonal part of the upper-left block is analyzed in detail. Since action of the preconditioner involves solution of a Schur complement system, an inexact form of the preconditioner can be of interest. This results in an inner-outer iterative process. Numerical experiments with solution of linearized Navier-Stokes equations demonstrate efficiency of the new preconditioner, especially when the left-upper block is far from symmetric.	discretization;experiment;henk van der vorst;iteration;iterative method;lu decomposition;microsoft outlook for mac;navier–stokes equations;numerical method;preconditioner	Mike A. Botchev;Gene H. Golub	2006	SIAM J. Matrix Analysis Applications	10.1137/040618680	mathematical optimization;mathematical analysis;calculus;mathematics;iterative method;algebra	HPC	83.28797528914399	20.055905694204526	190564
5d693a3c4be6f0b02cfd24649527e8d91f026507	nonlinear model order reduction via lifting transformations and proper orthogonal decomposition		This paper presents a structure-exploiting nonlinear model reduction method for systems with general nonlinearities. First, the nonlinear model is lifted to a model with more structure via variable transformations and the introduction of auxiliary variables. The lifted model is equivalent to the original model—it uses a change of variables, but introduces no approximations. When discretized, the lifted model yields a polynomial system of either ordinary differential equations or differential algebraic equations, depending on the problem and lifting transformation. Proper orthogonal decomposition (POD) is applied to the lifted models, yielding a reduced-order model for which all reduced-order operators can be pre-computed. Thus, a key benefit of the approach is that there is no need for additional approximations of nonlinear terms, in contrast with existing nonlinear model reduction methods requiring sparse sampling or hyper-reduction. Application of the lifting and POD model reduction to the FitzHugh-Nagumo benchmark problem and to a tubular reactor model with Arrhenius reaction terms shows that the approach is competitive in terms of reduced model accuracy with state-of-the-art model reduction via POD and discrete empirical interpolation, while having the added benefits of opening new pathways for rigorous analysis and input-independent model reduction via the introduction of the lifted problem structure.		Boris Kramer;Karen Willcox	2018	CoRR		model order reduction;applied mathematics;mathematical optimization;operator (computer programming);sampling (statistics);ordinary differential equation;discretization;change of variables;polynomial;mathematics;nonlinear system	AI	88.51558244939784	20.934910780299063	192202
3e98d472c194b561ce83a867e066dcc14508836e	large-scale scientific computing		The construction of efficient iterative linear equation solvers for ill-conditioned general symmetric positive definite systems is discussed. Certain known two-level conjugate gradient preconditioning techniques are presented in a uniform way and are further generalized and optimized with respect to the spectral or the K-condition numbers. The resulting constructions have shown to be useful for the solution of largescale ill-conditioned symmetric positive definite linear systems.	computational science;condition number;conjugate gradient method;iterative method;linear equation;linear system;preconditioner	Jan van Leeuwen	2001		10.1007/3-540-45346-6	computer-aided engineering;computational science;computer science	Theory	84.77461202851872	22.360059073377293	192219
f1a23d6c3dfeddd7d995029cd7bf1e30a793852f	superapproximation for projections on spline spaces	analisis numerico;41a15;approximation numerique;aproximacion numerica;analyse numerique;aproximacion esplin;numerical analysis;65d07;spline approximation;approximation spline;methode maille;mesh method;metodo malla;numerical approximation;maille non uniforme;non uniform mesh	In this paper general conditions are given for the superapproximation of projections on non-uniform mesh multiple knot splines in Lp-spaces. Various known results are contained as special cases.		Rolf Dieter Grigorieff	2005	Numerische Mathematik	10.1007/s00211-004-0551-8	mathematical optimization;numerical analysis;calculus;mathematics;geometry;algorithm	ML	86.63725995901834	18.26297388111522	192550
dbb9f7081a77f5b25746726386d2675d6c4e7f67	static and dynamic numerical characteristics of floating-point arithmetic	computers;mathematics;rounding errors floating point arithmetic representational errors;probability density function;floating point arithmetic accuracy computers mathematics data mining probability density function mathematical model;data mining;rounding errors;accuracy;mathematical model;floating point;floating point arithmetic;representational errors	The appearance of hexadecimal floating-point arithmetic systems has prompted a continuing discourse on the relative numerical merits of various choices of base. Until lately this discourse has centered around the static properties of the floating-point representation of numbers, and has primarily concerned only binary and hexadecimal representations. Recent events may change this discourse considerably. A third numerically attractive alternative for the choice of base has been proposed, and a comparison of the dynamic numerical properties of floating-point arithmetic systems has been completed. This paper surveys these recent events and summarizes our current knowledge of the numerical characteristics of floating-point arithmetic systems.	binary file;bitwise operation;hexadecimal;numerical analysis	William J. Cody	1973	IEEE Transactions on Computers	10.1109/TC.1973.5009112	arithmetic;minifloat;parallel computing;arbitrary-precision arithmetic;binary scaling;computer science;floating point;theoretical computer science;operating system;affine arithmetic;mathematics;machine epsilon;algorithm;statistics	SE	89.30784706671946	26.470614137223258	193228
c93775cc523795aceb03ebba06d69a24f3c6ae1e	solving irregular sparse linear systems on a multicomputer using the cgnr method	distributed memory;convergence rate;data distribution;conjugate gradient;col;parallel computer;iteration method;preconditioned conjugate gradient;sparse linear system;direct method	The eecient solution of irregular sparse linear systems on a distributed memory parallel computer is still a major challenge. Direct methods are concerned with unbalanced load processing or data distribution as well as diiculties pertaining to reuse eecient sequential codes. Iterative methods of the Krylov family are well suited for parallel computing but can provide disappointing convergence for general sparse problems. Therefore nding eecient parallel preconditioners is often required to obtain acceptable convergence rates. In this paper we explore the use of a pre-conditioned Conjugate Gradient algorithm for the parallel solution of irregular sparse nonsymmetric systems. A rst step is the choice of a high quality algorithm for matrix partitioning. For this purpose we have selected the Metis package, developed by Karypis and Kumar of the University of Minnesota. A second step is the choice of the preconditioner. We have selected the Block Jacobi preconditioner for its inherent parallelism and the local dense computation it generates. The iterative method itself is the standard conjugate gradient on the normal equations (known as CGNR). Experimental results are reported involving problems from the Harwell-Boeing collection executed on the Intel Paragon utilizing the Aztec distributed iterative library of the Sandia Laboratories.	algorithm;b. j. fogg;barrett reduction;code;computation;condition number;conjugate gradient method;display resolution;distributed memory;free license;intel paragon;iterative method;krylov subspace;linear least squares (mathematics);linear system;metis;parallel computing;preconditioner;solver;sparse matrix;the matrix;unbalanced circuit	Pierre Manneback	1997	IJHPCA	10.1177/109434209701100303	direct method;mathematical optimization;parallel computing;conjugate residual method;distributed memory;computer science;theoretical computer science;derivation of the conjugate gradient method;preconditioner;iterative method;conjugate gradient method;rate of convergence	HPC	84.53722067823603	22.83726991400472	193558
b5214d405be965eee7ea0f0470b1ec357a66b395	a new disk-based technique for solving the largeness problem of stochastic modeling formalisms	largeness tolerance methods;disk based segmentation;numerical technique;gauss elimination;stochastic petri net;stochastic reward net;stochastic system;stochastic reward nets;markov model;direct methods;markov process;stochastic model;iteration method;manufacturing system;direct method;generalized stochastic petri net;markov chain;dynamic behavior	Stochastic modeling formalisms such as stochastic Petri nets, generalized stochastic Petri nets, and stochastic reward nets can be used to model and evaluate the dynamic behavior of realistic computer systems. Once we translate the stochastic system model to the underlying corresponding Markov Chain (MC), the developed MC grows wildly to several hundred thousands states. This problem is known as the largeness problem. To tolerate the largeness problem of Markov models, several iterative and direct methods have been proposed in the literature. Although the iterative methods provide a feasible solution for most realistic systems, a major problem appears when these methods fail to reach a solution. Unfortunately, the direct method represents an undesirable numerical technique for tolerating large matrices due to the fill-in problem. In order to solve such problem, in this paper, we develop a Disk-Based Segmentation (DBS) technique based on modifying the Gauss Elimination (GE) technique. The proposed technique has the capability of solving the consequences of the fill-in problem without making assumptions about the underlying structure of the Markov processes of the developed model. The DBS technique splits the matrix into a number of vertical segments and uses the hard disk to store these segments. Using the DBS technique, we can greatly reduce the memory required as compared to that of the GE technique. To minimize the increase in the solution time due to the disk accessing processes, the DBS utilizes a clever management technique for such processes. The effectiveness of the DBS technique has been demonstrated by applying it to a realistic model for the Kanban manufacturing system.	approximation algorithm;byzantine fault tolerance;column (database);computation;dos;deep brain stimulation;direct method in the calculus of variations;direct-broadcast satellite;gaussian elimination;hard disk drive;iterative method;kanban (development);logical disk manager;markov chain;markov model;numerical analysis;recurrent neural network;requirement;steady state;stochastic petri net;stochastic modelling (insurance);stochastic process;system under test;the matrix;triangular matrix	Samir M. Koriem;Wail S. El-Kilani	2004	Journal of Systems and Software	10.1016/S0164-1212(03)00210-3	direct method;markov chain;mathematical optimization;gaussian elimination;simulation;stochastic petri net;computer science;stochastic modelling;theoretical computer science;iterative method;markov process;markov model;statistics	AI	86.90764030412161	23.322673537046985	193640
c7ae9c8298d559a4e56ea44bb20551a7b9678a07	weighted extended b-spline approximation of dirichlet problems	65n30;dimensionalidad;generation;41a63;distance function;hipersuperficie;peso;weighted approximation;fonctionnelle;methode element fini;metodo elemento finito;41a15;smooth approximation;generacion;implementation;aproximacion;weighting;dirichlet problem;dimensionality;fonction distance;finite element method;maillage;ponderacion;probleme dirichlet;meshless method;smooth form;finite element;approximation;stability;funcional;resolucion problema;ejecucion;forma lisa;aproximacion esplin;domaine;weight;celdarada;functional;approximation ponderee;dimensionnalite;spline approximation;approximation spline;poids;problema dirichlet;b spline approximation;regular grid;approximation reguliere;grid pattern;domains;b spline;approximation b spline;ponderation;forme lisse;stabilite;element fini;estabilidad;elemento finito;b splin;hypersurface;65n12;problem solving;resolution probleme	We describe a new finite element method which uses weighted extended B-splines on a regular grid as basis functions for solving Dirichlet problems on bounded domains in arbitrary dimensions. This web-method does not require any grid generation and can be implemented very efficiently. It yields smooth, high order accurate approximations with relatively low dimensional subspaces.	approximation;b-spline;basis function;boundary element method;condition number;finite element method;galerkin method;iterative method;mesh generation;meshfree methods;preprocessor;regular grid;simulation;structural analysis	Klaus Höllig;Ulrich Reif;Joachim Wipper	2001	SIAM J. Numerical Analysis	10.1137/S0036142900373208	mathematical optimization;mathematical analysis;finite element method;calculus;mathematics;geometry	Theory	86.86901866423177	18.453920786234082	195278
2f2d7864f440124c80945f9fdc19dac56bb6fa73	acceleration methods for total variation-based image denoising	65d05;calcul scientifique;analisis numerico;interpolation;convergence;fixed point method;image processing;nonlinear partial differential equation;interpolacion;multigrille;ecuacion lineal;punto fijo;image restoration;maillage;methode algebrique;fixed point iteration;analyse numerique;convergencia;computacion cientifica;iteraccion;numerical analysis;celdarada;point fixe;interpolation method;algebraic method;multigrid;numerical algorithm;algebraic multigrid method;nonlinear problem;multigrilla;mathematical model;iteration;grid pattern;algebraic multigrid;total variation;krylov acceleration;image denoising;metodo algebraico;krylov subspace;numerical experiment;linear equations;linear equation;scientific computation;65f30;fix point;equation lineaire	For a given blur, we apply a fixed point method to solve the total variation-based image restoration problem. A new algorithm for the discretized system is presented. Convergence of outer iteration is efficiently improved by adding a linear term on both sides of the system of nonlinear equations. In inner iteration, an algebraic multigrid (AMG) method is applied to solve the linearized systems of equations. We adopt the Krylov subspace method to accelerate the outer nonlinear iteration.	algorithm;circuit restoration;discretization;fixed point (mathematics);fixed-point iteration;gaussian blur;image restoration;iterative method;krylov subspace;linear algebra;multigrid method;noise reduction;nonlinear system;term (logic)	Qianshun Chang;I-Liang Chern	2003	SIAM J. Scientific Computing	10.1137/S106482750241534X	fixed-point iteration;mathematical optimization;mathematical analysis;discrete mathematics;image processing;interpolation;mathematics;linear equation;algorithm;multigrid method;algebra	ML	83.77632155848072	19.990176934877322	195421
759a9532daddf8c921b92a457e33911ad6af4c07	adaptive compression of large vectors	adaptive approximation;data sparse representation;ℋ matrices	Numerical algorithms for elliptic partial differential equations frequently employ error estimators and adaptive mesh refinement strategies in order to reduce the computational cost. #R##N#We can extend these techniques to general vectors by splitting the vectors into a hierarchically organized partition of subsets and using appropriate bases to represent the corresponding parts of the vectors. This leads to the concept of \emph{hierarchical vectors}. #R##N#A hierarchical vector with $m$ subsets and bases of rank $k$ requires $mk$ units of storage, and typical operations like the evaluation of norms and inner products or linear updates can be carried out in $\mathcal{O}(mk^2)$ operations. #R##N#Using an auxiliary basis, the product of a hierarchical vector and an $\mathcal{H}^2$-matrix can also be computed in $\mathcal{O}(mk^2)$ operations, and if the result admits an approximation with $\widetilde m$ subsets in the original basis, this approximation can be obtained in $\mathcal{O}((m+\widetilde m)k^2)$ operations. Since it is possible to compute the corresponding approximation error exactly, sophisticated error control strategies can be used to ensure the optimal compression. #R##N#Possible applications of hierarchical vectors include the approximation of eigenvectors and the solution of time-dependent problems with moving local irregularities.	adaptive compression	Steffen Börm	2018	Math. Comput.	10.1090/mcom/3203	mathematical optimization;combinatorics;mathematical analysis;discrete mathematics;mathematics;geometry;algorithm;statistics;algebra	Theory	90.24613457938774	18.842820594695688	196327
71c423c980a5f524add367cc66fa01186e6930b8	variable block multilevel iterative solution of general sparse linear systems	institutional repository research archive oaister	We present numerical results with a variable block multilevel incomplete LU factorization preconditioners for solving sparse linear sys- tems arising, e.g., from the discretization of 2D and 3D partial differential equations on unstructured meshes. The proposed method automatically detects and exploits any available block structure in the matrix to maxi- mize computational efficiency. Both sequential and parallel experiments are shown on selected matrix problems in different application areas, also against other standard preconditioners.	iterative method;linear system;sparse matrix	Bruno Carpentieri;Jia Liao;Masha Sosonkina	2013		10.1007/978-3-642-55195-6_49	mathematical optimization;computer science;theoretical computer science	HPC	84.68873074785488	21.76093644446951	197658
e26084c7237a5e5bd14a026fac3824277246887c	improvement of space-invariant image deblurring by preconditioned landweber iterations	metodo regularizacion;calcul scientifique;15a18;preconditionnement;iterative method;analisis numerico;problema mal planteado;regularisation;convergence;regularization method;probleme mal pose;image deblurring;methode regularisation;tion;preconditioning;regulariza;analyse numerique;regularization;metodo iterativo;algorithme;algorithm;reconstruction image;convergencia;computacion cientifica;iteraccion;numerical analysis;reconstruccion imagen;methode iterative;image reconstruction;ill posed problem;algebra lineal numerica;algebre lineaire numerique;iteration;65f22;precondicionamiento;regularizacion;numerical linear algebra;scientific computation;two level toeplitz and circulant matrices;landweber;65f10;45q05;58j70;analyse convergence;algoritmo	The Landweber method is a simple and flexible iterative regularization algorithm, whose projected variant provides nonnegative image reconstructions. Since the method is usually very slow, we apply circulant preconditioners, exploiting the shift invariance of many deblurring problems, in order to accelerate the convergence. This way reasonable reconstructions can be obtained within few iterations: the method becomes competitive and more robust than other approaches that, although faster, sometimes lead to lower accuracy. Some theoretical analysis of convergence is given, together with numerical validations.	algorithm;circulant matrix;deblurring;fast fourier transform;generalized minimal residual method;karush–kuhn–tucker conditions;landweber iteration;numerical analysis;periodic boundary conditions;preconditioner;robustness (computer science);signal-to-noise ratio;well-posed problem;white noise	Paola Brianzi;Fabio Di Benedetto;Claudio Estatico	2008	SIAM J. Scientific Computing	10.1137/050636024	iterative reconstruction;regularization;mathematical optimization;iteration;convergence;numerical analysis;landweber iteration;calculus;mathematics;preconditioner;geometry;iterative method;numerical linear algebra;algorithm;algebra	Vision	83.37965311306436	20.4051502581477	197700
f513a6a151ca8e3cb9ee17612d0afa6f2d4a6226	a domain decomposition multilevel preconditioner for interpolation with radial basis functions		We present the reasonableness of the extension of a two-level domain decomposition method to a multilevel method as a preconditioner for interpolation with radial basis functions (RBF) on distributed memory systems. The arising subproblems are efficiently solved using the FGP algorithm, a method that is well-suited for shared memory settings.	domain decomposition methods;interpolation;preconditioner;radial (radio);radial basis function	Gundolf Haase;Dirk Martin;Patrick Schiffmann;Günter Offner	2017		10.1007/978-3-319-73441-5_55	interpolation;domain decomposition methods;mathematical optimization;preconditioner;radial basis function;distributed memory;shared memory;mathematics	Crypto	85.31488267116087	21.932480453025743	197932
5de6e0ad6a5159ff7812d657d6b83f1b1bc4d551	a second order l0 stable algorithm for evaluating european options	second order;parallel computing;finite differencing;european option;high performance computing;pade approximation;finite difference;option pricing;shared memory multiprocessors;european options;computational finance	In this paper, we studythe option pricing problem,one of the prominent and challenging problems in computational finance. Using Pade approximation,we have developed a second order L0 stable discrete parallel algorithm for experimentation on advanced architectures. This algorithm is suitable for more complicated option pricing problems. For simulation purposes, we have implemented thesequential version of this algorithm and evaluated the European Options. Numerical results are compared with those obtained using othercommonly used numerical methods and shown that the new algorithm is robust and efficient than the traditional schemes. Using explicit Forward Time Centered Spaace (FTCS) on the reduced Black-Scholes partial differential equation, we report pricing of European options. We have done our experiments on a shared memory multiprocessor machine using OpenMP and report a maximum speedup of 3.43 with 16 threads.	approximation;black–scholes model;computation;computational finance;experiment;ftcs scheme;multiprocessing;numerical method;openmp;padé approximant;parallel algorithm;shared memory;simulation;speedup	Ruppa K. Thulasiram;Chen Zhen;Abba B. Gumel	2004		10.1504/IJHPCN.2006.013486	padé approximant;mathematical optimization;finite difference;parallel computing;simulation;computational finance;computer science;theoretical computer science;valuation of options;finite difference methods for option pricing;second-order logic	HPC	88.5975632876722	19.769336706867094	199712
fa84fa4eb281d638373e83e0a27759d29ff8fc3b	optimizing two-level preconditionings for the conjugate gradient method	nombre condition spectral;sistema lineal;preconditionnement;iterative method;symmetric positive definite;spectral condition number;ecuacion lineal;preconditioning;conjugate gradient method;matriz simetrica;nombre condition;linear system;k condition number;symmetric matrix;metodo iterativo;large scale;conjugate gradient;internal report;matrice definie positive;positive definite matrix;metodo gradiente conjugado;methode iterative;robustesse;condition number;robust preconditioning;matrice symetrique;robustness;precondicionamiento;methode gradient conjugue;linear equations;escala grande;systeme lineaire;matriz definida positiva;linear equation;two level preconditioning;nombre condition k;equation lineaire;robustez;echelle grande	The construction of efficient iterative linear equation solvers for ill-conditioned general symmetric positive definite systems is discussed. Certain known two-level conjugate gradient preconditioning techniques are presented in a uniform way and are further generalized and optimized with respect to the spectral or the K-condition numbers. The resulting constructions have shown to be useful for the solution of largescale ill-conditioned symmetric positive definite linear systems.	conjugate gradient method;optimizing compiler	Owe Axelsson;Igor E. Kaporin	2001		10.1007/3-540-45346-6_1	mathematical analysis;conjugate residual method;calculus;derivation of the conjugate gradient method;mathematics;geometry;conjugate gradient method;linear equation;nonlinear conjugate gradient method	EDA	82.9670077953843	20.803871894150106	199811
