id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
42b99524464b65673cda78f95238650e3f8cc63e	generating robust assembly plans in constrained environments	graph theory;mobile robot;robust assembly plan;degree of freedom;mobile robots;automatic assembly sequence generation;automatic generation;robotic assembly graph theory mobile robots multi robot systems robot kinematics;assembly planning;kinematic feasibility;structured factory environment;multi robot systems;robotic assembly;mobile robot robust assembly plan structured factory environment robot team automatic assembly sequence generation graph based framework kinematic feasibility;graph based framework;robustness robotic assembly orbital robotics mobile robots robotics and automation legged locomotion usa councils mars production facilities kinematics;robot kinematics;robot team	In the future, teams of robots will construct outposts on Mars and orbital structures in space. Such tasks will require assembly of a large number of components into structures. Automatic generation of assembly sequences is a difficult and well-studied problem in structured factory environments that are specifically engineered for the assembly task at hand, but it is much less understood in less constrained settings. Instead of representing the problem in the space of the many degrees of freedom of the robots and components involved in the assembly, we approach the problem in the space of valid configurations of the structure to be assembled. We use a graph-based framework to describe valid assembly configurations and feasible assembly steps. In addition to reasoning about kinematic feasibility of assembly steps, we consider the quality of potential configurations with respect to actions for the mobile robots. This method automatically repositions the structure in the workspace so that components to be assembled are most approachable. That is, the sequence of assembly and the position of the structure as it is assembled is chosen so as to maximize the area in which mobile robots can operate to perform their tasks. We present simulation results from a simple five-component assembly with and without the constraints of a narrow confined environment. Results show that our method allows over twice as much space available for robots during assembly. In addition, the plans preserve most of their free-space flexibility in tight workspaces where other planning approaches are left with only a few candidate solutions.	assembly language;automated planning and scheduling;autonomous robot;executable;graph (discrete mathematics);mobile robot;molecular orbital;motion planning;scheduling (computing);simulation;software factory;testbed;workspace	Frederik W. Heger	2008	2008 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2008.4543836	control engineering;mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence;graph theory	Robotics	56.16694592882881	-24.67652798605293	63660
4864fa3a5a6dc95ab8b205329b93f37ab7875a84	design and development of a soft robotic octopus arm exploiting embodied intelligence	artificial muscular hydrostat;manipulators;new technology;motion control;embodied intelligence exploitation;design and development;prototypes;tissue mechanical characteristics;wires;actuators;actuators springs robots prototypes muscles wires morphology;soft robotic octopus arm design;robot arm;morphology;springs;arm morphology;marine animal;robots;artificial intelligence;movement control;soft robotic octopus arm development;artificial muscular hydrostat soft robotic octopus arm design soft robotic octopus arm development embodied intelligence exploitation marine animal arm morphology tissue mechanical characteristics movement control;motion control artificial intelligence manipulators marine systems;muscles;marine systems	The octopus is a marine animal whose body has no rigid structures. It has eight arms mainly composed of muscles organized in a peculiar structure, named muscular hydrostat, that can change stiffness and that is used as a sort of a modifiable skeleton. Furthermore, the morphology of the arms and the mechanical characteristics of their tissues are such that the interaction with the environment, namely water, is exploited to simplify the control of movements. From these considerations, the octopus emerges as a paradigmatic example of embodied intelligence and a good model for soft robotics. In this paper the design and the development of an artificial muscular hydrostat are reported, underling the efforts in the design and development of new technologies for soft robotics, like materials, mechanisms, soft actuators. The first prototype of soft robot arm is presented, with experimental results that show its capability to perform the basic movements of the octopus arm (like elongation, shortening, and bending) and demonstrate how embodiment can be effective in the design of robots.	biomimetics;coat of arms;coherence (physics);lagrangian relaxation;mathematical morphology;prototype;robot;robotic arm;self-replicating machine;skin (computing);soft robotics;transverse wave;workspace	Matteo Cianchetti;Maurizio Follador;Barbara Mazzolai;Paolo Dario;Cecilia Laschi	2012	2012 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2012.6224696	robot;motion control;simulation;robotic arm;morphology;computer science;engineering;artificial intelligence;prototype;actuator	Robotics	68.15340068600649	-25.678389886362698	63991
b5856e867e9974b6534b1f2a1f3db859490bc692	control of a pcb drilling machine by visual feedback	visual feedback	A v i s u a l i n p u t i s l i k e l y t o p l a y a n i m p o r t a n t r o l e i n many f u t u r e m e c h a n i c a l h a n d l i n g and i n s p e c t i o n systems. T h i s paper w i l l d e s c r i b e one e x p e r i m e n t a l i m p l e m e n t a t i o n o f a machine o f t h i s t y p e ; a n a u t o m a t i c p r i n t e d c i r c u i t b o a r d d r i l l i n g machine i n w h i c h a T V camera i s used t o v i e w t h e b o a r d and a s m a l l computer i s used t o p r o c e s s t h e TV image. The computer c o n t r o l s t h e machine u s i n g o n l y t h e i n f o r m a t i o n e x t r a c t e d f r o m t h e p i c t u r e . I n t r o d u c t i o n I t i s becoming i n c r e a s i n g l y d i f f i c u l t f o r i n d u s t r y t o f i n d p e o p l e who a r e w i l l i n g t o d o d a n g e r o u s or monotonous j o b s . Those who a r e p e r f o r m i n g b o r i n g o r r e p e t i t i v e t a s k s a r e l i a b l e t o become f r u s t r a t e d and e r r o r p r o n e . Problems o f t h i s t y p e t o g e t h e r w i t h t h e i n c r e a s i n g c o s t o f manpower p r o v i d e s t r o n g i n c e n t i v e s f o r i n d u s t r y t o automate t h e i r p r o d u e t i o n l i n e s . W i t h t h e advent o f c o m p u t e r s , t r a d i t i o n a l f i x e d a u t o m a t i o n i s b e i n g s e l e c t i v e l y r e p l a c e d b y programmable n u m e r i c a l l y cont r o l l e d m a c h i n e s . These machines n e v e r t h e l e s s f o l l o w a f i x e d s e t o f i n s t r u c t i o n s , and i n g e n e r a l t h e y c a n n o t cope w i t h a change i n t h e i r e n v i r o n m e n t . A s c o m p u t e r s have become cheaper and more p o w e r f u l i t has become p o s s i b l e t o i n t r o d u c e i n t o f a c t o r i e s more i n t e l l i g e nt machines ( 1 ) w h i c h a r e aware o f t h e i r e n v i ronment and w h i c h a r e c a p a b l e o f r e a c t i n g t o changes i n t h a t e n v i r o n m e n t . Examples o f t h i s t y p e o f machine i n c l u d e H i t a c h i ' s v i s u a l l y c o n t r o l l e d b o l t t i g h t e n e r , and G e n e r a l M o t o r ' s system f o r p l a c i n g w h e e l s o n hubs ( 2 , 3 ) . I n t h i s paper w e a r e c o n c e r n e d w i t h m a c h i n e s w h i c h examine t h e i r e n v i r o n m e n t w i t h v i s u a l s e n s o r s and w h i c h we c a l l v i s u a l l y c o n t r o l l e d m a c h i n e s . Much o f t h e d i s c u s s i o n however w o u l d a p p l y t o machines e q u i p p e d w i t h o t h e r t y p e s o f s e n s o r . J u s t i f i c a t i o n f o r V i s u a l l y C o n t r o l l e d A u t o m a t i o n I t can b e a r g u e d t h a t t h e r e s h o u l d b e n o need f o r v i s u a l l y c o n t r o l l e d m a c h i n e s i n t h e i d e a l a u t o m a t i c f a c t o r y . C o n s i d e r f o r example, t h e p r o b l e m o f a u t o m a t i c a s s e m b l y . I f t h e o r i e n t a t i o n and p o s i t i o n o f a l l components were p r e s e r v e d f r o m t h e p o i n t o f i n i t i a l f a b r i c a t i o n , where t h e y are w e l l known, t o t h e f i n a l assembly i n t o t h e c o m p l e t e d p r o d u c t , t h e n ' b l i n d a u t o m a t i o n ' w o u l d b e q u i t e s a t i s f a c t o r y . I n p r a c t i c e however t h e r e a r e many r e a s o n s why t h i s d e s i r a b l e g o a l c a n n o t be a c h i e v e d . I t may o f t e n b e n e c e s s a r y t o M e t go' o f p a r t s , ( f o r example when s m a l l s h e e t m e t a l p r e s s i n g s a r e p l a t e d o r d e b u r r e d ) , and t o s t o r e t hem between m a n u f a c t u r e and a s s e m b l y . If t h e components a r e s t o r e d i n a ' l o o s e ' s t a t e , t h e n e i t h e r a p e r s o n o r a machine i s r e q u i r e d t o f e e d t h e component t o t h e a u t o m a t i c assembly machine. I n many c a s e s , t h i s p r o b l e m i s s o l v e d by i n g e n i o u s m e c h a n i c a l d e s i g n s such as bowl f e e d e r s . Some components however p r o v i d e h a r d e r p r o b l e m s f o r t h e m e c h a n i c a l d e s i g n e r and i t i s i n t h e s e c i r c u m s t a n c e s t h a t a v i s u a l l y c o n t r o l l e d machine i s u s e f u l . Thus v i s u a l l y c o n t r o l l e d machines may b e c o s t e f f e r t i v e when i t i s uneconomic t o keep components i n j i g s , when f r e q u e n t p r o d u c t changes make c o m p l e t e programming e x p e n s i v e , o r when i t i s i m p o r t a n t t o d e t e c t d r i f t s i n t h e p r o d u c t o r machine ( 2 5 ) . The A p p l i c a t i o n o f V i s u a l C o n t r o l t o D r i l l i n g P r i n t e d C i r c u i t Boards The d r i l l i n g o f P r i n t e d C i r c u i t Boards (PCBs) under v i s u a l c o n t r o l i s a p r o b l e m i n w h i c h b o t h t h e m e c h a n i c s and t h e scene a n a l y s i s a r e r e l a t i v e l y s i m p l e . The s o l u t i o n t o t h e p r o b l e m c o u l d however have g e n u i n e p r a c t i c a l a p p l i c a t i o n . I n r e s e a r c h l a b o r a t o r i e s and o t h e r e s t a b l i s h ments i n w h i c h PCBs a r e made i n v e r y s h o r t r u n s o f s m a l l numbers o f b o a r d s , t h e b o a r d s a r e o f t e n d r i l l e d by hand u s i n g a s i n g l e s p i n d l e d r i l l i n g machine such a s t h a t i l l u s t r a t e d d i a g r a m m a t i c a l l y i n F i g . l a . 1 . The Manual D r i l l i n g o f P r i n t e d C i r c u i t Boards The o p e r a t o r v i e w s t h e b o a r d t h r o u g h t h e e y e p i e c e , w h i c h c o n t a i n s a c r o s s w i r e i n d i c a t i n g t h e p o s i t i o n o f t h e d r i l l ( F i g . l b ) . T o d r i l l a h o l e , he moves t h e b o a r d u n t i l t h e p o i n t t o be d r i l l e d c o i n c i d e s w i t h t h e c r o s s w i r e , and t h e n a c t u a t e s t h e d r i l l . The e x p e r i m e n t a l equipment b u i I t a t MRL t o aut o m a t e t h i s p r o c e s s and r e p l a c e t h e human o p e r a t o r b y a computer v i s i o n s y s t e m , i s i l l u s t r a t e d d i a g r a m m a t i c a l l y i n F i g . 2 and b y t h e p h o t o g r a p h i n F i g . 3 . The b o a r d i s v i e w e d , v i a a h a l f s i l v e r e d m i r r o r , b y a T V camera w h i c h i s i n t e r f a c e d to a H o n e y w e l l 516 c o m p u t e r . The TV v i d e o s i g n a l can b e sampled w i t h a maximum r e s o l u t i o n o f 300 x 400 p i c t u r e e l e m e n t s ( p i x e l s ) o v e r t h e f i e l d o f v i e w o f t h e camera, and each p i x e l can b e d i g i t i s e d t o 5 b i t s .	artificial intelligence;digital-to-analog converter;emoticon;media resource locator;radio frequency;system f	J. Hale;P. Saraga	1975			computer vision;simulation;computer science;machine perception	AI	66.74987168271768	-34.28047577864183	64010
de8f09746ec3a023b70aeff7c62db349cd82fabb	multi-robot gas-source localization based on reinforcement learning	strategy sharing gas source localization multiple robots turbulence dominated airflow environment reinforcement learning;turbulence diffusion gas sensors learning artificial intelligence mobile robots multi robot systems;multirobot based gas source localization large scale advection diffusion simulated plume environments strategy sharing based rl algorithm searching efficiency improvement gsl task multiple robot training multiagent reinforcement learning algorithm turbulence dominated airflow environments	Multi-robot based gas source localization (GSL) in turbulence dominated airflow environments is addressed. A multi-agent reinforcement learning (RL) algorithm is proposed for training multiple robots to finish the GSL task. To improve searching efficiency, the strategy-sharing based RL algorithm is implemented for the GSL task in three different large-scale advection-diffusion simulated plume environments by using different number of robots. Simulation results show that multiple robots could successfully locate the gas source in turbulence dominated airflow environments with the proposed algorithm; Moreover, the results also demonstrate that the strategy-sharing RL outperforms the RL which does not share strategies.	algorithm;gnu scientific library;multi-agent system;plume (fluid dynamics);reinforcement learning;robot;simulation;turbulence	Jian-Long Wei;Ming Zeng;Ci Yan;Ming Zeng;Wei Li	2012	2012 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2012.6491171	simulation;engineering;artificial intelligence;machine learning	Robotics	56.71213423097109	-23.965820118464794	64159
32955678f2abdaf673b69943bad71a9f95791dec	current and future perspective of honda humamoid robot	legged locomotion;biped robot;mechanical stability;humanoid robots legged locomotion leg joints mobile robots humans intelligent robots fingers knee research and development;stability legged locomotion mechanical stability;stability;structural dynamics;stability maintenance honda humamoid robot legged locomotion biped robot	Noting that legged locomotion allows greater mobility than motion on wheels, the authors describe how they developed a biped robot capable of walking like a human. They discuss the leg's structure, dynamics etc. Ways of maintaining stability are considered. Areas on which future development efforts will be focussed are outlined.	robot	Kazuo Hirai	1997		10.1109/IROS.1997.655059	control engineering;mobile robot;structural dynamics;simulation;stability;engineering;humanoid robot;robot locomotion;control theory;robot control;statistics	Robotics	67.20710801426331	-26.346659164909667	64279
d8e4d5b0fbf03646b91702becd5d63c8a42dfa5e	development of urc testing & certification system	certification;intelligent robots;service quality ubiquitous robotic companion intelligent service robot industrial robot test specification certification system;service robots;ubiquitous computing certification industrial robots intelligent robots robot vision service robots;certification system;robot vision;industrial robots;system testing certification service robots intelligent robots safety communication system control standards development computational intelligence robotics and automation automatic testing;ubiquitous robotic companion;service robot;ubiquitous computing;test specification;intelligent service robot;service quality;industrial robot	Ubiquitous robotic companion (URC) is defined as a network-based intelligent service robot and it is in the early stage on commercial. URC provides various services directly to a user at close hand compare to industrial robot, and thus malfunction or electric unstability of URC can be a significant problem to the user. The poor service quality can also make a bad robot image and it can be an obstacle in robot commercialization. In this respect, the safety and service quality should be guaranteed. This paper focuses on a test specification and certification system of URC to guarantee the service quality and safety.	industrial robot;service robot;universal remote console	Sang-Guk Jung;Shim-Seok Lee;Yong-Bum Park;Jang-Kyung Kim	2007	2007 International Symposium on Computational Intelligence in Robotics and Automation	10.1109/CIRA.2007.382897	embedded system;simulation;computer science;certification;ubiquitous computing;service quality	Robotics	62.4651758137298	-28.6230851575697	64549
c66412cb1caea779897070d74b6f316e7f1d465f	autonomous pipeline inspection and maintenance robot with inch worm mobile mechanism	robot sensing systems;pipelines inspection mobile robots space technology intelligent robots service robots flanges robot sensing systems humans prototypes;intelligent robots;mobile robot;prototypes;service robots;mobile robots;inspection;pipelines;flanges;humans;space technology;control method	A new type of mobile robots with the inch worm mechanism is presented in this paper for inspecting pipelines from the outside of pipe surfaces under hostile environments. This robot, Mark 111, is made after the successful investigation of the prototypes, Mark I and 11, which can pass over obstacles on pipelines, such as flanges and T-joints and others. Newly developed robot, Mark 111, can move vertically along the pipeline and move to the adjacent pipeline for the inspection. The sensors, infra ray proximity sensor and ultra sonic sensors and others, are installed to detect these obstacles and can move autonomously controlled by the microprocessor. The control method of this robot can be carried out by the dual control mode proposed in this paper.	autonomous robot;microprocessor;mobile robot;pipeline (computing);sensor	Toshio Fukuda;Hidemi Hosokai;Masashi Otsuka	1987		10.1109/ROBOT.1987.1087850	mobile robot;embedded system;computer vision;simulation;computer science;engineering;artificial intelligence;social robot;robot control	Robotics	57.86211523772189	-31.596639391078266	64567
20d951b576458372a373b29712ae16b5d00e1990	intention recognition by inverted two-wheeled mobile robot through interactive operation	pendulums learning systems mobile robots nonlinear systems;assistive control learning control interactive operation cooperative operation inverted pendulum two wheeled mobile robots luggage transportation user intention recognition;mobile robots robot sensing systems wheels transportation angular velocity mobile communication	Recently, two-wheeled inverted pendulum mobile robots have been popular. They support human locomotion and/or small goods transportation based on inverted pendulum upright controllers. The conventional inverted pendulum mobile robot controls to follow the fixed desired posture angle and wheel velocity. It is desirable to change the control parameters according to the user intention in order to offer comfortable operability of the robot. This paper proposes a user intention recognition system for a inverted pendulum mobile robot and shows experimental results.	inverted pendulum;mobile robot;operability;poor posture;velocity (software development)	Shinnosuke Nomura;Takuya Inoue;Yasutake Takahashi;Takayuki Nakamura	2014	2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/SCIS-ISIS.2014.7044740	mobile robot;computer vision;simulation;social robot;robot control	Robotics	64.49464085663479	-24.395771748068615	64587
1812498a566ceccd94af1de75af2f69cfbafd71c	evolvable mechanics: hardware tools for evolutionary robotics	experimental design;autonomous robotic evolvable mechanics hardware tool evolutionary robotic articulated joint evolutionary search cost effective actuator module software controlled compliance arbitrary mechanical spring damping embedded control system minimal walking robot;damping;springs mechanical actuators compliance control control engineering computing damping evolutionary computation force control legged locomotion mechanical engineering computing motion control search problems;mechanical engineering computing;evolutionary computation;motion control;embedded control system;autonomous robotic;legged locomotion;articulated joint;iron;actuators;adaptive behavior;evolutionary search;arbitrary mechanical spring damping;compliance control;force;actuators springs force damping legged locomotion leg;springs mechanical;minimal walking robot;springs;evolutionary robotics;walking robot;software controlled compliance;cost effective actuator module;cost effectiveness;control engineering computing;search problems;evolutionary robotic;hardware tool;autonomous robot;leg;evolvable mechanics;force control	Embodying robot morphologies evolved in simulation can present serious problems for an engineer when translating simplified simulated mechanisms into working devices, often drawing on pre-existing component parts to provide specific functions, to reduce construction times and to cut costs. Actuators for generating motion in articulated joints are key components of any robot and a vast range of compact, low cost devices are available, but their behavior is based on generating positions and velocities by ironing out perturbations. In simulation it is easy to create variable compliance actuation schemes where damping and spring forces used to guide motion can be subject to evolutionary search and aid the generation of efficient adaptive behavior. We present an experimental design for a cost effective actuator module with software controlled compliance that can approximate arbitrary mechanical spring damping systems, with parameters that are software configurable at run time. The benefits of this software controlled compliance and the versatility of our embedded control system are demonstrated in a minimal walking robot. The potential value and inherent limitations of this device as a tool for evolutionary robotics, where software controlled compliant properties can form part of an evolutionary search, and in the wider field of autonomous robotics, are discussed.	adaptive behavior;approximation algorithm;autonomous robot;control system;design of experiments;embedded system;evolutionary algorithm;evolutionary robotics;genetic algorithm;mobile robot;perturbation theory;prototype;reconfigurable computing;refinement (computing);run time (program lifecycle phase);simulation;testbed	Bill Bigge Inman;R. Harvey	2010	IEEE Congress on Evolutionary Computation	10.1109/CEC.2010.5586134	damping;motion control;simulation;computer science;adaptive behavior;control theory;evolutionary robotics;iron;force;evolutionary computation	Robotics	65.85193840718095	-25.862905266416888	64920
4a28fd84ba4faeb2ede0e28dec85cf5dbf0119f0	learning task constraints in operational space formulation		Many human skills can be described in terms of performing a set of prioritised tasks. While a number of tools have become available that recover the underlying control policy from constrained movements, few have explicitly considered learning how constraints should be imposed in order to perform the control policy. In this paper, a method for learning the self-imposed constraints present in movement observations is proposed. The problem is formulated into the operational space control framework, where the goal is to estimate the constraint matrix and its null space projection that decompose the task space and any redundant degrees of freedom. The proposed method requires no prior knowledge about either the dimensionality of the constraints nor the underlying control policies. The techniques are evaluated on a simulated three degree-of-freedom arm and on the AR10 humanoid hand.		Hsiu-Chin Lin;Prabhakar Ray;Matthew Howard	2017	2017 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2017.7989039	mathematical optimization;simulation;machine learning	Robotics	62.13108135243768	-24.15858072517849	64971
cee8cee991de4c5b2bf4137249b26be54fa32f6b	tracking rigid bodies using only position data: a shadowing filter approach based on newtonian dynamics		Abstract Tracking a moving object like a ship, vehicle, aircraft or even an animal or human is challenging especially when given only noisy observations of the path. To successfully track such an object the method used needs to infer the unknown information, for example the acceleration, from noisy position data. Here we present such a method based on a shadowing filter algorithm. In comparison with other filters such as Kalman and Particle filters the shadowing filter solves the tracking problem based on deterministic dynamics instead of statistics. The algorithm presented shows how to track rigid bodies having an unknown moment of inertia and we validate the performance of the filter and explore how the two important parameters of the filter impact on its performance.		Ayham A. Zaitouny;Thomas Stemler;Kevin Judd	2017	Digital Signal Processing	10.1016/j.dsp.2017.04.004	computer vision;control theory	Robotics	55.905135949002464	-35.66530195632309	65151
37c4a8eca6b9f3d9e6b92f804cb3ca761f8446b3	motion control for novel emerging robotic devices and systems		Motion Control for Novel Emerging Robotic Devices and Systems W ITH THE ADVENT OF NEW FUNCTIONAL MATERIALS, MEMS actuators and sensors, or embedded computers, as well as the latest advance in real-time intelligence, machine learning and computational modeling, a lot of more intelligent, powerful, miniaturized or user-friendly engineered devices and robots are emerging, that are either bio-inspired, biomimetic, or special purpose designed. At the core of these emerging robotic products is essentially the Motion Control that coordinates the sensors that detect interactions with the surroundings and sense internal states, and also commands the actuators to achieve the action functionalities, and delivers the machine intelligence. Due to the small size for micro-/nano-devices, the many degrees of freedom for soft robots, the embodiment of actuators/sensors/controllers, the level of intelligence, speed, precision or compliance required, unique challenges emerge concerning the design and realization of novel controllers involving their methodology, algorithms and techniques. While a considerable amount of work has been published in recent years in various journals with varying scopes, no journal has devoted a special issue to the motion control for these emerging smart devices and robots. The objective of this Special Section is to bring the ideas of the worldwide research community into common platform, and to present the latest advances and developments in the motion control methods, algorithms and techniques for emerging and novel smart robotic devices, machines and systems. Editors invite original manuscripts presenting recent advances in these fields with special reference to the following topics:	algorithm;artificial intelligence;biomimetics;british informatics olympiad;common platform;computer;embedded system;interaction;machine learning;microelectromechanical systems;real-time clock;robot;sensor;smart device;usability	Weiliang Xu;Alexander W. Verl;Kiyoshi Ohishi	2017	IEEE Trans. Industrial Electronics	10.1109/TIE.2016.2617831	control engineering;engineering;motion control	Robotics	66.88518134799943	-28.126361732381287	65244
6fc5ea18ea9e0691e5183c769f9002d59b34fd86	design of an infrastructureless in-door localization device using an imu sensor	infrastructureless in door localization device magnetometer euler angles indirect kalman filter pendulum model motion equation pedestrians leg length yaw angle pitch angle 2d displacement pedestrians ankles orientation forward displacement imu sensor;pedestrians displacement measurement kalman filters magnetometers;estimation mathematical model magnetometers foot legged locomotion quaternions gyroscopes	There has been an increasing demand for localization for personnel like firemen, and soldiers for various reasons ranging from safety to strategy planning and coordination. There is also a need for the localization system to be free from infrastructure. For example, it is not practical to place various transmitters in a building before the users enter the building. Many of the current methods involving inertial measurement unit (IMU) utilize step detection and step counting to estimate the displacement. This does not account for the various legs length and step sizes though. Some groups have proposed algorithm that involves placing the IMU on the foot to estimate the step size. However, users have commented that it affects their walking. Hence, this paper presents a new method to estimate both the forward displacement and orientation. In this paper, the sensor unit is placed at the pedestrians ankles for greater ease of usage. The 2D displacement is then computed based on the estimations of pitch angle, yaw angle and pedestrians leg length. The advantage of this method is that the pedestrians leg length is automatically estimated during walking by exploiting the motion equation of a simple pendulum model and hence, no prior measurement or training is required. The proposed method also employs the quaternion-based indirect Kalman filter to estimate the Euler angles containing the yaw angle (heading), the pitch angle and the roll angle. The heading (yaw angle) is corrected by updating the reading data of magnetometer an estimated magnetometer bias. The real-time localization system has been implemented and experiments involving various subjects are conducted. The experimental results demonstrates the accuracy with the averaged displacement error less than 3%.	algorithm;course (navigation);displacement mapping;euler;experiment;internationalization and localization;kalman filter;real-time clock;real-time operating system;step detection;transmitter;yaws	Tri-Nhut Do;Ran Liu;Chau Yuen;U-Xuan Tan	2015	2015 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2015.7419086	computer vision;simulation;engineering;control theory	Robotics	57.46193788363903	-36.501687486663954	65532
0e569a16b25d0d95c98f34089f6a1d2d3638ec9f	a wearable motion tracker	ultrasound;sign language;wearable sensors;video game;ultrasound positioning;motion capture;low power;gait analysis;augmented reality;accelerometers;ultrasonic sensor	This paper presents the development and testing of a wearable, multi-modality, motion capture platform. This platform can be used in a range of applications including virtual and augmented reality, biomechanics, sign language translation, gait analysis and graphics in movies and video games. Our platform includes inertial and ultrasonic motion sensing modalities. The combination of these modalities is expected to improve the overall accuracy of the captured motion data. An electronic board for this has been designed, fabricated and programmed. The board measures 3.2 cm x 4.8 cm and includes a low-power microcontroller, a radio unit, a three-axis accelerometer, a two-axis gyroscope, an ultrasonic transmitter and an ultrasonic receiver. Results using the inertial and ultrasonic sensors to estimate position are presented.	apache axis;augmented reality;gait analysis;graphics;gyroscope;low-power broadcasting;microcontroller;modality (human–computer interaction);motion capture;motion detector;semiconductor device fabrication;sensor;transmitter;wearable computer	Fahad Moiz;Walter D. Leon-Salas;Yugyung Lee	2010		10.1145/2221924.2221965	embedded system;computer vision;simulation;engineering	HCI	58.988520414153335	-37.76125916801069	65649
4d85927089a865de32207be319e5390f1656925c	energy efficiency optimization of an interactive quadruped robot		Recent studies have witnessed a significant progress in developing legged robots with rapid and stable locomotion speeds and adaptability to complex roads, but their high energy consumption limited their development and applications. This paper analyzes the energy efficiency of a bionic electric-drive panda robot serving as an emotional companion for robot-enhanced therapy. Unlike other quadruped robots, our bionic robot focuses on emotional interaction rather than capability of dexterous locomotion and operations. This results in the need to change working period. Then we proposed four strategies to reduce energy consumption. The energy efficiency optimization strategy described in this paper is suitable for quadruped robots focusing on none-highly dynamic motions, and can be treated as locomotion optimization strategy based on energy efficiency optimization for quadruped robots to some extent.	mathematical optimization;robot	Fufei Fan;Jiaming Zhang;Yu Meng;Fuhao Deng;Huihuan Qian;Yangsheng Xu	2017	2017 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2017.8324678	control engineering;efficient energy use;robot;adaptability;energy consumption;engineering	Robotics	67.7222625696704	-25.818883019715532	65711
9566d42c3e4864cf0249dfeedddacd675a559bcf	visual servoing and obstacle avoidance method based control autonomous robotic systems servicing a mechatronics manufacturing line		In this paper is intended to control the entire flexible line using two wheeled mobile robot and two robotic manipulators. The mechatronics manufacturing line has no possibility of automatic feed with pieces and no automatic pickup of the scrap pieces from the storage station. The robotic manipulators are used for charging the buffer of the flexible line as well as emptying the storage station. These tasks are achieved through several algorithms proposed in the present paper (accomplished in Matlab) using image processing with the help of two video cameras synchronized with the grippers of the two robotic manipulators. One of the robotic manipulator (Pioneer 5-DOF Arm), takes with the gripper the pieces stored, is mounted on a mobile robot (Pioneer P3-DX two driving wheels). The Pioneer P3-DX wheeled mobile robot transfer the pieces one by one to another wheeled mobile robot — PeopleBot used to transport the processed piece in the storeroom or at the first station of the flexible line. The second robotic manipulator (Cyton 1500 7-DOF Arm) is fixed and it is used to take the pieces from the PeopleBot mobile robot and to transfer them to the handling work station of the flexible line. PeopleBot mobile robot used to transport the pieces is controlled using new control techniques (trajectory tracking control) with the possibility of obstacle avoidance. Sliding-mode control method is used to control nonlinear processes (the mobile robots). The algorithms proposed in this paper were first tested in simulation and after were implemented in real time on existing mechatronic system, making it completely autonomous.	algorithm;autonomous robot;image processing;matlab;mechatronics;mobile robot;nonlinear system;obstacle avoidance;robot end effector;simulation;visual servoing;wheels	George Ciubucciu;Razvan Solea;Adrian Filipescu;Adriana Filipescu	2017	2017 9th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)	10.1109/IDAACS.2017.8095212	image processing;mobile robot;visual servoing;mobile manipulator;manipulator;embedded system;computer science;robot end effector;mechatronics;obstacle avoidance	Robotics	63.823475503280804	-30.158514271395035	65771
ddd3d2a9aec84e7e17687a34bcd553fff29193b4	cooperative mobile robots using fuzzy algorithm	robot sensing systems;mignon park;sensor systems;intelligent robots;mobile robot;robotics and systems;mobile robots;대한전자공학회;hyuntae kim;autonomous mobile robot;cooperative mobile robots using fuzzy algorithm;institute of control;1992년 한국자동제어학술회의 논문집 제1권 제2호;vol 1 no 2;제어로봇시스템학회;mobile communication;대한전자공학회 92 한국 자동제어학술회의 논문집 국제학술편;the institute of electronics engineers of korea;mobile robots robot sensing systems sensor systems mobile communication ethernet networks laboratories intelligent sensors intelligent robots humans hardware;humans;ethernet networks;minkee park;intelligent sensors;seunghwan ji;hardware	"""In recent years, lots of researches on autonomous mobile robot have been accomplished. However they focused on environment recognition and its processing to make a decision on the motion. And cooperative multy-robot, which must be able to avoid crash and to make mutual communication, has not been studied much. #N#  This paper deals whth cooperative motion of two robots, """"Meari I"""" and """"Meari 2"""" made in our laboratory, based on communication between the two. Because there is an interference on communication occurring in cooperative motion of multi-robot, many restrictive conditions are required. Therefore, lie have designed these robot system so that communication between them is available and mutual interference is precluded, and lie used fuzzy interference to overcome unstability of sensor data."""	algorithm	Hyuntae Kim;Seungwoo Kim;Mignon Park;Heung-Sik Noh	1992		10.1109/IROS.1992.594484	control engineering;mobile robot;embedded system;simulation;computer science;engineering;artificial intelligence	Robotics	57.401432401194185	-30.956363994320686	65798
8672a6e334ff73c691cfd1d7d24ae5371ad9ec6b	conflict-free route planning in dynamic environments	complexity theory;path planning;robot kinematics planning delay collision avoidance complexity theory trajectory;vehicle routing;mobile robots;dynamic environment;trajectory;path planning automatic guided vehicles computational complexity mobile robots multi robot systems;container terminal;computational complexity;propagation delay;multi robot systems;motion planning;planning;automatic guided vehicles;nondelayed agents conflict free route planning algorithm dynamic environments motion planning multiple robots automated guided vehicle minimum time route delay propagation algorithm pareto optimal plan repair scheme;collision avoidance;automated guided vehicle;pareto optimality;route planning;robot kinematics	Motion planning for multiple robots is tractable in case we can assume a roadmap on which all the robots travel, which is often the case in many automated guided vehicle domains, such as factory floors or container terminals. We present an O(nv log(nv) + nv) (n the number of nodes, v the number of vehicles) route planning algorithm for a single robot, which can find the minimum-time route given a set of existing route plans that it may not interfere with. In addition, we present an algorithm that can propagate delay through the plans of the robots in case one or more robots are delayed. This delay-propagation algorithm allows us to implement a Pareto-optimal plan repair scheme, in which one robot can improve its route plan without adversely affecting the other robots. We compare this approach to several plan repair schemes from the literature, which are based on the idea of giving a higher priority to non-delayed agents.	algorithm;automated planning and scheduling;cobham's thesis;motion planning;pareto efficiency;robot;software propagation;time complexity	Adriaan ter Mors	2011		10.1109/IROS.2011.6094461	control engineering;computer vision;simulation;computer science;artificial intelligence;vehicle routing problem;motion planning	Robotics	54.08738382998617	-24.18549857239481	65808
6c8390fa52904e0d6bfe975cd2b10a89cd6eed43	a 10-gram microflyer for vision-based indoor navigation	optic flow;image sensors;gyroscopes;microcontroller;bluetooth;built environment;microcontrollers;prototypes;mobile robots	We aim at developing ultralight autonomous microflyers capable of navigating within houses or small built environments. Our latest prototype is a fixed-wing aircraft weighing a mere 10 g, flying around 1.5 m/s and carrying the necessary electronics for airspeed regulation and collision avoidance. This microflyer is equipped with two tiny camera modules, two rate gyroscopes, an anemometer, a small microcontroller, and a Bluetooth radio module. In-flight tests are carried out in a new experimentation room specifically designed for easy changing of surrounding textures	autonomous robot;bluetooth;camera module;microcontroller;prototype	Jean-Christophe Zufferey;Adam Klaptocz;Antoine Beyeler;Jean-Daniel Nicoud;Dario Floreano	2006	2006 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2006.282293	microcontroller;embedded system;computer vision;simulation;computer science;engineering	Robotics	57.190911097599844	-31.627802703637723	65839
6b2bbf87f48e9a9c644dc56f4280fc6655f3e892	groundscouts: architecture for a modular micro robotic platform for swarm intelligence and cooperative robotics	multitasking abilities;microrobots;swarm intelligence;groundscouts;mobile robot;cooperative robotics;mobile sensor network;robot programming artificial intelligence control engineering computing microrobots mobile robots multi robot systems multiprogramming;mobile robots;dynamic task uploading;multiprogramming;intelligent robots particle swarm optimization robot sensing systems mobile robots remote monitoring costs communication system control mobile communication runtime master slave;autonomous robots;remote sensing;modular hardware;multi robot systems;artificial intelligence;control engineering computing;autonomous robot;modular micro robotic platform;multitasking abilities modular micro robotic platform swarm intelligence cooperative robotics groundscouts mobile robot modular embedded micro os dynamic task uploading;modular embedded micro os;robot programming	This paper presents architecture for a modular micro robotic platform for swarm intelligence and cooperative robotics research and applications. In a swarm the value of an individual is negligible since the goal of the swarm is essential. Thus, the agents (robots) need to be small, low cost, and cooperative. GroundScouts are designed based on these conditions. The proposed architecture slices a robot into abstract modules such as locomotion, control, sensors, communication, and actuation. Any mobile robot can be constructed by combining these abstract modules for a specific application. A modular embedded micro-OS with dynamic task uploading and multi-tasking abilities is developed. In order to create better interface between robots and the command center and among the robots. The dynamic, task uploading allows the robots change their behaviors in runtime. Thus, the robots can work in swarm, master-slave, or hybrid mode and possibly be used in other applications such as mobile sensor networks, remote sensing, and plant monitoring	algorithm;computer multitasking;embedded system;mobile robot;operating system;real-time clock;robot locomotion;robotics;sensor;software architecture;swarm intelligence;upload	Ferat Sahin	2004	2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)	10.1109/ICSMC.2004.1398422	mobile robot;embedded system;swarm robotics;simulation;ant robotics;swarm intelligence;computer science;artificial intelligence;self-reconfiguring modular robot;robot control	Robotics	62.013423136714884	-27.626191167563604	65989
db6e2ccd65e1909413183abac97660a29bf02694	soft autonomous materials - using active elasticity and embedded distributed computation		The impressive agility of living systems seems to stem from modular sensing, actuation and communication capabilities, as well as intelligence embedded in the mechanics in the form of active compliance. As a step towards bridging the gap between man-made machines and their biological counterparts, we developed a class of soft mechanisms that can undergo shape change and locomotion under pneumatic actuation. Sensing, computation, communication and actuation are embedded in the material leading to an amorphous, soft material. Soft mechanisms are harder to control than stiff mechanisms as their kinematics are difficult to model and their degrees of freedom are large. Here we show instances of such mechanisms made from identical cellular elements and demonstrate shape changing, and autonomous, sensor-based locomotion using distributed control. We show that the flexible system is accurately modeled by an equivalent spring-mass model and that shape change of each element is linear with applied pressure. We also derive a distributed feedback control law that lets a belt-shaped robot made of flexible elements locomote and climb up inclinations. These mechanisms and algorithms may provide a basis for creating a new generation of biomimetic soft robots that can negotiate openings and manipulate objects with an unprecedented level of compliance and robustness. Nikolaus Correll Department of Computer Science University of Colorado at Boulder, Boulder, CO, USA, e-mail: nikolaus.correll@colorado.edu Çağdaş D. Önal and Daniela Rus Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA e-mail: cagdas@csail.mit.edu,rus@csail.mit.edu Haiyi Liang School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA e-mail: hyliang@seas.harvard.edu Erik Schoenfeld iRobot Inc., Bedford, MA, USA	algorithm;autonomous robot;biomimetics;bridging (networking);compliance and robustness;computation;distributed computing;distributed control system;elasticity (data store);email;embedded system;feedback;living systems;mit computer science and artificial intelligence laboratory;optimal control;sensor	Nikolaus Correll;Cagdas D. Onal;Haiyi Liang;Erik Schoenfeld;Daniela Rus	2010		10.1007/978-3-642-28572-1_16	control engineering;simulation;engineering;artificial intelligence;mechanical engineering	Robotics	66.25266443734978	-26.890559633352872	66381
681b7990a0465bf2a7ee35dc7ed8aa74f68d1749	visibility-based uav path planning for surveillance in cluttered environments	surveillance vegetation observers simulation spirals;surveillance autonomous aerial vehicles boundary value problems computational geometry image enhancement military aircraft mobile robots path planning probability robot vision;visibility based uav path planning clustered spiral alternating algorithm cvt centroidal voronoi tessellation fmm fast marching method visibility enhancement near optimal surveillance path determination probabilistic visibility model cluttered environments civil defence applications small unmanned aerial vehicles close range uav surveillance near optimal observation location determination problem cluttered environments	This paper focusses on the problem of determining near-optimal observation locations for an effective close-range UAV surveillance in terrains cluttered with buildings and trees. Use of Small-Unmanned Aerial Vehicles (S-UAVs) in civil defence applications has increased due to their portability and low operational costs. In close-range S-UAV surveillance in cluttered environments, there are two significant occlusions to visibility: complete (terrain) and partial (vegetation). However, in the existing literatures, the partial occlusions are generally neglected. In this paper, a probabilistic visibility model is proposed which considers both complete and partial occlusions to determine near-optimal surveillance path to enhance visibility of the desired regions on the ground using a two-step approach. In the first step, the waypoints are deployed in regions which provide near-uniform visibility of the desired target regions. This step involves finding the visibility space (region of space from which the desired target regions are visible) using the Fast Marching Method (FMM) and then deploying the waypoints in this region using Centroidal Voronoi tessellation (CVT). In the second step, flyable paths are constructed along the waypoints using an improved clustered spiral-alternating algorithm. Visibility with the proposed method is simulated for a synthetically generated terrain that resembles a residential area with buildings and trees. The results show the effectiveness of the proposed surveillance method in improving the visibility of the desired target regions.	aerial photography;algorithm;centroidal voronoi tessellation;fast marching method;fast multipole method;motion planning;software portability;uav outback challenge;unmanned aerial vehicle;waypoint	Vengatesan Govindaraju;Gerard Leng;Qian Zhang	2014	2014 IEEE International Symposium on Safety, Security, and Rescue Robotics (2014)	10.1109/SSRR.2014.7017660	computer vision;simulation;geography;remote sensing	Robotics	54.61093995796264	-26.492975658303322	66582
0f0170c1802efce8c060d3873910bd055ce5d7cc	dynamic tool vectors for robo-centric control	motion control;manipulator dynamics;position control;aerospace robotics;robot kinematics vehicle dynamics robot control motion control manipulator dynamics arm robot vision systems cameras space vehicles laboratories;space systems laboratory robo centric control free flying robots coordinate control manipulator dynamics motion control camera positioning self maneuvering ranger neutral buoyancy vehicle university of maryland;position control aerospace robotics manipulator dynamics motion control	TECHNICAL EXPERIENCE Control Station Lead Space Systems Laboratory May 1993 Present Developed Graphical User Interfaces used to control all aspects of three robotic vehicles. Features included 6 degree-of-freedom (DOF) free flying underwater, controlling up to four separate robotic manipulators varying between 6 to 10 DOF, and monitoring vehicle bus subsystems. Developed a virtual environment for visualizing the above robotic functions, allowing for multiple input and output devices to control hundreds of objects and over 50 independent virtual cameras. Developed an application that generates the code to automatically administer and monitor communication among multiple processes. Over 7000 pieces of information could be tracked, monitored, altered, graphed, and archived in real-time. Performed extensive testing to improve operator performance controlling a complex robot remotely under varying conditions of time delay, limited communication bandwidth, and calibration errors. This included the design of experiments, monitoring over 500 hours of testing, and analyzing the results. Designed process architecture for control station applications allowing for over 50 separate applications, over multiple processors, to appears as one program to an operator. Participated in several demonstrations, proposals, and design reviews including NASA Space Shuttle mission PDR, CDR, and Phase II Safety Review. Conducted VIP tours of laboratory facility Research Assistant Space Systems Laboratory Sept 1991 May 1993	archive;broadcast delay;central processing unit;computer graphics;design of experiments;design review (u.s. government);experiment;input/output;output device;process architecture;real-time clock;real-time computing;robot;user interface;vehicle bus;virtual reality;virtual tour	Craig R. Carignan;David L. Akin;J. Corde Lane	2000		10.1109/ROBOT.2000.844760	control engineering;motion control;computer vision;simulation;engineering;mobile manipulator;control theory;robot control	Robotics	62.650394421159326	-29.491038763143386	66597
1a7c89e2322314f5704fd3a8e7431e132fe03988	gaze stabilization of a humanoid robot based on virtual linkage	manipulators;visualization head couplings optical imaging optical feedback manipulators;optical flow minimization humanoid robot virtual linkage gaze stabilization visual data interpretation visual target closed loop algorithms head movements lower body commands feed forward controller image stabilization target fixation robot eye gaze control problem redundant serial robot manipulator self induced optical flow robot kinematics armar iv humanoid;visualization;robot vision closed loop systems data visualisation feedforward humanoid robots image sequences minimisation redundant manipulators;optical imaging;head;couplings;optical feedback	Gaze stabilization is a fundamental function for humanoid robots. Stabilizing the image being perceived facilitates the processing and thus the interpretation of visual data. In parallel, fixation should also guarantee that the visual target remains centered in the image. Several approaches exist to address the problem of gaze stabilization: closed-loop algorithms processing the visual data or inferring head movements from kinematic measurements, and feed-forward algorithms anticipating head movements from the lower-body commands. In this contribution, we develop a feed-forward controller addressing both image stabilization and target fixation into a unified framework. The addition of a virtual linkage between the robot eye and the visual target offers to elegantly rephrase the gaze control problem as the classical control of a redundant serial robot manipulator. Furthermore, a novel method to estimate the self-induced optical flow based on the robot kinematics - extended with this virtual linkage - is developed. It is then possible to solve the redundancy (i.e. guaranteeing target fixation) through a minimization of the optical flow (i.e. achieving image stabilization). This method is validated in simulation with a model of the head of the ARMAR IV humanoid. It is shown that the proposed controller offers to accurately estimate and minimize the optical flow, while keeping the visual target exactly in the center of the image.	3d modeling;arm architecture;algorithm;experiment;humanoid robot;image processing;interpretation (logic);jacobian matrix and determinant;linkage (software);mathematical optimization;optical flow;pixel;redundancy (engineering);simulation;unified framework;velocity (software development)	Timothee Habra;Renaud Ronsse	2016	2016 6th IEEE International Conference on Biomedical Robotics and Biomechatronics (BioRob)	10.1109/BIOROB.2016.7523616	control engineering;computer vision;simulation;computer science;humanoid robot;robot control;robot kinematics	Robotics	61.230236445476876	-32.20319505686851	66658
88e92e7448b821be37eee9b09b93d83d8df8194d	demonstration based trajectory optimization for generalizable robot motions		Learning motions from human demonstrations provides an intuitive way for non-expert users to teach tasks to robots. In particular, intelligent robotic co-workers should not only mimic human demonstrations but should also be able to adapt them to varying application scenarios. As such, robots must have the ability to generalize motions to different workspaces, e.g. to avoid obstacles not present during original demonstrations. Towards this goal our work proposes a unified method to (1) generalize robot motions to different workspaces, using a novel formulation of trajectory optimization that explicitly incorporates human demonstrations, and (2) to locally adapt and reuse the optimized solution in the form of a distribution of trajectories. This optimized distribution can be used, online, to quickly satisfy via-points and goals of a specific task. We validate the method using a 7 degrees of freedom (DoF) lightweight arm that grasps and places a ball into different boxes while avoiding obstacles that were not present during the original human demonstrations.	mathematical optimization;robot;trajectory optimization;workspace	Dorothea Koert;Guilherme Maeda;Rudolf Lioutikov;Gerhard Neumann;Jan Peters	2016	2016 IEEE-RAS 16th International Conference on Humanoid Robots (Humanoids)	10.1109/HUMANOIDS.2016.7803324	computer vision;simulation;artificial intelligence	Robotics	61.871132455648514	-24.68409710911528	66761
bd99021831b8f44c260655ac6dc5341007bfe0f9	pose estimation from minimal dual-receiver configurations	numerical stability;minimal problems;radio receivers;antenna arrays;time measurement;smart phones;receivers antenna arrays antenna measurements mathematical model polynomials directive antennas;time of arrival estimation antenna arrays direction of arrival estimation microphone arrays mobile antennas numerical stability pose estimation radio receivers smart phones time measurement;mobile antennas;orientation determination pose estimation minimal dual receiver configurations smartphone time difference of arrival measurement angle determination position determination;time of arrival estimation;microphone arrays;matematik;direction of arrival estimation;pose estimation;time difference of arrival	Using multiple receivers (microphones or antennas) in a rigid configuration, such as on a smartphone, it is possible to measure time difference of arrival to the receivers. This in turn can be used to determine the direction to the transmissions, if there are at least three receivers. When using two receivers it can be used to determine the angle to the transmissions relative to the line through the two receivers. In this paper we study three minimal problems for pose using such data: (i) determine position and orientation using five transmissions, (ii) determine position and orientation using four transmissions and known `down' direction and (iii) determine position using three transmissions and known orientation. Numerically stable solvers are implemented. An experimental validation of the solvers are performed on simulated data.	3d pose estimation;computer vision;high- and low-level;microphone;multilateration;numerical stability;random sample consensus;smartphone;transmitter;wearable technology	Simon Burgess;Yubin Kuang;Kalle Åström	2012	Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)		computer vision;simulation;pose;telecommunications;computer science;multilateration;geometry;radio receiver;numerical stability;time	Mobile	56.544245691578986	-37.606477202612695	66825
e26a9dca92001ae35a23f042c996b2f578516423	image processing based a wireless charging system with two mobile robots		This paper presents the image processing algorithm for wireless charging between each mobile robot. The image processing algorithm converts Red Green Blue (RGB) format of inputted image to detect edge. It calculates a specific area using Hough Transformation (HT) in detected edge and judges correct charging antenna using Speeded-Up Robust Features (SURF). Accordingly, the image processing algorithm can control position and direction of mobile robot and antenna for wireless charging. The image processing algorithm is implemented wireless charging systems, which are set up on each two mobile robot and it is verified with experiment.	image processing;robot	Jae-Oh Kim;ChanWoo Moon;Hyun-Sik Ahn	2013		10.1007/978-94-007-6738-6_95	embedded system;electronic engineering;simulation;wi-fi array	Robotics	58.84725705307547	-32.1396709329941	67497
da85a06acbfd83348fe40a57b7d049fecf38a529	introduction: darpa urban grand challenge		THE Urban Challenge is the third in a series of robotic grand challenges put on by the Defense Advanced Research Agency (DARPA). The grand challenges have the goal of developing robotic technologies that will reduce the number of warfighters operating in hazardous conditions and is in support of the government mandate that one-third of the military’s vehicles be autonomous by 2015. The first Grand Challenge was in March 2004 and was over a 142 mile course in the desert between Barstow, CA and Primm, NV. Fifteen vehicles made the final round, but none finished. The second Grand Challenge was in October 2005 and was over a similar 132 mile course. In this race four vehicles successfully completed the course with “Stanley” from Stanford University coming in first and winning the $2 million prize. The Urban Challenge will test the ability of robots to operate safely and effectively in populated, busy areas. It will feature autonomous ground vehicles maneuvering in a mock city environment, simulating military supply missions and must negotiate the course along with approximately 50 human-driven vehicles. The robotic vehicles will have to complete a 60-mile course in less than six hours and must obey California traffic laws while merging into moving traffic, navigating traffic circles, negotiating busy intersections and avoiding obstacles. The final event will take place on November 3, 2007 at the urban military training facility located on the former George Air Force Base in Victorville, Calif. The location has a network of urban roads and simulates the type of environment the military operates in when deployed overseas. The awards will be for $2 million, $1 million and $500,000 and will go to the top three finishers that complete the course within the six hour time limit. More information about the event is available at the DARPA web site at www.darpa.mil/grandchallenge. This special issue has nine papers from entrants to the urban challenge. The first paper by Wooden et al. describes the Sting Racing Team’s modular control architecture based on nested hybrid automata. The second paper by Crane et al. describe Team Gator Nation’s solution to the challenge to the determination of pose, appropriate behavior mode, and the smooth transition of vehicle control between behavior modes. The third paper by Upcroft et al. of the Sydney-Berkeley Driving Team discusses their solution to denied GPS and their use of vision for localization. The fourth paper by Effertz describes the Team CarOLO approach for multi-target, multi-sensor data fusion based on an extended Kalman filter algorithm. The fifth paper by Yang et al. of TeamUCF discusses their real-time trajectory planning for their vehicle. The sixth paper by Herpin et al. discusses the steering controller of their CajunBot II. The seventh paper from Henrie and Wilde describe their approach to generating clothoid-based trajectories using constructive polylines. The eighth paper from Basarke et al. discusses their system and software engineering process for developing the intelligent autonomous software for Team CarOLO. The ninth paper from Johnson discusses the TeamNOVA approach for navigating in GPS denied areas using modified orienteering techniques.	automata theory;autonomous robot;cajunbot;extended kalman filter;global positioning system;goto;grand challenges;hybrid automaton;internationalization and localization;mock object;nv network;peterson's algorithm;population;real-time transcription;sting;simulation;software development process;software engineering;stanley (vehicle);yang	Christopher A. Rouff	2007	JACIC	10.2514/1.35396	orienteering;control engineering;robot;mile;time limit;aeronautics;architecture;software development process;engineering;global positioning system;grand challenges	AI	56.07919011433639	-28.87184601620235	67504
06079f22f16d115a3afe25655d7daacc60ebffc3	the octopus as paradigm for soft robotics	soft robotics bioinspiration biomimetics;motion control;soft robotics;surgery manipulator kinematics marine vehicles medical robotics mobile robots motion control;mobile robots;manipulator kinematics;medical robotics;bioinspiration;manipulators artificial intelligence organisms robustness biological system modeling;marine vehicles;surgery;rigid link kinematic chains octopus soft robotics movement control motion parameter control marine robotics surgical robotics;biomimetics	Looking at an octopus from the roboticist view point it is easy to understand why it is considered a paradigmatic example for soft robotics: its arms are soft and deformable, they can bend in any direction, at any point along the arm; however, they can stiffen when needed and they can grasp and pull objects with considerable strength; the octopus does not have a large brain, yet it can control this huge amount of possible movements and motion parameters. These observations together with the growing need for robots in service tasks, in unstructured environments, in contact with humans, is leading to release the basic assumption of rigid parts in robotics and to the development of new enabling technologies for a new generation of soft robots for marine and surgical robotics.	coat of arms;programming paradigm;robot;soft robotics	Matteo Cianchetti	2013	2013 10th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2013.6677325	behavior-based robotics;biomimetics;motion control;mobile robot;computer vision;simulation;computer science;artificial intelligence;robotic paradigms;bio-inspired robotics;robotics	Robotics	67.74989699956527	-25.656524371182616	67606
2dfca7591d433937b520f0cbb91d83c72df15826	experimental evaluation of contact-less hand tracking systems for tele-operation of surgical tasks	robot kinematics tracking robot sensing systems surgery trajectory;trajectory control gesture recognition medical robotics motion control robust control telerobotics;medical robotics master contact less hand tracking system teleoperation surgical tasks contact less hand tracking sensor surgical robotics application hand tracking systems 3gear systems interface microsoft kinecttm sensor leap motion sensor system static positioning error trajectory accuracy single finger motion hand motion kinecttm 3gear gesture control simulated surgical positioning task translational accuracy robustness	This paper reports an evaluation of contact-less hand tracking sensors for the use of tele-operation, in particular for surgical robotics applications. Two hand tracking systems are investigated: 3Gear Systems interface with the Microsoft KinectTM sensor, and the Leap Motion sensor system. This paper reports an experimental evaluation and comparison of the two systems range, static positioning error, trajectory accuracy of single finger and hand motions, and latency. Latency and trajectory accuracy were found superior using the Leap system. KinectTM/3Gear was found superior when larger range and gesture control are necessary. 3Gear was used in a simulated surgical positioning task and demonstrated an average translational accuracy of 6.2mm. Given the data we have collected, we conclude that neither system, at present, possesses the high level of accuracy and robustness over the required range that would be a prerequisite for use as a medical robotics master.	high-level programming language;interrupt latency;leap (programming language);motion detector;natural user interface;robotics;sensor;television;tracking system	Yonjae Kim;Peter C. W. Kim;Rebecca Selle;Azad Shademan;Axel Krieger	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907364	control engineering;computer vision;simulation;tracking system;engineering	Robotics	59.12032483167411	-34.32586861606258	67851
f5df15a3ca0acddb8f61f4a0b7067f6d9cd0cd45	concept for building a mems based indoor localization system	indoor navigation;sensors;kalman filters;smart phones;smart phones indoor navigation indoor radio kalman filters microsensors particle filtering numerical methods position measurement;smartphone indoor navigation mems kalman filter particle filter;smartphone based navigation solution mems based indoor localization system global navigation satellite systems gnss based navigation gnss signal position estimation gnss shaded areas mems sensors microelectromechanical system accelerometer gyroscope magnetic field sensor barometer indoor navigation system position determination kalman filter particle filter;accelerometers;floors;sensors smart phones accelerometers kalman filters floors indoor navigation	Global Navigation Satellite Systems (GNSS)-based navigation with smartphones is very popular. But in areas where no GNSS signal is found navigation could be useful. Examples are navigation in shopping malls, in big offices, in train stations or museums. The goal is to estimate the position in GNSS shaded areas to make navigation possible. The MEMS sensors (Micro Electro Mechanical System) installed in current smartphones, such as accelerometer, gyroscope, magnetic field sensor and barometer allow now navigation also in GNSS shadowed areas. Due to the low quality of these sensors, however, support of the position estimate is needed. In this work, a concept is presented for the construction of an indoor navigation system based on low-cost sensors of smartphones. The position estimate from the available sensor data forms the basis of the position determination. So position estimation is always possible independent of location. First results with Kalman filter and particle filter are shown. The presented concept serves as a basis for the construction of a smartphone-based navigation solution for indoor use. Therefore the available MEMS sensors should be used as a position estimator and a wide variety of supporting information can be processed. A first approach for implementation on a smartphone is shown as an example.	galileo (satellite navigation);gyroscope;indoor positioning system;kalman filter;microelectromechanical systems;particle filter;satellite navigation;sensor;shading;smartphone	Thomas Willemsen;Friedrich Keller;Harald Sternberg	2014	2014 International Conference on Indoor Positioning and Indoor Navigation (IPIN)	10.1109/IPIN.2014.7275461	dead reckoning;air navigation;embedded system;electronic engineering;gnss augmentation;geography;remote sensing	Robotics	55.836225391763314	-34.397967753209066	67901
e56978afcc370de5c3580e281c6c388848293719	a fusion strategy for reliable vehicle positioning utilizing rfid and in-vehicle sensors	in vehicle sensors;vehicle positioning;rfid;multiple model;sensor fusion	RFID is introduced as a virtual sensor for vehicle positioning.LSSVM algorithm is proposed to obtain the distance between RFID tags and reader.In-vehicle sensors are employed to fuse with RFID to achieve vehicle positioning.An LSSVM-MM (multiple models) filter is proposed to realize the global fusion. In recent years, RFID has become a viable solution to provide object's location information. However, the RFID-based positioning algorithms in the literature have disadvantages such as low accuracy, low output frequency and the lack of speed or attitude information. To overcome these problems, this paper proposes a RFID/in-vehicle sensors fusion strategy for vehicle positioning in completely GPS-denied environments such as tunnels. The low-cost in-vehicle sensors including electronic compass and wheel speed sensors are introduced to be fused with RFID. The strategy adopts a two-step approach, i.e., the calculation of the distances between the RFID tags and the reader, and then the global fusion estimation of vehicle position. First, a Least Square Support Vector Machine (LSSVM) algorithm is developed to obtain the distances. Further, a novel LSSVM Multiple Model (LMM) algorithm is designed to fuse the data obtained from RFID and in-vehicle sensors. Contrarily to other multiple model algorithms, the LMM is more suitable for current driving conditions because the model probabilities can be calculated according to the operating state of the vehicle by using the LSSVM decision model. Finally, the proposed strategy is evaluated through experiments. The results validate the feasibility and effectiveness of the proposed strategy. This paper proposes a RFID/in-vehicle sensors fusion strategy for vehicle positioning in completely GPS-denied environments such as tunnels. The low-cost in-vehicle sensors including electronic compass and wheel speed sensors are introduced to be fused with RFID. The strategy adopts a two-step approach, i.e., the calculation of the distances between the RFID tags and the reader, and then the global fusion estimation of vehicle position. First, a least square support vector machine (LSSVM) algorithm is developed to obtain the distance. Further, a novel LSSVM multiple model (LMM) algorithm is designed to fuse the data obtained from RFID and in-vehicle sensors. Contrarily to other multiple models algorithms, LMM is more suitable for current driving conditions because the model probabilities can be calculated according to the operating state of the vehicle by using the LSSVM decision model. Finally, the proposed strategy is evaluated through experiments. The results validate the feasibility and effectiveness of the proposed strategy.Display Omitted	radio-frequency identification;sensor	Xiang Song;Xu Li;Wencheng Tang;Weigong Zhang	2016	Information Fusion	10.1016/j.inffus.2016.01.003	radio-frequency identification;embedded system;computer vision;simulation;telecommunications;computer science;sensor fusion	Mobile	56.39752042457583	-34.90696698654099	67919
44c3a8f2458947cc2fcd108decadd98fe2fc973b	novel vehicle information acquisition method using 2d reflector code for automotive infrared laser radar				Tomotaka Wada;Yusuke Shikiji;Keita Watari;Hiromi Okada	2015	IEICE Transactions		radar lock-on	Robotics	55.78067296168668	-31.94545901435194	67975
65089a3035576f588f1f13fc3aa1e67a0538641c	force control and visual servoing using planar surface identification	feedforward systems;vision system;white board force control visual servoing planar surface identification flexible multisensor based robot systems measurement combination cameras force sensors force feedback control loop vision based reference trajectory feed forward signal feedforward constrained image based visual servoing algorithm surface following planar constraint surface location planar constraint surface orientation online estimation camera calibration method force controlled drawing pen;robot sensing systems;white board;vision based reference trajectory;feed forward;online estimation;sensor systems;control algorithm;flexible multisensor based robot systems;feedforward;feed forward signal;force sensors;surface following;constrained image based visual servoing algorithm;datorseende och robotik autonoma system;force control visual servoing robot vision systems cameras robot sensing systems force measurement sensor systems force sensors force feedback feedforward systems;force feedback control loop;force feedback;robot vision;reglerteknik;measurement combination;camera calibration method;force measurement;planar constraint surface orientation;planar constraint surface location;force controlled drawing;sensor fusion;matematik;visual servoing;planar surface identification;calibration robot vision force control force feedback sensor fusion;pen;robot vision systems;algorithm design;calibration;cameras;force sensor;force control	When designing flexible multi-sensor based robot systems, one important problem is how to combine the measurements from disparate sensors such as cameras and force sensors. In this paper, we present a method for combining direct force control and visual servoing in the presence of unknown planar surfaces. The control algorithm involves a force feedback control loop and a vision based reference trajectory as a feed-forward signal. The vision system is based on a constrained image-based visual servoing algorithm designed for surface following, where the location and orientation of the planar constraint surface is estimated online using position-, forceand visual data. We show how data from a simple and efficient camera calibration method can be used in combination with force and position data to improve the estimation and reference trajectories. The method is validated through experiments involving force controlled drawing on an unknown surface. The robot will grasp a pen and use it to draw lines between a number of markers drawn on a white-board, while the contact force is kept constant. Despite its simplicity, the performance of the method is satisfactory.	algorithm;camera resectioning;control system;experiment;feedback;haptic technology;robot;sensor;visual servoing	Tomas Olsson;Johan Bengtsson;Rolf Johansson;Henrik Malm	2002		10.1109/ROBOT.2002.1014414	control engineering;computer vision;machine vision;computer science;engineering;artificial intelligence;control theory;visual servoing;feed forward	Robotics	60.935120265014156	-32.576176490232754	68160
a691d3a72a20bf24ecc460cc4a6e7d84f4146d65	the future of parking: a survey on automated valet parking with an outlook on high density parking		In the near future, humans will be relieved from parking. Major improvements in autonomous driving allow the realization of automated valet parking (AVP). It enables the vehicle to drive to a parking spot and park itself. This paper presents a review of the intelligent vehicles literature on AVP. An overview and analysis of the core components of AVP such as the platforms, sensor setups, maps, localization, perception, environment model, and motion planning is provided. Leveraging the potential of AVP, high density parking (HDP) is reviewed as a future research direction with the capability to either reduce the necessary space for parking by up to 50 % or increase the capacity of future parking facilities. Finally, a synthesized view discussing the remaining challenges in automated valet parking and the technological requirements for high density parking is given.	attribute–value pair;autonomous car;autonomous robot;internationalization and localization;map;microsoft outlook for mac;motion planning;requirement	Holger Banzhaf;Dennis Nienhüser;Steffen Knoop;Johann Marius Zöllner	2017	2017 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2017.7995971	parking guidance and information;simulation;motion planning;transport engineering;engineering	Robotics	54.24944011238747	-30.31086372634162	68183
64597bdf4d41d6190767599f0a9f881c639bd05f	adaptive control for human-robot skilltransfer: trajectory planning based on fluid dynamics	one shot learning;intelligent robots;trajectory planning;adaptive control;embedded system;learning by example;trajectory;learning by demonstration;surgery;robotic assembly;fluid dynamics;imitation learning;fluid dynamics learning by demonstration imitation learning one shot learning;human robot skilltransfer;adaptive control trajectory fluid dynamics robotics and automation robot kinematics robotic assembly end effectors surgery robot programming embedded system;intelligent controller;man machine systems;robotics and automation;man machine systems adaptive control fluid dynamics intelligent robots learning by example;end effectors;robot programming;imitation learning adaptive control human robot skilltransfer trajectory planning fluid dynamics learning by demonstration intelligent controller;robot kinematics	A popular method for an easy and also flexible programming of robots is learning by demonstration. An intelligent controller learns a task from several examples carried out by an experienced user. Afterwards, the task can be adapted to new, formerly unknown environments. One particular challenge arising with this technique is generalization of demonstrations in order to get a generic description of the task. In this paper a new methodology for solving this problem is proposed. The main part of the algorithm exploits principles known from fluid dynamics.	algorithm;approximation;autonomous robot;breakpoint;computation;experiment;fluid animation;graphics processing unit;maxima and minima;parallel computing;robot;sampling (signal processing);simulation;time complexity;video card	Hermann Georg Mayer;Istvan Nagy;Alois Knoll;Eva U. Braun;Rüdiger Lange;Robert Bauernschmitt	2007	Proceedings 2007 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2007.363583	control engineering;computer vision;robot end effector;simulation;adaptive control;computer science;artificial intelligence;trajectory;robot kinematics;fluid dynamics	Robotics	62.96964337667433	-25.55310864758041	68224
9802090f728c9e77c5fe065797b22072aed42c6f	real-time animation of a virtual arm and its collisions with a virtual environment	experimental tests;force feedback capabilities;nonuniform b splines;virtual body limb movements;real time graphical rendering;computer animation virtual reality rendering computer graphics realistic images real time systems splines mathematics;realistic rendering;parametric surfaces;degree of freedom;real time;optical encoders;virtual reality;virtual hand;virtual contact forces;integrated optics;splines mathematics;virtual arm;joint rotation sensors;mechanical structure;physically based behavior real time animation virtual arm virtual environment realistic rendering virtual body limb movements virtual environment system real time graphical rendering upper limb movements force feedback capabilities nonuniform b splines multiprocessor algorithms parametric surfaces polygon meshes joint rotation sensors optical encoders mechanical structure virtual contact forces realistic representation virtual hand collision detection algorithms;force feedback;virtual environment system;upper limb;collision detection;monos devices;design and implementation;animation rendering computer graphics virtual environment force feedback optical sensors mechanical sensors real time systems mechanical splines monos devices integrated optics;polygonal meshes;polygon meshes;real time animation;animation;mechanical sensors;collision detection algorithms;multiprocessor algorithms;realistic images;realistic representation;optical sensors;physically based behavior;virtual environment;computer animation;rendering computer graphics;mechanical splines;parametric surface;upper limb movements;real time systems	Realistic rendering of the virtual body limb movements represents one of the most interesting research areas for the design and implementation of the representation component of a Virtual Environment system. This paper addresses the description of a complete experimental Virtual Environment system including real-time graphical rendering of upper limb movements as well as force feedback capabilities to the user. The virtual arm and hand are modeled with a set of 40 nonuniform B-splines: mono and multiprocessors algorithms have been used in order to convert parametric surfaces in polygon meshes. Upper limb movements are recorded by means of joint rotation sensors (optical encoders) integrated on a 7 degrees of freedom mechanical structure wrapping up the whole arm and possessing the same joint rotation axes. The same mechanical structure is devoted to replicate virtual contact forces to the user’s hand. Data from joint rotation sensors are used to move the control points of the parametric surfaces. In this way, a realistic representation of the shape of the virtual hand and arm, including the deformation of the skin, has been empirically obtained. Collision detection algorithms as well as modules for the modeling of physically-based behavior of the virtual hand in contact with virtual objects have been developed. The paper will contain the complete description of their design. Results of experimental tests aimed at verifying the performances in terms of frame rates and force feedback capabilities during practical manipulative and exploratory tasks of virtual objects are presented. 13 1087.4844/96 $5.00	arm architecture;algorithm;b-spline;collision detection;encoder;graphical user interface;haptic technology;performance;polygon mesh;real-time locating system;real-time transcription;rendering (computer graphics);self-replicating machine;sensor;verification and validation;virtual body;virtual reality;wrapping (graphics)	Massimo Bergamasco	1996		10.1109/CA.1996.540482	computer vision;simulation;computer science;virtual finite-state machine;computer graphics (images)	Graphics	66.36053089673814	-31.94696853810463	68398
b577af464d79a173142fcfba454861a5610b3045	mobile microscope: a new concept for hand-held microscopes with image stabilization	focusing;inclined image sensor;prototypes;high speed optical techniques;image sensors;microscopes feedback image sensors;mobile microscope;feedback;hand held microscopes;image stabilization;high speed visual feedback;vibration control;microscopes;position measurement;vibration measurement;visual feedback;inclined image sensor mobile microscope hand held microscopes image stabilization high speed visual feedback;optical sensors;vibration measurement image sensors focusing prototypes position measurement vibration control optical microscopy high speed optical techniques optical feedback optical sensors;high speed;optical feedback;image sensor;optical microscopy	"""In this paper, we propose the concept of a """"mobile microscope"""". This is a hand-held microscope that can be used for observation in various places. Because microscopes which have a small observable area and are vulnerable to vibrations, images from hand-held microscopes are usually blurred. We propose a method of stabilizing images from a microscope which are affected by shaking, and we use the method to realize a mobile microscope. The method is based on high-speed visual feedback with an inclined image sensor for measuring the 3D movements of the microscope. We developed a prototype microscope system, without a built-in actuator, by employing this method. Experimental results showed that images from the hand-held microscope could be stabilized by our method."""	image sensor;mobile device;observable;prototype	Takahiko Ishikawa;Hiromasa Oku;Masatoshi Ishikawa	2008	2008 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2008.4543687	control engineering;computer vision;engineering;image sensor;stereo microscope;optics;microscope image processing;digital microscope	Robotics	60.31672047129567	-34.678869762691434	68406
29fd9ae0787d493f939a61f4a3dbe1f27d194cc2	towards fault-tolerant and energy-efficient swarms of underwater robots	mobile robots;image sensors;multi robot systems autonomous underwater vehicles fault tolerance image sensors mobile robots;autonomous underwater vehicles;fault tolerance;multi robot systems;robot sensing systems global positioning system conferences fault tolerance fault tolerant systems;mission tasks fault tolerant swarms energy efficient swarms underwater robots environmental monitoring autonomous underwater vehicles auv cameras environmental tracking systems acoustic modules mission time miniature auv monsun ii energy efficient behaviour underwater formations	The increasing urgency to study the world's native water bodies regarding environmental monitoring leads to a worldwide growing interest in the development of Autonomous Underwater Vehicles (AUVs). The robots are equipped with several sensors, e.g. cameras, environmental tracking systems and acoustic modules which provide an inexpensive alternative to manual investigations. To increase mission time and decrease sensitivity against faults, a swarm of such underwater robots can afford many benefits. Hence this paper presents the development of the miniature AUV MONSUN II, which acts in a networked swarm to reach an energy-efficient behaviour with simultaneous consideration of fault-tolerance. Therefore, the robots use their communication network to propagate internal states and build underwater formations according to current mission tasks.	acoustic cryptanalysis;autonomous robot;experiment;fault tolerance;fault-tolerant computer system;microsoft outlook for mac;sensor;simulation;swarm;telecommunications network;tracking system	Ammar Amory;Benjamin Meyer;Christoph Osterloh;Thomas Tosik;Erik Maehle	2013	2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum	10.1109/IPDPSW.2013.215	intervention auv;control engineering;embedded system;simulation;engineering	Robotics	56.50331794001209	-30.8014677909906	68435
874868d4778fd8caffac13f6d8bbe3132b0e7f82	the vahm project: a cooperation between an autonomous mobile platform and a disabled person	intelligent mobility functions handicapped aids mobile robots computerised control autonomous mobile platform disabled person vahm project electric wheelchair;computerised control;mobile robots wheelchairs sensor phenomena and characterization intelligent robots hardware vehicle safety hidden markov models birth disorders force sensors application software;software structure;mobile robots;handicapped aids;research and development;mobile robots computerised control handicapped aids;disabled person	The VAHM project constitutes a research and development project aimed at automating an electric wheelchair for the disabled. The aim consists in delegating the control of some low-level functionalities to the wheelchair during the motion in order to allow the person to be free of the driving constraints that may be painful for some handicapped persons. The authors describe the hardware and software structure chosen to perform the intelligent mobility functions in association with a disabled person. >	autonomous robot;mobile operating system	Alain Pruski;Guy Bourhis	1992		10.1109/ROBOT.1992.220252	mobile robot;embedded system;simulation;computer science;engineering;artificial intelligence	Robotics	62.24720815687777	-28.561085266891382	68466
b5adbe8a7f165bdebdb04d9ead8718ce8c627063	nonlinear fuzzy filters: an overview	fuzzy systems;fuzzy logic;fuzzy sets;noise	Emergent techniques based on Fuzzy Logic have successfully entered the area of nonlinear filters. Indeed, a variety of methods have been recently proposed in the literature which are able to perform detail-preserving smoothing of noisy image data yielding better results than classical operators. The aim of this paper is to present a selection of the most significant contributions in this field focussing on their similarities and differences. A brief introduction to the theory of fuzzy sets and systems is presented in order to make these results available to non-fuzzy researchers too.	emergent;fuzzy sets and systems;fuzzy logic;fuzzy set;nonlinear system;smoothing	Fabrizio Russo	1996	1996 8th European Signal Processing Conference (EUSIPCO 1996)		mathematical optimization;membership function;defuzzification;adaptive neuro fuzzy inference system;fuzzy classification;fuzzy number;neuro-fuzzy;machine learning;fuzzy measure theory;control theory;mathematics;fuzzy associative matrix;fuzzy set operations;fuzzy control system	AI	65.49621389150363	-36.4043514031186	68480
7b034aa74db14a751d3739510c8cabfffe70d158	a strategy for improving observability with mobile robots	observability mobile robots cameras surveillance robot vision systems costs humans reconnaissance batteries layout;observability;video surveillance mobile robots multi robot systems video cameras;video surveillance;mobile robot;surveillance;resource management;mobile docking stations observability mobile robots surveillance reconnaissance tasks multicameras fixed camera installation camera network robotic team batteries multiple task reallocation methods fixed docking stations;mobile robots;layout;fixed docking stations;mobile docking stations;robotic team;video cameras;batteries;multi robot systems;mobile communication;reconnaissance tasks;humans;multicameras;reconnaissance;camera network;fixed camera installation;robot vision systems;cameras;multiple task reallocation methods;robot kinematics;robot team	Many surveillance and reconnaissance tasks make use of multi-cameras in order to ensure that a particular mission is accomplished. These networks of cameras are useful as they can reduce the cost of human observers, are continuously observant (unlike humans who may fall asleep on the job), and can be implemented for a fairly low cost. However, in many scenarios, it does not make sense or may not be possible to have a fixed camera installation because the surveillance may only be needed for a short duration or it may take too long to do a proper install and observation is needed now. In terms of short terms and immediacy, mobile robots acting as a camera network provide an interesting middle ground. They can be deployed quickly to cover immediate needs, and they can be packed up and moved to another area if needs change. However, as the duration of the mission in which they are used increases, the robotic team will run out of power. This paper addresses some of the issues with keeping a surveillance team active while their batteries drain. Multiple task-reallocation methods are used in conjunction with an analysis of the effects of fixed vs mobile docking stations. Simulations were run requiring the team to provide camera coverage of a group of mobile “pedestrians” moving dynamically through a scene and the results are presented.	computer simulation;docking (molecular);humans;mobile robot	Andrew Drenner;Michael Janssen;Nikolaos Papanikolopoulos	2010	2010 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2010.5509198	mobile robot;embedded system;computer vision;simulation;computer science;engineering;artificial intelligence;resource management	Robotics	57.17218431299069	-29.389519563108358	68501
8849607817112b1a9e3be1a65a4735d0a145e6f6	error compensation for a parallel robot using back propagation neural networks	pose accuracy;backpropagation neural network;neural nets;pose accuracy error compensation parallel robot back propagation neural networks;back propagation neural networks;mobile robots;backpropagation;back propagation neural network;coordinate measuring machine;coordinate measuring machine error compensation parallel robot backpropagation neural network;coordinate transformation;neural nets backpropagation coordinate measuring machines error compensation mobile robots;error compensation;parallel robot;coordinate measuring machines;error compensation parallel robots neural networks robot kinematics robotic assembly coordinate measuring machines manufacturing fasteners manipulators error analysis	This paper presents an error compensation method for a novel 6 -DOF parallel robot using back propagation neural networks. The main error sources of the parallel robot are discussed. In order to improve the measuring accuracy, a specific target measured by a coordinate measuring machine is designed. The relationship of error map is established by the coordinate transformation. Experimental results showed that the pose accuracy of the parallel robot was improved by more than 60% after error compensation. A precise optical assembly was accomplished by the parallel robot after error compensation reliably and rapidly.	artificial neural network;backpropagation;capability maturity model;optical train;parallel manipulator;robot;software propagation	Li Ma;Weibin Rong;Lining Sun;Zhijun Li	2006	2006 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2006.340215	control engineering;mobile robot;computer vision;parallel manipulator;computer science;backpropagation;coordinate system;machine learning;artificial neural network	Robotics	61.68209755345219	-35.47513988276234	68913
f0cd9340e123ab3fa28de6139df80d88c75fc461	force controlled assembly of emergency stop button	robot sensing systems;feed forward;force sensors;uncertainty;operator space;force;assembly;feedback;force sensing force controlled assembly emergency stop button industrial robot feedback position sensor force sensor robot control;reglerteknik;industrial robots;robotic assembly feedback force control force sensors;robotic assembly;assembly switches force uncertainty robot sensing systems;switches;force sensor;force control	Modern industrial robots are fast and have very good repetitional accuracy, which have made them indispensable in many manufacturing applications. However, they are usually programmed to follow desired trajectories and only get feedback from position sensors. This works fine as long as the environment is very well structured, but does not give good robustness to objects not being positioned or gripped accurately. A solution is to use additional sensing, such as force sensors and vision. How to combine the data from the different sensors and use it in a good way to control the robot is still an area of research. This paper describes an assembly scenario where a switch should be snapped into place in a box. Force sensing is used to resolve the uncertain position of the parts and detect the snap at the end of the operation. During the assembly an uncertain distance is estimated to improve the performance. By performing the assembly several times, learning is used to generate feed-forward data, which is used to speed up the assembly.	computer vision;feedback;industrial robot;robustness (computer science);sensor;specification language	Andreas Stolt;Magnus Linderoth;Anders Robertsson;Rolf Johansson	2011	2011 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2011.5979745	operator space;control engineering;simulation;uncertainty;network switch;engineering;control theory;feedback;assembly;force;feed forward;force-sensing resistor	Robotics	59.93306699998806	-28.863661688067765	68923
374d6719bc71378f0107cd1f1465b8ad181c100b	flight path planning for mini rotor uavs	conferences automation;improved a star algorithm flight path planning mini rotor uav unmanned aerial vehicles rapidly exploring random tree rrt;trees mathematics aerospace control autonomous aerial vehicles path planning	Optimized path planning algorithm design is an important function of unmanned aerial vehicles (UAVs). Since the path obtained by the (rapidly exploring random tree) RRT is not necessarily optimal, excessive waypoints need to be refined. Heading of the quadrotor UAV is considered here as a moving cost of the improved A-star algorithm. Since the secondary path generated by the improved A-star algorithm is piecewise linear and may exhibit rugged curvature, it's necessary to refine the flight path making it to be applicable for quadrotor UAV flight. The proposed path planning method has been well verified via a variety of scenarios.	3d computer graphics;a* search algorithm;aerial photography;algorithm design;automated planning and scheduling;motion planning;national supercomputer centre in sweden;piecewise linear continuation;r.o.t.o.r.;rapidly-exploring random tree;real-time transcription;rugged computer;unmanned aerial vehicle	Chun-Liang Lin;Chia-Sung Lee;Yi-Ju Tsai;Ching-Huei Huang	2014	11th IEEE International Conference on Control & Automation (ICCA)	10.1109/ICCA.2014.6871118	simulation;aerospace engineering;engineering;aeronautics	Robotics	54.913924984310654	-26.30666299317965	69036
70493fc152eb7b99a761eba5f7a9c12e73aa464d	kinematic calibration system of robot hands using vision cameras	robot vision calibration humanoid robots manipulator kinematics;manipulator kinematics;robot vision;kinematic calibration system joint coordinates error estimation mark image analysis stage alignment image calibration calibration process finger skin vision image analysis alignment stages humanoid robot hands vision cameras;humanoid robots;finger joint error kinematic calibration robot hand vision camera;calibration thumb joints robot kinematics kinematics;calibration	Kinematic calibration system for humanoid robot hands was developed using vision cameras and alignment stages. Analysis of vision images of visual marks attached on the finger skin could give accurate joint coordinates of all finger joints through calibration process. This system consists of image calibration, stage alignment, mark image analysis, error estimate of joint coordinates, and finally calibrated kinematics of robot hand.	humanoid robot;image analysis	Sang-Mun Lee;Kyoung-Don Lee;Sang-Hyuek Jung;Tae-Sung Noh	2013	2013 10th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2013.6677506	computer vision;calibration;simulation;computer science;humanoid robot;artificial intelligence;inverse kinematics;robot kinematics;robot calibration;computer graphics (images)	Robotics	59.970006387550264	-35.1317345103886	69185
4bbb943a34aecd2607e9958e29588e7945ae4924	programmable ultrasonic range finder for mobile robot	navegacion;robot movil;ultrason;mobile robot;ultrasound;robotics;navigation;robot mobile;ultrasonido;robotica;robotique;moving robot;sonar		mobile robot	Rymantas Kazys;K. Kundrotas;V. Dzimidavicius;Liudas Mazeika;Andrzej Borkowski	1991	Robotersysteme		mobile robot;computer vision;navigation;computer science;artificial intelligence;ultrasound;robot control;robotics;sonar	Robotics	58.143882195783874	-32.413892562046875	69503
20c372ce0857963f53021e37755dc82a2b76c4cf	discovering a library of rhythmic gaits for spherical tensegrity locomotion		Tensegrity robots, which combine both rigid and soft elements, provide exciting new locomotion capabilities but introduce significant control challenges given their high-dimensionality and non-linear nature. This work first defines an effective parameterization of a spherical tensegrity for generating rhythmic gaits based on Central Pattern Generators (cp G). This allows the definition of periodic and rhythmic control signals, while exposing only five gait parameters. Then, this work proposes a framework for optimizing such gaits by exploring the parameter space through Bayesian Optimization on an underlying Gaussian Process regression model. The objective is to provide gaits that allow the platform to move along different directions with high velocity. Additionally, kNN binary classifiers are trained to estimate whether a parameter sample will result in an effective gait. The classification biases the sampling toward subspaces likely to yield effective gaits. An asynchronous communication layer is defined between the optimization and classification processes. The proposed gait discovery process is shown to efficiently optimize the parameters of gaits defined given the novel CPG architecture and outperforms less holistic approaches and Monte Carlo sampling.	angularjs;autonomous robot;bayesian optimization;biasing;central pattern generator;composability;experiment;feedback;gaussian process;holism;kinodynamic planning;kriging;lateral thinking;mathematical optimization;monte carlo method;nonlinear system;on the fly;paradiseo;sampling (signal processing);simulation;statistical classification;steady state;velocity (software development)	Colin Rennie;Kostas E. Bekris	2018	2018 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2018.8460873	bayesian optimization;parameter space;control engineering;monte carlo method;parametrization;gait;central pattern generator;architecture;machine learning;kriging;engineering;artificial intelligence	Robotics	62.9844300760164	-24.364917404810942	69577
6e7d7c5e6feac03de8c96f54fd74397178d026d6	evolution of a jump in an articulated leg with series-elastic actuation	evolutionary robotics dynamic maneuvers jump legged robot series elastic actuation sea;elasticity;animals;dynamic maneuvers;motion control;legged locomotion;mechanical property;actuators;articulated leg;biological control systems;dc motor;leg muscles actuators dc motors evolution biology humans animals elasticity genetic algorithms biological control systems;evolution biology;jump;jump articulated leg series elastic actuation dynamic maneuvers genetic algorithm;evolutionary robotics;motion control actuators genetic algorithms legged locomotion;series elastic actuation sea;genetic algorithm;genetic algorithms;humans;dc motors;skeletal muscle;series elastic actuation;legged robot;leg;muscles	The remarkable ability of humans and animals to perform dynamic maneuvers, such as a jump, is largely attributed to series-elastic elements in skeletal muscle. Both the degree of elasticity and the coordination of muscular contractions have been shown to impact jump performance. The objective of this paper is to use a genetic algorithm (GA) to optimize the control and actuator parameters of a series-elastic actuator (SEA), which is functionally analogous to skeletal muscle, in an articulated leg to produce the highest jump. Similar to skeletal muscle, the control and stiffness of the SEA is found by the GA to affect jump performance, yielding solutions with biological properties. In particular, the jumps evolved by the GA made use of the stretch and shortening cycle of the series-elasticity, which is commonly seen in nature to increase the force of an explosive movement. The model studied in this paper is of a prototype leg with series-elastic actuation. A detailed leg and actuator model was developed to include the important electrical and mechanical properties of the DC motors as well as the characteristics of the motor amplifiers.	amplifier;elasticity (cloud computing);elasticity (data store);genetic algorithm;prototype;software release life cycle	Simon Curran;David E. Orin	2008	2008 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2008.4543233	control engineering;simulation;genetic algorithm;computer science;engineering;artificial intelligence;dc motor;control theory	Robotics	67.78101374468925	-24.821353388864967	69641
d9108af58d64967af39d796b68a8cc04ff2159c0	accurate correction of robot trajectories generated by teaching using 3d vision by laser triangulation	trajectory correction;laser triangulation;teaching robot programming;3d vision	Normal utilization of robot manipulators of anthropomorphic type does not reach beyond the reiteration of preprogrammed trajectories. While static robot programs may be sufficient for high volume manufacturers, they are not adequate in one-off or small-batch manufacturing, where programs must be adapted and modified in a dynamic way to fulfill the changing requirements in this type of production. Among the different techniques for robot programming, teaching is one of the fastest when changes have to be applied in complex trajectories. The main drawback of this technique is that a lot of time is lost defining the robot points very precisely. The objective of the work presented in this paper is to facilitate robot programming by combining teaching programming techniques and a 3D machine vision based accurate trajectory following.	nvidia 3d vision;robot	Alberto Tellaeche;Ramón Arana;Iñaki Maurtua	2012		10.1007/978-3-642-33503-7_38	robot learning;computer vision;simulation;computer science;mobile robot navigation;personal robot;robot calibration;computer graphics (images)	Robotics	67.86203561140377	-32.279655746679	69670
9ab281839fdf101a5c1f03320161fa7360ac1e3f	advanced virtual testbeds: robotics know how for virtual worlds	virtual fores;working machine simulation;augmented reality technologies;mobile robots aerospace computing aerospace robotics aerospace simulation augmented reality;physics based modeling advanced virtual testbeds virtual worlds virtual reality space robotics augmented reality technologies;physics based modeling;space and industrial robotics;virtual fores projective virtual reality space and industrial robotics virtual factory working machine simulation;training;biological system modeling;virtual reality;mobile robots;advanced virtual testbeds;aerospace simulation;kinematics;projective virtual reality;virtual factory;virtual prototyping;aerospace computing;industrial robots;space robotics;solid modeling;aerospace robotics;robots;cost efficiency;manufacturing industry;humans;augmented reality;solid modeling biological system modeling robots humans training kinematics virtual reality;virtual worlds	"""In recent years, virtual reality has emerged as a key technology for improving and streamlining design, programming, manufacturing and training processes. Based on experiences in the fields of space robotics, industrial manufacturing, multi-physics and virtual prototyping, """"virtual testbeds"""" are currently being designed and implemented. Building on experiences gained in space robotics applications, the idea of """"virtual testbeds"""" currently conquers new fields of applications in the manufacturing industry, on construction sites and even """"in the woods"""". Interestingly, all fields can be supported with a rather generic and common basis so that the different applications can be realized very cost-efficiently. This paper is an attempt to give an overview over different current applications and setups. Furthermore, it will focus on the phases of a product's lifecycle that can already today be efficiently supported by virtual and augmented reality technologies. From a system theoretic standpoint, virtual testbeds are currently bridging the gap between virtual reality and robotics because on the one hand, robotics know how related to kinematics and physics based modeling is being used in virtual worlds to make them """"behave realistically"""", on the other hand, those virtual worlds make very efficient representations of """"real worlds"""" in which planning systems for robotics can try out action alternatives quickly and without danger to the robotic hardware."""	augmented reality;bridging (networking);experience;robot;robotic spacecraft;robotics;theory;virtual reality;virtual world	Jürgen Roßmann	2010	2010 11th International Conference on Control Automation Robotics & Vision	10.1109/ICARCV.2010.5707836	robot;mobile robot;augmented reality;kinematics;simulation;human–computer interaction;computer science;engineering;artificial intelligence;metaverse;virtual reality;solid modeling;manufacturing;cost efficiency;mechanical engineering	Robotics	66.3647648718996	-28.614854065133493	69813
a691a1bc38dc344c5126a080c21ff8bf1303c949	nimbro-op2x: adult-sized open-source 3d printed humanoid robot		Humanoid robotics research depends on capable robot platforms, but recently developed advanced platforms are often not available to other research groups, expensive, dangerous to operate, or closed-source. The lack of available platforms forces researchers to work with smaller robots, which have less strict dynamic constraints or with simulations, which lack many real-world effects. We developed NimbRo-OP2X to address this need. At a height of 135 cm our robot is large enough to interact in a human environment. Its low weight of only 19 kg makes the operation of the robot safe and easy, as no special operational equipment is necessary. Our robot is equipped with a fast onboard computer and a GPU to accelerate parallel computations. We extend our already opensource software by a deep-learning based vision system and gait parameter optimisation. The NimbRo-OP2X was evaluated during RoboCup 2018 in Montreál, Canada, where it won all possible awards in the Humanoid AdultSize class.	3d printing;computation;deep learning;graphics processing unit;humanoid robot;mathematical optimization;open-source software;robotics;simulation;vii	Grzegorz Ficht;Hafez Farazi;André Brandenburger;Diego Rodriguez;Dmytro Pavlichenko;Philipp Allgeuer;Mojtaba Hosseini;Sven Behnke	2018	CoRR		humanoid robot;simulation;control engineering;software;computer science;machine vision;robot;computation	Robotics	63.70603063255439	-30.101300554223066	69839
fd36492d659647834c20725509da595356af3bee	localization calibration using illuminance sensor for pedestrian dead reckoning with smartphones	indoor localization;legged locomotion;smart phones;illuminance sensor;accuracy;global positioning system;indoor environments;dead reckoning;pedestrian dead reckoning;smartphone;calibration	Pedestrian dead reckoning is a method of localization that uses inertial sensors to estimate the travelled distance from the previous position. This method can estimate the position when GPS or WiFi is not available such as indoor. However, pedestrian dead reckoning is subject to cumulative errors. In this paper, we exploit the fact that most of lights are located regularly in indoor environments. We calibrate the estimated position by pedestrian dead reckoning by the estimated distance between lights when we judge that lights are located regularly from the information obtained from illuminance sensor. In our proposed method, we do not need to know the position of lights. We judge whether lights are regularly located from the change of illuminance obtained by illuminance sensor in smartphone. When we judge that lights are regularly located, we calibrate the estimated position by the average estimated distance between lights. Our experimental results show that the accuracy of localization with our proposed method is higher than that of the conventional one that uses only inertial sensors.	dead reckoning;fiber optic sensor;global positioning system;internationalization and localization;need to know;smartphone	Yohei Murakami;Tomoaki Ohtsuki	2014	2014 IEEE 25th Annual International Symposium on Personal, Indoor, and Mobile Radio Communication (PIMRC)	10.1109/PIMRC.2014.7136506	dead reckoning;embedded system;computer vision;calibration;simulation;global positioning system;accuracy and precision;statistics	Mobile	56.37659890641055	-37.05416000015619	70220
f3f565ced6732a57ff76628ed72a14172df60c61	a cognitive architecture for modular and self-reconfigurable robots	robot sensing systems;robot sensing systems organisms robot kinematics mobile robots collision avoidance cameras;organisms;multi robot systems cognition mobile robots;h670 robotics and cybernetics;mobile robots;swarm organism swarm cognitive architecture self reconfigurable robots reconfigurable modular robot swarm heterogeneous modular robot swarm ec project replicator distributed cognition methods sos cycle;collision avoidance;cameras;robot kinematics	The field of reconfigurable swarms of modular robots has achieved a current status of performance that allows applications in diverse fields that are characterized by human support (e.g. exploratory and rescue tasks) or even in human-less environments. The main goal of the EC project REPLICATOR [1] is the development and deployment of a heterogeneous swarm of modular robots that are able to switch autonomously from a swarm of robots, into different organism forms, to reconfigure these forms, and finally to revert to the original swarm mode [2]. To achieve these goals three different types of robot modules have been developed and an extensive suite of embodied distributed cognition methods implemented [3]. Hereby the methodological key aspects address principles of self-organization. In order to tackle our ambitious approach a Grand Challenge has been proposed of autonomous operation of 100 robots for 100 days (100 days, 100 robots). Moreover, a framework coined the SOS-cycle (SOS: Swarm-Organism-Swarm) is developed. It controls the transitions between internal phases that enable the whole system to alternate between different modes mentioned above. This paper describes the vision of the Grand Challenge and the implementation and the results of the different phases of the SOS-cycle.		Paul Levi;Eugen Meister;Anne C. van Rossum;Tomás Krajník;Vojtech Vonásek;P. Stepan;Weiwei Liu;Fabio Caparrelli	2014	2014 IEEE International Systems Conference Proceedings	10.1109/SysCon.2014.6819298	control engineering;mobile robot;swarm robotics;simulation;ant robotics;engineering;artificial intelligence;social robot;self-reconfiguring modular robot;robot control;personal robot	Robotics	65.30286347471545	-28.209338893034978	70332
b22ace0b004d8b6d5b2ac6b53f3e0b8fb84a3890	effects of camera calibration errors on static-eye and hand-eye visual servoing	position;static;position image based;static hand eye;robustness;image based;camera calibration;visual servoing;article;hand eye	Effects of camera calibration errors for the point-to-point task are investigated in static-eye and hand-eye visual servoing realized with position-based and image-based control laws. For these four configurations, the effect of uncertainty on intrinsic and extrinsic parameters is analyzed. The results show local stability for all configurations under small calibration errors. However, a steady-state error is found in the hand-eye position-based configuration. Simulations have been carried out in order to confirm the theoretical results and evaluate the effects of the uncertainty in terms of the stability region. Another contribution of the paper consists of providing a method for estimating the stability region robust against uncertainty directions for the static-eye position-based case with uncertainty on the camera centers.	camera resectioning;visual servoing	Graziano Chesi;Koichi Hashimoto	2003	Advanced Robotics	10.1163/156855303322554409	computer vision;camera auto-calibration;camera resectioning;simulation;computer science;position;visual servoing;robustness	Robotics	60.8335045018901	-32.620186173303246	70378
8eb258d47acefc805795d1cf5621010d32870d9b	hand gesture interaction for virtual training of spg	feed forward neural network;virtual training;virtual reality;interactive method;image sensors;military systems;virtual reality data gloves feedforward neural nets gesture recognition image sensors military computing military systems tactile sensors;virtual reality training system hand gesture interaction driving training system virtual training environment data glove sensor finger movement monitoring wrist movement monitoring feed forward neural network hand gesture recognition artillery self propelled gun;tactile sensors;data gloves;feedforward neural nets;algorithm design;gesture recognition;military computing;virtual reality fingers neural networks virtual environment algorithm design and analysis vehicle driving application software skeleton wrist feedforward systems	We develop a virtual reality based driving training system of self-propelled gun (SPG). In order to make the interface of the system more powerful and natural, hand gesture interaction need to be incorporated into the system's interface. This paper discusses the use of hand gestures for interaction with the virtual training environment. We employ static hand gestures which coupled with hand translations and rotations as the method of interacting with the virtual training environment. An 18-sensor data glove is chosen for monitoring the movements of the fingers and the wrist. The feed-forward neural network is developed for recognizing gestures for use in virtual training application of artillery self-propelled gun (SPG). We present our approach for the algorithm design and implementation, and the use of the gestures in our application. The presented hand gesture interaction method can be effectively used in our virtual reality training system of SPG to perform various manipulating tasks in a more fast, precise, and natural way	algorithm design;artificial neural network;feedforward neural network;gesture recognition;interaction;self-propelled particles;virtual reality;wired glove	Deyou Xu;Wuyun Yao;Yongliang Zhang	2006	16th International Conference on Artificial Reality and Telexistence--Workshops (ICAT'06)	10.1109/ICAT.2006.68	embedded system;computer vision;simulation;engineering;gesture recognition	Visualization	62.52219455855494	-27.697920365908182	70446
96c30baff183ee3208312378c39b3eeba1c47336	acroban the humanoid: compliance for stabilization and human interaction	robot sensing systems;stability humanoid robots human robot interaction;humanoid robot;manipulators;human interaction;legged locomotion;humanoid robot acroban;human robot interaction;stability;trajectory;humanoid robots;human interaction humanoid robot acroban stability;legged locomotion humans manipulators robot sensing systems humanoid robots trajectory;humans;physical interaction	This video presents the humanoid robot Acroban which is to our knowledge the first humanoid robot which is able to: 1) demonstrate playful, compliant and intuitive physical interaction with children; 2) at the same time move and walk dynamically while keeping its equilibrium even if unpredicted physical interactions are initiated by humans.	fundamental interaction;humanoid robot;human–computer interaction	Olivier Ly;Pierre-Yves Oudeyer	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5650426	human–robot interaction;mobile robot;computer vision;simulation;computer science;humanoid robot;artificial intelligence;social robot;robot control;robot kinematics	Robotics	64.32235357850271	-24.24105379558274	70468
19b389a797a55c8b63dca8b6d1889df4cff8bfaa	a new technique for fully autonomous and efficient 3d robotics hand/eye calibration	contraste;image features;robot hand;image processing;prensor robot;camera television;procesamiento imagen;traitement image;robot industriel;computer vision;robot manipulator;prehenseur;algorithme;robot kinematics robotics and automation robot vision systems cameras arithmetic calibration manipulators grippers feature extraction testing;captador medida;algorithm;measurement sensor;capteur mesure;camara television;television camera;robots;robot industrial;ibm cartesian robot computer vision 3d robotics hand eye calibration eye on hand configuration accuracy;etalonnage;vision artificielle;gripper;artificial vision;calibration;industrial robot;robots calibration computer vision;algoritmo;vision artificial	The authors describe a novel technique for computing position and orientation of a camera relative to the last joint of a robot manipulator in an eye-on-hand configuration. It takes only about 100+64N arithmetic operations to compute the hand/eye relationship after the robot finishes the movement, and incurs only additional 64 arithmetic operations for each additional station. The robot makes a series of automatically planned movements with a camera rigidly mounted at the gripper. At the end of each move, it takes a total of 90 ms to grab an image, extract image feature coordinates, and perform camera extrinsic calibration. After the robot finishes all the movements, it takes only a few milliseconds to do the calibration. A series of generic geometric properties or lemmas are presented, leading to the derivation of the final algorithms, which are aimed at simplicity, efficiency, and accuracy while giving ample geometric and algebraic insights. Critical factors influencing the accuracy are analyzed, and procedures for improving accuracy are introduced. Test results of both simulation and real experiments on an IBM Cartesian robot are reported and analyzed. >	autonomous robot;robotics	Roger Y. Tsai;Reimar Lenz	1989	IEEE Trans. Robotics and Automation	10.1109/70.34770	robot;computer vision;calibration;simulation;image processing;computer science;engineering;professional video camera;feature;robot calibration;computer graphics (images)	Robotics	59.13987815173905	-34.03113302217216	70482
63218a118db5f1484e175a11caf472ad8933e068	design of a wireless assisted pedestrian dead reckoning system - the navmote experience	heading errors wireless assisted pedestrian dead reckoning system inertial sensing wireless sensor network navmote integrated magnetic compass accelerometers step detection step length estimation static calibrations dynamic calibrations wireless telemetry map matching pedestrian navigation system;estimation method;inertial navigation;pedestrian navigation system;indexing terms;sensor network;wireless sensor network;radiotelemetry;mobile radio;wireless sensor network dead reckoning pedestrian navigation system;middleware;dead reckoning;dead reckoning sensor systems wireless sensor networks magnetic sensors relays magnetic cores accelerometers hardware middleware software algorithms;wireless sensor networks;radiotelemetry inertial navigation mobile radio wireless sensor networks;embedded device	In this paper, we combine inertial sensing and sensor network technology to create a pedestrian dead reckoning system. The core of the system is a lightweight sensor-and-wireless-embedded device called NavMote that is carried by a pedestrian. The NavMote gathers information about pedestrian motion from an integrated magnetic compass and accelerometers. When the NavMote comes within range of a sensor network (composed of NetMotes), it downloads the compressed data to the network. The network relays the data via a RelayMote to an information center where the data are processed into an estimate of the pedestrian trajectory based on a dead reckoning algorithm. System details including the NavMote hardware/software, sensor network middleware services, and the dead reckoning algorithm are provided. In particular, simple but effective step detection and step length estimation methods are implemented in order to reduce computation, memory, and communication requirements on the Motes. Static and dynamic calibrations of the compass data are crucial to compensate the heading errors. The dead reckoning performance is further enhanced by wireless telemetry and map matching. Extensive testing results show that satisfactory tracking performance with relatively long operational time is achieved. The paper also serves as a brief survey on pedestrian navigation systems, sensors, and techniques.	algorithm;authentication;computation;course (navigation);data compression;data pre-processing;dead reckoning;download;embedded system;global positioning system;information centre;internet backbone;java;map matching;maxima and minima;memory management;middleware;missing data;multistage interconnection networks;network packet;network security;preprocessor;processor design;provisioning;relay;requirement;segmentation and reassembly;sensor node;step detection	Lei Fang;Panos J. Antsaklis;Luis Antonio Montestruque;M. Brett McMickell;Michael D. Lemmon;Yashan Sun;Hui Fang;Ioannis Koutroulis;Martin Haenggi;Min Xie;Xiaojuan Xie	2005	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2005.858557	dead reckoning;embedded system;simulation;wireless sensor network;telecommunications;computer science;engineering	Mobile	57.000409974448885	-34.79778838176427	70788
6a4f8f6bfb23b4d5d7e20b234874250da076913e	task-oriented planning algorithm for humanoid robots based on a foot repositionable inverse kinematics engine		Two major questions humanoid robots need to solve for manipulation tasks are whether they need to take steps and where to take steps to. In this paper, we introduce the formulation of a powerful inverse kinematics (IK) engine which can help to answer these questions. In the engine, the IK problem is formulated as an optimization problem. After configuring appropriate costs and constraints, the IK engine can compute a solution in which the robot is allowed to reposition its feet if necessary for meeting the task requirements. When the answers of these two questions are found, an integrated planning algorithm involving an IK solver, footstep planning and whole body manipulation motion planning is proposed. An object pickup scenario using the NASA-JSC Valkyrie robot is also provided in this paper to demonstrate the performance of the planning algorithm.	algorithm;automated planning and scheduling;humanoid robot;inverse kinematics;mathematical optimization;modality (human–computer interaction);motion planning;online and offline;optimization problem;requirement;robot end effector;solver;trajectory optimization	Xianchao Long;Murphy Wonsick;Velin D. Dimitrov;Taskin Padir	2016	2016 IEEE-RAS 16th International Conference on Humanoid Robots (Humanoids)	10.1109/HUMANOIDS.2016.7803410	simulation;artificial intelligence	Robotics	61.64733550462535	-24.462083294594343	70826
1aa7a80edfa19b90a74d5d58af2f24e9c1fa0c70	an evolutionary algorithm with non-random initial population for path planning of manipulators	path planning;motion planning;collision avoidance;evolutionary algorithm;computational efficiency	In this paper, a hierarchical evolutionary algorithm is proposed for the path planning of manipulators. The proposed algorithm consists of a global path planner (GPP) and a local motion planner (LMP). The global planner, a MAKLINK based approach, plans a trajectory for a robot end-effector from a starting free-space to goal free-space. An evolutionary algorithm with a non-random initial population is adopted to plan the manipulator configurations along a path given by the former stage. Once the optimal configuration is obtained by the evolutionary algorithm, the optimal chromosomes will be reserved as the initial population. Since the initial population is non-random, the evolution is more efficient and the planned path is smoother than traditional GA. Simulation results show that the proposed algorithm works well, specifically in terms of collision avoidance and computation efficiency.	evolutionary algorithm;motion planning	Chien-Chou Lin	2009		10.1007/978-3-642-02568-6_20	mathematical optimization;simulation;computer science;artificial intelligence;evolutionary algorithm;motion planning;population-based incremental learning	Robotics	54.581355426653644	-24.053163152878906	70884
581be7155bc48dcbfb5fd02daf012cda98474d31	a jacobian free approach for multi-robot relative localization	robot sensing systems robot kinematics estimation frequency measurement noise measurement accuracy;measurement update rate jacobian free approach multi robot relative localization rl approach multi robotics system mrs body fixed coordinate system square root cubature kalman filter high frequency egocentric sensory data low frequency inter robot relative measurements irrm monte carlo simulations sckf based rl scheme pose estimation exteroceptive sensory system;robot vision kalman filters monte carlo methods multi robot systems object detection object tracking pose estimation	This study presents a relative localization (RL) approach for an multi-robotics system (MRS), in which a robot detects and tracks one or more robots in its body-fixed coordinate system. A square-root cubature Kalman filter (SCKF) is employed to track the teammates' relative pose based on the high-frequency egocentric sensory data and the low-frequency inter-robot relative measurements (IRRM). This IRRM data consists of the relative range and the relative bearing between the tracking robot and its teammates. A series of Monte-Carlo simulations for a heterogeneous multi-robotic system is presented to evaluate the proposed SCKF-based RL scheme for different measurement noise configurations and different measurement update rates. To assess how the proposed SCKF-based RL scheme improves relative pose estimation, a comparison with the EKF and the general cubature Kalman filter-based RL schemes through numerical simulations are presented. The results suggest that the proposed SCKF-based RL scheme is a promising solution for relative pose estimation when an exteroceptive sensory system has high measurement uncertainty and/or low measurement update rate.	3d pose estimation;algorithm;approximation;computer simulation;correspondence problem;experiment;extended kalman filter;ground truth;image noise;jacobian matrix and determinant;minimal recursion semantics;monte carlo method;nonlinear system;numerical analysis;numerical integration;real-time clock;robot;robotic mapping;robotics;simulation;simultaneous localization and mapping	Thumeera R. Wanasinghe;George K. I. Mann;Ray G. Gosine	2014	2014 IEEE 27th Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2014.6901013	monte carlo localization;computer vision;simulation;computer science;control theory	Robotics	55.540088514740205	-37.14700432279615	71202
ac3e2eb5f69d76a26424678e58e4c41cec03a97a	object transport by modular robots that self-assemble	telerobotics mobile robots multi robot systems self adjusting systems;object transport;self assembling robots;self assembling robots object transport modular robots object manipulation task self reconfigurable robotic system swarm bot;self reconfigurable robotic system swarm bot;self adjusting systems;internal structure;mobile robots;mobots;swarm_bots;object manipulation;multi robot systems;self reconfigurable robots;telerobotics;self organization;mobile robots robotic assembly foot self assembly robotics and automation shape concrete robustness legged locomotion leg;modular robots;object manipulation task	We present a first attempt to accomplish a simple object manipulation task using the self-reconfigurable robotic system swarm-bot. The number of modular entities involved, their global shape or size and their internal structure are not pre-determined, but result from a self-organized process in which the modules autonomously grasp each other and/or an object. The modules are autonomous in perception, control, action, and power. We present quantitative results, obtained with six physical modules, that confirm the utility of self-assembling robots in a concrete task	autonomous robot;entity;machine perception;self-assembly;self-organization;self-reconfiguring modular robot;swarm intelligence	Roderich Groß;Elio Tuci;Marco Dorigo;Michael Bonani;Francesco Mondada	2006	Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.	10.1109/ROBOT.2006.1642087	telerobotics;control engineering;mobile robot;computer vision;self-organization;simulation;computer science;engineering;artificial intelligence;self-reconfiguring modular robot	Robotics	65.1380272243171	-26.481884349667144	71288
ca985bf7c66d067e1152601ad7f967a9e545e41a	design of obstacle modal discrimination system based on the neural network	robot sensing systems;backpropagation neural network;neural nets;path planning;training;simulation;mobile robots;backpropagation;autonomous mobile robot;neural networks infrared sensors robot sensing systems mobile robots turning robotics and automation computer simulation distance measurement testing dc motors;artificial neural networks;computational modeling;obstacle avoidance;bp neural network;bp network;computer simulation obstacle modal discrimination system bp neural network backpropagation neural network autonomous mobile robot path planning;obstacle modal discrimination system;control engineering computing;collision avoidance;neural nets backpropagation collision avoidance control engineering computing mobile robots;obstacle models;computer simulation;simulation bp network obstacle models;model simulation;data models;neural network	This paper is mainly to discriminate the obstacle models that the Robot may meet by using BP neural network. The essential work Autonomous Mobile Robot should complete includes path planning, localization and obstacle avoidance, and this paper has laid the foundation for these tasks. The result of computer simulation indicates that the design has achieved the expected task to judge the obstacle models.	artificial neural network;computer simulation;mobile robot;motion planning;obstacle avoidance	Hui Liu;Jianyi Lin;Qian Li	2009	2009 International Joint Conference on Bioinformatics, Systems Biology and Intelligent Computing	10.1109/IJCBS.2009.50	mobile robot;data modeling;computer vision;computer science;artificial intelligence;backpropagation;machine learning;motion planning;obstacle avoidance;computational model;artificial neural network	Robotics	63.471480146610595	-27.902226320894762	71410
61deeadf8c2a58c41782bf6326235bb6d025a700	flexible real-time control of home robots using a multi-agent based approach	command receiving behaviors flexible real time control home robots multi agent based approach autonomous mobile robot intelligent machines real time linux platform visual tracking obstacle avoidance;robot control real time systems control systems mobile robots intelligent robots machine intelligence competitive intelligence teamwork linux navigation;image motion analysis;agent based;intelligent robots;real time control;real time;mobile robots;control engineering computing multi agent systems home automation mobile robots intelligent robots image motion analysis robot vision collision avoidance;autonomous mobile robot;multi agent systems;control system;robot vision;obstacle avoidance;real time control system;control engineering computing;collision avoidance;visual tracking;home automation	This paper presents a multi-agent approach to developing a flexible real-time control system for an autonomous mobile robot. The main purpose of this study is to integrate heterogeneous algorithms and functions onboard the robot, while still to guarantee a reasonable responding time. The balance between generality and flexibility is also addressed. This strategy provides a framework for developing complex intelligent machines through teamwork of several people. The proposed control system has been implemented on an experimental robot based on a real-time Linux platform. Practical experiments show that the robot successfully navigates through complex environments by combining visual tracking, obstacle avoidance, and command receiving behaviors in a single system.	agent-based model;algorithm;autonomous robot;experiment;linux;mobile robot;multi-agent system;obstacle avoidance;rtlinux;real-time control system;real-time clock;real-time locating system;real-time transcription;video tracking	Chia-How Lin;Kai-Tai Song	2004	2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)	10.1109/IROS.2004.1389881	control engineering;mobile robot;embedded system;simulation;real-time control system;computer science;engineering;control system;artificial intelligence;social robot;robot control	Robotics	59.583249599407836	-30.547382310407354	71584
48a4711a6439a4ef25ce5ad5db7cae107310b34b	a dynamically reconfigurable stereoscopic/panoramic vision mobile robot head controlled from a virtual environment	dynamic reconfiguration;mobile robot;robot head;spherical mirror;computer vision;stereoscopic computer vision;high resolution camera;telerobotics;virtual environment;panoramic computer vision	We have built a mobile robotic platform that features an Active Robotic Head (ARH) with two high-resolution cameras that can be switched during robot operation between two configurations that produce respectively panoramic and stereoscopic images. Image disparity is used for improving the quality of the texture. The robot head switches dynamically, based on robot operation between the stereoscopic configuration and the panoramic configuration.	binocular disparity;image resolution;mobile robot;network switch;reconfigurability;stereoscopy;virtual reality	Walter A. Aprile;Emanuele Ruffaldi;Edoardo Sotgiu;Antonio Frisoli;Massimo Bergamasco	2008	The Visual Computer	10.1007/s00371-008-0278-0	telerobotics;mobile robot;computer vision;simulation;computer science;virtual machine;artificial intelligence;curved mirror;mobile robot navigation;computer graphics (images)	Robotics	59.30032668185612	-32.97134390120621	71767
02f2a2b1862bc37c0d4cb35b701c548975f74a51	development of a vision system for an outdoor service robot to collect trash on streets	outdoor service robot;trash collec- tion task;fast pattern matching;environment beautification;pattern matching;vision system	The outdoor service robot which we call OSR-01 is presently under development intending for cleaning up urban areas by means of collecting discarded trash such as PET bottles, cans, plastic bags and so on. We, in this paper, describe the architecture of OSR-01 consisting of hardwares such as sensors, a manipulator, driving wheels, etc. for searching for and picking up trash, and softwares such as fast pattern matching for identifying various trash and distance measurement for picking up via the manipulator. After describing the vision system in detail, which is one of the most critical parts of the trash collection task, we show the result of an open experiment in which OSR-01 collects plastic PET bottles on a real shopping street in the special zone for robot research and development in Kitakyushucity.	experiment;pattern matching;plasma cleaning;polyethylene terephthalate;poor posture;robotics;sensor;service robot;wheels	Yasuhiro Fuchikawa;Takeshi Nishida;Shuichi Kurogi;Takashi Kondo;Fujio Ohkawa;Toshinori Suehiro;Yasuhiro Watanabe;Yoshinori Kawamura;Masayuki Obata;Hidekazu Miyagawa;Yoshimitsu Kihara	2005			simulation;mobile robot navigation;pattern matching;machine vision;artificial intelligence;computer vision;service robot;geography	Robotics	57.81689553399151	-31.738872020483	71966
a2dcdd4ef98fbd7454ba146dd101b5e052214784	pareto-optimal collaborative defensive player positioning in simulated soccer	assignment problem;robot soccer;pareto optimality	The ability by the simulated soccer player to make rational decisions about moving without ball is a critical factor of success. In this study the focus is placed on the defensive situation, when the ball is controlled by the opponent team in 2D simulated soccer. Methods for finding good defensive positions by the robotic soccer players have been investigated by some RoboCup scholars. Although soccer teams using these methods have proved to be reasonably good, the collaboration issue in defense has been overlooked. In this paper, we demonstrate that collaboration in defense yields better results. In doing so, we treat optimal defensive positioning as a multi-criteria assignment problem and propose a systematic approach for solving it. Besides achieving better performance, this makes it possible to gracefully balance the costs and rewards involved in defensive positioning.	global positioning system;pareto efficiency	Vadim Kyrylov;Eddie Hou	2009		10.1007/978-3-642-11876-0_16	simulation;computer science;assignment problem	HCI	54.595185825016166	-25.16773643346935	72074
b1744e9d8ff1023c589ca5c06742871cf4c74edd	development of an integrated driving path estimation algorithm for acc and aebs using multi-sensor fusion	path planning;road traffic;adaptive control;braking;sensor fusion adaptive control brakes braking path planning position control road traffic;position control;advanced emergency braking system function integrated driving path estimation algorithm multisensor fusion adaptive cruise control system ego vehicle path primary target detection rate path prediction process vehicle states vision data dynamic maneuvering situation driving mode index driver maneuver intention driving path information closed loop simulation;vehicles roads vehicle dynamics estimation heuristic algorithms indexes geometry;brakes;sensor fusion	This paper presents an integrated driving path estimation algorithm for adaptive cruise control system and advanced emergency braking system using multi-sensor fusion. This algorithm is developed to predict the ego-vehicle's path accurately and improve primary target detection rate. The path prediction is consisted of two prediction process; one is based on vehicle states and the other is based on vision data. For application to dynamic maneuvering situation, the driving mode index which allows a detection of the driver maneuver intention is proposed. In accordance with the driving mode, the two types of driving path information are integrated finally. The proposed driving path estimation algorithm has been investigated via closed-loop simulation. It has been shown that the proposed driving path estimation algorithm enhance the capabilities of adaptive cruise control and advanced emergency braking system functions by providing the ego-vehicles path accurately, especially in dynamic maneuvering situation.	air traffic control radar beacon system;algorithm;control system;simulation	Dongwoo Lee;Beomjun Kim;Kyoungsu Yi;Jaewan Lee	2012	2012 IEEE 75th Vehicular Technology Conference (VTC Spring)	10.1109/VETECS.2012.6240284	control engineering;simulation;adaptive control;computer science;engineering;control theory;brake	Robotics	55.31579352826547	-31.45578280918116	72297
b1855cd974c66a86906f975e22f83b0054a0a487	the right direction to smell: efficient sensor planning strategies for robot assisted gas tomography	robots chemioception gas sensors;efficient sensor planning strategies human expert template matching technique optimization algorithm reconstruction errors sensing geometries smell robot assisted gas tomography;robot sensing systems geometry tomography planning mobile robots;robotics;datorsystem;computer systems;robotteknik och automation;datavetenskap;computer science	Creating an accurate model of gas emissions is an important task in monitoring and surveillance applications. A promising solution for a range of real-world applications are gas-sensitive mobile robots with spectroscopy-based remote sensors that are used to create a tomographic reconstruction of the gas distribution. The quality of these reconstructions depends crucially on the chosen sensing geometry. In this paper we address the problem of sensor planning by investigating sensing geometries that minimize reconstruction errors, and then formulate an optimization algorithm that chooses sensing configurations accordingly. The algorithm decouples sensor planning for single high concentration regions (hotspots) and subsequently fuses the individual solutions to a global solution consisting of sensing poses and the shortest path between them. The proposed algorithm compares favorably to a template matching technique in a simple simulation and in a real-world experiment. In the latter, we also compare the proposed sensor planning strategy to the sensing strategy of a human expert and find indications that the quality of the reconstructed map is higher with the proposed algorithm.	algorithm;hotspot (wi-fi);mathematical optimization;mobile robot;sensor;shortest path problem;simulation;template matching;tomographic reconstruction;tomography	Muhammad Asif Arain;Erik Schaffernicht;Victor Manuel Hernandez Bennetts;Achim J. Lilienthal	2016	2016 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2016.7487624	computer vision;simulation;computer science;engineering;artificial intelligence;robotics	Robotics	53.94725229066737	-25.672843809923386	72459
7c3c8f291ce3cadddc13e1ebbc9a41938b783c5c	robust direct visual servo using network-synchronized cameras	modelizacion;electric current;60 hz visual servoing system visual feedback eigenspace methods position measurement error euclidean distance kalman filter planar robot occlusions distributed vision network synchronize cameras;image motion analysis;euclidean theory;measurement error;analisis estadistico;filtro kalman;capteur position;occlusion;courant electrique;position transducteur;position measurement error;occultation;filtre kalman;kalman filters;asservissement visuel;mesure position;technique video;oclusion;kalman filter;movie camera;array signal processing;robotics;euclidean distance;probabilistic approach;indexing terms;tecnica video;eigenspace methods;medicion posicion;computer networks;network synchronize cameras;distributed vision;modelisation;camara;feedback;round robin;estimation erreur;robot vision;retroaccion;senal video;statistical analysis;signal video;retroaction;grande vitesse;velocity sensor;error estimation;enfoque probabilista;approche probabiliste;servomechanisms;analyse statistique;estimacion error;position measurement;position estimation;theorie euclidienne;capteur vitesse;feedback regulation;robotica;video signal;video technique;visual feedback;robustness;sensor posicion;gran velocidad;robotique;visual servoing system;ocultacion;visual servoing;sensor velocidad;experimental measurement;array signal processing servomechanisms robot vision kalman filters cameras image motion analysis;modeling;posicion transductor;corriente electrica;high speed;robot vision systems;occlusions;planar robot;transducer position;cameras;robustness servomechanisms cameras robot vision systems visual servoing feedback euclidean distance computer networks position measurement measurement errors;measurement errors;60 hz;servomando visual;teoria euclidiana;camera;position sensor	"""A direct visual servoing system is described which employs a network of cameras providing high-speed vision feedback that is robust to occlusions. This system does not rely on any external position or velocity sensors, but directly sets motor current using visual feedback alone. The limitation of 60 Hz video is overcome with multiple RS-170 cameras, synchronized over a network in round-robin fashion, to capture video fields at different instants in time. Each camera has its own computer that processes video at field rates to determine the position of a planar robot joint using eigenspace methods. The eigenspace computations produce position and Euclidean distance measurements sent from each camera node over a network to a master servo computer. It is shown that the Euclidean distance from the manifold in eigenspace in the presence of random occlusions is statistically related to the position measurement error. Occlusions are thus considered as """"noise,"""" and the measurement error variance is estimated directly from Euclidean distance. The measurement error variance is applied directly to a Kalman filter, which weights feedback from each camera to provide improved position estimates. The Kalman filter also models the vision transport delays to provide timely position estimates to ensure the stable direct visual servoing of a planar robot. Simulation results illustrate improvement in dynamic performance as the number of cameras are increased. Experimental measurements were obtained for a network of four cameras performing direct visual servoing of a simple planar robot. The results demonstrate the step response, as well as stable servo-hold operation in the presence of full occlusions in a subset of cameras or with partial occlusions in all cameras."""	algorithmic efficiency;byte;central processing unit;computation;computer;distributed computing;euclidean distance;kalman filter;kerrison predictor;megabyte;ntsc;negative feedback;network packet;redundancy (engineering);region of interest;response time (technology);robot;round-robin scheduling;sampling (signal processing);scalability;sensor;servo;simulation;step response;velocity (software development);visual servoing	Derek C. Schuurman;David W. Capson	2004	IEEE Transactions on Robotics and Automation	10.1109/TRA.2003.819718	kalman filter;computer vision;simulation;computer science;engineering;control theory;mathematics;robotics;statistics;observational error	Robotics	59.048012684881115	-35.561381394717756	72647
18c05ef4423903b8bee3a68c3ff267bedf5238e1	homography-based visual servo tracking control of a wheeled mobile robot	lyapunov methods;robot movil;visual servo control;homograph;systeme non holonome;underactuation;control design homography based visual servo tracking control underactuated wheeled mobile robot monocular camera system nonholonomic motion constraints camera in hand problem prerecorded image sequence stationary reference image target points projective geometric relationships euclidean homographies kinematic controller lyapunov based analysis adaptive update law translation error system;image motion analysis;euclidean theory;funcion lyapunov;sintesis control;subaccionamiento;nonholonomic;trajectoire optimale;mobile robot;lyapunov function;homografo;visual servo control lyapunov methods mobile robot nonholonomic;servomechanisms mobile robots target tracking motion control control systems robot vision systems cameras image sequences trajectory kinematics;asservissement visuel;cinematica;control design;technique video;sistema no holonomo;mobile robots;roue;robotics;rueda;tecnica video;kinematics;homographe;wheeled mobile robot;lyapunov method;robot mobile;fonction lyapunov;position control;sous actionnement;optimal trajectory;synthese commande;image sequence;cinematique;trayectoria optima;theorie euclidienne;tracking control;robotica;lyapunov methods image motion analysis position control mobile robots cameras image sequences robot kinematics;video technique;secuencia imagen;robotique;visual servoing;wheel;non holonomic system;control synthesis;cameras;moving robot;sequence image;servomando visual;teoria euclidiana;robot kinematics;image sequences	A visual servo tracking controller is developed in this paper for a monocular camera system mounted on an underactuated wheeled mobile robot (WMR) subject to nonholonomic motion constraints (i.e., the camera-in-hand problem). A prerecorded image sequence (e.g., a video) of three target points is used to define a desired trajectory for the WMR. By comparing the target points from a stationary reference image with the corresponding target points in the live image and the prerecorded sequence of images, projective geometric relationships are exploited to construct Euclidean homographies. The information obtained by decomposing the Euclidean homography is used to develop a kinematic controller. A Lyapunov-based analysis is used to develop an adaptive update law to actively compensate for the lack of depth information required for the translation error system. Experimental results are provided to demonstrate the control design.	euclidean distance;homography (computer vision);live usb;lyapunov fractal;mobile robot;servo;stationary process;visual servoing	Jian Chen;Warren E. Dixon;Darren M. Dawson;Michael L. McIntyre	2006	IEEE Transactions on Robotics	10.1109/TRO.2006.862476	control engineering;mobile robot;computer vision;computer science;artificial intelligence;control theory;mathematics;robotics	Robotics	61.045675589350665	-32.0604754320806	72724
8b7a278c8c3502d4de678c51452fdb294ab99719	the effect of kinematic model complexity on manipulator accuracy	spatial variables measurement computerised instrumentation ibm computers kinematics microcomputer applications robots;manipulators;ibm personal computer;joint offsets;personal computer;chaos;spatial variables measurement;robot kinematics calibration robotics and automation manipulators gears mechanical variables measurement chaos mechanical engineering microcomputers equations;manipulator accuracy;measurement system;robot location;kinematics;kinematic model;microcomputer;pose measurement system;model complexity;coordinate measuring machine;mechanical engineering;compliance microcomputer kinematic model complexity manipulator accuracy pose measurement system coordinate measuring machine ibm personal computer robot location joint offsets kinematic model;gears;robots;ibm computers;compliance;kinematic model complexity;computerised instrumentation;microcomputer applications;mechanical variables measurement;calibration;robotics and automation;microcomputers;robot kinematics	A pose measurement system consisting of a small coordinate measuring machine, an IBM personal computer, and several fixtures is described. The pose measurement system is used to collect two data sets of 45 poses each. These data are then used to identify the parameters in five manipulator models of increasing complexity. The models consist of a nominal model, a model with six parameters to determine the actual robot location, a 12-parameter model including robot location and joint offsets, a 30-parameter kinematic model, and a 32-parameter model including compliance in two joints. The pose measurement system is used to evaluate the accuracy of each of the five models. The results demonstrate that, in general, increases in model complexity lead to enhanced accuracy, although the degree of improvement at any level is dependent on the particular robot under study. >		Benjamin W. Mooring;S. S. Padavala	1989		10.1109/ROBOT.1989.100049	control engineering;embedded system;simulation;computer science;engineering;artificial intelligence;microcomputer	Robotics	61.13125905773826	-35.21196135575038	72963
0e49316b29ade95b2248a2e36a97d215fda5feed	lightweight procedural animation with believable physical interactions	automatic control;toy industry;procedural animation;computer animation artificial intelligence;virtual character;control systems;twig;motion control;virtual characters;animation system;virtual characters interactive narrative procedural animation;kinematics;believable physical interactions;kinematic control;motion capture;puppetry style;computational modeling;interactive narrative;control system synthesis;animation;animation automatic control computational modeling motion control control system synthesis control systems force control torque control kinematics toy industry;artificial intelligence;dynamic simulation;computer animation;lightweight procedural animation;physical interaction;virtual character lightweight procedural animation believable physical interactions twig artificial intelligence dynamic simulation puppetry style kinematic control interactive narrative;torque control;force control	In this paper, we describe Twig, a fast, AI-friendly procedural animation system that supports easy authoring of new behaviors. The system provides a simplified dynamic simulation that is specifically designed to be easy to control. Characters are controlled by applying external forces directly to body parts, rather than by simulating joint torques. This ldquopuppetry-stylerdquo of control provides the simplicity of kinematic control within an otherwise dynamic simulation. Although less realistic than motion capture or full biomechanical simulation, Twig produces compelling, responsive character behavior. Moreover, it is fast, stable, supports believable physical interactions between characters such as hugging, punching, and dragging, and makes it easy to author new behaviors.	drag and drop;dynamical simulation;fundamental interaction;motion capture;procedural animation;simulation;twig	Ian Horswill	2008	IEEE Transactions on Computational Intelligence and AI in Games	10.1109/TCIAIG.2009.2019631	motion control;anime;dynamic simulation;kinematics;motion capture;simulation;computer science;artificial intelligence;automatic control;computer animation;multimedia;computational model;computer graphics (images)	Graphics	66.86295328807961	-26.5197688936715	73069
5eea09f72fe67a35d7531568d0810b7281591e3c	a non-traditional omnidirectional vision system with stereo capabilities for autonomous robots	vision system;robot movil;obstaculo;ccd camera;obstacle detection;omnidirectional vision;perspectiva;sistema hibrido;traitement image stereoscopique;systeme discret;vision estereoscopica;autonomous system;vision stereoscopique;continuous system;perspective;sistema autonomo;computer vision;systeme continu;captador medida;measurement sensor;capteur mesure;robot mobile;sistema continuo;stereo image processing;systeme autonome;stereo vision;hybrid system;camara ccd;camera ccd;vision ordinateur;vision artificielle;sistema discreto;stereopsis;artificial vision;autonomous robot;moving robot;obstacle;discrete system;systeme hybride;vision artificial	In this paper we describe a vision system based on the use of both an omnidirectional vision sensor and a standard CCD camera. This hybrid system is aimed at compensating for drawbacks of both sensors and at offering new opportunities deriving by their joint use. It can be used in several tasks, such as implementation of peripheral/foveal vision strategies, stereo vision, etc. The paper describes the device on which the vision system is based and its use as a stereo system for obstacle detection in a semi-structured environment, based on a perspective removal algorithm.	autonomous robot	Giovanni Adorni;Luca Bolognini;Stefano Cagnoni;Monica Mordonini	2001		10.1007/3-540-45411-X_36	computer stereo vision;smart camera;stereo cameras;computer vision;simulation;machine vision;computer science;stereopsis	Robotics	57.984744767526884	-33.00442199885674	73161
1b3a65c2139577d0662650806b121c3188e19912	outdoor navigation using natural landmarks by teaching-playback scheme	teaching playback scheme;robot sensing systems;control systems;legged locomotion;mobile robot;path planning;mobile robots;autonomous mobile robot;automatic generation;educational robots;perceived route map;navigation;navigation robot sensing systems humans education educational robots robotics and automation legged locomotion dead reckoning robustness control systems;path planning landmark recognition teaching playback scheme outdoor navigation autonomous mobile robot perceived route map;robustness;humans;dead reckoning;landmark recognition;robotics and automation;outdoor navigation	In this paper, we report the outdoor navigation of an autonomous and self-contained mobile robot using the perceived route map (PRM) generated through human assisted route teaching. The PRM includes the path from the start to the goal taught by the operator and landmark information are automatically generated by the robot itself. The target environment is a paved or tiled pedestrian walkway. The pedestrian walkway can be assumed to be a two dimensional plane along with a wall, a hedge or a tree, etc., which can be utilized as landmarks for estimating the robot position. The robot is assumed to have sensors to detect landmarks and obstacles. A walking person or bicycle is assumed to be a moving obstacle.		Shoichi Maeyama;Akihisa Ohya;Shin'ichi Yuta	1997		10.1109/IROS.1997.656801	mobile robot;computer vision;simulation;computer science;control system;artificial intelligence;mobile robot navigation	Robotics	59.12732178801363	-29.856561502336465	73426
aa6bc92129434e7ec53dba2edd8774036993f5b2	multimodal feedback for teleoperation of multiple mobile robots in an outdoor environment	multimodal feedback;outdoor environment;bilateral teleoperation;psychophysical evaluation;multi robot systems	Better situational awareness helps understand remote environments and achieve better performance in the teleoperation of multiple mobile robots (e.g., a group of unmanned aerial vehicles). Visual and force feedbacks are the most common ways of perceiving the environments accurately and effectively; however, accurate and adequate sensors for global localization are impractical in outdoor environments. Lack of this information hinders situational awareness and operating performance. In this paper, a visual and force feedback method is proposed for enhancing the situational awareness of human operators in outdoor multi-robot teleoperation. Using only the robots’ local information, the global view is fabricated from individual local views, and force feedback is determined by the velocity of individual units. The proposed feedback method is evaluated via two psychophysical experiments: maneuvering and searching tests using a human/hardware-in-the-loop system with simulated environments. In the tests, several quantitative measures are also proposed to assess the human operator’s maneuverability and situational awareness. Results of the two experiments show that the proposed multimodal feedback enhances only situational awareness of the operator.	aerial photography;experiment;haptic technology;hardware-in-the-loop simulation;mobile robot;multimodal interaction;sensor;unmanned aerial vehicle;velocity (software development)	Ayoung Hong;Dong Gun Lee;Heinrich H. Bülthoff;Hyoung Il Son	2016	Journal on Multimodal User Interfaces	10.1007/s12193-016-0230-y	computer vision;simulation;communication	Robotics	57.81157881488485	-27.26536519819801	73440
aa5ac9f0091353af0f28e90d0a88f01f2007f331	infra-red location system for navigation of autonomous vehicles	automotive engineering;beacon navigation;flexible manufacturing systems;vehicles computerised navigation flexible manufacturing systems industrial robots position control;autonomous vehicle;intelligent manufacturing systems;geometry;positioning errors;mobile robots;remotely operated vehicles;infra red;navigation;flexible manufacturing;beacon navigation fms environment ir location system industrial robots computerised navigation autonomous vehicles positioning errors;position control;navigation remotely operated vehicles mobile robots position measurement goniometers geometry dead reckoning equations automotive engineering intelligent manufacturing systems;industrial robots;position measurement;ir location system;navigation system;vehicles;dead reckoning;goniometers;autonomous vehicles;computerised navigation;fms environment	A beacon method for locating autonomous vehicles in a flexible manufacturing environment is presented, and typical positioning errors of such a method are computed. Data obtained from an experimental beacon navigation system support the analytical results which indicate excellent positioning accuracy is possible over a large workspace, and that unlike dead reckoning systems, navigation errors are dependent solely upon the vehicle's position in the workspace and not the distance traveled. >	autonomous robot	Clare D. McGillem;Theodore S. Rappaport	1988		10.1109/ROBOT.1988.12230	remotely operated underwater vehicle;dead reckoning;control engineering;mobile robot;embedded system;navigation;simulation;infrared;wind triangle;goniometer;computer science;engineering	Robotics	57.23259205682364	-33.95659551398768	73479
07ed7a06f0902a7eb46005b32ee3637305ea5cc8	rejection of sliding effects in car like robot control: application to farm vehicle guidance using a single rtk gps sensor	agricultural machinery;nonlinear adaptive control;mobile robot;robot control vehicles navigation global positioning system wheels mobile robots adaptive control kinematics spraying production facilities;nonlinear control systems;adaptive control;field experiment;robot control;steering car farm vehicle guidance car like robot control agricultural applications row cropping vehicle localization single rtk gps sensor sliding effect rejection nonlinear adaptive control law robot control;global positioning system;nonlinear control system;agricultural machinery adaptive control automatic guided vehicles real time systems global positioning system nonlinear control systems vehicle dynamics;automatic guided vehicles;vehicle dynamics;real time systems	A very accurate vehicle guidance is required in numerous agricultural applications, as seeding, spraying, row cropping, . . . Accuracy in vehicle localization can be obtained in realtime from a RTK GPS sensor. Several control laws, relying on this sensor, have been previously designed and provide satisfactory results as long as vehicles do not slide. However, sliding has to occur in agricultural tasks (sloping fields, curves on a wet land, . . .). The challenge addressed in this paper is to preserve vehicle guidance accuracy in such situations. A nonlinear adaptive control law is here designed. Simulation results and field experiments, demonstrating the capabilities of that control scheme, are reported and discussed.	experiment;global positioning system;nonlinear system;optimal control;real time kinematic;rejection sampling;robot control;sensor web;simulation	Roland Lenain;Benoit Thuilot;Christophe Cariou;Philippe Martinet	2003		10.1109/IROS.2003.1249748	agricultural machinery;control engineering;mobile robot;vehicle dynamics;simulation;field experiment;global positioning system;adaptive control;computer science;engineering;artificial intelligence;control theory;robot control	Robotics	57.65641809205888	-29.01757623094218	73519
b3a755ba17b27b4ebbaf0870be653a71b15ce197	three-dimensional modeling of coordinate measuring machines probing accuracy and settings using fuzzy knowledge bases: application to tp6 and tp200 triggering probes	measurement;coordinate measuring machine calibration;fuzzy logic;genetic algorithms	One of the fundamental elements that determines the precision of coordinate measuring machines (CMMs) is the probe, which locates measuring points within measurement volume. In this paper genetically generated fuzzy knowledge based models of three-dimensional (3-D) probing accuracy for oneand two-stage touch trigger probes are proposed. The fuzzy models are automatically generated using a dedicated genetic algorithm developed by the authors. The algorithm uses hybrid coding, binary for the rule base and real for the database. This hybrid coding, used with a set of specialized operators of reproduction, proved to be an effective learning environment in this case. Data collection of the measured objects’ coordinates was carried out using a special setup for probe testing. The authors used a novel method that applies a low-force highresolution displacement transducer for probe error examination in 3-D space outside the CMM measurement. The genetically generated fuzzy models are constructed for both one stage (TP6) and two stage (TP200) types of probes. First, the optimal number of settings is defined using an analysis of the influence of fuzzy rules on TP6 accuracy. Then, once the number of settings is obtained, near optimal fuzzy knowledge bases are generated for both TP6 and TP200 triggering probes, followed by analysis of the finalized fuzzy rules bases for knowledge extraction about the relationships between physical setup values and error levels of the probes. The number of fuzzy sets on each premise leads to the number of physical setups needed to get satisfactory error profiles, whereas the fuzzy rules base adds to the knowledge linking the design experiment parameters to the pretravel error of CMM machines. Satisfactory fuzzy logic equivalents of the 3-D error profiles were obtained for both TP6 and TP200 with root mean squsre errors ranging from 0.00 mm to a maximum of 0.58 mm.	3d modeling;angularjs;capability maturity model;dimensional modeling;displacement mapping;experiment;fuzzy concept;fuzzy logic;fuzzy rule;fuzzy set;genetic algorithm;human error;image resolution;on-premises software;port triggering;rule-based system;transducer;xyz file format	Sofiane Achiche;Adam Wozniak	2012	AI EDAM	10.1017/S0890060411000151	fuzzy logic;genetic algorithm;defuzzification;adaptive neuro fuzzy inference system;computer science;artificial intelligence;machine learning;data mining;measurement	ML	61.75595522524646	-36.464910230928986	73780
a9334f77ad82a3c4535c8132e3a24208ff96e656	performance evaluation of real-time mems ins/gps integration with zupt/zihr/nhc for land navigation	global positioning system real time systems sensors accuracy synchronization;nonlinear filters;performance evaluation;kalman filters;inertial navigation;real time systems global positioning system inertial navigation kalman filters micromechanical devices nonlinear filters performance evaluation;micromechanical devices;global positioning system;nonholonomic constraint real time mems ins gps integrated system zupt zihr nhc land navigation real time low cost ins gps integrated navigator pc platform mems imu ekf update source navigation solutions gps signal blockages field tests frequent zupt zihr kinematically stable performance operation free inertial mode gps denied areas inertial navigation system global positioning system auto zero velocity update zero integrated heading rate;nhc real time ins gps zupt zihr;real time systems	INS/GPS integrated system has been one of the most popular methodologies in the research field of navigation technology. This paper aims at developing a real-time low-cost INS/GPS integrated navigator based on PC platform and reviewing many problems encountered in the development of real time system. A MEMS IMU is applied in the system to meet the requirements of low cost and small size. The proposed system utilizes Auto ZUPT/ZIHR as an accurate update source for EKF to improve the accuracy of navigation solutions during GPS signal blockages. In the end, various field tests which include a pure INS aided by ZUPT/ZIHR and NHC, a simple INS/GPS and an INS/GPS aided by ZUPT/ZIHR and NHC are conducted in downtown. The preliminary results illustrates the proposed system with frequent ZUPT/ZIHR provides a stable performance operating kinematically in free inertial mode without the aiding of GPS by 15 minutes with a low-cost IMU and the INS/GPS integrated solutions are improved by 50% when automatic ZUPT/ZIHR and NHC are applied in GPS denied areas.	extended kalman filter;global positioning system;microelectromechanical systems;performance evaluation;personal computer;real-time clock;requirement	Cheng-Yueh Liu;Cheng-An Lin;Kai-Wei Chiang;Shih-Ching Huang;Chin-Chia Chang;Jia-Ming Cai	2012	2012 12th International Conference on ITS Telecommunications	10.1109/ITST.2012.6425247	control engineering;embedded system;gps/ins;simulation;geography	Robotics	57.66046427604177	-34.65312214095279	73864
0b09b6aaf2c43294f676ee53f0c256e55715e662	visual simultaneous localization and mapping with direct orientation change measurements		This paper presents an extension of the visual simultaneous localization and mapping (VSLAM) system with the direct measurements of the robot’s orientation change. Four different sources of the additional measurements were considered: visual odometry using both the 5-point [10, 15] and 8-point algorithm [9], wheel odometry and Inertial Measurement Unit (IMU) measurements. The accuracy of the proposed system was compared with the accuracy of the canonical MonoSLAM [7]. The introduction of the additional measurements allowed to reduce the mean error by 17%.	simultaneous localization and mapping	Adam Schmidt;Marek Kraft;Michal Fularz;Zuzanna Domagala	2013		10.1007/978-3-319-02309-0_13	computer vision;simultaneous localization and mapping;inertial measurement unit;odometry;artificial intelligence;visual odometry;computer science;mean squared error	Robotics	55.47041760744249	-37.03746716008814	73988
efed77aa9c0df590c8863a3bf65f8a5849347913	teaching robots to do object assembly using multi-modal 3d vision		The motivation of this paper is to develop an intelligent robot assembly system using multi-modal vision for next-generation industrial assembly. The system includes two phases where in the first phase human beings demonstrate assembly to robots and in the second phase robots detect objects, plan grasps, and assemble objects following human demonstration using AI searching. A notorious difficulty to implement such a system is the bad precision of 3D visual detection. This paper presents multi-modal approaches to overcome the difficulty: It uses AR markers in the teaching phase to detect human operation, and uses point clouds and geometric constraints in the robot execution phase to avoid unexpected occlusion and noises. The paper presents several experiments to examine the precision and correctness of the approaches. It demonstrates the applicability of the approaches by integrating them with graph model-based motion planning, and by executing the results on industrial robots in real-world scenarios.	cognitive robotics;correctness (computer science);experiment;industrial robot;modal logic;motion planning;nvidia 3d vision;point cloud	Weiwei Wan;Feng Lu;Zepei Wu;Kensuke Harada	2017	Neurocomputing	10.1016/j.neucom.2017.01.077	computer vision;simulation;artificial intelligence;machine learning	Robotics	59.46155204950424	-34.42171496641115	74129
0fa11e7903cb7d084fcc27816090b0edf8ba1194	range and pose estimation for visual servoing of a mobile robot	vision system;real time visualization;mobile robot;behaviour based control pose estimation range estimation visual servoing mobile robots real time systems multiple robot cleaning system cooperative systems feature tracking robot vision 3d projective model;real time;feature tracking;multi robot system;motion estimation;mobile robots;servomechanisms mobile robots robot vision cooperative systems motion estimation position control optical tracking real time systems;autonomous mobile robot;visual servoing mobile robots cleaning machine vision multirobot systems laboratories cooperative systems robustness centralized control robot sensing systems;robot vision;cooperative systems;optical tracking;position control;servomechanisms;field of view;system development;visual tracking;visual servoing;real time systems;pose estimation	This paper describes the implementation of behaviour for real-time visual servoing on a mobile robot. The behaviour is a component of a multi -robot cleaning system developed in the context of our investigation into architectures for cooperative systems. An important feature for support of cooperation is the awareness of one robot by another, which this behaviour realises. Robust feature tracking aided by a hardware vision system is described. This forms the basis for range and pose estimation using a 3D projective model.	3d pose estimation;consensus dynamics;course (navigation);mobile robot;motion estimation;plasma cleaning;real-time clock;real-time computing;visual servoing	David Jung;Jochen Heinzmann;Alexander Zelinsky	1998		10.1109/ROBOT.1998.677266	control engineering;mobile robot;computer vision;simulation;machine vision;computer science;visual servoing	Robotics	59.83898975604074	-31.555356669211694	74473
1baf88ca5c3590caaad4b4bf3515027d3da9b7da	an overview of robot calibration	contraste;control systems;application software;adaptive control;transducers;kinematics;robot industriel;mechanical engineering;robot control;robots;robot industrial;calibration transducers kinematics end effectors mechanical engineering robotics and automation application software robot control control systems adaptive control;etalonnage;calibration;robotics and automation;robots calibration;end effectors;industrial robot	An overview is given of the existing work on robot calibration, and some of the basic issues are identified in calibration and improvement of robot precision. Modeling, measurement, identification, and correction issues in robot calibration are discussed, and some of the unresolved questions are identified.	robot calibration	Zvi S. Roth;Benjamin W. Mooring;Bahram Ravani	1987	IEEE Journal on Robotics and Automation	10.1109/JRA.1987.1087124	robot;control engineering;kinematics;robot end effector;application software;calibration;simulation;transducer;adaptive control;computer science;engineering;control system;artificial intelligence;control theory;robot control;robot calibration	Robotics	62.95635261848976	-32.340923525668714	74541
a02c1b55ab3daa63d1b4cb5c42241a249086c29f	operating multiple semi-autonomous ugvs: navigation, strategies, and instantaneous performance	ugv;unmanned ground vehicle;multi robot system;autonomy;route selection;multi robot systems;cse;manned unmanned teaming;field study	There is an interest in using multiple unmanned ground vehicles (UGV). The Swedish Army Combat School has evaluated an UGV called SNOOKEN II in a number of field studies. To investigate the possibility to handle multiple vehicles in a simulated setting was set up where the operator simultaneous managed one, two, or three UGVs with limited autonomy. The task was to navigate the UGVs to designated inspection points as fast as possible. The results showed that more inspections were made with multiple UGVs (p 0.05). Analysis of use of autonomous mode, route selection, and interviews also show that the subject managed to operate two vehicles with increased performance but that a third vehicle does not provide any extra benefits.	autonomous robot;semiconductor industry	Patrik Lif;Johan Hedström;Peter Svenmarck	2007		10.1007/978-3-540-73331-7_80	embedded system;simulation;engineering;transport engineering	Robotics	56.52991762256848	-27.867504438978894	74800
ee3bfa34d780d4c48f5b77d0f12dde8d9dd36670	decentralized motion coordination for a formation of rovers	navigation intrusion detection robot kinematics communication system control motion control intelligent robots switches motion analysis control systems broadcasting;collision free coordination;individual agent identity;multi agent formation;motion control;formation control;decentralized motion coordination;turning;rover formation;path planning;computer model;environmental conditions;navigation technique;system of systems;system of systems mobile robot navigation multi agent formation path planning robotic swarm;mobile robots;robotic swarm;data mining;position control collision avoidance decentralised control mobile robots motion control multi robot systems;obstacle avoidance decentralized motion coordination rover formation decentralized formation control collision free coordination collision free navigation multiagent individual agent identity navigation technique computational model;navigation;decentralised control;obstacle avoidance;shape;position control;decentralized formation control;collision free navigation;mobile robot navigation;multiagent;multi robot systems;motion coordination;angular velocity;collision avoidance;computational model;real time application;robot kinematics	In this paper, a decentralized formation control is proposed which enables collision free coordination and navigation of agents. We present a simple method to define the formation of multi-agents and individual identities (IDs) of agents. Two decentralized coordination and navigation techniques are proposed for the formation of rovers. Agents decide their own behaviors onboard depending upon the motion initiative of the master agent of the formation. In these approaches, any agent can estimate behavior of other agents in the formation. These will reduce the dependency of individual agent on other agents while taking decisions. These approaches reduce the communication burden on the formation where only the master agent broadcasts its motion status per sampled time. Any front agent can act as a master agent without affecting the formation in case of fault in initial master agent. The main idea of this paper is to develop an adequate computational model under which agents in the formation will perform to coordinate among each other. Assignments of IDs to agents are very useful in real-time applications. These proposed schemes are suitable for obstacle avoidance in unknown environment as a whole formation. Agents are free from collision among each other during navigation. These schemes can be used for velocity as well as orientation alignment problems for a multi-agent rover network. These schemes are tested with extensive simulations and responses of agents show satisfactory performances to deal with different environmental conditions.	aerial photography;angularjs;computation;computational model;consensus dynamics;multi-agent system;obstacle avoidance;performance;real-time clock;real-time computing;rover (the prisoner);run time (program lifecycle phase);sonar (symantec);sales outsourcing;simulation;unmanned aerial vehicle;velocity (software development)	Anjan Kumar Ray;Patrick Benavidez;Laxmidhar Behera;Mo M. Jamshidi	2009	IEEE Systems Journal	10.1109/JSYST.2009.2031012	computer simulation;control engineering;motion control;mobile robot;computer vision;navigation;simulation;system of systems;angular velocity;shape;computer science;engineering;artificial intelligence;motion planning;obstacle avoidance;computational model;mobile robot navigation;robot kinematics	AI	57.76690747207798	-24.18399797869474	74941
44b177ee21c66b61daf8ddad2c8f0a7aaab88f25	mechatronic design of the twente humanoid head	vision system;human like behavior;motion control;saliency based vision system;degree of freedom;two degree of freedom;humanoid head;control architecture;focus of attention;vision based motion control;long range;facial expression;target tracking;mechatronic design;human machine interaction	This paper describes the mechatronic design of the Twente humanoid head, which has been realized in the purpose of having a research platform for human-machine interaction. The design features a fast, four degree of freedom neck, with long range of motion, and a vision system with three degrees of freedom, mimicking the eyes. To achieve fast target tracking, two degrees of freedom in the neck are combined in a differential drive, resulting in a low moving mass and the possibility to use powerful actuators. The performance of the neck has been optimized by minimizing backlash in the mechanisms, and using gravity compensation. The vision system is based on a saliency algorithm that uses the camera images to determine where the humanoid head should look at, i.e. the focus of attention computed according to biological studies. The motion control algorithm receives, as input, the output of the vision algorithm and controls the humanoid head to focus on and follow the target point. The R. Reilink (B) · L. C. Visser · R. Carloni · S. Stramigioli Department of Electrical Engineering, Faculty of Electrical Engineering, Mathematics and Computer Science, University of Twente, Enschede, The Netherlands e-mail: r.reilink@utwente.nl L. C. Visser e-mail: l.c.visser@utwente.nl R. Carloni e-mail: r.carloni@utwente.nl S. Stramigioli e-mail: s.stramigioli@utwente.nl D. M. Brouwer Department of Mechanical Automation and Mechatronics, Faculty of Engineering Technology, University of Twente, Enschede, The Netherlands e-mail: d.m.brouwer@utwente.nl D. M. Brouwer DEMCON Advanced Mechatronics, Oldenzaal, The Netherlands control architecture exploits the redundancy of the system to show human-like motions while looking at a target. The head has a translucent plastic cover, onto which an internal LED system projects the mouth and the eyebrows, realizing human-like facial expressions.	algorithm;automation;brouwer fixed-point theorem;computer science;electrical engineering;email;human–computer interaction;image plane;kernel (linear algebra);mechatronics;motion compensation;normal mode	Rob Reilink;Ludo C. Visser;Dannis Michel Brouwer;Raffaella Carloni;Stefano Stramigioli	2011	Intelligent Service Robotics	10.1007/s11370-010-0077-0	motion control;computer vision;simulation;machine vision;computer science;humanoid robot;degrees of freedom;facial expression	Robotics	66.84638077246316	-29.951020096601148	74971
31ff586e4b18704fbea4818f1c01f3488b2947a4	pvs: a system for large scale outdoor perception performance evaluation	databases;robot sensing systems;obstacle detection;performance evaluation;measurement;autonomous vehicle;vehicles databases testing robot sensing systems measurement global positioning system;false negative;global position system;visual perception mobile robots numerical analysis object detection relational databases;mobile robots;testing;relational database;large scale;numerical analysis;design and implementation;global positioning system;visual perception;ground truth;relational databases;numerical estimation pvs outdoor perception performance evaluation perception validation system obstacle detection system relational database;vehicles;false positive;object detection	This paper describes the motivation, design and implementation of a Perception Validation System (PVS), a system for measuring the outdoor perception performance of an autonomous vehicle. The PVS relies on using large amounts of real world data and ground truth information to quantify performance aspects such as the rate of false positive or false negative detections of an obstacle detection system. Our system relies on a relational database infrastructure to achieve a high degree of flexibility in the type of analyses it can support.	algorithm;autonomous robot;experiment;ground truth;hoare logic;iteration;mathematical optimization;mobile robot;performance evaluation;postgresql;regression testing;relational database;repeatability;robotics;sensor	Cristian Dima;Carl Wellington;Stewart J. Moorehead;Levi Lister;Joan Campoy;Carlos Vallespí;Boyoon Jung;Michio Kise;Zachary Bonefas	2011	2011 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2011.5980419	computer vision;simulation;relational database;computer science;computer security	Robotics	54.04303278322557	-35.54667532229972	75255
b69ef7cb91799b31ad907fb3bb181d1331396642	system design and control of a sail-based autonomous surface vehicle	torque;sensors;actuators;force;propulsion;wind;boats	Ocean exploration has attracted enormous interest from human-kind for thousands of years. The sailing boat, propelled by wind is a historical invention. But human-involved marine exploration has high risk and low efficiency. This paper presents a new autonomous surface vehicle (ASV) based on retrofitting a trimaran sailing boat. The previous human-based maneuvering interfaces, i.e. sail and rudder control, are motorized by three electric actuators. The ASV acquires signals of wind speed and direction, GPS position, and rolling angle, determine the heading based on various wind direction. Experiments validates the effectiveness of the ASV.	autonomous car;autonomous robot;course (navigation);experiment;global positioning system;rudder	Tin Lun Lam;Huihuan Qian;Zhifeng Wang;Hongjie Chen;Yu Li;Yangsheng Xu	2016	2016 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2016.7866461	simulation;propulsion;engineering;sensor;aeronautics;marine engineering;torque;force;wind;actuator	Robotics	59.96569998345213	-26.795561383226648	75273
2758b7e562106de65d8eacc5888ea06288e467ce	uav circumnavigating an unknown target under a gps-denied environment with range-only measurements	sliding mode estimator;uav;computacion informatica;grupo de excelencia;autonomy;joint estimation and control;ciencias basicas y experimentales;gps denied environment	One typical application of unmanned aerial vehicles is the intelligence, surveillance, and reconnaissance mission, where the objective is to improve situation awareness through information acquisition. For examples, an efficient way to gather information regarding a target is to deploy UAV in such a way that it orbits around this target at a desired distance. Such a UAV motion is called circumnavigation. The objective of the paper is to design a UAV control algorithm such that this circumnavigation mission is achieved under a GPS-denied environment using range-only measurement. The control algorithm is constructed in two steps. The first step is to design a UAV control algorithm by assuming the availability of both range and range rate measurements, where the associated control input is always bounded. The second step is to further eliminate the use of range rate measurement by using an estimated range rate, obtained via a sliding-mode estimator using range measurement, to replace actual range rate measurement. Such a controller design technique is applicable in the control design of other UAV navigation and control missions under a GPS-denied environment.	aerial photography;algorithm;brian;global positioning system;unmanned aerial vehicle	Yongcan Cao	2015	Automatica	10.1016/j.automatica.2015.03.007	control engineering;simulation;engineering;control theory;autonomy	Robotics	57.5353871818721	-26.480994884638523	75299
baa590c5eb47cf47b80a771b00a3b4dd9abcce02	wireless camera nodes on a cyber-physical system	communication channel;real time detection;trajectory control loop;cyber physical system	This paper describes the configuration of a networked control system with multiple distributed cameras as edge nodes of a cyber-physical system. The proposed architecture deploys multiple distributed on computer vision edge nodes capturing the motion of mobile robots to interact with people on the environment. The camera nodes, network devices and mobile robots are considered part of the same control loop. Our approach provides a flexible scalable architecture that balances accuracy and reliability of the cyber-physical system, taking advantage of video processing on intermediate networked nodes and providing new functions and capabilities with minor changes. Main contribution of this paper is to configure the computer vision nodes considering the networked control loop with an adjustable sampling period to achieve the desired performance controlling the trajectory of multiple robots. Different tests have been done on a smart space as an end application framework.	application framework;computer vision;control system;cyber-physical system;mobile robot;sampling (signal processing);scalability;video processing	Alfredo Gardel Vicente;Felipe Espinosa;Rubén Nieto;José Luis Lázaro;Ignacio Bravo Muñoz	2016		10.1145/2967413.2967423	control engineering;embedded system;real-time computing;networked control system;engineering	Robotics	56.63370014905492	-34.40114380696714	75672
317e08ada278aff3ffe132ff6ef8b2862098d743	measuring human factors in port activities by using simulation	electro medical devices for performance and fatigue assessment;degree of freedom;technological development;hla federation;human factors;medical device;exponential growth;ship to shore gantry crane simulator;applied research;6 dof motion platform;physical simulation	This paper describes the Cagliari University portanier cranes simulator, an idea born with the goal to reduce mistakes of the quay crane operator, whose operations are virtually reproduced by the physical simulation model. The quay crane operator is even more under stress due to the growing number of functionalities of the new generations of portanier cranes and to the fact that the personnel is requested with a deeper and deeper level of specialization to operate in the maritime via container transportation, a sector that is living an exponential growth in the last years.  The paper will introduce the main simulator components: shelter installation with a 6 degrees of freedom motion platform, for a higher immersive performance to improve training but also to develop a base and applied research, whose goal is to analyze operator performance, by electro medical devices. By the use of the Cagliari simulator (in training, r&d and technological development) we have the goal to reduce accidents, that are usually due to fatigue.	dynamical simulation;human factors and ergonomics;immersion (virtual reality);motion simulator;partial template specialization;time complexity	Agostino G. Bruzzone;Paolo Fadda;Gianfranco Fancello;Alberto Tremori;Enrico Bocca;Gianmarco D'Errico	2009			exponential growth;simulation;computer science;engineering;artificial intelligence;human factors and ergonomics;degrees of freedom;management;computer security;algorithm;mechanical engineering	Robotics	63.32725399161667	-29.114336596121127	75776
98c0ce74e6891945487204a0c44162ec3bc6210a	learning robust policies for object manipulation with robot swarms		Swarm robotics investigates how a large population of robots with simple actuation and limited sensors can collectively solve complex tasks. One particular interesting application with robot swarms is autonomous object assembly. Such tasks have been solved successfully with robot swarms that are controlled by a human operator using a light source. In this paper, we present a method to solve such assembly tasks autonomously based on policy search methods. We split the assembly process in two subtasks: generating a high-level assembly plan and learning a low-level object movement policy. The assembly policy plans the trajectories for each object and the object movement policy controls the trajectory execution. Learning the object movement policy is challenging as it depends on the complex state of the swarm which consists of an individual state for each agent. To approach this problem, we introduce a representation of the swarm which is based on Hilbert space embeddings of distributions. This representation is invariant to the number of agents in the swarm as well as to the allocation of an agent to its position in the swarm. These invariances make the learned policy robust to changes in the swarm and also reduce the search space for the policy search method significantly. We show that the resulting system is able to solve assembly tasks with varying object shapes in multiple simulation scenarios and evaluate the robustness of our representation to changes in the swarm size. Furthermore, we demonstrate that the policies learned in simulation are robust enough to be transferred to real robots.	autonomous robot;high- and low-level;hilbert space;motion planning;sensor;simulation;swarm robotics	Gregor H. W. Gebhardt;Kevin Daun;Marius Schnaubelt;Gerhard Neumann	2018	2018 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2018.8463215	robustness (computer science);swarm behaviour;control engineering;operator (computer programming);kernel (linear algebra);engineering;robot;swarm robotics;population;trajectory;artificial intelligence	Robotics	61.03767264974518	-24.38425467644157	75870
dd92d2ffdec1fe206cf9263e4314303d2ebf50b7	what is a breakthrough toward human robotics?	human movement;robot hand;degree of freedom;inverse kinematics;central nervous system;everyday life	"""What is a decisive difference between a mechanical hand and our human hand? The robot hand can not be a versatile tool, even if it is made to resemble a human hand exactly in shape and mechanism. Even at the present age of robotics, it is too clumsy to perform a variety of ordinary tasks that a human encounters in his or her everyday life. In this talk, I claim that the clumsiness manifests the lack of knowledge of everyday physics and as well the lack of scheme for designing an artificial CNS (Central Nervous System) for the robot so as to cope with its sophisticated interplays with environments of everyday tasks. Here, the term """"everyday physics"""" is used as a scientific domain related to accountability of dexterous accomplishment of ordinary tasks through manipulating things, with or without sensing and with or without consciousness as seen in ordinary human life. Here, design of an artificial CNS should be a domain of science and engineering that should be called """"human robotics"""". It should be a core of robotics that attempts to unveil secrets of human intelligent behaviors from perception to action and vice versa. Actually, a half century ago N. A. Bernstein was enthusiastic in perceiving the mysteries of dexterity of human movements with redundant Degrees-of-Freedom regardless of illposedness of inverse kinematics. Our multifingered hand must be a wonderful organ with redundant joints that exhibits the mysteries of dexterity and versatility but still hides a secret of how adequately the central nervous system evokes neuro-motor signals. This talk discusses on what must be a breakthrough toward """"human robotics"""" through illustrating two simple but mysterious (unsolved) problems: 1) multi-joint point-to-point reaching movements with redundant DOFs and 2) 3-Dimensional stable grasping and object manipulation by a multifingered hand with redundant joints. The importance of incorporative approach of robotics and brain science is emphasized throughout the talk. Biography: Professor Suguru Arimoto was born on 3 August 1936 in Hiroshima, Japan. He l. received B.S. degree in mathematics from Kyoto University, Japan, in 1959 and *............I......I.....,.................... iiiiiiiiilllliill lll ll II I LDr. Eng. Degree in control engineering from the University of Tokyo, Japan, in | 4 ~~197. From 1959 to 1961 he was with Oki Electric Industry Co. Ltd., Tokyo, as l I111111111111111an engineer in Electric Computer Department. From 1962 to 1967 he was W ~~esearch Assistant, and from 1967 to 1968 Lecturer in the Department of Mathematical Engineering and Information Physics, the University of Tokyo. In 1968 he jointed the Faculty of Engineering Science at Osaka University, Osaka, Japan, as Associate Professor, and in 1973 he was promoted as Professor of Systems Engineering. In 1988 he was invited to join the University of Tokyo as Professor of the Department of Mathematical Engineering and Information Physics. In 1997 he retired from the University of Tokyo and moved to Ritsumeikan University, where he contributed to establishment of a new department. Since 1997 he has been Professor in the Department of Robotics. His research interests are in information theory, control theory, cybernetics, robotics, and machine intelligence. In recent years, he is anxious to unveil secrets of dexterity of human movements from the standpoint of robotics. He is IEEE Fellow (1983), JEICE Fellow (2000), RSJ Fellow (2003), and JSME Fellow (2005), and was awarded the Royal Medal with a Purple Ribbon from the Japanese Government in 2000, and the IEEE 3rd Millennium Medal from the IEEE in 2000, and the IEEE Robotics and Automation Society Pioneer Award in 2006."""	artificial intelligence;automation;cns;cognitive science;consciousness;control engineering;control theory;cybernetics;human-based computation;human–computer interaction;information theory;inverse kinematics;java platform, micro edition;open knowledge initiative;phil bernstein;physical information;point-to-point protocol;robot;robotics;systems engineering	Suguru Arimoto	2006		10.1109/IROS.2006.282196	computer vision;simulation;computer science;engineering;artificial intelligence;central nervous system;inverse kinematics;degrees of freedom	Robotics	67.31536225129535	-27.81075961989516	75980
824e14b11d5a247beb21e29708039d10b82b8243	fuzzy navigation for robotic manipulators	robot manipulator;fuzzy logic;navigation;obstacle avoidance;robotic manipulators	This paper describes a novel navigation and obstacle avoidance system for robotic manipulators. The system is divided into separate fuzzy units which individually control the links of a manipulator. The rule base of each unit combines the repelling influence of obstacles with the attracting influence of the target position in a fuzzy way to generate actuating commands for the link. Owing to its simplicity and hence its short response time, the fuzzy navigator is especially suitable in on-line applications with strong real-time requirements. Furthermore, this approach allows obstacle avoidance in dynamic environments. The functioning of the fuzzy navigator with respect to robotic manipulators and results of real-world experiments are presented.		Kaspar Althoefer;Lakmal D. Seneviratne;P. Zavlangas;Bart Krekelberg	1998	International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems	10.1142/S0218488598000161	fuzzy logic;navigation;simulation;computer science;artificial intelligence;control theory;obstacle avoidance	Robotics	59.38532688395773	-27.84291244289486	76374
e6a9abad2def95e729f4ec431ca2c11b15af2a9c	adapted wavelet analysis from theory to software (mladen victor wickerhauser)	wavelet analysis		wavelet	Charles K. Chui	1996	SIAM Review	10.1137/1038018	wavelet;mathematics;algorithm;statistics	SE	67.5806236989874	-35.43233946075954	76462
7376143f3f8ccd95d276814b73595fc72bf28454	cooperative transportation by swarm robots using pheromone communication		Ants communicate with each other using pheromones, and their society is highly sophisticated. When foraging, they transport cooperatively with interplay of forces. The swarm is robust against changes in internal state, and shows flexibility in dealing with external problems. In this brief paper, we focus on the robot swarm that achieves cooperative transportation making use of ethanol as a substantial artificial pheromone.We also propose a swarm system with a newly developed algorithm that enables cooperative transportation of real robots. They will transport food to the nest analogous to the behaviour of a swarm of ants. Emphasis will be placed on the systematic task solution process.We present a number of experiments demonstrating the robustness and flexibility of the system and also confirming the effectiveness of the algorithm.	robot;swarm robotics	Ryusuke Fujisawa;Hikaru Imamura;Fumitoshi Matsuno	2010		10.1007/978-3-642-32723-0_40	swarm robotics;ant robotics;communication	Robotics	59.11341627498488	-25.260121211900255	76465
58e771fc9c298d4bf82e9aace17e8c45d04e2537	some considerations concerning the influence of the inertial sensors errors on the solution of navigation for a bidimensional strap-down inertial navigation system	gyros sensors;gyroscopes;errors;sensor systems;bidimensional strap down inertial navigation system;sensors;helium;inertial navigation;inertial navigation accelerometers aerospace instrumentation gyroscopes;acceleration;navigation;inertial sensors errors;motion planning;mathematical model;gyros sensors inertial sensors errors bidimensional strap down inertial navigation system mathematical model accelerometers;accelerometer;errors inertial navigation gyro accelerometer;sensor systems inertial navigation vehicles equations mathematical model accelerometers motion planning acceleration numerical simulation helium;vehicles;accelerometers;inertial sensor;aerospace instrumentation;inertial navigation system;numerical simulation;gyro	The paper is a study of the errors induced by the inertial sensors in a bidimensional horizontal navigator. In the first stage, the basic equations of the navigator and the navigation solution are presented. Starting from the navigator mathematical model it is realized an error model for this, a model which considers the errors of the used inertial sensors. It is realized the numerical simulation and the validation of the navigator error model using error models for the accelerometers and gyros sensors implemented in Matlab/Simulink. Also, the navigation errors produced by the different categories of errors which affect the inertial sensors are evaluated.	computer simulation;inertial navigation system;matlab;mathematical model;numerical analysis;sensor;simulink	Teodor Lucian Grigorie	2008	2008 5th Workshop on Positioning, Navigation and Communication	10.1109/WPNC.2008.4510369	computer simulation;control engineering;inertial reference unit;simulation;geodesy;computer science;engineering;inertial navigation system;accelerometer	Robotics	57.73296617073268	-35.500182587997614	76493
9fe47cf18b8486290c12f6a6de4047520c7e9b88	use of active scope camera in the kumamoto earthquake to investigate collapsed houses		The Kumamoto Earthquake occurred in April 2016. We conducted an investigation using the active scope camera to examine the interiors of the collapsed houses. The robot video scope can move by itself to probe narrow gaps. We could safely gather information by inserting it inside houses. We further considered the future possible improvements to the robot based on the investigation. We also determined the constraints to be considered for the robot operation in disaster areas. In addition, we created a test field imitating the features of collapsed houses. We used this field to evaluate our robot mobility and related technologies that are being developed for future applications.	earthquake network;robot;ti advanced scientific computer	Yuichi Ambe;Tomonari Yamamoto;Shotaro Kojima;Eri Takane;Kenjiro Tadakuma;Masashi Konyo;Satoshi Tadokoro	2016	2016 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)	10.1109/SSRR.2016.7784272	simulation;engineering;civil engineering;cartography	Robotics	57.127213053342565	-31.160508234783812	76529
13191219470934edf94449193fb0b66511f67246	a remotely controlled out-pipe climbing robot	manipulators;motion control;service robots;mobile robots;robot sensing systems inspection climbing robots wheels;inspection;branch climbing maneuver remotely controlled out pipe climbing robot nuclear power plant pipe petrochemical complex pipes moving modules connecting arm maneuver pipeline surface obstacle climbing performance module robot vertical pipe segment rotating maneuver circumferential out pipe surface inspection;telecontrol;collision avoidance;pipes;pipe climbing out pipe robot wheel based climbing;telecontrol collision avoidance inspection manipulators mobile robots motion control pipes service robots	In this paper, a concept, design, modeling and prototype of a remotely controlled out-pipe climbing robot for inspection such as nuclear power plant pipe and petrochemical complex pipes are discussed. The robot consists of two moving modules and one connecting arm which can alternatively maneuver on the pipeline surface. This mechanism is a good solution for pipe climbing and obstacle. After discussing conceptions of the mechanism, modeling and some practical aspects of the detailed design are presented. Attached video shows the climbing performance of the two module robot on a 6-inch vertical pipe segment, the rotating maneuver for circumferential out-pipe surface inspection, and the branch climbing maneuver by two module cooperation.	prototype;remote control;robot;vertical bar	Sangchul Han;Jaekyu An;Hyungpil Moon	2013	2013 10th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2013.6677490	motion control;mobile robot;simulation;inspection;computer science;artificial intelligence;robot control	Robotics	64.6224085706933	-28.121571788279418	77076
d71ab9bae2d4ada71889453b3c2f303a178206e2	attitude estimation for small helicopter using extended kalman filter	mini helicopter;sensor phenomena and characterization;mini helicopter attitude estimation extended kalman filter;unmanned aerial vehicle;magnetic sensors;kalman filters;kalman filter;image sensors;military aircraft;low noise;micromechanical devices;estimation;global positioning system;position measurement;mathematical model;vertical take off and landing;attitude estimation;extended kalman filter;unmanned aerial vehicles;helicopters aircraft navigation position measurement unmanned aerial vehicles image sensors sensor phenomena and characterization micromechanical devices magnetic sensors global positioning system military aircraft;helicopters;quaternions;aircraft navigation	Accurate attitude estimation is vital for VTOL UAV (vertical take-off and landing unmanned aerial vehicle) systems, including small helicopter. The main focus of present research is to compile the principles of navigation and Kalman filtering, and their application and implementation towards UAV systems. This paper introduces a method based on EKF (Extended Kalman filter) to estimate small helicopter?s attitude with little drift and low noise, which uses strapdown attitude as state update, and treats the attitude estimated by the bi-vector method as measurement update. By evaluating the EKF method with small helicopter's real ground and flight sensor data, it shows good performance: stable, small error. So it is suitable for small helicopter attitude estimation application.	extended kalman filter	Yongliang Wu;Tianmiao Wang;Jianhong Liang;Chaolei Wang	2008		10.1109/RAMECH.2008.4690879	kalman filter;control engineering;aerospace engineering;engineering;aeronautics;control theory;statistics	Robotics	56.42784871990887	-34.20261368345999	77124
28a296e34fd9332be47c71ea09cd939ee095ce04	a genetic programming formulation to evade proportional navigation	force directed scheduling;genetic program;high level synthesis;scheduling	Genetic Programming evolves a manoeuvre plan for a single evader with constant velocity and a single pursuer employing proportional navigation with lag in a planar region. During evolution GP was required to discover the most effective evasion strategy which generalized across multiple training scenarios, i.e. different initial pursuer positions. GP was trained to evade interception for each of the multiple scenarios by controlling the evader's turn rate throughout pursuit.	evasion (network security);genetic programming;velocity (software development)	Daniel Howard	2005		10.1145/1167253.1167301	control engineering;simulation;engineering;control theory	ML	54.9306705012665	-25.20962726281281	77182
24cdfaeca726c56af5bc37a3931957ee152ccff7	an explorative study of visual servo control with insect-inspired reichardt-model	closed loop system;visual servo control;motion detector;detectors;velocity control;motion control;closed loop systems;end effector visual servo control insect inspired reichardt model motion detector stability time delay visual servoing velocity control closed loop system 1 dof linear motor module feedback gain;delay effects;time delay;stability;visualization;feedback;robot vision;servosystems velocity control stability delay effects motion detection detectors feedback visual servoing performance gain testing;servomechanisms;end effector;insect inspired reichardt model;1 dof linear motor module;visual servoing biomimetics closed loop systems delays end effectors feedback motion control robot vision servomechanisms stability velocity control;linear motor;visual servoing;feedback gain;cameras;delays;end effectors;biomimetics;servosystems	In this paper, an insect-inspired motion detector (Reichardt-model) is applied to visual servo control to ensure the stability of the system with high gain and time delay in its feedback. A Reichardt-based control scheme is compared with a conventional visual servoing approach. As a consequence of the specific velocity dependence of the Reichardt-model, the stability margin of the visual servo control is increased and high overall gains, thus, better performance are achievable. The response of the Reichardt-model in the experiment and the control performance of velocity control approach with the Reichardt-model in the closed loop are investigated. The velocity control model is tested on a 1-DOF linear motor module with different feedback gain and different time delay in the loop. The results of simulation and realtime experiments demonstrate the stabilizing character of the Reichardt-based approach.	broadcast delay;control system;control theory;experiment;feedback;limit cycle;motion detector;nonlinear system;performance;phase margin;real-time clock;servo;simulation;velocity (software development);vii;visual servoing	Haiyan Wu;Tianguang Zhang;Alexander Borst;Kolja Kühnlenz;Martin Buss	2009	2009 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2009.5152462	control engineering;computer vision;robot end effector;computer science;engineering;artificial intelligence;control theory	Robotics	60.942585987132496	-31.676034341676576	77258
04b284760b94926c8f531b0ce07d228f95dce4bf	motion synthesis for the self-reconfiguring molecule	rotations;molecule robot motion specification language;robot kinematics bonding legged locomotion stacking shape aggregates connectors computer science educational institutions motion planning;legged locomotion;language expression synthesis motion synthesis self reconfiguring molecule robot geometric approach molecule robot motion specification language global translations rotations molecular structure stacking;computational geometry;formal languages;motion synthesis;self reconfiguring molecule robot;language expression synthesis;molecular structure stacking;geometric approach;connectors;bonding;shape;stacking;computational complexity;aggregates;robots;motion planning;computer science;computational complexity robots formal languages computational geometry;global translations;robot kinematics;molecular structure	In this paper we present a geometric approach to specifying and planning the motion of robotic Molecules on a substrate of Molecules in O(n) time, where n is the number of Molecules in the substrate. We describe a language for specifying the Molecule motion. We give algorithms for performing global translations, rotations, and stacking of Molecular structures. We show that these motions are sufficient to guarantee certain classes of motion for Molecular structures. We also examine a geometric approach to synthesizing language expressions for moving a Molecule on a substrate of other Molecules.	algorithm;focus stacking;self-reconfiguring modular robot	Keith Kotay;Daniela Rus	1998		10.1109/IROS.1998.727304	robot;formal language;simulation;molecule;computational geometry;rotation;shape;computer science;artificial intelligence;theoretical computer science;stacking;motion planning;computational complexity theory;robot kinematics	Robotics	65.20971526180405	-26.23311499304689	77336
20829eda75823cdd66618c11308b4cd15ab93b8c	turbojet engine for aerial cargo robot (acr)	cargo uav;silent turbojet engine;aerial robot;aerial cargo robot acr		aerial photography;robot	Kakuya Iwata;Koji Matsubara;Kazumasa Kawasaki;Osamu Matsumoto	2012	JRM	10.20965/jrm.2012.p1040	engineering;aeronautics;automotive engineering;marine engineering	Robotics	60.197814107571524	-26.691141080038918	77433
7e382098d75dcaa7aef699b74ba5af74ec52b298	study on attitude measurement system for virtual surgery navigation	contraste;modelizacion;navegacion;elipsoide;error medida;ajustamiento modelo;consensus;teleenseignement;auto calibracion;measurement error;magnetic field;selfcalibration;autoetalonnage;random sampling;measurement system;divertissement;iron;virtual surgery;erreur mesure;ajustement modele;modelisation;navigation;ellipsoide;consenso;model matching;muestreo aleatorio;chirurgie;surgery;cirugia;etalonnage;teleensenanza;actitud;remote teaching;ellipsoid;echantillonnage aleatoire;modeling;attitude;entertainment;calibration	A source-less attitude measurement system and robust heading self-calibration method for virtual surgery navigation is presented. The proposed system includes three accelerometers and three magnetometers to measure the gravity field and the geomagnetic filed to calculate the attitude. During the heading calibration procedure, both the magnetic field and gravity field are measured in all three axes with a set of combinations of attitudes. The set of measurements of magnetometer triad are first selected by random sampling consensus (RANSAC), and then are used to fit an ellipsoid to remove the hard iron error, finally the measurements of the magnetometer triad without the hard iron error and the measurements of accelerometer triad are rearranged to a set of equations to solve the soft iron matrix. Compared with other existing calibration method, the proposed calibration method does not require heading reference. Experimental results show the effectiveness of the proposed method and its potential application in virtual surgery navigation.		Xiaoming Hu;Yue Liu;Yongtian Wang	2006		10.1007/11736639_156	attitude;navigation;entertainment;calibration;simulation;consensus;magnetic field;advertising;iron;attitude and heading reference system	Robotics	59.58294128598464	-35.918559105411845	77519
a54067fdfd135434fd2c5fe71ea19e6123f23b2b	motion planning for actively reconfigurable mobile robots in search and rescue scenarios	hazardous areas;path planning;service robots;actuators;mobile robots;stability;stability actuators disasters emergency services hazardous areas mobile robots path planning search problems service robots;search problems;robot traction actively reconfigurable mobile robots search and rescue scenarios disaster scenarios hazardous environments human rescuers rescue personnel inaccessible areas tracked platforms actuators robotic system navigation complex disaster environments autonomous navigation two phase motion planning algorithm platform operating limits terrain roughness search space robot stability;actuators autonomy motion planning rough terrain reconfigurable chassis mobile robot;disasters;emergency services	In disaster scenarios, mobile robots can be employed in hazardous environments where it is too dangerous for human rescuers. Robotic systems can assist rescue personnel as they can be used to explore those inaccessible areas and to assess the situation. Tracked platforms with actuators have been proven to be well suited for such deployments because they are agile enough to overcome quite challenging terrain. A very demanding task for operators is the navigation of the robotic system in complex disaster environments. Hence, an important capability of future systems for search and rescue missions is autonomous navigation in disaster scenarios. In this paper we introduce a two-phase motion planning algorithm for tracked robots with actively controlled actuators to find a fast and stable path to a user specified goal. In the first phase, we generate an initial path considering the platform's operating limits and the terrain roughness. In the second phase, we limit the search space to the area around the initial path and refine the preliminary solution accounting for the complete robot state including actuators and the robot's stability and traction. A main distinction of our method is that it does not rely on a previous classification of the terrain, thus, can be applied to a variety of environments. We present experiments evaluating our algorithm in simulation and in two real-world scenarios to demonstrate the validity and feasibility of our approach.	agile software development;algorithm;automated planning and scheduling;autonomous robot;experiment;mobile robot;motion planning;sampling (signal processing);simulation;smart environment;state space;traction teampage;two-phase commit protocol	Michael Brunner;Bernd Brüggemann;Dirk Schulz	2012	2012 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)	10.1109/SSRR.2012.6523896	control engineering;mobile robot;computer vision;simulation;rescue robot;engineering;robot control	Robotics	55.7759815781406	-27.538214805885136	77771
afb864605b58499534102b38379ca80984bce922	development of ground experiment system for space robot performing fine manipulation	force sensors;intelligent control;dexterous manipulators;position control aerospace robotics dexterous manipulators force control force sensors intelligent control;ground experiment space robot fine manipulation compliance control;position control;aerospace robotics;dexterous manipulation technology space robot fine manipulation technology space technology satellite service satellite construction satellite maintenance planning algorithm control algorithm mathematical model physical model industrial robot hand eye visual equipment force momentum sensor guide rail compliance control impedance control hybrid force position control intelligent control compliance control strategy;aerospace electronics joints space vehicles force robot kinematics service robots;force control	Robotic systems are expected to play an increasingly important role in future space activities with the development of space technology. One broad area of application is in the servicing, construction, and maintenance of satellites and large space structures in orbit. Fine manipulation technology is very important for space robot to perform there tasks, since it must ensure safe and reliable interaction with objects or environment. In order to assure the task is accomplished successfully, ground experimentations are required for verifying key planning and control algorithms before the space robot is launched. In this paper, based on the concept of a hybrid approach combining the mathematical model with the physical model, a ground experiment system is set up, which is composed of two industrial robots, global and hand-eye visual equipments, six-axis force/momentum sensors, guide rail and four computers. Many control approaches of fine manipulation, such as compliance control, impedance control, hybrid force/position control, intelligent control, and so on, can be verified using this system. As an example, contour curves tracking experiment based on compliance control strategy is performed. Experiment results show that the ground system is very useful for verifying dexterous manipulation technology of space robot.	algorithm;apache axis;characteristic impedance;computer;control theory;industrial robot;intelligent control;mathematical model;sensor;verification and validation	Houde Liu;Bin Liang;Wenfu Xu;Xueqian Wang;Ye Shi	2012	2012 12th International Conference on Control Automation Robotics & Vision (ICARCV)	10.1109/ICARCV.2012.6485312	control engineering;simulation;computer science;engineering;artificial intelligence;control theory;robot control;intelligent control	Robotics	63.87216282911108	-27.882475526990707	77808
f851f7661b82aaabe4be86d033541b77ab678fc8	m-tran ii: metamorphosis from a four-legged walker to a caterpillar	whole body;machine control legged locomotion distributed control;communication system;hardware design m tran ii metamorphosis four legged walker caterpillar self reconfigurable modular robotic system 3d configurations body motions second prototype complicated reconfigurations versatile connection detachment mechanism on board multicomputers high speed inter module communication system low power consumption precise motor control programing environments dynamics simulation distributed control;legged locomotion;programming environment;machine control;reliable connection;hardware design;dynamic simulation;hardware prototypes power system reliability distributed control energy consumption motor drives process design legged locomotion robot kinematics information processing;low power consumption;distributed control;high speed;motor control	− − We have been developing a self-reconfigurable modular robotic system (M-TRAN) which can make various 3-D configurations and motions. In the second prototype (M-TRAN II), various improvements are integrated in order to realize complicated reconfigurations and versatile whole body motions. Those are a reliable connection/detachment mechanism, on-board multi-computers, high speed inter-module communication system, low power consumption, precise motor control, etc. Programing environments are also integrated to design self-reconfiguration processes, to verify motions in dynamics simulation, and to realize distributed control on the hardware. Hardware design, developed software and experiments are presented in this paper.	amiga walker;computer;distributed control system;experiment;on-board data handling;prototype;self-reconfiguring modular robot;simulation	Haruhisa Kurokawa;Akiya Kamimura;Eiichi Yoshida;Kohji Tomita;Shigeru Kokaji;Satoshi Murata	2003		10.1109/IROS.2003.1249238	control engineering;motor control;embedded system;dynamic simulation;simulation;computer science;engineering;control theory;communications system	Robotics	66.64811155768662	-27.308980348008394	78111
b641d3612cfcfda122d92a4a2bfabc912a6594d0	online motion model parameter estimation using augmented kalman filter and discriminative training	convergence;motion control;mobile robot;stability convergence kalman filters mobile robots motion control parameter estimation;kalman filters;augmented kalman filter;global position system;kalman filter;mobile robots;autonomous mobile robots online motion model parameter estimation augmented kalman filter discriminative training kalman filtering algorithm akf real robot operation robot motion control convergence performance parameter estimation stability;stability;estimation;motion model parameter;global positioning system;mobile robot localization motion model parameter augmented kalman filter discriminative training;mobile robot localization;discriminative training;parameter estimation;parameter estimation estimation wheels global positioning system kalman filters mobile robots;wheels	In this paper, we propose an online motion model parameter estimation method. To achieve accurate localization, accurate estimation of motion model parameters is needed. However, the true values of motion model parameters change sequentially according to alteration of surrounding environments. Therefore the online estimation is absolutely imperative. As a typical method to estimate motion model parameters sequentially, Augmented Kalman Filter (AKF) is there. AKF achieve parameter estimation through Kalman filtering algorithm. However, AKF has serious problems to be implemented in real robot operation. These problems are the accuracy of observation and the limitation to motion control of robots. To solve these problems and achieve accurate motion model parameter estimation, proposed method introduces discriminative training. The introduction of discriminative training increases the convergence performance and stability of parameter estimation through AKF. The proposal method achieves accurate motion model parameter estimation in real robot operation. This paper describes the efficiency of our technique through simulations and an outdoor experiment.	algorithm;discriminative model;estimation theory;imperative programming;kalman filter;robot;simulation	Yuto Fujii;Yoji Kuroda	2011	2011 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2011.6181424	kalman filter;control engineering;mobile robot;computer vision;computer science;engineering;control theory;statistics	Robotics	56.15625485674188	-35.71935704535192	78170
4d05a995d297ea09f72a42d2b51ec6fc30a13e95	a new indoor position estimation method of rfid tags for continuous moving navigation systems	estimation theory;indoor communication;cm crr indoor position estimation method rfid tags continuous moving navigation systems radio frequency identification indoor environments gps rfid reader indoor robot navigations human society s crr swift communication range recognition mobile robot mobile entity rfid technology continuous moving crr communication ranges estimation error;radiofrequency identification robots radio navigation switches;mobile robots;indoor robot navigation rfid sysytem position estimation rfid tag continuous moving;navigation;position control;radiofrequency identification estimation theory indoor communication mobile robots navigation position control;radiofrequency identification	The RFID (Radio Frequency Identification) is considered as one of the most preferable ways for the position estimation in indoor environments, since GPS does not work in such situations. In RFID system, an RFID reader enables to estimate the position of RFID tags easily and inexpensively. In applications with the position estimation of RFID tags, indoor robot navigations are very important for human society. The problem is how to obtain the position estimations of RFID tags as accurately as possible. Previously S-CRR (Swift Communication Range Recognition) has been proposed for the appropriate estimation method of this kind of applications. This method is capable of the accurate position estimation of an RFID tag in very short time. The disadvantage of S-CRR is that the mobile robot must stop to search RFID tags accurately at each position. In indoor robot navigations, mobile entities like robots have to move continuously because they need to navigate smoothly and safely. In this paper, we propose a new position estimation method of RFID tags with continuous moving only using RFID technology. We call this Continuous Moving CRR (CM-CRR). CM-CRR uses two communication ranges, long and short ranges and switches them appropriately. The system estimates the position of RFID tags using their approaches and continuous moving. To show the effectiveness of CM-CRR, we evaluate the estimation error of an RFID tag by computer simulations. From the results, CM-CRR can accurately estimate the position of RFID tags with continuously moving of the mobile robot and be applied to indoor robot navigations.	binomial options pricing model;computer simulation;cyber resilience review;entity;global positioning system;mobile robot;network switch;norm (social);radio frequency;radio-frequency identification;smoothing;swift (programming language)	Emi Nakamori;Daiki Tsukuda;Manato Fujimoto;Yuki Oda;Tomotaka Wada;Hiromi Okada;Kouichi Mutsuura	2012	2012 International Conference on Indoor Positioning and Indoor Navigation (IPIN)	10.1109/IPIN.2012.6418858	embedded system;geography;telecommunications;communication	Mobile	54.91052138282831	-34.02317192085347	78441
004bce2e9803b84386be9645a75f6d98e6ad831e	indoor navigation with foot-mounted strapdown inertial navigation and magnetic sensors [emerging opportunities for localization and tracking]	indoor communication;magnetic sensors;inertial navigation;indoor communication inertial navigation magnetic sensors radio spectrum management;radio spectrum management	This article describes a method of navigation for an individual based on traditional inertial navigation system (INS) technology, but with very small and self-contained sensor systems. A conventional INS contains quite accurate, but large and heavy, gyroscopes and accelerometers, and converts the sensed rotations and accelerations into position displacements through an algorithm known as a strapdown navigator. They also, almost without exception, use an error compensation scheme such as a Kalman filter to reduce the error growth in the inertially sensed motion through the use of additional position and velocity data from GPS receivers, other velocity sensors (e.g., air, water, and ground speed), and heading aids such as a magnetic compass. This technology has been successfully used for decades, yet the size, weight, and power requirements of sufficiently accurate inertial systems and velocity sensors have prevented their adoption for personal navigation systems. Now, however, as described in this article, miniature inertial measurement units (IMUs) as light as a few grams are available. When placed on the foot to exploit the brief periods of zero velocity when the foot strikes the ground (obviating the need for additional velocity measurement sensors), these IMUs allow the realization of a conventional Kalman-filter-based aided strapdown inertial navigation system in a device no larger or heavier than a box of matches. A particular advantage of this approach is that no stride modeling is involved with its inherent reliance on the estimation of a forward distance traveled on every step ��� the technique works equally well for any foot motion, something especially critical for soldiers and first responders. Also described is a technique to exploit magnetic sensor orientation data even in indoor environments where local disturbances in the Earth���s magnetic field are significant. By carefully comparing INSderived and magnetically derived heading and orientation, a system can automatically determine when sensed magnetic heading is accurate enough to be useful for additional error compensation.	algorithm;course (navigation);global positioning system;grams;inertial navigation system;kalman filter;requirement;sensor;velocity (software development)	Jeff Bird;Dale Arden	2011	IEEE Wireless Communications	10.1109/MWC.2011.5751293	computer vision;simulation;inertial navigation system	Mobile	57.781369363546304	-36.42333064995157	78500
178470a49802842ba3c9ac96137251fe5f8362a5	theory and experiments in smartnav rover navigation	natural terrain;rovers;fuzzy logic;navigation;navigation system	This paper describes theoretical and experimental results using the SmartNav rule-free fuzzy rover navigation system. SmartNav divides the terrain perceived by the rover into a number of circular sectors, and evaluates each sector using goal and safety preference factors to differentiate between preferred and unpreferred terrain sectors. The goal-preference factor is used to make sector evaluation based on the sector orientation relative to the designated goal position. The safety-preference factors are used to make sector evaluations on the basis of the sector local and regional terrain hazards. Three methods are developed to blend the three sector evaluations in order to find the effective preference factor for each sector. Two sector selection methods are then described in which the sector preference factors are used to find the heading command for the rover. The rover speed command is also computed based on the goal distance and safety-preference factor of the chosen sector. The above navigation steps are continuously repeated throughout the rover motion. Experimental results are presented to demonstrate the navigational capabilities of SmartNav using a commercial Pioneer 2AT rover traversing a simulated Martian terrain at the JPL Mini Mars Yard.	experiment;rover (the prisoner)	Homayoun Seraji;Barry Brian Werger	2007	Auton. Robots	10.1007/s10514-006-9011-x	fuzzy logic;computer vision;navigation;simulation;computer science;artificial intelligence	Robotics	54.606876806300484	-30.800773601115885	78588
ecc50443541c6da244b8b755d44ddcec97eb00d4	a visual feedback approach for focal plane stabilization of a high resolution space camera (ein ansatz zur bildgestützten regelung für die fokalebenenstabilisierung einer hochauflösenden satellitenkamera)	high resolution;visual feedback	In this article a new concept of a smart satellite pushbroom imaging system with internal compensation of attitude instability effects is presented. The compensation is performed within the optical path by an active opto-mechatronic stabilization of the focal plane image motion in a closed loop system with visual feedback. The real-time image motion measurement is derived from an auxiliary matrix image sensor and an onboard optical correlator. In this way the effects of attitude instability, vibrations and micro shocks can be neutralized, the image quality is improved and the requirements to the satellite attitude stability can be reduced considerably. The paper describes the principles of operation, the main system elements and gives detailed performance figures derived from a simulation performance model, which contains all relevant components of the smart imaging system.	cross-correlation;focal (programming language);image quality;image sensor;instability;mechatronics;real-time clock;requirement;simulation	Klaus Janschek;Valerij Tchernykh;Serguei Dyblenko;Grégory Flandin	2005	Automatisierungstechnik	10.1524/auto.2005.53.10_2005.484	image resolution;telecommunications;engineering;electrical engineering;mechanical engineering	Robotics	66.01576442282868	-35.11763370369705	78597
cda04f31419d04068fb5bb254b466168835688be	editorial: towards practical motion planners		Ž . Robot motion planning MP deals with planning collision-free motions and is considered a mature field. Motion-planning type algorithms have great application potential in a wide span of areas ranging from virtual prototyping, mechanical design or ergonomics, to molecular chemistry, including consumer technology products such as computer animation, virtual reality, or even drug design. Many important contributions were made and the progress in research was rapid, its translation into industry and in commercial products seemed relatively slow. Some in the robotics field, in fact, perceived motion planning as a purely academic issue, and many outside felt that motion planning had failed in that its real industrial applications were almost non-existent.	algorithm;computer animation;human factors and ergonomics;motion planning;robotics;virtual reality	Angel P. Del Pobil;Kamal K. Gupta;José Mira Mira	2001	J. Field Robotics	10.1002/rob.1032	control engineering;mathematics;management science	Robotics	66.66595181903436	-28.502687530187576	78963
0eb07c32cdeeeaf9925cc9ecf87f8cf1fe05f085	midcourse guidance with terminal handover constraint	missiles optimal control cost function geometry handover radar tracking;closed loop control midcourse guidance terminal handover constraint energy cost function optimization time to go flight path radar environment optimal control theory;optimisation closed loop systems military radar missile guidance optimal control	This work addresses guiding a missile during the midcourse phase of flight. It is assumed the missile has the goal of arriving at a (possibly moving) target at a specified terminal flight path angle, while simultaneously optimizing an energy cost function. In general, the missile is assumed to have the entire flight time to meet the prescribed terminal set objective. This development is unique in that the missile is constrained to exert no control after a prespecified time-to-go is reached. This approach ensures the missile has obtained the desired terminal guidance handover basket. This approach can also be used in other scenarios where the desired flight path must be achieved prior to target acquisition, which may be useful in complex radar environments, and against highly maneuvering threats.	control theory;guidance system;interceptor pattern;loss function;optimal control;radar;tracking system;uncontrolled format string	Robert W. Morgan	2016	2016 American Control Conference (ACC)	10.1109/ACC.2016.7526612	control engineering;simulation;engineering;control theory	Robotics	55.38494693235747	-25.54090417029425	79073
a7722dd0204f8d34946226c3713063bd6dc77054	research on a mobile manipulator for biochemical sampling tasks		PurposernrnrnrnrnThe paper aims to present a tracked robot comprised of several biochemical sampling instruments and a universal control architecture. In addition, a dynamic motion planning strategy and autonomous modules in sampling tasks are designed and illustrated at length.rnrnrnrnrnDesign/methodology/approachrnrnrnrnrnSeveral sampling instruments with position tolerance and sealing property are specifically developed, and a robotic operation system (ROS)-based universal control architecture is established. Then, based on the system, two typical problems in sampling tasks, i.e. arm motion planning in unknown environment and autonomous modules, are discussed, implemented and tested. Inspired by the idea of Gaussian process classification (GPC) and Gaussian process (GP) information entropy, three-dimensional (3D) geometric modeling and arm obstacle avoidance strategy are implemented and proven successfully. Moreover, autonomous modules during sampling process are discussed and realized.rnrnrnrnrnFindingsrnrnrnrnrnSmooth implementations of the two experiments justify the validity and extensibility of the robot control scheme. Furthermore, the former experiment proves the efficiency of arm obstacle avoidance strategy, while the later one demonstrates the time reduction and accuracy improvement in sampling tasks as the autonomous actions.rnrnrnrnrnPractical implicationsrnrnrnrnrnThe proposed control architecture can be applied to more mobile and industrial robots for its feasible and extensible scheme, and the utility function in arm path planning strategy can also be utilized for other information-driven exploration tasks.rnrnrnrnrnOriginality/valuernrnrnrnrnSeveral specific biochemical sampling instruments are presented in detail, while ROS and Moveit! are integrated into the system scheme, making the robot extensible, achievable and real-time. Based on the control scheme, an information-driven path planning algorithm and automation in sampling tasks are conceived and implemented.	arm architecture;algorithm;automated planning and scheduling;autonomous robot;autonomous system (internet);computer;entropy (information theory);experiment;extensibility;gaussian process;geometric modeling;industrial robot;mobile manipulator;motion planning;obstacle avoidance;real-time clock;record sealing;robot operating system;robot control;robotics;sampling (signal processing);universal controls;utility	Weidong Wang;Wenrui Gao;Dongmei Wu;Zhijiang Du	2017	Industrial Robot	10.1108/IR-11-2016-0305	control engineering;automation;simulation;architecture;motion planning;robot control;sampling (statistics);mobile manipulator;mobile robot;obstacle avoidance;computer science	Robotics	62.979983480983165	-27.87034470129982	79083
d2d6b59727c6fdbb0ffd290679b10ac743f2256d	autonomous landing of a multicopter on a moving platform based on vision techniques		This paper proposes the whole system scheme designed for the autonomous landing of a multicopter on a moving platform. The technology used for the tracking and landing is the visual detection and recognition of a marker placed on the platform. Both the hardware and software architecture are explained and also the results of some succesful tests are shown. In addition, the proposed system was validated and compared during the MBZIRC robotics competition in March 2017.		José Joaquín Acevedo;Manuel García;Antidio Viguria;Pablo Ramón;Begoña C. Arrue;Aníbal Ollero	2017		10.1007/978-3-319-70836-2_23	computer vision;simulation;computer science;software architecture;artificial intelligence;robotics	Robotics	56.699203070508304	-29.6060935886409	79133
c63701f4fcb3d426270ef1da1bd4b8a2dd0048a1	contour based path planning for unmanned aerial vehicles (uavs) over hostile terrain	uav;low radar risk waypoints;spline;efficient algorithm;offline path planner contour based path planning unmanned aerial vehicles uav hostile terrain stealthy path line radar prone environments user specified threshold altitude value navigational space risk cost cubic b splines low radar risk waypoints;path planning;unmanned aerial vehicle;splines mathematics military aircraft path planning radar remotely operated vehicles search problems;path planning unmanned aerial vehicles;remotely operated vehicles;splines mathematics;military aircraft;unmanned aerial vehicles uavs;contour based path planning;offline path planner;radar cross section;optimal path;radar antennas;b splines unmanned aerial vehicles uavs radar path planning;stealthy path line;hostile terrain;b splines;airborne radar;navigational space risk cost;search problems;unmanned aerial vehicles;user specified threshold altitude value;radar prone environments;radar;aircraft;spaceborne radar;cubic b splines	In this paper, we present a contour based path planner for Unmanned Aerial Vehicles (UAVs).We make use of efficient algorithm to compute a stealthy path line with desired attributes in radar prone environments. The algorithm is employed to estimate the risk cost of the navigational space and generate an optimized path based on the user-specified threshold altitude value. Thus the generated path is represented with a set of low-radar risk waypoints being the coordinates of its control points. The offline path planner is then approximated using cubic B-splines by considering the least radar risk to the destination. Simulated results are presented, illustrating the potential benefits of such algorithms.	aerial photography;approximation algorithm;b-spline;computation;computational intelligence;contour line;cubic function;motion planning;online and offline;radar;simulation;unmanned aerial vehicle	Ee-May Kan;Van Khanh Doan;Chiew Seng Tan;Swee-Ping Yeo;Jiun-Sien Ho	2009	2009 International Conference of Soft Computing and Pattern Recognition	10.1109/SoCPaR.2009.148	remotely operated underwater vehicle;b-spline;spline;computer vision;simulation;computer science;motion planning;radar cross-section;radar	Robotics	54.659483449357836	-26.004756181259186	79205
64ccd3c00b6ecf9628b1f9adf59a70d75e99b7ef	fast biped walking with a sensor-driven neuronal controller and real-time online learning	control algorithm;dynamic biped;research outputs;biped robot;real time;reinforcement learning;center of mass;research publications;online learning;motor neuron;neuronal controller;trajectory tracking;reflex;fast walking	In this paper, we present our design and experiments on a planar biped robot under the control of a pure sensor-driven controller. This design has some special mechanical features, for example small curved feet allowing rolling action and a properly positioned center of mass, that facilitate fast walking through exploitation of the robot’s natural dynamics. Our sensor-driven controller is built with biologically inspired sensorand motor-neuron models, and does not employ any kind of position or trajectory tracking control algorithm. Instead, it allows our biped robot to exploit its own natural dynamics during critical stages of its walking gait cycle. Due to the interaction between the sensor-driven neuronal controller and the properly designed mechanics of the robot, the biped robot can realize stable dynamic walking gaits in a large domain of the neuronal parameters. In addition, this structure allows the use of a policy gradient reinforcement learning algorithm to tune the parameters of the sensor-driven controller in real-time, during walking. This way RunBot can reach a relative speed of 3.5 leg lengths per second after only a few minutes of online learning, which is faster than that of any other biped robot, and is also comparable to the fastest relative speed of human walking. KEY WORDS—dynamic biped, reflex, neuronal controller, online learning, fast walking The International Journal of Robotics Research Vol. 25, No. 3, March 2006, pp. 243-259 DOI: 10.1177/0278364906063822 ©2006 Sage Publications	algorithm;experiment;fastest;gradient;neuron;real-time clock;real-time transcription;reinforcement learning;robot;robotics;sensor	Tao Geng;Bernd Porr;Florentin Wörgötter	2006	I. J. Robotics Res.	10.1177/0278364906063822	control engineering;center of mass;simulation;reflex;computer science;engineering;artificial intelligence;control theory;reinforcement learning	Robotics	66.00808603000253	-24.76144072362899	79381
36365b1b67bd1899fb808be4a77f9bfccf5718e3	landing site searching algorithm of a quadrotor using depth map of stereo vision on unknown terrain			algorithm;depth map;stereopsis	Jongho Park;Youdan Kim	2012		10.2514/6.2012-2588	computer vision;simulation;geography;remote sensing	Robotics	53.84063347635592	-36.730107539456945	79403
1bcbb67cdb7fb3afb36c8b38fc90c9e8d05bd7ba	trajectory planning for autonomous high-speed overtaking using mpc with terminal set constraints		With self-driving vehicles being pushed towards the main-stream, there is an increasing motivation towards development of systems that autonomously perform manoeuvres involving combined lateral-longitudinal motion (e.g., lane-change, merge, overtake, etc.). This paper presents a situational awareness and trajectory planning framework for performing autonomous overtaking manoeuvres. A combination of a potential field-like function and reachability sets of a vehicle are used to identify safe zones on a road that the vehicle can navigate towards. These safe zones are provided to a model predictive controller as reference to generate feasible trajectories for a vehicle. The strengths of the proposed framework are: (i) it is free from non-convex collision avoidance constraints, (ii) it ensures feasibility of trajectory, and (iii) it is real-time implementable. A proof of concept simulation is shown to demonstrate the ability to plan trajectories for high-speed overtaking manoeuvres.		Shilp Dixit;Umberto Montanaro;Saber Fallah;Mehrdad Dianati;David W. Oxtoby;Tom Mizutani;A. Mouzakitis	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8569529		Robotics	56.112889368021904	-26.443905770266433	79476
e9fce977dbe7c2b0f40507aafe7e0d93968076bb	minimal communication strategies for self-organising synchronisation behaviours	self adjusting systems;synchronisation;multi robot systems;biological systems;behavioural sciences;physical robots minimal communication strategies self organising synchronisation behaviours biological system robotic system dynamical coupling artificial evolution robot controller;synchronisation behavioural sciences multi robot systems self adjusting systems;adaptive response;frequency synchronization robot kinematics oscillators interference insects switches biological systems stress evolution biology robot control;artificial evolution	The ability to synchronise the individual actions within large groups is an adaptive response observed in many biological systems. Indeed, synchrony can increase the efficiency of a group by maximising the global outcome or by minimising the interference among individuals. In any case, synchronisation appears desirable for a robotic system as it allows to coordinate through time the activities of the group. The main goal of the experiments presented in this paper is the study of self-organising synchronisation behaviours for a group of robots. To do so, we do not postulate the need of internal dynamics. Instead, we stress the importance of the dynamical coupling between robots and environment, which can be exploited for synchronisation, allowing to keep a minimal complexity of both the behavioural and the communication level. We use artificial evolution to synthesise the robot controllers, and we show how very simple communication strategies can produce self-organising synchronisation behaviours that scale to very large groups and that can be transfered to physical robots.	biological system;dynamical system;evolutionary algorithm;experiment;interference (communication);robot;sql;self-organization	Vito Trianni;Stefano Nolfi	2007	2007 IEEE Symposium on Artificial Life	10.1109/ALIFE.2007.367797	synchronization;behavioural sciences;computer science;adaptive response;genetics	Robotics	64.84357356044433	-25.97474489278269	79480
3e4eb5980d5d880b874b79f8943b610e01bbb8d0	grey wolf optimizer for unmanned combat aerial vehicle path planning	unmanned combat aerial vehicle;path planning;grey wolf optimizer	Unmanned combat aerial vehicle (UCAV) path planning is a fairly complicated global optimum problem.A new meta-heuristic grey wolf optimizer (GWO) is proposed to solve the UCAV path planning problem.The simulation results show that the proposed method is more competent for the UCAV path planning than other state-of-the-art evolutionary algorithms considering the quality, speed, and stability of solutions. Unmanned combat aerial vehicle (UCAV) path planning is a fairly complicated global optimum problem, which aims to obtain an optimal or near-optimal flight route with the threats and constraints in the combat field well considered. A new meta-heuristic grey wolf optimizer (GWO) is proposed to solve the UCAV two-dimension path planning problem. Then, the UCAV can find the safe path by connecting the chosen nodes of the two-dimensional coordinates while avoiding the threats areas and costing minimum fuel. Conducted simulations show that the proposed method is more competent for the UCAV path planning scheme than other state-of-the-art evolutionary algorithms considering the quality, speed, and stability of final solutions.	aerial photography;mathematical optimization;motion planning;unmanned aerial vehicle	Sen Zhang;Yongquan Zhou;Zhiming Li;Wei Pan	2016	Advances in Engineering Software	10.1016/j.advengsoft.2016.05.015	simulation;computer science;engineering;artificial intelligence;aeronautics;motion planning	Robotics	54.773144375735285	-25.4097612708524	79711
8943f552bde3cb6daf4690b122c536ffef88c148	hardware and software architecture of abby: an industrial mobile manipulator	hardware architecture abby stationary factory tasks mobile platform low price industrial mobile manipulator platform prototype abb irb 120 industrial robotic manipulator invacare electric wheelchair base robot operating system ros industrial facilitated development abb industrial manipulators ros industrial project workstations system development software architecture;mobile communication robot kinematics manipulators navigation robot sensing systems trajectory;mobile robots;software architecture;wheelchairs control engineering computing factory automation industrial manipulators mobile robots operating systems computers software architecture;factory automation;control engineering computing;operating systems computers;industrial manipulators;wheelchairs	Industrial robotic manipulators have successfully automated many stationary factory tasks, but there exist many other tasks which could be automated given a mobile platform. One such task is kitting, the process of gathering the constituent elements of a larger unit (the “kit”) from inventory. ABBY is a prototype of a low-price industrial mobile manipulator platform chiefly composed of an ABB IRB-120 industrial robotic manipulator and an Invacare electric wheelchair base. Use of the Robot Operating System (ROS) and ROS Industrial facilitated development and drivers for ABB industrial manipulators have been contributed back to the ROS Industrial project. ABBY is designed to autonomously navigate a factory to populate and deliver kits to workstations. This paper describes the prototype robot constructed to pursue this research, including the use of ROS and ROS Industrial to facilitate and accelerate system development.	existential quantification;industrial robot;mobile manipulator;mobile operating system;population;prototype;robot operating system;software architecture;stationary process;workstation	Edward Venator;Gregory S. Lee;Wyatt S. Newman	2013	2013 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/CoASE.2013.6653969	control engineering;embedded system;simulation;engineering;mobile manipulator	Robotics	62.11943233957585	-28.675182578597365	79816
637ec1450d726a141bf96e2cb80c44f36f6e648b	design of failover micro aerial vehicle with tilting rotors	drones;robots design;quadrotor systems;micro aerial vehicles;tiltrotors	In this paper we address the fault tolerance problem of micro aerial vehicles. This problem is important in cases where people and equipment safety and situation control matters. We propose an special construction of aerial vehicle that adds multiple additional degrees of freedom to vehicle's engines. Presented concept include different flight modes and these modes' benefits are described in paper.	aerial photography;direct inward dial;failover;fault tolerance;r.o.t.o.r.;testbed;thrust;turbulence;unmanned aerial vehicle	Denis A. Khvostov;Sergey A. Chepinskiy;Aleksandr J. Krasnov;Ksenia Khvostova;Grigory Shmigelsky	2016	2016 8th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT)	10.1109/ICUMT.2016.7765385	drone;simulation	Robotics	63.94803457622661	-28.99480755713178	79821
3c8692f97a473c1fb38f417849439fedf1ef6926	sharing effort in planning human-robot handover tasks	manipulators;path planning human robot interaction manipulators mobile robots motion control;motion control;path planning;mobile robots;human robot interaction;human receiver presence human robot handover tasks planning versatile human assisting mobile manipulating robot possibly cluttered workspaces motion planning human mobility human motion hri constraints pr2 robot;humans planning robot kinematics navigation	For a versatile human-assisting mobile-manipulating robot such as the PR2, handing over objects to humans in possibly cluttered workspaces is a key capability. In this paper we investigate the motion planning of handovers while accounting for the human mobility. We treat the human motion as part of the planning problem thus enabling to find broader type of handing strategies. We formalize the problem and propose an algorithmic solution taking into account the HRI constraints induced by the human receiver presence. Simulation results with the PR2 robot illustrate the efficacy of the approach.	algorithm;human–robot interaction;kinesiology;motion planning;robot;sampling (signal processing);simulation;vii;workspace	Jim Mainprice;Mamoun Gharbi;Thierry Siméon;Rachid Alami	2012	2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2012.6343844	human–robot interaction;motion control;mobile robot;computer vision;simulation;computer science;artificial intelligence;social robot;motion planning;robot control;mobile robot navigation;personal robot	Robotics	59.42907546097863	-26.615112407064043	79860
c5b579424b5d76982daa61666191556e3779b2c0	leader-follower system using two robot tractors to improve work efficiency	fault tolerant;leader follower system;robot tractor;work efficiency;rtk gps	A leader-follower system using two robot tractors was developed for field work.This system was designed for practical application.The experiment results showed the two robots can work safely to complete the work.The system's efficiency improved by 95.1 percent compared with using a single robot. Two robot tractors were used in a leader-follower system for agricultural field work. Each of the robots is fully independent and can conduct field work alone. They can also work together to form a certain spatial arrangement during the operation. During the headland turn, to make the best use of headland, the two robots coordinate to turn to next path and do not keep the spatial arrangement. Each robot is simplified as a rectangular zone, and the two robots cooperate and coordinate to turn to the next path without collision. This system is designed for practical application, and the system gains the ability to tolerate most of the disturbances in a real field. Fault tolerant methods in accordance with agricultural work are illustrated to solve the common disturbances from the GPS and the IMU. Field experiments were conducted to determine the effectiveness of the system. The results of the experiments showed that the two robot tractors can work safely together to complete the field work. The average lateral error of the navigation system of the robots was less than 0.04m, and the efficiency of the leader-follower system was improved by 95.1% compared with that of a conventional single robot.	robot	Chi Zhang;Noboru Noguchi;Liangliang Yang	2016	Computers and Electronics in Agriculture	10.1016/j.compag.2015.12.015	control engineering;fault tolerance;simulation;computer science;engineering;control theory;real time kinematic;remote sensing	Robotics	58.0109217338242	-28.25506329114886	79934
b7c1d06d38d16260dd03f236bcc7e9eff0b4cbbe	mapping, localization and motion planning in mobile multi-robotic systems	robot localization;robotic exploration;path planning;slam;mobile robots;motion planning;multi robotic systems	As researchers have pushed the limits of what can be accomplished by a single robot operating in a known or unknown environment, a greater emphasis has been placed on the utilization of mobile multi-robotic systems to accomplish various objectives. In transitioning from a robot-centric approach to a system-centric approach, considerations must be made for the computational and communicative aspects of the group as a whole, in addition to electromechanical considerations of individual robots. This paper reviews the state-of-the-art of mobile multi-robotic system research, with an emphasis on the confluence of mapping, localization and motion control of robotic system. Methods that compose these three topics are presented, including areas of overlap, such as integrated exploration and simultaneous localization and mapping. From these methods, an analysis of benefits, challenges and tradeoffs associated with multi-robotic system design and use are presented. Finally, specific applications of multi-robotic systems are also addressed in various contexts.	algorithm;autonomy;computation;confluence;high-level programming language;hoc (programming language);internationalization and localization;minimal recursion semantics;motion planning;real-time transcription;robot;simultaneous localization and mapping;sparse matrix;systems design;unified framework	William S. Rone;Pinhas Ben-Tzvi	2013	Robotica	10.1017/S0263574712000021	computer science;artificial intelligence;motion planning	Robotics	64.89719421015748	-28.575769113953328	80206
65b3e52bf842fe97ed06c5d9049c70e7a17bddb9	robot learns chinese calligraphy from demonstrations	unsupervised learning art brushes intelligent robots motion control regression analysis robot vision trajectory control;brushes trajectory writing robots joints kinematics training;stroke extraction robot chinese calligraphy learns brush manipulation 6d brush motion calligraphy images calligraphy writing learning from demonstration approach callibot calligraphy skills parametrization approach locally weighted linear regression stroke parameters human writing	Chinese calligraphy is a unique form of art in the world, whose aesthetic is mainly created by the proper manipulation of the brush. However, it is impossible for a person to figure out the 6-D motion of the brush from calligraphy images, if he has no experience of writing calligraphy. In this paper, we propose a Learning from Demonstration approach for our calligraphy robot, Callibot, to acquire calligraphy skills. We first propose a new stroke parametrization approach. Then we apply Locally Weighted Linear Regression to map from the stroke parameters to the trajectory of the brush. The training data are obtained from several demonstrations. Thereafter, Callibot is capable of writing a new stroke, if the stroke's parameters are given. The resulting motion is as natural as human writing. Experimental results prove the feasibility of our proposed approach. This approach is independent of the robot and is compatible with any robot with six or more degrees of freedom. This approach can be further integrated with our previous research, i.e. stroke extraction, so that Callibot will be able to replicate calligraphy from images.	chinese room;encoder;experiment;forward kinematics;jargon;robot;self-replication	Yuandong Sun;Huihuan Qian;Yangsheng Xu	2014	2014 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2014.6943186	computer vision;simulation;engineering;artificial intelligence	Robotics	62.306570723006274	-25.412148902650983	80271
8ec858260b25c7bc5d31c16bf8911c49a73ab3d4	cooperative positioning with multiple robots	robot sensing systems;animals;three dimensions;error variances cooperative positioning multiple robots positioning identification techniques mobile robots accumulated positioning error positioning accuracy;mobile robot;path planning;cooperative positioning;position control cooperative systems mobile robots path planning;mobile robots;error variances;accumulated positioning error;cooperative systems;positioning identification techniques;position control;global positioning system;positioning accuracy;multiple robots;optical sensors;dead reckoning;mobile robots dead reckoning wheels robot sensing systems costs optical sensors laboratories animals aircraft global positioning system;aircraft;wheels	A number of positioning identification techniques have been used for mobile robots. Dead reckoning is a popular method, but is not reliable when a robot travels long distances or over an uneven surface because of variations in wheel diameter and wheel slippage. The landmark method, which estimates the current position relative to landmarks, cannot be used in an uncharted environment. We propose a new method called “Cooperative Positioning with Multiple Robots.” For cooperative positioning, we divide the robots into two groups, A and B. One group, say A, remains stationary and acts as a landmark while group B moves. The moving group B then stops and acts as a landmark for group A. This “dance” is repeated until the target robot position are reached. Cooperative positioning has a far lower accumulated positioning error than dead reckoning, and can work in three-dimensions which is not possible with dead reckoning. Also, this method has inherent landmarks and therefore works in uncharted environments. This paper discusses the positioning accuracy of our method with error variances for an example with three mobile robots.	computer simulation;dead reckoning;experiment;mobile robot;stationary process	Ryo Kurazume;Shigemi Nagata	1994		10.1109/ROBOT.1994.351315	control engineering;mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence	Robotics	54.59198230457915	-34.02340552771313	80284
3c2cb6a5e1b28ac832b8c74755df377e3970f17b	optimizing plane-to-plane positioning tasks by image-based visual servoing and structured light	convergence analysis;image motion analysis;plane to plane positioning tasks;3d visualization;closed loop systems;structured light;global convergence;visual servoing cameras robot vision systems laser modes image processing convergence noise robustness optical control intelligent robots surgical instruments;plane to plane task;robot vision;position control;robot vision plane to plane positioning tasks image based visual servoing eye in hand system global convergence;indexation;robot vision closed loop systems image motion analysis position control;visual features;eye in hand system;image based visual servoing;visual servoing;visual servoing convergence analysis decoupled visual features plane to plane task structured light;decoupled visual features	This paper considers the problem of positioning an eye-in-hand system so that it becomes parallel to a planar object. Our approach to this problem is based on linking to the camera a structured light emitter designed to produce a suitable set of visual features. The aim of using structured light is not only for simplifying the image processing and allowing low-textured objects to be considered, but also for producing a control scheme with nice properties like decoupling, convergence, and adequate camera trajectory. This paper focuses on an image-based approach that achieves decoupling in all the workspace, and for which the global convergence is ensured in perfect conditions. The behavior of the image-based approach is shown to be partially equivalent to a 3-D visual servoing scheme, but with a better robustness with respect to image noise. Concerning the robustness of the approach against calibration errors, it is demonstrated both analytically and experimentally	coupling (computer programming);experiment;image noise;image processing;lambert's cosine law;local convergence;optimizing compiler;structured light;visual servoing;workspace	Jordi Pagès;Christophe Collewet;François Chaumette;Joaquim Salvi	2006	IEEE Transactions on Robotics	10.1109/TRO.2006.878785	computer vision;simulation;visualization;structured light;computer science;control theory;visual servoing	Vision	60.94192344008046	-32.35773219607527	80382
18d976aa09029cba139bdeabf1a53921ad0e47ce	predictive displays and shared compliance control for time-delayed telemanipulation	insertion;task performance;time delayed telemanipulation;telecontrol aerospace control robots;delay effects;round trip time;satellite ground stations;orbital robotics;time delay;shared compliance control;aerospace control;robot control;displays;space robotics;low earth orbit satellites;robots;2 to 8 s human task performance enhancement shared compliance control time delayed telemanipulation ground station control space robots predictive display free motion contact insertion;human task performance enhancement;space stations;2 to 8 s;telecontrol;free motion;artificial satellites;space robots;humans;ground station control;low earth orbit;communication system control;displays delay effects communication system control satellite ground stations space stations orbital robotics low earth orbit satellites robot control artificial satellites humans;contact;predictive display	Considers the ground station control of space robots in which a communication time delay problem arises. The round-trip time delay of the communication link between the ground station and a space robot in low earth orbit (via one or more geosynchronous satellites) is expected to be as long as 2-8 seconds. In order to enhance time delayed telemanipulation performance, the authors have recently developed two schemes at JPL: predictive display and shared compliance control. During free motion, predictive display is used. During contact or insertion, compliance control is used. Therefore the authors' strategy for time-delayed telemanipulation employs predictive display and shared compliance control alternately to enhance human task performance. >	remote manipulator	Antal K. Bejczy;Won S. Kim	1990		10.1109/IROS.1990.262418	robot;control engineering;insertion;simulation;computer science;engineering;artificial intelligence;control theory;robot control;robotic spacecraft;round-trip delay time;satellite	HCI	62.683531514644436	-29.493744931732966	80385
671f5e095f8c0ffbad0f3a66f9897e1cee9725c5	evolution of shape-changing and self-repairing control for the atron self-reconfigurable robot	robot sensing systems;motion control;shape changing control;distributed artificial neural network control shape changing control self repairing control atron self reconfigurable robot interconnected modules complex motion constraints meta modules;atron self reconfigurable robot;lattices;interconnected systems;self adjusting systems;bridges;orbital robotics;artificial neural networks;bones;robot control;shape control artificial neural networks robot sensing systems lattices orbital robotics robot control production motion control bridges bones;distributed artificial neural network control;robots;self reconfigurable robots;self repairing control;production;self adjusting systems distributed control interconnected systems motion control neurocontrollers robots;shape control;interconnected modules;neurocontrollers;meta modules;distributed control;control strategy;artificial neural network;complex motion constraints	The ATRON self-reconfigurable robot consists of simple interconnected modules. Modules move relative to other modules and as a result change the shape of the robot. The ATRON modules are difficult to control because of complex motion constraints on the modules. Motion constraints are reduced by using meta-modules composed of three modules. A meta-module may emerge from unstructured groups of modules if three modules are connected in the right configuration. The meta-module then moves on a surface of modules and stop at another position. To attract moving meta-modules and thereby to specify the shape-changing task of the robot we use attraction-points. In this work we evolve a distributed artificial neural network controller for the modules. The controller is identical on every module and controls when a meta-module emerges, how it move and when it stops. In simulation we demonstrate how this control strategy allows the ATRON robot to shape-change to support an unstable roof, build a bridge across a gap and to self-repair a broken bone. We conclude that the control strategy is able to shape-change and self-repair the ATRON robot independent on whether it consists of dozens, hundreds or thousands of modules	artificial neural network;control theory;emergence;network interface controller;self-reconfiguring modular robot;simulation	David Johan Christensen	2006	Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.	10.1109/ROBOT.2006.1642084	robot;control engineering;motion control;computer science;engineering;artificial intelligence;lattice;control theory;robot control;artificial neural network	Robotics	65.47250150822576	-26.66878890993745	80527
2bd0ef57ab0d5baa395af0bbd72795dc4874bd29	continuous motion planning for service robots with multiresolution in time		We present an approach to continuous motion planning with multiresolution in time. Our approach is based on stochastic trajectory optimization for motion planning (STOMP) and designed to decrease the optimization time in order to enable frequent replanning. Since service robots operate in environments with dynamic obstacles, it is likely that planned trajectories become invalid over time. Thus, it is not necessary to provide trajectories with a uniform high resolution. Our multiresolutional approach implicitly considers the uncertainty of the future by providing a trajectory with a gradually coarser schedule, which is refined trough replanning. In addition to employing temporal multiresolution, we speed up trajectory optimization by initializing replanning with the previous plan. The proposed multiresolution STOMP is evaluated in simulation in comparison to the original STOMP implementation. Our experiments show that multiresolution STOMP reduces the planning time and, hence, is able to avoid dynamic obstacles.	algorithm;automated planning and scheduling;coat of arms;experiment;image resolution;inverse kinematics;mathematical optimization;motion planning;multiresolution analysis;robot;simulation;trajectory optimization	Ricarda Steffens;Matthias Nieuwenhuisen;Sven Behnke	2014		10.1007/978-3-319-08338-4_16	computer vision;simulation;computer science;operations management	Robotics	53.88139399095301	-24.22517976924428	80687
03c993fb7361dd7c915f54d0ce548515099e25d4	learning slip behavior using automatic mechanical supervision	visual based classification slip behavior learning automatic mechanical supervision terrain traversability learning autonomous vehicle rover slippage learning visual information;rover slippage learning;autonomous vehicle;visual based classification;mechanical variables measurement mechanical factors extraterrestrial measurements navigation humans mechanical sensors mars robotics and automation remotely operated vehicles mobile robots;mobile robots;automatic mechanical supervision;robot vision;visual information;slip;slip behavior learning;terrain traversability learning;learning artificial intelligence;slip learning artificial intelligence mobile robots robot vision	We address the problem of learning terrain traversability properties from visual input, using automatic mechanical supervision collected from sensors onboard an autonomous vehicle. We present a novel probabilistic framework in which the visual information and the mechanical supervision interact to learn particular terrain types and their properties. The proposed method is applied to learning of rover slippage from visual information in a completely automatic fashion. Our experiments show that using mechanical measurements as automatic supervision significantly improves the visual-based classification alone and approaches the results of learning with manual supervision. This work will enable the rover to drive safely on slopes, learning autonomously about different terrains and their slip characteristics.	algorithm;autonomous robot;experiment;grayscale;lateral thinking;mer;nonlinear system;rover (the prisoner);sensor;transverse wave;yaws	Anelia Angelova;Larry H. Matthies;Daniel M. Helmick;Pietro Perona	2007	Proceedings 2007 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2007.363574	control engineering;mobile robot;robot learning;computer vision;simulation;computer science;engineering;artificial intelligence;slip	Robotics	57.098131452075926	-34.186853468449165	80735
b570f443750da94a22941be72786fac9aa324677	implementation of an orocos based real-time equipment controller for remote maintenance of tokamaks		A tokamak is a torus shaped device used to confine high temperature plasmas with the help of powerful superimposed magnetic fields. With high temperature, vacuum and radiation levels, the environment inside the tokamak is hostile to human beings. All the repair and maintenance tasks are handled by specialized Remote Handling (RH) equipment consisting of robotic manipulators, special tooling and deployment systems which are controlled by skilled RH operators. These RH equipment are integrated using a supervisory control architecture in which the control system is distributed into operator level and machine level control systems. The OROCOS real-time toolkit, available open source, is used to implement the equipment controller that encompasses the machine-level control system software and hardware for operating multi-joint programmable RH equipment devices. It provides a standard interface and insulates the operator level control system from details of low-level hardware. The communication between operator and machine level systems is achieved at 100Hz through a standard middleware.  This paper presents the detailed implementation of the equipment controller with the operator level & machine level interfaces and its successful implementation for controlling the articulated RH equipment having 25 Kg payload with a toroidal reach of ~2m and a 6 DOF industrial robot. The master control is achieved using a commercial haptic device. A novel concept of virtual move is also implemented for carrying out offline simulations. The performance tests show low latency and smooth control over the RH equipment.	control system;controller (control theory);haptic technology;high- and low-level;industrial robot;master control;middleware;online and offline;open-source software;real-time transcription;simulation;software deployment;toroidal graph	Naveen Rastogi;Pramit Dutta;Vamshi Krishna;Krishan Kumar Gotewal	2017		10.1145/3132446.3134900	machine learning;industrial robot;embedded system;architecture;computer science;control theory;radiation;artificial intelligence;software deployment;middleware;supervisory control;control system	Robotics	63.95159833120449	-29.38812577447108	80817
461ebf625ffcc38766c457744dc44943ecb88e91	energy-efficient surface propulsion inspired by whirligig beetles	energy efficiency;turning;biomechanics;propulsion turning robot kinematics biomechanics trajectory energy efficiency swimming robots;trajectory;trajectory control autonomous underwater vehicles bending strength biomechanics marine propulsion optimisation robot dynamics shear modulus;s shaped trajectory energy efficient surface propulsion whirligig beetles energy efficient surface swimming robot platform propulsor body fluid interaction dynamics model propulsor flexural rigidity beating pattern optimization energy efficient linear swimming energy efficient linear turning flexural rigidity vortex shedding thrust generation improvement asymmetrical beating sequence optimal beating frequency propulsion efficiency improvement alternating asymmetrical beating sequence outboard propulsors unfolded inboard propulsors brakes turning radius propulsor length oscillating body motion;propulsion;swimming robots;robot kinematics;propulsion bioinspired swimming robot energy efficient	The whirligig beetle, claimed to be one of the most energy-efficient swimmers in the animal kingdom, has evolved a series of propulsion strategies that may serve as a source of inspiration for the design of propulsion mechanisms for energy-efficient surface swimming. In this paper, we introduce a robot platform that was developed to test an energy-efficient propulsion mechanism inspired by the whirligig beetle. A propulsor-body-fluid interaction dynamics model is proposed, and based on this model, the propulsor flexural rigidity and beating patterns are optimized in order to achieve energy-efficient linear swimming and turning. The optimization results indicate that a propulsor with decreasing flexural rigidity enhances vortex shedding and improves thrust generation. It has also been found that an alternating asymmetrical beating sequence and optimal beating frequency of 0.71 Hz improves propulsion efficiency for linear swimming of the robot. The alternating beating of the outboard propulsors and the unfolded inboard propulsors working as brakes results in efficient turning with a smaller turning radius. Both simulation and experimental studies were conducted, and the results illustrate that decreasing flexural rigidity along the propulsor length, an oscillating body motion, and an S-shaped trajectory are critical for energy-efficient propulsion of the robot.	mathematical optimization;robot;simulation;thrust;vortex	Xinghua Jia;Zongyao Chen;Andrew Riedel;Ting Si;William R. Hamel;Mingjun Zhang	2015	IEEE Transactions on Robotics	10.1109/TRO.2015.2493501	structural engineering;simulation;propulsion;computer science;engineering;artificial intelligence;biomechanics;trajectory;efficient energy use;marine engineering;robot kinematics	Robotics	67.53891175280228	-24.307849525839263	80835
0bcd0ca5372ce5e5456ec4745543b45cab6fb40e	collaborative quadricopter-mobile robots ground scan using artags visual pose estimation		The use of collaborative robot systems to perform specific tasks is a strong research area on robotic systems. Robot platforms are becoming cheaper, increasing the number of applications and new tasks variations on research labs. A collaborative system that join together small mobile robots to scan some specific area and a drone to set their position on the ground is a good example of the possible applications of this kind. This work proposes the use of an autonomous quadri-copter and “dummy” small ground robots on a collaborative task that uses virtual reality tags to estimate robot positions and orientations on a simulation scene and provide information for their control. The robots are “dummy” because do not have any embedded odometer. The position and orientation data are achieved by the drone and transmitted via ROS to a computational system that runs a PID control for each individual robot. The simulation runs on a V-REP scene and use a C++ code to control the mobile robots moves.	autonomous robot;c++;cobot;displacement mapping;dummy variable (statistics);embedded system;error detection and correction;experiment;firmware;mobile robot;motion capture;pid;principle of good enough;robot operating system;simulation;unmanned aerial vehicle;video tracking;virtual reality	Alvaro R. Cantieri;Ronnier F. Rohrich;Andre S. Oliveira;Joao A. Fabro;Marco A. Wehrmeister	2017	2017 Latin American Robotics Symposium (LARS) and 2017 Brazilian Symposium on Robotics (SBR)	10.1109/SBR-LARS-R.2017.8215327	visualization;computer vision;robot;pid controller;pose;mobile robot;virtual reality;robot kinematics;artificial intelligence;computer science	Robotics	58.923849823277486	-34.6552307219114	80870
6ff168267fe916b634de27a108358e85207a6cc7	a real-time control system for a mobile dextrous 7 dof arm	automatic control;control systems;manipulators;motion control;mobile dexterous arm;elbow;arm angle control;path planning;robotics research corporation;hand placement;hand orientation;position control real time systems manipulators redundancy path planning;motorized platform;redundancy;position control;weighting factor assignment;motion control real time control system mobile dexterous arm 7 dof arm mobile redundant dexterous manipulator robotics research corporation motorized platform hand placement hand orientation configuration control arm angle control collision avoidance platform placement elbow angle control weighting factor assignment;robots;motion planning;real time control system;elbow angle control;robustness;collision avoidance;configuration control;7 dof arm;real time systems control systems automatic control manipulators robots collision avoidance elbow robustness motion control motion planning;platform placement;mobile redundant dexterous manipulator;real time systems	This paper describes the design and implementation of a real-time control system with multiple modes of operation for a mobile redundant dexterous manipulator. The manipulator under study is a seven degree-of-freedom (DOF) arm from Robotics Research Corporation, mounted on a motorized platform. The manipulator-plus-platform system has 2-DOF for the task of hand placement and orientation. The redundancy resolution is achieved by accomplishing two additional tasks using the configuration control technique. The system allows a choice of arm angle control or collision avoidance for the seventh task and platform placement or elbow angle control for the eighth task. In addition, joint limit avoidance task is automatically invoked when any of the joints approach their limits. The system is robust to singularities, and also provides the capability of assigning weighting factors to end-effector and redundancy resolution tasks. The motion control algorithms are executed at 1.1 ms on two MC68040 processors in a VME-bus environment running the VxWorks real-time operating system. The paper describes the hardware and software components of the VME environment. Experimental results are also presented. >	real-time control system;real-time transcription	David Lim;Thomas S. Lee;Homayoun Seraji	1994		10.1109/ROBOT.1994.351200	control engineering;simulation;computer science;engineering;control system;artificial intelligence;automatic control;control theory;motion planning	Robotics	62.28229279067635	-28.773341110108408	80916
4d175be2b82c8d55ab8deea54d7bd9110d07d4e9	fuzzy control to drive car-like vehicles	fuzzy controller;motion control;mobile robot;fuzzy rules;real time;fuzzy control;low resolution;motion autonomy;fuzzy logic;control system;fuzzy rule base;obstacle avoidance;control architecture;servo system;automated learning	The reactive component of a motion control architecture for a car-like vehicle intended to move in dynamic and partially known environments is presented in this paper. It is called the execution monitor(EM). The purpose of EM is to generate commands for the servo-systems of the vehicle so as to follow a given nominal trajectory while reacting in real time to unexpected events. EM is designed as a fuzzy controller, i.e. a control system based upon fuzzy logic, whose main component is a set of fuzzy rules encoding the reactive behaviour of the vehicle. A behaviour-based approach is used to set up the fuzzy rule base: the overall behaviour of the vehicle results from the combination of several basic behaviours (trajectory following, obstacle avoidance, etc.), each of which is encoded by a specific set of rules. This approach permits an easy and incremental construction of the fuzzy rule base and also to develop and test the basic behaviours separately. It is the fuzzy control mechanism that straightforwardly handles the problems of behaviour arbitration and command fusion. The basic behaviour rules are simply obtained through direct encoding of the human expertise about car driving. In addition, weighing coefficients are attached to the rules thus permitting a fine tuning of the influence of each basic behaviour. EM has been implemented and tested on a real computer-controlled car, equipped with sensors of limited precision and reliability. Experimental results obtained with the prototype vehicle are presented. They demonstrate the capability of EM to actually control a real vehicle and to perform trajectory following and obstacle avoidance in real outdoor environments by using simple fuzzy behaviours relying upon low-resolution sensor data. © 2001 Elsevier Science B.V. All rights reserved.	coefficient;fuzzy control system;fuzzy logic;fuzzy rule;obstacle avoidance;prototype;real computation;risk management;rule-based system;sensor;servo	Thierry Fraichard;Philippe Garnier	2001	Robotics and Autonomous Systems	10.1016/S0921-8890(00)00096-8	fuzzy logic;motion control;mobile robot;simulation;image resolution;defuzzification;adaptive neuro fuzzy inference system;computer science;control system;artificial intelligence;fuzzy number;neuro-fuzzy;servomechanism;obstacle avoidance;fuzzy associative matrix;fuzzy set operations;fuzzy control system	Robotics	59.14350460564686	-27.967271038463593	81047
f6c4586e35221d6c0d20ae278ea770e7e83c712d	instrumented scanning manipulator for landmines detection tasks	detectors;robot vision image sensors landmine detection manipulators;contaminated terrain scanning instrumented scanning manipulator landmines detection tasks instrumented robotic arm humanitarian demining activities mini tof camera terrain mapping metal detector;metals;humanitarian demining manipulator robotic arm scanning landmines time of flight camera;cameras detectors metals robot vision systems;time of flight camera;comunicacion de congreso;robotic arm;landmines;scanning;humanitarian demining;manipulator;robot vision systems;cameras	This paper presents an instrumented robotic arm for landmines detection tasks during humanitarian demining activities. The manipulator has 5 DOF and it is endowed with a metal detector for landmines detection and a mini-TOF camera for mapping the terrain that has to be scanned. The mini-TOF camera provides a point cloud of the terrain that allows keeping the metal detector at a constant height above the ground and performing an efficient scanning of the contaminated terrain.	inverse kinematics;point cloud;robot;robotic arm;time-of-flight camera	Javier Gavilanes;Roemi Fernández;Héctor Montes;Javier Sarria;Pablo González de Santos;Manuel A. Armada	2015	2015 IEEE International Conference on Autonomous Robot Systems and Competitions	10.1109/ICARSC.2015.36	computer vision;simulation;engineering;remote sensing	Robotics	58.12295031408305	-34.38016636922023	81273
26d25da36b3ad7a4b9c34a5ade79be78e9cc2d04	the alliance of global navigation satellite systems and fuzzy logic in unmanned cars	fuzzy logic	This paper presents a fuzzy control application in the unmanned driving field. Two electric cars have been conveniently instrumented in order to transform them in platforms for automatic driving experiments. The core of the guiding system is based essentially on an alliance of global navigation satellite systems, by now a centimetric DGPS, and on board speed and steering fuzzy controllers.	autonomous robot;differential gps;experiment;fuzzy control system;fuzzy logic;satellite navigation;unmanned aerial vehicle	Teresa de Pedro;Ricardo García Rosa;Carlos González;Jesús Reviejo;José Eugenio Naranjo	2001			alliance;fuzzy logic;simulation;fuzzy control system;satellite;computer science	Robotics	56.30207174148798	-31.273789757624023	81311
c8e5a82d6238f4bc39e2b18b5cf67c647aa36686	the adaptive compensation algorithm for small uav image stabilization	maximum likelihood detection nonlinear filters information filters low pass filters jitter motion estimation;video signal processing;adaptive control;atmospheric turbulence;motion estimation;intentional motion estimation;compensation;drift phenomenon;real aviation video data adaptive compensation algorithm small uav image stabilization unmanned aerial vehicle system uav platform real time observation atmospheric turbulence compensation image intentional motion estimation image information image jitter;drift phenomenon digital image stabilization intentional motion estimation;digital image stabilization;video signal processing adaptive control atmospheric turbulence autonomous aerial vehicles compensation jitter motion estimation;jitter;autonomous aerial vehicles	Today, there are an increasing number of Unmanned Aerial Vehicle (UAV) platforms being equipped with video for real-time observation. Unmanned Aerial Vehicle Systems (UAVs) have been generally used in a great variety of missions because of its inexpensiveness and flexibility. However, UAV often experience unintended translation and rotation due to atmospheric turbulence. And it leads the compensation image to losing lots of information when the large drift occurs. In order to get rid of the unwanted jitter and retain the most information, an estimate of the intentional motion is necessary. This paper presents a novel approach to estimating the intentional motion by adaptive compensation algorithm. And it can retain image information and remove image jitter when the pre-path is deemed to be a straight line. The method has been demonstrated through a series of experiments on real aviation video data.	aerial photography;algorithm;experiment;real-time locating system;turbulence;unmanned aerial vehicle	Lu Wang;Hongying Zhao;Shiyi Guo;Ying Mai;Sijie Liu	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6350400	computer vision;simulation;jitter;adaptive control;quarter-pixel motion;computer science;motion estimation;control theory	Robotics	62.912602524911435	-36.05043282411675	81320
08fa775b096cfc51efda6f6c0acac070c3c2b060	error analysis in strapdown ins for aircraft assembly lines	inertial measurement units;gyroscopes;interpolation;instrumentation;error analysis aircraft assembly systems optical sensors inertial navigation manuals gyroscopes instruments magnetic field measurement control systems;probability density function;inertial navigation;aerospace industry;inertial measurement unit;instrumentation inertial navigation systems ins boresighting inertial measurement units gyroscopes;assembly;error analysis;inertial navigation systems ins;mathematical model;gyroscopes error analysis aircraft assembly lines inertial measurement units aeronautics applications error dynamics analysis;humans;inertial navigation aerospace industry error analysis gyroscopes;boresighting;aircraft;dynamic analysis;inertial navigation system	This work proposes a methodology for assessing the use of commercial inertial measurement units in manual part alignment operations with high precision requirements, found in aircraft assembly lines. The underlying application is a situation where two separate parts must be mounted at different locations within a facility, guaranteeing a precise angular alignment between them. If, for construction reasons, there is no direct sight between both elements, optical methods must be ruled out and the problem can be tackled by means of inclinometers. However, their precision are often limited compared to standard requirements in aeronautics applications. In this paper we propose a method based on two inertial navigation systems, and provide the tools necessary for determining the precision requirements for the gyroscopes and IMUs involved, based on error dynamics analysis and simulation.	angularjs;computational auditory scene analysis;error analysis (mathematics);gyroscope;inertial navigation system;kinesiology;numerical analysis;numerical integration;programming tool;requirement;resultant;simulation;spline (mathematics);spline interpolation	Fabio Gómez-Estern;Francisco Gordillo	2008	2008 10th International Conference on Control, Automation, Robotics and Vision	10.1109/ICARCV.2008.4795514	control engineering;simulation;aerospace engineering;engineering;inertial navigation system;statistics	Robotics	60.66275299708656	-36.017046785567025	81600
ab186297aad8ba19c824b28cc00f60d6b2fe8cb0	dynamic graph-search algorithm for global path planning in presence of hazardous weather	graph search;lazy theta;tecnologia industrial tecnologia mecanica;aircraft path planning;tecnologia electronica telecomunicaciones;tecnologias;grupo a;uav 3d trajectories	This paper discusses several alternatives, based on graph search, to calculate UAV trajectories that avoid regions with dangerous weather effects and with the least deviation from the shortest trajectory. It is also explained how to adapt graph search algorithms to be used for 3D trajectories with UAVs, and which design considerations should be taken into account (for example the discretization of the airspace). Also, an extension of the Lazy Theta* algorithm is presented; a dynamic algorithm that calculates the trajectory while the weather hazards information is updated. The paper includes simulations and experimental results in the CATEC testbed with multiple UAVs.	discretization;dynamic problem (algorithms);facebook graph search;graph traversal;lazy evaluation;motion planning;search algorithm;simulation;testbed;unmanned aerial vehicle	Marcelo H. Garcia;Antidio Viguria;Aníbal Ollero	2013	Journal of Intelligent and Robotic Systems	10.1007/s10846-012-9704-7	simulation;artificial intelligence;machine learning	Robotics	53.9910459817163	-25.860989450886127	81978
1add4d6b78bf64c8517e2bb749d5ce2c3c3a0ad5	towards the automatic scanning of indoors with robots	indoor scanning;automatic 3d digitization;bim;lidar sensors	This paper is framed in both 3D digitization and 3D data intelligent processing research fields. Our objective is focused on developing a set of techniques for the automatic creation of simple three-dimensional indoor models with mobile robots. The document presents the principal steps of the process, the experimental setup and the results achieved. We distinguish between the stages concerning intelligent data acquisition and 3D data processing. This paper is focused on the first stage. We show how the mobile robot, which carries a 3D scanner, is able to, on the one hand, make decisions about the next best scanner position and, on the other hand, navigate autonomously in the scene with the help of the data collected from earlier scans. After this stage, millions of 3D data are converted into a simplified 3D indoor model. The robot imposes a stopping criterion when the whole point cloud covers the essential parts of the scene. This system has been tested under real conditions indoors with promising results. The future is addressed to extend the method in much more complex and larger scenarios.	3d scanner;algorithm;automated planning and scheduling;cns disorder;data acquisition;data redundancy;large;mobile robot;operating system;partial;point cloud;preparation;robot (device);robot control;scanner device component;scanning systems;solutions;stage level 1;system of measurement	Antonio Adán;Blanca Quintana;Andrés S. Vázquez;Alberto Olivares;Eduardo Parra;Samuel Prieto	2015		10.3390/s150511551	building information modeling;embedded system;computer vision;simulation;telecommunications;engineering	Robotics	53.80263095913152	-34.99970867616343	82107
c5adb8e008f1dc8d3e7e9b40ce45fa3bcc52bf4a	speed control for quadruped using duty factor	gait transition;velocity control legged locomotion robot dynamics motion control;mobile robots crawling quadruped robot legged locomotion duty factor wave gait gait transition speed control;velocity control;motion control;legged locomotion;foot;mobile robots;velocity control leg legged locomotion kinematics algorithm design and analysis ground support foot stability robots;kinematics;stability;wave gait;duty factor;robots;ground support;robot dynamics;speed control;quadruped robot;algorithm design and analysis;leg;crawling	This work deals with the design of a locomotion algorithm that changes the speed of a crawling quadruped by varying the duty factor /spl beta/. The walking pattern used is the well-known wave gait. This kind of gait should be maintained as much as possible since it is the most efficient locomotion pattern on flat ground. However, the transition between initial and final gaits cannot be based on a wave gait any more because support legs have to be resynchronized according to a new duty factor. This paper proposes an algorithm that deals with the gait transition between initial and final duty factors.	duty cycle	Vincent Hugel;Patrick Bonnin;Pierre Blazevic	2000		10.1109/IROS.2000.893147	robot;control engineering;motion control;mobile robot;algorithm design;effect of gait parameters on energetic cost;kinematics;simulation;stability;computer science;artificial intelligence;crawling;control theory;electronic speed control;duty cycle;foot	Robotics	67.04174285494791	-24.20486356478107	82238
18d4f415b39650006d92e42345264c33750273d0	learning basketball dribbling skills using trajectory optimization and deep reinforcement learning		Basketball is one of the world's most popular sports because of the agility and speed demonstrated by the players. This agility and speed makes designing controllers to realize robust control of basketball skills a challenge for physics-based character animation. The highly dynamic behaviors and precise manipulation of the ball that occur in the game are difficult to reproduce for simulated players. In this paper, we present an approach for learning robust basketball dribbling controllers from motion capture data. Our system decouples a basketball controller into locomotion control and arm control components and learns each component separately. To achieve robust control of the ball, we develop an efficient pipeline based on trajectory optimization and deep reinforcement learning and learn non-linear arm control policies. We also present a technique for learning skills and the transition between skills simultaneously. Our system is capable of learning robust controllers for various basketball dribbling skills, such as dribbling between the legs and crossover moves. The resulting control graphs enable a simulated player to perform transitions between these skills and respond to user interaction.	human–computer interaction;mathematical optimization;motion capture;nonlinear system;reinforcement learning;robust control;trajectory optimization	Libin Liu;Jessica K. Hodgins	2018	ACM Trans. Graph.	10.1145/3197517.3201315	artificial intelligence;computer vision;simulation;computer science;motion control;basketball;trajectory optimization;reinforcement learning	Graphics	62.397496333987846	-24.403192939261242	82354
bdecd2a5fc4f860675223a4fce3b302df4ad072a	simulation of a system architecture for cooperative robotic cleaning		The increase of the use of Autonomous Vehicles in different types of environments leads to an improvement of the Localization and Navigation algorithms. The goal is to increase the levels of efficiency, security and robustness of the system, minimizing the tasks completion time. The application of cleaning robots in domestic environments have several advantages however some improvements should be performed in order to develop a robust system. Also in large spaces one robot doesn’t achieve the desired performance in terms of robustness to faults and efficiency in the cleaning process. Considering a fleet of autonomous robots, this process could be improved. The purpose of our paper is the presentation of an architecture for management a fleet of cleaning robots, considering a complete coverage path planning for large and structured environments. Compartments are found in a grid-like decomposition and an area coverage strategy are evolved (optimized) by using Genetic Algorithms. The Task allocation module is based on Auctions strategy, thus obtaining cooperation under dynamic constraints in complex environments. The case study optimizes the number of robots involved in the cooperative cleaning of a full building in the campus, based on its real architectural plans.	algorithmic efficiency;autonomous robot;bi-directional text;centralized computing;computer security;computer-aided design;experiment;genetic algorithm;motion planning;plasma cleaning;robustness (computer science);simulation;sputter cleaning	Hugo Costa;Pedro Tavares;Joana Santos;Vasco Rio;Armando Sousa	2015		10.1007/978-3-319-27146-0_55	simulation	Robotics	56.09695095820308	-26.289031944440815	82549
d21b12524bdabf7d755f327d1c84b16e5bd92b36	total least squares in robot calibration	sensor calibration;total least square	The role of input noise is seldom considered in robot calibration. The methodology of total least squares may be applied to handle both input and output noise in robot calibration. Experimentally, we apply this method towards joint torque sensor calibration, and towards kinematic calibration of a redundant parallel-drive spherical joint in a variant called the implicit loop method.	experiment;input/output;ordinary least squares;robot calibration;total least squares	John M. Hollerbach;Ali Nahvi	1995		10.1007/BFb0035218	computer science	Robotics	57.391353951707586	-36.4578733323156	82559
6ed92f7aea84b66ccb4b2fb8dde81b29da43dcac	on the performance of state estimation for visual servo systems	lens distortion;state estimation servomechanisms machine vision robot sensing systems computer vision robot vision systems robot control lenses analytical models sampling methods;real time;state feedback;state estimation;computer vision;blurring visual servo systems computer vision real time state estimation feedback control systems visual state estimation detailed camera model image plane position estimation algorithm single circular feature lens distortion noise defocus;state feedback state estimation computer vision robots servomechanisms;servomechanisms;robots;position estimation;visual servoing;feedback control	Brad Bishop Seth Hutchinson Mark Spong Coordinated Science Lab Elect. and Comp. Eng. Coordinated Science Lab University of Illinois University of Illinois University of Illinois Urbana, IL 61801 Urbana, IL 61801 Urbana, IL 61801 Abstract In this paper we discuss the use of computer vision for real{time state estimation in feedback control systems. To this end, we construct a system for visual state estimation of simple state vectors and study the e ects of various real{world disturbances on the state estimates. Simulations are performed using a detailed camera model to study the performance of an image plane position estimation algorithm for a single circular feature. Various disturbances, such as lens distortion, noise, defocus, and blurring are simulated and analyzed with respect to this estimation routine and visual state estimation in general.	algorithm;computer simulation;computer vision;control system;distortion;feedback;image noise;image plane;my life as a teenage robot;servo	Bradley Bishop;Seth Hutchinson;Mark W. Spong	1994		10.1109/ROBOT.1994.350993	distortion;robot;control engineering;computer vision;computer science;artificial intelligence;control theory;feedback;visual servoing	Robotics	60.035185053827945	-32.48325828600288	82719
58672e93da7913bf744d9e21da18db036d7d7a40	agilo robocuppers: robocup team description	robocup team description;fg bv;single board computer;fused data;single consistent view;image understanding group;agilo robocuppers1 team;ccd camera;image processing library halcon;middle size;technische universit	This paper describes the Agilo RoboCuppers 1 – the RoboCup team of the image understanding group (FG BV) at the Technische Universität München. With a team of five Pioneer 1 robots, equipped with CCD camera and a single board computer each and coordinated by a master PC outside the field we participate in the Middle Robot League of the Third International Workshop on RoboCup in Stockholm 1999. We use a multi-agent based approach to represent different robots and to encapsulate concurrent tasks within the robots. A fast feature extraction based on the image processing library HALCON provides the data necessary for the onboard scene interpretation. In addition, these features as well as the odometric data of the robots are sent over the net to the master PC, where they are verified with regard to consistency and plausibility and fusioned to one global view of the scene. The results are distributed to all robots supporting their local planning modules. This data is also used by the global planning module coordinating the team’s behaviour.	agent-based model;charge-coupled device;computer vision;feature extraction;image processing;job control (unix);multi-agent system;plausibility structure;robot;single-board computer	Thorsten Bandlow;Robert Hanek;Michael Klupsch;Thorsten Schmitt	1998		10.1007/3-540-45327-X_83	planning;computer vision;simulation;decision support system;data processing;image processing;decentralised system;computer science;artificial intelligence;robotics;charge-coupled device	Robotics	57.75176249458074	-31.881874219582095	82843
b0a1ef335ebf5292be34a9f9839cf9540f3a0a08	new visibility-based path-planning approach for covert robotic navigation	stealth navigation;mobile robot;distance transform dt;path planning;robot navigation;visibility based path planning	A new promising approach for visibility-sensitive path-planning problems is presented. The paper focuses on covert navigation where a mobile robot needs to plan a stealthy path to approach a designated destination in a cluttered environment. The aim is to minimize the robot's exposure to hostile sentries within the same environment. The approach can be adapted to work with different levels of initial knowledge the robot may have about both the environment map and the sentries' locations. The approach depends on estimating a cost value at each free-space location that presents the risk of being seen by any sentry. Based on the distance transform algorithm methodology, the minimum visibility–distance cost to a goal is calculated at each cell in the grid-based environment map. Moving along the steepest descent trajectory from any starting point generates an optimal covert path to a goal. The approach has been evaluated with both simulated and physical experiments. A number of test cases are presented. In each case, a path with considerable covertness, compared to a short path to the same destination, is generated. In addition to covert navigation, the approach is introduced briefly as a potential solution for other visibility-based path-planning problems.	motion planning;robot;robotic mapping	Mohamed Marzouqi;Ray A. Jarvis	2006	Robotica	10.1017/S0263574706002931	mobile robot;computer vision;simulation;computer science;artificial intelligence;motion planning;mobile robot navigation	Robotics	54.09352497517014	-25.26454304946064	83016
4b7408c6b3195ca49b2461f915055a6b8dc9ebad	combining end-effector and legs observation for kinematic calibration of parallel mechanisms	jacobian matrix;mecanismo paralelo;contraste;matrice jacobi;redundancia;prensor robot;localization;cinematica;robot vision end effector observation legs observation kinematic calibration parallel mechanisms metrological redundancy jacobian matrix calibration methods;parallel mechanism;experimental procedure;localizacion;kinematics;manipulator kinematics;prehenseur;jacobi matrix;localisation;robot vision;leg kinematics calibration redundancy jacobian matrices cameras volume measurement neutron spin echo position measurement joining processes;redundancy;mecanisme parallele;matriz jacobi;cinematique;etalonnage;mecanisme articule;mecanismo articulado;gripper;jacobian matrices;calibration;robot vision end effectors manipulator kinematics jacobian matrices calibration redundancy;redondance;linkage mechanism;end effectors	In this paper, an original approach is proposed for the kinematic calibration of parallel mechanisms. The originality lies in the use of vision to get information on all parts of the mechanism, i.e. its end-effector as well as its legs. Metrological redundancy is therefore maximized to improve the calibration efficiency. The approach is implemented for the calibration of the I4 parallel mechanism, with the use of the Jacobian matrix. No accurate camera location is needed so that the experimental procedure is easy to achieve. The calibration algorithm is detailed and experimentally demonstrated more efficient than other calibration methods based on legs observation or end-effector observation.	algorithm;experiment;jacobian matrix and determinant;robot end effector;triple modular redundancy	Pierre Renaud;Nicolas Andreff;François Pierrot;Philippe Martinet	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1308916	jacobian matrix and determinant;computer vision;simulation;computer science;control theory;mathematics;robot calibration	Robotics	59.70813098682375	-35.856890586605786	83025
3fd0e2d210b586bc6bde8810cbf12cbd8c841036	high-accuracy dimensional measurement of cylindrical components by an automated test station based on confocal chromatic sensor		This paper presents the design and characterization of a test station for high-accuracy dimensional measurement of cylindrical components; it is conceived for quality control of turned parts. The system is based on a confocal chromatic sensor and a four degree of freedom scanning system. The station is capable of smart behaviors, which allow to keep measurement uncertainty under control: in particular self-centering of the confocal sensor inside the cylindrical part under inspection, self compensation of temperature effects and self calibration check. Results show how the test station can achieve uncertainty in the range of 10 μn.	sensor	Paolo Chiariotti;Matteo Fitti;Paolo Castellini;Saverio Zitti;Marco Zannini;Nicola Paone	2018	2018 Workshop on Metrology for Industry 4.0 and IoT	10.1109/METROI4.2018.8428340	confocal;process control;chromatic scale;calibration;temperature measurement;electronic engineering;measurement uncertainty;cylinder;physics	Mobile	60.72699484471856	-37.05653243145609	83160
a569d3adf7d3988da504b668ccaa726ffc19113b	range-limited uav trajectory using terrain masking under radar detection risk	uav;terrain masking;radar	Military manned and unmanned aerial vehicles UAVs may perform missions in contested airspace, where survival of the vehicle requires avoidance of hostile radar coverage. This research sought to determine optimum flight-path routes that make maximum utilization of UAV terrain-masking opportunities and flight range capability to avoid radar detection. The problem was formulated as one of constrained optimization in three dimensions; advantageous solutions were identified using Algorithm A*. Topographical features were exploited by the algorithm to avoid radar detection. The model included provisions for preferred altitude ranges, adjustable aircraft climb-and descent-rate envelopes, movement costs based on fractional detection probability, radar horizon masking, and simulated radar cross-section lookup tables.	radar;unmanned aerial vehicle	Michael Pelosi;Carlo Kopp;Michael Scott Brown	2012	Applied Artificial Intelligence	10.1080/08839514.2012.713308	man-portable radar;computer vision;radar engineering details;simulation;radar lock-on;radar configurations and types;fire-control radar;radar horizon;3d radar;procedural control;radar	AI	54.70651235671892	-26.603686531124286	83202
cddde6be9c6057b732c856c1cfdcaef880e00b34	motion constraints simulation based on matlab and haptic interface	matlab haptic interfaces robots virtual reality fixtures motion control control systems man machine systems collaboration imaging phantoms;robot trajectory motion constraints simulation matlab haptic interface serial robotic arm virtual reality world guidance virtual fixture control law human machine collaborative system haptic device phantom desktop master device virtual robot manipulator slave device force feedback haptic assisted system robot kinematics;motion control;virtual reality control engineering computing force feedback haptic interfaces manipulator kinematics man machine systems motion control position control;fixtures;haptic device;virtual reality;collaborative system;manipulator kinematics;force;force feedback;robot arm;position control;mathematical model;control engineering computing;haptic interfaces;man machine systems;matlab;robot kinematics;haptic interface	This paper proposes a system to simulate the motion constraints on the serial robotic arm in the virtual reality world. The concept of guidance virtual fixture is involved in the control law of the human-machine collaborative system, which guides the user's motion along the preferred direction while preventing the disturbance along the non-proffered direction. Haptic device, Phantom Desktop™, is used as the master device to manipulate the virtual robot as the slave device in the MATLAB and feeds back the force to the user. We proposed this method and haptic assisted system to simulate the kinematics and trajectory of the robot when user doing the manipulation. The simulation results verify the validity of our scheme.	3d computer graphics;haptic technology;matlab;optimal control;robot;robotic arm;robotics;simulation;test fixture;vrml;virtual fixture;virtual reality	Lin Qi;Max Q.-H. Meng	2009	2009 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2009.5420586	control engineering;computer vision;simulation;computer science;engineering;artificial intelligence;virtual reality;haptic technology	Robotics	68.18758201588436	-26.42097744522426	83641
05ccc7008e3592be6e773641763354fcdce01ccb	extensive and efficient search of human movements with hierarchical reinforcement learning	positional constraints;human movement;virtual reality learning artificial intelligence;virtual characters;search space;path planning;reinforcement learning;multiple key frames;virtual reality;virtual human;joints;automatic generation;skeleton;mechanical structures;human movements;endeffectors;learning systems;humans joints computational efficiency animation kinetic theory path planning skeleton leg learning systems optimization methods;kinetic theory;postures;searching space human movements hierarchical reinforcement learning positional constraints endeffectors multiple key frames postures mechanical structures virtual characters;animation;global optimization;humans;learning artificial intelligence;hierarchical search;computational efficiency;searching space;motion generation;leg;hierarchical reinforcement learning;optimization methods;discrete sampling	This paper proposes a method for creating human movements by imposing positional constraints of endeffectors at multiple key-frames. We introduce hierarchical reinforcement learning for efficiently searching postures at each key-frame among the huge number of possible candidates. The mechanical structures of virtual characters are also hierarchically decomposed so as to suit the learning mechanism, and each hierarchy prepares templates of discretely sampled postures for narrowing down the searching space. Our method automatically generates complex movements so that the resulting motions are globally optimized for a whole sequence.	computation;computer animation;intelligent user interface;key frame;plausibility structure;poor posture;reinforcement learning;sampling (signal processing)	Tomohiko Mukai;Shigeru Kuriyama;Toyohisa Kaneko	2002		10.1109/CA.2002.1017515	simulation;computer science;artificial intelligence;machine learning	AI	61.69716619103129	-24.8271400189596	83811
16430f506315c34bdb9b1d220ecf150a9bda7b88	research on automotive rear-end collision warning technology	road accidents;introduction;road traffic;sensor fusion alarm systems automated highways computer vision millimetre wave radar optical radar road accidents road traffic road vehicle radar;automated highways;multisensor information fusion technology automotive rear end collision warning technology freeway development traffic accidents arcwt machine vision radar;laser radar;road vehicle radar;introduction intelligent transportation rear end collision warning machine vision radar;computer vision;distance measurement;intelligent transportation;accidents;optical radar;machine vision;radar imaging;vehicles;sensor fusion;alarm systems;vehicles laser radar machine vision radar imaging accidents distance measurement;millimetre wave radar;radar;rear end collision warning	Nowadays with the development of freeway the traffic accidents have been increasing. Among the accidents, the rear-end collisions account for a large proportion and the researches on Automotive Rear-end Collision Warning Technology (ARCWT) have become a hot topic. In this paper, we talk about the Automotive Rear-end Collision Warning Technology, such as ARCWT based on machine vision, ARCWT based on radar and so on, analyzing their principles, features and disadvantages in details and introducing the ARCWT based on the multi-sensor information fusion techno-logy. At last, the trend of ARCWT is proposed.	freeway;machine vision	Ke-you Guo;Bin Ji;Hu-ming Jiang	2012	2012 Third International Conference on Digital Manufacturing & Automation	10.1109/ICDMA.2012.159	computer vision;simulation;engineering;remote sensing	EDA	55.630415215912635	-31.80910031754452	83916
79d36a6a078e4968d829707496b410407a5ab893	development of legged robots for use in disordered environments	control systems;silicon carbide;sensors;mobile robot;speech processing;environmental conditions;mobile robots;physical oceanography;digital control;legged robot	The SIC/R laboratory is conducting a research program called Autonomy of Mobile Robots in Unstructured Environments (AMRU), focusing on the realization of light low-cost legged robots for indoor and outdoor applications, study of image and speech processing, development of path planners. This paper summarizes the description of the first four robots (AMRU 1 to 4) of the table 1. Low cost allows the sacrifice and the replacement of the robots used in dangerous environmental conditions (minefield, battlefield, nuclear site, etc.) and implies the choice of low level proprioceptive and exteroceptive sensors coupled with a simple digital control system, light structure facilitates their transportation (by air, land or sea) to the application site.© (1995) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	robot	Yvan Baudoin;Paul Alexandre	1995		10.1117/12.228966	mobile robot;simulation;telecommunications;physical oceanography;speech processing;robot control	Robotics	56.28248956779495	-30.699649919428147	84026
5e248ffc8a63ed0391fdc1735e4a4aeea3899e9f	bearings-only path following with a vision-based potential field	control action bearings only path following vision based potential field vision based path following algorithm nonholonomic wheeled platform potential field cost function leader follower image collection forward prediction step differential gps outdoor environment;wheels image matching path planning robot vision;cost function cameras vehicles trajectory robot vision systems convergence	In this paper, we present a vision-based path following algorithm for a non-holonomic wheeled platform. The algorithm is based on choosing control actions that minimise the value of a potential field cost function calculated directly from the image plane. The algorithm is suitable for teach and replay or leader follower implementations where the desired path is represented as a collection of images. The algorithm computes the cost function based on the relative bearings of features matched between the current and previously observed images. A forward prediction step is then used to determine the control action that will lead to the greatest reduction in the cost function. The algorithm is demonstrated on a 400 m path in an outdoor environment where the accuracy is shown to be similar to that of differential GPS.	approximation algorithm;collision detection;differential gps;global positioning system;image plane;loss function;mobile robot	Deon George Sabatta;Roland Siegwart	2014	2014 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2014.6942939	control engineering;computer vision;simulation;engineering	Robotics	54.42050517851868	-35.04214724567581	84162
becedb33b864a54252fc9785d7838cda02021fca	tele-driving system with command data compensation for long-range and wide-area planetary surface explore mission	tele driving system;moon navigation delay path planning virtual environment extraterrestrial measurements earth communication system control supervisory control data engineering;environmental map;command path;reliability;command data compensation;virtual world simulator;supervisory control;lunar rover;path planning;earth;long range wide area planetary surface explore mission;mobile robots compensation planetary rovers telerobotics path planning reliability delays;mobile robots;data engineering;planetary rovers;navigation;compensation;moon;long range wide area planetary surface explore mission tele driving system lunar rover virtual world simulator command path path planning environmental map command data compensation;telerobotics;communication delay;long range;virtual environment;communication system control;extraterrestrial measurements;delays;virtual worlds	In this paper, we discuss tele-driving method for a long driving of a lunar rover. An operator uses virtual world simulator to make command path. The virtual environment of this simulator is constructed with measurement data from a rover on the moon. We have, however, a communication delay between the earth and the moon. So, there is the dsference between old map data which operator used for path planning and new data, which a rover is tracking on. The operator's path command has less reliability to avoid obstacles and to reach the goal. Therefore, to make high reliability of operator's command, we propose Command-Data Compensation (CDC), which compensates this difference as the distortion of the environmental map.	distortion;google lunar xprize;motion planning;planetary scanner;rover (the prisoner);simulation;television;virtual reality;virtual world	Yasuharu Kunii;Kouhei Tada;Yoji Kuroda;Takashi Kubota	2001		10.1109/IROS.2001.973343	telerobotics;mobile robot;computer vision;navigation;simulation;information engineering;computer science;natural satellite;virtual machine;artificial intelligence;reliability;motion planning;earth;supervisory control;remote sensing	Robotics	62.24094279155245	-29.96020064200251	84216
b32098f3ac8d95c352bca12fb23dc6daec38a19b	autonomous uav navigation using reinforcement learning		Unmanned aerial vehicles (UAV) are commonly used for missions in unknown environments, where an exact mathematical model of the environment may not be available. This paper provides a framework for using reinforcement learning to allow the UAV to navigate successfully in such environments. We conducted our simulation and real implementation to show how the UAVs can successfully learn to navigate through an unknown environment. Technical aspects regarding to applying reinforcement learning algorithm to a UAV system and UAV flight control were also addressed. This will enable continuing research using a UAV with learning capabilities in more important applications, such as wildfire monitoring, or search and rescue missions.	aerial photography;algorithm;mathematical model;q-learning;reinforcement learning;simulation;software deployment	Huy X. Pham;Hung Manh La;David Feil-Seifer;Luan Van Nguyen	2018	CoRR		engineering;simulation;reinforcement learning	Robotics	55.13476024152774	-28.292454976127868	84396
31f10c30b43063c555f766f90f8b121d2715af95	research on autonomous navigation of lunar rovers for the moon exploration	levenberg marquardt;stereo images;feature detection;image processing;image matching;lunar rover;path planning;feature tracking;motion estimation;mobile robots;motion estimation moon exploration lunar rover autonomous navigation stereo vision sun sensor;robust linear motion estimation;feature matching;estimation algorithm;moon navigation motion estimation motion analysis image processing computer vision image analysis algorithm design and analysis image motion analysis estimation error;planetary rovers;development tool;navigation;lunar rovers;robot vision;feature extraction;stereo image processing;stereo vision;weighted zssd algorithm;moon exploration;open inventor;stereo image processing feature extraction image matching mobile robots motion estimation navigation nonlinear estimation path planning planetary rovers robot vision;nonlinear estimation;autonomous navigation;virtual simulation system;long range;levenberg marquardt nonlinear estimation;virtual simulation system autonomous navigation lunar rovers moon exploration image processing feature detection feature tracking feature matching robust linear motion estimation levenberg marquardt nonlinear estimation sun sensor weighted zssd algorithm open inventor stereo images;sun sensor	In order to explore the moon more efficiently, it is very important to endow lunar rovers with increased autonomy both for exploration achievement of scientific goals and for safe navigation. In this paper, autonomous navigation techniques for lunar rovers are discussed, and an autonomous navigation scheme is presented. First, algorithm and technique of initial position determination of lunar rovers are introduced. Then, matched-features set is build by multi steps of image processing such as feature detection, feature tracking and feature matching. Based on the analysis of the image processing error, a two-stage estimation algorithm is used to estimate the motion, robust linear motion estimation is executed to estimate the motion initially and to reject the outliers, and Levenberg-Marquardt nonlinear estimation is used to estimate the motion precisely. The sun sensor is used to update the rover's heading periodically for long range navigation. Next, a weighted ZSSD algorithm is presented to estimate the image disparities by analyzing the traditional ZSSD. Finally, a virtual simulation system is constructed using the development tool of Open Inventor, this simulation system can provide stereo images for simulations of stereo vision and motion estimation techniques, simulation results are provided and future research work is addressed in the end.	autonomous robot;binocular disparity;course (navigation);distortion;feature detection (computer vision);feature detection (web development);feature model;google lunar xprize;image processing;levenberg–marquardt algorithm;motion estimation;nonlinear system;open inventor[by fei];rover (the prisoner);simulation;stereopsis	Pingyuan Cui;Fuzhan Yue;Hutao Cui	2006	2006 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2006.340372	mobile robot;computer vision;navigation;simulation;levenberg–marquardt algorithm;image processing;feature extraction;computer science;stereopsis;motion estimation;feature detection;motion planning;remote sensing	Robotics	54.21449633604092	-35.54245467187444	84407
29c15ffadb44b61e67a7c9e0e47bcc70c26d44cd	3d reconstruction of real world scenes using a low-cost 3d range scanner	tratamiento datos;modelizacion;realite virtuelle;modelo 3 dimensiones;realidad virtual;modele 3 dimensions;reconstruction;virtual reality;data processing;three dimensional model;scanneur;traitement donnee;developpement produit;data fusion;escaner;scanner;modelisation;fusion donnee;telemetria;fusion datos;modeling;desarrollo producto;3d reconstruction;range finding;telemetrie;reconstruccion;product development	This paper presents a 3D reconstruction technique for real world environments based on a traditional 2D laser range finder modified to implement a 3D laser scanner. The paper describes the mechanical and control issues addressed to achieve physically the 3D sensor as well as the adaptation of some previously developed techniques used to merge range and intensity data and illustrates the potential of such a unit. The result is a promising system for 3D modelling of real world scenes at a commercial price 10 or 20 times lower than current commercial 3D laser scanners.	3d modeling;3d reconstruction;3d scanner	Paulo Dias;Miguel Matos;Vítor M. F. Santos	2006	Comp.-Aided Civil and Infrastruct. Engineering	10.1111/j.1467-8667.2006.00453.x	3d reconstruction;computer vision;simulation;systems modeling;data processing;computer science;sensor fusion;virtual reality;new product development	Robotics	62.56289975022045	-37.31110354484571	84527
e52dbc9d2e727a149bec882ec82760ca98e33c6c	cellular sensor-processor array based visual collision warning sensor	arrays aircraft noise field programmable gate arrays machine vision collision avoidance kernel;focal plane sensor processor;qa75 electronic computers computer science szamitastechnika;uav;kernel;szamitogeptudomany;arrays;machine vision;fpga cellular sensor processor array based visual collision warning sensor on board vision system collision avoidance small form factor vision system low power consumption natural payload limitations uav collision warning algorithm mixed signal sensor processor array;remote aircraft detection;collision avoidance;field programmable gate arrays;fine grain cellular processor array;sensor arrays autonomous aerial vehicles cellular arrays collision avoidance image sensors mixed analogue digital integrated circuits navigation robot vision;aircraft;noise;remote aircraft detection focal plane sensor processor fine grain cellular processor array uav	Autonomous UAVs need on-board vision system to be able to navigate, avoid collisions, and execute missions. Small UAVs can carry small form factor vision system with low power consumption due to natural payload limitations. Therefore it is a natural idea to use cellular sensor-processor arrays to implement the necessary vision functions. In this paper, we present a UAV collision warning algorithm and its implementation on a 176×144 sized mixed-signal sensor-processor array. Besides the technical details of the implementation, the paper includes comparison with FPGA implementation of the same algorithm.	algorithm;field-programmable gate array;mixed-signal integrated circuit;on-board data handling;processor array;sensor;small form factor;unmanned aerial vehicle	Ákos Zarándy;Máté Németh;Borbala Jani Matyasne Pencz;Zoltán Nagy;Tamas Zsedrovits	2015	2015 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2015.7169061	embedded system;electronic engineering;kernel;simulation;machine vision;computer science;engineering;noise;field-programmable gate array	Embedded	56.49016365332815	-32.09058578391401	84634
5d286ff0a8bb44838ab3b1f852aaf6fd4b3a0679	integration of an adaptive swing control into a neuromuscular human walking model	legged locomotion robustness neuromuscular adaptation models hip;patient rehabilitation;biomechanics;mobile robots;prosthetics;medical robotics;distance 15 cm adaptive swing control integration neuromuscular control humanoid robot prosthetic robot neurocontroller forward dynamic simulation practical controller adaptive locomotion swing leg placement full neuromuscular human walking model integrated model rough terrain stair climbing human locomotion behavior rehabilitation robotics;prosthetics biomechanics medical robotics mobile robots neurocontrollers neurophysiology patient rehabilitation physiological models;neurocontrollers;neurophysiology;physiological models	Understanding the neuromuscular control underlying human locomotion has the potential to deliver practical controllers for humanoid and prosthetic robots. However, neurocontrollers developed in forward dynamic simulations are seldom applied as practical controllers due to their lack of robustness and adaptability. A key element for robust and adaptive locomotion is swing leg placement. Here we integrate a previously identified robust swing leg controller into a full neuromuscular human walking model and demonstrate that the integrated model has largely improved behaviors including walking on very rough terrain (±10cm) and stair climbing (15cm stairs). These initial results highlight the potential of the identified robust swing control. We plan to generalize it to a range of human locomotion behaviors critical in rehabilitation robotics.	behavior;climbing stairs;controllers;rehabilitation robotics;robot (device);simulation	Seungmoon Song;Ruta Desai;Hartmut Geyer	2013	2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2013.6610650	control engineering;mobile robot;simulation;computer science;engineering;biomechanics;control theory;physiology;neurophysiology	Robotics	67.76279232169087	-25.56632236359702	84688
dea394c7fe33b8ae87c0129c67d51e519a9a4a57	z-basic algorithm for collision avoidance system	ground based control;basic programming language;computer program;air traffic control;north america;america del norte;amerique du nord;amerique;aircraft maneuvers;air traffic computer control;air transportation;etats unis;estados unidos;compilers;algorithme;algorithm;transport aerien;collision avoidance systems;transporte aereo;macintosh personal computers;prevencion esquiva colision;aerospace computing;collision avoidance aircraft air traffic control airports faa transponders surveillance radar meteorology control systems;prevention esquive collision;airplane;avion;algorithms;collision avoidance;microcomputer applications aerospace computing air traffic computer control;macintosh air traffic computer control collision avoidance system z basic prediction algorithm aircraft basic compiler;america;microcomputer applications;prediction analysis techniques;prediction interval;algoritmo	A Z-Basic prediction algorithm for an aircraft ground-based collision avoidance system is presented. This system searches for mutually overlapping prediction intervals that are influenced by the aircraft's maneuver capabilities and surveillance accuracy. Z-Basic provides a powerful, fast, interactive, simple to use, and inexpensive Basic compiler. The algorithm is applied to a typical terminal airspace situation. The computer program was executed on Macintosh+, and the execution was less than one minute. The program is easy to understand and implement. >	algorithm	Roger G. Dear;Yosef S. Sherif	1991	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.108309	embedded system;compiler;simulation;prediction interval;computer science;artificial intelligence;air traffic control;computer security;aviation	Embedded	58.43302754823358	-28.08666711243268	84806
cba78356aa090b0545e693d034ed00fdab5c076f	a mobile robot target tracking via brain limbic system based control			mobile robot	Changwon Kim;Reza Langari	2011	I. J. Robotics and Automation	10.2316/Journal.206.2011.3.206-3439	mathematics;control engineering;limbic system;mobile robot	Robotics	58.389424152742436	-30.34716679363462	85074
7f585926187f7730e680df63508d3a255495a45f	tactile sensing in dexterous robot hands - review	dexterous manipulation;tactile sensing application;tactile sensing;tactile sensors;review;robot hands	Tactile sensing is an essential element of autonomous dexterous robot hand manipulation. It provides information about forces of interaction and surface properties at points of contact between the robot fingers and the objects. Recent advancements in robot tactile sensing led to development of many computational techniques that exploit this important sensory channel. This paper reviews current state-of-the-art of manipulation and grasping applications that involve artificial sense of touch and discusses pros and cons of each technique. The main issues of artificial tactile sensing are addressed. General requirements of a tactile sensor are briefly discussed and the main transduction technologies are analyzed. Twenty eight various tactile sensors, each integrated into a robot hand, are classified in accordance with their transduction types and applications. Previously issued reviews are focused on hardware part of tactile sensors, whereas we present an overview of algorithms and tactile feedback-based control systems that exploit signals from the sensors. The applications of these algorithms include grasp stability estimation, tactile object recognition, tactile servoing and force control. Drawing from advancements in tactile sensing technology and taking into consideration its drawbacks, this paper outlines possible new directions of research in dexterous manipulation.	algorithm;autonomous robot;control system;outline of object recognition;requirement;tactile sensor;transduction (machine learning);visual servoing	Zhanat Kappasov;Juan Antonio Corrales;Véronique Perdereau	2015	Robotics and Autonomous Systems	10.1016/j.robot.2015.07.015	computer vision;simulation;computer science;tactile sensor	Robotics	66.73360347842284	-28.932907240527772	85158
02803af321bdac1d914c67ebeb779fb275e1e8d7	optimizing the exploration efficiency of autonomous search and rescue agents using a concept of layered robust communication	robot sensing systems;telerobotics disasters path planning rescue robots;robot kinematics robot sensing systems robustness radiofrequency identification floods ieee 802 11 standard;robustness;floods;ieee 802 11 standard;search efficiency exploration efficiency autonomous search and rescue agents layered robust communication search and rescue missions disaster scenarios robot remote control cooperating robots communication methods search and rescue process;cooperation search and rescue multi agent systems ad hoc network communication;radiofrequency identification;robot kinematics	Robots deployed in Search and Rescue missions are required to act autonomously, since in disaster scenarios even a remote control of the robots might not be possible anymore. Additionally it is desirable to use several of these robots at once, since the search for survivors is a time-critical task, and the time to find victims should in the best case scale with the number of robots. In order to achieve this scaling the robots have to communicate and cooperate. This paper discusses how to optimize the search and rescue mission with multiple autonomous yet cooperating robots, evaluating different communication patterns to speed up the search process. Emphasis lies on the evaluation of the diverse types of communication methods, which can be direct, indirect or a combination thereof. Our studies show, that the combination of direct and indirect communication optimizes the search and rescue process. Further using a combined method of data transfer between the agents provides robust communication between the robots, improving the search efficiency.	autonomous robot;best, worst and average case;image scaling;optimizing compiler;remote control;speedup;window of opportunity	Florian Blatt;Matthias Becker;Helena Szczerbicka	2015	2015 IEEE 20th Conference on Emerging Technologies & Factory Automation (ETFA)	10.1109/ETFA.2015.7301424	simulation;computer science;engineering;artificial intelligence;programming language;computer security;robot kinematics;robustness	Robotics	56.305388436295246	-25.84338383162985	85173
c543ba0240c58b32baa3874498ee491fc2020545	a dddams-based planning and control framework for surveillance and crowd control via uavs and ugvs	uav;agent based simulation;ugv;surveillance;fidelity;dddams	A dynamic data driven adaptive multi-scale simulation (DDDAMS) based planning and control framework is proposed for effective and efficient surveillance and crowd control via UAVs and UGVs. The framework is mainly composed of integrated planner, integrated controller, and decision module for DDDAMS. The integrated planner, which is designed in an agent-based simulation (ABS) environment, devises best control strategies for each function of (1) crowd detection (vision algorithm), (2) crowd tracking (filtering), and (3) UAV/UGV motion planning (graph search algorithm). The integrated controller then controls real UAVs/UGVs for surveillance tasks via (1) sensory data collection and processing, (2) control command generation based on strategies provided by the decision planner for crowd detection, tracking, and motion planning, and (3) control command transmission via radio to the real system. The decision module for DDDAMS enhances computational efficiency of the proposed framework via dynamic switching of fidelity of simulation and information gathering based on the proposed fidelity selection and assignment algorithms. In the experiment, the proposed framework (involving fast-running simulation as well as real-time simulation) is illustrated and demonstrated for a real system represented by hardware-in-the-loop (HIL) real-time simulation integrating real UAVs, simulated UGVs and crowd, and simulated environment (e.g. terrain). Finally, the preliminary results successfully demonstrate the benefit of the proposed dynamic fidelity switching concerning the crowd coverage percentage and computational resource usage (i.e. CPU usage) under cases with two different simulation fidelities.		Amirreza M. Khaleghi;Dong Xu;Zhenrui Wang;Mingyang Li;Alfonso Lobos;Young-Jun Son	2013	Expert Syst. Appl.	10.1016/j.eswa.2013.07.039	computer vision;simulation	Robotics	56.07953632241489	-26.514291229721383	85347
c16afab25a287f0c2d1bb1b60096093e901f7239	auv localization using visual information of underwater structures	auv;basin environment autonomous underwater vehicle auv localization visual information underwater structure inertial navigation system ins;localization auv vision;localization;slam robots autonomous underwater vehicles inertial navigation marine systems mobile robots robot vision;vision;atmospheric measurements particle measurements robots	In this paper, we propose a method of AUV localization using visual measurement of underwater structures. Since the inertial navigation system (INS) of AUV suffers from drift, observing fixed objects can enhance the localization performance. The proposed method is validated by experiments performed in a structured basin environment.	experiment;inertial navigation system	Jongdae Jung;Hyun Myung	2015	2015 12th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2015.7358942	vision;computer vision;simulation;internationalization and localization;computer science	Robotics	54.273946708958235	-36.08960738502079	85615
3a5a716dabb5396600cecb83d8e6d3f1f68e1d77	wearable obstacle avoidance electronic travel aids for blind: a survey	aide handicape;handicapped aid;wearable obstacle detection systems;navegacion;wearable obstacle avoidance;wearable systems;locator;esquiva colision;ayuda minusvalido;evaluation performance;vision disorder;obstacle detection;performance evaluation;localisateur;trouble de la vision;informacion incompleta;electronic travel aids;evaluacion prestacion;wearable computers;wearable computers collision avoidance computerised instrumentation handicapped aids;indice aptitud;wearable obstacle detection systems wearable obstacle avoidance electronic travel aids wearable navigation systems visually impaired people blind people electronic orientation aids position locator devices;state estimation;reference point;blind people;user assistance;incomplete information;indice aptitude;navigation;hierarchical classification;visually impaired people;handicapped aids;eyes;installation exterieure;assistance utilisateur;obstacle avoidance;instalacion exterior;outdoor installation;capability index;navigation systems;displays;asistencia usuario;information incomplete;time of arrival estimation;position locator devices;navigation time of arrival estimation cameras displays feedback amplifiers state estimation eyes automation computer science object detection;assistive technology;classification hierarchique;electronic orientation aids;wearable systems electronic travel aids navigation systems obstacle avoidance survey;visual impairment;feedback amplifiers;navigation system;collision avoidance;computer science;computerised instrumentation;esquive collision;trastorno vision;indoor installation;instalacion interior;survey;clasificacion jerarquizada;installation interieure;cameras;object detection;localizador;wearable navigation systems;automation	The last decades a variety of portable or wearable navigation systems have been developed to assist visually impaired people during navigation in known or unknown, indoor or outdoor environments. There are three main categories of these systems: electronic travel aids (ETAs), electronic orientation aids (EOAs), and position locator devices (PLDs). This paper presents a comparative survey among portable/wearable obstacle detection/avoidance systems (a subcategory of ETAs) in an effort to inform the research community and users about the capabilities of these systems and about the progress in assistive technology for visually impaired people. The survey is based on various features and performance parameters of the systems that classify them in categories, giving qualitative-quantitative measures. Finally, it offers a ranking, which will serve only as a reference point and not as a critique on these systems.	assistive technology;obstacle avoidance;online locator service;programmable logic device;wearable computer	Dimitrios Dakopoulos;Nikolaos G. Bourbakis	2010	IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)	10.1109/TSMCC.2009.2021255	embedded system;computer vision;navigation;simulation;wearable computer;process capability index;computer science;artificial intelligence;automation;obstacle avoidance;complete information	HCI	56.86997046546442	-33.015541274027754	85656
00b40d16ae6c0691d32bc9d5a222e3b0e120bcd4	a hybrid teleoperation control scheme for a single-arm mobile manipulator with omnidirectional wheels	manipulators;performance evaluation;mobile robots;kinematics;mobile communication;haptic interfaces	In this paper, an hybrid position-position and position-velocity teleoperation control scheme for a generic mobile manipulator is presented and discussed. The mobile manipulator is composed by a mobile platform and a 5 dof arm, and the proposed control scheme allows the simultaneous control of both the devices by means of a single haptic device characterized by an open kinematic chain and not specifically designed for mobile manipulators teleoperation (e.g. a Phantom Omni). The proposed teleoperation controller overcomes the mismatch of the control signals to be sent to the arm (position) and to the mobile platform (velocity) through a proper partition of the master device workspace. Tests have been performed both by simulation and with a real setup. The setup is composed by a 6 dof Phantom Omni haptic device acting as master, and a single-arm Kuka youBot omnidirectional manipulator acting as slave. Experimental results related to a pick and place task, performed on the real setup and involving the motion of both the arm and the platform are reported and commented.	algorithm;autonomous robot;haptic technology;imaging phantom;kinematic chain;mobile device;mobile manipulator;mobile operating system;modal logic;obstacle avoidance;optimal control;reference frame (video);smt placement equipment;scroll wheel;simulation;tracking system;velocity (software development);wheels;workspace	Alberto Pepe;Davide Chiaravalli;Claudio Melchiorri	2016	2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2016.7759236	control engineering;mobile robot;kinematics;simulation;mobile telephony;computer science;engineering;artificial intelligence;mobile manipulator;control theory	Robotics	61.73538545108808	-30.128414856119317	85778
77353e8559e801115538084fb198879fdc9eea4b	reliable architecture of an embedded stereo vision system for a low cost autonomous vehicle	automotive electronics;dsp platform;autonomous vehicle;image sensors;embedded system;stereo vision costs remotely operated vehicles mobile robots vehicle driving road vehicles sensor systems embedded system digital signal processing embedded software;embedded systems;stereo image processing;embedded stereo vision system;stereo vision;software framework;dsp platform embedded stereo vision system autonomous vehicle rascal;digital signal processing chips;vehicles;rascal;vehicles automotive electronics digital signal processing chips embedded systems image sensors stereo image processing	In the 2005 DARPA Grand Challenge, five vehicles completed a preset course of 210 kilometers through desert dirt roads, completely driven by onboard automatic systems. This major achievement was accompanied by great progress of other vehicles which participated too but did not complete the course due to various reasons. The automatic vehicle RASCAL is one example of these vehicles: with its on-board autonomous capabilities, it reached a distance of 25.7 autonomously driven kilometers. One of the sensors implemented on RASCAL was a low-cost embedded stereo vision system. This dependable embedded system was based on a DSP platform and employed a novel software framework to guarantee reliable operations in the desert. This paper provides an overview on that particular subsystem	autonomous robot;darpa grand challenge;digital signal processor;embedded system;on-board data handling;sensor;software framework;stereopsis	Hannes Hemetsberger;Jürgen Kogler;William Travis;Reinhold Behringer;Wilfried Kubinger	2006	2006 IEEE Intelligent Transportation Systems Conference	10.1109/ITSC.2006.1706866	embedded system;computer vision;simulation;engineering	Robotics	56.58133491627245	-31.464286126721973	85804
45ac4cf48d788bd279abc28f9939af4e16411e8c	automated touch sensing: a brief perspective and several new approaches	robot sensing systems;service robots;prosthetics;automata;shape;information processing;pattern recognition;robot sensing systems robotics and automation humans automata prosthetics pattern recognition information processing shape service robots robustness;robustness;humans;robotics and automation	"""This  paper's  purpose  is twofold: 1) To outline  briefly  some of  the  principal considerations  in  achieving  competent  robotic tactile  s nsing,  and 2) to  describe  the beginnings of several new research projects in this area which have been initiated at Case Western Reserve University Touch-sensing  technology for robotics and prosthetics  presently  is  very  primitive.  The need  for obust  multiple-sensor,  gray-scaleresponsive robotic grippers and """"hands"""" has been widely perceived and extensively documentedl. Somewhat  less  of en discussed,  but  of considerable importance, is the need to provide tactile  """"pressure""""  to a human  operator for telemanipulation. Related to these technological needs  are  the  relatively  unknown  operating principles  of tactile  perception  in living systems  and  the  closely  related omain of replacement touch sensing for limb orthosis and prosthesis. The  pr ssing  requirements for  sensory feedback and control in automata have spurred a great  deal of research  in visual  pattern recognition in recent years. Though there have been some noteworthy and useful achievements, the state-of-the-art really ,is not far advanced. Device and system capabilities are modest and evolve slowly, owing mostly to many difficult problems in information processing and pattern recognition. Unlike vision, tactile sensing for automata has  been  relatively  neglected.  Concentrated study of fundamental issues in touch began only in the last few years. Part of the reason for this may have been the unavailability of useful tactile sensors. Achieving  improved  knowledge  and technological capability in tactile sensing is a problem of many dimensions. This includes need for fundamental research and development in such matters as transduction, three-dimensional object representation of shape, orientation, location, texture,  compliance,  and  the relating of information derived from touch to system-control and manipulation operations."""	automata theory;automaton;feedback;information processing;living systems;pattern recognition;remote manipulator;requirement;robot;robotics;sensor;transduction (machine learning);unavailability	Leon D. Harmon	1984		10.1109/ROBOT.1984.1087150	computer vision;simulation;information processing;shape;computer science;artificial intelligence;automaton;robustness	Robotics	66.97310003531022	-29.153179402119378	86032
ec17640377a37b42db562da999d0291aaa1cd307	estimation of mass and center of mass of unknown and graspless cylinder-like object	graspless manipulation of robot;estimation of object mass;center of mass;tip operation;passing c m line;estimation of center of mass	In manipulating an object stably and accurately by a robot, the mass and the center of mass of the object is often required. For cases when the weight or shape of an object is over the grasp capacity of a robot's hand, a technique that can estimate the mass and center of mass of a graspless unknown object, which has curved surfaces and a base plane is proposed in this paper. A line called Passing-C.M. Line which contains the center of mass, is defined. For estimating the passing-C.M. line, we proposed the Tip Operation by a robot finger, which tips the object slowly and repeatedly in a parallel motion with a vertical operation plane. Using the fingertip position and force information measured from tip operations, an algorithm to estimate the passing-C.M. line is described. Then an algorithm to estimate the mass and center of mass of the object is given by estimating the intersecting point of several differently oriented passing-C.M. lines.		Yong Yu;Takashi Kiyokawa;Showzow Tsujio	2004	I. J. Information Acquisition	10.1142/S0219878904000069	center of mass;computer vision;simulation	Vision	60.72201889797557	-34.98439379002935	86209
f4c2a9700e12e20da6649eda9b9e1d855af99297	real-time object detection for autonomous robots	mobile robot;real time;levels of abstraction;industrial robots;collision avoidance;autonomous robot;object detection	A new kind of robotswhosecharacteristics, objectivesandoperational modesdrasticallydiffer from moreconventionalindustrialrobotsis gainingincreasedinterest.Thisnew typeof robotsaimsto achieveahighlevel of flexibility , adaptability, andefficiency for actingin environmentsdesignedfor humans.To meetthesedemands, themobile robotsneedlots of informationabouttheir surroundingsatdifferentlevelsof abstraction,generallyin real-time.In this papera sensorconceptis describedcontainingsymbolicandsub-symbolicinformation deliveringtherequireddatafor all tasks.Basedon this informationtheplanning, navigation,andcollisionavoidanceof theARIADNE robotsis done.1	general material designation;humans;object detection;real-time transcription;sensor;typeof	Michael Pauly;Hartmut Surmann;Marion Finke;N. Liang	1988		10.1007/978-3-642-60043-2_8	mobile robot;computer vision;simulation;engineering;self-reconfiguring modular robot;robot control;communication;aisoy1	Robotics	58.825876234002784	-30.546215465016978	86416
d37b592f5ead4e41b8ad2b5ee970006bf867cdd8	reliability estimation of vehicle localization result		This paper proposes a method for estimation of the reliability of vehicle localization results. We previously proposed a fault detection method for indoor mobile robots using a convolutional neural network (CNN). Because image data is generally fed to a CNN, we feed image data obtained from the robot pose, occupancy grid map, and laser scan data to the CNN, which decides of whether localization has failed. The previous method also employed a Rao-Blackwellized particle filter to estimate the robot pose and reliability of this estimation simultaneously. However, it was difficult for vehicle robots to use the previous method as creating and processing image data is not a light computation process. In this study, we extend the previous method by improving the data fed to the CNN, thus making it possible for vehicle robots to perform simultaneous localization and estimation. This paper describes in detail the simultaneous estimation and shows that the reliability can be used as an exact criterion for detecting localization failures. Keywords-Vehicle Localization, Reliability	artificial neural network;computation;convolutional neural network;experiment;fault detection and isolation;internationalization and localization;kernel density estimation;mobile robot;newton's method;particle filter;sensor;simulation;simultaneous localization and mapping;time complexity	Naoki Akai;Luis Yoichi Morales Saiki;Hiroshi Murase	2018	2018 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2018.8500625	occupancy grid mapping;convolutional neural network;computation;mobile robot;fault detection and isolation;computer vision;particle filter;computer science;artificial intelligence	Robotics	54.4880043116531	-37.77307233164412	86453
570ca0babdd73c233421c3987f9edb42782167a2	a radar-based terrain mapping approach for stair detection towards enhanced prosthetic foot control		Ahstract- Current developments in ankle prosthetics are focusing on integrated actuators to fully control torques and angles. This enables terrain adaptive strategies e.g. for stairs and ramps. EMG and motion sensor input are state of the art approaches to classify different terrain or terrain changes, but these approaches have limited capabilities and detection accuracy. We present a novel approach for the detection of obstacles using a wearable Frequency-Modulated Continuous Wave (FMCW) radar integrated into a lower limb prosthetic device. With the continuous rotational motion of the tibia during the swing and stance phase, the radar scans the profile of the terrain in sagittal plane in front of the prosthesis. Gait phases are detected using a neural network classifiers based on inertial sensor data. Performance of the system is demonstrated in a single stair detection scenario.	apply;artificial neural network;cross section (geometry);electromyography;modulation;motion detector;motion estimation;neuroprosthetics;object type (object-oriented programming);radar;sensor;simulation;tibia;wearable computer	Bernhard Kleiner;Nils Ziegenspeck;Roman Stolyarov;Hugh Herr;Urs Schneider;Alexander Verl	2018	2018 7th IEEE International Conference on Biomedical Robotics and Biomechatronics (Biorob)	10.1109/BIOROB.2018.8487722	terrain;actuator;continuous wave;gait;computer vision;sagittal plane;radar;chirp;artificial intelligence;computer science	Robotics	58.04274064669133	-35.49093411491335	86495
e7831c1099434688bfffb5472d118d3f6acfcb70	an application of robotic cable harness bundling	robot sensing systems;design automation;automobiles;application software;assembly systems robot sensing systems hardware computer errors application software automobiles airplanes cables design automation workstations;airplanes;cables;workstations;software development;assembly systems;optical sensor;computer errors;hardware	Cable harnesses are used in various equipment including automobiles, airplanes, locomotives and computers. In the Cable Harness Design and Assembly System, cables are designed at a CAD workstation and the cable harness is built by a remote robot. This paper covers the bundling subsystem of the Cable Harness Design and Assembly System. This involved both hardware and software development. The hardware consists of the interface of the bundling tool to the robot controller and the circuitry for driving an optical sensor located at the end of the bundling tool for monitoring the cable height. The software developed consists of several programs, for processing the information coming from the CAD database and driving the manipulator through the process. The bundling subsystem relies on feedback from the sensor at the manipulator end effector for adapting to minor errors and for temporary suspension of the process when non-recoverable errors occur.	cable internet access;robot	Jose Bravo;James Graham;Mark Steiner	1986		10.1109/ROBOT.1986.1087526	embedded system;application software;simulation;workstation;electronic design automation;computer science;engineering;sensor;software development;computer engineering	Robotics	63.147890224813644	-29.751246088197185	86510
34f2786652b260f2d023bcbd01a9b817acd06b99	visual control for memory-based navigation using the trifocal tensor	visual navigation;mobile robots;fuzzy visual control;visual memory;visual path following	In this paper, we present a control scheme for visual path-following of wheeled mobile robots based on a robust geometric constraint: the trifocal tensor (TT). The proposed control law only needs one element of the TT as feedback information, which is computed from the current and the target images along the sequence of the visual path. The scheme is valid for images captured by cameras having approximately a unique center of projection, e.g., conventional, central catadioptric and some fisheye cameras. The benefits of the proposed scheme are that explicit pose parameters decomposition is not required and the rotational velocity is smooth or eventually piece-wise constant avoiding discontinuities that generally appear when a new target image must be reached. Additionally, the translational velocity is adapted as required for the path. The validity and performance of the approach is shown through realistic simulations using synthetic images.	fisheye;mobile robot;optimal control;robotic mapping;simulation;synthetic intelligence;trifocal tensor;velocity (software development)	Héctor M. Becerra	2012	World Automation Congress 2012	10.1080/10798587.2014.906378	mobile robot;computer vision;simulation;visual memory;computer science;artificial intelligence	Robotics	60.38842518492611	-31.859187420507865	86616
6a272af85d1dad354cacc4979fb542afbf6b1559	visual odometry system using multiple stereo cameras and inertial measurement unit	landmark matching visual odometry system stereo cameras inertial measurement unit gps denied environments human wearable systems pose estimation mechanism simultaneous localization and mapping type method;visual odometry;front end;and forward;image matching;real time;gps denied environments;inertial measurement unit;pose estimation mechanism;human wearable systems;visual odometry system;global positioning system;stereo image processing;simultaneous localization and mapping;robust method;cameras measurement units humans simultaneous localization and mapping global positioning system robustness portable computers algorithm design and analysis system testing prototypes;simultaneous localization and mapping type method;inertial systems;stereo image processing global positioning system image matching inertial systems pose estimation slam robots;stereo cameras;slam robots;landmark matching;real time systems;pose estimation	Over the past decade, tremendous amount of research activity has focused around the problem of localization in GPS denied environments. Challenges with localization are highlighted in human wearable systems where the operator can freely move through both indoors and outdoors. In this paper, we present a robust method that addresses these challenges using a human wearable system with two pairs of backward and forward looking stereo cameras together with an inertial measurement unit (IMU). This algorithm can run in real-time with 15 Hz update rate on a dual-core 2 GHz laptop PC and it is designed to be a highly accurate local (relative) pose estimation mechanism acting as the front-end to a simultaneous localization and mapping (SLAM) type method capable of global corrections through landmark matching. Extensive tests of our prototype system so far, reveal that without any global landmark matching, we achieve between 0.5% and 1% accuracy in localizing a person over a 500 meter travel indoors and outdoors. To our knowledge, such performance results with a real time system have not been reported before.	algorithm;global positioning system;internationalization and localization;multi-core processor;prototype;real-time clock;real-time computing;simultaneous localization and mapping;stereo camera;stereo cameras;system configuration;usability;visual odometry;wearable computer	Taragay Oskiper;Zhiwei Zhu;Supun Samarasekera;Rakesh Kumar	2007	2007 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2007.383087	stereo cameras;inertial measurement unit;computer vision;simulation;pose;global positioning system;computer science;visual odometry;front and back ends;simultaneous localization and mapping	Vision	55.33831973181184	-36.99685549298956	86633
93e966124f1ddec57d2d9d3f2e2fe8bd8a7a8819	navigation strategies for cooperative localization based on a particle-filter approach	cooperative localization technique;orientation measurement;global positioning system;main mission;initial configuration;particle-filter approach;navigation strategy;individual robot;fixed active beacon	This paper proposes a set of navigation strategies to cooperatively localize a team of robots by applying a Particle-Filter approach. The main mission consists in exploring unknown, isolated and unstructured scenarios, where no Global Positioning System is available. By means of the cooperative localization technique and a behaviour based controller the robots have to return to the initial configuration. The proposed approach relies on distance and orientation measurements between the individual robots, and between the robots and a fixed active beacon. Simulation results are presented. ∗Corresponding author: phone: +34 959 21 76 38; fax: +34 959 21 73 04; 1	experiment;fax;global positioning system;internationalization and localization;mobile robot;particle filter;simulation	Fernando Gómez-Bravo;Alberto Vale;M. Isabel Ribeiro	2007	Integrated Computer-Aided Engineering		computer vision;simulation	Robotics	54.15342809270956	-33.873949128048835	86683
4e540a1691583b4372e22a216153f51e43c3cc17	armo: adaptive road map optimization for large robot teams	dynamic change;robot kinematics roads planning hidden markov models navigation collision avoidance;motion control;hidden markov model;path planning;industrial plants;adaptive control;mobile robots;robotics;transportation adaptive control dispatching hidden markov models industrial plants industrial robots linear programming logistics manufacturing industries mobile robots motion control multi robot systems path planning;manufacturing industries;hidden markov model adaptive road map optimization autonomous robot teams transportation task dispatching logistic centers manufacturing plants robot motion planning industrial domain linear programming optimal road map configuration environmental constraints grid map;navigation;hidden markov models;logistics;roads;robot motion planning;industrial robots;transportation;multi robot systems;robotteknik och automation;linear programming;linear program;planning;collision avoidance;autonomous robot;dispatching;robot kinematics;robot team	Autonomous robot teams that simultaneously dispatch transportation tasks are playing more and more an important role in present logistic centers and manufacturing plants. In this paper we consider the problem of robot motion planning for large robot teams in the industrial domain. We present adaptive road map optimization (ARMO) that is capable of adapting the road map whenever the environment has changed. Based on linear programming, ARMO computes an optimal road map configuration according to environmental constraints (including human whereabouts) and the demand for transportation tasks from loading stations in the plant. For detecting dynamic changes, the environment is described by a grid map augmented with a hidden Markov model (HMM). We show experimentally that ARMO outperforms decoupled planning in terms of computation time and time needed for task completion.	autonomous robot;computation;computational resource;dynamic dispatch;experiment;hidden markov model;linear programming;linear programming formulation;map;markov chain;mathematical optimization;motion planning;plan;routing;sensor;throughput;time complexity	Alexander Kleiner;Dali Sun;Daniel Meyer-Delius	2011	2011 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6094734	planning;control engineering;motion control;mobile robot;logistics;transport;navigation;simulation;computer science;engineering;linear programming;artificial intelligence;motion planning;manufacturing;robot kinematics;hidden markov model	Robotics	54.72901180705701	-24.42465313854873	86886
6e872195c6a7608f4acab6ca5e65ca7e22acbcb3	camera view centered mobile robot control interface	cameras robot vision systems robot kinematics mobile robots trajectory planning;user interfaces cameras control engineering computing interactive devices mobile robots optimal control robot vision telerobotics;pan tilt camera camera view centered mobile robot control interface camera coordinate frame joystick optimal control inputs hardware constraints	Camera view centered mobile robot control is proposed to provide intuitive operation feeling. The proposed controller only requires the direction of the desired motion of the viewpoint. If an operator indicates a reference in the camera coordinate frame by a joystick, the controller generates the optimal control inputs to follow the reference considering the hardware constraints. The proposed method was implemented to the nonholonomic mobile robot with a pan-tilt camera, and the operability was improved.	joystick;mobile robot;operability;optimal control;robot control	Naoto Hirakawa;Tomohito Takubo;Atsushi Ueno	2014	2014 International Symposium on Micro-NanoMechatronics and Human Science (MHS)	10.1109/MHS.2014.7006101	control engineering;mobile robot;smart camera;computer vision;cartesian coordinate robot;simulation;computer science;social robot;robot control;mobile robot navigation	Robotics	60.55511409948786	-30.601867950475768	87021
87e91b6a926111ae45daa25595c0ffecef1acca0	path planning with markovian processes	path planning	This paper describes the path planning for the mobile robots, based on the Markov Decision Problems. The presented algorithms are developed for resolving problems with partially observable states. The algorithm is applied in an office environment and tested with a skid-steered robot. The created map combines two mapping theory, the topological respectively the metric method. The main goal of the robot is to reach from the home point to the door of the indoor environment using algorithms which are based on Markovian decisions.	algorithm;markov chain;markov decision process;mobile robot;motion planning;partially observable system;sensor	Istvan Szoke;Gheorghe Lazea;Levente Tamas;Mircea Popa;Andras Majdik	2009			computer science;artificial intelligence;motion planning	Robotics	53.933706643347946	-28.769761247691143	87298
87f07e99b4fe5e7f5bb8f956bc0a60a6641286cc	a vision based onboard approach for landing and position control of an autonomous multirotor uav in gps-denied environments	dedicated optical flow sensor;robot sensing systems;velocity control aerospace robotics aircraft control cascade control helicopters mobile robots position control remotely operated vehicles robot vision stability;aircraft control;multirotor uavs;velocity control;landing pad;dedicated optical flow sensor vision based onboard approach position control autonomous multirotor uav gps denied environments multirotor uavs autonomous landing landing pad vision based detection algorithm 3d position estimation cascaded controller structure velocity stabilitization position stabilitization;mobile robots;gps denied environments;remotely operated vehicles;vision based detection algorithm;cascade control;position stabilitization;stability;3d position estimation;optical imaging;robot vision;autonomous multirotor uav;position control;global positioning system;aerospace robotics;vision based onboard approach;detection algorithm;cascaded controller structure;autonomous landing;universal serial bus;optical flow;optical sensors;velocity stabilitization;position control unmanned aerial vehicles global positioning system optical sensors payloads batteries magnetic sensors sensor fusion image motion analysis robustness;unmanned aerial vehicles;helicopters;cameras;structural stability	We describe our work on multirotor UAVs and focus on our method for autonomous landing and position control. The paper describes the design of our landing pad and the vision based detection algorithm that estimates the 3D-position of the UAV relative to the landing pad. A cascaded controller structure stabilizes velocity and position in the absence of GPS signals by using a dedicated optical flow sensor. Practical experiments prove the quality of our approach.	algorithm;autonomous robot;experiment;gps signals;global positioning system;motion estimation;optical flow;systems architecture;unmanned aerial vehicle;velocity (software development)	Sven Lange;Niko Sünderhauf;Peter Protzel	2009	2009 International Conference on Advanced Robotics		control engineering;simulation;engineering;control theory	Robotics	57.19911074421388	-32.52588756808516	87372
98c4cdcd608bffa8e08ac44954dd80560493792b	robotic design principles emerging from balance of morphology and intelligence	genetic programming morphology intelligence design principle evolutionary robotic system;design principle;genetic program;robot design;decision tree;robotic design principles;genetic programming;robot intelligence;morphology;evolutionary robotics;distance maintaining function robotic design principles evolutionary robotic system sensor arrangement robot intelligence decision tree;distance maintaining function;tree structure;robots;intelligent robots morphology robot sensing systems intelligent sensors mouth tree data structures eyes nose intelligent structures decision trees;sensor arrangement;genetic algorithms;intelligence;evolutionary process;decision trees;robots decision trees genetic algorithms;evolutionary robotic system	We investigate robotic design principles using an evolutionary robotic system with reconfigurable morphology and intelligence. In this study, we focus on the relationship between an approaching part and the sensor arrangement. In nature, sensors such as the eyes and the nose are concentrated around the approaching part, i.e., the mouth, since the most important task for living creatures is to bring their mouth close to food. Consequently, for living creatures the arrangement of sensors must be based on the position of the mouth. However, a robot does not have a mouth. In addition, an approaching part of a robot can also be changed by a given task. On the basis of this concept, in this study, we investigate the relationship between an approaching part and the sensor arrangement by performing evolutionary simulations. In the simulations, the morphology of a robot is represented as a tree structure consisting of cylindrical cells, and the intelligence of this robot is described as a decision tree. The task given to the robot is to maintain a distance between an approaching part located at the nth cell and an object. The results clarified basic design principles: sensors are optimally arranged on the approaching part and toward the terminal of the tree structure for this task. Furthermore, by analyzing the evolutionary process, we clarified the evolution of a mechanism that creates an effective distance-maintaining function by using the robot's body structure as a scale.	decision tree;galaxy morphological classification;mathematical morphology;reconfigurable computing;robot;sensor;simulation;tree structure	Naohide Yasuda;Takuma Kawakami;Hiroaki Iwano;Koki Kikuchi	2007	2007 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2007.4522220	simulation;morphology;computer science;engineering;artificial intelligence;social robot;machine learning;decision tree	Robotics	59.525741365371516	-25.025130259552395	87624
2ec3c055bbbf4e169c28bdf518c47da35a0e6400	coverage algorithms for an under-actuated car-like vehicle in an uncertain environment	agricultural machinery;autonomous tractor mower;turning;lawnmowers;path planning;real time;ground robots;mobile robots;remotely operated vehicles;outdoor coverage task;kinematic constraint;coverage algorithms;spirals mobile robots path planning remotely operated vehicles turning global positioning system kinematics agricultural machinery shape robotics and automation;local system;kinematics;uncertain environment;science technology;shape;global positioning system;detected obstacle avoidance;ground robots coverage algorithm underactuated car like vehicle uncertain environment path planning algorithm outdoor coverage task kinematic constraint trajectory curvature detected obstacle avoidance autonomous tractor mower;spirals;path planning ground robots coverage algorithms;path planning algorithm;collision avoidance;coverage algorithm;robot dynamics;robot kinematics collision avoidance global positioning system lawnmowers mobile robots robot dynamics;underactuated car like vehicle;robotics and automation;trajectory curvature;robot kinematics	A coverage algorithm is an algorithm that deploys a strategy as to how to cover all points in terms of a given area using some set of sensors. In the past decades a lot of research has gone into development of coverage algorithms. Initially, the focus was coverage of structured and semi-structured indoor areas, but with time and development of better sensors and introduction of GPS, the focus has turned to outdoor coverage. Due to the unstructured nature of an outdoor environment, covering an outdoor area with all its obstacles and simultaneously performing reliable localization is a difficult task. In this paper, two path planning algorithms suitable for solving outdoor coverage tasks are introduced. The algorithms take into account the kinematic constraints of an under-actuated car-like vehicle, minimize trajectory curvatures, and dynamically avoid detected obstacles in the vicinity, all in real-time. We demonstrate the performance of the coverage algorithm in the field by achieving 95% coverage using an autonomous tractor mower without the aid of any absolute localization system or constraints on the physical boundaries of the area.	autonomous robot;genetic algorithm;global positioning system;internationalization and localization;motion planning;real-time clock;semiconductor industry;sensor	Michael Bosse;Navid Nourani-Vatani;Jonathan M. Roberts	2007	Proceedings 2007 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2007.363068	agricultural machinery;remotely operated underwater vehicle;control engineering;mobile robot;computer vision;kinematics;simulation;global positioning system;shape;computer science;engineering;artificial intelligence;motion planning;local system;robot kinematics;spiral	Robotics	54.327593291491176	-32.93952489499634	87735
b76a3f8bfc4114fff992c00cda73830de270f987	motion control for vehicle with unknown operating properties -on-line data acquisition and motion planning	motion control;path planning;hovercraft;omnidirectional camera vehicles motion control online data acquisition motion planning air cushion vehicle target position position estimation;mobile robots;motion control data acquisition propellers vehicle driving position measurement cameras underwater vehicles wheels mobile robots robot motion;computer vision;position control;computer vision motion control hovercraft path planning mobile robots position control vehicle dynamics;motion planning;data acquisition;vehicle dynamics	This paper describes a sequence of methods for controlling the vehicle with unknown operating properties, such as an air cushion vehicle, a submarine and an airship. We took up Air Cushion Vehicle (ACV) as an example of such a vehicle, and studied its motion planning based on acquired data. ACV in this paper has three simple unit motions (left-turn, right-turn and an advance), and can execute one of the unit motions optionally. After the execution, ACV measures its own position by itself and acquires data of how it moved in the real environment. Then it plans the motion that arrives at a target position using the acquired data. In this paper, we propose a sequence of these approaches and show the effectiveness of them by experiments.	data acquisition;motion planning	Kazuya Okawa;Shin'ichi Yuta	2003		10.1109/ROBOT.2003.1242117	control engineering;motion control;computer vision;simulation;computer science;engineering;artificial intelligence;motion planning	Robotics	57.792492461465045	-28.995345836182018	87768
a7b5753b4c2deba66f139bcbc1e3aff3bf6d0626	the library for grasp synthesis & robot simulation		This paper provides an overview of GSL (Grasp Synthesis Library) simulator. GSL is open source library for grasp synthesis and robot simulation. The library contain the functions for: virtual robot system, grasp synthesis, 3D drawing. It was developed by the standard library and grammar in C++. In this paper, we discuss characteristics of GSL, and a brief overview of a robot simulation using GSL.	c++;gnu scientific library;open-source software;robot;simulation;standard library	Jongwoo Park;Chanhun Park;Dong Il Park;Hwi-Su Kim	2017	2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2017.7992766	simulation;grasp;robot;robot kinematics;artificial intelligence;engineering	Robotics	65.69439976237065	-28.358983313947455	87871
ae02e29d150d44353511f33241a3ebab53a58576	specifications of a small electric vehicle: modular and distributed approach	hardware architecture;software control architecture small electric vehicle modular distributed approach autonomous motion urban transportation system door to door displacement car sharing mode self service mode electro mechanical structure computer aided driving modular distributed hardware architecture intelligent components;control architecture;energy storage;electric vehicles;electric vehicles vehicle driving driver circuits computer architecture intelligent sensors intelligent actuators automation remotely operated vehicles road transportation cities and towns;electric vehicle;urban transport	In this paper we describe a small electric vehicle equipped with automatisms that allow autonomous motion. A eet of such vehicles could be one element of a novel urban transportation system to door-to-door displacement in closed area (city centers but also touristic resorts, campuses, ...) if they are used in self-service and car-sharing mode. The speciications in the matter of performances (range, max speed, ...) or energy storage agree with this application within this kind of evolution space (several short trips at low speed). A stylish look and an original electro-mechanical structure with four steering and driving wheels was adopted. By the fact of its utilization opened to diierent users not having necessarily driving-license, the vehicle must be friendly, easy to handle and secure not only for the driver but also for the pedestians walking in the same area (computer aided driving). The driver must be carefree of parking or batteries recharging. The recent progresses of Electronics and Robotics allow to envisage that these maneuvers could run automatically without human intervention. We have designed a modular and distributed hardware architecture with intelligent components (actuactors and sensors) linked together by a eld bus. Several solutions for the implementing of our software control architecture are examined .	autonomous robot;can bus;coat of arms;displacement mapping;performance;robotics;sensor;stylish;vmebus;wheels	Leszek Lisowski;Gérard Baille	1997		10.1109/IROS.1997.655119	embedded system;simulation;engineering;automotive engineering;hardware architecture;energy storage	Robotics	62.476107739571624	-28.624818402282433	87884
40abbcffb8152a3128299dac0333c338e5ba4336	center-of-mass-based grasp pose adaptation using 3d range and force/torque sensing		Lifting objects, whose mass may produce high wrist torques that exceed the hardware strength limits, could lead to unstable grasps or serious robot damage. This work introduces a new Center-of-Mass (CoM)-based grasp pose adaptation method, for picking up objects using a combination of exteroceptive 3D perception and proprioceptive force/torque sensor feedback. The method works in two iterative stages to provide reliable and wrist torque efficient grasps. Initially, a geometric object CoM is estimated from the input range data. In the first stage, a set of hand-size handle grasps are localized on the object and the closest to its CoM is selected for grasping. In the second stage, the object is lifted using a single arm, while the force and torque readings from the sensor on the wrist are monitored. Based on these readings, a displacement to the new CoM estimation is calculated. The object is released and the process is repeated until the wrist torque effort is minimized. The advantage of our method is the blending of both exteroceptive (3D range) and proprioceptive (force/torque) sensing for finding the grasp location that minimizes the wrist effort, potentially improving the reliability of the grasping and the subsequent manipulation task. We experimentally validate the proposed method by executing a number of tests on a set of objects that include handles, using the humanoid robot WALK-MAN.	alpha compositing;control theory;displacement mapping;experiment;humanoid robot;internationalization and localization;iterative method;lambda lifting;lifting scheme;point cloud;simultaneous localization and mapping	Dimitrios Kanoulas;Jinoh Lee;Darwin G. Caldwell;Nikolaos G. Tsagarakis	2018	I. J. Humanoid Robotics	10.1142/S0219843618500135	humanoid robot;computer vision;center of mass;artificial intelligence;computer science;torque;grasp;torque sensor	Robotics	63.2098822839033	-33.782365265950155	87923
e27ce216aefe18f4d86bdb65a76474b1f6db4648	software framework for human neuromuscular behavior	neural prosthesis;software testing;manipulators;muscle synergistic activities;robotic details;neural commands;fault tolerant;anatomically correct testbed hand;prototypes;anatomically correct testbed;prosthetics;force;medical robotics;medical computing;hills model human neuromuscular behavior low level software framework biologically inspired prosthetic devices anatomically correct testbed hand robotic details muscle physiology programming muscle synergistic activities neural commands fault tolerant;physiology;fault tolerant computing;humans neuromuscular neural prosthesis muscles software testing abstracts robots physiology fault tolerant systems prototypes;fault tolerant systems;abstracts;robot programming fault tolerant computing manipulators medical computing medical robotics muscle prosthetics;robots;low level software framework;hills model;neuromuscular;software framework;humans;neurons;dc motors;biologically inspired prosthetic devices;muscle;conferences;human neuromuscular behavior;robot programming;muscles;muscle physiology programming	In this paper we present our low-level software framework that allows human neuromuscular properties and behaviors to be programmed modularly onto biologically inspired prosthetic devices. Specifically this software framework is used at the lowest level of the Anatomically Correct Testbed (ACT) Hand. It abstracts away from the robotic details and allows users including biologists to program individual muscle physiology, multiple muscle synergistic activities, neural commands, etc. independently. Our system has been designed to be fault-tolerant with the idea of safe and continued operation of prostheses if a new prototype behavior were to perform incorrectly or outright fail. Example coding of Hills model is shown.	fault tolerance;high- and low-level;modular programming;prototype;robot;software framework;synergy;testbed	Timothy Blakely;Yoky Matsuoka	2009	2009 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2009.5152801	robot;embedded system;fault tolerance;muscle;simulation;computer science;engineering;artificial intelligence;software framework;dc motor;prototype;software testing;force	Robotics	66.16147314545161	-29.63498038536224	88138
94b910049fa49b9ca623d378dcbfd7c78fa50efe	'friend' robot, space telerobot for rescue and recovery of astronauts in space stations	motion control;orbital robotics intelligent robots robot sensing systems intelligent sensors space stations prototypes medical services system testing control systems manipulators;expert systems;mobile robots;expert intelligent system space telerobot astronauts space stations friend robot project flying robot intelligently ended nursing dexterity remote operator autonomous energy source motion control structure visual recognition system;computer vision;aerospace control;intelligent system;telecontrol;energy source;telecontrol aerospace control computer vision expert systems mobile robots	Deals with the design, modelling and construction of a prototype of a space telerobot for the rescue and recovery of astronauts in the area around a space station. The objective of the FRIEND robot project (an acronym of Flying Robot with Intelligently Ended Nursing Dexterity) is the testing of a telerobotised system controlled by a remote operator. The FRIEND robot is designed and constituted by a mechanical structure with two arms, an autonomous energy source, a sensor and motion control structure, a visual recognition system which acts as operator support, an expert intelligent system memorised in the computer for alternative choices in the stage of rescue and recovery of an astronaut in an emergency. >	friend-to-friend;robot;telerobotics	Alberto Rovetta	1991		10.1109/IROS.1991.174756	control engineering;motion control;mobile robot;embedded system;simulation;computer science;engineering;artificial intelligence;social robot;robot control;expert system	Robotics	62.320962080087845	-28.3966254897559	88359
a526f1e75668fe647813b97655279b02c3f01ea9	high speed vision sensor and quick robotic hand enable a robot to catch a ball	new technology;robot hand;technology development;chip;robot vision;robots;visual servoing;vision;high speed	Professor Masatoshi Ishikawa of the University of Tokyo, Japan, has developed a super fast vision sensor and a super quick hand (gripper), and integrated them in an impressive demonstration system in which the vision sensor recognizes a free falling ball and the hand catches it in the air. The secret lies in a super fast vision chip and visual servo technology developed along with the chip. A lot of new applications for this new technology in future robotics are expected.	robot	Yoshihiro Kusuda	2003	Industrial Robot	10.1108/01439910310479577	chip;robot;embedded system;vision;computer vision;simulation;computer science;engineering;artificial intelligence;visual servoing	Robotics	66.62347293687232	-30.030767168247138	88408
ed13490b1d715609ccf882f824a0ff3bbcae4702	precise manipulation with endpoint sensing	architecture systeme;manipulateur;computer system;robotics;measurement sensor;capteur mesure;manipulador;systeme informatique;robotique;system architecture;manipulator	"""This paper describes recent work on manipulation strategies that rely on """"coarsefine"""" robot hardware and direct sensing of partworkpiece relationships. The experiments reported use an extremely precise, highbandwidth planar """"wrist"""" and an industrial vision system to perform accurate alignment of small parts. The system architecture, experimental hardware, and programming methods employed are all discussed."""	communication endpoint;experiment;systems architecture	Russell H. Taylor;Ralph L. Hollis;Mark A. Lavin	1985	IBM Journal of Research and Development	10.1147/rd.294.0363	control engineering;computer science;engineering;artificial intelligence;manipulator;robotics;systems architecture	Robotics	63.12400240712677	-32.50001082643904	88470
5e4e214605ca314ecd3890ec21af28f1ffa1b7a9	a novel diagnostic scheme for the classification of pistons	similar piston types exhibit;structured laser line;various piston;measurement system;laser line;computer vision system;incorrect piston;diagnosing piston;novel diagnostic scheme;optical system;piston crown	In this paper, a computer vision system for diagnosing pistons during the process of manufacture is designed. In fact, it is almost always readily possible to fit the incorrect piston to an engine because a number of similar piston types exhibit very slight differences but with the same overall diameter. Within a family, the difference is very subtle and may be simply a change in the shape of the bowl in the crown of the piston. Hereby, a vision based measurement system is designed to confirm the identity of the piston just after it has been fitted to the engine assembly. Structured laser lines are employed to obtain depth information on the piston crowns. A unique calibration technique involving an optical system is introduced in the scheme, in order to achieve precise 3D measurements. Since some pistons have shining surfaces, the reflection on the crowns influences the detection of the laser line, hence the dispersion of the laser lines increases the difficulty of locating the laser lines. The concept of fuzzy sets is employed to describe the features of the pistons to enable the measurement system to be more tolerant to the various pistons and to be able to obtain more accuracy in the recognition scheme.		Thompson Sarkodie-Gyan;Dezhong Hong;Andrew W. Campbell	2000	Journal of Intelligent and Fuzzy Systems		discrete mathematics;calibration;almost surely;dispersion (optics);fuzzy set;mathematics;piston;control engineering;laser	Robotics	60.94337605376508	-37.23560458091142	88608
19b27c225405349110facc24267b5dc09d37fed6	stride period adaptation of a biomimetic running hexapod	body length;locomotion;biomimetic robots;adaptation;fixed interval;mechanical systems;dynamic properties	We demonstrate an adaptation strategy for adjusting the stride period in a hexapedal running robot. The robot is inspired by discoveries about the self-stabilizing properties of insects and uses a sprawled posture, a bouncing alternating-tripod gait, and passive compliance and damping in the limbs to achieve fast (over four body-lengths per second), stable locomotion. The robot is controlled by an open-loop motor pattern that activates the legs at fixed intervals. For maximum speed and efficiency, the stride period of the pattern should be adjusted to match changes in terrain (e.g., slopes) or loading conditions (e.g., carrying an object). An ideal adaptation strategy will complement the design philosophy behind the robot and take advantage of the self-stabilizing role of the mechanical system. In this paper we describe an adaptation scheme based on measurements of ground contact timing obtained from binary sensors on the robot’s feet. We discuss the motivation for the approach, putting it in the context of previous research on the dynamic properties of running machines and bouncing multi-legged animals, and we show the results of the experiments. KEY WORDS—locomotion, adaptation, biomimetic robots	biomimetics;experiment;poor posture;robot;self-stabilization;sensor;tripod	Jorge G. Cham;Jonathan K. Karpick;Mark R. Cutkosky	2004	I. J. Robotics Res.	10.1177/0278364904041323	control engineering;simulation;engineering;control theory;mechanical system;adaptation	Robotics	67.02752495926231	-24.639690585935146	88904
58c4a4e5c6d57acbe1cd3fd649be2cdd93264c34	visuo-haptic transmission of contact information improve operation of active scope camera	vibrations;visualization;estimation;robot vision systems;cameras	Disaster response robots for searching in a narrow area have limited space to mount tactile sensors, but the operators require sensory feedback to recognize contact situations with the surrounding environment. This study proposes a new approach to transmitting contact information of a remote-operated snake-like robot called Active Scope Camera (ASC) to the operator using simple configurations for the sensing and display methods. For the sensing side, we develop a contact estimation method with a limited number of tactile sensors. We establish the method to localize the contact position and the magnitude by sensing multiple propagated vibrations based on experiments and formulations. Preliminary experiments show that the developed method estimates a collision angle with high probability (93.8% at the worst condition) at several collisional situations. For the display side, we combine visual and vibrotactile feedback to provide the operator both directional and temporal cues to perceive contact events. The proposed visualization method uses colored bars, peripherally superposed on the video image, to show the estimated contact location and magnitude. A single DoF vibrotactile feedback is used for a joystick interface to control the head movement of the ASC. The effect of vibrotactile feedback on the response time to contact events is evaluated. Finally, we investigate the performance of the operation by identifying the contact behavior at simulated scenarios. Experimental results show that collision times per operation time is decreased by the developed feedback system compared with a simple video-based operation.	555 timer ic;experiment;feedback;haptic technology;joystick;operation time;response time (technology);robot;sensor;simulation;ti advanced scientific computer;transmitter;with high probability	Takahito Funamizu;Hikaru Nagano;Masashi Konyo;Satoshi Tadokoro	2016	2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2016.7759190	computer vision;estimation;simulation;visualization;computer science;engineering;vibration;control theory;statistics	Robotics	66.93370691868613	-33.224460630211084	88988
d05ac35ae682d59f213bbfdbb58cbfdaf98eab16	fuzzy qualitative model of a robot sensor for locating three-dimensional objects	modelizacion;fuzzy set;localizacion objeto;implementation;three dimensional shape;object location;robot sensors;bin picking;ensemble flou;robotics;three dimensional;forma tridimensional;robot industriel;experimental result;modelisation;captador medida;ejecucion;measurement sensor;capteur mesure;forme tridimensionnelle;robot industrial;resultado experimental;fuzzy sets theory;robotica;robotique;conjunto borroso;qualitative modeling;resultat experimental;parts feeding;modeling;localisation objet;industrial robot		robot	D. T. Pham;K. Hafeez	1992	Robotica	10.1017/S0263574700005877	three-dimensional space;computer vision;simulation;systems modeling;locating engine;robotic sensing;computer science;engineering;artificial intelligence;fuzzy set;robotics;implementation	Robotics	63.17345640783677	-33.361971541680006	89122
d128fd4efe5e4ce4a25baaf5c9a58ffeaf33acb1	a modular bilateral haptic control framework for teleoperation of robots				Zeki Y. Bayraktaroglu;Omer F. Argin;D. Sinan Haliyo	2019	Robotica	10.1017/S0263574718001042		Robotics	68.01274906852143	-28.20769663331835	89317
c039223222ba85d36ef3ee4996afd7d8c2a601b5	scale-aware navigation of a low-cost quadrocopter with a monocular camera	visual slam;robotvision;quadrocopter;visual navigation;scale estimation;micro aerial vehicles mavs;ar drone;mavs;monocular slam;quadcopter	We present a complete solution for the visual navigation of a small-scale, low-cost quadrocopter in unknown environments. Our approach relies solely on a monocular camera as the main sensor, and therefore does not need external tracking aids such as GPS or visual markers. Costly computations are carried out on an external laptop that communicates over wireless LAN with the quadrocopter. Our approach consists of three components: a monocular SLAM system, an extended Kalman filter for data fusion, and a PID controller. In this paper, we (1) propose a simple, yet effective method to compensate for large delays in the control loop using an accurate model of the quadrocopter’s flight dynamics, and (2) present a novel, closed-form method to estimate the scale of a monocular SLAM system from additional metric sensors. We extensively evaluated our system in terms of pose estimation accuracy, flight accuracy, and flight agility using an external motion capture system. Furthermore, we compared the convergence and accuracy of our scale estimation method for an ultrasound altimeter and an air pressure sensor with filtering-based approaches. The complete system is available as open-source in ROS. This software can be used directly with a low-cost, off-the-shelf Parrot AR.Drone quadrocopter, and hence serves as an ideal basis for follow-up research projects.	computation;control system;effective method;extended kalman filter;global positioning system;laptop;machine vision;motion capture;open-source software;pid;parrot ar.drone;robot operating system;sensor;simultaneous localization and mapping	Jakob Engel;Jürgen Sturm;Daniel Cremers	2014	Robotics and Autonomous Systems	10.1016/j.robot.2014.03.012	computer vision;simulation	Robotics	55.3844939380778	-36.72077881447188	89386
1c0a1fedd3fd51181b435383fa2768426d60c097	optimized transit planning and landing of aerial robotic swarms	optimisation;path planning;atmospheric modeling airports computational modeling optimization aircraft object oriented modeling mathematical model;air safety;uav swarm navigation optimized transit planning optimized landing aerial robotic swarms unmanned aerial vehicle swarm sensitivity analysis performance measures flocking rules agent based simulation optimal path generation landing safety landing zones terminal airspace time expanded network model side constraints network based model analytical analysis centralized overarching airspace optimization model;multi robot systems;autonomous aerial vehicles;path planning air safety autonomous aerial vehicles multi robot systems optimisation	This research explores the efficient and safe landing and recovery of a swarm of unmanned aerial vehicles (UAVs). The presented work involves the use of an overarching (centralized) airspace optimization model, formulated analytically as a network-based model with side constraints describing a time-expanded network model of the terminal airspace in which the UAVs navigate to one or more (possibly moving) landing zones. This model generates optimal paths in a centralized manner such that the UAVs are properly sequenced into the landing areas. The network-based model is “grown” using agent-based simulation with simple flocking rules. Relevant measures of performance include, e.g., the total time necessary to land the swarm. Extensive simulation studies and sensitivity analyses are conducted to demonstrate the relative effectiveness of the proposed approaches.	aerial photography;agent-based model;centralized computing;mathematical optimization;network model;robot;swarm;unmanned aerial vehicle	Thomas F. Dono;Timothy H. Chung	2013	2013 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2013.6630820	control engineering;simulation;computer science;engineering;artificial intelligence;aeronautics;motion planning	Robotics	55.44811779685505	-25.987569288581625	89419
952afbce5bc0a56eea9adb0397f62b91e39e92c8	solving the pnp problem for visual odometry - an evaluation of methodologies for mobile robots			visual odometry	Dominik Aufderheide;Werner Krybus;Ulf Witkowski;Gerard Edwards	2012		10.1007/978-3-642-32527-4_54	computer vision;simulation;engineering;artificial intelligence;visual odometry	Robotics	53.98444141569422	-36.55603078799049	89549
e9ed62dc6f30cd9a0d918fa645f26d45c8e2ccb0	adaptation of the visuo-motor coordination	robot kinematics manipulators target tracking robotics and automation robot vision systems testing machine vision parallel robots rails hardware;optimisation;path planning;manipulator dynamics;online learning;learning systems;robot vision;optical tracking;position control;motor coordination;position control path planning real time systems robot vision optical tracking target tracking learning systems manipulator dynamics optimisation;learning systems visuo motor coordination online learning visually guided movements manipulator manoeuvering target tracking;target tracking;reaching movement;real time systems	In this paper, a method is presented f o r the on-line learning of visually guided movements. The presented algorithms have been tested with a manipulator tracking manoeuvering targets. Three parameters critical for the visuo-motor coordination are learned in less than one hour with repeated movements. A f t e r this learning phase, the robot performs smooth and fast reaching movements and can easily drop small objects into the waggon of a moving model train, independantly of the trajectory. ified motions parameters critical for the visuo-motor coordination. The resulting motion behavior is tested in several experiments and demonstrated by dropping objects into a moving waggon. In the video [9], the robot can be seen while learning reaching motions and loading the waggon. Two conditions were imposed for the experiments. As the algorithms should be usable on generally available systems, only standard hardware was used. Secondly, the learning had to take place automatically and in a short time, so that it could be performed frequently. Adaptable Motion Behaviour (AMB)	algorithm;experiment;online and offline;online machine learning;robot	Etienne Burdet;J. Luthiger	1996		10.1109/ROBOT.1996.506563	control engineering;robot learning;computer vision;simulation;tracking system;computer science;engineering;artificial intelligence;motion planning;motor coordination;iterative learning control	Vision	63.993744702860695	-24.566870432341677	89870
4e1c191ad8996b204e66c6e2005e3d9964c40e1e	scientific applications of robotic systems on planetary missions	distribution;scientific application;forage;seismology;automatisation;meteorological observation;robotics;drilling;low power;mars planet;science communication;marte planeta;echantillon;exploration;robotica;mars planete;observation meteorologique;surface;surfaces;sample;robotique;long range;muestra;seismologie;observacion meteorologica;automation	This paper focusses on Mars landing missions. It gives a brief survey of past international missions and outlines the objectives of the European science community concerning Mars surface exploration. It reviews the studies performed by the ESA science programme in the past (Marsnet, InterMarsnet), culminating in the current efforts to prepare the Mars Express mission for launch in 2003. From the scientific objectives, the functional and performance requirements of robotic systems are derived which are perceived as essential for unmanned Mars surface exploration. The very severe constraints on robot systems from the launch, cruise, and Mars surface environment are described as well as the need for extremely lightweight and low-power solutions with very high science support efficiency. Five typical classes of A&R systems for Mars exploration are specifically identified: simple masts or booms, automation systems for drilling and sample handling, micro rovers for instrument deployment, mini rovers for long range exploration, and mole type penetrators. Of these, the drilling/sample handling devices and the micro rovers are covered in more detail, with references to papers describing their developments.	planetary scanner;robot	A. Chicarro;G. Scoon;Peter Putz	1998	Robotics and Autonomous Systems	10.1016/S0921-8890(97)00059-6	simulation;robotics;surface	Robotics	56.018075790072764	-30.572920204996947	89934
702ce394f1e9d120fc41b98ea3d8d22eca91af9c	using mini robots for prototyping intersection management of vehicles		In this paper, an environment for prototyping algorithms for the autonomous intersection management of vehicles is presented. It is based on a colony of Khepera mini robots that cooperate via radio communication to enable a collision-free passing of an intersection. The design of the environment, a simple distributed algorithm, and results from first experiments are described. Compared to other work, multiple robots can pass the intersection simultaneously.		Matthias Grünewald;Carsten Rust;Ulf Witkowski	2005		10.1007/3-540-29344-2_43	embedded system;simulation	Robotics	56.956027129089385	-25.48540634828348	89940
49279e7812845f98ca53b8bdaee7fe4481bb9e22	measurement and analysis of train motion and railway track characteristics with inertial sensors	railways;measurement;inertial forces;track design;sensors;feature based localization purpose train motion measurement train motion analysis railway track characteristic inertial sensor inertial measurement unit imu microelectromechanical system mems passenger transport service urban railway environment track feature detection;motion;railroad trains;feature extraction;acceleration tracking sensors vibrations gyroscopes rail transportation engines;microelectromechanical system mems device;nachrichtensysteme;motion measurement;railways feature extraction microsensors motion measurement;microsensors;railroad tracks	This paper presents measurements of train motion with a low-cost inertial measurement unit (IMU) based on micro electro mechanical systems (MEMS). The measurements were recorded on-board a train during normal passenger transport service on a network with dense urban railway environment as well as a rural, regional network environment. Sensor measurements from several train runs were therefore analyzed and the data is presented with a discussion on typical characteristics, noise and dynamics. As the train motion is dependent on the track, local track characteristics are inferred from the train motion measurements. Finally, the inertial measurements are analyzed toward track feature detection for feature based localization purposes.	course (navigation);feature detection (computer vision);feature detection (web development);hardware acceleration;image noise;internationalization and localization;low-pass filter;microelectromechanical systems;on-board data handling;repeatability;sensor;signal-to-noise ratio;simulation;traction teampage;yaws	Oliver Heirich;Andreas Lehner;Patrick Robertson;Thomas Strang	2011	2011 14th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2011.6082908	embedded system;electronic engineering;simulation;engineering	Robotics	56.14834979640262	-36.48597281713362	90066
d160e2bdb07d5e571a06bf473a576ec7874e7e7e	kinematics analysis for obstacle-climbing performance of a rescue robot	ccd camera;search and rescue;kinematics robot sensing systems character generation temperature sensors mechanical systems explosives gas detectors mechanical sensors charge coupled devices robot vision systems;kinematic analysis;geometry parameter;obstacle climbing performance;service robots;kinematics analysis;geometry parameter kinematics analysis obstacle climbing performance rescue robot robot tracking mechanical system suspension system ccd camera center of gravity stability angle margin robot pitch angle;stability ccd image sensors robot kinematics service robots;ccd image sensors;stability;robot tracking;tracked robot;mechanical system;center of gravity;mechanical systems;stability angle margin;robot pitch angle;cg kinematics model tracked robot rescue robot;cg kinematics model;robot kinematics;suspension system;rescue robot	A tracked robot is designed for destroyed mine search and rescue. The mechanical system is introduced from reconfigurable structure, suspension system and anti- explosive and waterproof. The sensors include CCD camera, CO, CH4, temperature and air speed are equipped on the robot. Two pairs of swing arms are equipped on the robot. Their motions help robot climb up obstacle. Because the center of gravity (CG) plays an important role in the process of climbing up an obstacle, the CG kinematics model is built. Using this model, the CG change situation is obtained, and the maximum height of the obstacle which can be climbed up is obtained, and the stability angle margin is obtained too. The relationship between the robot pitch angle and the height of the obstacle is obtained. Using this relationship, the geometry parameter of the uncertain environment can be known. These analysis help to design and control the robot.	charge-coupled device;coat of arms;inverse kinematics;pitch (music);rescue robot;sensor;time-of-flight camera;velocity obstacle	Weidong Wang;Zhijiang Du;Lining Sun	2007	2007 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2007.4522406	control engineering;computer vision;bang-bang robot;simulation;computer science;engineering;artificial intelligence;snake-arm robot;mechanical system;robot kinematics;robot calibration	Robotics	62.272700707735	-30.59178891524186	90086
1c3b19364be8ffcd63b88ad9bd88ac09cc6ce8ed	relative position localizing system for multiple autonomous mobile robots in distributed robotic system: system design and simulation	laser beam;robot movil;distributed system;relative position;baliza;systeme reparti;autonomous system;localization;localizacion;robotics;autonomous mobile robot;haz laser;local system;sistema autonomo;sistema repartido;localisation;robot mobile;system design;systeme autonome;stereo vision;sensor array;robotica;location area;coordinacion;faisceau laser;robotique;balise;moving robot;beacon;coordination;distributed robotics	Coordination strategies and algorithms for a system with multiple autonomous mobile robots often require a robot to know the relative position of other robots in its vicinity (Beni and Wang, 1991; Wang, 1993; Wang and Premvuti, 1994). Many experimental systems employ centralized localization mechanisms, which are invalid for a fully distributed robotic system. An ideal mechanism for relative localization is a fully autonomous passive sensing system (Graefe, 1989; Miura and Shirai, 1994), such as stereo vision, which involves great degree of sophistication and high cost. In this paper, an alternative autonomous relative localization strategy is proposed. Measurement of distance is based on detecting linear velocity of a vertical slit laser beam from a rotating beacon that projected on the photodiode array mounted in round belt shape installed on a robot. Linear velocity of sweeping beam on the sensor array can be interpreted as the distance from a beacon based on an equation. u = rw, where u is the linear velocity of the laser beam projected on sensor array which can be measured, r is the distance from a beacon to the sensor array which we want to know, and w is the angular velocity of beacon which is constant and known. Direction is also detected by locating area on the sensor array where the beam is projected and finding the center of that area.	autonomous robot;mobile robot;simulation	Suparerk Premvuti;Jing Wang	1996	Robotics and Autonomous Systems	10.1016/0921-8890(95)00087-9	beacon;embedded system;computer vision;simulation;internationalization and localization;computer science;autonomous system;stereopsis;artificial intelligence;robotics;sensor array;local system;systems design	Robotics	58.39832056030202	-32.24027006220329	90221
7c8024fa19ce1a11813419fa3ef10475bcc5a916	the golem project: evolving hardware bodies and brains	printing;fabrication;microwave integrated circuits;evolutionary computation;robots controllers logic design electromechanical filters;electro mechanical machines;3d solid printing;logic design;building block;hardware fabrication morphology evolutionary computation computer science fabrics neurons solids printing microwave integrated circuits;evolvable hardware;virtual ancestors golem project hardware bodies brains evolutionary techniques electro mechanical machines robots hardware controllers virtual diversity electromechanical systems linear actuators neurons 3d solid printing;virtual diversity;morphology;virtual ancestors;brains;controllers;golem project;robots;hardware controllers;fabrics;electromechanical systems;evolutionary techniques;neurons;computer science;hardware bodies;electromechanical filters;linear actuators;solids;hardware	The GOLEM project is an attempt to extend evolutionary techniques into the physical world by evolving diverse electro-mechanical machines (robots) that can be fabricated automatically. In this work we go beyond evolution of hardware controllers and demonstrate for the first time a path that allows transfer of virtual diversity of morphology into reality. Our approach is based on the use of only elementary building blocks in both the design and embodiment. We describe a set of preliminary experiments evolving electromechanical systems composed of thermoplastic, linear actuators and neurons for the task of locomotion, first in simulation then in reality. Using 3D solid printing, these creatures then replicate automatically into reality where they faithfully reproduce the performance of their virtual ancestors.	elementary;experiment;mathematical morphology;printing;robot;self-replicating machine;simulation	Jordan B. Pollack;Hod Lipson	2000		10.1109/EH.2000.869340	control engineering;simulation;engineering;artificial intelligence	Graphics	65.4423961126135	-26.83169705031154	90538
5bb7f9f215c4ecc7d0e6ce9e7a206267fa3cecbe	exploiting human walking speed transitions using a dynamic bipedal walking robot with controllable stiffness and limb coordination		In this paper, we employ a two-dimensional dynamic bipedal walking robot to investigate the effects of controllable stiffness and limb coordination on speed transition of bipedal walking. The robot is equipped with a variable stiffness actuator at each joint. We proposed a central pattern generatorbased control method to implement limb coordination and realize independent control of torque and stiffness for the robot. Then we carry out human motion experiments on speed transitions. The comparison of hip joint kinematics and ground reaction forces between human and the robot during speed transitions shows that variable stiffness and limb coordination are important for adaptive human walking and can improve the performance of bipedal walking robot. The results may be used to exploit possible principles of complex human gaits.	central pattern generator;experiment;kinesiology;mobile robot;performance;stiffness	Yan Huang;Baojun Chen;Libo Meng;Zhangguo Yu;Xuechao Chen;Qiang Huang;Qining Wang	2016	2016 IEEE-RAS 16th International Conference on Humanoid Robots (Humanoids)	10.1109/HUMANOIDS.2016.7803323	simulation;control theory	Robotics	67.63221660457546	-24.197184980380023	90669
0aca840390231092f7a87cad8e10ec5611c8156c	coordinated mobile manipulator point-stabilization using visual-servoing techniques	cameras manipulators open loop systems robot kinematics feedback control mobile robots orbital robotics robot vision systems displacement control computer science;control algorithm;computer vision manipulator kinematics feedback stability servomechanisms;hybrid control;manipulator kinematics;computer vision;stability;feedback;servomechanisms;mobile manipulator;visual servoing;coordinated control mobile manipulator stabilization visual servoing hybrid control sensor based feedback planar manipulator mobile base kinematic model;feedback control	In this paper we consider the problem of stabilizing in a desired configuration a mobile manipulator; only the arm’s joint displacements information and the measures provided by a camera mounted on the end-effector are used to stabilize the system. In particular, no knowledge about the position and the orientation of the mobile base is supposed to be available. An hybrid control algorithm, based on the concatenation of a sensor-based feedback control and an open-loop strategy, is proposed. A 3-dof planar manipulator mounted on a mobile base, modelled as an unicycle, is considered as case study, and simulation results are reported in order to demonstrate the capabilities of the proposed control algorithm.	algorithm;coat of arms;concatenation;control theory;feedback;mobile manipulator;mobile operating system;mobile robot;optimal control;robot end effector;robotic mapping;simulation;technological singularity	Marco Gilioli;Claudio Melchiorri	2002		10.1109/IRDS.2002.1041406	control engineering;computer vision;parallel manipulator;computer science;engineering;mobile manipulator;control theory;feedback	Robotics	60.92187686309293	-30.798918164729	91320
2059e975f74346ca2be33e1e646f5a3432323dbf	optical beacon sensor for small unmanned aerial system state estimation		A new optical sensor system is presented that measures a reference vector direction relative to the body frame of a small unmanned aircraft system (sUAS) at medium ranges in daylight conditions with high precision and without drift using a low-power, nonlaser, eye-safe optical beacon. The beacon operates as a monochromatic, time-modulated optical source, and the airborne sensor uses both optical band-pass filtering and frequency domain signal processing to separate the beacon signal from reflected and scattered sunlight incident on the sensoru0027s aperture, thus providing increased sensitivity. Characterization of the prototype sensor shows that the reference-vector direction angles can be measured with an accuracy of better than 0.5% of the field of view, resulting in 0.1° accuracy over a 30 degree range, at a measurement update rate of 200 Hz. This result is based on an operating range of 134 m using a 1 W beacon with a 9° beamwidth. The prototype system was integrated into and tested on a small UAS. Flight test results are presented comparing the prototype sensor systemu0027s output to an estimate of the reference-vector direction produced by fusing inertial measurement and GPS information, thus demonstrating how this sensor system offers a method of validating sUAS attitude estimation systems. The sensor system may also be used to augment sUAS attitude estimation systems, or for other purposes such as in a precision sUAS landing system or for state estimation in GPS-denied environments.	aerial photography;unmanned aerial vehicle	Douglas Weibel;Dale Lawrence;Scott Palo	2017	J. Field Robotics	10.1002/rob.21648	simulation;telecommunications;remote sensing	Robotics	56.270375408069256	-33.57507598746622	91678
7efeac1c9d7161e471677aafef5bd58e2d944241	auv docking system for sustainable science missions	autonomous underwater vehicle;fuzzy logic remotely operated vehicles underwater vehicles oceanographic equipment oceanographic regions oceanographic techniques;underwater vehicles;technological development;oceanographic regions;remotely operated vehicles;fuzzy logic;evolutionary biology;system design;molecular biology;oceans environmental factors evolution biology sea measurements chemical technology marine technology underwater vehicles chemistry geology instruments;microbiology;mid ocean ridge;fuzzy logic based solution auv docking system sustainable science missions physical oceanography ocean chemistry midwater ecology biological oceanography molecular biology marine microbiology geology evolutionary biology benthic ecology coastal ocean deep ocean midocean ridge polar regions navigational sensors science pay loads;oceanographic equipment;oceanographic techniques	In this paper, we present a technological development of an autonomous underwater vehicle (AUV) docking system motivated by science requirements. Twenty-seven case studies were drafted after having elaborate discussions with twelve senior marine scientists from a wide range of oceanographic fields including physical oceanography, ocean chemistry, midwater ecology, biological oceanography, molecular biology, marine microbiology, geology, evolutionary biology, and benthic ecology. These science cases spread over coastal ocean, deep-ocean, mid-ocean ridge, and polar regions. All of these science missions can be significantly benefited from new and improved sets of data and samples that will be collected by using a docked AUV. The case studies are organized to address the science issue, significance of the problem, required data and measurements to address the scientific importance, a non-docked method for acquiring data, and the benefit of using a docked AUV. More than twenty science instruments (in addition to navigational sensors) are identified and evaluated for these science missions. Science pay loads for the AUV and the docking system are discussed in detail. Functional requirements for a general purpose docking system are identified and pros and cons of various docking subsystems are explained. A fuzzy logic based solution approach for an autonomous docking system design and development is also proposed in this paper.	autonomous robot;docking (molecular);ecology;fuzzy logic;requirement;sensor;systems design	Tarun Kanti Podder;Mark Sibenac;James Bellingham	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1302423	fuzzy logic;mid-ocean ridge;remotely operated underwater vehicle;oceanography;computer science;engineering;marine engineering;systems design	Robotics	55.73968795517393	-30.57964543161944	91795
fdfef6a6843a8c007287dfb50c049c479a9e34e3	off-world robotic excavation for large-scale habitat construction and resource extraction	excavation;resource extraction;robotics	This paper describes technologies we have developed to perform autonomous large-scale off-world excavation. A scale dragline excavator of size similar to that required for lunar excavation was made capable of autonomous control. Systems have been put in place to allow remote operation of the machine from anywhere in the world. Algorithms have been developed for complete autonomous digging and dumping of material taking into account machine and terrain constraints and regolith variability. Experimental results are presented showing the ability to autonomously excavate and move large amounts of regolith and accurately place it at a specified location.	algorithm;autonomous robot;habitat;spatial variability	Matthew Dunbabin;Peter I. Corke;Graeme J. Winstanley;Jonathan M. Roberts	2006			excavation;digging;terrain;simulation;remote operation;computer science;regolith;dragline excavator;natural resource;artificial intelligence;robotics	AI	55.418136438624984	-29.831531571385682	91810
e8546c87f0e30af38ba5d395464f33d05a3b7b57	rtr-trees for space robotics behavior simulation and visualization	robotics;motion simulation;space robotics;computer animation	New types of trees of structures and linked lists with variable order relations (RTR-trees and RTR-lists) are discussed. Using them enables application of the direct kinematic scheme for simulation of 3D-objects with reorderable structure, making behavior simulation more natural.	linked list;real-time recovery;robotic spacecraft;robotics;simulation;x3d	Valery Afanasiev;Dmitry Baigozin;Ilia Kazanski;Sergey Fomin;Stanislav V. Klimenko	2007	The Visual Computer	10.1007/s00371-007-0112-0	computer vision;simulation;computer science;computer animation;robotics;computer graphics (images)	Robotics	65.76674281984701	-31.641116844230172	91854
0f81d2509f72705ded44c75f2e049d6126e7ea65	development of sensor system of a small biped entertainment robot	equipement audiofrequence;modelizacion;robot movil;medicion esfuerzo;sensor system;reproduccion sonido;reproduction son;force sensors;legged locomotion;trunk;biped robot;safety systems;hombre;service robots;transductor fuerza;foot;capteur force;sound reproduction;robotics;image sensors;sensor systems robot sensing systems force sensors legged locomotion humans prototypes machine vision hardware foot domestic safety;dynamique robot;modelisation;captador medida;measurement sensor;capteur mesure;robot vision;robot mobile;locomocion bipedo;image acquisition;force transducer;human;mesure force;tronco;force measurement;robotica;audio equipment;sensor fusion legged locomotion service robots image sensors force sensors safety systems robot vision;vision artificielle;robotique;sensor fusion;bipedal walking;tronc;equipo audiofrecuencia;robot dynamics;pie;artificial vision;safety sensor system small biped entertainment robot vision sensor system distance image acquisition audio sensor system technology inclination sensor system force sensor system dynamic motion;modeling;locomotion bipede;audio acoustics;moving robot;force sensor;pied;homme;acoustique audio;vision artificial	SDR-4X II is the latest prototype model which is a small biped entertainment robot. We improved the SDR-4X. In this paper we report about the sensor system of this robot which is important and essential for a small biped entertainment robot which can be used in the home environment. One technology is the design of a vision sensor system. The configuration and the distance image acquisition are explained. Another technology is the audio sensor system technology which obtains the sound and the voice information. The hardware system and the direction recognition are explained. Next technology is the inclination sensor system and the force sensor system which obtains the inclination of the trunk and the foot with force. These sensor systems are the key to make the biped robot walking and dynamic motion highly stable. The robot is used in normal home environment, so we should strongly consider the safety for humans. Lastly we explain the safety sensor system for humans.	entertainment robot;mobile robot;prototype;sensor	Tatsuzo Ishida;Yoshihiro Kuroki	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1307222	control engineering;computer vision;simulation;systems modeling;computer science;engineering;artificial intelligence;social robot;image sensor;sensor fusion;robot control;robotics;system safety;foot;force-sensing resistor	Robotics	63.40792729908617	-32.44316474699969	92163
c4abdd691bd6bca9f121e2ae7866cfe4cdfec8ae	passivity-based iterative learning control for visual feedback system	robot vision adaptive control closed loop systems iterative methods learning systems observers pose estimation;control systems;closed loop systems;iterative learning control;adaptive control;camera control;visualization cameras control systems estimation error observers jacobian matrices iterative methods;observers;learning systems;iterative methods;visualization;robot vision;closed loop system passivity based iterative learning control three dimensional visual feedback systems visual motion observer pose control error system control law convergence analysis;visual feedback;estimation error;iteration method;jacobian matrices;cameras;pose estimation	This paper investigates iterative learning control based on passivity for three-dimensional (3-D) visual feedback systems. Firstly, a brief summary of a visual motion observer is given. Next, a pose control error system for iterative learning control that has an output strictly passivity property is constructed. Then, iterative learning control for 3-D visual feedback systems is proposed. The transient response of the proposed control law should be improved because of the repeatability. Convergence analysis of the closed-loop system is discussed based on passivity. Finally, simulation results are shown in order to confirm the proposed method.	iterative method;optimal control;repeatability;simulation	Toshiyuki Murao;Hiroyuki Kawai;Masayuki Fujita	2011	2011 IEEE International Conference on Control Applications (CCA)	10.1109/CCA.2011.6044394	control engineering;computer vision;computer science;control theory;iterative learning control	Robotics	61.05253876434331	-32.13793362761183	92245
43ac213c243194f2dd2c9bc4464e861ee0a6fbfc	fuzzy-genetic decision optimization for positioning of military combat units	near optimal unit position combination;simulated battle fuzzy genetic decision optimization military combat unit positioning fuzzy logic module genetic algorithm near optimal unit position combination human expert;human expert;military combat unit positioning;fuzzy genetic decision optimization;systems engineering and theory genetic algorithms weapons decision support systems intelligent vehicles fuzzy logic humans computer architecture design optimization fuzzy systems;design optimization;genetics;systems engineering and theory;fuzzy logic;computer architecture;intelligent vehicles;search problems military computing decision support systems genetic algorithms digital simulation fuzzy logic;decision support systems;genetic algorithm;genetic algorithms;humans;search problems;simulation model;fuzzy logic module;weapons;fuzzy systems;digital simulation;military computing;simulated battle	Fuzzy-genetic decision optimization solved a problem of positioning military combat units for optimum performance. It used a simulation model to evaluate solutions, a fuzzy logic module to map simulation outputs to a single fitness value, and a genetic algorithm to search the t,errain for a near-optimal combination of unit positions. In this study, the fuzzy-genetic system outperformed a human expert during a simulated battle.	extrapolation;fuzzy logic;genetic algorithm;mathematical optimization;simulation	Robert H. Kewley;Mark J. Embrechts	1998		10.1109/ICSMC.1998.726634	simulation;genetic algorithm;decision support system;computer science;artificial intelligence;fuzzy control system	AI	55.065262047932734	-24.646363675113296	92396
a030a6ca7bacf1a309cdf5070f75de38719f87de	research on alignment of camera and receptacle during the autonomous aerial refueling	autonomous aerial refueling;platform control;camshift algorithm;image tracking	The technique of the boom docking into the receptacle of the receiver is a difficult problem in the procedure of autonomous aerial refueling. The technique by image tracking is a hot solution to the problem and appropriate image information is required to calculate the coordinates of the target rigidly. A camera platform control system based on CamShift algorithm merged with Current Statistical model is proposed in this paper to adjust camera angle for the target tracking. The position and dimensions of the tracked target could be acquired by the CamShift algorithm, accordingly the camera can be controlled to turn to the target. To solve the background interference and occlusion problem, frame interpolation and tracking model are introduced. The simulation results show that the camera by the control way introduced in this paper is able to aim at the target when the speed of the target is in the required limit.	aerial photography	Qiuling Jia;Shuzheng Shi;Yaohong Qu;Guangwen Li	2012		10.1007/978-3-642-33509-9_31	control engineering;computer vision;simulation;engineering	Vision	59.131192033358175	-31.618281769505145	92546
bebed8aabd2e921adc100a38f8eebc54dacaf274	location of a dragline bucket in space using machine vision techniques	automatic control;closed loop system;dragline bucket location;position feedback;control systems;motion control;flexible manufacturing systems;image segmentation;machine vision control systems automatic control space technology motion control automation flexible manufacturing systems australia cameras image segmentation;closed loop systems;television applications;rope length;bucket motion control;television cameras;computer vision;feedback;experimental results dragline bucket location machine vision rope length boom position camera image segmentation angle vertical boom plane position feedback closed loop system bucket motion control colour intensity;space use;machine vision;cranes computer vision image segmentation closed loop systems feedback television cameras television applications;boom position;cranes;space technology;experimental results;angle;cameras;intensity;australia;vertical boom plane;camera;colour;automation	Because a dragline bucket's rigging is flexible, its position cannot be inferred from knowledge of rope length and boom position only. Moreover, active devices cannot be placed on the bucket itself to sense position because of the risk of damage. This paper describes a new machine vision system which is being developed to sense bucket position remotely. It is based on a single camera observing the field in which the bucket moves. An image segmentation process is used to classify the bucket and to identify its position in the scene. This data is used to determine the angle between the bucket and the vertical boom plane, which is used as position feedback in a closed loop system to control bucket motion. The segmentation processes employed, based on colour and intensity are outlined, and experimental results are presented. >	leaky bucket;machine vision	David W. Hainsworth;Peter I. Corke;Graeme J. Winstanley	1994		10.1109/ICASSP.1994.389916	motion control;computer vision;simulation;machine vision;computer science;automation;automatic control;professional video camera;feedback;space technology;intensity;image segmentation;angle	DB	60.49979582598618	-34.71131798570217	92563
54d19150773add1be09e9f21ef0fb1dcf25dd7c5	tracking prediction to avoid obstacle path of agricultural unmanned aerial vehicle based on particle filter			aerial photography;particle filter;unmanned aerial vehicle	Xihai Zhang;Chengguo Fan;Junlong Fang;Suijia Xu;Jiali Du	2018	J. Systems & Control Engineering	10.1177/0959651817710128	obstacle;particle filter;computer vision;artificial intelligence;computer science	Robotics	53.78792338611745	-36.0861445779222	92617
6c0f026dda00c8629a9fa891f833c6e4800beeac	velocity control for safe robot guidance based on fused vision and force/torque data	velocity control force sensors image fusion man machine systems robot vision safety;heterogeonous multisensor fusion;velocity control;force torque sensor human robot cooperation industrial robot workspace supervision difference image method heterogeonous multisensor fusion vision;force sensors;workspace velocity control safe robot guidance fused vision force torque data human robot cooperation force torque sensor cameras difference image method;image fusion;heterogeneous data;workspace supervision;robot vision;human robot cooperation;industrial robots;safety;force torque sensor;velocity control robot vision systems robot sensing systems cameras force sensors torque robot motion human robot interaction fuses sensor fusion;vision;man machine systems;difference image method;industrial robot	We present a method for securing guided robot motions in terms of human/robot cooperation. For this, we limit the maximum allowable velocity of the robot based on the distance to the human or to the next obstacle and generate the effective velocity using guidance informations provided by the interacting human. Therefore, we fuse the two heterogenous data types of a camera and a force torque sensor. The cameras are used to monitor the robot's workspace applying a difference image method. Given this obstacle information, distances are calculated between the robot and humans or objects in the environment respectively. The distance within each image is determined via an extended difference image method. The distances acquired from each camera are fused to approximate the real robot to object distance within the workspace. This distance regulates the maximum allowable velocity of the robot. The force/torque sensor provides the guidance information, i.e. amount, direction of the force and moment. This information is used to generate the robot's movement taking the maximum allowable velocity into consideration	approximation algorithm;image impedance;interaction;robot;velocity (software development);workspace	Stefan Kuhn;Thorsten Gecks;Dominik Henrich	2006	2006 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems	10.1109/MFI.2006.265623	control engineering;computer vision;bang-bang robot;cartesian coordinate robot;simulation;engineering;robot kinematics;robot calibration	Robotics	61.04656780248908	-30.613116195458762	92675
9c79dfc2394d1192643a7898e3d7962253e9c796	urban vehicle platoon using monocular vision: scale factor estimation	odometric data;inter vehicle communications;odometric data urban vehicle platoon monocular vision scale factor estimation environment sustainable development transportation service urban areas automated electric vehicles vehicle platooning global control strategy inter vehicle communications vehicle absolute localization virtual vision world telemetric data;automated electric vehicles;monocular vision;oscillations;transport service;measurement;virtual vision world;road traffic;vehicle absolute localization;vehicles trajectory telemetry measurement noise visualization cameras;mobile robots;nonlinear control;transportation artificial intelligence electric vehicles mobile robots road traffic;visualization;urban areas;trajectory;transportation service;automatic guided vehicle;urban vehicle platoon;scale factor estimation;environment;transportation;comparative study;electric vehicles;urban area;artificial intelligence;automatic guided vehicles;vehicles;telemetry;global control strategy;telemetric data;urban vehicles;electric vehicle;inter vehicle communication;vehicle platooning;platooning;cameras;control strategy;sustainable development;urban vehicles automatic guided vehicles platooning nonlinear control monocular vision;noise	Environment, sustainable development as well as new transportation service emergence in urban areas are major concerns. Consequently, studies are currently intended to automate electric vehicles designed for applications in free access. An additional functionality that appears very attractive is vehicle platooning. In order to avoid oscillations within the fleet when completing this task, a global control strategy, supported by inter-vehicle communications, is investigated. Vehicle absolute localization is then needed and is here derived from monocular vision. These data are however expressed in a virtual vision world, slightly distorted with respect to the actual metric one. It has previously been shown that such a distortion can accurately be corrected on-line in different ways, considering telemetric or odometric data. These strategies have here been refined in order to provide optimal corrections. A comparative study, supported by simulations and full-scale experiments, is reported to exhibit benefits and performances of proposed approaches.	control theory;distortion;emergence;experiment;full scale;line level;online and offline;performance;platoon (automobile);simulation	Pierre Avanzini;Benoit Thuilot;Philippe Martinet	2010	2010 11th International Conference on Control Automation Robotics & Vision	10.1109/ICARCV.2010.5707943	mobile robot;computer vision;transport;simulation;visualization;nonlinear control;computer science;engineering;monocular vision;noise;artificial intelligence;trajectory;comparative research;telemetry;transport engineering;natural environment;oscillation;sustainable development;measurement	Robotics	58.621394244391205	-27.03650523306936	92689
8795640ea4a80941d95223f51ffa426eebdf7e92	environmental complexity control for vision-based learning mobile robot	velocity control;mobile robot;path planning;mobile robots;goalkeeper environmental complexity control vision based learning mobile robot state vector collisions avoidance;robot vision identification mobile robots path planning learning artificial intelligence velocity control;robot vision;mobile robots adaptive systems artificial intelligence autonomous agents robot vision systems psychology animal behavior acceleration learning state estimation;identification;state space;learning artificial intelligence	This paper discusses how a robot can develop its state vector according to the complexity of the interactions with its environment. A method for controlling the complexity is proposed for a vision-based mobile robot of which task is to shoot a ball into a goal avoiding collisions with a goal keeper. First, we provide the most di cult situation (the maximum speed of the goal keeper with chasing-a-ball behavior), and the robot estimates the full set of state vectors with the order of the major vector components by a method of system identi cation. The environmental complexity is de ned in terms of the speed of the goal keeper while the complexity of the state vector is the number of the dimensions of the state vector. According to the increase of the speed of the goal keeper, the dimension of the state vector is increased by taking a trade-o between the size of the state space (the dimension) and the learning time. Simulations are shown, and other issues for the complexity control are discussed.	computer simulation;control theory;interaction;keeper (password manager);mobile robot;quantum state;state space	Eiji Uchibe;Minoru Asada;Koh Hosoda	1998		10.1109/ROBOT.1998.680514	mobile robot;robot learning;computer vision;simulation;computer science;engineering;artificial intelligence;social robot;robot control;mobile robot navigation	Robotics	58.25626544534187	-24.282841950855623	92721
712115f791de02aafc675ee84090fdf8e4ed88a5	elastic bands: connecting path planning and control	robot sensing systems;control systems;robots computerised control path planning;control theory;computerised control;uncertainty;path planning;real time;bubbles;bubbles global path planning real time sensor based robot control elastic band deformable collision free path uncertainties;real time sensor based robot control;uncertainties;robot control;shape;efficient implementation;elastic band;deformable collision free path;robots;global path planning;joining processes;joining processes path planning robot sensing systems control systems laboratories computer science robot control shape uncertainty control theory;computer science	Elastic bands are proposed as the basis for a new framework to close the gap between global path planning and real-time sensor-based robot control. An elastic band is a deformable collision-free path. The initial shape of the elastic is the free path generated by a planner. Subjected to artificial forces, the elastic band deforms in real time to a short and smooth path that maintains clearance from the obstacles. The elastic continues to deform as changes in the environment are detected by sensors, enabling the robot to accommodate uncertainties and react to unexpected and moving obstacles. While providing a tight connection between the robot and its environment, the elastic band preserves the global nature of the planned path. This paper outlines the framework and discusses an efficient implementation based on bubbles.	amazon elastic compute cloud (ec2);elastic net regularization;jean;motion planning;planner;real-time clock;real-time computing;robot control;ross quinlan;sensor;servo	Sean Quinlan;Oussama Khatib	1993		10.1109/ROBOT.1993.291936	robot;control engineering;computer vision;simulation;uncertainty;shape;computer science;engineering;control system;artificial intelligence;motion planning;robot control	Robotics	63.72333969516872	-25.15117597994073	92931
0ea6c12d6bb913f8b8fa7fb9f64d4caee81c2f0a	vehicular localization and intelligent transportation systems	recursive estimation;predictive control;swarm intelligence;motion control;distributed processing;automated highways;hybrid intelligent systems helium electromagnetic interference;swarm intelligence automated highways collision avoidance control engineering computing distributed processing feedback motion control on board communications predictive control recursive estimation;feedback;inter vehicular communication swarm logic model predictive control;control engineering computing;collision avoidance;cluttered indeterminist environment vehicular localization intelligent transportation systems swarm logic based approach inter vehicular communication distributed computing dsrc framework dedicated short range communication for inter vehicular communication us department of traffic darpa defense advanced research projects agency european commission save u project sensors and system architecture for vulnerable road users protection project autonomous unmanned ground system aerial vehicular systems recursively obtained sensor readings feedback loop mode model predictive approach nonlinear state functions recursive estimation collision avoidance target localization robot formation control;on board communications	We present a Swarm Logic based approach to vehicular localization and inter-vehicular communication using a distributed computing environment. Our work is towards the development of an application for the DSRC framework (Dedicated Short Range Communication for Inter-Vehicular Communication) by US Department of Traffic and DARPA (Defense Advanced Research Projects Agency) and European Commission- funded Project SAVE-U (Sensors and System Architecture for Vulnerable road Users Protection) and is a step towards Intelligent Transportation Systems such as Autonomous Unmanned Ground and Aerial Vehicular systems. The application depends on recursively obtained sensor readings in a feedback loop mode for processing and deploying a corrective action based on Model Predictive approach that exploits non-linear functions of the state and finds control inputs such as state of system, position, acceleration, peer movement to recursively estimate and improve the quality of resulting estimation for collision avoidance and target localization. The problem addresses is not only restricted to localization of target but to control a formation of robots in a cluttered indeterminist environment.	distributed computing environment;feedback;linear function;nonlinear system;recursion;robot;sensor;swarm;unmanned aerial vehicle	Mayur Parulekar;Dhaval Shroff;Viraj Padte;Harsh Nangalia;Akash Metawala	2012	2012 12th International Conference on Hybrid Intelligent Systems (HIS)	10.1109/HIS.2012.6421352	control engineering;simulation;engineering;vehicular communication systems;computer security	Robotics	56.40097531564629	-28.830491684663325	93002
2c71034a8c6e4463dacef38737367bca6cb5e1eb	small robot agents with on-board vision and local intelligence	sensor system;group behavior;autonomous mobile robot;local intelligence;operating system;robot agent;map generation;robot soccer;on board vision;eyebot;color image	We designed a family of completely autonomous mobile robots with local intelligence. We developed a controller with a variety of digital and analog I/O facilities and the operating system RoBIOS, which allows maximum flexibility. The robots have a number of on-board sensors, including vision, and do not rely on global sensor systems. The on-board computing power is sufficient to analyze several color images per second. This enables the robots to perform several different task such as navigation, map generation or intelligent group behavior and does not limit them to the game of robot soccer.	on-board data handling;robot	Thomas Bräunl;Birgit Graf	2000	Advanced Robotics	10.1163/156855300741438	mobile robot;computer vision;simulation;color image;computer science;engineering;artificial intelligence;social robot;robot control;ubiquitous robot;mobile robot navigation;personal robot;group dynamics	Robotics	57.81521061105562	-31.499708625722526	93014
a6520c0015bf6fe58d948e2df2095633de3cf43e	multi-robot coordination with balanced task allocation and optimized path planning	neural networks;optimal path planning;path planning;multiple mobile robot coordination;path planning mobile robots multi robot systems;mobile robots;balanced task allocation;automated path generation;multiple mobile robots;optimal path;multi robot systems;optimized path planning;environmental uncertainty;multi robot coordination;environmental uncertainty multiple mobile robot coordination balanced task allocation optimized path planning automated path generation shunting equation;neural networks multi robot coordination task allocation path planning;task allocation;neural network;path planning robot kinematics mobile robots robot sensing systems uncertainty neural networks robot control motion planning genetic algorithms orbital robotics;shunting equation	A modification to the well-known shunting equation has successfully created a method of automated path generation. This paper further investigates the integration of automated path generation with task allocation in multi-robot coordination. It presents an algorithm that is able to equally distribute the workload of multiple mobile robots while guiding them to move along optimized paths in the presence of obstacles and environmental uncertainty. Experiment results are also provided in the paper to examine the operation of the proposed algorithm and its application.	algorithm;mobile robot;motion planning;real-time computing;whole earth 'lectronic link	Xiaobu Yuan;Simon X. Yang	2007	2007 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2007.4522301	mobile robot;simulation;computer science;artificial intelligence;machine learning;motion planning;artificial neural network	Robotics	55.81595857848276	-24.145437167535626	93131
3e67973772d35152e8c15c5426aef99295dc5b2c	joint angle estimation for floating base robots utilizing mems imus		This paper describes a novel motion estimation algorithm for floating base manipulators that utilizes low-cost inertial measurement units (IMUs) containing a three-axis gyroscope and a three-axis accelerometer. Four strap-down microelectromechanical system (MEMS) IMUs are mounted on each link to form a virtual IMU whose body's fixed frame is located at the center of the joint rotation. An extended Kalman filter (EKF) and a complementary filter are used to develop a virtual IMU by fusing together the output of four IMUs. The novelty of the proposed algorithm is that no forward kinematic model that requires data flow from previous joints is needed. The measured results obtained from the planar motion of a hydraulic arm show that the accuracy of the estimation of the joint angle is within ± 1 degree and that the root mean square error is less than 0.5 degree.	algorithm;dataflow;extended kalman filter;forward kinematics;gyroscope;mean squared error;microelectromechanical systems;motion estimation;optic axis of a crystal;robot	Xiaolong Zhang;Eelis Peltola;Jouni Mattila	2017	2017 IEEE International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM)	10.1109/ICCIS.2017.8274788	control theory;engineering;control engineering;accelerometer;kinematics;motion estimation;inertial frame of reference;inertial measurement unit;extended kalman filter;mean squared error;gyroscope	Robotics	57.39531504734157	-35.97329470802114	93265
f8d99dbc1b335e15d1cc9c08078edf3180b4cb8e	real-time pattern recognition for guidance of an autonomous undersea submersible	robots computer vision marine systems;autonomous underwater vehicle;control systems;cable tv;pattern recognition underwater vehicles underwater cables oceans microcomputers magnetic sensors cameras cable tv hardware sonar;oceans;image processing;pc bus video frame grabber;underwater vehicles;real time;magnetic sensors;real time pattern recognition;autonomous undersea submersible;computer vision;gray level segmentation;underwater video images;robots;pc at compatible microcomputer computer vision marine systems robots real time pattern recognition gray level segmentation autonomous undersea submersible underwater video images hough transformation pc bus video frame grabber;pc at compatible microcomputer;pattern recognition;guidance;underwater cables;hough transformation;autonomous navigation;hough transform;video signals;guidance and control;reprints;microcomputers;cameras;hardware;marine systems;sonar	This paper reports the initial results of an effort to develop simple and fast vision algorithms on compact and imoeddaDle hardware for the guidance and control of an autonomous underwater vehicle. The specific application involves tracking underwater cables and chains. Feature points are identified in the underwater video images using a technique which combines segmentation by gray level and run length. Hough transformation is then used to find the straight line in the image. The process is performed at a throughput of approximately 1 image per second using a PC-bus video frame grabber and a PC/AT compatible micro-computer.	acoustic cryptanalysis;algorithm;autonomous robot;bus (computing);computer;docking (molecular);exploratory testing;frame grabber;grayscale;hough transform;line level;microcomputer;pattern recognition;real-time locating system;real-time transcription;run-length encoding;throughput	Hoa G. Nguyen;Paul J. Heckman;A. L. Pai	1988		10.1109/ROBOT.1988.12322	hough transform;embedded system;computer vision;simulation;image processing;computer science;engineering;control system	Vision	57.41229477577732	-32.40689626522934	93326
8fa0d4b19ec74c3bcc7509cc9ed500fdc1f48f86	adaptive behavior of a biped robot using dynamic movement primitives		Over the past few years, several studies have suggested that adaptive behavior of humanoid robots can arise based on phase resetting embedded in pattern generators. In this paper, we propose a movement control approach that provides adaptive behavior by combining the modulation of dynamic movement primitives (DMP) and interlimb coordination with coupled phase oscillators. Dynamic movement primitives (DMP) represent a powerful tool for motion planning based on demonstration examples. This approach is currently used as a compact policy representation well-suited for robot learning. The main goal is to demonstrate and evaluate the role of phase resetting based on foot-contact information in order to increase the tolerance to external perturbations. In particular, we study the problem of optimal phase shift in a control system influenced by delays in both sensory information and motor actions. The study is performed using the V-REP simulator, including the adaptation of the humanoid robot’s gait pattern to irregularities on the ground surface.		José Rosado;Filipe Miguel Teixeira Pereira da Silva;Vítor Manuel Ferreira dos Santos	2015		10.1007/978-3-319-23485-4_46	computer vision	Robotics	66.04167429085332	-25.156906523596344	93448
e2f8a9c205450a14b5b6da39b83e2b5bb51550cd	development of pavement surface inspection system for wheel chair comfortability	visualization method pavement surface inspection system development wheel chair comfortability position recognition pavement surface point clouds gathered data analysis;electronic mail;wheels inspection real time systems educational institutions electronic mail data visualization global positioning system;inspection;global positioning system;data visualization;roads computerised instrumentation ergonomics handicapped aids inspection;wheels;real time systems	This paper proposes a pavement surface inspection system for wheel chair comfortability. Our proposed wheel chair, which can recognize its position and gather pavement surface point clouds, displays barriers on the pavement to wheel chair users after analyzing gathered data. We present our concept and discuss a visualization method on this system.	point cloud;scientific visualization	Masataka Sato;Jun'ichi Kaneko;Kazuyuki Kojima	2014	2014 IEEE 3rd Global Conference on Consumer Electronics (GCCE)	10.1109/GCCE.2014.7031314	embedded system;simulation;engineering;forensic engineering	Robotics	61.592180770491	-36.15672503237477	93742
863be918cf92031f66ecf2e517a99e44e0120413	introducing robotic origami folding	space telescope;cmu;art;robots couplings humans robotics and automation kinematics mathematics art concrete optical design containers;planning artificial intelligence art manipulator kinematics;planning artificial intelligence;manipulator kinematics;robot manipulator;foldability theorem origami folding robot paper sculpture art robotic manipulation automatic planner;fast food	Origami, the human art of paper sculpture, is a fresh challenge for the field of robotic manipulation, and provides a concrete example for many difficult and general manipulation problems. This paper presents some initial results, including the world's first origami-folding robot, definition of a simple class of origami for which we have designed a complete automatic planner, an analysis of the kinematics of more complicated folds, and some new theorems about foldability.	robot	Devin J. Balkcom;Matthew T. Mason	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1308754	simulation;spitzer space telescope;engineering;artificial intelligence;mechanical engineering	Robotics	67.0555153326364	-28.647500530333787	93751
18504cc0a23829f05e0cad0415a7c0dd06d9aa8e	particle filtering for map-aided localization in sparse gps environments	map aided localization;filtering;nongaussian errors;aerospace engineering;bayes methods;real time;inertial navigation;mobile robots;remotely operated vehicles;usa councils;gps blackouts;computer vision;navigation;filtering global positioning system road vehicles aerospace engineering inertial navigation remotely operated vehicles mobile robots particle filters robotics and automation usa councils;vision based detection algorithms;global positioning system;sparse gps environments;particle filter;navigation bayes methods computer vision global positioning system;error modeling;detection algorithm;bayesian particle filtering;particle filters;vision based measurements;inertial navigation solutions;robotics and automation;vision based detection algorithms map aided localization sparse gps environments posteriorpose algorithm bayesian particle filtering inertial navigation solutions vision based measurements gps blackouts error modeling nongaussian errors;road vehicles;posteriorpose algorithm;hypothesis test	This study presents the PosteriorPose algorithm, a Bayesian particle filtering approach for augmenting GPS and inertial navigation solutions with vision-based measurements of nearby lanes and stoplines referenced against a known map of environmental features. These relative measurements are shown to improve the quality of the navigation solution when GPS is available, and they are shown to keep the navigation solution converged in extended GPS blackouts. Measurements are incorporated with careful hypothesis testing and error modeling to account for non-Gaussian errors committed by vision-based detection algorithms. The PosteriorPose algorithm is implemented and validated in real-time on Cornell University's 2007 DARPA Urban Challenge entry; experimental data is presented showing the algorithm outperforming a tightly- coupled GPS/inertial navigation solution both in full GPS coverage and in an extended GPS blackout.	algorithm;autonomous robot;computer vision;darpa grand challenge;dead reckoning;global positioning system;inertial navigation system;microsoft windows;particle filter;real-time clock;sensor;sparse matrix;vii	Isaac Miller;Mark E. Campbell	2008	2008 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2008.4543474	control engineering;computer vision;gps/ins;simulation;time to first fix;particle filter;computer science;engineering;assisted gps;statistics	Robotics	54.28617803131712	-36.3097938979872	93877
8d7f3fc70e9de342be9c450997153e494a298fb6	posture estimation of a car-like mobile robot using disturbance conditions	robot movil;position;odometer;mobile robot;real time;gyroscope;odometry;posicion;navigation estimee;orientation;odometre;perturbacion;posture estimation scaling factor of gyroscope;robot mobile;real time gyroscope identification;disturbance condition;orientacion;dead reckoning;perturbation;posture estimation;scaling factor of gyroscope;giroscopio;moving robot;odometro;navegacion a la estima	In this paper, we propose an improved dead-reckoning method for estimating the current position and orientation of a mobile robot using wheel-rotation sensors and a gyroscope. Up to now, a pre-identified model has usually been used to get accurate posture from the gyroscope. However, this model can lose its accuracy during the operation (e.g. due to temperature change). To overcome this limitation, a real-time identification method based on the disturbance condition is proposed so that the gyroscope information can keep its accuracy. The disturbance condition can determine whether there are lateral or longitudinal disturbances or not. Experimental results are presented, which show the effectiveness of our method in contrast with conventional ones.	dead reckoning;gyroscope;lateral thinking;mobile robot;poor posture;real-time clock;sensor	Min Chul Kim;Wan Kyun Chung	1998	Advanced Robotics	10.1163/156855399X00216	dead reckoning;control engineering;mobile robot;computer vision;perturbation;gyroscope;computer science;position;engineering;artificial intelligence;odometry;control theory;orientation;odometer	Robotics	56.81969453571728	-35.581572056042056	93888
f9a837b2ee6cca3eadfbdbd5a03e8e989ae928bb	object-action abstraction for teleoperation	manipulators;hand human telerobotics manipulation grasp;robot programming telerobotics manipulators;relational database;a priori knowledge;object manipulation;feature extraction;telerobotics;robotic grasp object action abstraction teleoperation telerobotic system object manipulation experiment feature extraction human grasp robot controller object centered programming relational database;robot programming;humans orbital robotics telerobotics humanoid robots robot control robot programming end effectors computer science mathematics feature extraction	In telerobotic systems human actions are mapped to robot actions. In an illustrative object manipulation experiment various human grasps were translated to configurationally similar robotic grasps. The experiment's results highlight the problems and suboptimal performance incurred when such a resemblance is maintained. A new approach to telerobotics based on the construction of object-action pairs is presented. Actions are identified in the context of the object they are being performed on according to features extracted from the human grasp and transport motion. A priori knowledge is introduced to the robot controller using object centered programming and a relational database.	heuristic (computer science);kinesiology;relational database;robot;telerobotics	Sigal Berman;Jason Friedman;Tamar Flash	2005	2005 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2005.1571546	telerobotics;computer vision;a priori and a posteriori;simulation;feature extraction;relational database;computer science;artificial intelligence;robot control	Robotics	63.59478069888871	-25.948471739916222	94099
c70619ccdb4e991f7ecf67898068a83b1985e0ac	modellbasierte merkmalsplanung zur objektbezogenen laserscannerbasierten navigation von fahrzeugen		This dissertation presents a novel approach to model-based feature planning for laser scanner-based object-related navigation of vehicles. Robust orientation and motion within natural environments is one of the key tasks in mobile robotics. The precise navigation relative to objects within an environment is a vital capability with respect to the realization of future assistance systems and autonomic functionalities for vehicles, automated guided vehicles and autonomous robots. Within the thesis at hand a navigation system is realized using laser scanners as sensors. Advanced laser scanner technology reliably delivers accurate range data even at varying light conditions and changeable weather. Therefore it is predestined for all indoor and outdoor applications that require a precise and robust relocalization in real-time. The major handicap of laser scanners is their limited field of view – they are capturing range data within discrete scanning planes only. Even worse, the posture of these scanning planes is typically constantly changing due to proper motions of the vehicle. The aim of this work is to introduce a system, that utilizes the best available object feature within a laser scan for feature-based object detection and object tracking at all times. For this reason the concept of laser scanner-based navigation is extended by two fundamental functionalities: feature prediction and feature planning. Feature prediction enables automatic pre-calculation of all object features visible within a laser scan for a freely chosen sensor pose in reference to a target object represented by an object model. This way feature-based object detection algorithms can make use of a dynamically calculated feature vector instead of relying on manually specified sets of object features. This thesis introduces abstract descriptions for the laser scanner and all detectable features within a laser scan as well as specific 3D modeling of target objects. Based on this, efficient algorithms for extracting features from the 3D object model are derived. Feature planning optimizes the alignment of the laser scanner and its scanning planes application-specifically. For this purpose a weighting function is developed that evaluates the results of a respective feature prediction regarding their potential position accuracy, orientation accuracy, stability and unambiguousness. The regarded planning method is applicable for both, fixed and actuated laser scanners. The latter feature an additional actuator which allows to dynamically adjust the sensors orientation in order to track the optimal features of the target object at all times. The theoretical fundamentals for the novel algorithms in this work are verified by practical experiments. Using the example of an assistance system for commercial vehicles it is demonstrated that both performance and range of the laser scanner-based navigation system for vehicles are significantly improved by the innovative methods of model-based feature prediction and feature planning. The results of this work are applicable to all currently available laser scanners and expectable further developments in the future.	3d modeling;3d scanner;algorithm;autonomic computing;autonomous robot;experiment;feature vector;mobile robot;object detection;poor posture;real-time locating system;robotics;sensor;weight function;zur farbenlehre	Roland Stahn	2010			library science;engineering;performance art	Robotics	53.9860473702532	-36.88431970595952	94125
116d6e724d0d15fbb2e84d741477102f9d988ed3	icub whole-body control through force regulation on rigid non-coplanar contacts	noncoplanar contact;force sensors;whole body control;floating base robots;rigid contacts;tactile sensors	*Correspondence: Francesco Nori , Cognitive Humanoids Laboratory, Department of Robotics Brain and Cognitive Sciences, Fondazione Istituto Italiano di Tecnologia, Via Morego 30, Genova 16163, Italy e-mail: francesco.nori@iit.it This paper details the implementation of state-of-the-art whole-body control algorithms on the humanoid robot iCub. We regulate the forces between the robot and its surrounding environment to stabilize a desired posture. We assume that the forces and torques are exerted on rigid contacts. The validity of this assumption is guaranteed by constraining the contact forces and torques, e.g., the contact forces must belong to the associated friction cones. The implementation of this control strategy requires the estimation of both joint torques and external forces acting on the robot. We then detail algorithms to obtain these estimates when using a robot with an iCub-like sensor set, i.e., distributed six-axis force-torque sensors and whole-body tactile sensors. A general theory for identifying the robot inertial parameters is also presented. From an actuation standpoint, we show how to implement a joint-torque control in the case of DC brushless motors. In addition, the coupling mechanism of the iCub torso is investigated.The soundness of the entire control architecture is validated in a real scenario involving the robot iCub balancing and making contact with both arms.	algorithm;apache axis;coat of arms;control theory;email;humanoid robot;icub;poor posture;robotics;sensor	Francesco Nori;Silvio Traversaro;Jorhabib Eljaik;Francesco Romano;Andrea Del Prete;Daniele Pucci	2015	Front. Robotics and AI	10.3389/frobt.2015.00006	simulation;computer science;tactile sensor	Robotics	66.94021535724725	-29.807171580995103	94163
aded82f2fe8b4ba6e257c8f8957d040ef7984ef1	relative navigation algorithm based on rodrigues and spacecraft orbit & attitude information	jacobian matrix;relative position;attitude information;space vehicles aerospace computing attitude control computer vision navigation;relative navigation;computer vision;spacecraft orbit;orbits;navigation;attitude control;theory of computing;computational modeling;aerospace computing;docking;relative navigation algorithm;jacobian matrix rank;relative navigation rodrigues computer vision spacecraft orbit attitude information relative position and pose;spacecraft orbit attitude information;rodrigues;jacobian matrix rank relative navigation algorithm rodrigues spacecraft orbit attitude information space missions space formation space capturing docking computer vision;mathematical model;space missions;relative position and pose;space formation;navigation space vehicles cameras computer vision iterative algorithms orbital calculations space missions sensor systems equations optical imaging;space capturing;cameras;space vehicles	It is vital to calculate the relative position and pose in many important space missions, such as space formation, rendezvous and docking, space capturing and maintenance etc. It is a direction to get the relative position and pose based on computer vision currently all over the world. And this method is also valid for spacecrafts. In this paper, on the basis of the attitude dynamics of spacecrafts and the theory of computer vision, a relative navigation algorithm based-on Rodrigues and the orbit & attitude information of the spacecrafts is proposed. This algorithm reduces the Jacobian matrix rank. Thus, its calculation speed is faster than the quaternion method. Additionally, the iterative numbers of this algorithm are reduced when the orbit & attitude information of the spacecrafts has been used. So the calculation efficiency of this algorithm is improved. Lastly, some simulation results are given to validate the above theoretical conclusions.	algorithm;computer vision;docking (molecular);iterative method;jacobian matrix and determinant;simulation	Kezhao Li;Qin Zhang;Chaoyin Zhao;Jianping Yuan;Keke Xu	2009	2009 Fifth International Conference on Natural Computation	10.1109/ICNC.2009.203	computer vision;simulation;geography;control theory	Robotics	54.58071297212899	-37.79996389192678	94434
b9e1a7530db405ff64f0773947c53d08154f69ed	a normal sensor calibration method based on an extended kalman filter for robotic drilling	extended kalman filter;laser displacement sensor;normal adjustment;parameter identification;robotic drilling system	To enhance the perpendicularity accuracy in the robotic drilling system, a normal sensor calibration method is proposed to identify the errors of the zero point and laser beam direction of laser displacement sensors simultaneously. The procedure of normal adjustment of the robotic drilling system is introduced firstly. Next the measurement model of the zero point and laser beam direction on a datum plane is constructed based on the principle of the distance measurement for laser displacement sensors. An extended Kalman filter algorithm is used to identify the sensor errors. Then the surface normal measurement and attitude adjustments are presented to ensure that the axis of the drill bit coincides with the normal at drilling point. Finally, simulations are conducted to study the performance of the proposed calibration method and experiments are carried out on a robotic drilling system. The simulation and experimental results show that the perpendicularity of the hole is within 0.2°. They also demonstrate that the proposed calibration method has high accuracy of parameter identification and lays a basis for high-precision perpendicularity accuracy of drilling in the robotic drilling system.	angularjs;apache axis;arabic numeral 0;axis vertebra;calibration;correctness (computer science);displacement mapping;experiment;extended kalman filter;geodetic datum;natural science disciplines;normal (geometry);peterson's algorithm;population parameter;psychologic displacement;requirement;robot;simulation;sensor (device)	Dongdong Chen;Peijiang Yuan;Tianmiao Wang;Ying Cai;Haiyang Tang	2018		10.3390/s18103485	calibration;electronic engineering;engineering;drilling;extended kalman filter	Robotics	60.04661327345788	-36.158544688631956	94722
3ed3d49b00531fb5cbdc2e932cba62ab6b07852e	state estimation for swarm uavs under data dropout condition		In this work, a method based on position predicting, velocity filtering and self adaptive parameter tunning is addressed for state estimation and control for swarm of mini unmanned aerial vehicles (UAVs), in order to deal with random noise and data dropout appeared during flights. Under conditions of random data dropout rates and communication latencies, the presented algorithm gives position prediction based on filtered velocity estimation and it fuses the prediction with sensor data. At the same time it corrects the prediction by the error between prediction and measurement of the previous step. The algorithm is designed for tracking mini UAVs with identical marker configuration, and the principles refered is in potential of serving to state estimation in various circumstances. Based on this localization algorithm, a cascade nonlinear control model is developed for swarm UAV control. This work contributes mainly to the object localization and control in a multi-agent system in which all the agents are considered to be in an identical form, hoping that this work will be the testbed for more complicated swarm robot control experiments. Comparison results of state estimation are presented by implementing experiments with or without data dropout.	dropout (neural networks);swarm;unmanned aerial vehicle	Hongzhe Yu;Weifan Zhang;Xinjun Sheng;Wei Dong	2018		10.1007/978-3-319-97586-3_7	engineering;control theory;swarm behaviour;control engineering;nonlinear control;robot control;filter (signal processing);testbed	ML	57.73170255925444	-26.315201336958946	94793
f5a63f1a2be817ef05270c67abd64e9cf2c13fe7	propulsion movement control using cpg for a manta robot	numerical simulation propulsion movement control central pattern generator cpg manta robot auv autonomous unmanned underwater vehicle underwater ecology investigation pectoral fin motion;numerical analysis autonomous underwater vehicles mobile robots motion control	In recent years, Autonomous unmanned Underwater Vehicles (AUVs) for underwater ecology investigation attracts attention from underwater researchers. Although the conventional AUV moves underwater by some screw propellers, it generates a loud noise. Therefore, it is difficult to observe underwater ecology. In this paper, an AUV which mimics a kind of Manta of the fish is developed for underwater living body investigation. Some Central Pattern Generators (CPGs) are also proposed to generate the motion of pectoral fins for the Manta robot. The effectiveness of the proposed method is checked with numerical simulations.	autonomous robot;central pattern generator;computer simulation;ecology;experiment;numerical analysis;unmanned aerial vehicle;uridium	Masaaki Ikeda;Keigo Watanabe;Isaku Nagai	2012	The 6th International Conference on Soft Computing and Intelligent Systems, and The 13th International Symposium on Advanced Intelligence Systems	10.1109/SCIS-ISIS.2012.6505174	simulation;computer science	Robotics	66.72396207081496	-24.408046419368734	94888
7c608eb1baaf931c10f3e22dda6a93f7b0df1c95	autonomous 2d slam and 3d mapping of an environment using a single 2d lidar and ros		This paper describes an algorithm that performs an autonomous 3D reconstruction of an environment with a single 2D Laser Imaging Detection and Ranging (LIDAR) sensor, as well as its implementation on a mobile platform using the Robot Operating System (ROS). A ROS node was used to redirect the flow of data that can go to either the 2D Simultaneous Localization And Mapping (SLAM) ROS node or to the 3D Octomap ROS node depending on the operation performed at that moment, with neither of the nodes going out of sync or crashing. The autonomous algorithm is implemented with the State Machines (SMACH) library and it uses ROS interfaces such as services and actions to create a 3D model of the robot's surroundings without prior information or human intervention.	3d reconstruction;algorithm;autonomous robot;dataflow;goto;mobile operating system;python;robot operating system;simultaneous localization and mapping	Manuel Gonzalez Ocando;Novel Certad;Said Alvarado;Angel Terrones	2017	2017 Latin American Robotics Symposium (LARS) and 2017 Brazilian Symposium on Robotics (SBR)	10.1109/SBR-LARS-R.2017.8215333	real-time computing;sync;3d reconstruction;finite-state machine;simultaneous localization and mapping;lidar;ranging;computer science	Robotics	54.46738325805974	-35.794515144514214	95152
7395b407d0157b6b55603ef2c4b6a8ab51d26f78	strategies for simultaneous multiple autonomous underwater vehicle operation and control	navegacion;robot movil;autonomous underwater vehicle;vehicle control;systeme commande;sistema control;early experience;submarine vehicle;architecture systeme;constraint propagation;concepcion sistema;distributed control system;autonomous system;cooperation;data collection;dynamical processes;decision borrosa;decision floue;commande repartie;cooperacion;sistema autonomo;tracking movable target;deformacion elastica;artefacto submarino;fau;navigation;control system;robot mobile;elastic deformation;system design;deformation elastique;systeme autonome;tracking control;engin sous marin;cost effectiveness;arquitectura sistema;poursuite;control repartido;system architecture;distributed control;conception systeme;moving robot;persecucion y continuacion;fuzzy decision;data logger	Under sampling of the coastal oceans remains a persistent problem for standard oceano-graphic measurement practice wherein an instrument package is tethered to a research vessel. The overhead costs associated with operating a large research vessel impose a strict minimum on the cost of data collected. Owing to the overheads, significant improvements in sampling technology on the tethered platform can only produce modest gains in the cost effectiveness. In contrast, untethered vehicles if operated simultaneously have the potential to increase cost effectiveness significantly by distributing the overhead costs over several sampling platforms. Furthermore, synoptic and pseudosynoptic data can be collected with multiple autonomous underwater vehicles (AUVs), thereby providing the type of information critical to dynamic process modeling unattainable with non-synoptic data. While the goal of simultaneous multiple-vehicle operation has been espoused over the last few years, AUV technology and practice have until...	autonomous robot	S. M. Smith;K. Ganesan;Pak Cheung Edgar An;S. E. Dunn	1998	Int. J. Systems Science	10.1080/00207729808929597	control engineering;embedded system;navigation;simulation;cost-effectiveness analysis;engineering;autonomous system;control system;data logger;control theory;mathematics;distributed control system;cooperation;local consistency;deformation;systems design;data collection	Robotics	57.23780502323306	-33.30688299451379	95198
1ebcc11c6740f2d8b6d08404abc43d38b968b38e	development of human symbiotic robot: wendy	whole body;humanoid robot;engineering design;egg breaking human symbiotic robot wendy design requirements psychological interaction informational interaction physical interaction waseda engineering designed symbiont mobility dexterity humanoid robot hadaly 2 object transport;mobile robots;dexterous manipulators;safety man machine systems mobile robots dexterous manipulators;safety;symbiosis orbital robotics safety robot kinematics humanoid robots service robots design engineering human robot interaction legged locomotion manipulators;man machine systems	An objective of this study is to find out design requirements for developing human symbiotic robots, which share working space with human, and have the ability of carrying out physical, informational, and psychological interaction. This paper mainly describes design strategies of the human symbiotic robots, through the development of a test model of the robots, WENDY (Waseda ENgineering Designed symbiont). In order to develop WENDY, mobility and dexterity of a humanoid robot Hadaly-2, which was developed in 1997, are improved on. The performances of WENDY are evaluated by experiments of object transport and egg breaking, which requires high revel integration of whole body system.	biological system;experiment;humanoid robot;performance;requirement;workspace	Toshio Morita;Hiroyasu Iwata;Shigeki Sugano	1999		10.1109/ROBOT.1999.774083	control engineering;mobile robot;simulation;computer science;engineering;humanoid robot;artificial intelligence;social robot;robot control;engineering design process	Robotics	68.09790681205084	-25.762700557375318	95631
fcf0cf282537e38d2a377c1258c52145ad3fb8ce	real-time vision-based contour following with laser pointer	vision system;edge detection;real time;image sensors;robot manipulator;robot vision;laser feedback automatic control robotics and automation optical control control systems visual servoing manipulators robot vision systems cameras laser noise;optical tracking;position control;real time vision;laser pointer;industrial robots;servomechanisms;edge detection robot vision industrial robots position control optical tracking image sensors real time systems servomechanisms;visual feedback;real time system robot visual servoing robotic manipulator laser pointer camera configuration end effector visual feedback robot orientation control automatic planar contour single camera vision precise positioning measurement noise image based control vision contour following;visual servoing;measurement noise;control strategy;real time systems	"""This article addresses the visual servoing of a rigid robotic manipulator under fixed camera configuration. A laser pointer is mounted on the end-effector of a robot whose orientation can be controlled by automatic visual feedback. The control goal is to drive the laser spot to follow a visually determined planar contour by using a single-camera vision system. In this research, image-based control approach is proposed to achieve """"precise"""" positioning in the absence of measurement noise. With this system, one can achieve automatic planar contour following using approximately calibrated single-camera vision. The control strategy is successfully validated in a real-time PC-based experimental system by performing experiments on arbitrary contour following."""	pointer (computer programming);real-time transcription	Wen-Chung Chang;Mong-Lu Chai	2003		10.1109/ROBOT.2003.1241976	control engineering;computer vision;simulation;edge detection;machine vision;computer science;engineering;image sensor;visual servoing	Robotics	60.04879375994688	-33.04680250205954	95739
4f2dbae652fa0179bc8dde16d0ebd481746fcc9a	proposed position and heading measurement system using laser beams on the vehicle and corner cubes	automotive engineering;mobile robot position measurement navigation heading measurement system laser beams laser transceiver optical references laser diode photo sensor time measurement;semiconductor junction lasers;heading measurement system;position measurement laser beams transceivers vehicle detection remotely operated vehicles mobile robots wheels dead reckoning nonlinear equations automotive engineering;time measurement;mobile robot;measurement system;vehicle detection;optical references;laser beams;mobile robots;remotely operated vehicles;navigation;laser diode;photo sensor;vehicles laser beam applications mobile robots navigation photodetectors position measurement semiconductor junction lasers;laser transceiver;position measurement;photodetectors;nonlinear equations;transceivers;vehicles;dead reckoning;laser beam applications;wheels	This paper presents the method to measure the position and heading of the vehicle which move on the circular course. The calculation is achieved by using the time data when the laser transceiver installed on the vehicle detects the optical references during the vehicle moves near of them. The laser transceiver is consist of laser diode and photo sensor. We use the geometry of the reference point, vehicle and vehicle’ s trajectory. The errors caused by time measurement are estimated by simulation. Experimental result for this proposed method shows that it is applicable for position and heading measurement system of mobile robot.	course (navigation);diode;mobile robot;olap cube;simulation;system of measurement;transceiver	Toshihiro Tsumura;Nobuo Komatsu	1991		10.1109/IROS.1991.174710	control engineering;mobile robot;embedded system;electronic engineering;nonlinear system;computer science;engineering;artificial intelligence	Robotics	56.73139167948832	-34.1683335761353	96000
3208a1e1aa14b95051f0cfb50059c3806d5f3e55	biologically motivated self-localization for mobile robots	mobile robots navigation humans path planning motion estimation robot motion robot vision systems cameras visual system nonlinear systems;mobile robot;path planning;location estimation;kalman filters;mobile robots;visual landmarks;position measurement biologically motivated self localization mobile robots autonomous navigation path planning visual landmarks position estimation location estimation position tracking unscented kalman filter nonlinear system;position control;position measurement;nonlinear system;filtering theory mobile robots path planning kalman filters position measurement position control;visual system;unscented kalman filter;filtering theory	An essential capability for mobile robots is to navigate autonomously in natural or human environments. This includes that a robot has to be able to determine its own position within its environment (self-localization), particularly with respect to the location of features relevant to the fulfilment of its defined task (localization of destination), and find the paths necessary to reach the destination (path planning). In this context, we present a new strategy for mobile robots to determine their position and orientation with respect to visual landmarks. In our case, the robot's position is not estimated with high accuracy. Instead, its estimation is improved repeatedly by analysing the landmarks from different positions, by exploiting the robots motion. Therefore, we only use the visual information given by a single camera, without reverting to a model of the environment, the robot or even the visual system. After a first location estimation, the robot tracks its position with the help of an unscented Kalman filter (UKF), which does not require derivations of the nonlinear system or measurement function. As experiments show, the accuracy of the chosen strategy is sufficient to move to a defined goal without the need of high computational power.	computation;experiment;kalman filter;mobile robot;motion planning;nonlinear system	Ralf Stemmer	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1308053	kalman filter;control engineering;mobile robot;monte carlo localization;computer vision;nonlinear system;computer science;engineering;artificial intelligence;control theory;robot control;mobile robot navigation	Robotics	54.537270463027795	-34.58594512417531	96091
6083c1a83a525505d5dbd74c12230d70c95cb3ca	computing camera viewpoints in an active robot work cell	ccd camera;feature detection;degree of freedom;satisfiability;field of view	This paper presents a dynamic sensor planning system, capab le of planning the locations and settings of vision sensors for use in an environment contain i g objects moving in known ways. The key component of this research is the computation of the came ra position, orientation, and optical settings to be used over a time interval. A new algorithm is pr esented for viewpoint computation which ensures that the feature detectability constraints o f focus, resolution, field-of-view, and visibility are satisfied. A five degree-of-freedom Cartesian rob ot carrying a CCD camera in a hand/eye configuration and surrounding the work-cell of a Puma 560 rob ot was constructed for performing sensor planning experiments. The results of these experime nts, demonstrating the use of this system in a robot work-cell, are presented. The research described in this paper was performed while thi s author was at the Columbia University Department of Computer Science. yThis work was supported in part by DARPA contract DACA-76-92 -C-0007, an ONR MURI Grant, NSF grants CDA-90-24735 and IRI-93-11877, and Toshiba Corporation	algorithm;charge-coupled device;columbia (supercomputer);computation;computer science;experiment;ibm notes;image sensor;programmable universal machine for assembly;puma (microarchitecture);re-order buffer;resolution (logic);robot	Steven Abrams;Peter K. Allen;Konstantinos A. Tarabanis	1999	I. J. Robotics Res.	10.1177/02783649922066204	smart camera;computer vision;camera auto-calibration;simulation;field of view;computer science;feature detection;degrees of freedom;charge-coupled device;satisfiability;computer graphics (images)	Robotics	57.8296280727895	-32.011707095216785	96108
40a1cb4a9a8a146fb4d6a7cad895b63e77910a4c	simulating missions of a uav with a communications payload	uav;communications;path planning;mobile communication mathematical model atmospheric modeling kinematics matlab noise receivers;simulation;radio links aircraft navigation autonomous aerial vehicles mobile radio path planning;mobile radio;simulation uav communications;uav path planning algorithm communications payload unmanned aerial vehicle military communication relay satellite european commission civilian application broadcast service communications service disaster mobile ground node navigation algorithm matlab mobiles communications link systems toolkit stk simulation environment;autonomous aerial vehicles;radio links;aircraft navigation	In 1996 Pinkney et. al. proposed that Unmanned Aerial Vehicles (UAV) could be used as military communications relays to supplement the capabilities offered by satellites. A recent study sponsored by the European Commission predicted a gradual increase of UAV in civilian applications for the period to 2020, including broadcast and communications services. Such UAVs could find roles providing communications in disasters and major events, or in any activity where quick response and short term area communications are required. Typical systems could comprise one or more UAVs and a number of mobile ground nodes that require interconnection. This simulation environment has been developed to test these ideas. Its main purpose has been to provide a testbed for potential navigation algorithms, written in MATLAB, in an environment that could simulate the movement of the UAV, mobiles, and the communications links. A suitable environment was developed using Systems Toolkit (STK) and MATLAB. This simulation environment has been in use for two years and has provided a flexible testbed for assessing operating concepts and UAV path planning algorithms. This paper outlines the requirements of this simulation environment and describes how it was implemented. It then describes the models used for each of the objects and, where appropriate, states the key equations used in each model.	aerial photography;algorithm;experiment;interconnection;matlab;marginal model;motion planning;online and offline;relay;requirement;stk;simulation;testbed;unmanned aerial vehicle	Philip B. Charlesworth	2013	2013 UKSim 15th International Conference on Computer Modelling and Simulation	10.1109/UKSim.2013.61	embedded system;simulation;telecommunications;engineering	Robotics	56.82460150301911	-27.533203868968858	96185
96c62ffd8aa7588cd67e0af244acbc14d7d0586d	lidar scan matching aided inertial navigation system in gnss-denied environments	ins;inertial navigation;scan matching;期刊论文;ekf;lidar	A new scan that matches an aided Inertial Navigation System (INS) with a low-cost LiDAR is proposed as an alternative to GNSS-based navigation systems in GNSS-degraded or -denied environments such as indoor areas, dense forests, or urban canyons. In these areas, INS-based Dead Reckoning (DR) and Simultaneous Localization and Mapping (SLAM) technologies are normally used to estimate positions as separate tools. However, there are critical implementation problems with each standalone system. The drift errors of velocity, position, and heading angles in an INS will accumulate over time, and on-line calibration is a must for sustaining positioning accuracy. SLAM performance is poor in featureless environments where the matching errors can significantly increase. Each standalone positioning method cannot offer a sustainable navigation solution with acceptable accuracy. This paper integrates two complementary technologies-INS and LiDAR SLAM-into one navigation frame with a loosely coupled Extended Kalman Filter (EKF) to use the advantages and overcome the drawbacks of each system to establish a stable long-term navigation process. Static and dynamic field tests were carried out with a self-developed Unmanned Ground Vehicle (UGV) platform-NAVIS. The results prove that the proposed approach can provide positioning accuracy at the centimetre level for long-term operations, even in a featureless indoor environment.	course (navigation);dead reckoning;extended kalman filter;forests;hl7publishingsubsection <operations>;inertial navigation system;loose coupling;matching;online and offline;slamf1 gene;satellite navigation;simultaneous localization and mapping;unmanned aerial vehicle;velocity (software development);centimeter	Jian Tang;Yuwei Chen;Xiaoji Niu;Li Wang;Liang Chen;Jingbin Liu;Chuang Shi;Juha Hyyppä	2015		10.3390/s150716710	dead reckoning;lidar;computer vision;gps/ins;simulation;wind triangle;extended kalman filter;inertial navigation system;physics;remote sensing	Robotics	56.459212760914056	-37.21157584746937	96373
81673567e11e3ca49dab7cd490176dd79bc2e95c	"""networked equilibrium sharing system """"balance seat"""""""	balance;three people;platform control;position control;interactive system;network equilibrium;interaction model;network sharing;equilibrium;networked systems;control method	"""This paper presents a networked system connecting real space, which is shared and operated by three people.We made three pneumatic triple-axis motion platforms as a system to share a """"sense of balance"""" with other people, and examined control methods for this system. Cylinders, which go up and down due to air pressure are used as actuators, and by moving the cylinders up and down while performing position control, the system can make the platform tilt.Since we use three platforms, an important issue was how to incorporate the interaction of the user to control the system. Therefore, we considered and experimented with four control models."""	apache axis	Nobuya Suzuki;Takahiro Kobayashi;Hiroshi Yasuda	2005		10.1145/1178477.1178504	control engineering;simulation;networked control system;engineering;control theory	Robotics	64.46872301454864	-24.028612117044396	96396
b13268470883d33e4ed7d9c552ad06e2450fe586	structuring sensory-motor coordination for the acquisition of dynamic identification using pso	robot sensing systems;motion control;mobile robot;dynamic identification;mobile robots;particle swarm optimisation humanoid robots mobile robots motion control;deliberative task;robot sensing systems trajectory robot kinematics mobile robots dynamics;motion identification task;adaptable smc;trajectory;humanoid robots;dynamics;motor coordination;natural organism;deliberative task dynamic identification particle swarm optimisation natural organism mobile robot motion identification task arbitrary smc adaptable smc reactive sensory motor coordination;particle swarm optimisation;reactive sensory motor coordination;arbitrary smc;robot kinematics	Sensory-motor coordination (SMC) is an important ability for both natural organisms and mobile robots. This work investigates the role that purely reactive SMC has on a robot's ability to perform a deliberative motion identification task. We investigate three conditions under which a robot can utilize SMC, namely arbitrary (the motion strategy of the robot is fixed), adaptable (the motion strategy co-adapts along with the motion identification ability), and pre-adapted (the motion strategy has been pre-adapted under the constraints of the identification task and then fixed). The results show that purely reactive sensory-motor coordination can be exploited to greatly improve performance at a necessarily deliberative task.	mobile robot;particle swarm optimization	Stephen Paul McKibbin	2010	IEEE Congress on Evolutionary Computation	10.1109/CEC.2010.5586412	mobile robot;computer vision;simulation;computer science;artificial intelligence	Robotics	64.49678373766757	-25.231817714414447	96487
0461b6498c1a3f25679980ac792e1de997c9fa87	method and apparatus of 3d kinematic calibration for lab setting	conferences automation;rods structures biomechanics calibration decision making image motion analysis;indoor lab settings 3d kinematic calibration poling calibration method 3d motion analysis decision making process coordination arrangements control point measurement pcm algorithm rod reflective makers	The objective of this article is to present a precise calibration method-Poling Calibration Method (PCM) for 3D motion analysis. The main content covers basic principle, decision-making process, co-ordination arrangements, control point measurement, PCM algorithm and the creation of calibration space. A 10.00cm long rod with 2 reflective makers was used to test the calculation error after calibration through PCM. The top error was 0.37cm, minimum error was 0.00 cm, and average error was 0.12cm. All maximum errors showed up at 20% rim area of calibrated space. The result showed that the computational error after calibration was greatly declined, and effectiveness of the calibration method was validated. Therefore, PCM is an effective calibration method, especially for fixing cameras under the indoor lab settings.	algorithm;computation;control point (mathematics);kinematic chain;piezoelectricity	Hai-Bin Liu;Wen-Xue Yuan;Zhi-Qiang He;Tan-Tan Cai;Xiao-Fei Wang	2014	11th IEEE International Conference on Control & Automation (ICCA)	10.1109/ICCA.2014.6871008	computer vision;simulation;engineering;engineering drawing;robot calibration	Robotics	61.07270976283582	-36.33023715524227	96544
958b27cab0f7aae5f70c38a063ad22ab1c0aedb2	a design for a visual motion transducer	flow field grating output signal modulation gratings visual motion transducer translational motion divergence curl;and forward;diffraction gratings;real time;transducers;motion estimation;visual motion;computer vision;transducers motion estimation computer vision diffraction gratings;flow field;transducers gratings frequency fourier transforms image edge detection image sensors layout photodetectors convolution current measurement	Autonomous vehicles could benefit greatly from visual-motion sensors of sufficiently low cost that 10 or 20 of them could be distributed around the vehicle’s periphery. Conventional arrangements with CCD cameras, framestores and computers are too expensive. A design is outlined here that builds on well-known schemes using gratings. The grating principle is illustrated by the fact that a man with a torch, walking at night behind a railing, seems to flash. The frequency of flashing is proportional to his velocity. A major drawback is that backward and forward motion are not distinguished. The key development here is the use of commutation as a means of modulating the grating output signal. This is equivalent, in the illustration above, to simulating stroboscopic motion of the railing. Thus, when the man is stationary, there is flashing at a resting frequency. When he moves one way the frequency increases, and for motion the opposite way, frequency decreases. Results from an analogue implementation of the visual motion transducer are presented. The current transducer measures translational motion across the grating. The design is also shown to be capable of extension to direct measurement of the divergence and curl of the flow field.	bios;charge-coupled device;computer;firmware;sensor;simulation;stationary process;torch;transducer;velocity (software development);curl	Andrew Blake;Gabriel Hamid;Lionel Tarassenko	1993		10.1109/ICCV.1993.378213	computer vision;diffraction grating;transducer;computer science;motion estimation	HCI	60.771895977899995	-34.8237778563242	96877
8675812c2866972e7d2b9d9c079be1c7cd27d43d	a type-2 fuzzy logic controller for autonomous mobile robots	knowledge based systems mobile robots fuzzy control uncertainty handling fuzzy set theory real time systems navigation;fuzzy set;mobile robot;real time control;fuzzy control;rule based;mobile robots;uncertainty handling;fuzzy logic controller;autonomous mobile robot;fuzzy logic mobile robots uncertainty fuzzy sets robot control navigation histograms computer science humidity control sensor phenomena and characterization;fuzzy set theory;navigation;type 2 fuzzy set;robotic behaviours type 2 fuzzy logic controller autonomous mobile robots uncertainty handling navigation type 1 fuzzy logic controller type 2 fuzzy sets real time control robotic platforms indoor unstructured environments outdoor unstructured environments fuzzy rule bases;knowledge based systems;real time systems	There are many sources of uncertainty facing the fuzzy logic controller (FLC) for autonomous mobile robots navigating in changing and dynamic unstructured environments. The traditional type-1 FLC using precise type-1 fuzzy sets cannot fully handle such uncertainties. A type-2 fuzzy logic controller (FLC) using type-2 fuzzy sets can handle such uncertainties to produce a better performance. In this paper, we present the type-2 FLC and its novel application for the real time control of mobile robots. We used the type-2 FLC to implement different robotic behaviours on different robotic platforms in indoor and outdoor unstructured and challenging environments. The type-2 FLCs dealt with the uncertainties facing mobile robots in unstructured environments and resulted in a very good performance that outperformed the type-1 FLCs whilst using smaller rule bases.	autonomous robot;fuzzy logic;fuzzy set;mobile robot;type-1 owa operators;type-2 fuzzy sets and systems;while	Hani Hagras	2004	2004 IEEE International Conference on Fuzzy Systems (IEEE Cat. No.04CH37542)	10.1109/FUZZY.2004.1375538	rule-based system;mobile robot;computer vision;computer science;artificial intelligence;knowledge-based systems;control theory;fuzzy set;fuzzy control system	Robotics	59.34283531051852	-27.86810551493267	96890
0cdb2eb1de3ea0af3b0f402c6c73abbcfec2f3fe	the obstacle-restriction method for tele-operation of unmanned aerial vehicles with restricted motion		This paper presents a collision avoidance method for tele-operated unmanned aerial vehicles (UAVs). The method is designed to assist the operator at all times, such that the operator can focus solely on the main objectives instead of avoiding obstacles. We restrict the altitude to be fixed in a three dimensional environment to simplify the control and operation of the UAV. The method contributes a number of desired properties not found in other collision avoidance systems for tele-operated UAVs. Our method i) can handle situations where there is no input from the user by actively stopping and proceeding to avoid obstacles, ii) allows the operator to slide between prioritizing staying away from objects and getting close to them in a safe way when so required, and iii) provides for intuitive control by not deviating too far from the control input of the operator. We demonstrate the effectiveness of the method in real world experiments with a physical hexacopter in different indoor scenarios. We also present simulation results where we compare controlling the UAV with and without our method activated.		Daniel Duberg;Patric Jensfelt	2018	2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)	10.1109/ICARCV.2018.8581381	control engineering;collision;obstacle;operator (computer programming);computer science;restrict	Robotics	59.24575072265453	-26.52044664021315	97054
093444b5bd1c1ee46862aa60fb470f381907f11b	vision-based control for an auv in a multi-robot undersea intervention task		This paper presents a novel vision-based framework for controlling an Autonomous Underwater Vehicle (AUV). In our application, this AUV is in charge of providing an alternative point of view of a predefined target during a multi-robot intervention mission, where two vehicles cooperate in order to perform the required task. Given this scenario, our framework is based on two main modules: on the one hand, a target detection and tracking module is used to determine the position of the target in the scene; on the other hand, a visual servoing module generates the required velocities for controlling the platform according to the estimated position of the target in the image plane. Results for a set of experiments in different environments are reported and discussed.	robot	Emilio Garcia-Fidalgo;Alberto Ortiz;Miquel Massot-Campos	2017		10.1007/978-3-319-70833-1_4	computer vision;underwater robotics;simulation;robot;visual servoing;artificial intelligence;image plane;computer science;intervention auv	Robotics	57.37361122226759	-28.39351744761201	97251
26b32e88f5d306c0f05d2c9730fc2bc74b86c7eb	a real-time vision-based 3d motion estimation system for positioning and trajectory following	motion vision;thruster system position correction;vision system;control systems;signal generators;time varying;sensor systems;optical positioning;pid controller;degree of freedom;camera position;motion estimation;image sensors;computer vision;camera motion;navigation;time varying imagery;control system;spatio temporal derivatives;automatic positioning;position control;image function;three term control;real time vision;one degree of freedom thruster;machine vision;laboratory water tank;estimated position information;signal generation;optical flow;positional information;optical encoder position sensor;optical sensors;real time vision based 3d motion estimation system;real time systems motion estimation control systems optical sensors cameras laboratories three term control signal generators machine vision sensor systems;image sensors motion estimation motion estimation real time systems real time systems computer vision computer vision position control position control three term control three term control optical sensors optical sensors tracking tracking image sensors;trajectory following;cameras;direct method;optical encoder position sensor real time vision based 3d motion estimation system automatic positioning trajectory following spatio temporal derivatives image function time varying imagery camera motion camera position one degree of freedom thruster laboratory water tank estimated position information control system pid controller signal generation thruster system position correction vision system performance;tracking;real time systems;vision system performance	The authors present a real-time vision-based system for automatic positioning and trajectory following, based on a direct method for 3D motion estimation. The spatio-temporal derivatives of the image function, calculated from time-varying imagery, are used to directly calculate the motion and position of the camera. For demonstration, they have implemented the system on a one-degree-of freedom thruster operating in a laboratory water tank. The estimated position information is communicated to the control system, a PID controller, in order to generate the appropriate signal to correct the thruster system's position. The performance of the vision system is demonstrated in selected experiments by comparing results with the data from an optical encoder position sensor.	motion estimation;real-time clock	Shahriar Negahdaripour;Lingling Jin;Xun Xu;C. L. Tsukamoto;Junku Yuh	1996		10.1109/ACV.1996.572067	pid controller;direct method;computer vision;navigation;machine vision;computer science;control system;motion estimation;image sensor;optical flow;control theory;tracking;degrees of freedom;motion field;signal generator	Robotics	58.6743469316739	-32.738952648226466	97318
9fec8d0b9c3baa82f9d62100411b54a448bd2576	research on locating and tracking automotive products in workshop based on active rfid technology	automotive products;active rfid;radar tracking;tracking tag automotive products tracking automotive products location active rfid technology land mine detection advanced radar concept system;land mine detection;landmarc;production engineering computing;radiofrequency identification automotive components production engineering computing;heuristic algorithms;automotive components;track;nearest nodes algorithm;vehicle dynamics;radiofrequency identification;heuristic algorithms conferences radiofrequency identification radar tracking equations vehicle dynamics;conferences;track automotive products active rfid landmarc nearest nodes algorithm	In order to track and monitor automotive products in workshop effectively, a method is proposed to locate and track automotive products with Land-Mine Detection Advanced Radar Concept system (LANDMARC) based on active RFID technology. As performance of LANDMARC to position the products is limited by factors, such as selecting nearest node and adjusting strength of readers, therefore an improved dynamic nearest nodes algorithm is adopted to locate the automotive products based on power adjustable readers. In the LANDMARC system based on active RFID for tracking automotive products in workshop, the locating information of the tracking tag on the products is obtained, meanwhile, the process information of the tag is achieved through position resolution module. Finally, the results of simulation show that the method of locating and tracking automotive products is effective.	algorithm;radio-frequency identification;simulation	Zhiyong Luo;Chaoyang Xing;Heng Wang;Ping Wang	2010	2010 IEEE/ACM Int'l Conference on Green Computing and Communications & Int'l Conference on Cyber, Physical and Social Computing	10.1109/GreenCom-CPSCom.2010.52	embedded system;electronic engineering;simulation;engineering	EDA	55.498947614038755	-32.042826052058686	97399
ec28da58d5495a6a60851454a76eeff257ddff2d	closed form solution for the sensor registration problem using only position information	contraste;closed form solution;information positionnelle;robotics;informacion posicional;captador medida;feedback;measurement sensor;capteur mesure;robotica;etalonnage;positional information;robotique;boucle reaction;retroalimentacion;calibration	Abstract#R##N##R##N#Sensors, mounted on the dexterous end of a robot, can be used for feedback control or calibration. When you mount a sensor on a robot it becomes necessary to find the pose (orientation and position) of the sensor relative to the robot. This is the sensor registration problem. Many researchers have provided closed-form solutions to the sensor registration problem; however, the published solutions apply only to sensors that can measure a complete pose (three positions and three orientations). Many sensors, however, can provide only position information; they cannot measure the orientation of an object. This article provides a closed-form solution to the sensor registration problem applicable when: (1) the sensor can provide only position information and (2) the robot can move along and rotate about straight lines. © 1994 John Wiley & Sons, Inc.		Liang Eng Ong;Louis J. Everett	1994	J. Field Robotics	10.1002/rob.4620110805	computer vision;closed-form expression;calibration;simulation;pose;computer science;engineering;position sensor;artificial intelligence;control theory;feedback;robotics	Robotics	59.18199944684281	-33.96969195780666	97866
528a71f3f2c1340a049c654e187363a4baae46a8	improved path planning and controlling for a low cost navigation solution of unmanned land vehicle	front wheel motor path planning low cost navigation solution unmanned land vehicle obstacle detection path calculations wheel position control control loop;obstacle detection;path planning;surface roughness;remotely operated vehicles;rough surfaces;low cost navigation solution;distance measurement;navigation;position control;global positioning system;remotely operated vehicles navigation path planning position control;rough surface;unmanned land vehicle;control loop;vehicles;dc motors;wheel position control;path calculations;front wheel motor;path planning costs navigation land vehicles wheels rough surfaces surface roughness global positioning system infrared detectors position control	A Low cost Navigation Solution has developed for Unmanned Land vehicle (ULV) by using GPS & one ABS Sensor. Two IR Modules are integrated to detect obstacles in the path of movement. This combined arrangement is simple and gave satisfactory results at smooth surfaces. At rough surfaces results are very poor and vehicle lost its calculated path due to change of direction of front wheel. Presence of Obstacles in circular path of ULV is another problem in ULV path calculations. There was no such solution for facing this problem. These problems are focused mainly in current research for making efficient low cost solution. Wheel position control is developed by providing a control loop for driving front wheel motor. It gives satisfactory result to maintain constant direction during motion. New algorithm is developed for proper determination of proposed path in case of obstacles present in circular paths. Better results are achieved after adopting new technique. This combined effort by adding no such expensive component produces efficient ULV Navigation solution. After a number of experiments it is still determined that in structured environment, better sensors with better algorithm are required. It will consider a future task for making efficient low cost solution.	algorithm;control system;experiment;global positioning system;motion planning;rough set;sensor;ultra-low-voltage processor;unmanned aerial vehicle	Syed Riaz un Nabi Jafri;Syed Minhaj un Nabi Jafri;Syed Zeeshan Shakeel	2009	2009 11th International Conference on Computer Modelling and Simulation	10.1109/UKSIM.2009.31	control engineering;computer vision;simulation;engineering	Robotics	56.27779708230866	-27.959357151561285	97897
16c248bec30bf7125b86527aded29a2fae7b9618	the design of leo: a 2d bipedal walking robot for online autonomous reinforcement learning	leo design;robot sensing systems;legged locomotion;biped robot;reinforcement learning;torso;hip;online autonomous reinforcement learning;software requirements;walking robot;low earth orbit satellites;aerospace robotics;pre programmed controller;servomotors;legged locomotion aerospace robotics learning artificial intelligence;learning artificial intelligence;legged locomotion robot sensing systems hip low earth orbit satellites servomotors torso;pre programmed controller leo design 2d bipedal walking robot online autonomous reinforcement learning;2d bipedal walking robot	Real robots demonstrating online Reinforcement Learning (RL) to learn new tasks are hard to find. The specific properties and limitations of real robots have a large impact on their suitability for RL experiments. In this work, we derive the main hardware and software requirements that a RL robot should fulfill, and present our biped robot LEO that was specifically designed to meet these requirements. We verify its aptitude in autonomous walking experiments using a pre-programmed controller. Although there is room for improvement in the design, the robot was able to walk, fall and stand up without human intervention for 8 hours, during which it made over 43; 000 footsteps.	algorithm;autonomous robot;control system;experiment;failure;leo (computer);machine learning;mobile robot;potentiometer;real-time clock;reinforcement learning;requirement;simulation;software requirements;time-invariant system;aptitude	Erik Schuitema;Martijn Wisse;Thijs Ramakers;Pieter P. Jonker	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5650765	control engineering;simulation;torso;computer science;engineering;artificial intelligence;social robot;robot control;reinforcement learning;servomotor;software requirements	Robotics	60.49958326892383	-26.041968982154803	98397
a020f6d8e55536d3b8cb1524cf748c6fbc966299	dlr's robotics technologies for on-orbit servicing	telepresence;satellite maintenance;on orbit servicing;institut fur robotik und mechatronik bis 2012;autonomous space robots	The paper outlines the long-term space robotics projects as well as recent results in DLR's robotics laboratory. The driving force behind all the efforts made in hardware and software development is to design highly integrated robot systems which can be utilized in space, especially for extravehicular activities. Our envisaged field of application reaches from servicing satellites in low Earth and geostationary orbit to space stations as well as planetary exploration robots, all of them fully ground controlled from Earth. The ground control concept is based on the MARCO architecture, which was verified in a few space robotics projects over recent years. It includes taskoriented programming capabilities for autonomous robot control at the remote site as well as methods for direct telemanipulation by means of virtual reality and telepresence techniques, which allows a realistic feeling for the ground operator via visual and haptic feedback devices. In addition to the control techniques, a new generation of ...	dynamic language runtime;robotics	Gerd Hirzinger;Klaus Landzettel;Bernhard Brunner;Max Fischer;Carsten Preusche;Detlef Reintsema;Alin Albu-Schäffer;Günter Schreiber;Bernhard-Michael Steinmetz	2004	Advanced Robotics	10.1163/156855304322758006	simulation;aerospace engineering;engineering;electrical engineering	Robotics	63.63426096919516	-28.38567800828232	98439
f9fe2fa35defed4fd51c0d552c6da2ea8aa1669c	human motion capture algorithm based on inertial sensors		On the basis of inertial navigation, we conducted a comprehensive analysis of the human body kinematics principle. From the direction of two characteristic parameters, namely, displacement and movement angle, we calculated the attitude of a node during the human motion capture process by combining complementary and Kalman filters. Then, we evaluated the performance of the proposed attitude strategy by selecting different platforms as the validation object. Results show that the proposed strategy for the real-time tracking of the human motion process has higher accuracy than the traditional strategy.	algorithm;motion capture;sensor	Peng-zhan Chen;Ye Kuang;Jie Li	2016	J. Sensors	10.1155/2016/4343797	control engineering;computer vision;simulation;engineering	Graphics	57.393402634441934	-36.15778053091236	98515
d0472979cd4f2ebf317d6426e114657d13c78f0a	vehicle following as backup control schemes for magnet-magnetometer-based lateral guidance	automatic control;laser scanning radar;direccion vehiculo;optical control;automatic driving;sensor systems;control algorithm;direction vehicule;programme commande;guidage;sensors;road traffic;magnet magnetometer based lateral guidance;magnetic sensors;error relativo;conduccion automatica;magnetometers;automated highways;navigation magnetometers laser radar automatic control magnetic sensors road vehicles magnets automated highways sensor systems optical control;laser radar;vehicle following;conduite automatique;magnetometro;guiado;vehicle steering control;captador medida;navigation;radar optico;relative error;measurement sensor;vehicle steering control automated vehicle lateral guidance laser scanning radar single input two output sito vehicle following;capteur mesure;optical radar;single input two output sito;control program;laser scanning radar sensor;erreur relative;guidance;programa mando;control engineering computing;automated highways road vehicles sensors optical radar road traffic control engineering computing;laser scanning;automated vehicle lateral guidance;magnetometre;magnets;vehicle direction;radar optique;backup vehicle lateral control algorithms;backup control schemes;lidar;road vehicles;lidar vehicle following backup control schemes magnet magnetometer based lateral guidance backup vehicle lateral control algorithms laser scanning radar sensor	This paper describes the development of the backup vehicle lateral control algorithms for the magnet-magnetometer-based automated lateral guidance. Current vehicle lateral controllers rely on the use of two sets of magnetometers, one under the front bumper and the other under the rear bumper of the vehicle. The magnetometers measure the vehicle's lane following error relative to the magnets buried along the center of the highway lane. The proposed algorithms, based on a laser scanning radar sensor (LIDAR), are backup systems for current magnetometer-based controllers in case of magnetometer failure. The LIDAR sensor measures the vehicle's lateral position relative to its preceding vehicle. The paper considers two magnetometer failure scenarios, i.e., failure in only one set of magnetometers and failure in all magnetometers. Experimental results are presented.	algorithm;backup;control system;dynamical system;experiment;interaction;lateral thinking;minimum phase	Gaung Lu;Masayoshi Tomizuka	2005	IEEE Transactions on Control Systems Technology	10.1109/TCST.2004.839564	control engineering;lidar;electronic engineering;engineering;automatic control;physics;remote sensing	Robotics	56.88770847465505	-33.457646509827605	98856
d9ce1e5e12da3e6b01acaee49ebf922570fc1851	vehicle self-localization using off-the-shelf sensors and a detailed map	sensors automobiles global positioning system mobile robots position control;publikationer;sensors vehicles roads cameras radar noise measurement global positioning system;konferensbidrag;autonomous vehicles vehicle self localization off the shelf sensors localization algorithm global positioning system receiver gyroscope wheel speed sensors;artiklar;rapporter	In the research on autonomous vehicles, self-localization is an important problem to solve. In this paper we present a localization algorithm based on a map and a set of off-the-shelf sensors, with the purpose of evaluating this low-cost solution with respect to localization performance. The used test vehicle is equipped with a Global Positioning System receiver, a gyroscope, wheel speed sensors, a camera providing information about lane markings, and a radar detecting landmarks along the road. Evaluation shows that the localization result is within or close to the requirements for autonomous driving when lane markers and good radar landmarks are present. However, it also indicates that the solution is not robust enough to handle situations when one of these information sources is absent.	algorithm;autonomous car;autonomous robot;global positioning system;gyroscope;internationalization and localization;radar;requirement;sensor	Malin Lundgren;Erik Stenborg;Lennart Svensson;Lars Hammarstrand	2014	2014 IEEE Intelligent Vehicles Symposium Proceedings	10.1109/IVS.2014.6856524	control engineering;embedded system;computer vision;engineering	Embedded	55.101537248783934	-36.482075706507615	99009
a7110449b8eab8db29336d98410ba481e1e2bbcf	object exploration in one and two fingered robots	robot sensing systems;object recognition;testing;psychology;surface texture;computer vision;shape;haptic interfaces shape end effectors surface texture temperature robot sensing systems psychology object recognition testing computer vision;temperature;haptic interfaces;end effectors		robot	Roberta L. Klatzky;Ruzena Bajcsy;Susan J. Lederman	1987		10.1109/ROBOT.1987.1087777	surface finish;computer vision;robot end effector;simulation;temperature;shape;computer science;cognitive neuroscience of visual object recognition;software testing	Robotics	62.65998205690154	-34.47570570393654	99068
64b3e67dd815a8642572561eb7dd82ee53dbc1dd	trajectory control based on discrete full-range dynamics	intelligent mechatronics and application;mechanical dynamics;actuator design;biomimetic systems;novel actuator systems	There has been an increasing interest in the use of mechanical dynamics, (e.g., assive, Elastic, And viscous dynamics) for energy efficient and agile control of robotic systems. Despite the impressive demonstrations of behavioural performance, The mechanical dynamics of this class of robotic systems is still very limited as compared to those of biological systems. For example, Passive dynamic walkers are not capable of generating joint torques to compensate for disturbances from complex environments. In order to tackle such a discrepancy between biological and artificial systems, We present the concept and design of an adaptive clutch mechanism that discretely covers the full-range of dynamics. As a result, The system is capable of a large variety of joint operations, including dynamic switching among passive, actuated and rigid modes. The main innovation of this paper is the framework and algorithm developed for controlling the trajectory of such joint. We present different control strategies that exploit passive dynamics. Simulation results demonstrate a significant improvement in motion control with respect to the speed of motion and energy efficiency. The actuator is implemented in a simple pendulum platform to quantitatively evaluate this novel approach.	full-range speaker	Nandan Maheshwari;Keith Gunura;Fumiya Iida	2012	JRM	10.20965/jrm.2012.p0612	control engineering;simulation;engineering;control theory	Robotics	65.75282355877948	-24.3339827043409	99070
f583f0cd6135ebfc56d0d884e89e8551deeb8152	optimal wind-assisted flight planning for planetary aerobots	data gathering;path planning;path planning aerospace robotics remotely operated vehicles mobile robots aerospace control;site investigation;mobile robots;remotely operated vehicles;planetary exploration;wind energy;aerospace control;long distance;solar system energy management resource management energy resources planetary orbits geoscience communication system control hazards navigation sampling methods;opportunistic flight path planning optimal wind assisted flight planning planetary aerobots autonomous airship onboard energy resources management planetary exploration;aerospace robotics;solar system;energy minimization;energy source	Autonomous airships, or aerobots, that have to traverse extensive distances or explore other bodies of the solar system require careful management of onboard energy resources. For planetary exploration, available energy has to be used for science data gathering, communications with an orbiter or directly with Earth, altitude control and hazard avoidance, close-up navigation for science site investigation, and surface sampling. Consequently, long-distance traverses should be done by relying as much as possible on external energy sources, and in particular on wind energy. In this paper, we address the problem of planning opportunistic flight paths that use know regional or global wind patterns to carry the aerobot to its destination. We assume that the aerobot is able to control its vertical displacement, while horizontal displacement is to be achieved through wind propulsion. We show how energy minimal and time minimal trajectories can be computed for aerobots traversing homogenous wind fields. We also present computational results for 2D and 3D wind fields.	aerobot;displacement mapping;planetary scanner;sampling (signal processing);traverse	Thomas Kämpke;Alberto Elfes	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1307444	wind power;remotely operated underwater vehicle;mobile robot;simulation;aerospace engineering;computer science;engineering;artificial intelligence;motion planning;solar system;energy minimization;remote sensing;data collection	Robotics	55.05110744379409	-26.600343261661685	99293
bc0344dc65003529128ca3a717386527bfb17424	mutual localization and positioning of vehicles sharing gnss pseudoranges: sequential bayesian approach and experiments	vehicles satellites global positioning system receivers clocks prediction algorithms data integration;kalman filtering;errors;vehicular ad hoc networks computer networks;data fusion;location;artificial satellites;wireless communication gnss pseudoranges sequential bayesian approach mutual localization vehicle positioning intelligent transportation systems its gnss positions gnss signal in space cooperative observation techniques structural properties sequential kalman filtering convex data fusion vehicle to vehicle communication;vehicular ad hoc networks bayes methods convex programming intelligent transportation systems kalman filters satellite navigation;global navigation satellite system	In many cooperative Intelligent Transportation Systems (ITS) applications, absolute positioning and relative localization are key issues. When vehicles share GNSS positions, there are often non negligible common-mode errors due mainly to GNSS signal-in-space. Cooperative observation techniques allow estimating common biases on the measured pseudodistances to correct these errors and to increase absolute positioning and relative localization accuracy. After having studied some structural properties of the problem in its general form, a low computational cooperative tightly-coupled approach is proposed using sequential Kalman filtering and convex data fusion. As a case study, we consider two vehicles which cooperate and exchange information in such a way that each vehicle can track the partner's position and improves its absolute position by merging common biases estimates. Experimental results are presented to illustrate the performance of the proposed approach in comparison with a classic standalone method.	experiment;international conference on services computing;kalman filter;mode (computer interface);satellite navigation;source code control system	Khaoula Lassoued;Isabelle Fantoni;Philippe Bonnifait	2015	2015 IEEE 18th International Conference on Intelligent Transportation Systems	10.1109/ITSC.2015.307	simulation;gnss augmentation;geography;telecommunications;remote sensing	Robotics	55.03925512087446	-32.76091946143878	99400
59c62fc28640e02509c7698d96d87c826730d51b	absolute gravimeter for terrain-aided navigation		Cold atom interferometer is a promising technology to obtain a highly sensitive and accurate absolute gravimeter. With the help of an anomalies gravity map, local measurements of gravity allow a terrain-based navigation. We describe the model of the absolute gravity measurement. We develop a Laplace-based particle filter adapted to this context. This non-linear filter is able to estimate the positions and velocities of a carrier (vessel). Some results on realistic simulated data are presented.	nonlinear system;onera;particle filter;simulation	Christian Musso;Alexandre Bresson;Yannick Bidel;Nassim Zahzam;Karim Dahia;Jean-Michel Allard;Bernard Sacleux	2017	2017 20th International Conference on Information Fusion (Fusion)	10.23919/ICIF.2017.8009805	computer vision;computer science;terrain;acceleration;artificial intelligence;geodesy;laplace transform;gravimeter;particle filter;interferometry	Robotics	55.2825648538178	-35.80558896449604	99401
240eaf2a662578cec927c361543f5be8e8a8544a	a visual-servoing scheme for semi-autonomous operation of an underwater robotic vehicle using an imu and a laser vision system	vision system;visual servo control;asynchronous unscented kalman filter;visual servoing inertial navigation kalman filters mobile robots remotely operated vehicles robot vision underwater vehicles;online estimation;under actuated degree of freedom semiautonomous operation underwater robotic vehicle imu laser vision system visual servoing control scheme online estimation asynchronous unscented kalman filter energy based shaping remotely operated vehicle input to state stability inertial measurement unit;underwater vehicles;on line estimation;imu;degree of freedom;kalman filters;inertial navigation;mobile robots;remotely operated vehicles;robot vision systems underwater vehicles machine vision control systems stability analysis remotely operated vehicles visual servoing humans state estimation measurement units;kinematics;inertial measurement unit;under actuated degree of freedom;input to state stable;robot vision;laser vision system;robots;field of view;visual servoing control scheme;controller design;input to state stability;mathematical model;vehicles;remotely operated vehicle;visual servoing;unscented kalman filter;semiautonomous operation;energy based shaping;vehicle dynamics;cameras;underwater robotic vehicle	This paper presents a visual servoing control scheme that is applied to an underwater robotic vehicle. The objective of the proposed control methodology is to provide a human operator the capability to move the vehicle without loosing the target from the vision system's field of view. On-line estimation of the vehicle states is achieved by fusing data from a Laser Vision System (LVS) and an Inertial Measurement Unit (IMU) using an asynchronous Unscented Kalman Filter (UKF). A controller designed at the kinematic level, is backstepped into the dynamics of the system, maintaining its analytical stability guarantees. It is shown that the under-actuated degree of freedom is input-to-state stable and an energy based shaping of the user input with stability guarantees is implemented. The resulting control scheme has analytically guaranteed stability and convergence properties, while its applicability and performance are experimentally verified using a small Remotely Operated Vehicle (ROV) in a test tank.	control system;experiment;kalman filter;linux virtual server;noise shaping;remotely operated vehicle;robot;semiconductor industry;underactuation;visual servoing	George C. Karras;Savvas G. Loizou;Kostas J. Kyriakopoulos	2010	2010 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2010.5509259	kalman filter;control engineering;inertial measurement unit;computer vision;machine vision;computer science;engineering;artificial intelligence;control theory	Robotics	60.50221873020247	-31.03606029377442	99433
7a8f1d3ef1086e3fceac93a90dbab3b46fb267b1	a geometric approach for learning compliant motions from demonstration		This paper proposes a method to learn from human demonstration compliant contact motions, which take advantage of interaction forces between workpieces to align them, even when contact force may occur from different directions on different instances of reproduction. To manage the uncertainty in unstructured conditions, the motions learned with our method can be reproduced with an impedance controller. Learning from Demonstration is used because the planning of compliant motions in 3-D is computationally intractable. The proposed method will learn an individual compliant motion, many of which can be combined to solve more complex tasks. The method is based on measuring simultaneously the direction of motion and the forces acting on the end-effector. From these measurements we construct a set of constraints for motion directions which, with correct compliance, result in the observed motion. Constraints from multiple demonstrations are projected into a 2-D angular coordinate system where their intersection is determined to find a set of feasible desired directions, of which a single motion direction is chosen. The work is based on the assumption that movement in directions other than the desired direction is caused by interaction forces. Using this assumption, we infer the number of compliant axes and, if required, their directions. Experiments with a KUKA LWR4+ show that our method can successfully reproduce motions which require taking advantage of the environment.	align (company);angularjs;characteristic impedance;computational complexity theory;hidden markov model;machine learning;markov chain;modulation;robot end effector;self-replicating machine	Markku Suomalainen;Ville Kyrki	2017	2017 IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids)	10.1109/HUMANOIDS.2017.8246961	control theory;control theory;computer science;coordinate system;contact force;electrical impedance	Robotics	61.83213951777331	-24.716751629462706	99570
4dafacf2da571f2015f238676fcc619a424ff7ce	a localization system using inertial measurement units from wireless commercial hand-held devices	gait inertial measurement unit inertial navigation system pedestrian dead reckoning step counter step length complementary filter accelerometer gyroscope;wireless commerical handheld devices trajectory calculation mobile objects commercially available sensors modern mobile phones step counting technique novel step length estimator accelerometer sensor heading information gyroscope complementary filter quaternion form low power arm processor trajectory points estimation accuracy return position error localization system interial measurement units;gyroscope;gait;inertial measurement unit;accelerometers trajectory acceleration estimation legged locomotion sensors gyroscopes;object tracking accelerometers gyroscopes inertial navigation mobile handsets;step counter;accelerometer;pedestrian dead reckoning;step length;complementary filter;inertial navigation system	This paper describes a newly developed technology for the calculation of trajectories of mobile objects, which is based on commercially available sensors being integrated into modern mobile phones and other gadgets. First, a step counting technique was implemented. Second, a novel step length estimator is proposed. These two algorithms utilize the data from accelerometer sensor only. Third, the heading information was obtained using a gyroscope with complementary filter in quaternion form. The combined algorithm was implemented on a low-power ARM processor to provide the trajectory points relative to an initial point. The proposed technique was tested by 10 subjects, in different shoes with different paces. The dependence of the performance of the technology on the attaching point of the mobile device is weak. The proposed algorithms have better balance and estimation accuracy and depend in less degree on the variety in physical parameters of people in comparison with the existing techniques. In experiments inertial measurement units were mounted in different places, i.e. in the hand, in trousers or in T-shirt pockets. The return position error did not exceed 5% of the total travelled distance for all performed tests.	algorithm;course (navigation);dead reckoning;design review (u.s. government);experiment;gyroscope;iso 10303;inertial navigation system;low-power broadcasting;mobile device;mobile phone;positioning system;sensor;shoes;velocity (software development)	Aleksandr Mikov;Alex Moschevikin;Axel Sikora	2013	International Conference on Indoor Positioning and Indoor Navigation	10.1109/IPIN.2013.6817924	control engineering;embedded system;inertial measurement unit;inertial reference unit;electronic engineering;engineering;inertial navigation system	Robotics	57.58356446559411	-37.364279472401016	99688
5996f69a39115b5c97863985e1ee825973669a5b	combining global and local planning with guarantees on completeness	search problem;robot sensing systems;oscillations;range planning;state space methods;turning;mobile robot;local path planning problem;path planning;oscillators;kinodynamic constraint;mobile robots;oscillation;satisfiability;constraint satisfaction problems;constraint satisfaction;motion planning completeness kinodynamic constraint mobile robot cluttered environment range planning constraint satisfaction oscillation 2d global path planning problem local path planning problem search problem 2d state space method;trajectory;cluttered environment;state space;state space methods constraint satisfaction problems mobile robots path planning robot dynamics robot kinematics search problems;motion planning;planning robot sensing systems oscillators trajectory turning;planning;2d global path planning problem;search problems;long range;completeness;robot dynamics;2d state space method;robot kinematics	Planning with kinodynamic constraints is often required for mobile robots operating in cluttered, complex environments. A common approach is to use a two-dimensional (2-D) global planner for long range planning, and a short range higher dimensional planner or controller capable of satisfying all of the constraints on motion. However, this approach is incomplete and can result in oscillations and the inability to find a path to the goal. In this paper we present an approach to solving this problem by combining the global and local path planning problem into a single search using a combined 2-D and higher dimensional state-space.	mobile robot;motion planning;state space	Haojie Zhang;Jonathan Butzke;Maxim Likhachev	2012	2012 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2012.6225382	computer vision;mathematical optimization;simulation;computer science;artificial intelligence;mathematics;kinodynamic planning;oscillation	Robotics	57.41927474855401	-25.232461683572957	99884
d09f91e28db51b53329e6014bc684617114549aa	vision-guided self-alignment and manipulation in a walking robot	vision system;robot mating;manipulators;bolts;walking;legged locomotion;limbed excursion mechanical utility robot;vision guided self alignment;walking robot nasa jet propulsion laboratory limbed excursion mechanical utility robot computer vision vision guided manipulation algorithm bolt fastening task vision guided self alignment robot mating docking station;computer vision;nasa jet propulsion laboratory;bonding;self alignment;robot vision;docking;walking robot;legged locomotion robot vision systems robot kinematics orbital robotics propulsion laboratories prototypes computer vision mobile robots robotic assembly;aerospace robotics;robots;walking robots;robot vision aerospace robotics legged locomotion manipulators;algorithms;lemur;visual guidance;docking station;bolt fastening task;vision guided manipulation algorithm;robot vision systems;alignment;jet propulsion laboratory	One of the robots under development at the NASAs Jet Propulsion Laboratory (JPL) is the limbed excursion mechanical utility robot, or LEMUR. Several of the tasks slated for this robot require computer vision, as a system, to interface with the other systems in the robot, such as walking, body pose adjustment, and manipulation. This paper describes the vision algorithms used in several tasks, as well as the vision-guided manipulation algorithms developed to mitigate mismatches between the vision system and the limbs used for manipulation. Two system-level tasks are described, one involving a two meter walk culminating in a bolt-fastening task and one involving a vision-guided alignment ending with the robot mating with a docking station	algorithm;computer vision;docking (molecular);docking station;mobile robot	Kevin Nickels;Brett Kennedy;Hrand Aghazarian;Curtis Collins;Mike Garrett;Avi Okon;Julie Townsend	2006	2006 IEEE/SMC International Conference on System of Systems Engineering	10.1109/SYSOSE.2006.1652287	docking;robot;control engineering;computer vision;simulation;machine vision;computer science;engineering;artificial intelligence;lemur;social robot;robot control	Robotics	65.82747348394795	-27.74052484069467	100022
4ea004abc15e170b79cfdbe52064bfb112c18d3d	a low-cost and robust optical flow cmos camera for velocity estimation	gyroscopes;vibrations estimation image motion analysis computer vision cameras histograms optical filters;velocity measurement cmos image sensors failure analysis global positioning system gyroscopes;cmos image sensors;failure analysis;global positioning system;on board gps system cmos camera low cost optical flow robust optical flow velocity estimation low cost monocular platform tri axial gyroscope px4flow platform open software solution open hardware solution monocular speed estimation feature block selection feed forward rotation motion compensation failure case detection failure case filtering integrated trajectory;velocity measurement	This paper presents a robust velocity estimation algorithm applicable to low-cost monocular platform with a tri-axial gyroscope. The algorithm is developed based on PX4FLOW platform which is an open software and open hardware solution for monocular speed estimation. The paper provides three main contributions. The first is the improved robustness achieved by various methods including feature block selection, feed-forward rotation, motion compensation, failure case detection and filtering. The second contribution is the improved performance in terms of resolution and search range achieved by adaptive frame interval and advanced search algorithm. The final contribution is a systematical strategy for parameter selection to fully utilize the hardware resources and optimize the performance in different contexts. The performance was benchmarked against the PX4FLOW and GPS. Results indicated that the proposed algorithm achieved levels of robustness exceeding that of PX4FLOW in measuring velocity. Also, the integrated trajectory agreed with the position calculated by an on-board GPS system.	active pixel sensor;benchmark (computing);cmos;global positioning system;gyroscope;motion compensation;on-board data handling;open-source hardware;open-source software;optical flow;search algorithm;triangular function;velocity (software development)	Ke Sun;Yun Yu;Wancheng Zhou;Guyue Zhou;Tao Wang;Zexiang Li	2013	2013 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2013.6739624	computer vision;failure analysis;electronic engineering;global positioning system;gyroscope;engineering;control theory	Robotics	56.61475390787445	-36.243355905600254	100331
300dead8a993ef310fc2e1117e185a316b4cdbad	failure detection and isolation of ultrasonic ranging sensors for robotic applications	ultrasonic transducers distance measurement failure analysis kinematics position control redundancy robots ultrasonic applications;ultrasonic probe;receiver;systeme commande;sistema control;measurement error;detection panne;palpeur ultrason;methode mesure;redundancia;isolation;failure detection;receptor;sonda de ultrasonidos;metodo medida;robotics;emetteur;ultrasonic transducers;ultrasonic applications;kinematics;failure analysis;captador medida;distance measurement;control system;measurement sensor;capteur mesure;redundancy;position control;transmitter;robots;recepteur;robotica;insulation;fdi technique failure detection failure isolation ultrasonic ranging sensors robot position control systems parity space analytic redundancy end effector position structural deflections;robot kinematics fault detection robot sensing systems orbital robotics position control redundancy ultrasonic variables measurement payloads sensor systems extraterrestrial measurements;robotique;measurement method;emisor;deteccion falla;redondance;aislamiento	A failure detection and isolation (FDI) method for validation of ultrasonic ranging sensor (URS) signals in robot position control systems is presented. The technique builds upon the concepts of parity space and analytic redundancy where integration of analytic and sensor redundancy provides a direct, reliable method for measuring the end effector position of a robot relative to the world coordinates. These measurements are not influenced by deflections caused hy the payload, accumulated joint measurement errors in a serial mechanism, and computational errors in executing kinematic relationships. The position control system's insensitivity to structural deflections allows the robot to handle larger payloads. Simulation results are presented to demonstrate how the FDI technique can be applied.	analytic signal;control system;fault detection and isolation;glossary of computer graphics;redundancy (engineering);robot end effector;sensor;simulation	Rogelio Luck;Asok Ray	1991	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.101151	robot;receiver;failure analysis;kinematics;transmitter;isolation;receptor;computer science;control system;artificial intelligence;control theory;redundancy;robotics;statistics;observational error	Robotics	59.13223448380688	-35.560979511480916	100359
f2cd6a6145fbdd763a3d165aeb75c3fad95828a8	efficient localization for robot soccer using pattern matching		One of the biggest challenges in the RoboCup Soccer Standard Platform League (SPL) is autonomously achieving and maintaining an accurate estimate of a robot’s position and orientation on the field. In other robotics applications many robust systems already exist for localization such as visual simultaneous localization and mapping (SLAM) and LIDAR based SLAM. These approaches either require special hardware or are very computationally expensive and are not suitable for the Nao robot, the current robot of choice for the SPL. Therefore novel approaches to localization in the RoboCup SPL environment are required. In this paper we present a new approach to localization in the SPL which relies primarily on the information contained within white field markings while being efficient enough to run in real time on board a Nao robot.		Thomas Whelan;Sonja Stüdli;John McDonald;Richard H. Middleton	2011		10.1007/978-3-642-34781-8_2	pattern matching;simultaneous localization and mapping;robot;computer vision;kalman filter;artificial intelligence;lidar;robotics;engineering	Robotics	54.05052103141565	-36.89982866105649	100731
92854822c75d07a6ae85e6f1abf7becfa32c2f71	a visual servoing approach for road lane following with obstacle avoidance	instruments for measuring speed or velocity;automobiles;roads visual servoing collision avoidance navigation vehicles cameras;robotics;urban areas;proximity detectors;obstacle avoidance visual servoing dynamic window approach local navigation;autonomous robotic automobiles visual servoing controller road lane following obstacle avoidance navigation strategy;visual servoing automobiles collision avoidance mobile robots navigation road traffic control robot vision;vehicle dynamics;autonomous vehicle guidance	This paper presents a local navigation strategy with obstacle avoidance applied to autonomous robotic automobiles in urban environments, based on the validation of a Visual Servoing controller in a Dynamic Window Approach. Typically, Visual Servoing applications do not consider velocity changes to stop the robot in danger situations or avoid obstacles, while performing the navigation task. However, in several urban conditions, these are elements that must be deal with to guarantee the safe movement of the car. As a solution for this problem, in this work a line following Visual Servoing controller will be used to perform road lane following tasks and its control outputs will be validated in an Image-Based Dynamic Window Approach. The final solution is a validation scheme for the Visual Servoing velocities which allows the obstacle avoidance, taking into account the car kinematics and some dynamics constraints. Experiments in simulation and with a full-sized car show the viability of the proposed methodology.	autonomous car;autonomous robot;data validation;dynamic window approach;experiment;mathematical model;obstacle avoidance;olami–feder–christensen model;simulation;velocity (software development);verve;visual servoing;workspace	Danilo Alves de Lima;Alessandro Corrêa Victorino	2014	17th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2014.6957725	control engineering;computer vision;simulation;geography;obstacle avoidance;visual servoing	Robotics	57.610665940714355	-28.95481547762486	100855
f61d2a30dec6d5ba07a941c3a380a886be5ea380	hybrid probabilistic trajectory optimization using null-space exploration		In the context of learning from demonstration, human examples are usually imitated in either Cartesian or joint space. However, this treatment might result in undesired movement trajectories in either space. This is particularly important for motion skills such as striking, which typically imposes motion constraints in both spaces. In order to address this issue, we consider a probabilistic formulation of dynamic movement primitives, and apply it to adapt trajectories in Cartesian and joint spaces simultaneously. The probabilistic treatment allows the robot to capture the variability of multiple demonstrations and facilitates the mixture of trajectory constraints from both spaces. In addition to this proposed hybrid space learning, the robot often needs to consider additional constraints such as motion smoothness and joint limits. On the basis of Jacobian-based inverse kinematics, we propose to exploit robot null-space so as to unify trajectory constraints from Cartesian and joint spaces while satisfying additional constraints. Evaluations of hand-shaking and striking tasks carried out with a humanoid robot demonstrate the applicability of our approach.	cartesian closed category;environment variable;humanoid robot;inverse kinematics;jacobian matrix and determinant;kernel (linear algebra);kernel method;mathematical optimization;reinforcement learning;requirement;spatial variability;trajectory optimization;velocity (software development)	Yanlong Huang;João Silvério;Leonel Dario Rozo;Darwin G. Caldwell	2018	2018 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2018.8460550	robot;humanoid robot;jacobian matrix and determinant;trajectory optimization;mathematical optimization;control theory;probabilistic logic;inverse kinematics;engineering;trajectory;robot kinematics	Robotics	62.27534511187199	-24.17770898911031	100929
e78791c363daa73bc59473b1a12a320f71fe1313	motion control design for unmanned ground vehicle in dynamic environment using intelligent controller		Purpose The motion control of unmanned ground vehicles is a challenge in the industry of automation. In this paper, a fuzzy inference system based on sensory information is proposed for the purpose of solving the navigation challenge of unmanned ground vehicles in cluttered and dynamic environments. Design/methodology/approach The representation of the dynamic environment is a key element for the operational field and for the testing of the robotic navigation system. If dynamic obstacles move randomly in the operation field, the navigation problem becomes more complicated due to the coordination of the elements for accurate navigation and collision-free path within the environmental representations. This paper considers the construction of the fuzzy inference system which consists of two controllers. The first controller uses three sensors based on the obstacles distances from the front, right and left. The second controller employs the angle difference between the heading of the vehicle and the targeted angle to obtain the optimal route based on the environment and reach the desired destination with minimal running power and delay. The proposed design shows an efficient navigation strategy that overcomes the current navigation challenges in dynamic environments. Findings Experimental analyses conducted for three different scenarios to investigate the validation and effectiveness of the introduced controllers based on the fuzzy inference system. The reported simulation results were obtained using MATLAB software package. The results show that the controllers of the fuzzy inference system consistently perform the manoeuvring task and manage the route plan efficiently, even in a complex environment that populated with dynamic obstacles. The paper demonstrates that the destination was reached optimally using the shortest free route. Research limitations/implications The paper represents efforts toward building a dynamic environment filled with dynamic obstacles that move to at various speeds and directions. The methodology of designing the fuzzy inference system is accomplished to guide the unmanned ground vehicle to the desired destination while avoiding collisions with obstacles. However, our methodology is approached using two-dimensional analyses. Hence, the paper suggests several extensions and variations to develop a three-dimensional strategy for further improvement. Originality/value This paper presents the design of a fuzzy inference system and its characterizations in dynamic environments, specifically for obstacles that move at different velocities. That facilitates an improved functionality of the operation of unmanned ground vehicles. The first author would like to express his gratefulness for his sponsor, the Ministry of Higher Education and Scientific Research in Iraq for funding his PhD scholarship in the United Kingdom. He also would like to thank the University of Basrah in Iraq for the support.	course (navigation);fuzzy logic;inference engine;matlab;motion planning;population;randomness;robot;robotic mapping;sensor;simulation;unmanned aerial vehicle	Auday Al-Mayyahi;Weiji Wang;Alaa Adnan Hussein;Phil Birch	2017	Int. J. Intelligent Computing and Cybernetics	10.1108/IJICC-11-2016-0044	computer science;artificial intelligence;machine learning;fuzzy logic;automation;control theory;simulation;motion control;navigation system;unmanned ground vehicle;control engineering;software;inference	Robotics	55.97614393354027	-26.464558020107216	101071
b153f0196039393bd0438b92d80e91fc31d74d16	towards guidance chip for micro aerial vehicles	microrobots;field programmable gate array;attitude and heading reference system;microaerial vehicles;ahrs400 guidance chip microaerial vehicles autonomous aerial vehicles attitude and heading reference system micro electro mechanical system sensors field programmable gate array fpga xilinx spartan iii x3csl500;ahrs400;real time;unmanned aerial vehicle;remotely operated vehicles aircraft field programmable gate arrays microrobots microsensors mobile robots;mobile robots;remotely operated vehicles;fpga;chip;micro electro mechanical system;reference systems;micro electro mechanical system sensors;guidance chip micro aerial vehicles attitude and heading reference system field programmable gate array;guidance chip;micro aerial vehicle;power consumption;field programmable gate arrays;micro aerial vehicles;navigation unmanned aerial vehicles remotely operated vehicles mechanical sensors sensor arrays field programmable gate arrays hardware mobile robots humans payloads;xilinx spartan iii x3csl500;high speed;hardware implementation;microsensors;autonomous aerial vehicles;aircraft	Autonomous aerial vehicles need to navigate as well as control themselves in real time without any human intervention. This requirement imposes an immense pressure on the processing powers as well as the accuracy of sensors used for navigation. Micro aerial vehicles (MAVs) have payload and power constraints that prohibit use of highly accurate sensors and powerful processors. This paper presents implementation of an attitude and heading reference system (AHRS) using low cost micro electro mechanical system (MEMS) sensors and field programmable gate array (FPGA). This hardware implementation of AHRS has enabled us to achieve attitude update rate of 20.0 micro seconds necessary for high speed control loop with power consumption of 110 mW. The target FPGA used for this work is Xilinx Spartan III x3csl500 which provides sufficient logic for implementation of AHRS algorithm. The work presented here is the first step towards a dedicated guidance chip for MAVs that will be able to navigate as well as control an MAV autonomously. Simulation and hardware implementation results were compared with Crossbow's AHRS400 which show that the design is suitable for implementing AHRS for MAVs and small unmanned aerial vehicles (UAVs).	aerial photography;algorithm;attitude and heading reference system;central processing unit;computation;control system;course (navigation);field-programmable gate array;maximum throughput scheduling;microelectromechanical systems;sensor;simulation;spartan;unmanned aerial vehicle	Muhammad Haris Afzal;Muhammad Asif;Muhammad Akhtar Khan	2006	2006 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2006.340179	control engineering;embedded system;electronic engineering;computer science;engineering;field-programmable gate array	Robotics	56.69919958921036	-32.01041387894197	101090
3d086827ff9585130a05fafd37d39d776fa2a7fe	guided self-organization in a dynamic embodied system based on attractor selection mechanism	curved beam hopping robot;attractor selection mechanism;sensory input;mechanical dynamics;stochastic perturbation;embodied system;goal directed locomotion;guided self organization	Guided self-organization can be regarded as a paradigm proposed to understand how to guide a self-organizing system towards desirable behaviors, while maintaining its non-deterministic dynamics with emergent features. It is, however, not a trivial problem to guide the self-organizing behavior of physically embodied systems like robots, as the behavioral dynamics are results of interactions among their controller, mechanical dynamics of the body, and the environment. This paper presents a guided self-organization approach for dynamic robots based on a coupling between the system mechanical dynamics with an internal control structure known as the attractor selection mechanism. The mechanism enables the robot to gracefully shift between random and deterministic behaviors, represented by a number of attractors, depending on internally generated stochastic perturbation and sensory input. The robot used in this paper is a simulated curved beam hopping robot: a system with a variety of mechanical dynamics which depends on its actuation frequencies. Despite the simplicity of the approach, it will be shown how the approach regulates the probability of the robot to reach a goal through the interplay among the sensory input, the level of inherent stochastic perturbation, i.e., noise, and the mechanical dynamics.	beam robotics;control flow;emergence;frequency-hopping spread spectrum;image noise;interaction;organizing (structure);programming paradigm;robot;self-organization	Surya Girinatha Nurzaman;Xiaoxiang Yu;Yongjae Kim;Fumiya Iida	2014	Entropy	10.3390/e16052592	simulation;control theory	Robotics	64.77968565661787	-25.67591394742257	101424
59180966c3f67bd3e1afa6efc42d80b229c8a323	solving peg-in-hole tasks by human demonstration and exception strategies	manipulation and compliant assembly;learning from demonstration	Purpose – The purpose of this paper is to propose a new algorithm based on programming by demonstration and exception strategies to solve assembly tasks such as peg-in-hole. Design/methodology/approach – Data describing the demonstrated tasks are obtained by kinesthetic guiding. The demonstrated trajectories are transferred to new robot workspaces using three-dimensional (3D) vision. Noise introduced by vision when transferring the task to a new configuration could cause the execution to fail, but such problems are resolved through exception strategies. Findings – This paper demonstrated that the proposed approach combined with exception strategies outperforms traditional approaches for robot-based assembly. Experimental evaluation was carried out on Cranfield Benchmark, which constitutes a standardized assembly task in robotics. This paper also performed statistical evaluation based on experiments carried out on two different robotic platforms. Practical implications – The developed framework can have an important impact for robot assembly processes, which are among the most important applications of industrial robots. Our future plans involve implementation of our framework in a commercially available robot controller. Originality/value – This paper proposes a new approach to the robot assembly based on the Learning by Demonstration (LbD) paradigm. The proposed framework enables to quickly program new assembly tasks without the need for detailed analysis of the geometric and dynamic characteristics of workpieces involved in the assembly task. The algorithm provides an effective disturbance rejection, improved stability and increased overall performance. The proposed exception strategies increase the success rate of the algorithm when the task is transferred to new areas of the workspace, where it is necessary to deal with vision noise and altered dynamic characteristics of the task.		Fares J. Abu-Dakka;Bojan Nemec;Aljaz Kramberger;Anders Glent Buch;Norbert Krüger;Ales Ude	2014	Industrial Robot	10.1108/IR-07-2014-0363	simulation;computer science;artificial intelligence	Robotics	63.24653059962891	-26.5783645547638	101440
e80f3ac5b5ea602bf32be5bb1b4296caf6a1b069	camber angle inspection for vehicle wheel alignments	camber angle;coordinate transformation;wheel alignment;accelerometer	This paper introduces an alternative approach to the camber angle measurement for vehicle wheel alignment. Instead of current commercial approaches that apply computation vision techniques, this study aims at realizing a micro-control-unit (MCU)-based camber inspection system with a 3-axis accelerometer. We analyze the precision of the inspection system for the axis misalignments of the accelerometer. The results show that the axes of the accelerometer can be aligned to the axes of the camber inspection system imperfectly. The calibrations that can amend these axis misalignments between the camber inspection system and the accelerometer are also originally proposed since misalignments will usually happen in fabrications of the inspection systems. During camber angle measurements, the x-axis or z-axis of the camber inspection system and the wheel need not be perfectly aligned in the proposed approach. We accomplished two typical authentic camber angle measurements. The results show that the proposed approach is applicable with a precision of ± 0.015 ∘ and therefore facilitates the camber measurement process without downgrading the precision by employing an appropriate 3-axis accelerometer. In addition, the measured results of camber angles can be transmitted via the medium such as RS232, Bluetooth, and Wi-Fi.	abbreviations;alignment;apache axis;attitude;axis vertebra;base excision repair;bluetooth;calibration;computation;conflict (psychology);control unit;downgrade;enzyme immunoassay;experiment;futures studies;genus axis;hl7publishingsubsection <operations>;imperative programming;least-angle regression;manuscripts;mathematics;mega man zx;optic axis of a crystal;rs-232;scart;system of measurement;wheels;accelerometers;disease transmission;sensor (device)	Jieh-Shian Young;Hong-Yi Hsu;Chih-Yuan Chuang	2017		10.3390/s17020285	structural engineering;computer science;engineering;coordinate system;camber angle;automotive engineering;engineering drawing;accelerometer;physics	SE	60.111864867813	-36.51712199084937	101602
79e72b75c9baeb68331f4d7622e4b1942a7846ae	evaluation of construction robot telegrasping force perception using visual, auditory and force feedback integration	master slave control;multimodal sensory feedback;manipulator;construction machinery		haptic technology;industrial robot	Ahmad A. Yusof;Takuya Kawamura;Hironao Yamada	2012	JRM	10.20965/jrm.2012.p0949	control engineering;computer vision;engineering;control theory	Robotics	67.95842216291834	-27.975929273833323	101624
b02f063b278da277c99a85810411a034cf22c742	reasons for singularity in robot teleoperation	learning from demonstration;teleoperation;singularity	In this paper, the causes for singularity of a robot arm in teleoperation for robot learning from demonstration are analyzed. Singularity is the alignment of robot joints, which prevents the configuration of the inverse kinematics. Inspired by users' own hypotheses, we investigated speed and delay as possible causes. The results show that delay causes problems during teleoperation though not in direct control with a control panel because users expect a different, more intuitive control in teleoperation. Speed on the other hand was not found to have an effect on the occurrence of singularity.	http 404;inverse kinematics;plugboard;reinforcement learning;robot learning;robotic arm;singularity project	Ilka Marhenke;Kerstin Fischer;Thiusius Rajeeth Savarimuthu	2014	2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/2559636.2559828	singularity;teleoperation;simulation;computer science;artificial intelligence	Robotics	64.13617960833109	-24.272435109987956	101639
1cef95221a3f49e6421eb8ffc33f8c9eb94f7720	some aspects of human performance in a human adaptive mechatronics (ham) system	helicopter test rig;hardware based experiment;human performance;simple tracking task;manual control system;human skill;point to point operation;model based approach;thesis;human adaptive mechatronics;simple tracking operation;ham;computer based experiment;non model approach	Human skill evaluation or human skill quantification in the original definition of a human adaptive mechatronics system is the main concern of this paper. However, a deficiency in terms of consistency and subjectivity makes human skill not fully indicative of actual human performance. That is, the term human skill can mean repeatability, adaptability, or learning capability depending on the aspects and systems of interest. This paper proposes a human performance index (HPI) concept to focus on human performance instead. The main contributions are the quantification of speed–accuracy characteristics based on Fitts’ classical speed–accuracy trade-off and determination of human control strategy involved in completing a task. The experiment in this paper was conducted on a computer-based simple tracking system by using a computer mouse to follow a set of random circles on a display. Human operators were told to complete the task as quickly as possible. HPI values were then calculated with and without weightings on speed and accuracy criteria. Different human performance values reflect how human operators accomplish the same task under the same working conditions. These control strategies are associated with a degree of emphasis on the speed and accuracy characteristics of the operators’ control actions.		Tussanai Parthornratt	2011			control engineering;simulation;engineering;artificial intelligence	AI	68.08709978044297	-30.355231554994866	101783
634f3d6eb3e3bddcedcd4a4b0b1ef2440df4008a	differential evolution for optimizing motion planning of mobile robot		The demand for faster, more precise and more sophisticated solutions in industrial robotics is growing more and more. People keep seeking for a better solution for robotic problems in general and mobile robots in particularly to meet this demand. In this paper, we propose a new evolutionary approach called Differential Evolution (DE) that can be employed to optimize the path planning task for mobile robots. The path not only needs to be optimized but also needs to be easy to traverse for non-holonomicity. Therefore, the path smoothening B-spline technique is integrated with the DE approach to provide traversable path for mobile robots. Our system has been implemented and evaluated on an Aria mobile robot in both simulated and real environments.	aria;b-spline;differential evolution;industrial robot;iterative and incremental development;mobile robot;motion planning;traverse	Cong Hung Do;Huei-Yung Lin	2017	2017 IEEE/SICE International Symposium on System Integration (SII)	10.1109/SII.2017.8279245	engineering;genetic algorithm;traverse;control engineering;differential evolution;motion planning;mobile robot;robotics;artificial intelligence	Robotics	55.004468677366866	-24.435034653659557	101791
9767c3e1830e5c71d190f29b07febd68342b7313	development of can bus application layer protocol for 6 dof shake table control system	protocols;sensors;multi axis control can bus application layer protocol shake table;actuators;graphical user interfaces;actuators protocols real time systems data transfer sensors graphical user interfaces data acquisition;protocols controller area networks field buses hydraulic actuators;can bus application layer protocol dacci dual can bus interfaces double actuator controller servo hydraulic actuators barc refuelling technology division degrees of freedom 6 dof shake table control system;data acquisition;data transfer;real time systems	A 500 kg payload 6 DOF (Degrees of Freedom) shake table has been designed and developed indigenously in Refuelling Technology Division, BARC. The Shake Table consists of 8 numbers of servo hydraulic actuators out of which four are vertical actuators and four are horizontal actuators. Four double Actuator Controller with dual CAN bus interfaces (DACCI) [1] are developed to control movement of servo hydraulic actuators. DACCI is having two independent CAN bus interfaces namely, CAN-A and CAN-B. All DACCIs are connected to CAN-A network. PC is also connected to CAN-A network. DACCI-A and DACCI-B are connected to CAN-B network. Another CAN-B network is used between DACCI-C and DACCI-D. This paper explains design and development of CAN-A and CAN-B network application layer protocols for transferring real time acquired data, transferring plot data, broadcasting commands and sending sensor data for control purpose.	can bus;control system;datacasting;servo	Tejas V. Unavane;M. S. Panse;Shiju Varghese;N. L. Soni;R. J. Patel	2015	2015 IEEE 2nd International Conference on Recent Trends in Information Systems (ReTIS)	10.1109/ReTIS.2015.7232892	control engineering;embedded system;real-time computing;engineering	Robotics	64.92419524340637	-30.40083230950824	101804
c7a876c8c80884e27f9291132f8c59cdd2a84f34	on the controllers of human handwriting motion	motion control geometry;shape writing muscles electromyography prediction algorithms mathematical model;prediction algorithms;shape;mathematical model;writing;cursive arabic letters human handwriting motion bresenham bi axis control algorithm;electromyography;geometric shape human handwriting motion controller handwriting trace generation bresenham algorithm trace generator algorithm arabic letter;muscles	In this paper, we are interested to the handwriting traces generation in order to reproduce those given by human beings. With the coordinates of a pen-tip moving on (x, y) plane during the human handwriting moving, a Bresenham algorithm can be used as a trace generator algorithm. This last one is well-used for a circle tracing to control bi-axis motions. On the basis of this algorithm, a new trace generator algorithm is presented to predict different cursive Arabic letters and geometric shapes. Using the recorded experimental data basis, a comparative study of these two algorithms will be presented.	apache axis;bresenham's line algorithm;tracing (software)	I. Mahmoud;Ines Chihi;L. Sidhom;Afef Abdelkrim	2016	2016 International Conference on Control, Decision and Information Technologies (CoDIT)	10.1109/CoDIT.2016.7593625	speech recognition;computer science;artificial intelligence;machine learning	Robotics	62.72015107876678	-25.499759498858285	101991
e5423ce99c23166fd0a596b76eae004718eb30cd	hardware implementation in dgps accuracy improvement by using rscmac	economic benefit;field programmable gate array;radio receivers;differential gps;hardware implementation dgps rscmac;neural nets;global position system;chip;error analysis;radio receivers error analysis field programmable gate arrays global positioning system neural nets;global positioning system;field programmable gate arrays;global positioning system satellites hardware receivers roads field programmable gate arrays accuracy;hardware implementation;cerebellar model articulation controller hardware implementation dgps rscmac recurrent s_cmac_gbf differential global positioning system fpga chip receiver positioning errors	The purpose of this research is to develop and apply the “Recurrent S_CMAC_GBF (RSCMAC) [2] to enhance the accuracy of Global Positioning System (GPS). The performance is implemented and tested by a FPGA chip. In the research, the previous work has accomplished outstanding performance by using RSCMAC to predict GPS receiver static error to improve the error of the Differential-GPS. The simulation result shows 10 times accuracy is improved — GPS error is improved from larger than **** 20M to less than **** 2M. This paper employs previous research result to whole area prediction (non single fixed position), and then implements the performance by a FPGA chip. The key point is to commercialize the prototype design and its development. The most advantage of this project is to improve inexpensive GPS receiver positioning errors to increase the economic benefit of higher accuracy.	assisted gps;differential gps;field-programmable gate array;global positioning system;prototype;recurrent neural network;simulation	Ching-Tsan Chiang;Jih-Sheng Hsu;Sheng-Jie Yang	2011	2011 4th International Conference on Biomedical Engineering and Informatics (BMEI)	10.1109/BMEI.2011.6098782	embedded system;real-time computing;computer science;precise point positioning;artificial neural network;field-programmable gate array	Robotics	58.142545123154726	-36.45187103662121	102059
7ed543a56aeea20e31040093564ac46bcf6e2905	vision guided circumnavigating autonomous robots	system performance;geometric model;autonomous robot;knowledge base	b`: 3hYV V¡`¢z¢ h¡`VzV V¡`¤£¥£¡`w`Y V V§¦=h ̈ ̈\© a z e  h«n ̈ h«¬hx nY V ¤¥ ­ ̈® ¥V¡``¢ h«Y ̄£°$h± «n2  ¬Vh¦Yh`¢ hV¢ h«nh£ ̈3? ́ μ`mYR¬­h2®8 Y¢z ̈¶a·«=h¢ ̧h«Y ̄£°t£°h V`VeVRh :`r ® hh3¤1m ` «n ̈` ®h«¬ho»£°h Vn hn¢%`\3 V b©μ ^£°¤jn £¡` ̈1⁄4  h«Y ̄£°¦Vμ`tY1⁄2 ¬3⁄4©m¥t¥h«^htD¬h¥1⁄2¢z¥w`1⁄4£yh£°V`PV ^£¿n£ h«Y ̄£°¦§¥ μzÀμ`hÁ hz¥h ̈?°ÂYn ̈h¥ V%h`¢l`\3 V VlhÀ nμ`h1⁄4¢%1⁄4 b¡`£¥μ h μz»£¡z: ̈1⁄4¥ ¡zh3l ́ μ`1⁄4 ̧n ¬ ¢`£°¥«¬b Ã¡` ̈ ̈l: h¥ ¢ Y*¦yh`¢±¦ ln 1⁄4£¡` ̈ ¦±:Y¢`¡`£° ̧£h`V`£h ̈¶a·Y©o3ÅÄn¡`μz¦g©mw¢`¥h® ¢`£° ̧h ̈ h«`¥h1⁄4£  μzY¢>h ̧¿n`¢nz »h«Y ̄£°e¬Vwh`¢ ¬VVlheμz ­V¡`ar¢` nV`h ̈?£hjh  hV¡``¢za·«nh¢lh«¬hÀ©oμl¡``£h ̈1⁄4«`¥ ¢Áh£h ̈x \h :eh$D£h ¥Y3 ÆÀV ­h h«n ̈D¥h«^ho£h «¬D ¢Áho h*¢`Ç^: `h«= ̈Èw¥h¢nV`h ̈§£°VÅa n¡z ̧YV§¦8he®h«n ̈Åh«¬heμnh  £¥μ` ¥h£°2£ ¬¥^£°hh¦gh`¢μ`w ̧ £h¡`h ̈ ¥ ̈ V «¬r©$a¥h«^h h£°V`whn¢ 3©X£¥μ`h` h3ÊÉ h`V`£h ̈¶a·Y©o    z3⁄4h ̈F¦Ph£°hjh«Y ̄H£°b`¥T V/¢z¥ Vz¢>¬£¿=£h ̈ ̈Á  Ëh*h¢z hT hjh μzo£°V`¥h:yh¬μz h«¬hxnY V V®nh«n ̈Ìbh ̈ ̈3⁄4©aÍw£:y£°h V`Vwh`¢ `Y V V±3		Nick Barnes;Zhi-Qiang Liu	1995		10.1007/3-540-60697-1_84	computer vision;knowledge base;simulation;computer science;artificial intelligence;social robot;geometric modeling;robot control	Robotics	58.13207068327311	-30.425407316477056	102152
a04d2bcf779a1cc2f5601b4e7557daa3dc67291c	towards supervisory control of humanoid robots for driving vehicles during disaster response missions	velocity control disasters humanoid robots image sensors mobile robots optical radar robot vision stereo image processing;mobile robots;joints;vehicles joints cameras mobile robots robot vision systems robot kinematics;stereo cameras humanoid robots disaster response missions vehicle driving wpi worcester polytechnic institute robotics engineering c squad wrecs defense advanced research projects agency robotics challenge trials darpa drc atlas robot supervisory control system vehicle speed lidar;vehicles;robot vision systems;cameras;robot kinematics	We describe the approach of Worcester Polytechnic Institute's (WPI) Robotics Engineering C Squad (WRECS)to the utility vehicle driving task at the Defense Advanced Research Projects Agency (DARPA) Robotics Challenge (DRC) Trials held in December 2013. WRECS was one of only seven teams to attempt the driving task, and the only team with an ATLAS robot to successfully drive the course. We implement a supervisory control system that allows the robot to control the speed of the vehicle, while the operator helps the robot steer the vehicle. Two different methods of estimating speed, using the LIDAR and stereo cameras, are presented, and the performance of the robot at the Trials is discussed.	atlas;algorithm;control system;darpa robotics challenge;fastest;humanoid robot;inverse kinematics;steering wheel;stereo camera;stereo cameras;velocity (software development)	Kevin Knoedler;Velin D. Dimitrov;Doug Conn;Michael A. Gennert;Taskin Padir	2015	2015 IEEE International Conference on Technologies for Practical Robot Applications (TePRA)	10.1109/TePRA.2015.7219695	control engineering;mobile robot;robot learning;computer vision;simulation;engineering;robot control;personal robot	Robotics	56.55617664357197	-28.939224879301737	102240
1440298db55ad46b862258469cea4a0a66916a6d	a travel-time optimizing edge weighting scheme for dynamic re-planning	graph planning;navigation;motion planning	The success of autonomous vehicles has made path planning in real, physically grounded environments an increasingly important problem. In environments where speed matters and vehicles must maneuver around obstructions, such as autonomous car navigation in hostile environments, the speed with which real vehicles can traverse a path is often dependent on the sharpness of the corners on the path as well as the length of path edges. We present an algorithm that incorporates the use of the turn angle through path nodes as a limiting factor for vehicle speed. Vehicle speed is then used in a time-weighting calculation for each edge. This allows the path planning algorithm to choose potentially longer paths, with less turns in order to minimize path traversal time. Results simulated in the Breve environment show that travel time can be reduced over the solution obtained using the Anytime D* Algorithm by approximately 10% for a vehicle that is speed limited based on turn rate.	anytime algorithm;automated planning and scheduling;automotive navigation system;autonomous car;autonomous robot;directory traversal attack;facebook graph search;motion planning;optimizing compiler;overhead (computing);traverse;tree traversal;breve	Andrew Feit;Lenrik Toval;Raffi Hovagimian;Rachel Greenstadt	2010			computer vision;mathematical optimization;navigation;simulation;fast path;any-angle path planning;computer science;artificial intelligence;motion planning	Robotics	53.8923820299988	-25.728375238501563	102424
8af6fb64eeea0e5aa24e650fa39cf3492fbe59f7	an indoor positioning system based on inertial sensors in smartphone	magnetometers legged locomotion gyroscopes feature extraction acceleration turning sensors;smart phones feature extraction gait analysis indoor navigation particle filtering numerical methods;particle filter pedestrian dead reckoning moving variance analysis model wave simulating feature vector;map matching indoor positioning system built in inertial sensor smartphone self contained approach pedestrian dead reckoning feature vector extraction step detection gait change equivalent model wave particle filter	Recently various indoor positioning techniques have been developed based on smartphone. However, most of them need external signals. In this paper a self-contained approach relying on built-in inertial sensors is implemented. Taking advantage of Pedestrian Dead Reckoning, it updates the current position by measuring the length and the heading of each step. Foremost the whole walking process is divided into segments, in which only straight walking is involved. After that the Feature Vectors are extracted for step detection. Specially, to cope with the instabilities caused by gait change, an equivalent Model Wave is created to substitute the original data. Finally, Particle Filter is employed for map matching. According to a group of experiments, our approach is as accurate as traditional positioning technique but shows more robustness.	built-in self-test;course (navigation);dead reckoning;experiment;foremost;indoor positioning system;map matching;particle filter;sensor;smartphone;step detection	Yi Sun;Yubin Zhao;Jochen H. Schiller	2015	2015 IEEE Wireless Communications and Networking Conference (WCNC)	10.1109/WCNC.2015.7127812	computer vision;simulation	Mobile	57.4242132518581	-37.501408937420635	102519
8103731c88b1319eb93a150feae3e370e2619645	application of vision information to planning trajectories of adept six-300 robot	servers;trajectory;grippers;robot vision systems;cameras;robot kinematics	This article1 presents the algorithms of calculations of the manipulation object coordinate position and orientation, for the planning movement of the robot Adept Six-300. Two cameras Edimax IC-7100P observe objects in the robot environment. To geometric calibration of these cameras it was used the original algorithm that does not require calculation of the projection matrix or fundamental matrix. Thanks to this used algorithm is faster and more accurate than methods with these arrays. The input of these algorithms are the coordinates of the characteristic points of the manipulation object, obtained by these two cameras. On the basis of these input data the coordinates of the position and orientation of the object seen by the cameras are calculated. For these coordinates the joint variables of the manipulator are calculated by means of the program that takes into account the singular configurations and that optimize a quality indicator. These variables describe the trajectory approaching of the gripper to the object, grasp and pick up it. All calculations are doing in external computer constituting a server that cooperates with cameras and robot controller, by means of the Ethernet.	algorithm;computation;computational intelligence;correctness (computer science);fundamental matrix (computer vision);robot end effector;server (computing)	Szkodny Tadeusz	2016	2016 International Conference on Advanced Robotics and Mechatronics (ICARM)	10.1109/ICARM.2016.7606900	control engineering;computer vision;bang-bang robot;simulation;computer science	Robotics	63.26028444048427	-30.304521375141707	102598
320c70e5a8714f497db1b88604d74a653717ddee	human training using hri approach based on fuzzy artmap networks	measurement;motor skills;skill acquisition;human factors;human robot interaction;cognitive robotics;evaluation function;machine learning;robots;feedback;cost function;convergence	Based on recent studies which establishes that skill acquisition requires not just specification of motor skills, learning and skill application but also intervention of human expert only in certain phases, we present an approach which encode the human expert demonstration into a teacher class based on Fuzzy ArtMap network. Then, the human novice trainee produces the approximate knowledge, which is in turn coded into student class. The evaluation function introduces a class metric which simultaneously allows the student to refine motor commands to increase the trainee pace while modifies accordingly the desired trajectory of the robot. Preliminary experiments indicates a high success rate in contact robotic tasks, in a deterministic setting.	approximation algorithm;encode;evaluation function;experiment;fuzzy concept;human–robot interaction;robot	Felipe Alberto Machorro-Fernández;Vicente Parra-Vega;Ismael Lopez-Juarez	2010	2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/1734454.1734498	human–robot interaction;robot;simulation;motor skill;convergence;computer science;artificial intelligence;human factors and ergonomics;machine learning;evaluation function;feedback;dreyfus model of skill acquisition;measurement;cognitive robotics	Robotics	61.616071857258554	-25.68943735421777	102787
0c32bc8650086af0485893cc9c862e1857a3e728	an intuitive human robot interface for tele-operation		This paper proposed an intuitive human robot interface for real-time tele-operation, where human operator can operate the Baxter robot to implement complicated tasks in unstructured and uncertain environment intuitively and efficiently. Firstly, In this paper a new method for building an human robot interaction interface is proposed. In addition, workspace mapping between master and slave manipulator is a key problem of human robot interaction (HRI) when there are huge difference in size and structure of human and robot's manipulators. So, the workspace mapping method between human arm and Baxter Robot manipulator and the inverse kinematics approach for solving 7-DOF redundant manipulator by using Kinect sensor were also discussed in detail. In the end, an experiment was employed to validate the performance of proposed interface.	baxter (robot);electromyography;human–robot interaction;inverse kinematics;kinect;real-time locating system;robot;solver;television;workspace	Lijun Zhao;Yihuan Liu;Ke Wang;Peidong Liang;Ruifeng Li	2016	2016 IEEE International Conference on Real-time Computing and Robotics (RCAR)	10.1109/RCAR.2016.7784072	control engineering;mobile robot;computer vision;cartesian coordinate robot;simulation;engineering;social robot;mobile manipulator;robot control;robot kinematics;robot calibration	Robotics	63.05535129160841	-26.07442749731725	102816
9c34c40ccdfc47e7b745340f3e5eeb717f45681f	multi-modal mapping and localization of unmanned aerial robots based on ultra-wideband and rgb-d sensing		This paper presents a methodology for mapping and localization of Unmanned Aerial Vehicles (UAVs) based on the integration of sensors from different modalities. Particularly, we integrate distance estimations to Ultra-Wideband (UWB) sensors and 3D point-clouds from RGB-D sensors. First, a novel approach for environment mapping is introduced, exploiting the synergies between UWB sensors and point-clouds to produce a multi-modal 3D map that integrates the estimated UWB sensors position. This map is further integrated into a Monte Carlo Localization method to robustly estimate the UAV pose. Finally, the full approach is tested with real indoor flights and validated with a motion tracking system.	aerial photography;algorithm;ground truth;mathematical optimization;modal logic;modality (human–computer interaction);monte carlo localization;monte carlo method;motion capture;point cloud;reflection mapping;robot;sensor;synergy;tracking system;ultra-wideband;unmanned aerial vehicle	Francisco Javier Perez-Grau;Fernando Caballero;Luis Merino;Antidio Viguria	2017	2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2017.8206191	computer vision;control engineering;computer science;artificial intelligence;robot;reflection mapping;rgb color model;ultra-wideband;monte carlo localization;match moving	Robotics	54.00903865919313	-36.59792361351906	102851
782251965f8936e5866bdf7acf700e5a72026569	a human robot interaction framework for robotic motor skill learning		A considerable amount of research in the field of human-robot interaction has shown that a human teacher can be an integral component during the learning process of a robot. In this paper, we propose a learning framework that is based on learning from demonstration at a trajectory level. Specifically, we illustrate a scenario where the Sawyer Robotic Arm must learn to pick and place a specific object according to the demonstration of a human teacher. The purpose of the experiment is to facilitate the effectiveness of the proposed method.	human–robot interaction;reinforcement learning;robot;robotic arm;smt placement equipment	Michail Theofanidis;Joe Cloud;Ashwin Ramesh Babu;James Brady;Fillia Makedon	2018		10.1145/3197768.3197790	simulation;artificial neural network;robot;robotic arm;computer science;trajectory;smt placement equipment;motor skill;human–robot interaction	Robotics	61.60152085920627	-25.422109569133873	102896
babb34c01c473953b393dccecc84690b13b2095d	water column current profile aided localisation combined with view-based slam for autonomous underwater vehicle navigation	autonomous underwater vehicle;underwater vehicles;path planning;water column current profile aided localisation autonomous underwater vehicle navigation doppler velocity logs mid water column navigation acoustic doppler current profiler sirius auv seafloor view based slam simultaneous localisation and mapping;global position system;mobile robots;remotely operated vehicles;doppler velocity log;sea surface;vehicles uncertainty global positioning system current measurement sea measurements acoustics;acoustic doppler current profiler;simultaneous localisation and mapping;positioning system;deep water;short period;slam robots;underwater vehicles mobile robots path planning remotely operated vehicles slam robots sonar;sonar	Survey class Autonomous Underwater Vehicles (AUVs) rely on Doppler Velocity Logs (DVL) for precise navigation near the seafloor. In cases where the seafloor depth is greater than the DVL bottom lock range, transiting from the surface where GPS is available to the seafloor presents a localisation problem since both GPS and DVL are unavailable in the mid-water column. This is traditionally addressed by using acoustic positioning systems, which take extra time to deploy or require a tracking vessel. Such systems increase the costs of operating in deep waters and reduce the flexibility of AUV operations. This paper proposes an alternative approach to navigation in the mid-water column that exploits the stability of current profiles of water columns over short periods of time. Observation of these currents are possible with the ADCP (Acoustic Doppler Current Profiler) mode of the DVL. Results with real data from missions with the Sirius AUV show how the full integration of water column descent with the ADCP, seafloor view-based SLAM (Simultaneous Localisation And Mapping), and ascent to the sea surface with ADCP gives results similar to having continuous bottom lock and shows potential to act as an alternative to acoustic localisation.	acoustic cryptanalysis;column (database);global positioning system;language localisation;simultaneous localization and mapping;sirius;state space;times ascent;velocity;voxel	Lashika Medagoda;Stefan B. Williams;Oscar Pizarro;Michael V. Jakuba	2011	2011 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2011.5980141	remotely operated underwater vehicle;mobile robot;geodesy;computer science;artificial intelligence;motion planning;marine engineering;sonar;remote sensing	Robotics	55.51259828163174	-34.87499205518452	103002
96b053dca98365cbf164c05f06921f5f168f97dd	human-oriented biped robot design: insights into the development of a truly anthropomorphic leg	humanoid robot;oscillations;human like knee;legged locomotion;biped robot;degree of freedom;mechanical design;center of mass;service robots;foot;mobile robots;legged locomotion humanoid robots;legged locomotion anthropomorphism leg humans humanoid robots service robots mobile robots knee foot robotics and automation;human like knee human oriented biped robot design anthropomorphic leg biped gait analysis humanoid robot walking motion mechanical design;human oriented biped robot design;humanoid robots;position control;range of motion;energy consumption;knee;stability analysis;lower limb;humans;biped gait analysis;anthropomorphism;point of view;anthropomorphic leg;mechanism design;walking motion;robotics and automation;legged robot;leg;light adaptation	In this paper we present a human-oriented approach to the study of the biped gait for a humanoid robot. Starting from the analysis of the human lower-limbs, we figured out which features of the human legs are fundamental for a correct walking motion and can be adopted in the mechanical design of a humanoid robot. In particular we focus here on the knee, designed as a compliant human-like knee instead of a classical pin-joint. For the foot we tried to reproduce in a simple mechanical device the mobility and lightness of the human foot, which is very different from a flat surface and has a big impact on walking. We complete the presentation with considerations about the energy consumption of our humanoid design. In our approach the robot gains in adaptability and energetic efficiency, which are the most challenging issues for a biped robot.	humanoid robot	Giuseppina C. Gini;Umberto Scarfogliero;Michele Folgheraiter	2007	Proceedings 2007 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2007.363913	control engineering;computer vision;simulation;computer science;humanoid robot;artificial intelligence	Robotics	66.97358688386855	-25.29614777453247	103056
cbfbc16dba707f3ad8b6e189b40cb6181145bd77	reinforcement learning of phase oscillators for fast adaptation to moving targets		Online movement generation in tasks involving real humanoid robots interacting with fast-moving targets is extremely difficult. This paper approaches this problem via imitation and reinforcement learning using phase variables. Imitation learning is used to acquire primitive trajectories of the demonstrator interacting with the target. The temporal progress of the robot is represented as a function of the target’s phase. Using a phase oscillator formulation, reinforcement learning optimizes a temporal policy such that the robot can quickly react to large/unexpected changes in the target movement. The phase representation decouples the temporal and spatial problems allowing the use of fast online solutions. The methodology is applicable in both cyclic and single-stroke movements. We applied the proposed method on a real bi-manual humanoid upper body with 14 degrees-of-freedom where the robot had to repeatedly push a ball hanging in front of it. In simulation, we show a human-robot interaction scenario where the robot changed its role from giver to receiver as a function of the interaction reward.	humanoid robot;human–robot interaction;reinforcement learning;simulation	Guilherme Maeda;Okan Koc;Jun Morimoto	2018				Robotics	62.1849836335771	-24.427903320220135	103150
694ddcdf669f274ebb31f08b501203bc861bed27	tracking visitors with sensor poles for robot's museum guide tour	human tracking laser range sensor museum guide robot;slam robots human robot interaction laser ranging mobile robots museums path planning sensors service robots;sensors;path planning;robot sensing systems laser modes vectors shape legged locomotion;service robots;mobile robots;human robot interaction;laser ranging;museums;sensor poles cameras bearing sensors laser range finders robot position localization slam positional information robot system guided tours visitor tracking robot museum guide tour;slam robots	In this paper, we propose a robot system which can take visitors on guided tours in a museum. When we consider developing a robot capable of giving a tour of an actual museum, we must implement a robot system able to measure the location and orientation of the robot and visitors using bearing sensors installed in a specific environment. Although many previous methods employed markers or tags attached to the robot to obtain positional information through cameras, it is not easy to situate sensors in the environment itself. SLAM is also used to localize the position of the robot. However, its robustness may not be sufficient when the system is deployed in an actual real-life situation since there will be many people moving freely around the robot. On the other hand, the robot needs information pertaining to both tour attendees and other visitors in the vicinity, in order to give a tour for the attendees. Therefore, we propose a new robot system which consists of simple devices such as multiple laser range finders attached to a pole. By just placing the sensor poles, we could track the location and orientation of the robot and visitors at the same time. We then conducted experiments to confirm the effectiveness and accuracy of our system. In addition, we conducted demonstrative experiments that our robot takes three visitors to the guide tour.	experiment;real life;robot;sensor;simultaneous localization and mapping;situated cognition	Takaya Ohyama;Eri Yoshida;Yoshinori Kobayashi;Yoshinori Kuno	2013	2013 6th International Conference on Human System Interactions (HSI)	10.1109/HSI.2013.6577893	mobile robot;robot learning;computer vision;simulation;engineering;social robot;arm solution;robot control;communication;mobile robot navigation;personal robot	Robotics	54.45637672753983	-34.149090517589315	103417
040aa204f70b8700dc66c82ff50fcd6015f45ac4	dynamic trajectory replanning for unmanned aircrafts supporting tactical missions in urban environments	urban environment;trajectory planning;unmanned aerial vehicle;course of action;dynamic model;satisfiability;qa75 electronic computers computer science	In the last decade we witnessed an increased demand for employment of unmanned aerial vehicles (UAV) in practise. For instance, there is a growing need to provide surveillance tasks in a given area by a team of cooperating UAVs. In this case, the ability of a single UAV to plan its course of actions (e.g., trajectories that the UAV must fly through) is essential. Trajectory planning algorithm used by UAVs must be able to find trajectories satisfying constraints given by environment (e.g., obstacles) or by UAVs’ dynamic models. Besides the planner itself the UAVs must somehow react to changes of high-level tasks or environment. Such a reaction often means to replan the trajectories towards new goals. In this paper, we will discuss the replanning related issues such as swapping the old and new trajectory smoothly respecting the UAV dynamics. We present an idea based on estimating running time of replanning tasks and evaluated its impact to safeness of replanning (e.g., avoiding to get to an inconsistent state).	a* search algorithm;agent architecture;algorithm;augmented lagrangian method;automated planning and scheduling;autonomous robot;high- and low-level;multi-agent system;paging;planner;smoothing;television antenna;time complexity;unmanned aerial vehicle	Lukás Chrpa;Peter Novák	2011		10.1007/978-3-642-23181-0_25	computer vision;simulation;engineering;operations management	AI	54.228105580721255	-26.30410821353898	103501
848538b9a87b8b2ea8afa577f973fe1577086909	hybrid vision based reach-to-grasp task planning method for trans-humeral prostheses		This paper proposes a hybrid vision-based reach-to-grasp task planning method for trans-humeral prostheses exploiting both vision and electromyography (EMG) signals. The hybrid method mainly consists of 2-1/2D visual servoing module and EMG-based module. The visual servoing intends to align the object on to the center of the palm while correcting its orientation. EMG signals extracted from the remaining muscles of the disabled arm due to amputation are used to control the elbow flexion/extension (FE). While using the 2-1/2D visual servoing module, the object reaching algorithm changes the elbow FE angle to reach the palm toward the object of interest. Initially, the EMG-based module controls the elbow FE. Once an object is detected, the EMG signals emanating from the arm muscles generate a reach request. This process then activates the visual servoing module to bring the palm toward the object. Since both EMG-based module and the visual servoing module are producing elbow FE angles while reaching toward an object, these two modules are integrated to obtain a resultant angle for elbow FE. Experiments are conducted using a simulation environment and a prosthesis to validate the proposed task planning method. The EMG-based module is capable of following the natural elbow FE motion. Moreover, the task planning method is capable of driving the prosthesis toward the object with proper orientation.	algorithm;align (company);electromyography;resultant;simulation;source-to-source compiler;visual servoing	D. G. Kanishka Madusanka;Ranathunga Arachchilage Ruwan Chandra Gopura;Y. W. R. Amarasinghe;George K. I. Mann	2017	IEEE Access	10.1109/ACCESS.2017.2727502	elbow;prosthesis;computer science;visual servoing;electromyography;grasp;computer vision;artificial intelligence	Robotics	63.50104295847511	-30.624170239932223	103774
7990a08f825e67c7c0f98a6546fb6ffa867e468a	non-vector space approach for nanoscale motion control	motion control;computacion informatica;mutation analysis;grupo de excelencia;scanning probe microscopes;ciencias basicas y experimentales;nanomanipulations;visual servoing;article;image based control	As the advancement of nanotechnology, it is possible to manipulate structures at nanoscale with various nanomanipulation tools such as scanning probe microscopes. To achieve successful manipulations, precise motion control is required, especially for objects with sizes from subnanometer to several nanometers. To address this issue, this paper presents an image based non-vector space control approach. Considering images obtained from the microscopes as sets, the dynamics of the system can be formulated in the space of sets. Since the linear structure of the vector space is not available in this space, this method is called the non-vector space control. With the dynamics in the non-vector space, we formulate the stabilization problem and design the controller. The stabilization controller is tested with images obtained by atomic force microscopes, and the results verify the proposed theory. The method presented in this paper does not rely on external sensors for position feedback. Moreover, unlike the traditional image based control method, we do not need to extract features from images and track them during the control process. Finally, the control precision can be as good as the imaging resolution. The approach presented in this paper can also be extended to other systems where the states can be represented as sets.		Jianguo Zhao;Bo Song;Ning Xi;Liang Sun;Hongzhi Chen;Yunyi Jia	2014	Automatica	10.1016/j.automatica.2014.04.018	control engineering;motion control;computer vision;engineering;control theory;mathematics;mutation testing;visual servoing	Robotics	61.96026044813685	-32.30616903590407	103808
6c48a17bd3f9a7bcb3afa2ee22b3d801e6b6027f	analysis and evaluation of a low-cost robotic arm for @home competitions		This paper reviews the design design, construction and performance of an affordable robotic arm of four degrees of freedom based on an Arduino controller in a home-like environment. This paper describes the kinematic design of our 4 DOF arm and the physical restrictions that this design imposes. We have also proposed two types of end-effectors to address two types of manipulation tasks: to grasp objects and to push different light switches. The arm was on board of the MYRABot platform and both were evaluated in the RoCKIn competition. This competition involves grasping and manipulation tasks that are described in the paper as well. Comments on the results of the competition and their implication in further improvement of the robot are also described in the paper.	robotic arm	Francisco J. Rodríguez Lera;Fernando Casado;Vicente Matellán Olivera;Francisco Martín	2015		10.1007/978-3-319-27149-1_48	simulation;robot;arduino;control theory;computer science;grasp;robotic arm;kinematics;robot end effector	HCI	66.07821978088067	-28.34706538713888	103861
34c2b9c861fd84cd9b45feeb308780c963a4f7d1	control strategies and particle filter for rgb-d based human subject tracking and behavior recognition by a bio-monitoring mobile robot		Our ultimate goal is to develop autonomous mobile home healthcare robots which closely monitor and evaluate the patientsu0027 motor function, and their at-home training therapy process, providing automatically calling for medical personnel in emergency situations. In our previous study, we developed basic algorithms for tracking, measuring, and behavior recognition of human subjects by a mobile robot, thus, demonstrated the feasibility of the idea of bio-monitoring home healthcare mobile robots. In this study, in order to realize effective bio-monitoring robots, we investigated 1 color based particle filter subject tracking with proposed depth likelihood integration to control the weights of particles; 2 control schemes for acquiring stable image sources for further human motion analysis, especially, the algorithms for reducing the camera vibration due to the acceleration and deceleration of the robot; 3 human activity recognition using contour data of the tracked human subjects extracted from depth images. Results showed that, depending on depth data can be quite useful as an observation by simplifying state space in 2D rather than 3D state space, and, a fuzzy control algorithm could decrease the vibration due to the acceleration and deceleration. Finally, the human activity recognition could be achieved with a high correct rate, by using geometric parameters extracted from contour data.	mobile robot;particle filter	Nevrez Imamoglu;Myagmarbayar Nergui;Yuki Yoshida;José González;Wenwei Yu	2013		10.1007/978-3-642-40852-6_33	control engineering;computer vision;tracking system;control theory;robot control	Robotics	58.64392457795692	-35.84427496192454	103936
7e688e6a8d682421d6c288edfa62332f0783c5cd	multi agent control for space based interferometry	tl motor vehicles aeronautics astronautics;qa75 electronic computers computer science	Agent systems have been accepted and used advantageously by computer scientists since their inception, but such systems have not been used so readily within the realms of control engineering or robotics. The work contained within this thesis investigates separated spacecraft interferometry in the context of a multi-agent system, under the influence of libration point orbital dynamics. The main focus is on the development of key agent skills, including state estimation, guidance, control and decision methods to attain the desired system output; within the consideration of decision methods, a comparison between centralized and distributed decisions is made. Whilst mainly focussing on the development of these skills, additional considerations pertinent to agent system development are also discussed.  A discrete time control method, integrating Kalman filtering with sliding mode control and using potential function guidance to achieve velocity tracking with six degrees of freedom, is developed for the purposes of controlling agent motion. Whilst developed for the purposes of spacecraft agent control, the presented methods are equally valid to any other vehicular agent system such as UAVs or AUVs if considering inter-agent regulation.  Centralized and distributed decision methods are developed to enable appropriate autonomous actions to be performed by the agent system. Primarily these actions include selective attainment and regulation of a non-natural orbits relative to a central agent to form an appropriate array configuration and instances of array reconfiguration to compensate for both failed agents and to maximize the mission duration.		Nicholas Lincoln	2009			control engineering;simulation;engineering;control theory	Robotics	57.67293779259671	-26.217675950025324	103949
259febb74be02e2df019688e7af78300eeab31a7	real world hardware evolution: a mobile platform for sensor evolution	electronic circuit;autonomous system;optical measurement;interaction;capteur optique;circuito electronico;captador optico;sistema autonomo;captador medida;measurement sensor;capteur mesure;mesure optique;systeme autonome;medida optica;algorithme evolutionniste;number;algoritmo evolucionista;interaccion;evolutionary algorithm;mobile systems;nombre;optical sensor;circuit electronique;numero	Although hardware evolution is becoming a more popular topic of research, the main focus of this research tends to be with reconfiguring electronic circuits using evolutionary techniques. Taking a step back, my research looks at some of the problems of configuring autonomous, mobile systems for varying goals and environments. Concentrating on optical sensors, I am hoping to show that evolving the placement of sensors on the surface of the entity and the frequencies of light these sensors respond to will improve the entity's performance in the environment.#R##N##R##N#This paper discusses some of the issues of working outside of simulation and presents a hardware platform I consider solves many of these to enable me to carry out the research described above. Unlike other mobile solutions, this platform was designed to be cheap, work in multiple entity environments and cope with large numbers of sensors (in my research, close to 200 sensors per entity) while still being extensible. This paper also covers issues such as processing power, environment management and entity interactions.		Robert Goldsmith	2003		10.1007/3-540-36553-2_32	electronic circuit;interaction;numero sign;telecommunications;computer science;engineering;autonomous system;sensor;artificial intelligence;machine learning;evolutionary algorithm;grammatical number	Vision	58.44441678797271	-31.81574639690294	104234
797ca2efb2523b3d1f02b9e1c5dee729a8b08eeb	vehicle command system and trajectory control for autonomous mobile robots	mobile robots remotely operated vehicles control systems navigation motion detection robot sensing systems robotics and automation feedback communication system control information science;planning artificial intelligence;mobile robots;autonomous mobile robot;navigation;feedback;position control;feedback control;feedback control path planning artificial intelligence trajectory control autonomous mobile robots vehicle command system navigation;control method;position control feedback mobile robots navigation planning artificial intelligence;numerical simulation	2 Vehicle command system for senIn this paper, a vehicle command system for the wheeled autonomous mobile robot with a high capability in describing the navigation task in the real environment, is proposed. And a 2.1 feedback control method to track along the given path by the sor based navigation Autonomous mobile robot and its sensor based navigation v vehicle commands is described. The effectiveness of the proposed vehicle command system and the trajectory control method are confirmed by numerical simulations and experiments in the real environment using a self-contained autonomous mobile robot. In this section, required functions for the autonomous mobile robot navigation in the real environment is analized. Now, assume that the path for the autonomous mobile robot is given as a sequence of straight lines or circular arcs. Figure 1 shows an example of the situation of the autonomous mobile robot navigation. The path from the start point S to the goal	autonomous robot;experiment;feedback;mobile robot;numerical analysis;robotic mapping;simulation	Shigeki Iida;Shin'ichi Yuta	1991		10.1109/IROS.1991.174452	computer simulation;control engineering;mobile robot;simulation;computer science;artificial intelligence;social robot;control theory;feedback;robot control;mobile robot navigation	Robotics	59.39626409964537	-29.055644142693772	104388
1e9d3bc1bb437d0c14a351f1214dc8e413d16815	visual odometry for the autonomous city explorer	jacobian matrix;visual odometry;system calibration approach visual odometry autonomous city explorer accurate localization navigation environment optical flow computation pyramidal lucas kanade algorithm camera ego motion image jacobian matrix least squares method kinematic model robot motion systematic errors;least squares approximations;urban environment;least squares method;systematic error;lucas kanade;navigation environment;mobile robots;least square method;kinematic model;distance measurement;systematic errors;navigation;visualization;optical imaging;cities and towns navigation high speed optical techniques optical computing image motion analysis robot vision systems cameras jacobian matrices least squares methods kinematics;system calibration approach;pixel;robot motion;optical flow;experimental evaluation;jacobian matrices;image jacobian matrix;camera ego motion;high speed;robot vision systems;calibration;optical flow computation;autonomous city explorer;cameras;accurate localization;pyramidal lucas kanade algorithm;robot kinematics;image sequences;robot kinematics distance measurement image sequences jacobian matrices least squares approximations mobile robots navigation	The goal of the autonomous city explorer (ACE) is to navigate autonomously, efficiently and safely in an unpredictable and unstructured urban environment. To achieve this aim, an accurate localization is one of the preconditions. Due to the characteristics of our navigation environment, an elaborated visual odometry system is proposed to estimate the current position and orientation of the ACE platform. The existing algorithms of optical flow computation are experimentally evaluated and compared. The method based on pyramidal Lucas-Kanade algorithm with high-speed performance is selected. Based on the optical flow in 2D images, the camera ego-motion is estimated using image Jacobian matrix and least squares method. The kinematic model is set up to map the camera ego-motion to the robot motion. To eliminate systematic errors, a novel system calibration approach is proposed. Finally the odometry system is evaluated in experiments.	ace;algorithm;autonomous robot;computation;encoder;experiment;experimental system;jacobian matrix and determinant;kalman filter;linear least squares (mathematics);lucas–kanade method;motion estimation;optical flow;precondition;system requirements;vii;visual odometry	Tianguang Zhang;Xiaodong Liu;Kolja Kühnlenz;Martin Buss	2009	2009 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2009.5354675	computer vision;simulation;computer science;artificial intelligence;visual odometry;systematic error;odometry;least squares;statistics;computer graphics (images)	Robotics	54.434117613658394	-37.00601929568831	104438
9b772d0826689a6bfed77d3478678167ade86dee	dynamic grouping of cooperating vehicles using a receding horizon controller for ground target search and track missions		Teams of unmanned vehicles are capable of accomplishing a wide variety of mission objectives, such as searching for and tracking targets. In this paper, a receding horizon control is utilized with information based reward measures to accomplish these two competing mission objectives. This approach for cooperatively searching and tracking has proven to be effective in past work. However, it is not generally scalable for large numbers of vehicles due to the computational expense required when generating joint path decisions. This paper proposes a method to dynamically group vehicles with neighbors that have intersecting decision spaces, thus reducing computational cost while still maintaining reasonable performance. Each vehicle also decides its ideal event horizon based upon inferred knowledge of the operational environment, further reducing cost.	algorithm;algorithmic efficiency;analysis of algorithms;computation (action);controllers;drug vehicle;estimated;inference;rhce gene;recueil des historiens des croisades;religious missions;routing;scalability;time complexity;unmanned aerial vehicle	Cameron K. Peterson	2017	2017 IEEE Conference on Control Technology and Applications (CCTA)	10.1109/CCTA.2017.8062726	horizon;scalability;control theory;control engineering;event horizon;engineering	Robotics	55.26811468616167	-24.505651499976338	104459
aeb7d0e10ac5091f7d008f6dc4188ad156ccfe11	vanet-assisted cooperative vehicle mutual positioning: feasibility study				Ali Ufuk Peker;Tankut Acarman	2017	IEICE Transactions		embedded system;simulation;particle filter;telecommunications;computer science;vehicular communication systems;statistics	HCI	57.19964450388247	-30.398674704221	105088
536f8ce613513172b53f0051ae21a5e968fbac30	convolutional neural network based multipath detection method for static and kinematic gps high precision positioning				Yiming Quan;Lawrence Lau;Gethin Wyn Roberts;Xiaolin Meng;Chao Zhang	2018	Remote Sensing	10.3390/rs10122052		Robotics	55.77824852790466	-36.33868494667733	105257
8e26c919556f89ccd8dafa9129ac42847b086da6	using eigenposes for lossless periodic human motion imitation	robot sensing systems;humanoid robot;complex dynamics;control algorithm;learning algorithm;motion control;motion optimization;high dimensionality;three dimensions;dynamic simulator lossless periodic human motion imitation robot complex dynamics complex control algorithm human motion capture robot programming motion pattern motion optimization high dimensional eigenpose data cylindrical coordinate transformation hyperdimensional subspaces imitative learning fujitsu hoap 2 humanoid robot;legged locomotion;high dimensional eigenpose data;intelligent robots;optimal method;robot programming humanoid robots intelligent robots learning artificial intelligence mobile robots motion control robot dynamics;dynamic model;dynamic simulator;lossless periodic human motion imitation;mobile robots;prior knowledge;motion capture data;joints;complex control algorithm;cylindrical coordinate transformation;humanoid robots;dynamics;human motion capture;human motion;hyperdimensional subspaces;coordinate transformation;imitative learning;fujitsu hoap 2 humanoid robot;dynamic simulation;robot complex dynamics;humans;humans robot kinematics humanoid robots orbital robotics principal component analysis mobile robots legged locomotion dynamic programming robot programming nonlinear dynamical systems;motion pattern;learning artificial intelligence;robot dynamics;dimensional reduction;robot programming;robot kinematics	Programming a humanoid robot to perform an action that takes the robot's complex dynamics into account is a challenging problem. Traditional approaches typically require highly accurate prior knowledge of the robot's dynamics and environment in order to devise complex control algorithms for generating a stable dynamic motion. Training using human motion capture is an intuitive and flexible approach to programming a robot but directly applying motion capture data to a robot usually results in dynamically unstable motion. Optimization using high-dimensional motion capture data in the humanoid full-body joint-space is also typically intractable. In previous work, we proposed an approach that uses dimensionality reduction to achieve tractable imitation-based learning in humanoids without the need for a physics-based dynamics model. This work was based on a 3-D “eigenpose” representation. However, for some motion patterns, using only three dimensions for eigenposes is insufficient. In this paper, we propose a new method for motion optimization based on high-dimensional eigenpose data. A one-dimensional computationally efficient motion-phase optimization method is implemented along with a newly developed cylindrical coordinate transformation technique for hyperdimensional subspaces. This results in a fast learning algorithm and very accurate motion imitation. We demonstrate the new algorithm on a Fujitsu HOAP-2 humanoid robot model in a dynamic simulator and show that a dynamically stable sidestep motion can be successfully learned by imitating a human demonstrator.	algorithm;algorithmic efficiency;cobham's thesis;complex dynamics;control theory;dimensionality reduction;hoap;humanoid robot;image scaling;kinesiology;lossless compression;mathematical optimization;motion capture;real-time computing;real-time locating system;shadow volume;simulation	Rawichote Chalodhorn;Rajesh P. N. Rao	2009	2009 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2009.5354391	control engineering;computer vision;dynamic simulation;simulation;computer science;humanoid robot;artificial intelligence	Robotics	62.024915962353134	-24.941971169213247	105353
0cd0c83a836901c7ea57527c55a29bf3de048464	configuration and construction of an autonomous vehicle for a mining task	autonomous vehicle;mining;geometry;geometry mobile robots mining;mobile robots;mining vehicle configuration autonomous vehicle mining task task geometric description;remotely operated vehicles mobile robots intelligent vehicles manipulators motion analysis algorithm design and analysis kinematics computational modeling robotics and automation intelligent systems	This paper describes the synthesis of an Autonomous Vehicle, using a method that aims at the vehicle configuration from concept to implementation. The configuration is expressed as a structure of components that fulfill the specifications to perform a given task under the constraints of a certain environment. The components embody the functionality of a composition of motions that solve the task. The composition is selected through a preliminary analysis, in which a geometric description of the task and the environment is used to combine motions and find viable compositions. Each motion of the selected composition is mapped as a component or components, which are subjected the operation parameters of the motion and in addition the above specifications and constraints (configuration requirements). The components are selected using criteria of engineering and robotics through mathematical expressions that relate the configuration requirements to the component features. An example involving a mining vehicle configuration is presented to demonstrate the feasibility of this approach.	configuration management;requirement;robotics	Joaquín Gutiérrez;José Luis Gordillo;Isidro Lopez	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1308119	control engineering;mobile robot;computer vision;mining;simulation;computer science;engineering	Robotics	64.09685169304898	-26.464842277412917	105676
ad819d67249901a2ee5973ddbc5b2d81f90335dc	fuzzy logic based control for autonomous mobile robot navigation		This paper describes the design and the implementation of a trajectory tracking controller using fuzzy logic for mobile robot to navigate in indoor environments. Most of the previous works used two independent controllers for navigation and avoiding obstacles. The main contribution of the paper can be summarized in the fact that we use only one fuzzy controller for navigation and obstacle avoidance. The used mobile robot is equipped with DC motor, nine infrared range (IR) sensors to measure the distance to obstacles, and two optical encoders to provide the actual position and speeds. To evaluate the performances of the intelligent navigation algorithms, different trajectories are used and simulated using MATLAB software and SIMIAM navigation platform. Simulation results show the performances of the intelligent navigation algorithms in terms of simulation times and travelled path.	algorithm;autonomous robot;controllers;encoder;fuzzy logic;matlab;mobile robot;navigation;obstacle avoidance;performance;simulation;spectroscopy, near-infrared;speed (motion);sensor (device)	Hajer Omrane;Mohamed Slim Masmoudi;Mohamed Masmoudi	2016		10.1155/2016/9548482	dead reckoning;computer vision;simulation;mobile robot navigation	Robotics	58.45485518513283	-29.73962482832169	105896
e4438d7fff0be864b44c8cce03f929288a02f85c	bayesian navigation system with particle filtering and dead reckoning in urban canyon environments	bayes methods;bayesian methods;smart phones;smart phones bayes methods compasses global positioning system particle filtering numerical methods;estimation;roads;global positioning system;global positioning system bayesian methods compass dead reckoning roads estimation;calibration bayesian navigation system particle filtering dead reckoning urban canyon environments position estimation digital compass smartphone gps positioning data digital compass readings directional measurements positioning information iphone 4s;dead reckoning;compass;particle filtering numerical methods;compasses	A Bayesian navigation system is designed to enhance the performance of the position estimate for a pedestrian in urban canyon environments using particle filtering and digital compass on Smartphone. The particle filtering is used to correct the inaccurate GPS positioning data (position and direction) caused by the strong multipath in the urban areas. The digital compass readings are employed to correct the directional measurements of the positioning information estimated by the particle filtering, but they need to be calibrated with another particle filtering and GPS since they are subject to cumulative errors. In this demo, we demonstrate a real implementation of the proposed Bayesian navigation system on the iPhone 4S. The demo shows the enhanced performance of the new navigation scheme compared to using only GPS signals.	dead reckoning;gps signals;global positioning system;multipath propagation;particle filter;smartphone	Kwangjae Sung	2012	2012 9th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks (SECON)	10.1109/SECON.2012.6275846	dead reckoning;embedded system;computer vision;estimation;simulation;global positioning system;bayesian probability;statistics;compass	Mobile	56.44584542018262	-37.136578324982096	105902
1b6b7489c2e57818edc4f424910fc7a0c452b534	metrics for performance benchmarking of multi-robot exploration	realtime operating system multi robot exploration performance benchmarking robotic fleet performance multi robot coordination algorithm frontier based exploration strategy ros;measurement;measurement robot kinematics benchmark testing multi robot systems software algorithms buildings;multi robot systems;software algorithms;operating systems computers control engineering computing multi robot systems;benchmark testing;buildings;robot kinematics	Performance benchmarking has become an important topic within robotics. It is indeed, a critical way to compare different solutions under different conditions. In this paper, we focus on performance benchmarking of multi-robot systems which explore and map unknown terrains. We present a collection of metrics to objectively compare different algorithms that can be applied to collaborative multi-robot exploration. We also identify parameters that impact robotic fleet performances. By varying the parameters, we can identify strengths and limits of an algorithm. This work is also a first concrete step to address the general problem of objectively comparing different multi-robot coordination algorithms. We illustrate these contributions with realistic simulations of the frontier-based exploration strategy. The simulations were implemented in ROS, which enables to uncouple the control software from the drivers of the robot body. We can therefore use the same code on both simulation and real robots.	algorithm;benchmark (computing);experiment;list of version control software;map;performance;repeatability;robot operating system;simulation;software propagation	Zhi Yan;Luc Fabresse;Jannik Laval;Noury Bouraqadi	2015	2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2015.7353852	embedded system;benchmark;real-time computing;simulation;computer science;engineering;artificial intelligence;robot kinematics;measurement	Robotics	56.776146651980575	-27.109946469888513	106785
39aa18d45df508ae0c54c7650fb4e5cdd54f27d2	the intelligent interaction dealer robot	image recognition;manipulators;mimetic machine arms;image motion analysis;radiofrequency identification image recognition robot kinematics service robots trajectory manipulators;travel industry approximation theory fuzzy set theory image motion analysis image recognition manipulator kinematics robot vision;robotic action databases;service robots;intelligent interaction dealer robot;manipulator kinematics;fuzzy set theory;chip;robotic control;approximation theory;robot vision;trajectory;robot control;fuzzy approximation;trajectory generation;human resource;robotic motion trajectory generation method;service robot;rfid recognition system;poker cards;gambling industry intelligent interaction dealer robot image recognition robotic control robotic kinematics robotic motion trajectory generation method poker cards rfid recognition system robotic action databases mimetic machine arms fuzzy approximation tourism industry;robotic kinematics;radiofrequency identification;tourism industry;robot kinematics;travel industry;gambling industry	All of the image recognition, the RFID recognition, the robotic control, the robotic kinematics, the robotic motion trajectory generation methods, and a robot are integrated into the Intelligent Interaction Dealer Robot. This dealer robot can imitate professional actions of a real card dealer to deal out poker cards in the front of players, recognize points of every card by image recognition system, count bets by RFID recognition system, pay or take chips by judging players' and the dealer's points, and collect all cards when this gambling have been finished. By using these recognition systems and the robotic action databases, the dealer robot can play a professional card dealer by itself to serve players in casino. The characteristics of the dealer robot include: 1. The dealer robot with two mimetic arms is designed and manufactured by ourselves. 2. Two mimetic machine arms are specially designed as one adsorption right arm and one sweeping left arm. 3. The robotic kinematics and fuzzy approximation are used to generate the robotic motion trajectories to establish the robotic action databases. 4. The image and RFID recognition methods are used to recognize points of cards and count bets of chips. In a word, the dealer service robot is developed to serve players in a casino. By using this dealer robot, the human resource cost can be reduced and the competitiveness of the tourism and gambling industry can be enhanced.	approximation;blackjack;casino;coat of arms;computer vision;database;motion planning;national supercomputer centre in sweden;rams;radio-frequency identification;robotic arm;service robot;take-grant protection model	Rong-Jyue Wang;Jhe-Yu Lee;Jia-Ming Xu;Hsin-Yu Liu	2010	International Conference on Fuzzy Systems	10.1109/FUZZY.2010.5584490	computer vision;simulation;human resources;computer science;artificial intelligence;tourism	Robotics	66.80856342210149	-30.673277076141762	106819
80caded2b9c8628ab9e18bee0236661cafb8b08d	visual end-effector position error compensation for planetary robotics	vision guided manipulation;prototypes;simulation;robotics;imaging techniques;computer vision;sensitivity;position errors;error compensation;mars exploration;vision guided manipulation algorithm;end effectors	This paper describes a vision-guided manipulation algorithm that improves arm endeffector positioning to subpixel accuracy and meets the highly restrictive imaging and computational constraints of a planetary robotic flight system. Analytical, simulationbased, and experimental analyses of the algorithm’s effectiveness and sensitivity to camera and arm model error is presented along with results on several prototype research systems and “ground-in-the-loop” technology experiments on the Mars Exploration Rover MER vehicles. A computationally efficient and robust subpixel end-effector fiducial detector that is instrumental to the algorithm’s ability to achieve high accuracy is also described along with its validation results on MER data. © 2007 Wiley Periodicals, Inc.	algorithm;algorithmic efficiency;computation;effective method;experiment;fault tolerance;fiducial marker;graceful exit;john d. wiley;mer;mission critical;pattern matching;pixel;planetary scanner;prototype;rejection sampling;robot end effector;robotic spacecraft;robotics;robustness (computer science);rover (the prisoner);simulation;verification and validation;visual servoing	Max Bajracharya;Matthew DiCicco;Paul Backes;Kevin Nickels	2007	J. Field Robotics	10.1002/rob.20186	computer vision;robot end effector;simulation;sensitivity;computer science;engineering;artificial intelligence;exploration of mars;prototype;robotics;computer graphics (images)	Robotics	59.11435698187945	-34.51925391141003	106823
bae8592ba546b68e0f921d363937bd28d2cafb99	precise industrial robot positioning and path-tracking over large surfaces using non-calibrated vision	robot vision cameras cartography image sensors industrial robots mobile robots path planning;design automation;cameras robot kinematics service robots robot vision systems surface emitting lasers design automation;path planning;service robots;mobile robots;image sensors;robot vision;camera space manipulation;robot control;industrial robots;service robot;cartography;virtual projection precise industrial robot positioning path tracking noncalibrated vision calibration free robot control method camera space manipulation cad file sensorless pan tilt units geodesic mapping;developable surface;surface emitting lasers;robot vision systems;path tracking camera space manipulation industrial robot;cameras;path tracking;robot kinematics;industrial robot;surface emitting laser	This paper presents a methodology for precise robot positioning and path tracking, performed by industrial robots over large surfaces of arbitrary size, shape and orientation. The methodology is based on a vision-based, calibration-free robot control method known as camera-space manipulation. The path, defined and stored in a CAD file, is later adapted to the curved, work-surface by using a mapping procedure. When applied to large surfaces, the precision of the positioning and path-tracking maneuvers depends on several factors like the resolution of the cameras per unit physical space and the mapping procedure, which may introduce distortion specially in the case of non-developable surfaces. In order to reduce the influence of camera-resolution, this paper presents two alternatives: the use of multiple cameras and the application of cameras mounted over non-expensive, sensorless pan/tilt units. In the case of the distortion produced by the mapping procedure, the paper discusses several options like a modified geodesic mapping and virtual projection. The proposed techniques were tested multiple times over flat and deformed surfaces, by using a large work-envelope, industrial robot.	computer-aided design;distortion;experiment;image sensor;industrial robot;robot control;robotics;rotary woofer	Emilio J. González-Galván;Cesar A. Chavez;Isela Bonilla;Marco Mendoza;Luis A. Raygoza;Ambrocio Loredo-Flores;Biao Zhang	2011	2011 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2011.5980316	control engineering;mobile robot;computer vision;simulation;developable surface;electronic design automation;computer science;engineering;artificial intelligence;image sensor;motion planning;robot control;robot kinematics	Robotics	59.548414674730125	-33.50919372952262	106965
9c54c7e4a571e3747b59684d6ed2846cf698bd6d	a characteristic parameter matching algorithm for gravity-aided navigation of underwater vehicles		The gravity matching algorithm is a key of the gravity-aided inertial navigation system (INS). The traditional matching algorithm connects only the measured gravity anomaly data to the position of the carrier according to a certain method to correct the inertial error. The gravitational field characteristic parameters should also be considered in the matching algorithm to improve the matching accuracy and reduce the number of mismatching. Therefore, based on the vector matching algorithm, a characteristic parameter matching algorithm is proposed. This paper presents new methods to calculate the characteristic parameters and the range of particle filters to increase the accuracy of matching. The gravity anomaly value of each particle is calculated more accurately by the proposed method of continuous gravity anomaly. Due to the high short-time accuracy of inertial navigation, the final trajectory is obtained by rigid transformation of a series of positions indicated by the INS corresponding to the trajectory. Simulation results prove that when compared with the vector matching algorithm, the proposed method makes the matching results more accurate and more reliable.	algorithm;anomaly detection;inertial navigation system;particle filter;simulation	Bo Wang;Jingwei Zhu;Mengyin Fu	2019	IEEE Transactions on Industrial Electronics	10.1109/TIE.2018.2831171	control theory;gravity anomaly;engineering;inertial frame of reference;inertial navigation system;approximation algorithm;particle filter;trajectory;gravitational field;blossom algorithm	Robotics	55.50953336912418	-35.76455345427971	106971
f3be31e802b1104adcd59f81b7d82ad5eaf322b4	the principle of turtle motion and bio-mechanism of its four limbs research	analytical models;torque;azimuth;oscillations;motion control;turtle motion bionic sample turtle motion biomechanism marine turtle swimming video processing methods dof motion model hydrodynamics characteristics;activation function;marine turtle swimming;dof motion model;real time;biological system modeling;biomechanics;video processing;mobile robots;hydrodynamics characteristics;marine turtles;robot dynamics biomechanics marine systems mobile robots motion control;coordinated control;propulsion motion analysis aerodynamics condition monitoring hydrodynamics vehicle dynamics motion control design optimization marine animals insects;propulsion;couplings;robot dynamics;turtle motion bionic sample;hydrodynamics;biomechanism;video processing methods;turtle motion;marine systems	As good pose agility and control ability of the marine turtle swimming, its motion principle and bionic of four-limbs are investigated. After building a real-time video monitor experiment platform for turtle motion, by the video processing methods and analyzing turtle characters, the movement parameters of turtle are extracted, the coordination control theory of multi-drive is put forward and the underwater motion principle of turtle is obtained. Secondly, establish the two DOF motion model of turtlepsilas four-limbs, analyze their hydrodynamics characteristics, and confirm that the model physical parameters and movement parameters as the influential factors for the bio-mechanism motion. Finally, in point of function bionics, the hydrofoil bio-mechanism and the palmiped bio-mechanism are designed. By use of the calibration experiments of oscillating interpolated activation function and the optimization experiments of hydrofoil-rootspsila key points, the feasibility and reliability of bio-mechanism are validated, at the same time, the foundation to optimize the bionic design and the reference to the control decision-making of turtle motion bionic sample are provided.	activation function;british informatics olympiad;computer monitor;control theory;display device;experiment;interpolation;mathematical optimization;real-time clock;turtle graphics;video processing	Mingjun Zhang;Xiaobai Liu;Dinghui Chu;Shaobo Guo	2008	2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application	10.1109/PACIIA.2008.312	motion control;mobile robot;simulation;propulsion;computer science;biomechanics;machine learning;video processing;azimuth;torque;coupling;activation function;oscillation	Vision	67.08332747130214	-24.02322901982516	106983
c17976c9f70f314244c830a735d10c62029e54cd	primitive static states for intelligent operated-work machines	state identification;manipulators;grasping;intelligent robots;environmental conditions;construction industry;virtual reality;cognitive support;virtual reality simulator;intelligent operated work machine;work environment;complicated operating system;joints;data mining;construction equipment;force;operating system;machine intelligence machinery intelligent robots intelligent systems safety intelligent control robotics and automation operating systems virtual reality robustness;lever input;construction work environment;intelligent system;quantitative work analysis;environmental condition;pss based skill analysis;machinery;manipulators construction construction equipment intelligent robots machinery;manipulator;construction;primitive static state;environmental condition primitive static state intelligent operated work machine complicated operating system quantitative work analysis cognitive support construction work environment manipulator virtual reality simulator pss based skill analysis state identification lever input	Advanced operated-work machines, which have been designed for complicated tasks and which have complicated operating systems, requires intelligent systems that can provide the quantitative work analysis needed to determine effective work procedures and that can provide operational and cognitive support for operators. Construction work environments are extremely complicated, however, and this makes state identification, which is a key technology for an intelligent system, difficult. We therefore defined primitive static states (PSS) that are determined using on-off information for the lever inputs and manipulator loads for each part of the grapple and front and that are completely independent of the various environmental conditions and variation in operator skill level that can cause an incorrect work state identification. To confirm the usefulness of PSS, we performed experiments with a demolition task by using our virtual reality simulator. We confirmed that PSS could robustly and accurately identify the work states and that untrained skills could be easily inferred from the results of PSS-based work analysis. We also confirmed in skill-training experiments that advice information based on PSS-based skill analysis greatly improved operator's work performance. We thus confirmed that PSS can adequately identify work states and are useful for work analysis and skill improvement.	artificial intelligence;experiment;grapple;operating system;physical symbol system;simulation;switch;virtual reality simulator	Mitsuhiro Kamezaki;Hiroyasu Iwata;Shigeki Sugano	2009	2009 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2009.5152848	control engineering;simulation;construction;computer science;engineering;artificial intelligence;control theory;virtual reality	Robotics	68.11490354539966	-30.381622028267934	107102
798c6c7e3dd53c6c4327be88993ce96ff3a9c3d9	dynamically reconfigurable robotic system	self repairing;intelligent robots robotics and automation manipulators orbital robotics shape mobile robots intelligent structures fault tolerance hardware cells biology;concept;cell structured manipulator;manipulators;adaptability;cell structured manipulator concept dynamically reconfigurable robotic system cell structure flexibility adaptability intelligent cells self repairing fault tolerant;fault tolerant;dynamic reconfiguration;computerised control;intelligent robots;mobile robot;intelligent cells;mobile robots;robots computerised control;orbital robotics;cell structure;shape;fault tolerance;robots;next generation;dynamically reconfigurable robotic system;intelligent structures;robotics and automation;flexibility;cells biology;hardware	"""The recent robots in an experimental or practical stage in many fields are designed for unmetamorphosis total shapes, so that they can not adapt to the change of working environments and demands so much. The newly proposed robotic system """"Dynamically Reconfigurable Robotic System (DRRS)"""" in this paper, however, can be self-reorganize its total shape and its software to a given task, so that the level of the flexibility and adaptability to a change of task is much higher than that of the conventionals. This robotic system consists of a lot of intelligent cells which have a fundamental mechanical function. Each cell can detach itself and combine them autonomously depending on a task, such as manipulators or mobile robots, so that the system can also self-repairing. DRRS has many unique advantages, such as optimal shaping under circumstances, fault tolerance, self repairing and others. Some demonstrations can be shown experimentally and a decision method for such cell structured manipulator configurations is also proposed."""	autonomous robot;experiment;fault tolerance;mobile robot;noise shaping;reconfigurability;reconfigurable computing	Toshio Fukuda;Seiya Nakagawa	1988		10.1109/ROBOT.1988.12291	control engineering;mobile robot;embedded system;fault tolerance;simulation;computer science;engineering;artificial intelligence	Robotics	64.7882936048509	-26.93744629299925	107265
a97e99d958e48fdc427dd981753cb1accab57b91	a nonlinear observer approach for concurrent estimation of pose, imu bias and camera-to-imu rotation	lyapunov methods;observability;observers cameras observability visualization accelerometers acceleration;observer design;lyapunov function;lyapunov function inertial estimation inertial vision nonlinear observers;observability conditions nonlinear observer approach concurrent pose estimation imu bias camera to imu rotation inertial visual sensor calibration errors high quality estimates visual inertial data fusion observer stability lyapunov functions;observers;acceleration;stability;inertial estimation;visualization;nonlinear observers;stability lyapunov methods observability observers pose estimation sensor fusion;nonlinear observer;sensor fusion;accelerometers;cameras;inertial vision;pose estimation	This paper concerns the problem of pose estimation for an inertial-visual sensor. It is well known that IMU bias, and calibration errors between camera and IMU frames can impair the achievement of high-quality estimates through the fusion of visual and inertial data. The main contribution of this work is the design of new observers to estimate pose, IMU bias and camera-to-IMU rotation. The observers design relies on an extension of the so-called passive complementary filter on SO(3). Stability of the observers is established using Lyapunov functions under adequate observability conditions. Experimental results are presented to assess this approach.	lyapunov fractal;nonlinear system	Glauco Garcia Scandaroli;Pascal Morin;Geraldo F. Silveira	2011	2011 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6094702	acceleration;control engineering;computer vision;observability;pose;visualization;stability;lyapunov function;computer science;control theory;mathematics;sensor fusion;accelerometer	Robotics	56.58468446421396	-37.59293535400625	107364
830d77e890c120d9f270b2dcbb5c60ada6a59902	real-time visual tracking for surveillance and path planning	real time visualization;path planning;robot arm;object manipulation	In this paper we report progress towards a flexible, visually driven, object manipulation system. The aim is that a robot arm with a camera and gripper mounted on its tip should be able to transport objects across an obstacle-strewn environment. Our system is based on the analysis of moving image contours, which can provide direct estimates of the shape of curved surfaces. Recently we have elaborated on this basis in two respects. First we have developed real-time visual tracking methods using dynamic contours with Lagrangian Dynamics allowing direct generation of approximations to geodesic paths around obstacles. Secondly we have built a 2 1/2D system for incremental, active exploration of free-space.	automated planning and scheduling;motion planning;real-time transcription	Rupert W. Curwen;Andrew Blake;Andrew Zisserman	1992		10.1007/3-540-55426-2_102	computer vision;simulation;robotic arm;computer science;motion planning;computer graphics (images)	Robotics	58.886325060582955	-32.374182551081084	107608
895aec97ce0a11d1efd91304fa93c10fa0acc82a	remote biological and robotic sensor networks for environmental monitoring		Abstract   Environment monitoring of large areas requires for many in-situ pollutant measurements. An efficient approach which integrates biological and robotic systems is presented in this contribution. In this approach bees provide an early detection capacity which is complemented by mobile robots to verify pollution indications by obtaining more detailed in-situ measurements. This contribution reports on the system architecture and the challenging technical components related to detecting the sampling location of the bees by observing their dancing behavior, the autonomous transfer of the rovers to these target positions for detailed measurements, the integration of the obtained data from the different sources into an overall characterization of the area's pollution status and an autonomous flexible alerting system.		Robin Heß;Florian Kempf;Jürgen Tautz;Klaus Schilling	2013		10.3182/20131111-3-KR-2043.00014	control engineering;simulation;engineering;remote sensing	Robotics	55.727566784233744	-30.647514615702793	107710
93092448e4d3fffd7c0d1c11b0d4bfc059f1cab0	extrinsic calibration of a set of range cameras in 5 seconds without pattern	slam robots calibration distance measurement image sensors mobile robots remotely operated vehicles robot vision;cameras calibration vectors maximum likelihood estimation robot vision systems simultaneous localization and mapping;range camera calibration design parameters omnidirectional rgb d sensor geometric configurations arbitrary configuration slam visual odometry field of view autonomous vehicles mobile robotics	The integration of several range cameras in a mobile platform is useful for applications in mobile robotics and autonomous vehicles that require a large field of view. This situation is increasingly interesting with the advent of low cost range cameras like those developed by Primesense. Calibrating such combination of sensors for any geometric configuration is a problem that has been recently solved through visual odometry (VO) and SLAM. However, this kind of solution is laborious to apply, requiring robust SLAM or VO in controlled environments. In this paper we propose a new uncomplicated technique for extrinsic calibration of range cameras that relies on finding and matching planes. The method that we present serves to calibrate two or more range cameras in an arbitrary configuration, requiring only to observe one plane from different viewpoints. The conditions to solve the problem are studied, and several practical examples are presented covering different geometric configurations, including an omnidirectional RGB-D sensor composed of 8 range cameras. The quality of this calibration is evaluated with several experiments that demonstrate an improvement of accuracy over design parameters, while providing a versatile solution that is extremely fast and easy to apply.	autonomous robot;camera resectioning;experiment;kernel density estimation;mobile operating system;mobile robot;range imaging;robotics;sensor;simultaneous localization and mapping;visual odometry	Eduardo Fernández-Moral;Javier González;Patrick Rives;Vicente Arévalo	2014	2014 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2014.6942595	control engineering;computer vision;simulation;engineering	Robotics	54.7902564369664	-37.67975911425505	107792
641daf4904340f962ed674b33a6dd2a61aabaf4d	collision-free navigation of multiple unicycle mobile robots		Wheeled Robots (WRs) are widely used in many different contexts, and usually they are required to operate in partial or total autonomy. In particular, in a wide range of situations, having the capability of following a predetermined path and avoiding unexpected obstacles can be extremely relevant. On these basis, this paper analyzes an integrated approach for path following and obstacle avoidance applied to unicycletype robots. The approach is based on the definition of the path to be followed as a curve f(x, y) in space, while obstacles are modeled as Gaussian functions that modify the original function, generating a resulting safe path. The attractiveness of this methodology which makes it look very simple, is that it neither requires the computation of a projection of the robot position on the path, nor does it need to consider a moving virtual target to be tracked. The performances of the proposed approach are analyzed by means of a series of experiments performed in dynamic environments with unicycle-type robots.	algorithm;autonomy;computation;experiment;mobile robot;obstacle avoidance;performance;velocity (software development)	M. Hassan Tanveer;Antonio Sgorbissa;Carmine Tommaso Recchiuto	2017	2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)	10.1109/ROMAN.2017.8172482	computer vision;collision;artificial intelligence;mobile robot;real-time computing;robot;computer science;computation;robot kinematics;obstacle avoidance;trajectory	Robotics	57.05542726957064	-26.026462434776086	107934
046bc2044912a5be8a336bb6d9d9a4c5c3fb928a	accurate ranging of multiple objects using ultrasonic sensors	processing element;robot sensing systems;triangulation measurements;sensor system;sensor phenomena and characterization;optical reflection;real time;ultrasonic variables measurement;acoustic signal processing;ultrasonic transducers;acoustic sensors ultrasonic variables measurement optical reflection acoustic transducers ultrasonic transducers acoustic reflection sensor phenomena and characterization robot sensing systems acoustic measurements laboratories;distance measurement;multiple objectives;ultrasonic sensors;signal processing;acoustic reflection;multiple objects ranging;cost effectiveness;scalability;acoustic sensors;scalability sonar multiple objects ranging ultrasonic sensors triangulation measurements signal processing transputers;microcomputer applications;transputers;acoustic measurements;sonar acoustic signal processing distance measurement microcomputer applications parallel processing;parallel processing;acoustic transducers;ultrasonic sensor;sonar	The authors propose a measurement setup consisting of a number of ultrasonic sensors used in parallel to perform triangulation measurements. The sensor system is based on two ideas. The first idea was to use signal processing techniques borrowed from existing radar and sonar systems. This allows the accurate determination of the position of multiple objects. Processing data in real time demands a fairly powerful processing system. The second idea was to assign a microprocessor to each transducer. To support the use of multiple sensors in the final measurement setup, transputers were used as processing elements as they offer easy scalability because of their serial links. This sensor measured the distance to multiple objects very accurately and with a resolution of 2 cm. It is shown that these techniques could be implemented in a cost-effective manner. >	sensor	Koenraad Audenaert;Herbert Peremans;Y. Kawahara;Jan M. Van Campenhout	1992		10.1109/ROBOT.1992.220128	embedded system;parallel processing;electronic engineering;acoustics;computer science;engineering;signal processing;ultrasonic sensor	Robotics	55.44023875538381	-32.953913122895855	107938
810e2a81a9de4857c93722ca99e6ee1e579cc9e7	robust and computationally efficient navigation in domestic environments	motion control;path planning;human robot interaction;system performance;dynamic environment;object manipulation;service robot	Presented in this paper is a complete system for robust autonomous navigation in cluttered and dynamic environments. It consists of computationally efficient approaches to the problems of simultaneous localization and mapping, path planning, and motion control, all based on a memory-efficient environment representation. These components have been implemented and integrated with additional components for human-robot interaction and object manipulation on a mobile manipulation platform for service robot applications. The resulting system performed very successfully in the 2008 RoboCup@Home competition.	algorithmic efficiency;autonomous robot;human–robot interaction;mobile manipulator;motion planning;robustness (computer science);service robot;simultaneous localization and mapping	Dirk Holz;Gerhard K. Kraetzschmar;Erich Rome	2009		10.1007/978-3-642-11876-0_10	human–robot interaction;motion control;computer vision;simulation;computer science;artificial intelligence;motion planning;computer performance;mobile robot navigation	Robotics	59.06914946985771	-30.91929431269518	107997
a33c1f2fbcc527b77b757b7edbe3d0dcb122231a	robotic path learning with graphical user interface	machining;robot programming control engineering computing force control graphical user interfaces human robot interaction industrial robots machining path planning position control production engineering computing program verification;path planning;human robot interaction;program verification;production engineering computing;graphical user interfaces;george zhang jianjun wang jingguo ge 机器人路径规划 工业机器人 图形用户界面 学习功能 机器人控制器 位置数据 自动生成 生成方法 robotic path learning with graphical user interface;position control;robots servomotors lead indexes finishing;industrial robots;control engineering computing;robot operator interaction robotic path learning graphical user interface automated robot path generation method industrial robotics dummy tool rough points force controlled hybrid mode position controlled hybrid mode contact force direction robot actual position robot controller automatic robot path program generation robot lead through robot position teaching control point creation control point teaching program verification program execution force control machining product option gui;user interface robot force control easy to program;robot programming;force control	This paper describes an automated path generation method for industrial robotics. Based on force control, a method and system was developed for robot path automatic generation or path learning. Using a dummy tool and rough points around the part contour, robot moves in position and force controlled hybrid mode, following the order of the taught points and contact force direction and value predefined. During the motion, robot actual position is read and stored into in the robot controller. After the motion, recorded data is used to generate a robot path program automatically. Robot lead-through can be used in the robot position teaching. Furthermore, a Graphical User Interface is developed on the teach pedant to guide through the control point creation and teaching, path learning, program verification and execution. The development has been incorporated into a force control machining product option. Combination of the robot path learning and GUI enhances interaction between the robot and operator and drastically increases the level of the ease-of-use.	control point (mathematics);dummy variable (statistics);formal verification;graphical user interface;industrial robot;robotics	George Zhang;Jianjun Wang;JingGuo Ge	2013	IEEE ISR 2013	10.1109/ISR.2013.6695709	human–robot interaction;robot learning;bang-bang robot;cartesian coordinate robot;simulation;machining;computer science;artificial intelligence;social robot;arm solution;graphical user interface;motion planning;mobile robot navigation	Robotics	68.21989216712916	-32.17216230747505	108060
0c602ece97c89afb647a4bec22c9b0d12dc13422	wavelet methods for characterising mono- and poly-fractal noise structures in shortish time series: an application to functional mri	fractals;local stationarity;brain;functional mri;medical image processing 1 f noise wavelet transforms fractals time series biomedical mri image colour analysis brain;time series;1 f noise;wavelet transforms;colored noise magnetic resonance imaging magnetic noise fractals wavelet transforms autocorrelation testing 1f noise gaussian noise image processing;image colour analysis;medical image processing;functional magnetic resonance images;uniformly most powerful;long range dependent;poly fractal noise structures functional magnetic resonance imaging fmri time series endogenous auto correlation long range dependence wavelet based methodology short medium length hurst exponent noise variance local stationarity uniformly most powerful test time constancy bootstrap approach 1 f noise color brain voxels mono fractal noise structures;power law;hurst exponent;biomedical mri	HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Wavelet methods for characterising monoand poly-fractal noise structures in shortish time series: An application to functional MRI Jalal M. Fadili, Edward T. Bullmore, Matthew Brett		Mohamed-Jalal Fadili;Edward T. Bullmore;M. Brett	2001		10.1109/ICIP.2001.958465	econometrics;power law;speech recognition;fractal;detrended fluctuation analysis;time series;mathematics;hurst exponent;statistics;wavelet transform	ML	67.61663487636298	-35.437081925411064	108130
e188b02f57b766b0d3415c9f74ec6336cd99b5ff	pspht a water strider-like robot for water inspection: framework and control architecture	legged locomotion;water quality biomimetics inspection lakes microrobots mobile robots ph;biology;real time ph measurement water strider robot framework locomotion striding control;force;computer architecture;bioinspired microrobot pspht water strider like robot water inspection control architecture portable striding ph tester water quality measurement light steel beam polypropylene based material archimedes principle remote controlled ph data logger radio frequency rf communication striding topology test real time data potential hydrogen reading test lake;tk electrical engineering electronics nuclear engineering;legged locomotion robot kinematics force real time systems biology computer architecture;robot kinematics;real time systems	This paper presents the framework and control of a proposed water strider-liked robot, named as Portable Striding pH Tester (PSpHT) that is able to measure the water quality. PSpHT is designed with its leg and tip configurations made respectively from the light-steel beam and polypropylene-based material. The design of the leg is calculated and fabricated using Archimedes' principle. In addition, real-time software for use in a remote controlled pH data logger that strides the robot, called PSpHT-VI, is developed using radio frequency (RF) communication. The PSpHT is verified and validated by running two specific tests, which are striding topology test and real-time data Potential Hydrogen (pH) reading test. The tests were conducted in a lake within the campus of the Universiti Malaysia Pahang, Pekan.	acorn archimedes;data acquisition;data logger;hydrogen;malaysian identity card;ph (complexity);radio frequency;real-time data;real-time transcription;remote control;robot;server (computing);water cooling;waypoint	Addie Irawan;Beh Khi Khim;TanYee Yin	2014	2014 11th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2014.7057377	embedded system;simulation;computer science;artificial intelligence;force;robot kinematics	Robotics	63.668464641593765	-29.46585368500228	108136
4f34af5152315cfce0d0a73ff4a7c2a44a0826f9	reconfigurable swarm robots for structural health monitoring: a brief review	reconfigurable swarm robots;structural health monitoring;autonomous inspection	Autonomous monitoring of infrastructure systems offers a promising alternative to manual inspection techniques which are mostly tedious, expensive and prone to error. Robot-based autonomous monitoring systems not only provide higher precision, but they also allow frequent inspection of infrastructure systems at a much lower cost. Recent advancements in robotic systems have led to the development of reconfigurable swarm robots (RSR) that can change their shape and functionality dynamically, without any external intervention. RSR have the advantages of being modular, on-site reconfigurable, multifunctional, incrementally assemble-able, reusable, fault-tolerant, and even repairable on the orbit. Newly-developed reconfigurable robots are expected to bring a radical change in the prevailing structural health monitoring techniques, thus augmenting the efficiency, accuracy and affordability of inspection operations. This paper presents a holistic review of the previous studies and state-of-the-art technologies in the field of RSR, and argues that RSR offer great potential advantages from the perspective of monitoring and assessment of civil and mechanical systems. A roadmap for future research has also been outlined based on the limitations of the current methods and anticipated needs of future inspection systems.	aerial photography;autonomous robot;cluster analysis;control system;fault tolerance;holism;modular design;multi-function printer;pattern formation;reconfigurable computing;self-assembly;self-reconfiguring modular robot;software deployment;swarm robotics;transmission line	Mohammad R. Jahanshahi;Wei-Min Shen;Tarutal Ghosh Mondal;Mohamed Abdelbarr;Sami F. Masri;Uvais A. Qidwai	2017	International Journal of Intelligent Robotics and Applications	10.1007/s41315-017-0024-8	robot;computer science;simulation;structural health monitoring;mechanical system;swarm robotics;modular design	Robotics	56.09650424744252	-30.867362536486016	108343
2fccfc8ecd4b6d018a41e7e2cc62f5c6efe0c6c5	subtractive composite simpson method for low cost inertial navigation systems	fourth order runge kutta method rk4;numerical integration;composite simpson s rules;inertial navigation system ins	This paper presents a new method to decrease the error of real time numerical integration in an Inertial Navigation System (INS), which is widely used in aircrafts, spacecrafts, and field robotics. The well-known Runge–Kutta method is often used for real time numerical integration in INS algorithms. Here a combination of the composite Simpson's 1/3 and 3/8 rules is developed to effectively reduce the total integration error, named Subtractive Composite Simpson Method (SCSM). Also we propose a new method that efficiently reduces the error of the integrator block using the combination of a fourth-order Runge–Kutta (RK4) and SCSM. Simulation results show one order of magnitude decrease in position error after double integration of acceleration value. Extra accuracy gain using this new method makes it possible to choose low cost inertial sensors to realize a low cost INS.	simpson's rule	Amir Moosavie Nia;R. Mirzajani;M. Esfalani	2011	Journal of Circuits, Systems, and Computers	10.1142/S0218126611007530	control engineering;gps/ins;simulation;adaptive simpson's method;numerical integration;control theory;mathematics	EDA	58.36615523066022	-36.283572373204514	108441
603d1ccd30aebdb4cfc7f48d14a50b2673706f06	cascade control of uncertain manipulator systems through immersion and invariance adaptive visual servoing	manipulators;control systems programmable control adaptive control visual servoing manipulator dynamics robot vision systems cameras visual system calibration target tracking;image motion analysis;uncertain systems;nonlinear control systems;adaptive control;cascade control;nonlinear control systems image motion analysis manipulators uncertain systems cascade control adaptive control;camera calibration;robot dynamics;visual servoing;visual system;nonlinear dynamics invariance adaptive visual servoing uncertain manipulator systems cascade control direct adaptive visual control planar manipulators camera calibration robot dynamics multivariable parameter adaptive problem	A control-theoretical solution is presented for the direct adaptive visual control of planar manipulators using a fixed camera, when both camera calibration and robot dynamics are uncertain. The proposed scheme is developed for image-based look-and-move visual systems to allow tracking of a moving target. In order to solve the multivariable parameter adaptive problem, the proposed immersion and invariance (I&I) method is used. The scheme is then combined with the adaptive controller for the manipulator, taking into account its nonlinear dynamics and leading to an overall stable adaptive visual system. Simulations and experimental results are also presented for the proposed strategy.	camera resectioning;computer simulation;immersion (virtual reality);nonlinear system;visual servoing	Alessandro R. L. Zachi;Liu Hsu;Romeo Ortega;Fernando C. Lizarralde	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1307164	control engineering;computer vision;camera resectioning;visual system;adaptive control;computer science;control theory;visual servoing	Robotics	61.00189514959849	-32.001768065471595	108451
894a7c069af6197e934e80d2b65ebf440842c82a	wheelchair support by a humanoid through integrating environment recognition, whole-body control and human-interface behind the user	whole body;robot sensing systems;humanoid robot;motion control;legged locomotion;whole body control;environment recognition;mobile robots;medical robotics;zmp;wheelchair support;human interface;wheelchairs face recognition gesture recognition humanoid robots medical robotics mobile robots motion control particle filtering numerical methods;face recognition;gesture recognition wheelchair support humanoid robot environment recognition whole body control human interface pushing motion control zmp particle filter face detection;humanoid robots;robots mobile robots wheelchairs robot sensing systems face legged locomotion robot kinematics;particle filter;robots;nursing care;face;face detection;gesture recognition;pushing motion control;wheelchairs;particle filtering numerical methods;robot kinematics	In this paper, we treat with wheelchair support by a life-sized humanoid robot. It is quite essential to integrate whole-body motion, recognition of environment and human-interface behind the user in order to achieve this task. Contributions of this paper is whole-body control including pushing motion using the offset of the ZMP and observation of the attitude outlier, recognition of the wheelchair using particle filter and human-interface behind the person using face detection and recognition of gesture.	anomaly detection;elemental;face detection;humanoid robot;particle filter;zero moment point	Shunichi Nozawa;Toshiaki Maki;Mitsuharu Kojima;Shigeru Kanzaki;Kei Okada;Masayuki Inaba	2008	2008 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2008.4650903	computer vision;simulation;computer science;humanoid robot;artificial intelligence;gesture recognition	Robotics	60.29421726094842	-30.87419889489662	108967
53086c27cbc437f380f199dbf97c3a42bb45cf1e	environment prediction for a mobile robot in a dynamic environment	robot sensing systems;sensor systems;neural nets;mobile robot;path planning;real time;mobile robots;control engineering;mobile robots navigation artificial neural networks backpropagation algorithms trajectory orbital robotics robot sensing systems motion planning sensor systems control engineering;indexing terms;backpropagation;orbital robotics;backpropagation mobile robots path planning sensor fusion computerised navigation real time systems neural nets;dynamic environment;navigation;artificial neural networks;relative error;trajectory;real time multisensor data fusion;minimum relative error environment prediction mobile robot dynamic environment navigation moving obstacles real time multisensor data fusion artificial neural network relative error backpropagation rebp algorithm;minimum relative error;relative error backpropagation;backpropagation algorithms;motion planning;moving obstacles;sensor fusion;article;environment prediction;training algorithm;rebp algorithm;artificial neural network;real time systems;computerised navigation	The problem of navigating a mobile robot among moving obstacles is usually solved on the condition of knowing the velocity of obstacles. However, it is difficult to provide such information to a robot in real time. In this paper, we present an environment predictor that provides an estimate of future environment configuration by fusing multisensor data in real time. The predictor is implemented by an artificial neural network (ANN) trained using a relative-errorbackpropagation (REBP) algorithm. The REBP algorithm enables the ANN to provide output data with a minimum relative error, which is better than conventional backpropagation (BP) algorithms in this prediction application. The mobile robot can, therefore, respond to anticipated changes in the environment. The performance is verified by prediction simulation and navigation experiments.	algorithm;approximation error;artificial neural network;backpropagation;experiment;kerrison predictor;mobile robot;simulation;velocity (software development)	Charles C. Chang;Kai-Tai Song	1997	IEEE Trans. Robotics and Automation	10.1109/70.650165	mobile robot;computer vision;computer science;artificial intelligence;machine learning;motion planning;artificial neural network	Robotics	53.8586891538284	-31.998129264925502	109150
cfecf9dc718b9b5db93bc61071c45c1aa2507266	a decentralized task allocation approach for cooperative transportation missions	aerospace engineering;sensors;simulation;resource management;coupled constraints cbba task assignment cooperative transportation;aerospace engineering area decentralized task allocation approach cooperative transportation missions coupled constraints consensus based bundle algorithm reward function arrival time calculation constraint handling unmanned systems;time factors;transportation;transportation resource management sensors aerospace engineering algorithm design and analysis time factors simulation;algorithm design and analysis;resource allocation autonomous aerial vehicles constraint handling decentralised control multi robot systems	This paper presents modified formulations of coupled-constraints consensus based bundle algorithm to resolve the cooperative transportation problem. Formulation frameworks for a cooperative transportation mission are suggested. Suggested frameworks are deal with various types of constraints and characteristics of cooperative transportation mission. In this paper, several modifications on reward function and arrival time calculation are suggested to handle the constraints of cooperative transportation mission.	algorithm;reinforcement learning;time of arrival;transportation theory (mathematics)	Keum-Seong Kim;Han-Lim Choi	2014	2014 13th International Conference on Control Automation Robotics & Vision (ICARCV)	10.1109/ICARCV.2014.7064534	control engineering;algorithm design;transport;simulation;computer science;engineering;sensor;resource management	Robotics	57.326081956685535	-24.51499312494222	109323
9080663d35fb7eb6c5d8478b916b06a0d594e4ad	exploration of unknown map for safety purposes using wheeled mobile robots		Exploring unknown 2-D grid map using multi-robots has a great significance in a vast domain of applications. One possible application is to search for a gas leakage or a fire source which we address in this paper. We propose an algorithm called Zigzag Ray for multi-robot exploration. The aim is to reduce the required time to discover the environment as much as possible to suit the critical applications such as rescue operations. Experiments are done using two, three, and four Khepera robots for exploring a map. The exploration time without the boundary scan offset is ranged from 28.4% to 17.2% of the time taken by Albers algorithm and from 41.2% to 30.7% of the time taken by the Zigzag algorithm for a single robot. Also, the time of four robots by using a Zigzag algorithm for multi-robots is about 46% of Albers time of four robots. A disparity in time existing between the algorithms shows the effectiveness of the new proposed algorithm. Additionally, the Zigzag algorithm of a single robot is compared with the heuristic SRT algorithm. Zigzag time takes about 54.5% to 77.4% from heuristic SRT time. The evaluation is done using the Exploration Index strategy.	best, worst and average case;binary prefix;binocular disparity;boundary scan;centralisation;decentralised system;division algorithm;heuristic;khepera mobile robot;map;regular grid;spectral leakage	Sara Ashry Mohammed;Walid Gomaa	2017		10.5220/0006430903590367	control engineering;engineering;simulation;mobile robot	Robotics	55.96710614082085	-27.58372958607763	109334
6004ddf54c163741aa14f1595aabe8bc93b3db30	map - a mobile agile printer robot for on-site construction		In this paper, we present a Mobile Agile Printer (MAP) construction robot; a highly agile, 4-legged, omnidirectional robot capable of 3D printing large structures. To overcome dynamic challenges when operating within an outdoors construction site, MAP incorporates a high-DoF 3D printing system connected to a mobile platform with novel features designed to enable disturbance rejection and live adaption to the robot's pose. In doing so, we demonstrate the benefits of designing construction robots with a focus on agility, a compact working volume and ability to operate within a potentially unlimited workspace. Performance tests were conducted showing smooth omni-directional motion as a key requirement for maintaining low 3D printing trajectory deviations over a large volume. In doing so, we show that MAP has the ability to construct in new ways more sensitive to its environment, context and concurrent on-site operations.		Julius Sustarevas;Daniel Butters;Mohammad Hammid;George Dwyer;Robert Stuart-Smith;Vijay M. Pawar	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8593815	workspace;control engineering;real-time computing;computer science;3d printing;robot;omnidirectional antenna;agile software development;trajectory	Robotics	56.070749335336494	-27.8091061843158	109431
13386adc20bfb77aee3d595788f2c20e359aa6e2	motion segmentation and balancing for a biped robot's imitation learning	humanoid robots;dynamics;humanoid robots robot kinematics clustering algorithms dynamics clustering methods learning artificial intelligence;clustering algorithms;learning artificial intelligence;key postures humanoid robots reinforcement learning imitation learning;clustering methods;robot kinematics	Techniques for transferring human behaviors to robots through learning by imitation/demonstration have been the subject of much study. However, direct transfer of human motion trajectories to humanoid robots does not result in dynamically stable robot movements because of the differences in human and humanoid robot kinematics and dynamics. An imitating algorithm called posture-based imitation with balance learning (Post-BL) is proposed in this paper. This Post-BL algorithm consists of three parts: a key posture identification method is used to capture key postures as knots to reconstruct the motion imitated; a clustering method classifies key postures with high similarity; and a learning method enhances the static stability of balance during imitation. In motion reproduction, the proposed system smoothly transits between key poses and the robot learns to maintain balance by slightly adjusting the leg joints. The developed balance controller uses a reinforcement learning mechanism, which is sufficient to stabilize the robot during online imitation. The experimental results for simulation and a real humanoid robot show that the Post-BL algorithm allows demonstrated motions to be imitated balance to be preserved.	algorithm;bl (logic);cluster analysis;humanoid robot;kinesiology;poor posture;reinforcement learning;simulation;smoothing	Kao-Shing Hwang;Wei-Cheng Jiang;Yu-Jen Chen;Haobin Shi	2017	IEEE Transactions on Industrial Informatics	10.1109/TII.2017.2647993	robot learning;computer vision;dynamics;simulation;computer science;engineering;humanoid robot;artificial intelligence;social robot;robot control;cluster analysis;robot kinematics	Robotics	62.81975485226227	-25.007671785810704	109600
da4e7e63c880f3de054c5e19f6c3ba89c7382a16	a cost-effective stereo camera system for online pose control of patient handling robots	accuracy cameras tumors robot sensing systems position measurement;patient diagnosis;stereo image processing cameras medical robotics patient diagnosis patient treatment position control;online measurements;measurement system;medical robots;medical robotics;deflection compensation;patient couch cost effective stereo camera system online pose control patient handling robots patient positioning diagnostic purposes therapeutic purposes patient weights serial kinematics camera based measuring system;position control;stereo image processing;stereo vision;patient treatment;cost effectiveness;deflection compensation medical robots stereo vision online measurements;cameras	Patient handling robots are employed more and more frequently to enable a flexible positioning of the patient for diagnostic and therapeutic purposes. Due to the greatly differing robot loads because of varying patient weights especially serial kinematics are no longer able to keep up with the constantly increasing medical demands for positioning accuracy. In this paper a camera-based measuring system is introduced which can measure the pose of a patient couch mounted on a patient handling robot with high accuracy. Through the use of cost-effective hardware components the stereoscopic system is suitable for a permanent integration into the workspace of the robot. This enables online pose control of the patient couch. In tests on a robot system a maximum positioning error of 0.25 mm was achieved for a diversity of medically relevant poses.	ccir system a;industrial robot;robot calibration;stereo camera;stereoscopy;tracing (software);workspace	Christian Ziegler;Jörg Franke	2011	The 5th International Conference on Automation, Robotics and Applications	10.1109/ICARA.2011.6144927	computer vision;simulation;cost-effectiveness analysis;computer science;stereopsis;system of measurement;multimedia	Robotics	58.57721633063428	-37.83016597876647	109603
63f20a91b3bd01cb57b6453b72214ce9f08ca65f	an advanced spider-like rocker-bogie suspension system for mars exploration rovers		This paper describes the working of the system design for the Mars rover. The rover, developed to compete in the Mars Society’s University Rover Challenge 2015, was designed to perform various tasks such as site survey, sample return, equipment servicing, and astronaut assistance in a Mars-like landscape of dry, non-vegetated, rocky terrain. The complete design features a bioinspired eight-wheeled drive mechanism, an integrated robotic arm along with a stereo vision technique for advanced image processing. This paper focuses on the drive mechanism of the rover design. The 8-wheeled rover combines the rocker-bogie mechanism with four rocker wheels and four spider-leg wheels. The spider legs ensure that it can traverse over heights greater than the chassis height, which could be three times as much as the diameter of the wheels. NASA’s current rover can only traverse a height twice the diameter of the wheel. Additionally, the wheels are actuator-powered, and hence, the slope of the rover can be adjusted in such a way that it does not topple for a wide range of inclination allowing the rover to traverse over highly rugged terrain. The rover design can be modified for many applications notably the exploration of alien planets, deep sea trench, and other environments where human exploration is almost impossible. This effort to make the rover mechanism more efficient may one day be instrumental in detecting life and many such possibilities, in Mars and other planets.		Aswath Suresh;Nitin Ajithkumar;Sreekuttan T. Kalathil;Abin Simon;V. J. Unnikrishnan;Deepu P. Mathew;Praveen Basil;Kailash Dutt;Ganesha Udupa;C. M. Hariprasad;Maya Menon;Arjun Balakrishnan;Ragesh Ramachandran;Arun Murali;Balakrishnan Shankar	2015		10.1007/978-3-319-31293-4_34	astrobiology	Robotics	56.229111433413784	-30.067530243972527	109608
c7671f3b12ef86ffd3fb769f87ccd71fa6032570	visual control of autonomous mobile robot based on self-organizing model for pattern learning	navegacion;robot movil;vision ordenador;learning;autonomous system;camera television;control por ordenador;base connaissance;robotics;autonomous mobile robot;sistema autonomo;robot industriel;computer vision;aprendizaje;captador medida;navigation;apprentissage;measurement sensor;capteur mesure;robot mobile;camara television;television camera;systeme autonome;robot industrial;pattern recognition;robotica;base conocimiento;self organization;vision ordinateur;computer control;vision artificielle;robotique;reconnaissance forme;pilotage ordinateur;reconocimiento patron;artificial vision;moving robot;industrial robot;knowledge base;vision artificial	Abstract#R##N##R##N#This article proposes a self-organizing model for pattern learning together with an application to an autonomous mobile robot system. The self-organizing model consists of a processing rule prescribed and a memory part being blank at the initial stage. To an input signal, the model searches for a similar signal in the memory, and recalls its related information. If the information accompanied with the input signal differs from the recalled information, the model adds the new information to the memory. It influences the subsequent operations. Thus, the model constructs successively a data-base in a self-organizing way. This model can universally learn and reproduce any pattern of input-output response desired. Two principal functions in autonomous movement, i.e., position identification and obstacle avoiding movement were realized based on the self-organizing model. Furthermore, a camera type autonomous mobile robot system for indoor was made up. The size of the robot is about 0.7 × 0.7 × 0.7 m, and the weight is about 30 kg. The speed of movement is less than 3 km/h. A small computer that has a 16 bit microprocessor and a 1 Mbyte RAM controls the motion of the robot with an extended C language.	autonomous robot;mobile robot;organizing (structure);self-organization	Hisashi Suzuki;Suguru Arimoto	1988	J. Field Robotics	10.1002/rob.4620050505	computer vision;knowledge base;navigation;self-organization;simulation;computer science;engineering;autonomous system;artificial intelligence;professional video camera;robotics	Robotics	57.89831277988736	-32.88419797914656	109686
9bb15dc33742f56e375582cea1e7bd53b08105ea	learnt knot placement in b-spline curve approximation using support vector machines		Abstract Knot placement for curve approximation is a well known and yet open problem in geometric modeling. Selecting knot values that yield good approximations is a challenging task, based largely on heuristics and user experience. More advanced approaches range from parametric averaging to genetic algorithms. In this paper, we propose to use Support Vector Machines (SVMs) to determine suitable knot vectors for B-spline curve approximation. The SVMs are trained to identify locations in a sequential point cloud where knot placement will improve the approximation error. After the training phase, the SVM can assign, to each point set location, a so-called score. This score is based on geometric and differential geometric features of points. It measures the quality of each location to be used as knots in the subsequent approximation. From these scores, the final knot vector can be constructed exploring the topography of the score-vector without the need for iteration or optimization in the approximation process. Knot vectors computed with our approach outperform state of the art methods and yield tighter approximations.	approximation;b-spline;spline (mathematics);support vector machine	Pascal Laube;Matthias O. Franz;Georg Umlauf	2018	Computer Aided Geometric Design	10.1016/j.cagd.2018.03.019	mathematics;mathematical optimization;knot (unit);support vector machine;point cloud;b-spline;geometric modeling;parametric statistics;approximation error;heuristics	EDA	67.09614531460956	-37.21307218568421	109697
50a13376c50c3816d3292338f9aa2a02f15e6013	associating and reshaping of whole body motions for object manipulation	whole body;constrained inverse kinematics;humanoid robot;body motion reshaping;learning;hidden markov model;reinforcement learning;manipulator kinematics;hidden markov models;trajectory;humanoid robots;object manipulation;feature extraction;robots;manipulator kinematics end effectors hidden markov models humanoid robots learning artificial intelligence;inverse kinematics;humans;learning artificial intelligence;humans robot kinematics humanoid robots robotics and automation service robots intelligent robots neuroscience biological system modeling hidden markov models feedback control;end effectors humanoid robots object manipulation hidden markov models body motion primitives motion primitives learning body motion reshaping feedback control reinforcement learning constrained inverse kinematics;feedback control;end effectors;motion primitives learning;body motion primitives;timing	Since humanoid robots have similar body structures to humans, a humanoid robot is expected to perform various dynamic tasks including object manipulation. This research focuses on issues related to learning and performing object manipulation. Basic motion primitives for tasks are learned from observation of human's behaviors. An object manipulation task is divided into two types of motion primitives, which are represented as hidden Markov models (HMMs): one for a body motion primitive and the other for the relation between the object and body parts, which manipulate the object. When performing a task, a natural whole body motion is associated from an object motion by using learned motion primitives. Furthermore, the associated body motion is reshaped in both spatial and temporal space, in a more precise way. The reshaping in spatial space is realized in two stages by a feedback control policy learned with reinforcement learning and by constrained inverse kinematics. Key features like end-effectors for manipulation and timing for a task are extracted and used for the feedback control policy learning. The reshaping in temporal space is realized by comparing a predicted and observed object motion speed.	feedback;hidden markov model;humanoid robot;humans;inverse kinematics;markov chain;real-time locating system;reinforcement learning;robot end effector;unsupervised learning	Hirotoshi Kunori;Dongheui Lee;Yoshihiko Nakamura	2009	2009 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2009.5354022	computer vision;simulation;computer science;humanoid robot;artificial intelligence;hidden markov model	Robotics	63.088598878782065	-25.24594263902657	109738
a40ba0b849e5146a36b2136f6a67cb0c10eb4db2	a study of cooperative control of self-assembling robots in space with experimental validation	cooperative control;robot sensing systems;control systems;modular space systems;robot control orbital robotics optimal control robot kinematics assembly systems robotic assembly control systems robot sensing systems satellites costs;satellite systems;self assembling robots;cooperation;optimal control methods;orbital robotics;optimal control;assembly;symposia;optimal control aerospace robotics;trajectory;robot control;fuels;satellites;aerospace robotics;robots;aerospace electronics;assembly systems;experimental validation;robotic assembly;optimization;modular space systems cooperative control self assembling robots on orbit robotic satellite systems optimal control methods;on orbit robotic;robot kinematics	Modular self-assembling on-orbit robotic and satellite systems can be more reliable, have lower launch costs, and be more easily repaired and refueled. However, when individual modules assemble, many challenges and opportunities make the control of the assembled system complex. These issues include changes in inertial properties, and redundancy of actuators and sensors. Optimal control methods may be used to coordinate the control of the modules after assembly, insure good performance, and best utilize the combined resources of the assembly of modules. Simulation and experimental results compare this Cooperative algorithm's performance to that of an approach in which the control of the individual modules is not coordinated. Cooperative optimal control methods prove well-suited for controlling redundant, modular space systems.	algorithm;assembly language;automated planning and scheduling;computer performance;consensus dynamics;cooperative multitasking;hall-effect thruster;neural oscillation;online and offline;optimal control;plume (fluid dynamics);robot;sensor;sensor web;simulation;thrust;on-line system	Chiara Toglia;Daniel T. Kettler;Fred Kennedy;Steven Dubowsky	2009	2009 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2009.5152788	robot;control engineering;simulation;optimal control;computer science;engineering;control system;artificial intelligence;trajectory;control theory;assembly;robot control;cooperation;robot kinematics;satellite	Robotics	62.88400733392606	-27.57733594886543	109812
bdbc7d26aabd9be0b986fbf66770b76e99764dbf	global map building and navigation of mobile robot based on ultrasonic sensor data fusion	mobile robot;intelligent space;multiple vision;tracking;covariance intersection	In mobile robotics, ultrasonic sensors became standard devices for collision avoiding. Moreover, their applicability for map building and navigation has exploited in recent years. In this paper, as the preliminary step for developing a multi-purpose autonomous carrier mobile robot to transport trolleys or heavy goods and serve as robotic nursing assistant in hospital wards. The aim of this paper is to present the use of multi-sensor data fusion such as ultrasonic sensor, IR sensor for mobile robot to navigate, and presents an experimental mobile robot designed to operate autonomously within both indoor and outdoor environments.   The global map building based on multi-sensor data fusion is applied for recognition an obstacle free path from a starting position to a known goal region, and simultaneously build a map of straight line segment geometric primitives based on the application of the Hough transform from the actual and noisy sonar data. We will give an explanation for the robot system architecture designed and implemented in this study and a short review of existing techniques, Hough transform, since there exist several recent thorough books and review paper on this paper. Experimental results with a real Pioneer DX2 mobile robot will demonstrate the effectiveness of the discussed methods.		Shin-Chul Kang;Tae-Seok Jin	2007	Int. J. Fuzzy Logic and Intelligent Systems	10.5391/IJFIS.2007.7.3.198	mobile robot;embedded system;computer vision;simulation;engineering;mobile robot navigation	Robotics	53.893819132164545	-34.308908448581256	110010
e0122f5e1a3be3ad65834e0b3d898ec53c47a2e1	visual guidance of a pig evisceration robot using neural networks	vision system;vision ordenador;evisceration;aplicacion;image processing;slaughterhouse;procesamiento imagen;estrategia;wisard;robotics;classification;traitement image;computer vision;strategy;matadero;robot vision;ram networks;robotica;vision ordinateur;robotique;vision active;abattoir;reseau neuronal;application;strategie;clasificacion;evisceracion;red neuronal;neural network;active vision	The application of a RAM-based neural network to robot vision is demonstrated for the guidance of a pig evisceration robot. Tests of the combined robot-vision system have been performed at an abattoir. The vision system locates a set of feature points on a pig carcass and transmits the 3D coordinates of these points to the robot. An active vision strategy taking advantage of the generalisation capabilities of neural networks is used to locate the control points. A neural network PC-expansion board that provides a new classification every 180 μs is used to speed up the neural network processing.	artificial neural network;robot	Steen Sloth Christensen;Allan Weimar Andersen;Thomas Martini Jørgensen;C. Liisberg	1996	Pattern Recognition Letters	10.1016/0167-8655(95)00130-1	evisceration;computer vision;simulation;active vision;image processing;biological classification;strategy;computer science;artificial intelligence;robotics	Robotics	57.77983235328739	-32.94801949915152	110062
5bd95c5346032fbd31774e70a07c44aab3b94db0	a frequency domain approach to registration estimation in three-dimensional space	phase correlation technique;3 d modeling;computational stability;performance evaluation;fourier transform;range imaging;frequency domain analysis;hermitian symmetry;multidimensional fourier transform;coarse to fine approach;mobile robots;data fusion;rotated images;robot vision fourier transforms frequency domain analysis image registration mobile robots multidimensional signal processing;iterative algorithm;three dimensional;3 d modeling autonomous robotics data fusion frequency domain pose estimation range imaging registration;robot vision;on board sensors;range image;image registration;fourier transforms;multidimensional signal processing;three dimensional space;registration;rotational parameters;frequency domain approach;iterative closest point;translational parameters;automatic registration estimation;autonomous robotic systems;frequency domain analysis frequency estimation fourier transforms robot sensing systems orbital robotics robotics and automation iterative methods sensor systems iterative algorithms multidimensional systems;axis of rotation;frequency domain;local minima;autonomous robotics;autonomous robot;phase correlation;pose estimation frequency domain approach automatic registration estimation three dimensional space autonomous robotic systems on board sensors multidimensional fourier transform rotational parameters translational parameters 3 d images registration minimal energy differential coarse to fine approach rotated images hermitian symmetry phase correlation technique computational stability data fusion;pose estimation;minimal energy differential;3 d images registration	Autonomous robotic systems require automatic registration of data that are collected by on-board sensors. Techniques requiring user intervention are unsuitable for autonomous robotic applications, whereas iterative-based techniques do not scale well as the data set size increases and, additionally, tend toward locally minimal solutions. To avoid the latter problem, an accurate initial estimation of the transformation is required for iterative algorithms to properly perform. However, in some situations, an initial estimate of the transformation may not be readily available; hence, a method that does not require such an initial estimate nor descends into local minima is desirable. The method presented in this paper takes advantage of the multidimensional Fourier transform, which inherently decouples the estimation of the rotational parameters from the estimation of the translational parameters, to compute 3-D registration between range images without requiring an initial estimation of the transformation and avoiding problems of the classical iterative techniques. Using the magnitude of the Fourier transform, an axis of rotation is estimated by determining the line that contains the minimal energy differential between two rotated 3-D images. A coarse-to-fine approach is used to determine the angle of rotation from the minimal sum of the squared difference between the two rotated images. Due to the Hermitian symmetry introduced by the Fourier transform, two possible solutions for the angle of rotation exist. The proper solution is identified through the use of a phase-correlation technique, and the estimate of translation is simultaneously obtained. Experimental results and an extended performance evaluation illustrate the accuracy that can be achieved by the proposed registration technique on simulated and on real range images. Last, a comparison of computational stability with that of the classical iterative closest point method is presented.	algorithm;autonomous robot;closest point method;iteration;iterative closest point;iterative method;maxima and minima;on-board data handling;optic axis of a crystal;performance evaluation;phase correlation;sensor	Phillip Curtis;Pierre Payeur	2008	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2007.909499	fourier transform;three-dimensional space;computer vision;mathematical optimization;simulation;computer science;mathematics;frequency domain	Vision	54.46434289140505	-37.671457998411924	110303
7dc0effbb8ecf470f8b5eef3a78d068fd368d906	feedforward control for human-in-the-loop camera systems	image motion analysis;feedforward;hidden feature removal;degree of freedom;collision avoidance feedforward cameras hidden feature removal image motion analysis;human in the loop;feedforward control;collision avoidance;control systems cameras target tracking dc motors vehicles broadcasting head servomechanisms layout filters;visual servoing;collision avoidance feedforward control human in the loop camera system occlusions visual servoing;cameras	Cameras are often mounted on platforms that can move like rovers, booms, gantries and aircraft. People operate such platforms to capture desired views of a scene or a target. To avoid collisions with the environment and occlusions, such platforms often possess redundant degrees-of-freedom. As a result, manual manipulating of such platforms demands much skill. Visual-servoing some degrees-of-freedom may reduce operator burden and improve tracking performance. This concept, which we call human-in-the-loop visual-servoing, is demonstrated And applies a /spl alpha/ /spl rarr/ /spl beta/ /spl rarr/ /spl gamma/ filter and feedforward controller to a broadcast camera boom.	experiment;feed forward (control);feedforward neural network;pixel	Rares I. Stanciu;Paul Y. Oh	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1307120	control engineering;computer vision;engineering;control theory;feed forward	Robotics	60.68618112530632	-31.183734490131467	110337
447656db7d04d042bddf5f4c7d97e2da3bc988c5	measurement of a vehicle motion using a new 6-dof motion sensor system - angular velocity estimation with kalman filter using motion characteristic of a vehicle -	motion sensor;6 dof acceleration;kalman filter;angular velocity;motion characteristics		kalman filter;motion detector;velocity	Ryoji Onodera;Nobuharu Mimura	2008	JRM	10.20965/jrm.2008.p0116	control engineering;computer vision;control theory;linear motion	Robotics	57.221101157360856	-35.779419699283466	110381
27926c256fdeb962e41d193fc48306f407a0f37f	wad project where attractor dynamics aids wheelchair navigation	keyboards;intelligent robots;head direction;mobile robots;navigation;handicapped aids;obstacle avoidance;heading direction dynamics;dynamics;modular control system;infrared distance sensors;project engineering;acquired immune deficiency syndrome wheelchairs navigation infrared sensors mobile robots security keyboards intelligent robots humans indoor environments;indoor environments;collision avoidance handicapped aids vehicles infrared detectors computerised navigation dynamics project engineering;humans;collision avoidance;vehicles;infrared;security;acquired immune deficiency syndrome;infrared sensors;infrared detectors;electrical wheelchairs;target acquisition;wheelchairs;modular control system wad project electrical wheelchairs obstacle avoidance infrared distance sensors heading direction dynamics target acquisition;computerised navigation;wad project	The WAD project is aimed to provide limited autonomy to electrical wheelchairs. The primary focus is to provide a secure obstacle avoidance behavior based on infrared distance sensors which generate contributions to the heading direction dynamics that steers the wheelchair away from obstructions. Moreover, the attractor dynamics approach is used to integrate the obstacle avoidance behavior to a user defined target acquisition behavior, in which the direction and the distance to the target are indicated by the user at different points in time.		Pierre Mallet;Gregor Schöner	2002		10.1109/IRDS.2002.1041471	mobile robot;embedded system;computer vision;dynamics;navigation;simulation;infrared;computer science;engineering;artificial intelligence;information security;obstacle avoidance	Robotics	57.73117377509558	-31.017155276375252	110444
f2085da209e18c8d59235fa59ecd7b7923ee2476	optimization of the uav-p's motion trajectory in public flying ubiquitous sensor networks (fusn-p)			unmanned aerial vehicle	Ruslan Kirichek;Alexander Paramonov;Karine Vareldzhyan	2015		10.1007/978-3-319-23126-6_32	control engineering;computer vision;simulation	Robotics	57.46201145207167	-30.24602580709304	110868
a2af15b073d58c76b88065251651e472d45a51b4	intelligent lighting control for vision-based robotic manipulation	robot sensing systems;active lighting control;lighting control;manipulators;numerical simulation intelligent lighting control vision based robotic manipulation active lighting control visual interpretation large signal to noise ratio image contrast color rendering object natural properties extreme intensity unbalance information extraction fuzzy controller;fuzzy controller;fuzzy control;intelligent control;computer vision;robot manipulator;robot intelligence;dynamic environment;numerical analysis;robot vision;lighting robot sensing systems light sources cameras lighting control image color analysis;image color analysis;illumination planning;robot vision fuzzy control intelligent control lighting control manipulators numerical analysis;robot intelligence active lighting control active vision computer vision fuzzy control illumination planning perception;lighting;perception;signal to noise ratio;cameras;light sources;numerical simulation;active vision	The ability of a robot vision system to capture informative images is greatly affected by the condition of lighting in the scene. This paper reveals the importance of active lighting control for robotic manipulation and proposes novel strategies for good visual interpretation of objects in the workspace. Good illumination means that it helps to get images with large signal-to-noise ratio, wide range of linearity, high image contrast, and true color rendering of the object's natural properties. It should also avoid occurrences of highlight and extreme intensity unbalance. If only passive illumination is used, the robot often gets poor images where no appropriate algorithms can be used to extract useful information. A fuzzy controller is further developed to maintain the lighting level suitable for robotic manipulation and guidance in dynamic environments. As carried out in this paper, with both examples of numerical simulations and practical experiments, it promises satisfactory results with the proposed idea of active lighting control.	algorithm;color depth;experiment;information;large-signal model;lighting control system;numerical analysis;robot;signal-to-noise ratio;simulation;workspace	S. Y. Chen;Jianwei Zhang;Houxiang Zhang;N. M. Kwok;Youfu Li	2012	IEEE Transactions on Industrial Electronics	10.1109/TIE.2011.2146212	control engineering;computer vision;simulation;active vision;numerical analysis;computer science;engineering;artificial intelligence;lighting;signal-to-noise ratio;perception;intelligent control;image-based lighting;cognitive robotics	Robotics	61.112825635525695	-32.191033186434225	110876
28aeaddab1e5cc5bfdcb4d7302907411aafe5441	real-time perception-guided motion planning for a personal robot	lasers;robot sensing systems;manipulators;semantic annotation;personal robot;path planning;real time;personal robotics perception guided motion planning personal robot manipulation;operator space;personal robotics;collision detection;dynamics;three dimensional displays;path planning manipulators;motion planning;planning;motion planning robot sensing systems intelligent robots usa councils layout robustness computer science software safety real time systems intelligent systems;manipulation;collision avoidance;perception guided motion planning;mobile manipulator	This paper presents significant steps towards the online integration of 3D perception and manipulation for personal robotics applications. We propose a modular and distributed architecture, which seamlessly integrates the creation of 3D maps for collision detection and semantic annotations, with a real-time motion replanning framework. To validate our system, we present results obtained during a comprehensive mobile manipulation scenario, which includes the fusion of the above components with a higher level executive.	cloud computing;cognition;collision detection;columbia (supercomputer);conley–zehnder theorem;distributed computing;epr paradox;ibm notes;internet information services;lydia kavraki;map;mobile manipulator;motion planning;personal robot;real-time clock;real-time locating system;real-time transcription;robot operating system;robotics;smt placement equipment;willow	Radu Bogdan Rusu;Ioan Alexandru Sucan;Brian P. Gerkey;Sachin Chitta;Michael Beetz;Lydia E. Kavraki	2009	2009 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2009.5354396	control engineering;computer vision;simulation;computer science;artificial intelligence;motion planning	Robotics	63.98305500625042	-31.42934139774698	110904
a14cf4bb082dabd8febf2ed6ada85aa6412dcef6	a sensitive skin system for motion control of robot arm manipulators	motion in unstructured environment;systeme commande;sistema control;reseau capteur;bras robot;movimiento;radiacion infrarroja;motion control;infrared sensor array;manipulateur;robotics;rayonnement ir;motion;interfase;captador medida;robot arm;prevencion esquiva colision;control system;planificacion;measurement sensor;infrared radiation;red sensores;capteur mesure;robot control;obstacle avoidance;manipulador;mouvement;prevention esquive collision;interface;sensor array;robotica;planning;collision avoidance;robotique;planification;sensitive skin;distributed sensing;manipulator;materiel informatique;material informatica;sensor based motion planning;hardware	Cheung. E. a nd Lumelsky, Y .. A sensitive skin system for motion control of robot arm manipulators. Robotic~ and Autonomous Systems, 10 (1992) 932. This work addresses the implementation issues of sensor-based motion planning system for a robot arm manipulator ope ra ting among unknown obstacles of arbit rary shape. In order to realize on-line planning algorithms while protecting the whole arm body from potential collisions with obstacles, the system includes infrared based proximity sensitive skin covering the arm body, compute r hardware for signal processing and motion pla nning, and a n interface between th e planning and arm control systems. These components are described in detail, and their characteristics a re discussed.	algorithm;autonomous system (internet);control system;motion planning;online and offline;robotic arm;signal processing	Edward Cheung;Vladimir J. Lumelsky	1992	Robotics and Autonomous Systems	10.1016/0921-8890(92)90012-N	planning;motion control;embedded system;robot end effector;simulation;robotic arm;infrared;computer science;control system;artificial intelligence;motion;arm solution;manipulator;interface;robot control;obstacle avoidance;robotics;sensor array;robot kinematics	Robotics	58.13441501955981	-32.548330675878994	110921
f6f70a316240d789663f574be0d16c4fc9c7b21e	autonomous mobile patrol system for nuclear power plants: field test report of vehicle navigation and sensor positioning	nuclear power stations;nuclear engineering computing;path planning;cad;field test;maintenance engineering;mobile robots;laser ranging;image sensors;power generation inspection pressing humans computerized monitoring radiation monitoring remote monitoring international trade prototypes databases;power engineering computing;monitoring;mockup tests autonomous mobile patrol system nuclear power plants vehicle navigation sensor positioning automated monitoring radiation exposure ministry of international trade and industry toshiba remote inspection system tosris 3d cad database;ministry of international trade and industry;telerobotics;tactile sensors;nuclear power plant;power system reliability;cad telerobotics monitoring mobile robots path planning robot kinematics laser ranging local area networks image sensors tactile sensors nuclear engineering computing nuclear power stations power system reliability maintenance engineering power engineering computing;radiation exposure;local area networks;robot kinematics	The integrity in components of an operating nuclear power plant (NPP) is usually monitored on a daily basis by operator patrols. Currently, there is a pressing need to replace such human patrol activities by systems of automated monitoring in order to reduce radiation exposure and the workload imposed on operators. From this perspective, and under the sponsorship of the Ministry of International Trade & Industry (MITI), we embarked upon a R&D project in 1991 with the objective of developing TOSHIBA Remote Inspection System (TOSRIS) for NPPs. We built a prototype system and examined it in a mockup of a typical NPP environments. This project was completed in 1996. This paper describes the concept of TOSRIS, how the inspection position is calculated, how plans are passed using a 3D-CAD database, and mockup tests.	computer-aided design;prototype	Katsuhiko Sato;Hisashi Hozumi;Satoshi Okada;Takao Itoh;Shigeru Kanemoto;Hideharu Okano	1996		10.1109/IROS.1996.571045	local area network;telerobotics;maintenance engineering;mobile robot;embedded system;simulation;computer science;engineering;artificial intelligence;image sensor;cad;motion planning;tactile sensor;robot kinematics;mechanical engineering	Robotics	62.998157730379	-29.731135806396576	110956
2459883f87f7d28ad1412036f3558a0a97fb5c06	two-dimensional active sensing system for bicyclist-motorist crash prediction		This paper develops an active sensing system for a bicycle to accurately track rear vehicles that can have two-dimensional motion. The active sensing system consists of a single-beam laser sensor mounted on a rotationally controlled platform. The sensing system is inexpensive, small, lightweight, consumes low power, and is thus ideally suited for the bicycle application. The rotational orientation of the laser sensor needs to be actively controlled in real-time in order to continue to focus on a rear vehicle, as the vehicle's lateral and longitudinal distances change. This tracking problem requires controlling the real-time angular position of the laser sensor without knowing the future trajectory of the vehicle. The challenge is addressed using a novel receding horizon framework for active control and an interacting multiple model framework for estimation. The features and benefits of this active sensing system are illustrated first using simulation results. Then, preliminary experimental results are presented using an instrumented bicycle to show the feasibility of the system in tracking rear vehicles during both straight and turning maneuvers.	algorithm;angularjs;control system;interaction;lateral thinking;motion compensation;optimal control;radar tracker;real-time clock;real-time computing;real-time transcription;simulation	Woongsun Jeon;Rajesh Rajamani	2017	2017 American Control Conference (ACC)	10.23919/ACC.2017.7963298	horizon;control theory;computer science;control engineering;angular displacement;laser;trajectory;crash	Robotics	57.23983112359452	-33.87496571906348	111064
0f449328b1f73063ff53a0adaaf8a61a0a364f4a	vessel detection algorithm used in a laser monitoring system of the lock gate zone	user interfaces computerised monitoring database management systems marine engineering marine vehicles object detection optical scanners scada systems software engineering;measurement by laser beam;detection algorithms;scada interface vessel detection algorithm online laser monitoring system lock gate zone computer program object detection pattern recognition interference recognition partition water surface recognition partition infrared laser scanner controller industrial pc software development database;laser radar;lock gates;laser beams;indexes;ships;logic gates;monitoring;pattern recognition;algorithms;monitoring logic gates laser beams detection algorithms pattern recognition indexes measurement by laser beam;automatic vessel control;detection and identification systems;pattern recognition systems;pattern recognition vessel detection algorithm laser scanner monitoring system water transport lock gate	In this paper, we propose a vessel detection algorithm used in an online laser monitoring system in the lock of a hydropower plant. The system has to ensure the strict detection of the position of a vessel in order to prevent the manipulation of pound lock doors while the vessel is in the door zone. This paper describes in detail the monitoring concept, i.e., the detection algorithm implemented in the computer program that performs object detection in the view field of laser scanners. The detection algorithm has been developed in accordance with the modular principle and contains a number of functional partitions based on pattern recognition, i.e., the partition for the recognition of interference, the partition for water surface recognition in the conditions of debris floating on the water surface, the partition for the recognition of interference caused by the overflight of a single bird or a flock of birds, the partition for the recognition of interference caused by meteorological conditions, the partition for the recognition of high waves, and the partition for the recognition and detection of vessels. The main parts of the monitoring system are as follows: infrared laser scanners, controllers, an industrial PC, developed software with the implemented detection algorithm, a database, and a SCADA interface. This monitoring system has a vital role in keeping water transport operations safe and in the preventive maintenance and avoidance of vessel damaging in the area of gates at each end that controls the level of water in the lock chambers. The implementation of the detection algorithm has significantly improved the characteristics of the monitoring system. The system successfully detects all vessels, whereas the number of false detections remains neglectable.	3d scanner;algorithm;computer program;database;fail-safe;flock;industrial pc;interference (communication);object detection;pattern recognition;sensor	Dejan S. Misovic;Sasa D. Milic;Zeljko M. Durovic	2016	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2015.2477352	lidar;database index;embedded system;electronic engineering;logic gate;computer science;engineering;computer security	Robotics	65.97074681479695	-33.89940020142542	111190
7bf95632e086065d19d800694a32bee5216a1f68	speech robot mimicking human articulatory motion	ema;speech production;talking robot	We have developed a mechanical talking robot, Waseda Talker No. 7 Refined II, to study the human speech mechanism. The conventional control method for this robot is based on a concatenation rule of the phoneme-specific articulatory configurations. With this method, the speech mechanism of the robot is much slower than is required for human speech, because the robot requires momentary movement of motors. To resolve this problem, we have developed a control method that mimics human articulatory trajectory data. The human trajectory data for continuous speech was obtained by using an electromagnetic articulography (EMA) system. The EMA data was converted to the robot control parameters by applying inverse kinematics as well as geometric transformation. Experimental results show that the robot can produce continuous speech with human-like speed and smooth movement.	concatenation;inverse kinematics;robot control;speech synthesis	Kotaro Fukui;Toshihiro Kusano;Yoshikazu Mukaeda;Yuto Suzuki;Atsuo Takanishi;Masaaki Honda	2010			speech production;speech recognition	Robotics	68.22715946987164	-28.478778034561863	111220
d437f9f16dfdd03c1feb0d17ccd7c18552ae653e	virtual deformable image sensors: towards to a general framework for image sensors with flexible grids and forms	hog;penrose;deformable sensor;framework;hexagonal;pixel form;sensor grid	Our vision system has a combination of different sensor arrangements from hexagonal to elliptical ones. Inspired from this variation in type of arrangements we propose a general framework by which it becomes feasible to create virtual deformable sensor arrangements. In the framework for a certain sensor arrangement a configuration of three optional variables are used which includes the structure of arrangement, the pixel form and the gap factor. We show that the histogram of gradient orientations of a certain sensor arrangement has a specific distribution (called ANCHOR) which is obtained by using at least two generated images of the configuration. The results showed that ANCHORs change their patterns by the change of arrangement structure. In this relation pixel size changes have 10-fold more impact on ANCHORs than gap factor changes. A set of 23 images; randomly chosen from a database of 1805 images, are used in the evaluation where each image generates twenty-five different images based on the sensor configuration. The robustness of ANCHORs properties is verified by computing ANCHORs for totally 575 images with different sensor configurations. We believe by using the framework and ANCHOR it becomes feasible to plan a sensor arrangement in the relation to a specific application and its requirements where the sensor arrangement can be planed even as combination of different ANCHORs.	computation (action);conflict (psychology);experiment;gradient;gradient descent;html element;histogram;image sensor;inspiration function;mental orientation;oxygen 100 % gas for inhalation;pixel;randomness;requirement;twenty five	Wei Wen;Siamak Khatibi	2018		10.3390/s18061856	electronic engineering;engineering;computer vision;image sensor;artificial intelligence	Vision	65.49789047561048	-35.43674732947505	111366
0691d815809ac83bff7aca0449b9cb862beb2b53	swarm robots: from self-assembly to locomotion	autonomous docking;distributed control;locomotion;self-assembly;swarm robotics	Inspired by the swarm behaviours of social insects, research into the self-assembly of swarm robots has become an attractive issue in the robotic community. Unfortunately, there are very few platforms for self-assembly and locomotion in the field of swarm robotics. The Sambot is a novel self-assembling modular robot that shares characteristics with swarm robots and self-reconfigurable robots. Each Sambot can move autonomously and connect with the other. This paper discusses the concept of combining self-assembly and locomotion for swarm robots. Distributed control algorithms for selfassembly and locomotion are proposed. Using five physical Sambots, experiments were carried out on autonomous docking, self-assembly and locomotion. Our control algorithm for self-assembly can also be used to realize the autonomous construction and self-repair of robotic structures consisting of a large number of Sambots.	algorithm;autonomous robot;central pattern generator;distributed control system;docking (molecular);eusociality;experiment;new star games;self-assembly;self-reconfiguring modular robot;swarm robotics	Hongxing Wei;Youdong Chen;Miao Liu;Yingpeng Cai;Tianmiao Wang	2011	Comput. J.	10.1093/comjnl/bxq072	mobile robot;swarm robotics;simulation;ant robotics;artificial intelligence;bio-inspired robotics;robot locomotion	Robotics	65.17148338883064	-26.80269557054251	111598
bc799097ec2000c7a294e01c80825185f23e0331	fast computational processing for mobile robots' self-localization	software;sensors;kalman filters;spirals;mathematical model;robot kinematics	This paper intends to present a different approach to solve the Self-Localization problem regarding a RoboCup's Middle Size League game, developed by MINHO team researchers. The method uses white field markings as key points, to compute the position with least error, creating an error-based graphic where the minimum corresponds to the real position, that are computed by comparing the key (line) points with a precomputed set of values for each position. This approach allows a very fast local and global localization calculation, allowing the global localization to be used more often, while driving the estimate to its real value. Differently from the majority of other teams in this league, it was important to come up with a new and improved method to solve the traditional slow Self-Localization problem.		Helder Ribeiro;Pedro Silva;Ricardo Roriz;Tiago Maia;Rui Saraiva;Gil Lopes;A. Fernando Ribeiro	2016	2016 International Conference on Autonomous Robot Systems and Competitions (ICARSC)	10.1109/ICARSC.2016.40	computer vision;simulation;engineering;artificial intelligence	Robotics	54.55101841322034	-34.66850869192443	111690
b738bb153a14ccc650dd923f6266dc7e9262ef42	animal-inspired agile flight using optical flow sensing	motion control;unmanned aerial vehicle animal inspired agile flight optical flow sensing pigeons goshawks bats forest clutter obstacle field motion control law feedback law distance measurement bearing measurement robotic air vehicle uav;mobile robots;robot vision;robot vision autonomous aerial vehicles collision avoidance image sequences mobile robots motion control;markovian obstacle field optical flow sensing dubins vehicle;collision avoidance;optical sensors vehicles animals robot sensing systems optical feedback optical imaging;autonomous aerial vehicles;image sequences	There is evidence that flying animals such as pigeons, goshawks, and bats use optical flow sensing to enable high-speed flight through forest clutter. This paper discusses the elements of a theory of controlled flight through obstacle fields in which motion control laws are based on optical flow sensing. Performance comparison is made with feedback laws that use distance and bearing measurements, and practical challenges of implementation on an actual robotic air vehicle are described. The related question of fundamental performance limits due to clutter density is addressed.	agile software development;autonomous robot;clutter;glossary of computer graphics;image sensor;observable;optical flow;optimal control;theory;uncontrolled format string;velocity (software development)	Kenneth Sebesta;John Baillieul	2012	2012 IEEE 51st IEEE Conference on Decision and Control (CDC)	10.1109/CDC.2012.6426163	control engineering;motion control;mobile robot;computer vision;simulation;computer science;engineering;control theory	Robotics	56.01168808584519	-32.31554661111613	111751
4e7a74a8d6106cedaa1b42d373dd9ad340b1a61d	swarms of micro aerial vehicles stabilized under a visual relative localization	stability autonomous aerial vehicles helicopters microrobots multi robot systems position control;swarm stabilization visual relative localization control technique unmanned microaerial vehicles swarms multirobot teams real world dynamic environments reynold boid model 2d simulations quadrotors unmanned quadrotors precise positioning systems swarming behaviour;force collision avoidance visualization robot sensing systems vectors vehicles	A stabilization and control technique developed for steering swarms of unmanned micro aerial vehicles is proposed in this paper. The presented approach based on a visual relative localization of swarm particles is designed for utilization of multi-robot teams in real-world dynamic environments. The core of the swarming behaviour is inspired by Reynold's BOID model proposed for 2D simulations of schooling behaviour of fish. The idea of the simple BOID model, with three simple rules: Separation, Alignment and Cohesion, is extended for swarms of quadrotors in this paper. The proposed solution integrates the swarming behaviour with the relative localization and with a stabilization and control mechanism, which respects fast dynamics of unmanned quadrotors. The proposed method aspires to be an enabling technique for deployment of swarms of micro areal vehicles outside laboratories that are equipped with precise positioning systems. The swarming behaviour as well as the possibility of swarm stabilization with the visual relative localization in the control feedback are verified by simulations and partly by an experiment with quadrotors in this paper.	aerial photography;algorithm;global positioning system;precise point positioning;robot;simulation;software deployment;swarm robotics;unmanned aerial vehicle	Martin Saska;Jan Vakula;Libor Preucil	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907374	control engineering;computer vision;simulation;engineering	Robotics	58.23021371234024	-25.71684798884335	111765
49bffc952d78ae4b3f0ae24b04f7b105825ac59d	experimental odometry calibration of the mobile robot khepera ii based on the least-squares technique	linearity;mobile robot;calibration mobile robots wheels kinematics equations position measurement linearity velocity measurement angular velocity current measurement;mobile robots;least square method;kinematics;current measurement;least square;position measurement;angular velocity;velocity measurement;calibration;wheels	This paper develops an algorithm for odometry calibration of differential-drive mobile robots. As a first step, the kinematic equations are written so as to underline linearity in a suitable set of unknown parameters; then, the least-squares method is applied to estimate them. The wide literature on the least-squares formulation can thus be exploited; suitability of the data can be numerically verified. The proposed technique has been implemented on the Khepera II mobile robot; the obtained results confirm the effectiveness of the proposed calibration method also in comparison to other existing approaches.	algorithm;khepera mobile robot;least squares;numerical analysis;odometry	Gianluca Antonelli;Stefano Chiaverini	2005	Proceedings of the 2005 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2005.1570321	control engineering;mobile robot;simulation;computer science;engineering;artificial intelligence;odometry;control theory;least squares;robot calibration	Robotics	57.35866928328795	-36.1634209129768	111895
5a36c6c5be27d251ce5be67ea98f82af706bf194	vessel target prediction method and dead reckoning position based on svr seaway model			dead reckoning	Joo-Sung Kim	2017	Int. J. Fuzzy Logic and Intelligent Systems	10.5391/IJFIS.2017.17.4.279	support vector machine;dead reckoning;pattern recognition;artificial intelligence;computer science	Robotics	55.330815274351	-36.230405556685774	112317
25d4978cd1f5d08326a96edac27ebd8fe119f4eb	using task efficient contact configurations to animate creatures in arbitrary environments	procedural animation;range of motion;autonomous virtual characters;animation for games;force transmission ratio;contact before motion	A common issue in three-dimensional animation is the creation of contacts between a virtual creature and the environment. Contacts allow force exertion, which produces motion. This paper addresses the problem of computing contact configurations allowing to perform motion tasks such as getting up from a sofa, pushing an object or climbing. We propose a two-step method to generate contact configurations suitable for such tasks. The first step is an offline sampling of the range of motion (ROM) of a virtual creature. The ROM of the human arms and legs is precisely determined experimentally. The second step is a run time request confronting the samples with the current environment. The best contact configurations are then selected according to a heuristic for task efficiency. The heuristic is inspired by the force transmission ratio. Given a contact configuration, it measures the potential force that can be exerted in a given direction. The contact configurations are then used as inputs for an inverse kinematics solver that will compute the final animation. Our method is automatic and does not require examples or motion capture data. It is suitable for real time applications and applies to arbitrary creatures in arbitrary environments. Various scenarios (such as climbing, crawling, getting up, pushing or pulling objects) are used to demonstrate that our method enhances motion autonomy and interactivity in constrained environments. & 2014 Elsevier Ltd. All rights reserved. Research in computer animation is motivated by the need to provide virtual creatures with an increased autonomy of motion in 3D environments. Such improvements allow to propose new forms of gameplay in video games, or to validate ergonomic designs. In this work we are interested in the contacts created between a creature and the environment: contacts allow to efficiently exert the force necessary to perform motion tasks (such as getting up, climbing or pulling). For instance in Fig. 13, several contacts are created between the end-effectors of a virtual insect and the books composing the environment. Motion capture methods are inherently limited in such a constrained context: addressing various tasks and environments for different creatures requires the creation of prohibitively large motion databases. Therefore, a common approach is the decomposition of the motion into a sequence of contact configurations between a virtual creature and the environment. The notion of configuration is central in motion planning [1]. Such planners often use randomly generated configurations [2], and select those preserving static stability [3]. However, they lack heuristics to determine if those configurations are suited for the task in terms of force exertion. In the rest of the paper such configurations are called task efficient. Dynamic simulations use predefined configurations as inputs to motion controllers, but show little adaptation to the environment [4]. Thus, motion planners and dynamic controllers could benefit from a method to generate appropriate contact configurations. This is our problem statement, formalized in Section 2. The key idea: The environment as a mean to exert a force: Contacts allow force exertion, which in turn produces the motion. Therefore to select a contact configuration, it is important to make sure it will allow to perform the task. For this reason we need heuristics to measure the compatibility of a contact configuration with a translational motion task. Examples of such tasks are pushing, pulling, standing up, or climbing. This set of motions is commonly needed by interactive simulations (such as videogames). They could benefit from our method to introduce more variety in the environments and interactions they propose. Rotational tasks will be addressed in future works. To measure the task efficiency, we propose a heuristic inspired by the force transmission ratio [5]. It defines the efficiency of a configuration as the potential force it allows to exert in the direction of a translational task, as detailed in Section 2.4. It is traditionally used to optimize the configuration of a robotic arm, but requires to	book;coat of arms;computer animation;database;evolutionary computation;experiment;heuristic (computer science);human factors and ergonomics;interaction;interactivity;inverse kinematics;motion capture;motion controller;motion planning;online and offline;procedural generation;pull technology;real-time computing;relevance;robot;robotic arm;run time (program lifecycle phase);sampling (signal processing);simulation;solver;xfig	Steve Tonneau;Julien Pettré;Franck Multon	2014	Computers & Graphics	10.1016/j.cag.2014.08.005	computer vision;simulation;range of motion;computer science;artificial intelligence;computer graphics (images)	Robotics	65.91382080631894	-25.911164134504325	112336
e1f7db7406cd68936fe438cc6467a3adc9b1350a	trajectory-model-based reinforcement learning: application to bimanual humanoid motor learning with a closed-chain constraint	standards;joints;trajectory;vectors;humanoid robots;predictive models	We propose a reinforcement learning (RL) framework to improve policies for a high-dimensional system through fewer interactions with real environments than standard RL methods. In our learning framework, we first use off-line simulations to improve the controller parameters with an approximated environment model to generate samples along locally optimized trajectories. We then use the approximated dynamics to improve the performance of a tool manipulation task in a path integral RL framework, which updates a policy from the sampled trajectories of the state and action vectors and the cost. In this study, we apply our proposed method to a bimanual humanoid motor learning task in which we need to explicitly consider a closed-chain constraint. We show that a 51-DOF real humanoid robot can learn to manipulate a rod to hit via-points using both arms within 36 interactions in a real environment.	approximation algorithm;coat of arms;humanoid robot;interaction;online and offline;path integral formulation;reinforcement learning;simulation	Norikazu Sugimoto;Jun Morimoto	2013	2013 13th IEEE-RAS International Conference on Humanoid Robots (Humanoids)	10.1109/HUMANOIDS.2013.7030010	simulation;computer science;humanoid robot;artificial intelligence;trajectory;machine learning;predictive modelling	Robotics	62.24276879421854	-24.1499738691258	112610
18faffb619e2ad940f11dd7fe875b562dc49b6b6	a generalized framework for interactive dynamic simulation for multirigid bodies	contact problem;algorithms biomechanics computer simulation humans joints models biological movement nonlinear dynamics robotics user computer interface;object oriented methods;articulated bodies;rigid body;object oriented design;haptic device;degree of freedom;virtual reality multi robot systems mobile robots digital simulation object oriented methods haptic interfaces;biological system modeling;virtual reality;biomechanics;object oriented framework;models biological;mobile robots;robotics;joints;virtual environments;indexing terms;contact dynamics;virtual prototyping;imaging phantoms;impulse based methods interactive dynamic simulation multirigid bodies prototype simulator interactive generalized motion simulator virtual environments free flying rigid object robotic systems human body simulation object oriented framework haptic interface articulated bodies phantom haptic device;interactive dynamic simulation;coulomb friction;robots;nonlinear dynamics;multi robot systems;interactive simulation;phantom haptic device;robotic systems;multirigid bodies;algorithms;dynamic simulation;free flying rigid object;impulse based methods;human body simulation;humans;interactive generalized motion simulator;user computer interface;couplings;virtual environment;haptic interfaces;friction;user interaction;prototype simulator;computer simulation;object oriented modeling;movement;object oriented modeling biological system modeling haptic interfaces friction virtual prototyping virtual environment couplings robots humans imaging phantoms;digital simulation;haptic interaction;haptic interface	"""This paper presents a generalized framework for dynamic simulation realized in a prototype simulator called the Interactive Generalized Motion Simulator (I-GMS), which can simulate motions of multirigid-body systems with contact interaction in virtual environments. I-GMS is designed to meet two important goals: generality and interactivity. By generality, we mean a dynamic simulator which can easily support various systems of rigid bodies, ranging from a single free-flying rigid object to complex linkages such as those needed for robotic systems or human body simulation. To provide this generality, we have developed I-GMS in an object-oriented framework. The user interactivity is supported through a haptic interface for articulated bodies, introducing interactive dynamic simulation schemes. This user-interaction is achieved by performing push and pull operations via the PHANToM haptic device, which runs as an integrated part of I-GMS. Also, a hybrid scheme was used for simulating internal contacts (between bodies in the multirigid-body system) in the presence of friction, which could avoid the nonexistent solution problem often faced when solving contact problems with Coulomb friction. In our hybrid scheme, two impulse-based methods are exploited so that different methods are applied adaptively, depending on whether the current contact situation is characterized as """"bouncing"""" or """"steady."""" We demonstrate the user-interaction capability of I-GMS through online editing of trajectories of a 6-degree of freedom (dof) articulated structure."""	adaptive stepsize;ball project;behavior;cns disorder;dynamic simulation;extensibility;friction;generic drugs;globalization management system;hl7publishingsubsection <operations>;haptic device component;haptic technology;human body;interactivity;interface device component;interpolation;linkage (software);mechanics;motion simulator;muscle rigidity;numerical analysis;prototype;real-time transcription;robot;virtual reality;body system	Wookho Son;Kyunghwan Kim;Nancy M. Amato;Jeffrey C. Trinkle	2004	IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)	10.1109/TSMCB.2003.818434	computer simulation;computer vision;dynamic simulation;simulation;computer science;artificial intelligence;biomechanics;virtual reality;haptic technology;robotics;computer graphics (images)	Robotics	66.73848732729212	-31.699414051797426	112671
728985de4f38de561af2f32f31451462985dded2	a robot self-localization system using one-way ultra-wideband communication	robot sensing systems;clocks synchronization noise measurement extraterrestrial measurements global positioning system robot sensing systems;clocks;noise measurement;ultra wideband communication feedback helicopters multi robot systems slam robots time of arrival estimation;global positioning system;synchronization;extraterrestrial measurements;quadrocopter robot self localization system one way ultrawideband communication robot position estimation ultrawideband radio signals multiple robots feedback control system high speed dynamic motion tracking motion capture system	A robot localization system is presented that enables a robot to estimate its position within some space by passively receiving ultra-wideband radio signals from fixed-position modules. Communication from the fixed-position modules is one-way, allowing the system to scale to multiple robots. Furthermore, the system's high position update rate makes it suitable to be used in a feedback control system, and enables the robot to track and perform high-speed, dynamic motions. This paper describes the algorithmic underpinnings of the system, discusses design decisions and their impact on the performance of the resulting localization, and highlights challenges faced during implementation. Performance of the localization system is experimentally verified through comparison with data from a motion-capture system. Finally, the system's application to robot self-localization is demonstrated through integration with a quadrocopter.	algorithm;algorithmic efficiency;biasing;clock synchronization;control system;elegant degradation;experiment;feedback;internationalization and localization;motion capture;multilateration;one-way function;radiation pattern;robot;robotic mapping;scalability;swarm robotics;time of arrival;ultra-wideband	Anton Ledergerber;Michael Hamer;Raffaello D'Andrea	2015	2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2015.7353810	control engineering;mobile robot;synchronization;simulation;global positioning system;computer science;engineering;noise measurement;control theory;robot control;mobile robot navigation;robot calibration	Robotics	55.52904029725398	-36.73633611633608	112842
6c66f38e55f93d6d7f11f1b214b60c7f92d7f646	prototyping the autonomous flight algorithms using the prepar3d® simulator		* Abstract. This article concerns prototyping of the control algorithms for un- manned flying objects using the virtual reality. More specifically, there is discussed an integration between simulation environment and unmanned aerial vehicle (UAV) control software. This integration is based on software in the loop simulation. The control software uses PI controllers cascade, which stabilize the aircraft in the simulated air. Used simulator is Prepar3D® from Lockheed Martin corporation. Implemented algorithms that are used to control the UAV in simulation environment can be used to future prototype of vision based algo- rithms. All implemented algorithms are presented along with the developed soft- ware, which we are using to navigate the flying object on real map.	algorithm	Krzysztof Daniec;Pawel Iwaneczko;Karol Jedrasiak;Aleksander Nawrat	2013		10.1007/978-3-319-00369-6_14	control engineering;embedded system;simulation;engineering	Robotics	62.20766987502515	-29.359031231563744	112884
a50f744d6db3dcfd04a58df5a5cb302fcc4ac520	‘teleportation’-based motion planner for design error analysis	motion analysis;industrial assembly teleportation based motion planner design error analysis probabilistic path planning technique;interpolation;probability;design error analysis;path planning;design for manufacture;telerobotics design for manufacture error analysis mobile robots path planning probability robotic assembly;mobile robots;joints;process design;assembly;error analysis;distance measurement;proteins;error correction;robots;industrial assembly;teleportation based motion planner;telerobotics;production;robotic assembly;probabilistic path planning technique;algorithm design and analysis;robotics and automation;motion analysis error analysis path planning algorithm design and analysis production proteins robotics and automation robotic assembly error correction process design	Probabilistic path planning techniques have proven to be vital for finding and validating solutions for difficult industrial assembly tasks. Nevertheless, the failure of a path planner to find a solution to a task does not suggest how to correct the error. We suggest a methodology to identify possible bottlenecks and present an algorithm to analyze the extent to which the design must be modified in order for the task to complete successfully. We validate our algorithm on two industrial problems involving design errors, and explain how to interpret the results in order to improve the design.	algorithm;bottleneck (software);computer-aided design;interpolation;motion planning;series and parallel circuits;statistical relational learning	Jesse C. Himmelstein;Etienne Ferre;Jean-Paul Laumond	2009	2009 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2009.5152191	telerobotics;robot;control engineering;mobile robot;process design;algorithm design;computer vision;simulation;error detection and correction;interpolation;computer science;artificial intelligence;probability;assembly;motion planning;design for manufacturability	Robotics	62.049965894079286	-35.468994861480624	112941
93f74ff8d45418de392eb81adfd8252bf5c938eb	structure-reconfiguring robots: autonomous truss reconfiguration and manipulation	motion control;rods structures;path planning;connectors mobile robots servomotors robot sensing systems reconfigurable logic;supports buildings structures motion control path planning robots rods structures structural engineering;structural engineering;robots;buildings structures;supports;truss module design structure reconfiguring robot truss reconfiguration truss manipulation 3d truss structure translational motion rotational motion bidirectional geared rod structural building block traversal plan motion primitive robot architecture	In this article, we present a robot capable of autonomously traversing and manipulating a three-dimensional (3-D) truss structure. The robot can approach and traverse multiple structural joints using a combination of translational and rotational motions. A key factor in allowing reliable motion and engagement is the use of specially designed structural building blocks comprised of bidirectional geared rods. A set of traversal plans, each comprised of basic motion primitives, were analyzed for speed, robustness, and repeatability. Paths covering eight joints are demonstrated, as well as automatic element assembly and disassembly. We suggest that the robot architecture and truss module design, such as the one presented here, could open the door to robotically assembled, maintained, and reconfigured structures that would ordinarily be difficult, risky, or time consuming for humans to construct.	autonomous robot;disassembler;repeatability;traverse	Franz Nigl;Shuguang Li;Jeremy Blum;Hod Lipson	2013	IEEE Robotics & Automation Magazine	10.1109/MRA.2012.2201579	structural engineering;robot;control engineering;motion control;computer science;engineering;artificial intelligence;motion planning;engineering drawing	Robotics	65.02484878831915	-27.224645723846596	113032
53c281219eed78d052bba42aec2ec9d04262ba55	magnetometer-augmented imu simulator: in-depth elaboration	micro electrical mechanical systems;biomechanical phenomena;absolute magnetic reference;imu;simulator;acceleration;magnetometer;algorithms;humans;modeling;computer simulation;aircraft	The location of objects is a growing research topic due, for instance, to the expansion of civil drones or intelligent vehicles. This expansion was made possible through the development of microelectromechanical systems (MEMS), inexpensive and miniaturized inertial sensors. In this context, this article describes the development of a new simulator which generates sensor measurements, giving a specific input trajectory. This will allow the comparison of pose estimation algorithms. To develop this simulator, the measurement equations of every type of sensor have to be analytically determined. To achieve this objective, classical kinematic equations are used for the more common sensors, i.e., accelerometers and rate gyroscopes. As nowadays, the MEMS inertial measurement units (IMUs) are generally magnetometer-augmented, an absolute world magnetic model is implemented. After the determination of the perfect measurement (through the error-free sensor models), realistic error models are developed to simulate real IMU behavior. Finally, the developed simulator is subjected to different validation tests.	allan variance;approximation algorithm;drug vehicle;euler;evaluation;gyro;gyroscope;mental orientation;microelectromechanical systems;microsoft outlook for mac;numerous;orientation (graph theory);physical object;population parameter;sample variance;simulation;simulators;white noise;accelerometers;algorithm;magnetometers;sensor (device)	Thomas Brunner;Jean-Philippe Lauffenburger;Sébastien Changey;Michel Basset	2015		10.3390/s150305293	computer simulation;acceleration;control engineering;embedded system;inertial measurement unit;electronic engineering;magnetometer;simulation;systems modeling;computer science;engineering;electrical engineering;physics;quantum mechanics	Robotics	57.95024723691795	-35.69272828904815	113373
0053ccfb88da226691bbe60505ba1cf3826d2350	sensor-based globally asymptotically stable filters for attitude estimation: analysis, design, and performance evaluation	nonlinear filters;sensors asymptotic stability attitude measurement kalman filters mobile robots nonlinear filters;sensors;kalman filters;mobile robots;asymptotic stability;globally asymptotically stable gas attitude and heading reference system ahrs extended kalman filters ekfs;ekf sensor based globally asymptotically stable filter attitude estimation performance evaluation gas filter design gas filter analysis sensor driven design attitude and heading reference system ahrs low cost inertial measurement unit high precision motion rate table ground truth signals extended kalman filters;vectors position measurement noise observers kalman filters robot sensing systems;attitude measurement	This technical note presents the design, analysis, and performance evaluation of a novel globally asymptotically stable (GAS) filter for attitude estimation. The design is sensor-driven and departs from traditional solutions as no explicit representations of the attitude are considered. The proposed solution yields unique estimates and it does not suffer from drawbacks such as singularities, topological limitations for achieving global stabilization, or unwinding phenomena. The performance of the overall attitude estimation solution is evaluated with the design and implementation of an Attitude and Heading Reference System (AHRS) based on a single low-cost Inertial Measurement Unit. The performance of the proposed AHRS is assessed experimentally using a high precision motion rate table, which provides ground truth signals for comparison with the resulting estimates.	attitude and heading reference system;experiment;ground truth;lookup table;loop unrolling;performance evaluation;robot;simulation	Pedro Tiago Martins Batista;Carlos Silvestre;Paulo Jorge Ramalho Oliveira	2012	IEEE Transactions on Automatic Control	10.1109/TAC.2012.2187142	kalman filter;control engineering;mobile robot;invariant extended kalman filter;simulation;engineering;sensor;control theory;extended kalman filter;exponential stability;attitude and heading reference system	Robotics	57.52611892075983	-35.81433246409905	113495
d29d6721d492abc24076d677b69dd8dec904d90f	feature-based visual servoing and its application to telerobotics	manipulators;control algorithm;theory and practice;institut fur dynamik der flugsysteme;visual servoing telerobotics orbital robotics calibration space technology robot vision systems manipulator dynamics robustness robotics and automation robotic assembly;manipulator dynamics;orbital robotics;computer vision;robot manipulator;feedback;aerospace control;rotex space teleoperation system feature based visual servoing telerobotics robot manipulator;rotex space teleoperation system;feature based visual servoing;telerobotics;tracking telerobotics feedback manipulators aerospace control computer vision;robotic assembly;robustness;space technology;visual servoing;robot vision systems;calibration;robotics and automation;tracking	Recent advances in visual servoing theory and practice now make it possible to accurately and robustly position a robot manipulator relative to a target. Both the vision and control algorithms are extremely simple, but they must be initialized on task-relevant features in order to be applied. Consequently, they are particularly well-suited to telerobotics systems where an operator can initialize the system but round-trip delay prohibits direct operator feedback during motion. This paper describes the basic theory behind feature-based visual servoing and discusses the issues involved in integrating visual servoing into the ROTEX space teleoperation system.	algorithm;telerobotics;visual servoing	Gregory D. Hager;Gerhard Grunwald;Gerd Hirzinger	1994		10.1109/IROS.1994.407395	telerobotics;control engineering;computer vision;calibration;simulation;computer science;engineering;artificial intelligence;feedback;tracking;space technology;visual servoing;robustness	Robotics	60.5928571928122	-32.03190352198241	113646
db97e567df44868d4129fad35b3f9f64a89f77a8	module design with communication and reconfiguration for snake-type modular robotic systems	snake robots;wireless communication;reconfiguration planning;modular robots	In this paper, the module hardware design is addressed and a wireless communication algorithm is proposed for the motion coordination and reconfiguration planning of snake-type robots. The objective of the modular design and the planning algorithm is on self-intelligence and distributed feature for the adding of new modules and the removal of broken parts during motion reconfiguration. Particularly, the automatic connector and wireless communication are implemented on each module, and a planning algorithm for motion reconfiguration is proposed for determining the physical position and acting role of the sequential connected modules in a snake-like robot. Finally, two types of case studies are conducted for testing the communication feasibility and motion reconfigurability of the proposed robotic modules.	robotics	Feng-Li Lian;Ping-Chih Lin	2010	I. J. Information Acquisition	10.1142/S0219878910002166	embedded system;real-time computing;computer science;self-reconfiguring modular robot;wireless	Robotics	64.85348488867221	-27.701850763235445	113728
2ab8c46ce83f9337ebad2be86838c5a61068eeca	multimodal autonomous tool analyses and appropriate application	relative position;contact area;mobile robots;geometric feature;model complexity;robot arm;image edge detection three dimensional displays robot sensing systems visualization feature extraction;position control;feature extraction;visual features;force torque sensors multimodal autonomous tool analyses visual features extraction robot visual exploration geometric features potential contact areas manipulation tasks;position control feature extraction mobile robots	In this work we propose a method to extract visual features from a tool in the hand of a robot to derive basic properties how to handle this tool correctly. We want to show how a robot can improve its accuracy in certain tasks by a visual exploration of geometric features. We also show methods to extend the proprioception of the robots arm to the new end-effector including the tool. By a combination of 3D and 2D data, it is possible to extract features like geometric edges, flat surfaces and concavities. From those features we can distinguish several classes of objects and make basic measurements of potential contact areas and other properties relevant for performing tasks. We also present a controller that uses the relative position or orientation of such features as constraints for manipulation tasks in the world. Such a controller allows to easily model complex tasks like pancake flipping or sausage fishing. The extension of the proprioception is achieved by a generalized filter setup for a set of force torque sensors, that allows the detection of indirect contacts performed over a tool and extract basic information like the approximated direction from the sensor data.	approximation algorithm;autonomous robot;multimodal interaction;robot end effector;sensor	Ingo Kresse;Ulrich Klank;Michael Beetz	2011	2011 11th IEEE-RAS International Conference on Humanoid Robots	10.1109/Humanoids.2011.6100860	mobile robot;computer vision;simulation;robotic arm;feature extraction;computer science;artificial intelligence;contact area	Robotics	64.0243329983592	-25.81612465817338	113933
16c99bb76b895d698075fe529f195374ef835aba	autonomous stair-hopping with scout robots	search and rescue;motion control;urban rescue missions scout robot mobile robots autonomous stair hopping visual servoing pose estimation motion control;mobile robots;humans mobile robots wheels intelligent robots robot sensing systems distributed computing personnel surveillance shape springs;robot vision;servomechanisms;robot dynamics;visual servoing;servomechanisms mobile robots robot dynamics motion control robot vision	Search and rescue operations in large disaster sites require quick gathering of relevant information. Both the knowledge of the location of victims and the environmental/structural conditions must be available to safely and efficiently guide rescue personnel. A major hurdle for robots in such scenarios is stairs. A system for autonomous surmounting of stairs is proposed in which a Scout robot jumps from step to step. The robot’s height is only about a quarter step in size. Control of the Scout is accomplished using visual servoing. An external observer such as another robot is brought into the control loop to provide the Scout with an estimation of its pose with respect to the stairs. This cooperation is necessary as the Scout must refrain from ill-fated motions that may lead it back down to where it started its ascend. Initial experimental results are presented along with a discussion of the issues involved.	ascend;autonomous robot;control system;frequency-hopping spread spectrum;high- and low-level;personal digital assistant;scout;software architecture;surface hopping;user interface;visual servoing;wheels	Sascha Stoeter;Paul E. Rybski;Maria L. Gini;Nikolaos Papanikolopoulos	2002		10.1109/IRDS.2002.1041476	control engineering;motion control;mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence;social robot;control theory;robot control;visual servoing;personal robot	Robotics	57.060967919125304	-29.169302084503812	114520
7b68364e1edfad9b0ba62a51d31c4ff965ba5296	improving ability of tele-operators to complete progressively more difficult mobile robot paths using simple expert systems and ultrasonic sensors	robot movil;esquiva colision;interfase usuario;sensor system;control theory;sistema experto;cable;ultrason;sensors;input output equipment;mobile robot;user interface;ultrasound;teoria sistema;course of action;mesure acoustique;asservissement visuel;logique propositionnelle;robotics;riesgo accidente;remote operation;computing;risque accidentel;transductor ultrasonido;captador medida;systems and control theory;levier commande;measurement sensor;equipement entree sortie;capteur mesure;obstacle avoidance;robot mobile;ultrasonido;operating system;câble;systems theory;palanca de mando;propositional logic;teleaccion;theorie systeme;telecontrol;equipo entrada salida;robotica;ultrasonic transducer;visual feedback;interface utilisateur;medida acustica;control lever;collision avoidance;robotique;systeme expert;logica proposicional;ultrasonics;esquive collision;visual servoing;hazard;moving robot;servomando visual;teleoperation;transducteur ultrason;acoustic measurement;design methodology;expert system;ultrasonic sensor	Purpose – The purpose of this paper is to describe the use of simple expert systems to improve the performance of tele-operated mobile robots and ultrasonic sensor systems. The expert systems interpret data from the joystick and sensors and identify potentially hazardous situations and then recommend safe courses of action so that tele-operated mobile-robot tasks can be completed more quickly. Design/methodology/approach – The speed of a tele-operator in completing progressively more complicated driving tasks is investigated while using a simple expert system. Tele-operators were timed completing a series of tasks using a joystick to control a mobile robot through a simple expert system that assisted them with driving the robot while using ultrasonic sensors to avoid obstacles. They either watched the robot while operating it or sat at a computer and viewed scenes remotely on a screen from a camera mounted on the robot. Tele-operators completed tests with the simple expert system and the sensors connected. The system used an umbilical cable to connect to the robot. Findings – The simple expert systems consistently performed faster than the other systems. Results are compared with the most recently published results and show a significant improvement. In addition, in simple environments, tele-operators performed better without a sensor system to assist them but in more complicated environments than tele-operators performed better with the sensor systems to assist. Research limitations/implications – Simple expert systems are shown to improve the operation of a tele-operated mobile robot with an obstacle avoidance systems fitted. Practical implications – Tele-operated systems rely heavily on visual feedback and experienced operators. This paper investigates how to make tasks easier. Simple expert systems are shown to improve the operation of a tele-operated mobile robot. The paper also suggests that the amount of sensor support should be varied depending on circumstances. Originality/value – The simple expert systems are shown in this paper to improve the operation of a tele-operated mobile robot. Tele-operators completed tests with the simple expert system and the sensors connected. The results are compared with a tele-operator driving a mobile robot without any assistance from the expert systems or sensors and they show a significant improvement.		David A. Sanders;Jasper Graham-Jones;Alexander E. Gegov	2010	Industrial Robot	10.1108/01439911011063254	control engineering;embedded system;simulation;computer science;engineering;artificial intelligence;social robot;ultrasonic sensor;robotics;expert system	Robotics	59.00798783182136	-29.62816812498217	114620
4317e87b66b7e381e153b9c8d13cc525368f2419	optical flow-based perception, behavior-based control, and topological path planning for mobile robots using fuzzy logic concepts			fuzzy logic;mobile robot;motion planning;optical flow	Ngoc Anh Mai	2012				Robotics	58.22841855975005	-30.239892049028008	114621
2960af0da6619a1f1f8ed2e88c7c094ccd40a462	seabed terrain match algorithm based on hausdorff distance and particle swarm optimization	fault tolerance performance;complexity theory;fault tolerant;stan;underwater vehicles;particle measurements;seabed terrain aided navigation system;image matching;path planning;anti interference performance;underwater vehicle;search strategy;mobile robots;pso;data mining;underwater vehicles image matching mobile robots particle swarm optimisation path planning robot vision;accuracy;robot vision;particle swarm optimizer;positioning accuracy pso stan;particle swarm optimization;positioning accuracy;hausdorff distance;underwater vehicle seabed terrain matching algorithm hausdorff distance particle swarm optimization seabed terrain aided navigation system anti interference performance fault tolerance performance electronic chart;navigation system;electronic chart;particle swarm optimization algorithm;particle swarm optimisation;similarity measure;algorithm design and analysis;particle swarm optimization aircraft navigation marine technology computer errors magnetohydrodynamics educational institutions automation fault tolerance robustness weapons;seabed terrain matching algorithm;aircraft navigation	When most of terrain match algorithms were directly applied to seabed terrain-aided navigation system (STAN), the positioning accuracy would fall off sharply and become unstable because of the particularity of seabed terrain. Here, a new approach of seabed terrain matching algorithm was proposed. It used the mean Hausdorff distance as similarity measure for its great anti-interference performance and fault-tolerance performance. As to searching strategy, particle swarm optimization algorithm was used to achieve high searching speed. The experiments of seabed terrain match based on electronic chart confirmed the effectiveness of the proposed approach. The algorithm was robust, and reduced the calculation Complexity greatly. The positioning accuracy had been increased by 20% at least.	algorithm;computational complexity theory;control theory;experiment;fault tolerance;hausdorff dimension;interference (communication);mathematical optimization;particle swarm optimization;robustness (computer science);similarity measure;terrain rendering	Gannan Yuan;Jialin Tan;Liqiang Liu;Yang Song	2009	2009 International Joint Conference on Computational Sciences and Optimization	10.1109/CSO.2009.312	mobile robot;algorithm design;hausdorff distance;computer vision;mathematical optimization;fault tolerance;simulation;computer science;artificial intelligence;mathematics;motion planning;accuracy and precision;particle swarm optimization;statistics	Robotics	54.86682172626434	-33.55106290593243	114721
9a2ded03323843f1ad7d4f28296bb0557772849f	integrating orientation constraints into the attractor dynamics approach for autonomous manipulation	humanoid robot;attractor dynamics approach;grasping;humanoid robot autonomous manipulation autonomous robots obstacle avoidance gripper attractor dynamics approach dynamic contribution component movement manipulation task;mobile robots grippers humanoid robots manipulator dynamics;dynamic contribution;reference frame;manipulator dynamics;dynamic system;mobile robots;joints;satisfiability;manipulation task;autonomous robots;obstacle avoidance;humanoid robots;autonomous manipulation;robots;grippers;component movement;neurons;gripper;vector field;switches;joints robots neurons grasping vehicle dynamics containers switches;vehicle dynamics;autonomous robot;containers	When autonomous robots generate behavior in complex environments they must satisfy multiple different constraints such as moving toward a target, avoidance of obstacles, or alignment of the gripper with a particular orientation. It is often convenient to represent each type of constraint in a specific reference frame, so that the satisfaction of all constraints requires transformation into a shared base frame. In the attractor dynamics approach, behavior is generated as an attractor solution of a dynamical system that is formulated in such a base frame to enable control. Each constraint contributes an attractive (for targets) or repulsive (for obstacles) component to the vector field. Here we show how these dynamic contributions can be formulated in different reference frames suited to each constraint and then be transformed and integrated within the base frame. Building on earlier work, we show how the orientation of the gripper can be integrated with other constraints on the movement of the manipulator. We also show, how an attractor dynamics of “neural” activation variables can be designed that activates and deactivates the different contributions to the vector field over time to generate a sequence of component movements. As a demonstration, we treat a manipulation task in which grasping oblong cylindrical objects is decomposed into an ensemble of separate constraints that are integrated and resolved using the attractor dynamics approach. The system is implemented on the small humanoid robot Nao, and illustrated in two exemplary movement tasks.	activation function;autonomous robot;dynamical system;experiment;humanoid robot;nao (robot);oblong industries;reference frame (video);robot end effector;spatial reference system	Hendrik Reimann;Ioannis Iossifidis;Gregor Schöner	2010	2010 10th IEEE-RAS International Conference on Humanoid Robots	10.1109/ICHR.2010.5686349	computer vision;simulation;computer science;humanoid robot;artificial intelligence	Robotics	62.25641942801863	-24.41137382593678	114802
bc27d6b2d57c58fc01b8a80276856b7fa9d28379	feasible pattern generation method for humanoid robots	humanoid robot;legged locomotion;pattern generation;foot;joints;satisfiability;method integration;feasible pattern generation method;trajectory;humanoid robots;parameter tuning;humanoid robots joints kinematics legged locomotion humans robotics and automation collision avoidance motion detection computer graphics intelligent systems;stiffness varying constraint feasible pattern generation method humanoid robots parameter tuning;stiffness varying constraint;leg	This paper proposes a feasible pattern generation method for humanoid robots. One of the difficulties in pattern generation for humanoid robots is that generated patterns must satisfy many constraints such as physical limits, self-collision and so on to be feasible in addition to constraints to achieve a specified task. In reality, some of these constraints are not often taken into account during the pattern generation and they are just checked afterwards and unsatisfied constraints are fixed by hand. It is not easy to find a parameter set to get a feasible motion for humanoid robot and these pattern generators need to be used carefully when they are used online. The proposed method integrates the feasibility constraints into the pattern generation algorithm and enables to use it online more safely and releases human from parameter tuning. Moreover, a stiffness varying constraint is introduced to improve the feasibility.	algorithm;humanoid robot	Fumio Kanehiro;Wael Suleiman;Kanako Miura;Mitsuharu Morisawa;Eiichi Yoshida	2009	2009 9th IEEE-RAS International Conference on Humanoid Robots	10.1109/ICHR.2009.5379520	simulation;computer science;humanoid robot;artificial intelligence;control theory	Robotics	64.67294646358393	-23.988109100101696	114916
bd8ad4821b7157f1532551c7a2f6c8c1c71d93fb	improved control of visually observed robotic agents based on autoregressive model prediction	vision system;robot sensing systems;agent based;parameter estimation mobile robots multi robot systems multi agent systems transient response robot vision position control navigation autoregressive processes;autoregressive model prediction;time delays;delay effects;mobile robots;parameter estimation autoregressive model prediction multiple robotic agents centralized control global vision system position control orientation time delays transient response mobile robots;orientation;time delay;autoregressive model;navigation;multi agent systems;transient response;robot vision;robot control;autoregressive processes;position control;multiple robotic agents;machine vision;multi robot systems;predictive models;centralized control;parameter estimation;global vision system;modeling methodology;predictive models robot kinematics robot vision systems delay effects mobile robots robot sensing systems robot control centralized control machine vision cameras;robot vision systems;cameras;robot kinematics	Recent investigation on the cooperation of multiple robotic agents with centralized control, has ushered in small and less sophisticated robots that are observed by a global vision system. This paper presents a modeling methodology that enables accurate prediction of such small robot's position and orientation from data measured using the global vision system. Results of several experiments show that the predictions of the model can be used to compensate time delays and improve the transient response of the robots.	autoregressive model;centralized computing;experiment;external vision system;input/output;mathematical model;mobile robot	Guilherme A. S. Pereira;Mario Fernando Montenegro Campos;Luis Antonio Aguirre	2000		10.1109/IROS.2000.894671	control engineering;mobile robot;computer vision;navigation;simulation;machine vision;computer science;engineering;artificial intelligence;robot control;predictive modelling;orientation;autoregressive model;estimation theory;transient response;robot kinematics	Robotics	60.41373093163405	-31.547094516903943	115725
56ef82803e8fa604aa3ef7ce92d717b99adad1a4	extraction of candidate points for a destination estimation method based on behavior dynamics	evaluation function;trajectory legged locomotion collision avoidance regression analysis availability safety;legged locomotion;estimation method;availability;robots trajectory formation candidate points extraction destination estimation method;path planning;candidate points extraction;mobile robots;potential field;robot dynamics gait analysis mobile robots path planning;trajectory;robots trajectory formation;safety;gait analysis;destination estimation method;regression analysis;collision avoidance;robot dynamics	For effective trajectory formation of robots, we propose a method to extract candidate points of the destination of walking people from their walking trajectories. The method is useful for setting the candidate points of the destination automatically which is necessary to estimate the pedestrians' destination. We assume that potential fields influence pedestrians. After estimating parameters of the potential fields and evaluating their minimum points, we extracted candidate points of the respective destinations of pedestrians. To estimate the parameters of the potential fields accurately, we classified data of pedestrian' walking trajectories into groups. Thereby, the trajectories leading to the same destination are gathered in one group. We designed an evaluation function that indicates the conformity between the trajectory and the destination to classify the data correctly. Results obtained from experiments in an actual environment to verify the availability of the proposed method show that appropriate candidate points of the destination are extracted.	conformity;estimation theory;evaluation function;experiment;robot	Yoshitaka Terada;Soichiro Morishita;Hajime Asama	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5650841	mobile robot;computer vision;availability;simulation;gait analysis;computer science;artificial intelligence;trajectory;evaluation function;motion planning;regression analysis	Robotics	54.66166277235271	-33.90423546491847	115989
9e6b0fe2a6a3f61252a24bf9c171de8a181650e6	a relnav enhancement for reducing cumulative position error in link-16 without gru	time measurement;jamming;estimation;global positioning system;signal processing;position measurement	Position information is important for conducting battlefield missions. GPS generally enables allies to identify positions. RELNAV defined in Link-16 is used for JU in the air to estimate its position as an auxiliary navigation system of GPS. However, there is a critical problem in RELNAV. To operate accurately, RELNAV requires the presence of ground reference units that help to estimate the positions of JUs operated by RELNAV. However, guaranteeing the constant presence of ground reference units in a battlefield is difficult. If the presence of ground reference units is not assured, JUs operated by RELNAV have a critical problem in maintaining high positional quality. They depend on inertial navigation systems that can accumulate positional errors with time. In this environment, such errors will become large, and hence maintaining accurate operation of RELNAV is difficult. Therefore, we propose an alternative that can solve such problems. In the proposed scheme, we select new references that can play the role of GRU in RELNAV among allies conducting operations on the ground. The new references are responsible for estimating the positions of JUs. To do so optimally, a JU uses a reference selection algorithm that assures high quality of dilution of precision between the JU and the new references. Position errors of JUs decrease largely as a result of the presence of new references in the proposed scheme. RELNAV can therefore be conducted with higher positional accuracy of JUs than that of the existing RELNAV. We verify through some simulations that the feasibility and performance of the proposed scheme are better than those of the existing scheme.	dilution of precision (computer graphics);display resolution;global positioning system;inertial navigation system;radio jamming;selection algorithm;simulation	Kihyoung Kim;Kyuman Lee;Jaesung Lim	2016	MILCOM 2016 - 2016 IEEE Military Communications Conference	10.1109/MILCOM.2016.7795451	simulation;telecommunications;engineering;operations management	Visualization	54.60857214922363	-27.10959486858192	116063
9c89ab68e5db5959f5eb8a1b7fd26f5683173d24	validation of underwater sensor package using feature based slam	vision range finder;slam;fastslam;ekf slam;vision odometry;underwater range finder	Robotic vehicles working in new, unexplored environments must be able to locate themselves in the environment while constructing a picture of the objects in the environment that could act as obstacles that would prevent the vehicles from completing their desired tasks. In enclosed environments, underwater range sensors based off of acoustics suffer performance issues due to reflections. Additionally, their relatively high cost make them less than ideal for usage on low cost vehicles designed to be used underwater. In this paper we propose a sensor package composed of a downward facing camera, which is used to perform feature tracking based visual odometry, and a custom vision-based two dimensional rangefinder that can be used on low cost underwater unmanned vehicles. In order to examine the performance of this sensor package in a SLAM framework, experimental tests are performed using an unmanned ground vehicle and two feature based SLAM algorithms, the extended Kalman filter based approach and the Rao-Blackwellized, particle filter based approach, to validate the sensor package.	algorithm;amiga reflections;closure;drug vehicle;ekf slam;extended kalman filter;greater than;internationalization and localization;motion estimation;particle filter;physical object;slamf1 gene;sensor web;simultaneous localization and mapping;speech acoustics;telecommunications network;unmanned aerial vehicle;visual odometry;sensor (device)	Chris Cain;Alexander Leonessa	2016	Sensors	10.3390/s16030380	embedded system;computer vision;simulation;engineering	Robotics	55.29014013775794	-35.57032320509867	116088
30defe9511889a6e07566c4049235105d06962f0	wheeled mobile robots navigation from a visual memory using wide field of view cameras	robot sensing systems;mobile robots robot sensing systems robot kinematics;visual path following control scheme;path planning;robot vision cameras mobile robots path planning;mobile robots;translational velocity;translational velocity wheel mobile robot navigation epipolar geometry visual memory cameras visual path following control scheme;unified model;epipolar geometry;wheeled mobile robot;robot vision;wheel mobile robot navigation;field of view;visual memory;path following;cameras;robot kinematics	In this paper, we propose a visual path following control scheme for wheeled mobile robots based on the epipolar geometry. The control law only requires the position of the epipole computed between the current and target views along the sequence of a visual memory. The proposed approach has two main advantages: explicit pose parameters decomposition is not required and the rotational velocity is smooth or eventually piece-wise constant avoiding discontinuities that generally appear when the target image changes. The translational velocity is adapted as required for the path and the approach is independent of this velocity. Furthermore, our approach is valid for all cameras obeying the unified model, including conventional, central catadioptric and some fisheye cameras. Simulations as well as real-world experiments with a robot illustrate the validity of our approach.	epipolar geometry;experiment;fisheye;mobile robot;obedience (human behavior);optimal control;simulation;unified model;velocity (software development)	Héctor M. Becerra;Jonathan Courbon;Youcef Mezouar;Carlos Sagüés	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5650114	control engineering;mobile robot;computer vision;simulation;field of view;visual memory;computer science;artificial intelligence;unified model;motion planning;robot kinematics;epipolar geometry	Robotics	60.41477899655192	-31.805026498419526	116739
2447fba51e6257983959305881bbd56ed0688f08	3d position sensing using the differences in the time-of-flights from a wave source to various receivers	robot sensing systems;3d position sensing;vibration analysis;time of flight;autonomous guided vehicle;tracking navigation position control robots;environmental conditions;virtual reality;robot navigation;mobile robots;time of flights;robotics;remotely operated vehicles;wave source;indexing terms;orbital robotics;triangulation 3d position sensing time of flights wave source robotics navigation autonomously guided vehicles object tracking vibration analysis;navigation;position control;speed of sound;space technology transmitters robustness robot sensing systems robot kinematics orbital robotics navigation remotely operated vehicles mobile robots virtual reality;robots;object tracking;transmitters;robustness;space technology;triangulation;autonomously guided vehicles;tracking;robot kinematics	This paper presents a novel formulation for the estimation of the coordinates of a wave source based on the differences in the time-of-flights from a single transmitter to various receivers fixed in 3D space. The formulation is closed form linear, and estimates the speed of sound at every ranging operation. This leads to a robust system that is insensitive to changes in the environmental conditions. Typical applications that will benefit from this technology are 3D position sensing systems that may be used in robotics, navigation of autonomously guided vehicles, tracking of objects for virtual reality cells, and vibration analysis.		Ajay Mahajan;Maurice Walworth	2001	IEEE Trans. Robotics and Automation	10.1109/70.917087	speed of sound;remotely operated underwater vehicle;robot;control engineering;mobile robot;computer vision;transmitter;navigation;time of flight;simulation;index term;triangulation;computer science;engineering;artificial intelligence;vibration;video tracking;virtual reality;tracking;space technology;robotics;robot kinematics;robustness	Robotics	55.185025849741	-35.767145998730165	116876
40122c9821e34fa82e1e45dce1973166c1fe42a2	design and development of an automated band wrapper robot for grapevine pest control	robot sensing systems;band barrier automated band wrapper robot grapevine pest control organic requirements wine industry autonomous vehicle;manipulators;autonomous vehicle;design and development;degree of freedom;real time;pest control;mobile robots;grapevine pest control;springs;pipelines;band barrier;robots;spirals;organic requirements;robotics and automation pipelines pest control remotely operated vehicles service robots wine industry prototypes mobile robots automatic control kinematics;automated band wrapper robot;inverse kinematics;agriculture;wine industry;wine industry mobile robots pest control	With a view toward enhancing pest control and achieving organic requirements in wine industry, development of a prototypical autonomous vehicle that automatically applies a band barrier on grapevine is detailed in this paper. A novel band wrapper mechanism is proposed in this work. The band wrapper serving as the carrier for pest control is applied by the vehicle's six-degree-of-freedom articulator real-time controlled through classical inverse kinematics. It is found in the laboratory that the automated band wrapper robot can successfully detect a rod-like object and optimally place the band wrapper on the desired location for pest control.	algorithm;autonomous robot;autonomous system (internet);feedback;inverse kinematics;prototype;real-time clock;real-time locating system;requirement;set packing;wrapping (graphics)	Todd Lee;Scott Hudson;Jen-Yuan Chang	2000	2009 4th International Conference on Autonomous Robots and Agents	10.1109/ICARA.2000.4803971	agriculture;simulation;computer science;artificial intelligence;inverse kinematics;pest control	Robotics	65.0075281023039	-28.098221607807364	116993
040dfda3c0321def493cb3cddb90900420cd9a34	a reconfigurable fpga framework for data fusion in uav's.	noise figure;uav onboard navigational system;accelerometer data;field programmable gate arrays accelerometers global positioning system sensor fusion frequency helicopters fuses sensor systems stability unmanned aerial vehicles;sensor fusion field programmable gate arrays global positioning system kalman filters remotely operated vehicles;low frequency;absolute gps location data;degree of freedom;noise figures;low frequency stability;accelerometer data reconfigurable fpga framework field programmable gate arrays data fusion reconfigurable helicopter platform autonomous flight absolute gps location data kalman filter low frequency stability three degree of freedom tracking uav onboard navigational system sensor data data rates noise figures;kalman filters;autonomous flight;kalman filter;data rates;remotely operated vehicles;data fusion;reconfigurable fpga framework;global positioning system;sensor data;reconfigurable helicopter platform;navigation system;velocity estimation;sensor fusion;field programmable gate arrays;accelerometers;high frequency;hardware;three degree of freedom tracking	This paper presents the results of an effort to develop a reconfigurable helicopter platform capable of autonomous flight using a reconfigurable FPGA Framework to fuse the data from sensors, Readings from accelerometer and absolute GPS Location data is fused using Kalman filter to combine the low frequency stability of GPS systems with the high frequency tracking of accelerometers thus achieving stable static and dynamic three-degree-of-freedom tracking for the use of an UAV onboard navigational system. The sensor data can have different data rates and noise figures. Simulation was done on data fusion of noisy GPS and accelerometer data using Kalman filter. The results showed the data fusion of the sensors gives a better positional and velocity estimates decreasing the average errors of positional and velocity estimates by more than 50%. More over the fused data does not accumulate error over time, as compared to positional and velocity estimates obtained earlier.	autonomous robot;field-programmable gate array;frequency drift;global positioning system;kalman filter;sensor;simulation;unmanned aerial vehicle;velocity (software development)	S. Veera Ragavan;Velappa Ganapathy;E. Xian	2009	2009 World Congress on Nature & Biologically Inspired Computing (NaBIC)	10.1109/NABIC.2009.5393662	kalman filter;embedded system;computer science;machine learning;sensor fusion	Robotics	56.51229396339706	-35.173468083393416	117007
8b1eb97a3c948d48e8f258c079e71b8dd5a83848	increasing safety of bomb disposal missions: a body sensor network approach	biomedical monitoring;systeme temps reel;modelizacion;body temperature;explosion protection;red sin hilo;thermal sensation modeling;correlacion;unfolding;reseau capteur;ejercicio fisico;safety clothing;peso;metrologia;thermal variation;body sensor networks;cooling system actuation;measurement;fisiologia;fuente calor;high temperature;reseau sans fil;cuerpo;securite;deploiement;weapons body sensor networks temperature sensors biomedical monitoring skin cooling protection health and safety remote monitoring thermal conductivity;surveillance;wireless network sensing system;etude experimentale;heat source;body;real time;skin;multipoint temperature data;temperature control;temperature sensors;wireless network;wireless sensor networks armour explosion protection military equipment sensor fusion temperature control;ecoulement air;military equipment;despliegue;variation thermique;telecommunication network;protective suit;metrologie;fusion capteur;data fusion;thermal sensation model;cooling system actuation bomb disposal mission safety body sensor network physiological monitoring health information fusion remote alerts protective suit body temperature sensor fusion multipoint temperature data thermal sensation model multisite skin measurement wireless network sensing system;vetement protection;metrology;alta temperatura;air flow;transfert chaleur;physiologie;modelisation;protection;physiology;vigilancia;red sensores;weight;monitoring;health information fusion;medida;bomb disposal mission safety;red telecomunicacion;variacion termica;fusion donnee;health information;poids;heat transfer;health and safety;temps reel;safety;fluctuation temperature;reseau telecommunication;transferencia termica;sensor array;first responder;haute temperature;corps;temperature fluctuation;thermal conductivity;tiempo real;source chaleur;flujo aereo;fluctuacion temperatura;remote alerts;real time system;sistema tiempo real;remote monitoring;mesure;monitorage;core temperature;correlation;sensor fusion	During manned bomb disposal missions, the combination of the protective suit's weight (37 kg), physical activity, high ambient temperatures, and restricted airflow can cause the operative's temperature to rise to dangerous levels during missions, impairing their physical and mental ability. This work proposes to use body sensor networks (BSNs) to increase the safety of operatives in such missions through detailed physiological monitoring, fusion of health information, and remote alerts. Previous trials conducted by the authors have shown no correlation between the suit wearer's temperature at any single skin site and their core temperature, nor between single-point temperature variations and subjective thermal sensation. This paper reports on the development of a wearable, wireless, networked sensing system suitable for integration within the suit and deployment in manned missions. A sensor fusion and modeling approach is proposed that estimates the overall thermal sensation of the suit wearer, in real time, based on the multipoint temperature data. Zhang's thermal sensation model was used in this work. Modeling is performed locally to enable cooling system actuation, provide local feedback, and accommodate application specific constraints. Experimentation with the prototype confirms the importance of multisite skin measurement, timely cooling actuation, and monitoring the operative's thermal state. Evaluation of Zhang's model highlights the need for a bespoke model to account for suit and mission specific factors. The deployed BSN has been evaluated through experimental trials using a number of subjects in mission-like conditions and has been shown to be appropriate for the target application.	application domain;autonomous robot;bespoke;coat of arms;computer cooling;control system;experiment;information extraction;mission control;modal logic;multipoint ground;poor posture;prototype;real-time locating system;sampling (signal processing);sensor;software deployment;user experience;wearable computer	Elena I. Gaura;James Brusey;John Kemp;C. Douglas Thake	2009	IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)	10.1109/TSMCC.2009.2022403	human body temperature;simulation;real-time operating system;telecommunications;computer science;sensor fusion;occupational safety and health	Mobile	65.91505004982368	-34.52413986850861	117054
f8675a7b17707973534ff3920e54741b786099e5	fuzzy decentralized sliding-mode control of a car-like mobile robot in distributed sensor-network spaces	charge coupled image sensors;ccd camera;control systems;velocity control;fuzzy sliding mode control;personal computer;and forward;trajectory planning;reference trajectory;mobile robot;forward backward velocity;fuzzy control sliding mode control mobile robots trajectory charge coupled devices charge coupled image sensors velocity control control systems robot vision systems cameras;fuzzy control;mobile robots;variable structure systems;car like mobile robot;dc motor;charge coupled devices;distributed charge coupled device cameras;distributed sensor network spaces;ccd image sensors;digital signal processor fuzzy decentralized sliding mode control car like mobile robot distributed sensor network spaces trajectory tracking dynamic obstacle avoidance distributed charge coupled device cameras reference trajectory steering angle forward backward velocity upper bound;input output;distributed sensors;upper bound;control system;trajectory;decentralised control;obstacle avoidance;fuzzy decentralized sliding mode control;dynamic positioning;dynamic obstacle avoidance;decentralized control;mathematical model;digital signal processor;variable structure systems ccd image sensors collision avoidance decentralised control distributed sensors fuzzy control mobile robots;charged couple device;collision avoidance;trajectory tracking;steering angle;distributed sensor network;trajectory planning car like mobile robot decentralized control distributed sensor network spaces fuzzy sliding mode control;robot vision systems;cameras;sliding mode control	In this paper, the trajectory tracking and (dynamic) obstacle avoidance of a car-like mobile robot (CLMR) within distributed sensor-network spaces via fuzzy decentralized sliding-mode control (FDSMC) is developed. To implement trajectory tracking and (dynamic) obstacle avoidance, two distributed charge-coupled device (CCD) cameras are set up to realize the dynamic position of the CLMR and the obstacle. Based on the control authority of these two CCD cameras, a suitable reference trajectory including desired steering angle and forward-backward velocity for the proposed controller of the CLMR is planned. It is also transmitted to the CLMR by a wireless module. The proposed FDSMC can track a reference trajectory without the requirement of a mathematical model. Only the input-output data pairs of the CLMR and the upper bound of its dynamics are required for the selection of suitable scaling factors. The proposed control system includes two processors with multiple sampling rates. One is a personal computer employed to obtain the image of the CLMR and the obstacle, to plan a reference trajectory for the CLMR, and then to transmit the planned reference trajectory to the CLMR. The other is a digital signal processor (DSP) implementing in the CLMR to control two dc motors. Finally, a sequence of experiments is carried out to confirm the performance of the proposed control system.	central processing unit;charge-coupled device;coefficient;control system;control theory;database normalization;digital signal processor;emoticon;experiment;image scaling;internationalization and localization;mathematical model;mobile robot;obstacle avoidance;personal computer;sampling (signal processing);sensor;signal processing;spaces;velocity (software development)	Chih-Lyang Hwang;Nai-Wen Chang	2008	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2006.889935	mobile robot;computer vision;computer science;control system;artificial intelligence;control theory;charge-coupled device	Robotics	60.43163248617281	-30.060973128297306	117109
ed63fcf7e8829ae1fea3d6779e4e84cc0262b8ff	mobile robot with following and returning mode	robot vision cameras mobile robots;mobile robot;mobile robots;target object;returning mode;monocular camera;robot vision;mobile robots legged locomotion robotics and automation robot vision systems cameras wheelchairs medical robotics indoor environments human robot interaction mobile communication;image edge detection;following mode;indoor environment;pixel;region extraction method mobile robot following mode returning mode indoor environment monocular camera target object;region extraction method;robot vision systems;cameras;extraction method;robot kinematics	This paper proposes the mobile robot embedded two functions, the following function and returning function in the indoor environment with monocular camera. In the following mode, the robot follows the target object such as the person who walks in front of robot, and runs until reaching his destination. To follow him, the region extraction method is applied. Furthermore, the robot records the running route. In the returning mode, the robot runs by tracing the recorded route. We developed the mobile robot based on the electronic wheelchair and carried out some experiments. As the result, we confirm that our robot runs both following and returning mode by satisfactory performance.	embedded system;experiment;mobile robot;usability	Naoki Tsuda;Shuji Harimoto;Takeshi Saitoh;Ryosuke Konishi	2009	RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2009.5326252	mobile robot;embedded system;computer vision;bang-bang robot;simulation;computer science;artificial intelligence;mobile robot navigation	Robotics	59.612774906020775	-30.322608364450616	117168
516138345766d4d7eb9c3c429664eb9a9f9b9505	force reflection for ground control of space robots	predictive simulation space robots force reflecting hand controllers continuous teleoperation operator performance time delays japanese engineering test satellite 7 ets 7 predictive display;reflection force control robot control orbital robotics space technology delay effects robotics and automation satellites displays robot sensing systems;time delay;force feedback;digital simulation aerospace robotics telerobotics force feedback delays;space robotics;aerospace robotics;telerobotics;digital simulation;delays	Ideas for improving continuous teleoperation and operator performance despite time delays using force-reflecting hand controllers. They have been tested on the Japanese Engineering Test Satellite-7 (ETS-7). Predictive display and predictive simulation are used.	robot	Luis F. Peñín;Kohtaro Matsumoto;Sachiko Wakabayashi	2000	IEEE Robot. Automat. Mag.	10.1109/100.894033	telerobotics;control engineering;simulation;computer science;engineering;artificial intelligence;control theory;haptic technology	Robotics	62.63393046165674	-29.409925107220154	117231
c425d21e8915297baf602e15db059c5bf7946c35	dynamic positioning of idle automated guided vehicles	mobile robot;control problem;dynamic positioning;automated guided vehicle	An automated guided vehicle (AGV) is a mobile robot commonly used to carry loads in material handling systems (MHS). Once a transfer is completed, an AGV stops at a home position, a point where it can park until it is assigned a new task. Determining the home positions is an important control problem with a direct in ̄uence on the overall performance of the MHS. The problem can be viewed as a location-allocation problem on a network. In this paper two fast and effective heuristics which dynamically determine the home positions are proposed. The methods were tested using two real-world instances. The obtained results are shown and discussed.	algorithm;computation;heuristic (computer science);location-allocation;material handling;mobile robot;parallel redundancy protocol;simulation	Giuseppe Bruno;Gianpaolo Ghiani;Gennaro Improta	2000	J. Intelligent Manufacturing	10.1023/A:1008947018074	mobile robot;embedded system;simulation;computer science;engineering;artificial intelligence;dynamic positioning	Robotics	58.81771732909953	-26.376394038108703	117297
78bbfb5952bebd90b5ec73b8d0c06da76fb06ee5	landmark recognition for autonomous navigation using odometric information and a network of perceptrons	navegacion;robot movil;error medida;reseau information;arquitectura red;measurement error;odometer;autonomous system;real time;mesure position;robotics;autonomous mobile robot;architecture reseau;information network;sistema autonomo;medicion posicion;odometre;erreur mesure;navigation;robot mobile;systeme autonome;position measurement;robust method;robotica;autonomous navigation;network architecture;robotique;perceptron;reseau neuronal;red neuronal;moving robot;odometro;red informacion;neural network	In this paper two methods for the detection and recognition of landmarks to be used in topological modeling for autonomous mobile robots are presented. The first method is based on odometric information and the distance between the estimated position of the robot and the already existing landmarks. Due to significant errors arising in the robot’s position measurements, the distance-based recognition method performs quite poorly. For such reason a much more robust method, which is based on a neural network formed by perceptrons as the basic neural unit is proposed. Apart from performing very satisfactorily in the detection and recognition of landmarks, the simplicity of the selected ANN architecture makes its implementation very attractive from the computational standpoint and guarantees its application to real-time autonomous navigation.	artificial neural network;autonomous robot;mobile robot;perceptron;real-time clock	Javier de Lope Asiaín;Darío Maravall Gómez-Allende	2001		10.1007/3-540-45723-2_54	computer vision;navigation;simulation;network architecture;computer science;autonomous system;artificial intelligence;perceptron;machine learning;robotics;odometer;artificial neural network;observational error	Robotics	57.01302621491698	-33.082410536597294	117307
83f18e9e8f857277c41720a2aa13e7f836ca7d31	acoustic target impact point identification system		This paper proposes a new target impact point estimation system using acoustic sensors. The proposed system estimates projectile trajectory where it hits a target plane by detecting shock wave created by the passage of a supersonic projectile near the target. The method first measures TDOA (Time Delay Of Arrival) of the shock wave from the two sets of acoustic sensors of the equilateral triangular shape arranged horizontally under the target. Then the acoustic hit coordinate on the target is calculated using triangulation method. The performance of the proposed algorithm was confirmed by comparing the actual impact point with the estimated coordinates of the impact point calculated by proposed algorithm through the actual shooting experiments.	acoustic cryptanalysis;algorithm;experiment;futures studies;microphone;multilateration;optic axis of a crystal;sensor;triangulation (geometry)	Hyun S. Lee;J. S. Won;K. S. Park;Meong Cheol Shin;D. Y. Sun;Sun Hur;E. J. Lee	2017	2017 4th International Conference on Systems and Informatics (ICSAI)	10.1109/ICSAI.2017.8248444	equilateral triangle;control theory;multilateration;computer science;shock wave;supersonic speed;point estimation;projectile;triangulation (social science);trajectory of a projectile	Robotics	59.25965164697881	-37.19503629442709	117331
b0147f068c1e083db0501f5b23e5673b5b3982cc	a parameterized geometric magnetic field calibration method for vehicles with moving masses with applications to underwater gliders	preprint	The accuracy of magnetic measurements performed by autonom ous vehicles is often limited by the presence of moving ferrous masse s. This work proposes a third order parameterized ellipsoid calibration method f or magnetic measurements in the sensor frame. In this manner the ellipsoidal calibrat on coefficients are dependent on the locations of the moving masses. The parameterize d calibration method is evaluated through field trials with an autonomous underwate r glider equipped with a low power precision fluxgate sensor. These field trials were p formed in the East Arm of Bonne Bay, Newfoundland in December of 2013. During th ese trials a series of calibration profiles with the mass shifting and balla st mechanisms at different locations were performed before and after the survey portio n of the trials. The nominal ellipsoidal coefficients were extracted using the full set of measurements from a set of calibration profiles and used as the initial condition s for the third order polynomials. These polynomials were then optimized using a grad ient descent solver resulting in a RMS error between the calibration measuremen ts and the local total field of 28 nT and 17 nT for the first and second set of calibratio n runs. When the parameterized coefficients are used to correct the magnetic m asurements from the survey portion of the field trials the RMS error between the su rvey measurements and the local total field was 124 nT and 69 nT when using the first and second set of coefficients.	autonomous robot;coefficient;glider (conway's life);gradient;initial condition;newton's method;polynomial;solver	Brian Claus;Ralf Bachmayer	2017	J. Field Robotics	10.1002/rob.21660	simulation;chemistry;engineering;electrical engineering;preprint;mechanical engineering	Robotics	56.02087301292814	-35.16063716027056	117346
aef877c2bbb75e841e067c01b5536ec8ed6c3b82	vision-based vehicle body slip angle estimation with multi-rate kalman filter considering time delay	motion control;image processing;sensors;estimation method;kalman filters;kalman filter;image sensors;time delay;power engineering computing;feedback;visual modeling;estimation;roads;power engineering computing delays electric vehicles feedback image processing image sensors kalman filters;electric vehicles;mathematical model;vehicles mathematical model kalman filters cameras sensors roads estimation;vehicles;image processing techniques vision based vehicle body slip angle estimation multirate kalman filter time delay vehicle motion control estimation methods gyro sensor encoder camera ev electric vehicle short control period fast signal feedback sampling rate;real time image processing;electric vehicle;high performance;cameras;delays	Body slip angle is one of the most important information for vehicle motion control; as specific sensors for body slip angle measurement are expensive, it is necessary to investigate estimation methods using existing popular sensors such as gyro sensor, encoder, camera, etc. For EV (electric vehicle), in particular, the motor response is several milliseconds which enables high performance control with short control period; fast signal feedback is consequently desired. Nevertheless, the sampling rate of a normal camera is much slower compared with other kinds of onboard sensors and the time delay caused by image processing cannot be neglected. In this paper, the two problems are solved using a multi-rate Kalman filter with measurement delay included; the estimated body slip angle can be updated every 1 ms. First of all, vehicle model and visual model are explained followed with experimental setup introduction; then, real-time image processing techniques are briefly introduced; and then, single-rate and multi-rate Kalman filters considering time delay are designed to estimate body slip angle; finally, conclusion and further works are presented.	broadcast delay;encoder;extended validation certificate;fault detection and isolation;fault tolerance;gyro;image processing;kalman filter;real-time clock;real-time locating system;regular expression;sampling (signal processing);sensor;spectral density estimation;visual modeling	Yafei Wang;Binh Minh Nguyen;Hiroshi Fujimoto;Yoichi Hori	2012	2012 IEEE International Symposium on Industrial Electronics	10.1109/ISIE.2012.6237314	control engineering;simulation;engineering;control theory	Robotics	57.75895719797674	-35.13826118124963	117803
23157fad3be8807ac9594cb9733ad3aec4756246	vision-based target three-dimensional geolocation using unmanned aerial vehicles		This paper develops a method of calculating the three-dimensional (3-D) coordinates of a target with image information taken from an unmanned aerial vehicle (UAV). Unlike the usual approaches to target geolocation that rely heavily on georeferenced terrain database or accurate attitude sensors, the contribution of the proposed method is to offset the constraints and also perform 3-D geolocation of the target based on the relative altitude between the aircraft and the target calculated using the stereo vision technique. Considering the poor performance of the yaw-angle measurement provided by the low-quality attitude sensors in the UAV, a novel vision-based 3-D geolocation method is designed. The proposed method is proven to be valid and practical via simulation results and actual flight experiments.	aerial photography;experiment;geolocation;sensor;simulation;stereopsis;unmanned aerial vehicle;yaws	Lele Zhang;Fang Deng;Jie Chen;Yingcai Bi;Swee King Phang;Xudong Chen;Ben M. Chen	2018	IEEE Transactions on Industrial Electronics	10.1109/TIE.2018.2807401	computer vision;control engineering;terrain;offset (computer science);georeference;geolocation;engineering;artificial intelligence;altitude	Robotics	54.6645273688654	-37.12988569767562	117817
6a11f32e641114e96e3c6fd0efc3d3f2e972b85b	study on whole body motion planner of humanoid robot		In this paper, whole-body motion planner of humanoid robot based on real time path planner and self-collision detection is proposed.	collision detection;humanoid robot	Hwan-Joo Kwak;Dong Won Kim	2017	2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2017.7992739	humanoid robot;planner;simulation;computer vision;kinematics;artificial intelligence;computer science	Robotics	58.58772324528782	-30.52422973986184	117920
80fbc736fc6b5a54090d989ea0557fe658d66d70	realization of the table tennis task based on virtual targets	mirror law table tennis task realization virtual targets table tennis robot flat paddle movement coordination efficient strokes stroke movement generation input output maps i o maps k d tree multidimensional tree paddle visual feedback control scheme;robot sensing systems;mirrors;table tennis task realization;virtual targets;flat paddle;aerodynamics;k d tree;i o maps;visual feedback control scheme;efficient strokes;robot kinematics robot sensing systems feedback control mirrors aerodynamics timing humans process planning training data;robot vision sport games of skill optical feedback;input output;training data;robot vision;mirror law;stroke movement generation;games of skill;paddle;input output maps;visual feedback;humans;process planning;sport;multidimensional tree;table tennis robot;feedback control;optical feedback;movement coordination;robot kinematics;timing	This paper describes how a table tennis robot with a fiat paddle coordinates its movement in order to achieve efficient strokes for any given ball. We propose a method of generating stroke movement based on virtual targets that means the point at which the ball should be struck and the paddle velocity just before hitting the ball. These targets are predicted using inputs-outputs maps implemented efficiently by means of a k-d tree (k dimensional tree). The paddle approaches these targets by using a visual feedback control scheme similar to the mirror law proposed by Koditschek. The results of the implementation are also given to show the effectiveness of the proposed method.	feedback;map;robot;velocity (software development)	Fumio Miyazaki;Masahiro Takeuchi;Michiya Matsushima;Takamichi Kusano;Takaaki Hashimoto	2002		10.1109/ROBOT.2002.1014320	paddle;computer vision;simulation;aerodynamics;computer science;engineering;artificial intelligence;sport;control theory;robot kinematics	Robotics	63.41850861589869	-24.491770022515798	117945
5623b1c1f207203f1822a77259ee05fc39ff3cc5	portable situation-reporting system by a palmtop humanoid robot for daily life	humanoid robot;reconfigurable system;intelligent robots;software system restructuring portable situation reporting system palmtop humanoid robot device distributed approach patterned processing tree structuring sensor information processing attachment mechanism;software systems;personal digital assistants humanoid robots orbital robotics robot sensing systems hardware software systems sensor systems monitoring robot control home appliances;service robots;service robots humanoid robots control engineering computing intelligent robots sensor fusion robot programming;humanoid robots;tree structure;information processing;control engineering computing;sensor fusion;robot programming	We propose the portable situation reporting system by a small robot for daily life, which demands the rapidly system reconstitution for daily life support. In this paper, we established a system by an attachment mechanism assisted the robot system based on device-distributed approach and the patterned processing by the tree structuring of sensor information processing. The attachment mechanism facilitates the hardware system reconstitution and the patterned processing simplifies the software system restructuring. We evaluated the reconfigurable system not to re-write programs and judged the effectiveness of the system by the experiments.	attachments;experiment;humanoid robot;information processing;palmtop pc;reconfigurable computing;software system	Yasumoto Ohkubo;Kei Okada;Takeshi Morishita;Masayuki Inaba;Hirochika Inoue	2004	2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)	10.1109/IROS.2004.1389966	control engineering;mobile robot;embedded system;simulation;information processing;computer science;engineering;humanoid robot;artificial intelligence;social robot;robot control;personal robot	Robotics	62.05745337053159	-27.828300382750115	118219
3edd01ddf9ff47c50dbf3a16bb2ffa09621df409	towards adaptive aircraft landing order with aircraft routes partially fixed by air traffic controllers as human intervention		This paper focuses on how cognitive loads of air traffic controllers can be reduced when optimizing both aircraft route and landing order in the airport landing problem (ALP), and proposes its method which can adaptively change the optimized aircraft landing order according to the aircraft routes partially fixed by air traffic controllers as human intervention. Though the intensive simulation on Haneda Airport in ALP, the following implications have been revealed: (1) our proposed optimization method succeeded to mostly maintain the same level of the results without fixing some of aircraft routes (i.e., the mostly same total distance of all aircrafts from the start position to the destination airport) even if air traffic controllers fixed some of aircraft routes; and (2) this result indicates that our proposed method has a great potential of reducing the cognitive loads of air traffic controllers by reducing the number of aircrafts that should be watched with fixing some of aircraft routes.		Akinori Murata;Hiroyuki Sato;Keiki Takadama	2017		10.1007/978-3-319-58524-6_33	aircraft vectoring;air traffic control;control engineering;precision approach radar;computer science;wide area multilateration	Robotics	54.761289475654735	-26.901560040409308	118454
fb44ac704722038b89d19ae2c1af1a9852bde552	study of the toes role in human walk by toe elimination and pressure measurement system	image motion analysis;measurement system;gait analysis pressure measurement pneumodynamics image motion analysis stability;stability;motion capture;pressure measurement;energy consumption;pressure distribution;gait analysis;posture stabilization pressure measurement system human walk toe elimination pressure distribution 3d motion capture system energy consumption spirometry system;pneumodynamics;humans pressure measurement legged locomotion motion measurement foot footwear robot sensing systems energy consumption energy measurement shape	In this paper, the role of the human being toe is investigated. The change of the sole pressure distribution using a sole pressure distribution measurement system and that of the toe pressure using a toe pressure measurement system at walk by the existence of a toe are investigated. In order to investigate the change of the whole walking, the affection of a walk posture using a 3D motion capture system by the existence of a toe is also measured. Furthermore, the change of the amount of energy consumption at walk by the existence of a toe is measured by a spirometry system. At last, we investigate the roles of the toe, such as, the efficiency of the big and 2nd toe, and the stabilization of the posture, by the synthesis	motion capture;poor posture;system of measurement	Hiroshi Takemura;Abdelaziz Khiat;Hiroya Iwama;Jun Ueda;Yoshio Matsumoto;Tsukasa Ogasawara	2003		10.1109/ICSMC.2003.1244270	motion capture;simulation;gait analysis;stability;pressure measurement;computer science;system of measurement;control theory;pressure coefficient	AI	67.4023722610422	-24.725347088296623	118763
1a0158b278f8e87d06d93801c0f336de9702c5fd	a measurement system for 3d hand-drawn gesture with a phantom	hand held device;inertial measurement unit;hand drawn gesture;phantom tm;calibration	"""This paper presents a measurement system for 3D hand-drawn gesture motion. Many pen-type input devices with Inertial Measurement Units (IMU) have been developed to estimate 3D hand-drawn gesture using the measured acceleration and/or the angular velocity of the device. The crucial procedure in developing these devices is to measure and to analyze their motion or trajectory. In order to verify the trajectory estimated by an IMU-based input device, it is necessary to compare the estimated trajectory to the real trajectory. For measuring the real trajectory of the pen-type device, a PHANToMTM haptic device is utilized because it allows us to measure the 3D motion of the object in real-time. Even though the PHANToMTM measures the position of the hand gesture well, poor initialization may produce a large amount of error. Therefore, this paper proposes a calibration method which can minimize measurement errors."		Seong-Young Ko;Won-Chul Bang;Sang-Youn Kim	2010	JIPS	10.3745/JIPS.2010.6.3.347	embedded system;inertial measurement unit;computer vision;calibration;simulation	HCI	57.892592019076915	-37.87601672096783	118771
80765b2d24316b4b6c66e3c85e57713b2a1772be	biologically-inspired motion pattern design of multi-legged creatures	character motion;multi legged creatures;computer animation	In this paper, we propose a novel strategy to synthesize motion patterns for multi---legged creatures inspired by the biological knowledge. To prove the concept, our framework deploys an approach of coupling the dynamics model, the Inverted Pendulum Model, and the biological controller, the Central Pattern Generator, to synthesize the motion of multiple legged creatures. The dynamics model ensures the physical plausibility and allows the virtual character to react to the external perturbations, where the biological controller coordinates the motion of several legs with designed numerical operators, providing user-friendly high---level control. This novel framework is computationally efficient by taking advantages of the self-similarity in motion and able to animate characters with different skeletons.	creatures	Shihui Guo;Safa Tharib;Jian Chang;Jian-Jun Zhang	2013		10.1007/978-3-642-36955-1_13	simulation;engineering;artificial intelligence;computer graphics (images)	Vision	65.53521425332447	-25.758107874573195	118805
049b6866d7bdb62f29d3df5239dcaa23a8e027d9	computation of configuration-space obstacles using the fast fourier transform	fast fourier transforms;path planning;robots;configuration-space obstacles;convolution;fast fourier transform;motion-planning;obstacle avoidance;parallel method;robot;fast fourier transformation;manipulator;control system;hardware;computing;motion planning;shape;planning	A method is proposed for computing the configuration-space map of obstacles. The map is used in motion-planning algorithms. The method derives from the observation that, when the robot is a rigid object that can only translate, the configuration space is a convolution of the workspace and the robot. It makes use of the fast Fourier transform (FFT) algorithm to compute this convolution. The method is particularly promising for workspaces with many and/or complicated obstacles, or when the shape of the robot is not simple. It is an inherently parallel method, and it can significantly benefit from existing experience and hardware on the FFT	computation;fast fourier transform	Lydia E. Kavraki	1993		10.1109/ROBOT.1993.292185	computer vision;fast fourier transform;mathematical optimization;computer science;control system;artificial intelligence;prime-factor fft algorithm;computer graphics (images)	Vision	60.170655501389504	-23.96070143801508	118896
4e332a76e06c9552c470557da40c97fe049e7dff	using bayesian filtering to localize flexible materials during manipulation	bayes estimation;modelizacion;propiocepcion;human like arm;methode particulaire;capteur tactile;flexible manipulators;robonaut 2;sensors;robot anthropomorphe;manipulation and compliant assembly;tactile sensor;sensor tactil;haptic map bayesian filtering flexible material localization feature manipulation fabrics load based tactile information robot manipulation robonaut 2 human like hand human like arm particle filtering tactile measurement proprioceptive measurement;force and tactile sensing;bayes methods;load based tactile information;localization;training;feature manipulation;espace etat;robot manipulation;proprioception;human like hand;bayesian methods;metodo particula;mobile robots;anthropomorphous robot;localizacion;robotics;joints;materials;bayesian method;thumb;robot manipulator;proprioceptive measurement;particle method;modelisation;haptic map;assembly;dexterous manipulators;materials training robots sensors joints thumb bayesian methods;tactile sensing;estimacion bayes;localisation;state space method;methode espace etat;particle filter;filter;local features;sensibilidad tactil;state space;robots;particle filtering;bayesian filtering;robotica;tactile sensors;filtre;fabrics;arm;montage;bras;tactile sensors bayes methods dexterous manipulators fabrics flexible manipulators haptic interfaces mobile robots particle filtering numerical methods;robot antropomorfo;brazo;robotique;montaje;tactile measurement;haptic interfaces;espacio estado;manipulation and compliant assembly force and tactile sensing localization;modeling;filtro;sensibilite tactile;tactile sensitivity;flexible material localization;particle filtering numerical methods;metodo espacio estado;estimation bayes	Localization and manipulation of features such as buttons, snaps, or grommets embedded in fabrics and other flexible materials is a difficult robotics problem. Approaches that rely too much on sensing and localization that occurs before touching the material are likely to fail because the flexible material can move when the robot actually makes contact. This paper experimentally explores the possibility to use proprioceptive and load-based tactile information to localize features embedded in flexible materials during robot manipulation. In our experiments, Robonaut 2, a robot with human-like hands and arms, uses particle filtering to localize features based on proprioceptive and tactile measurements. Our main contribution is to propose a method to interact with flexible materials that reduces the state space of the interaction by forcing the material to comply in repeatable ways. Measurements are matched to a “haptic map,” which is created during a training phase, that describes expected measurements as a low-dimensional function of state. We evaluate localization performance when using proprioceptive information alone and when tactile data are also available. The two types of measurements are shown to contain complementary information. We find that the tactile measurement model is critical to localization performance and propose a series of models that offer increasingly better accuracy. Finally, this paper explores the localization approach in the context of two flexible material insertion tasks that are relevant to manufacturing applications.	coat of arms;embedded system;experiment;haptic technology;internationalization and localization;particle filter;robonaut;robot;robotics;state space	Robert Platt;Frank Permenter;Joel Pfeiffer	2011	IEEE Transactions on Robotics	10.1109/TRO.2011.2139150	computer vision;simulation;particle filter;bayesian probability;computer science;engineering;artificial intelligence;robotics;tactile sensor	Robotics	63.951064358637765	-33.23631062096117	118915
2543ae9d00df82dc5315839058b2f1737dfd0008	underwater box-pushing with multiple vision-based autonomous robotic fish	multi robot systems image sensors;pose estimation underwater box pushing multiple vision based autonomous robotic fish market based dynamic task allocation method goal location monocular camera;market based dynamic task allocation method;robot kinematics robot vision systems collision avoidance cameras image color analysis;image sensors;monocular camera;image color analysis;multi robot systems;multiple vision based autonomous robotic fish;collision avoidance;underwater box pushing;robot vision systems;autonomous robot;cameras;goal location;task allocation;robot kinematics;pose estimation	This paper presents an underwater cooperative box-pushing scenario in which three autonomous robotic fish that sense, plan and act on their own move an elongated box from some initial location to a goal location. With the onboard monocular camera, the robotic fish can estimate the pose of the object in the swimming tank. Considering the complexity of the underwater environment and the limited capability of a single robotic fish, we address the task by decomposing it into three subtasks and assigning them to capable robotic fish. With one robotic fish observing the box at the goal location and two robotic fish pushing the left and right ends of the box, the box can be moved gradually towards the goal location. The subtask consists a series of behaviors, each designed to fulfill one step of the subtask. The robotic fish coordinate through explicit communications and distribute the subtasks with a market-based dynamic task allocation method. Task reallocation mechanism that permits robotic fish to auction its assigned task to capable ones is used to cope with unexpected changes in the environment and the limited sensing range of the robotic fish. Experiments are conducted to verify the feasibility of the proposed methods.	autonomous robot;experiment;thinking outside the box	Yonghui Hu;Long Wang;Jianhong Liang;Tianmiao Wang	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5650295	embedded system;computer vision;simulation;pose;computer science;engineering;artificial intelligence;robotic paradigms;image sensor;robot kinematics	Robotics	59.08664767158165	-31.097505893220802	118953
f6a0fe6115018b50c74c30fcb801b4ad5b2b0e74	kinematic approach for the evaluation of human visual perceptibility in the workspace	human visual perceptibility;human visual system human visual perceptibility kinematic approach image quality;visual perception ergonomics kinematics;kinematics;body size;human subjects;motion perception;human visual system;kinematic approach;image quality;field of view;visual perception;kinematics humans neck visual system image quality focusing eyes robotics and automation manufacturing automation laboratories;ergonomics;human visual perception	This paper presents a new kinematic method to evaluate the human visual perceptibility in the workspace. The results of the method determine the regions of the workspace from which human visual system (HVS) has high quality images in most of the eye and neck postures. To evaluate the image quality of points in the HVS, motion perceptibility and acuity measures are defined and computed for the points that are in the focus range and field-of-view (FOV) of the observer. Motion perceptibility in the HVS is evaluated by applying a motion resolvability concept for the first time. The perceptibility measures are averaged over all the eye poses to determine the average visual perceptibility of the human workspace. The method is implemented on a subject with average body sizes, however, it can be easily adapted to different human subjects	display resolution;human visual system model;image quality;workspace	Behdad Masih-Tehrani;Farrokh Janabi-Sharifi	2006	Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.	10.1109/ROBOT.2006.1642259	image quality;computer vision;kinematics;simulation;field of view;motion perception;visual perception;human factors and ergonomics;human visual system model;computer graphics (images)	Robotics	62.66489424629911	-31.46735938005165	118988
4f11acec93154baac5b29f5dfe28759455264dec	a new approach to visual servoing in uncalibrated environments	lyapunov methods;manipulators;image motion analysis;motion control;adaptive control visual servoing uncalibrated environments motion control robot manipulator online parameter estimation pd control gravity compensation lyapunov function asymptotic convergence asymptotic stability;lyapunov function;eye in hand uncalibrated environment visual servoing adaptive control eye and hand;adaptive control;eye in hand;visual servoing parameter estimation robot vision systems convergence motion control manipulators cameras adaptive algorithm gravity lyapunov method;asymptotic stability;robot manipulator;eye and hand;adaptive algorithm;robot vision;pd control;position control;robot vision adaptive control asymptotic stability image motion analysis lyapunov methods manipulators motion control parameter estimation pd control position control;uncalibrated environments;online parameter estimation;uncalibrated environment;asymptotic convergence;parameter estimation;gravity compensation;visual servoing	The objective of the work is to regulate selected features to desired positions on the image plane by controlling motion of a robot manipulator. We assume the system is totally uncalibrated, i.e. both the camera intrinsic parameters and the homogeneous transformation matrix between the robot frame and the vision frame are not calibrated. An adaptive algorithm is proposed to estimate the parameters online. The proposed controller adopts the simple PD plus the gravity compensation scheme with the estimated parameters. A new Lyapunov function is introduced to prove asymptotic convergence of the position errors on the image plane and convergence of the estimated parameters to the real ones up to a scale. Simulations and experiments have been carried out to verify asymptotic stability of the proposed controller	adaptive algorithm;camera resectioning;computer simulation;experiment;image plane;lyapunov fractal;online and offline;robot;servo;transformation matrix;visual servoing	Hesheng Wang;Yunhui Liu;Kinkwan Lam	2004	2004 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2004.1521844	control engineering;motion control;computer vision;adaptive control;lyapunov function;control theory;mathematics;estimation theory;visual servoing	Robotics	61.186477802092405	-31.665593401995906	119080
e4aef043c5a17e42f9cb3923e97e83ea8cd76cff	nested marsupial robotic system for search and sampling in increasingly constrained environments	chemicals;mobile robots;trajectory;planning;containers;robot kinematics	This paper presents a nested marsupial robotic system and its execution of a notional disaster response task. Human supervised autonomy is facilitated by tightly-coupled, high-level user feedback enabling command and control of a bimanual mobile manipulator carrying a quadrotor unmanned aerial vehicle that carries a miniature ground robot. Each robot performs a portion of a mock hazardous chemical spill investigation and sampling task within a shipping container. This work offers an example application for a heterogeneous team of robots that could directly support first responder activities using complementary capabilities of autonomous dexterous manipulation and mobility, autonomous planning and control, and teleoperation. The task was successfully executed during multiple live trials at the DARPA Robotics Challenge Technology Expo in June 2015. A key contribution of the work is the application of a unified algorithmic approach to autonomous planning, control, and estimation supporting vision-based manipulation and non-GPS-based ground and aerial mobility, thus reducing algorithmic complexity across this capability set. The unified algorithmic approach is described along with the robot capabilities, hardware implementations, and human interface, followed by discussion of live demonstration execution and results.	aerial photography;algorithm;autonomous robot;computational complexity theory;darpa robotics challenge;global positioning system;high- and low-level;mobile manipulator;mock object;sampling (signal processing);unmanned aerial vehicle;user interface	Joseph Moore;Kevin C. Wolfe;Matthew S. Johannes;Kapil D. Katyal;Matthew P. Para;Ryan J. Murphy;Jessica Hatch;Colin J. Taylor;Robert J. Bamberger;Edward Tunstel	2016	2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2016.7844578	planning;mobile robot;embedded system;chemical industry;simulation;computer science;artificial intelligence;trajectory;social robot;robot control;robot kinematics	Robotics	55.63647336544865	-28.7550430779122	119167
10f901d110f3c70c68918dbb5bdf35e6dfe5695a	2d mobile multi-sensor navigation system realization using fpga-based embedded processors	riss gps integration;gyroscopes;satellite based navigation system;sensors;low cost motion sensors;real time;global position system;real time embedded system;integrated navigation algorithm;fpga;embedded system;portable low cost real time embedded system;embedded systems;soft core microblaze processor;research paper;real time navigation system;sensor fusion accelerometers field programmable gate arrays global positioning system gyroscopes motion measurement;global positioning system;indoor environment;global positioning system program processors real time systems algorithm design and analysis embedded systems sensors;fpga embedded systems riss gps integration real time navigation system soft core microblaze processor;navigation system;2d mobile multisensor navigation system;sensor fusion;field programmable gate arrays;motion measurement;accelerometers;portable low cost real time embedded system 2d mobile multisensor navigation system fpga based embedded processors global positioning system satellite based navigation system integrated navigation algorithm low cost motion sensors accelerometers gyroscopes;embedded processor;program processors;algorithm design;algorithm design and analysis;fpga based embedded processors;real time systems	Global positioning system (GPS) is a satellite-based navigation system that is widely used for different navigation applications. In open-sky, GPS can provide an accurate navigation solution, however, in urban canyons and indoor environments, the satellite signals are blocked and GPS fails to provide a reliable navigation solution. Towards the search for a more accurate and low-cost positioning solution, integrated navigation algorithms are developed which utilize the measurements of low-cost motion sensors such as accelerometers and gyroscopes, and integrate them with GPS measurements to provide a reliable navigation solution. The goal of this research paper is to narrow the idea-to-implementation gap by realizing the navigation algorithm on a portable low-cost real-time embedded system. The role of such system is to acquire and synchronize the measurements from multiple sensors and then apply a navigation algorithm which integrates the various measurements to provide a reliable real-time navigation solution.	algorithm;central processing unit;embedded system;field-programmable gate array;global positioning system;real-time clock;realization (systems);sensor	Walid Farid Abdelfatah;Jacques Georgy;Umar Iqbal;Aboelmagd Noureldin	2011	2011 24th Canadian Conference on Electrical and Computer Engineering(CCECE)	10.1109/CCECE.2011.6030656	dead reckoning;air navigation;embedded system;algorithm design;receiver autonomous integrity monitoring;electronic engineering;real-time computing;time to first fix;gnss augmentation;local positioning system;computer science;engineering;mobile robot navigation;field-programmable gate array	Robotics	56.92154729508493	-34.62571729703624	119171
0e91273f7edb8e3e085a2cd66e5c1a7a8c851db9	autonomous helicopter tracking and localization using a self-surveying camera array	camera tracking;self-surveying cam- eras;camera localization;structure from motion;bundle adjustment	Summary. This paper describes an algorithm that tracks and localizes a helicopter using a ground-based trinocular camera array. The three cameras are placed indepen- dently in an arbitrary arrangement that allows each camera to view the helicopter's ∞ight volume. The helicopter then ∞ies an unplanned path that allows the cameras to self-survey utilizing an algorithm based on structure from motion and bundle adjustment. This yields the camera's extrinsic parameters allowing for real-time po- sitioning of the helicopter's position in a camera array based coordinate frame. In flelded experiments, there is less than a 2m RMS tracking error and the update rate of 20Hz is comparable to DGPS update rates. This system has successfully been integrated with an IMU to provide a positioning system for autonomous hovering.		Masayoshi Matsuoka;Alan Chen;Surya P. N. Singh;Adam Coates;Andrew Y. Ng;Sebastian Thrun	2005		10.1007/978-3-540-33453-8_3	kalman filter;computer vision;structure from motion;simulation;eye tracking;computer science;engineering;control theory;bundle adjustment	Robotics	54.91392263881492	-36.958788050265866	119246
41c35e003625e62cd3d36b32a9b9f17307a350d5	exploration and dynamic shape estimation by a robotic probe	shape estimation;metodo cuadrado menor;eficacia sistema;sistema mecanico;methode moindre carre;least squares approximations;trajectoire;robots dynamics feedback kinematics least squares approximations parameter estimation position control;least squares method;plane motion;morfoscopia;manipulateur;shape analysis;performance systeme;shape robots probes manipulator dynamics parameter estimation kinematics end effectors force feedback motion estimation solid modeling;robotics;systeme mecanique;three link planar manipulator parameter estimation kinematics dynamics motion strategy force feedback least squares approximations position control dynamic shape estimation robotic probe planar manipulator least squares estimators local sensory data end effector;system performance;kinematics;feedback;trajectory;manipulador;position control;dynamics;morphoscopie;robots;mechanical system;estimacion parametro;robotica;mouvement plan;trayectoria;robotique;parameter estimation;estimation parametre;manipulator;movimiento plano	A strategy for motion of a planar manipulator on an unknown surface is presented. To estimate a parameter vector for the surface, least-squares estimators are formulated that use both the kinematic and dynamic data available online. The authors begin with the presentation of a control strategy that uses local sensory data to guide the end effector incrementally over the surface. Force feedback is given, which is later shown to be successful in the uninterrupted maintenance of contact. Motion over the unknown shape is justified by demonstrating that a simple shape estimation algorithm can converge to give a parametric description of the surface. Geometric and differential models of the surface are presented and the estimation procedure is specified. Also presented are the results of a number of computer simulations for a three-link planar manipulator moving over an ellipse whose parameters are unknown to the controller. It is found that, in the presence of noise, dynamic data degrade the estimates. >	robot	Krishna Pribadi;John S. Bay;Hooshang Hemami	1989	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.35347	robot;dynamics;kinematics;simulation;computer science;artificial intelligence;trajectory;manipulator;shape analysis;control theory;feedback;mathematics;robotics;estimation theory;mechanical system;least squares	Robotics	61.418831453694054	-32.92569180326054	119410
c83dbe78000a637955db9caf0f43f8f908a511ef	an elastic force based collision avoidance method and its application to motion coordination of multiple robots	process variation;collision free coordination;work environment;potential field;multiple robots;motion coordination;elastic force;collision avoidance;priority;manufacturing system	A key contribution of robots to a manufacturing system is flexibility and automation. The robots can handle part batches of varying size and mix and can adapt to process variations and uncertainties in the working environment. This paper proposes a method for the collision-free motion coordination of multiple robots in a common working environment. The method uses an improved elastic force based method for collision avoidance. For the motion coordination of multiple robots, prioritisation-and-avoidance is used. Priority is assigned to each robot with a robot of lower priority avoiding the robots of higher priority. Without priority, every robot takes pains to avoid all the other robots. This degrades the overall performance of the coordinated motion. In addition, priority allows a robot with an urgent job to perform its job quicker. For collision avoidance, elastic force as well as potential field force is used. Compared with the method using only the potential field force, the robot can keep its configur...	collision detection;robot	Dong Jin Seo;Nak Yong Ko;Reid G. Simmons	2009	Int. J. Computer Integrated Manufacturing	10.1080/09511920902741083	control engineering;simulation;engineering;operations management;process variation	Robotics	63.98679679235872	-26.826520809327537	119628
dcd20c3945bc2a5bf1db76785ec636d82e7bb81a	a mechatronics approach to the design of light-weight arms and multifingered hands	robot sensing systems;mechatronics arm robot sensing systems service robots intelligent robots humans defense industry orbital robotics intelligent sensors brushless dc motors;light weight arms;design and development;intelligent robots;dexterous manipulators mechatronics state feedback;service robots mechatronics approach light weight arms multifingered hands ultra light weight robots articulated hands fully sensorized joints 4 finger hand personal robots;multifingered hands;defense industry;state feedback;service robots;orbital robotics;personal robots;dexterous manipulators;mechatronics approach;institut fur robotik und mechatronik bis 2012;arm;ultra light weight robots;humans;mechatronics;brushless dc motors;articulated hands;4 finger hand;fully sensorized joints;intelligent sensors	The paper describes recent design and development efforts in DLR's robotics lab towards a new generation of ultra-light weight robots with articulated hands. The design of fully sensorized joints with complete state feedback and the underlying mechanisms are outlined. The second light-weight arm generation is available now, as well as the second generation of a worldwide most highly integrated 4 fingerhand is available now. Thus we hope that important steps towards a new generation of service and personal robots have been achieved.	coat of arms;dynamic language runtime;mechatronics;robot;robotics;second generation multiplex plus	Gerd Hirzinger;Jörg Butterfaß;Max Fischer;Markus Grebenstein;Matthias Hähnle;Hong Liu;Ingo Schäfer;Norbert Sporer	2000		10.1109/ROBOT.2000.844038	control engineering;simulation;mechatronics;computer science;engineering;artificial intelligence;arm architecture;personal robot;intelligent sensor;mechanical engineering	Robotics	66.24094193261645	-28.06954804304287	120326
1615b5ac457307959f93854d658af2d9ba52234b	dependability evaluation of a gnss and ecs based localisation unit for railway vehicles	sensor fusion eddy currents electric sensing devices rail traffic satellite navigation;dependability evaluation global navigation satellite system eddy current sensor galoroi european project localisation system position quality railway context train localisation function localisation unit for railway vehicles ecs gnss;eddy currents;rail traffic;satellite navigation;global positioning system data models robustness lead receivers rail transportation;sensor fusion;electric sensing devices	Today, GNSS-based solutions (Global Navigation Satellite Systems) facilitate the implementation of the train localisation function on-board the vehicle. In the railway context, as a train has to travel different zones on its itinerary, multiple obstacles in these environments can cause different signal perturbations: multipaths, signal delays and masking phenomena that lead to negative consequences on the position accuracy. To reinforce the position quality, a localisation system, developed in the GaLoROI european Project and based on the combination of sensors such as a GNSS receiver and an Eddy Current Sensor, is studied. In this paper, we present a procedure and a model, which aims at evaluating the dependability of this system under local impacts of different railway environments. It allows us analysing complex behaviours of the sensor fusion component on the availability and accuracy of data provided by GNSS & ECS sub-systems and also to take into account the reliability parameters of hardware components.	algorithm;amiga enhanced chip set;causal filter;dependability;fault tree analysis;galileo (satellite navigation);numerical analysis;on-board data handling;petri net;rams;satellite navigation;sensor web;simulation;sun outage	Thi Phuong Khanh Nguyen;Julie Beugin;Juliette Marais	2013	2013 13th International Conference on ITS Telecommunications (ITST)	10.1109/ITST.2013.6685591	embedded system;electronic engineering;gnss augmentation;engineering;transport engineering	Robotics	55.31027989678847	-32.92315322076309	120358
0dd0797ede108f932ba0319dfe5438ae9cef9626	subtractive clustering as zupt detector	subtractive clustering;inertial measurement unit;polynomials computerised instrumentation micromechanical devices pattern clustering pedestrians;subtractive clustering zero velocity updates inertial measurement unit;consistent performance level subtractive clustering zupt detector inertial based indoor pedestrian tracking microelectromechanical systems technology mems positional drift zero velocity updates stance phase error growth third order polynomial publicly available datasets;zero velocity updates;acceleration accelerometers detectors legged locomotion conferences gyroscopes	Inertial-based indoor pedestrian tracking that uses Micro electro mechanical Systems (MEMS) technology suffers undesirable positional drift over time. As widely attested, zero-velocity updates (ZUPT) from the stance phase reduce the error growth from a third order polynomial to a linear one. However, researchers are struggling to find consistent ZUPT, especially when the pedestrian walks naturally, which has changes in walking speed or unpredictable pauses. In this paper, a novel approach to extract the ZUPT based on subtractive clustering is proposed and discussed. Its performance is compared to other techniques using internally collected and publicly available datasets. The results show that the proposed method outweighs the others in providing consistent performance level.	algorithm;cluster analysis;microelectromechanical systems;online and offline;polynomial;real-time clock;sensor;velocity (software development);wearable technology	Mohd Nazrin Muhammad;Zoran A. Salcic;Kevin I-Kai Wang	2014	2014 IEEE 11th Intl Conf on Ubiquitous Intelligence and Computing and 2014 IEEE 11th Intl Conf on Autonomic and Trusted Computing and 2014 IEEE 14th Intl Conf on Scalable Computing and Communications and Its Associated Workshops	10.1109/UIC-ATC-ScalCom.2014.114	embedded system;inertial measurement unit;simulation	Embedded	57.43106612757513	-37.56893901143242	120387
22795040bf9dc7b1f8cb7d22423857326969f5bb	identification and selection of sensors suitable for integration into sport equipment: smart golf club		Smart sport equipment is being increasingly used in highly competitive (professional) sport. By definition, smart equipment employs various sensors for detecting its state and actions. The correct choice of the most appropriate sensor(s) is of paramount importance. When integrated into the equipment, ideal sensors are unobstructive, and do not change the functionality of the equipment. The article focuses on identification and selection of sensors suitable for the integration into a golf club. We used two orthogonally affixed strain gage sensors, a 3-axis accelerometer, and a 3-axis gyroscope. The responses of strain gage sensors are used for measuring golf club flex. They are calibrated and validated in the laboratory environment by the highly accurate optical tracking system Qualisys Track Manager (QTM). Accelerometer and gyroscope are used to measure golf club acceleration and angular speed. Field tests are performed without QTM, only with the sensors affixed to the golf club. The first set of results show that the strain gage sensors complement the inertial sensors. For some golf swing tracking and error detection applications strain gage sensors could be the only type of sensors needed. Our final goal is to be able to acquire and analyze as many parameters of a golf club in real time during the entire swing. Such information would make the identification and selection of the most appropriate sensors to be applicable for a defined task easier.	angularjs;error detection and correction;gyroscope;quantum turing machine;sensor web;smart tv;the golf club;tracking system;usability	Anton Kos;Anton Umek;Saso Tomazic	2016	2016 International Conference on Identification, Information and Knowledge in the Internet of Things (IIKI)	10.1109/IIKI.2016.71	club;computer network;strain gauge;inertial measurement unit;computer science;sports equipment;control engineering;intelligent sensor;accelerometer;tracking system;gyroscope	Robotics	57.55217671262926	-36.0662620221941	120446
36d220d701c59f97ccd087cdaa10cdbed6cae19d	wearable gait logging system attached on ankles to estimate foot steps and trajectories		Conventional pedestrian dead-reckoning systems that use shoe-mounted inertial sensors are not suitable for use in daily life. For example, such systems are not convenient because they compel individuals to wear such pairs of shoes; moreover, these systems are not suitable for use in barefoot conditions. A novel gait logging system is proposed to estimate foot steps and walking trajectories using a combination of high frequency vibration and inertial measurements from the upper part of the ankle. First, a three-step method is proposed to estimate Heel Strike and Toe Off. It is verified that the present method is suitable for estimating Midstance (MSt) time. Then, a trajectory and position estimation procedure is proposed that considers the MSt ankle velocity. A model for MSt ankle velocity is derived. The performance of the trajectory estimation is evaluated with various types of footwear. It is verified that the proposed method is suitable for estimating step lengths of each stride and total distance regardless of the footwear. Furthermore, the trajectories estimated using the proposed method approximated the actual walking path with high accuracy.	approximation algorithm;dead reckoning;f-15 strike eagle;kalman filter;keystroke logging;propagation of uncertainty;sensor;shoes;velocity (software development);wearable computer	Yoshihiro Kato;Hikaru Nagano;Masashi Konyo;Satoshi Tadokoro	2017	2017 IEEE/SICE International Symposium on System Integration (SII)	10.1109/SII.2017.8279228	computer vision;artificial intelligence;engineering;inertial frame of reference;inertial measurement unit;barefoot;ankle;trajectory;control theory;gait;vibration;stride	Robotics	57.62492288463987	-37.016701938068714	120478
0e15dda3d006ee74dcdffc27a6b69c826f864781	visual servoing control of a 9-dof wmra to perform adl tasks	visual servo control;task performance;wheelchairs dexterous manipulators feature extraction living systems mobile robots optimisation robot vision trajectory control visual servoing;optimisation;manipulators;living systems;wmra;mobile robots;eye in hand monocular camera;joints;ibvs;adl task;dexterous manipulators;robot arm;mobility control;manipulation control;robot vision;task performance dof wmra adl task wheelchair mounted robotic arm mobile manipulator power wheelchair manipulation control mobility control weighted optimization trajectory tracking image based visual servoing scale invariant feature transform sift eye in hand monocular camera activities of daily living ibvs;sift;scale invariant feature transform;feature extraction;mobile communication;image based visual servoing;dof;visual servoing manipulators wheelchairs cameras mobile communication joints;weighted optimization;wheelchair mounted robotic arm;activity of daily living;trajectory tracking;mobile manipulator;visual servoing;activities of daily living;trajectory control;cameras;power wheelchair;wheelchairs	The wheelchair-mounted robotic arm (WMRA) is a mobile manipulator that consists of a 7-DoF robotic arm and a 2-DoF power wheelchair platform. Previous works combined mobility and manipulation control using weighted optimization for dual-trajectory tracking [7]. In this work, we present an image-based visual servoing (IBVS) approach with scale-invariant feature transform (SIFT) using an eye-in-hand monocular camera for combined control of mobility and manipulation for the 9-DoF WMRA system to execute activities of daily living (ADL) autonomously. We also present results of the physical implementation with a simple “Go to and Pick Up” task and the “Go to and Open the Door” task previously published in simulation, using IBVS to aid the task performance.	autonomous robot;goto;mathematical optimization;mobile manipulator;robotic arm;scale-invariant feature transform;simulation;velocity (software development);visual servoing	William G. Pence;Fabian Farelo;Redwan Alqasemi;Yu Sun;Rajiv V. Dubey	2012	2012 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2012.6225162	control engineering;computer vision;simulation;activities of daily living;computer science;engineering;artificial intelligence;scale-invariant feature transform	Robotics	60.81124115017544	-30.57200811078526	120621
f16ab52f0cb83f349d1b81bc8a8f183b7e49961d	design and implementation of autonomous navigation system for mobile harbors	optimal path planning;path planning;conference;real time;design and implementation;autonomous navigation;navigation system	This paper describes an implementation of an autonomous navigation system for a USV-type Mobile Harbor (MH) prototype and for multiple MHs. The MH is a novel maritime container transport solution that can go out to a ship to load/unload containers at sea and take them to their destination ports. We demonstrate the feasibility of the navigation system for a MH by performing experiments using a prototype in a basin. A devised multiple navigation system enables multiple MHs navigate safely without colliding with each other. In the initial stage of path planning, 3D optimal path planning algorithm in ConfigurationTime space is performed. When the MHs navigate using those generated paths, the decentralized and delayed path planning method is performed in real-time by predicting the collision expected regions. To demonstrate the feasibility of this algorithm, simulations were performed.	algorithm;automated planning and scheduling;autonomous robot;experiment;modified huffman coding;motion planning;prototype;real-time clock;real-time computing;real-time operating system;simulation	Iksu Shin;Yuseok Bang;Donghoon Kim;Jongdae Jung;Hyun Myung	2010		10.1007/978-3-642-15810-0_28	simulation;systems engineering;engineering;transport engineering;mobile robot navigation	Robotics	56.24495078047409	-26.777445839412398	120669
4881cf5770e6886e8e7f4d1097f57e5ef44adcdd	using genetic algorithms for tasking teams of raven uavs	cooperative control;tecnologia industrial tecnologia mecanica;tecnologia electronica telecomunicaciones;tasking algorithms;uavs;genetic algorithms;tecnologias;grupo a	Control of multiple unmanned aerial vehicles is of importance given that so many have been deployed in the field. This work discusses how genetic algorithms (GA) have been applied to the cooperative tasking of the AeroVironment’s Raven unmanned aerial vehicle (UAV) engaged in an intelligence, reconnaissance, and surveillance (ISR) mission. Mission assumptions, development of the GA, the method used to test for convergence, and the outcome of preliminary testing are all discussed.	aerial photography;genetic algorithm;information systems research;simulation;software release life cycle;unmanned aerial vehicle	Marjorie Darrah;Edgar Fuller;Thilanka Munasinghe;Kristin Duling;Mridul Gautam;Mitchell Wathen	2013	Journal of Intelligent and Robotic Systems	10.1007/s10846-012-9696-3	simulation;genetic algorithm;computer science;engineering;artificial intelligence;machine learning;operations research	Robotics	56.204079551140964	-27.391794132211462	120743
afce21f8878c1657420fcecb32c889d9efeb1565	joint route planning for uav and sensor network for data retrieval	path planner joint route planning uav data retrieval large scale data gathering remote sensor networks remote deployments manual data collection ground robots uneven terrain unmanned aerial vehicle flight time network lifetime joint route optimization kinematic constraints communication range limitations heuristic solution information collection;optimisation;wireless sensor networks autonomous aerial vehicles information retrieval mobile robots optimisation path planning robot kinematics terrain mapping;information retrieval;path planning;mobile robots;robot sensing systems optimization joints kinematics wireless sensor networks vehicles;terrain mapping;autonomous aerial vehicles;wireless sensor networks;robot kinematics	Large scale data gathering from remote sensor networks is a key issue in many remote deployments. Manual data collection is difficult and sending ground robots to collect information can be complex due to uneven terrain. Alternately, unmanned aerial vehicle (UAV) can be used to collect data from sensor networks. The UAV will fly over the sensors gathering the data. However, to minimize the flight time of the UAV and maximize the network lifetime, a joint route optimization for UAV and sensor network must be carried out. Additionally, the UAV has kinematic constraints and communication range limitations. Determining solution with these constraints is difficult and computationally intensive. In this paper, we propose a heuristic solution by decoupling the problem into four sub-problems. The first is to determine clusters of sensors with communication range limitations. The second is to efficiently connect the clusters. The third is to design the route inside the cluster that will maximize the information collection and the fourth is to design a path planner for the UAV for data collection. We show the proposed solution through an example.	aerial photography;algorithm;coupling (computer programming);data mule;data retrieval;heuristic (computer science);linear programming;mathematical optimization;nonlinear programming;nonlinear system;robot;sensor;uav outback challenge;unmanned aerial vehicle	P. B. Sujit;Daniel Enrique Lucani;João Borges de Sousa	2013	2013 IEEE International Systems Conference (SysCon)	10.1109/SysCon.2013.6549957	computer vision;simulation;engineering;key distribution in wireless sensor networks;remote sensing	Robotics	54.79973786134211	-26.754222622614435	120818
03a7b863a943b6dc4490d5349a5977f680bd8296	localization of avalanche victims using robocentric slam	magnetic field;snow avalanche;mobile robots;particle filter;gaussian filter;gaussian filter avalanche victims localization robocentric slam snow avalanche particle filter;slam robots mobile robots;simultaneous localization and mapping magnetic field measurement magnetic sensors antenna measurements snow motion estimation motion measurement gaussian processes magnetic separation filters;avalanche victims localization;robocentric slam;slam robots;inertial sensor;3d measurement	"""A person buried by a snow avalanche can be found by measuring the magnetic field generated by an avalanche beacon or ARVA carried by the victim. However, the signals received are difficult to interpret and require people with good training on the actual searching techniques. In this paper we show that the search can be automated using SLAM techniques. The rescuer is equipped with an inertial sensor to estimate its own motion and a triple antenna to obtain 3D measurements of the magnetic field generated by the victim's ARVA. Both measurements are used to build a """"robocentric"""" map that contains the location of the victim relative to the rescuer. To solve this highly non-linear SLAM problem we propose and compare two alternative solutions based on a sum of Gaussians (SOGs) filter and a particle filter. We present simulation results showing that, for comparable computing times, the SOGs solution gives more accurate results"""	algorithm;avalanche effect;kalman filter;multimodal interaction;nonlinear system;particle filter;simulation;simultaneous localization and mapping;transmitter	Pedro Pinies;Juan D. Tardós;José Neira	2006	2006 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2006.282247	mobile robot;computer vision;electronic engineering;simulation;particle filter;magnetic field;computer science;gaussian filter	Robotics	56.126390390899005	-36.635952109508054	120834
03ecb761810585a0b2397f4f29176373b0949923	""""""" arnie p."""" - a robot golfing system using binocular and a heuristic feedback mechanism"""	robot sensing systems;feedback mechanism;learning;intelligent robots;feedback;artificial intelligence;humans;robot vision systems;robotics and automation;intelligent sensors;robot kinematics	This paper describes a robot vision golfing system. The Automated Robotic Navigational unit with Intelligent Eye and Putter (ARNIE P)τproject was initiated to investigate the problems and develop software solutions for robotic tasks that require good hand-eye coordination and an intelligent sensor feedback mechanism. This system has only one frame buffer and no specialized hardware, so quasi-real time 3D tracking is accomplished in software using the Unix Spline facility. The single frame buffer and digitizer, stores and retains the location of the ball from two separate cameras during the time interval between the golf ball initially crossing a trigger scan line and the ball coming to a complete stop. The most novel aspect of this study is that by attempting to build or model a difficult perceptory task such as golf, which requires integrating many complicated computational pieces (binocular stereo vision, robot arm motion, heuristic feedback, learning), it appears to be a good plarform to experiment with artificial intelligence techniques and robotics.	binocular vision;feedback;heuristic;robot	Roger W. Webster	1992		10.1109/IROS.1992.601935	control engineering;mobile robot;robot learning;computer vision;simulation;articulated robot;computer science;artificial intelligence;social robot;arm solution;feedback;robot control;ubiquitous robot;mobile robot navigation;personal robot	Robotics	60.01141431354698	-28.921367004050854	120992
89bc2a5efab9075f459c742e0dd4679195305297	experimental validation of a reach-and grasp optimization algorithm inspired to human arm-hand control	minimisation;biology computing;grasping;robot hand;physiological models biology computing biomechanics manipulator kinematics minimisation;biomechanics;joints thumb robots grasping humans optimization;joints;manipulator kinematics;thumb;objective function;robots;hand joint object surface distances reach and grasp optimization algorithm human arm hand control human grasping action stable human like cylindrical grasp robotic hand optimal hand position optimal finger configuration cylindrical object grasping objective function minimization;algorithms arm hand hand strength humans joints;experimental validation;optimization;humans;optimal algorithm;physiological models	Taking inspiration from neurophysiological studies on synergies in the human grasping action, this paper tries to demonstrate that it is possible to find a general rule for performing a stable, human-like cylindrical grasp with a robotic hand. To this purpose, the theoretical formulation and the experimental validation of a reach-and-grasp algorithm for determining the optimal hand position and the optimal finger configuration for grasping a cylindrical object with known features are presented. The proposed algorithm is based on the minimization of an objective function expressed by the sum of the distances of the hand joints from the object surface. Algorithm effectiveness has preliminarily been tested by means of simulation trials. Experimental trials on a real arm-hand robotic system have then been carried out in order to validate the approach and evaluate algorithm performance.	algorithm;articular system;distance;hand joint structure;inspiration function;loss function;mathematical optimization;optimization problem;robot;simulation;synergy	Francesca Cordella;Loredana Zollo;Antonino Salerno;Eugenio Guglielmelli;Bruno Siciliano	2011	2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/IEMBS.2011.6092010	robot;computer vision;minimisation;simulation;computer science;engineering;artificial intelligence;biomechanics;mathematics;statistics	Robotics	66.04836362942552	-24.47212849053533	121028
20732957b2c2af8d2dab73269620167cae649002	learning task space control through goal directed exploration	robot learning;humanoid robot;state space methods;motion control;forward model;reference frame;mobile robots;prior knowledge;perturbation techniques;joints;kinematics;trajectory;redundancy;humanoid robots;estimation;aerospace electronics jacobian matrices robots joints kinematics trajectory estimation;stress analysis;state space;robots;task space reference frame learning task space control goal directed exploration autonomous goal directed strategy redundant robot motor babbling joints space humanoid robot simulation 3d targets waist motion arm motion robot structure kinematic perturbations;aerospace electronics;jacobian matrices;redundant manipulators;stress analysis humanoid robots mobile robots motion control perturbation techniques redundancy redundant manipulators robot kinematics state space methods;robot kinematics;approaches to learning	We present an autonomous goal-directed strategy to learn how to control a redundant robot in the task space. We discuss the advantages of exploring the state space through goal-directed actions defined in the task space (i.e. learning by trying to do) instead of performing motor babbling in the joints space, and we stress the importance of learning to be performed online, without any separation between training and execution. Our solution relies on learning the forward model and then inverting it for the control; different approaches to learn the forward model are described and compared. Experimental results on a simulated humanoid robot are provided to support our claims. The robot learns autonomously how to perform reaching actions directed toward 3D targets in task space by using arm and waist motion, not relying on any prior knowledge or initial motor babbling. To test the ability of the system to adapt to sudden changes both in the robot structure and in the perceived environment we artificially introduce two different kinds of kinematic perturbations: a modification of the length of one link and a rotation of the task space reference frame. Results demonstrate that the online update of the model allows the robot to cope with such situations.	autonomous robot;humanoid robot;jacobian matrix and determinant;kernel (linear algebra);kobian;motor babbling;performance;reference frame (video);robot end effector;simulation;state space	Lorenzo Jamone;Lorenzo Natale;Kenji Hashimoto;Giulio Sandini;Atsuo Takanishi	2011	2011 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2011.6181368	control engineering;robot learning;computer vision;simulation;computer science;engineering;humanoid robot;artificial intelligence;social robot	Robotics	62.544222297698994	-24.373103930773848	121248
aaba5b7c5ed6697e8a30e93dc9fcc268bca59192	low-altitude aerial methane concentration mapping		Detection of leaks of fugitive greenhouse gases (GHGs) from landfills and natural gas infrastructure is critical for not only their safe operation but also for protecting the environment. Current inspection practices involve moving a methane detector within the target area by a person or vehicle. This procedure is dangerous, time consuming, labor intensive and above all unavailable when access to the desired area is limited. Remote sensing by an unmanned aerial vehicle (UAV) equipped with a methane detector is a cost-effective and fast method for methane detection and monitoring, especially for vast and remote areas. This paper describes the integration of an off-the-shelf laser-based methane detector into a multi-rotor UAV and demonstrates its efficacy in generating an aerial methane concentration map of a landfill. The UAV flies a preset flight path measuring methane concentrations in a vertical air column between the UAV and the ground surface. Measurements were taken at 10 Hz giving a typical distance between measurements of 0.2 m when flying at 2 m/s. The UAV was set to fly at 25 to 30 m above the ground. We conclude that besides its utility in landfill monitoring, the proposed method is ready for other environmental applications as well as the inspection of natural gas infrastructure that can release methane with much higher concentrations.	aerial photography;effective method;global positioning system;item unique identification;memory leak;microprocessor;mobile device;on-board data handling;r.o.t.o.r.;unmanned aerial vehicle	Bara J. Emran;Dwayne D. Tannant;Homayoun Najjaran	2017	Remote Sensing	10.3390/rs9080823	geology;remote sensing;natural gas;methane;greenhouse gas;detector;altitude	Robotics	54.03329292575989	-29.585764932595488	121329
78ae8668165c36280b3ef924615c5d8bd5a8e4f1	passivity-based visual feedback control for an endpoint closed-loop system with a movable camera		This paper presents passivity-based visual feedback control for an endpoint closed-loop system with a movable camera. The objective of the system is that a controlled mobile vehicle tracks a target object vehicle by using only aerial vehicle's visual information. First, a brief summary of the estimation and pose error systems for the camera-mounted aerial vehicle is presented. Second, we design a novel nonlinear observer to estimate the pose of the controlled mobile vehicle. Next, we propose a visual feedback control law for the constructed visual motion error system based on the passivity. After discussing stability analysis of the closed-loop system through Lyapunov stability theorem, simulation results are provided to illustrate the performance of the proposed control method.		Mamoru Kuroda;Toshiyuki Murao;Hiroyuki Kawai	2018	IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2018.8591582		Robotics	60.98240795901683	-31.97548356175923	121424
a4656c4ab6e6f6d8d22229e17b9cb46f1618f11d	design of a remote control system for maintaining and repairing tasks in npp		This paper describes the design of a remote control system for maintaining and repairing tasks in a nuclear power plant (NPP). As the remote target tasks, we set up a remote manipulation of the manual operation mechanism of the nuclear fuel changer of the heavy water NPP and remote pipe cutting/welding, which may be necessary in the case of an emergency or dismantling of the NPP. The system to be developed is composed of a master device, a slave robot, and a mobile platform, as well as a telescopic mast that moves the slave robot to the desired position. To effectively perform remote tasks, we designed the architecture of an integrating program. The integrating program has a system components control module, a virtual guide implementing module, and egocentric remote control algorithms. We also designed psychophysics experiment for evaluating the individual technologies and integrated systems.	algorithm;control system;control unit;mobile operating system;radio masts and towers;remote control;remote manipulator;robot	Hocheol Shin;You-rak Choi;Chang-Hoi Kim	2017	2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2017.7992774	nuclear power plant;embedded system;architecture;robot;remote control;engineering;control system	Robotics	63.70571680226364	-29.428661346030765	121565
fac3383f2b930b26c14a58f17f99477ad5042378	i can see for miles and miles: an extended field test of visual teach and repeat 2.0		Autonomous path-following systems based on the Teach & Repeat paradigm allow robots to traverse extensive networks of manually driven paths using on-board sensors. These methods are well suited for applications that involve repeated traversals of constrained paths such as factory floors, orchards, and mines. In order for path-following systems to be viable for these applications they must be able to navigate large distances over long time periods, a challenging task for vision-based systems that are susceptible to appearance change. This paper details Visual Teach & Repeat 2.0, a vision-based path-following system capable of safe, long-term navigation over large-scale networks of connected paths in unstructured, outdoor environments. These tasks are achieved through the use of a suite of novel, multi-experience, vision-based navigation algorithms. We have validated our system experimentally through an eleven-day field test in an untended gravel pit in Sudbury, Canada, where we incrementally built and autonomously traversed a 5 km network of paths. Over the span of the field test, the robot logged over 140 km of autonomous driving with an autonomy rate of 99.6%, despite experiencing significant appearance change due to lighting and weather, including driving at night using headlights.	algorithm;autonomous car;autonomous robot;backtrack;experiment;ground truth;on-board data handling;programming paradigm;robot;robotics;safe area (television);sensor;traverse;tree traversal	Michael Paton;Kirk MacTavish;Laszlo-Peter Berczi;Sebastian Kai van Es;Tim D. Barfoot	2017		10.1007/978-3-319-67361-5_27	computer science;traverse;gravel pit;simulation;robot;suite	Robotics	53.785352179237556	-30.491679777203412	121739
72351f8dd4e5f4992bca30b2cd34306371275163	function of human-oriented compensator for human dynamics with uncertainties		"""In a human-machine system, operator skill is required in order to realize a meaningful operation. In this paper, a new concept of human-oriented compensator is proposed for improving the control performance of a human-machine system. The system aims to support human work and not to obstruct operational feeling. The compensator called a """"collaborator"""" has two degree of freedom. When such a compensator is applied to a human-machine system, it is worried that the bad influence on a system occurs due to adaptation of a human operator to the environment. But the collaborator maintains the control performance of the human-machine system in spite of a variation in human dynamics."""	human dynamics;human–machine system;simulation	Koki Shibasato;Hirofumi Ohtsuka;Shigeyasu Kawaji	2004	IEEE Conference on Robotics, Automation and Mechatronics, 2004.		control engineering;simulation;engineering;control theory	Robotics	64.24587188689146	-24.59567585307699	121853
c6d2b34e32a865cec1d80c4125f1d9c43b29ea7d	feeding a hungry world: the potential for unmanned aircraft systems	next generation sensor;hungry world;unmanned aircraft system;global conflict;sustainable manner;aerospace engineering technology;future world;advanced information system	The fusion of next generation sensors and advanced information systems, combined with advances in unmanned aircraft systems that have emerged through aerospace engineering technologies, will contribute to the challenge of feeding our future world in a sustainable manner. Without these advances, the world may find itself short of food and perhaps on the brink of global conflict.	information system;sensor;unmanned aerial vehicle	Wayne Woldt;Eric W. Frew;George Meyer	2014	ACM Crossroads	10.1145/2590599	simulation	HCI	55.63572575552192	-29.79448967208667	122180
ecff2f9e5b7a4c531900b3b671e65b4caa6f8271	passive reconfigurable manipulation assistive aids	manipulators;acquired immune deficiency syndrome couplings hardware prototypes application software mechanical systems humans assembly robot kinematics actuators;degree of freedom;cad;cad manipulators fourier analysis;fourier analysis;design enhancements passive reconfigurable manipulation assistive aids articulated mechanical systems motion flexibility reduced degree of freedom control hardware constraints end effector planar path;mechanical systems;multiple degree of freedom	Articulated mechanical systems with multiple joints possess multiple degrees-of-freedom which are often not required for performing typical low-dimensional manipulation tasks. These excessive degrees of freedom then need to be reduced by application of constraints, either actively by suitable control or passively in hardware, prior to performance of the task. Our interest is in creating articulated manipulation assistive aids, which combine the motion flexibility due to the multiple articulations with the simplicity of reduced degree-of-freedom control due to the presence of hardware constraints. Specifically we investigate the process of design and prototyping of such reduced-degree-of-freedom manipulators whose end-effector is required to closely approximate a desired planar path. We also examine design enhancements that permit easy reconfiguration of our prototype manipulator for multiple sets of tasks, by a controlled variation of the principal structural parameters.	approximation algorithm;constraint (mathematics);prototype;robot end effector	Xichun Nie;Venkat N. Krovi	2001		10.1109/IROS.2001.976305	control engineering;simulation;engineering;cad;control theory;fourier analysis;degrees of freedom;mechanical system	Robotics	68.03081171041474	-25.367136898081153	122184
80738d5ebc7a6d751b3fe3d31583bea75440a615	visual measurement of pile penetration and rebound movement using a high-speed line-scan camera	ccd camera;edge detection ccd image sensors motion measurement image motion analysis;control systems;speckle;sensor phenomena and characterization;image motion analysis;edge detection;visual measurement system;measurement system;high speed line scan camera;ccd camera pile penetration rebound movement high speed line scan camera visual measurement system penetration movement two dimensional motion parameters;pile penetration;intelligent control;acceleration;ccd image sensors;rebound movement;smart cameras;intelligent systems;vibration measurement;motion measurement sensor phenomena and characterization vibration measurement acceleration ground support speckle smart cameras intelligent systems intelligent control control systems;penetration movement;dynamic characteristic;ground support;motion measurement;high speed;two dimensional motion parameters	When a construction company builds a high structure, many piles should be driven into the ground by a hammer whose weight is 7,000 Kg in order to make the ground under the structure safe and strong. So, it is essential to determine whether a pile is penetrated into the ground enough to support the weight of the structure since ground characteristics at different locations are different each other. This paper proposes a visual measurement system for pile rebound and penetration movement including vibration using a high-speed line-scan camera and a specially designed mark to recognize two-dimensional motion parameters of the mark using only a line-scan camera. A mark stacking white and black right-angled triangles is used for the measurement, and movement information for vertical distance, horizontal distance and rotational angle is determined simultaneously. Especially, by adopting a line-scan CCD camera whose line rate is 20 KHz, the measurement performance of dynamic characteristics of the pile at impact instant is improved	charge-coupled device;distortion;pixel;sensor;stacking;system of measurement	Se-Na Lee;Bum-Jae You;Mee-Seub Lim;Sang-Rok Oh;Song-Soo Han;Sang-Heon Lee	2002		10.1109/ROBOT.2002.1014436	acceleration;speckle pattern;smart camera;computer vision;simulation;edge detection;computer science;engineering;control system;artificial intelligence;system of measurement;optics;charge-coupled device;intelligent control	HCI	60.565892888627666	-34.77181706007928	122193
946ae3c0bf104eace74104654c2bfc5a760af633	a human aided learning process for an artificial immune system based robot control - an implementation on an autonomous mobile robot	robot control;artificial immune system	A pressure sensing device has a light source, and an optical sensor for externally sensing a predetermined change in the pressure within a sealed system which has a conventional gauge. Illumination from the light source is reflected off of the gauge dial and detected by the optical sensor. When the pressure in the sealed system changes a predetermined amount, the needle on the gauge moves so as to interrupt the illumination reaching the optical sensor. The optical sensor in turn produces a voltage that can be used to turn on a light or other indicator.	artificial immune system;autonomous robot;mobile robot;robot control	Jan Illerhues;Nils Goerke	2007			engineering;control engineering;real-time computing;social robot;interrupt;robot control;robot learning;personal robot;ubiquitous robot;mobile robot navigation;mobile robot	Robotics	59.29820899637546	-30.43898447306054	122624
c21fcb62f7a31cf6c8e64960fe5d79a30d4f5861	sharing charging stations for long-term activity of autonomous robots	energy conservation;plugs;long period;cognitive robotics;robot task accomplishment;long term activity;space exploration;mobile robots;autonomous mobile robot;robot kinematics orbital robotics mobile robots cognitive robotics humanoid robots humans sleep plugs navigation space exploration;orbital robotics;battery chargers;sleep;pioneer 2 robots;navigation;humanoid robots;energetic capabilities;energy preservation;pioneer 2 robots autonomous mobile robots charging station sharing long term activity robot recharging power source energy preservation energy sharing coordination group survival robot task accomplishment energetic capabilities activity level;autonomous mobile robots;multi robot systems;energy conservation mobile robots multi robot systems battery chargers;group survival;humans;activity level;robot recharging;charging station sharing;autonomous robot;energy sharing;coordination;robot kinematics;power source	To operate over a long period of time, autonomous mobile robots must have the capability of recharging themselves whenever necessary. In addition to be able to find and connect to a power source, robots must also consider taking actions to preserve and share energy in an environment where energy is a limited resource. Coordination is then required to ensure the survival of the group and the accomplishment of the robots' tasks. This paper explores these issues by allowing robots to predict and reason about their energetic capabilities, as individuals and as a group. The approach described allows robots to determine when to recharge, when to change their activity level and how long they should recharge. Validation of the work is done in simulation to demonstrate the versatility of the approach for different numbers of robots and power sources. Experiments with Pioneer 2 robots are also reported.	autonomous robot	François Michaud;Etienne Robichaud	2002		10.1109/IRDS.2002.1041685	control engineering;mobile robot;embedded system;navigation;simulation;energy conservation;computer science;engineering;humanoid robot;artificial intelligence;space exploration;sleep;aisoy1;robot kinematics;cognitive robotics	Robotics	58.68710991885336	-25.375909207711338	122761
ded23f2c52cb2ab339c1c5b3c4b9039b26f3612b	maintaining odor tracking behavior using an established tracking direction in a dynamic wind environment	engineering systems;fluid borne odor;robot sensing systems;animals;search and rescue;low flow;generators;odor tracking;robomoth;tracking system;dangerous chemical location;turning;vehicles animals robot sensing systems turning generators;path planning;mobile robots;odor tracking behavior maintenance;ecological benefit;tracking direction;3d odor tracking robot odor tracking behavior maintenance tracking direction dynamic wind environment fluid borne odor engineering applications natural occurrences engineering systems odor guided navigation search and rescue dangerous chemical location unsteady turbulent flow environments ecological benefit wind driven tracking behavior odor tracking robomoth;wind driven tracking behavior;dynamic wind environment;engineering system;engineering applications;dynamic environment;tracking electronic noses mobile robots path planning;3d odor tracking robot;unsteady turbulent flow environments;vehicles;electronic noses;turbulent flow;odor guided navigation;natural occurrences;tracking	The ability to autonomously track a fluid-borne odor has numerous engineering applications and natural occurrences. Engineering systems can use odor-guided navigation in tasks ranging from search and rescue to locating dangerous chemicals. Animals use odors to locate food and mates. For animals in strong unsteady turbulent flow environments where the wind is intermittent and occasionally vanishes, there is an ecological benefit to maintaining wind-driven tracking behavior. This has been shown in experiments performed using moths and cockroaches, where animals that began tracking odor in wind maintained their wind driven tracking behavior and eventually located the source after the wind was shut off during their tracking behavior. Here, we use RoboMoth, a previously developed 3D odor-tracking robot, to replicate these experiments. Our results can aid biologists in understanding how animals track odors in dynamic environments. In engineering, this study provides a first step in a hardware system towards linking odor tracking in strong wind environments to tracking in zero/low flow environments by studying the transition between the two regimes. This can help further engineers' efforts to design odor-tracking systems capable of negotiating diverse and dynamic environments. Our study of the transition from using the wind as a primary directional cue to relying on odor and an established tracking direction appears to be novel in an engineering context and unique to our work.	experiment;self-replicating machine;shutdown (computing);tracking system;turbulence	Brian K. Taylor;Dora Wu;Mark A. Willis;Roger D. Quinn	2012	2012 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2012.6225019	turbulence;mobile robot;computer vision;simulation;tracking system;computer science;engineering;artificial intelligence;motion planning;tracking	Robotics	59.5501279305581	-25.705453767406688	122771
1eaa28cc2d0d85927013867a48958a663794d284	modular software architecture for teams of cooperating, heterogeneous robots	radio networks;robot control software;humanoid robot;software architecture control engineering computing motion control multi robot systems radio networks;motion control;behavior control;platform independent modular software architecture;mobile robot;mobile robotics;wireless network;data processing;multi robot system;cooperating heterogeneous robots;indexing terms;behavior control cooperating heterogeneous robots cooperating autonomous lightweight robots dynamical locomotion properties platform independent modular software architecture sensor data processing motion control control architecture wireless network;sensor data processing;software architecture;robot control;humanoid robots;control architecture;multi robot systems;dynamical locomotion properties;robot control software cooperative multi robot systems mobile robotics humanoid robots;property a;cooperating autonomous lightweight robots;software architecture robot sensing systems communication system control computer architecture data processing motion planning process planning motion control control systems computer networks;control engineering computing;cooperative multi robot systems;behavioral control	For teams of cooperating autonomous lightweight robots with challenging dynamical locomotion properties a platform independent modular software architecture and platform independent modules for sensor data processing, planning and motion control have been developed. The software architecture allows high level communication between modules on different abstraction levels of the control architecture within one robot system as well as communication between different and heterogeneous robots and computers using wireless network. Very different behavior control paradigms may be realized on the basis of the developed architecture. The application to teams of cooperating small and medium size humanoid robots is investigated in this paper. Scenarios for inter robot communication and cooperative task accomplishment are described.	autonomous robot;computer multitasking;high-level programming language;humanoid robot;modular programming;software architecture	Martin Friedmann;Jutta Kiener;Sebastian Petters;Dirk Thomas;Oskar von Stryk	2006	2006 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2006.340270	control engineering;reference architecture;embedded system;simulation;data processing;computer science;engineering;humanoid robot;applications architecture;artificial intelligence	Robotics	62.11272528995833	-27.66267548899418	122832
9c509306af7f2a27eeeaa715def9b13ef51a9633	study on self-contained and terrain adaptive active cord mechanism	sloping surfaces self contained terrain adaptive active cord mechanism one dimensional configuration creeping dynamics acmr r1 skating;adaptive control;mobile robots;experimental model;robots manipulator dynamics ice adaptive control motion control kinematics torque motion analysis animals biological system modeling;adaptive control mobile robots robot kinematics robot dynamics;robot dynamics;robot kinematics	"""A snake is able to attain high terrain adaptability and versatile locomotion even though it has an extremely simple one-dimensional configuration. In order to utilize these functions for robotics, we have adapted the basic biological machine elements of the snake into the active cord mechanism (ACM). We have discussed the creeping dynamics and applications to manipulation. In this paper, we develop a new experimental model named """"ACMR-R1"""" with a self-contained system, which realizes higher mobility and terrain adaptability compared with the past model. Next, gliding experiments on ice were carried out in order to demonstrate that the creeping motion is the same as the principle of skating. Finally, a new terrain adaptive control method for sloping surfaces is proposed, and we verified the effectiveness of it by slope climbing experiments."""		Gen Endo;Keiji Togawa;Shigeo Hirose	1999		10.1109/IROS.1999.811675	control engineering;mobile robot;simulation;adaptive control;computer science;engineering;artificial intelligence;control theory;robot control;robot kinematics	Robotics	68.04476293273525	-24.14200930924016	122844
f52d1e8efc18c4c1a6d55a44e62352bcc9c4f833	virtual-reality-based point-and-direct robotic inspection in manufacturing	neural nets;prension;atelier flexible;virtual reality;automatisation;robotics;inspection materials handling robot sensing systems service robots flexible manufacturing systems pulp manufacturing neural networks manufacturing processes grippers skeleton;automatizacion;gripping;inspection;robot industriel;flexible manufacturing;robot vision;imagen virtual;flexible manufacturing system;industrial robots;image virtuelle;robot industrial;robotica;telerobotics;sistema flexible produccion;prehension;robotique;neural network virtual reality based point and direct robotic inspection flexible manufacturing fms robot grasping skeletal images surface flaw identification small quantity large variety manufacturing material handling virtual tools workpiece placement;reseau neuronal;inspeccion;neural nets industrial robots telerobotics robot vision inspection virtual reality;virtual image;red neuronal;neural network;industrial robot;automation	This paper explores a flexible manufacturing paradigm in which robot grasping is interactively specified and skeletal images are efficiently used in combination to allow rapidly setting up surface flaw identification tasks in small-quantity/large-variety manufacturing. Two complementary technologies are combined to make implementation of inspection as rapid as possible. First, a novel material handling approach is described for robotic picking and placing of parts onto an inspection table using virtual tools. This allows an operator to point and give directives to set up robotic inspection tasks. Second, since specification may be approximate using this method, a fast and flexible means of identifying images of perfect and flawed parts is explored that avoids rotational or translational restrictions on workpiece placement. This is accomplished by using skeleton pixel counts as neural network inputs. The total system, including material handling and skeleton-based inspection, features flexibility during manufacturing set-up, and reduces the process time and memory requirements for workpiece inspection.	robot;virtual reality	Collin Wang;David J. Cannon	1996	IEEE Trans. Robotics and Automation	10.1109/70.508435	telerobotics;computer vision;virtual image;simulation;inspection;automated x-ray inspection;computer science;engineering;artificial intelligence;automation;engineering drawing;artificial neural network;automated optical inspection	Robotics	64.33291082981812	-34.445914500442704	123118
10bfc189853bafc6872f7bb20bbd40d838699665	reliable orientation estimation for mobile motion capturing in medical rehabilitation sessions based on inertial measurement units	platform independence;wireless sensor network;inertial sensor fusion;wireless inertial sensor	Fully mobile and wireless motion capturing is a mandatory requirement for undisturbed and non-reactive analysis of human movements. Inertial sensor platforms are used in applications like training session analysis in sports or rehabilitation, and allow non-restricted motion capturing. The computation of the required reliable orientation estimation based on the inertial sensor RAW data is a demanding computational task. Therefore, an analysis of the computational costs and achievable accuracy of a Kalman filter and a complementary filter algorithm is provided. Highly customized and thus low-power, wearable computation platforms require low-level, platform independent communication protocols and connectivity. State-of-the-art small sized commercial inertial sensors either lack the availability of an open, platform independent protocol, wireless connectivity or extension interfaces for additional sensors. Therefore, an extensible, wireless inertial sensor called Institute of Microelectronic Systems Inertial Measurement Unit (IM)2SU, featuring onboard inertial sensor fusion, for use in home based stroke rehabilitation is presented. Furthermore, a Quaternion based, singularity free orientation estimation accuracy error measure is proposed and applied. To evaluate orientation estimation accuracy an optical system is used as golden reference. Orientation estimation based on a Kalman filter and a complementary filter algorithm is evaluated. The proposed IMU provides high orientation estimation accuracy, is platform independent, offers wireless connection and extensibility and is low cost.	motion capture	Hans-Peter Brückner;Benjamin Krüger;Holger Blume	2014	Microelectronics Journal	10.1016/j.mejo.2014.05.018	embedded system;electronic engineering;simulation;wireless sensor network;engineering	Vision	58.511351603885856	-37.94587731628986	123204
e1a6587593c8bcb921f4a0dc23468c2d1e8de0bf	closed-loop single-beacon passive acoustic navigation for low-cost autonomous underwater vehicles		Accurate localization is critical for a robotic vehicle to navigate autonomously. Conventional autonomous underwater vehicles (AUV s) typically rely on an inertial navigation system (INS) aided by a Doppler velocity log (DVL) in order to reduce the rate of positional error growth of dead-reckoning to a level suitable for reliable navigation underwater. The size, cost, and power requirements of these systems result in vehicles that are prohibitively large and expensive for multi-AUV operations. In this work we present the first results of closed-loop experiments using a miniature, low-cost SandShark AUV and a custom-designed, inexpensive acoustic system first described in our previous work. Results are validated using an independent LBL system, and indicate that our approach is suitably accurate to enable the self-localization of such AUVs without the use of an expensive DVL-aided INS. Self-localization is performed by obtaining acoustic range and angle measurements from the AUV to a single acoustic beacon using a vehicle-mounted passive hydrophone receiver-array, and fusing these measurements using a particle filter. A critical aspect of our approach that allows for real-time, closed-loop operation is the close coupling of conventional phased-array beamforming and particle filtering - this implementation detail reduces the computational complexity associated with our previously described two-stage beamforming plus particle filtering process, and consequently also enables an increase in particle count and an improvement in navigational accuracy. Experimental results are provided for two cases: first, absolute navigation in the case where the beacon is fixed at a known position; and second, relative navigation with a moving beacon, a novel operating paradigm for AUVs which promises to enable multi-AUV operations while maintaining bounded navigation error.		Nicholas R. Rypkema;Erin M. Fischell;Henrik R. Schmidt	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8593626	computer science;control engineering;real-time computing;hydrophone;computational complexity theory;inertial navigation system;doppler effect;particle filter;underwater;beamforming;transponder	Robotics	55.3954659924495	-36.34932806558354	123242
4ef27dff3050725e204d887947623f0cabf6bf55	automatic measuring system of body fit on the automobile assembly line	robot sensing systems;ccd camera;sensor systems;optical system;measurement by laser beam;automobiles;three dimensions;automobiles assembly systems vehicles robotic assembly robot vision systems sensor systems position measurement laser beams optical sensors robot sensing systems;measurement system;automatic optical inspection;laser beams;continuously moving assembly line conveyor;ccd image sensors;synchronization;assembling;industrial control;slit beam laser;optical system automatic measuring system body fit automobile assembly line continuously moving assembly line conveyor robot synchronization vision sensor positioning slit beam laser ccd camera;position measurement;assembly systems;robotic assembly;optical sensors;vehicles;automobile assembly line;body fit;vision sensor positioning;measurement by laser beam automatic optical inspection assembling industrial control automobile industry active vision ccd image sensors;robot;automatic measuring system;robot vision systems;automobile industry;active vision	Just a few millimeters make a big difference on an automated assembly line as doors, hood, windshield, wheel housings, and other parts are installed on a body-in-white (BIW), the partially completed body of an automobile. If BIW openings are slightly off kilter or parts vary much from specifications, the overall fit and finish of the completed car suffers. When dimensions vary more radically, a BIW may have to be custom-assembled by hand. In addition, if the variations grow too large, the entire BIW may be pulled from the assembly line and junked.	hood method	M. Kondo;S. Tachiki;M. Ishida;K. Higuchi	1995		10.1109/ROBOT.1995.525339	robot;embedded system;three-dimensional space;synchronization;computer vision;simulation;active vision;computer science;engineering;position sensor;artificial intelligence;system of measurement;charge-coupled device	Robotics	60.655423932436555	-35.48871053075663	123429
157e0771b4230ec3c4f40130fe2cc76b5f8a7635	the task-level evaluation model for a flexible assembly task with an industrial dual-arm robot		This paper is aimed to propose an evaluation model for a flexible assembly task with an industrial dual-arm robot. A simple peg-in-hole insertion process is initially realized by a Kawada Nextage Open dual-arm robot equipped with a vision system in a structured environment. Several assumptions are used to satisfy the scenario in practical manufacturing, and various kinds of evaluation performance indices are introduced to analyze the task-level performance in a robotic assembly system with the development of an evaluation model based on CTMC for practitioners to assess the performance of the robotic assembly system. Finally, we implement the peg-in-hole task by means of two strategies respectively. The generated experimental results are combined with the evaluation model to verify the cost-effectiveness for these two strategies.	robot	Ching-Yen Weng;I-Ming Chen	2017		10.1109/ICCIS.2017.8274801	engineering;control engineering;task analysis;robot;machine vision	Robotics	63.368501936154054	-26.7655292425753	123580
e51e392b6957c494e9eba730a8ade976a5a61744	bouncing monopod with bio-mimetic muscular-skeleton system	robot sensing systems;motion control;pneumatic artificial muscle;sensors;human like morphology;biomimetic muscular skeleton system;stable bouncing bouncing monopod biomimetic muscular skeleton system human like morphology dynamic bouncing pneumatic artificial muscle biarticular muscle;mobile robots;biarticular muscle;joints;bouncing monopod;pneumatic actuators;robots;bone;muscles joints robots robot kinematics sensors robot sensing systems valves;artificial organs;valves;dynamic bouncing;stable bouncing;muscle;pneumatic actuators artificial organs biomimetics bone medical control systems mobile robots motion control muscle;robot kinematics;biomimetics;muscles;medical control systems	Structure of a humanpsilas muscular-skeleton system is supposed to play an essential role for realizing dynamic locomotion such as jumping and running. This paper investigates the effectiveness of the human-like morphology for dynamic bouncing. We designed a monopod that had a bio-mimetic muscular-skeleton system utilizing pneumatic artificial muscles. Through the experiments, we confirmed that the biarticular muscles strongly governed the coordinated movement of its body. Utilizing such synergy brought by the muscles, a simple controller could realize stable bouncing even though the pneumatic artificial muscles have complicated characteristics.	british informatics olympiad;experiment;galaxy morphological classification;pneumatic artificial muscles;synergy	Koh Hosoda;Hitoshi Takayama;Takashi Takuma	2008	2008 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2008.4650801	biomimetics;robot;control engineering;motion control;mobile robot;muscle;simulation;pneumatic actuator;computer science;engineering;sensor;artificial intelligence;robot kinematics	Robotics	68.13865421402251	-24.84536204731715	123850
880d70d00bac61c6b628851be18aa132d253085e	ground micro-gravity emulation system for space robot capturing the target satellite	simulation aerospace robotics artificial satellites compensation force sensors manipulators motion control;satellites space vehicles manipulator dynamics robot sensing systems dynamics;force sensor ground microgravity emulation system space robotic system space manipulator target satellite hardware in the loop simulation robot motion emulation gravity compensation method	Ground micro-gravity verification and test is vitally important for space robot. This paper mainly introduces a kind of ground micro-gravity emulation system, which can be used to verify the process of space robot capturing the target satellite in the 3-dimensional space. The system adopts the hardware-in-the-loop simulation, which mainly includes the real hardware system and the simulation software. The dynamics of space robot and the target satellite are modelled, respectively. The motion emulation of the servicing satellite base and that of the target satellite are realized by the dynamics simulation and the motion of two industrial robots. Then, the gravity compensation methods of force sensor for space manipulator and the target satellite are described, respectively. Finally, the ground micro-gravity emulation system is built and the base motion emulation of space manipulator capturing the target satellite is realized.	emulator;hardware-in-the-loop simulation;industrial robot;motion compensation;simulation software	Haitao Yang;Zongwu Xie;Xiaoyu Zhao;Ming-He Jin	2015	2015 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2015.7419729	control engineering;simulation;engineering;control theory	Robotics	64.74108627791601	-29.45582316707748	123869
eafd97e5524ce667285a75f8ffc6e20ce46b300c	in-field self-calibration of robotic manipulator using stereo camera: application to humanitarian demining robot	hand eye calibration;stereo camera;robot calibration;field robot	A robotic manipulator using a stereo camera mounted on one of its links requires a precise kinematic transformation calibration between the manipulator and the camera coordinate frames, the so-called hand–eye calibration, to achieve high-accuracy end-effector positioning. This paper introduces a new method that performs simultaneous joint angle and hand–eye calibration, based on a traditional method that uses a sequence of pure rotations of the manipulator links. The new method considers an additional joint angle constraint, which improves the calibration accuracy when the circular arc that can be measured by the stereo camera is very limited. Experimental results using a manipulator developed for humanitarian demining demonstrate that relative errors between the end effector and the external points mapped by the stereo camera are greatly reduced compared to traditional methods.	robot;stereo camera	Jianhua Li;Alex Masuo Kaneko;Gen Endo;Edwardo F. Fukushima	2015	Advanced Robotics	10.1080/01691864.2015.1012555	stereo camera;computer vision;camera auto-calibration;camera resectioning;simulation;computer science;engineering;artificial intelligence;robot calibration	Robotics	59.51180777493404	-35.86507937224242	124345
2cd52dd7c9e6def9245efcb533aa91faa35f8c84	pusher-watcher: an approach to fault-tolerant tightly-coupled robot coordination	automatic control;moving object;control systems;protocols;fault tolerant;pusher watcher;mobile robot;distributed control mobile robots multi robot systems cooperative systems fault tolerance;multiple robot system;mobile robots;autonomous mobile robot;box pushing;human behavior;murdoch;robot control;cooperative systems;fault tolerant systems;object manipulation;autonomous mobile robots;fault tolerance;multi robot systems;positional information;multiple robot system mobile robots pusher watcher cooperative systems autonomous mobile robots murdoch auction based resource centric task allocation fault tolerance distributed algorithm box pushing;computer science;distributed algorithm;auction based resource centric task allocation;distributed control;fault tolerance robot kinematics robotics and automation control systems mobile robots fault tolerant systems automatic control robot control protocols computer science;robotics and automation;task allocation;robot kinematics	We present a distributed planar object manipulation algorithm inspired by human behavior. The system, which we callpusher-watcher, enables the cooperative manipulation of large objects by teams of autonomous mobile robots. The robots are not equipped with gripping devices, but instead move objects by pushing against them. The pusher robots have no global positioning information, and cannot see over the object; thus a w tcher robot has the responsibility for leading the team (and object) to the goal, which only it can perceive. The system is entirely distributed, with each robot under local control. Through the use ofMURDOCH, an auction-based resource-centric general purpose task-allocation framework, roles in the team are automatically assigned in an efficient manner. Further, robot failures are easily tolerated and, when possible, automatically recovered. We present results and analysis from a battery of experiments with pusher-watcher implemented on a group of Pioneer 2 mobile robots.	algorithm;autonomous robot;experiment;fault-tolerant computer system;global positioning system;mobile robot	Brian P. Gerkey;Maja J. Mataric	2002		10.1109/ROBOT.2002.1013403	control engineering;mobile robot;distributed algorithm;fault tolerance;simulation;computer science;engineering;control system;artificial intelligence;social robot;automatic control;distributed computing;robot control;human behavior	Robotics	59.20041414081441	-31.07319956614149	124775
ed0954914aaa79541ca326296daca3b767b38986	proposed position and heading measurement system of ground vehicle using laser beams	automotive engineering;position measurement land vehicles laser beams transceivers navigation road vehicles clocks constitution automotive engineering automation;clocks;constitution;measurement system;laser beams;navigation;land vehicles;position measurement;transceivers;road vehicles;automation	The authors are interested i n developing the position and heading measurement system for vehicle automation and car navigation. T h i s paper proposes the new method t o measure the position and heading of ground vehicle. ins ta l led r ig id ly on the vehicle and a l i ne of corner cubes placed on roadway side. By measuring the time or distance when a corner cubes are de tec ted , i t calculates the position and heading. Experimental resu l t for this proposed method shows tha t it is applicable fo r the ground vehicles' position and hea&ing qeasurement . The method uses laser beam transceivers	automotive navigation system;course (navigation);olap cube;system of measurement;transceiver	Toshihiro Tsumura;Noboru Komatsu	1989		10.1109/IROS.1989.637908	navigation;computer science;engineering;automation;automotive engineering;system of measurement;forensic engineering;transceiver;mechanical engineering	Robotics	56.799615676782835	-34.09801602303772	124829
1a3b37de4f3a9b9bcb20306510806d7c9fdc7bc0	an intelligent dual mode vision guided robotic system	vision system;intelligent robots;industrial robots intelligent robots robot vision pd control servomechanisms;linear approximation;visual servoing intelligent dual mode vision guided robotic system industrial robotics hybrid system look and move system linear approximation gain scheduled pd controller;system performance;gain scheduling;robot control visual servoing vision guided robotics robot vision;robot vision;robot control;pd control;industrial robots;servomechanisms;hybrid system;visual servoing;intelligent robots machine vision robot vision systems visual servoing service robots bandwidth calibration linear approximation performance gain job shop scheduling	Industrial robotics have looked to vision systems for flexibility. This promise has largely been unrealized because existing systems are either too slow or too inaccurate. Both visual servoing and traditional look and move are insufficient because visual servoing requires too much bandwidth, and look and move requires very accurate calibration. To mitigate these effects, we have designed a hybrid system. Our hybrid system is composed of a roughly calibrated look-and-move system using a linear approximation, and a gain scheduled PD controller which performs visual servoing. The system performs markedly better than visual servoing or look-and-move techniques in isolation. This system have many potential applications including bin-picking, sorting, and tele-operation.	hybrid system;linear approximation;robot;sorting;television;vision guided robotic systems;visual servoing	Kevin G. Stanley;Q. M. Jonathan Wu;William A. Gruver	2005	2005 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2005.1571483	computer vision;machine vision;computer science;artificial intelligence;control theory;robot control;computer performance;gain scheduling;visual servoing;linear approximation;hybrid system	Robotics	61.65374784816298	-31.847039625494578	124889
717a5e001e3f9eb2f8d37f93fa53c048fc51d8cc	vision based manipulation of non-rigid objects	motion estimation vision based manipulation nonrigid object manipulation discovery driven robotic manipulation relative elasticity flexible linear objects image representation;robot sensing systems;elasticity;discovery driven robotic manipulation;manipulators;pediatrics;motion estimation;psychology;jacobian matrices manipulators robot vision motion estimation image representation elasticity;robot manipulator;robot vision;flexible linear objects;motor coordination;image representation;object manipulation;solid modeling;relative elasticity;robustness;vision based manipulation;humans;nonrigid object manipulation;physical model;structure and motion;jacobian matrices;robot vision systems;robotics and automation;object model;robot kinematics;pediatrics robot kinematics psychology robustness robot sensing systems robot vision systems robotics and automation solid modeling humans elasticity	Since the analytical expressions for the representation of nonrigid object structure and motion are severely underconstrained, current techniques for nonrigid object manipulation employ physical object models known prior to sensing. Recently, however, psychophysical studies have revealed that humans are able to discover proper motor coordination skills through sensory input without the use of previously known physical models. I n this paper, a robust, discovery-driven, vision-based robotic manipulation algorithm for nonrigid objects, based on the novel concept of relative elasticity, is developed which requires the use of no a priori physical models. The manipulation technique is also experimentally verified on different flexible linear objects.	algorithm;elasticity (data store);experiment;robot	Philip W. Smith;Nagaraj Nandhakumar;Arvind K. Ramadorai	1996		10.1109/ROBOT.1996.509198	control engineering;computer vision;simulation;object model;physical model;computer science;motion estimation;solid modeling;elasticity;motor coordination;robot kinematics;robustness	Robotics	67.34172361462196	-25.593664725099433	124899
47466f8550769f37ec93fe349635dd49d9c802eb	survey of robotic manipulation studies intending practical applications in real environments -object recognition, soft robot hand, and challenge program and benchmarking-		Aiming at accelerating the creation of new techniques on dexterous robotic manipulations, this paper surveyed the recent results on object recognition, soft robotic hands, and benchmarks and challenge/competition programs. The former two topics construct the elemental components of the new technologies on robotic manipulations, while the last one is a key for proceeding the creation and realization of the actual robotic manipulations with the new techniques. With these surveys, we will reveal the solved and unsolved issues for the next step to realize robotic dexterous manipulation systems comparable to human being.	outline of object recognition;robot	Tetsuyou Watanabe;Kimitoshi Yamazaki;Yasuyoshi Yokokohji	2017	Advanced Robotics	10.1080/01691864.2017.1365010	system integration;engineering;human–computer interaction;benchmarking;control engineering;robot;emerging technologies;robotic paradigms;soft robotic;artificial intelligence;cognitive neuroscience of visual object recognition	Robotics	66.7901490174152	-29.18819769098803	124920
ff773cc9498ca79e2f409ee4266a8a53afe23634	uav grouping and coordination tactics for ground attack missions	sensor phenomena and characterization;unmanned aerial vehicle;mobile robots autonomous aerial vehicles military aircraft;mobile robots;firing;military aircraft;weapons reconnaissance vehicles mobile communication firing sensor phenomena and characterization;field of view;mobile communication;attack uav uav grouping coordination tactics ground attack mission heterogeneous mix reconnaissance enemy suppression unmanned aerial vehicle weapon seeker range generic battlefield scenario group flyer simulation platform;vehicles;reconnaissance;autonomous aerial vehicles;weapons	Grouping and coordination tactics for ground attack missions by a heterogeneous mix of reconnaissance, enemy suppression, and attack unmanned aerial vehicles (UAVs) is presented. Dubins' paths are used to determine the optimal number of attack UAVs and their positional and heading freedoms, as functions of weapon seeker range and field of view. A generic battlefield scenario with layered defense is created and the tactics are evaluated on a Group Flyer simulation platform for both nominal and off-nominal conditions.	aerial photography;algorithm;autonomous robot;autonomous system (internet);course (navigation);dubins path;simulation;simulation software;snapshot (computer storage);unmanned aerial vehicle;xslt/muenchian grouping;zero suppression	M. Suresh;Debasish Ghose	2012	IEEE Transactions on Aerospace and Electronic Systems	10.1109/TAES.2012.6129663	mobile robot;simulation;mobile telephony;field of view;computer science;engineering;aeronautics;computer security	Vision	56.81118053574775	-26.83319964713935	125063
6d7351c9b45e415848811d48e8b081a14abe2abf	on the retrieval of underwater dispersed sensors using unmanned vehicles	sensors;euclidean distance;underwater sensor network;vehicles sensors sea measurements estimation navigation mathematical model acoustic measurements;unmanned vehicles;limited on board navigation sensor underwater dispersed sensor retrieval unmanned vehicle underwater sensor network ocean environment monitoring euclidean distance;navigation;estimation;autonomous underwater vehicles;mathematical model;vehicles;acoustic measurements;oceanographic techniques;wireless sensor networks autonomous underwater vehicles oceanographic techniques;wireless sensor networks;sea measurements	Underwater sensor networks represent a rapidly growing technology to monitor the ocean environment. This paper describes a solution to the problem of retrieving underwater dispersed sensors on behalf of an unmanned vehicle: assuming that the vehicle can only measure euclidean distances from itself to the dispersed sensors, an algorithm is designed allowing the vehicle to automatically find the sensors. The solution takes explicitly into account the presence of constant ocean currents and the availability of limited on-board navigation sensors.	acoustic cryptanalysis;algorithm;computer simulation;euclidean distance;experiment;mathematical model;on-board data handling;sensor;uncrewed vehicle;unmanned aerial vehicle	Giovanni Indiveri;Roberta Ingrosso;Michele Cuccovillo	2011	2011 15th International Conference on Advanced Robotics (ICAR)	10.1109/ICAR.2011.6088560	engineering;aeronautics;marine engineering;remote sensing	Robotics	55.58082111268675	-33.85735261799083	125174
ccb91154a440ae24c387e5e6c88b793ba335f243	intelligent computing and sensing for active safety on construction sites	camino mas corto;modelizacion;esquiva colision;shortest path;clutter;sistema activo;securite;image databank;routing;path planning;real time;routage;plus court chemin;intelligence artificielle;three dimensional;systeme actif;active system;planification trajectoire;modelisation;fouillis echo;obstacle avoidance;civil engineering;active safety;confusion eco;banco imagen;temps reel;banque image;safety;tiempo real;artificial intelligence;genie civil;collision avoidance;inteligencia artificial;esquive collision;seguridad;modeling;data acquisition;ingenieria civil;spatial model;enrutamiento	On obstacle-cluttered construction sites where heavy equipment is in use, safety issues are of major concern. The main objective of this paper is to develop a framework with algorithms for obstacle avoidance and path planning based on real-time three-dimensional job site models to improve safety during equipment operation. These algorithms have the potential to prevent collisions between heavy equipment vehicles and other on-site objects. In this study, algorithms were developed for image data acquisition, real-time 3D spatial modeling, obstacle avoidance, and shortest path finding and were all integrated to construct a comprehensive collision-free path. Preliminary research results show that the proposed approach is feasible and has the potential to be used as an active safety feature for heavy equipment.	algorithm;data acquisition;motion planning;obstacle avoidance;pathfinding;real-time clock;real-time locating system;shortest path problem	Carlos H. Caldas;Seokho Chi;Jochen Teizer;Jie Gong	2006		10.1007/11888598_11	three-dimensional space;routing;simulation;systems modeling;computer science;artificial intelligence;active safety;clutter;motion planning;obstacle avoidance;shortest path problem;data acquisition;computer security	Robotics	62.63694263965362	-37.19875394885438	125320
1955a11fadb1f4fbf80fd23f355493623d7a279d	proprioceptive control for a robotic vehicle over geometric obstacles	velocity;control systems;angular motion;autonomous vehicle;path planning;terrain intelligence;suspension force robotic vehicle geometric obstacles software system autonomous vehicle variable configuration rough terrain conditions action planning function proprioceptive algorithm wheel torques;surface roughness;proprioception;software systems;self operation;actuators;mobile robots;robotics;indexing terms;action plan;ground vehicles;computer programs;path planning mobile robots terrain mapping computerised navigation position control;feedback;position control;bearing direction;artificial intelligence;algorithms;robot control remotely operated vehicles actuators wheels sensor systems software systems mobile robots computer architecture land vehicles marine vehicles;rough terrain;terrain mapping;system architecture;attitude inclination;crossings;conference proceeding;computerised navigation	In this paper we describe a software system built to coordinate an autonomous vehicle with variable configuration ability operating in rough terrain conditions. The paper describes the system architecture, with an emphasis on the action planning function. This is intended to work with a proprioceptive algorithm that continuously coordinates wheel torques and suspension forces and positions to achieve optimal terrain crossing performance.	algorithm;autonomous robot;software system;systems architecture	Kenneth J. Waldron;Ronald C. Arkin;Douglas Bakkum;Ernest Merrill;Muhammad E. Abdallah	2003		10.1109/ROBOT.2003.1241581	control engineering;mobile robot;computer vision;simulation;index term;surface roughness;computer science;engineering;control system;artificial intelligence;circular motion;feedback;motion planning;proprioception;velocity;robotics;software system;actuator	Robotics	62.892509452851996	-27.81859657901923	125389
cfa12ee2ad9cb358cffdab0c5b26038c64592afe	real-time coordination and control of multiple heterogeneous uavs: the comets project	control systems;intelligent robots;intelligent transportation systems;real time;remotely operated vehicles;inspection;navigation;control system;humans;unmanned aerial vehicles intelligent robots navigation inspection intelligent transportation systems humans robot kinematics intelligent sensors remotely operated vehicles control systems;unmanned aerial vehicles;intelligent sensors;central station;robot kinematics	This video presents a control system that autonomously coordinates and supervises a fleet of heterogeneous UAVs to achieve complex observation missions. The system is composed of a central planning and monitoring station, and rely on a UAV decisional architecture that is designed to fit various levels of autonomy. The architecture and its adaptation to various kinds of UAVs is described, focusing on the role of the UAVs supervisors. A demonstration that illustrates a fire detection, confirmation and monitoring scenario, completed with a mapping task is shown. It involves three UAVs : two helicopters and a blimp, each of them being endowed with a supervisor linked to the central station. During the demonstration, the UAVs achieve various observation tasks coordinated thanks to their supervisor.	autonomy;control system;real-time transcription;unmanned aerial vehicle	Simon Lacroix;Jeremi Gancet	2006	2006 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2006.282303	remotely operated underwater vehicle;control engineering;embedded system;intelligent transportation system;navigation;simulation;inspection;computer science;engineering;control system;artificial intelligence;control theory;robot kinematics;intelligent sensor	Robotics	57.010491488837886	-27.797395000544586	125569
3a4131a411a9c51c74747da7c6faecb781effc2e	mars exploration rover surface operations: driving opportunity at meridiani planum	mars;planetary surfaces;plains;mars robots space vehicles landmine detection minerals protection atmosphere soil instruments image sampling;aerospace engineering;mars rovers;mars exploration rover;robot arms;surface operations;meteorite craters;terrain;rover planners mars exploration rover surface operations meridiani planum opportunity eagle crater endurance crater martian atmosphere mobile robots victoria crater;mobile robots;autonomy;topography;planetary rovers;robot arm;aerospace robotics;mars exploration;mobile robots mars planetary rovers planetary surfaces aerospace robotics aerospace engineering meteorite craters;point of view;robot autonomy;mars surface	Since landing on the Meridiani Planum region of Mars in January 2004, the Mars exploration rover (MER) vehicle named Opportunity has been sending back pictures taken from several different craters that would provide evidence that the region did indeed have a watery past. This paper details the experience of driving Opportunity through this alien landscape during its first 400 days on Mars, from the point of view of the other rover planners, the people who tell the rover where to drive and how to use its robotic arm	image;image processing;robot;robotic arm;rover (the prisoner);victoria (3d figure)	Jeffrey J. Biesiadecki;Eric T. Baumgartner;Robert G. Bonitz;Brian K. Cooper;Frank R. Hartman;Chris Leger;Mark W. Maimone;Scott Maxwell;Ashitey Trebi-Ollennu;Edward Tunstel;John R. Wright	2005	2005 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2005.1571412	mobile robot;mars exploration program;terrain;robotic arm;computer science;plain;topography;exploration of mars;autonomy	Robotics	55.02026510297838	-30.44590935512025	125689
c653a275c1ad184a42a91aec9a93a5d1fee02f67	a force-distance model of humanoid arm withdrawal reflexes		This paper presents the force-distance model of humanoid robot arm withdrawal reflexes. The model was developed in order to provide humanoid robots with a generic withdrawal reflex that could complement other robot safety mechanisms based on collision avoidance, reduced momentum, and compliance. The model goes beyond existing work on withdrawal behaviours by studying reflexes for arbitrary poses on a humanoid robots. It is inspired by a human withdrawal reflex trigger mechanism, the reflex receptive field and the withdrawal motions in the model are based on human reflex motion data. The model is implemented on a Nao humanoid robot with its upper and lower arms covered in a custom made tactile skin sensor. The efficiency of the resulting reflexes is analysed in terms of the distance the stimulation point on the robot is moved away from the spacial point of impact and in terms of whether the robot collides with itself during the expression of the reflex.		Torbjørn S. Dahl;Alexandros Paraschos	2012		10.1007/978-3-642-32527-4_2	simulation;engineering;humanoid robot;artificial intelligence;communication	Robotics	67.93353208595735	-24.875791500282137	125847
bb5195a2a81b5bd7a3610b7df25f4a1ebfd7b991	terrain-based robot navigation using multi-scale traversability indices	robot sensing systems;traverse local behaviors;traverse global behaviors;mobile robot;fuzzy set theory mobile robots navigation collision avoidance fuzzy logic;surface roughness;terrain;robot navigation;mobile robots;orbital robotics;fuzzy set theory;fuzzy logic mobile robot terrain based navigation traversability index traverse global behaviors traverse regional behaviors traverse local behaviors seek goal behavior obstacle avoidance;rough surfaces;fuzzy logic;navigation;obstacle avoidance;traversability index;traverse regional behaviors;terrain based navigation;robots;navigation mobile robots rough surfaces surface roughness robot sensing systems propulsion laboratories extraterrestrial measurements space technology orbital robotics;simulation study;propulsion;space technology;collision avoidance;extraterrestrial measurements;seek goal behavior	The concepts of Local, Regional, and Global Traversability Indices have been introduced recently [ l , 8-91. These indices represent the suitability of a terrain for traversal by a mobile robot at different scales of resolution. This paper utilizes these indices to develop a navigation strategy for a mobile robot traversing a challenging terrain. .The traversability indices form the basis of three navigational behaviors; namely, Traverse-Local, Traverse-Regional, and TraverseGlobal behaviors. These behaviors are blended with the Seek-Goal behavior to ensure that the mobile robot reaches the goal safely while avoiding obstacles and impassable terrain segments. The paper is concluded by an illustrative graphical simulation study l.	graphical user interface;mobile robot;robotic mapping;simulation;traverse	Homayoun Seraji	2001		10.1109/FUZZ.2001.1008899	mobile robot;computer vision;simulation;computer science;artificial intelligence;mobile robot navigation	Robotics	54.48907071598619	-30.92186902820756	126043
244149f2aa1a21f3e9d927c6eb5390052aac12eb	localization on curved objects using tactile information	manipulators;convergence;fingers image segmentation partitioning algorithms kinematics shape image reconstruction forward contracts robots computational geometry computer science;global algorithm curved object localization tactile information finger localization rolling finger boundary segments curvature based analysis global convergence;global convergence;local convergence;computational complexity;computational complexity manipulators position measurement tactile sensors convergence;position measurement;tactile sensors	Thispaperoffers a computationalstudyof finger localizationon 2-D curvedobjectsusing tactile data which builds on efficient numericalprocessingof curves. Our first algorithm localizesonerolling finger on a stationary object. It finds all boundarysegmentswith the samearc lengthand total curvature computedfrom tactile data. Thealgorithm slidesan imaginary segmentalong the objectboundary byalternativelymarching its twoendpointsforward, stretchingor contractingthesegmentif necessary . Througha curvature-based analysisweestablishtheglobal convergenceof thealgorithmto every location of such a segmentand also derivethe local convergencerate. Thealgorithm runs in time linear in the sizeof the discretizedboundarycurvedomain,which is asymptotically asfastascomputingtheobject’s perimeterthroughnumericalintegration. Basedontheaboveresults,wethenpresenta globalalgorithm to localizetwo fingers rolling on a freeobject.Thishasconsider ablyimprovedoverour previouslocalalgorithm[6] usinga leastsquaresformulation. Thealgorithmpartitions theobjectboundary into segmentsoverwhich relatedtotal curvature functionsare monotonic.Thenit combinesbisectionwith forward marching to search for possiblelocationsof the fingers within every pair of such segments.	algorithm;imaginary time;sizeof;stationary process	Yan-Bin Jia	2001		10.1109/IROS.2001.976251	local convergence;computer vision;mathematical optimization;convergence;computer science;mathematics;computational complexity theory;engineering drawing;tactile sensor	Robotics	61.07743012212981	-37.93257154064063	126287
354291b79da458db771354ea806bcb27c9bfae0e	robust landmark estimation and unscented particle sampling for slam in dynamic outdoor environment	fastslam;data association;landmark estimation;simultaneous localization and mapping;unscented transformation		simultaneous localization and mapping	Atsushi Sakai;Teppei Saitoh;Yoji Kuroda	2010	JRM	10.20965/jrm.2010.p0140	computer vision;control theory;cartography	Robotics	53.79115074164246	-36.88507079826221	126314
4d01d8e7a05740d89d9d39a978d6e71ddab24d2c	unmanned aerial vehicles evolutional flight route planner using the potential field approach		This study proposes a newflight route-planning technique for autonomous navigation of unmanned aerial vehicles (UAVs) based on the combination of evolutionary algorithms with virtual potential fields. By combining a radial forcefieldwith a swirling forcefield, three-dimensional virtual potentialfields are constructed for repelling infeasible UAV flight routes from threatening zones. To ensure feasibility, major flight constraints are considered when searching for the optimal flight route. This study examines both singleand multiple-obstacle cases to determine the efficiency of the proposed flight route planner. The UAV navigation method uses an offline planner in known environments and an online planner for flight route replanning when popup threats emerge. Both planners were tested under various scenarios. The results show that the proposed planner can efficiently enable the safe navigation of UAVs.	aerial photography;unmanned aerial vehicle	Chun-Liang Lin;Chia-Sung Lee;Ching-Huei Huang;Tzu-Chiang Kao	2012	JACIC	10.2514/1.54107	simulation;aerospace engineering;aeronautics	Robotics	54.733589803154416	-26.154142551717545	126419
17082f1770d2f54f95066823b76315c2b1746824	simulation of an optical tracking control system of a differentially-driven wheeled robot	wheeled robots;computer mouse;mobile robots;autonomous robots;control system;kinematic modelling;optical tracking;tracking control;dynamic modelling;wmr;optical sensors;computer simulation	Reliable tracking control of autonomous wheeled mobile robots has long been a goal of researchers. To improve tracking precision, expensive sensor systems along with complicated algorithms are often used. This paper proposes a relatively simple and inexpensive method that maintains a good level of accuracy. This is accomplished by the use of optical sensors that are found in the common computer mouse. An additional advantage of this set-up is that the basic friction circle can be used instead of complex friction modelling. The entire system is dynamically modelled in MATLAB and Simulink.	algorithm;autonomous robot;computer mouse;control system;matlab;mobile robot;sensor;simulation;simulink	Loren Yeo;Sabu John;John P. T. Mo	2010	IJCAET	10.1504/IJCAET.2010.029593	computer simulation;control engineering;mobile robot;simulation;tracking system;computer science;engineering;control system;artificial intelligence;control theory;robot control	Robotics	58.78270096108843	-29.580079134581485	126465
f1f2179c0f6fbe6029e1d4227dcc6776cdcbd979	data fusion of stereo vision and gyroscope for estimation of indoor mobile robot orientation		Abstract   In this paper a Kalman filter based data fusion method uses a novel combination of stereo vision and gyroscope angular velocity information. The proposed solution helps to eliminate the gyroscope unbounded drift errors. Since the gyroscope offers a higher bandwidth and availability of angular velocity it is corrected with the stereo vision system which has lower bandwidth and availability but bounded errors. A successful set of experiments were conducted to evaluate the integrated angle calculated from gyroscope and the proposed sensor fusion method.	gyroscope;mobile robot;stereopsis	Ahmad Kamal Nasir;Christof Hille;Hubert Roth	2012		10.3182/20120403-3-DE-3010.00058	computer vision;geodesy;engineering;control theory	Robotics	55.5852159461263	-36.54758174859354	126618
1471a3053053eb378fe86c213146186943c895df	superdiffusive dispersion and mixing of swarms	deployment;levy flight;anomalous diffusion;reactive;swarm;coverage;levy walk;mixing;spatial computing;dispersion	A common swarm task is to disperse evenly through an environment from an initial tightly packed formation. Due to communication and sensing limitations, it is often necessary to execute this task with little or no communication between swarm members. Unfortunately, prior approaches based on repulsive forces or uniform random walks can often converge quite slowly. With an appropriate choice of random distribution, however, it is possible to generate optimal or near-optimal dispersion and mixing in swarms with zero communication. In particular, we discuss three extremely simple algorithms: reactive Levy walk, reactive ball dispersion, and purely reactive dispersion. All three algorithms vastly outperform prior approaches in both constrained and unconstrained environments, providing a range of options for trading off between aggressiveness and evenness in dispersion.	algorithm;converge;lévy flight;no-communication theorem;swarm	Jacob Beal	2015	TAAS	10.1145/2700322	mathematical optimization;simulation;lévy flight	ECom	56.523531541963294	-24.817891923924694	126757
888743eb13cd1abff002a11ebe4a7bc4b373dca4	a primer on autonomous aerial vehicle design	simultaneous localization and mapping slam;micro aerial vehicles mav;microsoft kinect;slam;data processing;laser interferometry detection and ranging lidar;mav;autonomous;compression;quadcopter;stereo cameras;article;lidar	There is a large amount of research currently being done on autonomous micro-aerial vehicles (MAV), such as quadrotor helicopters or quadcopters. The ability to create a working autonomous MAV depends mainly on integrating a simultaneous localization and mapping (SLAM) solution with the rest of the system. This paper provides an introduction for creating an autonomous MAV for enclosed environments, aimed at students and professionals alike. The standard autonomous system and MAV automation are discussed, while we focus on the core concepts of SLAM systems and trajectory planning algorithms. The advantages and disadvantages of using remote processing are evaluated, and recommendations are made regarding the viability of on-board processing. Recommendations are made regarding best practices to serve as a guideline for aspirant MAV designers.	aerial photography;algorithm;automated planning and scheduling;autonomous robot;autonomous system (internet);best practice;drug vehicle;on-board data handling;primer;recommender system;slamf1 gene;simultaneous localization and mapping;x-ray microtomography	Hugo H. G. Coppejans;Herman C. Myburgh	2015		10.3390/s151229785	lidar;stereo cameras;computer vision;simulation;data processing;computer science;engineering;autonomy;compression;physics;remote sensing	AI	56.07762151807568	-30.844818578355493	126816
64389f78ac2077a0ae9cd23cef9f78dbfb34c948	a hexapod walks over irregular terrain using a controller adapted from an insect's nervous system	robot sensing systems;neurophysiology legged locomotion;legged wonder;legged locomotion;nervous system;neurobiological method;foot;joints;hexapod robot;hexapod walk;leg joints robot sensing systems legged locomotion robot kinematics foot;hexapod robot hexapod walk irregular terrain insect nervous system neurobiological method legged wonder;design and implementation;walking robot;insect nervous system;irregular terrain;neurophysiology;legged robot;leg;control method;robot kinematics	Insects have long been a source of inspiration for the design and implementation of legged robots. Their extraordinary mobility, agility, and adaptability are features sought after when developing competent, useful mobile walkers. Externally witnessed behaviors have been successfully implemented in walking robots for decades with great success. More recent years of biological study have solved some of the mysteries surrounding the actual neurobiological methods for mobilizing these legged wonders. This paper describes the first implementation of these neurobiological mechanisms in a physical hexapod robot that is capable of generating adaptive stepping actions with the same underlying control method as an insect.	autonomous robot;centralized computing;control system;emergence;experiment;ganglia;interaction;modulation;stepping level;the world wonders	William A. Lewinger;Roger D. Quinn	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5650200	control engineering;simulation;computer science;engineering;artificial intelligence;hexapod;nervous system;neurophysiology;robot kinematics;foot	Robotics	67.30581719030845	-25.57461206559696	126885
eae33a78fbdc01dd46e8d631dca078be76a66973	simulative analysis of accuracy demands of co-operative localization in the covel project	vehicles global positioning system position measurement accuracy mathematical model wheels global navigation satellite systems;inertial navigation;vehicular ad hoc networks global positioning system inertial navigation;global positioning system;vehicle to vehicle communication simulative analysis cooperative localization covel project vehicle localization positioning accuracy;vehicular ad hoc networks	Accurate and reliable vehicle localization is a challenging task. As the sensor budget of a vehicle is limited, new approaches to improve the positioning accuracy have to be exploited. One cost-efficient option is to incorporate digital maps to perform some kind of map matching. Furthermore, vehicle-to-vehicle communication can be used to exchange information about the relative position of the vehicles, which in turn can also be used to improve the ego positioning. The described approach is elaborated in the European Project COVEL. This paper aims to evaluate the influence of the accuracy of the relative position information as well as the number of communicating vehicles to the accuracy of a position estimated from this information. To do so, a simulation environment using data from a real test drive has been created. The algorithmic results were compared to Ground Truth data from a high-accuracy and high-availability GPS/INS reference system.	algorithm;amos fiat;cost efficiency;global positioning system;ground truth;high availability;image scaling;internationalization and localization;map matching;microsoft outlook for mac;motion estimation;odometry;real-time transcription;scalability;simulation;test drive;vehicle-to-vehicle;yaws	Norman Mattern;Marcus Obst;Robin Schubert;Gerd Wanielik	2011	2011 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2011.5940520	embedded system;simulation;geography;precise point positioning;computer security	Robotics	54.4348302870819	-36.3202711705189	127074
434c9583cfaa3dff5bf3f42b4cc1e6748375e449	kinematic estimator for flexible links in parallel robots		Control of flexible link parallel manipulators is still an open area of research. The flexibility and deformations of the limbs make the estimation of the Tool Center Point (TCP) position a non-trivial area, being one of the main challenges on this type of robots. In the literature different approaches to estimate this deformation and determine the location of the TCP have been proposed. However, most of these approaches require the use of high computational cost integration methods or expensive measurement systems. This work presents a novel approach which can not only estimate precisely the deformation of the flexible links (less than 3% error), but also its derivatives (less than 4% error). The validity of the developed estimator is tested in a Delta Robot, resulting in less than 0.025% error in the estimation of the TCP position in comparison with the results obtained with ADAMS Multibody software.	parallel manipulator;robot	Pablo Bengoa;Asier Zubizarreta;Itziar Cabanes;Aitziber Mancisidor;Charles Pinto	2017		10.1007/978-3-319-70836-2_58	estimator;delta robot;deformation (mechanics);computer vision;artificial intelligence;computer science;robot;kinematics;parallel manipulator;control engineering;software	Robotics	57.8840080803505	-35.981112627305336	127175
ee9f25fe06ebd33743a6d508133795e88bc85b74	detection of cattle using drones and convolutional neural networks	unmanned aerial vehicle;cattle detection;convolutional neural network;drone;multirotor	Multirotor drones have been one of the most important technological advances of the last decade. Their mechanics are simple compared to other types of drones and their possibilities in flight are greater. For example, they can take-off vertically. Their capabilities have therefore brought progress to many professional activities. Moreover, advances in computing and telecommunications have also broadened the range of activities in which drones may be used. Currently, artificial intelligence and information analysis are the main areas of research in the field of computing. The case study presented in this article employed artificial intelligence techniques in the analysis of information captured by drones. More specifically, the camera installed in the drone took images which were later analyzed using Convolutional Neural Networks (CNNs) to identify the objects captured in the images. In this research, a CNN was trained to detect cattle, however the same training process could be followed to develop a CNN for the detection of any other object. This article describes the design of the platform for real-time analysis of information and its performance in the detection of cattle.	algorithm;artificial intelligence;autonomous robot;computation (action);convolutional neural network;execution;experiment;federal law on protection of personal data held by individuals;global positioning system;identifier;linear algebra;mechanics;ninety nine;olami–feder–christensen model;physical object;real-time web;unmanned aerial vehicle;video;hemoglobin castilla	Alberto Rivas;Pablo Chamoso;Alfonso González-Briones;Juan Manuel Corchado	2018		10.3390/s18072048	convolutional neural network;electronic engineering;drone;engineering;artificial intelligence	AI	55.853898381151566	-29.88043496895822	127314
46936d2311c0216357405530b26f1ee1a461a3a2	sensor data integration based on the border distance model	robot sensing systems;data integrity;mobile robot;data processing;mobile robots;autonomous mobile robot;data mining;minimum distance;solid modeling;information processing;sensor fusion;machinery;intelligent sensors;intelligent sensors mobile robots solid modeling robot sensing systems sensor fusion data processing equations machinery information processing data mining			Takanori Ikegami;Jun-ichi Kato;Shigeo Ozono	1989		10.1109/IROS.1989.637884	control engineering;mobile robot;embedded system;computer vision;data processing;information processing;computer science;engineering;artificial intelligence	DB	56.931373077625345	-31.35924858311054	127434
bb8ce70d6834e50e3d8aa78ee320614f0b6bdbbc	an automated method to calibrate industrial robots using a virtual closed kinematic chain	contraste;robot calibration kinematic parameter estimation laser tool parameter identification robot accuracy;lasers;virtual closed kinematic chain;fixed point theorem;measurement accuracy;standard deviation;real time;prensor robot;localization;kinematic parameter estimation;feedback system virtual closed kinematic chain industrial robot calibration algorithm robot kinematic calibration methods end effector joint angle measurements;mesure position;joint angle measurements;angular measurement;punto fijo;localizacion;robotics;orientation;kinematics;manipulator kinematics;parameter identification;cinematique robot;theoreme point fixe;robot industriel;medicion posicion;teorema punto fijo;fixed point;prehenseur;medida angulo;robot calibration;localisation;retroaccion;estimation;retroaction;point fixe;service robots robotics and automation calibration end effectors robot kinematics current measurement position measurement goniometers feedback real time systems;laser pointer;precision mesure;mesure angle;industrial robots;identification;temps reel;end effector;robot industrial;robot accuracy;position measurement;feedback regulation;robotica;orientacion;tiempo real;robot kinematic calibration methods;etalonnage;robotique;parameter estimation;precision medida;feedback system;manipulator kinematics calibration end effectors industrial manipulators;gripper;industrial robot calibration algorithm;calibration;fix point;industrial manipulators;laser tool;end effectors;robot kinematics;industrial robot	This paper describes an industrial robot calibration algorithm called the virtual closed kinematic chain method. Current robot kinematic calibration methods use measurements of position and orientation of the end effector. The accuracy of these measurements is limited by the resolution of the measuring equipment. In the proposed method, a laser pointer tool, attached to the robot's end effector, aims at a constant but unknown location on a fixed object, effectively creating a virtual 7 DOFs closed kinematic chain. As a result, small variations in position and orientation of the end effector are magnified on the distant object. Hence, the resolution of observations is improved, increasing the accuracy of joint angle measurements that are required to calibrate the robot. The method is verified using both simulation and real experiments. It is also shown in simulation that the method can be automated by a feedback system that can be implemented in real time. The accuracy of the robot after using the proposed calibration procedure is measured by aiming at an arbitrary fixed point and measuring the mean and standard deviation of the radius of spread of the projected points. The mean and standard deviation of the radius of spread were improved from 5.64 and 1.89 mm to 1.05 and 0.587 mm, respectively.	algorithm;communication endpoint;experiment;fixed point (mathematics);image resolution;industrial robot;kinematic chain;planar (computer graphics);pointer (computer programming);robot calibration;robot end effector;simulation	Chandra Sekhar Gatla;Ronald Lumia;John E. Wood;Gregory P. Starr	2007	IEEE Transactions on Robotics	10.1109/TRO.2007.909765	control engineering;robot end effector;simulation;computer science;engineering;artificial intelligence;control theory;mathematics;robotics;statistics;robot calibration	Robotics	59.571710039502754	-35.839470182822225	127441
88b9f4056a5e93857087ac71b4e176ad6932eb91	the impact of cooperative perception on decision making and planning of autonomous vehicles	vehicles roads hidden markov models sensors planning mobile robots satellites;sensors;mobile robots;hidden markov models;roads;road vehicles decision making mobile communication mobile robots;satellites;planning;satellite view cooperative perception decision making autonomous vehicles planning local sensing information wireless communications augmented perception capability oncoming traffic information field of view unmanned vehicles manned vehicles on road sensing system see through extended perception capability augmented situation awareness lifted seat;vehicles	In this article, we investigate how cooperative perception gives the impact on decision making and planning of autonomous vehicles on the road. Cooperative perception is the exchange of local sensing information with other vehicles or infrastructures via wireless communications, by which the perception range can be considerably extended up to the boundary of connected vehicles. This augmented perception capability can provide oncoming traffic information beyond line-of-sight and field-of-view, which enables better control of both manned and unmanned vehicles. In this article, we first present an on-road sensing system to provide a see-through/lifted-seat/satellite view to drivers. Then, we investigate how the extended perception capability can contribute to situation awareness on the road. Finally, we provide methods for safer and smoother autonomous driving using the augmented situation awareness and perception capability. All introduced and proposed concepts are implemented and validated on autonomous vehicles.	autonomous car;autonomous robot;autonomous system (internet);cooperative mimo;line-of-sight (missile);unmanned aerial vehicle	Seong-Woo Kim;Wei Liu;Marcelo H. Ang;Emilio Frazzoli;Daniela Rus	2015	IEEE Intelligent Transportation Systems Magazine	10.1109/MITS.2015.2409883	planning;mobile robot;computer vision;simulation;computer science;engineering;sensor;transport engineering;satellite;hidden markov model	Robotics	54.11203020552538	-31.45013289294848	127725
cac26c91ebfee1d034b3c583974816d8933a31c1	using mems sensors to enhance positioning when the gps signal disappears		This paper presents the concept of using embedded MEMS sensors position objects especially when the GPS signal is weak, e.g. in underground car parks, tunnels. Such an approach is important for controlling indoor objects or autonomous vehicles. The signals are acquired by a Raspberry Pi platform with external sensors such as an accelerometer, gyroscope and magnetometer. A self-propelled vehicle was used and several exemplary paths were designed for acquiring signals. It was proven that appropriate signal filtering allows a position to be determined with a small error at a constant velocity condition. Comparing filters such as the moving average, median, Savitzky-Golay and Hampel filters were investigated. Moreover, the system offers a high degree of accuracy in a short time for indoor hybrid positioning systems that also have video processing capabilities. The cyber-physical system can also be used with the existing infrastructure in a building, such as Wi-Fi access points and video cameras.	gps signals;global positioning system;microelectromechanical systems;sensor	Damian Grzechca;Krzysztof Tokarz;Krzysztof Paszek;Dawid Poloczek	2017		10.1007/978-3-319-67077-5_25	computer science;machine learning;artificial intelligence;filter (signal processing);gps signals;pi;embedded system;global positioning system;electronic engineering;accelerometer;hybrid positioning system;video processing;gyroscope	Mobile	56.11149952734687	-34.46121445271475	127816
728dbe93a2f1b97f88aa2130be7d206f711f0672	homography-based visual servo tracking control of a wheeled mobile robot	lyapunov methods;servomechanisms mobile robots target tracking motion control control systems robot vision systems cameras image sequences trajectory kinematics;mobile robots;image reconstruction homography based visual servo tracking control wheeled mobile robot monocular camera system underactuated wheeled robot image sequence projective geometric relationships euclidean homography kinematic controller lyapunov based analysis;wheeled mobile robot;robot vision;lyapunov methods servomechanisms robot vision robot kinematics mobile robots cameras image sequences image reconstruction tracking;image reconstruction;servomechanisms;image sequence;tracking control;visual servoing;cameras;tracking;robot kinematics;image sequences	A visual servo tracking controller is developed in this paper for a monocular camera system mounted on an underactuated wheeled robot (WMR) subject nonholonomic motion constraints (i.e., the camera-in-hand problem). A prerecorded image sequence (e.g., a video) of three target points is used to define a desired trajectory for the WMR. By comparing the target points from the prerecorded sequence with the corresponding target points in the live image, projective geometric relationships are exploited to construct a Euclidean homography. The information obtained by decomposing the Euclidean homography is used to develop a kinematic controller. A Lyapunov-based analysis is used to develop an adaptive update law to actively compensate for the lack of depth information required for the translation error system.	homography (computer vision);mobile robot;servo;visual servoing	Jian Chen;Warren E. Dixon;Darren M. Dawson;Michael L. McIntyre	2003		10.1109/IROS.2003.1248907	iterative reconstruction;homography;control engineering;mobile robot;computer vision;computer science;artificial intelligence;control theory;tracking;visual servoing;robot kinematics	Robotics	60.93571049141561	-32.07340281056774	127935
ac1f5a28886e2dd4f71b22dc3d72c967ded53c28	image feedback path tracking control using an uncalibrated ccd camera	ccd camera;control algorithm;real time;intelligent machining;key words vision servo visual feedback tracking control thinning algorithm intelligent machining;tracking control;visual feedback;camera calibration;path tracking;thinning algorithm;vision servo	 Abstract. Image feedback path tracking (IFPT) control of a laser light point (LLP) using a CCD camera is studied in this paper. The tracking path and the LLP are assumed clearly focused in the scene, but no camera calibration is needed. A modified version of the thinning algorithm SPTA is proposed to skeletonize the path in a piecewise manner. The proposed thinning algorithm takes less computer time than the original SPTA and makes the real-time skeletonization possible. Included in the paper is also the development of a control algorithm with image feedback to assure LLP tracking along the required path, as well as an experimental study to demonstrate how IFPT control can be realized in practice.	algorithm;camera resectioning;charge-coupled device;experiment;national supercomputer centre in sweden;real-time clock;real-time locating system;thinning;topological skeleton	Ku Chin Lin;Mi Ching Tsai	2000	Machine Vision and Applications	10.1007/s001380050124	computer vision;camera resectioning;simulation;tracking system;computer science;charge-coupled device	Robotics	60.05734076393889	-33.02100576782005	128036
40acbd232111ac2ff60e5f1f7fa06b497764b0bf	legged robots	useful legged vehicle;legged machine;legged robot;legged locomotion	Research on legged machines can lead to the construction of useful legged vehicles and help us to understand legged locomotion in animals.	robot	Marc H. Raibert	1986	Commun. ACM	10.1145/5948.5950	robot control	Robotics	66.2483516204709	-27.379753559708742	128204
a2e9dfa6008fd662f49a29d73517ab5d1fb7a1c0	close range tracking of an uncooperative target in a sequence of photonic mixer device (pmd) images		German Space Operations Center, German Aerospace Center, Muenchener Str. 20, 82234 Wessling, Germany; jacopo.ventura@dlr.de (J.V.); heike.benninghoff@dlr.de (H.B.); felix.huber@dlr.de (F.H.) * Correspondence: ksenia.klionovska@dlr.de; Tel.: +49-8153-283465 † This paper is extended version of an earlier conference paper Ksenia Klionovska, Jacopo Ventura, Heike Benninghoff, Felix Huber. Close range tracking of an Uncooperative Target in a Sequence of PMD Images. In proceeding of 1st IAA Conference on Space Situation Awareness (ICSSA), Orlando, FL, USA, 13–15 November 2017.	c++ string handling;pmd;time-of-flight camera	Ksenia Klionovska;Jacopo Ventura;Heike Benninghoff;Felix Huber	2018	Robotics	10.3390/robotics7010005	control engineering;computer vision;grayscale;image processing;redundancy (engineering);point cloud;artificial intelligence;pose;rendezvous;engineering;ranging;lidar	Robotics	53.808024729070915	-36.355874423037776	128213
fee00084f8d96314a7f969f09e0cfe25ab4c9c4d	infeasibility driven evolutionary algorithm with the anticipation mechanism for the reaching goal in dynamic constrained inverse kinematics	constraints handling;infeasibility driven evolutionary algorithm;proactive evolutionary algorithm;inverse kinematics;dynamic optimization problem	A dynamic version of the Inverse Kinematics problem addresses the two main objectives: One objective is to find a configuration of joints such that a desired pose and orientation can be reached by a robotic arm. Another one is to preserve this state in a continuously changing environment. In this paper a reaching goal in dynamic constrained Inverse Kinematics is considered where either a target point to be reached or locations of obstacles or both can change in time. The Infeasibility Driven Evolutionary Algorithm is applied for an exploration of the set of possible joint angles configurations in every moment. Additionally, the anticipation mechanism based on Auto-Regressive Integrated Moving Average Model is used in order to speed up an adaptation process so that a population of candidate solutions can be directed in advance towards the most probable future global optima.	evolutionary algorithm;inverse kinematics;moving-average model;robot;robotic arm	Patryk Filipiak;Krzysztof Michalak;Piotr Lipinski	2015		10.1145/2739482.2764683	mathematical optimization;simulation;artificial intelligence;mathematics	Robotics	54.23805090562652	-24.257129235193517	128294
7b56af7e1129e1049d7f9047e756614848186cf3	autonomous driving of intelligent vehicle bit in 2009 future challenge of china	rgb space;intelligent vehicle;autonomous driving;turning;traffic lights recognition;path planning;laser radar;mobile robots;testing;remotely operated vehicles;navigation;formal verification;path planning method;roads;global positioning system;intelligent vehicles;haar feature;traffic engineering computing automatic guided vehicles formal verification haar transforms learning artificial intelligence path planning pattern classification road vehicles tracking;pattern classification;curve tracking strategy;traffic engineering computing;hsv space autonomous driving intelligent vehicle china bit system structure path planning method curve tracking strategy curve bisector complex path traffic lights recognition haar feature adaboost algorithm rgb space;automatic guided vehicles;complex path;vehicles;curve bisector;learning artificial intelligence;target tracking;china;haar transforms;hsv space;bit system structure;cameras;intelligent vehicles path planning testing decision making navigation remotely operated vehicles mobile robots global positioning system laser radar cameras;tracking;adaboost algorithm;wheels;road vehicles	The 2009 Future Challenge - Intelligent Vehicle and Beyond (FC'09) was held in Xi'an, China. Our intelligent vehicle named BIT participated in all competitions at this event. This paper describes BIT's system structure and its capabilities. BIT combines a global path planning method and local path planning to drive the vehicle to address the challenges posted by the unknown competition environment. A novel curve tracking strategy based on preview and curve bisector is developed for complex paths such as U-turn. For recognizing traffic lights, Haar feature and AdaBoost algorithm are used to train and obtain traffic light classifiers. Normalization of every candidate region in RGB and HSV spaces is performed and compared with a threshold to fulfill the verification. The experiment describes BIT's performance and the conclusion sets forth the main work in the next step.	adaboost;algorithm;autonomous car;haar wavelet;motion planning	Guangming Xiong;Peiyun Zhou;Shengyan Zhou;Xijun Zhao;Haojie Zhang;Jianwei Gong;Huiyan Chen	2010	2010 IEEE Intelligent Vehicles Symposium	10.1109/IVS.2010.5548147	embedded system;computer vision;simulation;engineering	Robotics	55.06132699441019	-31.893434235881955	128304
2c0351c53b63e88e8f44acdcc85d365161d4ade9	decentralized control of multi-articular snake-like robot for efficient locomotion	animals;oscillations;cost function;degree of freedom;real time;joints;force;control system;decentralised control;muscles robots distributed control force joints animals cost function;robots;decentralized control;central pattern generator;antagonistic muscle tendon chains decentralized control multiarticular snake like robot efficient locomotion multiarticular muscles;robot dynamics;robot dynamics decentralised control;continuum model;mechanical systems;distributed control;muscles	The mechanism of multi-articular muscles that contributes to the emergence of macroscopic behavior of animals has not been clarified thus far. To address this issue, we focus on the slithering motion of snakes, which have numerous antagonistic muscle-tendon chains that span several tens of vertebrae. From theoretical analyses based on the continuum model, the acceleration of the body in the longitudinal direction is found to be proportional to the number of segments spanned by each muscle. On the basis of this theoretical result, we propose a decentralized control scheme for the efficient locomotion of a multi-articular snake-like robot. We conduct simulations using this control scheme, and the results show that the locomotion efficiency increases as the number of segments spanned by each muscle increases	distributed control system;emergence;robot;simulation;triune continuum paradigm	Takeshi Kano;Takahide Sato;Ryo Kobayashi;Akio Ishiguro	2011	2011 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6094712	robot;control engineering;central pattern generator;simulation;decentralised system;computer science;engineering;control system;artificial intelligence;control theory;degrees of freedom;mechanical system;oscillation;force	Robotics	67.98111825699624	-24.591564347861265	128396
2a370210e1734c69b47f6f0fdf851b65efa0e42f	a dynamic bipedal walking method using coupled elastic actuation	robot dynamics legged locomotion motion control;motion control;legged locomotion;walker dynamics dynamic bipedal walking method coupled elastic actuation actuated level ground walking method passive dynamic walker actuated bars linear spring potential energy spring coefficient periodical walking gait period doubling bifurcation chaos gait evolution;legged locomotion springs bars potential energy chaos force dynamics;robot dynamics	The aim of this research is to find an actuated level ground walking method, which is analogous to the dynamics of a passive dynamic walker on a slope. We propose to take advantage of the coupled elastic to actuate legs. As a result, maintaining the character of passive dynamic and a simple control algorithm are achieved simultaneously. In our walking model, actuated bars are installed on each leg and connected with a linear spring at their ends. By properly swinging the bars forward and backward periodically, the spring is stretched to store potential energy at the walker's each stride. And after the heel strike the stored energy is transported to the whole system to compensate for the energy lost at the heel strike. By tuning three control parameters, namely the spring coefficient, the length and amplitude of the actuated bar, the walker exhibits stable periodical walking gait. While continuously changing these parameters, the gait of the walker also demonstrates period-doubling bifurcation and chaos. In some certain parameters, the gait can also evolves from chaos back to bifurcation. This gait evolution phenomenon has never been reported in the actuated walking robot before, it shows that the walker's dynamics is somewhat analogical to the passive dynamic walker. We also show this walker can walk over a wide range of speed, that have a reference value to build the actual robot.	algorithm;amazon elastic compute cloud (ec2);amiga walker;bifurcation theory;coefficient;mobile robot;motor babbling;period-doubling bifurcation;prototype;sudden strike	Mingguo Zhao;Botao Wu	2013	2013 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2013.6739775	control engineering;motion control;simulation;engineering;control theory	Robotics	66.95107091771261	-24.40338929479977	128612
a4a43cfa3eb1d5b7af126160477e6cf085244789	exploration strategies for a robot with a continously rotating 3d scanner	3d laser scanner;competitive strategy;path planning;simulation framework;evaluation framework	To benchmark the efficiency of exploration strategies one has to use robot simulators. In an exploration task, the robot faces an unknown environment. Of course one could test the algorithm in different real-world scenarios, but a competitive strategy must have good performance in any environment that can be systematically constructed inside a simulator. This paper presents an evaluation of exploration strategies we developed for a specific sensor. A continously rotating 3D laser scanner that scans only into one direction at a time moves through the environment sampling the surrounding. Our evaluation framework features an efficient scanning and robot simulator for kinematic feasible trajectories. We will show that shorter trajectories do not necessarily imply quicker exploration. A simple simulator framework is sufficient for evaluating these properties of path planning algorithms.	3d scanner;algorithm;benchmark (computing);motion planning;robot;sampling (signal processing);sensor;simulation;strategic management	Elena Digor;Andreas Birk;Andreas Nüchter	2010		10.1007/978-3-642-17319-6_35	computer vision;simulation;computer science;artificial intelligence;motion planning;competitive advantage	Robotics	54.30063707725695	-24.988143962955686	128645
235af9926a85a951819cd501b2c50eff4e40aa6a	cooperative multi-agent inference over grid structured markov random fields	approximate algorithm;multi agent system;approximation algorithms;approximation method;computer model;data capture;markov random field;computational modeling;markov process;message passing inference algorithms modis approximation methods approximation algorithms computational modeling probabilistic logic;detection rate;message passing;modis;inference algorithms;approximation methods;approximate inference;markov processes;autonomous surface vehicle;probabilistic logic;loopy belief propagation;scale invariance	In this work we investigate cooperative inference in multi-agent systems where uncertainty is modeled by the grid structured pairwise Markov random field. A framework is proposed, which we term the multi-agent Markov random field, that decomposes the global inference problem into inter-agent belief exchanges over a hypertree topology and local intra-agent inference problems. Due to the exponential complexity of exact inference, we propose a loopy belief propagation algorithm for approximate inference over appropriately formed local generalized cluster graphs. Both synchronous and intelligent message passing are considered and a grid scale-invariant scheme based on the notion of regions of influence in a cluster graph is presented. The algorithms are simulated over a grid workspace with a team of virtual Autonomous Surface Vehicles (ASVs), with the goal of spatial plume detection in oceanographic data captured from the Moderate Resolution Imaging Spectroradiometer (MODIS) instrument. We show that while the exact method produces predictably accurate and smooth grid maps, the approximate method competes well in terms of plume detection rate with the region of influence message passing scheme excelling over large tasks due to a lack of dependence on grid size.	agent-based model;approximation algorithm;belief propagation;casio loopy;computation;grid (spatial index);map;markov chain;markov random field;message passing;model checking;multi-agent system;norm (social);overhead (computing);plume (fluid dynamics);region of interest;requirement;robot;simulation;software propagation;time complexity;workspace	Ryan K. Williams;Gaurav S. Sukhatme	2011	2011 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6094872	mathematical optimization;computer science;theoretical computer science;machine learning;multi-agent system;markov process;approximation algorithm;statistics	Robotics	53.854504979029514	-27.187105326882392	128739
5996307fc3fccd0cc7a99360a7347bbb89556ba3	low-speed modeling and simulation of torpedo-shaped auvs		Autonomous underwater vehicles (AUVs) have become important in many marine engineering applications, such as environmental monitoring, pipeline inspections, or oceanography. For these types of applications, most of the AUVs available in both academia and industry are shaped like a torpedo and travel at speeds of 3 knots or higher. There is an growing interest in AUVs that are capable of performing tasks at both low-speed as well as high speeds. Currently, many torpedo-shaped AUVs are not capable of controlled low-speed motion. This paper presents a simulation model for the low-speed motion of torpedo-shaped AUVs. The model is capable of simulating the surge, sway, heave, and yaw motions. The hydrodynamic forces acting on the AUV hull are modelled using strip theory, experimental data, and computational fluid dynamics. The simulation model was implemented using a commercially available software and validated using experimental data obtained from the Gavia AUV. The results show that the simulation model captures the AUV motion at low-speed and agrees well with the experimental data.	computation;computational fluid dynamics;emoticon;experiment;pipeline (software);pulse (signal processing);simulation;testbed;vortex;yaws	Bjarni Helgason;Leifur Þ. Leifsson;Indridi Rikhardsson;Helgi Thorgilsson;S. Kozie&#x0142;	2012			engineering;control engineering;torpedo;modeling and simulation	Robotics	66.02617132570742	-30.621107409668994	128890
bb3d6add7506d48baa80e5a3377dafa0f081bfc3	developing central pattern generator based periodic motions using tactile interaction	evaluation function;touch physiological;motion control;legged locomotion;oscillators;robot motions;joints;policy gradient;tactile interaction;motion control central pattern generator periodic motions tactile interaction bio inspired technique robot motions genetic algorithms policy gradient;centralised control;touch physiological centralised control motion control robot dynamics;motion control automatic control centralized control automatic generation control robot control robotics and automation robot motion genetic algorithms robot programming control systems;periodic motions;tactile sensors;genetic algorithm;bio inspired technique;genetic algorithms;central pattern generator;robot dynamics	Controlling robots by Central Pattern Generators (CPGs) is a widespread bio-inspired technique for the realization of robot motions. The numerous parameters of the CPGs, often specialized for a specific task, are usually set by automatic techniques like genetic algorithms or policy gradient. However, using these approaches leaves the users with little control on the resulting motion, which can be modified only by changing the evaluation function. Conversely manually setting each parameter gives the user full control over the motion, but identifying which parameters should be altered to obtain a desired effect is not intuitive and therefore developing motion requires time and effort. We present a system that allows programming the CPG parameters by interacting with the robot and in particular by intuitively touching the robot, giving the user full control on the resulting motion without requiring a direct modification of the parameter values.	british informatics olympiad;central pattern generator;evaluation function;genetic algorithm;gradient;interaction;robot	Fabio Dalla Libera;Takashi Minato;Hiroshi Ishiguro;Emanuele Menegatti	2009	2009 9th IEEE-RAS International Conference on Humanoid Robots	10.1109/ICHR.2009.5379591	simulation;genetic algorithm;computer science;artificial intelligence;control theory	Robotics	65.71481153984493	-24.897999263767066	128912
f3298dc5d23f5c7d976dcd27ae30792314e8ff7a	a formation control approach to adaptation of contour-shaped robotic formations	general curve evolution theory;autonomous underwater vehicle;keywords autonomous underwater vehicles;formation control;flexible manipulators;spatial reasoning;geometrical reasoning formation control contour shaped robotic formations plume boundaries flock shepherding shape formation general curve evolution theory;underwater vehicles;curve evolution;formations;boundary conditions;path planning;geometrical reasoning;virtual reality;flock shepherding;robotics autonomous underwater vehicles;contour shaped robotic formations;mobile robots;robotic formations;conference paper;plume boundaries;curve evolution theory;position control;autonomous underwater vehicles;geometric reasoning;underwater vehicles mobile robots multi robot systems path planning position control spatial reasoning;swarms;multi robot systems;robot kinematics intelligent robots shape robot sensing systems australia aggregates underwater vehicles distributed control mobile robots remotely operated vehicles;exploration;shape formation;exploration autonomous underwater vehicles formations distributed control swarms;distributed control;distributed parameter control systems	Much research has been done in the area of robot formations. Most of them consider rigid formations where the robot aggregate forms a rigid virtual body. Relatively little has been done on deformable formations composed of rigid links as well as flexible ones. In this paper, we will examine and design controllers for a special type of robotic formations, i.e., those resembling contours. These type of formations have numerous applications in the underwater world, including adaptation to plume boundaries and isoclines of concentration fields, flock shepherding, and shape formation. We adopt general curve evolution theory as a suitable abstraction to describe the motion of such formations. We will first design controllers using simple geometrical reasoning, based on basic requirements on connectivity and mission accomplishment, and will later show that they lead to the same controller structure	aggregate data;consensus dynamics;contour line;flock;plume (fluid dynamics);requirement;robot;virtual body	Shahab Kalantar;Uwe R. Zimmer	2006	2006 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2006.281977	control engineering;mobile robot;computer vision;swarm behaviour;simulation;exploration;boundary value problem;computer science;engineering;artificial intelligence;motion planning;virtual reality;spatial intelligence	Robotics	68.02700399115307	-24.07505829798661	128990
f89754fd981103db18f5c60005a80a2fdd73d32a	modelling uneven terrain for geo-location of mines detected via vehicular mounted sensors	search problem;modelizacion;ruido aleatorio;landmine detection;mesure distance;topographie;bruit aleatoire;informacion incompleta;infrared thermography;localization;radar abertura sintetica;systeme gps;localizacion;robotics;digital elevation model;problema investigacion;gps system;topography;data association;mine detection;modelisation;captador medida;incomplete information;thermographie ir;distance measurement;random noise;measurement sensor;capteur mesure;localisation;vehicular mounted sensors;field of view;ranging lasers;information incomplete;detecteur ir;robotica;termografia ir;terrain modeling;digital elevation models;robotique;landmine search;infrared;infrared detector;probleme recherche;modeling;detector rayos infrarrojos;radar ouverture synthetique;detection mine terrestre;landmine geo location;topografia;sistema gps;synthetic aperture radar	Modelling uneven terrain for geo-location of mines detected via vehicular mounted sensors Smriti Kansal a , Gerald Cook a , Charles Amazeen b & Kelly Sherbondy b a Department of Electrical and Computer Engineering , School of Information Technology and Engineering, George Mason University , 4400 University Drive, Fairfax, VA 22030, USA b Countermine Technology Team , NVESD , Fort Belvoir, VA 22060-5806, USA c Department of Electrical and Computer Engineering , School of Information Technology and Engineering, George Mason University , 4400 University Drive, Fairfax, VA 22030, USA Email: Published online: 23 Feb 2007.	computer engineering;email;geolocation;kelly criterion;mason;sensor	Smriti Kansal;Gerald Cook;Charles Amazeen;Kelly Sherbondy	2005	Int. J. Systems Science	10.1080/00207720500119130	digital elevation model;telecommunications;topography;robotics	SE	58.34068947504788	-33.5102730427149	129311
96ca752ca42ecd60950c8f41f90292a4c78d7017	locomotion gait optimization for modular robots; coevolving morphology and control	central pattern generators;cpg based control;evolutionary algorithms;robotics locomotion;modular robotics	This study aims at providing a control-learning framework capable of generating optimal locomotion patterns for the modular robots. The key ideas are firstly to provide a generic control structure that can be well-adapted for the different morphologies and secondly to exploit and coevolve both morphology and control aspects. A generic framework combining robot morphology, control and environment and on the top of them optimization and evolutionary algorithms are presented. The details of the components and some of the preliminary results are discussed.	control flow;evolutionary algorithm;galaxy morphological classification;mathematical morphology;mathematical optimization;robot	Soha Pouya;Ebru Aydin Gol;Rico Moeckel;Auke Jan Ijspeert	2011		10.1016/j.procs.2011.09.084	central pattern generator;simulation;computer science;artificial intelligence;machine learning;bio-inspired robotics;evolutionary algorithm;self-reconfiguring modular robot	Robotics	59.59638543383366	-24.813391397499807	129323
26b829d1c44576f164bcd21a201bc007704a3b23	a generic approach to self-localization and mapping of mobile robots without using a kinematic model		In this paper a generic approach to the SLAM (Simultaneous Localization and Mapping) problem is proposed. The approach is based on a probabilistic SLAM algorithm and employs only two portable sensors, an inertial measurement unit (IMU) and a laser range finder (LRF) to estimate the state and environment of a robot. Scan-matching is applied to compensate for noisy IMU measurements. This approach does not require any robot-specific characteristics, e.g. wheel encoders or kinematic models. In principle, this minimal sensory setup can be mounted on different robot systems without major modifications to the underlying algorithms. The sensory setup with the probabilistic algorithm is tested in real-world experiments on two different kinds of robots: a simple two-wheeled robot and the six-legged hexapod AMOSII. The obtained results indicate a successful implementation of the approach and confirm its generic nature. On both robots, the SLAM problem can be solved with reasonable accuracy.	mobile robot	Patrick Kesper;Lars Berscheid;Florentin Wörgötter;Poramate Manoonpong	2015		10.1007/978-3-319-22416-9_15	occupancy grid mapping;computer vision;inertial measurement unit;simultaneous localization and mapping;probabilistic logic;hexapod;kinematics;artificial intelligence;randomized algorithm;mobile robot;computer science	Robotics	55.431031364585344	-37.56304135988772	129710
15acb9e48d59f676cc0e7ed49131437941608df6	online estimation of image jacobian matrix by kalman-bucy filter for uncalibrated stereo vision feedback	robotic workspace;uncalibrated stereo cameras hand eye coordination visual servoing sensory feedback stereo vision feedback image jacobian matrix image space robotic workspace kalman bucy filter tracking robot manipulator;jacobian matrix;robot sensing systems;instruments;filters;kalman bucy filter;dynamic system;sensory feedback;indexing terms;orbital robotics;jacobian matrices filters stereo vision feedback robot vision systems cameras instruments visual servoing robot sensing systems orbital robotics;computer vision;robot manipulator;feedback;uncalibrated stereo cameras;position control;image space;filtering theory industrial manipulators stereo image processing computer vision position control servomechanisms feedback jacobian matrices tracking;servomechanisms;stereo image processing;stereo vision;visual feedback;visual servoing;jacobian matrices;image jacobian matrix;robot vision systems;industrial manipulators;stereo vision feedback;filtering theory;cameras;tracking;hand eye coordination	This paper studies the visual servoing problem with sensory feedback from uncalibrated stereo cameras. The linear image Jacobian matrix is used to describe the spatial and temporary approximation of the differential movement relation between image space and robotic workspace. We suggest to construct an instrumental dynamic system with state variables formed from elements of the image Jacobian matrix. Thus a Kalman-Bucy filter is used to estimate the state variables of the constructed system online, which is robust to system noise and external disturbances. A 3D tracking task by a robot manipulator with visual feedback from uncalibrated stereo cameras is exemplified to show the formation of the instrumental system, estimation process and performance of the image Jacobian matrix and the design of the servo controller. Effectiveness of the proposed method and satisfactory tracking process can be found from extensive simulations and experiments provided in the paper.	jacobian matrix and determinant;kalman filter;stereopsis	Jiang Qian;Jianbo Su	2002		10.1109/ROBOT.2002.1013418	jacobian matrix and determinant;control engineering;computer vision;eye–hand coordination;index term;computer science;stereopsis;dynamical system;control theory;feedback;tracking;visual servoing	Vision	60.56371363244003	-31.91206741895947	130382
33e391bfdad9f54afe20160acf463acd03b72b31	a novel online model-based wind estimation approach for quadrotor micro air vehicles using low cost mems imus	force;rotors;wind speed;drag;vehicles;atmospheric modeling;accelerometers	This work extends the drag-force enhanced quadrotor model by denoting the free stream air velocity as the difference between the ground speed and the wind speed. It is demonstrated that a relatively simple nonlinear observer is capable of estimating the local wind components, provided accelerometer and GPS-velocity measurements are available. We perform a wind tunnel experiment at various wind speeds using a quadrotor vehicle with a low-cost Inertial Measurement Unit (IMU) and a motion tracking system to provide accurate ground speed measurements. It is shown that the onboard Extended Kalman Filter (EKF) accurately estimates the wind components.	extended kalman filter;global positioning system;kilobyte;microelectromechanical systems;nonlinear system;optic axis of a crystal;r.o.t.o.r.;thrust;tracking system;velocity (software development)	L. N. C. Sikkel;Guido C. H. E. de Croon;C. De Wagter;Qiping Chu	2016	2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2016.7759336	wind speed;control engineering;atmospheric model;simulation;engineering;drag;control theory;force;accelerometer	Robotics	57.087966548261726	-35.908173104744385	131024
bbad209270707d8bf503890491917a53d6ca6029	exploiting the development of robotic hands	communities actuators;dexterous manipulators;shape memory alloy robotic hand development multiple degrees of freedom	In this paper, some considerations about the state-of-the-art and the current trends in the design and mechanisms of robotic hands are reported and discussed. Several robotic hands with multiple degrees-of-freedom have been developed over the last two decades, mainly through the use of traditional means of action (e.g., electric actuators). This paper surveys the related work accomplished by the scientific community so far, focusing on the problems engendered by these often conflicting requirements, and the work that has been done in this area. Although there are many robotic hands projects, only a few have been addressing alternative technologies such as the use of Shape Memory Alloy.	requirement;robot;robotic arm	Ivo M. Sousa;Micael S. Couceiro;Ana R. Barbosa;Carlos M. Figueiredo;Nuno M. Fonseca Ferreira	2013	2013 IEEE 2nd International Conference on Serious Games and Applications for Health (SeGAH)	10.1109/SeGAH.2013.6665321	control engineering;simulation;engineering;mechanical engineering	Robotics	66.86568471818138	-28.072147193843254	131124
7cd0f6ec028b29d6264fa354c9cee767fd71ec07	rf-based relative position estimation in mobile ad-hoc networks with confidence regions		Relative localisation of mobile robots can provide useful information to applications, from formation control, to joint exploration and inspection. One way to obtain relative localisation is to measure distances between the multiple robots. In this scope, distance estimates based on RF ranging data can be beneficial for small/inexpensive communicating robots that have no other means of measuring distances, or as disambiguation of multiple hypothesis in high accuracy localisation systems. In this work, we present a technique of estimating the relative positions of simple mobile robots in a small team using the distance information that can be captured by a wireless transceiver, only. Simulation results with a team of five mobile robots show that we can estimate their relative positions with an average accuracy of 1.3 meters without any fixed reference and using RF information, only. The main contribution of our work is that we can provide consistent reliability information as the covariance of the obtained positions.	bilateral filter;consensus dynamics;experiment;hoc (programming language);international symposium on fundamentals of computation theory;mobile robot;qualis (capes);radio frequency;simulation;transceiver;word-sense disambiguation	Luis Oliveira;Luis Fernando de Almeida	2014		10.1007/978-3-319-18615-3_31	computer vision;artificial intelligence;computer science;mobile ad hoc network;robot;wireless;mobile robot;transceiver;multidimensional scaling;ranging;covariance;distributed computing	Robotics	54.45049974415814	-33.802098935949964	131313
efe57b2aae61cd33ede046946eb29992100a8e1b	design of a soft robophysical earthworm model		Soft-bodied organisms accomplish their locomotor tasks in complex environments based primarily on changes in the dimensions of their body segments. Inspired by the morphology and behavior of the earthworm, we designed a multi-segmented soft worm robot and tested its performance experimentally through three locomotion tests: forward/backward motion, turning motion and sideways motion on a hard surface.	experiment;mathematical morphology	Yasemin Ozkan Aydin;Jennifer L. Molnar;Daniel I. Goldman;Frank L. Hammond	2018	2018 IEEE International Conference on Soft Robotics (RoboSoft)	10.1109/ROBOSOFT.2018.8404901	actuator;control engineering;solid modeling;robot;soft robotics;earthworm;computer science	Robotics	67.95708927249555	-24.958753147084987	131416
44da690f807336c77b8076e21d8cf063c0c43cec	quaternion-based kalman filter with vector selection for accurate orientation tracking	gyroscopes;magnetic sensors;kalman filters;magnetometers;quaternion;inertial navigation;kalman filter;acceleration;angular velocity measurement;vector selection inertial sensing kalman filter orientation tracking quaternion;vectors;estimation;magnetic separation;synthetic environments quaternion based kalman filter orientation tracking human body orientation estimation microinertial sensor unit magnetic sensor unit robotics human computer interaction linear acceleration interference magnetic disturbance attitude estimation error vector selection scheme gyroscope measurement linear process equation magnetometer measurement accelerometer measurement linear pseudomeasurement equation linear kalman filter;vector selection;magnetometers vectors kalman filters magnetic separation estimation quaternions acceleration;inertial systems;acceleration measurement;attitude measurement;accelerometers;microsensors;measurement errors;microsensors acceleration measurement accelerometers angular velocity measurement attitude measurement gyroscopes inertial navigation inertial systems kalman filters magnetic sensors magnetometers measurement errors;quaternions;orientation tracking;inertial sensing	Human body orientation estimation from microinertial/magnetic sensor units is highly important for synthetic environments, robotics, and other human-computer interaction applications. In practice, the main challenge is how to deal with linear acceleration interference and magnetic disturbance which always cause significant attitude-estimation errors. In this paper, we present a novel quaternion-based Kalman filter with vector selection scheme for accurate human body orientation estimation using an inertial/magnetic sensor unit. In the proposed algorithm, the gyroscope measurement is used as an input to construct the linear process equation, and the accelerometer and magnetometer measurements are manipulated to establish the linear pseudomeasurement equation. A linear Kalman filter is then deployed to estimate the body orientation. In the Kalman filter framework, a vector selection scheme is designed to protect the algorithm against undesirable conditions such as temporary intensive movement and magnetic disturbance and enable it to acquire more accurate orientation estimation. The experimental results have shown that the proposed algorithm can provide accurate attitude estimations with regard to the ground truth.	algorithm;ground truth;gyroscope;human–computer interaction;interference (communication);kalman filter;process modeling;robotics;synthetic intelligence	Zhiqiang Zhang;Xiaoli Meng;Jian-Kang Wu	2012	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2012.2196397	kalman filter;control engineering;computer vision;invariant extended kalman filter;engineering;control theory;mathematics;extended kalman filter;moving horizon estimation;physics;quantum mechanics;statistics;quaternion	Robotics	57.25936556158571	-35.98850991805574	131619
97ca6e7057acf92eb43ef81007fc82641b26afd7	target aware optimal visual navigation for uavs		In this paper we propose an effective visionbased navigation method that allows a multirotor vehicle to simultaneously reach a desired goal pose in the environment while constantly facing a target object or landmark. Standard techniques such as Position-Based Visual Servoing (PBVS) and Image-Based Visual Servoing (IBVS) in some cases (e.g., while the multirotor is performing fast maneuvers) do not allow to constantly maintain the line of sight with a target of interest. Instead, we compute the optimal trajectory by solving a non-linear optimization problem that minimizes the target re-projection error while meeting the UAV’s dynamic constraints. The desired trajectory is then tracked by means of a real-time Non-linear Model Predictive Controller (MPC): This implicitly allows the multirotor to satisfy both the required constraints. We successfully evaluate the proposed approach in simulated and real experiments. We also present a performance comparison against a typical PBVS approach and a recent Hybrid visual servoing technique.	agile software development;experiment;linear model;linear programming;loss function;machine vision;mathematical optimization;nonlinear programming;nonlinear system;optimization problem;real-time clock;unmanned aerial vehicle;virtual reality headset;visual servoing	Ciro Potena;Daniele Nardi;Alberto Pretto	2017	CoRR		computer vision;simulation;engineering;control theory	Robotics	54.458871947077064	-32.40622262040294	131639
02dcaad6e32a91df2b1851f2e2eb379f825f032e	attitude stability of a cable driven balloon robot	cable driven balloon robot;search and rescue;information acquisition;stability robot sensing systems robot vision systems cameras large scale systems earthquakes humans crawlers shape cables;rescue robots cable driven balloon robot attitude stability large scale urban earthquake disaster;stability;large scale;attitude control;wind speed;rescue robots;aerospace robotics;attitude stability;large scale urban earthquake disaster;stability aerospace robotics attitude control	"""At the time of a large-scale urban earthquake disaster, human search activities and information collection are the most important processes of rescue operations. Robots for search and rescue (e.g., aero-robots, crawler type robots) have been studied extensively recently. We have developed a cable driven balloon robot for information acquisition from the sky during disaster rescue and recovery operations. The balloon, from which hang several sensors (sensor unit, SU), uses """"a natural shape balloon"""". Three cables connect the SU, and the balloon, with its sensors, is driven by expansion and contraction of the cable length. Cameras and several sensors or wireless relays are loaded onto the SU. The attitude stability of the SU is required to eliminate camera shaking resulting from wind. Such stability is necessary for high-precision information collection because this robot is used in the open air. This study verifies the attitude stability of an SU using a cable arrangement between the balloon and the SU; it statically calculates the movable scope of the SU at an arbitrary wind speed and direction"""	computation;disaster recovery;discharger;experiment;relay;robot;sensor;superuser;web crawler;windows aero	Fumiaki Takemura;Kiyoshi Maeda;Satoshi Tadokoro	2006	2006 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2006.281633	wind speed;structural engineering;simulation;stability;rescue robot;engineering;artificial intelligence;attitude control;statistics;remote sensing	Robotics	62.362385024618256	-30.41838686637422	131712
23f4a669d9ffd532de313ace0bbf572976c660b3	intelligent navigation of autonomous underwater vehicles for cage aquafarm surveillance	autonomous underwater vehicle;control functions;underwater vehicles aquaculture artificial immune systems navigation path planning remotely operated vehicles surveillance;underwater vehicles;surveillance;path planning;remotely operated vehicles;aquaculture;navigation;energy consumption;clonal selection algorithm intelligent navigation autonomous underwater vehicles cage aquafarm surveillance artificial monitoring control functions coastal structure inspection undersea exploration;autonomous underwater vehicles;intelligent navigation;artificial monitoring;intelligent vehicles navigation underwater vehicles surveillance artificial intelligence monitoring control systems environmental factors productivity oceans;clonal selection algorithm;coastal structure inspection;cage aquafarm surveillance;artificial immune systems;monitoring and control;undersea exploration;environmental factor	Cage aquafarm systems need to provide artificial monitoring and control functions to maintain essential environmental factors for the high productivity of marine products. Autonomous underwater vehicles (AUVs), which have been utilized for various ocean applications such as coastal structure inspection and undersea exploration, are emerging as effective candidate tools for aquafarm surveillance due to their capability of broad range navigation. This paper proposes a technique for intelligent navigation of AUVs around cage aquafarms based on the artificial immune technology. We adopt a clonal selection algorithm(CSA) to determine optimal navigation paths surrounding the aquafarms while reducing energy consumption.	autonomous robot;control function (econometrics)	Jongan Lee;Mootaek Roh;Jinsung Lee;Doheon Lee	2007	2007 Frontiers in the Convergence of Bioscience and Information Technologies	10.1109/FBIT.2007.74	simulation;engineering;marine engineering;remote sensing	Robotics	55.9149407901308	-30.435677634441966	131733
f3bc1f34cf861e20851166a9a8bd5009168841e4	docking in self-reconfigurable robots	protocols;autonomous reconfigurations self reconfigurable robots guiding systems intelligent control protocols kinematics constraints communication limitations distributed control software configuration conro reconfigurable robot project three stage docking process alignment protocols distributed inverse kinematics conro like robots;intelligent robots;position control distributed control robot kinematics self adjusting systems intelligent control;conro reconfigurable robot project;conro like robots;self adjusting systems;mobile robots;robot kinematics mobile robots protocols joining processes tail intelligent control intelligent robots distributed control lubrication shape;intelligent control;communication limitations;kinematics constraints;autonomous reconfigurations;shape;distributed inverse kinematics;position control;intelligent control protocols;lubrication;self reconfigurable robots;joining processes;inverse kinematics;alignment protocols;guiding systems;distributed control software;configuration;distributed control;three stage docking process;tail;robot kinematics	Docking is a crucial action for self-reconfigurable robots because it supports almost all practical advantages of such robots. In addition to the classic docking challenges found in other applications, such as reliable dock/latch mechanics, effective guiding systems, and intelligent control protocols, docking in selfreconfigurable robots is also subject to some unique constraints. These constraints include the kinematics constraints imposed on the docking modules by other modules in the configuration, communication limitations between the docking and relevant modules, and the demand for distributed control software because of the dynamics of configuration. To solve these challenging problems, this paper reports a set of solutions developed in the CONRO reconfigurable robot project. The paper presents a three-stage docking process, six different alignment protocols, distributed inverse kinematics, and other techniques such as dynamic lubrication that are essential for successful docking in CONRO-like robots. These solutions enable CONRO robots to perform autonomous and distributed reconfigurations in a laboratory environment, and they also suggest important considerations for docking in self-reconfiguration in general.	autonomous robot;content-control software;distributed control system;docking (molecular);experiment;intelligent control;inverse kinematics;self-reconfiguring modular robot;software deployment	Wei-Min Shen;Peter M. Will	2001		10.1109/IROS.2001.976307	lubrication;control engineering;mobile robot;communications protocol;simulation;shape;computer science;engineering;artificial intelligence;inverse kinematics;control theory;configuration;tail;robot kinematics;intelligent control	Robotics	65.50747563739873	-26.39691513657408	132083
c15606726454858be0083d2e83ca94bd99f5cfd2	inertial rotation center position estimation for a perching treaded vehicle	rigid body;common mode;mobile robots;low pass filter;frequency measurement;acceleration accelerometers noise noise measurement angular velocity frequency measurement estimation;position control inertial systems mobile robots;noise measurement;acceleration;estimation;position control;tactile feedback;position estimation;balance beam inverted pendulum apparatus inertial rotation center position estimation perching treaded vehicle offset accelerometers inertial measurement foot slippage detection legged robots treaded robots discontinuity recognition visual tracking tactile feedback offset tangential acceleration measurement common mode tangential acceleration angular velocity estimates calculated angular acceleration gyroscope measurement;angular velocity;linear accelerator;inverted pendulum;inertial systems;velocity estimation;perch;visual tracking;accelerometers;legged robot;noise	A method for estimating the rotation center position (RCP) of a rigid body in the x-y plane using two offset accelerometers is presented. RCP estimation via inertial measurement is motivated by the related problems of detecting foot slippage of legged robots and detecting stair edges for treaded robots, for applications in which alternative methods such as discontinuity recognition, visual tracking, and/or tactile feedback are impractical. The RCP may be directly solved for as a function of the two offset tangential acceleration measurements, when the RCP is colinear with the two accelerometers, and when the common-mode tangential accelerations, due to linear acceleration and/or gravity, can be independently measured or estimated. Angular velocity estimates may be enhanced by combining calculated angular acceleration with gyroscope measurements, even when both the RCP and common-mode tangential accelerations cannot be independently measured. An input variance modulated variable cutoff low-pass filter is also proposed for RCP estimation in the absence of independent measurements, which is validated on a balance-beam inverted-pendulum apparatus.	angularjs;encoder;frequency-hopping spread spectrum;gyroscope;inverted pendulum;low-pass filter;modulation;prototype;reflections of signals on conducting lines;robot;sensor;velocity (software development);video tracking	Christopher Schmidt-Wetekam;Nicholas Morozovsky;Thomas R. Bewley	2011	2011 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6094659	acceleration;control engineering;mobile robot;inverted pendulum;estimation;rigid body;simulation;common-mode signal;eye tracking;low-pass filter;angular velocity;engineering;noise measurement;noise;control theory;linear particle accelerator;accelerometer	Robotics	57.433951489679934	-35.65947285333004	132194
1643fc72a451aeefa3c017ae76a4087922c438d8	compensation of observability problem in a multi-robot localization scenario using cekf	observability;robot localization;relative position;nonlinear filters;mobile robots observability multi robot systems nonlinear filters kalman filters position control;mobile robot;kalman filters;mobile robots;endnotes;reference point;mobile robots observability multirobot localization scenario absolute landmark measurement centralized extended kalman filter robot team relative position measurement;long distance;position control;multi robot systems;pubications;observability robot kinematics orbital robotics position measurement robot sensing systems robot localization degradation cybernetics extraterrestrial measurements kalman filters;extended kalman filter;robot team	Many localization techniques today rely on absolute landmark measurements to efficiently track the robot's position in space. Although absolute landmarks are essential for correctly estimating its position, they might be rare in an unknown environment. This means that the robot would have to traverse long distances without any outside reference point resulting in system degradation. In case of a robot team though, each robot can rely on both absolute or relative position measurements between robots. This paper describes an approach for a multi-robot localization system, based on a single centralized extended Kalman filter (CEKF) to track the position and orientation changes of a group of robots. Moreover, it is shown that if the robots in the group collect only relative measurements the system suffers from observability problem. It is proven that an increasing number of mobile robots capable of relative measurements only, reduces the observability problem and compensates for the need of external absolute landmarks thus providing efficient localization.	algorithm;centralized computing;computation;elegant degradation;extended kalman filter;internationalization and localization;mobile robot;positioning system;robotic mapping;sql;stationary process;steady state;traverse	Polychronis Kondaxakis;Virginie F. Ruiz;William S. Harwin	2004	2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)	10.1109/IROS.2004.1389651	control engineering;mobile robot;monte carlo localization;simulation;computer science;engineering;artificial intelligence;control theory	Robotics	55.08018635643941	-34.87383684517395	132258
196497a04e3b691a9e3f1f020fd8985afb390aec	about biologically plausible trajectory generators	mobile robots;topographic map;nontopographical map biologically plausible trajectory generators artificial trajectory generation problem where to go next local mechanism locus map global trajectory generation problem neural map activity obstacles avoidance harmonic potential biological modelization hippocampal structures;trajectory generation;state space;collision avoidance;neurocontrollers;biological system modeling state space methods trajectory surgery hippocampus coherence biology computing robustness roads equations;neurocontrollers collision avoidance mobile robots	"""Considering the biological or artificial trajectory generation problem, we propose a biologically plausible model of the link between the (i) local """"where-to-go-next"""" local mechanism in a locus map and the (ii) global trajectory generation problem. This explains how the well known hippocampal related areas containing place fields with local mechanisms are also very likely able to solve the global problem, providing the neural map activity is related to harmonic potentials. Such representation assume that obstacles to avoid (or constraints not to violate) correspond to maxima of a so-called potential, while the goal corresponds to its minimum. The corresponding algorithm thus behaves as if one throws a sheet onto this state space, this hyper-surface relief being elevated on obstacles, with a hole at the goal location. Finding a trajectory thus reduces to """"roll down"""" along this relief, in the direction of the potential gradient. The originality of the present work is to build an harmonic potential (thus without local minimum) from a sparse adaptive combination of elementary place fields, as inspired by the biological modelization of the hippocampal structures. This leads to an internal representation of the problem as a non-topographical map, incrementally built during the system exploration. As such, it provides a key element for a biologically plausible model of the related hippocampus mechanisms in coherence with usual biological assumptions about such behavior."""	algorithm;automated planning and scheduling;computation;computational model;curse of dimensionality;gradient;locus;map;mathematical model;mathematical optimization;maxima and minima;nonlinear system;plausibility structure;quantum harmonic oscillator;sparse approximation;sparse matrix;state space;synaptic package manager;time complexity;topography;trajectory optimization;whole earth 'lectronic link	Thierry Viéville	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/IJCNN.2006.246732	mobile robot;computer vision;topographic map;simulation;computer science;state space;artificial intelligence;machine learning	Robotics	60.92387502155124	-24.08806459046077	132442
2230b3d411f9a8664ea800911cbcfe9bb2e27fa6	rgb-d sensor setup for multiple tasks of home robots and experimental results	navigation cameras robot vision systems collision avoidance lasers;service robots collision avoidance gesture recognition home automation image colour analysis manipulators mobile robots object recognition robot vision;frequency 10 hz rgb d sensor setup home robots experimental results navigation 2d laser data home environments rgb d cameras localization obstacle avoidance object searching object recognition gesture recognition ros modules virtual rgb d scans home service robot	While navigation based on 2D laser data is well understood, the application of robots at home environments requires seeing more than a slice of the world. RGB-D cameras have been used to perceive the full scenes and solutions exist consuming extensive computing power. We propose a setup with two RGB-D cameras that covers the need for conflicting requirements regarding localization, obstacle avoidance, object search and recognition, and gesture recognition. We show that this setup provides sufficient data to enable navigation at homes and we present how ROS modules can be configured to use virtual RGB-D scans instead of laser data for operation in real-time (10Hz). Finally, we present first results of exploiting this versatile setup for a home service robot that picks up things from the floor to prevent potential falls of its future users.	algorithm;dr-dos;experiment;gesture recognition;obstacle avoidance;real-time clock;requirement;robot operating system;semantic mapper;sensor;service robot	Paloma de la Puente;Markus Bajones;Peter Einramhof;Daniel Wolf;David Fischinger;Markus Vincze	2014	2014 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2014.6942915	embedded system;computer vision;simulation;engineering;robot control	Robotics	58.589631128987925	-32.46838801572811	132445
3be7acbc1cae10dd04aa253986b38b947b49b026	self-localization method using a single omni-directional camera based on landmark positions and arrangement	agricultural machinery;sensors;global positioning system;mathematical model;estimation error;cameras	This paper proposes a self localization method for autonomous vehicles with just a omni-directional camera. Proposed method uses positions and arrangement of landmarks which are preliminarily obtained, and estimates the position of omni-directional camera based on the cosine formula. Also measurements of distances between the camera and the landmarks are not required, which are needed for conventional self-localization method but becomes the major reason of estimation errors. So, this method can obtain a large advantage to avoid the estimation errors due to the measurement error of the distance between camera and landmarks. The geometric nonlinear simultaneous equations consists of the cosine formulas are solved by recursive least squares method. Performance and accuracy are indicated by the results of simulations.	autonomous robot;motion estimation;nonlinear system;recursion;recursive least squares filter;simulation;system of polynomial equations	Yohei Hoshino;Liangliang Yang;Soichiro Suzuki	2016	2016 IEEE/SICE International Symposium on System Integration (SII)	10.1109/SII.2016.7844061	computer vision;camera auto-calibration;mathematical optimization;camera resectioning;simulation;computer science	Robotics	54.72828512438947	-37.36700904219672	132697
652fa32a3cad9a644468c8a2025d8f32b3e2831c	a time stamp control strategy for cbr based reactive navigation in dynamic environments with priorities	case-based reasoning;mobile robots;navigation;path planning;cbr based reactive navigation system;autonomous robots;case-based reasoning;dynamic environments;layered architecture;mobile obstacles;time stamp control strategy	This work presents a CBR based reactive navigation system for autonomous robots. The main advantage of the proposed system is that it learns by experience how to deal with unexpected situations in dynamic environments. A time stamp control method has been included to deal with mobile obstacles in intersections, where there are priorities depending on the relative positions of those obstacles and the robot. The proposed strategy has been successfully tested in real environments.	autonomous robot;basic stamp;case-based reasoning;control theory	Cristina Urdiales;Eduardo J. Pérez;Francisco Sandoval Hernández	2004	Proceedings. IEEE/WIC/ACM International Conference on Intelligent Agent Technology, 2004. (IAT 2004).	10.1109/IAT.2004.1342924	control engineering;computer vision;simulation;engineering	Robotics	59.27746471793562	-27.681302729037846	132746
2de324aa7dbcc5606fe1a44fd54b2ab47f67d70a	vibration occurrence estimation and avoidance for vision inspection system		Disturbance / vibration reduction is critical in many applications using machine vision. The off-focusing or blurring error caused by vibration degrades its performance. Instead of going with the more familiar approach like vibration absorber, a real-time disturbance estimation and avoidance is proposed.		Kap-Ho Seo;Yongsik Park;Sungjo Yun;Sung-Ho Park;Jeong Woo Park	2013		10.1007/978-3-319-05582-4_54	computer vision	Robotics	61.26604977788111	-33.62994759316875	132824
31f11d411342d8cb61023069ef5598b92d2c75fc	decentralized planning and control for uav-ugv cooperative teams		In this paper we study a symbiotic aerial vehicle-ground vehicle robotic team where unmanned aerial vehicles (UAVs) are used for aerial manipulation tasks, while unmanned ground vehicles (UGVs) aid and assist them. UGV can provide a UAV with a safe landing area and transport it across large distances, while UAV can provide an additional degree of freedom for the UGV, enabling it to negotiate obstacles. We propose an overall system control framework that includes high-accuracy motion planning for each individual robot and ad-hoc decentralized mission planning for complex missions. Experimental results obtained in a mockup arena for parcel transportation scenario show that the system is able to plan and execute missions in various environments and that the obtained plans result in lower energy consumption.	unmanned aerial vehicle	Barbara Arbanas;Antun Ivanovic;Marko Car;Matko Orsag;Tamara Petrovic;Stjepan Bogdan	2018	Auton. Robots	10.1007/s10514-018-9712-y	simulation;computer science;motion planning;decentralized planning;robot;mockup;control system	Robotics	56.11083732737058	-26.302373281936337	132841
f78e7a21eeaadfc708167b081eb841e0195c3ac4	a concept for an intelligent and fault-tolerant robot system	elementary operator;error recovery;fault tolerant;autonomous mobile robot;intelligent control;federal republic of germany;control system;fault tolerant system;uncertain data;real time computing	A concept for the intelligent control of subsystems of a flexible assembly cell is presented. Unknown or uncertain data about the real world may lead towards failure during an assembly task. Therefore, a fault tolerant system must be capable of reacting immediately to error situations. Thus, the major topic of this paper is the dynamic handling of unforeseen situations during realtime activities. This will be achieved by combining sensor guided actions with an advanced autonomous supervision system. Experimental results will be derived from the mobile two-arm robot system KAMRO of the Institute for Real-Time Computer Control Systems and Robotics, University of Karlsruhe, Federal Republic of Germany.		Andreas Hörmann;Th. Hugel;Wolfgang Meier	1988	Journal of Intelligent and Robotic Systems	10.1007/BF00238769	control engineering;fault tolerance;real-time computing;simulation;computer science;engineering;control system;artificial intelligence;control theory;intelligent control	Robotics	57.089840989489424	-28.37004043581797	133334
0f0ede8ff7f9345bb872e623f545bd40acde3ac5	manual control of the langley laboratory telerobotic manipulator	control systems;jet propulsion laboratory langley laboratory telerobotic manipulator langley research center control input devices dual armed force reflecting master slave manipulator total computer control six degrees of freedom hand controllers kraft minimasters;manipulators;kraft minimasters;input device;remote control;control systems design;orbital assembly;master slave manipulator;computerised control;degree of freedom;human factors laboratories telerobotics control systems force control manipulators master slave arm robots propulsion;teleoperators;robotics;force reflecting;robots computerised control;six degrees of freedom hand controllers;langley research center;degrees of freedom;test facilities;human factors;langley laboratory telerobotic manipulator;robot control;robots;total computer control;remote manipulator system;telerobotics;arm;propulsion;control input devices;computer control;master slave;manual control;systems integration;man machine systems;evaluation studies;dual armed;jet propulsion laboratory;force control	The authors describe the LTM (Laboratory Telerobotic Manipulator), its installation at Langley Research Center, and plans for a comparative evaluation study of various control input devices to the system. The LTM is a full, dual-armed, force reflecting, master/slave manipulator in its basic form. It also has full robotic capability, with both slave arms functioning under total computer control. The control input devices to be studied will include: control from the system's basic master arms, six-degrees-of-freedom hand controllers, Kraft minimasters, and the Jet Propulsion Laboratory (JPL) force-reflecting hand controller. The initial master/slave control studies will consist of evaluating performance of simple task board operations as well as more realistic tasks typical of those a manipulator system might actually be required to perform in space. >	telerobotics	Walter W. Hankins;Randolph W. Mixon	1989		10.1109/ICSMC.1989.71266	simulation;computer science;artificial intelligence;control theory;degrees of freedom;robotics	Robotics	63.19992821344554	-29.262795595707022	133631
73829c51c9d58a2e91e8251499a0569228453098	fluidized bed agglomeration diagnosis based on wavelet packet entropy and gaussian test			wavelet	Weiguo Lin;ShuoChen Wu;Wu HaiYan;Changli Chang li;Yuanhua Qi	2016	IJDSN	10.1155/2016/4145373		Robotics	67.55317385602432	-35.43674561703519	133714
c2c59c0f096f6135cc0985e4d12856292e289101	intelligent sensor network simulation for battlefield resources management	intelligent sensor;games wireless sensor networks servers vehicles computational modeling helicopters monitoring;multiagent system;agent based computing sensor network battle field multiagent systems;computer model;unmanned aerial vehicle;resource manager;network simulator;sensor network;wireless sensor network;public domain software;servers;computational modeling;monitoring;games;agent based computing;target classification intelligent sensor network simulation battlefield resource management battlefield simulation platform optimal resources management publically available software gecco repast user developed optimization engine wireless sensor network unmanned aerial vehicles unattended ground sensors target detection;vehicles;wireless sensor networks intelligent sensors military computing public domain software;battle field;target detection;helicopters;unattended ground sensor;wireless sensor networks;intelligent sensors;military computing;multiagent systems	This paper presents a study of a battlefield simulation platform with consideration of sensor network and optimal resources management. This development is mainly based on two public ally available software - GECCO and REPAST. The platform allows integration with a user developed optimization engine for optimal battlefield management. A simulation example was presented to show the application to a wireless sensor network composed of unattended ground sensors and unmanned aerial vehicles for target detection, classification and localization in the battlefield.	aerial photography;genetic and evolutionary computation conference;internationalization and localization;mathematical optimization;online and offline;repast (modeling toolkit);sensor web;simulation;unmanned aerial vehicle	H. Y. Yu;Y. L. Lu	2011	2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing	10.1109/DASC.2011.59	embedded system;simulation;wireless sensor network;computer science;engineering;resource management;multi-agent system;computer security	Robotics	57.81564177323167	-26.061187614393738	133858
dd64b0212e2511674af036cdc1fa784f4b46729d	minimum volume bounding box decomposition for shape approximation in robot grasping	sensors intelligent robots;robot grasping;shape approximation;sensors;model interpretation;intelligent robots;bounding box decomposition;computer and information science;dynamic environment;sensor perception;grasplt;shape robot sensing systems intelligent robots robotics and automation grasping clouds service robots usa councils intelligent sensors kinematics;data och informationsvetenskap;grasplt bounding box decomposition shape approximation robot grasping intelligent robots sensor perception model interpretation	Thinking about intelligent robots involves consideration of how such systems can be enabled to perceive, interpret and act in arbitrary and dynamic environments. While sensor perception and model interpretation focus on the robot's internal representation of the world rather passively, robot grasping capabilities are needed to actively execute tasks, modify scenarios and thereby reach versatile goals. These capabilities should also include the generation of stable grasps to safely handle even objects unknown to the robot. We believe that the key to this ability is not to select a good grasp depending on the identification of an object (e.g. as a cup), but on its shape (e.g. as a composition of shape primitives). In this paper, we envelop given 3D data points into primitive box shapes by a fit-and-split algorithm that is based on an efficient Minimum Volume Bounding Box implementation. Though box shapes are not able to approximate arbitrary data in a precise manner, they give efficient clues for planning grasps on arbitrary objects. We present the algorithm and experiments using the 3D grasping simulator Grasplt!.	approximation algorithm;data point;experiment;minimum bounding box;robot;shape context	Kai Huebner;Steffen Ruthotto;Danica Kragic	2008	2008 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2008.4543434	control engineering;computer vision;simulation;engineering;sensor;robot control	Robotics	63.76483202277676	-25.430232772907495	134018
7c97cf5aea4eb25a648ce022d2a920657db06dfd	the trajectory generation algorithm for the cable-suspended parallel robot - the cpr trajectory solver	trajectory planning;real time;cpr system;object monitoring	Abstract The CPR Trajectory Solver is a procedure defined in this paper which is used to generate a smooth reference trajectory of CPR system’s camera which has a task to monitor and track the object in real time. We have generated a data base of four primitive trajectories (primitives) which are chosen by the CPR Trajectory Solver during the generation of camera’s complex reference trajectory. For trajectory generation, the CPR Trajectory Solver uses the knowledge about the current positions and velocity orientations of the camera and object and then it defines the goal position and velocity orientation of the camera. The CPR Trajectory Solver chooses one of the generated primitives for interconnecting the current and goal positions of the camera. After completing the chosen primitive, the CPR Trajectory Solver establishes the new positions and velocity orientations of the object. This process is repeated cyclically until the real time object monitoring and tracking task is completed. For the purpose of analysing and using the defined algorithm, we have synthesized a program package: CPRTS ( CPR T rajectory S olver). By using this program package, the simulation experiments of the camera’s trajectory generation for the purpose of the object monitoring and tracking are presented. By using the CPR Trajectory Solver, motion autonomy of CPR system’s camera is increased. The camera has a task to follow and monitor the chaotically moving object.	algorithm;parallel manipulator;solver	Ljubinko Kevac;Mirjana Filipovic;Aleksandar Rakic	2017	Robotics and Autonomous Systems	10.1016/j.robot.2017.04.018	simulation;computer vision;artificial intelligence;computer science;trajectory;algorithm;parallel manipulator;solver	Robotics	57.935939321514695	-28.367241362787677	134046
511655e3ad0bb5b145959e838c643e8c802ce5f8	errors analysis on posing measure system of “dragon of puncturing mud” robot	robot sensing systems;dragon of puncturing mud robot;forestry;robot vision error analysis path planning pose estimation;path planning;measurement system;path planning errors analysis posing measure system dragon of puncturing mud robot;calculating method;error analysis;errors analysis;robot vision;machine vision;errors analysis dragon of puncturing mud robot posing measure calculating method;manufacturing;sun;posing measure;error analysis educational institutions manufacturing robot sensing systems robot vision systems forestry soil machine vision man machine systems sun;soil;man machine systems;robot vision systems;pose estimation	Based on the reality posing measure of “Dragon of puncturing mud” robot, error roots are analyzed and researched in detail including fixing error, pose signal error, manufacturing error and magnetic deviation as well as influence to posing measure system and calculating method of various corresponding errors are presented. New theory base for more researching on Path Planning of “Dragon of Puncturing Mud” Robot is provided.	motion planning;puncturing;robot	Xue Li Sun;Li-bin Guo;Li-quan Wang;San-ping Li;Kai-yi Jiang	2010	2010 International Conference on Machine Vision and Human-machine Interface	10.1109/MVHI.2010.129	computer vision;simulation;pose;machine vision;computer science;artificial intelligence;system of measurement;motion planning;manufacturing	Robotics	61.417597122106415	-35.64615722818655	134112
6402c01c33be88ddfdafb5fe31f02ead9e25d731	vision-based collision avoidance for personal aerial vehicles using dynamic potential fields	mobile robots collision avoidance potential fields personal aerial vehicles stereo vision;mobile robots;vehicles force collision avoidance vehicle dynamics dynamics three dimensional displays navigation;force;navigation;potential fields;dynamics;three dimensional displays;stereo vision;collision avoidance;vehicles;personal aerial vehicles;obstacle detection vision based collision avoidance personal aerial vehicles dynamic potential fields prototype system pav vehicle surroundings autonomous control obstacle avoidance personal air transportation system pats human operators human controlled vehicles pseudo repulsive forces operator controls collision avoidance controls dynamic repulsive potential function collision avoidance system mobile platform quadcopter model stereo vision sensor;visual perception aerospace control collision avoidance computer vision space vehicles stereo image processing;vehicle dynamics	In this paper we present a prototype system that aids the operator of a Personal Air Vehicle (PAV) by actively monitoring vehicle surroundings and providing autonomous control inputs for obstacle avoidance. The prototype is developed for a Personal Air Transportation System (PATS) that will enable human operators with low level of technical knowledge to use aerial vehicles for a day-to-day commute. While most collision avoidance systems used on human controlled vehicles override operator input, our proposed system allows the operator to be in control of the vehicle at all times. Our approach uses a dynamic potential field to generate pseudo repulsive forces that, when converted into control inputs, force the vehicle on a trajectory around the obstacle. By allowing the vehicle control input to be the sum of operator controls and collision avoidance controls, the system ensures that the operator is in control of the vehicle at all times. We first present a dynamic repulsive potential function and then provide a generic control architecture required to implement the collision avoidance system on a mobile platform. Further, extensive computer simulations of the proposed algorithm are performed on a quad copter model, followed by hardware experiments on a stereo vision sensor. The proposed collision avoidance system is computationally inexpensive and can be used with any sensor that can produce a point cloud for obstacle detection.	aerial photography;algorithm;autonomous robot;computer simulation;experiment;feedback;haptic technology;human factors and ergonomics;mobile operating system;obstacle avoidance;point cloud;prototype;rover (the prisoner);stereopsis;television antenna;unmanned aerial vehicle	Faizan Rehmatullah;Jonathan Kelly	2015	2015 12th Conference on Computer and Robot Vision	10.1109/CRV.2015.46	mobile robot;embedded system;computer vision;dynamics;navigation;vehicle dynamics;simulation;computer science;stereopsis;obstacle avoidance;force	Robotics	60.05580471130797	-30.377673894607334	134235
dfc8e0b740fe90f6b2c1ee702fbd4fee3aff58ca	determining the principles of human motion by combining motion analysis and motion synthesis	motion analysis;humanoid robot;multibody systems;humanoid robotics;path planning;optimal control theory;optimal trajectories human motion analysis human motion synthesis humanoid robotics human motor control multibody systems optimal control theory large scale dynamic analysis;optimal trajectories;motion synthesis;mobile robots;joints;kinematics;optimal control;motion capture;large scale;trajectory;human motor control;humanoid robots;human motion;motion analysis humans;human motion analysis;service robot;large scale dynamic analysis;human motion synthesis;humans;robot dynamics;dynamic analysis;motor control;robot kinematics;robot dynamics humanoid robots mobile robots path planning	Synthesizing of human motion is one of the challenges in humanoid robotics research. Interested in the construction of humanoid service robots exhibiting human-like movements research is following different ways. This paper is going along with the idea of determining the principles of human motor control in order to understand the generation of human motion. A computational framework based on an efficient technique combining motion capture with multibody systems and optimal control theory for large-scale dynamic analysis and synthesis of motion is presented. Experiments were performed for human pointing gestures and the framework was validated computing the optimal trajectories of minimum hand jerk, modified minimum hand jerk, minimum angle jerk and minimum torque change.	control theory;experiment;kinesiology;motion capture;optical flow;optimal control;robot;robotics	Christian Simonidis;Thorsten Stein;Fabian Bauer;Andreas Fischer;Hermann Schwameder;Wolfgang Seemann	2009	2009 9th IEEE-RAS International Conference on Humanoid Robots	10.1109/ICHR.2009.5379557	computer vision;simulation;computer science;humanoid robot;artificial intelligence	Robotics	65.63478638638554	-24.124603785686297	134374
516d9bdfad67b7cf7d31db8a9724042db53f5802	a genetic algorithm for task completion time minimization for multi-robot sensor-based coverage	robot sensing systems;hierarchical oriented genetic algorithm;genetic algorithms minimization methods robot sensing systems mobile robots partitioning algorithms costs path planning orbital robotics acceleration intelligent control;travel time;mobilesim task completion time minimization multirobot sensor sensor based coverage mobile robot hierarchical oriented genetic algorithm c language;task analysis c language genetic algorithms mobile robots multi robot systems robot programming;mobile robot;path planning;mobile robots;minimization methods;orbital robotics;intelligent control;acceleration;c language;sensor based coverage;biological cells;mobilesim;multirobot sensor;task analysis;multi robot systems;genetic algorithm;genetic algorithms;task completion;time minimization;robot programming;partitioning algorithms	Minimizing the coverage task time is important for many sensor-based coverage applications. The completion time of a sensor-based coverage task is determined by the maximum time traveled by a robot in a mobile robot group. So the environment needs to be partitioned among robots considering their travel times. Most of the coverage algorithms results in sharp turns which require the robot to slow down, turn and accelerate. So the actual travel time of a mobile robot is depending on the traveled distance and number of turns both. In this study, previously proposed hierarchical oriented genetic algorithm (HOGA) is extended to consider the travel time rather than just the traveled distances. The HOGA consists of two phases. In the first phase, a previously proposed oriented genetic algorithm is used to find a single route with minimum repeated coverage. Then, in the second phase, a directed genetic algorithm is used to partition the route among robots considering actual travel time costs. The algorithms are coded in C++ and simulations are conducted using P3-DX mobile robots in the MobileSim environment.	c++;genetic algorithm;mobile robot;sensor;simulation	Metin Ozkan;Ahmet Yazici;Muzaffer Kapanoglu;Osman Parlaktuna	2009	2009 IEEE Control Applications, (CCA) & Intelligent Control, (ISIC)	10.1109/CCA.2009.5281055	real-time computing;simulation;computer science;distributed computing	Robotics	53.921530547160636	-24.901954010875915	134452
83250b3c78b326376291e4f0c5af96c6316a38f6	assisting strategy of walking assistive device on inclined terrain	optimal walking assisting strategy walking assistive device inclined terrain robotic walking support system smart mobile walker terrain slope estimation robotic system;terrain assistive device walking assisting;mobile robots;legged locomotion assistive devices wheels kinematics force mathematical model;mobile robots gait analysis;gait analysis	This paper introduces a robotic walking support system, Smart Mobile Walker (SMW), and suggests an assisting strategy through an algorithm which estimates terrain slope on heading direction. There is already a theoretical algorithm to calculate terrain slope, but it does not be suitable to apply on robotic system, because it needs heavy quantity of calculation. Therefore, this paper suggests a simplified algorithm to estimate terrain slope and a feasibility of the algorithm is investigated by comparing theoretical algorithm on simulation environment. The feasibility shows the suggested algorithm can be applied to the real robotic system and makes a base of optimal walking assisting strategy on several terrain types.	algorithm;amiga walker;assistive technology;course (navigation);mathematical optimization;robot;simulation	Inho Kim;Woong-Hee Cho;Hyunseok Yang	2013	2013 10th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2013.6677331	mobile robot;computer vision;simulation;gait analysis;computer science;artificial intelligence	Robotics	63.89012577681746	-24.185877068927038	134619
1ec542819079b619daf8a957f583d0bbc31ee1da	biologically-inspired dynamical systems for movement generation: automatic real-time goal adaptation and obstacle avoidance	humanoid robot;spinal cord stimulation;real time;differential equation;dynamic system;prosthetics;orbital robotics;human behavior;robot arm;trajectory;obstacle avoidance;humanoid robots;affine transformation;force measurement;mathematical model;robustness;humans;differential equations;biological data;real time systems humans robot kinematics differential equations orbital robotics humanoid robots prosthetics robustness force measurement robotics and automation;robotics and automation;coordinate system;robot kinematics;real time systems	Dynamical systems can generate movement trajectories that are robust against perturbations. This article presents an improved modification of the original dynamic movement primitive (DMP) framework by Ijspeert et al [1], [2]. The new equations can generalize movements to new targets without singularities and large accelerations. Furthermore, the new equations can represent a movement in 3D task space without depending on the choice of coordinate system (invariance under invertible affine transformations). Our modified DMP is motivated from biological data (spinal-cord stimulation in frogs) and human behavioral experiments. We further extend the formalism to obstacle avoidance by exploiting the robustness against perturbations: an additional term is added to the differential equations to make the robot steer around an obstacle. This additional term empirically describes human obstacle avoidance. We demonstrate the feasibility of our approach using the Sarcos Slave robot arm: after learning a single placing movement, the robot placed a cup between two arbitrarily given positions and avoided approaching obstacles.	dynamical system;experiment;obstacle avoidance;perturbation theory;real-time computing;real-time locating system;robot;robotic arm;semantics (computer science);spinal cord stimulator	Heiko Hoffmann;Peter Pastor;Dae-Hyung Park;Stefan Schaal	2009	2009 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2009.5152423	control engineering;computer vision;simulation;computer science;engineering;humanoid robot;artificial intelligence;human behavior;differential equation	Robotics	65.08279724443544	-24.82302798017074	134820
972e89bb076b3b3f4d20d46846d5625463259107	an active sensing method using estimated errors for multisensor fusion systems	estimation theory;reseau capteur;errors;optimisation;deteccion blanco;sensorial perception;sensors;methode mesure;tactile sensor;localizacion objeto;object location;multitarget tracking;visual fusion multisensor fusion systems estimated errors active sensing method actuators sensor positioning data association data fusion optimal sensor locations multitarget tracking hand eye cameras tactile sensor;actuators;control system analysis sensor fusion target tracking actuators sensors errors estimation theory optimisation position control optimal control;tracking movable target;detection cible;optimal control;red sensores;position control;measuring methods;sensor array;pattern recognition;control system analysis;active sensing;poursuite;sensor fusion actuators tactile sensors fuses cameras sensor systems optimization methods automotive engineering power engineering and energy land vehicles;reconnaissance forme;estimation error;sensor fusion;target tracking;percepcion sensorial;target detection;localisation objet;perception sensorielle;persecucion y continuacion	An active sensing method for multisensor fusion systems with actuators is proposed. To realize active sensing with multiple sensors, i) where to position sensors, ii) how to associate data, and iii) how to fuse data should be determined. The authors propose a new method mainly concerning i). The method utilizes estimated errors of estimated values to determine optimal sensor locations where useful data are expected to be obtained and effectively associated. An algorithm to calculate nearly optimal sensor locations, instead of exact optimal locations, is also proposed to reduce calculation. As examples, the active sensing method is applied to multi-target tracking by a system with two hand-eye cameras, and visual and tactile fusion in a system with a camera and a tactile sensor. By using this method, the sensing strategy is optimized for the object of measurement.	algorithm;fusion camera system;sensor web;tactile sensor;tracking system	Toshiharu Mukai;Masatoshi Ishikawa	1996	IEEE Trans. Industrial Electronics	10.1109/41.499810	control engineering;computer vision;optimal control;computer science;engineering;sensor;control theory;sensor fusion;estimation theory;sensor array;tactile sensor;remote sensing;actuator	Robotics	58.53918033733245	-33.78201550428297	134865
202027acc448128619f8f120716c8a233fab36ef	optimal robot arm control using the minimum variance model	minimum variance;robot arm	Models of human movement from computational neuroscience provide a starting point for building a system that can produce flexible adaptive movement on a robot. There have been many computational models of human upper limb movement put forward, each attempting to explain one or more of the stereotypical features that characterize such movements. While these models successfully capture some of the features of human movement, they often lack a compelling biological basis for the criteria they choose to optimize. One that does provide such a basis is the minimum variance model and its extension—task optimization in the presence of signal-dependent noise . Here, the variance of the hand position at the end of a movement is minimized, given that the control signals on the arm’s actuators are subject to random noise with zero mean and variance proportional to the amplitude of the signal. Since large control signals, required to move fast, would have higher amplitude noise, the speed-accuracy trade-off emerges as a direct result of the optimization process. We chose to implement a version of this model that would be suitable for the control of a robot arm, using an optimal control scheme based on the discrete-time linear quadratic regulator. This implementation allowed us to examine the applicability of the minimum variance model to producing humanlike movement. In this paper, we describe our implementation of the minimum variance model, both for point-to-point reaching movements and for more complex trajectories involving via points. We also evaluate its performance in producing humanlike movement and show its advantages over other optimization based models the well-known minimum jerk and minimum torque-change models for the control of a robot arm. © 2005 Wiley Periodicals, Inc.	computation;computational model;computational neuroscience;john d. wiley;mathematical optimization;noise (electronics);optimal control;point-to-point protocol;robot;robotic arm;whole earth 'lectronic link	Gavin Simmons;Yiannis Demiris	2005	J. Field Robotics	10.1002/rob.20092	control engineering;minimum-variance unbiased estimator;simulation;robotic arm;computer science;engineering;artificial intelligence;control theory	Robotics	65.71944784077925	-24.737092373251816	135079
137a086c1b352beba3a9b7e51f00e5b0045a3578	contact-based blind grasping of unknown objects	manipulators;finite state machines;robot vision;robot vision finite state machines manipulators;simple vision system contact based blind grasping unknown objects force torque data tactile data manipulation primitives paradigm atomic controllers elemental manipulation actions finite state machine reactive controller sensor based primitives;vectors robot sensing systems force grasping robustness torque	This paper explores to which extent contact information is enough to perform grasps on unknown objects. The specific scenario addressed consists of emptying a box which contains an undefined number of unknown objects using only force-torque and tactile data. The proposed approach to solve the task, follows the manipulation primitives paradigm, which is based on the use of atomic controllers specifically designed to perform robustly elemental manipulation actions. A set of sensor based primitives that implement a reactive controller that adapts to the uncertain real environment is implemented. Manipulation primitives are assembled within a Finite State Machine, which sequentially searches, grasps and transports all the objects in the box to a predefined location. Two different blind exploration approaches are used to deal with the task. Performance results showing grasp attempts, corrections performed, error corrected and elapsed time are presented and discussed. Moreover a simple vision system is added to compare its results to the blind approaches.	elemental;experiment;finite-state machine;lambertian reflectance;programming paradigm;sensor;test bench;thinking outside the box;undefined behavior	Javier Felip;José A. Bernabé;Antonio Morales	2012	2012 12th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2012)	10.1109/HUMANOIDS.2012.6651550	computer vision;simulation;computer science;finite-state machine	Robotics	61.12704876452751	-29.506303515322696	135160
dd646377116847186a270c1bd5f347d7acde706b	self-calibrating multi-sensor fusion with probabilistic measurement validation for seamless sensor switching on a uav	global positioning system current measurement switches calibration noise measurement robot sensing systems position measurement;telerobotics aerospace control autonomous aerial vehicles calibration mobile robots pose estimation probability sensor fusion;visual pose estimation self calibrating multisensor fusion probabilistic measurement validation seamless sensor switching uav data fusion multiple sensors mobile platform state estimation accurate calibration accurate initialization delays agile aerial vehicles measurement validation statistical signal quality analysis extrinsic sensor states ultrawideband range measurements uwb range measurements	Fusing data from multiple sensors on-board a mobile platform can significantly augment its state estimation abilities and enable autonomous traversals of different domains by adapting to changing signal availabilities. However, due to the need for accurate calibration and initialization of the sensor ensemble as well as coping with erroneous measurements that are acquired at different rates with various delays, multi-sensor fusion still remains a challenge. In this paper, we introduce a novel multi-sensor fusion approach for agile aerial vehicles that allows for measurement validation and seamless switching between sensors based on statistical signal quality analysis. Moreover, it is capable of self-initialization of its extrinsic sensor states. These initialized states are maintained in the framework such that the system can continuously self-calibrate. We implement this framework on-board a small aerial vehicle and demonstrate the effectiveness of the above capabilities on real data. As an example, we fuse GPS data, ultra-wideband (UWB) range measurements, visual pose estimates, and IMU data. Our experiments demonstrate that our system is able to seamlessly filter and switch between different sensors modalities during run time.	aerial photography;agile software development;autonomous robot;experiment;global positioning system;mobile operating system;on-board data handling;run time (program lifecycle phase);seamless3d;sensor;television antenna;ultra-wideband;unmanned aerial vehicle	Karol Hausman;Stephan Weiss;Roland Brockers;Larry H. Matthies;Gaurav S. Sukhatme	2016	2016 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2016.7487626	control engineering;computer vision;engineering;remote sensing	Robotics	54.351057171334716	-34.87364875472433	135246
5909f88d369b0db981191c657b9d0442e123c613	autonomous robot calibration using a trigger probe	contraste;circuit declenchement;robot movil;circuito desenganche;autonomous system;degree of freedom;coaccion;contrainte;robotics;sistema autonomo;coordinate measuring machine;constraint;robot mobile;systeme autonome;robotica;trigger;etalonnage;robotique;calibration;autonomous robot;moving robot	Abstract   This paper presents a new robot autonomous calibration method using a trigger probe. The robot grips a simple probe (which was manufactured as a standard end-effector tool) automatically to touch constraint planes in a workspace (the locations of the constraint planes are not necessarily known exactly). The robot internal sensor measurements are recorded for kinematic calibration while the tip-point of the probe is in contact with the constraint plane. The kinematic constraint conditions are obtained from the known shape of the constraint surface, rather than from the measured reference locations in a workspace. The new method eliminates any use of external measuring devices for robot end-effector location measurements for robot calibration; thus it is suitable for a periodic robot re-calibration in a shop-floor environment. Both simulation and experimental results for a six degree-of-freedom (DOF) PUMA robot are given in this paper. The evaluation results using an external precision measuring device — Coordinate Measuring Machine(CMM) — are also presented.	autonomous robot;robot calibration	Xiao-Lin Zhong;John M. Lewis;Francis L. N.-Nagy	1996	Robotics and Autonomous Systems	10.1016/0921-8890(96)00011-5	computer vision;cartesian coordinate robot;calibration;simulation;computer science;autonomous system;artificial intelligence;degrees of freedom;constraint;robotics;robot kinematics;robot calibration	Robotics	64.26656199139096	-32.95723311612821	135345
af7f2549216ade23983c64a6219c8099157f019c	editorial: annals of mathematics and artificial intelligence special issue on multi-robot coverage, search, and exploration	artificial intelligent	Research in multi robot area coverage, search, and exploration has been receiving consistent attention in recent years, due to the increasing number of real-world applications, such as vacuuming, lawn mowing, demining, surveillance, search and rescue operations, mapping, planetary exploration, etc. All of these applications require that the area of interest be covered by the robots sensors or end-effectors for various purposes. The use of multiple robots potentially provides redundancy and offers opportunities for increasing efficiency. The problem of multi robot area coverage imposes great challenges to researchers in robotics and AI area. This special issue explores the new research frontiers that emerge as new applications are identified and new technologies in robots are introduced. This special issue follows in the footsteps of the highly successful 2001 special issue on coverage. However, the objective of this issue has been broaden to include the adjacent and related fields of multi-robot search and multi-robot exploration. This special issue contains nine research papers that were carefully selected to be both of high quality and to deal with a wide verity of problems related to multi-robot coverage, search, and exploration. The first paper by Rekleitis et al. concerns with the multi-robot coverage problem. The paper presents an algorithm that solves the problem online by sending scout robots to explore the area. The second paper by Agmon, Hazon, and Kaminka deals with the same problem, but here the authors took a different approach by circumnavigating a spanning tree. The third paper by Sarid and Shapiro analyze the competitive complexity of a multi-robot search	algorithm;artificial intelligence;display resolution;planetary scanner;redundancy (engineering);robot;robotics;sensor;spanning tree	Gal A. Kaminka;Amir Shapiro	2008	Annals of Mathematics and Artificial Intelligence	10.1007/s10472-008-9105-6	computer science;artificial intelligence	AI	54.491996920413996	-29.606848474931894	135403
7d6bba64f2003055762fbb90be2748dac8af4e12	from walking to running	legged robot	The implementation of bipedal gaits in legged robots is still a challenge in state-of-the-art engineering. Human gaits could be realized by imitating human leg dynamics where a spring-like leg behavior is found as represented in the bipedal spring-mass model. In this study we explore the gap between walking and running by investigating periodic gait patterns. We found an almost continuous morphing of gait patterns between walking and running. The technical feasibility of this transition is, however, restricted by the duration of swing phase. In practice, this requires an abrupt gait transition between both gaits, while a change of speed is not necessary.	morphing;robot	Juergen Rummel;Yvonne Blum;André Seyfarth	2009		10.1007/978-3-642-10284-4_12	control engineering;legged robot;gait;computer science	HCI	64.97138114471022	-25.137532484558125	135427
2c3310215fb5f4784b68fa808463d077f71f9ccd	ambulatory human motion tracking by fusion of inertial and magnetic sensing with adaptive actuation	relative position;magnetic sensing;magnetics;human motion tracking;measurement system;biomechanics;models biological;orientation;motion tracking;monitoring ambulatory;human motion;algorithms;humans;extended kalman filter;inertial sensor;movement;inertial sensing	Over the last years, inertial sensing has proven to be a suitable ambulatory alternative to traditional human motion tracking based on optical position measurement systems, which are generally restricted to a laboratory environment. Besides many advantages, a major drawback is the inherent drift caused by integration of acceleration and angular velocity to obtain position and orientation. In addition, inertial sensing cannot be used to estimate relative positions and orientations of sensors with respect to each other. In order to overcome these drawbacks, this study presents an Extended Kalman Filter for fusion of inertial and magnetic sensing that is used to estimate relative positions and orientations. In between magnetic updates, change of position and orientation are estimated using inertial sensors. The system decides to perform a magnetic update only if the estimated uncertainty associated with the relative position and orientation exceeds a predefined threshold. The filter is able to provide a stable and accurate estimation of relative position and orientation for several types of movements, as indicated by the average rms error being 0.033 m for the position and 3.6 degrees for the orientation.	actuation dosing unit;angularjs;cooley's anemia;extended kalman filter;inertial navigation system;kinesiology;mental orientation;movement;system of measurement;the filter;velocity (software development);sensor (device)	H. Martin Schepers;Daniel Roetenberg;Peter H. Veltink	2009	Medical & Biological Engineering & Computing	10.1007/s11517-009-0562-9	movement;control engineering;computer vision;inertial reference unit;gps/ins;magnetism;engineering;biomechanics;system of measurement;control theory;mathematics;extended kalman filter;orientation;physics;quantum mechanics	Robotics	56.81696989314335	-36.42206263833151	135450
206c52f75c8bd42e6231dfcb6eaec817af4f0ab4	analysis of relationship between limb length and joint load in quadruped walking on the slope	joint load;torque;stability criteria;legged locomotion;rear leg length;legged locomotion robots leg torque joints stability criteria mathematical model;work environment;joints;numerical analysis;energy consumption;robots;mathematical model;walking quadruped limb length joint load quadruped robot numerical simulation rear leg length;simulation analysis;quadruped robot;numerical analysis legged locomotion;leg;walking quadruped;limb length;numerical simulation	An animal has a characteristic ratio of forefoot and rear legs so that its morphology can adapt to the living environment. Likewise, the structure of robot should be better fitted the locomotion in the working environment. This paper derives an optimal structure of the quadruped robot, which minimizes the sum of joint torques of the robot. Minimization of the joint torque allows to reduce the joint acceleration in walking motion, and hence to reduce energy consumption. Numerical simulation analyzed joint torques in each limb length and slope angle under walking on a slope. The optimal rate of rear leg length (RRL) is derived by the simulation as the physical structure. Our analysis suggests that the joint torque will increase as the slope angle becomes steeper in the case that the rear legs are shorter than forelegs. On the other hand, the joint torque will decrease as the slope angle is declined in the case that the forelegs are shorter than the rear legs. Experimental results validated the simulation analysis.	computer simulation;mathematical morphology;rich representation language;robot	Tadayoshi Aoyama;Kousuke Sekiyama;Yasuhisa Hasegawa;Toshio Fukuda	2008	2008 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2008.4651074	computer simulation;robot;control engineering;simulation;numerical analysis;computer science;engineering;artificial intelligence;mathematical model;control theory;torque	Robotics	67.58495020738464	-24.27971182101388	135586
76235a27c2eaa47ab3f5c8c6efe516e02788577e	learning the velocity kinematics of icub for model-based control: xcsf versus lwpr	humanoid robot;supervised learning;solid modeling joints kinematics visualization computational modeling end effectors;mobile robots;forward velocity kinematics extraction icub velocity kinematics model based control xcsf lwpr humanoid robots mechanical models machine learning method standard control approach visual servoing supervised learning methods;robot vision;humanoid robots;machine learning;model based control;visual servoing humanoid robots learning artificial intelligence mobile robots robot kinematics robot vision;learning artificial intelligence;visual servoing;robot kinematics	The model-based control of humanoid robots requires the availability of accurate mechanical models that can be hard to obtain in practice. One approach to this problem consists in calling upon machine learning methods. In this paper, using a standard control approach based on visual servoing, we compare the accuracy of two supervised learning methods, namely LWPR and XCSF, to extract the forward velocity kinematics of the upper body of the ICUB robot. Experiments are performed in simulation, using one arm and the head for reaching tasks. We show that both methods provide accurate models of the robot, with a slight advantage to XCSF over LWPR.	humanoid robot;icub;machine learning;simulation;spatial variability;supervised learning;velocity (software development);visual servoing	Guillaume Sicard;Camille Salaün;Serena Ivaldi;Vincent Padois;Olivier Sigaud	2011	2011 11th IEEE-RAS International Conference on Humanoid Robots	10.1109/Humanoids.2011.6100818	robot learning;computer vision;simulation;computer science;humanoid robot;artificial intelligence;robot control;supervised learning;visual servoing;robot kinematics	Robotics	66.88281493326899	-25.67363593993688	135748
baca8dc5c6c3681b2f12e8d386c79d06991d57e0	humanoid head prototype with uncoupled eyes and vestibular sensors	humanoid robot;prototypes eyes humans sensor systems humanoid robots mechanical sensors biosensors target tracking visual perception biomimetics;target tracking vestibular sensors uncoupled eyes mechanism humanoid head prototype biomimetic design multimodality objectives vestibular ocular reflex generic visual perception processor;sensors;uncoupled eyes mechanism;mechanical design;real time;biomimetic design;generic visual perception processor;robot vision;target tracking humanoid robot mechanical design vestibular ocular reflex;humanoid robots;humanoid head prototype;visual perception;multimodality objectives;sensors humanoid robots robot dynamics robot vision;target tracking;mechanism design;robot dynamics;vestibular ocular reflex;vestibular sensors	This paper deals with the biomimetic design of a humanoid head prototype. This prototype is developed in order to offer some mechanical device for multimodality objectives, and to demonstrate the importance of uncoupled eyes mechanism in humanoid head function. Indeed, the prototype development is based on our understanding of the humans head properties in the filed of visual and vestibular capabilities. The final prototype will have 3 DOF for each eye and 2 DOF for the neck. The developed device based as on one dof for each eye and one dof for the neck is able to show the vestibular ocular reflex (VOR) and the target tracking (TT) in real time. To carry out all these capabilities, a generic visual perception processor is developed and used. The first experiments on 3 DOF mechanism are given	biomimetics;color vision;digital single-lens reflex camera;experiment;prototype;sensor	Fethi Ben Ouezdou;Samer Alfayad;P. Pirim;S. Barthelemy	2006	2006 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2006.282231	computer vision;simulation;computer science;engineering;humanoid robot;artificial intelligence	Robotics	62.57995340142751	-31.458015148871674	135971
03e608bceaec93c39932fb9aaa284c54f64cd0a9	a dynamic calibration method of installation misalignment angles between two inertial navigation systems	dynamic calibration;inertial navigation system (ins);misalignment angles;output information fusion	Generally, in order to ensure the reliability of Navigation system, vehicles are usually equipped with two or more sets of inertial navigation systems (INSs). Fusion of navigation measurement information from different sets of INSs can improve the accuracy of autonomous navigation effectively. However, due to the existence of misalignment angles, the coordinate axes of different systems are usually not in coincidence with each other absolutely, which would lead to serious problems when integrating the attitudes information. Therefore, it is necessary to precisely calibrate and compensate the misalignment angles between different systems. In this paper, a dynamic calibration method of misalignment angles between two systems was proposed. This method uses the speed and attitude information of two sets of INSs during the movement of the vehicle as measurements to dynamically calibrate the misalignment angles of two systems without additional information sources or other external measuring equipment, such as turntable. A mathematical model of misalignment angles between two INSs was established. The simulation experiment and the INSs vehicle experiments were conducted to verify the effectiveness of the method. The results show that the calibration accuracy of misalignment angles between the two sets of systems can reach to 1″ while using the proposed method.	attitude;autonomous robot;calibration;conflict (psychology);converge;convergence (action);drug vehicle;experiment;inertial navigation system;mathematical model;natural science disciplines;pa-risc;revision procedure;simulation;sensor (device)	Kota Kita;Zengjun Liu;Yanhong Lv;Qi Wu	2018		10.3390/s18092947	electronic engineering;calibration;inertial navigation system;engineering	Robotics	56.75427715890033	-36.29399836151842	136113
c82a88a00bbdbd54472394e657ba357ed5ec4caa	temporal combination of positioning modes for auv navigation in perturbed environments	navigation acoustic measurements sea measurements position measurement velocity measurement marine vehicles costs oceans acoustic emission underwater acoustics;underwater vehicles;kalman filters;distance measurement underwater vehicles position control mobile robots transponders kalman filters navigation;mobile robots;autonomous underwater vehicle positioning modes auv navigation perturbed environments acoustical subsystem high accuracy active mode degraded passive mode sea currents active interrogation acoustic transponders active navigation mode;distance measurement;navigation;position control;positioning system;transponders	In this paper we present a positioning system for AUV’s that relies on the possibility of using its acoustical subsystem in two distinct modes: a high accuracy active mode, which is energy consuming, and a degraded passive mode, which requires no emission from the vehicle. This enables eficient use of the available on-board energy, by providing reliable estimates of external forces acting upon the vehicle (sea currents), and allowing a minimum amount of active interrogation of the acoustic transponders. The paper presents the entire architecture of the positioning system and simulation results that demonstrate the importance of careful distribution, along the mission, of the active navigation mode.	acoustic cryptanalysis;on-board data handling;positioning system;simulation;transponder	Maria-João Rendas;Isabel Lourtie	1998		10.1109/IROS.1998.727447	kalman filter;control engineering;mobile robot;navigation;simulation;telecommunications;computer science;engineering;artificial intelligence;long baseline acoustic positioning system;transponder;underwater acoustic positioning system	Robotics	55.90246699430475	-33.93005082018709	136139
f8248beda793b0b4d63790aac6d3d0d3d9eaa7ce	design and evaluation of reconfigurable robotic systems for 2 1/2 axis based material deposition strategies	process analysis activity;material deposition;modeling complexity issue;material deposition process;advanced tool motion;reconfigurable robotic system;existing tool;appropriate base platform;axis tool path;material deposition strategy;alternative deposition strategy;base platform	Simulation tools need to be developed to support modeling and product/process analysis activities for material deposition processes. The long term research goal is to develop a set of virtual modeling tools to support advanced tool motions and process planning strategies for this application. The goal of this research is to develop a reconfigurable robotic platform that can adapt alternative deposition strategies while respecting the unique process-related constraints for 2 /2 axis and 2 /2 axis + 2 axis tool paths. A variety of topologies are investigated. For the selected systems, a parametric kinematic, dynamic and control model is developed, and results presented for kinematic and dynamic reconfigurations. An adaptability assessment is performed to determine a relative effort measure to physically reconfigure a base platform to a potential new configuration. This combined with reviewing the modeling complexity issue, is used to determine an appropriate base platform. To simulate the process realistically using existing tools, a methodology is developed to illustrate material deposition in conjunction with the tool motions for the systems investigated.	apache axis;chemical vapor deposition;physical vapor deposition;robot;simulation	Ana M. Djuric;Jill Urbanic	2009	Integrated Computer-Aided Engineering	10.3233/ICA-2009-0322	simulation	Robotics	64.47456954722351	-27.165492440855115	136181
26d9ac840d8624cca359b7ed787b566205f4e510	optimization for lunar mission training scheme based on anybody software	simulation;会议论文;lunar mission training;optimization	Since majority of the lunar missions are accomplished by the upper limbs according to literature analysis, it is necessary for us to focus on studying astronauts' upper limb movement. This paper aims at studying the training schemes for the lunar mission through computer simulation with AnyBody software. Knocking, one of the typical lunar missions was selected as the study subject. Based on the verification experiment of earth's gravity level, the model of AnyBody software can be used to simulate lunar missions. An optimization of knocking move were provided by our AnyBody model.		Jing Zhang;Rong Zhou;Jingwen Li;Li Ding;Li Wang	2013		10.1007/978-3-642-39182-8_20	simulation;geography;aeronautics;remote sensing	Crypto	60.108159316509685	-26.772555765222968	136584
dbb29c019eaeb1f753049d357614c0c502711278	synthesizing a desired trajectory and sensory feedback control laws for an origami-folding robot based on the statistical characteristics of direct teaching by a human	robot sensing systems;art;motion control;probability;direct human teaching;teaching art control system synthesis feedback hidden markov models path planning position control probability robots sensors statistical analysis;fluctuations;canonical correlation origami folding robot statistical characteristics direct human teaching trajectory control synthesis sensory feedback control law hmm hidden markov model motion control probability density function parameter velocity variance;force sensors;sensors;hidden markov model;path planning;probability density function;sensory feedback control law;hmm;sensory feedback;force;educational robots;trajectory control synthesis;velocity variance;force feedback;motion segmentation;feedback;hidden markov models;trajectory;statistical analysis;origami folding robot;position control;control system synthesis;statistical characteristics;robots;success rate;feedback control robot sensing systems educational robots education humans hidden markov models fluctuations probability density function force feedback force sensors;humans;probability density function parameter;feedback control;teaching;canonical correlation	In this paper, a novel method to synthesize a desired trajectory and sensory feedback control laws for robots based on the statistical characteristics of direct teaching data by a human is proposed. This work was motivated by a poor performance of an origami-folding robot developed by the authors. Since the robot simply replayed a given trajectory without sensory feedback control, it often failed in folding due to the fluctuation of origami paper behaviors.	existential quantification;feedback;hidden markov model;humans;markov chain;robot;sensor;trajectory optimization;universal conductance fluctuations;velocity (software development)	Kenta Tanaka;Yasuyuki Kihara;Yasuyoshi Yokokohji	2009	2009 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2009.5152368	control engineering;simulation;computer science;engineering;artificial intelligence;control theory;feedback;hidden markov model;statistics	Robotics	62.29784816112048	-25.4121635513409	136803
94794467e74db8b711e6662fa160fe896d310601	real-time ego-motion estimation using lidar and a vehicle model based extended kalman filter	kalman filtering;driving;in vehicle sensors;laser radar;automated driving maneuvers lidar detected objects ego motion estimation scheme ego localization scheme driving physics nonlinear tire characteristics advanced vehicle model based extended kalman filter vehicle sensors landmarks bearing measurements lidar based range measurements lateral dynamic state variables longitudinal dynamic state variables real time estimation vehicle motion vehicle position vehicle guidance automation preventive vehicle safety systems;proximity detectors;vehicle dynamics direction of arrival estimation kalman filters motion estimation nonlinear filters optical radar;estimating;autonomous land vehicles;vehicles estimation sensors laser radar vehicle dynamics tires mathematical model	Automated driving maneuvers enable a highly reproducible validation of preventive vehicle safety systems. However, the automation of vehicle guidance requires an exact and reliable knowledge of current vehicle position and motion. This paper presents a new method for the real-time estimation of the vehicle position and of further longitudinal and lateral dynamic state variables. Fundamental idea is the fusion of the Lidar-based range and bearing measurements of landmarks with the information of various vehicle sensors by means of an advanced vehicle model based Extended Kalman Filter. It takes into account the nonlinear tire characteristics at the limits of driving physics when estimating the variables. Moreover, the proposed ego-localization and ego-motion estimation scheme incorporates an approach for the automated association of Lidar-detected objects to predefined landmarks. Using the experimental results of a highly dynamic driving maneuver the accuracy and robustness of the proposed method is demonstrated.	algorithm;extended kalman filter;lateral thinking;mathematical optimization;motion estimation;nonlinear system;real-time clock;region of interest;satellite navigation;sensor;test automation;visual odometry	Klaus Zindler;Niklas Geiß;Konrad Doll;Sven Heinlein	2014	17th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2014.6957728	control engineering;simulation;engineering;control theory	Robotics	54.440204942498674	-36.39589782986463	137002
72765313c74c72706abe495635adca62980c2c1d	learning and prediction of slip from visual information	slip prediction;negative affect;errors;prediction error;predictions;roving vehicles;slopes;mobility;terrain;chip;navigation;soils;robots;rover;rough terrain;planetary geology;imaging systems;nonlinear regression	This paper presents an approach for slip prediction from a distance for wheeled ground robots using visual information as input. Large amounts of slippage which can occur on certain surfaces, such as sandy slopes, will negatively affect rover mobility. Therefore, obtaining information about slip before entering such terrain can be very useful for better planning and avoiding these areas. To address this problem, terrain appearance and geometry information about map cells are correlated to the slip measured by the rover while traversing each cell. This relationship is learned from previous experience, so slip can be predicted remotely from visual information only. The proposed method consists of terrain type recognition and nonlinear regression modeling. The method has been implemented and tested offline on several off-road terrains including: soil, sand, gravel, and woodchips. The final slip prediction error is about 20%. The system is intended for improved navigation on steep slopes and rough terrain for Mars rovers. © 2007 Wiley Periodicals, Inc. • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • •	john d. wiley;nonlinear system;online and offline;robot;rover (the prisoner)	Anelia Angelova;Larry H. Matthies;Daniel M. Helmick;Pietro Perona	2007	J. Field Robotics	10.1002/rob.20179	chip;robot;computer vision;navigation;terrain;simulation;planetary geology;prediction;mean squared prediction error;slope;nonlinear regression;statistics;remote sensing;affect	Robotics	54.09600008107654	-31.44308148790516	137003
55ae83f42e0f1e0d6aea1d06aa5ac187d2ef06ea	effect of sequence order on autonomous robotic database expansion		Generating trajectories autonomously through generalization requires an extensive database of motion, which is usually time-consuming and difficult to obtain. Recently approaches for autonomous database expansion for the generation of compliant and accurate motion were proposed, all showing that autonomous generation of the database of motion can be significantly speed up. However, no extensive analysis was performed to show what would be the optimal sequence of learning. In this paper we analyze different strategies to further speed up the learning process of autonomous database expansion for compliant movement primitives (CMPs). An extensive analysis was performed for finding an optimal learning sequence in a simulated environment for a peg-in-hole task with a Kuka LWR-4 robot. The obtained results were then confirmed on a real Kuka LWR-4 robot set up performing a peg-in-hole task.		Tadej Petric;Andrej Gams	2016		10.1007/978-3-319-49058-8_44	robot;database;speedup;computer science	Robotics	61.17358334559239	-24.698435589814615	137135
e02bd7b0f123d6b9a77d9acc635f1f052fa21b31	bipedal walking with corrective actions in the tilt phase space		Many methods exist for a bipedal robot to keep its balance while walking. In addition to step size and timing, other strategies are possible that influence the stability of the robot without interfering with the target direction and speed of locomotion. This paper introduces a multifaceted feedback controller that uses numerous different feedback mechanisms, collectively termed corrective actions, to stabilise a core keypointbased gait. The feedback controller is experimentally effective, yet free of any physical model of the robot, very computationally inexpensive, and requires only a single 6-axis IMU sensor. Due to these low requirements, the approach is deemed to be highly portable between robots, and was specifically also designed to target lower cost robots that have suboptimal sensing, actuation and computational resources. The IMU data is used to estimate the yaw-independent tilt orientation of the robot, expressed in the so-called tilt phase space, and is the source of all feedback provided by the controller. Experimental validation is performed in simulation as well as on real robot hardware.	computational resource;control theory;experiment;feedback;game controller;mechatronics;requirement;robot;robustness (computer science);sensor;simulation;yaws	Philipp Allgeuer;Sven Behnke	2018	CoRR		inertial measurement unit;control theory;control engineering;control theory;phase space;robot;computer science;gait	Robotics	65.0521350562506	-24.471556265887102	137137
aa5ca83bfa1f3b433376b63c42d567ddd3370811	a fusion of a monocular camera and vehicle-to-vehicle communication for vehicle tracking: an experimental study		In this paper we present the procedure of fusing a monocular camera based vehicle tracking and IEEE 802.11p Vehicle-to-Vehicle communication enabled position, velocity and time sharing. Toward a monocular camera-based detection and tracking, Haar-like features of a vehicle are trained, median flow tracking algorithm is applied, pixel based relative distance and relative speed is estimated. In order to improve reliability and availability of tracking system, IEEE 802.11p radio modem is added. Then, we implement Particle Filter algorithm in order to fuse the information provided by these two sensors subject to different characteristics. We evaluate the tracking system by the real road data collected on highway. Sensor fusion results along different road scenarios are presented. We present the state-of-the-art low cost sensor fusion, our application setup and elaborate some experimental results.	benchmark (computing);haar wavelet;modem;particle filter;peterson's algorithm;pixel;satellite navigation;sensor web;time-sharing;vehicle tracking system;vehicle-to-vehicle;velocity (software development)	Daniel L. Lepkowski;Cagdas Yaman;Tankut Acarman;Murat Akin	2018	2018 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2018.8500449	vehicle tracking system;vehicular communication systems;radio modem;pixel;feature extraction;computer vision;tracking system;sensor fusion;monocular;computer science;artificial intelligence	Robotics	53.853154030625184	-37.72004630071901	137155
a15aefc3468da549808620aba4f3cb28758ccf23	vision tracking application for mobile navigation using humanoid robot nao	robot sensing systems;microcontrollers;robot vision collision avoidance humanoid robots microcontrollers mobile robots object tracking;turning;navigation turning robot sensing systems visualization microcontrollers mobile communication;navigation;visualization;mobile communication;nao mark visual tracking vision tracking application mobile navigation humanoid robot nao humanoid operated mobile platform aldebaran robotics arduino microcontroller target board mobile platform arduino microcontroller programming choregraphe obstacle avoidance human following ability	This project presents a new approach of humanoid-operated mobile platform. The robot used in this work is Nao by Aldebaran Robotics. Nao is chosen because of its versatility. Its wide range of movements allows it to perform various tasks such as steering through a simple programming algorithm. Arduino microcontroller target board is used to provide the interface between Nao robot and the mobile platform. This project consist of several parts. This study will focuses on the development of mobile platform, integration of Arduino microcontroller programming with Nao's Choregraphe, navigation with obstacle avoidance and finally navigation with human following ability by implementing Nao Mark visual tracking.	algorithm;arduino;humanoid robot;microcontroller;mobile operating system;nao (robot);obstacle avoidance;robotics;video tracking	Ilmi Mohd Ariffin;Ahmad Ismat Hakam Mohamed Rasidi;Hanafiah Yussof;Mohd Azfar Miskam;Abdul Rahman Bin Omar	2015	2015 International Symposium on Micro-NanoMechatronics and Human Science (MHS)	10.1109/MHS.2015.7438284	mobile robot;embedded system;computer vision;simulation;engineering;mobile robot navigation	Robotics	60.09843979667961	-30.384310203971648	137345
ae32bcafbb9122c901ca7a6411318612122755cb	two vision-guided vehicles: temporal coordination using nonlinear dynamical systems	motion control;mobile robot;path planning;nonlinear dynamical systems;dynamic system;mobile robots;nonlinear;remotely operated vehicles;generation time;nonlinear dynamical systems vehicle dynamics robot kinematics noise generators timing limit cycles trajectory mobile robots robust control decision making;position control;limit cycle;robot movement vision guided vehicles temporal coordination nonlinear dynamical systems limit cycle type solutions vision guided mobile robots;vision guided vehicles;remotely operated vehicles mobile robots motion control nonlinear dynamical systems path planning position control;non structural;vision guided mobile robots;robot movement;limit cycle type solutions;dynamical systems;temporal coordination;nonlinear dynamic system;simulation environment	This article addresses the problem of generating timed trajectories and temporally coordinated movements for two wheeled vehicles, when relatively low-level, noisy sensorial information is used to steer action. The generated trajectories have controlled and stable timing (limit cycle type solutions). Incoupling of sensory information enables sensor driven termination of movement. We build on a previously proposed solution in which timed trajectories and sequences of movements were generated as attractor solutions of dynamic systems. We present a novel system composed of two coupled dynamical architectures that temporally coordinate the solutions of these dynamical systems. The coupled dynamics enable synchronization of the different components providing an independence relatively to the specification of their individual parameters. We apply this architecture to generate temporally coordinated trajectories for two vision-guided mobile robots in a non-structured simulated environment, whose goal is to reach a target within a certain time independently of the environment configuration or the distance to the target. The results illustrate the robustness of the proposed decision-making mechanism and show that the two vehicles are temporal coordinated: if a robot movement is affected by the environment configuration such that it will take longer to reach the target, the control level coordinates the two robots such that they terminate approximately simultaneously.	autonomous robot;control system;course (navigation);dynamical system;high- and low-level;limit cycle;microsoft outlook for mac;mobile robot;nonlinear system;requirement;simulation;systems architecture;temporal logic;terminate (software);velocity (software development);virtual reality	Cristina P. Santos;Manuel Ferreira	2007	Proceedings 2007 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2007.363758	control engineering;mobile robot;simulation;nonlinear system;computer science;engineering;artificial intelligence;control theory	Robotics	57.855862480691385	-25.381424474384072	137728
59b31e63d7493901bf863e82c656843fc9873669	low cost robot arm with visual guided positioning		Low cost robotic solutions are of great importance for improvement and development of robotics. In this paper, two visually guided low cost robot arms are proposed. The proposed system performs automatic hand-eye calibration and, after the calibration, positions its end effector above the object of interest using visual servoing based on off the shelf marker tracker. The presented experiments demonstrate positioning accuracy of the proposed setup.	coat of arms;experiment;robot end effector;robotic arm;visual servoing	Petra Durovic;Ratko Grbic;Robert Cupec;Damir Filko	2017	2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)	10.23919/MIPRO.2017.7973592	robot calibration;arm solution;mobile robot;computer science;robot control;computer vision;visual servoing;robotic arm;robot kinematics;robot end effector;artificial intelligence	Robotics	59.09402472194023	-34.60812199181522	137873
cdd1e154fb894fbbb192b8f285ccf3ee9c51d4f5	a coupled oscillators-based control architecture for locomotory gaits	optimal control torque shape robot kinematics equations mathematical model;coupled planar rigid body systems coupled oscillators based control architecture locomotory gaits bio inspired central pattern generator architecture optimal control cpg circuit coupled oscillator feedback particle filter posterior distribution;optimal control biomimetics gait analysis neural net architecture neurocontrollers	This paper presents a bio-inspired central pattern generator (CPG) architecture for optimal control of locomotory gaits. The CPG circuit is realized as a coupled oscillator feedback particle filter. The collective dynamics of the filter are used to approximate a posterior distribution that is used to construct the optimal control input. The architecture is illustrated with the aid of a model problem involving locomotion of coupled planar rigid body systems, with two links. For this problem, the coupled oscillator feedback particle filter is designed and its control performance demonstrated in a simulation environment.	approximation algorithm;biological system;british informatics olympiad;central pattern generator;optimal control;particle filter;robot;simulation	Amirhossein Taghvaei;Seth Hutchinson;Prashant G. Mehta	2014	53rd IEEE Conference on Decision and Control	10.1109/CDC.2014.7039930	control engineering;simulation;engineering;control theory	Robotics	65.66637525755473	-25.490925650822092	138463
576b7f0a337db7ccbcc2b1b064c07c62b5a2ec50	study on the target positioning for an omni-directional 3 dof mobile manipulator based on machine vision		The omni-directional mobile robot with multi DOF, because the operation posture and operation accuracy of the manipulator can be better controlled in a narrow or crowded workplace compared with the general manipulator, is getting more interested in practical applications. The present problem is to improve its flexibility for operating multiple different targets. Target recognition with image processing is an effective solution. Based on the image processing, the position and posture of the target can be determined. Then the signal will be sent to the arm control system. In this paper, the illumination conditions, distortion, etc. are studied in the target recognition. The target position with image processing, is verified with real coordinates. The experiments show target recognition with image processing can effectively improve the flexibility of our robot.	control system;distortion;experiment;image processing;machine vision;mobile manipulator;mobile robot;poor posture	Jiwu Wang;Yao Du;Wensheng Xu;Masanori Sugisaka	2017	JRNAL	10.2991/jrnal.2017.4.3.9	mobile robot;mobile manipulator;computer vision;machine vision;artificial intelligence;computer science	Robotics	59.0858003450602	-32.04358527151935	138482
64bad7b9513476e42893c752d2a608fa6c7b487c	mga trajectory planning with an aco-inspired algorithm	optimization;space missions;time of arrival;genetic algorithm;ant colony optimization;planning	Given a set of celestial bodies, the problem of finding an optimal sequence of swing-bys, deep space manoeuvres (DSM) and transfer arcs connecting the elements of the set is combinatorial in nature. The number of possible paths grows exponentially with the number of celestial bodies. Therefore, the design of an optimal multiple gravity assist (MGA) trajectory is a NP-hard mixed combinatorial-continuous problem. Its automated solution would greatly improve the design of future space missions, allowing the assessment of a large number of alternative mission options in a short time. This work proposes to formulate the complete automated design of a multiple gravity assist trajectory as an autonomous planning and scheduling problem. The resulting scheduled plan will provide the optimal planetary sequence and a good estimation of the set of associated optimal trajectories. The trajectory model consists of a sequence of celestial bodies connected by twodimensional transfer arcs containing one DSM. For each transfer arc, the position of the planet and the spacecraft, at the time of arrival, are matched by varying the pericentre of the preceding swing-by, or the magnitude of the launch excess velocity, for the first arc. For each departure date, this model generates a full tree of possible transfers from the departure to the destination planet. Each leaf of the tree represents a planetary encounter and a possible way to reach that planet. An algorithm inspired by Ant Colony Optimization (ACO) is devised to explore the space of possible plans. The ants explore the tree from departure to destination adding one node at the time: every time an ant is at a node, a probability function is used to select a feasible direction. This approach to automatic trajectory planning is applied to the design of optimal transfers to Saturn and among the Galilean moons of Jupiter. Solutions are compared to those found through more traditional genetic-algorithm techniques. Multiple gravity assist, Interplanetary trajectory design, Ant colony optimization, Planning, Optimization	ant colony optimization algorithms;automated planning and scheduling;autonomous robot;binary tree;celestial coordinate system;genetic algorithm;hercules graphics card;mathematical optimization;np-hardness;offset binary;planetary scanner;program optimization;programming paradigm;scheduling (computing);time of arrival;velocity (software development)	Matteo Ceriotti;Massimiliano Vasile	2010	CoRR		planning;mathematical optimization;ant colony optimization algorithms;simulation;genetic algorithm;engineering;space exploration;time of arrival;evolutionary computation	Robotics	54.051053947768885	-24.85408475137791	138889
9f50c4033e2069206c1059fdc8cc3f96875d3fdf	autonomous flying with quadrocopter using fuzzy control and aruco markers		In this paper, we present an approach which enables a low-cost quadrocopter to fly various trajectories autonomously. Artificial landmarks are used for pose estimation, and a fuzzy controller is utilized to generate steering commands. The presented system can navigate a low-cost quadrocopter along a predefined path without the need for any additional external sensors. In addition to a full description of our system, we also introduce our software package for Robot Operating System, which allows the robotics community to experiment with proposed mapping algorithm.	fuzzy control system	Jan Bacik;Frantisek Durovsky;Pavol Fedor;Daniela Perdukova	2017	Intelligent Service Robotics	10.1007/s11370-017-0219-8	control theory;fuzzy logic;computer vision;robot;simulation;computer science;pose;fuzzy control system;software;robotics;artificial intelligence	Robotics	58.70443276147149	-29.730190151005228	139050
b0866c3e9ed4725f54fe203b6baa4912ca20271a	feature extraction from partial shape information for fast grasping of unknown objects	robot sensing systems;grasping;mobile robot;mobile robots;image sensors;three dimensional;dexterous manipulators;robot vision;shape;three dimensional displays;grasping robot sensing systems grippers feature extraction shape three dimensional displays;feature extraction;grippers;robot vision dexterous manipulators feature extraction grippers image sensors mobile robots;feature extraction partial shape information unknown object grasping mobile robot parallel jaw gripper 2d range sensor inclined angle candidate grasping points object lifting grasping trials object information	In this work, we present a method involving the fast grasping of an unknown object by a mobile robot with a parallel-jaw gripper. A 2D range sensor is installed on the robot at an inclined angle to acquire partial shape information regarding the unknown objects. The candidate grasping points for an unknown object can then be determined by directly extracting features from this partial shape information. After object grasping and lifting, whether the object can be lifted is judged. If the robot fails to lift the object, then detects other candidate grasping points and performs grasping trials until the object is lifted. The path for the robot to find the grasping points is also designed. The grasping time can be decreased without the need for acquiring and processing all of the object information. Experiments are conducted, and the results illustrate the validity of the proposed algorithm.	algorithm;experiment;feature extraction;lifting scheme;mobile robot;robot end effector	Zhaojia Liu;Lounell B. Gueta;Jun Ota	2011	2011 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2011.6181473	control engineering;mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence;robot control	Robotics	59.730868296434004	-35.14483848299455	139159
ee3451fc0e9f4eba3e07b874dfc5703036be34e1	autonomous maneuvers of a robotic tractor for farming	agricultural machinery;robot sensing systems;turning;navigation;trajectory;robot kinematics	This paper address the problem of motion control of an agricultural robot during the whole process of farming work; including maneuvers to follow straight crop rows inside the field, and operations of lane change at the headland. The navigation sensors consisted of an inertial measurement unit and a real-time kinematic GPS. The control algorithm was able to identify the bias of the yaw angle and compensate lateral deviation caused by inclination of the robotic tractor, in order to guide the robot accurately in the field. A circle-back turning algorithm based on continuous primitives connected together was used at the headland to create reference paths. In addition, steering maneuvers for lane change were performed while the robot tractor is moving in order to protect the surface of the soil at the headland. To follow the path accurately, the slide movement of the tractor and the steering rate were taken into account by estimating the turning radius on real-time. Therefore, guidance paths could be optimized based on the specific condition of the field. Finally, the performance of proposed autonomous maneuvers was evaluated in field experiments.	agricultural robot;algorithm;autonomous car;autonomous robot;experiment;global positioning system;lateral thinking;nautical chart;real time kinematic;real-time clock;sensor;velocity (software development);yaws	Hao Wang;Noboru Noguchi	2016	2016 IEEE/SICE International Symposium on System Integration (SII)	10.1109/SII.2016.7844063	control engineering;simulation;engineering;control theory	Robotics	57.63137150410854	-29.056058827458383	139247
185f0d377b31d365f2f90aed759ee8dca54c429a	manipulating deformable linear objects: sensor-based skills of adjustment motions for vibration reduction		The vibration of a deformable object is often a problem when it is automatically handled by a robot manipulator. However, humans can often handle and damp the vibration of deformable objects with ease. This paper presents force/torque sensor-based skills for handling deformable linear objects in a manner suitable to reduce acute vibration with simple human skill inspired strategies, that consist of one or two adjustment motions. The adjustment motion is a simple open-loop motion that can be attached to the end of any arbitrary end-effector’s trajectory. As an ordinary industrial robot’s simple action, it has three periods, i.e., acceleration, constant speed and deceleration periods; it starts from a predicted time tightly close to a force/moment maximum. The predicted time for the adjustment action is generated automatically on-line based on the vibration rhythm and the data sensed by a force/torque sensor mounted on the robot’s wrist. To find the matching point between the vibrational signal of the deformable object and a template, template matching techniques including crosscorrelation and minimum squared error methods are used and compared. Experiments are conducted with an industrial robot to test the new skills under various conditions. The results demonstrate that an industrial robot could perform effective vibration reduction skills with simple strategies.	artificial neural network;cross-correlation;discontinuity layout optimization;experiment;feedback;industrial robot;online and offline;robot end effector;sensor;template matching	Shigang Yue;Dominik Henrich	2005	J. Field Robotics	10.1002/rob.20049	control engineering;computer vision;simulation;engineering;control theory	Robotics	65.03587798541186	-24.657681011121575	139271
380a058e22574a7503a700ae980a45cc19c79110	a cooking support system with force visualization using force sensors and an rgb-d camera		This paper describes the development of a cooking support system using force sensors and an RGB-D camera. The knife and the cutting board with 6-axis force sensors can detect the external force vector and the position of the exerted force. The proposed force visualization system is supposed to be utilized during cooking.		Nobuhiro Totsu;Sho Sakaino;Toshiaki Tsuji	2016		10.1007/978-981-10-4157-0_50	visualization;haptic technology;rgb color model;computer vision;computer science;artificial intelligence	Robotics	66.78795484104357	-30.708641709538128	139288
b5144f47b3e0489703483d932b95092da2d6e6f3	navigational strategies of mobile robots: a review	navegacion;compas;robot movil;gas;ensayo no destructivo;disco magnetico;control difusa;methode potentiel;mesure magnetique;neural networks;sensors;essai non destructif;ga;mobile robot;infrared thermography;fuzzy control;heuristic method;robot sensors;mesure acoustique;logique floue;robot navigation;logica difusa;metodo heuristico;mobile robots;robotics;circuito logico;algoritmo genetico;magnetic disk;medida sin contacto;laser sensors;transductor ultrasonido;fuzzy logic;captador medida;thermographie ir;navigation;measurement sensor;research and development;capteur mesure;robot vision;ultrasonic sensors;robot mobile;non destructive test;circuit logique;investigacion desarrollo;detecteur ir;potential method;algorithme genetique;robotica;ultrasonic transducer;termografia ir;genetic algorithm;genetic algorithms;medida acustica;non contact measurement;medida magnetica;metodo potencial;magnetic compass disk sensors;robotique;methode heuristique;reseau neuronal;magnetic measurement;disque magnetique;infrared detector;logic circuit;detector rayos infrarrojos;mesure sans contact;infrared sensors;red neuronal;moving robot;recherche et developpement;transducteur ultrason;acoustic measurement;commande floue;neural network;compasses	Present research and development in the area of mobile robots mainly aims at study of various techniques, methods and sensors being used for navigation of mobile robots. Different techniques have been discussed for the navigation of mobile robots in the first part. These techniques can be subdivided as (1) fuzzy logic technique, (2) neural network technique and (3) genetic algorithm technique. In the second part, five methods are being discussed for navigation of mobile robots. These methods are (1) potential field method, (2) grid-type method, (3) heuristic method, (4) adaptive navigation method and (v) Virtual Impedance method. The last segment focuses on different sensors being used for navigation of mobile robots. The sensors discussed are (1) ultrasonic sensor, (2) laser sensor, (3) magnetic compass disk sensor, (4) infrared sensor and (5) vision (camera) sensor. Keeping the above strategies in forefront, a comprehensive discussion has been made and is described methodologically in the current paper.	artificial neural network;cognition;computer multitasking;control theory;emoticon;fuzzy logic;genetic algorithm;heuristic;microsoft forefront;mobile robot;nominal impedance;robotic mapping;sensor;software release life cycle	Dayal R. Parhi;Mukesh Kumar Singh	2009	IJAAC	10.1504/IJAAC.2009.025237	mobile robot;genetic algorithm;telecommunications;computer science;engineering;artificial intelligence;ultrasonic sensor;mobile robot navigation;artificial neural network	Robotics	63.22569511105599	-32.987688844598566	139335
01269c4dce9e6151e0a80b006017de6054e8af82	kinematic modeling of a small mobile robot with multi-locomotion modes	kinematic modeling;motion control;legged locomotion;mobile robot;multi locomotion modes;rough terrains;kinematic mobile robot multi locomotion modes;slippage;rough terrains kinematic modeling small mobile robots multi locomotion modes wheel track legged robots mobit hazardous environments obstacle negotiating mode differential driven robots slippage posture definition autonomous motion control;differential driven robots;kinematic;kinematics mobile robots control systems robot sensing systems machine vision equations wheels vehicles monitoring sensor systems;obstacle negotiating mode;collision avoidance;rough terrain;robot kinematics collision avoidance legged locomotion motion control;mobit;small mobile robots;posture definition;wheel track legged robots;hazardous environments;autonomous motion control;robot kinematics	The paper describes the kinematic modeling of a small wheel-track-legged mobile robot MOBIT which is targeted to applications in various hazardous environments to carry out military and civilian missions. The kinematic modeling for MOBIT has some individuality because of its multi-locomotion modes named wheeled, tracked, legged mode and obstacle negotiating mode. Different kinematics equations are derived based on its multi-locomotion modes respectively, and their features of kinematics in different modes are revealed. Particularly, the kinematic description of differential driven in wheeled mode, characteristics of slippage in tracked mode and posture definition in legged mode are presented mathematically. Unlike other robot operating on a flat surface, the proposed equations are solved to obtain the robot position and posture which can be used for autonomous motion control of robot operating in rough terrains	autonomous robot;mobile robot;poor posture;rough set	Xingguang Duan;Qiang Huang;Nasir Rahman;Jingtao Li;Qinjun Du	2006	2006 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2006.282276	control engineering;motion control;mobile robot;computer vision;kinematics;simulation;computer science;engineering;artificial intelligence;inverse kinematics;robot kinematics;robot calibration	Robotics	63.93405516266122	-27.661128563197334	139458
b0e1fbb4a1cce9a616e0bbdecd67e65f5cbd5877	a visual servoing algorithm using fuzzy logics and fuzzy-neural networks	moving object;image features;ccd camera;fuzzy neural network;fuzzy neural nets;motion control;perspective projection;input variables;fuzzy control;4 axis scara robot;fuzzy logic;camera motion;fuzzy logics;compensation;robot vision;visually guided line of sight robot motion;servomechanisms;b w ccd camera visual servoing algorithm fuzzy logics fuzzy neural networks image features visually guided line of sight robot motion 4 axis scara robot;robot motion;visual servoing algorithm;dynamic characteristic;visual servoing fuzzy logic robot vision systems cameras tracking input variables robot motion motion measurement motion control fuzzy neural networks;fuzzy neural networks;motion measurement;visual servoing;robot vision systems;b w ccd camera;cameras;line of sight;tracking;compensation robot vision servomechanisms fuzzy control fuzzy neural nets	A visual servoing algorithm is proposed for a robot with a camera in hand, where fuzzy logics and fuzzy-neural networks are employed to represent and/or learn camera motion commands to track a moving object in terms of image features and their variations. Specifically, novel image features are suggested by employing a viewing model of perspective projection to estimate relative pitching and yawing angles between the object and the camera. And, owing to the uniqueness of the proposed image features, at most two input variables are shown to be sufficient for the design of fuzzy logics and/or fuzzy-neural networks. To compensate dynamic characteristics of the robot, desired feature trajectories for the learning of visually guided line-of-sight robot motion are obtained by measuring features by the camera in hand not in the entire workspace, but on a single linear path along which the robot moves under the control of a commercially provided function of linear motion. And then, control actions of the camera are approximately found by fuzzy neural networks to follow such desired feature trajectories. To show the validity of proposed algorithm, some experimental results are illustrated, where a four axis SCARA robot with a B/W CCD camera is used.	algorithm;artificial neural network;fuzzy logic;visual servoing	Il Hong Suh;Tae Won Kim	1996		10.1109/ROBOT.1996.509262	fuzzy logic;control engineering;motion control;computer vision;camera auto-calibration;perspective;computer science;artificial intelligence;control theory;tracking;charge-coupled device;visual servoing;feature;fuzzy control system	ML	60.70291574734068	-31.58780777558268	139488
8b53a78cce335a06cbd87c95062b3491843ba94d	a fault tolerant state estimation framework with application to ugv navigation in complex terrain	stereo sensors;fault detection and isolation;atmospheric measurements;navigation kinematics computer architecture mathematical model position measurement quaternions atmospheric measurements;fault tolerant;ugv;sensor fault detection;angular motion model;path planning;fault tolerant state estimation;mobile robots;remotely operated vehicles;data fusion;state estimation;kinematics;state estimation fault diagnosis fault tolerance filtering theory global positioning system mobile robots path planning remotely operated vehicles road vehicles robot dynamics sensor fusion;unmanned ground vehicle navigation;computer architecture;navigation;fault tolerant state estimation framework;bayesian filtering framework;degeneration;kinematic state transition model;global positioning system;sensor measurements;fault tolerance;position measurement;bayesian filtering;mathematical model;ugv navigation;unmanned ground vehicle navigation fault tolerant state estimation framework ugv navigation sensor measurements sensor fault detection uncoupled fusion architecture asynchronous sensors bayesian filtering framework stereo sensors kinematic state transition model angular motion model coupled linear motion model ftse system;asynchronous sensors;complex terrain;sensor fusion;robot dynamics;data fusion navigation asynchronous sensors fault tolerant state estimation ugv;filtering theory;state transition;ftse system;uncoupled fusion architecture;coupled linear motion model;quaternions;fault diagnosis;road vehicles	In this paper a fault tolerant state estimation (FTSE) framework is developed for reliable navigation. The framework features kinematic state estimation using Bayesian filtering of sensor measurements, and sensor fault detection and isolation. Another development is an uncoupled fusion architecture that allows the system state to be updated by asynchronous sensors, makes the system easily scalable and allows the system to degenerate gracefully during one or more sensor outage. A novel procedure to incorporate relative measurements, such as relative pose from stereo sensors, into the Bayesian filtering framework is also developed. In addition, a novel kinematic state transition model is developed that exploits the dynamics of UGV, provides a coupled linear and angular motion model and avoids over-fitting of measurement data. The FTSE system's performance is demonstrated based on results from processing real data.	angularjs;autonomous robot;bayesian network;downtime;fault detection and isolation;fault tolerance;fundamental theorem of software engineering;global positioning system;nonlinear system;overfitting;scalability;sensor	Abhijit Sinha;Abir Mukherjee;Xia Liu;Simon Monckton;Gregory Broten	2011	14th International Conference on Information Fusion		control engineering;computer vision;engineering;control theory	Robotics	54.12139503836506	-35.517409347698695	139651
9786dbc587cfebde99e3ec3e0c8165ced0a4b431	mechanical planning and actual test results of a robot for painting the exterior walls of high-rise buildings	estructura mecanica;robotics;paint;mechanical structure;structure mecanique;peinture;edificio;robotica;robotique;pintura;bâtiment;buildings	A robot developed for repainting the exterior walls of Tokyo's Shinjuku Center Building (54 stories above and 3 stories below the ground, and 219.5 m high) is introduced with an explanation of its mechanism and a demonstration of its actual use. The first robot of its kind developed in Japan successfully demonstrated its capability to complete its mission of painting an area of 95,400 m2 while automatically avoiding glass and openings.	robot	Shigeru Sakamoto	1990	Advanced Robotics	10.1163/156855391X00331	simulation;computer science;engineering;artificial intelligence;robotics	Robotics	65.4650217383411	-31.673677658914276	139800
8b5e46291ae0af8ec7bbf2047cb839aabd1289c2	a general control architecture for dynamic bipedal walking	spatial variables control;control algorithm;learning algorithm;velocity control;legged locomotion leg velocity control humans laboratories partitioning algorithms algorithm design and analysis torso taxonomy biomechanics;legged locomotion;spatial variables control velocity control legged locomotion robot dynamics learning systems learning artificial intelligence;dynamic model;learning systems;control architecture;local speed control mechanism general control architecture dynamic bipedal walking intuitive control algorithms learning algorithms swing leg body posture planar biped 3d biped;learning artificial intelligence;robot dynamics;speed control	W e propose a general but simple bipedal walking control architecture that incorporates intuitive control and learning algorithms. The learning algorithm is mainly used to generate the key parameters for the swing leg. The intuitive control is used to maintain the height and body posture. Based on the proposed architecture, a control algorithm is constructed and applied to a planar biped and a 30 biped. B y applying appropriate local speed control mechanism, we demonstrate that the bipeds can successfully achieve walking of 100 seconds within a reasonable number of trials. No dynamic models or nominal joint trajectory data are required for the implementations. .	algorithm;machine learning;poor posture	Chee-Meng Chew;Gill A. Pratt	2000		10.1109/ROBOT.2000.845353	control engineering;simulation;computer science;engineering;artificial intelligence;control theory;electronic speed control	Robotics	63.713688851802516	-24.815394102978182	139849
468c412e3bbfc74311c6dda156251d4325cfefae	motion planning for multiple mobile robots using dynamic networks	selected works;path planning;position control path planning mobile robots multi robot systems robot dynamics;mobile robots;motion planning mobile robots robot kinematics robot sensing systems aerodynamics computational modeling process planning aerospace safety mobile communication sensor systems;dynamic environment;multiple mobile robots;position control;multi robot systems;motion planning;on the fly;real robot experiments motion planning multiple mobile robots dynamic environments centralized planning decentralized planning dynamic robot networks localized robot groups robot goals coordinated trajectories;bepress;robot dynamics;dynamic networks	Abslrucl A new motion planning framework is presented that enables multiple mobile robots with limited ranges of sensing and communication to maneuver and achieve goals safely in dynamic environments. To combine the respective advantages of centralized and de-centralized planning, this framework is based on the concept of centralized planning within dynamic robot networks. As the robots move in their environment, localized robot groups form networks, within which world models and robot goals can be shared. Whenever a network is formed, new information then becomes available to all robots in this network. With this new information, each robot uses a fast, centralized planner to compute new coordinated trajectories on the fly. Planning over several robot networks is decentralized and distributed. Both simulated and real-robot experiments have validated the approach.	12-hour clock;algorithm;artificial intelligence;canny edge detector;centralized computing;collision detection;experiment;mobile robot;motion planning;on the fly;robotics;stationary process;statistical relational learning;workspace	Christopher M. Clark;Stephen M. Rock;Jean-Claude Latombe	2003		10.1109/ROBOT.2003.1242252	control engineering;mobile robot;computer vision;simulation;articulated robot;computer science;engineering;artificial intelligence;social robot;arm solution;motion planning;robot control;ubiquitous robot;mobile robot navigation;personal robot	Robotics	57.642841662662995	-24.741100780372694	139997
436c492bd3415596d0d8182d4f4c73acaa232d0b	gmp based fuzzy reasoning: an application to sonar based navigation	fuzzy reasoning;gmp based reasoning;fuzzy logic;mobile robot navigation;sonar		gnu multiple precision arithmetic library;sonar	Kudret Demirli;I. Burhan Türksen;Mohammad Molhim	2003	JACIII	10.20965/jaciii.2003.p0053	fuzzy logic;computer vision;computer science;artificial intelligence;neuro-fuzzy;machine learning;mobile robot navigation;sonar	Robotics	59.30749134468492	-27.980808784254833	140090
14a2b6f3effce8e9be66f07fdf06c1ed59d906f8	the function of the spine and its morphological effect in quadruped robot locomotion	gait property morphological effect quadruped robot locomotion quadruped animal spinal movement body posture control leg movement quadruped model spine driven locomotion behavior axial driven propulsion spinal morphology actuated spinal joint minimalistic control strategy;propulsion legged locomotion position control	In quadruped animals, spinal movements contribute to locomotion in terms of controlling body posture, providing the foundation to generate leg movement, and integrating limb and trunk actions. Inspired by this biological findings, we develop two quadruped models featuring different numbers of spinal joints to demonstrate the spine-driven locomotion behaviors. To gain a deep understanding of how the locomotion is achieved by axial driven propulsion and how the spinal morphology affects locomotion, we exclusively employ actuated spinal joint(s) to the model with a minimalistic control strategy. We choose three individuals from these two models and analyze their behaviors in terms of gait properties, i.e., angle of attack, ground clearance, and movement of the center of mass. The results show that employing the spinal morphology with two joints can greatly enhance the stability and speed of locomotion. Among several advantageous properties of the two spinal joint model we identify the following. First, it allows the robot to adjust the movement of the center of mass to stabilize itself. Second, by providing more freedom to bend the spine, the robot can pull the rear legs forward, thus increasing the stride length. Finally, locomotion with this model exhibits two flight phases and greater flight proportion during each stride, similar to what it is observed from running cheetahs, which make significant difference in the speed and the gait.	control theory;galaxy morphological classification;lightweight java;mathematical morphology;microsoft outlook for mac;poor posture;propel;robot locomotion;spinal cord stimulator	Qian Zhao;Hidenobu Sumioka;Xiaoxiang Yu;Kohei Nakajima;Zhimin Wang;Rolf Pfeifer	2012	2012 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2012.6490945	simulation;gait;computer science;engineering;robot locomotion	Robotics	68.27101417062849	-24.466204184362102	140116
44bf49070f6775f792f8eef3738f21d731fdcb06	building a warehouse control system using ride		There is a growing interest in the use of Autonomous Guided Vehicles (AGVs) in the Warehouse Control Systems (WCS) in order to avoid installing fixed structures that complicate and reduce the flexibility to future changes. In this paper a highly flexible and hybrid operated WCS, developed using the Robotics Integrated Development Environment (RIDE), is presented. The prototype is a forklift with cognitive capabilities that can be operated manually or autonomously and it is now being tested in a warehouse located in the Parque Tecnologico Logistico (PTL) of Vigo. The main advantages and drawbacks on this kind of implementation are also discussed in the paper.	control system	Joaquín López;Diego Pérez;Iago Vaamonde;Enrique Paz;Alba Vaamonde;Jorge Cabaleiro	2015		10.1007/978-3-319-27149-1_59	computer engineering;simulation;computer science;warehouse;development environment;artificial intelligence;installation;robotics;control system	Robotics	61.194751504533805	-28.768878724508063	140406
a6734c4d53098c056e4518fe8cee1f89b7ba47a1	fault feature extraction of hydro-generator vibration signals based on wavelets shrinkage	feature extraction		feature extraction;wavelet	T. Sun;T. S. Huang;M. Li;F. X. Sun;J. D. Xiang	2003			wavelet;feature extraction;shrinkage;electronic engineering;mathematics;vibration	EDA	67.60341392275917	-35.46691542635234	140493
7e367a00a9674221724eab096fc4e068528078d0	building a winning self-driving car in six months		The SAE AutoDrive Challenge is a three-year competition to develop a Level 4 autonomous vehicle by 2020. The first set of challenges were held in April of 2018 in Yuma, Arizona. Our team (aUToronto/Zeus) placed first. In this paper, we describe our complete system architecture and specialized algorithms that enabled us to win. We show that it is possible to develop a vehicle with basic autonomy features in just six months relying on simple, robust algorithms. We do not make use of a prior map. Instead, we have developed a multisensor visual localization solution. All of our algorithms run in real-time using CPUs only. We also highlight the closed-loop performance of our system in detail in several experiments.	algorithm;autonomous car;autonomous robot;central processing unit;deep learning;encode;experiment;field-programmable gate array;global positioning system;modal logic;real-time clock;selective area epitaxy;simultaneous localization and mapping;systems architecture;uav outback challenge	Keenan Burnett;Andreas Schimpe;S Abdolvahab Samavi;Mona Gridseth;Chengzhi Winston Liu;Qiyang Li;Zachary Kroeze;Angela P. Schoellig	2018	CoRR			Robotics	55.72927648254746	-29.182632644994836	140606
98406f4e78fe5ebf863c40ed727380541e99c87a	audio-based relative positioning system for multiple micro air vehicle systems	aerial robotics	Employing a group of independently controlled flying micro air vehicles (MAVs) for aerial coverage missions, instead of a single flying robot, increases the robustness and efficiency of the missions. Designing a group of MAVs requires addressing new challenges, such as inter-robot collision avoidance and formation control, where individual’s knowledge about the relative location of their local group members is essential. A relative positioning system for a MAV needs to satisfy severe constraints in terms of size, weight, processing power, power consumption, three-dimensional coverage and price. In this paper we present an on-board audio based system that is capable of providing individuals with relative positioning information of their neighbouring sound emitting MAVs. We propose a method based on coherence testing among signals of a small onboard microphone array to obtain relative bearing measurements, and a particle filter estimator to fuse these measurements with information about the motion of robots throughout time to obtain the desired relative location estimates. A method based on fractional Fourier transform (FrFT) is used to identify and extract sounds of simultaneous chirping robots in the neighbourhood. Furthermore, we evaluate our proposed method in a real world experiment with three simultaneously flying micro air vehicles.	aerial photography;consensus dynamics;fractional fourier transform;global positioning system;microphone;on-board data handling;particle filter;piezoelectricity;robot;sensor;telecommunications network;television antenna;transducer;unmanned aerial vehicle	Meysam Basiri;Felix Schill;Dario Floreano;Pedro U. Lima	2013		10.15607/RSS.2013.IX.002	embedded system;simulation;computer science	Robotics	55.770217795344294	-33.75567278681958	140832
119ea63048408e86a51e83fed9050bba109c2094	dynamic modeling and its robotic applications ( the robot phi system)	elasticity;viscosity;path planning;dynamic modeling;dynamic model;dextrous hand;deformable models;motion;collision detection;deformation;programming profession;grasped object;solid modeling;robots;robotic applications;all terrain vehicle;hierarchical object representation;energy based adaptative time step approach dynamic modeling robotic applications robot spl phi system complex contact interactions dextrous hand grasped object all terrain vehicle motion deformation physical behaviour hierarchical object representation collision detection;energy based adaptative time step approach;robotφ system;vehicles;path planning robot dynamics robot programming;robot dynamics;physical behaviour;robotics and automation;vehicle dynamics;complex contact interactions;object detection;physical properties;robot programming;robots solid modeling robotics and automation vehicle dynamics vehicles deformable models elasticity viscosity object detection programming profession	Complex contact interactions between the robot and its environment (contact between a dextrous hand and a grasped object, contact between an all-terrain vehicle and the terrain, ..) depend on physical properties such as mass, mass distribution, rigidity/elasticity factors, viscosity, and collision forces. Classical geometrical models (representing the spatial properties of an object) are obviously not helpful to study such interactions. So we need another model which represents not only the fo rm of the object but also its motion, its deformation and, its interaction with the environment. Such a model is called the “dynamic model”. This paper describes the Robot@ system, which enables do physically represent robots and to study their physical behaviour. This system uses a hierarchical representation of objects in order to accelerate collision detection (linear time for rigid objects). A n energy based adaptative time step approach was developed in order to detect and avoid numerical divergence and to reduce computational time. The success of a robotic task, depends on the capability of the used model to represent the studied phenomenon. For instance, a geometrical model enables us to detect collisions but it is incapable of giving the collision force and its effect on the colliding objects (motion, deformation, ..). So geometrical models are not helpful when a tele-programming robot task needs to study a complex contact interactions. This is the case, for instance, when manipulating a rigid or a deformable object using a dextrous hand [l], or when moving an all-terrain vehicle on a hilly terrain 131. These interactions depend on physical properties such as mass, mass distribution, rigidity/elasticity factors, viscosity, collision forces. Taking into account such properties remains an important overhead to be considered by the programmer himself. Yet this work is not a part of the initial problem (planning, obstacle avoiding, ..). This forces the programmer to work in a restricted condition (point contact, polyhedral object, ..). In order to deal with the problem, we developed a dynamic modeling system named Robot@. The purpose of this paper is to describe the Robot@ system, and the underlying models and algorithms which have been developed for programming the above-mentioned robotic tasks.	algorithm;collision detection;computation;elasticity (data store);fo (complexity);interaction;mathematical model;numerical analysis;overhead (computing);polyhedron;programmer;robot;television;time complexity	Ammar Joukhadar;Christian Laugier	1995		10.1109/ROBOT.1995.525662	robot;control engineering;computer vision;vehicle dynamics;simulation;viscosity;computer science;engineering;artificial intelligence;motion;motion planning;system dynamics;solid modeling;elasticity;collision detection;deformation;physical property;quantum mechanics	Robotics	66.69554960469853	-25.68118468524374	140856
6d72c998eb6668b8ac92fa88f2fc7396d326c6d8	improving planetary rover attitude estimation via mems sensor characterization	micro electrical mechanical systems;transducers;equipment failure analysis;robotics;inertial measurement unit imu;equipment design;micro electro mechanical systems mems;geographic information systems;planets;algorithms;attitude estimation;sensor fusion;sensor characterization;planetary rover;inertial navigation system ins	Micro Electro-Mechanical Systems (MEMS) are currently being considered in the space sector due to its suitable level of performance for spacecrafts in terms of mechanical robustness with low power consumption, small mass and size, and significant advantage in system design and accommodation. However, there is still a lack of understanding regarding the performance and testing of these new sensors, especially in planetary robotics. This paper presents what is missing in the field: a complete methodology regarding the characterization and modeling of MEMS sensors with direct application. A reproducible and complete approach including all the intermediate steps, tools and laboratory equipment is described. The process of sensor error characterization and modeling through to the final integration in the sensor fusion scheme is explained with detail. Although the concept of fusion is relatively easy to comprehend, carefully characterizing and filtering sensor information is not an easy task and is essential for good performance. The strength of the approach has been verified with representative tests of novel high-grade MEMS inertia sensors and exemplary planetary rover platforms with promising results.	medication event monitoring system;microelectromechanical systems;planetary scanner;robotics;rover (the prisoner);spacecraft;systems design;visual accommodation;sensor (device)	Javier Hidalgo;Pantelis Poulakis;Johan Köhler;Jaime del Cerro;Antonio Barrientos	2012		10.3390/s120202219	planet;control engineering;embedded system;electronic engineering;simulation;transducer;computer science;engineering;sensor fusion;robotics;physics	Robotics	56.3726013955428	-33.27149815161874	140898
64d1e44cee060905ff5f1f8ca2631b816fa0a1dd	comparative analysis of collision-free path-planning methods for multi-manipulator systems	manipulators;comparative analysis;path planning;dynamic environments;reactive;collision free	Motion planning for manipulators with many degrees of freedom is a complex task. The research in this area has been mostly restricted to static environments. This paper presents a comparative analysis of three reactive on-line path-planning methods for manipulators: the elastic-strip, strategy-based and potential field methods. Both the elastic-strip method [O. Brock and O. Khatib, “Elastic strips: A framework for integrated planning and execution,” Int. Symp. Exp. Robot. 245–254 (1999)] and the potential field method [O. Khatib, “Real-time obstacle avoidance for manipulators and mobile robots,” Int. J. Robot. Res. 5(1), 90–98 (1986)] have been adapted by the authors to the problem at hand related to our multi-manipulator system (MMS) (three manipulators with five degrees of freedom each). Strategy-based method is an original contribution by the authors [M. Mediavilla, J. L. Gonzalez, J. C. Fraile and J. R. Peran, “Reactive approach to on-line path planning for robot manipulators in dynamic environments,” Robotica 20, 375–384 (2002); M. Mediavilla, J. C. Fraile, T. Gonzalez and I. J. Galindo, “Selection of strategies for collision-free motion in multi-manipulator systems,” J. Intell. Robot Syst 38, 85–104 (2003)].The three methods facilitate on-line path planning for our MMS in dynamic environments with collision avoidance, where the three manipulators may move at the same time in their common workspace. We have defined some ‘basic motion problems’ for the MMS, and a series of simulations has been running that will tell us how effective each path-planning method is. The simulations have been performed and the obtained results have been analysed by using a software program developed by the authors.The paper also presents experimental results obtained applying the path-planning methods to our MMS, that perform pick-and-place tasks sharing common working areas.	motion planning	Juan Carlos Fraile Marinero;Javier Pérez Turiel;José Luis González;Enrique Baeyens;R. Perez	2006	Robotica	10.1017/S0263574706002888	control engineering;qualitative comparative analysis;simulation;computer science;engineering;artificial intelligence;motion planning	Logic	63.255466452768545	-26.23332176733348	141405
b21a89d75fec4da3deec0a5b96ac77bfdd884f86	a new procedure for multi-mode sequential flocking with application to multiple non-holonomic mobile robot motion control: implementation and analysis	simulations of multiple mobile robot system;simulation system;flocking control;multi robot	This is the second of a two-part paper that investigates the multi-mode sequential flocking with application to multiple non-holonomic mobile robot motion control. In this part, a multiple mobile robotsimulation system based on MuRoS is used to simulate the real multiple mobile robots running environment. Furthermore, an analysis method of the flocking system based on ‘minimum stable time’ is proposed, which can be employed to analyse the performance of multi-mode sequential flocking of mobile robots team. At last, bench tests have been comprehensively conducted to demonstrate the efficacy of the proposed procedures on efficient collision and obstacle avoidance in flocking motion, which were described in the first part.	mobile robot	Lei Cheng;Xiujuan Zheng;Huaiyu Wu;Quanmin Zhu;Yongji Wang;Hassan Nouri	2012	IJMIC	10.1504/IJMIC.2012.046695	control engineering;mobile robot;simulation;engineering;control theory;robot control	Robotics	58.93894694155213	-24.83330817217407	141407
33f13a0b91adde38e8d5bbf0ebe3a3db23921ded	multi-robot localization and mapping based on signed distance functions	robot kinematics simultaneous localization and mapping buildings computer architecture;mobile robotics;slam;software architecture control engineering computing data integration mobile robots multi robot systems optical radar pose estimation radar imaging slam robots;computer architecture;drift reduced pose estimation multirobot localization multirobot mapping signed distance functions 2d simultaneous localization and mapping approach multiple mobile robots 2d lidar sensors dynamic representation multithreaded software architecture data integration;rescue robotics mobile robotics slam multi robot;simultaneous localization and mapping;rescue robotics;buildings;multi robot;robot kinematics	This publication describes a 2D Simultaneous Localization and Mapping approach applicable to multiple mobile robots. The presented strategy uses data of 2D LIDAR sensors to build a dynamic representation based on Signed Distance Functions. A multi-threaded software architecture performs registration and data integration in parallel allowing for drift-reduced pose estimation of multiple robots. Experiments are provided demonstrating the application with single and multiple robot mapping using simulated data, public accessible recorded data as well as two actual robots operating in a comparably large area.	experiment;ground truth;internationalization and localization;map;mobile robot;open-source software;robotic mapping;sensor;simultaneous localization and mapping;software architecture;software deployment;tsd;thread (computing)	Philipp Koch;Stefan May;Michael Schmidpeter;Markus Kühn;Christian Pfitzner;Christian Merkl;Rainer Koch;Martin Fees;Jon Martin;Andreas Nüchter	2015	2015 IEEE International Conference on Autonomous Robot Systems and Competitions	10.1109/ICARSC.2015.18	mobile robot;embedded system;computer vision;simulation;engineering;occupancy grid mapping	Robotics	54.49440098214753	-35.81558642913277	141724
7087ebc159ed6ad7154b363dab28d476698d3966	real-time dynamic trajectory planning for highly automated driving in highways	vehicle control;trajectory planning;path planning;real time;europe acceleration;simulation;automated highways;haveit;polynomials;acceleration;dynamic environment;partial motion planning approach;5 th degree polynomials;haveit european project;highly automated driving;copilot;motion planning;trajectory spatio temporal description real time dynamic trajectory planning highly automated driving highway scenario haveit european project partial motion planning approach 5 th degree polynomials;algorithms;real time dynamic trajectory planning;vehicle control motion planning in dynamic environments copilot haveit highly automated driving;experimental research;polynomials automated highways path planning;highway scenario;europe;simulation environment;vehicle trajectories;driver support systems;motion planning in dynamic environments;trajectory spatio temporal description	This paper presents the implementation of two methods for real-time trajectory planning in a dynamic environment applied to highly automated driving in a highway scenario. Both methods have been implemented for the HAVEit European project. The first method follows the Partial Motion Planning approach, and the second method uses 5th degree (quintic) polynomials to generate a detailed spatio-temporal description of a trajectory to be performed. Both implementations are integrated in a simulation environment and in an experimental research vehicle within HAVEit. Results and evaluations of the trajectory planning algorithms are presented.	algorithm;automated planning and scheduling;autonomous car;computation;experiment;motion planning;polynomial;quintic function;real-time clock;real-time transcription;robotics;simulation	Paulo Resende;Fawzi Nashashibi	2010	13th International IEEE Conference on Intelligent Transportation Systems	10.1109/ITSC.2010.5625194	control engineering;computer vision;simulation;computer science	Robotics	55.23679105489986	-26.863509094031112	141770
0e3b7d39af484eb8242f57ef29ffc76befff7b92	real-time robot-human interaction by tracking hand movement & orientation based on morphology	mathematical morphology;manipulators;human interaction;image segmentation;real time tracking;edge detection;nonlinear control systems;real time;human robot interaction;robot manipulator;3d space real time robot human interaction hand movement tracking robotic spherical wrist image processing technique mathematical morphological filter formulae hand position tracking hand orientation tracking nonlinear systems robotic manipulator computer simulation human computer remote handling interaction hand rotation;robot vision;position control;image edge detection;feature extraction;object tracking;image processing techniques;humans;remote handled;nonlinear system;robot vision human robot interaction manipulators mathematical morphology nonlinear control systems object tracking position control;computer simulation;manipulators image edge detection humans image segmentation real time systems feature extraction;real time systems	In this paper we present a method that allows real time tracking on a hand in 3D space and notes its orientation and position accordingly, with the goal of ultimately tying it to a robotic spherical wrist as well as the wrist's 3D position. Several image processing techniques were used in conjunction with mathematical morphological filters formulae in order to understand the hand's position and orientation. The proposed methods have showed great success in identifying the Nonlinear systems, variable 3D levels of hand movements and rotations correctly, which could be applied in different types of robotic manipulators, computer simulations or a number of human-computer remote handling interactions. Real time took place in system response.	computer simulation;image processing;interaction;mathematical morphology;morphing;nonlinear system;real-time transcription;robot;telerobotics;television	Abadalsalam T. Hussain;Zamzamir Said;Nizam Uddin Ahamed;Kenneth Sundaraj;Desa Hazry	2011	2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA)	10.1109/ICSIPA.2011.6144117	computer simulation;computer vision;interpersonal relationship;simulation;mathematical morphology;edge detection;nonlinear system;feature extraction;computer science;video tracking;image segmentation	Robotics	61.78216578108432	-31.901791960292957	141906
1cfb0f94f6bfefee2e419682996a553777724cd3	mobile robot localization using odometry and kinect sensor	robot localization;robot sensing systems;sensor system;mobile robot;odometry;kalman filters;mobile robots;slam robots distance measurement kalman filters mobile robots object detection particle filtering numerical methods pose estimation robot vision sensor fusion;kinect sensor extended kalman filter particle filter robot localization odometry;visual landmarks;distance measurement;robot vision;estimation;particle filter;robot sensing systems mobile robots estimation wheels noise cameras;indoor environment;mobile robot localization;sensor fusion;extended kalman filter;slam robots;cameras;object detection;particle filtering numerical methods;noise;kinect sensor;wheels;pose estimation;robot odometry kinect sensor mobile robot localization system indoor environment extended kalman filter particle filter sensor fusion pose estimation visual landmarks ekf pf	This paper presents a mobile robot localization system for an indoor environment using an inexpensive sensor system. The extended Kalman filter (EKF) and the particle filter (PF) is used for sensor fusion in pose estimation in order to minimize uncertainty in robot localization. The robot is maneuvered in a known environment with some visual landmarks. The prediction phase of the EKF and the PF are implemented using the information from the robot odometry whose error may accumulate over time. The update phase uses the Kinect measurements of the landmarks to correct the robot's pose. Experiment results show that, despite its low cost, the accuracy of the localization is comparable with most state-of-the-art odometry based methods.	extended kalman filter;internationalization and localization;kinect;mobile robot;odometry;particle filter;robotic mapping	Nuwan Ganganath;Henry Leung	2012	2012 IEEE International Conference on Emerging Signal Processing Applications	10.1109/ESPA.2012.6152453	computer vision;simulation;visual odometry;odometry;control theory	Robotics	55.258651660646876	-36.67427828233305	141911
7bb3db0c6419c214e598d53d0a2f8300f16ff77f	path planning to improve reachability in a forced landing	path planning;forced landing;gliding;reachability analysis;aircraft	This paper proposes a novel path planning method for improving the feasibility of a forced landing. When an aircraft completely loses its thrust, the only measure it can take is to make a forced landing at an adjacent airport as soon as possible. In such a situation, the flight path to the landing point must be safe and viable. This paper details a method which enables safer and easier landing by transferring the benefits of excess altitude to the final approach length. Moreover, by planning the descent angle of final approach to be in the middle of a non-spoiler and a full-spoiler glide angle, this method enables a change in descent angle to correct any tracking errors, without using thrust. To verify the effectiveness of the proposed method, six degrees-of-freedom nonlinear simulations were performed and the results are compared with comparable methods. From the simulation results, it was confirmed that the proposed method could plan a safe path in a sufficiently short time and the aircraft could reach the landing point safely. Shusuke Izuta ( ) Center for Space and Environment Design Engineering School of Science for Open and Environmental Systems, Keio University, Minato-ku, Japan e-mail: one-world.b8@z5.keio.jp Masaki Takahashi Department of System Design Engineering, Keio University, Minato-ku, Japan e-mail: takahashi@sd.keio.ac.jp	bézier curve;cobham's thesis;descent;email;environment (systems);glide os;ku band;motion planning;nonlinear system;offset binary;quadratic formula;reachability;simulation;six degrees of separation;thrust;tomotaka takahashi	Shusuke Izuta;Masaki Takahashi	2017	Journal of Intelligent and Robotic Systems	10.1007/s10846-016-0431-3	simulation;computer science;engineering;artificial intelligence;control theory;motion planning;gliding flight;precision approach radar	Robotics	56.79748276475457	-28.366287380699536	142128
eb1aa17691bb7c413acefa07c34f1bae0d023bf1	a study toward cognitive action with environment recognition by a learning space robot	sensor system;cognitive systems;learning systems cognitive systems aerospace robotics manipulator kinematics manipulator dynamics image sensors space vehicles;reinforcement learning;manipulator dynamics;image sensors;manipulator kinematics;learning systems;cognitive robotics orbital robotics robot sensing systems robotics and automation robotic assembly manipulators force control computational modeling robot vision systems computer vision;frame problem;space robotics;aerospace robotics;collision avoidance;autonomous construction cognitive action environment recognition learning space robot free flying space robot frictionless table system computer system vision sensor system manipulators two dimensional planar table air bearings reinforcement learning kinematic problem complicated dynamic problem on line learning;system simulation;space vehicles;on line learning;force control	This paper addresses an experimental system simulating a free-flying space robot, which has been constructed to study autonomous space robots. The experimental system consists of a space robot model, a frictionless table system, a computer system, and a vision sensor system. The robot model is composed of two manipulators and a satellite vehicle, and can move freely on a two-dimensional planar table, without friction, using air-bearings. The robot model has successfully performed the automatic truss structure assembly, including many jobs, e.g., manipulator berthing, component manipulation, arm trajectory control collision avoidance, assembly using force control, etc. Moreover, even if the robot fails in a task planned in advance, the robot re-plans the task by using reinforcement learning, and obtains the task goal for basically kinematic problems. But, for a class of complicated dynamic problems, the computational periods and efforts are infeasible for on-line learning. Some approaches are proposed to accelerate the learning speed, which also give models of cognitive actions and approaches to so-called a frame problem. The experiment demonstrates the possibility of the autonomous construction and the usefulness of space robots.	robot	Kei Senda;Tsutomu Matsumoto;Yuzo Okano	2003		10.1109/ROBOT.2003.1241691	control engineering;mobile robot;robot learning;computer vision;cartesian coordinate robot;simulation;articulated robot;frame problem;computer science;engineering;artificial intelligence;social robot;arm solution;image sensor;robot control;reinforcement learning;personal robot;robot kinematics;robot calibration	Robotics	63.45361241318057	-26.242118171302412	142239
f0b239f4f37d157cc9140e8717902fa246c2ea9f	reactive and tracking control of a mobile robot in a distributed environment using fuzzy logic	robot sensing systems;mobile robot;fuzzy control;mobile robots;integration;reactive control;fuzzy logic;robot sensing systems fuzzy logic mobile robots servomotors collision avoidance;distributed environment;integration method;distributed parameter systems;tracking control;servomotors;collision avoidance;integration method tracking control reactive control mobile robot distributed environment fuzzy logic;tracking distributed control distributed parameter systems fuzzy control integration mobile robots;distributed control;tracking	This paper describes reactive and tracking control of a mobile robot using integration methods to combine the response of both types of controls based on fuzzy logic. Simulation and experimental results of the complete system demonstrates the effectiveness of the proposed approach.	fuzzy logic;mobile robot;simulation	Abraham Melendez;Oscar Castillo;Arnulfo Alanis Garza;José Soria	2010	International Conference on Fuzzy Systems	10.1109/FUZZY.2010.5583955	mobile robot;real-time computing;computer science;artificial intelligence;control theory;fuzzy control system	Robotics	59.50988854548989	-27.529728118376614	142244
45d5e2d1e24136dac9660b2be962b11cbac893c7	neural network and striped lighting pattern-based autograsping technology for flexible robotic assembly	neural network		artificial neural network;robot	Collin Wang;Edmund Chang	1997	J. Field Robotics	10.1002/(SICI)1097-4563(199707)14:7%3C559::AID-ROB4%3E3.0.CO;2-M		Robotics	63.98193402624021	-35.281886998922495	142513
36ff90b2d86061618522f70367e14f77593e5e78	genetic algorithm aided antenna placement in 3d and parameter determination considering electromagnetic field pollution constraints	transmitter;electromagnetic radiation;genetic algorithms;optimization	This paper presents genetic algorithm based method for antenna placement in 3D space and parameter determination satisfying environmental electromagnetic field pollution constraints. The main goal is to find out antenna parameters (power, position in 3D, azimuth and elevation) in the area of interest so that electromagnetic field satisfies minimal electromagnetic field strength for service availability and, at the same time, be below prescribed limit in restricted subareas (people populated areas). The proposed method is validated with two real world antenna types and with seven different terrain configurations (various restricted areas). Besides finding the most optimal antenna parameters, the method finds “almost” optimal solutions which give certain freedom to choose alternative antenna position if optimal is not available. The investigation described here is extension of previous 2D research.	genetic algorithm;population;requirement	Tomislav Rolich;Darko Grundler	2012	CIT		electromagnetic radiation;mathematical optimization;transmitter;simulation;genetic algorithm;computer science	HCI	54.608514299478	-26.59115099788794	142723
55a3c14180b1fe91569c9629091d76323d0c6ec2	algorithmic design of low-power variable-stiffness mechanisms	optimization;actuators;robot kinematics;mathematical model	Compliant actuators enabling low-power stiffness adaptation are missing ingredients and key enablers of next generation robotic systems. One of the key components of these actuators is the mechanism implementing stiffness adaptation that requires sophisticated control and nontrivial mechanical design. However, despite recent advances in controlling these systems, their design remains experience based and not well understood. In this paper, we present an optimization-based computational framework for the design of intrinsically low-power compliant variable stiffness mechanisms. The core ingredient of this framework is the mathematical formulation of the design problem—provided by a constrained nonlinear parameter optimization—which is computationally solved here to identify optimal variable stiffness designs. We show the basic capability of this formulation in finding parameters for variable stiffness mechanisms that require the least power by design. Further, we demonstrate the generality of this method in cross-comparing mechanisms with different kinematic topology to identify the one that requires the least power by design.	computation;low-power broadcasting;mathematical optimization;next-generation network;nonlinear system;robot;stiffness matrix	Vincent Chalvet;David J. Braun	2017	IEEE Transactions on Robotics	10.1109/TRO.2017.2719049	control engineering;actuator;nonlinear system;algorithm design;ingredient;control theory;generality;mathematics;stiffness;kinematics;robot kinematics	Robotics	66.12673265399769	-25.419298302165082	142759
113fde25c2c5364ba16f133cf984e2951baa4faa	models for the design of bioinspired robot eyes	experimental tests;modelizacion;bioinspired robot eyes;robot humanoide;humanoid robot;evaluation performance;vision ordenador;ocular motion strategy;eye;performance evaluation;eyes solid modeling humanoid robots humans performance evaluation visual perception computational geometry guidelines discrete event simulation testing;evaluacion prestacion;tendon driven robots;computational geometry;hombre;visual perception active vision eye humanoid robots robot vision;testing;robotics;anatomia;computer vision;modelisation;eyes;robot vision;humanoid robots;percepcion visual;guidelines;smooth pursuit;biomimetique;solid modeling;human;listing s law bioinspired robot eyes active vision visual perception ocular motion strategy humanoid robot eyes ocular movements;humanoid robot eyes;perception visuelle;robotica;visual perception;vision ordinateur;humans;saccadic eye movement;robotique;vision active;ocular movements;mouvement oculaire saccade;tendon driven robots humanoid robot eyes listing s law ocular movements robot vision systems;anatomie;modeling;anatomy;robot vision systems;listing s law;quantitative evaluation;tendon;movimiento ocular brusco;homme;biomimetics;active vision;discrete event simulation	Active vision has the goal of improving visual perception; therefore, the investigation of ocular motion strategies must play an important role in the design of humanoid robot eyes. Listing's law is a basic principle, which characterizes various ocular movements in humans, including saccades and smooth pursuit, and its neural or mechanical origin has been debated for a long time. Recent anatomical advances suggest that motions compatible with Listing's law could be mainly caused by the mechanical structure of the eye plant. In this paper, we present a bioinspired model of the eye plant, and we formally prove that according to the model, the implementation of Listing's law can be actually explained on the base of the geometry of the eye and of its actuation system. The proposed model is characterized by a limited number of geometric parameters, which can be easily used to set the guidelines for the design of humanoid, and possibly tendon-driven, robot eyes. Simulative and experimental tests performed on a robot prototype are eventually presented to perform a quantitative evaluation of the performance of the model, also in comparison with physiological data measured in humans and primates and reported in the literature.	active vision;humanoid robot;prototype	Giorgio Cannata;Marco Maggiali	2008	IEEE Transactions on Robotics	10.1109/TRO.2007.906270	computer vision;simulation;computational geometry;computer science;engineering;humanoid robot;artificial intelligence;robotics	Robotics	64.06729890181386	-32.11836105481313	142807
8db332de4d152b01a990325e726ab39ef7dcfa47	a vision-based quadrotor multi-robot solution for the indoor autonomy challenge of the 2013 international micro air vehicle competition	robotica e informatica industrial	This paper presents a completely autonomous solution to participate in the Indoor Challenge of the 2013 International Micro Air Vehicle Competition (IMAV 2013). Our proposal is a multi-robot system with no centralized coordination whose robotic agents share their position estimates. The capability of each agent to navigate avoiding collisions is a consequence of the resulting emergent behavior. Each agent consists of a ground station running an instance of the proposed architecture that communicates over WiFi with an AR Drone 2.0 quadrotor. Visual markers are employed to sense and map obstacles and to improve the pose estimation based on Inertial Measurement Unit (IMU) and ground optical flow data. Based on our architecture, each robotic agent can navigate avoiding obstacles and other members of the multi-robot system. The solution is demonstrated and the achieved navigation J. Pestana ( ) · J. L. Sanchez-Lopez · P. de la Puente · A. Carrio · P. Campoy Computer Vision Group, Centre for Automation and Robotics, CSIC-UPM, Calle Jose Gutierrez Abascal, 2, 28006 Madrid, Spain e-mail: jesus.pestana@upm.es; jespestana@gmail.com URL: www.vision4uav.eu/ J. L. Sanchez-Lopez e-mail: jl.sanchez@upm.es P. Campoy e-mail: pascual.campoy@upm.es performance is evaluated by means of experimental flights. This work also analyzes the capabilities of the presented solution in simulated flights of the IMAV 2013 Indoor Challenge. The performance of the CVG UPM team was awarded with the First Prize in the Indoor Autonomy Challenge of the IMAV 2013	3d reconstruction;algorithm;ar (unix);automation;autonomous robot;centralized computing;computation;computer vision;continuation;email;emergence;extended kalman filter;internationalization and localization;linear algebra;middleware;on-board data handling;open-source software;optical flow;robot operating system;robotics;simulation;simultaneous localization and mapping;software deployment;unmanned aerial vehicle	Jesús Pestana;José Luis Sánchez-López;Paloma de la Puente;Adrian Carrio;Pascual Campoy Cervera	2016	Journal of Intelligent and Robotic Systems	10.1007/s10846-015-0304-1	simulation;computer science;engineering;artificial intelligence;transport engineering	Robotics	56.03808900808601	-29.05554125944767	142857
1d2fb91e0fd5c75a8ad4ebdfa38aeadaaed4657c	kinematical analysis of synthetic dynamic signatures using the sigma-lognormal model	databases;artificial signatures;analytical models;human movement;kinematical information;kinematics databases trajectory computational modeling signal to noise ratio analytical models biological system modeling;kinematic analysis;synthetic generation;rapid human movements;synthetic generation method;synthetic dynamic signatures;biological system modeling;digital signatures;kinematics;information presentation;computational modeling;trajectory;general methods;humanly produced signatures;signature;sigma lognormal model;signal to noise ratio;sigma lognormal model signature synthetic generation kinematical information;velocity profile;kinematical analysis;rapid human movements kinematical analysis synthetic dynamic signatures sigma lognormal model humanly produced signatures artificial signatures velocity profile synthetic generation method	The kinematical information present in synthetically generated signatures is analyzed using the Sigma-Lognormal model and compared to the kinematical properties of real samples. Experiments are carried out on totally independent development and test sets and show a high degree of similarity between humanly produced and artificial signatures. One particular flaw is found in the velocity profile of synthetic signatures. Two possible solutions are proposed to improve the synthetic generation method using the Kinematic Theory of rapid human movements.	antivirus software;electronic signature;experiment;flaw hypothesis methodology;floating-point unit;online and offline;serial digital video out;synthetic intelligence;type signature;velocity (software development);vii	Javier Galbally;Julian Fiérrez;Marcos Martinez-Diaz;Javier Ortega-Garcia;Réjean Plamondon;Christian O'Reilly	2010	2010 12th International Conference on Frontiers in Handwriting Recognition	10.1109/ICFHR.2010.24	kinematics;digital signature;simulation;speech recognition;computer science;trajectory;machine learning;signature;signal-to-noise ratio;computational model	Robotics	66.90259400477412	-32.25742931479426	143101
c1a2646865cfbc0b828f60ee8b94be5229ca9f54	low cost imu–odometer–gps ego localization for unusual maneuvers	localization;dynamic model;kalman filter;intelligent vehicles;multiple sensor fusion;sensor fusion;extended kalman filter;high speed;interacting multiple model	This paper presents the problem of outdoor vehicle localization during unusual maneuvers with the Interacting Multiple Model (IMM) and Extended Kalman Filter (EKF) approaches. IMM, contrary to classical methods, is based on the discretization of the vehicle evolution space into simple maneuvers. Each maneuver is represented by a simple dynamic model such as a constant velocity or a constant turning model. This allows the method to be optimized for highly dynamic vehicles. In this work, we focus on unusual vehicle maneuvers during some special driving situations, including very strong accelerations, high speed turnings or backwards driving with stop stages. The presented results are based on real measurements collected from different scenarios. Based on an EKF vs. IMM comparison, these results show a real interest of using the IMM method in order to take into account unusual maneuvers.		Alexandre Ndjeng Ndjeng;Dominique Gruyer;Sebastien Glaser;Alain Lambert	2011	Information Fusion	10.1016/j.inffus.2010.06.006	kalman filter;simulation;internationalization and localization;computer science;machine learning;control theory;sensor fusion;extended kalman filter	Robotics	56.19018026517839	-35.62569082838031	143697
13f541614b29d44572cbda73f4e4b8ee8dc747f3	automated surface deformations detection and marking on automotive body panels	automotive engineering;3d image;robot sensing systems;3d imaging;integrable system;feature extraction robot sensing systems three dimensional displays tracking automotive engineering assembly;motion estimation;surface defects;quality control automobile industry deformation pose estimation;assembly;deformation;robotic marking station;surface deformation;three dimensional displays;feature extraction;automated surface deformations marking;passive vision;assembly line;industrial manufacturing;automotive body panels;quality control;automobile car door panel automated surface deformations detection automotive body panels automated surface deformations marking quality control industrial manufacturing 3d image surface defects robotic marking station pose estimation motion estimation assembly line passive vision;automobile car door panel;automobile industry;tracking;pose estimation;automated surface deformations detection	This paper proposes an integrated solution for automated surface deformations detection and marking on automotive body panels in the context of quality control in industrial manufacturing. Starting from a 3D image of the surface of the panel, deformations are extracted and classified automatically. The positions of the surface defects are provided to a robotic marking station that handles pose and motion estimation of the part on an assembly line using passive vision. The integrated system is validated with an experimental setup, using an automobile car door panel.	feature extraction;item unique identification;motion estimation;robot	Valentin Borsu;Arjun Yogeswaran;Pierre Payeur	2010	2010 IEEE International Conference on Automation Science and Engineering	10.1109/COASE.2010.5584643	computer vision;engineering;automotive engineering;engineering drawing	Robotics	60.89750468960801	-36.2934997769128	143750
1ad0c95dd008db6d3c713d6f8f87858d8ae1799b	an improved robot path planning model using cellular automata		Bio-inspired techniques have been successfully applied to the path-planning problem. Amongst those techniques, Cellular Automata (CA) have been seen a potential alternative due to its decentralized structure and low computational cost. In this work, an improved CA model is implemented and evaluated both in simulation and real environments using the e-puck robot. The objective was to construct a collision-free path plan from the robot initial position to the target position by applying the refined CA model and environment pre-processed images captured during its navigation. The simulations and real experiments show promising results on the model performance for a single robot.		Luiz G. A. Martins;Rafael da P. Cândido;Mauricio Cunha Escarpinati;Patrícia Amâncio Vargas;Gina Maira Barbosa de Oliveira	2018		10.1007/978-3-319-96728-8_16	cellular automaton;distributed computing;robot;motion planning;computer science	Robotics	54.69074019031524	-24.434413090423725	143814
3f7cfa5bd998669b357a93448191952ad391c0cd	dynamic area coverage for multi-uav using distributed ugvs: a two-stage density estimation approach		This paper focuses on increasing the duration of autonomous missions performed by Unmanned Aerial Vehicles (UAVs) by deploying a swarm of Unmanned Ground Vehicles (UGVs) as mobile refueling and maintenance stations. Conventionally UAVs are refueled with the fixed centralized Main Charging Stations (MCS). An algorithm is developed for efficiently distributing the swarm of UGVs to act as mobile refueling stations for UAVs. We have proposed a two-stage density estimation approach. In the first-stage, the optimal number of UGVs and its distribution were computed. In the second-stage, the UGVs coordinates with the nearest UAVs dynamically, while minimizing the average distance for refueling. The performance of the algorithm is compared with the static placement of control station for UAVs to coordinate. The numerical simulation shows a considerable advantage of distributed UGVs over the static placement of control stations.	aerial photography;algorithm;autonomous robot;centralized computing;estimation theory;numerical weather prediction;simulation;swarm;unmanned aerial vehicle	Senthilnath Jayavelu;Harikumar Kandath;Suresh Sundaram	2018	2018 Second IEEE International Conference on Robotic Computing (IRC)	10.1109/IRC.2018.00033	swarm behaviour;computer simulation;density estimation;control engineering;computer science	Robotics	55.645768963392946	-26.639552177013226	144404
b42f6900bd1a335123c4c172cd63393dc670c114	high-level mobility controller for a remotely operated unmanned land vehicle	vehicle control;mobile robot;real time control;department of defense;hierarchical control;control system;design and implementation;industrial robots;real time control system;system architecture;manufacturing system;national institute of standards and technology	The U.S. Army Laboratory Command, as part of the Department of Defense Robotics Testbed Program, is developing a testbed for cooperative, real-time control of unmanned land vehicles. The program entails the development and integration of many elements which allow the vehicles to perform both autonomous and teleoperated functions. The National Institute of Standards and Technology (NIST) is supporting this program by developing the vehicle control system using the Real-time Control System (RCS) architecture. RCS is a hierarchical, sensorybased control system, initially developed for the control of industrial robots and automated manufacturing systems. NIST is developing the portions of RCS that control all vehicle mobility functions, coordinate the operations of the other subsystems on the vehicle, and communicate between the vehicle and the remote operator control station. This paper reviews the overall control system architecture, the design and implementation of the mobility and communication functions, and results from recent testing. This work is funded by the U.S. Army Laboratory Command. This paper was prepared by U.S. Government employees and is not subject to copyright. Equipment listings do not imply a recommendation by NIST.	automation;autonomous robot;control function (econometrics);industrial robot;inertial navigation system;real-time control system;real-time transcription;remote control;robotics;sensor;systems architecture;traverse;testbed;throughput;unmanned aerial vehicle	Sandor Szabo;Harry Scott;Karl N. Murphy;Steven A. Legowik;Roger Bostelman	1992	Journal of Intelligent and Robotic Systems	10.1007/BF00357131	control engineering;embedded system;industrial control system;simulation;real-time control system;computer science;engineering;control system;artificial intelligence;hierarchical control system	Robotics	56.746954349484206	-28.6050394776433	144479
d5ca927257ae32f2eade2632d06251de34b5d835	visual-inertial teach and repeat for aerial inspection		Industrial facilities often require periodic visual inspections of key installations. Examining these points of interest is time consuming, potentially hazardous or require special equipment to reach. Micro Air Vehicles (MAVs) are ideal platforms to automate this expensive and tedious task. In this work we present a novel system that enables a human operator to teach a visual inspection task to an autonomous aerial vehicle by simply demonstrating the task using a handheld device. To enable robust operation in confined, GPS-denied environments, the system employs the Google Tango visual-inertial mapping framework [1] as the only source of pose estimates. In a first step the operator records the desired inspection path and defines the inspection points. The mapping framework then computes a feature-based localization map, which is shared with the robot. After take-off, the robot estimates its pose based on this map and plans a smooth trajectory through the waypoints defined by the operator. Furthermore, the system is able to track the poses of other robots or the operator, localized in the same map, and follow them in real-time while keeping a safe distance.	aerial photography;autonomous robot;global positioning system;mobile device;point of interest;real-time clock;tango;visual inspection;waypoint	Marius Fehr;Thomas Schneider;Marcin Dymczyk;Jürgen Sturm;Roland Siegwart	2018	CoRR		control engineering;computer vision;engineering;robot;point of interest;visual inspection;operator (computer programming);inertial frame of reference;trajectory;mobile device;artificial intelligence	Robotics	54.93262370755002	-36.756650355449615	144555
362ded44b81facc4489845bde5ea7b7765362eba	learning based gaits evolution for an aibo dog	evolutionary computation;legged locomotion;reinforcement learning;steepest descent method;learning methods;legged locomotion evolutionary computation learning artificial intelligence;legged locomotion robots wireless sensor networks tactile sensors multidimensional systems learning systems machine learning robotics and automation orbital robotics evolutionary computation;reinforcement learning gaits evolution aibo dog legged robots hand tuning evolutionary algorithm;evolutionary algorithm;learning artificial intelligence;legged robot	Developing fast gaits for legged robots is a difficult task that requires optimizing parameters in a multidimensional space. In most previous works, it was done by hand-tuning the parameters related to walking, using evolutionary algorithm or reinforcement learning to optimize these parameters. As we know, the approach combining evolution and learning would have some special characters compared to any solo one. But few papers contributed on this direction. In this paper, we combined evolution and learning and produced a fast forward gait for an AIBO dog. On considering the whole time to train the robot, we took an analogy steepest descent method as the learning method. Although it's a rather simple learning method, the final results showed it improved the performance not only in the walking speed but also in the evolution efficiency.	aibo;evolution;evolutionary algorithm;fast forward;gradient descent;random search;reinforcement learning;robot;software release life cycle;software testing;structure of observed learning outcome	Jiaqi Zhang;Qijun Chen	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424653	robot learning;simulation;computer science;method of steepest descent;artificial intelligence;machine learning;evolutionary algorithm;evolutionary robotics;reinforcement learning;evolutionary computation	Robotics	61.526070194060395	-25.033853838414704	144847
463c168cc6bcdc9480f690ffdc1b8fd3fffe2681	monte carlo localization of underwater robot using internal and external information	underwater robot;robot localization;robot sensing systems;monte carlo localization;underwater vehicles inertial systems monte carlo methods particle filtering numerical methods path planning sensor fusion stochastic processes telerobotics;atmospheric measurements;underwater vehicles;particle measurements;path planning;localization;euler angle underwater robot localization mcl algorithm beacon;probabilistic approach;mcl algorithm;estimation;stochastic processes;robot kinematics robot sensing systems estimation particle measurements atmospheric measurements;particle filter;external sensor information fusion monte carlo localization underwater robot localization method particle filter thrusters inertial sensors electronic compass probabilistic approach stochastic approach trilateration principle motion fusion internal sensor information fusion;monte carlo algorithm;telerobotics;dead reckoning;inertial systems;sensor fusion;inertial sensor;monte carlo methods;beacon;particle filtering numerical methods;robot kinematics;euler angle	This paper proposes a method for localization of an underwater robot. The method uses Monte Carlo algorithm called the particle filter. It predicts the pose of the robot using the internal sensor information from thrusters, inertial sensors, and electronic compass. A correction procedure follows the prediction. The correction uses external sensor information, that is, the distance from landmarks whose locations are known a priori. The prediction and correction process use samples of robot pose in stochastic and probabilistic approach. Though the external information available from the sensors could include depth, angle and angle rates of yaw, pitch, and roll, the proposed method uses only the distance from some beacons. In contrast to the classical methods which usually use either trilateration principle or dead reckoning to calculate the pose, the proposed approach fuses motion and internal sensor information with the external sensor information. The simulation shows that localization is possible even if only one or two beacons are available for range measurement. The experiments which uses two beacons in a tank suggest that the proposed method can be effective where the number of beacons is limited due to geographical features of the robot work area.	acoustic cryptanalysis;dead reckoning;experiment;internationalization and localization;monte carlo algorithm;monte carlo localization;monte carlo method;particle filter;robot;sensor;simulation;velocity (software development);workspace;yaws	Nak Yong Ko;Tae Gyun Kim;Sung Woo Noh	2011	2011 IEEE Asia-Pacific Services Computing Conference	10.1109/APSCC.2011.37	beacon;telerobotics;dead reckoning;stochastic process;monte carlo localization;computer vision;estimation;euler angles;simulation;internationalization and localization;particle filter;computer science;motion planning;sensor fusion;robot kinematics;monte carlo algorithm;statistics;monte carlo method	Robotics	54.335707981159224	-34.21936349192232	145273
55a5bae1a1d77b37b6d1897cbc7f322b527292c0	estimation for grasp behavior of vehicle driver by using steering wheel sensor system	sensor systems;automobiles;wheels estimation sensor systems humans vehicles accidents;driver sensing;behavioural sciences computing;wheels automobiles behavioural sciences computing pressure sensors road safety steering systems;steering wheel grasp states grasp behavior estimation vehicle driver vehicle steering wheel sensor system biological information instrumentation driver state estimation pressure sensor points grasp pressure data distribution;steering wheel;estimation;steering wheel driver sensing safe assistance system;accidents;safe assistance system;humans;pressure sensors;vehicles;road safety;wheels;steering systems	A vehicle's steering wheel is a special interface because it needs to be grasped by the driver's hand while driving. This is very useful from the viewpoint of biological instrumentation. This may achieve steady instrumentation for biological information, and by using this information, an estimate of the driver's state can also be made. In past research, a steering wheel sensor system was proposed by the authors. It has 28 pressure sensor points, and several of its characteristics have been analyzed. In this paper, an estimation method of grasp behavior is proposed based on the distribution of grasp pressure data. Four kinds of steering wheel grasp states are defined. Finally, the estimation method and its results are evaluated experimentally.	biological system;experiment;instrumentation amplifier;newton's method;poor posture;sensor;steering wheel	Takashi Imamura;Yuto Takeuchi;Zhong Zhang;Tetsuo Miyake	2012	2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/ICSMC.2012.6377950	embedded system;estimation;pressure sensor;statistics	Robotics	58.108502321094136	-34.95562196933885	145427
483d8194a4f9d6079aad4b9d2da098a60728d937	robot position realization based on multi-sensor information fusion algorithm	ukf;velocity control;mobile robot;kalman filters;mobile robots;mobile robots robot kinematics robot sensing systems angular velocity wheels;position control;velocity control kalman filters mobile robots position control sensor fusion;unscented kalman filter robot position realization multi sensor information fusion algorithm mobile robots inertial measurement unit speedometer;information fusion;auto position;ukf mobile robot auto position information fusion;sensor fusion	The accurate auto-position is on the basis of many smart actions for mobile robots. The higher cost performance has much significance to the producing process of brainpower robots. This paper works on a differential wheels mobile robot platform. And it researches on the mobile robot's auto-position in a complementary manner of information fusion. The sensing equipments contain an Inertial Measurement Unit (IMU) and a speedometer. This preliminary fusion process deals with the robotic movement velocity and angular velocity on data plane. And then, the further fusion on estimation plane, takes advantages of Unscented Kalman Filter (UKF) to estimate the position and orientation of the robot. The system test proves that the position method referred in this paper is able to meet the application. In addition, the real-time and accuracy has obtained a satisfactory effect.	algorithm;angularjs;forwarding plane;kalman filter;mobile robot;real-time clock;smart pascal;system testing;velocity (software development);wheels	Kai Yuan;Heng Wang;Huaguang Zhang	2011	2011 Fourth International Symposium on Computational Intelligence and Design	10.1109/ISCID.2011.81	mobile robot;computer vision;computer science;artificial intelligence;control theory;robot control	Robotics	57.17940129252864	-35.28064154589118	145525
cfc9543e995e6fb6a3000f9fa7c9691a1beea23e	a contingent of autonomous marching robots: intricacies of system design and motion control	vision system;feedback mechanism;control algorithm;motion control;path planning;mobile robots;infra red;control system;radio frequency;robot vision;system design;multi robot systems;human computer interaction autonomous marching robots robots contingent system design motion control position sensing techniques control algorithms synchronised movement infrared sensing global vision system coloured hat real world position real world orientation transition based supervisory control remote controlled robots complex multi agent collaborative system robot path planning automated guided vehicle systems;telerobotics;automatic guided vehicles;infrared;automatic guided vehicles mobile robots multi robot systems motion control path planning robot vision telerobotics;motion control robot sensing systems control systems service robots frequency synchronization robot vision systems machine vision cameras us department of transportation feedback;state transition	"""This paper details the intricacies of system design and the challenges faced in the construction and control of a contingent of four Marching Robots. Two systems, based on different position sensing techniques and control algorithms for the synchronised movement, are presented. The first system uses infrared-red sensing (IR) to make a robot follow a white track on the marching platform beneath. The second system uses a global vision system with a camera mounted on top of the parade field with every robot wearing a """"coloured hat"""" for identification and to facilitate calculation of its real world position and orientation. The movements are synchronized using State Transition Based Supervisory (STBS) control. The robots can move in straight lines and make sharp, accurate turns albeit using different feedback mechanisms. The robots are autonomous and remote-controlled by a PC using Radio Frequency or Infra Red wireless transmission. The control system can be adapted for industrial environment where robots need to collaborate."""	autonomous robot;contingency (philosophy);systems design	Toh Ser Khoon;Gourab Sen Gupta;Christopher H. Messom;Serge N. Demidenko;Bob Craig	2003		10.1109/ICECS.2003.1302060	control engineering;computer vision;simulation;engineering	Robotics	59.64075960875753	-29.424439058358683	145596
a028eaa9e729606087e289bf534d99bd45679180	learning utility surfaces for movement selection	humanoid robot;first order differential equation;movement selection;numerical solution;cost function;learning;statistical machine learning;degree of freedom;differential equation;null space control;open form model learning utility surfaces movement selection humanoid robots optimal control statistical machine learning kinematically controlled mechanical system dynamically controlled mechanical system task space components null space components first order differential equation statistical learning;statistical analysis humanoid robots learning artificial intelligence mobile robots optimal control;mobile robots;indexing terms;learning redundancy null space control dynamic and kinematic control;conference paper;optimal control;statistical learning;first order;redundancy;statistical analysis;humanoid robots;task space components;null space components;kinematically controlled mechanical system;open form model;learning artificial intelligence;dynamic and kinematic control;cost function optimal control humanoid robots constraint optimization machine learning mechanical variables control control systems mechanical systems differential equations training data;mechanical systems;learning utility surfaces;dynamically controlled mechanical system	Humanoid robots are highly redundant systems with respect to the tasks they are asked to perform. This redundancy manifests itself in the number of degrees of freedom of the robot exceeding the dimensionality of the task. Traditionally this redundancy has been utilised through optimal control in the null-space. Some cost function is defined that encodes secondary movement goals and movements are optimised with respect to this function, subject to fulfilment of task constraints. Until now design of cost functions has been carried out on an ad-hoc basis and has required time-consuming hand-tuning to ensure that the desired (or acceptable) behaviour is realised. Here we present a novel approach for designing cost functions for optimal control in the null-space by exploiting recent advances in statistical machine learning. The behaviour of a (kinematically or dynamically controlled) mechanical system performing some task is observed and separated into task- and null-space components. The null-space component is then modelled as a first order differential equation with the cost as the independent variable. Numerical solution of this equation provides training data for a statistical learning algorithm that is used to build an open-form model of the cost function. Results are presented in which the reconstructed function is used to replace that of the original control scheme and the resultant behaviour, for the same set of tasks, is compared.	asimo;algorithm;euler method;hoc (programming language);humanoid robot;kernel (linear algebra);kinesiology;loss function;machine learning;mathematical optimization;numerical partial differential equations;optimal control;perturbation theory;resultant;reverse engineering;robot control;supervised learning	Matthew Howard;Michael Gienger;Christian Goerick;Sethu Vijayakumar	2006	2006 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2006.340168	control engineering;computer vision;simulation;computer science;humanoid robot;artificial intelligence;control theory	Robotics	62.534073942383884	-24.14462187687504	145606
6fa90286d0ddf52a59cd0e3ebabec53d4774a89b	clustering four bit sequence control for serpentine gait of hyper redundant robot system	robot kinematics joints actuators service robots ambient intelligence kinematics;ambient intelligence;denavit harternberg method four bit sequence control clustering serpentine gait hyper redundant robot system snake robot complex robotic system four bit bang bang sequence control serpentine shape configuration;service robots;actuators;joints;kinematics;pattern clustering bang bang control gait analysis mobile robots;hyper redundant robot robot forward kinematic binary robot;robot kinematics	Snake robot or hyper redundant robot is very complex robotic system since it posses very large active and passive degree of freedom. To simplify the design, modeling and locomotion, a simpler approach is needed. In this paper a clustering of four bit bang-bang sequence control is proposed for every robot module to achieve serpentine shape configuration or gait. Next the Denavit Harternberg Method is used to model the segment or module involved. Scalable combination of this approach will become complex system of snake robot for serpentine gait.	bang file;chris sawyer's locomotion;cluster analysis;complex system;robot;scalability	Samsi Md Said;Amir Sharizam Ismail;Ishkandar Baharin	2014	2014 11th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2014.7057376	mobile robot;kinematics;cartesian coordinate robot;simulation;articulated robot;ambient intelligence;human–computer interaction;computer science;artificial intelligence;snake-arm robot;robot control;robot kinematics;robot calibration;actuator	Robotics	65.8662011000761	-26.984235412108326	145998
c20ee30bf34d342f4d857cdda49e18c272791aa9	a versatile tactile sensor system for covering large and curved surface areas	robot sensing systems;sensor systems;sensor phenomena and characterization;rubber;robot sensing systems sensor phenomena and characterization rubber sensor systems conferences;humanoid robots;sensitive impact resistant body coverage large curved surface areas sensor arrays biological systems humanoid platform tactile sensing system spatial resolution finger tips;tactile sensors;haptic interfaces;sensor arrays;conferences;tactile sensors haptic interfaces humanoid robots sensor arrays	Most of today's robots, while being equipped with arrays of ever more impressive sensors, still lack a fundamental ability so readily available to biological systems: a sense of touch. With the exception of a few humanoid platforms tactile sensing is typically limited to small areas such as palms or finger tips. In this paper we present a tactile sensing system designed specifically to meet the needs of covering large, possibly curved surfaces of the robot. The sensors are at the same time highly sensitive and robust, cheap to manufacture and can be made to have almost any size and shape. As such the presented system can ideally complement existing systems and their high spatial resolution required in finger tips with a system providing highly sensitive and impact resistant coverage for the rest of the body.	biological system;complement (complexity);robot;robustness (computer science);tactile sensor	Michael Zillich;Wendelin Feiten	2012	2012 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2012.6385806	control engineering;natural rubber;embedded system;computer vision;computer science;engineering;humanoid robot;artificial intelligence;tactile sensor	Robotics	66.90874133253149	-28.611474490255574	146107
32c47675d6e4183b3c847720cae19fac2ee616ad	a control method for a swarm of plant pot robots that uses artificial potential fields for effective utilization of sunlight	artificial potential fields;agricultural robotics;swarm robotics;plant pot robots system		robot;swarm	Masato Yuasa;Ikuo Mizuuchi	2014	JRM	10.20965/jrm.2014.p0505	control engineering;simulation;engineering;artificial intelligence	Robotics	59.58730967861702	-26.155751176310822	146233
14b287bf01bc1cfc656be1493aadd21cca3ae8d3	imitation and reinforcement learning	ball in a cup;discrete dynamical system;learning algorithm;ball paddling;reinforcement learning;dynamic system;robots discrete systems learning artificial intelligence regression analysis;learning systems;humans learning systems robot programming service robots intelligent robots manufacturing anthropomorphism stability planar motors legged locomotion;trajectory;human factors;shape;industrial robots;robots;whole arm manipulator;discrete systems;regression analysis;imitation learning;learning artificial intelligence;motor primitive;ball paddling imitation learning reinforcement learning motor primitive whole arm manipulator industrial robots discrete dynamical system weighted regression ball in a cup;weighted regression	In this article, we present both novel learning algorithms and experiments using the dynamical system MPs. As such, we describe this MP representation in a way that it is straightforward to reproduce. We review an appropriate imitation learning method, i.e., locally weighted regression, and show how this method can be used both for initializing RL tasks as well as for modifying the start-up phase in a rhythmic task. We also show our current best-suited RL algorithm for this framework, i.e., PoWER. We present two complex motor tasks, i.e., ball-in-a-cup and ball paddling, learned on a real, physical Barrett WAM, using the methods presented in this article. Of particular interest is the ball-paddling application, as it requires a combination of both rhythmic and discrete dynamical systems MPs during the start-up phase to achieve a particular task.	algorithm;barrett reduction;dynamical system;experiment;mps (format);machine learning;rl (complexity);reinforcement learning	Jens Kober;Jan Peters	2010	IEEE Robotics & Automation Magazine	10.1109/MRA.2010.936952	robot;simulation;unit-weighted regression;shape;computer science;artificial intelligence;trajectory;dynamical system;machine learning;reinforcement learning;regression analysis	ML	62.348366830746535	-25.22659756747082	146256
b1737739daf5b05729806b361143cd3693ddf86f	unmanned underwater vehicle navigation and collision avoidance using fuzzy logic	collision avoidance underwater vehicle fuzzy logic autonomous navigation;controller output parameter unmanned underwater vehicle navigation uuv underwater explorations human interaction vehicle dynamics underwater environment fuzzy logic based controller obstacle avoidance low cost underwater vehicle magnetometer ultrasonic sensor fuzzy logic block motion control block heading correction block fuzzy logic controller heading error rate vehicle bearing vehicle direction vehicle collision avoidance;motion control;fuzzy control;vehicle dynamics autonomous underwater vehicles collision avoidance fuzzy control machine bearings marine navigation motion control;autonomous underwater vehicles;collision avoidance;machine bearings;vehicle dynamics;vehicles fuzzy logic navigation sensors underwater vehicles clocks educational institutions;marine navigation	Unmanned underwater vehicles (UUVs) have become an integral part in helping humans do underwater explorations more efficiently and safely since these vehicles can stay underwater much longer than any human can possibly do and they require little or almost no human interaction. These vehicles are subject to dynamic and unpredictable nature of the underwater environment resulting to complexities in their navigation. This paper proposes a fuzzy logic-based controller to allow the vehicle to navigate autonomously while avoiding obstacles. The said controller is implemented in an actual low-cost underwater vehicle equipped with magnetometer and ultrasonic sensors. The intelligence of the UUV includes a two fuzzy logic block, namely Motion Control block and Heading Correction block. The fuzzy logic controller takes in target positions in X, Y and Z axes. Also, the heading error and rate of heading error are included as inputs in order to correct the bearing or direction of the vehicle. A heuristic and integration stage is also included after these fuzzy logic blocks for vehicle's collision avoidance. The controller output parameters are the adjusted thrusters' speeds which dictate the six thrusters speed and direction. With the proper output commands from this controller, the vehicle is able to navigate in its predefined destination.	course (navigation);floor and ceiling functions;fuzzy control system;fuzzy logic;heuristic;logic block;sensor;unmanned aerial vehicle	Kanny Krizzy A. David;Ryan Rhay P. Vicerra;Argel A. Bandala;Laurence A. Gan Lim;Elmer P. Dadios	2013	Proceedings of the 2013 IEEE/SICE International Symposium on System Integration	10.1109/SII.2013.6776715	control engineering;simulation;engineering;control theory	Robotics	58.9338719100835	-28.42453699511473	146464
baea2e7b5f9cbed8c64aa1c5d3ae463d897b968f	a preliminary experiment in dual-channel tactile information flow	eficacia sistema;capteur tactile;tactile sensor;sensor tactil;etude experimentale;dual channel;performance systeme;test bed;robotics;flujo informacion;system performance;flux information;information flow;single channel;robotica;robotique;estudio experimental	Abstract#R##N##R##N#Recent developments in theoretical robotics, sensor technology and fusion, and on-line processing allow for both anthropomorphic behavior on the part of robots, as well as tactile and environmental intelligence. This article considers the feasibility, use, and applications of dual-channel tactile information flow. In single-channel systems, the tactile sensors are exclusively mounted on the robot, whereas in dual-channel systems both the robot and the environment with which it interacts are supplied with sensors. A test bed is described by which a number of single- and dual-channel experiments are carried out. The focus of the dual channel experiments is on its use as this additional channel of sensory perception and on its potential for application in future robotic systems.	multi-channel memory architecture	R. M. Taylor;B. Kawarizadeh;Hooshang Hemami;K. L. Boyer	1993	J. Field Robotics	10.1002/rob.4620100203	simulation;information flow;computer science;engineering;artificial intelligence;robotics;multi-channel memory architecture;tactile sensor;testbed	Robotics	63.28452167685758	-32.483774397938774	146527
a1053e8a84df63c1930d8a1c0939eada62cb98e4	the design of an effective marine inertial navigation system scheme	marine systems compasses gyroscopes inertial navigation;gyroscopes;optimal 2 order horizontal damping network;inertial navigation;doppler log;gyro drift marine inertial navigation system scheme inertial gyrocompass system doppler log optimal 2 order horizontal damping network 1 order azimuth damping network logical damping parameter;logical damping parameter;marine inertial navigation system scheme;1 order azimuth damping network;inertial gyrocompass system;gyro drift;computer simulation;inertial navigation damping automation azimuth computer errors error analysis oscillators data mining gallium nitride marine technology;inertial navigation system;marine systems;compasses	Accuracy of marine inertial navigation system (INS) is mainly dominated by gyroscope. In this paper, a new scheme (inertial gyrocompass system) is designed to realize high accuracy INS on the basis of low accuracy float gyros and velocity information of Doppler log. By choosing optimal 2-order horizontal damping network and 1-order azimuth damping network and designing logical damping parameter, the positioning error caused by gyro drift can be eliminated to a large extent. Computer simulation and experimentations show this scheme is effective and practicable.	computer simulation;gyro;gyrocompass;gyroscope;inertial navigation system;velocity (software development)	Jian-hua Cheng;Ji-bin Zou;Lei Wu;Yan-ling Hao;Shuai Gan	2008	First International Workshop on Knowledge Discovery and Data Mining (WKDD 2008)	10.1109/WKDD.2008.130	computer simulation;geodesy;control theory;inertial navigation system	Mobile	58.18432581075945	-36.00351649262367	146700
402fb0e347b86d1c6c491792eafbe7a9eebf17ce	online boundary estimation in partially observable environments using a uav	environment monitoring;uav;boundary tracking;online estimation	Environmental boundary estimation is the process of bounding the region(s) where the measurement of all locations exceeds a certain threshold value. In this paper, we develop a framework for environmental boundary tracking and estimation in partially observable environments which are processed in an online manner. Dedicated sensors mounted on the vehicle are considered to be capable of on-the-spot field intensity measurements. Focusing on the limited resources of Unmanned Aerial Vehicles (UAVs), it is important to track an unknown boundary in a fast manner. Therefore, we present a motion planning strategy that enables a single UAV to estimate the boundary of a given target area while minimizing the exploration cost. To do so, we improve the conventional position controller based framework by integrating a noise canceling filter and a novel adaptive crossing angle correction scheme. The effectiveness of the proposed algorithm is demonstrated in three different simulated environments. We also analyze the performance of framework subject to various conditions.	partially observable system;unmanned aerial vehicle	Abdullah Al Redwan Newaz;Sungmoon Jeong;Nak Young Chong	2018	Journal of Intelligent and Robotic Systems	10.1007/s10846-017-0664-9	control theory;engineering;control engineering;control theory;active noise control;motion planning;observable	Robotics	55.58866299176301	-33.3176570015825	146831
ea2d64b8a69570c1651250143ffe7eed0b0c6d04	localization and control of an autonomous orchard vehicle	agricultural robotics;tree fruit production;autonomous orchard vehicle;orchard automation	A new row localization system which uses a laser scanner is proposed.The proposed methodology offers a successful turning between rows of trees.The proposed methodology can run without using a GPS system.The algorithms can be adapted into the real autonomous orchard applications. In this paper we propose a novel model-based control method for an autonomous agricultural vehicle that operates in tree fruit orchards. The method improves path following performance by taking into account the vehicle's motion model, including the effects of wheel sideslip, to calculate speed and steering commands. It also generates turn paths that improve visibility of the orchard rows, thus increasing the probability of a successful turn from one row into another, while respecting maximum steering rate limits. The method does not depend on GPS signals for either state estimation or path following, relying instead only on data from a planar laser scanner and wheel and steering encoders. This makes it suitable for real agricultural applications where acquisition cost is key to a farmer's decision to invest in new technologies. We show the controller's stability using Lyapunov functions and demonstrate its feasibility in experiments conducted in an orchard-like nursery.	autonomous robot;orchard	Gokhan Bayar;Marcel Bergerman;A. Bugra Koku;E. Ilhan Konukseven	2015	Computers and Electronics in Agriculture	10.1016/j.compag.2015.05.015	control engineering;embedded system;simulation;engineering	Robotics	57.44479894050379	-28.938965197263553	146843
3bde47543fd8a6ce96bda280f390e6fc50790039	wireless time synchronization module for ubiquitous robot system	wireless sensor network ubiquitous robot time synchronization module;distributed devices wireless time synchronization module ubiquitous robot system robotics field ur system mobile robots ur environment feedback control;mobile robots;synchronisation;feedback;synchronization receivers robot sensing systems wireless communication transmitters wireless sensor networks;ubiquitous computing;control engineering computing;ubiquitous computing control engineering computing feedback mobile robots synchronisation	Recently, the study of Ubiquitous Robot(UR) is one of the hot topics in robotics field. The UR system can support several types of robots and mobile robots from an environment. Moreover, human can also be supported by UR system. Each device is independently distributed in UR environment. When these devices are controlled such like feedback control, time synchronization is one of the important technologies for the control. In this paper, the wireless time synchronization module is proposed as one of the solutions of time synchronization for distributed devices, and evaluated through the experiment.	feedback;mobile robot;robotics;ubiquitous robot;ur, ur/web	Kenichi Ohara;Tamio Tanikawa	2013	2013 10th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2013.6677291	mobile robot;embedded system;synchronization;real-time computing;human–computer interaction;computer science;artificial intelligence;feedback;ubiquitous robot;ubiquitous computing	Robotics	60.95484620882646	-27.03525844194512	146869
628097b3048633593e97bb20cbd23559653b1513	underwater slam for structured environments using an imaging sonar	imaging sonar;computer engineering;underwater slam;autonomous underwater vehicles;simultaneous localization;structured environment;previous work;autonomous harbour;previous knowledge;auvs capability;accurate positioning;absolute positioning system;structured environments;sonar	Underwater SLAM for Structured Environments Using an Imaging Sonar This thesis is concerned with the navigation problem for autonomous underwater vehicles operating in artificial structured environments like harbours, marinas, marine platforms and other similar scenarios. Obtaining an accurate position in such scenarios would notably increase the capabilities of underwater vehicles and open the door to real autonomous operation. Maintenance, inspection and surveillance of marine installations are only a few examples of possible applications. The principal contributions of this thesis consist of the development of different localization systems for those situations in which an a priori map of the environment is available but, in particular, in the development of a novel solution to the Simultaneous Localization and Mapping (SLAM) problem. This solution pursues the objective of providing an autonomous vehicle with the ability to build a map within an unknown environment while, at the same time, using this same map to keep track of its current position. A mechanical scanning imaging sonar has been chosen as the principal sensor for this work because of its relative low cost and its capacity to produce a rich representation of the environment. On the other hand, the particularities of its operation and, especially, its low scanning rate, have presented many challenges during the development of this proposed localization strategies. The solutions adopted to address these problems constitute another contribution in this thesis. The development of underwater vehicles and their use as experimental platforms is another important aspect of the research work presented here. Experiments carried out in both laboratory and real application environments have provided the different datasets necessary for the testing and evaluation of the different localization approaches.		David Ribas;Pere Ridao;José Neira	2010		10.1007/978-3-642-14040-2	simulation;telecommunications;engineering;cartography	Robotics	53.79016099859879	-35.05445915792425	147021
86f3bc19f23a048aea68747769a7ec9c00a026bc	extended-2d visual servoing	image motion analysis;control design;computer vision;stability;control system synthesis;control system analysis;camera calibration errors 2d visual servoing extended 2d coordinates estimated depth distribution estimated camera model;target tracking control system synthesis control system analysis stability image motion analysis computer vision;camera calibration;target tracking;visual servoing;local minima;visual servoing cameras robust stability robust control target tracking image reconstruction control design analytical models calibration error correction	This work presents a novel visual servoing approach, aimed at controlling the so-called extended-2D (E2D) coordinates of the points constituting a tracked target. This approach does not require any pose reconstruction. Rather, the only information required to build the E2D coordinates are the estimated depth distribution of the target points, and the estimated camera model. Several implementations of the controller are considered, which are inspired from conventional image based visual servoing from points. In spite of their simplicity, the proposed control laws exhibit remarkable stability robustness properties. A key issue is that only three configurations of undesired equilibrium exist, and they are all proven to be unstable even in the uncalibrated case. In other words, contrarily to existing 2D methods, there are no local minima. The paper details the control design and analysis and provides simulation results, emphasizing the remarkable robustness with respect to camera calibration errors.	camera resectioning;control theory;maxima and minima;simulation;visual servoing	Florian Schramm;Guillaume Morel;Alain Micaelli;Anne Lottin	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1307162	control engineering;computer vision;camera resectioning;stability;computer science;maxima and minima;control theory;visual servoing	Robotics	60.99031836600732	-32.6108780154287	147068
3ee028945886d7ce3c3338cf519985029a5796f4	thermal detection and generation of collision-free trajectories for cooperative soaring uavs	multi robot systems autonomous aerial vehicles collision avoidance cooperative systems mobile robots;thermal detection cooperative system architecture multiple gliding fixed wing unmanned aerial vehicles cooperative soaring uav points of interest flight duration static soaring collision free trajectory planner optimal rapidly exploring random trees planning algorithm rrt planning algorithm la cartuja;mobile robots;cooperative systems;multi robot systems;collision avoidance;autonomous aerial vehicles;trajectory planning computational modeling atmospheric modeling wind speed thermal noise approximation algorithms	This paper presents a cooperative system architecture that extends the flight duration of multiple gliding fixed-wing Unmanned Aerial Vehicles (UAVs) for long endurance missions. The missions are defined by a set of Points of Interest (PoI) and UAVs should pass through them. A module to detect and identify thermals is implemented to exploit their energy and extend the flight duration, known as static soaring. A collision-free trajectory planner based on the RRT* (Optimal Rapidly-exploring Random Trees) planning algorithm is implemented. The proposed system allows applications in real time because of its low computational needs. Simulations and experiments carried out in the airfield of La Cartuja (Seville, Spain) show the performance and advantages of the proposed system.	aerial photography;algorithm;automated planning and scheduling;autonomous robot;collision detection;computation;computer simulation;consensus dynamics;experiment;linear algebra;point of interest;rapidly-exploring random tree;real-time computing;sensor;systems architecture;unmanned aerial vehicle	Jose A. Cobano;David Alejo;Salah Sukkarieh;Guillermo Heredia;Aníbal Ollero	2013	2013 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2013.6696774	control engineering;mobile robot;simulation;computer science;artificial intelligence;aeronautics	Robotics	55.514889605286506	-26.54357783643872	147119
cab7b2e1533d6d8f870320010b886d5bdceb1d71	dorapicker: an autonomous picking system for general objects	robot sensing systems;conference_paper;three dimensional displays;grippers;planning;object detection;pose estimation	Robots that autonomously manipulate objects within warehouses have the potential to shorten the package delivery time and improve the efficiency of the e-commerce industry. In this paper, we present a robotic system that is capable of both picking and placing general objects in warehouse scenarios. Given a target object, the robot autonomously detects it from a shelf or a table and estimates its full 6D pose. With this pose information, the robot picks the object using its gripper, and then places it into a container or at a specified location. We describe our pick-and-place system in detail while highlighting our design principles for the warehouse settings, including the perception method that leverages knowledge about its workspace, three grippers designed to handle a large variety of different objects in terms of shape, weight and material, and grasp planning in cluttered scenarios. We also present extensive experiments to evaluate the performance of our picking system and demonstrate that the robot is competent to accomplish various tasks in warehouse settings, such as picking a target item from a tight space, grasping different objects from the shelf, and performing pick-and-place tasks on the table.	algorithm;autonomous robot;e-commerce;experiment;mobile manipulator;pose (computer vision);robot end effector;smt placement equipment;workspace	Hao Zhang;Pinxin Long;Dandan Zhou;Zhongfeng Qian;Zheng Wang;Weiwei Wan;Dinesh Manocha;Chonhyon Park;Tommy Hu;Chao Cao;Yibo Chen;Marco Chow;Jia Pan	2016	2016 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/COASE.2016.7743473	planning;computer vision;simulation;pose;computer science;engineering	Robotics	59.25699659745929	-32.622528580284985	147192
51770ba897f3d10f3f75de0bae6ae756723a3dd5	intelligent off-road navigation algorithms and strategies of team desert buckeyes in the darpa grand challenge 2005		Summary. This paper describes one aspect of our approach in developing an intelligent off-road autonomous vehicle, the Intelligent Off-road Navigator (ION), as team Desert Buckeyes from the Ohio State University for the DARPA Grand Challenge 2005. The real-time navigation is one of the critical components in an autonomous ground vehicle system. In this paper, we focus on the navigation module, whose main responsibility is to generate smooth and obstacle-free local paths with appropriate speed setpoints. For the smooth path generation, we introduce a polynomial interpolation method. To generate obstacle-free paths, a steering controller utilizing a fuzzy obstacle avoidance algorithm is presented. A speed fuzzy controller is introduced to generate the speed setpoints. These two fuzzy controllers collaborate with each other to guide our vehicle ION to the goal safely. The obstacle avoidance algorithm proposed in this paper was also tested in simulations and on small robots successfully. Other issues related to the navigation module are discussed in the paper as well, such as the vehicle’s system structure and its finite state machine. As a result, ION achieved great performance in the National Qualification Event (NQE), covered about 30miles in the Nevada Desert with complete autonomous operations, and finished 10th in the Grand Challenge 2005.	algorithm;darpa grand challenge	Qi Chen;Ümit Özgüner	2006	J. Field Robotics	10.1002/rob.20138	simulation;engineering;artificial intelligence;mechanical engineering	Robotics	56.973958544644184	-28.46939294026779	147409
0940a0df527a5bf37aff020e466f18e425dfe5ef	real-time interference analysis between a tool and an environment	modelizacion;concepcion asistida;machining;computer aided design;interferencia;modele geometrique;geometrie solide;real time;geometrie constructive;geometria solidos;interference;colision;modelisation;herramienta corte;outil coupe;usinage;commande force;collision detection;binary space partition;haptic rendering;sensibilidad tactil;temps reel;geometria constructiva;conception assistee;tiempo real;control fuerza;mecanizado;collision;cutting tool;constructive geometry;modeling;sensibilite tactile;solid geometry;tactile sensitivity;geometrical model;modelo geometrico;force control	In applications such as haptic rendering, NC Verification and CAM, it is often necessary to rapidly detect and correct collision between a known tool, such as a cutting tool, and an arbitrary environment, such as the workpiece to be machined. In these situations, the tool can be manually pre-defined, but the workpiece needs a general representation; and careful fulfillment of these requirements enables extremely rapid performance. We describe an algorithm and representations for rapidly detecting and correcting collision between a manually pre-defined tool and an arbitrary workpiece. For the tool, we prescribe a form of CSG consisting of implicit equations separated by binary space partitions. This representation can be enhanced to also yield depth information and exit vector information for many useful solids. The user must hand-construct the tool using this representation. For the environment, we use a cloud of over 10,000 points. This is a general representation. The collision between tens of thousands of points and the implicit representation can be accelerated with a bounding box hierarchy. We show that we can compute collision and correction information at the rate of 1000 times a second, making it possible to perform force control for haptics using the collision detection algorithm in the real-time loop.	interference (communication);real-time transcription	Stephen Ho;Sanjay E. Sarma;Yoshitaka Adachi	2001	Computer-Aided Design	10.1016/S0010-4485(00)00117-2	simulation;systems modeling;machining;computer science;engineering;artificial intelligence;computer aided design;solid geometry;geometry;interference;engineering drawing;collision detection;collision;mechanical engineering	EDA	68.04119804008704	-37.66845459905411	147443
0941bcd18fdf52d9e25984ff067eebe6834ad7c6	development of an autonomous vehicle for high-speed navigation and obstacle avoidance		This paper introduces the autonomous vehicle Pharos, which participated in the 2010 Autonomous Vehicle Competition organized by Hyundai-Kia motors. Pharos was developed for high-speed on/off-road unmanned driving avo iding diverse patterns of obstacles. For the high speed travel ing up to 60 Km/h, long range terrain perception, real-time path planning and high speed vehicle motion control algorithms are developed. This paper describes the major hardware and software components of our vehicle.	algorithm;astrophysical virtual observatory;autonomous robot;component-based software engineering;motion planning;obstacle avoidance;real-time path planning;real-time transcription;unmanned aerial vehicle	Jee-Hwan Ryu;Dmitriy Ogay;Sergey Bulavintsev;Hyuk Kim;Jang-Sik Park	2012		10.1007/978-3-642-33926-4_9	simulation;geography;automotive engineering;transport engineering	Robotics	56.452002196997434	-29.218381510667854	147486
7fe680297a5521e9add69c2591e7b967f806acd8	driving with tentacles: integral structures for sensing and motion		In this paper we describe a LIDAR-based navigation approach applied at both the C-Elrob (European Land Robot Trial) 2007 and the 2007 DARPA Urban Challenge. At the C-Elrob 2007 the approach was used without any prior knowledge about the terrain and without global positioning system (GPS). At the Urban Challenge the approach was combined with a GPS-based path follower. At the core of the method is a set of “tentacles” that represent precalculated trajectories defined in the ego-centered coordinate space of the vehicle. Similar to an insect's antennae or feelers, they fan out with different curvatures discretizing the basic driving options of the vehicle. We detail how the approach can be used for exploration of unknown environments and how it can be extended to combined GPS path following and obstacle avoidance allowing safe road following in case of GPS offsets. © 2008 Wiley Periodicals, Inc.		Felix von Hundelshausen;Michael Himmelsbach;Falk Hecker;André Müller;Hans-Joachim Wünsche	2008	J. Field Robotics	10.1002/rob.20256	control engineering;simulation;engineering;artificial intelligence	Robotics	56.80483587391911	-28.632833970692612	147527
b028958746c33898b1a87873602c44c7f632d841	gpgpu implementation of on-line point to plane 3d data registration	parallel computing;outdoor environments;mobile robot operator;software tool;measurement by laser beam;empirical analysis;mobile robot;point to point;path planning;computer model;computer graphic equipment;measurement system;semantic simulation engine;semantics;graphics processor unit;mobile robots;parallel computation gpgpu implementation online point to plane 3d data registration classic point implementation gpgpu parallel computation 3d laser measurement system outdoor environments indoor environments graphic processor unit nvidia gf 580 semantic simulation engine data registration module semantic entities identification module robot observations mobile robot operator augmented reality techniques;augmented reality techniques;coprocessors;three dimensional;parallel computation;gpgpu implementation;3d laser measurement system;iterative closest point algorithm three dimensional displays graphics processing unit computational modeling semantics mobile robots;robot observations;computational modeling;data registration module;path planning augmented reality computer graphic equipment control engineering computing coprocessors measurement by laser beam mobile robots parallel processing;graphic processor unit nvidia gf 580;three dimensional displays;gpgpu parallel computation;classic point implementation;parallel computer;indoor environments;graphic processing unit;semantic entities identification module;mobile robot data registration parallel computing point to plane;control engineering computing;iterative closest point algorithm;augmented reality;graphics processing unit;parallel processing;online point to plane 3d data registration;data registration;point to plane	The paper concerns the result of the implementation of classic point to plane 3D data registration method with an improvement based on GPGPU parallel computation. 3D data is delivered by mobile robot equipped with 3D laser measurement system for INDOOR and OUTDOOR environments. Presented empirical analysis of the implementation shows the On-Line computation capability using modern graphic processor unit NVIDIA GF 580. The implementation is a part of a project “Semantic simulation engine” composed of following modules: data registration module, semantic entities identification module, semantic simulation. The goal of the project is to deliver software tools capable to create virtual model of the environment based on robot observations and perform semantic simulation, where all virtual entities correspond to real one. Possible practical application of the project are supervision and control of robotic system and mobile robot operator training using Augmented Reality techniques. Data registration module is composed of the implementation of point to point and point to plane classic methods improved by the usage of parallel computation. In this paper it has been shown that the implementation of GPGPU point to plane registration method is accurate in INDOOR structured environment but it has some difficulties in accurate alignment in OUTDOOR environment.	3d modeling;augmented reality;computation;entity;general-purpose computing on graphics processing units;grammatical framework;mobile robot;parallel computing;simulation;system of measurement	Janusz Bedkowski;Andrzej Maslowski	2011	Proceedings of the 2011 International Conference on Electrical Engineering and Informatics	10.1109/ICEEI.2011.6021620	mobile robot;parallel processing;computer vision;augmented reality;computer science;theoretical computer science;operating system;semantics;computer graphics (images)	Robotics	61.96343777856044	-37.46901685386658	147989
c71a8204e9f7d0f0fa8f1f9ed45f853e47147159	robust mobile robot localization based on security laser scanner	industrial environment robust mobile robot localization security laser scanner agv enhanced artificial beacon detection algorithm kalman filter outlier rejection method;lasers;measurement by laser beam;security laser;localization;mobile robotics;slam robots automatic guided vehicles industrial robots kalman filters mobile robots optical scanners;kalman filters;artificial beacons;kalman filter;mobile robots;security laser agv mobile robotics localization artificial beacons kalman filter outliers rejection;filtering algorithms;lasers measurement by laser beam security filtering algorithms kalman filters mobile robots;agv;security;outliers rejection	This paper addresses the development of a new localization system based on a security laser presented on most AGVs for safety reasons. An enhanced artificial beacons detection algorithm is applied with a combination of a Kalman filter and an outliers rejection method in order to increase the robustness and precision of the system. This new robust approach allows to implement such system in current AGVs. Real results in industrial environment validate the proposed methodology.	algorithm;computation;experiment;extended kalman filter;mobile robot;odometry;rejection sampling;robotic mapping;time complexity	Héber M. Sobreira;António Paulo Moreira;Paulo Gomes Costa;José Lima	2015	2015 IEEE International Conference on Autonomous Robot Systems and Competitions	10.1109/ICARSC.2015.28	control engineering;computer vision;simulation;engineering	Robotics	54.765984343737294	-36.039335014695205	148008
912120ef0dca6778a49db47028305d1e0fa3c029	collision-free 4d trajectory planning in unmanned aerial vehicles for assembly and structure construction	tecnologia industrial tecnologia mecanica;tecnologia electronica telecomunicaciones;trajectory planning;aerial robotics;real time applications;tecnologias;grupo a	This paper presents a new system for assembly and structure construction with multiple Unmanned Aerial Vehicles (UAVs) which automatically identifies conflicts among them. The system proposes the most effective solution considering the available computation time. After detecting conflicts between UAVs, the system resolves them cooperatively using a collision-free 4D trajectory planning algorithm based on a simple one-at-a-time strategy to quickly compute a feasible but non-optimal initial solution and a stochastic optimization technique named Particle Swarm Optimization (PSO) to improve the initial solution. An anytime approach using PSO is applied. It yields trajectories whose quality improves when available computation time increases. Thus, the method could be applied in real-time depending on the available computation time. The method has been validated with D. Alejo · J. A. Cobano (B) · G. Heredia · A. Ollero Robotics, Vision and Control Group Engineering School, University of Seville, 41092 Seville, Spain e-mail: jacobano@cartuja.us.es D. Alejo e-mail: dalejo@us.es G. Heredia e-mail: guiller@us.es A. Ollero e-mail: aollero@us.es simulations in scenarios with multiple UAVs in a common workspace and experiment in an indoor testbed.	aerial photography;anytime algorithm;apache axis;automated planning and scheduling;computation;email;experiment;genetic algorithm;mathematical optimization;minimum bounding box;particle swarm optimization;program optimization;real-time clock;real-time computing;robotics;sensor;simulation;stochastic optimization;testbed;time complexity;unmanned aerial vehicle;workspace	David Alejo;Jose A. Cobano;Guillermo Heredia;Aníbal Ollero	2014	Journal of Intelligent and Robotic Systems	10.1007/s10846-013-9948-x	control engineering;simulation;computer science;engineering;artificial intelligence	Robotics	55.34220545937487	-25.530196232198143	148117
8b01dd9be67cb2ff990e89c41c7bfe388f46b599	data-driven robot gait modeling via symbolic time series analysis	analytical models;statistical learning data driven robot gait modeling symbolic time series analysis bayesian mode estimation hidden mode hybrid systems hmhs six legged t hex robot walking robot motion behavior;legged locomotion;power system dynamics;computational modeling;hidden markov models;legged locomotion analytical models power system dynamics data models computational modeling hidden markov models;time series bayes methods estimation theory gait analysis legged locomotion motion control statistical analysis;data models	This paper addresses data-driven mode modeling and Bayesian mode estimation in hidden-mode hybrid systems (HMHS). For experimental validation in a laboratory setting, an HMHS is built upon a six-legged T-hex robot that makes use of a library of gaits (i.e., the modes of walking) to perform different motion maneuvers. To accurately predict the behavior of the robot, it is important to first infer the gait being used by the robot. The walking robot's motion behavior can then be modeled as a transition system based on the pattern of switching among these gaits. In this paper, a symbolic time-series-based statistical learning method has been adopted to construct the generative models of the gaits. Efficacy of the proposed algorithm is demonstrated by laboratory experimentation to model and then infer the hidden dynamics of different gaits for the T-hex walking robot.	algorithm;generative model;hybrid system;machine learning;mathematical optimization;mobile robot;motion capture;motion planning;stochastic matrix;time series;transition system	Yusuke Seto;Noboru Takahashi;Devesh K. Jha;Nurali Virani;Asok Ray	2016	2016 American Control Conference (ACC)	10.1109/ACC.2016.7525522	data modeling;simulation;computer science;engineering;artificial intelligence;machine learning;computational model;hidden markov model	Robotics	61.67221018633634	-25.796048536374265	148569
0e9984e275bbf957e6bca58ec7663abed2c4b4dc	atr applications in military missions	weapon guidance atr applications military missions automatic target recognition military systems operational capability surveillance reconnaissance;object recognition;operational capability;weapon guidance automatic target recognition surveillance reconnaissance strike;image resolution;surveillance;surveillance target recognition weapons reconnaissance military computing object detection computational intelligence aircraft image resolution image sensors;atr applications;computational intelligence;military missions;image sensors;target recognition;military systems;automatic target recognition;weapon guidance;target tracking;weapons military computing military systems object recognition surveillance target tracking;reconnaissance;strike;weapons;object detection;military computing;aircraft	While there has been a nominal effort to develop automatic target recognition (ATR) technologies for military systems for the last couple of decades, there have been relatively few significant breakthroughs. At the same time, the evolution of some of our missions has made it more desirable to achieve solutions from this technology to meet some of the escalating operational challenges. This paper is intended to identify and characterize some areas where ATR algorithms might materially improve our operational capability	algorithm;automatic target recognition	Ted Wong	2007	2007 IEEE Symposium on Computational Intelligence in Security and Defense Applications	10.1109/CISDA.2007.368131	computer vision;simulation;image resolution;computer science;cognitive neuroscience of visual object recognition;computational intelligence;image sensor;computer security;automatic target recognition	Security	55.35152379184247	-30.653578895497727	148598
2b34b60e95a2db211ed9883b0189369049f4ab61	canadian artic sovereignty: local intervention by flocking uavs	self adjusting systems aircraft artificial intelligence remotely operated vehicles;local intervention;visual presence canadian artic sovereignty local intervention flocking uav canadian sovereignty rapid intervention system carrier scouts design unmanned aerial vehicles carrier aircraft tactical combat aircraft programs boeing aerospace company us air force airborne launch human controllers close up images;carrier scouts design;canadian artic sovereignty;surveillance;arctic surveillance water resources security nuclear facility regulation remote monitoring satellites synthetic aperture radar military aircraft computational intelligence;unmanned aerial vehicle;self adjusting systems;rapid intervention system;remotely operated vehicles;force;military aircraft;arctic;region of interest;canadian sovereignty;human controllers;us air force;artificial intelligence;carrier aircraft;self organization;flocking uav;tactical combat aircraft programs;airborne launch;close up images;unmanned aerial vehicles;boeing aerospace company;cameras;probability of detection;visual presence;aircraft	The importance of local intervention capability for the assertion of Canadian Sovereignty in the Northwest Passage is recognized. However, Canada lacks the ability to deploy, on demand, assets to search a wide area for rescue or surveillance purposes in the North. This fact motivated our investigation of the feasibility of a rapid intervention system based on a carrier-scouts design in which a number of unmanned aerial vehicles (UAVs) would be transported, air launched and recovered by a carrier aircraft. These UAVs would have the ability to self-organize in formations that correspond to the task at hand. When searching for a target, they would fly in a linear pattern so that the search area swept per hour and the probability of detecting the target would be considerably increased. A 1973 report by the Tactical Combat Aircraft Programs of the Boeing Aerospace Company for the US Air Force and a 2007 thesis by Chalamont indicate that airborne launch and recovery of many UAVs from a carrier aircraft is feasible and requires only already existing technology. We propose here a solution to the remaining problem of managing simultaneously the many UAVs that are required by the vastness of the areas to be surveyed, with a minimum number of human controllers and communications. Namely, we present algorithms for the self-organization of the UAVs in the required formations. These allow for surveillance operations during which close-up images would be acquired of activities in a region of interest, and searching an area for assets in distress and providing a visual presence for such. We reach the conclusion that our proposed local intervention system with flocking UAVs is feasible and would provide a valuable asset for asserting Canadian Sovereignty in the North.	airborne ranger;algorithm;cyber sovereignty;flocking (behavior);inventory;region of interest;self-organization;sensor;television antenna;unmanned aerial vehicle	Gilles Labonté	2009	2009 IEEE Symposium on Computational Intelligence for Security and Defense Applications	10.1109/CISDA.2009.5356552	remotely operated underwater vehicle;self-organization;simulation;arctic;computer science;artificial intelligence;statistical power;computer security;force;region of interest	Vision	55.00546118051241	-28.64440688335122	148735
2330b13f520c1781579ee2d8d373602d1e6e212a	modular robot path planning using genetic algorithm based on gene pool	self assembly;path planning;gene pool;success rate;genetic algorithm;modular robots	As a new generation of robotics, a modular robot is flexible enough to achieve self-replication by attaching a new modular, or perform self-assembly by transferring into different shapes. However, the path planning for modular robots, the fundamental function is seldom studied until now. In this paper, we improve the path schedule method of Molecubes, by designing a gene pool, to speed the convergence and avoid the uncertain of the original genetic algorithm (GA). Experiments show that the gene-pool based GA outperforms the old one in both success rate and speed in planning the long path.	gene pool;genetic algorithm;motion planning;self-reconfiguring modular robot	Huaming Zhong;Zhenhua Li;Hao Zhang;Chao Yu;Ni Li	2010		10.1007/978-3-642-16493-4_39	simulation;engineering;artificial intelligence;machine learning	Robotics	55.40673680068821	-24.09371026340795	148836
3910859da1fe95c24bc3ebf8d40ebd2c86ebd34c	localization of miniature mobile robots using constant curvature dynamic contours	robot localization;mobile robots cameras target tracking robot vision systems acceleration monitoring orbital robotics shape computer science springs;robot vision mobile robots path planning image motion analysis tracking;image motion analysis;fast accelerations tracking;mobile robot;path planning;mobile robots;orbital robotics;acceleration;jumps miniature mobile robots constant curvature dynamic contours robot localization observer robot camera fast accelerations tracking fast decelerations tracking scout robot;springs;constant curvature dynamic contours;fast decelerations tracking;robot vision;shape;monitoring;miniature mobile robots;observer robot;jumps;scout robot;computer science;target tracking;robot vision systems;cameras;tracking;camera	This paper presents a novel method for localizing miniature mobile robots (Scouts) using dynamic contours. An observer robot with a camera follows the miniature robot as it moves and jumps in the workspace. Dynamic contours are very effective in tracking the fast accelerations and decelerations of the Scout robot. We show initial experimental results with particular emphasis on the task of monitoring a Scout during jumps.	microbotics;mobile robot;principle of good enough;robotics;scout;topography;wheels;workspace;ranger	Douglas P. Perrin;Esra Kadioglu Urtis;Sascha Stoeter;Nikolaos Papanikolopoulos	2002		10.1109/ROBOT.2002.1013440	control engineering;mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence	Robotics	59.15468168726215	-33.41806947691759	148942
abcaffe03351b938bd9e9ed376afec6590671316	determining the time delay between inertial and visual sensor measurements	three dimensional orientation space time delay inertial sensor measurements visual sensor measurements imu camera data streams registration problem;navigation calibration robot sensing systems computer vision sensor fusion time measurement;sensors calibration cameras delays inertial navigation;sensor fusion aided navigation calibration and identification computer vision inertial sensing	We examine the problem of determining the relative time delay between IMU and camera data streams. The primary difficulty is that the correspondences between measurements from the sensors are not initially known, and hence, the time delay cannot be computed directly. We instead formulate time delay calibration as a registration problem, and introduce a calibration algorithm that operates by aligning curves in a three-dimensional orientation space. Results from simulation studies and from experiments with real hardware demonstrate that the delay can be accurately calibrated.	algorithm;broadcast delay;experiment;sensor;simulation	Jonathan Kelly;Nicholas Roy;Gaurav S. Sukhatme	2014	IEEE Transactions on Robotics	10.1109/TRO.2014.2343073	computer vision;simulation;engineering;control theory	Robotics	55.74139561093654	-36.15622794854177	148979
c46bef14ff823132f10df8c91eb125efff07a8cd	obstacle avoidance perception processing for the autonomous land vehicle	experimental tests;systolic array;complete computer programs;transport computer control cellular arrays complete computer programs computer vision computerised navigation computerised picture processing position control road vehicles robots;cellular arrays;computer vision;land vehicles navigation mobile robots testing systolic arrays remotely operated vehicles road vehicles color intelligent robots machine intelligence;obstacle avoidance;position control;video range sensor data sensor data fusion obstacle region location mobile robot computer vision obstacle avoidance perception sensing system martin marietta s autonomous land vehicle range image based methods high speed systolic array processor warp machine;range image;robots;autonomous land vehicle;computerised picture processing;system development;high speed;road vehicles;transport computer control;computerised navigation	A description is given of an obstacle avoidance perception sensing system developed for use on Martin Marietta's autonomous land vehicle. The focus is on range-image-based methods developed to run on a high-speed systolic array processor called the Warp machine. Techniques are presented for fusing video/range sensor data, locating obstacle regions in range imagery, and mapping of the algorithm onto Warp machine. The results of applying the perception sensing system in an experimental test run are presented, and limitations of its use are discussed. >	autonomous robot;obstacle avoidance	R. Terry Dunlay	1988		10.1109/ROBOT.1988.12176	robot;embedded system;computer vision;simulation;systolic array;computer science;engineering;artificial intelligence;obstacle avoidance	Robotics	57.58626829288917	-32.01046322407355	149052
4f600215ae9ed7643322bea46e77b834336aed67	a crowd avoidance method using circular avoidance path for robust person following		A life-support service robot must avoid both static and dynamic obstacles for working in a real environment. Here, a static obstacle means an obstacle that does not move, and a dynamic obstacle is the one that moves. Assuming the robot is following a target person, we discuss how the robot avoids a crowd through which the target person passes and arrives at the target position. The purpose of this paper is to propose a crowd avoidance method that makes a robot to be able to avoid both static and dynamic obstacles. The method uses the surface points of the obstacles to form an avoidance region, and the robot moves along the edge of the region. We conducted experiments assuming various situations such that the robot was blocked, there was a wide gap in the crowd, or a person in the crowd yielded for the robot to pass through. As an experimental result, it was confirmed the robot could avoid the crowd even when the obstacles were aligned in an “inverted wedge” shape.		Kohei Morishita;Yutaka Hiroi;Akinori Ito	2017	J. Robotics	10.1155/2017/3148202	computer vision;bang-bang robot;simulation;obstacle avoidance	Robotics	58.30054397962195	-26.774468802967036	149094
acead149433a0a1eb9234d8d860eb770f1513a20	design of a networked control system for biomimetic robot fish	image processing algorithms;robot sensing systems;sensor information;control systems;sensor systems;marine animals;motion control;image processing;robot vision control engineering computing feature extraction internet mobile robots motion control;networked control systems;local sensor;point to point;rule based;biomimetic robot fish;posture extraction;network camera;mobile robots;rule based point to point motion control algorithm;remote computer;microsoft foundation classes;wireless communication;network control;ftp;biomimetic robot fish networked control system image processing rule based motion control;robot vision;internet;rule based motion control;rule based point to point motion control algorithm networked control system biomimetic robot fish network camera ftp web server local sensor remote computer sensor information local controller wireless communication image processing algorithms posture extraction;feature extraction;networked control systems biomimetics marine animals robot sensing systems communication system control sensor systems wireless sensor networks control systems motion control robot vision systems;control engineering computing;web server;local controller;networked control system;communication system control;robot vision systems;wireless sensor networks;biomimetics	In this paper, a networked control system for a biomimetic robot fish is introduced. The whole system includes four parts: a network camera which is embedded with FTP and Web server and used as a local sensor; a remote computer which works as a networked controller and obtains sensor information from the network camera, processes the information, generates instructions for the robot fish, and sends them to the local controller; a local controller which relays the instructions to the robot fish via wireless communication; a robot fish without embedded sensors. Image processing algorithms for posture extraction and a rule-based point-to-point motion control algorithm are proposed for the networked control of the robot fish. All these algorithms are realized with Microsoft Foundation Class (MFC) and work on the remote computer. The experimental platform is set up on Intranet. An experiment of point-to-point motion control of a robot fish is shown and the statistic of the transmission delay of the images is given.	algorithm;biomimetics;control system;embedded system;ip camera;image processing;intranet;logic programming;microsoft foundation class library;point-to-point protocol;poor posture;relay;remote computer;robot;sensor;server (computing);web server	Xiang Dong;Shuo Wang;Zhiqiang Cao;Min Tan	2008	2008 IEEE International Conference on Networking, Sensing and Control	10.1109/ICNSC.2008.4525236	biomimetics;control engineering;motion control;mobile robot;embedded system;computer vision;file transfer protocol;the internet;wireless sensor network;image processing;feature extraction;point-to-point;computer science;networked control system;engineering;control system;artificial intelligence;control theory;robot control;web server;wireless	Robotics	60.11960070099834	-30.542735641532666	149149
d765666aed8cc3ec8169c022708bfba84b0ec47e	cameraman: a multirobot system for nanohandling in a scanning electron microscope	sem vacuum chamber;nanohandling robot cell;object recognition;object recognition cameraman multirobot system scanning electron microscope nanohandling robot cell sem vacuum chamber miniature video microscope image processing techniques stereo vision;heterogeneous systems;scanning electron microscopes;multirobot system;multi robot system;nanotechnology;multirobot systems;scanning electron microscope;three dimensional;stereo image processing;stereo vision;multi robot systems;image processing techniques;multirobot systems scanning electron microscopy robotics and automation robot kinematics automatic control control systems feedback orbital robotics robot sensing systems electron beams;cameraman;miniature video microscope;stereo image processing multi robot systems nanotechnology object recognition scanning electron microscopes	This paper presents the detailed design of a nanohandling robot cell that can work inside an SEM's vacuum chamber and incorporates miniature video microscopes in order to enable fully automated nanohandling and -assembly. The geometrical and mechanical requirements are defined and addressed in a modular implementation. Image processing techniques can be used to recognize and track objects and three dimensional information can be obtained by stereo vision as well as the microscope's focus. To control this highly heterogeneous system, different low-level controllers are used, challenges for cooperatively controlling the multi-robot system are outlined, and high-level automation is discussed.	algorithm;electron;high- and low-level;image processing;outline of object recognition;piezoelectricity;prototype;requirement;robot;stereopsis	Sergej Fatikow;Daniel Jasper;Christoph Edeler;Christian Dahmen	2008	2008 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2008.4543246	computer vision;simulation;engineering;optics;scanning electron microscope	Robotics	63.3870976509253	-34.99393665976871	149633
7b21910511e518ec4064b631bb2411f99f69d497	analysis of period-1 passive limit cycles for flexible walking of a biped with knees and point feet	robot design;passive dynamic walking;flexible walking;gait analysis;biped with knees;article	In this paper, we investigate dynamic walking as a convergence to the systemu0027s own limit cycles, not to artificially generated trajectories, which is one of the lessons in the concept of passive dynamic walking. For flexible walking, gait transitions can be performed by moving from one limit cycle to another one, and thus, the flexibility depends on the range in which limit cycles exist. To design a bipedal walker based on this approach, we explore period-1 passive limit cycles formed by natural dynamics and analyze them. We use a biped model with knees and point feet to perform numerical simulations by changing the center of mass locations of the legs. As a result, we obtain mass distributions for the maximum flexibility, which can be attained from very limited location sets. We discuss the effect of parameter variations on passive dynamic walking and how to improve robot design by analyzing walking performance. Finally, we present a practical application to a real bipedal walker, designed to exhibit more flexible walking based on this study.	limit cycle	Jae-Sung Moon;Seong-Min Lee;Joonbum Bae;Youngil Youm	2016	Robotica	10.1017/S0263574715000144	power walking;gait analysis	NLP	66.4480614225402	-24.659226871988196	149930
6324d9a820cd1f5264c370bc40563887e6d70cf5	development of an unmanned tail-sitter with reconfigurable wings: u-lion	cfd simulation unmanned tail sitter reconfigurable wings reconfigurable hybrid unmanned aerial vehicle u lion uav small scale uav vtol mode vertical takeoff and landing mode fixed wing flight mode expanded polyolefin foam epo foam electronic avionic components cruise mode national university of singapore nus unmanned system research group reconfigurable wing fixed wing plane rotor helicopter hovering stage thrust vectored propulsion system computational fluid dynamics;polymer foams aerospace components aerospace propulsion autonomous aerial vehicles computational fluid dynamics flow simulation mobile robots;servomotors aircraft couplings automotive components batteries brushless motors educational institutions	In this paper, we present the development of a reconfigurable hybrid unmanned aerial vehicle (UAV): U-Lion. U-Lion is a small-scale UAV that is capable of vertical takeoff and landing (VTOL) and fixed-wing flight modes through its unique mechanical design. Mainly built with carbon fiber and Expanded PolyOlefin (EPO) foam, U-Lion is equipped with an array of electronic avionic components which enable stable control of the UAV both in VTOL and Cruise modes. It was employed by the National University of Singapore (NUS) Unmanned System Research Group to participate in the 2013 UAV Grand Prix (UAVGP) competition held in Beijing, China. Its design adopts a reconfigurable wing and a tailsitter structure, which combines the advantages of a fixed-wing plane and a rotor helicopter effectively. U-Lion could transit from vertical takeoff to a hovering stage before flying in cruise mode to realize efficient long duration flight. The propulsion of U-Lion comes from a self-fabricated contra-rotating motor fixed on a gimbal mechanism which can change the direction of the motor for the required thrust. This thrust-vectored propulsion system primarily provides control in the VTOL mode but also enhances flight capabilities in the cruise mode. The detailed design and implementation procedure have been presented in this paper along with our Computational Fluid Dynamics (CFD) simulation results, real flight tests and competition performance.	aerial photography;algorithm;assisted gps;autonomous robot;computation;computational fluid dynamics;computer multitasking;darpa grand challenge;experiment;mathematical model;obstacle avoidance;optical fiber;r.o.t.o.r.;simulation;sitter (beam);tail call;thrust;unmanned aerial vehicle	Kevin Z. Y. Ang;Jinqiang Cui;Tao Pang;Kun Li;Kangli Wang;Yijie Ke;Ben M. Chen	2014	11th IEEE International Conference on Control & Automation (ICCA)	10.1109/ICCA.2014.6871015	simulation;aerospace engineering;engineering;aeronautics	Robotics	63.611685827193185	-28.446247875321497	150180
4c92a8b23f686164e7f121f8e36c35f59f5b721e	the tekkotsu robotics development environment	robot sensing systems;tekkotsu robotic development environment;undergraduate education;autonomous operation;legged locomotion;undergraduate education tekkotsu robotic development environment sony aibo autonomous operation virtual simulation;computer aided instruction;actuators;robot kinematics robot sensing systems hardware real time systems cameras actuators;development environment;virtual simulation;sony aibo;cameras;robot kinematics;legged locomotion computer aided instruction;hardware;real time systems	Tekkotsu has grown from a specialized framework for development on the Sony Aibo to a general purpose robotics development environment with support for a variety of hardware, algorithms for autonomous operation, virtual simulation, and associated curriculum for undergraduate education. This paper describes the implementation of these features, provides examples of their use in research and education, and draws a comparison with other popular open-source robotics frameworks.	aibo;algorithm;autonomous robot;distributed computing;embedded system;open-source robotics;open-source software;real-time clock;robot operating system;simulation	Ethan J. Tira-Thompson;David S. Touretzky	2011	2011 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2011.5980533	control engineering;computer vision;simulation;computer science;engineering;artificial intelligence;aibo;geography of robotics;development environment;robot kinematics;actuator	Robotics	64.56456917314212	-29.064220467199732	150193
2749bf3cd116dbbfad1a34376a519d10b0a7bde9	fusion of the magnetic and optical information for motion capturing	magnetic sensor;optical marker;motion capture;system identification;sensor fusion;article	We propose a sensor fusion technique for motion capture system. In our system, two kinds of sensors are used for mutual assistance. Six magnetic sensors are attached on the arms and feet for assisting twelve optical markers and six optical markers, which are attached on the arms and feet of a performer, respectively. The optical marker information is not always complete because the optical markers can be hidden due to obstacles. In this case, magnetic sensor information is used to link discontinuous optical marker information. We use a system identification technique for modeling the relation between the two signals of sensor and marker. We determine the best model from the set of candidate models using the canonical system identification technique. In order to show the efficiency of the proposed system, experiments are performed for motion capture data obtained from both the optical and magnetic motion capture system, and the animation results are shown.	coat of arms;dynamical system;experiment;fits;kalman filter;motion capture;nl-complete;nonlinear system;numerical aperture;polynomial;programming paradigm;sandy bridge;sensor;signal processing;simulation;system identification;wiener filter	Chan-Jong Park;KwangYun Wohn	2007	Int. J. Image Graphics	10.1142/S0219467807002842	computer vision;motion capture;simulation;system identification;computer science;machine learning;sensor fusion	Robotics	64.87305156217856	-34.58120691446853	150260
f8cdff9958b7eca63d2b70091029d0db288b6b37	implementation of a homography-based visual servo control using a quaternion formulation		Abstract: In this paper, we present the implementation of a homography-based visual servo controller as introduced in (Hu et al., 2006). In contrast to other visual servo controllers, this formulation uses a quaternion representation of the rotation. By doing so, potential singularities introduced by the rotational matrix representation can be avoided, which is usually a very desirable property in, for example, aerospace applications such as for visual control of satellites, helicopters, etc. The movement of the camera and the image processing were performed using a simulation of the real environment. This testing environment was developed in Matlab-Simulink and it allowed us to test the controller regardeless of the mechanism in which the camera was moved and the underlying controller that was needed for this movement. The final controller was tested using yet another simulation program provided by Kawasaki Japan for the UX150 industrial robot. The setup for testing and the results of the simulations are presented in this paper.	c++;discretization;experiment;holographic principle;homography (computer vision);image processing;industrial robot;matlab;matrix representation;perf (linux);servo;simulation;visual servoing	T. Koenig;G. N. De Souza	2008			industrial robot;engineering;quaternion;control theory;image processing;control theory;visual control;rotation matrix;control engineering;servo control;servo	Robotics	64.31669686843614	-30.33645273484398	150375
9af5d93b7c17a0560d48c8f87b65e551a910eb3d	on the duality of robot and sensor path planning	tomlab cplex mobile sensor sensor path planning robot path planning mixed integer programming mip vehicle dynamics obstacle avoidance robot navigation problems mobile robots path optimization problems matlab;geometry;mobile robots;mobile robots collision avoidance geometry integer programming;integer programming;collision avoidance;robot sensing systems path planning collision avoidance robot kinematics planning geometry	The performance of a mobile sensor can be greatly improved by planning its path with respect to its sensing objective, field-of-view, and platform geometry. Although many algorithms have been developed for the related field of robot path planning, a majority of these methodologies cannot be directly applied to the problem of sensor path planning. This paper presents a technique by which mixed-integer programming (MIP) can be used to determine the optimal path of a mobile sensor. MIP is able to return solutions in non-convex environments, and has a flexible framework that allows for the consideration of vehicle dynamics, obstacle avoidance, and, as shown here, target measurement objectives. The primary contribution of this work is the development of a poof of the duality of robot and sensor path planning. By use of MIP, the proof shows that many approaches to classical robot navigation problems can be reformulated for sensor path planning. Illustrative simulation results for the paths of mobile robots and sensor platforms are presented; MATLAB and Tomlab/CPLEX were used to solve the path optimization problems.	algorithm;automated planning and scheduling;cplex;convex function;integer programming;linear programming;matlab;mathematical optimization;mobile robot;motion planning;obstacle avoidance;robotic mapping;sensor;simulation	Ashleigh Swingler;Silvia Ferrari	2013	52nd IEEE Conference on Decision and Control	10.1109/CDC.2013.6760010	mobile robot;computer vision;mathematical optimization;simulation;integer programming;any-angle path planning;engineering;mathematics;robot control;obstacle avoidance;mobile robot navigation	Robotics	53.863156117571016	-24.867328662023827	150507
da2c098e9e66f53a8872b487dd22199cd03fa63a	assisted control for semi-autonomous power infrastructure inspection using aerial vehicles		This paper presents the design and implementation of an assisted control technology for a small multirotor platform for aerial inspection of fixed energy infrastructure. Sensor placement is supported by a theoretical analysis of expected sensor performance and constrained platform behaviour to speed up implementation. The optical sensors provide relative position information between the platform and the asset, which enables human operator inputs to be autonomously adjusted to ensure safe separation. The assisted control approach is designed to reduced operator workload during close proximity inspection tasks, with collision avoidance and safe separation managed autonomously. The energy infrastructure includes single vertical wooden poles and crossarm with attached overhead wires. Simulated and real experimental results are provided.		Aaron McFadyen;Feras Dayoub;Steve Martin;Jason Ford;Peter I. Corke	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8593529	simulation;workload;collision;task analysis;speedup;operator (computer programming);computer science;multirotor	Robotics	56.36363675561205	-25.931035219145972	150775
0ac1a7a35de7b962fa83b5af712a6f6143c66903	microphone-accelerometer based 3d posture estimation for a hose-shaped rescue robot	microphones;robot sensing systems;rescue robots accelerometers kalman filters loudspeakers microphones nonlinear filters;vibration motor microphone accelerometer based 3d posture estimation hose shaped rescue robot complex physical environments 3d posture estimation sound based time difference of arrival tdoa tilt information nonlinear state space model unscented kalman filter loudspeaker;estimation;loudspeakers;microphones accelerometers loudspeakers estimation robot sensing systems three dimensional displays;three dimensional displays;accelerometers	3D posture estimation for a hose-shaped robot is critical in rescue activities due to complex physical environments. Conventional sound-based posture estimation assumes rather flat physical environments and focuses only on 2D, resulting in poor performance in real world environments with rubble. This paper presents novel 3D posture estimation by exploiting microphones and accelerometers. The idea of our method is to compensate the lack of posture information obtained by sound-based time-difference-of arrival (TDOA) with the tilt information obtained from accelerometers. This compensation is formulated as a nonlinear state-space model and solved by the unscented Kalman filter. Experiments are conducted by using a 3m hose-shaped robot with eight units of a microphone and an accelerometer and seven units of a loudspeaker and a vibration motor deployed in a simple 3D structure. Experimental results demonstrate that our method reduces the errors of initial states to about 20 cm in the 3D space. If the initial errors of initial states are less than 20 %, our method can estimate the correct 3D posture in real-time.	angularjs;kalman filter;loudspeaker;microphone;multilateration;nonlinear system;poor posture;real-time clock;rescue robot;robotics;sensor;state space;velocity (software development)	Yoshiaki Bando;Katsutoshi Itoyama;Masashi Konyo;Satoshi Tadokoro;Kazuhiro Nakadai;Kazuyoshi Yoshii;Hiroshi G. Okuno	2015	2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2015.7354168	loudspeaker;control engineering;estimation;simulation;acoustics;computer science;engineering;accelerometer;statistics	Robotics	57.15680215134094	-35.80994103647526	150787
f307726ee515136ef815951389f2dbfeeef7bd25	quantitative analysis of distributed control paradigms for robot swarms	robot sensing systems;mobile robot;neurocontrollers control system synthesis distributed control mobile robots;mobile robots;artificial neural networks;control system synthesis;neural network based control quantitative analysis distributed control paradigms robot swarm aggregation controller design mobile robots;controller design;quantitative analysis;swarm robotics;neurocontrollers;distributed control;light sources;robot kinematics;neural network;robot sensing systems artificial neural networks robot kinematics light sources mobile robots distributed control	Given a task of designing controller for mobile robots in swarms, one might wonder which distributed control paradigms should be selected. Until now, paradigms of robot controllers have been within either behaviour based control or neural network based control, which have been recognized as two mainstreams of controller design for mobile robots. However, in swarm robotics, it is not clear how to determine control paradigms. In this paper we study the two control paradigms with various experiments of swarm aggregation. First, we introduce the two control paradigms for mobile robots. Second, we describe the physical and simulated robots, experiment scenario, and experiment setup. Third, we present our robot controllers based on behaviour based and neural network based paradigms. Fourth, we graphically show their experiment results and quantitatively analyse the results in comparison of the two methods. Closing remarks conclude the paper.	algorithm;artificial neural network;closing (morphology);control theory;distributed control system;emergence;experiment;mobile robot;programming paradigm;simulation;swarm robotics	Trung Dung Ngo	2010	2010 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2010.5723313	control engineering;mobile robot;simulation;computer science;engineering;artificial intelligence;artificial neural network	Robotics	65.04232548985777	-24.894725274346143	150796
70d3eeb330b3193fc36812ae999746ce77384841	visual tracking of a hand-eye robot for a moving target object with multiple feature points: translational motion compensation approach	feature points;hand eye robot;motion compensated;eye in hand configuration;control system;charged couple device;visual tracking;visual servoing;moving target object;control method	In this paper, we propose a visual tracking control method of a hand-eye robot for a moving target object with multiple feature points. The hand-eye robot is composed of a three degrees-offreedom planar manipulator and a single CCD camera that is mounted on the manipulator’s endeffector. The control objective is to keep all feature points of the target object around their desired coordinates on the image plane. In many conventional visual servo methods, it is assumed that the target object is static. Consequently, the visual tracking error arises in the case of a moving target object. We have already proposed a visual tracking control system that takes into consideration the target object motion. This method can reduce the visual tracking error, but can only deal with a single feature point. Therefore, this paper extends such a visual tracking control method to multiple feature points. The effectiveness of our control method is evaluated experimentally. keywords: visual servoing, moving target object, feature points, eye-in-hand configuration, hand-eye robot	charge-coupled device;control system;experiment;eye tracking;image plane;motion compensation;robot;servo;velocity (software development);video tracking;visual servoing	Masahide Ito;Masaaki Shibata	2011	Advanced Robotics	10.1163/016918610X552150	computer vision;simulation;tracking system;eye tracking;computer science;control system;control theory;charge-coupled device;visual servoing	Robotics	60.71941472276779	-32.083192054344536	150956
3536c9fe5f40b0a2b16ec74cba08ae3736448e62	coordinated protocols: an approach to formalize coordination between mobile robots	animals;protocols;underwater vehicles;mobile robot;collaboration;space exploration;mobile robots;orbital robotics;protocols mobile robots robot kinematics orbital robotics space exploration animals collaboration large scale systems buildings underwater vehicles;buildings;large scale systems;robot kinematics		mobile robot	Fabrice R. Noreils	1992		10.1109/IROS.1992.594472	control engineering;mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence;robot control	Robotics	58.05591164165711	-25.006113837729206	151238
2b520fe4e1f55b2c622022dfff4b87fdbb0dfc24	an accelerometers-size-effect self-calibration method for triaxis rotational inertial navigation system		Rotational inertial navigation system (RINS) could improve navigation performance by rotating the inertial measurement unit (IMU) with gimbals, and error parameters could be self-calibrated as well. However, accelerometers size effect would cause more influence on navigation accuracy in RINS than a strapdown inertial navigation system because of gimbals rotation, which should be calibrated and compensated for high-end application. In this paper, size effect and other IMU errors are calibrated through optimal estimation with navigation errors in triaxis RINS. The rotation scheme is designed by the characteristics of size effect and other errors, and all errors are verified to be observable by piece-wise constant system method and singular value decomposition method. The self-calibration method is tested by simulations and experiments. The calibration repeatability of size-effect parameters is less than 0.15 cm, while other IMU errors reach higher calibration accuracy compared with traditional methods. Navigation experiments indicate that the sharply changing velocity errors are greatly corrected after compensation, and position and velocity accuracy have improved 30% and 70%, respectively, during 12-h navigation experiment. Therefore, the navigation performance of RINS could be further improved in both the short term and long term with the proposed self-calibration method.	experiment;inertial navigation system;observable;repeatability;rotation system;simulation;singular value decomposition;velocity (software development)	Pengyu Gao;Zengjun Liu;Tianxiao Song;Zengjun Liu	2018	IEEE Transactions on Industrial Electronics	10.1109/TIE.2017.2733491	control theory;gimbal;engineering;acceleration;repeatability;angular velocity;inertial reference unit;geodesy;inertial navigation system;accelerometer;inertial measurement unit	Robotics	57.541047360269864	-35.92760536329556	151501
878eb4ac1c4df9d6fb7e8b5d6f2d7d308deb6856	elevation moment of inertia: a new feature for monte carlo localization in outdoor environment with elevation map	elevation moment;emoi matching;monte carlo localization;proposed emoi;conventional range matching;reference map;pregiven reference elevation map;elevation map;outdoor environment;popular map;new feature;outdoor localization;range matching;moment of inertia	The elevation map is one of the most popular maps for outdoor navigation. We propose the elevation moment of inertia (EMOI), which represents the distribution of elevation around a robot in an elevation map, for use in the matching of elevation maps. Using this feature, outdoor localization can be performed with an elevation map without external positioning systems. In this research, the Monte Carlo localization (MCL) method is used for outdoor localization, and the conventional method is based on range matching, which compares range sensor data with the range data predicted from an elevation map. Our proposed method is based on EMOI matching. The EMOI around a robot is compared with the EMOIs for all cells of the pregiven reference elevation map to find a robot pose with respect to the reference map. MCL based on EMOI matching is very fast, although its accuracy is slightly lower than that of conventional range matching. To deal with the disadvantage of EMOI matching, an adaptive switching scheme between EMOI matching and range matching was also proposed. Various outdoor experiments indicated that the proposed EMOI significantly reduced the convergence time of MCL. Therefore, the proposed feature is considered to be useful when an elevation map is used for outdoor localization. C © 2010 Wiley Periodicals, Inc.	adaptive switching;approximation algorithm;computation;experiment;internationalization and localization;john d. wiley;macintosh common lisp;map matching;monte carlo localization;monte carlo method;norm (social);pattern matching;propagation of uncertainty;robot;software propagation;time complexity	Tae-Bum Kwon;Jae-Bok Song;Sang-Hyun Joo	2010	J. Field Robotics	10.1002/rob.20338	monte carlo localization;computer vision;simulation;chemistry;moment of inertia	Robotics	53.856538997214734	-37.93947066619061	151823
aa1396ff2cecab882c041156d19cfe237729f4b6	development of dgps guidance system for agricultural machinery	field test;chip;development tool;operating system;object oriented	The purpose of this research was to develop a kind of light bar parallel guidance system based on DGPS for small agriculture machinery. This system consists of field computer, light bar and DGPS. The field computer is developed using PC/104 CPU module, running on which the embedded realtime operation system was customized by a special development tool. Single chip and CAN controller was selected for guidance light bar design, which use a row of indicator LEDs to guide drivers. Field computer and guidance light bar communicate with each other by using CAN bus. The guidance software running on the field computer was designed in object-oriented manner by integrating embedded GIS development kit. Field-testing and experiments have been done to evaluate the accuracy of the system with Trimble AgGPS 132 under different speeds, application width and light bar sensitivity, and the average of offline distance was 0.4517 meter. Results show this kind of guidance system is suitable for small-size machinery and can meet the need for parallel swath guidance for different kinds of field operation.	can bus;central processing unit;computer;differential gps;embedded system;experiment;geographic information system;guidance system;online and offline;operating system;pc/104	Zhijun Meng;Wenqian Huang;Hui Liu;Liping Chen;Weiqiang Fu	2007		10.1007/978-0-387-77253-0_67	control engineering;embedded system;engineering;automotive engineering	Graphics	57.09224459606075	-30.187858830541618	151924
5b85c0d425b94f5157cfd7b6f6cb18e1449ab972	simultaneous arrival planning for multiple unmanned vehicles formation reconfiguration		This paper presents 3-D real-time simultaneous arrival planning for multiple unmanned vehicles formation reconfiguration. The unmanned vehicleu0027s physical constraints are considered. Moreover, the proposed method is adaptable to different configurations of initial and final velocities. The proposed algorithm consists of path generation and velocity planning. Path generation can produce a smooth and feasible path connecting the initial pose to the final pose for every vehicle. This generated path satisfies the minimum turning radius and pitch angle constraints. Velocity planning is designed to address tangent acceleration and velocity constraints such that unmanned vehicles reach their respective final poses simultaneously. Finally, the summary for the algorithm of simultaneous arrival is given. The numerical results demonstrate that the proposed method is effective while satisfies real-time performance.	unmanned aerial vehicle	Yu Wang;Shuo Wang;Min Tan;Junzhi Yu	2017	I. J. Robotics and Automation	10.2316/Journal.206.2017.4.206-4751	tangent;mathematics;control theory;acceleration;control engineering;control reconfiguration;turning radius;pitch angle	Robotics	56.79300611043046	-24.900745911639152	152165
94d3979a5d2d72d362930e06a5c4c98fc05a0713	real world application of a low-cost high-performance sensor system for autonomous mobile robots	sensor system;motion control;ultrasonic transducer arrays intelligent control mobile robots path planning motion control sensor fusion;path planning;mobile robots;field trial;autonomous mobile robot;intelligent control;sensor systems mobile robots ultrasonic transducer arrays costs sensor phenomena and characterization immune system navigation path planning composite materials colored noise;real world application;modular sensor system low cost high performance sensor system autonomous mobile robots constantly changing dynamic unstructured environments;sensor fusion;high performance;ultrasonic transducer arrays	"""Commercially successful autonomous mobile robot systems demand the development of new methodologies for dealing with """"real world"""" requirements of very low cost and very high performance sensing technology for use in the constantly changing, dynamic, unstructured environments in which society expects such robots to operate unsupervised on a daily basis. This paper presents a new modular sensor system which, based on long term real world field trials appear to meet the basic requirements. Examples of test results in a wide variety of applications in unstructured environments are provided as well as future directions. DESCRIPTION A major impediment in the development of commercially successful autonomous mobile robot systems has been the availability of a very low cost, yet very high performance sensor system. The incredible wealth of research on path planning and autonomous navigation architectures often assume either the presence of an """"ideal"""" sensor, or the performance of real sensors in highly constrained environments to which that specific sensor is well adapted (for example, environments with simple or solid polygonal obstacles constructed of vertical surfaces), Hence, the research is of limited value to the real world which is characterized by the ever increasing frequency of novel and extremely creative furniture design which due to material composition and oblique planes often creates severe difficulties for low cost sensors. Even one failure to detect such an object out of a thousand trials would deem the technology commercially unacceptable in real world unstructured environments. Sensors which approximate ideal performance are available at very high cost, but this is of limited value to the real world. To achieve the dramatically enhanced levels of """"human scale performance"""" demanded in the increasingly unstructured types of environments in which mobile robots are being required to operate, sensor systems must fulfill certain fundamental requirements which include: a) very low cost b) c) very high sensitivity d) e) very high immunity to ambient noise immunity to signal loss due to angle of incidence, material composition, colour immunity to cross-talk and multipath interference. In our evaluations, camera vision systems met all requirements except the first. However, since the ultimate aim of the research was commercial viability, this approach was abandoned. Similarly laser imagers fulfilled all but the first objective and was hence also discarded (note however, that both camera vision and laser systems continue to be a focus of our research). Conventional ultrasound techniques met the first requirement but required significant …"""	approximation algorithm;autonomous robot;catastrophic interference;crosstalk;emoticon;incidence matrix;interference (communication);mobile robot;motion planning;oblique projection;requirement;sensor;smart environment	V. P. Burhanpurkar	1994		10.1109/IROS.1994.407609	control engineering;motion control;mobile robot;embedded system;simulation;computer science;engineering;artificial intelligence;motion planning;sensor fusion;intelligent control	Robotics	55.63958090576902	-31.594330184696627	152263
848a101d2aa93594a7c29bcd06f8c06371b3d4e1	an operation-time simulation framework for uav swarm configuration and mission planning		In recent years, Unmanned Aerial Vehicles (UAV), have been increasingly utilized by both military and civilian organizations because they are less expensive, provide greater flexibilities and remove the need for on-board pilot support. Largely due to their utility and increased capabilities, in the near future, swarms of UAVs will replace single UAV use. Efficient control of swarms opens a set of new challenges, such as automatic UAV coordination, efficient swarm monitoring and dynamic mission planning. In this paper, we investigate the problem of dynamic mission planning for a UAV swarm. A centralized-distributed hybrid control framework is proposed for mission assignment and scheduling. The Dynamic Data Driven Application System (DDDAS) principles are applied to the framework so that it can adapt to the changing nature of the environment and the missions. A prototype simulation program is implemented as a proof-ofconcept of the framework. Experimentation with the framework suggests the effectiveness of swarm control for several mission planning mechanisms. © 2013 The Authors. Published by Elsevier B.V. Selection and/or peer-review under responsibility of the organizers of the 2013 International Conference on Computational Science	aerial photography;centralized computing;computation;computational science;dynamic data driven applications systems;on-board data handling;prototype;scheduling (computing);simulation;swarm;unmanned aerial vehicle	Yi Wei;M. Brian Blake;Gregory R. Madey	2013		10.1016/j.procs.2013.05.364	simulation;operations research	Robotics	55.811111085080206	-27.0423620982415	152473
463b2dbf62913d04cc28e48e9cbc357fa2371922	human-like adaptation of force and impedance in stable and unstable interactions	minimisation;feedforward neural network;torque;feedforward neural networks;impedance;feedforward;variable impedance actuators human like force adaptation human like impedance adaptation stable interactions unstable interactions human like learning controller instability minimization feedforward force conventional learning controllers joint torque controlled robots;stability actuators feedforward learning artificial intelligence minimisation service robots;service robots;actuators;feedforward force;force;stability;robotic control;dynamic environment;adaptation model;robot control;human motor control;robots;robotic control feedforward force human motor control impedance;force impedance robots humans feedforward neural networks torque adaptation model;humans;learning artificial intelligence;motor control	This paper presents a novel human-like learning controller to interact with unknown environments. Strictly derived from the minimization of instability, motion error, and effort, the controller compensates for the disturbance in the environment in interaction tasks by adapting feedforward force and impedance. In contrast with conventional learning controllers, the new controller can deal with unstable situations that are typical of tool use and gradually acquire a desired stability margin. Simulations show that this controller is a good model of human motor adaptation. Robotic implementations further demonstrate its capabilities to optimally adapt interaction with dynamic environments and humans in joint torque controlled robots and variable impedance actuators, without requiring interaction force sensing.	characteristic impedance;computer simulation;control theory;feedforward neural network;instability;interaction;nominal impedance;robot	Chenguang Yang;Ganesh Gowrishankar;Sami Haddadin;Sven Parusel;Alin Albu-Schäffer;Etienne Burdet	2011	IEEE Transactions on Robotics	10.1109/TRO.2011.2158251	control engineering;feedforward neural network;simulation;computer science;engineering;artificial intelligence;control theory	Robotics	62.8991077149292	-24.08966173383696	152552
b663d91017673189f594e5137fd06247d9709998	learning to predict resistive forces during robotic excavation	motion analysis;analytical models;soil robot sensing systems blades analytical models motion analysis sensor phenomena and characterization shape earth kinematics rain;excavators;robot sensing systems;soil removal;global regression;sensor phenomena and characterization;neural nets;earth;kinematics;learning systems;shape;materials handling;industrial robots;neural nets resistive force prediction robotic excavation learning systems soil removal global regression memory based learning;robots;rain;learning problems;blades;robotic excavation;force control robots industrial robots excavators learning systems neural nets materials handling;memory based learning;resistive force prediction;soil;analytical model;force control	with the world as excavation. In order to effectively plan its actions, our robot excavator requires a method that allows it to predict the resistive forces experienced as it scoops soil from the terrain. In this paper we present methods for a robot to predict the resistive forces and to improve its predictions based on experience. We start with a simple analytical model of a flat blade moving through soil and show how this analysis can be extended to account for the phenomena specific to excavation. In addition, we examine how representation of the learning problem and methodology affect prediction performance using several criteria.	approximation algorithm;artificial neural network;basis function;experience;justin (robot);requirement;robot;sparc;test set	Sanjiv Singh	1995		10.1109/ROBOT.1995.526025	excavator;robot;control engineering;kinematics;simulation;shape;computer science;engineering;artificial intelligence;control theory;earth;artificial neural network	Robotics	63.29913597751278	-27.814011766266898	152866
da1950ce286cd52aba7a87940d98939bc98dccea	dynamic modeling and computer simulation of 3d objects grasping		Among the essentials functionalities of several robotic systems are grasping and manipulating of objects by multi-fingered robot hands. Therefore many researchers have studied features of the two major closely related tasks. In this paper, we consider the problem of mathematical modeling of the robotic hand, the object and the physical interactions between the object and fingers under sliding constraints. Development of a numerical simulator for 3-D object grasping and manipulation by multi-fingered robot hands is an active area in robotic field. By integrating the derived Lagrange's equations of motion of the fingers and object under sliding constrains in the 3D simulator HandGrasp that is designed and developed at REGIM (Laboratory of REsearch Group on Intelligent Machine), numerical simulation results of 3-D object pinching and manipulation based on the impedance control law. This simulation results show the validity of mathematical modeling and the control method	computer simulation	Rim Boughdiri;Hala Bezine;Nacer K. M'Sirdi;Aziz Naamane;Adel M. Alimi	2012		10.1007/978-3-642-33941-7_26	control engineering;computer vision;simulation;computer science	Robotics	67.91875401909462	-27.437936730869357	152937
f8a76c424e2fd75d4377340b43e96ddfa24ece41	navigation and mobile security system of home security robot	multiinteraction system;usb web camera mobile security system home security robot intelligent security architecture image system multiinteraction system obstacle avoidance system intelligent automation robot system;image processing;obstacle avoidance system;intelligent robots;intelligent security architecture;mobile robots;motion;security system;home security robot;imaging system;image system;obstacle avoidance;interactive system;secure system;usb web camera;security architecture;security navigation mobile robots robotics and automation robot sensing systems intelligent robots intelligent sensors infrared sensors intelligent systems home automation;robot security system motion;collision avoidance;robot;interactive systems;intelligent automation robot system;mobile robots collision avoidance home automation image processing intelligent robots interactive systems;mobile security system;home automation	We have recently developed an intelligent security architecture in robot (ISR). Image system, security system, multi-interaction system and obstacle avoidance system can all communicate with each other through intelligent automation robot system (IA robot). We also discuss the modes and distance of obstacle avoidance that influence in the pathway of obstacle avoidance. In order to navigate IA robot to complete mission with obstacle avoidance system and security system by using IR sensors, and USB Web-camera installed in IA robot. Therefore, because the limitation of IR sensors and the action mode we have set, we have to choose a critical distance. When IA robot approaches an obstacle into this distance, ISR will start to avoid obstacle. We also provide seven kinds of functions installed on this IA robot to reach security service. We have successfully demonstrated the modes and distance of obstacle avoidance and the security system.	computer security;gene regulatory network;information systems research;mobile security;obstacle avoidance;robot;security service (telecommunication);sensor;usb;webcam	Ren C. Luo;Po Kai Wang;Yu Feng Tseng;Tung-Yi Lin	2006	2006 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2006.384377	robot;mobile robot;embedded system;home automation;computer vision;simulation;image processing;computer science;artificial intelligence;social robot;motion;robot control;obstacle avoidance;enterprise information security architecture	Robotics	58.072795659967696	-31.05360104215251	153091
0e3bf215725372f3263c90b4a32d37c6b9c0d322	onboard autonomy on the intelligent payload experiment cubesat mission		The Intelligent Payload Experiment (IPEX) is a CubeSat that flew from December 2013 through January 2015 and validated autonomous operations for onboard instrument processing and product generation for the Intelligent Payload Module of the Hyperspectral Infrared Imager (HyspIRI) mission concept. IPEX used several artificial intelligence technologies. First, IPEX used machine learning and computer vision in its onboard processing. IPEX used machine-learned random decision forests to classify images onboard (to downlink classification maps) and computer vision visual salience software to extract interesting regions for downlink in acquired imagery. Second, IPEX flew the Continuous Activity Scheduler Planner Execution and Re-planner AI planner/scheduler onboard to enable IPEX operations to replan to best use spacecraft resources such as file storage, CPU, power, and downlink bandwidth. First, the ground and flight operations concept for proposed HyspIRI IPM operations is described, followed by a description ...		Steve A. Chien;Joshua Doubleday;David R. Thompson;Kiri Wagstaff;John Bellardo;Craig L Francis;Eric Baumgarten;Austin Williams;Edmund Yee;Eric T. Stanton;Jordi Piug-Suari	2017	J. Aerospace Inf. Sys.	10.2514/1.I010386	embedded system;simulation;engineering	AI	56.08375046248533	-29.081111416780086	153427
12cbbab0633def82875a644a699ed7cbc2af6257	recognizing and handling articulated objects in robotic tasks		The paper presents a model and an algorithm for recognizing and handling articulated objects using industrial robots. The model is based on the skeleton of the object and it is used for recognition and to associate multiple grasping positions for robot handling. The object skeleton is a shape descriptor which preserves the topology of the object, even if the shape is changing. The model can associate multiple grasping positions in order that a robot system to be able to handle the object, multiple grasping positions are required because in the case of articulated objects the grasping positions can be invalidated by the object itself, depending on the configuration of the articulations. The solution can be implemented on robot systems with integrated vision and computing resources or on a PC, like the programming workstations connected to the vision system and to the robot, also a cloud computing solution can be used.	algorithm;cloud computing;industrial robot;shape context;workstation	Silvia Anton;Florin Daniel Anton	2017	2017 40th International Conference on Telecommunications and Signal Processing (TSP)	10.1109/TSP.2017.8076070	robot;skeleton (computer programming);articulated robot;machine vision;cloud computing;computer science;computer vision;artificial intelligence	Robotics	59.42709728026543	-31.365828447427212	153708
de16eb52440b6796684e5a2b2504cf642bc0b417	adaptive visual-force control in unknown workspaces	autocalibration;info eu repo semantics bookpart;image based control;force control	This paper proposes the definition of a new adaptive system that combines visual and force information. At each moment, the proportion of information used from each sensor is variable depending on the adequacy of each sensor to control the task. The sensorial information obtained is processed to allow the use of both sensors for controlling the robot and avoiding situations in which the control actions are contradictory. Although the visual servoing systems have certain robustness with respect to calibration errors, when the image-based control systems are combined with force control we must accurately know the intrinsic parameters. For this purpose an adaptive approach is proposed which updates the intrinsic parameters during the task.	adaptive system;camera resectioning;control system;glr parser;robot;sensor;visual servoing;workspace	Jorge Pomares;Fernando Torres Medina;Laura Payá	2005			control engineering;simulation;computer science;control theory	Robotics	60.9463153448195	-31.83456892327233	154022
6c30f969ee9e1169623340aa409f539fddb9c413	active stereo vision-based mobile robot navigation for person tracking	robot motion;target tracking method;robot motion controller;person tracking;target dynamic;mobile robot navigation;robot platform;target destination;mobile robot architecture;active stereo vision module;hybrid navigation algorithm;stereo vision	In this paper, we propose a mobile robot architecture for person tracking, consisting of an active stereo vision module (ASVM) and a navigation module (NM). The first tracks the person in stereo images and controls the pan/tilt unit to keep the target in the visual field. Its output, i.e. the 3D position of the person, is fed to the NM, which drives the robot towards the target while avoiding obstacles. As a peculiarity of the system, there is no feedback from the NM or the robot motion controller (RMC) to the ASVM. While this imparts flexibility in combining the ASVM with a wide range of robot platforms, it puts considerable strain on the ASVM. Indeed, besides the changes in the target dynamics, it has to cope with the robot motion during obstacle avoidance. These disturbances are accommodated by generating target location hypotheses in an efficient manner. Robustness against outliers and occlusions is achieved by employing a multi-hypothesis tracking method the particle filter based on a color model of the target. Moreover, to deal with illumination changes, the system adaptively updates the color model of the target. The main contributions of this paper lie in (1) devising a stereo, color-based target tracking method using the stereo geometry constraint and (2) integrating it with a robotic agent in a loosely coupled manner.	automotive navigation system;image plane;loose coupling;missile guidance;mobile robot;motion controller;obstacle avoidance;pid;particle filter;reverse monte carlo;robotic mapping;stereopsis;system dynamics	Valentin Enescu;Geert De Cubber;Kenny Cauwerts;Sid Ahmed Berrabah;Hichem Sahli;Marnix Nuttin	2005	Integrated Computer-Aided Engineering		mobile robot;computer vision;tracking system;mobile robot navigation	Robotics	59.05823775402095	-30.8845373778177	154230
26b15f6a60f8a0617728e54a244df6604a4a4e7e	dynamic programming algorithm based path planning of the multiple robot system	computers;dynamic programming;robot sensing systems;obstacle detection;mobile robots computers heuristic algorithms robot sensing systems trajectory compass;mobile robot;user interface;path planning;dynamic programming algorithm;mobile robots;dc motor;compass module;multiple mobile robots;size 15 cm dynamic programming algorithm path planning mobile robots target position unknown environment minimum displacement technique supervised computer mcs 51 microchip keil c language program controller module dc motor driver obstacle detection module voice module wireless rf module encoder module compass module orientation error moving distance compensation user interface multiple mobile robot system wireless rf interface size 10 cm;trajectory;optimal path;position control;minimum distance;heuristic algorithms;user interfaces compasses control engineering computing dynamic programming mobile robots multi robot systems path planning position control radiocommunication;multi robot systems;compass module path planning multiple mobile robots dynamic programming algorithm;control engineering computing;radiocommunication;compass;user interfaces;heuristic algorithm;compasses	The article researChed the path planning of the multiple mobile robots moving to the target position in the unknown environment, and used the dynamic programming algorithm to solve the minimum displacement techniques on the supervised computer. The mobile robot has the shape of cyLinder and its diameter, height and weight is 10cm, 15cm and 1.5kg. The controller of the mobile robot is MCS-51 microchip, and programs Keil-C language to control the mobile robot. The mobile robot contains a controller module (including two DC motor drivers), an obstacle detection module, a voice module, a wireless RF module, an encoder module, and a compass module. The mobile robot can modify the error of the orientation using the compass module, and uses encoder module to calculate and compensate the moving distance. We design the user interface of the multiple mobile robot system, and search the minimum distance using the proposed method on the experimental platform. In the experimental results, mobile robots can receive the command from the supervised computer via wireless RF interface, and move to the unknown target position, and find the optimal path on the many times test according to the proposed algorithm.	algorithm;communications protocol;cylinder seal;displacement mapping;dynamic programming;encoder;integrated circuit;intel mcs-51;mobile robot;motion planning;radio frequency;user interface	Ting-Li Chien;Hsin-Chou Lai;Yung-Chien Lin;Yung-Chin Lin	2011	2011 Second International Conference on Digital Manufacturing & Automation	10.1109/ICDMA.2011.121	control engineering;embedded system;simulation;computer science;mobile robot navigation	Robotics	57.30467040402188	-32.585631898368696	154345
16c8a8d0255958fd2a757cccb8e030057fb875fd	in-pipe robot for inspection and sampling tasks	vision system;sistema mecanico;tratamiento desperdicios;concepcion ingenieria;multiagent system;engineering design;traitement dechet;guidage;systeme vision;piping;pipe;agua residual;conception ingenierie;analyse fonctionnelle;echantillonnage;compact design;concepcion compacta;manipulateur;elimination dechet;eliminacion residuo;waste disposal;roue;robotics;systeme mecanique;rueda;guiado;conduite horizontale;inspection;eau usee;caneria;sampling;manipulador;horizontal pipe;functional analysis;conception compacte;canalizacion;traction;mechanical system;waste water;controle qualite;tuyauterie;robotica;traccion;guidance;canalisation;waste treatment;robotique;pipes;sampling methods;muestreo;sistema multiagente;quality control;wheel;robot;manipulator;structural design;sistema vision;conducto horizontal;control calidad;systeme multiagent;design methodology;analisis funcional	Purpose – To develop an in‐pipe robot to be used for inspecting pipes that are laid underneath a waste disposal site and for sampling sewage water leaking from holes around the pipe.Design/methodology/approach – The paper presents a compact design of the robot's mechanical and electronic systems, and develops a simple and practical method for determining the hole position using some characteristics of this in‐pipe robot.Findings – Development of a multi‐functional in‐pipe robot with elaborate design is feasible, and multiple trapezoidal‐shaped wheels have good capabilities of providing the robot large traction force and keeping the robot horizontal in pipeline. A good mechanical structure design can greatly reduce control and computation cost by using some specific features of the object system.Research limitations/implications – This study provides guidance for future design of multi‐functional in‐pipe robots.Practical implications – The combination of a vision system and a manipulator can perform in‐pip...	robot;sampling (signal processing)	Chi Zhu	2007	Industrial Robot	10.1108/01439910710718432	functional analysis;sampling;simulation;computer science;engineering;artificial intelligence;robotics;mechanical engineering	Robotics	64.55908802365839	-32.84264814573413	154876
242b24b232ea314ecdfcc8dbf0afbc0703711b2f	visual tracking and grasping of a dynamic object: from the human example to an autonomous robotic system		In this thesis a robotic hand-eye system capable of visual tracking of a moving object and reaching out to grasp this object using a robotic manipulator is described. A noticeable number of successful methods performing those tasks has been published (also recently) and impressive demonstrations have been shown thereby. Nevertheless, there is still one system that is superior to all the demonstrated ones: the human. Humans perform catching tasks with a high degree of accuracy, robustness and flexibility. Therefore this thesis investigates results of neuroscience and applies them to design a robotic hand-eye system for grasping a moving object. From the experimental data of human catching movements it can be derived that humans are performing different subtasks during catching: tracking of the target object, prediction of the future target trajectory, determination of an interaction point in space and time, and execution of an interceptive arm movement. Thereby the different subtasks are performed in parallel and the coordination between “hand and eye” is reactive: the human can easily adapt and correct its interceptive movement triggered either by (sudden) changes in the targets trajectory or by refinement of the predicted object trajectory and the hand-target interaction point. Transferring knowledge gained by the neuroscientists to robotics is often difficult since the underlying physical systems are very different. Nevertheless there exist interesting models or experimental data that offer the possibility of transfer. In this thesis for two of the above noticed subtasks biological concepts are deployed: for visual tracking and for the execution and timing of the interceptive catching movement. For the tracking subtask the used visual sensors are closely related to those found in the human brain: Form, color and motion (optic flow). Through analysis of human visual processing from the eye up to the visual cortex three main concepts could be separated: parallel information flow, pre-attentive processing and reentry of information. These mechanism allow the human the optimal utilization of the presented information before attention is put on a certain stimulus. This can be seen as a form of image pre-processing. Integrating those concepts in a robotic hand-eye system improves image pre-processing for still images as well as in a tracking task noticeable. For the determination of hand-target interaction points and the timing of the arm movement relative to the target motion a human-like behavior is adopted. Based on experimental data a four phasic model for the determination of interaction points and the generation	autonomous robot;digital pet;existential quantification;humans;optical flow;preprocessor;refinement (computing);sensor;video tracking	Michael Sorg	2003			computer vision;eye tracking;artificial intelligence;computer science	Robotics	61.898639027441675	-33.08901649865453	155305
42bd0d82204d66c1421844e87f5924cc433cae49	a visuo-tactile control framework for manipulation and exploration of unknown objects	grasping;visual servoing dexterous manipulators grippers haptic interfaces hierarchical systems pose estimation robot vision robust control tactile sensors;force;force tactile sensors visualization grasping shape;visualization;shape;tactile sensors;visuo tactile control framework sensitive fingertip kuka lwr arms high level fingertip motion commands object pose controls blind surface exploration skills joint level layer visual servoing layer tactile servoing layer object surface exploration in hand manipulation online grasp optimization robust grasping robust unknown object exploration robust unknown object manipulation tactile servoing approach visual servoing approach hierarchical control framework	"""We present a novel hierarchical control framework that unifies our previous work on tactile-servoing with visual-servoing approaches to allow for robust manipulation and exploration of unknown objects, including - but not limited to - robust grasping, online grasp optimization, in-hand manipulation, and exploration of object surfaces. The framework is divided into three layers: a joint-level layer, a tactile servoing layer, and a visual servoing layer. While the middle layer provides """"blind"""" surface exploration skills, maintaining desired contact patterns, the visual layer monitors and controls the actual object pose providing high-level fingertip motion commands that are merged with the tactile-servoing control commands. We illustrate the versatility of the proposed framework using a series of manipulation actions performed with two KUKA LWR arms equipped with a tactile sensor array as a """"sensitive fingertip"""". The two considered objects are unknown to the robot, i.e. neither shape nor friction properties are available."""	coat of arms;high- and low-level;mathematical optimization;robot;tactile sensor;visual servoing	Qiang Li;Robert Haschke;Helge J. Ritter	2015	2015 IEEE-RAS 15th International Conference on Humanoid Robots (Humanoids)	10.1109/HUMANOIDS.2015.7363434	computer vision;simulation;visualization;shape;computer science;visual servoing;force;tactile sensor	Robotics	64.2232968747239	-25.689249609680463	155438
500d9819d03a95c9ecd027e834010525978c051a	the analysis of human walking stability using zmp in sagittal plane		This paper investigates the difference of walking stability between the young and the elderly by using the method of zero moment point(ZMP) in sagittal plane. 3 young subjects and 3 elderly subjects participated in free walking experiment in a straight line on level ground. Motion capture system was used to collect the experimental data of lower limbs movement while walking. Experimental results show that in the comparison between young and elderly, there are some effective walking stability parameters, specifically including the horizontal distance (δZmp) between ZMP and the center of mass of body, the horizontal distance (δankie) between ZMP and the ankle joint, the linear relationship between δZMP and gait speed, and the trajectories of ZMP in ground plane. These parameter criteria can be used to analyze dynamic walking stability for guiding the development of walking assistance devices.	motion capture;zero moment point	Shizhen Meng;Shanhai Jin;Junqiang Li;Kazunobu Hashimoto;Shijie Guo;Shijie Dai	2017	2017 IEEE International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM)	10.1109/ICCIS.2017.8274826	engineering;center of mass;experimental data;line (geometry);control theory;ground plane;ankle;sagittal plane;gait;zero moment point	Robotics	67.45284594238724	-24.70115407316977	155648
4bc367440b393843e9610ba37a56aa7939312ad0	real-time monitoring and diagnosing of robotic assembly with self-organizing neural maps	torque;robot sensing systems;topology;flexible manufacturing systems;force sensors;computerised control;real time diagnosis;real time;self organising feature maps assembling computerised control computerised monitoring industrial robots real time systems;real time monitoring;dynamic assembly processes real time monitoring real time diagnosis robotic assembly self organizing neural maps real time execution monitoring;dynamic assembly processes;time factors;monitoring;self organising feature maps;assembling;industrial robots;monitoring robotic assembly robot sensing systems time factors topology tactile sensors force sensors torque robot vision systems flexible manufacturing systems;tactile sensors;self organization;robotic assembly;self organized map;computerised monitoring;robot vision systems;real time execution monitoring;self organizing neural maps;neural network;real time systems	An application of self-organizing neural-network maps is presented for real-time execution monitoring and diagnosing of robotic assembly. The self-organizing maps not only have the ability to spontaneously react to changes in dynamic assembly processes, but also to offer simplicity and feasibility for organizing diverse assembly interactions between tools, parts, robot, and sensory data. A number of different types of multidimensional maps are described for various combinations of assembly interactions. >	map;organizing (structure);real-time transcription;robot;self-organization	A. Syed;Hoda A. ElMaraghy;N. Chagneux	1992		10.1109/REAL.1992.242653	computer vision;real-time computing;self-organization;simulation;computer science;torque;artificial neural network;tactile sensor	Robotics	62.110525634156275	-27.530202476297156	155733
555f8380e919b45a04a0ae1f4ff2bf930487c1ef	sonar-based guidance of unmanned underwater vehicles	acoustics;motion estimation;unmanned underwater vehicle;guidance;control;guidance and control;finite state machine;coordination	This paper addresses the problem of the design and coordination of guidance and sonarbased motion estimation algorithms for unmanned underwater vehicles. In the framework of a two-layered hierarchical architecture uncoupling the system's dynamics and kinematics, a couple of guidance laws for approaching a target with the desired orientation and following an environmental feature have been designed with Lyapunov-based techniques. Suitable acoustic-based estimators of the corresponding operational variables have been designed and integrated with the guidance and control system. A finite state machine combined with a suitable interface for event generation allows the coordinated execution of basic guidance and motion estimation tasks to carry out more complex functions. Experimental results of pool trials of a prototype unmanned underwater vehicle executing free-space maneuvering, wall-following tasks and the more complex mission of following the perimeter of the trial pool are reported and discussed.	sonar;unmanned aerial vehicle	Massimo Caccia;Gabriele Bruzzone;Gianmarco Veruggio	2001	Advanced Robotics	10.1163/156855301317033568	control engineering;computer vision;simulation;computer science;engineering;motion estimation;finite-state machine;scientific control	Robotics	57.61296471023716	-26.071890179669392	155749
87cf18c1f4545e456380a226123698d1d7b618fd	virtual model for a multi-finger robot hand design	virtual model;fingers motion planning virtual model multifinger robot hand design actuator virtual prototyping robot control system distributed control system servo control node i2c network 3d model mechanical design dynamics behavior control software motor drive system robot performance software design hardware design rapid prototyping mechanical component embedded system code generation man machine gui interface communication protocol off line simulation tool control interface;grasping;motor drives;rapid prototyping industrial;robot hand;path planning;virtual reality;actuators;virtual reality control engineering computing dexterous manipulators distributed control embedded systems graphical user interfaces motor drives path planning rapid prototyping industrial robot dynamics servomechanisms solid modelling virtual prototyping;joints;thumb;dexterous manipulators;embedded systems;virtual prototyping;graphical user interfaces;robots thumb solid modeling joints grasping actuators;servomechanisms;solid modeling;robots;control;control engineering computing;robot dynamics;distributed control;control robot hand virtual model;solid modelling	A robot hand with 10 actuators and 14 joints are developed using the virtual prototyping approach. The control system of the robot hand is a distributed control system with 10 servo control nodes connected by an I2C network. A virtual model based on the 3D model from the mechanical design is extended to include the dynamics behaviors of control software and the motor drive systems to provide a platform to predict the performance of the robot hand before production. After finalize the software and hardware design, the same model is used to rapid prototyping the mechanical components and also for embedded system code generation at the implementation phase. With the addition of man-machine GUI interface and the communication protocol, this same virtual model is adopted again to provide an off-line simulation tool and an intuitive control interface for the fingers motion planning.	3d modeling;code generation (compiler);communications protocol;computer-aided design;control function (econometrics);distributed control system;eeprom;embedded system;finalize (optical discs);grams;graphical user interface;mechatronics;microcontroller;motion planning;online and offline;programming tool;rapid prototyping;service robot;servo;simulation	Chwan Hsen Chen	2012	2012 Fourth International Conference on Computational Intelligence, Communication Systems and Networks	10.1109/CICSyN.2012.41	robot;embedded system;simulation;computer science;artificial intelligence;graphical user interface;motion planning;virtual reality;solid modeling;scientific control;actuator	Robotics	67.04310521551476	-27.43201013910894	155835
3176c86a550137d0c7fb9f36451fc38393c541a7	myrio based mobile robot for rescue competitions		Labview and National Instruments hardware is used to measure, analyze and solve multiple Industry problems, mostly in small mechatronics systems or fixed manipulators. myRIO have been used worldwide in the last few years to provide a reliable data acquisition. While in Industry and in Universities myRIO is vastly used, Arduino is still the most common tool for hobby or student based projects, therefore Mobile Robotics platforms integrate Arduino more often than myRIO. In this study, an overall hardware description will be presented, together with the software designed for autonomous and remote navigation in unknown scenarios. The designed robot was used in EuroSkills 2016 competition in Sweden.	arduino;autonomous robot;data acquisition;labview;mechatronics;mobile robot;myrio;robotics	Tiago Caldeira;Hamad Al Remeithi;Ibrahim Al Raeesi	2017	2017 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC)	10.1109/ICARSC.2017.7964071	software;robot;embedded system;arduino;mobile robot;data acquisition;mobile telephony;robotics;artificial intelligence;computer science;mechatronics	Robotics	63.42936663193072	-29.26729552642405	155922
6d867205453f798cbbe2809733c7a5fd8cd6402e	an innovative decentralized strategy for i-auvs cooperative manipulation tasks	cooperative mobile manipulation;intervention autonomous underwater vehicle;decentralized control strategy;potential field method;underwater robotics	In the last years, a challenging field of autonomous robotics is represented by cooperative mobile manipulation carried out in different environments (aerial, terrestrial and underwater environment). As regards cooperative manipulation of Intervention-Autonomous Underwater Vehicles (I-AUVs), this application is characterized by a more complex environment of work, compared to the terrestrial or aerial ones, both due to different technological problems, e.g. localization and communication in underwater environment. However, the use of Autonomous Underwater Vehicle (AUV) and I-AUV will necessarily grow up in the future exploration of the sea. Particularly, cooperative I-AUVs represent the natural evolution of single centralized I-AUV because they may be used in various underwater assembly tasks, such as complex underwater structure construction andmaintenance (e.g. underwater pipeline and cable transportation can be carried out by multiple cooperative I-AUVs). Furthermore, underwater search and rescue tasks could be more efficient and effective if multiple I-AUVs were used. In this paper, the authors propose an innovative decentralized approach for cooperative mobile manipulation of I-AUVs. This decentralized strategy is based on a different use of potential field method; in particular, a multi-layer control structure is developed to in parallel manage the coordination of the swarm, the guidance and navigation of the I-AUVs and the manipulation task. The main advantage of the potential field method is that less information is necessary: navigation and control problems are reduced to the evaluation of the distance vector among the vehicles, object and obstacles. Moreover, because of the technological problems caused by the underwater environment, the reduction of the transmitted data is one of the keypoints of this architecture. In MATLAB R -Simulink R , the authors have simulated a transportation task of a partially known object along a reference trajectory in an unknown environment, where some obstacles are placed. The task is performed by an I-AUV swarm composed of four vehicles, each one provided of a 7 Degrees Of Freedom (DOFs) robotic arm. © 2015 Elsevier B.V. All rights reserved. ∗ Corresponding author at: University of Florence, Department of Industrial Engineering (DIEF), Via di Santa Marta 3, 50139-Florence, Italy. E-mail address: roberto.conti@unifi.it (R. Conti). 1 www.isme.unige.it http://dx.doi.org/10.1016/j.robot.2015.06.006 0921-8890/© 2015 Elsevier B.V. All rights reserved.	acoustic cryptanalysis;aerial photography;autonomous robot;centralized computing;computer simulation;control flow;control theory;distance-vector routing protocol;download;genetic algorithm;harbour project;industrial engineering;interaction;layer (electronics);matlab;master data management;mobile manipulator;modem;network packet;numerical analysis;performance;robotic arm;robotics;sensor;simulink;swarm;terrestrial television	Roberto Conti;Enrico Meli;Alessandro Ridolfi;Benedetto Allotta	2015	Robotics and Autonomous Systems	10.1016/j.robot.2015.06.006	simulation	Robotics	56.83044020891724	-27.121135005584456	155948
9b74310b8c297832ed12141ea905c27cd816e2fb	estimation of the absolute position of mobile systems by an optoelectronic processor	simulation ordinateur;navegacion;robot movil;evaluation performance;position control computer vision computerised navigation hough transforms mobile robots optoelectronic devices;optoelectronic devices;estimacion;position;performance evaluation;position sensing;evaluacion prestacion;point spread functions;calcul erreur;navigation circular landmark analysis position control machine vision mobile systems optoelectronic processor tv camera optical hough transform;image;posicion;information positionnelle;mobile robots;robotics;transformacion hough;informacion posicional;experimental result;television cameras;computer vision;algorithme;algorithm;error analysis;sensitivity;position location;navigation;optoelectronic device;robot mobile;estimation;position control;imagen;point spread function;fast algorithm;computerized simulation;position estimation;resultado experimental;robotica;calculo error;hough transforms;high speed optical techniques mobile computing tv cameras shape robustness data mining coprocessors estimation error performance analysis;hough transformation;positional information;procesador;hough transform;transformation hough;robotique;simulacion computadora;dispositif optoelectronique;processeur;mobile systems;resultat experimental;robot dynamics;computer simulation;high speed;processor;dispositivo optoelectronico;moving robot;algoritmo;computerised navigation	AbstrucfA method that determines the absolute position of a mobile system with a hybrid optoelectronic processor has been developed. Position estimates are based on an analysis of circular landmarks that are detected by a TV camera attached to the mobile system. The difference between the known shape of the landmark and its image provides the information needed to determine the absolute position of the mobile system. For robust operation, the parameters of the landmark image are extracted at high speeds using an optical processor that performs an optical Hough transform. The coordinates of the mobile system are computed from these parameters in a digital co-processor using fast algorithms. Different sources of position estimation errors have also been analyzed, and consequent algorithms to improve the navigation performance of the mobile system have been developed and evaluated by both computer simulation and experiments.	algorithm;computer simulation;coprocessor;experiment;hough transform;optical computing;time complexity	Liqiang Feng;Yeshaiahu Fainman;Yoram Koren	1992	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.179835	computer simulation;hough transform;embedded system;computer vision;simulation;computer science;robotics	Robotics	57.925875853629414	-33.84202582530457	156022
4f76445aff547f7465ad47313e316071625435a2	global path planning for robust visual servoing in complex environments	robot sensing systems;path planning;joints;satisfiability;orbital robotics;search trees;robot arm;feedback;trajectory;space use;field of view;robustness;collision avoidance;path planning robustness visual servoing cameras robot vision systems robot sensing systems trajectory orbital robotics feedback robotics and automation;visual servoing;robot vision systems;robotics and automation;cameras;robot kinematics	We incorporate sampling-based global path planning with Visual Servoing (VS) for a robotic arm equipped with an in-hand camera. The path planning accounts for a number of constraints: 1) maintaining continuous visibility of the target within the camera's field of view, 2) avoiding visual occlusion of target features caused by the workspace obstacles, robot's body, or the target itself, 3) avoiding collision with physical obstacles or self collision, and 4) joint limits. Incorporating these constraints enhances the applicability of VS to significantly more complex environments/tasks, thereby making the resulting VS much more robust. The proposed planner explores the camera space, i.e. 3D Cartesian space, for permissible camera paths satisfying the aforementioned constraints by iteratively extending a search tree in camera space and simultaneously tracking these paths in the robot's joint space using a local planner. The planned camera path is then projected into the image space and tracked using an image-based visual servoing scheme. The validity and effectiveness of the proposed approach in accomplishing VS tasks in complex environments are demonstrated through a number of simulations on a 6-dof robot arm moving among obstacles.	camera matrix;motion planning;real-time clock;robot;robotic arm;strips;sampling (signal processing);search tree;servo;simulation;visual servoing;workspace	Moslem Kazemi;Kamal K. Gupta;Mehran Mehrandezh	2009	2009 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2009.5152453	control engineering;computer vision;camera auto-calibration;simulation;robotic arm;field of view;computer science;artificial intelligence;trajectory;feedback;motion planning;visual servoing;robot kinematics;robustness;satisfiability	Robotics	60.10958169004581	-31.990761783025967	156256
4b02e01a7dbf2c60d9d24fe6fa49549d30956b5b	biomimetic control of pan-tilt-zoom camera for visual tracking based-on an autonomous helicopter	tracking aerospace robotics aircraft control cameras helicopters mobile robots motion compensation motion control robot vision;pan tilt zoom camera;aircraft control;motion control;motion compensation;pan tilt zoom;mobile robots;biomimetic control;system performance;deflection compensation pan tilt zoom camera visual tracking autonomous helicopter active camera object tracking vibration image stabilization biomimetic oculomotor control model physiological neural path eye movement control simulation experiments flight tracking experiments;autonomous helicopter;deflection compensation;robot vision;image stabilization;physiological neural path;vibration;eye movement control;eye movement;flight tracking experiments;aerospace robotics;object tracking;biomimetics helicopters control systems automatic control intelligent robots robot vision systems target tracking humans smart cameras robotics and automation;oculomotor;biomimetic oculomotor control model;active camera;visual tracking;helicopters;cameras;control strategy;simulation experiments;tracking;model simulation;autonomous helicopter biomimetic control pan tilt zoom camera visual tracking	A novel control strategy of pan-tilt-zoom camera is described. Because the active camera is mounted on a moving autonomous helicopter in visual tracking system, and the tracked object is moving at same time, and there exists the vibration influence of the helicopter, image stabilization becomes poor, and all pixels are running. Therefore, a biomimetic control strategy of on-board pan-tilt-zoom camera is presented. In this paper, the biomimetic oculomotor control model is obtained based on physiological neural path of eye movement control. In order to validate the functions of the biomimetic control model, simulation experiments were done under the same condition as the physiological experiments in physiological researches. Then the biomimetic controller of onboard pan-tilt-zoom camera is developed. The results of flight tracking experiments show that the biomimetic controller can compensate the deflection caused by the flight platform, and enhance the visual tracking system performance.	autonomous robot;biomimetics;control theory;emoticon;experiment;on-board data handling;pan–tilt–zoom camera;pixel;simulation;tracking system;video tracking	Shaorong Xie;Jun Luo;Zhenbang Gong;Wei Ding;Hairong Zou;Xiangguo Fu	2007	2007 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2007.4399295	control engineering;motion control;mobile robot;computer vision;simulation;eye tracking;computer science;engineering;vibration;video tracking;computer performance;tracking;motion compensation;image stabilization;eye movement	Robotics	60.44531238387383	-32.1093406029024	156337
c88d112b5f872d83257cc039ca6cba7a8790e648	localization method for mobile robots moving on stairs in multi-floor environments	wheels mobile robots motion control particle filtering numerical methods;robot kinematics mobile robots robot sensing systems navigation elevators;caterpillar wheels mobile robots localization method multifloor environments grid based map robot surroundings interfloor map stairs data interfloor localizations particle filter method coordinate system multifloor office spaces	This paper presents about the localization technology to estimate the positions of the mobile robot that is able to navigate through the multi-floor spaces, for expanding the application ranges of the robots. For this purpose, the mobile robots can use some maps having some information about the spaces in advance. In this paper, the maps are divided into two types according to the application; as to one, it is the grid-based map that represents the locations and the structures of objects in the robot surroundings with each floor. The other is the inter-floor map containing the stairs data to help the robot move into other floors. And the localization method is consisted of the floor and the inter-floor localizations. The floor localization uses the particle filter method to estimate the robot position in each floor. And the inter-floor localization can help the robot safely move to other floors by recognizing the stairs and change the coordinate system. Finally we performed the experiments in the multi-floor office spaces to verify the effectiveness of the proposed localization method by using the robot with the caterpillar wheels and the maps.	algorithm;experiment;map;mobile robot;particle filter;wheels	Yu-Cheol Lee;Seunghwan Park	2014	2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2014.6974559	mobile robot;computer vision;simulation;robot control	Robotics	54.326524968577054	-34.18325889647133	156566
c3a334edffceea37ebb38455a87e6735b979d632	handling uncertainty due to the delay between complex sensing and manipulation in an industrial workcell	timing model;industrial robots;dynamic manipulation	In this paper, we propose a generic method to model the dynamic intercept and manipulation capability of vision-based industrial robot systems. In order to verify the method, we present experiments using our industrial workcell prototype to dynamically intercept and manipulate semi-randomly moving objects.	industrial pc	Yanfei Liu;Adam W. Hoover;Ian D. Walker	2006	Robotica	10.1017/S0263574706002864	control engineering;simulation;engineering;manufacturing engineering	Robotics	64.57021620650653	-28.331463345210164	156729
2276792d4546b134e9675daf13a4a917d5a79e8d	safe navigation on hazardous terrain	safe navigation;mobile robot;pioneer all terrain rover;path planning;real time;field test;proceedings;robot navigation;mobile robots;steering commands;fuzzy logic navigation algorithms safe navigation autonomous navigation field mobile robots hazardous natural terrain terrain traversability seek goal behaviour traverse terrain behaviour avoid obstacle behaviour weighting factors steering commands speed commands fuzzy logic rules on board traversability analysis pioneer all terrain rover real time capabilities terrain assessment;cmos image sensors;fuzzy logic;navigation robot kinematics mobile robots testing fuzzy logic propulsion laboratories nasa mars planets;robot vision;terrain assessment;a priori information;autonomous navigation;terrain classification;speed commands;cmos image sensors mobile robots path planning fuzzy logic robot vision	This pap erpresents a n e w strategy f o r autonomous navigation of field mobile robots o n hazardous natural t e r r a i n using a f u z z y l q i c approach and a novel m a sure of terra in traversability T h e navigation strategy i s comprised of three simple, independent behaviors: seek-goal, traverse-terrain, and avoid-obstacle. T h e recommendat ions from thest: three behaviors are combine d through appropriate weighting fac tors t o generate t h e f inal steering and speed c o m m a n d s tha t are e x e c u t e d by the arbot. T h e weighting fac tors are produc edby f u z z y lo gicrules tha t take i n t o account t h e c u r r e n t s ta tus of t h e wbot. T h i s navigation strategy requir es n o a pr ior i in form a t ion about the environm e n t , and uses the on-board traversability analysis t o enable t h e robot t o select relatively easy-to-tr averse p a t h s autonomously . Field test results obtained from implementa t ion o f t h e proposed algorithms o n the commercial Pioneer A T r o v e r a r e presented. T h e s e results demonstrate t h e r e d t i m e cap abilities of t h e terra in assessment and f u z z y logic navigation algor i thms .	algorithm;artificial intelligence;autonomous robot;fly-by-wire;mobile robot;on-board data handling;pr/sm;traverse	Ayanna M. Howard;Homayoun Seraji;Edward Tunstel	2001		10.1109/ROBOT.2001.933091	control engineering;mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence;mobile robot navigation	Robotics	54.922619985962896	-30.650218556632307	156793
aa005f92550d5ff1e4fc4114d112242872943896	sweeping a terrain by collaborative aerial vehicles	sensors;coordinated motion planning;mobile guards	Mountainous regions are typically hard to access by land; because of this, search operations in hilly terrains are often performed by airborne force such as Unmanned Aerial Vehicles (UAVs). We give algorithms for motion planning and coordination for a team of UAVs under various assumptions on the vehicles equipage/capabilities and present outputs of an implementation of the algorithms.	aerial photography;airborne ranger;algorithm;diagram;mathematical optimization;motion planning;np-hardness;optimization problem;situated;time complexity;unmanned aerial vehicle;yet another	Alon Efrat;Mikko Nikkilä;Valentin Polishchuk	2013		10.1145/2525314.2525355	simulation;sensor;remote sensing	Robotics	54.975196509500456	-26.762525116918233	156821
b98a8717490ed862e58800df418125bbee1fa004	multiple-place swarm foraging with dynamic depots	swarm robotics;foraging;scalable system	Teams of robots can be organized to collectively complete complex real-world tasks, for example collective foraging in which robots search for, pick up, and drop off targets in a collection zone. In the previously proposed central-place foraging algorithm (CPFA), foraging performance decreases as swarm size and search areas scale up: more robots produce more inter-robot collisions and larger search areas produce longer travel distances. We propose the multiple-place foraging algorithm with dynamic depots ((hbox {MPFA}_{dynamic})) to address these problems. Depots are special robots which are initially distributed in the search area and can carry multiple targets. Depots move to the centroids of the positions of local targets recently detected by robots. The spatially distributed design reduces robot transport time and reduces collisions among robots. We simulate robot swarms that mimic foraging ants using the (hbox {MPFA}_{dynamic}) strategy, employing a genetic algorithm to optimize their behavior in the robot simulator ARGoS. Robots using the (hbox {MPFA}_{dynamic}) find and collect targets faster than both the CPFA and the static MPFA. (hbox {MPFA}_{dynamic}) outperforms the static MPFA even when the static depots are optimally placed using global information, and it outperforms the CPFA even when the dynamic depots deliver targets to a central location. Further, the (hbox {MPFA}_{dynamic}) scales up more efficiently, so that the improvement over the CPFA and the static MPFA is even greater in large (50 (times ) 50 m) areas. Including simulated error reduces foraging performance across all algorithms, but the MPFA still outperforms the other approaches. Our work demonstrates that dispersed agents that dynamically adapt to local information in their environment provide more flexible and scalable swarms. In addition, we illustrate a path to implement the (hbox {MPFA}_{dynamic}) in the physical robot swarm of the NASA Swarmathon competition.	swarm	Qi Lu;Joshua P. Hecker;Melanie E. Moses	2018	Auton. Robots	10.1007/s10514-017-9693-2	genetic algorithm;computer vision;swarm behaviour;computer science;artificial intelligence;mathematical optimization;scalability;swarm robotics;foraging	Robotics	56.26682592407134	-23.953295346429318	157013
f60f2edec6ada13f5835ba350c51e360076999c9	a study of reinforcement learning for the robot with many degrees of freedom - acquisition of locomotion patterns for multi legged robot	learning process;state space methods;locomotion pattern reinforcement learning multiple legged robot action state space genetic algorithm legged locomotion q learning dynamics;high dimensionality;legged locomotion;intelligent robots;degree of freedom;computational intelligence;reinforcement learning;q learning;space exploration;adaptive behavior;orbital robotics;learning systems;indium tin oxide;learning methods;dynamics;locomotion pattern;heuristic algorithms;space exploration orbital robotics heuristic algorithms legged locomotion learning systems state space methods genetic algorithms intelligent robots indium tin oxide computational intelligence;state space;genetic algorithm;genetic algorithms;learning artificial intelligence;multiple legged robot;robot dynamics;action state space;legged robot;genetic algorithms legged locomotion robot dynamics learning artificial intelligence	Reinforcement learning has recently been receiving much attention as a learning method for not only toy problems but also complicated systems such as robot systems. It does not need priori knowledge and has higher capability of reactive and adaptive behaviors. However, increasing of action-state space makes it difficult to accomplish the learning process. In most of the previous works, the application of the learning is restricted to simple tasks with a small action-state space. Considering this point, we present a new reinforcement learning algorithm: Q-learning with dynamic structuring of exploration space based on genetic algorithm. The algorithm is applicable to systems with high dimensional action and interior state spaces, for example, a robot with many redundant degrees of freedom. To demonstrate the effectiveness of the proposed algorithm simulations of locomotion patterns for a 12-leged robot were carried out. As the result, an effective behavior was obtained by using our proposed algorithm.	reinforcement learning;robot	Kazuyuki Ito;Fumitoshi Matsuno	2002		10.1109/ROBOT.2002.1014235	robot learning;error-driven learning;simulation;genetic algorithm;wake-sleep algorithm;computer science;artificial intelligence;machine learning;computational intelligence;stability;reinforcement learning	Robotics	61.58884012278185	-24.766384749446026	157116
4861742d5e77dc7445c8e842e99e9afb2bfe6b7d	learning inverse statics models efficiently		Online Goal Babbling and Direction Sampling are recently proposed methods for direct learning of inverse kinematics mappings from scratch even in high-dimensional sensorimotor spaces following the paradigm of ”learning while behaving”. To learn inverse statics mappings – primarily for gravity compensation – from scratch and without using any closed-loop controller, we modify and enhance the Online Goal Babbling and Direction Sampling schemes. Moreover, we exploit symmetries in the inverse statics mappings to drastically reduce the number of samples required for learning inverse statics models. Results for a 2R planar robot, a 3R simplified human arm, and a 4R humanoid robot arm clearly demonstrate that their inverse statics mappings can be learned successfully with our modified online Goal Babbling scheme. Furthermore, we show that the number of samples required for the 2R and 3R arms can be reduced by a factor of at least 8 and 16 resp. – depending on the number of discovered symmetries.	coat of arms;control theory;gibbs sampling;humanoid robot;inverse kinematics;microsoft outlook for mac;motion planning;nonlinear system;programming paradigm;robotic arm;sampling (signal processing)	Rania Rayyes;Daniel Kubus;Carsten Hartmann;Jochen Steil	2017	CoRR		humanoid robot;mathematical optimization;control theory;statics;inverse;scratch;homogeneous space;inverse kinematics;babbling;mathematics	Robotics	62.88723888957838	-24.30178922057817	157232
1e0df25d6a88a76aaaa8272399dee002202065fd	surveying a subsea lava flow using the autonomous benthic explorer (abe)	submarine observation;robot movil;detecteur image;concepcion sistema;autonomous system;observation sous marine;relief sous marin;sistema autonomo;temperature sensor;experimental result;robot mobile;system design;systeme autonome;resultado experimental;relieve submarino;detector imagen;dead reckoning;sea floor relief;observacion submarina;resultat experimental;juan de fuca ridge;conception systeme;image sensor;moving robot	This paper summarizes results from the first science deployment of the Autonomous Benthic Explorer (ABE), conducted on the Juan de Fuca Ridge (46°N, 129°W) at depths between 2200 and 2400 m. Using long baseline acoustic transponders, the ABE descended with precision to a preassigned starting point, then executed dead-reckoned tracklines. It followed the bottom at distances between 7 and 20 m using an acoustic fathometer as a reference sensor. The ABE mapped a new subsea lava flow with a magnetometer, imaged the seafloor with a stereo snapshot video system, and mapped a hydro thermal plume with conductivity and temperature sensors. The ABE completed 7 successful dives and covered over 35 km of tracklines. Detailed power records were logged, which permits extrapolation of the ABE's performance to other missions and higher capacity batteries.	attribute-based encryption	Dana R. Yoerger;Albert M. Bradley;Barrie B. Walden;Hanumant Singh;Ralf Bachmayer	1998	Int. J. Systems Science	10.1080/00207729808929596	dead reckoning;telecommunications;autonomous system;image sensor;systems design	Logic	57.847088733231665	-33.374756667886665	157238
c7e34943e2651b9e227ee58b5b548a9d752bb23f	implementing a new approach for bidirectional interaction between a real-time capable overall system simulation and structural simulations - completion of the virtual testbed with finite element analysis		Modern technical systems consist of various different components acting together. Robotics is a sophisticated example, as mechanical and electrical components interact with the environment. With size and complexity of the system, the susceptibility to errors rises, when the interaction between components fails. Often this happens if a component shows minimal changes to the nominal function. The structural behaviour of a single component is therefore as crucial for the functionality of the whole system as the interaction of all components. Although sophisticated Overall System Simulations exist and create powerful Virtual Testbeds, structural influences are neglected. As the underlying models differ, structural simulations are used as a stand-alone tool and their results are barely considered in the overall picture. In this work an interface was implemented, which is capable to integrate structural simulation automatically into a Virtual	algorithm;c++;co-simulation;computer simulation;correlation does not imply causation;delaunay triangulation;dynamic language runtime;electronic component;emoticon;experiment;federal enterprise architecture;finite element method in structural mechanics;graphical user interface;interpolation;lookup table;matlab;real-time clock;real-time transcription;robotics;system simulation;testbed;traffic collision avoidance system	Dorit Kaufmann;Malte Rast;Jürgen Roßmann	2017		10.5220/0006439301140125	simulation;finite element method;testbed;computer science;distributed computing	Robotics	67.76541259787602	-31.205476192429114	157524
887529bc33e3334d63548c55237fff7909eab7ef	on optimizing autonomous pipeline inspection	pipelines inspection skeleton robot sensing systems algorithm design and analysis optimization;3 d region guarding autonomous pipeline inspection;robot sensing systems;hierarchical integer linear programming optimization algorithm autonomous pipeline inspection optimal inspection autonomous robots 3d region guarding problem;3 d region guarding;inspection;three dimensional;skeleton;robots inspection integer programming linear programming pipelines;integer programming;autonomous pipeline inspection;pipelines;d region;robots;linear programming;algorithms;optimization;optimal algorithm;article;algorithm design;algorithm design and analysis;autonomous robot;integer linear program;simulation environment;robot programming	This paper studies the optimal inspection of autonomous robots in a complex pipeline system. We solve a 3-D region-guarding problem to suggest the necessary inspection spots. The proposed hierarchical integer linear programming optimization algorithm seeks the fewest spots necessary to cover the entire given 3-D region. Unlike most existing pipeline inspection systems that focus on designing mobility and control of the explore robots, this paper focuses on global planning of the thorough and automatic inspection of a complex environment. We demonstrate the efficacy of the computation framework using a simulated environment, where scanned pipelines and existing leaks, clogs, and deformation can be thoroughly detected by an autonomous prototype robot.	algorithm;autonomous robot;computation;electron hole;experiment;function prototype;integer programming;internationalization and localization;linear programming;mathematical optimization;optimizing compiler;pipeline (computing);prototype;reflection mapping;simulation;the wall street journal;virtual reality	Xin Li;Wuyi Yu;Xiao Lin;S. Sitharama Iyengar	2012	IEEE Transactions on Robotics	10.1109/TRO.2011.2169619	control engineering;algorithm design;computer vision;simulation;integer programming;computer science;engineering;linear programming	Robotics	53.981724743029105	-25.23853275174096	157545
b194fd0af3ce663fd500e862138abb2bef2006c9	robust pedestrian dead reckoning using anchor point recalibration		All indoor positioning approaches face the challenge to deal with erroneous input data from sensors. Especially independent systems like dead reckoning rely on highly accurate input data from accelerometers and gyroscopes for an accurate prediction of the user's position. But with the widespread of affordable mobile devices equipped with low-cost sensors, the obtained input data is noisy and of poor quality. Since errors accumulate within a pedestrian dead reckoning (PDR) system, there is an inevitable need for recalibration on a regular basis. We propose a PDR system based on state-of-the-art particle filters, which is recalibrated using both anchor points and a pedestrian movement model. Our evaluation compares standard particle filters with a backtracking particle filter including information from indoor maps and our enhancements. We show that a combination of anchor point recalibration, error calculation of sensor bias, and a fine-tuned movement model can decrease the RMSE by 1.07 m.	algorithm;analysis of algorithms;backtracking;dead reckoning;deployment environment;design review (u.s. government);experiment;fingerprint;mobile device;particle filter;sensor;step detection	Eike Jens Hoffmann;Lorenz Schauer;Mirco Schönfeld;Maximilian Kraus	2017	2017 International Conference on Indoor Positioning and Indoor Navigation (IPIN)	10.1109/IPIN.2017.8115948	computer vision;artificial intelligence;engineering;backtracking;accelerometer;pedestrian;dead reckoning;mobile device;particle filter;gyroscope	HCI	55.352076584058246	-37.4379236048098	157580
aa9f0e5dd2587d426b5fab152cbe331b9eae4614	increasing optical tracking workspace of vr applications using controlled cameras	virtual reality;optical tracking;workspace;controlled camera	We propose an approach to greatly increase the tracking workspace of VR applications without adding new sensors. Our approach relies on controlled cameras able to follow the tracked markers all around the VR workspace providing 6DoF tracking data. We designed the proof-of-concept of such approach based on two consumer-grade cameras and a pan-tilt head. The resulting tracking workspace could be greatly increased depending on the actuators' range of motion. The accuracy error and jitter were found to be rather limited during camera motion (resp. 0.3cm and 0.02cm). Therefore, whenever the final VR application does not require a perfect tracking accuracy over the entire workspace, we recommend using our approach in order to enlarge the tracking workspace.	digital camera;performance;sensor;tracking system;user experience;workspace	Guillaume Cortes;Éric Marchand;Jérôme Ardouin;Anatole Lécuyer	2017	2017 IEEE Symposium on 3D User Interfaces (3DUI)	10.1109/3DUI.2017.7893313	computer vision;simulation;computer science;computer graphics (images)	Visualization	58.12121914413948	-37.96083429628193	157628
8966ff6e039cde9437a1f4ba30cfb49ed9cfeb35	planning single-arm manipulations with n-arm robots		Many robotic systems are comprised of two or more arms. Such systems range from dual-arm household manipulators to factory floors populated with a multitude of industrial robotic arms. While the use of multiple arms increases the productivity of the system and extends dramatically its workspace, it also introduces a number of challenges. One such challenge is planning the motion of the arm(s) required to relocate an object from one location to another. This problem is challenging because it requires reasoning over which arms and in which order should manipulate the object, finding a sequence of valid handoff locations between the consecutive arms and finally choosing the grasps that allow for successful handoffs. In this paper, we show how to exploit the characteristics of this problem in order to construct a planner that can solve it effectively. We analyze our approach experimentally on a number of simulated examples ranging from a 2-arm system operating at a table to a 3-arm system working at a bar and to a 4-arm system in a factory setting.	a* search algorithm;coat of arms;computation;experiment;heuristic (computer science);high-level programming language;industrial robot;lazy evaluation;motion planning;point of sale;population;regular expression;scalability;simulation;table (database);workspace	Benjamin J. Cohen;Mike Phillips;Maxim Likhachev	2014		10.15607/RSS.2014.X.033	simulation;engineering;artificial intelligence;operations management	Robotics	61.03346983577056	-28.688595714827333	157677
b622800271785eaa892f16a71936bb673cf2e868	intelligent buffer storage system: enabling fast and flexible assembling with industrial robots	production engineering human work science and ergonomics;storage system;produktionsteknik arbetsvetenskap och ergonomi;search algorithm;buffer storage;industrial robots;industrial robot;automation	"""Production cells usually require a continuous supply of parts to be assembled. Elaborate feeding mechanisms or a system of prepared pallets on which the parts have exact positions are expensive and the feeding mechanism or pallets must be modified if a variation of the product is to be produced. Such solutions do not provide sufficient flexibility and increase production costs. Today's requirements for smaller series and customized orders have higher requirements on production cells. In this paper we show how flexible and adaptive production can be achieved through methods and techniques from artificial intelligence by introducing an """"autonomous"""" production cell that integrates and manages its own local buffer storage. The production cell is able to produce a number of variants of the product with no time delay between different configurations. The storage system, designated """"Floating Storage"""", handles the local buffer storage and guides the industrial robots to use available floor-space as storage. The system also orders parts from the main storage as the buffer storage approaches depletion. The parts arrive to the cell in standard containers and a commercially available vision system is used to locate the material. The prototype has been introduced in an assembly line at ABB."""	computer data storage;industrial robot	Mikael Hedelind;Peter Funk;Milun Milic	2006	Journal of Intelligent and Fuzzy Systems		simulation;converged storage;computer science;artificial intelligence;automation;search algorithm	Robotics	63.81739743922958	-30.360475790752368	157811
1ed38f14783d94eeb7fa47aa2a4b6f0ef5503d29	visual vein-finding for robotic iv insertion	robot sensing systems;visual vein finding;annular tracking window;optimal needle insertion point;image processing;venous bifurcations;bifurcation;veins bifurcation needles image edge detection robot sensing systems robot kinematics humans robotics and automation usa councils catheters;intravenous insertion visual vein finding robotic iv insertion optimal needle insertion point venous bifurcations annular tracking window;veins;usa councils;medical robotics;robot vision;robot vision bifurcation blood vessels image processing medical robotics;robotic iv insertion;image edge detection;catheters;success rate;humans;estimation error;robotics and automation;needles;blood vessels;intravenous insertion;robot kinematics	This paper presents a new algorithm for selecting the optimal needle insertion point in images of hand veins for robotic IV insertion. The 3D coordinates and orientation of the vein that the algorithm detects would eventually be fed to a robot for insertion of the IV needle. The goal of the algorithm is to identify venous bifurcations and determine an insertion point and approach angle for the needle in between their branches. The algorithm uses an annular tracking window that tracks along the veins and searches for bifurcations. We describe methods for centering the initial bifurcation estimates, error-checking, and positioning the needle exactly in between the bifurcation branches. We conclude with an experimental study of 50 subjects that shows a 32.4% success rate at detecting all bifurcations and a 82.6% success rate at finding at least one bifurcation in each image that contains bifurcations.	algorithm;bifurcation theory;caret;experiment;robot;sensor	Reuben D. Brewer;John Kenneth Salisbury	2010	2010 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2010.5509575	computer vision;simulation;image processing;computer science;engineering;artificial intelligence;robot kinematics	Robotics	59.981316926142014	-35.21736844874108	158176
499c6730928ccb59c404b49a72aa7e1ac7575673	navigation and control of a space robot capturing moving target		This paper presents navigation and control of a robot for capturing a moving target using the vision system. A stereo camera is used to calculate the pose of the moving target (position and orientation). An Adaptive Unscented Kalman Filter (AUKF) is used to generate an optimal path to capture the moving object by estimating the state vector (position, orientation, linear and angular velocities) of the target. The Fuzzy Logic Adaptive System (FLAS) has been used to prevent the AUKF from divergence. The FLAS can evaluate the performance of UKF and tuning the factors in the weighted covariance to improve the accuracy of UKF. A new trajectory planning method for the space robot is proposed based on the information acquired from the vision system and estimation the linear and angular velocities of the target by AUKF. The results from simulation experiments were presented and discussed. It was concluded that the Fuzzy Adaptive Unscented Kalman Filter methods give more accurate results rather than the Unscented Kalman filter or Extended Kalman Filter.	adaptive system;algorithm;angularjs;experiment;extended kalman filter;formal system;fuzzy logic;mathematical model;pose (computer vision);real-time clock;real-time computing;robot;simulation;stereo camera	Malik M. A. Al-Isawi;Jerzy Z. Sasiadek	2017	2017 11th International Workshop on Robot Motion and Control (RoMoCo)	10.1109/RoMoCo.2017.8003908	angular velocity;machine vision;computer vision;artificial intelligence;extended kalman filter;kalman filter;stereo camera;trajectory;covariance;engineering;control theory;state vector	Robotics	54.09885569108679	-33.29394050385902	158299
9b6d6c27d0e1857986386a0f49fc326b13b0cab2	iterative individual plant clustering in maize with assembled 2d lidar data		Abstract A two dimensional (2D) laser scanner was mounted at the front part of a small 4-wheel autonomous robot with differential steering, at an angle of 30 ° pointing downwards. The machine was able to drive between maize rows and collect concurrent time-stamped data. A robotic total station tracked the position of a prism mounted on the vehicle. The total station and laser scanner data were fused to generate a three dimensional (3D) point cloud. This 3D representation was used to detect individual plant positions, which are of particular interest for applications such as phenotyping, individual plant treatment and precision weeding. Two different methodologies were applied to the 3D point cloud to estimate the position of the individual plants. The first methodology used the Euclidian Clustering on the entire point cloud. The second methodology utilised the position of an initial plant and the fixed plant spacing to search iteratively for the best clusters. The two algorithms were applied at three different plant growth stages. For the first method, results indicated a detection rate up to 73.7% with a root mean square error of 3.6 cm. The second method was able to detect all plants (100% detection rate) with an accuracy of 2.7–3.0 cm, taking the plant spacing of 13 cm into account.	cluster analysis	David Reiser;Manuel Vázquez-Arellano;Dimitris Paraforos;Miguel Garrido Izard;Hans W. Griepentrog	2018	Computers in Industry	10.1016/j.compind.2018.03.023	point cloud;total station;computer vision;control engineering;cluster analysis;engineering;row;lidar;autonomous robot;mean squared error;artificial intelligence;laser scanning	ML	54.99015435634129	-32.76205555166958	158363
f664bcdd93b9762c38e11c2be043b486d8086755	object exploration and manipulation using a robotic finger equipped with an optical three-axis tactile sensor	article publisher;surface measurement;tactile sensor;contour measurement;three axis;object manipulation;robotic finger	To evaluate our three-axis tactile sensor developed in preceding papers, a tactile sensor is mounted on a robotic finger with 3-degrees of freedom. We develop a dual computer system that possesses two computers to enhance processing speed: one is for tactile information processing and the other controls the robotic finger; these computers are connected to a local area network. Three kinds of experiments are performed to evaluate the robotic finger's basic abilities required for dexterous hands. First, the robotic hand touches and scans flat specimens to evaluate their surface condition. Second, it detects objects with parallelepiped and cylindrical contours. Finally, it manipulates a parallelepiped object put on a table by sliding it. Since the present robotic hand performed the above three tasks, we conclude that it is applicable to the dexterous hand in subsequent studies.	optic axis of a crystal;robot;tactile sensor	Masahiro Ohka;Jumpei Takata;Hiroaki Kobayashi;Hirofumi Suzuki;Nobuyuki Morisawa;Hanafiah B. Yussof	2009	Robotica	10.1017/S0263574708005213	embedded system;computer vision;simulation;computer science;engineering;tactile sensor	Robotics	67.53588262425683	-29.86654352894689	158647
464d79702f92499b9a2c044a69e5b3691e28ff3d	fem-based soft robotic control framework for intracavitary navigation		Bio-inspired robotic structure composed of soft actuation units has attracted increasing research interests in its potential and capacity of complying with unstructured and dynamic environment, as well as providing safe interaction with human; however, this inevitably poses technical challenging to achieve steady, reliable control due to the remarkable non-linearity of its kinematics and dynamics. To resolve this challenge, we propose a novel control framework that can characterize the kinematics of a soft continuum robot through the hyper-elastic Finite-element modeling (FEM). This enables frequent updates of the Jacobian mapping from the user motion input to the end-effector's point of view. Experimental validation has been conducted to show the feasibility of controlling the soft robot for intracavitary path following. This could be the first success to demonstrate the perspectives of achieving stable, accurate and effective manipulation under large change of robot morphology without having to deduce its analytical model. It is anticipated to draw further extensive attention on resolving the bottleneck against the application of FEM, namely its intensive computation.	computation;extended validation certificate;finite element method;jacobian matrix and determinant;mathematical morphology;nonlinear system;robot end effector;triune continuum paradigm	Kit-Hang Lee;Martin C. W. Leong;Marco C. K. Chow;Hing-Choi Fu;Wayne Luk;Kam-Yim Sze;Chung-Kwong Yeung;Ka-Wai Kwok	2017	2017 IEEE International Conference on Real-time Computing and Robotics (RCAR)	10.1109/RCAR.2017.8311828	jacobian matrix and determinant;robot;computation;finite element method;control engineering;robot kinematics;kinematics;artificial intelligence;bottleneck;computer science;robotics	Robotics	67.33219297384535	-25.9026603130856	158663
c2eb17aa0695287ee4a986eee36176cb52e622da	servo motor controller design for robotic manipulator	manipulators;motion control;rs 485 serial transmission interface servo motor controller design robotic manipulator servo motors ex 106 sopc system module command transform module motor control module arm movement control command rs 232 serial transmission interface;sopc servo motor fpga nios ii;machine control;control system synthesis;servomotors;control engineering computing;servomotors manipulators motor drives process control transforms microcomputers field programmable gate arrays;servomotors control engineering computing control system synthesis machine control manipulators motion control	A servo motor controller design for robotic manipulator is proposed in this paper. This servo motor controller is used to control a manipulator, which has servo motors EX-106, to accomplish the movement of gripping some goods. This servo motor controller consists of three modules: (1) SOPC System Module, (2) Command Transform Module, and (3) Motor Control Module. This servo motor controller architecture process described as follow: First, SOPC System Module received the movement control command from the personal computer, and processed the feedback command from servo motor simultaneously. Second, let the arm movement control command transformed into the servo motor control command packet, and via the external transform protection circuit to transform the signals from RS-232 serial transmission interface into RS-485 serial transmission interface. Finally, the above steps can let manipulator to drive several servo motors to accomplish the movement of gripping some goods. The results of this experiment show that the proposed servo motor controller, which is implemented on the SOPC, is not only can deliver the control command correctly, but also can control the actions of two manipulators completely.	personal computer;rs-232;rs-485;robot;serial communication;servo	Shih-An Li;Chung-Wei Weng;Yi-Hong Chen;Chia-Hung Lo;Min-Hao Yang;Yi-Chun Lin;Ming-Hua Hsieh;Ching-Chang Wong	2012	2012 International Symposium on Intelligent Signal Processing and Communications Systems	10.1109/ISPACS.2012.6473490	control engineering;motion control;embedded system;motor controller;servo control;engineering;control theory;servo drive	Robotics	64.98879011501977	-30.431138316184846	158756
a80a09c38bed99290cca0510819ad76b2c6de211	localisation et navigation d'un robot humanoïde en environnement domestique. (localization and navigation of a humanoid robot in a domestic environment)		This thesis covers the topic of low cost humanoid robots localization and navigation in a dynamic unconstrained environment. It is the result of a collaboration between the Centre for Robotics of Mines ParisTech and Aldebaran, whose robots, NAO and Pepper, are used as experimental platforms. We will describe how to derive information on the orientation and the position of the robot, under high constraints on computing power, sensor field of view and environment genericity. The environment is represented using a topological formalism : places are stored in vertices, and connected by transitions. The environment is learned in a preliminary phase, which allows the robot to construct a reference. The main contribution of this PHD thesis lies in orientation and approximate position measurement methods, based on monocular cameras with a restricted field of view, and their integration into a topological structure. To localize the robot in the robot, we use mainly data provided by the monocular cameras of the robot, while also allowing extensions, for example with a 3D camera. The different localization methods are combined into a hierarchical structure, which makes the whole process more robust and merges the estimations. A trajectory control has also been developped in order to transition accurately from one vertex to another, and incidently to provide a feedback on the walk of the robot. The results of this thesis have been integrated into Aldebaran software suite, and thoroughly tested in various conditions, in order to validate the conclusions and prepare a client delivery.		Émilie Wirbel	2014				Robotics	54.50584376645821	-32.16909037825769	158912
bff6fab381f1a5e15e4989715984edbc699226f4	distal learning applied to biped robots	terrains;robot sensing systems;robot dynamics learning artificial intelligence legged locomotion mobile robots;motion control;neural networks;supervised learning;legged locomotion;forward model;biped robot;mobile robots;automatic generation;distal supervised learning;stability;biped robots;walking gaits;sd 2 biped robot biped robots terrains walking gaits distal supervised learning forward model stability;legged locomotion robotics and automation neural networks humans stability mobile robots robot programming supervised learning robot sensing systems motion control;humans;learning artificial intelligence;robot dynamics;robotics and automation;sd 2 biped robot;robot programming	In order for biped robots to handle a variety of tasks, the robot must be able to traverse different terrains. Different terrains require different walking gaits, and if all these gaits must be programmed by human operators then this programming can be a very large and time consuming process. If, however, the robot has the capability to automatically generate different gaits when placed on unfamiliar terrain, then the need to program many different gaits is eliminated. This paper looks at a method to generate gaits based on distal supervised learning. This method incorporates a forward model of the robot dynamics and uses it to convert stability information into information on how to adjust the robot’s joints so as to regain stability. The method is tested with a simulation of the SD-2 biped robot.	robot;simulation;supervised learning;traverse	Steve Stitt;Yuan F. Zheng	1994		10.1109/ROBOT.1994.350998	motion control;mobile robot;computer vision;terrain;simulation;stability;computer science;engineering;artificial intelligence;social robot;robot control;supervised learning	Robotics	62.04528463201065	-25.16933858239893	158968
1a8716c4290e6aee7c93f3c6515f54531c867ba3	a visual servoing path-planning strategy for cameras obeying the unified model	camera pose estimation;polynomial parametrization;conference_paper;ibvs controller;camera model;path planning;calibration error;conventional camera;constraint satisfaction;image noise;polynomials;3 d object reconstruction;unified model;control system;multiconstraint satisfaction;robot vision;trajectory;catadioptric system;image projection;image reconstruction;unified camera model;mathematical model;planned image trajectory;cameras trajectory polynomials visual servoing mathematical model;object reconstruction;visual servoing;virtual plane;calibration error visual servoing path planning unified camera model visual control system mathematical model fisheye camera catadioptric system virtual plane image projection camera pose estimation 3d object reconstruction multiconstraint satisfaction polynomial parametrization planned image trajectory ibvs controller image noise;cameras;visual servoing cameras image reconstruction path planning pose estimation robot vision;fisheye camera;visual control system;3d object reconstruction;pose estimation	Recently, a unified camera model has been introduced in visual control systems in order to describe through a unique mathematical model conventional perspective cameras, fisheye cameras, and catadioptric systems. In this paper, a path-planning strategy for visual servoing is proposed for any camera obeying this unified model. The proposed strategy is based on the projection onto a virtual plane of the available image projections. This has two benefits. First, it allows one to perform camera pose estimation and 3D object reconstruction by using methods for conventional camera that are not valid for other cameras. Second, it allows one to perform image path-planning for multi-constraint satisfaction by using a simplified but equivalent projection model, that in this paper is addressed by introducing polynomial parametrizations of the rotation and translation. The planned image trajectory is hence tracked by using an IBVS controller. The proposed strategy is validated through simulations with image noise and calibration errors typical of real experiments. It is worth remarking that visual servoing path-planning for non conventional perspective cameras has not been proposed yet in the literature.	3d pose estimation;constraint satisfaction;control system;experiment;fisheye;image noise;mathematical model;motion planning;obedience (human behavior);polynomial;simulation;unified model;visual servoing	Tiantian Shen;Graziano Chesi;Yeung Sam Hung	2010	2010 IEEE International Symposium on Computer-Aided Control System Design	10.1109/CACSD.2010.5612865	computer vision;simulation;mathematics;computer graphics (images)	Robotics	60.7146215963573	-32.056777247474066	159045
1bc54b2c7774d0cf4fb27f71f24f89b148164710	on an optical inertial navigation system—part i	inertial navigation;optical crosstalk;optical sensors;optical computing;unmanned aerial vehicles;predictive models;optical fibers;angular velocity;image sequences;insects	We introduce a new method for computing the linear velocity and angular velocity of an unmanned air vehicle (UAV) using only the information obtained from image sequences. We show that it is possible to build a strap-down type inertial navigation system [that we call an optical inertial navigation system (ONS)] using a simple apposition eye, that is a type of compound eye found in insects. In Part I, we use a recently proposed model for a lens and optical fiber system and show through computations that the model can predict well the angular sensitivity of a single ommatidium of a worker bee and an artificial eye. We develop the optical transfer function of the lens-fiber system for quasi-monochromatic, incoherent excitation, and study the properties of the kernel function. We study the cross-talk between neighboring fibers of the lens-fiber system for a worker bee and an artificial eye, and show that it is not significant.	angularjs;approximation;bessel filter;computation;crosstalk;emoticon;geographic coordinate system;inertial navigation system;monochrome;motion estimation;optical fiber;polarizer;transfer function;transverse wave;unmanned aerial vehicle;velocity (software development);well-posed problem	Ram Iyer;Jessica eixner;Richard Buckalew	2008	IEEE Transactions on Automatic Control	10.1109/TAC.2008.929389	computer vision;simulation;engineering;optics	Robotics	55.68882354852332	-35.31924215410223	159352
819fc54a41f367262efcf1dbf387f23e75c65afc	online planning of action sequences for a two-arm manipulator system	robot sensing systems;robot programming automatic programming;unix command sequence fate action sequences two arm manipulator system f sub a te online task level planning system assembly robot overhead camera force torque sensors explicit robot commands prolog sun 4 75 sparcstation;command sequence;assembly robot;sensor systems;prolog;real time;robotic assembly sensor systems robot sensing systems manipulator dynamics tellurium robot vision systems cameras assembly systems real time systems robot control;sun 4 75 sparcstation;tellurium;manipulator dynamics;fate;action sequences;f a te;automatic programming;online task level planning system;robot control;force torque sensors;explicit robot commands;assembly systems;robotic assembly;overhead camera;robot vision systems;unix;cameras;robot programming;two arm manipulator system;real time systems	In this paper, an on-line task-level planning system for an advanced assembly robot consisting of two manipulators and a set of different sensors like e.g. an overhead camera and force-torque sensors is presented. The planning system takes an implicit description of the assembly task, plans a sequence of explicit robot commands and monitors the execution by the real-time robot control system. Because it is running completely on-line, the planning process is highly reactive using sensor information about the robot's present environment.	control system;online and offline;overhead (computing);real-time clock;robot control;sensor	Andreas Hermann;Ulrich Rembold;Rüdiger Dillmann	1992		10.1109/ROBOT.1992.220200	control engineering;embedded system;simulation;computer science;artificial intelligence;tellurium;robot control;unix;prolog	Robotics	62.73054543786944	-27.2136635377638	159379
c60c2412b25a2b40168597ad43943f2264406ae9	build your own visual-inertial drone: a cost-effective and open-source autonomous drone		This article describes an approach to building a cost-effective and research-grade visual-inertial (VI) odometry-aided vertical takeoff and landing (VTOL) platform. We utilize an off-the-shelf VI sensor, an onboard computer, and a quadrotor platform, all of which are factory calibrated and mass produced, thereby sharing similar hardware and sensor specifications [e.g., mass, dimensions, intrinsic and extrinsic of camera-inertial measurement unit (IMU) systems, and signal-to-noise ratio]. We then perform system calibration and identification, enabling the use of our VI odometry, multisensor fusion (MSF), and model predictive control (MPC) frameworks with off-the-shelf products. This approach partially circumvents the tedious parameter-tuning procedures required to build a full system. The complete system is extensively evaluated both indoors using a motioncapture system and outdoors using a laser tracker while performing hover and step responses and trajectory-following tasks in the presence of external wind disturbances. We achieve root-mean-square (rms) pose errors of 0.036 m with respect to reference hover trajectories. We also conduct relatively long distance (.180 m) experiments on a farm site, demonstrating a 0.82% drift error of the total flight distance. This article conveys the insights we acquired about the platform and sensor module and offers open-source code with tutorial documentation to the community.	documentation;dynamical system;experiment;laser tracker;microsoft solutions framework;open-source software;oracle fusion architecture;sensor;signal-to-noise ratio;stepping level;switzerland;system identification;unmanned aerial vehicle;visual odometry	Inkyu Sa;Mina Kamel;Michael Burri;Michael Bloesch;Raghav Khanna;Marija Popovic;Juan Nieto;Roland Siegwart	2018	IEEE Robotics & Automation Magazine	10.1109/MRA.2017.2771326	calibration;vehicle dynamics;documentation;laser tracker;engineering;control engineering;odometry;takeoff and landing;inertial measurement unit;model predictive control	Robotics	55.6672341261327	-36.22407784321536	159616
6eb9cb64bd653a8b365d9f8b40bc8997dae346e6	vision-based vehicles in japan: machine vision systems and driving control systems	systeme commande;sistema control;vision ordenador;obstacle detection;control algorithm;systeme intelligent;50 km h vision based vehicles driving control systems intelligent vehicles obstacle detection dead reckoning system autonomous navigation stereo tv cameras hard wired logic personal vehicle system automated highway vehicle system pvs ahvs lane keeping pd control machine vision system edge extraction lane markings detection 10 to 30 km h;personal vehicle system;intelligent vehicle;articulo sintesis;article synthese;intelligent transportation systems;sistema inteligente;automated highways;real time processing;edge extraction;mobile robots;robotics;automated highway vehicle system;advanced vehicle control systems;intelligent control;computer vision;vehiculo;japon;control system;asie;vehicule;stereo image processing mobile robots road vehicles computer vision intelligent control;machine vision;intelligent vehicles;stereo image processing;intelligent system;robotica;vision ordinateur;autonomous navigation;robotique;dead reckoning;vehicle;vehicle driving machine vision remotely operated vehicles cameras intelligent vehicles dead reckoning tv road vehicles control systems vehicle detection;review;japan;asia;road vehicles	This paper surveys three intelligent vehicles developed in Japan, and in particular the configurations, the machine vision systems, and the driving control systems. The first one is the Intelligent Vehicle, developed since the mid 1970's, which has a machine vision system for obstacle detection and a dead reckoning system for autonomous navigation on a compact car. The machine vision system with stereo TV cameras is featured by real time processing using hard-wired logic. The dead reckoning function and a new lateral control algorithm enable the vehicle to drive from a starting point to a goal. It drove autonomously at about 10 km/h while avoiding an obstacle. The second one is the Personal Vehicle System (PVS), developed in the late 1980's, which is a comprehensive test system for a vision-based vehicle. The machine vision system captures lane markings at both road edges along which the vehicle is guided. The PVS has another machine vision system for obstacle detection with stereo cameras. The PVS drove at 10-30 km/h along lanes with turnings and crossings. The third one is the Automated Highway Vehicle System (AHVS) with a single TV camera for lane-keeping by PD control. The machine vision system uses an edge extraction algorithm to detect lane markings. The AHVS drove at 50 km/h along a lane with a large curvature. >	control system;machine vision	Sadayuki Tsugawa	1994	IEEE Trans. Industrial Electronics	10.1109/41.303790	dead reckoning;mobile robot;embedded system;computer vision;intelligent transportation system;simulation;machine vision;computer science;engineering;control system;artificial intelligence;robotics;intelligent control	Robotics	57.371143138915855	-32.473412547003456	159647
6184baa8e83ed5eb4b0b6abd56eff1296177bdca	automation of an agricultural tractor for fruit picking	agricultural machinery;automation agricultural machinery hardware software architecture vehicles robot kinematics safety control systems software maintenance radio control;control systems;traction control;vehicle automation;software maintenance;real time;software architecture;control system;radio control;traction control agricultural vehicles vehicle automation steering control;safety;agricultural vehicles;vehicles;steering control;robot kinematics;hardware;automation	This paper presents the hardware and software architectures of a compact agricultural tractor, that is currently being developed as a generic mobile platform for agricultural tasks. The specific task that is being addressed is fruit picking. Such systems require precision outdoor maneuvering and coordination with the implement attached to the vehicle. The system described also includes a loader attached to the front of the tractor which carries the fruit picking robot. First the hardware associated with the safety subsystem, steering, traction and loader control systems are described. Then the real-time software that coordinates the control of all subsystems while maintaining a functional radio link to a remote station is described.	automation;control system;loader (computing);mobile operating system;real-time computing;real-time transcription;traction teampage	Jayantha Katupitiya;Ray Eaton;Guy Rodnay;Anthony Cole;Craig Meyer	2005	Proceedings of the 2005 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2005.1570603	agricultural machinery;control engineering;embedded system;software architecture;engineering;control system;artificial intelligence;automation;automotive engineering;traction control system;software maintenance;robot kinematics;radio control	Robotics	62.519694110587366	-28.758342723348107	159691
43aaf15cf77bfda791506f0f3cdab2c082891eb8	on the performance of a biologically motivated visual control strategy for robotic hand-eye coordination	robot hand;image processing;manipulator kinematics;feedback;robot vision;stereo image processing;biological control systems robots neurofeedback calibration control systems visual servoing feedback loop image processing humans performance analysis;error compensation;visual servoing biologically motivated visual control robotic hand eye coordination imprecisely calibrated robot uncalibrated robot control loop visual feedback image processing calibration error compensation neuroscience human grasping robotic hand eye system manipulator pan tilt head stereo camera system sparse feedback simulation model;visual feedback;profitability;visual servoing;error compensation robot vision calibration feedback manipulator kinematics stereo image processing;simulation model;calibration;control strategy	Recently, research has focused o n developing control strategies that allow to work with imprecisely calibrated or even uncalibrated robot systems. A popular approach is to close the control loop with visual feedback (visual seruoing), even though this requires continuous, high rate image processing. In contrast, we developed a strategy that can compensate calibrat ion errors by integrating sparse visual feedback asynchronously. This strategy was motivated by neuroscientific studies which show that human grasping definitely requires only sparse asynchronous visual feedback, even with disturbed visual input. I n this paper, we analyze the performance of our control strategy o n a robotic hand-eye sys tem consisting of a 6 d.0.f. manipulator and a pan-tilt head with a stereo camera system. To analyze thoroughly which calibration errors can be compensated by sparse feedback, we furthermore built a complete simulation model of the real hand-eye system, including the vision modules. Taken together, experimental and simulation results show that calibration errors can be compensated with a very moderate amount of (asynchronous) visual feedback. Thus, the proposed control strategy can indeed be seen as a serious alternative to visual servoing f o r real robotics applications. This shows that robotics can profit f rom taking a closer look at the results of neuroscience.	asynchronous i/o;control system;control theory;image processing;robot;robotics;simulation;sparse matrix;stereo camera;visual servoing	Alexa Hauck;Georg Passig;Thomas Schenk;Michael Sorg;Georg Färber	2000		10.1109/IROS.2000.895205	control engineering;computer vision;calibration;simulation;image processing;computer science;simulation modeling;control theory;feedback;visual servoing;profitability index	Robotics	64.75383362229157	-31.64449188918721	159747
5fa4892c6ab5a65d37ba911d25b0931d1d42b6ab	implementation of an integrated navigation, guidance and control system for an unmanned surface vehicle		In this paper, an integrated navigation, guidance and control system of an unmanned surface vehicle (USV) is implemented. Main contributions are as follows: 1) Aiming to obtain precise heading estimation, Kalman filter technique that can combine predictions from designed model with actual sensor measurements is adopted in navigation system; 2) The line-of-sight (LOS) with a time-varying lookahead distance is employed in guidance system. Remarkably, a novel arc transition strategy is proposed such that the vehicle can turn around smoothly when completing the way-point guidance mission; 3) In addition, strong robustness to dynamic characteristics is enhanced by employing a fuzzy PID controller. Finally, simulation studies and field experiments demonstrate remarkable performance of the integrated USV system.	algorithm;control system;course (navigation);experiment;guidance system;kalman filter;line-of-sight (missile);pid;parsing;simulation;smoothing;unmanned aerial vehicle;waypoint	Ning Wang;Yuncheng Gao;Yongpeng Weng;Zhongjiu Zheng;Hong Zhao	2018	2018 Tenth International Conference on Advanced Computational Intelligence (ICACI)	10.1109/ICACI.2018.8377549	pid controller;kalman filter;robustness (computer science);global positioning system;guidance system;control engineering;fuzzy control system;navigation system;computer science;control system	Robotics	57.873054752817815	-28.718301820092815	159803
bcacc2db1d9a669d1152396653d98c7624c9a9ad	a simulation environment for multi-sensor planning	multiagent system;multisensor;simulation;simulacion;movie camera;captador medida;planificacion;camara;measurement sensor;capteur mesure;agent intelligent;intelligent agent;planning;agente inteligente;planification;sistema multiagente;capteur multiple;simulation environment;systeme multiagent;camera	The aim of this work is to design a flexible multiagent environment for simulating the deployment of multiple sensors for a given sensing task. The environment is based on a multi-agent architecture such that each sensor is controlled by an autonomous intelligent agent. This allows the user great flexibility in manipulating the number of sensors and also the capabilities of each sensor. The simulation system permits the user to visualize the outcome of the deployment for various sensor configurations prior to implementation in the real world. Currently, the system focuses on the use of cameras for visual inspection tasks in which a single camera would be inadequate due to occluding objects in the scene or the sheer size of the target.	agent architecture;agent-based model;intelligent agent;multi-agent system;sensor;simulation;software deployment;visual inspection	Lovell Hodge;Mohamed S. Kamel	2001	Simulation	10.1177/003754970107600605	planning;embedded system;computer vision;simulation;computer science;engineering;artificial intelligence;intelligent agent	Robotics	62.568161795264295	-37.1932718211697	159939
ca8860612636582614a8d03554f21bf51f4c750b	roll oscillation modulated turning in dynamic millirobots	frequency 5 hz roll oscillation modulated turning maneuverable legged robots legged turning dynamics dynamic turning motion analysis dynamic hexapedal millirobot phase locked turning gaits roll angle vertical height single harmonic sinusoidal functions robot turning behavior compliant leg forces high speed turning gait;robot dynamics gait analysis legged locomotion microrobots;legged locomotion turning oscillators harmonic analysis kinematics dynamics	As we seek to develop more maneuverable legged robots, we need to understand the dynamics of legged turning in an approachable fashion. In this work, we analyze the dynamic turning motion of a dynamic hexapedal millirobot. We explore a family of phase locked turning gaits where all legs of the robot move at the same speed. These gaits are highly periodic, allowing the vertical height and roll angle of the robot to be approximated by single harmonic sinusoidal functions. We demonstrate that oscillations in height and roll angle determine the robot's turning behavior. The phase between these oscillations (and therefore the turning behavior) was modulated by the phase between the left and right sets of legs. A simple model using compliant leg forces was shown to match turning behavior for a range of 5Hz turning gaits. Based on the finding that roll oscillations are major determinants of turning behavior, we modified the robot to create a new high speed turning gait (forward velocity: 0.4 m/s, turn rate 206°/s).	approximation algorithm;human height;microbotics;modulation;robot;velocity (software development)	Duncan W. Haldane;Ronald S. Fearing	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907526	control engineering;simulation;control theory	Robotics	67.09445591100716	-24.30768099573272	160003
124ce07744b4a2241701250478b50cff94aa7411	a two-level approach for multi-robot coordinated exploration of unstructured environments	multi robot system;unstructured environments;coordinated exploration;conference paper;multi robot systems;multi robot coordination	The efficiency of Multi-Robot Exploration can be improved by having a balanced distribution of robots in the environment. Exploration strategies for indoor/structured environments can ensure a balanced distribution of robots by explicitly assigning robots to distinct regions in the environment. However, unstructured environments do not support partitioning of environments to distinct regions, thus requires an alternative way of ensuring the balanced distribution of the robots. This paper presents a two level approach to multi-robot coordinated exploration of unstructured environments where a classical coordination method is employed at the lower level to provide a localized coordination while a higher level robot repositioning strategy is used to generate a balanced distribution of the robots in the environment. Simulation results indicate that this new approach provides a balanced distribution of the robots over the environment and improves the exploration efficiency over localized coordination strategies.	integrated development environment;robot;simulation	P. G. C. N. Senarathne;Danwei Wang	2012		10.1145/2245276.2245331	simulation;distributed computing	Robotics	56.58236939205161	-24.930223885560196	160251
132148e9dc71f46ec2362271fbddd4015ac08671	implementation of sensors and control paradigm for a hybrid mobile robot manipulator for search and rescue operations	search and rescue;manipulators;control paradigm;hybrid mobile robot manipulator;embedded sensors;search rescue operations;mobile robot;service robots intelligent sensors manipulators mobile robots robot vision;onboard rf data communication;camera layout;robot sensors;mobile robots robot sensing systems manipulator dynamics service robots robotics and automation mechanical sensors sensor systems radio frequency data communication hazardous materials;service robots;mobile robots;extensible power source system;data communication;extensible power source system control paradigm hybrid mobile robot manipulator search rescue operations embedded sensors onboard rf data communication camera layout;robot vision;control architecture;system design;search and rescue mobile manipulator robot sensors control architecture;mobile manipulator;intelligent sensors	This paper presents the control paradigm and embedded sensors for a mobile robot manipulator whereby the mobile platform and manipulator arm are designed as one entity to support both locomotion and manipulation simultaneously and interchangeably in several configuration modes. Along with the description of the novel design architecture, we developed, constructed and tested a novel paradigm for on-board RF data communication among robot's joints. This paper also describes the sensor and camera layout and their implementation in the mobile robot manipulator. A modular and extensible power source system design with major key elements that allow for easy reconfiguration and expansion was also developed, implemented and tested for the hybrid mobile robot manipulator.	embedded system;extensibility;mobile manipulator;mobile operating system;mobile robot;on-board data handling;programming paradigm;radio frequency;robot locomotion;sensor;systems design	Pinhas Ben-Tzvi;Andrew A. Goldenberg;Jean W. Zu	2007	2007 International Workshop on Robotic and Sensors Environments	10.1109/ROSE.2007.4373974	control engineering;mobile robot;embedded system;parallel manipulator;simulation;engineering;social robot;mobile manipulator;robot control	Robotics	64.72069462318028	-28.36415764287959	160359
916589d197f4ea3024470ca9bd9de9ac7d58a46e	a global navigation management architecture applied to autonomous robots in urban environments	advanced driver information systems;digital maps sensor based navigation global navigation management;route guidance;navigation roads vehicles routing robot sensing systems;global navigation management architecture autonomous car reference trajectory round constraints local navigation task global navigation goal digital road map data perceived information traffic laws urban context autonomous vehicle global behavioral architecture urban environments autonomous robots;digital maps;urban areas;global navigation management;global positioning system;intelligent vehicles;sensor based navigation;trajectory control automobiles control engineering computing geographic information systems mobile robots road traffic control;trajectory control	This paper presents a global behavioral architecture used as a coordinator for the global navigation of an autonomous vehicle in an urban context including traffic laws and other features. As an extension to our previous work, the approach presented here focuses on how this manager uses perceived information (from low cost cameras and laser scanners) combined with digital road-map data to take decisions. This decision consists in retrieving the car's state regarding the global navigation goal, selecting which local navigation task should be executed (either lane following or intersection maneuvers), providing some round constraints and further defining the reference trajectory to be met by the selected local task. This system was experimented in a real autonomous car and provided satisfactory results.	autonomous car;autonomous robot;feedback;motion planning;performance;reflections of signals on conducting lines;sensor;silk road;tree traversal	Ide-Flore Kenmogne;Danilo Alves de Lima;Alessandro Corrêa Victorino	2015	2015 IEEE 18th International Conference on Intelligent Transportation Systems	10.1109/ITSC.2015.341	turn-by-turn navigation;computer vision;simulation;geography;virtual reference station;transport engineering;mobile robot navigation	Robotics	53.83256563229007	-31.52056774726868	160404
61a40692515bf2e00d3d3c668105392bd20164c1	unimodal asymmetric interface for teleoperation of mobile manipulators: a user study	telerobotics haptic interfaces manipulators mobile robots;manipulators;mobile communication cameras manipulators robot vision systems switches haptic interfaces;mobile manipulation unimodal asymmetric interface mobile manipulators user study complex systems mission critical applications 6 dof input device haptic feedback slave devices haptic interface workspace clutching differential end zone rate switching position switching hanoi manipulation;mobile robots;mobile communication;telerobotics;haptic interfaces;switches;robot vision systems;cameras	There is demand to develop methods and interfaces for teleoperation of complex systems in mission-critical applications. In this paper, we study three different methods to command a one-arm mobile manipulator from a 6-DOF input device capable of haptic feedback. The linkage between the master and the slave devices is asymmetric, that is, the input haptic interface (master) is much smaller and has different kinematics and dynamics from the robot arm and the mobile base (slave). Three different master-slave motion coordination schemes are compared here (1) workspace clutching, (2) differential end-zone, and (3) position/rate switching. We study repetitive user performance for seven subjects in a static Tower of Hanoi manipulation task and present single case studies for two mobile manipulation tasks: door opening and large-displacement Towers of Hanoi. Our experimental platform consists of a 4-DOF WAM (Whole Arm Manipulator) on a Segway RMP (Robotic Mobility Platform) controlled by a Phantom Omni haptic device. Cameras are used to relay scene images to the remote operator. The human stays in the loop throughout the entire task. The results obtained from user studies provide insight on how to interface and command a mobile manipulator.	complex systems;displacement mapping;experiment;haptic technology;input device;linkage (software);mission critical;mobile manipulator;relay;risk management plan;robot;robotic arm;smt placement equipment;telerobotics;television;tower of hanoi;usability testing;warren abstract machine;workspace	Alejandro Hernandez Herdocia;Azad Shademan;Martin Jägersand	2012	2012 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2012.6386201	telerobotics;control engineering;mobile robot;embedded system;simulation;mobile telephony;network switch;computer science;engineering;artificial intelligence;mobile manipulator	Robotics	62.146996256285995	-29.879733296965803	160550
c066b8aa906f06d306a6f8a297a20ee0be1e4692	vision-only automatic flight control for small uavs	automatic control;aircraft control;low cost vision only automatic flight control system small uav skyline detection algorithm unmanned aerial vehicles remotely controlled airplane wireless transmitter wireless receiver ground control computer flight stability static tests dynamic tests;radio receivers;vision control automated vehicles skyline detection;remotely controlled airplane;edge detection;unmanned aerial vehicle;static tests;drone aircraft;mobile robots;remotely operated vehicles;wireless receiver;stability aircraft control aircraft testing mobile robots radio receivers radio transmitters remotely operated vehicles robot vision;radio transmitters;stability;aircraft testing;skyline detection;pixel videos aircraft aerospace control image edge detection cameras image color analysis;small uav;flight control systems;low cost vision only automatic flight control system;aerospace control;robot vision;remotely piloted aircraft;image edge detection;image color analysis;system integration;pixel;detection algorithm;dynamic tests;ground control computer;flight stability;image analysis;automated vehicles;unmanned aerial vehicles;wireless transmitter;flight control;cameras;aircraft;videos;vision control;skyline detection algorithm	In this paper, a vision-based flight control system that uses a skyline-detection algorithm is developed for application to small unmanned aerial vehicles. The skyline-detection algorithm can detect straight or uneven skylines. The system integrates a remote controller, a remotely controlled airplane, a camera, a wireless transmitter/receiver, a ground control computer, and the proposed skyline-detection algorithm to achieve automatic control of flight stability. Static and dynamic tests are conducted to validate the system. In the static tests, the average accuracy rate for skyline detection is 98.62% based on five test videos. In the dynamic tests, straight and circular flights are used to verify lateral and longitudinal stability for the proposed flight control system. The experimental results demonstrate the performance and robustness of the algorithm and the feasibility and potential of a low-cost vision-only flight control system.	aerial photography;algorithm;anomaly detection;automatic control;control system;gnu compiler collection;gps signals;global positioning system;lateral thinking;remote control;rudder;transmitter;unmanned aerial vehicle	Chung-Cheng Chiu;Ching-Tung Lo	2011	IEEE Transactions on Vehicular Technology	10.1109/TVT.2011.2157545	remotely operated underwater vehicle;mobile robot;embedded system;computer vision;transmitter;image analysis;simulation;edge detection;stability;computer science;engineering;automatic control;radio receiver;pixel;system integration	Robotics	56.67218829449013	-32.931049404151885	160593
5535eabfd25fc5933d97950761728cc762f2165f	a heterogeneous modular robotic design for fast response to a diversity of tasks	mechanical design;locomotion;heterogeneous;manipulation;tasks;modular robot	This paper describes a heterogeneous modular robot system design which attempts to give a quick solution to a diversity of tasks. The approach is based on the use of an inventory of three types of modules i.e., power and control module, joint module and specialized module. Each module type aims to balance versatility and functionality. Their design permits rapid and cost effective design and fabrication. They are interchangeable in different ways to form different robot or system configurations. Depending on the task, the operator decides what type of robot can provide the best performance within the mission. A spherical joint module is described and used to build different robots, hence, forward and inverse kinematics models are obtained. Finally, from the modules described in this work, several robot configurations such as robotic arms, leg-based robots and wheel-based robots are assembled to demonstrate the execution of manipulation and locomotion tasks.	robot	José Baca;Manuel Ferre;Rafael Aracil	2012	Robotics and Autonomous Systems	10.1016/j.robot.2011.11.013	mobile robot;embedded system;simulation;self-reconfiguring modular robot;robot control	Robotics	64.51391360677113	-27.173252173029695	160768
3aaa28a0febe469e917c1fd22d3e5e8a05dbf2e4	constraints of potential field for obstacle avoidance on car-like mobile robots		The well-known potential field method for obstacle avoidance in the scope of mobile robots is discussed in this paper. Particular attention is on the car-like mobile robots, which impose practical limitations on the application of potential field method due to its limited speed and curvature in motion. Along with the review of some recent studies on this topic, we point out the necessity of implementing a nonholonomic motion planner and propose some extensions to other potential-field-related methods to deal with the constraints of car-like robots. Two exemplary scenarios based on our extensions are simuated to prove their feasibility in application.	autonomous robot;experiment;mobile robot;obstacle avoidance;program optimization;quantum harmonic oscillator;robotic mapping;simulation;whole earth 'lectronic link	Zhihao Xu;Robin Heß;Klaus Schilling	2012		10.3182/20120403-3-DE-3010.00077	computer vision;simulation;geography;artificial intelligence;obstacle avoidance	Robotics	55.293489519507474	-27.554252395587532	161229
49647f21457c675450891943306ae292ed81417f	pedestrian dead reckoning on smartphones with varying walking speed	step length estimation pedestrian dead reckoning smartphones varying walking speed inertial sensors body mounted sensors sensor noise walking state transitions real time acceleration date kalman filters;legged locomotion;foot;legged locomotion acceleration estimation accelerometers dead reckoning foot real time systems;acceleration;estimation;smart phones kalman filters;step length estimation inertial sensor pedestrian dead reckoning smartphone step detection;dead reckoning;accelerometers;real time systems	Pedestrian dead reckoning uses inertial sensors carried by pedestrians to track their positions, wherein step detection and step length estimation play the key roles. Compared with pioneer researches using body-mounted sensors, smartphone-based dead reckoning has more flexibility but raises more challenges. To reduce the negative influence of sensor noise and varying walking speed, the paper proposes an adaptive step detection algorithm based on walking state transitions, parameters of which are determined dynamically on the fly using the real-time acceleration date. Based on the fact that step length changes gradually instead of abruptly during walking, the paper applies Kalman filters to mainstream step length estimation algorithms to correlate consecutive steps and achieve more accurate step length estimation. Experiments show that the proposed algorithm performs well for step detection with varying walking speed and reduces errors of step length estimation by 30%. Tracking experiments in corridors and rooms show a positioning accuracy of less than 3 meters.	algorithm;apache axis;dead reckoning;design review (u.s. government);experiment;finite-state machine;human dynamics;image noise;kalman filter;on the fly;real-time clock;sensor;smartphone;step detection	Rui Zhou	2016	2016 IEEE International Conference on Communications (ICC)	10.1109/ICC.2016.7510774	acceleration;dead reckoning;embedded system;estimation;simulation;computer science;control theory;accelerometer;foot;statistics	Robotics	57.468932959255625	-37.41017593099044	161261
7621e826b57c0d86ef17c873feddb20dc6f03f0a	vision based gait analysis on robotic walking stabilization system for patients with parkinson's disease	legged locomotion;joints;monitoring;three dimensional displays;diseases;senior care unit vision based gait analysis robotic walking stabilization system parkinson disease patient active robotic walker single rgb d camera lower limbs skeleton kinematic model adjustable motion control auditory cues;stability cameras diseases gait analysis medical image processing medical robotics mobile robots motion control robot kinematics robot vision;legged locomotion joints diseases cameras three dimensional displays monitoring;cameras	In this paper, we propose a gait analysis based walking stabilization system on an active robotic walker for Parkinson's Disease patient. We developed a vision based gait analysis that lower limbs from the frontal view which is captured by single RGB-D camera on the robotic walker. Our system constructs the lower limbs skeleton and kinematic model for calculating the walking gait features such as average walking step length, velocity, width and joint angles. When the user suffer in abnormal gait, the robotic walker assists user to stabilize their gaits through the adjustable control motion of walker according to the user's walking gait and prompting user with auditory cues. In experiment, we had invited Parkinson's Disease patients to test our system in senior care unit, the experimental results show that when the patients have relatively stable gait than without using this system.	amiga walker;gait analysis;robot;topological skeleton;velocity (software development)	Chien-Ke Liao;Chung Dial Lim;Ching-Ying Cheng;Cheng-Ming Huang;Li-Chen Fu	2014	2014 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/CoASE.2014.6899420	computer vision;simulation;engineering;physical therapy	Robotics	62.676089285194585	-31.289628468530612	161526
06241e4bbf7969fceeeda5aae3261794f35b0e79	3d obstacle detection and avoidance in vegetated off-road terrain	universitaet;biologisch;rrlab;3d laser scanner;vegetation mapping;karsten berns;obstacle detection;seminar;optical scanners;roboter;3d obstacle avoidance;robotik;mobile robots;robotics;sensor systems navigation vehicle detection vegetation mapping clouds robotics and automation laser fusion mobile robots robot sensing systems sensor phenomena and characterization;laser ranging;studium;praktikum;forschung;robot vision;ravon mobile off road platform;informatik;agrosy;virtual sensor;lehre;vegetation mapping collision avoidance laser ranging mobile robots object detection optical scanners robot vision terrain mapping;vegetated off road terrain;collision avoidance;terrain mapping;computer science;autonom;kaiserslautern;vorlesung;robot;object detection;ravon mobile off road platform 3d obstacle detection 3d obstacle avoidance vegetated off road terrain;3d obstacle detection	This paper presents a laser-based obstacle detection facility for off-road robotics in vegetated terrain. In the context of this work the mobile off-road platform RAVON was equipped with a 3D laser scanner and accompanying evaluation routines working on individual vertical scans. Identified terrain characteristics are used to build up a local representation of the environment. Introducing the abstraction concept of virtual sensors the transparent integration of additional terrain information on the basis of standardized behavior modules can be achieved.	abstraction layer;autonomous robot;behavior-based robotics;content-control software;entity;instruction creep;obstacle avoidance;sensor;television;voxel	Bernd-Helge Schäfer;Andreas Hach;Martin Proetzsch;Karsten Berns	2008	2008 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2008.4543323	robot;mobile robot;computer vision;simulation;computer science;artificial intelligence;robotics;remote sensing	Robotics	56.541294783891814	-32.19392370569272	161543
0e5b2794d01fc41af9ec9e2f9f416f22e214dc72	feed forward visual servoing for object exploration	manipulators;redundant 7 dof manipulator feed forward visual servoing method object exploration position based visual servoing method pbvs image based control layer image based visual servoing method ibvs;cameras visual servoing visualization manipulators asymptotic stability aerospace electronics feeds;feeds;asymptotic stability;visualization;robot vision;visual servoing manipulators robot vision;aerospace electronics;visual servoing;cameras	A new visual servoing method is proposed which uses position based visual servoing (PBVS) in combination with an additional image based control layer on the target pose to maintain fixation on an object. The proposed method (denoted feed forward PBVS) does not require trajectory generation but instead uses via-points to explore the object. It exploits the advantages of PBVS without the disadvantages of image based visual servoing (IBVS) as occurs in hybrid approaches. The proposed method is experimentally validated with a redundant 7-DOF manipulator. Comparison with existing visual servoing methods (PBVS and one partitioned approach) shows the effectiveness of the method.	apple a5;denavit–hartenberg parameters;experiment;feed forward (control);pose (computer vision);visual servoing	Roel Pieters;Alejandro Alvarez-Aguirre;Pieter P. Jonker;Henk Nijmeijer	2012	2012 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2012.6385613	control engineering;computer vision;visualization;computer science;engineering;control theory;visual servoing	Robotics	61.076576312545264	-31.249278613063055	161699
f16e1dc112e7832a9427275f85bb99df9e0a9b08	binocular visual coordinated tracking control for a multi-robot system based on terminal sliding mode			binocular vision;robot	Nuan Shao	2016	Control and Intelligent Systems	10.2316/Journal.201.2016.4.201-2787	computer vision;control theory	Robotics	58.95076167382048	-30.356168828313358	161754
f465492c4fdaabc69801165701caa806145cbcb0	an autonomous biped - concept and design		This paper argues for a new approach in the mechanical design principle for the humanoid walkers. Applying linear electric direct drive motors the biped mechanism is able to behave as dynamically highly reactive walker admissible to exploiting its own natural dynamics. Based on this, a whole new concept of an anthropomorphic walker prototype is described including the interaction of the design and algorithmic aspects of the motion control.	admissible heuristic;algorithm;amiga walker;prototype	Peter Jakubik	2012			control engineering;engineering	HCI	65.16784267657577	-25.32375633432195	161913
a7cfcfcf27ddb2f741312894aab4a8467eebe63c	a topological map based approach to long range operation of an unmanned surface vehicle	marine vehicles;mobile robots;path planning;remotely operated vehicles;trajectory control;vehicle dynamics;dynamically feasible vehicle trajectory planning;kinematic model;long range operation;topological map based approach;tropical riverine system;unmanned surface vehicle;vehicle dynamics	We present an approach to planning dynamically feasible vehicle trajectories for applications where the vehicle operates in very large environments and for which a kinematic model is a poor approximation of the vehicle's dynamics. Our approach is based on new methods for generating topological maps of a sparse and natural environment, such as a tropical riverine system.	approximation;map;sparse matrix;unmanned aerial vehicle	Aditya S. Gadre;Shu Du;Daniel J. Stilwell	2012	2012 American Control Conference (ACC)		remotely operated underwater vehicle;planning;control engineering;mobile robot;vehicle dynamics;simulation;computer science;artificial intelligence;trajectory;motion planning;transport engineering;skeleton	Robotics	54.87988300775019	-26.784352006915675	162384
fe02e0771bfc060bf35a40bc504b19b361bbed8f	night vision applicability in anti-sway vision-based solutions	photonics;sensors;cameras machine vision cranes sensors night vision photonics;overhead travelling crane night vision applicability antisway vision based solutions vision based sway sensors close loop systems infrared radiation noncontact vision based sensor architecture infrared illuminator;smart camera night vision infrared radiation swinging sensor overhead travelling crane vision methods;night vision;machine vision;night vision image processing image sensors;cranes;cameras	This paper describes a common issues in architecture of the variety kind of vision-based sway sensors dedicated for the anti-sway solution as a feedback in close-loop systems. However, in the statement the author's attention was focused on the issue related with vision sensor architecture insensitiveness on actual exposure light conditions. The night vision functionality was obtained through use infrared radiation. Author main attention was focused on possibility of use IR as a solution for insufficient light condition and their usefulness in different non-contact vision-based sensor architecture. All obtained results and considerations were conducted on the base vision sway sensor integrated with infrared illuminator assembled on the physical scaled model of the overhead travelling crane with hosting capability of 150 kg.	feedback;illuminator (backlight);overhead (computing);sensor	Pawel Hyla	2015	2015 20th International Conference on Methods and Models in Automation and Robotics (MMAR)	10.1109/MMAR.2015.7283902	smart camera;stereo cameras;computer vision;simulation;machine vision;engineering;optics	Robotics	58.618641959718275	-34.35779392446983	162629
2514e1da901fb1ac1c1d746174281900533814be	experiments in adjustable autonomy	adjustable autonomy;human robot interaction;robots delays;robot control;robots;human meta level control adjustable autonomy human robot interaction human robot system prototype interface robot behaviors;delays;delay effects humanoid robots prototypes intelligent robots robot control human robot interaction supervisory control remotely operated vehicles mobile robots switches	Human-robotinteractionis becominganincreasinglyimportant researcharea. In this paper , we presentour work on designinga human-robotsystemwith adjustableautonomy anddescribenotonly theprototypeinterfacebut alsothecorrespondingrobot behaviors. In our approach,we grant the humanmeta-level control over the level of robot autonomy, but we allow the robot a varying amountof self-direction with eachlevel. Within this framework of adjustableautonomy, we explore appropriateinterfaceconceptsfor controlling multiple robotsfrom multiple platforms.	autonomy;robot	Jacob W. Crandall;Michael A. Goodrich	2001		10.1109/ICSMC.2001.973517	human–robot interaction;robot;mobile robot;robot learning;simulation;articulated robot;computer science;humanoid robot;artificial intelligence;social robot;arm solution;robot locomotion;control theory;robot control;ubiquitous robot;personal robot	Robotics	61.212926161700196	-26.83559499864998	162650
2fd134d3ddbe9b349c8ff8286327988e5614ff37	haptic perception of shape and hollowness of deformable objects using the anthrobot-iii robot hand			robot	Ismet Erkmen;Aydan M. Erkmen;A. Erman Tekkaya;T. Pasinlioglu	1999	J. Field Robotics	10.1002/(SICI)1097-4563(199901)16:1%3C9::AID-ROB2%3E3.0.CO;2-%23	computer vision;simulation;computer science	Robotics	67.90722471121272	-28.600895001306256	162731
a69869cac82c483727ad9478d3321eecb754da08	robotic system for inspection of test objects with unknown geometry using ndt methods	robot movil;complejo industrial;ensayo no destructivo;non destructive testing;walking;caminata;control technology;trajectoire optimale;essai non destructif;defecto;dexterity;industrial complex;manipulateur;palpador;robotics;orientation;pressure vessel;regulacion de la posicion;comportement grimpeur;aube turbine;remote operation;eddy current;paleta turbina;robot arm;commande force;commande position;marche a pied;robot control;robot mobile;non destructive test;manipulador;position control;walking robot;optimal trajectory;dexterite;teleaccion;defect;trayectoria optima;turbine blade;defaut;robotica;orientacion;complexe industriel;control fuerza;arm;bras;palpeur;brazo;robotique;permanent magnet;climbing behavior;destreza;comportamiento trepador;data acquisition;manipulator;stylus;moving robot;force sensor;teleoperation;design methodology;force control	Purpose – The purpose of this paper is to develop a portable non‐destructive testing (NDT) robotic arm that can be carried by climbing and walking robots (CLAWAR). The arm is required to maintain, during a scanning trajectory, a desired NDT probe contact force and orientation to evaluate defects in geometrically complex industrial infrastructure and products such as turbine blades.Design/methodology/approach – A seven‐axis arm transportable by CLAWAR was developed to deploy NDT probes with suitable dexterity. It was equipped with a force sensor to scan a complex shape by keeping the NDT probe normal to the surface while maintaining a constant contact force with it. Two approaches were used. One used permanent magnet adhesion to obtain secure contact while the other used position‐force‐moment (PFM) feedback to adapt the arm.Findings – Tests were performed on turbine blades with eddy‐current inspection techniques to assess the quality of defect data using manual inspection and automated inspection. Signific...		Tariq Pervez Sattar;Alina-Alexandra Brenner	2009	Industrial Robot	10.1108/01439910910957093	control engineering;simulation;nondestructive testing;computer science;engineering;artificial intelligence;robotics;engineering drawing	Robotics	64.55800164778437	-32.918081850165294	162791
0671a708dc2328a04b28dd632c47bd7e25cbf264	self-organized flocking with a mobile robot swarm	mobile robot;self organization;swarm robotics;flocking	In flocking, a swarm of robots moves cohesively in a common direction. Traditionally, flocking is realized using two main control rules: proximal control, which controls the cohesion of the swarm using local range-and bearing information about neighboring robots; and alignment control, which allows the robots to align in a common direction and uses more elaborate sensing mechanisms to obtain the orientation of neighboring robots. So far, limited attention has been given to motion control, used to translate the output of these two control rules into robot motion. In this paper, we propose a novel motion control method: magnitude-dependent motion control (MDMC). Through simulations and real robot experiments, we show that, with MDMC, flocking in a random direction is possible without the need for alignment control and for robots having a preferred direction of travel. MDMC has the advantage to be implementable on very simple robots that lack the capability to detect the orientation of their neighbors. In addition, we introduce a small proportion of robots informed about a desired direction of travel. We compare MDMC with a motion control method used in previous robotics literature, which we call magnitude-independent motion control (MIMC), and we show that the swarms can travel longer distances in the desired direction when using MDMC instead of MIMC. Finally, we systematically study flocking under various conditions: with or without alignment control, with or without informed robots, with MDMC or with MIMC.	aerial photography;align (company);apache axis;collective motion;control theory;experiment;flocking (behavior);futures studies;marco dorigo;mobile robot;optic axis of a crystal;point of view (computer hardware company);reference frame (video);requirement;self-organization;simulation;swarm intelligence;swarm robotics;wheels	Ali Emre Turgut;Hande Çelikkanat;Fatih Gökçe;Erol Sahin	2008		10.1145/1402383.1402394	mobile robot;swarm robotics;self-organization;simulation;computer science;artificial intelligence;flocking	Robotics	60.17889970087015	-24.916451290864895	162861
7ca3c6daeaefabd1790862ee08debf90278dbdba	navigating multiple mobile robots without direct communication		A bulk of research is being done for the autonomous navigation of a mobile robot. Multi-robot motion planning techniques often assume a direct communication amongst the robots, which makes them practically unusable. Similarly approaches assuming the robot moving amidst humans assume cooperation of humans which may not be the case if the human is replaced by a robot. In this paper a deliberative planning at the higher level with a new cell decomposition technique is presented, along with a reactive planning technique at the finer level which uses fuzzy logic. Coordination amongst the robots in the absence of direct communication and knowledge of other robot’s intent is a complex research question, which is solved using a simple fuzzy based modelling. Experimental results show that the multiple robots maintain comfortable distances from the obstacles, robots navigate by near optimal paths, robots can easily escape previously unseen obstacles, and robots coordinate with each other to avoid collision as well as maintain a large separation. This work displays a simple and easy to interpret system for solving complex coordination problem in multi-robotics.	autonomous robot;deadlock;fuzzy logic;inference engine;mobile robot;motion planning;reactive planning;robotics;simulation;usability	Rahul Kala	2014	Int. J. Intell. Syst.	10.1002/int.21662	simulation;artificial intelligence;social robot	Robotics	56.553300893461724	-25.339738173741683	163051
82a2e80cc2eafcf017409386a3b9961e86d53801	the space station freedom evolution-phase: crew-eva demand for robotic substitution by task primitive	crew performed extravehicular activities;manipulators;task primitive;kernel;generic task activities;orbital assembly;extravehicular activity;tear down aerospace control robots telecontrol space station freedom task primitive crew performed extravehicular activities generic task activities task setup kernel;telecontrol aerospace control robots;space tools;orbital robotics;assembly;aerospace control;tear down;robots;space stations;task setup;telecontrol;space stations orbital robotics robotics and automation space technology assembly manipulators propulsion laboratories kernel frequency;propulsion;space technology;frequency;spacecrews;robotics and automation;space station freedom	Space Station Freedom (SSF) represents a significant demand for automation and robotics services as substitutes for crew-performed extra-vehicular activities (crew-EVA). This paper describes a recent study aimed at identifying this demand (requirements) for crew-performed activities and the crew task primitive distributions derived for input to future robotic substitution studies [l]. Generic EVA tasks are developed from historical EVA mission timelines and a set of seventy task primitives defined. are partitioned into task setup, kernel, and teardown with standardized task times and frequencies. These standardized times are coupled with inputs from numerous mission databases in a probabilistic simulation to obtain estimates of total crew-EVA task time demand by crew task primitive. The generic task activities	database;requirement;robot;shortest seek first;simulation;timeline	Jeffrey H. Smith;Jay Estus;Cate Heneghan;Charles Nainan	1989		10.1109/ROBOT.1989.100187	robot;kernel;real-time computing;simulation;propulsion;computer science;engineering;artificial intelligence;frequency;extra-vehicular activity;task analysis;assembly;space technology;quantum mechanics	Robotics	63.130365034314146	-29.171071952328468	163088
6535b4c8ac0d7c0cdae9698df6e41f7b317c904f	maximum reward collection problem: a cooperative receding horizon approach for dynamic clustering	maximum reward collection problem mrcp;cooperative receding horizon crh	In this paper, the Maximum Reward Collection Problem (MRCP) in uncertain environments is investigated where multiple agents cooperate to maximize the total reward collected from a set of moving targets in the mission space with unknown arrival times, trajectories and dynamics. The reward with respect to each of the targets has a time discounting value and can be collected only if a cluster of agents with proper number of elements visits the targets. Meanwhile, in each cluster, it is assumed that agents are able to extract a larger fraction of reward when their configuration in the cluster is close to specific configuration around the respective target. The inherited uncertainty in the environment and the dynamic clustering factor render the one-shot optimization in MRCP rather impractical. Therefore, a Cooperative Receding Horizon (CRH) controller is utilized toward maximizing the collected reward and based on the prediction of the future positions of targets with the given limited information. Some analytical aspects of problem is discussed and the effectiveness and advantages of the proposed algorithm is demonstrated via numerical simulations.	algorithm;cluster analysis;computer simulation;mathematical optimization;numerical analysis	Mohammad Khosravi;Hossein Khodadadi;Amir G. Aghdam;Hassan Rivaz	2015		10.1145/2811411.2811550	mathematical optimization;simulation;reward-based selection;engineering;control theory	ML	55.1934207444693	-25.35292666243418	163207
ddcf76c283cc20e75718de4af5aa97de41737dbb	flexible control of complex kinematic chains		Robots providing meaningful services in unconstraint environments require advanced mobility, manipulation, sensing and perception capabilities. KUKA’s task in DESIRE was to develop robot arms and control hardware and software that are flexible with respect to the number of degrees of freedom and their connections to build kinematic chains and the type of sensors used to perceive the environment. To enable the DESIRE project partners and research partners beyond the DESIRE consortium to work with advanced lightweight torquecontrolled robot arms KUKA and DLR engaged in a technology transfer leading to the commercialization of the DLR Lightweight Robot. After many innovative steps, first at DLR beginning in the early 1990s, later at DLR and KUKA, both partners managed to successfully go the strenuous road from the original invention, an idea made manifest in 1991, to prototypes produced in a small series starting in December 2008 [5]. This paper first reviews the most important steps leading to this development. Second, the development of flexible controllers which enabled the project partners to integrate the KUKA-DLR Lightweight Robot in a dual-arm robot system is presented. Furthermore, independent KUKA demonstrators – an omnidirectional mobile manipulator and a dual arm system – are introduced which demonstrate the capabilities of a newly developed controller framework.	coat of arms;dynamic language runtime;kinematic chain;mobile manipulator;robot;sensor	Rainer Bischoff;Günter Schreiber;Bernd Finkemeyer;Yevgen Kogan;Marinus Danzer;Johannes Kurth	2012		10.1007/978-3-642-25116-0_22	kinematic chain	Robotics	65.65639473103899	-28.2705874000703	163218
238f20ec69627ceb40cfef17bde3dbfde6e6687a	artificial behavioral system by sensor-motor mapping strategy for multi-objective robot tasks	learning process;genetic program;fuzzy neural nets;evolutionary computation;diploid genetic programming;virtual reality viewer;self learning processes;mobile robot;virtual reality;behavior generation;inference mechanisms;mobile robots;sensor motor mapping strategy;fuzzy inference structures;nonholonomic constraints;fuzzy logic;robot behavior;robot sensing systems mobile robots robot kinematics laboratories robot control control systems orbital robotics sensor systems fuzzy logic intelligent robots;multiobjective robot tasks;artificial behavioral system;fuzzy inference;multi robot systems;fuzzy inference system;four wheel steered mobile robot;relational fuzzy logic;evolutionary neural fuzzy inference system;control engineering computing;kinematics and dynamics;autonomous robotics robot behavior som neural networks relational fuzzy logic diploid genetic programming;robot dynamics;autonomous robotics;real time application;autonomous robot;som neural networks;fuzzy inference structures artificial behavioral system sensor motor mapping strategy multiobjective robot tasks robot control architecture four wheel steered mobile robot evolutionary neural fuzzy inference system behavior generation self learning processes robot kinematics robot dynamics nonholonomic constraints virtual reality viewer;robot kinematics;neural network;robot control architecture;virtual reality control engineering computing evolutionary computation fuzzy neural nets inference mechanisms mobile robots multi robot systems robot dynamics robot kinematics	In this study, behavioral system based robot control architecture is built up for a four-wheel driven and four-wheel steered mobile robot. Behavioral system is determined as evolutionary neural-fuzzy inference system for behavior generation and self-learning processes in the general robot control architecture. The kinematics and dynamic model of the mobile robot with non-holonomic constraints is used as present structure which is modeled in previous studies. The posture and speed of the robot and the configurations, speeds and torques of the wheels can be observed from the simulation plant and virtual reality viewer. The behaviors are investigated regarding their gains, fuzzy inference structures, real-time applicability and their coordination.	artificial intelligence;artificial neural network;embedded system;fuzzy logic;fuzzy set;genetic programming;grid network;inference engine;mathematical model;mobile robot;network architecture;poor posture;programming paradigm;real-time locating system;robot control;self-organizing map;simulation;virtual reality;wheels	Evren Daglarli;Hakan Temeltas	2007	Third International Conference on Natural Computation (ICNC 2007)	10.1109/ICNC.2007.268	control engineering;mobile robot;robot learning;simulation;engineering;artificial intelligence;social robot;robot control;mobile robot navigation;robot calibration	Robotics	61.088247416219865	-26.48118746695847	163343
40253d8c726793fe8f3603ab04530e8a4599b093	omnidirectional mobile platform for research and development	platform;omnidirectional driving mechanism;robocup			Kuniaki Kawabata;Tsuyoshi Suzuki;Hayato Kaetsu;Hajime Asama	2002	JRM	10.20965/jrm.2002.p0105	simulation	Robotics	56.81336499599133	-29.7029495785363	163558
12853df772e2e0d8d6a6561d296ef08c0c7f2b7e	sensor data fusion using unscented kalman filter for vor-based vision tracking system for mobile robots		This paper presents sensor data fusion using Unscented Kalman Filter (UKF) to implement high performance vestibulo-ocular reflex (VOR) based vision tracking system for mobile robots. Information from various sensors is required to be integrated using an efficient sensor fusion algorithm to achieve a continuous and robust vision tracking system. We use data from low cost accelerometer, gyroscope, and encoders to calculate robot motion information. The Unscented Kalman Filter is used as an efficient sensor fusion algorithm. The UKF is an advanced filtering technique which outperforms widely used Extended Kalman Filter (EKF) in many applications. The system is able to compensate for the slip errors by switching between two different UKF models built for slip and no-slip cases. Since the accelerometer error accumulates with time because of the double integration, the system uses accelerometer data only for the slip case UKF model. Using sensor fusion by UKF, the position and orientation of the robot is estimated and is used to rotate the camera mounted on top of the robot towards a fixed target. This concept is derived from the vestibuloocular reflex (VOR) of the human eye. The experimental results show that the system is able to track the fixed target in various robot motion scenarios including the scenario when an intentional slip is generated during robot navigation.	algorithm;digital single-lens reflex camera;encoder;extended kalman filter;gyroscope;image sensor;mobile robot;robotic mapping;tracking system	Muhammad Latif Anjum;Omar Ahmad;Basilio Bona;Dong-Il Cho	2013		10.1007/978-3-662-43645-5_12	control engineering;computer vision;engineering;control theory;sensor fusion	Robotics	56.810727089388344	-35.37067215823631	163846
0b6d97e39cc5ba8ed924caea80e3bb29c513c0e7	estimation of the position and orientation of a planar surface using multiple beams	robot sensing systems;design automation;robot arm pose estimation orientation estimation planar surface multiple beams sensory system laser beams camera industrial environment automation;service robots;laser beams;length measurement;computer industry;aerospace industry;computer vision;multiple beams;laser beam applications parameter estimation computer vision cameras;robot arm;planar surface;industrial environment;sensory system;laser beams cameras robot vision systems robotics and automation surface emitting lasers design automation robot sensing systems head length measurement aerospace industry;head;parameter estimation;surface emitting lasers;laser beam applications;orientation estimation;robot vision systems;robotics and automation;cameras;camera;pose estimation;automation	A sensory system consisting of a camera and several laser beams is described. It is designed for estimating the parameters of a planar surface with respect to the camera. Estimation is possible when the beam positions and directions are known, as well as the image of the beam spots on a planar surface. The system is readily applicable in an industrial environment for automation, if it is attached to a robot arm and is connected to a computer. >		Jaekyu Ha;Robert M. Haralick	1993		10.1109/CVPR.1993.341054	sensory system;computer vision;simulation;pose;robotic arm;electronic design automation;length measurement;computer science;automation;aerospace;estimation theory;head	Robotics	60.82528415961088	-36.15808991649111	163896
50ee38e59315c805efbd75d44ad91b4bfd3b35e1	autonomous gait transition and galloping over unperceived obstacles of a quadruped robot with cpg modulated by vestibular feedback		Abstract The aim of this paper is to demonstrate, based on robot results, the effectiveness and practicability of vestibular feedback to central pattern generators (CPG) employed for the locomotion of quadruped robots. We build a new quadruped robot with mechanisms enabling walking to running and apply CPGs modulated by simple vestibular sensory feedback (a body tilt multiplied by a fixed gain). As a result, the robot safely locomotes at a variety of speeds by autonomously changing the gait from walking to trotting to galloping according to speed, despite the fact that the walk and gallop are not preprogrammed. In addition, as this paper’s major contribution, we discover and demonstrate that the robot robustly runs with an emergent gallop while stepping on and over several types of unperceived obstacles, while being suddenly pulled forward, and while the physical balance is changed (i.e., a weight is put forward on the robot), by autonomously modifying the phase differences between the four legs from the basic gallop. To our knowledge, no other galloping robots have been reported that can adapt to an unperceived obstacle. We conclude that CPGs modulated by vestibular feedback is effective and practical as a gait generator for bio-inspired robots that are expected to have both the abilities of “speed-based autonomous gait transition” and “autonomous robust running”.		Takahiro Fukui;Hisamu Fujisawa;Kotaro Otaka;Yasuhiro Fukuoka	2019	Robotics and Autonomous Systems	10.1016/j.robot.2018.10.002	simulation;central pattern generator;obstacle;gait;vestibular system;robot;computer science;control engineering	Robotics	66.14809404282931	-24.924361957535943	164246
07d4bff4b6665e9ae2d07881cbe88d9e7ca00b98	behavior integration for whole-body close interactions by a humanoid with soft sensor flesh	whole body;robot sensing systems;tactile sensors humanoid robots human robot interaction;tactile sensor;integrable system;tactile sensors sensor systems robot sensing systems hardware human robot interaction humanoid robots multimodal sensors force sensors event detection fabrics;interaction behavior;3d force directions;human robot interaction;distributed sensors;humanoid robots;monitoring;behavior integration system;whole body close interactions;parallel evaluating monitors whole body close interactions soft sensor flesh humanoid robots whole body contacts 3d force directions interaction behavior tactile sensors distributed sensors behavior integration system;robots;tactile sensors;face;humans;parallel evaluating monitors;whole body contacts;robot kinematics;soft sensor flesh	In order for humanoids to be able to have close interactions with humans or environments using whole body contacts, development of humanoids with soft sensor flesh is one of the key issues. Therefore we have been developed dasiamacrapsila, a humanoid with soft sensor flesh, and it can sense distributed 3D force directions during interaction behavior with humans or environments. However, development of such hardware system itself is not enough. For utilizing the hardware ability more effectively, design of interaction behavior using rich sensor information including tactile sensors is indispensable. Clearly, the analytical design for the specific task is getting harder for such humanoids. This is because those kinds of humanoids are expected to have many contact points with outer environments during their interaction behavior. Also, many locally occurred events, which humanoids have to response, are detected by the distributed sensors. In order to deal with such complex circumstances, behavior integration system is introduced in the interaction behavior of the humanoids with soft sensor flesh. By introducing such behavior integration system, adaptability to many local events can be added incrementally. Also the analytically designed and slightly limited behaviors can be accumulated for generating next richer behavior during the close interactions with humans or outer environments. As such behavior integration system, dasiaParallel Evaluating Monitorspsila are introduced and applied to the macra's interaction behaviors with humans and environments in this paper.	interaction;tactile sensor	Tomoaki Yoshikai;Marika Hayashi;Yui Ishizaka;Takashi Sagisaka;Masayuki Inaba	2007	2007 7th IEEE-RAS International Conference on Humanoid Robots	10.1109/ICHR.2007.4813856	human–robot interaction;computer vision;simulation;computer science;artificial intelligence;tactile sensor	Robotics	61.059801285232346	-27.79865512685987	164301
a741aeccb4d369d4554f3ef377d18549f27d52ab	passive target location using bearings from a platform whose track is uncertain (corresp.)	tracking direction finding parameter estimation;parameter estimation;direction finding;tracking	Suppose that a moving platform measmw the relative bearings of a number of distant targets. If the platform track is precisely known and the targets are stationary, then two sucsessive bearings are sufficient to identify the location of a given target using triangulation. As there is always some error in the bearing estimates, additional bearings are needed to obtain a more accurate estimate of each target's location. If the position of the platform is ancertaiq then the target location problem is more complicated. Simple ad hoc estimators of target coordinates when there are significant random errors in the measurem ent of the platform track are presented. The only assumption made about the platform track is that it is distant from the targets.		Melvin J. Hinich	1980	IEEE Trans. Information Theory	10.1109/TIT.1980.1056181	simulation;geodesy;control theory;mathematics;tracking;estimation theory;statistics	Embedded	55.25434106811583	-34.81506133816449	164457
3e37fd2ab458515fa28707572f595448fd079f37	cooperative localisation of uavs in a gps-denied environment using bearing measurements	observers;noise measurement;trajectory;coordinate measuring machines;extraterrestrial measurements;unmanned aerial vehicles	This paper studies the problem of localising a Global Positioning System (GPS)-denied Unmanned Aerial Vehicle (UAV) in two-dimensional space. Suppose there are two vehicles, one which is equipped with GPS and the other is GPS-denied (but has an inertial navigation system (INS) and so is able to determine its trajectory in a local coordinate frame, but not a global coordinate frame). The GPS-equipped vehicle broadcasts its global coordinates to the GPS-denied vehicle and the GPS-denied vehicle also obtains, in its local coordinate frame, a bearing measurement of the GPS-equipped UAV. The paper shows that with four or more such measurements and generic trajectories of the two UAVs, localisation in a global coordinate frame of the GPS-denied UAV is achievable. Certain nongeneric trajectories for which localisation is impossible are also identified. While in the first instance, the solution assumes zero noise in the measurements, the techniques are then extended to deal with the presence of measurement noise.	8k resolution;extended kalman filter;global positioning system;inertial navigation system;language localisation;numerical linear algebra;particle filter;simulation;uav outback challenge;unmanned aerial vehicle	Lvtianyang Zhang;Mengbin Ye;Brian D. O. Anderson;Peter Sarunic;Hatem Hmam	2016	2016 IEEE 55th Conference on Decision and Control (CDC)	10.1109/CDC.2016.7798924	computer vision;simulation;noise measurement;trajectory;aeronautics	Robotics	55.28552565372026	-34.81827517597902	164484
92a1306a3ab0d309d75ba9af885efa1ec4bb1c98	filtering approach to online estimate the position of high-speed train	intelligent transportation systems;conferences	It's of great significance to achieve high-accuracy positioning for the safe operation and running efficiency of high-speed trains. Positioning error will accrete as train is moving away from balise. Not until the train passes through next balise group will the accumulated error be corrected. In this paper, integrated filtering approach is presented to online estimate the position of high-speed train. We firstly proceed the statistical analysis of relative range error defined by the ratio of correcting value to the link distance of balise. It indicates that the relative error conforms to the normal distribution. Then an approximate model is proposed for range acquisition, which can be offline and online identified by least squares support vector regression. Basing on the noise statistics and model of range acquisition, a linear model for updating relative position of high-speed train is proposed. And we use linear Kalman filter to estimate the position states, according to linear model. Thus obtaining the absolute position of train referring to the location of balise coordinate. Simulations are conducted with field data from type tests of trains. Results show that the procedure presented in this paper can bring at least 35.34% higher precision of positioning as regards Mean Absolute Percentage Error.	approximation algorithm;approximation error;computer simulation;global positioning system;kalman filter;least squares;linear model;link distance;mean squared error;online and offline;support vector machine	Qingpeng Gan;Kaicheng Li;Lei Yuan;Qiang Fu	2016	2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2016.7795704	control engineering;simulation;computer science;control theory	Robotics	58.50560597154793	-36.59532030239839	164551
20cb1b5ce4e66bebdfdc9a921a11a7e098fdcf25	improved tau-guidance and vision-aided navigation for robust autonomous landing of uavs		Abstract In many unmanned aerial vehicle (UAV) applications, flexible trajectory generation algorithms are required to enable high levels of autonomy for critical mission phases, such as take-off, area coverage, and landing. In this paper, we present a guidance approach which uses the improved intrinsic tau guidance theory to create spatio-temporal 4-D trajectories for a desired time-to-contact with a landing platform tracked by a visual sensor. This allows us to perform maneuvers with tunable trajectory profiles, while catering for static or non-static starting and terminating motion states. We validate our method in both simulations and real platform experiments by using rotary-wing UAVs to land on static platforms. Results show that our method achieves smooth landings within 10 cm accuracy, with easily adjustable trajectory parameters.	aerial photography;algorithm;algorithmic efficiency;autonomous robot;experiment;global positioning system;ground truth;newman's lemma;rotary woofer;simulation;switzerland;unmanned aerial vehicle	Amedeo Rodi Vetrella;Inkyu Sa;Marija Popovic;Raghav Khanna;Juan I. Nieto;Giancarmine Fasano;Domenico Accardo;Roland Siegwart	2017		10.1007/978-3-319-67361-5_8	computer science;artificial intelligence;computer vision;trajectory	Robotics	54.01548087537778	-36.36049646569959	164675
3fc23de3d90dc7d77ca9eb10bfac63e8fbea6ced	state space modeling of dimensional variation propagation in multistage machining process using differential motion vectors	machining;state space methods;industrial robots machining state space methods error analysis;indexing terms;process design;error analysis;state space methods machining fixtures symmetric matrices thermal force robot kinematics orbital robotics solid modeling fault diagnosis process design;motion vector;industrial robots;deviation transformation state space modeling dimensional variation propagation multistage machining process differential motion vectors machining errors robotics field deviation accumulation;state space model;state transition	In this paper, a state space model is developed to describe the dimensional variation propagation of multistage machining processes. A complicated machining system usually contains multiple stages. When the workpiece passes through multiple stages, machining errors at each stage will be accumulated and transformed onto the workpiece. Differential motion vector, a concept from the robotics field, is used in this model as the state vector to represent the geometric deviation of the workpiece. The deviation accumulation and transformation are quantitatively described by the state transition in the state space model. A systematic procedure that builds the model is presented and an experimental validation is also conducted. The validation result is satisfactory. This model has great potential to be applied to fault diagnosis and process design evaluation for complicated machining processes.	cross-validation (statistics);multistage amplifier;robotics;software propagation;state space;state transition table;state-space representation;tree accumulation	Shiyu Zhou;Qiang Huang;Jianjun Shi	2003	IEEE Trans. Robotics and Automation	10.1109/TRA.2003.808852	control engineering;process design;index term;machining;engineering;state-space representation;engineering drawing;mechanical engineering	Robotics	62.021603145013614	-35.49900434967104	164716
4e95d7995048e10fb7476621e6f027ae449e755f	a cascaded two-step kalman filter for estimation of human body segment orientation using mems-imu	microsensors biomechanics biomedical measurement biomems body sensor networks inertial systems kalman filters kinematics magnetic sensors medical signal processing;human body segment orientation estimation magnetically disturbed conditions kinematically disturbed conditions tactical grade imu yaw angle calculation tilt angles cascaded two step kalman filter orientation estimation algorithm miniature body worn mems based inertial measurement units raw data drift free 3 d orientation biomechanical analyses mems imu;kalman filters vectors acceleration magnetometers accelerometers gyroscopes estimation	Orientation of human body segments is an important quantity in many biomechanical analyses. To get robust and drift-free 3-D orientation, raw data from miniature body worn MEMS-based inertial measurement units (IMU) should be blended in a Kalman filter. Aiming at less computational cost, this work presents a novel cascaded two-step Kalman filter orientation estimation algorithm. Tilt angles are estimated in the first step of the proposed cascaded Kalman filter. The estimated tilt angles are passed to the second step of the filter for yaw angle calculation. The orientation results are benchmarked against the ones from a highly accurate tactical grade IMU. Experimental results reveal that the proposed algorithm provides robust orientation estimation in both kinematically and magnetically disturbed conditions.	algorithm;algorithmic efficiency;benchmark (computing);computation;deuterium exchange measurement;kalman filter;magnetic resonance imaging;mathematical optimization;medication event monitoring system;microelectromechanical systems;motion;multiple encryption;yaws;sensor (device)	Shaghayegh Zihajehzadeh;Darrell Loh;M. Lee;Reynald Hoskinson;E. J. Park	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6945062	control engineering;electronic engineering;engineering;control theory	Robotics	58.631281108483165	-37.41895285340023	164992
4c129c200e9aad96e62d5c7ee92b97c9c2f0ea17	argos - system for heterogeneous mobile robot teleoperation	telepresence;mobile robots robot sensing systems reconnaissance humanoid robots dc motors control systems user interfaces personal digital assistants intelligent robots instruments;advanced robotic graphical operation system;mobile robot;user interface;heterogeneous mobile robot teleoperation;ccd color camera argos heterogeneous mobile robot teleoperation advanced robotic graphical operation system visual telepresence orpheus hermes data fusion;telerobotics ccd image sensors control engineering computing mobile robots sensor fusion;mobile robots;data fusion;ccd image sensors;visual telepresence;operating system;telerobotics;control engineering computing;sensor fusion;data fusion telepresence user interface mobile robot;argos;hermes;ccd color camera;orpheus	ARGOS (advanced robotic graphical operation system) for teleoperation of various mobile robots through sensory supported visual telepresence is presented. Two robots -Orpheus and Hermes - made on Department of Control and Instrumentation (DCI) are described as examples of systems with different features and capabilities that may be controlled through ARGOS. Integration of 3D scanners to the robots and their measurement to ARGOS system is presented. Data fusion of CCD color camera data, thermovision data and 3D proximity data through extended 3D robot evidence grids is described	3d scanner;charge-coupled device;digitally controlled impedance;graphical user interface;mobile robot;operating system;real-time clock;real-time computing;sensor	Ludek Zalud	2006	2006 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2006.282495	mobile robot;embedded system;computer vision;simulation;computer science;engineering;artificial intelligence;sensor fusion	Robotics	58.98842081731641	-31.38939977631858	165082
8727026463bf4572edfd8003abc8739f61b55faa	factory automation adapted for the decommissioning of nuclear reprocessing facilities	manufacturing automation service robots robotics and automation nuclear fuels humans robot vision systems research and development control systems plasma measurements programmable control;control systems;materials handling factory automation industrial robots nuclear fuel cycle facilities;radioactive facilities;nuclear industry;programmable control;manufacturing automation;service robots;decommissioning;control system;research and development;factory automation decommissioning nuclear reprocessing facilities radioactive facilities nuclear industry industrial robots;plasma measurements;materials handling;industrial robots;nuclear fuels;nuclear fuel cycle facilities;factory automation;humans;nuclear reprocessing facilities;robot vision systems;robotics and automation	Decommissioning of redundant radioactive facilities is a growing world wide activity engaging the nuclear industry. This paper reports the results of recent research and development into the use of industrial robots for decommissioning tasks. A brief discussion of the decommissioning problem domain compared with factory automation is followed by a description of the control system developed to utilise factory automation robotics.	automation	A. Bicknell;G. Hardey	1998		10.1109/ROBOT.1998.676318	engineering;control system;automation;nuclear decommissioning;manufacturing engineering;mechanical engineering	EDA	65.97636692038579	-28.5430027180149	165104
4809b6a9011e86dfa55bef2b517bcbf1da27b949	new traversability indices and traversability grid for integrated sensor/map-based navigation		This paper presents new measures of terrain traversability at short range and long range of a mobile robot; namely, local and global traversability indices. The sensor-based local traversability index is related by a set of linguistic rules to large obstacles and surface softness within a short range of the robot measured by on-board sensors. The map-based global traversability index is obtained from the terrain topographic map, and is based on major surface features such as hills and lakes within a long range of the robot. These traversability indices complement the mid-range sensor-based regional traversability index introduced earlier. Each traversability index is represented by four fuzzy sets with the linguistic labels POOR, LOW, MODERATE, HIGH , corresponding to surfaces that are unsafe, moderately-unsafe, moderately-safe, and safe for traversal, respectively. The global terrain analysis also leads to the new concepts of traversability map and traversability grid for representation of terrain quality based on the global map information. The traversability indices are used in two sensor-based traverse-local and traverse-regional behaviors and one map-based traverse-global behavior. These behaviors are integrated with a map-based seek-goal behavior to ensure that the mobile robot reaches its goal safely while avoiding both sensed and mapped terrain hazards. This provides a unified system in which the two independent sources of terrain quality information, i.e., prior maps and on-board sensors, are integrated together for reactive robot navigation. The paper is concluded by a graphical simulation study. © 2003 Wiley Periodicals, Inc. • • • • • • • • • • • • • • • • • • • • • • • • • • • • • • •	fuzzy set;graphical user interface;john d. wiley;map;mobile robot;on-board data handling;robotic mapping;sensor;simulation;traverse;topography;tree traversal	Homayoun Seraji	2003	J. Field Robotics	10.1002/rob.10074	computer vision;remote sensing	Robotics	54.10726356476403	-31.30469559981258	165268
33fefa934829664f4c3da2e0bba0f1511112140b	on-line collision-free path planning for service and assembly tasks by a two-arm robot	kamro online collision free path planning service tasks assembly tasks two arm robot two arm manipulator system action sequence planning 2d geometric model swept regions robot arms pay loads dynamic deadlock free scheduling concept regrasping off line connectivity analysis;robot programming path planning manipulators;manipulators;pay loads;online collision free path planning;kamro;path planning;robot arms;mobile robots;robot arm;action sequence planning;system recovery;2d geometric model;dynamic deadlock free scheduling concept;regrasping;path planning motion planning manipulators robot kinematics robotic assembly solid modeling system recovery dynamic scheduling robot motion mobile robots;system integration;solid modeling;motion planning;robot motion;robotic assembly;off line connectivity analysis;geometric model;swept regions;two arm robot;assembly tasks;service tasks;robot programming;dynamic scheduling;two arm manipulator system;robot kinematics	This paper presents a new approach for on-line collision-free path planning of a two-arm manipulator system, integrated in an on-line task-level planning system. For service and assembly tasks, pick and place operations are requested asynchronously by the action sequence planning. Collision-free paths for independent tasks are planning using a 2D geometric model in consideration of the swept regions by the robot arms and the pay loads during their motions. A dynamic, deadlock-free scheduling concept coordinates the robot motions in the case that a collision-free path for one arm can not be found at moment. The on-line path planning for two-arm cooperations for exchanging and regrasping parts incorporates an off-line connectivity analysis, avoiding both collisions and kinematic restrictions. The implemented on-line planning system can generate collision-free path for one manipulator while the other is moving. The time needed for motion planning is in the average case shorter and in the worst case comparable with that needed for motion execution. Experiments have been successfully conducted with the mobile two-arm robot KAMRO at the author's institute.	motion planning;robot	Xiaoqing Cheng	1995		10.1109/ROBOT.1995.525491	control engineering;computer vision;simulation;any-angle path planning;computer science;artificial intelligence;motion planning	Robotics	59.516462670542936	-24.410926065546633	165340
f7091323c825553e1c5bae6969516fd3bf9c0617	visual control system design of wheeled inverted pendulum robot based on beaglebone black		The wheeled inverted pendulum robot has broad prospects of applications in real life. It can use two coaxial wheels to achieve the body self-balancing, forward moving and turning. But the general wheeled inverted pendulum robot seldom has vision function to perceive enviromental change. In order to realize the robust visual control, a wheeled inverted-pendulum vision robot with attitude sensors, photoelectric encoders, ultrasonic sensors and so on is designed based on Beaglebone Black board. The moving object is separated in the space domain by obtaining the image sequence which is sent by a robot-mounted camera, and the modeling, identification and tracking of target sequence are implemented in the time domain. The balance PD, speed PI and steering PD controllers are designed to realize the dynamic balance, forward and steering function of the robot. To satisfy the functional requirements of the visual tracking system, an improved tracking-learning-detection algorithm based on kernelized correlation filtering is used, and a tracking anomaly based on spatial context is detected to determine the tracking state and reduce the error rate. Experimental results show that the robot reaches the requirement of design and achieves better visual control effectiveness.	algorithm;anomaly detection;beagleboard;control system;encoder;functional requirement;inverted pendulum;kernel method;photoelectric effect;real life;robot;self-balancing binary search tree;sensor;systems design;tracking system;video tracking;wheels	Jian Lan;Jinxue Xu;Xiaoling Huang	2017	2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)	10.1109/FSKD.2017.8393254	visual control;pi;filter (signal processing);artificial intelligence;inverted pendulum;machine learning;time domain;ultrasonic sensor;mobile robot;eye tracking;control engineering;computer science	Robotics	57.07319752872331	-34.9984322224222	165584
e01578ca68741f7b691350ac55ec41d165330074	stable grasping under pose uncertainty using tactile feedback	grasping;uncertainty;tactile sensing;robustness	This paper deals with the problem of stable grasping under pose uncertainty. Our method utilizes tactile sensing data to estimate grasp stability and make necessary hand adjustments after an initial grasp is established. We first discuss a learning approach to estimating grasp stability based on tactile sensing data. This estimator can be used as an indicator to the stability of the current grasp during a grasping procedure. We then present a tactile experience based hand adjustment algorithm to synthesize a hand adjustment and optimize the hand pose to achieve a stable grasp. Experiments show that our method improves the grasping performance under pose uncertainty.	algorithm;bag-of-words model;control theory;experiment;simulation;tactile sensor	Hao Dang;Peter K. Allen	2014	Auton. Robots	10.1007/s10514-013-9355-y	computer vision;simulation;uncertainty;computer science;robustness	Robotics	61.132338447701954	-32.46350003150285	165692
ed4b79ee3e5fd5fb67bb8ba1d01b23c60c3cd6ab	a survey on decentralized flocking schemes for a set of autonomous mobile robots (invited paper)	formation generation;mobile robots;autonomous mobile robot;fault tolerance;collision avoidance;flocking	Recently, control and coordination of a set of autonomous mobile robots has been paid a lot of attentions, because the cooperation of simple robots offers several advantages, such as redundancy and flexibility, and allows performing hard tasks that could be impossible for one single robot. There are a lot of interesting applications of multiple robots, such as satellite exploration and surveillance missions. The characteristic of simplicity of mobile robots brings potential wide applications; however this characteristic also lead to crash with higher probability during cooperation, especially in harsh environment. Surprisingly, only few researches consider the fault tolerance of mobile robots, especially for dynamic coordination application--- robot flocking. In this paper, we summarize the existed flocking algorithms and discuss their characteristics. Then we briefly described our fault tolerant flocking algorithms in different models. Finally we proposed the potential future research directions for dynamic flocking of a group of mobile robots. In all, this work can provide a good reference for the researchers working on dynamic cooperation of robots in distributed system.	autonomous robot	Naixue N. Xiong;Jing He;Yan Yang;Yanxiang He;Tai-Hoon Kim;Chuan Lin	2010	JCM	10.4304/jcm.5.1.31-38	mobile robot;fault tolerance;simulation;computer science;flocking;distributed computing	Robotics	55.02060567996117	-28.02687207986819	165764
ae0ce0e2b3095637e283e657e425928e7bd99d1b	real-time soft-finger grasping of physically based quasi-rigid objects	rigid body simulator real time soft finger grasping quasi rigid object software architecture rotational friction;paper;rigid body;real time;software architecture;rigid body dynamics;nvidia geforce fx 5600;nvidia;deformable models grasping haptic interfaces computational modeling friction rendering computer graphics computer simulation layout virtual environment graphics;computer science;interface tracking;haptic interfaces;haptic interfaces real time systems digital simulation;digital simulation;real time systems	"""This paper describes the implementation of a demo. The demo of """"soft-finger grasping of physically based quasi-rigid objects"""" will provide solutions to grasp objects that are locally deformable and move according to rigid-body dynamics. This work summarizes the choices of the overall software architecture and the single algorithms used to run the simulation of """"soft-finger grasping"""" in real time on high-end hardware. The soft-finger grasping is obtained extending a local model to include rotational friction while the local deformations are achieved through displacement fields directly on the GPU. Dynamics of the objects in the scene is simulated by a rigid body simulator which allows realistic interactions with other objects existing in the scene."""	algorithm;displacement mapping;game demo;graphics processing unit;interaction;real-time transcription;simulation;software architecture	Maurizio de Pascale;Gabriele Sarcuni;Domenico Prattichizzo	2005	First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. World Haptics Conference	10.1109/WHC.2005.110	software architecture;computer vision;rigid body;simulation;rigid body dynamics;computer science;physics;computer graphics (images)	Robotics	66.33696559535356	-31.9756242835534	165851
bfb401e551f19966791597120fe068ae571305b4	characterization and compensation of xy micropositioning robots using vision and pseudo-periodic encoded patterns	accuracy position measurement trajectory interpolation cameras robot sensing systems measurement uncertainty;interpolation techniques xy micropositioning robot characterization xy micropositioning robot compensation vision patterns pseudo periodic encoded patterns microrobotic systems systematic error reduction positioning accuracy improvement position dependent error characterization microscale motion characterization range to resolution ratio look up tables;table lookup image coding interpolation micromanipulators micropositioning motion compensation robot vision	Accuracy is an important issue for microrobotic applications. High accuracy is usually a necessary condition for reliable system performance. However there are many sources of inaccuracy acting on the microrobotic systems. Characterization and compensation enable reduction of the systematic errors of the micropositioning stages and improve the positioning accuracy. In this paper, we propose a novel method based on vision and pseudo-periodic encoded patterns to characterize the position-dependent errors along XY stages. This method is particularly suitable for microscale motion characterization thanks to its high range-to-resolution ratio and avoidance of camera calibration. Based on look-up tables and interpolation techniques, we perform compensation and get improved accuracy. The experimental results show an accuracy improved by 84% for square tracking and by 68% for random points reaching (respectively from 22 μm to 3.5 μm and from 22 μm to 7 μm).	algorithm;angularjs;camera resectioning;classical xy model;linear interpolation;lookup table;robot;x–y plotter	Ning Tan;Cédric Clévy;Guillaume J. Laurent;Patrick Sandoz;Nicolas Chaillet	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907263	control engineering;computer vision;engineering;control theory	Robotics	61.26785006216875	-33.95631355408181	166074
505fa7ad34380b728699a11ad1323f25b4bd9b9e	improving estimation of vehicle's trajectory using the latest global positioning system with kalman filtering	prediction error;geographic information system;intelligent transport system;intelligent transportation systems;kalman filters;global position system;kalman filter;geographic information system gis;indexing terms;kalman filters geographic information systems global positioning system;global positioning system gps;collision avoidance trajectory global positioning system intelligent transportation systems geographic information systems kalman filters estimation;trajectory;estimation;global positioning system;geographic information systems;kalman filter kf;trajectory prediction;collision avoidance;error detection;trajectory prediction geographic information system gis global positioning system gps kalman filter kf;iterated geometrical error detection method vehicle trajectory estimation global positioning system kalman filtering gps location geographic information system data interacting multiple model imm system;global po sitioning system;interacting multiple model	This paper proposes several extensive methods to predict the future location of an automobile. The goals of this paper are to find a more accurate way to predict the future location of an automobile by 3 s ahead, so that the prediction error can be greatly reduced with the innovative idea of merging global-positioning-system (GPS) data with geographic-information-system (GIS) data. The improvement starts by applying existing techniques to extrapolate the current GPS location. Comprehensive Kalman filters (KFs) are implemented to deal with inaccuracy in the different identified possible states an automobile could be found in, which are identified as constant locations, constant velocity, constant acceleration, and constant jerks. Then, the KFs are set up to be part of a interacting-multiple-model (IMM) system that provides the predicted future location of the automobile. To reduce the prediction error of the IMM setup, this paper imports an iterated geometrical error-detection method based on GIS data. The assumption that the automobile will remain on the road is made; therefore, the predictions of future locations that fall outside are corrected accordingly, making a great reduction to the prediction error. The actual experimental results validate our proposed system by reducing the prediction error to around half of what it would be without the use of GIS data.	extrapolation;geographic information system;global positioning system;interaction;iteration;kalman filter;radar tracker;velocity (software development)	Cesar Barrios;Yuichi Motai	2011	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2011.2147670	kalman filter;computer vision;simulation;computer science;control theory;geographic information system;physics;statistics	Mobile	58.130553408076835	-36.53021393531576	166250
3dafe6fd528231b73f4efb0ef052807a7e68a128	local planning of auv based on fuzzy-q learning in strong sea flow field	auv local planning;auv;fuzzy membership function;learning;integrated reinforcement learning;underwater vehicles;sea flow field;reinforcement learning;underwater vehicles collision avoidance fuzzy logic fuzzy set theory learning artificial intelligence mobile robots;mobile robots;fuzzy set theory;fuzzy behavior;collision avoiding behavior;fuzzy logic;moving to goal behavior;local planning;navigation;artificial neural networks;see flow;flow field;autonomous underwater vehicles;collision avoidance;collision avoiding behavior auv local planning autonomous underwater vehicles fuzzy q learning sea flow field integrated reinforcement learning logic method fuzzy behavior moving to goal behavior;learning artificial intelligence;fuzzy q learning;logic method;fuzzy q;see flow local planning auv fuzzy q;fuzzy logic learning technology planning navigation orbital robotics optimization methods computer science resists algorithm design and analysis vehicle dynamics	This article integrated reinforcement learning with fuzzy logic method for AUV local planning under the strong sea flow field. A fuzzy behavior is defined to resist the sea flow by giving a extra angle towards sea flow. And Q-learning is used to adjust the peak point of fuzzy membership function of the resisting sea flow behavior. This behavior is complemented by two other behaviors, the moving-to-goal behavior and collision avoiding behavior. The recommendations of these three behaviors are integrated through adjustable weighting factors to generate the final motion command for the AUV. Simulation shows it improve the adaptability of AUV under different sea flow greatly.	fuzzy logic;q-learning;reinforcement learning;simulation	Ge Yang;Rubo Zhang;Dong Xu;Ziyin Zhang	2009	2009 International Joint Conference on Computational Sciences and Optimization	10.1109/CSO.2009.244	fuzzy logic;mobile robot;navigation;simulation;computer science;artificial intelligence;machine learning;fuzzy set;reinforcement learning;artificial neural network	Robotics	55.975835319112015	-24.032380724698307	166400
51cfd53aea66d995ad2819ec6034841bd261cb7a	teleoperator response in a touch task with different display conditions	biofeedback;mechanoception;neurologie;manual task;operateur humain;manipulators;tarea manual;mouvement corporel;electromyographie;motion control;operador humano;robot hand;performance evaluation;biocontrol;mechanoception telecontrol manipulators human factors man machine systems electromyography biocontrol feedback muscle neurophysiology;motricite;relacion hombre maquina;neurology;virtual reality;hombre;man machine relation;teleoperators;robotics;biological control systems;motricidad;remote operation;teleoperators displays fingers humans biological control systems robots virtual reality performance evaluation motion control electromyography;feedback;human factors;display conditions;teleaccion;displays;tâche manuelle;neurology teleoperator response touch task display conditions human biofeedback response virtual reality direct view telemanipulation surface emg neuromuscular activity;robots;motricity;direct view;human;neurologia;fingers;touch task;human operator;telecontrol;human biofeedback response;robotica;electromyography;man machine interface;humans;robotique;relation homme machine;neurophysiology;electromiografia;movimiento corporal;teleaction;telemanipulation;man machine systems;teleoperator response;neuromuscular activity;body movement;muscle;homme;surface emg	This paper deals with the evaluation of human biofeedback response in virtual reality and in direct view. The experiments have been performed with a new paradigm for the evaluation of human biofeedback during the telemanipulation performance of a touch task. The controlled motion of one finger is monitored with the surface EMG, while a mechanical robotized hand finger follows the motion imposed by the human finger. The biofeedback is detected in a direct way, by the vision of the robotized finger action, and in an indirect way, with the support of three different types of interfaces. The neuromuscular activity presents different features and delays in the four cases: A measurement of the attention and participation in the madmachine interface is obtained, in a first series of experiments. The paradigm adopted in this research is the result of the integration of robotics and neurology. 1. NEUROBIOLOGY AND NEUROROBOTICS PROJECT This paper examines the influence of biofeedback on the muscular strategy by which a motion plan is executed. In telemanipulation, the control of a remote system is performed by a human operator, as part of the telemanipulation control loop. A better understanding of mechanical and manipulating systems control can be achieved by means of a comparative study of biological systems. Hogan has investigated the problem of formalizing informational and energetic transactions in control system software and in physical systems, with application to the problem of contact during telemanipulation [ I ] . Mechanical informations such as position, pressure distribution, force and so on are required for a better knowledge of human behavior as well as of human kinematics and contact movements, while sensory systems in robotics can provide methods and tools to achieve comfortable man-machine interfaces. Human sensory fusion has been analyzed by means of virtual reality interfaces by Ishikawa 121. High fidelity real-time computer graphics displays as well as a force reflecting teleoperation simulator have been developed at JPL to provide operator aid in telemanipulation tasks, and different types of interfaces have been evaluated [ 3 ] , [4]. Manuscript received May 7. 1993, reviscd April 1, 1994 and July 10, 1994. This work was supported by C.N.R. (Italian National Council of Researches) and M.P.1 (Ministry of Education). The authors are with the Department of Mechanics, Politccnico di Milano, 20133 Milano, Italy. lEEE Log Number 9409228. The process of visual search in virtual environments has been investigated by Stark et a/., as well as the role of visual depth cues and effects of stereo and occlusion on simulated manipulation [5] . Experimental studies were conducted by Massimino and Sheridan to determine the effects of visual and force feedback on human performance in telemanipulation, with varying frame rates and subtended visual angles, with and without force feedback [6]. Kazerooni has proposed a framework for the design of a telerobot controller in which the dynamic behaviors of master and slave systems are mutually dependent [7]. In his book [SI, Sheridan provides a wide survey on the efforts that have been made to model the man-in-the-loop and the operator’s role in supervisory control. Our research provides an experimental evaluation of the different control strategies adopted by the human neuromuscular system when the same teleoperation task is performed with the aid of different madmachine interfaces 191, I I O ] , [ 1 1 1. The EMG recording during a teleoperation experiment, performed both in conditions of direct visual contact with the remote environment and utilizing different interfaces, allows an investigation of the neuromuscular activity of a human subject. A better understanding of how human control is performed can then be achieved. The sensory signals processed by the cerebral cortex and the cerebellum represent the feedback aspect in the human control loop. To adjust neuromuscular activity to the desired behavior in anticipation of the sensory signals is performed by a feedfonvard control as the human motion plan does not contain, in itself, a complete description of the task 1121. In this experiment, the operator wears an exoskeleton system that drives the mechanical finger motion. During the operator’s finger motion, the sensed signals from the exoskeleton change and these changes provide signals to actuate the mechanical finger. The sensory biofeedback in the tests is obtained by the eyes, which are observing the performance of the telemanipulation action and the contact force of the robotic finger, depicted on a monitor or expressed by the bending of a loaded blade. The line-of-sight distances from the operator’s eyes to the display and the blade are respectively 2 meters and 1.30 meters. The process monitoring continues throughout the duration of the test. The following signals are sampled and memori7ed for quantitative analysis: 1) operator’s finger motions, 2) EMG signals, 3) forces exerted by the mechanical finger on the blade.	biological system;control system;electromyography;experiment;haptic technology;human reliability;human–computer interaction;ishikawa diagram;kinesiology;line-of-sight (missile);neurorobotics;programming paradigm;real-time computer graphics;real-time transcription;remote manipulator;robot;robotics;telerobotics;virtual reality	Alberto Rovetta;Francesca Cosmi;Lorenzo Molinari Tosatti	1995	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.376501	human–machine interface;robot;motion control;neurology;muscle;simulation;computer science;artificial intelligence;feedback;virtual reality;biological pest control;robotics;neurophysiology	Robotics	64.83413516163593	-31.683915696475157	166450
f0c9ed3cb24e98cd0f306c0d8492137d067e929f	correction of vehicle positioning error using 3d-map- gnss and vision-based road marking detection	optical filters;vehicle positioning error correction 2d map changing behavior lane keeping lane marking detection visual information road surface error mitigation urban canyon multipath propagation effect nonline of sight propagation autonomous driving urban environment robust vehicle self localization vision based road marking detection 3d map gnss positioning technique;vehicles three dimensional displays roads buildings cameras ray tracing optical filters;satellite navigation object detection road vehicles;roads;three dimensional displays;ray tracing;vehicles;cameras;buildings	Accurate and robust vehicle self-localization in the urban environment is a new challenge arising in the autonomous driving. GNSS positioning technique suffers from the effects of multipath and Non-Line-Of-Sight (NLOS) propagation in urban canyon. This paper proposes to employ an innovative GNSS positioning technique with the aid of 3D building map, to mitigate the error caused by multipath and NLOS. In addition, the road markings on road surface provide the significant visual information for driving, which can also be used for localization. Based on the lane marking detection, the lane keeping and changing behavior can be recognized and used for positioning. This paper integrates 3D-map-GNSS with vision-based road marking detection and 2D Map to reduce the vehicle positioning error. The experiment results demonstrate that the proposed method can provide sub-meter accuracy with respect to positioning error mean.	algorithm;autonomous car;global positioning system;internationalization and localization;item unique identification;multipath propagation;particle filter;satellite navigation;software propagation	Yanlei Gu;Li-Ta Hsu;Shunsuke Kamijo	2015	2015 IEEE International Conference on Vehicular Electronics and Safety (ICVES)	10.1109/ICVES.2015.7396908	computer vision;geography;transport engineering;remote sensing	Robotics	53.76331696743435	-37.65642187678563	166466
b010b6051c3861e4abcda0361d2b5a1b0bd6c8ce	acoustic-inertial underwater navigation		In this paper, we introduce a novel acoustic-inertial navigation system (AINS) for Autonomous Underwater Vehicles (AUVs). We are aiming to reduce the cost and latency of current underwater navigation systems that typically employ high-accuracy and thus high-cost inertial sensors. In particular, the proposed approach efficiently fuses the acoustic observations from a 2D imaging sonar and the inertial measurements from a MEMS inertial measurement unit (IMU) within a tightly-coupled EKF framework, while having no need to keep the acoustic features in the state vector. As a result, the computational complexity of the proposed AINS is independent from the scale of the operating environment. Moreover, we develop an acoustic feature linear triangulation to provide accurate initial estimates for iterative solvers, and perform an in-depth observability analysis to investigate the effects of sensor motion on the triangulation. Additionally, since it is challenging to perform a priori sensor extrinsic calibration underwater, we advocate to calibrate IMU-sonar online. The proposed AINS has been validated extensively in Monte-Carlo simulations.	acoustic cryptanalysis;computational complexity theory;extended kalman filter;inertial navigation system;iterative method;microelectromechanical systems;operating environment;sonar (symantec);sensor;simulation	Yulin Yang;Guoquan Huang	2017	2017 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2017.7989571	latency (engineering);control engineering;engineering;inertial measurement unit;observability;sonar;navigation system;extended kalman filter;triangulation (social science);state vector	Robotics	55.42500486470753	-37.24534927695655	166605
31332ad03e04f819dd13d8b0eec70db478999aa5	a virtual sensor implementation for a flexible assembly machine	systeme commande;sistema control;maquina ensambladora;architecture systeme;manufacturing process;atelier flexible;flexible assembly;conception;robotics;transputer;productique;captador medida;control system;measurement sensor;capteur mesure;flexible manufacturing system;procedimiento fabricacion;virtual sensor;diseno;robotica;design;arquitectura sistema;sistema flexible produccion;robotique;machine assemblage;procede fabrication;system architecture;robot;computer integrated manufacturing;assembling machine	We describe a sensor integration system which we have designed and implemented for a large fully-integrated flexible assembly machine. The machine was developed by a consortium to explore the design and implementation issues involved. The sensor integration system was designed for execution on a multiple transputer architecture, and co-ordinates all the sensory information in the machine. It uses the concept of virtual sensing to provide sensory data at an appropriate level of abstraction to the machine supervisor, which controls execution of the assembly tasks		Jem J. Rowland;Howard R. Nicholls	1995	Robotica	10.1017/S0263574700017707	robot;control engineering;embedded system;design;computer science;engineering;control system;artificial intelligence;robotics;engineering drawing;virtual finite-state machine	Robotics	63.17941400621399	-32.4102905100184	166915
354fff3fb89baedb8c65adff190fdb2c84f67644	autonomous guided car using a fuzzy controller	autonomous ground vehicle;fuzzy control;vision servoing	The goal of the work described in this paper is to develop a visual line guided system for being used on-board an Autonomous Guided Vehicle (AGV) commercial car, controlling the steering and using just the visual information of a line painted below the car. In order to implement the control of the vehicle, a Fuzzy Logic controller has been implemented, that has to be robust against curvature changes and velocity changes. The only input information for the controller is the visual distance from the image center captured by a camera pointing downwards to the guiding line on the road, at a commercial frequency of 30Hz. The good performance of the controller has successfully been demonstrated in a real environment at urban velocities. The presented results demonstrate the capability of the Fuzzy controller to follow a circuit in urban environments without previous information about the path or any other information from additional sensors.		Miguel A. Olivares-Méndez;Pascual Campoy Cervera;Ignacio Mellado;Iván Fernando Mondragón;Carol Martínez;José Luis Sánchez-López	2011		10.1007/978-3-642-37387-9_3	control engineering;computer vision;simulation;engineering	Robotics	58.13710492788255	-29.00547704637734	167034
4777c22ae1fa9e032934a59564a15b480790aeb5	experience-based imitation using rnnpb	humanoid robot;pattern generation;imitation;recurrent neural network with parametric bias;active sensing;recurrent neural network;experience base;robot programming	Robot imitation is a useful and promising alternative to robot programming. Robot imitation involves two crucial issues. The first is how a robot can imitate a human whose physical structure and properties differ greatly from its own. The second is how the robot can generate various motions from finite programmable patterns (generalization). This paper describes a novel approach to robot imitation based on its own physical experiences. We considered the target task of moving an object on a table. For imitation, we focused on an active sensing process in which the robot acquires the relation between the object's motion and its own arm motion. For generalization, we applied the RNNPB (recurrent neural network with parametric bias) model to enable recognition/generation of imitation motions. The robot associates the arm motion which reproduces the observed object's motion presented by a human operator. Experimental results proved the generalization capability of our method, which enables the robot to imitate...		Ryunosuke Yokoya;Tetsuya Ogata;Jun Tani;Kazunori Komatani;Hiroshi G. Okuno	2007	Advanced Robotics	10.1163/156855307781746106	computer vision;imitation;computer science;humanoid robot;artificial intelligence;recurrent neural network;social robot;arm solution	Robotics	62.0745427715282	-25.296711995683303	167111
da159b11b781b9f11ce2d546f9932de848d895b0	a bayesian approach to diameter estimation in the diameter control system of silicon single crystal growth	silicon;belief networks;silicon single crystal;control systems;least squares approximations;silicon single crystal bayesian inference diameter estimation ellipse fitting growth control;single crystal;si bayesian model diameter estimation diameter control system silicon single crystal growth solid crystal liquid solution casting speed charge coupled device camera halo ellipses elliptical aperture posterior distribution markov chain monte carlo method hough transform based algorithm direct least squares fitting method;single crystal growth;velocity control;bayesian approach;temperature control;bayesian inference;crystal growth;bayesian methods;velocity control belief networks casting charge coupled devices crystal growth curve fitting diameter measurement elemental semiconductors hough transforms least squares approximations markov processes monte carlo methods semiconductor device manufacture semiconductor growth temperature control;elemental semiconductors;semiconductor growth;charge coupled devices;bayesian method;crystals;control system;casting;posterior distribution;diameter measurement;estimation;markov chain monte carlo methods;least square;markov process;semiconductor device manufacture;hough transforms;growth control;hough transform;charged couple device;markov processes;curve fitting;monte carlo methods;apertures;diameter estimation;bayesian model;apertures crystals silicon estimation bayesian methods markov processes control systems;ellipse fitting	In the diameter control system of silicon single crystal growth, the variation of the diameter of the aperture (i.e., a halo with high brightness, which appears at the junction of a solid crystal and a liquid solution) is consistent with the change in the diameter of the growing crystal. Therefore, the diameter of the aperture can be used as a control variable for adjusting the casting speed and temperature so that the grown silicon single crystal approximates to a perfect cylinder. It is obvious that the measured diameter of the current aperture plays an important role in the diameter control system of silicon single crystal growth. In fact, the obtained aperture image from a charge-coupled device camera is a halo of ellipses instead of circles. To estimate the diameter (or radius) of the elliptical aperture, we propose a Bayesian approach, in which a Bayesian model is derived to define a posterior distribution for the unknown parameters. This distribution is too complicated for analytical extraction of moments to sample directly. An efficient computational algorithm based on a Markov chain Monte Carlo method is derived to estimate the posterior distribution and draw samples from the distribution. Comparing with the classical Hough transform-based algorithm and the direct least-squares fitting method, the proposed algorithm has higher estimation accuracy. Some simulated and experimental examples are presented to illustrate the algorithm's effectiveness.	algorithm;bayesian network;charge-coupled device;control system;cylinder seal;hough transform;least squares;markov chain monte carlo;monte carlo method	Ding Liu;Junli Liang	2011	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2010.2086610	econometrics;mathematical optimization;bayesian probability;control system;feret diameter;mathematics;markov process;optics;bayesian inference;statistics	Vision	63.56031649424194	-36.442573595482855	167307
758bae4b3cd0a12e71f6236f67d20e743e9ec84a	information sharing in uavs cooperative search based on calculating the minimum time		This paper proposes an optimization strategy for sharing and merging information of target's existence in Unmanned Aerial Vehicles (UAVs) cooperative search. That main is to minimize the search time subject to both sensing and communication limitations. We derive limits for the required number of sensor observations considering false alarms and miss detections, to declare the existence or absence of a target. the search environment is partitioned into equal-size cells, where each cell is associated with a probability of target existence and the number of visits by the UAVs, wich constitutes a probability map (search map) and a visit map (certainty map). We present a decentralized control model for cooperative target-searching and we develop a real-time approach for direct cooperation between vehicles, which is based on calculating the minimum time required to reach a cell. Each UAV takes into account the possible actions of other UAVs to increase the overall information about the environment. The simulation results illustrate the effectiveness of the proposed strategy by comparing it with the free moving strategy and show that our proposed algorithm performs out it.	algorithm;distributed control system;mathematical optimization;real-time clock;real-time computing;sensor;simulation;unmanned aerial vehicle	Hassan Saadaoui;Faissal El Bouanani	2017		10.1145/3128128.3128154	decentralised system;merge (version control);real-time computing;certainty;information sharing;simulation;geography	Robotics	55.242761905337325	-25.4328956100197	167550
0bc785d73cbb4d0f7dc5afb15c97bac545711864	efficient path re-planning for auvs operating in spatiotemporal currents	autonomous underwater vehicle;tecnologia industrial tecnologia mecanica;tecnologia electronica telecomunicaciones;quantum behaved particle swarm optimization;spatiotemporal current map;dynamic path re planning;tecnologias;grupo a	This paper presents an on-line dynamic path re-planning system for an autonomous underwater vehicle (AUV) to enable it to operate efficiently in a spatiotemporal, cluttered, and uncertain environment. The proposed strategy combines path re-planning with an evolutionary algorithm to adapt and regenerate the trajectory during the course of the mission using continuously updated current profiles from on-board sensors, such as a Horizontal Acoustic Doppler Velocity Logger. A quantum-behaved particle swarm optimization (QPSO) algorithm is used with a cost function which is based on the total time required to travel along the path segments accounting for the effect of space-time variable currents. The proposed path planner is designed to generate an optimal trajectory for an AUV navigating through a spatiotemporal ocean environment in the presence of irregularly shaped terrains as well as obstacles whose position coordinates are uncertain. Simulation results show that using the same on-board computation resources, the proposed path re-planning methodology with reuse of information gained from the previous planning history is able to obtain a more optimized trajectory than one relying on reactive path planning. Subsets of representative Monte Carlo simulations were run to analyse the performance of these dynamic planning systems. The results demonstrate the inherent robustness and superiority of the proposed planner based on path re-planning scheme when compared with the reactive path planning scheme.		Zheng Zeng;Karl Sammut;Andrew Lammas;Fangpo He;Youhong Tang	2015	Journal of Intelligent and Robotic Systems	10.1007/s10846-014-0104-z	control engineering;simulation;any-angle path planning;engineering;artificial intelligence	Robotics	54.39149706262644	-24.226658436357916	167677
c7232c23999fcf4eaba1d84fcb12445e367a207e	things are made for what they are: solving manipulation tasks by using functional object classes	manipulators;path planning;robots containers;human robot interaction;humanoid robots;institut fur robotik und mechatronik bis 2012;control engineering computing;path planning control engineering computing humanoid robots human robot interaction manipulators;functional object classes planning process centralized world representation object specific task constraints object context handling methods generic action description complex mechanisms humanoid service robots arbitrary manipulation tasks	Solving arbitrary manipulation tasks is a key feature for humanoid service robots. However, especially when tasks involve handling complex mechanisms or using tools, a generic action description is hard to define. Different objects require different handling methods. Therefore, we try to solve manipulation tasks from point of view of the object, rather than in the context of the robot. Action templates within the object context are introduced to resolve object specific task constraints. As part of a centralized world representation, the action templates are integrated into the planning process. This results in an intuitive way of solving manipulation tasks. The underlying architecture as well as the mechanisms are discussed within this paper. The proposed methods are evaluated in two experiments.	centralized computing;experiment;robot	Daniel Leidner;Christoph Borst;Gerd Hirzinger	2012	2012 12th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2012)	10.1109/HUMANOIDS.2012.6651555	human–robot interaction;computer vision;simulation;computer science;humanoid robot;artificial intelligence;motion planning	Robotics	63.65202968108456	-25.75594047819841	167684
42bfe2b7f42afb10483516d270f5d6f5f1f37043	a multi-agent platform for biomimetic fish		Through interactions with live animals biomimetic robots can be used to analyze social behaviors. We have developed a robotic fish enabling us to examine complex interactions in fish shoals. The system uses small wheeled robots under a water tank. The robots are coupled to a fish replica inside the tank using neodymium magnets. The fish integrate a battery pack and two infrared LEDs that are used to track the replicas in the tank. Here, we describe the procedure to build a fish replica, review the implementation details of our hardware and software and compare it to a previous plotter-based system.	biomimetics;interaction;plotter;robot	Tim Landgraf;Rami Akkad;Hai Nguyen;Romain O. Clément;Jens Krause;Raúl Rojas	2012		10.1007/978-3-642-31525-1_44	swarm intelligence;battery pack;replica;robot;embedded system;plotter;software;computer science	Robotics	59.66983849966115	-26.143540412729923	167726
0841ea6c939c2fa39d444c798a2bfcd541b31b26	experimental and simulation results of wheel-soil interaction for planetary rovers	motion control;dynamic simulation planetary rovers rover locomotion performance prediction planetary robotic mission single wheel testbed single wheel dynamic computer simulator matlab simulink simmechanics toolbox wheel soil interaction computer model aesco soft soil tire model as sup 2 tm;computer model;mobile robots;planetary rovers wheel soil interaction dynamic simulation;motion control planetary rovers mobile robots control engineering computing;planetary rovers;soft soil;computational modeling mathematical model tires mobile robots testing computer simulation soil wheels torque;dynamic simulation;control engineering computing;computer simulation	The ability to predict rover locomotion performance is critical during the design, validation and operational phases of a planetary robotic mission. Predicting locomotion performance depends on the ability to accurately characterize the wheel-soil interactions. In this research, wheel-soil interaction experiments were carried out on a single-wheel testbed and the results were compared with a single-wheel dynamic computer simulator which was developed in Matlab and Simulink's SimMechanics toolbox using a commercially-available wheel-soil interaction computer model called AESCO Soft Soil Tire Model (AS/sup 2/TM). Two different tire treads were used and compared in this study. There is good agreement between experimental and simulation results for wheel sinkage as a function of slip ratio; however, more investigation is needed to understand the differences observed for the drawbar pull and motor torque results.	chris sawyer's locomotion;computer simulation;experiment;interaction;matlab;numerical weather prediction;planetary scanner;robot;rover (the prisoner);simulink;testbed;tire-pressure monitoring system	Robert Bauer;Winnie Leung;Tim D. Barfoot	2005	2005 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2005.1545179	computer simulation;control engineering;motion control;mobile robot;simulation;aerospace engineering;computer science;engineering	Robotics	67.88801348820668	-27.205914921978987	168153
e9604d7f65f8f79901664b60885cd06ec4a40118	realization of biped walking in unstructured environment using motion primitives	robot dynamics humanoid robots legged locomotion;legged locomotion;humanoid robots legged locomotion trajectory robot kinematics dynamics;trajectory;humanoid robots;dynamics;motion primitives humanoid robots unstructured dynamic environments biped robot motion synthesis biped robot motion realization motion characteristics dynamic robot model balanced walk biped walking realization;motion primitives humanoid and bipedal locomotion humanoid robots;robot kinematics	Effective and efficient motion of humanoid robots in unstructured dynamic environments is a prerequisite for their activity in the living and working environment of humans. Motion in such environments has to be adjusted all the time to suit the current conditions. This paper presents a method for the synthesis and realization of the biped robot motion (walking) composed of simple movements-primitives, because any complex motion can be composed of tied primitives. The primitives are parametrized with the relationship established between the overall motion characteristics and their own parameters. This way, it is possible to achieve online modification at any moment. The proposed solution was tested by the simulation involving a dynamic robot model. The results demonstrate that it is possible to generate a dynamically balanced walk that can be modified online at any moment of its realization.	humanoid robot;simulation	Mirko Rakovic;Branislav Borovac;Milutin Nikolic;Srdan Savic	2014	IEEE Transactions on Robotics	10.1109/TRO.2014.2344431	control engineering;mobile robot;computer vision;dynamics;simulation;computer science;humanoid robot;artificial intelligence;trajectory;robot locomotion;robot control;robot kinematics	Robotics	65.87349554642057	-24.735768527519276	168220
d8e8e72c763c786492ad4d8473712e365a134369	an image-based uterus positioning interface using adaline networks for robot-assisted hysterectomy		Surgical manipulators are becoming more popular in modern operating theatres. Robots which work side-by-side with the surgeon and perform supportive tasks are one of the examples. However, how to allow the user to control the robot in a user-friendly manner is challenging. In this paper, we present our work on developing an image-based adaptive user interface to control a robot which assist in uterus positioning during laparoscopic hysterectomy for the hand-busy surgeon. The presented interface can be operated in two different modes, the pick and place mode, and the command specifying mode. Under the pick and place mode, the user specifies the desired starting point and ending point of the manipulation with his/her eyes and the robot drives automatically based on these points specified by the user; under the command specifying mode, the user specifies which joint and in which direction to move by looking at features of the laparoscopic monitor, then a driving command would be sent to the robot. Details of these two control approaches and the experimental results demonstrating how they work in uterus positioning are presented.	adaline;adaptive user interface;experiment;eye tracking;robot control;smt placement equipment;semiconductor industry;tracking system;usability;velocity (software development)	Hiu Man Yip;David Navarro-Alarcon;Yunhui Liu	2017	2017 IEEE International Conference on Real-time Computing and Robotics (RCAR)	10.1109/RCAR.2017.8311857	robot;operating theatres;computer vision;smt placement equipment;robot kinematics;computer science;artificial intelligence;adaptive user interface;user interface	Robotics	61.72001737000519	-30.093073495357167	168296
996d8a21154c04b47f65b7f8e7b4de95c4f9961b	bilateral human-robot control for semi-autonomous uav navigation	navigation robots safety generators unmanned aerial vehicles europe communication channels;generators;human robot control cognitive ability unmanned aerial vehicle semiautonomous bilateral control architecture semiautonomous uav navigation;navigation;robots;safety;path planning autonomous aerial vehicles cognitive systems human robot interaction mobile robots;europe;communication channels;unmanned aerial vehicles	This paper proposes a semi-autonomous bilateral control architecture for unmanned aerial vehicles. During autonomous navigation, a human operator is allowed to assist the autonomous controller of the vehicle by actively changing its navigation parameters to assist it in critical situations, such as navigating through narrow paths. The overall goal of the controller is to combine the stability and precision of an autonomous control with the cognitive abilities of a human operator, only when strictly required for the accomplishment of a task. The control architecture has been validated through simulations and experiments.	aerial photography;algorithm;automated planning and scheduling;autonomous robot;bilateral filter;cognition;experiment;line-of-sight (missile);overshoot (signal);responsiveness;robot control;semiconductor industry;simulation;unmanned aerial vehicle	Han W. Wopereis;Matteo Fumagalli;Stefano Stramigioli;Raffaella Carloni	2015	2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2015.7354115	robot;control engineering;computer vision;navigation;simulation;computer science;engineering;artificial intelligence;mobile robot navigation;channel	Robotics	59.6854146513082	-26.83220868117334	168418
da9f4cc755dee2ec9a897c495ab8f1ec36a5c38b	asymmetrical prototype of a five-wheeled robot and maneuver analysis	reconfiguration;asymmetrical prototype;mobile robot;maneuver;control strategy	An innovative asymmetrical prototype of a five-wheeled robot is first proposed with reconfiguration features. Based on mechanical prototype, the fifth wheel with slippage measurement is then rendered for details. In terms of s maneuver features, different control strategy and steering performance for asymmetrical prototype with rhomboid shape have been discussed analytically. At last some tests including reconfiguration tests, straight-line motion and traversing tests have been implemented.	prototype;robot	He Xu;Jinfeng Zhao;Dawei Tan;Zhenyu Zhang	2010		10.1007/978-3-642-16584-9_47	control engineering;mobile robot;simulation;computer science;engineering;artificial intelligence;control reconfiguration;control theory	Robotics	60.13230611238352	-27.923420725749654	168532
0146f65aee45303a982500a478382b94640877b6	symbricatorrtos: a flexible and dynamic framework for bio-inspired robot control systems and evolution	robot sensing systems;software architecture control engineering computing evolutionary computation multi robot systems;organisms;evolutionary computation;sensors;robot control organisms hardware operating systems robot sensing systems service robots parallel robots aggregates software architecture humans;service robots;actuators;computer architecture;software architecture;artificial neural networks;robot control;parallel robots;software architecture bioinspired robot control systems multirobot organism evolutionary concepts;aggregates;robots;multi robot systems;control engineering computing;humans;evolutionary concepts;bioinspired robot control systems;multirobot organism;biochemistry;operating systems;hardware	One of the main aspects of the ‘SYMBRION’ and ‘REPLICATOR’ projects is that the robots can aggregate to form a multi-robot organism. For this reason the control mechanisms have to be able to control a single robot, a swarm of robots or an aggregated collective organism. To break down the complexity of development and to take the interaction with the environment and other robots into account, bio-inspired and evolutionary concepts are applied. In this paper we describe the underlying software architecture for the projects to enable different controller types, evolution and learning.	aggregate data;british informatics olympiad;control system;robot control;software architecture;swarm;symbrion	Marc Szymanski;Lutz Winkler;Davide Laneri;Florian Schlachter;Anne C. van Rossum;Thomas Schmickl;Ronald Thenius	2009	2009 IEEE Congress on Evolutionary Computation	10.1109/CEC.2009.4983365	robot;organism;software architecture;parallel manipulator;simulation;computer science;sensor;artificial intelligence;robot control;evolutionary computation;actuator	Robotics	64.94958641334216	-26.662200866148904	168552
a257711f17d237e1548f6ce3b75803cf4712ff13	data fusion of an attitude estimator for global localization of a robot	quaternions vectors estimation acceleration robot sensing systems;mobile robots;mobile robot data fusion attitude estimator global localization inertial measurement unit covariance matrix measurement noise gravity vector inertial frame calibration noncollinear directional sensors embedded implementations integrated ahrs attitude estimation;sensor fusion attitude measurement calibration covariance matrices mobile robots;covariance matrices;sensor fusion;attitude measurement;calibration;mem s quaternion attitude data fusion robot mobile	This paper focuses on the design and test results of an estimator based on fusing data from Inertial Measurement Unit (AHRS). Therefore in order to improve the quality of the attitude estimates, the covariance matrix of measurement noise is estimated in real time upon information obtained from the differential measurements, so that the estimator continually is “tuned” as well as possible. No a priori knowledge on the direction of the gravity vector in the inertial frame is required as these parameters can be also identified by the KF, relieving any need for calibration. With this approach, only the measurements of at least two non-collinear directional sensors are needed. Since the control laws are highly simple and a model based in an observer for angular velocity reconstruction is not needed, the proposed new strategy is very suitable for embedded implementations. Test results are presented showing the performance of the integrated AHRS to estimate the attitude of a mobile robot moving across uneven terrain. The global convergence of the estimation techniques is proved.	algorithm;angularjs;apache axis;attitude and heading reference system;baseline (configuration management);computer simulation;constraint (mathematics);cubic function;embedded system;global positioning system;image noise;kalman filter;local convergence;mobile robot;numerical analysis;sensor;spline (mathematics);triangular function;velocity (software development)	Bernardino Benito Salmeron-Quiroz;Gerardo Villegas-Medina;José-Fermi Guerrero-Castellanos;R. Villalobos-Martinez;M. A. Mendoza-Nunez	2013	2013 10th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE)	10.1109/ICEEE.2013.6676042	control engineering;mobile robot;computer vision;calibration;computer science;engineering;control theory;sensor fusion	Robotics	56.44828855779072	-35.81490828677183	168669
b0decfb65ec083382f87730e057411105e31589a	integrating multirobot coordination in a mobile-robot control system	control systems;protocols;error recovery;error recovery multirobot coordination control task planning mobile robot multirobot control level flexibility labeled petri nets;underwater vehicles;mobile robot;planning artificial intelligence;mobile robots;multirobot control level;multirobot coordination control;control system;position control;workstations;mobile communication;task planning;computer science;petri nets;position control mobile robots petri nets planning artificial intelligence;petri net;labeled petri nets;vehicle dynamics;flexibility;control systems robot kinematics mobile robots workstations vehicle dynamics protocols underwater vehicles computer science petri nets mobile communication;robot kinematics	A system that coordinates the activity of several mobile robots is described. In the author's (1989) previous work, he developed a control system for one mobile robot that executes high-level tasks or missions. This new capability called multirobot control level (MRC), is viewed as a new layer in the system that uses functionalities offered by the lower levels. This improvement shows the flexibility of the approach. In order to maintain this flexibility, the coordination must also be programmable therefore an extension of the previous formalism is also proposed. This coordination is validated by the use of labeled Petri nets. A first step towards error recovery at the coordination level is also addressed. Several experiments are also proposed that show the advantages of the approach. >	control system;mobile robot;robot control	Fabrice R. Noreils	1990		10.1109/IROS.1990.262367	control engineering;mobile robot;simulation;computer science;control system;artificial intelligence;distributed computing;petri net	Robotics	61.75661657934014	-27.677123916587465	168756
57998796b8d3a36c291b55bef14b1ff33e1b0636	modern advances in applied intelligence		In recent decade years, AUG has been attached importance to oceanographic sampling tool. AUG is a buoyancy driven vehicle with low energy consumption, and capable of long-term and large-scale oceanographic sampling. However, ocean environment is characterized by variable and severe current fields, which jeopardizes AUG cruise. Therefore, an efficient path planning is a key point that can assist AUG to arrive at each waypoint and reduces the energy consumption to prolong AUG sampling time. To improve AUG cruise efficiency, a path planning framework with evolutionary computation is proposed to map out an optimal cruising path and increases AUG mission reachability in this work.	evolutionary computation;motion planning;reachability;sampling (signal processing);waypoint	Moonis Ali;Jeng-Shyang Pan;Shyi-Ming Chen;Mong-Fong Horng	2014		10.1007/978-3-319-07467-2	computer science	AI	54.46426087526897	-28.971237131311337	168805
e5caddde47e67fedb023fb5df5fcc3ae8cb304f3	controlling anthropomorphic kinematics as multi-agent systems	international space station anthropomorphic kinematics control multi agent systems multi robot systems sensible couplings industrial robots virtual reality natural arm movement hierarchical control structure articulated robots equilibrium conditions astronauts simulation;multi agent system;modeling and simulation;hierarchical systems;virtual reality;hierarchical control;multi robot system;control systems anthropomorphism multiagent systems robot kinematics humans aerospace industry service robots robot sensing systems orbital robotics arm;international space station;intelligent control;robot kinematics multi agent systems intelligent control multi robot systems virtual reality industrial robots hierarchical systems;arm movement;multi agent systems;control structure;industrial robots;multi robot systems;industrial application;control strategy;robot kinematics	"""AbsIradBuilding on existent robotics knowledge to model and simulate anthropomorphic kinematics Is an appealing approach, because sound knowledge gained in the fields of multi-robot and multi-agent systems can he applied. This pmvides -with little additional effort the """"new human"""" with capabilities ranging from nstural sm movement up to the coordinated operation of his arms and the cooperation between multiple anthrapomorphic kinematics. The same general hierarchical control structure that has successfully been used to control multi-robot system for space and industrial application has therefore ken enhanced to incorporate the newly required capabilities. The enhancements focus on a new approach to on the one hand eomider human exhmities as articulated robob which are mechanically connected to make up the body and on the other hand to provide a control strategy to move the full body correctly under equiIihrium conditions. We provide an overall control Structure that preserves the capabilities of the single robots und introduces """"sensible couplings"""" to move the body as a whole in a naturally looking way. As described in the paper, this work is currently being applied to seleral application fields in industry up to the simulation of astronauts' work on the ~ International Space Station."""	coat of arms;control flow;control theory;inverse kinematics;multi-agent system;robot;robotics;simulation	Eckhard Freund;Jürgen Roßmann;Christian Schlette	2003		10.1109/IROS.2003.1249724	control engineering;computer vision;simulation;international space station;computer science;engineering;artificial intelligence;multi-agent system;control flow;robot kinematics	Robotics	68.19673562377568	-24.873752212141454	168901
3186f82000e19c76c114dd4a3f764389705bb5c7	discovery of complex behaviors through contact-invariant optimization	physics based animation;control	We present a motion synthesis framework capable of producing a wide variety of important human behaviors that have rarely been studied, including getting up from the ground, crawling, climbing, moving heavy objects, acrobatics (hand-stands in particular), and various cooperative actions involving two characters and their manipulation of the environment. Our framework is not specific to humans, but applies to characters of arbitrary morphology and limb configuration. The approach is fully automatic and does not require domain knowledge specific to each behavior. It also does not require pre-existing examples or motion capture data.  At the core of our framework is the contact-invariant optimization (CIO) method we introduce here. It enables simultaneous optimization of contact and behavior. This is done by augmenting the search space with scalar variables that indicate whether a potential contact should be active in a given phase of the movement. These auxiliary variables affect not only the cost function but also the dynamics (by enabling and disabling contact forces), and are optimized together with the movement trajectory. Additional innovations include a continuation scheme allowing helper forces at the potential contacts rather than the torso, as well as a feature-based model of physics which is particularly well-suited to the CIO framework. We expect that CIO can also be used with a full physics model, but leave that extension for future work.	chief information officer;continuation;loss function;mathematical morphology;mathematical optimization;motion capture;search algorithm	Igor Mordatch;Emanuel Todorov;Zoran Popovic	2012	ACM Trans. Graph.	10.1145/2185520.2185539	computer vision;mathematical optimization;simulation;computer science;artificial intelligence;machine learning;geometry;algorithm;scientific control;statistics;computer graphics (images)	Graphics	63.408434956816166	-24.20765640405589	168907
0237de39c6f59287bd35f2f5583515e723ec4382	morpho: a self-deformable modular robot inspired by cellular structure	robot sensing systems;cellular structure;embryo shape change;robot design;morpho;self deformable modular robot design;intelligent robots;sensing adaptive shape change;amoeba like robot;real time;complex structure;individual cell shape control;self adjusting systems;biology;self deformable structures;cell shape;embryos;mechanical engineering;deformable multicellular structure;large scale;tissue inspired material;computational modeling;thesis;shape;self adjusting systems bio inspired materials intelligent robots robot dynamics;bio inspired materials;robots;tensegrity model;bio inspired robots;lamprey locomotion;expandable cube;modular robotic systems;active filaments;sensing adaptive shape change morpho self deformable modular robot design tensegrity model active filaments individual cell shape control embryo shape change lamprey locomotion modular robotic systems deformable multicellular structure self deformable structures self deformable surface expandable cube terrain adaptive bridge robotic structures real time deformation bio inspired robots amoeba like robot tissue inspired material;robots shape robot kinematics biology computational modeling cells biology robot sensing systems;robotic structures;robot dynamics;real time deformation;self deformable surface;terrain adaptive bridge;hardware implementation;cells biology;robot kinematics	We present a modular robot design inspired by the creation of complex structures and functions in biology via deformation. Our design is based on the Tensegrity model of cellular structure, where active filaments within the cell contract and expand to control individual cell shape, and sheets of such cells undergo large-scale shape change through the cooperative action of connected cells. Such deformations play a role in many processes, e.g. early embryo shape change and lamprey locomotion. Modular robotic systems that replicate the basic deformable multicellular structure have the potential to quickly generate large-scale shape change and create dynamic shapes to achieve different global functions. Based on this principle, our design includes four different modular components: (1) active links, (2) passive links, (3) surface membranes, and (4) interfacing cubes. In hardware implementation, we show several self-deformable structures that can be generated from these components, including a self-deformable surface, expandable cube, terrain-adaptive bridge [C.-H. Yu et al., 2007]. We present experiments to demonstrate that such robotic structures are able to perform real time deformation to adapt to different environments. In simulation, we show that these components can be configured into a variety of bio-inspired robots, such as an amoeba-like robot and a tissue-inspired material. We argue that self-deformation is well-suited for dynamic and sensing-adaptive shape change in modular robotics.	algorithm;amoeba;biological system;bridging (networking);british informatics olympiad;distributed control system;emoticon;experiment;ibm notes;olap cube;self-assembly;self-reconfiguring modular robot;self-replicating machine;simulation;xfig	Chih-Han Yu;Kristina Haller;Donald E. Ingber;Radhika Nagpal	2008	2008 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2008.4651130	robot;control engineering;embryo;computer vision;simulation;shape;computer science;engineering;artificial intelligence;tensegrity;generalized complex structure;self-reconfiguring modular robot;computational model;robot kinematics	Robotics	65.75869578693857	-26.63634010770558	169018
8d6a619ccc5615faccbecbfc30434c550e77317a	accurate platoon control of urban vehicles, based solely on monocular vision	inter vehicle communications;automated electric vehicles;monocular vision;oscillations;urban transportation system;transport service;measurement;nonlinear control systems;accurate platoon control;vehicles measurement observers trajectory mathematical model equations cameras;urban vehicles automatic guided vehicles platooning nonlinear control observer monocular vision;nonlinear control techniques;nonlinear control;observers;global decentralized control strategy;robot vision automatic guided vehicles decentralised control electric vehicles nonlinear control systems observers;robot vision;trajectory;decentralised control;transportation service;automatic guided vehicle;decentralized control;electric vehicles;mathematical model;nonlinear observer;automatic guided vehicles;vehicle localization;vehicles;global control strategy;automatic guided vehicles accurate platoon control urban vehicles monocular vision automated electric vehicles urban transportation system transportation service global control strategy inter vehicle communications vehicle localization nonlinear observer global decentralized control strategy nonlinear control techniques;urban vehicles;electric vehicle;observer;inter vehicle communication;platooning;cameras;control strategy;urban transport;virtual worlds	Automated electric vehicles for public use constitute a promising very efficient and environment-friendly “urban transportation system”. An additional functionality that could enhance this transportation service is vehicle platooning. In order to avoid inter-distance oscillations within the platoon, a global control strategy, supported by inter-vehicle communications, is investigated. Vehicle localization in an absolute frame is needed and is derived here from monocular vision. The vision data is however expressed in a virtual world, slightly distorted with respect to the actual metric one. It is shown that such a distortion can accurately be corrected by designing a nonlinear observer that relies on odometric data. A global decentralized control strategy, relying on nonlinear control techniques, can then be designed to achieve accurate vehicle platooning. Simulations and full-scale experiments demonstrate the performance of the proposed approach.	computer simulation;control theory;distortion;distributed control system;experiment;full scale;nonlinear system;on-board data handling;online and offline;performance;platoon (automobile);tree accumulation;virtual world	Pierre Avanzini;Benoit Thuilot;Philippe Martinet	2010	2010 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2010.5650018	control engineering;simulation;nonlinear control;decentralised system;computer science;engineering;monocular vision;artificial intelligence;trajectory;mathematical model;control theory;oscillation;observer;quantum mechanics;measurement	Robotics	58.67661508566153	-26.9782647122448	169030
44e7e708c7ee37181c9d9acbce8e22892bf1aac5	the reliability of curvature estimates from linear elastic tactile sensors	robot sensing systems;tactile sensors shape rubber robot sensing systems fingers calibration humans low pass filters performance analysis machine vision;indenter parameters;fourier series;rubber;tactile sensor;band limited shape interpretation;edge detection;contact models;linear elastic tactile sensors;curvature measurement;shape;linear elasticity;bias;band limited shape interpretation curvature estimates linear elastic tactile sensors linear elastic model indenter parameters contact models calibration bias fourier series;machine vision;fingers;performance analysis;curvature measurement tactile sensors parameter estimation fourier series edge detection calibration;curvature estimates;tactile sensors;low pass filters;humans;linear elastic model;parameter estimation;calibration	This papers analyzes the reliability of radius of curvature estimates from tactile sensor data. A linear elastic model is used to t the indenter parameters, load, location, and curvature, to the sensor output. It was found that both contact models and calibration techniques could dramatically eeect the bias and variance of the estimated indenter parameters. The Fourier series is found to be an appropriate basis in which to analyze both the calibration of tactile sensors and the problem of bandlimited shape interpretation.	bandlimiting;tactile sensor	Edward J. Nicolson;Ronald S. Fearing	1995		10.1109/ROBOT.1995.525432	control engineering;computer vision;machine vision;computer science;engineering;optics;tactile sensor	Robotics	62.892049506908485	-34.57591164617425	169282
ec73861a8a82c662c79e00ca594729384455ba55	biologically inspired gait transition control for a quadruped walking robot	gait transition;leg control;sequence;quadruped walking robot	The gait transition of a quadruped walking robot is the switching of gait with non-periodic gait sequences between the periodic ones such as from walk to trot or trot to walk etc. It is very much important because the robot should change its gait depending upon the moving speed to enhance the efficiency of locomotion. In this paper, we present a quasi-static gait transition control method for a quadruped walking robot. It is based on the observation on the locomotion behaviors of quadruped animals, which show a sudden and discrete changes of gait patterns depending on the speed. The method predefines gait transition patterns, and gait sequences are determined according to the current and desired leg postures. It can be useful because the applicable to any type of walking controller. In this study, we implement the proposed method on a self-contained quadruped walking robot, called Artificial Digitigrade for Natural Environment Version III (AiDIN-III), and its effectiveness is experimentally validated.	mobile robot	Igmo Koo;Tran Duc Trong;Yoon Haeng Lee;Hyungpil Moon;Jachoon Koo;Sangdeok Park;Hyoukryeol Choi	2015	Auton. Robots	10.1007/s10514-015-9433-4	effect of gait parameters on energetic cost;simulation;gait;sequence	Robotics	66.0551443154978	-24.395909967834214	169833
61b81ade2b4684bea0733288e01f604b293b766f	human reach-to-grasp compensation with object pose uncertainty	motion compensation;biomechanics;kinematics;somatosensory phenomena;apertures thumb uncertainty kinematics robot sensing systems;medical image processing;object tracking;somatosensory phenomena biomechanics kinematics medical image processing motion compensation object detection object tracking;robotic hand human reach to grasp compensation object orientation uncertainty motion tracking framework hand object interaction capturing hand object contact detection vision sensing apparatus human reach to grasp kinematics object orientation sensing tactile sensing;object detection	This paper examined how humans alter reach-to-grasp behavior to compensate for environmentally-induced object orientation uncertainty. We used a novel motion tracking framework to capture hand-object interactions, as well as a custom cylindrical object to detect contacts. Subjects were instructed to reach, grasp, and lift the object with or without vision. The orientation of the object was randomly changed on each trial. We hypothesized subjects would use a reach-to-grasp strategy that minimizes post-contact adjustments. However, our results indicate that (1) subjects are more likely to use the hand as a sensing apparatus prior to contact, and (2) the reach-to-grasp kinematics may be optimized for efficient sensing of object orientation. Our findings could provide potential solution to efficient tactile sensing for robotic hand in unstructured environment.	interaction;randomness;robot	Qiushi Fu;Arash Ushani;Leif P. Jentoft;Robert D. Howe;Marco Santella	2013	2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2013.6611142	computer vision;kinematics;simulation;pose;computer science;engineering;biomechanics;video tracking;communication;physiology;motion compensation	Robotics	63.25220205210845	-33.70328038906746	169841
ddd54a9624d0fee0c436240ab5a5a4802a190621	rebound modeling of spinning ping-pong ball based on multiple visual measurements	analytical models;spinning ball continuous function motion state multiple visual measurement rebound model;force analytical models friction spinning visualization adaptation models mathematical model;pan tilt vision system rebound modeling spinning ping pong ball multiple visual measurement collision dynamics ultrahigh speed camera mean value theorem angular momentum theorem multilayer perception position vision system;force;high speed optical techniques angular momentum;visualization;mathematical model;adaptation models;friction;spinning	The research on the collision between a spinning ball and a table, as a general issue for the trajectory analysis of the spinning-flying objects, is important but complicated. Traditionally, it is studied either by simplifying the collision process as a black box in which the ball's motion state changes abruptly before and after collision, or by assuming that the coefficient of restitution and the coefficient of friction are simply piecewise linear or even constant during the whole collision process. In this paper, we first analyze the mechanism of the collision dynamics and conclude from mathematical derivations that the collision between a ping-pong ball and a table is a continuous transition process and its collision duration is a constant irrelevant to the ball's motion state. These two conclusions are also verified by the visual measurement using an ultrahigh-speed camera. Then, we propose a novel rebound model using the mean value theorem, momentum theorem, and angular momentum theorem. The novelty of the proposed model is that the forces and the parameters in it are formulated as the continuous functions related to the ball's motion state, which is more accurate, rather than as constants. The integrations of these functions over time can be formulated by using the mean value theorem, and their expressions are learned using multilayer perception with a large data set collected by the position vision system and the pan-tilt vision system. The experimental results verify the effectiveness and accuracy of the proposed model.	angularjs;black box;box modeling;coefficient;consistency model;interaction;next-generation network;piecewise linear continuation;racket;relevance;robot;singular value decomposition;traffic enforcement camera	Yongsheng Zhao;Rong Xiong;Yifeng Zhang	2016	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2016.2555179	classical mechanics;simulation;visualization;spinning;friction;mathematical model;optics;force;physics;quantum mechanics	Robotics	67.07958063503305	-33.05734551942188	170121
91f221d6732328bd702a1bbd9549cd8cac482d6c	asc localization in noisy environment based on wireless sensor network	active shopping cart;mobile robot;localization;zigbee wireless sensor network	This study investigates indoor localization problem of robot or a customer at shopping mall environment. To improve the localization accuracy, a sensor fusion-based approach is employed, which combines data from ZigBee, odometry of active shopping cart (ASC), andQRmarker. The proposed algorithmemploysGaussian probability estimation method and thus it is adaptive to localization problem even at noisy environment such as the shopping mall. To implement the localization service, an ASC which is equipped with motors for navigation, a laser sensor for tracking, and a tablet computer for human–computer interaction is designed. Through experimental work, we corroborate the feasibility of the proposed localization algorithms.	algorithm;encoder;experiment;human–computer interaction;odometry;qr code;robotics;sensor;ti advanced scientific computer;tablet computer	Shengnan Gai;Se Min Oh;Byung-Ju Yi	2015	Intelligent Service Robotics	10.1007/s11370-015-0172-3	mobile robot;embedded system;computer vision;simulation;internationalization and localization;computer science;artificial intelligence	Robotics	56.96805576983568	-35.89558136905924	170165
3378a7f4162719f4b8157e00ef64410c24906066	investigation of reality constraints: morphology and controller of two-link legged locomotors for dynamically stable locomotion	morphologie;walking;caminata;realite virtuelle;controlabilidad;realidad virtual;legged locomotion;locomotion avec jambes;controllability;virtual reality;animal;controlabilite;morphology;marche a pied;distraccion;educacion;morfologia;distraction	Evolutionary robotics aims at designing autonomous robots with technological applications of biological evolution. These design approaches have characteristics to exclude designer’s bias so that unexpected superior functions tend to emerge. In this research, we mainly focus on “interdependence between controller and morphology,” which is represented by passive dynamics walkers, and apply evolutionary robotics to achieve dynamically stable legged locomotion such as running and jumping. (i) We investigated the morphology and controller of biped robots because we viewed them as design components that together can induce dynamically stable locomotion. We conducted coupled evolution of the morphology and controller in three-dimensional simulation. As results, both pseudo-passive dynamic walkers (PPDWs) and active-control walkers (ACWs) emerged, but the PPDWs showed more dynamic stability than ACWs. Finally, we have concluded that appropriate compliance is a key to achieving dynamical stability and a computational trade-off between controller and morphology occurs in these devices. (ii) An important issue in evolutionary robotics is to solve “reality gap” problem, which indicates functions of virtual robots do not necessarily realize in real world. We propose interdependent use of evolutionary and heuristic designs for crossing reality gaps and develop graphical interfaces, which integrate heuristics into evolutionary design (fig.2).	autonomous robot;continuous design;evolution;evolutionary robotics;galaxy morphological classification;heuristic (computer science);interdependence;mathematical morphology;simulation	Kojiro Matsushita;Hiroshi Yokoi;Tamio Arai	2006		10.1007/11840541_9	simulation;controllability;morphology;computer science;artificial intelligence;virtual reality	Robotics	64.96793689850101	-25.483043930958367	170264
6eadff238e367f2b9b15c33650917151e1de2e83	automatic generation of reduced cpg control networks for locomotion of arbitrary modular robot structures	central pattern generators;locomotion;reconfigurable modular robots	The design of efficient locomotion controllers for arbitrary structures of reconfigurable modular robots is challenging because the morphology of the structure can change dynamically during the completion of a task. In this paper, we propose a new method to automatically generate reduced Central Pattern Generator (CPG) networks for locomotion control based on the detection of bio-inspired sub-structures, like body and limbs, and articulation joints inside the robotic structure. We demonstrate how that information, coupled with the potential symmetries in the structure, can be used to speed up the optimization of the gaits and investigate its impact on the solution quality (i.e. the velocity of the robotic structure and the potential internal collisions between robotic modules). We tested our approach on three simulated structures and observed that the reduced network topologies in the first iterations of the optimization process performed significantly better than the fully open ones.	biconnected component;british informatics olympiad;central pattern generator;galaxy morphological classification;iteration;mathematical morphology;mathematical optimization;network topology;on-board data handling;pseudorandomness;self-reconfiguring modular robot;velocity (software development)	Stéphane Bonardi;Massimo Vespignani;Rico Moeckel;Jesse van den Kieboom;Soha Pouya;Alexander Spröwitz;Auke Jan Ijspeert	2014		10.15607/RSS.2014.X.004	central pattern generator;simulation;computer science;control theory	Robotics	65.50771178708933	-25.489689537483734	170431
d972aef1776673ba91b77668152027e58db8f14c	learning forward and inverse kinematics maps efficiently		When learning forward and inverse kinematics maps of manipulators, usually little attention is paid to data-efficiency, i.e., the accuracy gained per action-outcome sample. This paper examines properties of popular (online) learning techniques and demonstrates that - regardless of the employed exploration strategy - the structure of kinematics mappings does not allow for a practically viable trade-off between the number of samples and the resulting approximation error for manipulators with more than a few DoFs - unless tailored parametric models are employed. We discuss suitable choices for these parametric models for both rigid and elastic discretely-actuated robots and compare their data -efficiency to that of popular exploratory learning approaches relying on non-parametric models. Our theoretical considerations are confirmed by various experimental results for inverse kinematics mappings of rigid and omnielastic manipulators.		Daniel Kubus;Rania Rayyes;Jochen J. Steil	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8593833	computer science;control engineering;algorithm;parametric model;robot;kinematics;inverse kinematics;approximation error;solid modeling	Robotics	63.51840827792171	-24.576258342657642	170509
e16e6c4aba99f71958d02eaf097e96b9946024cf	disaster management using mobile robots	relative position;search and rescue;formation control;disaster management;mobile sensors;mobile robot;ad hoc network;moment generating function;log normal fading;sensor network;coalition formation;oil spill;thermal imaging;channel capacity;human in the loop;coastal area;diversity method;nuclear waste	Disasters themselves are not limited to specific parts of world, though certain areas might be more prone to certain specific types of disasters. Some countries are more prone to terrorist activities, some coastal areas are more prone to cyclones, some areas are more prone to floods while some other areas are prone to oil spills. Loss of human life and property are obvious consequences of disasters. However, the level of preparedness is the key element that can limit the extent of damage. Use of sensor network based technologies can enhance the level of preparedness and the ability to handle consequences of the disaster. This higher level of preparedness can provide a better control over the loss. A team of mobile robots can quickly set up a network of mobile sensors and actuators for rapid action. This talk presents an overview of applications of distributed mobile robots in disaster management.  Applications which have human risks such as handling of nuclear waste, identification of location of explosives, etc., show the potential of use of mobile robots functioning as a group. Mobile robots have been used in search and rescue operation of World Trade centre terrorist attack and Hanshin-Awaji earthquake. In such situations mobile robots can enter voids too small or deep for a person, and can begin surveying larger voids that people are not permitted to enter until a fire has been put out or the structure has been reinforced. Robots can carry cameras, thermal imagers, hazardous material detectors, and medical payloads into the interior of a rubble pile and set up communication link with human operator using the ad-hoc network set-up by these robots. Each robot equipped with accelerometer, gyroscope and magnetic compass as sensor devices, can plan its navigational path with reference to each other and can get the sensor network dynamically relocated. Team of mobile robots equipped with appropriate sensors and distributed and cooperative planning algorithms can also autonomously generate maps for oil spill or radiation leaks.  In this context obviously the protocol for coalition formation between multiple robots becomes an important issue. Formation Control strategies have been developed focusing on control and coordination for multiple robots that have to move as a group with user-defined relative positions, i.e., in formations for performing different tasks. In case of disaster management, with human in the loop, a new problem, that of coalition formation in a team consisting of multiple robots and human beings, needs to be addressed.	as-interface;algorithm;control theory;gyroscope;hoc (programming language);map;mobile robot;sensor	Santanu Chaudhury	2011		10.1145/2185216.2185254	simulation;engineering;operations management;computer security;aisoy1	Robotics	56.58575644775219	-30.26990602829322	170512
541d5f969c6bbae66364d6da9e4c7262b25ada78	trajectographie passive sans manoeuvre de l'observateur. (target motion analysis without maneuver of the observer)			sans institute;target motion analysis	Julien Clavard	2012				HCI	58.56192170674174	-30.837499631000636	170550
802d7d97eeef2ba1e44a3b2a2c79fa8c37202223	a bio-inspired neuro-controller for an anthropomorphic head-arm robotic system	bio inspired control;anthropomorphism robot sensing systems robot kinematics biology biological systems motor drives humans robust control control systems system testing;sensory motor coordination bio inspired control neural control;neural control;motor coordination;biological systems;sensory motor coordination;motor control	In recent years, advances and improvements in engineering and robotics have been strengthening interactions between biological science and robotics in the goal of mimicking the complexity of biological systems. In this paper, motor control paradigms inspired by human mechanisms of sensory-motor coordination are applied to a biologically-inspired, purpose-designed robotic platform. The goal was to define and implement a multi-network architecture and to demonstrate that progressive learning of object grasping and manipulation can greatly increase performance of a robotic system in terms of adaptability, flexibility, growing competences and generalization, while preserving the robustness of traditional control. The paper presents the neural approach to sensory-motor coordination and shows preliminary results of the integration with the robotic system by means of simulation tests and experimental trials.	biological system;computation;experiment;interaction;network architecture;offline learning;online and offline;online machine learning;robot;simulation	Loredana Zollo;Eugenio Guglielmelli;Giancarlo Teti;Cecilia Laschi;Selim Eskiizmirliler;Franck Carenzi;Patrice Bendahan;Philippe Gorce;Marc A. Maier;Yves Burnod;Paolo Dario	2005	Proceedings of the 2005 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2005.1570089	control engineering;motor control;simulation;engineering;artificial intelligence;robotic paradigms;motor coordination	Robotics	67.65755806057291	-26.33396481954818	170773
9bda11a1999ca34aa0b6eff9d19e93084e38598d	design of walking gaits for tao-pie-pie, a small humanoid robot	robot humanoide;humanoid robot;walking;caminata;legged locomotion;and forward;autonomous system;soccer;gyroscope;locomotion avec jambes;gait;marcha;intelligence artificielle;robotics;tecnologia mos complementario;sistema autonomo;captador medida;posture;measurement sensor;left right;capteur mesure;marche a pied;international competitiveness;football;systeme autonome;postura;robotica;vitesse angulaire;artificial intelligence;angular velocity;rapport signal bruit;robotique;relacion senal ruido;inteligencia artificial;signal to noise ratio;technologie mos complementaire;allure;giroscopio;autonomous robot;complementary mos technology;futbol	This paper describes the methodology that we used to design and implement balancing and walking gaits for TAO-PIE-PIE, a small 30cm tall humanoid robot. TAO-PIE-PIE is a fully autonomous robot with all power, sensing, and processing done on-board. It is also a minimalistic design with only six degrees of freedom. Nevertheless, its performance is comparable to that of other more complex designs. The paper describes three patterns: (a) a straight walk, (b) a turn on the spot, and (c) a kicking pattern. Sensor feedback is provided by two gyroscopes that provide angular velocity in the left-right and forward-backward plane and a CMOS camera providing vision information. The feedback from the gyroscopes is not used to directly control the walking gait, because the signal is noisy and it would be computationally too expensive for the current processor hardware. Instead, coarse feedback from the gyroscopes is used to monitor the transition from one phase of the pattern to the next. This feedback is used to: (a) determine when a phase has completed successfully, and (b) when to change the endpoints of certain phases. TAO-PIE-PIE proved to be a successful design winning a number of honors at international competitions.	algorithm;angularjs;autonomous robot;cmos;computer vision;embedded system;emoticon;federation of international robot-soccer association;feedback;gyroscope;hiro (robot);humanoid robot;minimalism (computing);on-board data handling;robotics;six degrees of separation;tao;tao framework;velocity (software development)	Jacky Baltes;Patrick Lam	2003		10.1007/978-3-540-25940-4_31	simulation;gyroscope;angular velocity;computer science;autonomous system;humanoid robot;artificial intelligence;gait;robotics;signal-to-noise ratio	Robotics	58.314046018980974	-33.17712974268911	170950
d6195438c5b52f7a9fd57797a941249020be49cf	robot's energy consumption based multi-robot exploration strategy	robot sensing systems;mobile robots;energy consumption;dc motors;robot kinematics	This paper addresses the problem of exploring an unknown environment with a team of mobile robots. The objective is to build a coherent representation of the environment in minimum time. This can be achieved by applying an efficient coordination method which assigns to each robot the appropriate target location. In this context, we present a decentralized coordination approach that takes into account the structure of the environment and the energy consumption of each robot favouring a well-balanced spatial distribution of the robots in this one. The exploration target is the segment of environment including the frontiers between the unknown and the explored areas. The robot evaluates its relative rank among the other robots in term of energy consumption to reach this target. Thus, the robot is assigned to the segment for which it has the lowest rank. This approach has been implemented and tested in computerized simulation and a comparison with some existing approaches has been performed. The results demonstrate that our approach distributes efficiently the robots over the environment which allows to reduce the overall exploration time.	algorithm;coherence (physics);computation;interference (communication);mobile robot;simulation	Abdenour Benkrid;Abdelaziz Benallegue;Nouara Achour	2016	2016 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2016.7866477	control engineering;mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence;dc motor;robot control;robot kinematics	Robotics	56.44819058258907	-25.123825587866257	170989
2b29e576200a22148646e24ccb59db82a7895a0e	supervised autonomy for exploration and mobile manipulation in rough terrain with a centaur-like robot	mobile manipulation;navigation;space robotics and automation;mapping;perception for grasping and manipulation	2 Planetary exploration scenarios illustrate the need for autonomous robots that are capable to 3 operate in unknown environments without direct human interaction. At the DARPA Robotics 4 Challenge, we demonstrated that our Centaur-like mobile manipulation robot Momaro can 5 solve complex tasks when teleoperated. Motivated by the DLR SpaceBot Cup 2015, where 6 robots should explore a Mars-like environment, find and transport objects, take a soil sample, 7 and perform assembly tasks, we developed autonomous capabilities for Momaro. Our robot 8 perceives and maps previously unknown, uneven terrain using a 3D laser scanner. Based 9 on the generated height map, we assess drivability, plan navigation paths, and execute them 10 using the omnidirectional drive. Using its four legs, the robot adapts to the slope of the terrain. 11 Momaro perceives objects with cameras, estimates their pose, and manipulates them with 12 its two arms autonomously. For specifying missions, monitoring mission progress, on-the-fly 13 reconfiguration, and teleoperation, we developed a ground station with suitable operator interfaces. 14 To handle network communication interruptions and latencies between robot and ground station, 15 we implemented a robust network layer for the ROS middleware. With the developed system, our 16 team NimbRo Explorer solved all tasks of the DLR SpaceBot Camp 2015. We also discuss the 17 lessons learned from this demonstration. 18	autonomous robot;coat of arms;dynamic language runtime;heightmap;map;middleware;mobile manipulator;planetary scanner;robot operating system;robotics	Max Schwarz;Marius Beul;David Droeschel;Sebastian Schüller;Arul Selvam Periyasamy;Christian Lenz;Michael Schreiber;Sven Behnke	2016	Front. Robotics and AI	10.3389/frobt.2016.00057	mobile robot;computer vision;navigation;simulation;social robot	Robotics	56.454890633543535	-28.457955991960606	171006
48d1e649f03713ad27f13fe7ba0db0061f30a4bd	whole-body sensory concept for compliant mobile robots		Most of the conventional approaches to mobile robot navigation avoid any kind of contact with the environment or with humans. As nowadays distance sensors typically have a limited - and often only two-dimensional - field of view, collisions with the environment or contacts with humans cannot be fully avoided in practical mobile robot applications. On the other hand, direct physical contact can be used for intuitive communication between a robot and humans. In this paper, we present a whole-body sensory concept based on a 6-DoF force-torque sensor to perceive physical interaction between the robot and humans. To distinguish between external contact and disturbance forces that result from the motion of the mobile platform or oscillations, we present a novel model-free filtering approach based on a neural network. In extensive experiments carried out with our robot Canny we demonstrate the effectiveness and advantages of the neural network approach, which clearly outperforms a classical model-based one.	artificial neural network;baseline (configuration management);canny edge detector;error-tolerant design;experiment;fundamental interaction;mobile device;mobile robot;robotic mapping;stemming;tactile sensor	Marina Kollmitz;Daniel Buscher;Tobias Schubert;Wolfram Burgard	2018	2018 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2018.8460510	control engineering;robot;mobile robot navigation;artificial neural network;filter (signal processing);mobile robot;sensory system;engineering;field of view	Robotics	53.84636038720273	-32.56815836467813	171033
4514f4cf5ee0528db38789894248f1c64551751e	navigation and control of the nereus hybrid underwater vehicle for global ocean science to 10,903 m depth: preliminary results	autonomous underwater vehicle;navigation underwater vehicles oceans remotely operated vehicles sampling methods marine vehicles sea floor control systems mobile robots sonar;control systems;sampling instruments nereus hybrid underwater vehicle global ocean science navigation control system design nereus hybrid underwater robotic vehicle vehicle performance scientific survey autonomous underwater vehicle sea floor mapping sonars cameras remotely operated vehicle lightweight fiber optic tether electro hydraulic manipulator arm;scientific survey;oceans;underwater vehicles;vehicle performance;ceramics;acoustics;real time;nereus hybrid underwater robotic vehicle;electro hydraulic manipulator arm;mobile robots;remotely operated vehicles;sonars;sea floor mapping;fiber optic;sea surface;navigation;marine vehicles;control system synthesis;lightweight fiber optic tether;present day;control system design;sampling instruments;nereus hybrid underwater vehicle;underwater vehicles control system synthesis mobile robots navigation;global ocean science;vehicles;telemetry;remotely operated vehicle;sampling methods;cameras;sea floor;sonar	This paper reports an overview of the navigation and control system design for the new Nereus hybrid underwater robotic vehicle (HROV). Vehicle performance during its first sea trials in November 2007 near Hawaii, and in May and June 2009 in the Challenger Deep of the Mariana Trench is reported. During the latter expedition, the vehicle successfully performed scientific observation and sampling operations at depths exceeding 10,903 m. The Nereus underwater vehicle is designed to perform scientific survey and sampling to the full depth of the ocean — significantly deeper than the depth capability of all other present-day operational vehicles. For comparison, the second deepest underwater vehicle currently operational worldwide can dive to 7,000 m maximum depth. Nereus operates in two different modes. For broad-area survey, the vehicle can operate untethered as an autonomous underwater vehicle (AUV) capable of exploring and mapping the sea floor with sonars and cameras. Nereus can be converted at sea to become a tethered remotely operated vehicle (ROV) to enable close-up imaging and sampling. The ROV configuration incorporates a lightweight fiber-optic tether (for high-bandwidth, real-time video and data telemetry to the surface), an electro-hydraulic manipulator arm, and sampling instruments. The Nereus vehicle is designed to render all parts of the Earth's seafloor accessible to oceanographic science.	acoustic cryptanalysis;autonomous robot;control system;imperative programming;optical fiber;real-time clock;remotely operated vehicle;sampling (signal processing);shallow trench isolation;systems design	Louis L. Whitcomb;Michael V. Jakuba;James C. Kinsey;Stephen C. Martin;Sarah E. Webster;Jonathan C. Howland;Chris L. Taylor;Daniel Gomez-Ibanez;Dana R. Yoerger	2010	2010 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2010.5509265	remotely operated underwater vehicle;mobile robot;sampling;ceramic;navigation;simulation;remotely operated vehicle;computer science;engineering;control system;optical fiber;seabed;telemetry;marine engineering;sonar;remote sensing	Robotics	56.337312263534265	-30.723568124526594	171140
5c962e1c4ac1acb9a8ea3f445464783049ed7537	blacky, an interactive mobile robot at a trade fair	low level controller;completely autonomous robot;control systems;multi threading;motion control;intelligent robots;mobile robot;virtual corridor map;multi threading collision avoidance mobile robots kalman filters filtering theory motion control distance measurement;kalman filters;mobile robots;testing;trade fair interactive mobile robot;distance measurement;navigation;denning mrv4 robot;control system synthesis;mobile robots navigation intelligent robots control system synthesis sonar hardware control systems motion control robustness testing;simulated perception;robustness;collision avoidance;extended kalman filter;local guide;blacky;denning mrv4 robot blacky trade fair interactive mobile robot completely autonomous robot local guide remote guide low level controller virtual corridor map simulated perception extended kalman filter;filtering theory;remote guide;hardware;sonar	Presents the first approach towards the main goal of developing a completely autonomous robot that serves as a local and remote guide at a trade fair. Innovative solutions are provided to solve several problems found in this environment. Reactive-perceptual behaviors are executed to provide motion while a low level controller avoids collisions. A virtual corridor map, simulated perception, and an extended Kalman filter for localization, are used to overcome the lack of perception. Voice synthesizing is proved to be an effective aid for navigation, as well as for the overall success and acceptance of the system. A Denning Mrv4 robot called Blacky was used to carry out experiments in actual environments on three occasions, and the obtained conclusions sound promising for future research.	autonomous robot;mobile robot	Diego Rodríguez-Losada;Fernando Matía;Ramón Galán;Agustín Jiménez	2002		10.1109/ROBOT.2002.1014341	control engineering;mobile robot;computer vision;simulation;computer science;engineering;control system;control theory	Robotics	58.813968353577444	-28.57271348875997	171173
05b583156d6736b50982e6d0a575832e239da62e	mems imu based pedestrian indoor navigation for smart glass	indoor navigation;imu;extended kalman filter;step detection;pdr	In open air environment, Global Positioning System (GPS) receiver can determine its position with very high accuracy. Inside a building the GPS signal is degraded, the position estimation from the GPS receiver is very erroneous and of no practical use. In this paper, we present an indoor navigation system to track the position of a pedestrian by using built-in inertial measurement unit (IMU) sensors of a smart eyeglass. The device used for this project was an intelligent eye-wear JINS MEME. Here algorithm for step detection, heading and stride estimation are used to estimate the position based on the known locations of the walker using Pedestrian Dead Reckoning method (PDR). We have used extended Kalman filters as sensor fusion algorithm, where measurements of acceleration and orientation from IMU are used to track useru0027s movement, pace, and heading. The results showed that the level of accuracy was entirely acceptable. Average deviancy between the estimated and real position was less than 1.5 m for short range of walk was accomplished. There are some ideas for further development. Increasing the accuracy of the position estimation by palliation of stride length estimation error was identified as the most essential.	microelectromechanical systems	Md Abid Hasan;Mohammad Nasimuzzaman Mishuk	2018	Wireless Personal Communications	10.1007/s11277-018-5688-3	inertial measurement unit;computer science;real-time computing;kalman filter;gps signals;global positioning system;sensor fusion;dead reckoning;extended kalman filter;navigation system	Mobile	56.91905260371645	-36.99941038865613	171225
34cc4b47cd5eb8f859146db5281bd256ca81b825	tactile gloves for autonomous grasping with the nasa/darpa robonaut	hand;robot humanoide;humanoid robot;grasping;robot hand;force sensors;gloves;dexterity;prension;ruggedized equipment;nasa humans grasping robotics and automation humanoid robots robot sensing systems force sensors sensor phenomena and characterization control systems orbital robotics;hombre;hands;aplicacion espacial;broca herramienta;defense advanced research projects agency tactile gloves tactile data autonomous grasping nasa darpa robonaut hands dexterous humanoid robot astronauts torque tool tactile sensor power drill national aeronautics and space administration;autonomy;robotics;gripping;captador medida;dexterous manipulators;measurement sensor;capteur mesure;foret outil;dexterite;robots;grippers;human;drill;mano;robotica;tactile sensors;data gloves;prehension;data gloves tactile sensors dexterous manipulators force sensors grippers;robotique;tools;main;destreza;humanoid;application spatiale;space application;homme	Tactile data from rugged gloves are providing the foundation for developing autonomous grasping skills for the NASA/DARPA Robonaut, a dexterous humanoid robot. These custom gloves compliment the human like dexterity available in the Robonaut hands. Multiple versions of the gloves are discussed, showing a progression in using advanced materials and construction techniques to enhance sensitivity and overall sensor coverage. The force data provided by the gloves can be used to improve dexterous, tool and power grasping primitives. Experiments with the latest gloves focus on the use of tools, specifically a power drill used to approximate an astronaut's torque tool.	approximation algorithm;autonomous robot;color gradient;humanoid robot;robonaut;rugged computer;wired glove	Toby B. Martin;Robert O. Ambrose;Myron A. Diftler;Robert Platt;Melissa Butzer	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1308071	robot;control engineering;computer vision;simulation;drill;computer science;engineering;humanoid robot;artificial intelligence;robonaut;autonomy;robotics;tactile sensor	Robotics	65.66842550274957	-29.28271387920782	171233
5d91f4c8588a751b3aff853945f7fc0326899ffe	depth sensor placement for human robot cooperation	mobile robot sensor placement;collision avoidance cameras mobile robots robot kinematics robot vision systems;human robot cooperation mobile robot sensor placement collision avoidance;human robot cooperation;collision avoidance	Continuous sensing of the environment from a mobile robot perspective can prevent harmful collisions between human and mobile service robots. However, the overall collision avoidance performance depends strongly on the optimal placement of multiple depth sensors on the mobile robot and maintains flexibility of the working area. In this paper, we present a novel approach to optimal sensor placement based on the visibility of the human in the robot environment combined with a quantified risk of collision. Human visibility is determined by ray tracing from all possible camera positions on the robot surface, quantifying safety based on the speed and direction of the robot throughout a pre-determined task. A cost function based on discrete cells is formulated and solved numerically for two scenarios of increasing complexity, using a CUDA implementation to reduce computation time.	cuda;computation;computational resource;decision problem;expectation propagation;genetic algorithm;human–robot interaction;linear programming;loss function;mathematical optimization;mobile robot;motion planning;nonlinear system;numerical analysis;online and offline;ray tracing (graphics);sensor;signal processing;simulated annealing;simulation;time complexity	Max Stähr;Andrew M. Wallace;Neil M. Robertson	2014	2014 11th International Conference on Informatics in Control, Automation and Robotics (ICINCO)	10.5220/0005017103110318	mobile robot;robot learning;embedded system;computer vision;simulation;engineering;social robot;arm solution;robot control;mobile robot navigation;robot calibration	Robotics	54.0096501516324	-25.737301461710956	171241
8cf5ecb9bde72822a0cfb25da9da397c6c2167ed	optimization of biarticular gastrocnemius muscle in humanoid jumping robot simulation	elasticity;humanoid robot;biarticular muscle;vertical jump	We propose a new human inspired structure of the lower extremity mechanism by which a humanoid robot will be able to efficiently perform fast movements such as running and jumping. We build a dynamic model of the humanoid robot which includes an elastic model of the biarticular muscle gastrocnemius and determine the role of the biarticular muscles and the elastic tendons in performing the vertical jump. We demonstrate that biarticular links contribute a great deal to the performance of the vertical jump. We also show that timing of the biarticular link activation and stiffness of the biarticular link influence the height of the jump considerably.	humanoid robot;mathematical model;simulation	Jan Babic;Jadran Lenarcic	2006	I. J. Humanoid Robotics	10.1142/S0219843606000722	simulation;computer science;humanoid robot;artificial intelligence;elasticity	Robotics	68.16971847208302	-24.52470929843032	171380
9aba0dd0a960cc7429a8f8811e7cdb5389ab92d7	design of a low-level radar and time-of-flight sensor fusion framework		We present an open hardware and software platform to efficiently fuse heterogeneous sensor data in an automotive/robotic context. The framework presented in this paper provides researchers a base platform in order to develop and evaluate sensor fusion strategies. In contrast to similar approaches, this framework exploits in particular the raw radar data and enables the fusion at low-level. The proposed system utilizes low-level data from radar sensors as well as indirect (e.g. 3D imaging) and direct (e.g. LIDAR) Time-of-Flight (ToF) sensors. After a configurable amount of pre-processing at sensor-level, the sensor data is transferred to a centralized platform and aligned temporally and spatially. We demonstrate the transformation of radar data into the 3D coordinate system in order to fuse it with point cloud data from ToF sensors. Due to the modular structure of the framework, it also enables the exploration of various system partitioning concepts.	3d reconstruction;amd accelerated processing unit;centralized computing;high- and low-level;online and offline;open-source hardware;point cloud;preprocessor;radar;robot;sensor web;software framework;temporal logic;unmanned aerial vehicle	Josef Steinbaeck;Christian Steger;Gerald Holweg;Norbert Druml	2018	2018 21st Euromicro Conference on Digital System Design (DSD)	10.1109/DSD.2018.00056	real-time computing;point cloud;software;radar;time of flight;chirp;lidar;sensor fusion;modular design;computer science	Robotics	54.51133036871863	-35.663471965368714	171720
d2eff95d745feed25950545f3d159b331b5ab6c3	multi-directional camera 3-d vision system for micro-operation	vision system;unnatural hand manipulations;multidirectional camera 3d vision system;micromachine production;image recognition;microscopic images;3d entire shape model;microscopy;3d model extraction system multidirectional camera 3d vision system micro operation micro objects micromachine production unnatural hand manipulations microscopic images 3d software camera system 3d entire shape model texture extraction system stereo image generation system;ccd image sensors;micro objects;cameras machine vision microscopy image recognition shape image generation head optical sensors production productivity;materials handling stereo image processing ccd image sensors micromanipulators biotechnology;image generation;shape;3d software camera system;machine vision;materials handling;stereo image generation system;stereo image processing;production;micromanipulators;head;optical sensors;shape modeling;productivity;micro operation;3d model extraction system;biotechnology;texture extraction system;cameras	Hutidlitig oj micro-objects ubour 0.1 mm .squure is rssi~ntiul in rhr field3 (4 hio-rechnology and micromachine producrion. Thew oprrurions huw some dificulr) hrcuusr ir reyuirr.\ rhr unnuturul hand.s niunipuluiions underthe microscopic imuges. So the productitity 0 4 ihow operutions is nor high. To solvt. rhesr problems, U 3-11 sof wure cumim .system hus been introduced. The .system consists of IWO subsystems those UIY rhr .+I) entire shupe model wirh Irxrurc extruction .system und the .stc-rco imugr generution system. Herr, the mrrhrd c f l 3-11 model rxrruction .system using multidiructionul cumrru is introduced, then the umempr t o grnrrurr the stereo i m q e from the 3-11 model is diwrihrd.	micro-operation	Seiji Hata;Daisuke Torigoe;Shuxiang Guo;Kohichi Sugimoto	2000		10.1109/ICPR.2000.902987	smart camera;computer vision;productivity;simulation;machine vision;shape;computer science;micro-operation;head;computer graphics (images)	Robotics	63.90080366747406	-35.350625746700764	171764
b72fc60d783a37636e780552a85873daad6e9fbe	on the bending problem for large scale mapping	slam robots bending motion control position control;virtual environments and gaming;bending;motion control;localization;large scale systems simultaneous localization and mapping vehicle dynamics intelligent robots delay estimation state estimation shape measurement usa councils security safety;trajectory based representation;geometrical constraint;measurement uncertainty;data mining;universiteitsbibliotheek;large scale;bending problem;large scale mapping;trajectory;estimation;position control;heuristic algorithms;robots;simultaneous localization and mapping;bending effect;mapping;vehicles;geometrical constraints;heading based curvature measurement;geometric constraints;heading based curvature measurement bending problem large scale mapping simultaneous localization and mapping geometrical constraint motion prediction trajectory based representation;slam robots;motion prediction	During Simultaneous Localization And Mapping, geometrical constraints are established between map features. These constraints, introduced through measurements and motion prediction, produce a bending effect in the event of closing a large loop. In this paper we present a discussion of the bending problem for trajectory based representations. Furthermore, we propose a generic approach to reduce the bending effect that exploits common geometrical constraints in human-made environments through the use of a Heading Based Curvature measurement. We show by means of experimental results that our approach increases significantly both the global and local map accuracy.	closing (morphology);simultaneous localization and mapping	Isaac Esteban;Olaf Booij;Judith Dijk;Frans C. A. Groen	2009	2009 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2009.5354490	robot;control engineering;motion control;computer vision;estimation;bending;internationalization and localization;computer science;engineering;artificial intelligence;trajectory;control theory;statistics;measurement uncertainty;simultaneous localization and mapping	Robotics	59.96330296057539	-32.450192396721654	172375
4ad9e9a002229e9143213c8b84c5c8c0c545c0f8	automatic guided intelligent wheelchair system using hierarchical grey-fuzzy motion decision-making algorithms	intelligent systems wheelchairs decision making intelligent robots service robots prototypes hospitals mobile robots laboratories motion control;fuzzy control;hierarchical systems;look ahead;chung cheng 1 automatic guided intelligent wheelchair system hierarchical grey fuzzy motion decision making algorithms severely handicapped people hierarchical look ahead algorithm tracking control multisensor based intelligent wheelchair prototype luoson iii;intelligent control;handicapped aids;tracking control;service robot;grey systems;sensor fusion;sensor fusion handicapped aids intelligent control fuzzy control grey systems hierarchical systems tracking;tracking	The development of intelligent wheelchairs can bring a good solution to assist severely handicapped people who are unable to operate the classical electrical wheelchair by themselves in their daily activities. In this paper; we have developed a new I concept on automatic guided intelligent wheelchair system, through which the wheelchair users can extend their activity area from a priori known environment as many autonomous approaches addressed. We describe a hierarchical look-ahead grey-fuzzy decision motion algorithm for the tracking control of the wheelchair to follow a guiding service robot in an unknown environment. ,We have developed a multisensor based intelligent wheelchair prototype called “Luoson III” to work with the previous built autonomous guiding service robot “Chung-Cheng #I ”. The experimental results have demonstrated the success for the motion decision algorithm and the whole concept.	algorithm;autonomous robot;prototype;service robot	Ren C. Luo;Tse Min Chen;Meng-Hsien Lin	1999		10.1109/IROS.1999.812794	control engineering;simulation;computer science;engineering;artificial intelligence;sensor fusion;tracking;intelligent control	Robotics	59.12489180860246	-29.20688062254451	172394
e0a941c376fc1647f6d51b779f763f87d4fedf16	prehensile pushing: in-hand manipulation with push-primitives	field robot prehensile pushing in hand manipulation push primitive grasped object precise arm motion frictional contact dexterous manipulation service robot;geometry;force;acceleration;service robots dexterous manipulators friction;computational modeling;force grippers acceleration robots computational modeling friction geometry;robots;grippers;friction;article	This paper explores the manipulation of a grasped object by pushing it against its environment. Relying on precise arm motions and detailed models of frictional contact, prehensile pushing enables dexterous manipulation with simple manipulators, such as those currently available in industrial settings, and those likely affordable by service and field robots.	push technology;robot	Nikhil Chavan Dafle;Alberto Rodriguez	2015	2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2015.7354264	acceleration;robot;control engineering;computer vision;simulation;engineering;friction;computational model;force;quantum mechanics	Robotics	67.32598794086469	-26.22972512169173	172745
a9fd17e98b852fcba94520fadaef7b61c43deca4	fusion of laser scanner and camera using a direct drive gimbal for leader-following formation control	vibration fusion laser scanner camera direct drive gimbal leader following formation control;vibrations;laser fusion;vibration control mobile robots motion control multi robot systems optical scanners;cameras robot vision systems vibrations laser fusion;sensor fusion formation control leader follower multi robot direct drive gimbal;robot vision systems;cameras	In this paper, we discuss how to determine the position of the leader for leader-following formation control. In order to prepare the fusion of laser and camera, we complement each other's strengths and weaknesses. And we proposed using a gimbal to eliminate the vibration that makes both sensors unreliable.	consensus dynamics;sensor	Hyeon-woo Park;Jong-suk Choi	2014	2014 11th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2014.7057430	computer vision;inertial confinement fusion;vibration	Robotics	59.34879034045281	-34.14356483422991	172932
710d314c6a2517de0d7c6befdecf3534af8522ee	high quality goal connection for nonholonomic obstacle navigation allowing for drift using dynamic potential fields	robot sensing systems;spline;optimized production technology;turning;path planning;nonholonomic obstacle navigation;mobile robots;testing;euclidean distance;dynamic potential fields;orbital robotics;potential field;global maps;navigation;adaptive replanning nonholonomic obstacle navigation dynamic potential fields computational cost global maps generic gradient based methodology;nonholonomic constraint;generic gradient based methodology;gradient methods;computational cost;robustness;planning;collision avoidance;adaptive replanning;local minima;robotics and automation;navigation orbital robotics robot kinematics robustness mobile robots robotics and automation testing optimized production technology turning path planning;robot kinematics;mobile robots collision avoidance gradient methods	The problem we address in this paper is how to plan and execute high quality paths for robots subject to nonholonomic constraints while navigating obstacles in 2D space. The navigation is to be carried out continuously at speed and may be subject to drift that is not predictable a priori. The problem raises the challenge of adaptively maintaining a smooth robust path of low computational cost. The algorithm is complete in providing feasible paths connecting to the goal in cluttered environments without global maps or positioning while also optimising the path curvature in free space. The approach is a generic gradient-based methodology set in dynamic potential fields that are not subject to fixed local minima or other misdirecting surface features of static fields. Multiple planning and execution cycles are interleaved to allow frequent updates for dealing with unanticipated obstacles and drift. We present our methodology and demonstrate experimental results for simulated robots. The results show that low curvature paths are found that robustly connect to the goal under perturbation through a sequence of fast adaptive replanning.	algorithm;algorithmic efficiency;computation;display resolution;gradient descent;map;maxima and minima;positioning system;robot;simulation;velocity obstacle	Michael K. Weir;Matthew Bott	2010	2010 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2010.5509519	planning;control engineering;spline;mobile robot;computer vision;navigation;simulation;computer science;artificial intelligence;maxima and minima;euclidean distance;mathematics;motion planning;software testing;robot kinematics;robustness	Robotics	53.95130017511662	-24.2235599127887	172971
7487bc5b5fc120a192582e38ae4ca355da4718ff	firefly optimization: a study on frame invariance		This paper investigates whether or not the swarm based firefly optimization algorithm is invariant under reference frame alteration, specifically, under rotation, translation, and scale changes to the reference frame. A reference frame can be seen as the perspective used to view an optimization problem. The simplest example of a reference frame alteration is that of a scale change, for example if the unit of measure in an optimization problem is in millimeters or meters. An important characteristic of any optimization algorithm is its ability to maintain a high degree of performance stability under reference frame alteration. If an algorithm's performance is in fact dependent on the reference frame, it implies existence of an optimal reference frame that should be used during the optimization process. Having to select a reference frame places a greater burden on an individual utilizing the optimization algorithm, as the choice of reference frame may have a profound impact on performance. In practice, it is unlikely that the ideal reference frame is known a priori. This paper provides theoretical proofs that the firefly optimization algorithm is invariant under rotation and translation but not invariant under scaling. Furthermore, the effects of frame alteration on the firefly optimization algorithm performance are empirically demonstrated.	algorithm;firefly (cache coherence protocol);image scaling;mathematical optimization;optimization problem;reference frame (video);swarm	Christopher Wesley Cleghorn;Andries Petrus Engelbrecht	2017	2017 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2017.8285251	reference frame;invariant (physics);mathematical proof;scaling;firefly protocol;mathematical optimization;invariant (mathematics);optimization problem;mathematics	Vision	64.42876836233414	-37.013576980473324	173468
5137e891412461972f5a3cf1d82a93880c4b52ec	a novel method for determining centers of rotation of human joints		Adjustment is necessary for wearable devices such as rehabilitation anthropomorphic leg devices and exoskeletons. However, this is normally done by trial and error and requires a significant amount of expertize. A novel methodology is developed to locate centers of rotation of human joints. The developed methodology is applicable to human joints with fixed centers of rotation, but it is also applicable to knee joints where an equivalent center of rotation can be identified for a given range of motion. The proposed novel methodology involves a device consisting of two slides and procedures of position measurements during flexion/extension which yield the position of a human joint in a Sagittal plane. The third coordinate can be obtained by repeating the procedure in a lateral plane. A theoretical proof is presented based on complex numbers, the proposed system is modeled using Solid Works and results are promising.	align (company);curve fitting;displacement mapping;lateral computing;lateral thinking;solidworks;wearable technology	L. J. Yan;D. Yang;P. Datseris;X. M. Mo;Jing Xu	2018	2018 15th International Conference on Ubiquitous Robots (UR)	10.1109/URAI.2018.8441869	instant centre of rotation;computer vision;sagittal plane;complex number;computer science;artificial intelligence;range of motion	Robotics	60.27211511376311	-36.73644491415192	173880
8ab998bdc54e88d510ef432f1d2ce1f94471e8f9	adaptive locomotion controller and reflex system for humanoid robots	robot sensing systems;humanoid robot;piecewise linear;generators;motion control;force sensors;legged locomotion;piecewise linear techniques;adaptive control;pattern generation;mobile robots;joints;adaptive locomotion controller;piecewise linear pattern generator;humanoid robots;robots;reflex system;force sensors adaptive locomotion controller reflex system humanoid robots piecewise linear pattern generator;piecewise linear techniques adaptive control force control force sensors humanoid robots mobile robots motion control;robots robot sensing systems legged locomotion joints leg humanoid robots generators;leg;force sensor;neural network;force control	This paper deals with reflexes against sudden obstacles for humanoid robots, which are combined with a proposed piecewise-linear pattern generator. The reflex action consists of modulating the motorspsila commands by the outputs of the force sensors located under the robot legs, and through a given primitive neural network previously proposed. Eventually, the primitive reflex is modified by the afferent signals to be more adaptable and robust against sudden obstacles. The final reflex structure enables the response of the sensory signals to be coordinated and modulated with locomotion controllerpsilas outputs to achieve an intended stabilizing behavior of the robot. The effectiveness of the proposed reflex is demonstrated by experiment using Fujitsupsilas humanoid robot HOAP-3. It is shown that the primitive reflex movement previously proposed becomes robust against sudden obstacle that hits the robot sole plate at different locations. The proposed reflex system, therefore, contributes towards the safer interaction of the humanoid robot with the environment.	artificial neural network;gyro;humanoid robot;modulation;robot leg;sensor;velocity obstacle	Riadh Zaier;Shinji Kanda	2008	2008 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2008.4650738	control engineering;simulation;adaptive control;computer science;engineering;humanoid robot;artificial intelligence;control theory	Robotics	65.95866606417367	-24.420394076913283	173929
f09296370b791e1df18dd2e253df9bbfeb3fa317	animated robots and robotic animation	robotic animation;control systems;motion control;legged locomotion;motion control computer animation robots;task level instructions;task level instructions robotic animation animated robots active balance springy legs dynamic control body motion;dynamic control;springy legs;control system;robot control;body motion;animated robots;animation robot control control systems legged locomotion leg motion control;robots;animation;active balance;computer animation;leg;virtual worlds	"""We are interested in physical robots that move in the physical world and in simulated creatures that move in the virtual world. We have built a series of physical robots that include one-legged hoppers, biped runners, a quadruped, and two kangaroo-like robots. These robots use simple control systems to run with several gaits (hop, run, trot, pace, bound), go fast, traverse simple paths, jump obstacles, climb a simplified stairway, and perform rudimentary gymnastic maneuvers. Although no one robot performs all these task, they all use a common set of principles for their control. We think that active balance, springy legs, and dynamic control are the features responsible for whatever """"lifelike"""" behavior these machines have. Recently we have begun to use ideas about robot control to control animated creatures. The idea is to give these creatures knowledge and control of their body motion so the animator can act more like a director, working at a relatively high level. If the creature knows how to move in response to task-level instructions, then the director can concentrate on creating the overall action and story."""	control system;flash animation;high-level programming language;robot control;simulation;traverse;virtual world	Marc H. Raibert	1995		10.1109/ROBOT.1995.525736	robot;motion control;anime;computer vision;simulation;computer science;control system;artificial intelligence;robot control;computer animation;computer graphics (images)	Robotics	66.06442380809787	-26.101770842545893	174133
91cc74c2b6da401e6a797ae373220d156820efa5	fuzzy genetic motion planning under diverse terrain conditions for autonomous robots	motion planning;genetics		autonomous robot;motion planning	Terrence P. Fries	2004			robot;fuzzy logic;terrain;simulation;motion planning;robot control;artificial intelligence;computer vision;autonomous robot;computer science	Robotics	55.72538340552258	-24.448256561242847	174507
c3be9eb505154d166787dc0138af4c8fe44e2145	speed adaptation for self-improvement of skills learned from user demonstrations		The paper addresses the problem of speed adaptation of movements subject to environmental constraints. Our approach relies on a novel formulation of velocity profiles as an extension of dynamic movement primitives (DMP). The framework allows for compact representation of non-uniformly accelerated motion as well as simple modulation of the movement parameters. In the paper, we evaluate two model free methods by which optimal parameters can be obtained: iterative learning control (ILC) and policy search based reinforcement learning (RL). The applicability of each method is discussed and evaluated on two distinct cases, which are hard to model using standard techniques. The first deals with hard contacts with the environment while the second process involves liquid dynamics. We find ILC to be very efficient in cases where task parameters can be easily described with an error function. On the other hand, RL has stronger convergence properties and can therefore provide a solution in the general case.		Rok Vuga;Bojan Nemec;Ales Ude	2016	Robotica	10.1017/S0263574715000405	simulation;human–computer interaction;computer science;multimedia	ML	61.91843529227798	-24.27355114850262	174778
02eb4d15a04276b823291f800be549cf4139efa0	visual detection and implementation aspects of a uav see and avoid system	qa75 electronic computers computer science szamitastechnika;uav;szamitogeptudomany;long range visual detection uav see and avoid many core;mobile robots;remotely operated vehicles;aerospace safety;arrays aircraft cameras estimation target tracking visualization;arrays;collision avoidance systems;visualization;control system;see and avoid;research and development;long range visual detection;robot vision;estimation;detection algorithm;robot vision aerospace safety aircraft collision avoidance mobile robots object detection remotely operated vehicles;collision avoidance;long range;power consumption;target tracking;many core;cameras;object detection;core processor device visual detection uav see and avoid system critical on board safety equipment unmanned arial vehicles collision avoidance system small aircraft power consumption control system;aircraft	One of the missing critical on-board safety equipment of the Unmanned Arial Vehicles (UAVs) is the collision avoidance system. In 2010 we launched a project to research and develop an SAA system for UAS. As the system will be on-board in a small aircraft we have to minimize the weight, the volume, and the power consumption. The acceptable power consumption is 1–2W and the mass of the control system is maximum 300–500g. Here we present the concept of a visual input based See and Avoid (SAA) system. This paper introduces the long range visual detection algorithm and the implementation aspect of the many core processor device.	algorithm;computation;control system;flowchart;high-level architecture;image processing;intel core (microarchitecture);low-power broadcasting;manycore processor;on-board data handling;pixel;sense;unmanned aerial vehicle	Tamas Zsedrovits;Ákos Zarándy;Bálint Vanek;Tamas Peni;Jozsef Bokor;Tamás Roska	2011	2011 20th European Conference on Circuit Theory and Design (ECCTD)	10.1109/ECCTD.2011.6043389	remotely operated underwater vehicle;mobile robot;embedded system;computer vision;estimation;simulation;visualization;computer science;engineering;control system;statistics	Robotics	56.44917768058322	-32.135443905807655	174828
c456d3d17c947e64b62958f8addd087b3c043b05	an adaptive genetic path planner for rovers operating in partially known environments	genetics			Mahmoud Tarokh;David Debonis	2002			planner;simulation;artificial intelligence;machine learning;computer science	Robotics	55.53953441836601	-24.49017496665601	174853
a64fe885b5a11f222d3569de1d4378500f276d21	fast adaptation for effect-aware pushing	pushing actions fast adaptation effect aware pushing skilled manipulation external stimulus robot knowledge mathematical compact model planar sliding motion;force friction predictive models cognition robot kinematics mathematical model;robots;learning artificial intelligence;robots learning artificial intelligence;compact model	In order to produce robots that are more capable of skilled manipulation tasks, they must learn meaningful knowledge of how objects behave to external stimulus. With this knowledge a robot can predict the outcome of an action, control the object to serve a particular purpose, and together with reasoning, create or modify robot plans. In this paper we 1) build a mathematical compact model for planar sliding motion of an object, 2) show how a robot acquires the parameters of such a model; then how this is used to 3) predict pushing actions; and 4) to move an object from any1 position and orientation to another.	robot	Federico Ruiz-Ugalde;Gordon Cheng;Michael Beetz	2011	2011 11th IEEE-RAS International Conference on Humanoid Robots	10.1109/Humanoids.2011.6100863	robot;computer vision;simulation;computer science;artificial intelligence;social robot;robot control	Robotics	62.21070787206413	-25.18731502186034	175027
14203016b29c47d4ef1db140c03109067453b34a	self-configuring robot swarms with dual rotating infrared sensors	robot sensing systems;dual rotating infrared sensors;mobile robot;position geometry;mobile robots;autonomous mobile robot;surface geometry;autonomous mobile robots;robot sensing systems infrared sensors robot kinematics mobile robots network topology intelligent robots hardware infrared detectors large scale systems costs;object identification self configuring robot swarms dual rotating infrared sensors autonomous mobile robots low cost position detection system position geometry surface geometry;multi robot systems;low cost position detection system;servomotors;multi robot systems infrared detectors mobile robots;infrared;object identification;hardware implementation;infrared sensors;infrared detectors;self configuring robot swarms;robot kinematics	This paper presents practical design and hardware implementation issues of self-configuring swarms of autonomous mobile robots. For the purpose, we develop a new low-cost position detection system that we call dual rotating infrared (DRIr) sensor. The DRIr sensor can provide robots with advanced sensing capabilities that give reliable information about the position and surface geometry of neighboring robots and obstacles. Special focus is placed on how to realize the observation and object identification of mobile robots through the use of DRIr sensors. We verify the functionality and performance of the DRIr sensors mounted on a commercial mobile robot. Experimental results show that a swarm of mobile robots equipped with the DRIr sensors can autonomously configure themselves into an area.	autonomous robot;mobile robot;prototype;sensor;swarm robotics	Geunho Lee;Seokhoon Yoon;Nak Young Chong;Henrik I. Christensen	2009	2009 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2009.5354737	control engineering;mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence	Robotics	57.550409122577285	-31.416644917990265	175102
cc48a0a4bec65a885de4159f43520e2f50c44a5c	the use of biologically-inspired rules to control a collective robotic arm		Robotic arms are generally not adaptable in unknown, dynamic environments. This research tested whether a robotic arm using a collective control architecture could exhibit adaptive behavior without centralized control. To simulate the physical properties of a collective robotic arm, we used a puppet arm with six identical elbow-shaped segments, each of which rotated orthogonally with respect to its adjacent neighbors. A control strategy of sensor-driven, distal leadership was applied to the collection of autonomous segments, each encapsulated with identical movement rules and without any central control or explicit communication. A goal of pointing to a target was chosen to assess the possible emergent behaviors of the system. The results indicated that the simple movement rules in a collective control architecture lead to coordinated pointing behavior.	robotic arm;robotics	Gene G. Korienek;Abigail B. Bautista;Tyson H. Harty;Charles Leddon	2000			computer science;robotic paradigms	Robotics	64.8870506718403	-26.009504038112016	175143
36a964f22e506f2cc50495baf8cae8b09078218f	airborne simultaneous localisation and map building	observability;aircraft control;control nonlinearities aerospace robotics aircraft navigation aircraft control observability;mobile robots;radar information simultaneous localisation and map building uninhabited aerial vehicle single vision camera inertial measurement unit observability autonomous navigation airborne platforms vision sensor;image sensors;inertial measurement unit;computer vision;conference paper;uninhibited aerial vehicle;simultaneous localization and mapping unmanned aerial vehicles vehicle dynamics remotely operated vehicles navigation australia aerospace engineering aerodynamics land vehicles robots;keywords aerial photography;mathematical models;aerospace robotics;control nonlinearities;algorithms;mapping;flight test;computer simulation;cameras;simultaneous localisation and map building;uninhabited aerial vehicle;aircraft navigation	This paper presents results of the application of simultaneous localisation and map building (SLAM) for an uninhabited aerial vehicle (UAV). Single vision camera and inertial measurement unit (IMU) are installed in a UAV platform. The data taken from a flight test is used to run the SLAM algorithm. Results show that both the map and the vehicle uncertainty are corrected even though the model of the system and observation are highly non-linear. The results, however, also indicate that further work of observability and the relationship between vehicle model drift and the number and the location of landmarks need to be further analysed given the highly dynamic nature of the system.	airborne ranger;simultaneous localization and mapping	Jong-Hyuk Kim;Salah Sukkarieh	2003		10.1109/ROBOT.2003.1241629	computer simulation;mobile robot;inertial measurement unit;computer vision;observability;simulation;computer science;engineering;aeronautics;image sensor;mathematical model	Vision	54.5586375897624	-36.28057832038034	175209
666b2379051b4eb90d76ce4d858a4820b1116e39	soft-body muscles for evolved virtual creatures: the next step on a bio-mimetic path to meaningful morphological complexity		In the past, evolved virtual creatures (EVCs) have been developed with rigid, articulated bodies, and with soft bodies, but never before with a combination of the two. In nature, however, creatures combining a rigid skeleton and non-rigid muscles are some of the most complex and successful examples of life on earth. Now, for the first time, creatures with fully evolved rigid-body skeletons and soft-body muscles can be developed in the virtual world, as well. By exploiting and re-purposing the capabilities of existing soft-body simulation systems, we can evolve complex and effective simulated muscles, able to drive a rigid-body skeleton. In this way, we can begin to bridge the gap between articulated and softbodied EVCs, and take the next step on a nature-inspired path to meaningful morphological complexity for evolved virtual creatures.	british informatics olympiad;creatures;dynamical simulation;evolutionary computation;experiment;mathematical morphology;physics engine;simulation;straight skeleton;vesa enhanced video connector;virtual world	Dan Lessin;Sebastian Risi	2015		10.7551/978-0-262-33027-5-ch105	simulation;artificial intelligence;computer graphics (images)	AI	66.2245073194545	-26.473458217894013	175243
6f12683e049d1e810414a80aa5689db12d062f08	the poppy humanoid robot: leg design for biped locomotion	legged locomotion;legged locomotion humanoid robots;poppy humanoid robot morphological parts design 3d printing techniques human morphology functional modeling full body compliant physical human robot interaction humanoid robotic platform biped locomotion leg design;legged locomotion robot sensing systems morphology materials foot humanoid robots;humanoid robots	We introduce a novel humanoid robotic platform designed to jointly address three central goals of humanoid robotics: 1) study the role of morphology in biped locomotion; 2) study full-body compliant physical human-robot interaction; 3) be robust while easy and fast to duplicate to facilitate experimentation. The taken approach relies on functional modeling of certain aspects of human morphology, optimizing materials and geometry, as well as on the use of 3D printing techniques. In this article, we focus on the presentation of the design of specific morphological parts related to biped locomotion: the hip, the thigh, the limb mesh and the knee. We present initial experiments showing properties of the robot when walking with the physical guidance of a human.	3d printing;arm span;chris sawyer's locomotion;experiment;galaxy morphological classification;human-based computation;humanoid robot;human–computer interaction;human–robot interaction;lateral thinking;mathematical morphology;sensor	Matthieu Lapeyre;Pierre Rouanet;Pierre-Yves Oudeyer	2013	2013 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2013.6696375	control engineering;mobile robot;simulation;computer science;engineering;humanoid robot;artificial intelligence;robot locomotion	Robotics	67.66531546399322	-26.459452312794323	175253
ceb2a796d9a2749b5d73b8df64d7204db383d974	robot end-effector based sensor integration for tracking moving parts	robot sensing systems infrared sensors fuzzy logic sensor systems control systems manipulators belts robot vision systems motion measurement sensor systems and applications;vision system;manipulators;vision system robot end effector based sensor integration moving part tracking cost efficient end effector end effector based infrared proximity sensor integration system fuzzy logic control algorithm end effector sensor outputs robotic manipulator moving conveyor belt robot movements comparative measurements moving target gripper;fuzzy control;sensor integration;fuzzy logic control;robot manipulator;robot vision;optical tracking;cost efficiency;sensor fusion;infrared;optical tracking manipulators sensor fusion fuzzy control robot vision	The paper presents a cost-efficient end-effector based infrared proximity sensor integration system and the implementation of a fuzzy logic control algorithm. End-effector sensor outputs are incorporated in a fuzzy logic control algorithm to make the robotic manipulator grasp objects on a moving conveyor belt. The robot movements are going to be the result of the comparative measurements made by the sensors after the motion of the moving target is predicted and the gripper is brought into a zone close to the object to be grasped by the application of a vision system.	robot end effector	E. Ilhan Konukseven;Bilgin Kaftanoglu	2000		10.1109/KES.2000.884126	control engineering;computer vision;robot end effector;engineering;control theory;robot control	Robotics	58.494194025851094	-33.27952243135349	175479
5337f9563e7c727f39f29e18065d6137d3b630b6	teaching grasping to a humanoid hand as a generalization of human grasping data	humanoid robot;inf;data collection;programming by demonstration;mathematical model;imitation learning;programming tool;neural network	Humanoid robotics requires new programming tools. Programming by demonstration is good for simple movements, but so far the adaptation for fine movements in grasping is too difficult for it. Grasping of natural objects with a natural hand is known as one of the most difficult problems in robotics. Mathematical models have been developed only for simple hands or for simple objects. In our research we try to use data directly obtained from a human teacher as in imitation learning. To get data from users we built a data glove, we collected data from different experiments, and generalized them through neural networks. Here we discuss the nature of the data collected and their analysis.	artificial neural network;experiment;humanoid robot;mathematical model;programming by demonstration;programming tool;robotics;wired glove	Michele Folgheraiter;Ilario Baragiola;Giuseppina C. Gini	2004		10.1007/978-3-540-30478-4_12	computer vision;computer science;artificial intelligence;communication	Robotics	61.898503542157684	-25.417481945829934	175537
53f720af631569a2579a4b14f70adf30d896ed15	autonomous object handover using wrist tactile information		Grasping in an uncertain environment is a topic of great interest in robotics. In this paper we focus on the challenge of object handover capable of coping with a wide range of different and unspecified objects. Handover is the action of object passing an object from one agent to another. In this work handover is performed from human to robot. We present a robust method that relies only on the force information from the wrist and does not use any vision and tactile information from the fingers. By analyzing readings from a wrist force sensor, models of tactile response for receiving and releasing an object were identified and tested during validation experiments.		Jelizaveta Konstantinova;Senka Krivic;Agostino Stilli;Justus H. Piater;Kaspar Althoefer	2017		10.1007/978-3-319-64107-2_35	handover;simulation;wrist;robot;computer vision;computer science;artificial intelligence;robotics	Robotics	59.91674397502279	-29.01084746210893	175596
fd1e96c99d6952e904da1fe521f91d58b5435ef5	an endocrine system inspired behavior selecting algorithm for moving robot system	endocrine system inspired behavior selecting algorithm artificial endocrine system collectable objectives moving robot system;artificial endocrine system;biochemistry robot kinematics endocrine system fatigue algorithm design and analysis heuristic algorithms;robotics;robotics artificial endocrine system behavior switching;robots biomimetics;behavior switching	The robots that operate in real environment are often limited to many different problems. One of the main problems comes from the fact that outdoor real-world environments are dynamic and full of interventions, and the reactive behaviors may be sometimes conflicting to each other correspondingly. Artificial endocrine system can be the key to solve the problem. This paper proposes an algorithm for the coordination of multiple and possible conflicting behaviors selecting algorithm, devoted to reach the goal while collecting collectable objectives. The proposed endocrine based behavior selecting algorithm is composed of an artificial endocrine system, including two hormones, and three behaviors. The experiments are performed in simulation conditions. The results show that the algorithm proposed is able to coordinate a multiple and conflicting behaviors task, with less time and being more efficient.	algorithm;experiment;robot;simulation	Fangzhou Li;Lihong Ren;Yongsheng Ding;Kuangrong Hao	2015	2015 10th International Conference on Intelligent Systems and Knowledge Engineering (ISKE)	10.1109/ISKE.2015.67	control engineering;simulation;engineering;artificial intelligence	Robotics	59.15176077788203	-25.044662394218513	175637
238224e7d993bed64620b14a0386628f9baa918b	active-vision for the autonomous surveillance of dynamic, multi-object environments	10 1;tecnologia industrial tecnologia mecanica;tecnologia electronica telecomunicaciones;multi agent system;surveillance;surveillance system;real time;a priori knowledge;103 0;sensor fusion;tecnologias;grupo a;1 0;active vision	This paper presents a novel method for active-vision-based sensing-system reconfiguration for the autonomous surveillance of an object-of-interest as it travels through a multi-object dynamic workspace with an a priori unknown trajectory. Several approaches have been previously proposed to address the problem of sensor selection and control. However, these have primarily relied on off-line planning methods and rarely utilized on-line planning to compensate for unexpected variations in a target’s trajectory. The method proposed in this paper, on the other hand, uses a multi-agent system for on-line sensing-system reconfiguration, eliminating the need for any a priori knowledge of the target’s trajectory. Thus, it is robust to unexpected variations in the environment. Simulations and experiments have shown that the use of dynamic sensors with the proposed on-line reconfiguration algorithm can tangibly improve the performance of an active-surveillance system.	active vision;algorithm;autonomous robot;computer simulation;desktop virtualization;experiment;multi-agent system;online and offline;sensor;workspace	Ardevan Bakhtari;Matthew D. Mackay;Beno Benhabib	2009	Journal of Intelligent and Robotic Systems	10.1007/s10846-008-9247-0	embedded system;a priori and a posteriori;simulation;active vision;computer science;engineering;artificial intelligence;multi-agent system;sensor fusion;division by zero	Robotics	58.899350239023605	-31.01949138028674	175706
99e1ea5178ee38d826ed41873b880deeebd2dc2b	biomimetic robotics: mechanisms and control. ranjan vepa. (2009, cambridge university press.) $99, 360 pages.	biomimetic robotics;ranjan vepa;cambridge university press;book review	Biomimetic Robotics is a well-organized book for understanding the basic concepts and theories of robotic control. It is an excellent textbook for beginners in robotics and those interested in performing control tasks both on mobile robots and on manipulators, especially for aerial or underwater mechanisms. The book introduces every aspect in a progressive way, chapter by chapter, helping the reader to get deeper into the theory and concepts. The book contains exercises at the end of each chapter (and the solutions to those exercises at the end of the text), which help the reader to test and reinforce the theories and methods described. This is fundamental for any textbook, especially for beginners. The tables and figures are sufficient to illustrate the given concepts and summarize the data. The book is written in nontechnical language and gives many practical examples.	aerial photography;biomimetics;mobile robot;robotics;theory	Adalberto Llarena	2010	Artificial Life	10.1162/artl_r_00003	cognitive science	Robotics	66.96437487602712	-27.918245816502722	175932
8d84bf93c6467f0ea52bd470c33b993f43336782	error modelling for multi-sensor measurements in infrastructure-free indoor navigation	error modelling;indoor positioning;particle filtering;sensor fusion	The long-term objective of our research is to develop a method for infrastructure-free simultaneous localization and mapping (SLAM) and context recognition for tactical situational awareness. Localization will be realized by propagating motion measurements obtained using a monocular camera, a foot-mounted Inertial Measurement Unit (IMU), sonar, and a barometer. Due to the size and weight requirements set by tactical applications, Micro-Electro-Mechanical (MEMS) sensors will be used. However, MEMS sensors suffer from biases and drift errors that may substantially decrease the position accuracy. Therefore, sophisticated error modelling and implementation of integration algorithms are key for providing a viable result. Algorithms used for multi-sensor fusion have traditionally been different versions of Kalman filters. However, Kalman filters are based on the assumptions that the state propagation and measurement models are linear with additive Gaussian noise. Neither of the assumptions is correct for tactical applications, especially for dismounted soldiers, or rescue personnel. Therefore, error modelling and implementation of advanced fusion algorithms are essential for providing a viable result. Our approach is to use particle filtering (PF), which is a sophisticated option for integrating measurements emerging from pedestrian motion having non-Gaussian error characteristics. This paper discusses the statistical modelling of the measurement errors from inertial sensors and vision based heading and translation measurements to include the correct error probability density functions (pdf) in the particle filter implementation. Then, model fitting is used to verify the pdfs of the measurement errors. Based on the deduced error models of the measurements, particle filtering method is developed to fuse all this information, where the weights of each particle are computed based on the specific models derived. The performance of the developed method is tested via two experiments, one at a university's premises and another in realistic tactical conditions. The results show significant improvement on the horizontal localization when the measurement errors are carefully modelled and their inclusion into the particle filtering implementation correctly realized.	algorithm;awareness;course (navigation);curve fitting;design review (u.s. government);experiment;fuse device component;hl7publishingsubsection <operations>;kalman filter;medication event monitoring system;microelectromechanical systems;motion;normal statistical distribution;numerous;particle filter;portable document format;requirement;sonar (symantec);simultaneous localization and mapping;software propagation;statistical model;utility functions on indivisible goods;version;weight;sensor (device)	Laura Ruotsalainen;Martti Kirkko-Jaakkola;Jesperi Rantanen;Maija Mäkelä	2018		10.3390/s18020590	observational error;electronic engineering;engineering;simultaneous localization and mapping;kalman filter;inertial measurement unit;gaussian noise;control engineering;sensor fusion;particle filter;statistical model	Robotics	54.77163699677191	-37.44262729115147	176088
2c29370fcfd36699fa263f1bf942d5b60b9eb974	conops and autonomy recommendations for vtol small unmanned aerial system based on hurricane katrina operations		This field study examines vertical takeoff and landing (VTOL) small unmanned aerial system (SUAS) operations conducted as part of an 8-day structural inspection task following Hurricane Katrina in 2005. From the observations of the 32 flights spread over 12 missions, four key findings are identified for concept of operations (CONOPS) and the next level of artificial intelligence for rotary-wing SUASs operating in cluttered urban environments. These findings are (1) the minimum useful standoff distance from inspected structures is 2–5 m, (2) omnidirectional sensor capabilities are needed for obstacle avoidance, (3) global positioning system waypoint navigation is unnecessary, and (4) these operations require three operators for one SUAS. Based on the findings and other observations, a crewing organization and flight operations protocol for SUASs are proposed. Needed directions in research and development are also discussed. These recommendations are expected to contribute to the design of platforms, sensors, and artificial intelligence as well as facilitate the acceptance of SUASs in the workplace. © 2009 Wiley Periodicals, Inc.	aerial photography;unmanned aerial vehicle	Kevin S. Pratt;Robin R. Murphy;Sam Stover;Chandler Griffin	2009	J. Field Robotics	10.1002/rob.20304	simulation;chemistry;aerospace engineering;engineering;aeronautics	Robotics	54.477101953964414	-29.31140913950352	176151
36da87610cd0080a2c5c5d3addedf9dd8f52a81f	experimental analysis of the conditions of applicability of a robot sensorimotor coordination scheme based on expected perception	cognitive systems;experimental analysis;intelligent robots;environmental conditions;settore m fil 02 logica e filosofia della scienza;cognitive systems feedback sensor fusion dexterous manipulators intelligent robots;dexterous manipulators;robot arm;feedback;trajectory following expected perception robot sensorimotor coordination scheme feedback loops color camera dexter 8 d o f robotic arm pushing task;feedback loop;sensor fusion;robot sensing systems robot kinematics humans delay sensor systems subspace constraints paper technology laboratories feedback loop robot vision systems;settore ing inf 06 bioingegneria elettronica e informatica	This paper describes an experimental work conducted in order to estimate the conditions of applicability of expected perception (EP) based on a scheme for robot sensorimotor coordination. The starting hypothesis is that predictions of incoming sensory data can improve sensorymotor coordination respect to pure feedback loops. This implies that the environment presents a level of predictability, as in realistic environments. An implementation of the EP-based scheme has been realized on a platform composed by the Dexter 8-d.o.f. robotic arm and a color camera, for executing a pushing task in a real-world environment. Its performance, where defined as a combination of the error in the trajectory following and the computational effort, has been compared with that of a feedback-based system executing the same task in the same environmental conditions. The results have been put in relation with the degree of environmental predictability, which was controlled in the experimental trials. The experimental results give support and useful insights for analyzing the applicability of the EP-based scheme.	computation;expectation propagation;feedback;robot;robotic arm	Edoardo Datteri;Gioel Asuni;Giancarlo Teti;Cecilia Laschi;Paolo Dario;Eugenio Guglielmelli	2004	2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)	10.1109/IROS.2004.1389577	control engineering;computer vision;simulation;robotic arm;computer science;engineering;artificial intelligence;social robot;feedback loop;control theory;feedback;sensor fusion;robot control;experimental analysis of behavior	Robotics	60.71827171954698	-27.780703559402614	176415
65d15422569614cc18200b8a19db936ad997507e	rapid pole climbing with a quadrupedal robot	quadrupedal robot;uniformly convex;legged locomotion;selected works;rise v3 climbing machine;mechanical design;roll stability;rapid pole climbing;foot;actuators;ad hoc network;energy dense power transmission;power transmission;force;stability;robots legged locomotion telephone poles tail couplings leg power transmission propulsion stability energy consumption;energy consumption;stability design energy consumption legged locomotion;behavioral robot gait;bepress;design;minimal energy consumption quadrupedal robot rapid pole climbing legged robot rise v3 climbing machine energy dense power transmission behavioral robot gait mechanical design roll stability;complex terrain;mechanism design;minimal energy consumption;high speed;legged robot;leg;traction motors	This paper describes the development of a legged robot designed for general locomotion of complex terrain but specialized for dynamical, high-speed climbing of a uniformly convex cylindrical structure, such as an outdoor telephone pole. This robot, the RiSE V3 climbing machine—mass 5.4 kg, length 70 cm, excluding a 28 cm tail appendage—includes several novel mechanical features, including novel linkage designs for its legs and a non-backdrivable, energy-dense power transmission to enable high-speed climbing. We summarize the robot's design and document a climbing behavior that achieves rapid ascent of a wooden telephone pole at 21 cm/s, a speed previously unachieved—and, we believe, heretofore impossible—with a robot of this scale. The behavioral gait of the robot employs the mechanical design to propel the body forward while passively maintaining yaw, pitch, and roll stability during climbing locomotion. The robot's general-purpose legged design coupled with its specialized ability to quickly gain elevation and park at a vertical station silently with minimal energy consumption suggest potential applications including search and surveillance operations as well as ad hoc networking.	attachments;dynamical system;expect;futures studies;general-purpose modeling;hill climbing;hoc (programming language);interaction;linkage (software);propel;prototype;robot;times ascent;uniformly convex space;yaws	G. Clark Haynes;Alex Khripin;Goran Lynch;Jonathan Amory;Aaron Saunders;Alfred A. Rizzi;Daniel E. Koditschek	2009	2009 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2009.5152830	control engineering;mechanism design;design;simulation;stability;power transmission;engineering;control theory;force;foot	Robotics	67.1893063089728	-26.192605721460545	176459
8166092bd75e64731bf74721dad9d50c2a6d3ca7	experiments with cooperative control of underwater robots	vision based navigation;cooperative control;autonomous underwater vehicle;underwater vehicles;coupled system;sensor network;underwater sensor network;software architecture;long distance;autonomous underwater vehicles;underwater sensor networks;sensor nodes;underwater vehicle control;autonomous robot;underwater communications	In this paper we describe cooperative control algorithms for robots and sensor nodes in an underwater environment. Cooperative navigation is defined as the ability of a coupled system of autonomous robots to pool their resources to achieve long-distance navigation and a larger controllability space. Other types of useful cooperation in underwater environments include: exchange of information such as data download and retasking; cooperative localization and tracking; and physical connection (docking) for tasks such as deployment of underwater sensor networks, collection of nodes, and rescue of damaged robots. We present experimental results obtained with an underwater system that consists of two very different robots and a number of sensor network modules. We present the hardware and software architecture of this underwater system. We then describe various interactions between the robots and sensor nodes and between the two robots, including cooperative navigation. Finally, we describe our experiments with this underwater system and present data.	acoustic cryptanalysis;algorithm;autonomous robot;browser extension;consensus dynamics;docking (molecular);download;entity–relationship model;experiment;human–computer interaction;ibm notes;leslie speaker;partial template specialization;sensor node;software architecture;software deployment	Matthew Dunbabin;Peter I. Corke;Iuliu Vasilescu;Daniela Rus	2009	I. J. Robotics Res.	10.1177/0278364908098456	control engineering;underwater acoustic communication;embedded system;software architecture;simulation;wireless sensor network;computer science;engineering	Robotics	58.01810812989257	-27.066629862524316	176507
4a9f6d7e67fc3c4a9050940263ef125adaa6cca6	navigation and sar focusing with map aiding	detectors;signalbehandling;synthetic aperture radar navigation optical imaging image edge detection trajectory detectors optical sensors;navigation;optical imaging;trajectory;image edge detection;signal processing;synthetic aperture radar autonomous aerial vehicles edge detection geophysical image processing image fusion image matching inertial navigation least mean squares methods optimisation radar imaging remote sensing by radar search radar;optical sensors;error size estimation synthetic aperture radar sar navigation sar focusing sar image fusion optical aerial image coordinates absolute position estimation orientation estimation inertial navigation system small unmanned vehicles survelliance remote sensing edge detection algorithm navigation state optimisation binary image matching least square method;synthetic aperture radar	A method for fusing synthetic aperture radar (SAR) images with optical aerial images is presented. This is done in a navigation framework, in which the absolute position and orientation of the flying platform, as computed from the inertial navigation system, is corrected based on the aerial image coordinates taken as ground truth. The method is suitable for new low-price SAR systems for small unmanned vehicles. The primary application is surveillance, and to some extent it can be applied to remote sensing, where the SAR image provides complementary information by revealing reflectivity to microwave frequencies. The method is based on first applying an edge detection algorithm to the images and then optimising the most important navigation states by matching the two binary images. To get a measure of the estimation uncertainty, we embed the optimisation in a least squares framework, in which an explicit method to estimate the (relative) size of the errors is presented. The performance is demonstrated on real SAR and aerial images, leading to an error of only a few pixels (around 4 m in our case), which is a quite satisfactory performance for applications like surveillance and navigation.	aerial photography;algorithm;aperture (software);backup;binary image;chamfer;datasaab;edge detection;estimation theory;explicit and implicit methods;goto;ground truth;inertial navigation system;informatics;lars bak (computer programmer);least squares;mathematical optimization;microwave;pattern matching;pixel;principle of good enough;radar;remote sensing application;satellite navigation;simplified instructional computer;simulation;synthetic data;unmanned aerial vehicle	Zoran Sjanic;Fredrik Gustafsson	2015	IEEE Transactions on Aerospace and Electronic Systems	10.1109/TAES.2015.130397	computer vision;detector;navigation;synthetic aperture radar;geodesy;trajectory;signal processing;optical imaging;radar imaging;inverse synthetic aperture radar;side looking airborne radar;physics;remote sensing	Vision	54.283255522168005	-37.538875372395275	176527
3143fb6e7e96431b7953f23bc3c3dc6fce8acfb0	design and implementation of a dual-axis tilting quadcopter		Standard quadcopters are popular largely because of their mechanical simplicity relative to other hovering aircraft, low cost and minimum operator involvement. However, this simplicity imposes fundamental limits on the types of maneuvers possible due to its under-actuation. The dexterity and fault tolerance required for flying in limited spaces like forests and industrial infrastructures dictate the use of a bespoke dual-tilting quadcopter that can launch vertically, performs autonomous flight between adjacent obstacles and is even capable of flying in the event of the failure of one or two motors. This paper proposes an actuation concept to enhance the performance characteristics of the conventional under-actuated quadcopter. The practical formation of this concept is followed by the design, modeling, simulation and prototyping of a dual-axis tilting quadcopter. Outdoor flight tests using tilting rotors, to follow a trajectory containing adjacent obstacles, were conducted in order to compare the flight of conventional quadcopter with the proposed over-actuated vehicle. The results show that the quadcopter with tilting rotors provides more agility and mobility to the vehicle especially in narrow indoor and outdoor infrastructures.		Ali Bin Junaid;Alejandro Diaz De Cerio Sanchez;Javier Betancor Bosch;Nikolaos Vitzilaios;Yahya H. Zweiri	2018	Robotics	10.3390/robotics7040065	control engineering;fault tolerance;engineering;trajectory;quadcopter	Robotics	63.579383057456354	-27.975071263422613	176705
9c86b0a6a17d2bbf20901a99d96c94bdb5b8d596	petri net with rfid distributed database for autonomous search and rescue in tracks and crossings		A modified Petri Net inside RFID database is proposed to assist search and rescue in trails and crossings. The main idea is presented directing rescue agents and trekkers in external areas without the guarantee of satellite communication and with restriction of points with electric power.	communications satellite;distributed database;petri net;radio-frequency identification	João Paulo da Silva Fonseca;José Jean-Paul Zanlucchi de Souza Tavares	2017			search and rescue;petri net;distributed database;distributed computing;computer science	Robotics	57.04060728735523	-25.78282782215635	176792
50809b77bfa4691ad2676867a32da51a6ccdb374	network-centric multisensor-multitarget tracking testbed based on peer-to-peer communication	multisensor multitarget tracking testbed;testing peer to peer computing radar tracking target tracking sensor fusion surveillance state estimation electronic mail sea measurements sensor systems;imm assignment tracker;sensor systems;electronic mail;radar tracking;fusion;surveillance;multiple hypothesis tracker;multitarget tracking;particle filter tracker;multiple hypothesis tracker multisensor multitarget tracking testbed peer to peer communication maritime surveillance imm assignment tracker particle filter tracker;testing;state estimation;testbed;particle filter;peer to peer communication;distributed;sensor fusion;peer to peer computing;target tracking;fusion testbed tracking distributed;target tracking large scale systems peer to peer computing sensor fusion;scenario generation;peer to peer;maritime surveillance;tracking;large scale systems;distributed architecture;sea measurements	In this paper we present a multisensor-multitarget tracking testbed for large-scale distributed scenarios. The objective is to develop a testbed capable of handling multiple, heterogeneous sensors in a hierarchical architecture for maritime surveillance. The testbed consists of a scenario generator that can generate simulated data from multiple sensors including radar, sonar, IR and ESM as well as a tracker framework into which different tracking algorithms can be integrated. In the current stage of the project, the IMM/assignment tracker, and the particle filter (PF) tracker are implemented in a distributed architecture and some preliminary results are obtained. Other trackers like the multiple hypothesis tracker (MHT) are also planned for the future	algorithm;distributed computing;mhtml;particle filter;performance evaluation;radar;sonar (symantec);sensor;testbed;tracking system	Dmitry Akselrod;Abhijit Sinha;Thia Kirubarajan;Mohamad Farooq;Z. J. Ding	2006	2006 Canadian Conference on Electrical and Computer Engineering	10.1109/CCECE.2006.277340	embedded system;computer vision;radar tracker;simulation;particle filter;fusion;computer science;engineering;sensor fusion;tracking;software testing;testbed	Robotics	57.03163774707119	-26.89890515151562	176854
9bb5049dbf05fff2bbcf63fc24124dfd36672a56	trajectory generation for 1000 fps direct visual servoing	visual servoing	This paper presents a trajectory generation method by using a repetitive product pattern as visual encoder for control feedback. A direct, high-speed coupling between camera measurements and local motor control motivates the omission of local motor encoders. By exploiting the repetitive structure of the product and sampling at a high update rate (i.e., 1000 fps), a velocityconstraint polynomial trajectory is designed for imagebased velocity feedback. We present algorithms for image processing and trajectory generation with a frame rate of 1000 fps and an image size of 619× 75 pixels.	algorithm;computation;control system;encoder;field-programmable gate array;high- and low-level;image processing;image resolution;pixel;polynomial;sampling (signal processing);sensor;time complexity;velocity (software development);visual servoing	Roel Pieters;Pieter P. Jonker;Henk Nijmeijer	2011			computer vision;computer science;control theory	Robotics	60.04372811486983	-33.57144708373718	176888
d06a3c0daea446d7a6232463a9b589d2c74f63bd	scalable distributed collaborative tracking and mapping with micro aerial vehicles	computers;robot kinematics bandwidth cameras computers sensors tracking;scalable distributed collaborative tracking off board computer optimization map creation frame to frame tracking image capture collaborative multirobot localisation distributed framework micro aerial vehicles scalable distributed collaborative mapping;sensors;qa75 electronic computers computer science;image capture aircraft cartography;bandwidth;cameras;tracking;robot kinematics	This paper describes work on a distributed framework for collaborative multi-robot localisation and mapping with large teams of Micro Aerial Vehicles (MAVs). We demonstrate the benefits of running both image capture and frame-to-frame tracking on the same device while offloading the more computationally intensive aspects of map creation and optimization to an off-board computer. We show no impact on the accuracy of pose estimates of this distributed approach and indeed demonstrate a robustness to delay that improves localisation performance. The bandwidth requirements of our system are much lower than similar systems which enables us to accommodate larger teams of MAVs. In the results section we demonstrate the performance of our system in both simulated and real-world environments.	aerial photography;distributed computing;mathematical optimization;requirement;robustness (computer science);simulation;simultaneous localization and mapping	Richard Williams;Boris Konev;Frans Coenen	2015	2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2015.7353804	embedded system;computer vision;simulation;computer science;engineering;sensor;artificial intelligence;tracking;bandwidth;robot kinematics	Robotics	54.2127638105497	-36.17984708898853	177018
9beaa288276002299190ecb662646b24430a904c	a robot-machine interface for full-functionality automation using a humanoid	flight simulation equipment robot machine interface full functionality automation humanoid robots airplane control flight control equipment kinematic variables piloting robot system;robot kinematics aerospace simulation aircraft control humanoid robots human robot interaction;conferences intelligent robots	Humanoid robots can be a highly desirable substitute for humans when it performs various tasks using tools and equipment designed for humans. One of such possible applications is controlling a vehicle. A humanoid robot can sit in the pilot's seat and command the vehicle using the control columns or steering wheels, pedals, switches, levers, and dials. In this paper, we propose a framework of automating a vehicle, an airplane in particular, with a humanoid. In order to perform various tasks of flying an unmodified airplane, the robot needs to perform three levels of tasks - recognition, decision, and action. The robot should collect information of the vehicle by using its own sensors and from various instruments in the cockpit, in addition to possible data link, a privilege of a robot. The robot then decides how to operate the flight control equipment in order to follow a given flight plan. Finally, it directly manipulates the control input equipment by computing the kinematic variables in the presence of various constraints from the surroundings. In order to validate the proposed framework, a piloting robot system is developed using a small low-cost humanoid and a flight simulation equipment designed for humans. The robot showed adequate performance to fly the airplane from cold start to landing to a stop on the runway.	autopilot;cold start;column (database);emoticon;flight simulator;humanoid robot;humans;input device;inverter (logic gate);network switch;radio control;sensor;simulation;steering wheel;vhf omnidirectional range;wheels	Heejin Jeong;David Hyunchul Shim;Sungwook Cho	2014	2014 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2014.6943131	control engineering;mobile robot;embedded system;robot end effector;simulation;engineering;humanoid robot;social robot;robot control;personal robot;robot calibration	Robotics	61.742377170736155	-29.327737555436823	177178
945be97dcc0c7505c91b8448dc01b550e5f3aa61	simulation of small humanoid robots for soccer domain	vision system;modelizacion;robot humanoide;humanoid robot;zona urbana;disaster;vision robot;motion control;competition;realite virtuelle;realidad virtual;sauvetage;soccer;degree of freedom;simulation;zone urbaine;virtual reality;bucle control;salvamento;robotics;commande mouvement;modelisation;captador medida;control movimiento;3d simulation;measurement sensor;capteur mesure;robot vision;robot control;sinistre;football;urban search and rescue;robotica;urban area;control loop;robotique;small humanoid robots;robot soccer;virtual environment;modeling;boucle commande;rescue;computer game;competencia;siniestro;futbol	In this paper, we illustrate the development of a realistic simulation of a humanoid robot model in a virtual environment using USARSim (Urban Search and Rescue Simulator). USARSim provides an accurate 3D simulation of a virtual environment with a detailed rendering and a realistic physics. Moreover, USARSim allows users to observe the virtual environment from different views. One of these is the egocentric view, which can simulate the camera mounted on the robot. The small humanoid robot presented in this work is Robovie-M, developed by VStone Ltd. (Japan). This robot is used by our team Artisti in the RobotCup soccer competitions. Reported experiments compare the behaviors of a real robot and of its virtual model, when controlled by the same control software to asses the possibility to faithfully simulate a robot with 22 degrees of freedom in USARSim. Moreover, we discuss the possibility to close the control loop of the robot in simulation, by simulating also the main robot sensor, i.e. the camera. The experiments show that USARSim, despite being a simple simulator based on a low cost computer game, provides an accurate enough simulation of the physics and a realistic rendering of the 3D scene enabling a faithfully simulation of a small humanoid robot at low cost. Thus, one can entirely test the robot software modules in the simulation (namely: the motion control modules, the vision system modules and, by closing the robot control loop in simulation, the behavior and behaviorselection modules).	3d modeling;closing (morphology);content-control software;control system;experiment;global illumination;humanoid robot;internet authentication service;mobile robot;order of approximation;pc game;principle of good enough;robot control;robot software;sensor;simulation;software development;virtual reality	Nicola Greggio;Emanuele Menegatti;Giovanni Silvestri;Enrico Pagello	2009	J. Franklin Institute	10.1016/j.jfranklin.2009.01.006	motion control;computer vision;disaster;simulation;competition;systems modeling;engineering;virtual machine;control system;humanoid robot;artificial intelligence;social robot;virtual reality;robot control;degrees of freedom;robotics;robot calibration	Robotics	65.29496062653871	-31.733274353380327	177260
3047c4ee24c97fa79c1e822b8c10bedb13fdca19	a comparison of industrial robots interface: force guidance system and teach pendant operation		Purpose – This paper aims to propose an evaluation method to compare two different Human–Robot Interaction (HRI) solutions that can be used for on-line programming in an industrial context: a force guidance system and the traditional teach pendant operation. Design/methodology/approach – The method defines three evaluation criteria (agility, accuracy and learning) and describes an experimental approach based on the analysis of variance to verify the performance of guidance systems according to these criteria. This method is used in this paper to compare the traditional teach pendant interface with an implementation of a force guidance system based on the use of an external force/torque sensor. Findings – The application of the proposed method to an off-the-shelf industrial robot shows that the force guidance system has a better performance according to the agility criterion. Both solutions have a similar performance for the accuracy criterion, with a limit of about 2 mm in the achieved position accuracy. Regarding the learning criterion, the authors cannot affirm that any of the methods has an improved agility when the operator repeats the tasks. Practical implications – This work supports the selection of guidance systems to be used in on-line programming of industrial applications. It shows that the force guidance system is an option potentially faster than the teach pendant when the required positioning accuracy is greater than 2 mm. Originality/value – The new method proposed in this paper can be applied to a large range of robots, not being limited to commercial available collaborative robots. Furthermore, the method is appropriate to accomplish further investigations in HRI not only to compare programming methods but also to evaluate guidance systems approaches or robot control systems.	cobot;control system;guidance system;human–robot interaction;industrial robot;online and offline;robot control	Guilherme Boulhosa Rodamilans;Emília Villani;Luís Gonzaga Trabasso;Wesley Rodrigues de Oliveira;Ricardo Suterio	2016	Industrial Robot	10.1108/IR-02-2016-0074	control engineering;simulation;engineering;artificial intelligence;mechanical engineering	Robotics	63.374331719410186	-26.67575399440036	177290
8afd02ca88393f2e2bb712afd7434ec610be8b2f	online motion planning using incremental construction of medial axis	mobile robot;path planning;computational geometry;mobile robots;mobile robots robot sensing systems motion planning path planning industrial engineering dead reckoning iterative algorithms navigation mechanical engineering orbital robotics;computational geometry collision avoidance path planning real time systems mobile robots;motion planning;collision avoidance;medial axis;sensor information online motion planning workspace medial axis construction mobile robots sonar sensor medial axis nodes hierarchical generalized voronoi graph collision detection;line of sight;real time systems	Absfracf This paper deals with the online path planning of mobile robots. We first suggest B systematic method to incrementally construct the Medial Axis of the workspace. This is done by using sensor information for land-marking the nodes of medial axis, which will guide the robot to explore the unknown environment thoroughly. Next, this approach is implemented in an online motion planning algorithm. This method c m be generalized to higher spaces, and uses only the line of sight information of sonar sensors. It is much simpler than HGVG method, and is eomplefe. The simulations showed good results for different environments.	algorithm;apache axis;automated planning and scheduling;item unique identification;medial graph;mobile robot;motion planning;optic axis of a crystal;sonar (symantec);sensor;simulation;workspace	Ellips Masehian;Mohammad Reza Amin-Naseri;Siamak Esmaeilzadeh Khadem	2003		10.1109/ROBOT.2003.1242040	control engineering;mobile robot;computer vision;simulation;computational geometry;computer science;engineering;artificial intelligence;motion planning	Robotics	54.00254018003637	-33.26975060284927	177480
95d853ae1b0e06f0794fb7242b51173d71055e78	role-based multi-robot exploration		The advent of robotic technologies means that teams of robots can be used for an ever wider range of tasks, such as exploration of unknown terrain, search and rescue in disaster scenarios, and inspection of hazardous areas. In many such applications, partial or full autonomy is a desirable characteristic for the robots, since this can reduce the load on human operators and improve the speed and quality of team coordination. However, in many scenarios the environments of interest may contain significant communication challenges due to their size or complexity, introducing the need for robust methods for communication-limited exploration by multiple robots. This thesis proposes “Role-Based Exploration”, a novel exploration algorithm for multi-robot systems that aims to efficiently gather information obtained by all members of the team in a single location. In Role-Based Exploration, some of the robots in the team explore the environment while others act as mobile relays, ferrying information back and forth within the team. By imposing a team hierarchy, choosing clever locations for robots to meet, and applying some simple rules that allow robots to exchange places within this hierarchy, a robust exploration system emerges that reactively adjusts to communication availability and to the shape of the environment. Role-Based Exploration demonstrates several advantages over other methods, particularly as communication becomes less reliable. New information obtained by the team is brought to a single location quickly and in regular intervals, team members share information well and often, and the full team effort can be easily monitored and controlled. The approach has been implemented and compared to competing algorithms both in simulation, and on a team of Pioneer robots.	algorithm;autonomy;complexity;dos;emergence;relay;robot;simulation	Julian de Hoog	2011				Robotics	56.21528998804562	-25.744009556875927	177766
70cd6a374e82a5306070436700d8a3fcfb17b223	adaptive visual servo control of robot manipulators via composite camera inputs	lyapunov methods;vision system;closed loop system;visual servo control;asymptotic end effector position tracking;uncertain systems;motion control;3d visualization;composite camera inputs;uncertainty;closed loop systems;robot work space;adaptive control;manipulateur;uncertainty compensation;programmable control;manipulator dynamics;robotics;asymptotic stability;orbital robotics;mechanical parameters;3d visual inclination;robot manipulator;stability;commande mouvement;lyapunov approach;control movimiento;compensation;robot vision;manipulador;control adaptativo;position control;control system synthesis;closed loop system adaptive visual servo control robot manipulators composite camera inputs position control uncertainty compensation robot dynamics vision system mechanical parameters 3d visual inclination robot work space asymptotic end effector position tracking lyapunov approach stability boundedness;servomechanisms;stereo image processing;commande adaptative;visual control;robotica;controle visuel;boundedness;robotique;robot dynamics;visual servoing;robot manipulators;programmable control adaptive control servosystems robot vision systems cameras manipulator dynamics uncertainty orbital robotics position control visual servoing;manipulator;end effectors manipulator dynamics servomechanisms position control robot vision stereo image processing asymptotic stability lyapunov methods closed loop systems adaptive control uncertain systems compensation control system synthesis;robot vision systems;adaptive visual servo control;cameras;control visual;end effectors;servosystems	This paper considers the problem of position control of robot manipulators via visual servoing in the presence of uncertainty associated with the robot dynamics and the vision system. Specifically, an adaptive controller is designed to compensate for the uncertainties associated with the mechanical parameters of the robot manipulator and the intrinsic parameters of the cameras. The 3D visual inclination is obtained from the composite inputs of two separate cameras placed in the robot work space. Despite the uncertainties associated with the camera system and robot dynamics the proposed adaptive controller achieves asymptotic end effector position tracking. A Lyapunov based approach is presented to prove the stability and boundedness of the closed loop system.	camera matrix;camera resectioning;closed-loop transfer function;image sensor;lyapunov fractal;nonlinear system;numerical stability;robot end effector;servo;visual servoing	H. Türker Sahin;Erkan Zergeroglu	2005	Proceedings of the Fifth International Workshop on Robot Motion and Control, 2005. RoMoCo '05.	10.1109/ROMOCO.2005.201427	control engineering;motion control;computer vision;robot end effector;visualization;uncertainty;stability;adaptive control;computer science;engineering;artificial intelligence;manipulator;control theory;mathematics;robot control;robotics;visual servoing;robot kinematics;statistics;robot calibration	Robotics	61.104967134894	-32.09787266797812	177847
b5a559115dcaa91202a2f3d879f8b27febd931fe	a dynamic adaptive deviation registration algorithm for heterogeneous sensors			algorithm;sensor	Zhimin Chen;Yuanxin Qu;Yuming Bo;Xiaodong Ling;Yongliang Zhang	2018	Computational Intelligence	10.1111/coin.12179	artificial intelligence;pattern recognition;computer science;particle filter;3d radar	AI	54.16028399878004	-36.852877598614086	177863
8d76cce2874ee107183c2f89482043a1cd263419	designing the ngc system of a small asv for tracking underwater targets	software;navigation guidance and control;autonomous surface vehicle asv;navigation;mathematics all;guidance and control;computer science applications1707 computer vision and pattern recognition;control and systems engineering;marine systems	The paper describes the development of the Navigation, Guidance and Control system of a small, prototypal Autonomous Surface Vehicle (ASV), which is part of an ASV/UUV (Unmanned Underwater Vehicle) robotic system. The main task of the ASV is to serve as supply vessel for the UUV it can carry, deploy and recover and to allow communication with a remote control station. The main problem the NGC system has to handle is that of making the ASV track the UUV and maintain the relative distance within a given bound, using delayed information about the UUV position provided by an acoustic tracking and positioning systems. The specific tracking problem is formulated in a suitable way and a strategy for its solution is proposed and implemented by means of an appropriate control architecture. Stability is discussed using Lyapunov techniques and performances are shown by means of simulations. A novel ASV/UUV system is described.The ASV is able to track autonomously the UUV after deployment.A suitable behavioral tracking strategy is defined and implemented.Stability of the involved control law is proved.Performances are evaluated by simulations.	new general catalogue	Giuseppe Conte;G. P. De Capua;D. Scaradozzi	2016	Robotics and Autonomous Systems	10.1016/j.robot.2015.11.008	embedded system;navigation;simulation	Robotics	57.77247964842133	-28.5361421275832	177930
d8c0b7a194816351f971416594afce51b30cc25a	relative navigation of an auv using a light-section ranging system	autonomous underwater vehicle;underwater vehicles;laser beams;mobile robots;laser ranging;navigation;navigation sea surface testing remotely operated vehicles marine technology underwater vehicles robustness umbilical cable humans motion control;collision avoidance mobile robots underwater vehicles laser ranging laser beams navigation;collision avoidance;depth map;precise depth mapping relative navigation light section ranging system autonomous underwater vehicles condition survey artificial structures sheet laser beam video images 3d mapping tri dog 1	"""Autonomous underwater vehicles (AUVs) are suitable for condition survey of the surface of artificial structures such as pillars and caissons in harbors. This paper introduces a method for AUVs to trace artificial structures using a light-section ranging system. This system acquires the profile of the target objects over a wide area using a sheet laser beam. The vehicle navigates by referencing the principal shape of the structure, and traces its surface while taking video images of it. This ranging system also enables 3D mapping of its surroundings based on high accuracy positioning. The method is implemented on the testbed AUV """"Tri-Dog 1"""" and its performance is verified through tank tests. It is shown that the AUV navigates robustly against small obstacles and floating particles. Precise depth mapping of the tank floor is also carried out using the same system."""	testbed;tracing (software)	Hayato Kondo;Toshihiro Maki;Tamaki Ura;Yoshiaki Nose;Takashi Sakamaki;Masaaki Inaishi	2004	ICARCV 2004 8th Control, Automation, Robotics and Vision Conference, 2004.	10.1109/ICARCV.2004.1468863	mobile robot;navigation;geodesy;computer science;engineering;artificial intelligence;marine engineering;depth map	Robotics	54.27218904998056	-34.99512742146889	178048
d75bfa2b2e715f3c8d84c1f2d75bfc120b6bfe73	microscale and nanoscale robotics systems [grand challenges of robotics]	robot sensing systems orbital robotics mobile robots robotics and automation space technology physics chemistry conducting materials humans sensor phenomena and characterization;robot sensing systems;microrobots;sensor phenomena and characterization;motion mechanisms;mobile robot;programmable manipulation;microscale robotics systems;mobile robots;nanotechnology;robotics;orbital robotics;nanoscale robotics systems;wireless communication;physics;conducting materials;nanotecnologia;space robotics;chemistry;robotica;mobile robotic systems;humans;space technology;robotique;mobile robots microrobots;nanotechnologie;motion mechanisms nanoscale robotics systems microscale robotics systems programmable manipulation mobile robotic systems;robotics and automation	Depending on their overall size, sensing and actuation precision, part or tool size, and task space, robotic systems can be classified as microrobotics or nanorobotics, respectively. Micro/nanorobotics represents these two different scale robotics areas jointly while keeping their clear scale differences in mind. At its current early infancy, the field of micro/nanorobotics has two major research thrust areas. Analogous to the manipulation area in macroscale robotics, the first area explores new methods for programmable manipulation and assembly of micro- and nanoscale entities. Here, the overall micro/nanorobotic system size can be very large, while only the manipulation tools, manipulated objects, and sensing, actuation, and manipulation precision are required to be at the micro/nanoscale. On the other hand, the second research area focuses on overall miniaturization of mobile robots down to mum overall sizes with various locomotion capabilities such as flying, swimming, walking, hopping, rolling, and climbing. In these mobile robotic systems, overall system size is very limited, which induces severe constraints in utilized actuators, sensors, motion mechanisms, power sources, computing power, and wireless communication capability. These two research thrusts are described in detail in the following sections	assembly language;entity;frequency-hopping spread spectrum;grand challenges;microbotics;mobile robot;nanorobotics;robotics;sensor;thrust	Metin Sitti	2007	IEEE Robotics & Automation Magazine	10.1109/MRA.2007.339606	control engineering;mobile robot;simulation;computer science;engineering;artificial intelligence;robotics	Robotics	66.59965662693494	-27.953050860431585	178108
12944f63ada888df14b364ec3c8105eadbbe3706	an autonomous path planner implemented on the rocky7 prototype microrover	mars;robot sensing systems;instruments;intelligent control space research mobile robots path planning navigation;trajectory planning;mobile robot;path planning;prototypes;autonomous path planning;terrain;mobile robots;autonomy;orbital robotics;intelligent control;prototypes mobile robots mars instruments soil propulsion laboratories path planning robot sensing systems orbital robotics;planetary terrains;navigation;planetary terrains rocky7 prototype microrover autonomous path planner;mars rover;tangentbug algorithm;robots;tangentbug algorithm autonomous path planning rocky 7 microrover mobile robot planetary terrains mars rover jet propulsion laboratory terrain traversability;planning;propulsion;autonomous navigation;terrain traversability;rocky 7 microrover;soil;space research;jet propulsion laboratory	Much prior work in mobile robot path planning har been based on assumptions that are not really applicable for exploration of planetary terrains. Based on the first author’s experience with the recent Mars Pathfinder mission, this paper reviews the issues that are critical for successful autonomous navigation of planetary rovers. No currently proposed methodology accurately addresses ali of these issues. We next report on an extension of the recently proposed “Tangent Bug” algorithm. The implementation of this extended algorithm on the Rocky 7 Mars Rover prototype at the Jet Propulsion Laboratory is described, and experimental results are presented. In addition, experience with the limitations encountered by the Sojourner rover in actual Marh’an terrain suggest that terrain traversability must be more accurately handled in autonomous planning algorithms for interplanetary rovers.	algorithm;autonomous robot;mobile robot;motion planning;planetary scanner;prototype;rover (the prisoner)	Sharon L. Laubach;Joel W. Burdick;Larry H. Matthies	1998		10.1109/ROBOT.1998.676401	mobile robot;computer vision;simulation;computer science;artificial intelligence;remote sensing;intelligent control	Robotics	54.92222230464723	-30.556014377868106	178246
5eaf00db2892248e6791d8ff150bf5d14dc181bf	chilean underground mine dataset	field and service robotics;mapping;mining robotics;slam;robotics in hazardous fields;sensing and perception;computer vision;sensor fusion	This article presents a robotic dataset collected from the largest underground copper mine in the world. The sensor measurements from a 3D scanning lidar, a 2D radar, and stereo cameras were recorded from an approximately two kilometer traverse of a production-active tunnel. The equipment used and the data collection process is discussed in detail, along with the format of the data. This dataset is suitable for research in robotic navigation, as well as simultaneous localization and mapping. The download instructions are available at the following website http://dataset.amtc.cl.	3d scanner;download;radar;robot;robotic mapping;simultaneous localization and mapping;stereo camera;stereo cameras;traverse	Keith Yu Kit Leung;Daniel Lühr;Hamidreza Houshiar;Felipe Inostroza;Dorit Borrmann;Martin David Adams;Andreas Nüchter;Javier Ruiz-del-Solar	2017	I. J. Robotics Res.	10.1177/0278364916679497	kilometer;traverse;control engineering;mathematics;stereo cameras;simultaneous localization and mapping;radar;computer vision;lidar;download;sensor fusion;artificial intelligence	Robotics	54.28668856786893	-35.09088515916958	178426
aa522a5a564df10ec696a50d321c833cd39f815b	visual tracking and control using lie algebras	lie algebra;robot sensing systems;video camera visual tracking and control lie algebras visual servoing affine transformations visual sensor robot arm end effector robot motion scene transformations target planar contour nonlinear control structure;nonlinear control structure;motion control;target planar contour;visual tracking and control;lie algebras;active contours;layout;robot arm;feedback;robot vision;algebra layout feedback robot sensing systems robot motion target tracking visual servoing end effectors active contours motion control;algebra;robot vision lie algebras feedback;affine transformation;end effector;robot motion;affine transformations;target tracking;visual tracking;visual servoing;video camera;scene transformations;visual sensor;end effectors	A novel approach to visual servoing is presented, which takes advantage of the structure of the Lie algebra of aane transformations. The aim of this project is to use feedback from a visual sensor to guide a robot arm to a target position. The sensor is placed in the end eeector of the robot, thècamera-in-hand' approach, and thus provides direct feedback of the robot motion relative to the target scene via observed transformations of the scene. These scene transformations are obtained by measuring the aane deformations of a target planar contour, captured by use of an active contour, or snake. Deformations of the snake are constrained using the Lie groups of aane and projective transformations. Properties of the Lie algebra of aane transformations are exploited to integrate observed deformations to the target contour which can be compensated with appropriate robot motion using a non-linear control structure. These techniques have been implemented using a video camera to control a 5 DoF robot arm. Experiments with this implementation are presented , together with a discussion of the results.	active contour model;contour line;control flow;control system;feedback;nonlinear system;robotic arm;visual servoing	Tom Drummond;Roberto Cipolla	1999		10.1109/CVPR.1999.784996	lie algebra;computer vision;robot end effector;computer science;control theory;affine transformation;mathematics	Robotics	60.682496318432705	-32.29606956405477	178502
f9171439ed9ffa1adb55e0271ab60049e0b388b4	optic-flow-based collision avoidance	robot sensing systems;aircraft control;collision avoidance optical sensors image motion analysis insects prototypes navigation terrorism surveillance aircraft unmanned aerial vehicles;image motion analysis;flight control system;surveillance;prototypes;sonar sensor;image sequences aircraft control collision avoidance control engineering computing;navigation;optical imaging;cruise flight;robots;infrared sensor;optical flow;control engineering computing;collision avoidance;optical sensors;optic flow based collision avoidance;biomedical optical imaging;infrared;insects;unmanned aerial vehicles;flight control;flight control system optic flow based collision avoidance aircraft sonar sensor infrared sensor cruise flight;aircraft;terrorism;image sequences	Flying in and around caves, tunnels, and buildings demands more than one sensing modality. This article presented an optic-flow- based approach inspired by flying insects for avoiding lateral collisions. However, there were a few real-world scenarios in which optic flow sensing failed. This occurred when obstacles on approach were directly in front of the aircraft. Here, a simple sonar or infrared sensor can be used to trigger a quick transition into the hovering mode to avoid the otherwise fatal collision. Toward this end, we have demonstrated a fixed-wing prototype capable of manually transitioning from conventional cruise flight into the hovering mode. The prototype was then equipped with an IMU and a flight control system to automate the hovering process. The next step in this research is to automate the transition from cruise to hover flight.	automation;autonomous robot;control system;lateral thinking;modality (human–computer interaction);optical fiber;optical flow;pitch (music);prototype;robotics;sonar (symantec);yaws	William E. Green;Paul Y. Oh	2008	IEEE Robotics & Automation Magazine	10.1109/MRA.2008.919023	robot;embedded system;navigation;simulation;infrared;computer science;engineering;artificial intelligence;aeronautics;optical imaging;optical flow;prototype;terrorism	Robotics	56.83388456805506	-32.069725790712006	178570
c0b006c33066a77f4cfc4e6eae4cb11e317fb6ec	correspondence mapping induced state and action metrics for robotic imitation	kinematic models;algorithms artificial intelligence biomimetics computer simulation cybernetics humans imitative behavior models biological movement robotics task performance and analysis;body mapping;imitation and social learning;intelligent robots;social learning;software agents intelligent robots learning artificial intelligence;robotic imitation;degree of freedom;p rogramming by demonstration;action metrics;kinematic models correspondence mapping induced state action metrics robotic imitation body mapping correspondence matrices associations degrees of freedom state matching simulated 3 d robotic examples agents;correspondence problem;mirrors robot programming humans computer science psychology robot kinematics morphology symmetric matrices education pediatrics;indexing terms;degrees of freedom;software agents;simulated 3 d robotic examples;agents;induced state;state matching;associations;state and action metrics correspondence problem imitation and social learning p rogramming by demonstration;correspondence mapping;correspondence matrices;imitation learning;learning artificial intelligence;article;robot programming;state and action metrics	This paper addresses the problem of body mapping in robotic imitation where the demonstrator and imitator may not share the same embodiment [degrees of freedom (DOFs), body morphology, constraints, affordances, and so on]. Body mappings are formalized using a unified (linear) approach via correspondence matrices, which allow one to capture partial, mirror symmetric, one-to-one, one-to-many, many-to-one, and many-to-many associations between various DOFs across dissimilar embodiments. We show how metrics for matching state and action aspects of behavior can be mathematically determined by such correspondence mappings, which may serve to guide a robotic imitator. The approach is illustrated and validated in a number of simulated 3-D robotic examples, using agents described by simple kinematic models and different types of correspondence mappings	addresses (publication format);galaxy morphological classification;matching;many-to-many;mental association;one-to-many (data model);one-to-one (data model);robot	Aris Alissandrakis;Chrystopher L. Nehaniv;Kerstin Dautenhahn	2007	IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)	10.1109/TSMCB.2006.886947	computer science;artificial intelligence;software agent;machine learning;degrees of freedom	Robotics	67.1734767341122	-25.605065563835264	178589
02ac7426b3b3cf560e9d7dd1c133c9992564c026	an almost communication-less approach to task allocation for multiple unmanned aerial vehicles	telerobotics aerospace robotics aircraft mobile robots remotely operated vehicles;synchronized clocks;clocks;unmanned aerial vehicle;mobile robots;unmanned aerial vehicles global positioning system robot kinematics trajectory usa councils synchronization clocks broadcasting communication system control robotics and automation;remotely operated vehicles;usa councils;communication less approach;synchronized clocks communication less approach task allocation multiple unmanned aerial vehicles decentralized task allocation algorithm gps receivers;multiple unmanned aerial vehicles;trajectory;global positioning system;synchronization;aerospace robotics;telerobotics;broadcasting;gps receivers;communication system control;unmanned aerial vehicles;robotics and automation;simulation environment;decentralized task allocation algorithm;aircraft;task allocation;robot kinematics	In this paper, we present a scalable, decentralized task allocation algorithm for a group of unknown number of unmanned aerial vehicles (UAVs), which are equipped with GPS receivers, synchronized clocks and radars with a finite, but known operating distance to identify neighbors. The algorithm assigns subgroups of UAVs, whose initial positions are randomly scattered in a bounded space, to a finite set of independent tasks. The key features of the proposed algorithm are: (1) the algorithm does not require any communication between the UAVs; (2) the task allocation is achieved in finite time. The analysis and results in the simplified 2D simulation environment respectively prove and verify the correctness of the proposed algorithm.	aerial photography;algorithm;correctness (computer science);global positioning system;maximal set;optimal control;radar;randomness;scalability;simulation;television antenna;unmanned aerial vehicle;velocity (software development)	Peng Cheng;Vijay Kumar	2008	2008 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2008.4543396	remotely operated underwater vehicle;telerobotics;control engineering;mobile robot;embedded system;synchronization;simulation;global positioning system;computer science;engineering;artificial intelligence;trajectory;broadcasting;robot kinematics	Robotics	55.94041613084441	-26.339504367409415	178949
f91a794b0a09f424f63e4c418a2dd0b4e004c324	a new method for kinematic parameter calibration via laser line tracking	data collection process;robot sensing systems;goodness of fit;position feedback;robots calibration kinematics laser beam applications photodetectors;laser line tracking;straight line constraint;intelligent robots;data collection;calibration robot kinematics robot sensing systems laser feedback service robots robotics and automation intelligent robots gears laser theory laser beams;service robots;laser beams;kinematics;laser theory;gears;industrial robots;robots;photodetectors;straight line constraint kinematic parameter calibration laser line tracking robot optical detector position feedback data collection process goodness of fit metric;kinematic parameter calibration;laser feedback;laser beam applications;robot;optical detector;calibration;robotics and automation;robot kinematics;goodness of fit metric	A robot kinematic calibration technique is presented. The process assumes the use of an optical detector mounted on the robot's end-effector, which is used in position feedback. By this method, calibration data can be acquired for detector positions along a straight laser beam, and the detector is precisely centered on the laser line at each sample point. By structuring the data collection process this way, post processing to deduce kinematic parameters is simplified. A goodness-of-fit metric is given which exploits the straight-line constraint of the data. This metric is well suited for use within a numerical search for best-fit kinematic parameters. Illustrations of the technique's virtues and limitations are presented. An experimental apparatus for evaluating the technique on industrial robots is described. The approach is shown to be simple, inexpensive, and feasible. >		Wyatt S. Newman;David W. Osborn	1993		10.1109/ROBOT.1993.292141	robot;control engineering;computer vision;simulation;computer science;engineering;artificial intelligence;robot calibration;data collection	Robotics	60.55752893299695	-35.923995116811355	179193
5b1a28cf2d1154c92cfc3cfb1f80ea2b37a43062	accurate target tracking control for a mobile robot: a robust adaptive approach for off-road motion	robust control adaptive control mobile robots motion control observers position control;target tracking control observation strategy null velocity grip condition trajectory condition nonautonomous vehicle tracking observer based approach tracking accuracy terrain geometry natural environment context control strategy off road motion robust adaptive approach mobile robot;observers mobile robots vehicles trajectory convergence	In this paper a control strategy for a mobile robot enabling to track a manually driven vehicle or a moving target is proposed in the context of natural environment. In such a context, the motion does not meet classical assumptions usually proposed for mobile robots, since the terrain geometry is not necessarily flat and wheels are subject to sliding. As a result, in order to preserve the accuracy of tracking, it appears necessary to account for such phenomena in the control law. Several observer-based approaches have already been developed in the framework of path following in off-road conditions, but suffer from several limitations. In particular, the velocity should not be null, which appears to be an important drawback in the proposed application: the tracking of a non-autonomous vehicle indeed imposes possible stops. In this paper, a new observation strategy is proposed allowing to avoid non-observable situations (null velocity). This permits to achieve an accurate vehicle tracking whatever its velocity, its trajectory and the grip conditions.	algorithm;autonomous robot;control theory;experiment;high-level programming language;lateral thinking;mobile robot;observable;online and offline;optimal control;point of view (computer hardware company);settling time;simulation;vehicle tracking system;velocity (software development);wheels	Roland Lenain;Benoit Thuilot;Audrey Guillet;Bernard Benet	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907239	control engineering;computer vision;tracking system;control theory;robot control	Robotics	60.73295362099307	-31.749007175432833	179215
ff7aa32725601c360a89901d5f6d792bc6fd47a3	practical application of an evolutionary algorithm for the design and construction of a six-inch submarine	optimization vehicles underwater vehicles shape cameras drag geometry;underwater vehicles autonomous underwater vehicles evolutionary computation;torpedo shaped μuuv six inch submarine microunmanned underwater vehicles miniature uuv optimization algorithm infeasibility driven evolutionary algorithm idea uuv design	Unmanned underwater vehicles (UUVs) are becoming an attractive option for maritime search and survey operations as they are cheap and efficient compared to conventional use of divers or manned submersibles. Consequently, there has been a growing interest in UUV research among scientific and engineering communities. Although UUVs have received significant research interest in recent years, limited attention has been paid towards design and development of mini/micro UUVs (usually less than 1 foot in length). Micro unmanned underwater vehicles (μUUVs) are particularly attractive for deployment in extraordinarily confined spaces such as inspection of intricate underwater structures, ship wrecks, oil pipe lines or extreme hazardous areas. This paper considers previous work done in the field of miniature UUVs and presents an optimization framework for preliminary design of that class of UUVs. A state-of-the-art optimization algorithm namely infeasibility driven evolutionary algorithm (IDEA) is used to carry out optimization of the μUUV designs. The framework is subsequently used to identify optimal design of a torpedo-shaped μUUV with an overall length of six inches (152.4 mm). The preliminary design identified through the process of optimization is further analyzed with the help of a computer-aided design tool to come up with a detailed design. The final design has since then been built and is currently undergoing trials.	catia;coefficient;computer-aided design;design tool;embedded system;evolutionary algorithm;internationalized domain name;iterative and incremental development;matlab;mathematical optimization;minimum bounding box;optimal design;remote control;requirement;software deployment;unmanned aerial vehicle;yaws;yet another;zettabyte;zyweb	Khairul Alam;Tapabrata Ray;Sreenatha G. Anavatti	2014	2014 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2014.6900264	simulation	EDA	55.55608538505432	-25.003232649094443	179336
8d4d3b181d8146b643fc0e6212c69ef74d0522ca	distributed data acquisition unit with microsecond-accurate wireless clock synchronisation	mobile robotic platforms distributed data acquisition unit microsecond accurate wireless clock synchronisation embedded data acquisition unit babelfuse generic sensor data acquisition generic sensor data timestamping general purpose i o events gpio data fusion microsecond accurate wirelessly distributed global clock simultaneous localisation and mapping slam robot swarm environment inaccurate clock synchronisation protocols nondeterministic communication hardware ieee 802 11 based wireless industry standards firmware indeterminism minimization;mobile robots;firmware;synchronization protocols clocks hardware cameras robot sensing systems universal serial bus;synchronisation;synchronisation data acquisition firmware mobile robots multi robot systems sensor fusion slam robots;multi robot systems;sensor fusion;slam robots;data acquisition	This paper describes the implementation of the first portable, embedded data acquisition unit (BabelFuse) that is able to acquire and timestamp generic sensor data and trigger General Purpose I/O (GPIO) events against a microsecond-accurate wirelessly-distributed `global' clock. A significant issue encountered when fusing data received from multiple sensors is the accuracy of the timestamp associated with each piece of data. This is particularly important in applications such as Simultaneous Localisation and Mapping (SLAM) where vehicle velocity forms an important part of the mapping algorithms; on fast-moving vehicles, even millisecond inconsistencies in data timestamping can produce errors which need to be compensated for. The timestamping problem is compounded in a robot swarm environment especially if non-deterministic communication hardware (such as IEEE-802.11-based wireless) and inaccurate clock synchronisation protocols are used. The issue of differing timebases makes correlation of data difficult and prevents the units from reliably performing synchronised operations or manoeuvres. By utilising hardware-assisted timestamping, clock synchronisation protocols based on industry standards and firmware designed to minimise indeterminism, an embedded data acquisition unit capable of microsecond-level clock synchronisation is presented.	algorithm;can bus;clock drift;clock synchronization;crystal oscillator;data acquisition;download;embedded system;firmware;general-purpose input/output;rs-232;rs-485;sensor;simultaneous localization and mapping;swarm robotics;velocity (software development)	Philip Cadell;Ben Upcroft	2013	2013 IEEE Eighth International Conference on Intelligent Sensors, Sensor Networks and Information Processing	10.1109/ISSNIP.2013.6529775	embedded system;real-time computing;computer hardware;computer science	Robotics	55.341594052031226	-35.27958297177844	179428
a3931c57b3fd67ab6df5f73e7806cc29f01425c5	neural networks for autonomous path-following with an omnidirectional image sensor	vision omnidirectionnelle;navegacion;robot movil;omnidirectional vision;settore inf 01 informatica;detecteur image;information visuelle;robot navigation;visoin robot;omnidirectional image;autonomous mobile robot;image sensors;dynamic environment;navigation;informacion visual;robot mobile;visual information;reseau neuronal;visual system;red neuronal;path following;moving robot;software process;neural network	This paper presents a path-following system implemented with two different types of neural networks, that enables an autonomous mobile robot to return along a previously learned path in a dynamic environment. The path-following is based on data provided by an omnidirectional conical visual system, derived from the COPIS sensor, but with different optical reflective properties. The system uses optical and software processing and a neural network to learn the path, described as a sequence of selected points. In the navigation phase it drives the robot along this learned path. Interesting results have been achieved using low cost equipment. Test and results are presented.	artificial neural network;autonomous robot;data pre-processing;image sensor;mobile robot	Alessandro Rizzi;Riccardo Cassinis;N. Serana	2002	Neural Computing & Applications	10.1007/s005210200015	embedded system;computer vision;navigation;simulation;visual system;computer science;machine learning;image sensor;software development process;artificial neural network	Robotics	57.77007437989287	-32.78916543953124	179487
780b8a0cf76c73b387e58e920690ba1a54a5b623	high accuracy mobile robot positioning using an external large volume metrology instrument			global positioning system;mobile robot	Zheng Wang;Min Liang;Paul G. Maropoulos	2009		10.1007/978-3-642-10430-5_48	laser tracker;embedded system;robot;mobile robot;computer vision;artificial intelligence;metrology;computer science	Robotics	55.627294896529676	-36.24461731819634	179493
e5833b7b837c0ebd7e370bcb218b01dbdce6969d	robust uav relative navigation with dgps, ins, and peer-to-peer radio ranging	phase measurement;noise measurement;satellite broadcasting;vectors;global positioning system;satellites;ultra wideband communication autonomous aerial vehicles filtering theory global positioning system inertial navigation measurement errors monte carlo methods peer to peer computing radio direction finding sensor fusion;carrier ambiguity integer resolving algorithm carrier phase differential gps peer to peer ranging radios low cost inertial navigation systems small unmanned aerial vehicles sensor fusion algorithm gps ins based absolute navigation solutions relative navigation filter baseline separation integer fixed relative cp dgps dynamic baseline estimation performance monte carlo simulation trials uav formation flight control simulator gps constellation simulator stochastic models inertial measurement unit sensor errors imu sensor errors measurement noise 3d relative positioning 3d residual sum of squares accuracy 3d rss accuracy differential carrier phase ambiguities phase ambiguity ultra wideband ranging radios;relative navigation cooperative remote sensing cooperative uavs differential gps ins multi sensor fusion;global positioning system vectors satellites satellite broadcasting noise measurement phase measurement	This paper considers the fusion of carrier-phase differential GPS (CP-DGPS), peer-to-peer ranging radios, and low-cost inertial navigation systems (INS) for the application of relative navigation of small unmanned aerial vehicles (UAVs) in close formation-flight. A novel sensor fusion algorithm is presented that incorporates locally processed tightly coupled GPS/INS-based absolute navigation solutions from each UAV in a relative navigation filter that estimates the baseline separation using integer-fixed relative CP-DGPS and a set of peer-to-peer ranging radios. The robustness of the dynamic baseline estimation performance under conditions that are typically challenging for CP-DGPS alone, such as a high occurrence of phase breaks, poor satellite visibility/geometry due to extreme UAV attitude, and heightened multipath intensity, amongst others, is evaluated using Monte Carlo simulation trials. The simulation environment developed for this work combines a UAV formation flight control simulator with a GPS constellation simulator, stochastic models of the inertial measurement unit (IMU) sensor errors, and measurement noise of the ranging radios. The sensor fusion is shown to offer improved robustness for 3-D relative positioning in terms of 3-D residual sum of squares (RSS) accuracy and increased percentage of correctly fixed phase ambiguities. Moreover, baseline estimation performance is significantly improved during periods in which differential carrier phase ambiguities are unsuccessfully fixed. Note to Practitioners-This paper was motivated by the need to enhance the robustness of CP-DGPS/INS relative navigation. In particular, small UAVs exhibit fast dynamics and are often subjected to large and quickly changing bank angles. This in turn induces missed satellite observations and changes in the phase ambiguity. This paper suggests leveraging the emergence of Ultra Wideband ranging radios to directly observe the baseline separation. In this paper, we outline the details of the algorithm implementation. We then use a simulation to show that adding UWB greatly helps to enhance the robustness of the carrier ambiguity integer-resolving algorithm, which is necessary for improved solution accuracy. This work has extensions to ground vehicles, ocean buoys, and space vehicles. In future work, we will experimentally validate results.	aerial photography;algorithm;baseline (configuration management);differential gps;emergence;experiment;global positioning system;inertial navigation system;monte carlo method;observable;peer-to-peer;rss;residual sum of squares;simulation;stochastic process;ultra-wideband;unmanned aerial vehicle	Jason N. Gross;Yu Gu;Matthew B. Rhudy	2015	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2014.2383357	gps/ins;satellite navigation;simulation;global positioning system;telecommunications;noise measurement;satellite	Robotics	55.20697929084141	-36.24273249631305	179755
b4e6a0429dd229167317279361e683fac647d521	a novel low-cost, limited-resource approach to autonomous multi-robot exploration and mapping	mobile robot;multi robot system;mobile robots;planetary exploration;multi robot team;design and implementation;space robotics;simultaneous localization and mapping;solar system;low cost slam;distributed robots;robot team;distributed robotics	Mobile robots are becoming more heavily used in environments where human involvement is limited, impossible, or dangerous. These robots perform some of the more laborious human tasks on Earth and throughout the solar system, simultaneously saving resources and offering automation. Higher levels of autonomy are also being sought in these applications, such as distributed exploration and mapping of unknown areas. Smaller, less expensive mobile robots are becoming more prevalent, which introduces unique challenges in terms of limited sensing accuracy and onboard computing resources. This paper presents a novel low-cost, limited-resource approach to autonomous multi-robot mapping and exploration in unstructured environments. Design and implementation details are presented, along with results from two planetary style environments. Results demonstrate that low-cost ($ 1250) mobile robots capable of simultaneous localization and mapping can be successfully constructed. The multirobot system presented in this paper participated in the 2008 International Conference on Robotics and Automation (ICRA) Space Robotics Challenge, receiving two awards for successfully completing the ’Onto the Surface’ and ’Map the Environment’ events in a simulated planetary environment. This work demonstrates not only that such systems are possible, but also that this direction of research is important and needs attention. Published by Elsevier B.V.	algorithm;automation;autonomous robot;autonomy;central processing unit;complex system;computer science;distributed computing;emergence;experiment;icra;interference (communication);internationalization and localization;jaus;map;mobile robot;paging;planetary scanner;real-time clock;robotic spacecraft;robotics;scalability;sensor;simulation;simultaneous localization and mapping;software deployment;software development kit;sparse matrix;sun spot;swarm intelligence;thrust	Christopher M. Gifford;Russell Webb;James Bley;Daniel Leung;Mark Calnon;Joseph Makarewicz;Bryan Banz;Arvin Agah	2010	Robotics and Autonomous Systems	10.1016/j.robot.2009.09.014	mobile robot;computer vision;simulation;ant robotics;computer science;artificial intelligence;occupancy grid mapping;future of robotics	Robotics	55.330926916625	-28.77453313770983	179887
ae0f617fd8cb2da6f964004a79ab5fb6203a9727	development of quadruped walking robot titan-viii	energy efficiency;legged locomotion leg wire shafts pulleys foot payloads batteries standards development energy efficiency;velocity control;shafts;motion control;legged locomotion;energy efficient;foot;walking posture;leg mechanism;drives;walking velocity quadruped walking robot titan viii leg mechanism one leg model wire driving system energy consumption energy efficiency walking posture;wire;standards development;one leg model;energy consumption;walking robot;pulleys;batteries;wire driving system;payloads;walking velocity;drives legged locomotion motion control velocity control force control;high performance;quadruped walking robot;leg;titan viii;force control	In this paper, we discuss about the development of quadruped walking robot TITAN-VIII , especially about its leg mechanism and results of experiments using one-leg model. In the design of TITAN-VIII , we have been considering not only about “high performance of the movement” but also about “low price”, “Simplicity of the treatment”, “simplicity of the functional extension” etc so that many researchers can get walking robots easily. For example, we introduce driving system using wires which is helpful to achieve these objectives. We made one-leg model of TITAN-VIII at first. By using this one-leg model, we did experiments and made remarks about feature of response,velocity,force and energy consumption. From these results, we estimate that the limitation of walking velocity of TITAN-VIII in standard walking posture is O.S[m/s](crawl gait of /3 = 0.75) ,0.9[m/s](trot gait of /3 = O S ) , the payload is 5 N 7 [ k g ] and it with 2.5[Ah] battery can walk 2000 steps. And we discuss about standard walking posture of TITAN-VIII based on energy efficiency.	experiment;mobile robot;poor posture;titan rain;velocity (software development)	Keisuke Arikawa;Shigeo Hirose	1996		10.1109/IROS.1996.570670	control engineering;simulation;engineering;control theory;efficient energy use	Robotics	67.25981155892376	-24.31978546752516	180166
6d241c138a7b2a2980146def2929d8890b2b6061	comparison of small unmanned aerial vehicles performance using image processing	digital image processing;unmanned aerial vehicle uav;machine vision;agriculture;precision agriculture	Precision agriculture is a farm management technology that involves sensing and then responding to the observed variability in the field. Remote sensing is one of the tools of precision agriculture. The emergence of small unmanned aerial vehicles (sUAV) have paved the way to accessible remote sensing tools for farmers. This paper describes the development of an image processing approach to compare two popular off-the-shelf sUAVs: 3DR Iris+ and DJI Phantom 2. Both units are equipped with a camera gimbal attached with a GoPro camera. The comparison of the two sUAV involves a hovering test and a rectilinear motion test. In the hovering test, the sUAV was allowed to hover over a known object and images were taken every quarter of a second for two minutes. For the image processing evaluation, the position of the object in the images was measured and this was used to assess the stability of the sUAV while hovering. In the rectilinear test, the sUAV was allowed to follow a straight path and images of a lined track were acquired. The lines on the images were then measured on how accurate the sUAV followed the path. The hovering test results show that the 3DR Iris+ had a maximum position deviation of 0.64 m (0.126 m root mean square RMS displacement) while the DJI Phantom 2 had a maximum deviation of 0.79 m (0.150 m RMS displacement). In the rectilinear motion test, the maximum displacement for the 3DR Iris+ and the DJI phantom 2 were 0.85 m (0.134 m RMS displacement) and 0.73 m (0.372 m RMS displacement). These results demonstrated that the two sUAVs performed well in both the hovering test and the rectilinear motion test and thus demonstrated that both sUAVs can be used for civilian applications such as agricultural monitoring. The results also showed that the developed image processing approach can be used to evaluate performance of a sUAV and has the potential to be used as another feedback control parameter for autonomous navigation.	aerial photography;algorithm;autonomous robot;displacement mapping;emergence;feedback;image processing;imaging phantom;mean squared error;phantom reference;regular grid;shepp–logan phantom;spatial variability;unmanned aerial vehicle	Esteban Cano;Ryan Horton;Chase Liljegren;Duke M. Bulanon	2017	J. Imaging	10.3390/jimaging3010004	computer vision;simulation;engineering;remote sensing	Robotics	55.76274784511052	-36.34880900801889	180368
9386f701ab68f2e9162aea7d5695e397415d255a	simple muscle models regularize motion in a robotic leg with neurally-based step generation	animals;control systems;robot design;motion control;legged locomotion;robotic control system;nonlinear control systems;degree of freedom;biological system modeling;motor system;robust control;robot dynamics legged locomotion motion control neurocontrollers nonlinear control systems;biological control systems;physical characteristic;robotic leg;piecewise constant model;step generator;robot control;muscle model;linear model;neural motor system;biological systems;step generator muscle model motion regularization robotic leg neural based step generation robotic control system neural pathway neural motor system piecewise constant model linear model;neural based step generation;neurocontrollers;motion regularization;robot dynamics;leg;neural pathway;dynamic properties;muscles;muscles legged locomotion leg biological system modeling animals biological systems biological control systems robot control control systems robust control	Robotic control systems inspired by animals are enticing to the robot designer due to their promises of simplicity, elegance and robustness. While there has been success in applying general and behaviorally-based knowledge of biological systems to control, we are investigating the use of control based on known and hypothesized neural pathways in specific model animals. Neural motor systems in animals are only meaningful in the context of their mechanical body, and the behavior of the system can be highly dependent on nonlinear and dynamic properties of the mechanical part of the system. It is therefore reasonable to believe that to reproduce behavior, the physical characteristics of the biological system must also be modeled or accounted for. In this paper we examine the performance of a robotic system with three types of muscle model: null, piecewise-constant, and linear. Results show that adding very simple models of muscle properties at a single joint cause marked improvement in the performance of a neurally-based step generator for a 3-degree-of-freedom robotic leg.	biological system;control system;nonlinear system;robot leg;robotic arm	Brandon L. Rutter;William A. Lewinger;Marcus Blümel;Ansgar Büschges;Roger D. Quinn	2007	Proceedings 2007 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2007.363057	robust control;control engineering;motion control;simulation;computer science;engineering;control system;linear model;motor system;control theory;robot control;degrees of freedom	Robotics	67.49708381000467	-25.527962727177975	180610
fd995feea76c456adf601353df7da62f195515fc	development of robotic transportation system - shopping support system collaborating with environmental cameras and mobile robots -	acoustics;service robots;cameras robot vision systems acoustics service robots;robot vision systems;cameras	A robotic transportation system for shopping assistance has been developed. The system consists of a guidance robot, a cart robot, and environmental cameras. The guidance robot is an autonomous mobile robot with a position localization function, the cart robot with a shopping basket can follow the guidance robot, and environmental cameras can detect the robot and humans. A verification test has been performed in the test environment assumed for a food store. The guidance robot was able to guide the person to his/her desired place and to follow the person, and the cart robot was able to carry the articles while a shopping demonstration. Furthermore, safety technologies in the environment where robots and humans co-exist have been developed.		Nobuto Matsuhira;Fumio Ozaki;Seiji Tokura;Takafumi Sonoura;Tsuyoshi Tasaki;Hideki Ogawa;Masahito Sano;Akiko Numata;Naohisa Hashimoto;Kiyoshi Komoriya	2010			mobile robot;embedded system;computer vision;simulation;engineering;robot control	Robotics	58.128674510183934	-29.4094701680488	180815
96ffe3c2724a59d334242b015208cce47f7badf8	experimental ekf-based slam for mini-rovers with ir sensors only	ir sensors;sparse sensing.;index terms— slam	The performances of an EKF-based SLAM approach are experimentally discussed in the case of a mini-robot equipped with low-cost IR sensors only, showing that despite of the sparseness and noisiness of the sensors, SLAM experiments using classical SLAM methods can be performed even on a Khepera robot in a real arena, whose dimensions may be significantly larger than the robot size. The main characteristics of the SLAM approach and of the used sensors are described in the paper, which illustrates and discusses the performed tests and their results.	correspondence problem;experiment;extended kalman filter;khepera mobile robot;neural coding;performance;sensor;simultaneous localization and mapping	Fabrizio Abrate;Basilio Bona;Marina Indri	2007			computer vision;sliding window protocol;simulation;artificial intelligence;extended kalman filter;computer science	Robotics	55.12268400919172	-37.29926313295915	180865
00c7372bef0971067643bbc7d38dd4dcbcdea139	smart roadster project: setting up drive-by-wire or how to remote-control your car	esp;. drive-by-wire;autonomous vehicle;abs;driver assistance;vehicle control;electric power steering;remote control	Since research in intelligent autonomous road vehicles gets more and more popular, many interested researchers are confronted with the needs to setup a commercially available vehicle with drive-by-wire. Up-to-date road vehicles contain many mechatronical components, sensors and driver assistance systems, which can be interfaced and thus reduce the needs of expensive modifications and additional actors to a minimum. This paper describes how to interface steering, throttle and brake as well as built-in sensors, and shows an inexpensive way to provide a safe research platform for road traffic.	as-interface;autonomous car;autonomous robot;block cipher mode of operation;lateral thinking;remote control;sensor	Joachim Schröder;Udo Müller;Rüdiger Dillmann	2006			embedded system;remote control vehicle;drive by wire;remote control;computer science	Robotics	61.54127386658489	-29.106494576728892	180957
1c9d949bc30bc00d50f9bd78d2eca7f6fcba137c	development of a transformable mobile robot with a variable wheel diameter	search and rescue;mobile robot;variable wheel diameter		mobile robot	Keiji Nagatani;Mitsuhiro Kuze;Kazuya Yoshida	2007	JRM	10.20965/jrm.2007.p0252	embedded system;simulation;automotive engineering	Robotics	65.89046408124933	-27.55590592148576	181504
ea60e5ac75a07b0d728260f4c50f5386e35a0e7d	learning coupling terms for obstacle avoidance	couplings collision avoidance trajectory robots three dimensional displays mathematical model vectors;trajectory;vectors;three dimensional displays;robots;planning methods coupling term learning obstacle avoidance autonomous manipulation dynamic environments robots manipulator planning system dynamic movement primitives reactive control strategies;mathematical model;collision avoidance;couplings;planning artificial intelligence collision avoidance manipulators	Autonomous manipulation in dynamic environments is important for robots to perform everyday tasks. For this, a manipulator should be capable of interpreting the environment and planning an appropriate movement. At least, two possible approaches exist for this in literature. Usually, a planning system is used to generate a complex movement plan that satisfies all constraints. Alternatively, a simple plan could be chosen and modified with sensory feedback to accommodate additional constraints by equipping the controller with features that remain dormant most of the time, except when specific situations arise. Dynamic Movement Primitives (DMPs) form a robust and versatile starting point for such a controller that can be modified online using a non-linear term, called the coupling term. This can prove to be a fast and reactive way of obstacle avoidance in a human-like fashion. We propose a method to learn this coupling term from human demonstrations starting with simple features and making it more robust to avoid a larger range of obstacles. We test the ability of our coupling term to model different kinds of obstacle avoidance behaviours in humans and use this learnt coupling term to avoid obstacles in a reactive manner. This line of research aims at pushing the boundary of reactive control strategies to more complex scenarios, such that complex and usually computationally more expensive planning methods can be avoided as much as possible.	automated planning and scheduling;autonomous robot;constraint (mathematics);extrapolation;feedback;hidden variable theory;motion planning;nonlinear system;obstacle avoidance;reinforcement learning;simple features;term (logic);velocity (software development)	Akshara Rai;Franziska Meier;Auke Jan Ijspeert;Stefan Schaal	2014	2014 IEEE-RAS International Conference on Humanoid Robots	10.1109/HUMANOIDS.2014.7041410	robot;computer vision;simulation;computer science;artificial intelligence;trajectory;mathematical model;obstacle avoidance;coupling	Robotics	62.26854634532362	-24.40273047273164	181683
0a55df635bc082308e99709b62d79eba0822d570	a behaviour-based optimisation strategy for multi-robot exploration	- multi-robot;social potential-fields;optimisation;exploration;mobile robots;search space;path planning;nonlinear programming	To efficiently explore an unknown environment with a team of robots, a coordinated strategy that maximises the exploration area is required. This is a difficult optimisation problem, as there may exist many suboptimal solutions. In order to reduce the search space to a region that is near the optimal, a behaviour-based exploration strategy is used to define the region in which an optimal solution can be found. A numerical optimisation technique is then used to find the solution in this region. In particular, the proposed strategy uses a potential-fields technique to obtain a coarse movement direction for each robot. A nonlinear optimisation method is then used to calculate the velocity and angle deviation from the coarse direction to achieve the maximum exploration for each move. Simulation results have shown that the proposed method provides an efficient exploration strategy.	mathematical optimization;nonlinear system;robot;simulation;velocity (software development)	Gu Fang;Gamini Dissanayake;Haye Lau	2004	IEEE Conference on Robotics, Automation and Mechatronics, 2004.		control engineering;mobile robot;mathematical optimization;simulation;nonlinear programming;computer science;engineering;artificial intelligence;motion planning	Robotics	54.83231581494991	-25.028024287446073	181693
95a00a6353811fe9602973b38eaf69fd9609f818	simulation of the video feedback for mobile robots in simbad environment		Rapid progress in the field of machine vision applications can be especially clearly visible in robotics. For this reason many groups of image processing and analysis algorithms and solutions which have not been previously applied in automation and robotics require testing, verification and modifications before their application in any hardware solution. Such prototyping of video applications for robotics is possible using a simulation environment without the necessity of building the physical robot which can be damaged or even lost during some preliminary experiments. In order to verify and demonstrate the usefulness of such approach some experiments related to video feedback for mobile robotics have been conducted using free Java based 3D mobile robot simulator known as Simbad. Presented results confirm the great potential of such simulation environments in rapidly developing area of machine vision applications in robotics.	simbad;simulation	Piotr Lech;Krzysztof Okarma;Konrad Derda;Jaroslaw Fastowicz	2015		10.1007/978-3-319-18503-3_22	computer vision;simulation;multimedia	Robotics	59.62811921996375	-34.38980728957295	181816
f8dfe873d26d3a81db10374593b4df1d59a8f33d	altitude determination of a pedestrian in a multistorey building	pedestrian navigation;standard deviation;pedestrian navigation system;pressure sensor	A challenging task in using pedestrian navigation and guidance services indoors is to determine the correct floor of a user in a multi-storey building because most indoor location techniques only provide 2-D information. In this case it can be recommended to augment the position determination system with a barometric pressure sensor for direct observation of height differences. In the research project NAVIO (Pedestrian Navigation Systems in Combined Indoor/Outdoor Environments) tests with different sensors have been performed and their results are presented. The tests show that it is possible to determine the correct floor of a user using a barometric pressure sensor as the standard deviation of the estimation of the height differences is better than ± 1 m.	sensor	Günther Retscher	2007		10.1007/978-3-540-36728-4_9	simulation;architectural engineering;geography;transport engineering	HCI	54.70846519561239	-35.276517381720836	181873
ac487380f7acd7cfdd9046f4cb1c7e6a28f20f6e	towards a systematic assessment of the functions of unmanned autonomous systems	databases;unmanned aerial vehicle;slam;unmanned ground vehicle;perception algorithms;autonomic system;evaluation metric;simultaneous localization and mapping;unmanned systems;evaluation metrics;evaluation protocols;standardization	Being able to assess the performance of the algorithmic components of unmanned autonomous systems is a necessity. Defining repeatable and commonly shared test protocols to assess the performance of the algorithms involved in autonomy is the key to achieve standardization in the unmanned autonomous systems field (Unmanned Ground Vehicles (UGVs) and Unmanned Aerial Vehicles (UAVs)).  This paper proposes a generic methodology to evaluate any function of an autonomous system and illustrates the methodology on two examples: for the evaluation of visual beacon tracking algorithm and for the evaluation of Simultaneous Localization And Mapping (SLAM) algorithms. The lessons learnt from these evaluations are then described.	aerial photography;algorithm;autonomous system (internet);simultaneous localization and mapping;unmanned aerial vehicle	Robin Jaulmes;Éric Moliné;Laurent Vielle	2009		10.1145/1865909.1865922	control engineering;computer vision;simulation;engineering	Robotics	54.04170033881388	-35.25493022373837	181877
45624f783e86779814a6c722bbd112dadc361b81	re-configurable dual-robot assembly system design, development and future directions	vision system;design and development;degree of freedom;hall effect;assembly;robot arm;programmable logic controllers;system design;robots;off the shelf;programmable logic controller	This paper describes the design and development of a re-configurable dual-robot assembly system using off-the-shelf re-configurable pneumatic modules, Hall-effect sensors, a vision system, and a programmable logic controller (PLC). Each robot arm consists of three sets of pneumatic modules and a pneumatic gripper. Each module consists of a pneumatic housing, an air cylinder, and a Hall-effect sensor, and provides one degree of freedom. Solenoids are used to redirect airflow and thereby extend and/or retract the air cylinder. A vision system is used for fixture inspection. A conveyor and part stopper are designed to transfer and stop pallets. All these modules, the gripper, the part stopper, and the vision system are controlled and synchronized using a PLC. At the end of this paper, a framework for making the system over the Web for remote operation and diagnosis is proposed and described.	as-interface;automation;computer;controlnet;cylinder seal;devicenet;hall effect sensor;high- and low-level;input/output;programmable logic device;redirection (computing);robot end effector;robotic arm;systems design;test fixture;world wide web	Sheng-Jen Hsieh	2003	Industrial Robot	10.1108/01439910310473960	control engineering;machine vision;computer science;engineering;artificial intelligence;programmable logic controller;control theory;engineering drawing	Robotics	63.93916921849766	-29.561482850355475	181982
232dd11e4093b43b2854a3f1d2aebfbf1ac3b037	design of a positioning system for agv navigation	navigation wheels control systems land vehicles vehicle dynamics tires uncertainty automatic control sensor systems laboratories;kalman filters;control system;position control;design and implementation;global positioning system;positioning system;containers automatic guided vehicles kalman filters global positioning system sensor fusion position control;automatic guided vehicles;real world environment automated ground vehicle positioning system agv navigation kalman filter sensor data fusion control system;sensor fusion;extended kalman filter;containers	The development and implementation of an Automated Ground Vehicle (AGV) positioning and control system in a real world environment presents a challenge. The positioning system for this outdoor, container-carrying AGV, uses an extended Kalman Filter to estimate its position, heading and velocity by fusing together sensor data from several sources. This paper presents the design and implementation considerations for the positioning system in this platform.	control system;course (navigation);extended kalman filter;positioning system;velocity (software development)	Tow Yong Teo;Joo Siong Chai;Wan Li Yao	2002		10.1109/ICARCV.2002.1238498	kalman filter;control engineering;embedded system;simulation;global positioning system;computer science;engineering;control system;machine learning;precise point positioning;control theory;sensor fusion;extended kalman filter;hybrid positioning system	Robotics	56.045523226354014	-32.276116809928226	182022
54b42efa5039c124165a2da58627b49e588ca6e5	fusion of art-1 and advanced logistic belief neural network for object grasping robot arm	belief networks;motion control;learning rule advanced logistic belief neural network object grasping robot arm adaptive resonance theory art 1 robot manipulator end effectors stability movement logarithm likehood function;stability;learning systems;grippers;robot arm art grasping logidtic belief neural nework;control engineering computing;neurocontrollers;art neural nets;stability art neural nets belief networks control engineering computing end effectors grippers learning systems motion control neurocontrollers;end effectors	This paper discusses the combination of adaptive resonance theory (ART-1) and advanced logistic belief neural network for controlling robot arms grasping objects. In order for the robot manipulator, end-effectors keep its stability at any given movement; the derivation and maximization of the logarithm-like hood function of the learning rule of the logistic belief network is used.	adaptive resonance theory;artificial neural network;bayesian network;coat of arms;expectation–maximization algorithm;hood method;learning rule;robotic arm	Mbaitiga Zacharie	2012	2012 5th International Conference on BioMedical Engineering and Informatics	10.1109/BMEI.2012.6512990	motion control;computer vision;robot end effector;stability;artificial intelligence;machine learning;statistics	Robotics	62.7906708154454	-25.882438609622344	182073
1627392ea6d2c4c8670f3b16005120bb6fb8b579	timed trajectory generation combined with an extended kalman filter for a vision-based autonomous mobile robot		Planning collision-free trajectories requires the combination of generation and modulation techniques. This is especially important if temporal stabilization of the generated trajectories is considered. Temporal stabilization means to conform to the planned movement time, in spite of environmental conditions or perturbations. This timing problem has not been addressed in most current robotic systems, and it is critical in several robotic tasks such as sequentially structured actions or humanrobot interaction. This work focuses on generating trajectories for a mobile robot, whose goal is to reach a target within a constant time, independently of the world complexity. Trajectories are generated by nonlinear dynamical systems. Herein, we extend our previous work by including an Extended Kalman Filter (EKF) to estimate the target location relative to the robot. A simulated hospital environment and a Pioneer 3-AT robot are used to demonstrate the robustness and reliability of the proposed approach in cluttered, dynamic and uncontrolled scenarios. Multiple experiments confirm that the inclusion of the EKF preserves the timing properties of the overall architecture.	autonomous robot;ball project;dynamical system;experiment;extended euclidean algorithm;extended kalman filter;international symposium on fundamentals of computation theory;mobile robot;modulation;nonlinear system;oe-cake!;time complexity;uncontrolled format string	Jorge Bruno Silva;Cristina P. Santos;João S. Sequeira	2012		10.1007/978-3-642-33926-4_6	control engineering;computer vision;control theory	Robotics	57.94099163500467	-25.65101199267962	182373
703ac4e5d5c607365a865baf870d808b101c4e4a	autonomous reactive control for simulated humanoids	motion control;support vector machines;legged locomotion;reactive control;automatic control object oriented modeling support vector machines protection legged locomotion computer science motion control humanoid robots machine learning humans;autonomous reactive control motor controllers autonomous composite reactive behaviors bipedal robots autonomous humanoids physically simulated humanoids svm support vector machine learning theory;support vector machine;motion control legged locomotion support vector machines;learning theory;physical simulation	We present a framework for composing motor controllers into autonomous composite reactive behaviors for bipedal robots and autonomous, physically-simulated humanoids. A key contribution of our composition framework is an explicit model of the “preconditions” under which motor controllers are expected to function properly. Pre-conditions may be determined manually or learned automatically by algorithms based on Support Vector Machine (SVM) learning theory. We demonstrate controller composition and evaluate our composition framework using a family of controllers capable of synthesizing basic actions such as balance, protective stepping when balance is disturbed, protective arm reactions when falling, and multiple ways of regaining an upright stance after a fall.	algorithm;autonomous robot;complexity;precondition;stepping level;support vector machine	Petros Faloutsos;Michiel van de Panne;Demetri Terzopoulos	2003		10.1109/ROBOT.2003.1241710	control engineering;support vector machine;simulation;computer science;engineering;control theory	Robotics	64.73765749871778	-24.842399854078955	182544
5e59b2e5f29920f74bbe6a558b3fa81652be99b2	direction-dependent optimal path planning for autonomous vehicles	rover path planning;optimal path planning;ordered upwind method;tip over stability axes	The optimal path planning problem is considered for rovers. Tip-over risk is accurately modelled using direction dependence. In the previous direction-independent model, the value function was approximated using the Fast Marching Method (FMM). The risk was not accurately modelled. Solar energy is considered here for the first time. Minimizing path length, obstacle avoidance and soil risk are also considered. For a direction-dependent model, the value function in the optimal path planning problem can be approximated accurately using the Ordered Upwind Method (OUM) but not FMM. The value function is used to synthesize the optimal control, which is shown to have no local minima. A novel algorithmic improvement, OUM-BD over the OUM to include a bi-directional search is presented. The OUM-BD is slightly slower than the FMM, but can accurately solve a larger class of problems. The OUM-BD is faster than the existing OUM, an optimal bi-directional RRT path planner (Bi-RRT*), and a genetic algorithm (GA) path planner in terms of time, and outperforms both the GA and Bi-RRT* planner in cost in tested examples. Optimal rover path planning is extended to consider direction in tip-over risk.Solar energy in net consumed energy is also considered in the optimal problem.The Ordered Upwind Method (OUM) is used to solve the rover path planning problem.A novel bi-directional (OUM) is introduced and is faster than the original algorithm.The bi-directional OUM is shown to outperform genetic algorithm and Bi-RRT*	autonomous robot;motion planning	Alex Shum;Kirsten A. Morris;Amir Khajepour	2015	Robotics and Autonomous Systems	10.1016/j.robot.2015.02.003	mathematical optimization;simulation	Robotics	53.84926465797866	-25.413398428049078	182600
140877b40e9ca2cc97e0270d78bf5c786128345d	a four degree-of-freedom robot head for active vision	vision ordenador;architecture systeme;concepcion sistema;vision estereoscopica;degree of freedom;vision stereoscopique;controller;robot head;robotics;computer vision;supervisor;system design;controleur;robotica;stereo;arquitectura sistema;vision ordinateur;robotique;system architecture;stereopsis;conception systeme;active vision	The design of a robot head for active computer vision tasks is described. The stereo head/eye platform uses a common elevation configuration and has four degree-of-freedom. The joints are driven by DC servo motors coupled with incremental optical encoders and backlash minimizing gearboxes. The details of mechanical design, head controller design, the architecture of the system, and the design criteria for various specifications are presented.	active vision;robot	Fenglei Du;Michael Brady	1994	IJPRAI	10.1142/S021800149400070X	computer vision;simulation;controller;active vision;computer science;stereopsis;degrees of freedom;robotics;stereophonic sound;systems design	Robotics	63.09265232647822	-32.403798386895104	183159
738fe1c92e2398b95a64543bb82a9da45a357ffa	procedural generation of cuban dance motion	computers;legged locomotion;procedural generation;hip;rumba;foot;cha cha;cuban dance motion;dance styles;natural looking dance moves procedural generation cuban dance motion inverse kinematics model animation dance styles salsa rumba cha cha normal rigging constraints;natural looking dance moves;foot animation hip games timing computers legged locomotion;humanities;humanities computer animation;games;animation;salsa;inverse kinematics;model animation;computer animation;weight change;timing;normal rigging constraints	Inverse kinematics greatly simplifies the animation of models: positioning the hand alone will position the entire arm. In some dance styles, the position of the feet, together with which foot the weight is on, determines much of the bending and rotation of the legs, hips, rib cage, shoulders and arms. Cuban motion is a highly stylized example of this, used in several dances such as Salsa, Rumba, and Cha-cha. The principles covering Cuban motion, when combined with normal rigging constraints, allow a wide variety of dances and dance moves to be synthesized rapidly with minimal input. Only the timing of the weight changes (usually fixed for each dance), and the placement of the feet (usually fixed for each dance move), need be specified. In this talk we outline the principles of Cuban motion, and demonstrate how natural looking dance moves can be procedurally generated. We have found that the code for dance moves can be simplified enough to resemble the instructions given in dance guidebooks.	blender (software);coat of arms;computer animation;dance dance revolution extreme;experiment;inverse kinematics;jason;polygon mesh;procedural generation;rumba;salsa;testbed	Elizabeth A. Matthews;Geoffrey B. Matthews	2011	2011 16th International Conference on Computer Games (CGAMES)	10.1109/CGAMES.2011.6000356	anime;games;simulation;computer science;artificial intelligence;inverse kinematics;computer animation;foot;computer graphics (images)	Vision	66.34522187034712	-26.46531043765644	183206
13aec7c9c259176036528aad3448e22d923dc27e	intelligent unmanned explorer for deep space exploration	near earth asteroid;system design	In recent years, such small body exploration missions as asteroids or comets have received remarkable attention in the world. In small body explorations, especially, detailed in-situ surface exploration by tiny rover is one of effective and fruitful means and is expected to make strong contributions towards scientific studies. JAXA/ISAS is promoting MUSES-C mission, which is the world’s first sample and return attempt to/from the near earth asteroid. Hayabusa spacecraft in MUSES-C mission took the tiny rover, which was expected to perform the in-situ surface exploration by hopping. This paper describes the system design, mobility and intelligence of the developed unmanned explorer. This paper also presents the ground experimental results and the flight results.	frequency-hopping spread spectrum;robot;rover (the prisoner);systems design;unmanned aerial vehicle	Takashi Kubota;Tetsuo Yoshimitsu	2007	CoRR		astrobiology;computer science;near-earth object;remote sensing;systems design	Robotics	54.679846304992374	-29.368768390449834	183321
c95b4365a306d68358c730faaa8bee623d34d323	domestic service robots in the real world: more on the case of intelligent robots following humans		The international initiative “Robocup”, and in particular its “@Home” league of Robocup, are excellent environments for focusing robotics research and AI as well as, more specifically, for testing the abilities of domestic service robots. Following humans has long been recognized as a basic capability in this context. It allows in our case for convenient path programming (teaching of itineraries). Although, the cognitive requirements are quite high (20 lin of knowledge, 200 lin/s of expertise), humans usually proceed in the same way. The environment is dynamic and disturbances may occur, which may cause errors. Therefore, safety measures must be devised, such as close human-robot interaction to prevent path crossing by third parties; the availability of light signals as a discrete warning; close interaction for accurate positioning in complex trajectories; coordinated, unidirectional blocking; vocally warnings and the ability to stop when people cross the path between the robot and the guide; the definition of a maximal radius of influence beyond which stopping is triggered; procedures for emergency stopping; robust vision-methods; and ultrasonic sensors and map-based obstacle avoidance. At the most abstract semantic level, about 15 bits per second of information must be acquired. For this purpose a variety of sensors are considered, each with specific advantages: a color camera, a planar laser range scanner, a 3D-ranger, ultrasonic sensors, and joint sensors. Smooth and stable real-time behavior is ensured by a 5-level hierarchical control structure and agents implemented in different technologies (computers, PLC, servo controllers, etc.), inheriting some developments resulting from research in Eurobot context.	humans;robot	Jean-Daniel Dessimoz;Pierre-François Gauthey	2011		10.1007/978-3-642-21975-7_9	simulation;artificial intelligence	Robotics	59.5924648627055	-28.750127638921363	183475
9adb353c52ba176a208ba4e4a393832362749671	evolutionary learning of basic functionalities for snake-like robots		The objective of the work presented in this paper is to investigate the optimal learning strategy for snake-like modular robots using a (1+1) Evolutionary Algorithm. We take into account three different but correlated tasks: efficient locomotion, reaching a given point and obstacle avoidance.	robot	Dámaso Pérez-Moneo Suárez;Claudio Rossi	2013		10.1007/978-3-319-03413-3_28	artificial intelligence;machine learning	Robotics	59.42592296126083	-24.86391145825733	183738
8c2d069b2e83a965b3fe9063905a13627ef43535	research of a kind of new uav training simulator based on equipment simulation	aircraft control;training visualization computers software mathematical model computational modeling aerospace control;mobile robots;real time simulation;aerospace simulation;real time simulation equipment simulation rtx;aircraft testing;unmanned aerial vehicles uav training simulator equipment simulation uav operator system testing signal pipeline scene editor flight control system testing radio data link ground station real time simulation;telerobotics aerospace simulation aircraft control aircraft testing computer based training mobile robots radio links real time systems;computer based training;telerobotics;real time systems;radio links	Traditional UAV training Simulator is independent of UAV System, so the UAV operator cannot accomplish both system test and training in one training process. This paper presented and realized a kind of new Training Simulator based on simulation for the equipment on UAV. The new kind of system structure and signal pipeline was introduced first, then the method and process to treat plane model equipment model into real time. At last the main function and effect of scene editor and displaying were presented. The result shows that the new training Simulator can not only meet the training requirement but also accomplish the testing for flight control system, radio data link, and ground station in the meantime. This Training Simulator has successfully applied in a certain kind of UAV system and wined prime estimate.	computer simulation;control system;entry point;software portability;system testing;unmanned aerial vehicle	Jianan Wu;Wei Wang;Jinhong Zhang;Bodong Wang	2011	Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology	10.1109/EMEIT.2011.6024116	telerobotics;mobile robot;embedded system;simulation;aerospace engineering;computer science;engineering;artificial intelligence	Robotics	64.26729956050957	-30.285455894360705	184112
9a7a62d0cac7242ee22ff53c3ab15ee9ceae58e3	design of a high performance dual arm aerial manipulator		This paper presents the design of a dual arm aerial manipulation robot consisting of a customized hexarotor platform equipped with a lightweight dual arm manipulator. The proposed design is intended to integrate multiple devices required for building a complete aerial manipulation system, including vision and range sensors, on-board computers, communication devices, navigation systems, along with the manipulator. The developed platform will provide optimum performance in terms of flight time and payload taking into account the current technology available for building these kind of aircrafts. The design of the platform also considers vibration isolation, control and stability, and extended workspace for the manipulator. A lightweight (1.8 kg) and human-size dual arm manipulator has been integrated in the developed platform. Each arm provides 5 degrees of freedom (DOF) for end effector positioning and orientation. The arms are built using smart servo actuators and a frame structure manufactured in anodized aluminum. The design is validated through rigidity and modal analysis using finite element methods (FEM). The developed platform has been tested in outdoor flights, evaluating the influence of arms motion over the stability of the platform.	aerial photography;autopilot;coat of arms;computer;control system;differential gps;finite element method;modal logic;multistage interconnection networks;on-board data handling;payload (computing);robot end effector;sensor;servo;workspace	Pedro Grau;Alejandro Suárez;Víctor Manuel Vega;Ángel Rodriguez Castaño;Aníbal Ollero	2017		10.1007/978-3-319-70833-1_59	computer vision;robot;workspace;modal analysis;artificial intelligence;actuator;payload;servo;computer science;vibration isolation;control engineering;robot end effector	Robotics	65.13127897490453	-28.998787961513585	184326
e7233570c89435e5554bee27ab2cc0a49ec18846	multirobot plan generation in a continuous domain: planning by use of plan graph and avoiding collisions among robots	assemblage;graph theory;ensamble;plan graph;trajectoire;robot plan generation system;systeme multirobot;intelligent robots;job shop scheduling;multirobot system;plamat;operations research;orbital robotics;methode calcul;robot industriel;metodo calculo;calculating method;assembly;prevencion esquiva colision;time factors;trajectory;parallel robots;parallel robots robotic assembly orbital robotics assembly systems intelligent robots artificial intelligence job shop scheduling space technology time factors continuous production;sydamuc;prevention esquive collision;robots;robot industrial;assembly systems;artificial intelligence;robots artificial intelligence graph theory operations research;robotic assembly;trayectoria;space technology;collision avoidance;continuous production;joining;production rule;industrial robot;assembly collision avoidance artificial intelligence plan graph robot plan generation system plamat sydamuc	A robot plan generation system is described which treats continuous state changes in time for multiple robots; a model for a continuous domain is represented, and a parallel plan generation system, based on production rules for multiple robots in this domain, is proposed. The system consists of two subsystems: a fundamental planning subsystem for multiple robots and a subsystem for detecting and avoiding mutual collisions of cylindrical-type robots. These subsystems are called PLAMAT and SYDAMUC, respectively. In addition to examples for each subsystem, an assembly problem is solved as an example for the total plan generation system and the usefulness of the system is confirmed.	robot;sensor	Tadashi Nagata;Kunihiko Honda;Yoshiaki Teramoto	1988	IEEE J. Robotics and Automation	10.1109/56.766	robot;control engineering;job shop scheduling;parallel manipulator;simulation;computer science;engineering;artificial intelligence;graph theory;trajectory;assembly;space technology	Robotics	59.06184702443199	-24.210988222376947	184615
3991f0a44f04465ebc250cc289a9900a44b17b37	strap and row: rowing technique analysis based on inertial measurement units implemented in mobile phones	gyroscopes;smart phone phone sensing inertial measurment unit gyroscope rowing technique stroke length;smart phones boats blades algorithm design and analysis gyroscopes angular velocity;smart phones;blades;angular velocity;algorithm design and analysis;boats	The length of a rowing stroke is an important performance metric for athletes and coaches. Accurate measurements are possible with optical or mechanical systems, which require significant setup effort. This work presents a new approach using a smart phone as a sensor device that is strapped to the oar. Two algorithms are introduced to calculate stroke lengths from the raw phone sensor data. The performance of each algorithm is evaluated by comparing the results to a mechanical reference system. Data was recorded during a single-user study performed on a rowing simulator. The best algorithm showed an average stroke length error of 7.64° ± 2.95°.	algorithm;android;gyroscope;microsoft outlook for mac;mobile app;mobile phone;multi-user;sensor;simulation;smartphone;synchronicity;usability testing	Franz Gravenhorst;Amir Muaremi;Felix Kottmann;Gerhard Tröster;Roland Sigrist;Nicolas Gerig;Conny Draper	2014	2014 IEEE Ninth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP)	10.1109/ISSNIP.2014.6827677	embedded system;electronic engineering;simulation;engineering	Robotics	57.86718410641793	-37.55446008806819	184803
33de117241340fd71bc573fadf7fc0ff49d506e4	lessons learned after more than 1000 km in an autonomous shuttle guided by vision	prototypes;visualization;trajectory;roads;cameras;autonomous vehicles	This article presents a large scale and long duration experiment as part of the French FUI VipaFleet project. A driverless shuttle has been operated for three month on an industrial site, totaling nearly 1500 km of autonomous travel and 300 passengers transported. The localization relies mainly on a multi camera system and a visual SLAM algorithm. Besides the vision algorithms themselves, this article develops the practical aspects of a large scale experiment and the lessons learned from this experience.	algorithm;autonomous robot;simultaneous localization and mapping	Eric Royer;François Marmoiton;Serge Alizon;Datta Ramadasan;Morgan Slade;Ange Nizard;Michel Dhome;Benoit Thuilot;Florent Bonjean	2016	2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2016.7795919	computer vision;simulation;engineering;remote sensing	Robotics	54.325725279903736	-30.34425831409822	185139
6f13a89c4f4fc3e1888df54a02c05078cada2240	autonomous precision landing for commercial uav: a review		This paper reviews a various methods exploring the topic of unmanned aerial vehicles (UAV) autonomous precision landing, covering two types of commercial UAVs, multi-rotor and fixed-wing UAVs. Four general methods gain the most eminence for the autonomous precision landing, which generally known as visual processing landing, satellite navigations landing, ground station navigation landing, and arrestor recovery landing. The assessment of the landing accuracies of each method are assessed and compared, if the results are being made available in the reviewed research articles. We also discussed the recent breakthroughs in sensors, processor, and flight technology that can improve the accuracy of UAV autonomous precision landing.	unmanned aerial vehicle	Mohd Yusri Bin Mohd Noor;M. A. Ismail;M. F. Khyasudeen;A. Shariffuddin;N. I. Kamel;Saaidal Razalli Bin Azzuhri	2017		10.3233/978-1-61499-828-0-459	remote sensing;visual processing;engineering	SE	54.907224208784505	-30.394371342428897	185210
c834fcad52f1184e1212bb14046f5b5a25676750	integration of vision and inertial sensors for 3d arm motion tracking in home-based rehabilitation	human motion tracking;real time;data fusion;motion tracking;human motion;hybrid system;robust performance;sensor fusion;home based rehabilitation;extended kalman filter;inertial sensor	The integration of visual and inertial sensors for human motion tracking has attracted significant attention recently, due to its robust performance and wide potential application. This paper introduces a real-time hybrid solution to articulated 3D arm motion tracking for home-based rehabilitation by combining visual and inertial sensors. Data fusion is a key issue in this hybrid system and two different data fusion methods are proposed. The first is a deterministic method based on arm structure and geometry information, which is suitable for simple rehabilitation motions. The second is a probabilistic method based on an Extended Kalman Filter (EKF) in which data from two sensors is fused in a predict-correct manner in order to deal with sensor noise and model inaccuracy. Experimental results are presented and compared with commercial marker-based systems, CODA and Qualysis. They show good performance for the proposed	coda;extended kalman filter;hybrid system;image noise;kinesiology;real-time locating system;sensor	Yaqin Tao;Huosheng Hu;Huiyu Zhou	2007	I. J. Robotics Res.	10.1177/0278364907079278	control engineering;computer vision;simulation;tracking system;computer science;engineering;control theory;sensor fusion	Robotics	57.89803648279509	-37.72323561316793	185326
6aa2acff32d0f958d992679cf2890ee1a518c813	preliminary results on instantaneous uav-based 3d mapping for rescue applications		This report presents a novel approach to generate a 3D map with an UAV while flying over a disaster scene with the aim to present the map instantaneously to the operator and the rescue workers. Our approach extends the well-known ICP algorithm.	genetic algorithm;unmanned aerial vehicle;whole earth 'lectronic link	Helge A. Lauterbach;Andreas Nüchter	2018	2018 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)	10.1109/SSRR.2018.8468625	artificial intelligence;simulation;computer vision;operator (computer programming);computer science	Robotics	54.32193245243529	-26.336119641474507	185422
87e81739f4a39a56784a2d9d928a8ae3597fbfce	adas applications for improving traffic safety	video signal processing;road traffic;traffic safety;large scale;road safety large scale systems laser radar government image reconstruction navigation collision avoidance velocity measurement radar imaging image analysis;collision avoidance;road safety;article in monograph or in proceedings;video imaging adas applications road traffic safety improvement infrastructure measures its applications large scale infrastructure reconstruction speed assistance collision avoidance intersection support lane keeping;road traffic road safety collision avoidance video signal processing	Governments in several European countries, and the EU have set challenging targets for the improvement of road traffic safety by the year 2010. In the Netherlands a program for infrastructure measures was launched, to meet the Dutch targets. The ongoing developments in the field of ITS applications seem however to offer viable alternatives for large-scale infrastructure reconstruction. This paper explores the feasibility of five ADAS applications (navigation, speed assistance, collision avoidance, intersection support and lane keeping) to complement or partly substitute infrastructure measures to reach the stated goals. State-of-the-art and the potential of enabling technologies like positioning, radar, laser, video imaging and communication are analysed from a technical perspective. Technical issues relating to large-scale dedicated ADAS implementation for traffic safety, as well as related policy issues are discussed.	architecture design and assessment system;radar	Meng Lu;Kees Wevers;Rob van der Heijden;Tom Heijer	2004	2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)	10.1109/ICSMC.2004.1400969	simulation;advanced driver assistance systems;computer security	Visualization	54.17806229851158	-30.341660206115634	185469
e93cca415d956ca6b7bd209a5187d67d3e0093a3	from swarm robotics to smart materials	smart material;swarm robotics	Swarm intelligence refers to the phenomenon of a system of spatially distributed individuals that coordinate their actions in a decentralized and self-organized manner, so as to exhibit complex collective behavior. Such systems tend to have large numbers of individual agents that interact with each other in simple ways. This allows swarm-intelligent systems to be inherently robust and flexible. As these principles are scale-free, systems with these properties can range in size from the nano to the macro scale. Swarm-intelligent systems are common throughout nature. Examples are bacteria colonies, neural networks, social insects, and flocks/herds of vertebrates. In addition, humans have produced a variety of (artificial) swarm systems ranging from swarm-based optimization algorithms to sensor networks, swarms of robots, and smart materials. In each of these natural or artificial systems, populations of agents change their spatiotemporal configuration solely based on the agents’ local interactions with each other and the environment. This special issue on ‘‘Swarm Robotics’’ provides an overview of recent results and trends in this emerging field. Contributions to this special issue range from programming paradigms for swarming systems to specific distributed algorithms and modular robotic systems. The unifying theme of these works is individual simplicity: complex global behavior emerges from purely local interactions and simple local rules. Examples covered in this special issue range from spatial behaviors such as flocking and dispersion, computational behaviors such as shortest-path routing and collective decisions, up to full-body behaviors of modular robot ensembles. In their paper, ‘‘Composable continuous-space programs for robotic swarms’’, Bachrach, Beal, and McLurkin present the functional programming language Proto that allows individual behavior to be described by expressions over a global field. By computing the global field not only from local measurements but also based on data received from other swarm members within the local neighborhood, previous state, and control logic, Proto allows complex swarming behaviors to be composed with highly compact code. Proto code is then compiled into op-codes for the Proto Virtual Machine, which needs to provide abstractions for sensing, actuation, estimation of the geometric relations between neighboring swarm members, and local communication. Algorithms such as shortest-path routing are demonstrated on a swarm of 40 miniature mobile robots, as well as in computer simulations. In their paper, ‘‘Collective decision-making based on social odometry’’, Gutiérrez, Campo, Monasterio-Huelin, Magdalena, and Dorigo investigate a novel collective decision-making mechanism using a colony of mobile robots that accomplish a foraging task. The robots are required to establish a path from a central place to the closest of multiple resource sites. To reach a consensus, they make use of social odometry. The latter mechanism enables the robots to estimate the position of resource sites by exchanging and aggregating odometry-based positional information and confidence levels. The collective decisionmaking mechanism is successfully validated by experiment N. Correll (&) Department of Computer Science, University of Colorado at Boulder, 430 UCB, Boulder, CO 80309, USA e-mail: nikolaus.correll@colorado.edu	artificial neural network;code;compiler;computer science;computer simulation;distributed algorithm;email;emergence;eusociality;flocking (behavior);functional programming;gnu nano;humans;intelligent agent;interaction;mathematical optimization;mobile robot;odometry;population;programming language;programming paradigm;routing;self-organization;self-reconfiguring modular robot;shortest path problem;swarm intelligence;swarm robotics;virtual machine	Nikolaus Correll;Roderich Groß	2010	Neural Computing and Applications	10.1007/s00521-010-0440-2	swarm robotics;computer science;smart material	Robotics	58.45736310808053	-25.241182417447444	186048
826c18d0bfbc703eea9cb67cc33a002a8917d75a	real-time navigation for a personal mobility in an environment with pedestrians	trajectory planner;two wheeled inverted pendulum mobile robot;mobile robot;nonlinear control systems;real time;mobile robots;dynamic environment;navigation;personal mobility;trajectory;robot pitching movements;position control;heuristic algorithms;real time navigation;pedestrian detection;simultaneous localization and mapping;position control collision avoidance mobile robots nonlinear control systems;pedestrian localization;planning;inverted pendulum;navigation system;collision avoidance;navigation robot kinematics mobile robots simultaneous localization and mapping trajectory robotics and automation orbital robotics real time systems robustness wheels;robot pitching movements real time navigation personal mobility navigation system two wheeled inverted pendulum mobile robot pedestrian tracking pedestrian detection pedestrian localization trajectory planner;pedestrian tracking;robot kinematics	This paper describes a navigation system in a dynamic environment for a two-wheeled inverted pendulum mobile robot, PMR. Our system is organized by localization, detection and tracking of pedestrians, and trajectory planner. The localization is robust to effects of moving obstacles and pitching movements of the robot, and the trajectory planner creates a path with a certain smoothness considering movements of pedestrians. In addition, the planner introduces strategies to avoid pedestrians to be friendly to pedestrians around the robot. Besides, our system can run on two laptop PCs in real time. Finally, we show experimental results as well.	algorithm;internationalization and localization;inverted pendulum;item response theory;laptop;mobile robot;pmr446;real-time transcription	Naotaka Hatao;Ryo Hanai;Kimitoshi Yamazaki;Masayuki Inaba	2009	RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2009.5326074	mobile robot;computer vision;simulation;computer science;artificial intelligence	Robotics	59.17946375744331	-29.61946404053278	186163
9273cc527d3fb8c2709465816747434466f93ca0	seamless indoor-outdoor robust localization for robots		In this paper we present a unified localization technique for indoor-outdoor environments that allows a seamless transition between a mapped zone using laser rangefinder on-board sensors and a GPS based localization zone. Different situations are detected during the indoor-outdoor transitions, in which the sensors used change and the localization estimator has to manage them properly for a continuous localization. The quality in the GPS measurements and the zone where the robot is localized are used to determine the best instant for switching the localization parameters for adapting to the situations.	robot;seamless3d	Pablo Urcola;María-Teresa Lorente;José Luis Villarroel;Luis Montano	2013		10.1007/978-3-319-03653-3_21	computer vision;artificial intelligence;estimator;covariance intersection;robot;global positioning system;computer science;assisted gps	Robotics	54.21492090755507	-34.606473523898124	186482
ee1f918b32e01b265ec35825aaed6bbedbb5d2bd	repellent pheromones for effective swarm robot search in unknown environments	effective swarm robot search locally distributed repellent pheromones rescue missions;robot sensing systems;swarm intelligence multi robot systems rescue robots;radiation detectors;actuators;mobile robots;vectors;robot sensing systems robot kinematics actuators radiation detectors mobile robots vectors;robot kinematics	In time-critical situations such as rescue missions, effective exploration is essential. Exploration of such unknown environments may be achieved through the dispersion of a swarm of robots. Recent research has turned to biology where pheromone trails provide a form of collective memory of visited areas. Rather than the attractive pheromones that have been the focus of much research, this paper considers locally distributed repellent pheromones. Further, the conditions for maximising search efficiency are investigated.	robot;swarm;window of opportunity	Filip Fossum;Jean-Marc Montanier;Pauline C. Haddow	2014	2014 IEEE Symposium on Swarm Intelligence	10.1109/SIS.2014.7011802	control engineering;mobile robot;swarm robotics;simulation;engineering;artificial intelligence;social robot;robot control	Robotics	57.746627682130814	-23.97292794123884	186566
756025984fcae02aee815f4679704b5027b84274	concept of an autonomous disassembly system using behavior-based robotics	behavior based robotics;robotics;desmontaje;robotica;demontage;reconversion;robotique;recycling;recyclage;control method;desassembly	Automatic disassembly of disused products into parts is important for high-level recycling. Analysis of a disassembly process in contrast to an assembly process suggests that disassembly is easier than assembly and that it can be performed by a robot with appropriate behaviors, such as to look for parts, to turn a hexagon counterclockwise and to make a loosened part looser. The disassembly process for unknown simple mechanical products is simulated using a set of behaviors of a robot. A concept of an autonomous disassembly system is proposed using behavior-based robotics with help of other control methods and appropriate design of products.	autonomous robot;behavior-based robotics;disassembler	Kazuo Tanie;Ertan Güner	1996	Advanced Robotics	10.1163/156855397X00317	behavior-based robotics;simulation;computer science;engineering;artificial intelligence;robotics;recycling;manufacturing engineering	Robotics	64.28010151373658	-27.131811093235786	186683
76053ba897a3e6ced837b957aa729d5104e815ed	cost functions based dynamic optimization for robot action planning		Human-robot collaboration provides a great solution to the complex hybrid assembly tasks of intelligent manufacturing. In order to augment and guarantee the task quality in the human-robot collaboration process, the collaboration efficiency, including time consumption and human efforts, should be considered in the robot action planning. In this study, we propose a novel and practical approach using cost functions for the robot to plan actions in human-robot collaboration to address this challenge. By this approach, the robot action planning can be dynamically optimized to determine assisted assembly steps in the human-robot co-assembly task. A preliminary experiment is conducted to evaluate the proposed approach. Experimental results suggest that the proposed approach successfully generates the optimal actions for the robot to improve the task efficiency in human-robot collaboration.	human–robot interaction;program optimization;robot	Weitian Wang;Yi Chen;Zachary Max Diekel;Yunyi Jia	2018		10.1145/3173386.3177021	simulation;computer science;robot	Robotics	60.65468713040895	-24.654552298210383	186753
177099af4cf1cca7fa889771f08bfd658d353df2	real-time hand and eye coordination for flexible impedance control of robot manipulator	real time;online learning;robot manipulator;robot control;impedance control;linear equations;neural network;force control	In recent years a lot of versatile robots have been developed to work in environments with human. However they are not sufficiently flexible nor safe in terms of interaction with human. In our approach we focused on hand and eye coordination in order to establish a flexible robot control, in which a robot recognizes its environment from the input camera images and equips a soft contacting strategy by impedance control. To recognize the environment, we adopt a method to reconstruct motion from a sequence of monocular images by using a pair of parallel straight line segments, which enables us to obtain linear equations to solve the problem. On the other hand the impedance control strategy conveys a flexible interaction between robots and humans. The strategy can be considered as a passive force control, when something contacts the end-effector of the robot. In order to avoid a collision, we introduce a virtual impedance control which can generate force prior to the contact. Neural networks (hereafter: NN) learning is used to decide parameters for impedance control, in which NNs can obtain parameters during the motion (aka: online learning). The validity of the proposed method was verified through experiments with a multijoint robot manipulator.	artificial neural network;automation;autonomous system (internet);cvpr;characteristic impedance;computation;computer vision;control theory;cybernetics;experiment;graphics;humans;image processing;impedance parameters;linear equation;neural networks;nominal impedance;real-time transcription;robot control;robot end effector;robotics;sethi–ullman algorithm	Mutsuhiro Terauchi;Yoshiyuki Tanaka;Toshio Tsuji	2008		10.1007/978-3-540-78157-8_23	control engineering;robot learning;computer vision;bang-bang robot;simulation;engineering;social robot;robot control	Robotics	63.1163464327543	-25.85205684129537	186904
b69afddf760a3a384202f504171198be9bce1b87	an approximate dynamic programming approach to the dynamic traveling repairperson problem	dynamic programming;asymptotic optimality;aerodynamics;travelling salesman problems dynamic programming planning traffic transportation;vehicle routing problem approximate dynamic programming approach dynamic traveling repairperson problem dynamic planning asymptotic optimal policy traffic load;usa councils;artificial neural networks;vehicles vehicle dynamics dynamic programming artificial neural networks steady state aerodynamics usa councils;travelling salesman problems;transportation;traffic;planning;approximate dynamic programming;vehicles;vehicle dynamics;steady state	This paper presents a novel suboptimal policy for the Dynamic Traveling Repairperson Problem (m-DTRP), a problem requiring dynamic planning for a team of vehicles. The suggested policy is adaptive, locally distributed, computationally efficient, and independent of traffic load intensities. It is shown that the policy is asymptotically optimal in the light traffic load case. Experimental results are provided to show that the performance in the moderate and heavy load cases is comparable to the best known policies.	algorithmic efficiency;approximation algorithm;asymptotically optimal algorithm;computation;dynamic programming;reactive planning;travelling salesman problem;usb on-the-go	Hyung Sik Shin;Sanjay Lall	2010	49th IEEE Conference on Decision and Control (CDC)	10.1109/CDC.2010.5717061	planning;transport;mathematical optimization;vehicle dynamics;simulation;aerodynamics;computer science;dynamic programming;steady state	Robotics	54.50180543848434	-24.510025628623172	187266
94f90d9c30083a7d5546a9cbda185cb9b5a772d8	haptics and virtual reality based bilateral telemanipulation of miniature aerial vehicle over open communication network		In this paper, we develop haptic interface system for bilateral telemanipulation of unmanned miniature aerial vehicle (MAV). The proposed interface allows operator to navigate MAV in order to control and interact with uncertain indoor flying environments without using vision systems. The master interface combines bilateral shared control terms with the reflected remote interaction force fields mapped by two different types of force field algorithms as potential force field and spring-damper force field. The shared control strategy for the master comprises velocity signals of the remote MAV with the scaled position of the master haptic manipulator. The bilateral shared input interface for the slave is designed by combining scaled position of the master manipulator with the velocity of the remote MAV. The data transmission between ground station and remote vehicle are carried out by open internet communication network. In contrast with other haptic interface system, the proposed interface system only uses laser technology equipped with the slave MAV. Compared with potential force field based interface, the interface introduced in this paper provides better situational awareness about remote environment helping operator to navigate and control MAV for safe interaction with uncertain indoor dynamic environment. Experimental results together with comparative studies on laboratory made quadrotor MAV are presented to demonstrate the effectiveness of the proposed methods for real-time applications.	aerial photography;algorithm;autonomous robot;autonomous system (internet);bilateral filter;control theory;experiment;force field (chemistry);haptic technology;input device;net neutrality;real-time clock;remote manipulator;telecommunications network;unmanned aerial vehicle;velocity (software development);virtual reality	Shafiqul Islam;Dongming Gan;Reem Ashour;Paolo Dario;Jorge Manuel Miranda Dias;Lakmal D. Seneviratne	2017	2017 18th International Conference on Advanced Robotics (ICAR)	10.1109/ICAR.2017.8023629	telecommunications network;operator (computer programming);manipulator;situation awareness;haptic technology;data transmission;open communication;virtual reality;engineering;control engineering	Robotics	61.638715313890486	-27.611800784426002	187414
9abf90dd5321165f887c8e5aafec4e77af689f81	the cablerobot simulator large scale motion platform based on cable robot technology	force;solid modeling;robots;safety;predictive models;winches;power cables	This paper introduces the CableRobot simulator, which was developed at the Max Planck Institute for Biological Cybernetics in cooperation with the Fraunhofer Institute for Manufacturing Engineering and Automation IPA. The simulator is a completely novel approach to the design of motion simulation platforms in so far as it uses cables and winches for actuation instead of rigid links known from hexapod simulators. This approach allows to reduce the actuated mass, scale up the workspace significantly, and provides great flexibility to switch between system configurations in which the robot can be operated. The simulator will be used for studies in the field of human perception research and virtual reality applications. The paper discusses some of the issues arising from the usage of cables and provides a system overview regarding kinematics and system dynamics as well as giving a brief introduction into possible application use cases.	algorithm;automation;cybernetics;motion simulator;nonlinear system;parallel manipulator;prototype;robot;simulation;system dynamics;virtual reality;workspace	Philipp Miermeister;Maria Lächele;Rainer Boss;Carlo Masone;Christian Schenk;Joachim Tesch;Michael Kerger;Harald J. Teufel;Andreas Pott;Heinrich H. Bülthoff	2016	2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2016.7759468	robot;control engineering;simulation;computer science;engineering;artificial intelligence;winch;control theory;predictive modelling;solid modeling;force;mechanical engineering	Robotics	66.56967251937742	-27.628718202570344	187436
a2c40c5a80656c83d4d275216e05fa20247bf3a4	motion planning of legged vehicles in an unstructured environment	cmu;legged locomotion;distributed computational platform motion planning legged vehicles unstructured environment statically stable motion uneven terrain footplacement traversability complexity reduction heuristics xerox parc polybot modular reconfigurable robot cmu ambler;path planning;distributed processing;distributed computing;search problems path planning legged locomotion distributed processing;vehicles leg legged locomotion robots foot sea surface surface finishing motion planning computational modeling distributed computing;motion planning;search problems;complex terrain;parc;legged robot	A planner for statically-stable motion of a legged robotic vehicle over an uneven terrain is presented that can plan the footplacement of individual legs for highly cluttered terrain. A method for determining the traversability over a generic discretised height map terrain is presented. Planning is broken into two levels of refinement to reduce the overall complexity and incorporates a number of heuristics. The planner has successfully planned the motion of 6 and 8 legged configurations of the XEROX PARC PolyBot modular reconfigurable robot as well as the CMU Ambler in simulation over arbitrarily complex terrain. A distributed implementation of the planner has also been shown on PolyBot’s distributed computational platform.	algorithm;computation;discretization;heightmap;heuristic (computer science);high- and low-level;high-level programming language;motion planning;refinement (computing);scott ambler;self-reconfiguring modular robot;simulation;smart environment;star height;workspace;ical	Craig Eldershaw;Mark Yim	2001		10.1109/ROBOT.2001.933140	control engineering;computer vision;simulation;computer science;engineering;artificial intelligence;motion planning	Robotics	54.93843233660579	-26.47570361045673	187800
d86c537494c2ba951f11fd76f7518ec6aac9e18e	intuitive humanoid motion generation joining user-defined key-frames and automatic learning	humanoid robot;human movement;learning algorithm;parameter space;development time;learning strategies;quantitative evaluation;qualitative evaluation;fitness function	In this paper we present a new method for generating humanoid robot movements. We propose to merge the intuitiveness of the widely used key-frame technique with the optimization provided by automatic learning algorithms. Key-frame approaches are straightforward but require the user to precisely define the position of each robot joint, a very time consuming task. Automatic learning strategies can search for a good combination of parameters resulting in an effective motion of the robot without requiring user effort. On the other hand their search usually cannot be easily driven by the operator and the results can hardly be modified manually. While the fitness function gives a quantitative evaluation of the motion (e.g. ”How far the robot moved?”), it cannot provide a qualitative evaluation, for instance the “human-likeness” of the movement. In the proposed technique the user, exploiting the key-frame approach, can intuitively bound the search by specifying relationships to be maintained between the joints and by giving a range of possible values for easily understandable parameters. The automatic learning algorithm then performs a local exploration of the parameter space inside the defined bounds. Thanks to the clear meaning of the parameters provided by the user, s/he can give qualitative evaluation of the generated motion (e.g. ”This walking gait looks odd. Let’s raise the knee more”) and easily introduce new constraints to the motion. Experimental results proved the approach to be successful in terms of reduction of motiondevelopment time, in terms of natural appearance of the motion, and in terms of stability of the walking.	algorithm;fitness function;humanoid robot;key frame;machine learning;mathematical optimization	Marco Antonelli;Fabio Dalla Libera;Emanuele Menegatti;Takashi Minato;Hiroshi Ishiguro	2008		10.1007/978-3-642-02921-9_2	robot learning;computer vision;simulation;computer science;humanoid robot;artificial intelligence;parameter space;fitness function	AI	62.121653597818586	-25.28463461080591	187826
67cdbca4e36bb34a61424396d45c3a107556aa2f	reinforcement learning for balancer embedded humanoid locomotion	humanoid robot;legged locomotion function approximation humanoid robots learning artificial intelligence;legged locomotion humanoid robots aerospace electronics foot learning wire;function approximator reinforcement learning balancer embedded humanoid locomotion learning walking scheme humanoid robot;learning;balancer embedded humanoid locomotion;legged locomotion;reinforcement learning;foot;wire;function approximator;humanoid robots;function approximation;aerospace electronics;learning walking scheme;learning artificial intelligence	Reinforcement learning (RL) applications in robotics are of great interest because of their wide applicability, however many RL applications suffer from large learning costs. We study a new learning-walking scheme where a humanoid robot is embedded with a primitive balancing controller for safety. In this paper, we investigate some RL methods for the walking task. The system has two modes: double stance and single stance, and the selectable action spaces (sub-action spaces) change according to the mode. Thus, a hierarchical RL and a function approximator (FA) approaches are compared in simulation. To handle the sub-action spaces, we introduce the structured FA. The results demonstrate that non-hierarchical RL algorithms with the structured FA is much faster than the hierarchical RL algorithm. The robot can obtain appropriate walking gaits in around 30 episodes (20∼30 min), which is considered to be applicable to a real humanoid robot.	algorithm;embedded system;gradient;humanoid robot;iteration;maxima and minima;reinforcement learning;robotics;simulation	Akihiko Yamaguchi;Sang-Ho Hyon;Tsukasa Ogasawara	2010	2010 10th IEEE-RAS International Conference on Humanoid Robots	10.1109/ICHR.2010.5686296	simulation;computer science;humanoid robot;artificial intelligence;reinforcement learning	Robotics	62.87110946356923	-24.375556267715012	188075
bea1db394c3b5f69703a4ab5cb1f049cf6345339	the robot that can achieve card magic	thumb force actuators grasping robot kinematics;dexterous manipulators;four fingered robot card magic robot magician first card dealing second card dealing key time chart human magician	We develop a robot magician capable of taking out the first or second card from the top of a bundle of cards. We can switch first-card-dealing and second-card-dealing freely by introducing a key time chart that can not be followed by human, which allows the robot to achieve card magic. The robot can deal the cards with the speed of six cards/sec, which is even faster than human magician. Through the observation of the human magician, we extract the fundamental functions and implement them into the robot. Eventually, the developed robot has four fingers. In order to achieve a quick manipulation, we reduce active degrees of freedom as many as possible. Finally, we can examine the card magic by using the developed robot beyond the limit of human vision.	robot	Ryoma Koretake;Makoto Kaneko;Mitsuru Higashimori	2014	2014 IEEE/ASME International Conference on Advanced Intelligent Mechatronics	10.1109/AIM.2014.6878253	computer vision;simulation;engineering;artificial intelligence;social robot;robot control;personal robot	Robotics	67.65198692331698	-29.80606335086969	188336
2e68f22c7846073d5161a41f1b28a3b7b3f5c402	applications of highly accurate localization and navigation to mobile robot	kalman filtering;robot sensing systems;navigation mobile robots robot kinematics robot sensing systems kalman filters filtering algorithms robot motion appropriate technology fuzzy logic equations;shortest moving route;mobile robot;path planning;fuzzy control;fuzzy logic control;kalman filters;laser navigation system route planning kalman filtering fuzzy logic control ultrasonic sensor;kalman filter;mobile robots;fuzzy logic controller;path planning fuzzy control kalman filters mobile robots;navigation;highly accurate localization;tangent method;optimal routing;mobile robot navigation;kalman filtering algorithm;navigation system;laser navigation system;optimal route planning;fuzzy logic controller mobile robot navigation highly accurate localization optimal route planning tangent method shortest moving route kalman filtering algorithm;route planning;robot kinematics;ultrasonic sensor	The optimal route planning is to seek the most appropriate path for robot to arrive the desired destination smoothly in the shortest time. In this paper, the Tangent method is firstly used to find the shortest moving route. Secondly, the Kalman Filtering algorithm is employed to amend the route errors at the kth time during the moving status. Simultaneously, the route for next (k + 1)th time can be also estimated. Finally, the robot route is continuously adjusted using the fuzzy logic controller for the robot moving more smoothly and efficiently. Both simulation and experimental results confirm that the robot can reach the destination fast within no exceeding ±2cm localization error.	algorithm;fuzzy control system;fuzzy logic;kalman filter;mobile robot;simulation;smoothing	Guo-Shing Huang;Jie-Cong Ciou;Hsiung-Cheng Lin	2009	2009 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2009.5346083	kalman filter;computer vision;computer science;artificial intelligence;control theory;fuzzy control system	Robotics	54.77440763632184	-33.606816563763864	188396
56e586ca6e1e93a9b98ade27625945f2a08207e7	care-o-bot ii-development of a next generation robotic home assistant	robotic home assistant;tecnologia industrial tecnologia mecanica;robot hand;touch screen;user interface;path planning;dynamic model;grupo de excelencia;laser scanner;assisted living;object manipulation;indoor environment;walking aid;next generation;service robot;task planning;fetch and carry tasks;tecnologias;path modification	Technical aids allow elderly and handicapped people to live independently and supported in their private homes for a longer time. As a contribution to such technological solutions, two demonstrator platforms for a robotic home assistant—called Care-O-bot—were designed and implemented at Fraunhofer IPA, Stuttgart. Whereas Care-O-bot I is only a mobile platform with a touch screen, Care-O-bot II is additionally equipped with adjustable walking supporters and a manipulator arm. It has the capability to navigate autonomously in indoor environments, be used as an intelligent walking support, and execute manipulation tasks. The control software of Care-O-bot II runs on two industrial PCs and a hand-held control panel. The walking aid module is based on sensors in the walking aid handles and on a dynamic model of conventional walking aids. In “direct mode”, the user can move along freely with the robot whereas obstacles are detected and avoided. In “planned mode”, he can specify a target and be lead there by the robotic assistant. Autonomous planning and execution of complex manipulation tasks is based on a symbolic planner and environmental information provided in a database. The user input (graphical and speech input) is transferred to the task planner and adequate actions to solve the task (sequence of motion and manipulation commands) are created. A new method for sensor based manipulation using a tilting laser scanner and camera integrated in the head of the robot has been implemented. Additional sensors in the robot hand increase the grasping capabilities. The walking aid has been tested with elderly users from an assisted living facility and a nursery home. Furthermore, the execution of fetch and carry tasks has been implemented and tested in a sample home environment.	care-o-bot;next-generation network	Birgit Graf;Matthias Hans;Rolf Dieter Schraft	2004	Auton. Robots	10.1023/B:AURO.0000016865.35796.e9	laser scanning;embedded system;simulation;computer science;artificial intelligence;motion planning;user interface	Robotics	61.156491903795235	-28.870951624772243	188532
91c50f239890e64c246130e94e795568a2e38c98	modular self-reconfigurable robot systems [grand challenges of robotics]	automatic control;fabrication;control systems;reconfigurable system;motion control;modular self reconfigurable robot systems;self adjusting systems;variable morphology modular self reconfigurable robot systems fixed morphology robots proof of concept systems motion planning autonomous kinematic machines;kinematics;morphology;robots;self reconfigurable robots;telerobotics self adjusting systems;motion planning;telerobotics;robustness;fixed morphology robots;autonomous kinematic machines;robots robotics and automation fabrication motion planning automatic control motion control control systems kinematics morphology robustness;robotics and automation;proof of concept systems;variable morphology	The field of modular self-reconfigurable robotic systems addresses the design, fabrication, motion planning, and control of autonomous kinematic machines with variable morphology. Modular self-reconfigurable systems have the promise of making significant technological advances to the field of robotics in general. Their promise of high versatility, high value, and high robustness may lead to a radical change in automation. Currently, a number of researchers have been addressing many of the challenges. While some progress has been made, it is clear that many challenges still exist. By illustrating several of the outstanding issues as grand challenges that have been collaboratively written by a large number of researchers in this field, this article has shown several of the key directions for the future of this growing field	autonomous robot;galaxy morphological classification;grand challenges;motion planning;robotics;self-reconfiguring modular robot;semiconductor device fabrication	Mark Yim;Wei-Min Shen;Behnam Salemi;Daniela Rus;Mark Moll;Hod Lipson;Eric Klavins;Gregory S. Chirikjian	2007	IEEE Robotics & Automation Magazine	10.1109/MRA.2007.339623	telerobotics;robot;control engineering;motion control;computer vision;kinematics;simulation;morphology;computer science;engineering;artificial intelligence;automatic control;motion planning;fabrication;robustness	Robotics	66.0601792361	-28.15338104798362	188548
91e00abaee60fd39bf9317f94338864fc9701666	design concept of detail musculoskeletal humanoid “kenshiro” - toward a real human body musculoskeletal simulator	muscles bones joints shape actuators materials;legged locomotion;muscle control system synthesis humanoid robots legged locomotion;humanoid robots;control system synthesis;natural dynamic motions kenshiro fullbody musculoskeletal humanoid design real human body musculoskeletal simulator human like humanoid muscle arrangement joint arrangement;muscle	We have developed and studied musculoskeletal humanoids. Our goal is to realize a more human-like humanoid as a real human simulator, which has the same muscle and joint arrangements as human's and can do natural and dynamic motions as well as humans. Especially, it is very challenging to design musculoskeletal structure which can contain a large number of high powered muscles. Now, we design new fullbody musculoskeletal humanoid Kenshiro. This paper presents the concepts of this new robot and also shows the outline of our latest results Kenshiro, which is the succeeding version of our previous robot Kojiro.	human-based computation;planar (computer graphics);robot;simulation	Yuto Nakanishi;Yuki Asano;Toyotaka Kozuki;Hironori Mizoguchi;Yotaro Motegi;Masahiko Osada;Takuma Shirai;Junichi Urata;Kei Okada;Masayuki Inaba	2012	2012 12th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2012)	10.1109/HUMANOIDS.2012.6651491	muscle;simulation;computer science;humanoid robot;artificial intelligence	Robotics	67.10271233603302	-26.30452393681207	188661
ec4a23fc5f4f5800ed2e46662e6567985ded0717	vision-assisted control for manipulation using virtual fixtures	computer vision position control stability manipulators telerobotics;manipulators;direct manipulation;computer vision;stability;position control;fixtures robot sensing systems surgery motion control robot vision systems human robot interaction high performance computing control systems force control microassembly;telerobotics;assisted path following vision assisted control virtual fixtures steady hand concept direct manipulation path following tasks direction based control law autonomy;path following	We present the design and implementation of a vision-based system for cooperative manipulation at millimeter to micrometer scales. The system is based on an admittance control algorithm that implements a broad class of guidance modes called virtual fixtures. A virtual fixture, like a real fixture, limits the motion of a tool to a prescribed class or range of motions. We describe how both hard (unyielding) and soft (yielding) virtual fixtures can be implemented in this control framework. We then detail the construction of virtual fixtures for point positioning and curve following as well as extensions of these to tubes, cones, and sequences thereof. We also describe an implemented system using the JHU Steady Hand Robot. The system uses computer vision as a sensor for providing a reference trajectory, and the virtual fixture control algorithm then provides haptic feedback to implemented direct, shared manipulation. We provide extensive experimental results detailing both system performance and the effects of virtual fixtures on human speed and accuracy.	algorithm;anisotropic diffusion;autonomous robot;best, worst and average case;computer vision;experiment;gradient-index optics;haptic technology;imaging technology;optimal control;pixel;real-time clock;run time (program lifecycle phase);shr;sensor;smoothing;test fixture;usability testing;user interface;virtual fixture	Alessandro Bettini;Samuel Lang;Allison M. Okamura;Gregory D. Hager	2001	IEEE Transactions on Robotics	10.1109/IROS.2001.976327	telerobotics;control engineering;computer vision;simulation;stability;computer science;engineering;artificial intelligence;statistics	Robotics	61.06999345095154	-30.57589790511414	188684
795acb8695764ec1f973d6e6403939145c3c4cfd	control of two-wheeled mobile manipulator with vision servoing	wheels manipulators mobile robots nonlinear control systems object tracking pendulums robot vision stereo image processing visual servoing;manipulators;nonlinear control systems;inverted pendulum visual servoing mobile manipulator balance control;mobile robots;robot vision;object tracking;stereo image processing;manipulators mobile robots joints mobile communication visual servoing conferences;inverted pendulum;mobile manipulator;balance control;pendulums;visual servoing;two wheeled mobile manipulator control ibvs image based visual servoing camshift algorithm object tracking mobile robot platform inverted pendulum two wheeled mobile robot 10 dof dual arm manipulator stereo vision system vision servoing;wheels	This paper presents a method for controlling a two-wheeled mobile manipulator with visual servoing. There are three subsystems: stereo vision system, 10 DOF dual arm manipulator and two-wheeled mobile robot. The whole system can be seen as an inverted pendulum. When the robot reaches the stable state, the centroid of the whole system is in the perpendicular line of the central point of mobile robot platform and ground. The target object can be tracked using CamShift algorithm. The size, position of the object, and the distance between the object and mobile manipulator can be obtained with visual servoing. A stereo vision system with image based visual servoing (IBVS) is proposed in this paper.	algorithm;inverted pendulum;mobile manipulator;mobile robot;stereopsis;visual servoing	Hu Chen;Jangmyung Lee	2013	2013 Seventh International Conference on Image and Graphics	10.1109/ICIG.2013.155	mobile robot;inverted pendulum;computer vision;pendulum;computer science;video tracking;mobile manipulator;control theory;visual servoing	Robotics	60.842901219725135	-30.987055189588165	188761
c917a05d93612f2a2de1d07b94dd48e11fcc51ca	fuzzy logic kalman filter estimation for 2-wheel steerable vehicles	recursive estimation;fuzzy logic global positioning system wheels remotely operated vehicles road vehicles mobile robots satellite navigation systems filters recursive estimation gyroscopes;fuzzy control;optimal estimation;multisensor data fusion;kalman filters;kalman filter;mobile robots;field trial;fuzzy logic;global positioning system;position estimation;recursive estimation vehicles mobile robots fuzzy control kalman filters filtering theory sensor fusion global positioning system computerised navigation;differential global positioning system;process model;vehicles;sensor fusion;extended kalman filter;side slip angles fuzzy logic kalman filter estimation 2 wheel steerable vehicles multisensor data fusion problem position estimation golf buggy extended kalman filter approach differential global positioning system dgps gyroscope odometry recursive optimal estimation orientation estimation modified kinematic process model;filtering theory;computerised navigation	This article addresses the multi-sensor data fusion problem in the position estimation of a two-wheel steerable vehicle converted from a golfbuggy. The fusion is based mainly on the extended Kalntan filter approach. This paper describes how the estimator integrates sensory data from the DifSerential Global Positioning System (DGPS), gyroscope and odometry to provide recursively an optimal estimate of the position and orientation of the vehicle. In addition, a modified kinematic process model is proposed that accounts and estimates the side-slip angles at the wheels. A technique that incorporates fuzzy logic to maintain the estimation consistency of the filter is also described. Finally, the filter’s performance is evaluated with simulations conducted using true data obtained from field trials.	differential gps;fuzzy logic;global positioning system;gyroscope;kalman filter;odometry;process modeling;recursion;simulation;wheels	Han Wang;Ching Tard Goh	1999		10.1109/IROS.1999.812986	kalman filter;control engineering;computer vision;computer science;engineering;artificial intelligence;control theory;extended kalman filter;moving horizon estimation;fuzzy control system	Robotics	56.97457714390231	-35.29925274349086	188821
bb4bebec5bf5eb892fa20aeccf9c7aed6f3b3f4c	exomars rover pancam: autonomous & computational intelligence [application notes]	image fusion;planetary rovers;software agents;image colour analysis;stereo image processing;stereo image processing astronomical instruments cameras computerised instrumentation filtering theory image colour analysis image fusion object detection planetary rovers software agents;computerised instrumentation;space vehicles optical filters image resolution cameras mars image coding image color analysis;filtering theory;cameras;object detection;astronomical instruments;altitude 5150 m ptu mast position image quality autonomous system mission specific data processor msdp visual data fusion vdf learning enabled object detection lod self learning agent sla environment model library eml pan and tilt unit color images wac filters hrc emulator stereo wac emulators exomars rover rsm reference surface mission ebc mount everest base camp himalayas ucl graduate school university college london high resolution camera stereo wide angle cameras panoramic camera exobiology on mars esa european space agency uksa united kingdom space agency mars exploration aurora programme computational intelligence exomars rover pancam altitude 3490 m	As a part of the Aurora programme for Mars exploration, funded by the United Kingdom Space Agency (UKSA) and European Space Agency (ESA), the UK contributes to the Exobiology on Mars (ExoMars) rover science and engineering programme, with a scheduled launch in 2018; Hence, our Panoramic Camera (PanCam) [9][15] research and development (R&D) is timely. PanCam consists of two stereo Wide Angle Cameras (WAC) and one High Resolution Camera (HRC). While the development is still ongoing, we used funding awarded by the University College London (UCL) Graduate School to conduct investigations in the Himalayas and at Mount Everest Base Camp (EBC), according to the ExoMars rover Reference Surface Mission (RSM). The investigations included capturing stereo and high resolution images using stereo WAC emulators and HRC emulator at altitudes 3490 m, 5150 m and above. Images from different WAC filters, and color images from HRC were acquired at various Pan and Tilt Unit (PTU) mast positions. Our investigation results show significant reduction in data volume with minimum loss in image quality. Furthermore, we introduce a novel autonomous and computational intelligent system called Mission-Specific Data Processor (MSDP) for the rover. It includes Pan-Cam, Visual Data Fusion (VDF), Learning-enabled Object Detection (LOD), Self-Learning Agent (SLA) [22], and Environment Model Library (EML) as part of the rover's computational intelligence [7].	artificial intelligence;aurora;autonomous robot;computation;computational intelligence;esa;emotion markup language;emulator;ibm personal computer;image quality;image resolution;object detection;radio masts and towers;reference surface;response surface methodology;rover (the prisoner);service-level agreement;unified extensible firmware interface	Peter Yuen;Yang Gao;Andrew Griffiths;Andrew Coates;Jan-Peter Muller;Alan Smith;Dave Walton;Craig Leff;Barry Hancock;Dongjoe Shin	2013	IEEE Computational Intelligence Magazine	10.1109/MCI.2013.2279561	computer vision;simulation;computer science;artificial intelligence;software agent;image fusion	Robotics	55.998982252651636	-29.186287592502172	188841
58f78fad5c7e6578be907385c523db4540ae93e0	using kinematic clones to control the dynamic simulation of articulated figures	automatic control;dynamic programming;motion control;articulated figures;computer graphics;kinematic clones;kinematics cloning animation computational modeling computer simulation automatic control automation motion control computer graphics production;dynamic programming computer animation kinematics;emotion kinematic clones dynamic simulation articulated figures animator animation dampened spring forces;kinematics;cloning;dampened spring forces;computational modeling;emotion;animation;production;dynamic simulation;computer animation;computer simulation;animator;automation	A new paradigm is presented for the control of dynamic simulations involving articulated figures. A clone of a figure is manipulated by an animator using traditional kinematic control techniques. The realized dynamic simulation is injluenced by this animation through dampened spring forces that connect each link to its corresponding link in the clone. Varying tensions dictate the tightness of the correlation between the animated actions and the computed movements of the simulation. This paradigm strikes a compromise between the absolute control of kinematics and the realistic automation of dynamics. Such a compromise is often sought by animators who want realistic motion but do not want to lose the ability to impart feeling and emotion in a character.	dynamic simulation;programming paradigm	Bill Westenhofer;James K. Hahn	1996		10.1109/CGI.1996.511784	computer simulation;motion control;computer vision;dynamic simulation;kinematics;simulation;emotion;computer science;automation;dynamic programming;automatic control;cloning;computer animation;computer graphics;computer graphics (images)	Robotics	66.23819832888601	-26.233470898092662	188848
20b16770e3dcd1da8ca9b847235a980d4cf37ba3	position computation models for high-speed train based on support vector machine approach	positioning error;least square support vector machine;high speed train;support vector machine	Graphical abstractDisplay Omitted HighlightsWe increase the positioning accuracy of high-speed train in a new view of advanced computing methods.We formulate a mathematical model based on the analysis of wireless message from train control system.Three positioning computation models and their parameter updating methods are developed.Although LSSVM-based model performs almost the same as SVM-based model, both of them perform much better than the LSM-based model.LSSVM-based model with parameter updating method performs the best among the three models for the online positioning for high-speed trains. High-accuracy positioning is not only an essential issue for efficient running of high-speed train (HST), but also an important guarantee for the safe operation of high-speed train. Positioning error is zero when the train is passing through a balise. However, positioning error between adjacent balises is going up as the train is moving away from the previous balise. Although average speed method (ASM) is commonly used to compute the position of train in engineering, its positioning error is somewhat large by analyzing the field data. In this paper, we firstly establish a mathematical model for computing position of HST after analyzing wireless message from the train control system. Then, we propose three position computation models based on least square method (LSM), support vector machine (SVM) and least square support vector machine (LSSVM). Finally, the proposed models are trained and tested by the field data collected in Wuhan-Guangzhou high-speed railway. The results show that: (1) compared with ASM, the three models proposed are capable of reducing positioning error; (2) compared with ASM, the percentage error of LSM model is reduced by 50.2% in training and 53.9% in testing; (3) compared with LSM model, the percentage error of SVM model is further reduced by 38.8% in training and 14.3% in testing; (4) although LSSVM model performs almost the same with SVM model, LSSVM model has advantages over SVM model in terms of running time. We also put forward some online learning methods to update the parameters in the three models and better positioning accuracy is obtained. With the three position computation models we proposed, we can improve the positioning accuracy for HST and potentially reduce the number of balises to achieve the same positioning accuracy.	computation;support vector machine	Dewang Chen;Lijuan Wang;Lingxi Li	2015	Appl. Soft Comput.	10.1016/j.asoc.2015.01.017	support vector machine;simulation;computer science;machine learning;data mining	NLP	58.58530957613993	-36.6142784452118	188904
539b684130fb0c637bbb377112bfc228c252afb8	evolution of central pattern generators for the control of a five-link planar bipedal walking mechanism	humanoid robotics;genetic algorithms;bipedal walking;central pattern generator	With the aim of producing a stable human-like bipedal gait, a five-link planar walking mechanism was coupled with a central pattern generator (CPG) neural network, consisting of units based on Matsuoka half-center oscillator model with a firm basis in neurophysiologic studies. As a minimalistic approach to bipedal walking, this type of walking mechanism contains only four actuators, and is lacking feet and ankles. Firstly, the mechanism was fashioned as a computer simulation with realistic physics, providing a platform for heuristic tests and allowing accurate fitness evaluations for the creation of CPG controllers through evolutionary algorithms. The oscillatory characteristics of the CPG networks, their internal connectivity structure, and the external feedback pathways were subject to a genetic algorithms (GA) optimization. In the second stage, the evolved CPG networks were transferred to a hardware implementation of the mechanism, to test their performance under real-world dynamics. Results confirmed that the biologically inspired CPG model is very well suited for controlling legged locomotion, since a diverse manifestation of CPG networks (both with and without external feedback) have been observed to succeed during the course of GA evaluations. Observations also implied that while the CPG mechanism is inherently able to sustain a stable gait, the utilization of feedback pathways makes the gait more human-like and is needed to provide a means to adapt to irregularities in the environment.		Atilim Günes Baydin	2008	CoRR			Robotics	65.67391968325968	-25.465272154380656	189155
49b4a6052d35be517a8fb42d31e32463b38ba474	a validation framework for visible light positioning in mobile robotics	robot sensing systems;azimuth;photodiodes free space optical communication light emitting diodes mobile robots;hemispherical dome visible light positioning mobile robotics indoor localization vlp led illumination dissemination photo diode receivers;mobile robot localization visible light positioning visible light communication simulator;mobile robots;receivers;three dimensional displays;lighting;light sources receivers robot sensing systems azimuth three dimensional displays mobile robots lighting;light sources	Visible Light Positioning (VLP) is emerging as a solution for indoor localization. Interest on VLP has risen, amongst other reasons, as a result of the dissemination of LED illumination. This paper proposes a VLP system based on photo-diode receivers arranged in a regular pattern over a hemispherical dome to detect the position of a light source. Additionally, it proposes a 3D test environment, based on Gazebo, allowing the simulation and validation of our system and its application to mobile robot systems. The results show that the proposed system is capable of estimating the location of a mobile robot with an error of a few centimetres in a 3D space of 20×20×5m.	deployment environment;diode;mobile robot;robotics;simulation	Miguel Vieira;Rui Costa;Artur Pereira;Pedro Fonseca	2016	2016 International Conference on Autonomous Robot Systems and Competitions (ICARSC)	10.1109/ICARSC.2016.25	computer vision;geography;optics;remote sensing	Robotics	53.789579707846535	-37.659969430995716	189357
b2d72c9faf0f97c77e07a36a46afa234135d5ae9	particle swarm optimization of matsuoka's oscillator parameters in human-like control of rhythmic movements	particle swarm optimisation approximation theory medical control systems motion control neurocontrollers neurophysiology;oscillators;pso particle swarm optimization matsuoka oscillator human like control rhythmic movement neuroscience nonlinear neural oscillator central pattern generator describing function analysis linear approximation timing sensitive task ball bouncing task;oscillators mathematical model neurons tuning trajectory couplings robots;trajectory;tuning;robots;mathematical model;neurons;couplings	In the field of neuroscience, the Matsuoka's nonlinear neural oscillator is commonly used to model Central Pattern Generator (CPG) in humans/animals. How the parameters of such structure should be selected is not always clear. It was generally done in past studies thanks to a trial-and-error method that needs to be reiterated each time the task changes. Recent studies using a Describing Function Analysis (DFA) of this CPG model provide interesting analytical tuning methods. Nevertheless, as they are based on a linear approximation, they might have a limited efficiency in the particular case of timing-sensitive task, such as the ball-bouncing task considered in this study. A Particle Swarm Optimization (PSO) is thus proposed to select the parameters of a novel neural oscillator-based human-like control architecture able to face disturbances and to adapt to new reference set-points during the ball-bouncing task. The general method presented in the present paper can also be used for other Matsuoka's oscillator tunings and other tasks.	central pattern generator;linear approximation;nonlinear system;oscillator (cellular automaton);particle swarm optimization	Guillaume Avrin;Maria Makarov;Pedro Rodríguez-Ayerbe;Isabelle A. Siegler	2016	2016 American Control Conference (ACC)	10.1109/ACC.2016.7524938	robot;control engineering;artificial intelligence;trajectory;mathematical model;control theory;mathematics;coupling;oscillation;quantum mechanics	Robotics	66.1887455910032	-25.094166586962412	189366
73fdeb5b237c6cf6422884e19109a07e1aa5d9ca	affine visual servoing for robot relative positioning and landmark-based docking	relative position;control systems;systeme commande;posicionamiento;robotics;computer vision;navigation;positioning;model error;feedback loop;stability analysis;feedforward control;vision ordinateur;planning and control;etalonnage;robotique;visual servoing;spatial configuration;calibration;positionnement	This paper addresses the problem of positioning a robot camera with respect to a fixed object in space by means of visual information. The ultimate goal of positioning is to achieve and/or to maintain a given spatial configuration (position and orientation) with respect to the objects in the environment so as to execute at best the task at hand. Positioning involves the control of 6 d.o.f. in space, which are conveniently referred to as the parameters of the transformation between a camera-centered frame and an object-centered frame. In this paper, we will address the positioning problem referring to these d.o.f.'s, regardless of the specific robot configuration used to move the camera (e.g. eye-in-hand setup, navigation platform with a robot head mounted on it, etc.). The domain of application ranges from navigation tasks, (e.g. localization, docking, steering by means of natural landmarks), grasping and manipulation tasks, and autonomous/intelligent tasks based on active visual behaviors such as reading...	docking (molecular);robot;visual servoing	Carlo Colombo;Benedetto Allotta;Paolo Dario	1994	Advanced Robotics	10.1163/156855395X00517	control engineering;computer vision;navigation;von neumann stability analysis;calibration;simulation;computer science;engineering;artificial intelligence;errors-in-variables models;feedback loop;robotics;visual servoing;mobile robot navigation;feed forward	Robotics	61.2509889454538	-32.39786610035335	189395
bb3096bb7dc20602119ebf4a61127945abc513e8	an evolutionary algorithm for autonomous robot navigation		This paper presents an implementation of an evolutionary algorithm to control a robot with autonomous navigation in avoiding obstacles. The paper describes how the evolutionary system controls the sensors and motors in order to complete this task. A simulator was developed to test the algorithm and its configurations. The tests were performed in a simulated environment containing a set of barriers that were observed by means of a set of sensors. The solution obtained in the simulator was embedded in a real robot, which was tested in an arena containing obstacles. The robot was able to navigate and avoid the obstacles in this environment.	autonomous robot;embedded system;evolutionary algorithm;sensor;simulation;virtual reality	Anderson da Silva Soares;Telma Woerle de Lima Soares	2016		10.1016/j.procs.2016.05.404	computer vision;simulation;social robot;robot control;mobile robot navigation	Robotics	58.25785276699612	-27.551027447738953	189512
feeae5db26dd8619bc1d63f915dc9baf0ca433fa	a new way to detect the position and orientation of the wheeled mobile robot on the image plane	mobile robots;robot kinematics mobile robots wheels target tracking visual servoing;camshift image processing wheeled mobile robot robot position robot orientation tracking detection;robot vision mobile robots position control;target tracking;visual servoing;robot kinematics;wheels;image coordinate position detection wheeled mobile robot image plane black rectangle board search window camshift algorithm opencv function	In this paper, a new method to detect wheeled mobile robot's position and orientation is proposed. First, we paste a black rectangle board on the head of the robot as a mark, whose long side is parallel to the robot's orientation. And then on the image plane, we use CAMShift to track the robot after some pre-processing. We will get a search window which includes the target robot only by the use of the CAMShift algorithm. The search window's center is approximately identical to the robot's geometry center. Then we take appropriate approach (here we use the OpenCV function directly) to detect the angle between the black rectangle board's long side and the X axle of the image coordinate on the image plane, there we can get the robot's orientation.	algorithm;image plane;image processing;mobile robot;opencv;paste;preprocessor;requirement	Chaoli Wang;Zhenyu Fu	2014	2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014)	10.1109/ROBIO.2014.7090656	mobile robot;embedded system;computer vision;bang-bang robot;robot end effector;cartesian coordinate robot;simulation;computer science;engineering;artificial intelligence;arm solution;robot control;visual servoing;mobile robot navigation;robot kinematics;robot calibration	Robotics	59.88718690874724	-35.228994510403005	189539
1da4d4db4216578c82853a83a402690692e0a0a3	sit-to-stand task on a humanoid robot from human demonstration	humanoid robot;human kinematics;ground contact force information;center of mass;mobile robots;carnegie mellon sarcos hydraulic humanoid robot sit to stand task humanoid robot ground contact force information inverse kinematics procedure human kinematics center of mass trajectory inertial parameter identification technique;joints;kinematics;force;parameter identification;sit to stand task;human subjects;robot kinematics humanoid robots mobile robots parameter estimation;trajectory;humanoid robots;elderly person;humans humanoid robots trajectory kinematics joints force;inverse kinematics;inertial parameter identification technique;inverse kinematics procedure;humans;parameter estimation;center of mass trajectory;carnegie mellon sarcos hydraulic humanoid robot;robot kinematics	In this work, we perform the challenging task of a humanoid robot standing up from a chair. First we recorded demonstrations of sit-to-stand motions from normal human subjects as well as actors performing stylized standing motions (e.g. imitating an elderly person). Ground contact force information was also collected for these motions, in order to estimate the human's center of mass trajectory. We then mapped the demonstrated motions to the humanoid robot via an inverse kinematics procedure that attempts to track the human's kinematics as well as their center-of-mass trajectory. In order to estimate the robot's center-of-mass position accurately, we additionally used an inertial parameter identification technique that fit mass and center-of-mass link parameters from measured force data. We demonstrate the resulting motions on the Carnegie Mellon/Sarcos hydraulic humanoid robot.	humanoid robot;inverse kinematics	Michael Mistry;Akihiko Murai;Katsu Yamane;Jessica K. Hodgins	2010	2010 10th IEEE-RAS International Conference on Humanoid Robots	10.1109/ICHR.2010.5686270	computer vision;simulation;computer science;humanoid robot;artificial intelligence;robot kinematics	Robotics	61.86567920545267	-25.73449818597905	189555
4e646049ee6f822ef0e6ffc54628cea7b524cee1	online generation of trajectories for autonomous vehicles using a multi-agent system	trajectory shape sociology statistics vehicles euclidean distance registers;trajectory control evolutionary computation learning artificial intelligence multi robot systems remotely operated vehicles;differential evolution trajectory generation autonomous vehicles multi agent system trajectory discovery reinforcement learning	Autonomous vehicles are frequently deployed in environments where only certain trajectories are feasible. Classical trajectory generation methods attempt to find a feasible trajectory that satisfies a set of constraints. In some cases the optimal trajectory may be known, but it is hidden from the autonomous vehicle. Under such circumstance the vehicle must discover a feasible trajectory. This paper describes a multi-agent system that uses a combination of reinforcement learning and differential evolution to generate a trajectory that is ε-close to a target trajectory that is hidden.	autonomous robot;autonomous system (internet);differential evolution;multi-agent system;reinforcement learning	Garrison W. Greenwood;Saber M. Elsayed;Ruhul A. Sarker;Hussein A. Abbass	2014	2014 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2014.6900345	computer vision;simulation	Robotics	55.067057731722386	-24.608004937739373	189686
9e3978e5f2904b5fa2b9d35549b183c5f60a1d8f	non-contact collision avoidance with sensory servo control in real time for industrial automation		This paper presents a combination of repulsive and attractive vector generator in non-contact obstacle avoidance for an intelligent robot manipulator. A 7-DoFs robot arm developed in our lab at NTU is equipped with multiple cameras in the environment. This provides flawless sights for a robot to detect the obstacles and react to end-effector pose. An algorithm is introduced to compute the vector of end-effector to obstacle whether it is repulsive or attractive. The key component of collision avoidance lies on the position of an object in the environment. The performance toward different position shows an intuitive reaction in the manipulator. If the repulsive vectors are generated according to the relationship between obstacles and partial of arm body, the machine will react to commands derived from Vector Trajectory Generator algorithm. In the end of this paper, the system which has been successfully implemented as a proof of the principle is the proper behavior for non-contact avoidance.	algorithm;automation;cognitive robotics;collision detection;image sensor;kinect;network interface device;obstacle avoidance;pose (computer vision);robot end effector;robotic arm;smt placement equipment;sampling (signal processing);servo;workspace	Ren C. Luo;Chun-Hao Liao;Mong-Hsun Kuo	2017	2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)	10.1109/UIC-ATC.2017.8397451	computer science;collision;distributed computing;sight;automation;servo control;robot kinematics;robotic arm;control engineering;trajectory;obstacle avoidance	Robotics	61.2671200977446	-29.635453796385413	189688
3e554665d493120697a8506813d165d450851bf6	an effective simulated annealing for off-line robot motion planning		The path planning problem using mobile robots has been a key issue on robotics since a couple of decades. Algorithms for robot motion planing should be fast, effective and adaptive to face the complexity of changing environments. In this work we propose an effective simulated annealing approach to find paths in different scenarios. Our approach allow us to find short and smooth paths in a variety of problems with different features and resolutions.	algorithm;mobile robot;motion planning;robotics;simulated annealing	Andrea Figueroa;Elizabeth Montero;María Cristina Riff	2017	2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)	10.1109/ICTAI.2017.00148	machine learning;computer vision;robot;motion planning;simulated annealing;computer science;mobile robot;robot kinematics;artificial intelligence;robotics	Robotics	54.68327489713744	-24.26049786120063	189832
10a9ea91ebbec51730239489b387b4c69a6bcafc	underwater position estimation for an underwater vehicle using unscented kalman filter		Marine researchers need consistent historical and georeferenced data from the marine environment in order to constantly monitor the biological condition of the habitat or to document delicate archeological sites. To overcome the difficulties related to the acquisition of high quantity of worthy data and to the accurate estimation of the position, the development of easy-to-use IT tools could certainly help. This article aims to present a tool that can equip different type of underwater vehicles capable of estimating its position during his surveys using its on-board sensors and with the aid of an external buoy. The estimation algorithm is based on the UKF technique and some preliminary simulation results of its performances are presented.	algorithm;habitat;kalman filter;on-board data handling;performance;sensor;simulation	David Scaradozzi;Luca Panebianco;Nicolò Ciuccoli;Silvia Zingaretti;Salih Murat Egi;Corentin Altepe	2017	2017 25th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2017.7960617	artificial intelligence;computer science;computer vision;global positioning system;buoy;algorithm design;georeference;underwater;kalman filter	Robotics	55.899833716174896	-34.19736053691101	189856
7cbb86f692a677bdb5fe84cc053760fda8d323fd	task space hri for cooperative mobile robots in fit-out operations inside ship superstructures	welding;service robots;marine vehicles;robot vision systems;cameras;robot kinematics	In the rising area of close human-robot collaboration in industrial scenarios, the human operator must be able to easily understand the intent of and data from the robot. Shipbuilding environments exhibit unique features, which make deployment of mobile robots both challenging, relevant, and interesting. One task that is still solely carried out manually today due to its complexity and high need for mobility is the fit-out operation stud welding. This paper presents the latest state-of-the-art developments in human-robot interaction (HRI) for robotic stud welding in large semi-structured manufacturing spaces. The welding itself is carried out autonomously by an autonomous industrial mobile manipulator (AIMM). A novel HRI is proposed, which employs projection mapping and an IMU device to enable intuitive and natural interaction with the robot. Task specific information is projected directly into task space as augmented reality using a projector mounted on the robot end-effector. The IMU device enables non-expert operators to program, verify, and reprogram the robot's task on-site in a ship superstructure. The usability of the system is tested in an extensive user test. It is concluded that non-experts after a short introduction are able to both modify a previous task and instruct and a new task using on average 1:01 and 1:16 minutes. Finally, the HRI has been implemented on a prototype robot and tested in an actual shipyard facility. The precision of the system, including operator inaccuracy, was evaluated to have a standard deviation of 3.6mm.	agp inline memory module;augmented reality;autonomous robot;human–robot interaction;mobile manipulator;mobile robot;prototype;robot end effector;semiconductor industry;software deployment;usability;video projector	Rasmus S. Andersen;Simon Boegh;Thomas B. Moeslund;Ole Madsen	2016	2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)	10.1109/ROMAN.2016.7745223	mobile robot;computer vision;simulation;computer science;artificial intelligence;robot control;personal robot;robot kinematics;welding	Robotics	58.992874045912316	-34.670020905180436	189990
ea0db9ebb6dabc7570588f0b5c41ba96da0b062a	singular configurations analyses of the modifiable theo jansen-like mechanism by focusing on the jacobian determinant — a finding limitations to exceed normal joint range of motion	robot dynamics jacobian matrices legged locomotion;control parameter singular configuration analysis modifiable theo jansen like mechanism jacobian determinant adaptive locomotion mobile robot design smooth leg movement bio inspired robot animal walking mechanism multibody dynamics approach eleven bar linkage multilegged animal locomotion pattern mechanism trajectory flexibility normal motion joint range jacobian matrix spatio temporal properties;joints legged locomotion couplings orbits jacobian matrices trajectory dynamics	Adaptive locomotion is an important topic for the design of mobile robots, and smooth leg movement is of interest for investigating an indicator of how much bio-inspired robot represents the essential mechanism in animal walking. Using the multibody dynamics approach, we have investigated a potential extension of the Theo Jansen mechanism, an eleven-bar linkage that generates the locomotion pattern of multi-legged animals. Our extension highlighted a flexibility of the mechanism's trajectory, but an unclear limitation beyond normal joint range of motion was found. In this study, we examined the theoretical limitation of joint range of motion by singular configuration analysis. Multibody dynamics provide the Jacobian matrix to represent whole kinetics with constraints from close linkages and enables a singularity from the Jacobian determinant to be found. The method of finding a singularity in the mechanism may help to understand spatio-temporal properties of the control parameter, thus generating various stable motions toward mobility in an uneven ground.	british informatics olympiad;jacobian matrix and determinant;kinesiology;linkage (software);mobile robot	Kazuma Komoda;Hiroaki Wagatsuma	2014	2014 IEEE/ASME International Conference on Advanced Intelligent Mechatronics	10.1109/AIM.2014.6878050	control engineering;simulation;control theory;mathematics	Robotics	67.70758455114341	-24.647920179565276	190048
3c2b1a996c994444a71942ce1ee1d2796156168f	the use of modular approaches for robots to learn grasping and manipulation		Modular approaches are widely used methods in AI and engineering. This approach reduces the difficulty of solving a complex problem by subdividing the problem into several smaller parts, i.e. modules, and tackle each independently. In this dissertation we show how modular approaches can simplify grasping and manipulation problems of service robots. We use the modular approach to tame the difficulties in solving three main research problems in this field: grasp planning, object manipulation and reach motion planning. Different from industrial controlled environments, service robots have to handle abrupt changes and uncertainties occurring in dynamic and cluttered human centered environments. Planning behaviours in such an environment needs to be fast and adaptive to changing context. Programming robot with adaptive behaviours usually is a difficult task and takes a long time. By adopting modular approaches, the task difficulty is reduced as well as the programming time. The proposed approach is based on the method of imitation learning, sometimes referred to as the Programming by Demonstration (PbD). In this framework, we first let human or robot demonstrate possible solutions of the problem. After collecting the demonstrations, we extract multiple modules from the data. Each module represents a part of the system and their corresponding demonstrations are modeled with a statistical method. According to the environment condition, a set of appropriate modules are chosen to provide the final solution. In this dissertation we present three different modular approaches in tackling three subareas in robot grasping and manipulation: grasp planning, object manipulation adaptive control and planning reaching motions. In Chapter 3, we propose a fast method for computing grasps for known objects and extend this method by a modular approach to work with novel objects. We implemented this method with two different robot hands: the Barrett hand and the iCub hand, and show that the computation time is always in the millisecond scale. In Chapter 4, we present our modular approach in extracting adaptive control strategies using human demonstrations of object manipulation tasks. We successfully implement this method to teach a robot an manipulation tasks: opening bottle caps. In Chapter 5, we present a method to model reaching motion primitives that would allow humans to modulate robot motions by verbal commands.		Bidan Huang	2014			computer vision;simulation;computer science;artificial intelligence	Robotics	63.482620478229684	-26.216336608550566	190225
e498f090f2dd3307a3c18c16b71ed51b4613be6c	constructing an indoor floor plan using crowdsourcing based on magnetic fingerprinting	dtw;affinity propagation clustering;crowdsourcing;floor plan construction;indoor localization	A large number of indoor positioning systems have recently been developed to cater for various location-based services. Indoor maps are a prerequisite of such indoor positioning systems; however, indoor maps are currently non-existent for most indoor environments. Construction of an indoor map by external experts excludes quick deployment and prevents widespread utilization of indoor localization systems. Here, we propose an algorithm for the automatic construction of an indoor floor plan, together with a magnetic fingerprint map of unmapped buildings using crowdsourced smartphone data. For floor plan construction, our system combines the use of dead reckoning technology, an observation model with geomagnetic signals, and trajectory fusion based on an affinity propagation algorithm. To obtain the indoor paths, the magnetic trajectory data obtained through crowdsourcing were first clustered using dynamic time warping similarity criteria. The trajectories were inferred from odometry tracing, and those belonging to the same cluster in the magnetic trajectory domain were then fused. Fusing these data effectively eliminates the inherent tracking errors originating from noisy sensors; as a result, we obtained highly accurate indoor paths. One advantage of our system is that no additional hardware such as a laser rangefinder or wheel encoder is required. Experimental results demonstrate that our proposed algorithm successfully constructs indoor floor plans with 0.48 m accuracy, which could benefit location-based services which lack indoor maps.	3d floor plan;affinity propagation;algorithm;crowdsourcing;dead reckoning;deploy;dynamic time warping;encoder device component;fingerprint;indoor positioning system;inference;location-based service;map;odometry;processor affinity;smartphone;software propagation;sensor (device)	Haiyong Luo;Fang Hui Zhao;Mengling Jiang;Hao Ma;Yuexia Zhang	2017		10.3390/s17112678	computer vision;electronic engineering;encoder;dynamic time warping;software deployment;engineering;odometry;floor plan;affinity propagation;dead reckoning;tracing;artificial intelligence	Mobile	54.60036838581395	-37.66768980660558	190245
4f0f175967759e5982a78fb79db94ced2635b040	development of the quadruped walking robot, titan-ix -- mechanical design concept and application for the humanitarian de-mining robot	mine detection;walking robot;titan ix;mechanism design;de mining;humanitarian demining;high performance;quadruped walking robot	This paper proposes a quadruped walking robot that has high performance as a working machine. This robot is needed for various tasks controlled by tele-operation, especially for humanitarian mine detection and removal. Since there are numerous personnel landmines that are still in place from many wars, it is desirable to provide a safe and inexpensive tool that civilians can use to remove those mines. The authors have been working on the concept of the humanitarian demining robot systems for 4 years and have performed basic experiments with the  rst prototype VK-I using the modi ed quadruped walking robot, TITAN-VIII. After those experiments, it was possible to re ne some concepts and now the new robot has a tool (end-effector)changing system on its back, so that by utilizing the legs as manipulation arms and connecting various tools to the foot, it can perform mine detection and removal tasks. To accomplish these tasks, we developed various end-effectors that can be attached to the working leg. In this paper we will discuss the mechanical design of the new walking robot called TITAN-IX to be applied to the new system VK-II.	coat of arms;experiment;list of doctor who robots;mobile robot;prototype;requirement;television;titan rain	Keisuke Kato;Shigeo Hirose	2001	Advanced Robotics	10.1163/15685530152116227	mechanism design;simulation;engineering;artificial intelligence;social robot;robot control	Robotics	65.49330690924063	-29.338953590825433	190396
7e8d85b240949dd971085a471a2ef1e9658766d2	accuracy quantification and improvement of serial micropositioning robots for in-plane motions	accuracy open loop systems calibration position control;sensors micropositioning microrobots nanopositioning open loop systems;mpr calibration approach accuracy quantification serial micropositioning robots in plane motions complex tasks high resolution micrositioning robots high resolution nanopositioning robots multidegree of freedom motions measuring system pseudoperiodic patterns open loop control approach sensor integration angle dependent errors position dependent errors geometric errors;open loop systems;accuracy;position control;calibration	High positioning accuracy with micropositioning robots (MPRs) is required to successfully perform many complex tasks, such as microassembly, manipulation, and characterization of biological tissues and minimally invasive inspection and surgery. Despite the widespread use of high-resolution micro- and nanopositioning robots, there is very little knowledge about the real positioning accuracy that can be obtained and what the main influential factors are. Indeed, very few notable methods are available to measure multi-degree-of-freedom motions with adapted range, resolution, and dynamic capabilities. The main objective of this paper is to quantify the positioning accuracy of serial MPRs and to identify the main influential factors (a typical XY Θ serial robot is chosen as a case study). To reach this goal, a measuring system that combines vision and pseudoperiodic patterns with an extremely large range-to-resolution ratio is introduced as a new way to quantify the positioning accuracy of MPRs for in-plane motions. Then, an open-loop control approach based on MPR calibration is chosen for several reasons: the use of different models to identify influential factors, the quantification of the positioning accuracy, and the necessity of the method when sensor integration is too complex. Experiments using five different calibration models were conducted to classify factors influencing the positioning accuracy of MPRs. The results show that positioning accuracy can be improved by more than 35 times from 96 μ with no imperfection compensation to 2.5 μ by compensating for geometric, position-dependent, and angle-dependent errors through the MPR calibration approach.	image resolution;minkowski portal refinement;robot	Ning Tan;Cédric Clévy;Guillaume J. Laurent;Patrick Sandoz;Nicolas Chaillet	2015	IEEE Transactions on Robotics	10.1109/TRO.2015.2498301	control engineering;open-loop controller;computer vision;calibration;simulation;engineering;mathematics;accuracy and precision;statistics	Robotics	61.43087299114263	-34.6429671682749	190553
da232762ab22e40b6b65e5d7a63fb88ab45e12e7	design and validation of an rgb-d based localization system - integration in a docking system	lyapunov methods;tecnologia industrial tecnologia mecanica;tecnologia electronica telecomunicaciones;nonlinear control systems;mobile robots;tecnologias;grupo a;robot kinematics	This paper proposes a localization system for a mobile robot based on odometric data and RGB-D (Red, Green, Blue image and Depth map) measurements relative to a landmark, available from sensors installed on board. The localization system is composed of two cascaded estimators: i) a kinematic optimal attitude estimator; and ii) a position This work was partially supported by the program COMPETE/QREN/FEDER under PRODUTECH-PTI (P. 3904) and FCT, through IDMEC, under LAETA Pest-OE/EME/LA0022 and ISR/LARSyS PEst-OE/EEI/LA0009. J. Barbosa · C. Cardeira ( ) · P. Oliveira IDMEC/LAETA-Instituto Superior Técnico, Universidade de Lisboa, 1049-001 Lisboa, Portugal e-mail: carlos.cardeira@tecnico.ulisboa.pt J. Barbosa e-mail: joao.vitor.barbosa@tecnico.ulisboa.pt P. Oliveira · P. Batista · C. Silvestre ISR/LARSyS-Instituto Superior Técnico, Universidade de Lisboa, 1049-001 Lisboa, Portugal e-mail: pjcro@isr.tecnico.ulisboa.pt P. Batista e-mail: pbatista@isr.tecnico.ulisboa.pt C. Silvestre e-mail: cjs@isr.ist.utl.pt C. Silvestre Department of Electrical and Computer Engineering, Faculty of Science and Technology, University of Macau, Macau, China estimator designed in body-frame, based on an underlying LPV (Linear Parameter Varying) model, that avoids the need of approximations or linearization. Both underlying models are observable, even considering the presence of angular and linear slippages and the resulting estimators present globally asymptotically stable estimation error dynamics. Experiments to assess the performance of the proposed estimators were carried out resorting to a wheeled differential drive mobile robot in a laboratory instrumented with a Qualysis Motion Tracking System, used for groundtruth validation. An effective real-time localization system is obtained, featuring convergence to zero of the estimated errors, regardless the initial estimate and without requiring the landmark to be always visible, thus validating the system global stability. The results obtained paved the way to the integration of the proposed localization solution in a docking system for the same robot. The docking problem is solved with a smooth, time-invariant, globally asymptotically stable feedback control law, which allows for a very humanlike closed-loop steering that drives the robot to a certain goal with a desired attitude and tunable curvature. Simulation and experimental results with the aforementioned robot are also presented, that illustrate the performance of the docking solution based on the proposed localization methods central to this work.	angularjs;approximation;computer engineering;computer simulation;control theory;depth map;docking (molecular);email;encrypted media extensions;experiment;feedback;information systems research;international symposium on fundamentals of computation theory;internationalization and localization;mobile robot;observable;optimal control;real-time clock;sensor;system integration;time-invariant system;tracking system	João Barbosa;Carlos Cardeira;Paulo Jorge Ramalho Oliveira;Pedro Tiago Martins Batista;Carlos Silvestre	2015	Journal of Intelligent and Robotic Systems	10.1007/s10846-015-0181-7	control engineering;mobile robot;simulation;computer science;engineering;artificial intelligence;control theory;robot kinematics	Robotics	55.93949270082182	-29.240683901645454	190621
111f0d6f1dfb675c24a720f5c9c4c47f63e4b4b8	hierarchical traffic control for partially decentralized coordination of multi agv systems in industrial environments	path planning hierarchical traffic control partially decentralized coordination multi agv systems industrial environments automated guided vehicles;splines mathematics path planning optimization vectors computer architecture materials prediction algorithms;vehicles decentralised control hierarchical systems mobile robots multi robot systems path planning traffic control	This paper deals with decentralized coordination of Automated Guided Vehicles (AGVs). We propose a hierarchical traffic control algorithm, that implements path planning on a two layer architecture. The high-level layer describes the topological relationships among different areas of the environment. In the low-level layer, each area includes a set of fixed routes, along which the AGVs have to move. An algorithm is also introduced for the automatic definition of the route map itself. The coordination among the AGVs is obtained exploiting shared resources (i.e. centralized information) and local negotiation (i.e. decentralized coordination). The proposed strategy is validated by means of simulations using real plant.	algorithm;centralized computing;high- and low-level;mathematical optimization;motion planning;performance;physical plant;simulation	Valerio Digani;Lorenzo Sabattini;Cristian Secchi;Cesare Fantuzzi	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907764	control engineering;simulation;engineering;distributed computing;hierarchical control system	Robotics	57.10968293640559	-24.62095439712023	190648
1330f312963f0a9cd51288db7b6ee027574f6316	a simple hand-eye calibration method for a 3d laser range sensor	laser range sensor;simple hand-eye calibration method	A simple and a reliable full pose (translation and orientation) calibration for a range sensor is necessary for the measurement applications of industrial robots. In this paper we present a method based on hand-eye-calibration. We estimate the parameters using the Bayesian -form iterative model, which also provides possibilities to estimate error covariances of the pose parameters. In addition to this, we can use the sensor error covariance to estimate to combined uncertainty in e.g. measurement applications.		Mikko Sallinen;Tapio Heikkilä	2000			calibration curve	Robotics	55.45881113851888	-37.47547025417181	191118
199104c2ae8f997a1c91d57ad8c3790fd2deca36	dynamics of a quadruped robot during locomotion	locomotion quadruped robot dynamics ground reaction force grf stance phase walk gait center of gravity cog dynamics equations swing phase central pattern generator model cpg discrete tracking differentiator discrete td vertical reaction force joint torque;legged locomotion;oscillators;joints;force;force legged locomotion joints mathematical model dynamics oscillators;dynamics;torque control discrete systems force control gait analysis legged locomotion motion control robot dynamics;mathematical model;quadruped robot	In this paper we analyze characteristics of the ground reaction force (GRF) experienced by the legs of the quadruped robot during stance phase in walk gait, in particular, when the height of center of gravity (COG) of the quadruped robot is changeable. We also build the dynamics model of the quadruped robot. Two dynamics equations during swing phase and stance phase are established, respectively. Additionally, we design a controller to adjust the height of COG of the quadruped robot. The controller uses the central pattern generator (CPG) model to generate basic rhythmic motion, and utilizes the discrete tracking differentiator (TD) to implement the transition between two different rhythmic medium values of the CPG. The combination of the CPG model and the discrete TD enables the quadruped robot to adjust the height of COG according to the environment. The ground reaction peak force and the joint torque of the quadruped robot increase with the reduction of the height of COG. Finally, we give a simulation example and the results, including an analysis of the vertical reaction force and the joint torque of the quadruped robot.	central pattern generator;computation;differentiator;inverse dynamics;robot;simulation;traverse	Xiaoqi Li;Wei Wang;Jianqiang Yi;Hongjian Zhang	2014	2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014)	10.1109/ROBIO.2014.7090427	control engineering;dynamics;simulation;engineering;mathematical model;control theory;oscillation;force;quantum mechanics	Robotics	67.23622736157023	-23.974730199864002	191229
e8061ee00180cf337a36b0c25bda0c043f0a27ea	dynamic positioning of remotely operated underwater vehicles	underwater vehicles;data analysis;software architecture;industrial robots;matlab application software software architecture analytical models data analysis service robots educational robots software tools;factory automation;software tools;user interfaces;model reference adaptive control remotely operated vehicles underwater vehicles rov dynamic positioning system mechanical passive arm tracking variable structure systems;force control	We present a toolbox that enables access to real robotics and automation (R&A) equipment from the MATLAB shell. If used in conjunction with a robotics toolbox, it will extend significantly their application, i.e., besides robotic simulation and data analysis, the user can interact online with the equipment he or she is using. This article briefly presents the software architecture adopted and how it was used to generate the MATLAB MEX files presented. It then exemplifies application to two types of equipment, complemented with a generic manipulation example using a robotic gripper. The utilization of this tool with force control experiments is also briefly explored.		Liu Hsu;Ramon R. Costa;Fernando C. Lizarralde;José Paulo Vilela Soares da Cunha	2000	IEEE Robot. Automat. Mag.	10.1109/100.876909	control engineering;embedded system;software architecture;simulation;computer science;engineering;automation;data analysis;user interface	Robotics	65.32174140197647	-28.967128875839702	191293
b8fd7fafc0bb2f0e43cc47c9fdf4f889f8839cff	implementation of an inertial measurement unit based motion capture system	units measurement accelerometers gyroscopes magnetometers sensors;gyroscopes;rigid body;serial chain network;sensors;real time;magnetometers;sensors inertial measurement unit rigid body gyroscope accelerometer magnetometer orientation calculation multiple imu devices human arm motion realtime motion capture system serial chain network;computers real time systems prototypes humans tracking sensors gyroscopes;inertial measurement unit;motion capture;serial chain network motion capture inertial measurement unit;units measurement;accelerometers	Nowadays, due to its broad applications, demands on motion capture technology is increasing. Inertial Measurement Unit (IMU) is one of technology that is capable of estimating orientation of a rigid body. IMU technology uses information from three sensors, i.e. gyroscope, accelerometer and magnetometer to calculate the orientation. By using multiple IMU devices, human arm motion can be tracked. This paper presents an implementation of a real-time motion capture system. We proposed a serial-chain network to collect orientation data from the IMU devices. The proposed network focuses on flexibility and easy-to-use factor. Real-time experimental results show that our prototype is capable of capturing human arm motion.	coexist (image);gyroscope;meltwater entrepreneurial school of technology;motion capture;prototype;real-time clock;real-time transcription;sensor	Iman Prayudi;Eun-Ho Seo;Doik Kim;Bum-Jae You	2011	2011 8th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2011.6145856	embedded system;inertial measurement unit;inertial reference unit;rigid body;magnetometer;motion capture;simulation;gyroscope;computer science;sensor;accelerometer	Robotics	57.76346886431225	-36.78380679954113	191330
cea531d0f4ecb751d036890ab521d59ba2b4c8ce	shape-based compliant control with variable coordination centralization on a snake robot	robot sensing systems;oscillators;shape;aerospace electronics;mathematical model;robot kinematics	For highly articulated robots, there is a tradeoff between the capability to navigate complex unstructured environments and the high computational cost of coordinating many degrees-of-freedom. In this work, an approach that we refer to as shape-based control helps to balance this trade-off using shape functions, geometric abstractions that determine the coupling between multiple degrees-of-freedom during locomotion. This approach provides a way to intuitively adapt the shape of highly articulated robots using joint-level torque feedback control, allowing a robot to compliantly feel its way through unstructured terrain. In this work we specifically focus on compliance in the spatial frequency and temporal phase parameters of a snake-like robot's wave-like periodic wave-like kinematics. We show how varying the spatial frequency within the shape-based control architecture allows a single controller to vary the degree to which different degrees-of-freedom are coupled throughout a mechanism's body, i.e., the controller's degree of centralization. We experimentally find that for a snake-like robot locomoting through an irregularly spaced peg array, shape-based control results in more effective locomotion when compared to a central pattern generator-based approach.	algorithmic efficiency;central pattern generator;control theory;experiment;feedback;heart rate variability;robot;sensor	Julian Whitman;Francesco Ruscelli;Matthew J. Travers;Howie Choset	2016	2016 IEEE 55th Conference on Decision and Control (CDC)	10.1109/CDC.2016.7799059	control engineering;simulation;articulated robot;shape;engineering;mathematical model;control theory;mathematics;oscillation;robot kinematics	Robotics	65.6604676360949	-24.409796992565546	191589
088f70d794a4e59f0de90e3f4dc6087fe9217f87	vision guided navigation for a nonholonomic mobile robot	observability;piecewise linear;navigation mobile robots shape control phase estimation visual servoing phase measurement controllability control systems observability image sensors;noisy images vision guided navigation nonholonomic mobile robot visual servoing pose estimation nonholonomic ground mobile base arbitrarily shaped continuous ground curve curve shape control controllability linear curvature parameters stabilizing control laws piecewise analytic curve tracking piecewise linear curvature curve tracking observability extended kalman filter image quantity dynamic estimation feedback control;piecewise linear techniques;mobile robot;controllability;kalman filters;mobile robots;indexing terms;stability;control problem;feedback;robot vision;nonholonomic mobile robot;servomechanisms;feedback mobile robots computerised navigation robot vision servomechanisms controllability stability piecewise linear techniques observability kalman filters filtering theory;trajectory tracking;extended kalman filter;visual servoing;feedback control;filtering theory;control strategy;computerised navigation;pose estimation	Visual servoing, i.e., the use of the vision sensor in feedback control, has gained recently increased attention from researchers both in vision and control community. A fair amount of work has been done in applications in autonomous driving, manipulation, mobile robot navigation and surveillance. However, theoretical and analytical aspects of the problem have not received much attention. Furthermore, the problem of estimation from the vision measurements has been considered separately from the design of the control strategies. Instead of addressing the pose estimation and control problems separately, we attempt to characterize the types of control tasks which can be achieved using only quantities directly measurable in the image, bypassing the pose estimation phase. We consider the task of navigation for a nonholonomic ground mobile base tracking an arbitrarily shaped continuous ground curve. This tracking problem is formulated as one of controlling the shape of the curve in the image plane. We study the controllability of the system characterizing the dynamics of the image curve, and show that the shape of the image curve is controllable only up to its “linear” curvature parameters. We present stabilizing control laws for tracking piecewise analytic curves, and propose to track arbitrary curves by approximating them by piecewise “linear” curvature curves. Simulation results are given for these control schemes. Observability of the curve dynamics by using direct measurements from vision sensors as the outputs is studied and an Extended Kalman Filter is proposed to dynamically estimate the image quantities needed for feedback control from the actual noisy images.	3d pose estimation;autonomous car;extended kalman filter;feedback;image plane;image sensor;mobile robot;robotic mapping;simulation;visual servoing	Yi Ma;Jana Kosecka;S. Shankar Sastry	1999	IEEE Trans. Robotics and Automation	10.1109/70.768184	control engineering;mobile robot;computer vision;computer science;control theory;feedback;mathematics	Robotics	61.01684099262169	-32.559491469236036	191702
867fe3f316a3a2e4e548e89e8db5773b62b14234	a simulation environment for middle-size robots with multi-level abstraction	time triggered;sensor model;robot control;simulation environment	Larger fields in the Middle-size league as well as the effort to build mixed teams from different universities require a simulation environment which is capable to physically correctly simulate the robots and the environment. A standardized simulation environment has not yet been proposed for this league. In this paper we present our simulation environment, which is based on the Gazebo system. We show how typical Middle-size robots with features like omni-drives and omni-directional cameras can be modeled with relative ease. In particular, the control software for the real robots can be used with few changes, thus facilitating the transfer of results obtained in simulation back to the robots. We address some technical issues such as adapting time-triggered events in the robot control software to the simulation, and we introduce the concept of multi-level abstractions. The latter allows switching between faithful but computionally expensive sensor models and abstract but cheap approximations. These abstractions are needed especially when simulating whole teams of robots.	approximation;list of version control software;robot control;simulation	Daniel Edward Robert Beck;Alexander Ferrein;Gerhard Lakemeyer	2007		10.1007/978-3-540-68847-1_12	real-time computing;simulation;computer science;artificial intelligence;robot control;aisoy1	Robotics	61.43128952762295	-28.704882129654845	191831
496915bbee55a43d5acde3f70a9792a157f3a9a5	opportunities for enhanced robot control along the adjustable autonomy scale	telerobotics human robot interaction robot control context awareness;context awareness;human robot interaction;flexible work sharing principle enhanced robot control opportunities adjustable autonomy scale direct teleoperation robot control automation control quality user feedback machine learning telerobotics situational awareness knowledge acquisition human operator;intelligent control;robot control;humans cameras robot vision systems automation;ubiquitous computing human robot interaction intelligent control learning artificial intelligence telerobotics;telerobotics;ubiquitous computing;learning artificial intelligence	As we move along the scale of adjustable autonomy for the control of robots from direct teleoperation at one extreme to full automation at the other, several opportunities for improvement in control quality, user feedback and machine learning suggest themselves. We describe three experiments, in telerobotics, the provision of situational awareness, and the acquisition of knowledge for automation from the human operator, and explain our concept of explicit, assigned responsibility as an organising principle for flexible work-sharing between humans and robots. A novel design for an interface based on this principle is outlined.	experiment;machine learning;robot control;telerobotics	Graham A. Mann;Nicolas J. Small	2012	2012 5th International Conference on Human System Interactions	10.1109/HSI.2012.15	control engineering;mobile robot;robot learning;computer vision;simulation;engineering;social robot;robot control;ubiquitous robot	Robotics	60.78004428848646	-27.2078077799433	191886
c3dd247b53633d5e6bf75ec868b7018783d92d64	a strategy for vision-based controlled pushing of microparticles	charge coupled image sensors;ccd camera;high resolution;robot vision atomic force microscopy microassembling micromanipulators position control;wavefront expansion;nonholonomic differential drive robot;optical microscope;charge coupled devices;probes;glass;4 5 micron;robot vision;position control;real time vision;vision based control;particle system;micromanipulators;microassembling;microassembly;microparticle pushing;atomic force microscopy;particle position tracking;flat glass substrate;robot vision systems;optical feedback;4 5 micron vision based control microparticle pushing microassembly polystyrene particles flat glass substrate atomic force microscope ccd camera optical microscope particle position tracking nonholonomic differential drive robot cell decomposition wavefront expansion position control;optical microscopy;atomic force microscope;cell decomposition;polystyrene particles;atomic force microscopy optical feedback optical microscopy force control microassembly glass probes charge coupled devices robot vision systems charge coupled image sensors;force control	In this paper, a strategy for controlled pushing is presented for microassembly of 4.5 mum polystyrene particles on a flat glass substrate using an atomic force microscope probe tip. Real-time vision based feedback from a CCD camera mounted to a high resolution optical microscope is used to track particle positions relative to the tip and target position. Tip-particle system is modeled in 2D as a nonholonomic differential drive robot. Effectiveness of the controller is demonstrated through experiments performed using a single goal position as well as linking a series of target positions to form a single complex trajectory. Cell decomposition and wavefront expansion algorithms are implemented to autonomously locate a navigable path to a specified target position. Control strategy alleviates problem of slipping and spinning during pushing.	algorithm;atomic-force microscopy;charge-coupled device;experiment;haptic technology;image resolution;particle system;pixel;real-time transcription;velocity (software development)	Nicholas A. Lynch;Cagdas D. Onal;Eugenio Schuster;Metin Sitti	2007	Proceedings 2007 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2007.363182	control engineering;computer vision;atomic force microscopy;optical microscope;optics;physics	Robotics	59.611911435795676	-33.86574164172572	191910
00385089e777a23e154cc50f8a0996458937a6ca	evolutionary controllers for snake robots basic movements	genetics algorithms.;snake robots;proportional-integral-derivate controllers	A method to generate movements in a snake robot using proportional-integral- derivate controllers (PID) and adjust the constants values to be natural is proposed. Specifically, the method is applied to adjust the movement of a snake robot to natural postures defining a simplify PID controller and adjusting the constants values of the controller. Our approach is based on proportional-integral-derivate controllers, using genetics algorithms to solve the problem. In this paper we explain how adjust the restrictions that must be accomplished for generate a natural movement and make an exhaustive study about snake robots, proportional-integral-derivate controllers and genetics algorithms.	robot	Juan C. Pereda;Javier de Lope Asiaín;María Victoria Rodellar Biarge	2008		10.1007/978-3-540-74972-1_23	control engineering;simulation;engineering;control theory	Robotics	65.42862325681719	-24.35159345389098	192117
ed647a325b28fa1450d2f9087d5b525993a6024b	visual 3d self localization with 8 gram circuit board for very compact and fully autonomous unmanned aerial vehicles	printed circuits autonomous aerial vehicles helicopters;field programmable gate arrays cameras feature extraction robot sensing systems three dimensional displays hardware;visual 3d self localization palm sized quad copter ground truth sensor hovering robots hardware system autonomous unmanned aerial vehicles	We describe an algorithm and hardware system of a 3D self-localization method for very cost effective hovering robots. The hardware system consists of very compact calculation and sensor units, instead of using a high performance calculation unit like a laptop PC. In the experiment, the comparison with the ground truth sensor is discussed and implementation of the system on a palm-sized quad-copter is studied to realize a very compact, on-board, fully autonomous quad-copter.	algorithm;autonomous robot;bundle adjustment;computer;field-programmable gate array;ground truth;laptop;microcontroller;on-board data handling;printed circuit board;supercomputer;television antenna;unmanned aerial vehicle;unmanned spacecraft	Ryo Konomura;Koichi Hori	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907625	embedded system;computer vision;simulation;engineering	Robotics	57.14866825347419	-32.11295552138017	192313
a6fee6845989c1227ae209a795296e867ddf381a	nasa advances robotic space exploration	nasa orbital robotics space exploration earth solar system planets hardware system software application software robot sensing systems;mobile robots;aerospace industry;aerospace computing;rovers nasa robotic space exploration onboard processing hardware system software imaging radar multispectral imager spectrometers gravity wave detectors;mobile robots aerospace industry aerospace computing	NASA's successful exploration of space has uncovered vast amounts of new knowledge about the Earth, the solar system and its other planets, and the stellar spaces beyond. To continue gaining new knowledge has required - and will continue to require - new capabilities in onboard processing hardware, system software, and applications such as autonomy. For example, initial robotic space exploration missions functioned, for the most part, as large flying cameras. These instruments have evolved over time to include more sophisticated imaging radar, multispectral imagers, spectrometers, gravity wave detectors, a host of prepositioned sensors and, most recently, rovers.	robotic spacecraft	Daniel S. Katz;Raphael R. Some	2003	IEEE Computer	10.1109/MC.2003.1160056	mobile robot;simulation;computer science;aerospace	Vision	55.39225468795061	-30.652987510144175	192727
50f4e4d00cfc3e5dbc55047661e7a99ce8baf6b3	collaboration of multiple autonomous industrial robots through optimal base placements	autonomous industrial robots;base placement optimization;complete coverage;multi-robot collaboration;68t40;65k99	Multiple autonomous industrial robots can be of great use in manufacturing applications, particularly if the environment is unstructured and custom manufacturing is required. Autonomous robots that are equipped with manipulators can collaborate to carry out manufacturing tasks such as surface preparation by means of grit-blasting, surface coating or spray painting, all of which require complete surface coverage. However, as part of the collaboration process, appropriate base placements relative to the environment and the target object need to be determined by the robots. The problem of finding appropriate base placements is further complicated when the object under consideration is large and has a complex geometric shape, and thus the robots need to operate from a number of base placements in order to obtain complete coverage of the entire object. To address this problem, an approach for Optimization of Multiple Base Placements (OMBP) for each robot is proposed in this paper. The approach aims to optimize base placements for multi-robot collaboration by taking into account task-specific objectives such as makespan, fair workload division amongst the robots, and coverage percentage; and manipulator-related objectives such as torque and manipulability measure. In addition, the constraint of robots maintaining an appropriate distance between each other and relative to the environment is taken into account. Simulated and real-world experiments are carried out to demonstrate the effectiveness of the approach and to verify that the simulated results are accurate and reliable.	autonomous robot;industrial robot	Mahdi Hassan;Dikai Liu;Gavin Paul	2018	Journal of Intelligent and Robotic Systems	10.1007/s10846-017-0647-x	control engineering;workload;job shop scheduling;robot;torque;engineering;spray painting;geometric shape	Robotics	64.10344467022733	-27.095577845309577	192736
14e9bed7b3621bbbedcfcfcee45184421ab00abf	perception for a river mapping robot	size weight and power;high resolution;measurement by laser beam;rivers;rivers vehicles visualization global positioning system adaptation models three dimensional displays measurement by laser beam;global position system;aquatic vegetation;three dimensional;computer vision;visualization;shallow water;global positioning system;three dimensional displays;simultaneous localization and mapping;map estimation;laser scanning;vehicles;adaptation models;inertial sensor;pose estimation	Rivers with heavy vegetation are hard to map from the air. Here we consider the task of mapping their course and the vegetation along the shores with the specific intent of determining river width and canopy height. A complication in such riverine environments is that only intermittent GPS may be available depending on the thickness of the surrounding canopy. We present a multimodal perception system to be used for the active exploration and mapping of a river from a small rotorcraft flying a few meters above the water. We describe three key components that use computer vision, laser scanning, and inertial sensing to follow the river without the use of a prior map, estimate motion of the rotorcraft, ensure collision-free operation, and create a three dimensional representation of the riverine environment. While the ability to fly simplifies the navigation problem, it also introduces an additional set of constraints in terms of size, weight and power. Hence, our solutions are cognizant of the need to perform multi-kilometer missions with a small payload. We present experimental results along a 2km loop of river using a surrogate system.	algorithm;apache axis;autonomous robot;computer vision;global positioning system;image scaling;motion planning;motorola canopy;multimodal interaction;thickness (graph theory);visual odometry	Andrew Chambers;Supreeth Achar;Stephen Nuske;Jörn Rehder;Bernd Kitt;Lyle Chamberlain;Justin Haines;Sebastian Scherer;Sanjiv Singh	2011	2011 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6095040	laser scanning;three-dimensional space;computer vision;simulation;pose;visualization;image resolution;global positioning system;computer science;waves and shallow water;aquatic plant;remote sensing;simultaneous localization and mapping	Robotics	53.851885099486665	-31.240928057288905	193210
78a42372246148377d2c0d3f0cb859ec24e7db58	3d imaging with a sonar sensor and an automated 3-axes frame for selective spraying in controlled conditions	3d imaging;agricultural robot;point cloud;selective spraying;single plant;ultrasonic;sonar	Autonomous selective spraying could be a way for agriculture to reduce production costs, save resources, protect the environment and help to fulfill specific pesticide regulations. The objective of this paper was to investigate the use of a low-cost sonar sensor for autonomous selective spraying of single plants. For this, a belt driven autonomous robot was used with an attached 3-axes frame with three degrees of freedom. In the tool center point (TCP) of the 3-axes frame, a sonar sensor and a spray valve were attached to create a point cloud representation of the surface, detect plants in the area and perform selective spraying. The autonomous robot was tested on replicates of artificial crop plants. The location of each plant was identified out of the acquired point cloud with the help of Euclidian clustering. The gained plant positions were spatially transformed from the coordinates of the sonar sensor to the valve location to determine the exact irrigation points. The results showed that the robot was able to automatically detect the position of each plant with an accuracy of 2.7 cm and could spray on these selected points. This selective spraying reduced the used liquid by 72%, when comparing it to a conventional spraying method in the same conditions.	3d reconstruction;algorithm;autonomous robot;cluster analysis;euclidean distance;mobile robot;point cloud;point of view (computer hardware company);random sample consensus;real-time clock;sonar (symantec);sensor;stereoscopy	David Reiser;Javier M. Martín-López;Emir Memic;Manuel Vázquez-Arellano;Steffen Brandner;Hans W. Griepentrog	2017	J. Imaging	10.3390/jimaging3010009	control engineering;simulation;engineering;remote sensing	Robotics	57.65748717172399	-29.519707706112726	193385
04578a6b31233d4b2b47d1590fa6fa47a14ff9cc	path-planning for elastically constrained space manipulator systems	space vehicles aerospace control manipulators path planning;manipulators;path planning manipulator dynamics space technology vehicle dynamics control systems satellites space vehicles space stations orbital robotics mechanical engineering;path planning;algorithms motion planning remote manipulator telerobotics path planning space shuttle elastically constrained space manipulator systems general purpose dexterous arm long flexible arm coupling map relatively low residual vibrations supporting structures prototype simulation;control problem;flexible manipulator;aerospace control;experimental evaluation;space vehicles	Current design proposals of space manipulator systems use a relatively small dextrous manipulator attached to the end of a long flexible manipulator or supporting structure to perform a variety of tasks. Such a configuration presents a number of control problems due to the dynamic interaction between the components of the systems. Principally, the motion of the small manipulator can excite difficult to control vibrations of the large manipulator. This paper presents an analytical technique called the Coupling Map to plan motions of an elastically constrained space manipulator system that result in relatively low residual vibrations to its supporting elastic system. A prototype system is design in some detail as a baseline for simulation evaluation of the performance of the path planning algorithms developed in this study. Experimental evaluation of these algorithms are currently underway.	algorithm;baseline (configuration management);excite;motion planning;prototype;simulation	Miguel A. Torres;Steven Dubowsky	1993		10.1109/ROBOT.1993.292077	control engineering;parallel manipulator;simulation;robotic arm;computer science;engineering;artificial intelligence;mobile manipulator;control theory;motion planning	Robotics	63.49979159458879	-28.41264656792398	193534
fc5bad0edf147bda7ee2c15e100d7907bfe5809a	covert path planning in unknown environments with known or suspected sentry location	mobile robot;path planning;mobile robots;path planning costs navigation mobile robots intelligent robots orbital robotics testing humans surveillance observability;military systems mobile robots path planning;military systems;distance transform;distance transform visibility based covert path planning covert robotics mobile robot	This paper describes an approach for solving a visibility-based covert path planning problem. It is an extension to our research on covert robotics which aims to create robots with the ability to achieve different covert navigation missions. A promising method is presented that allows a mobile robot in a complex, initially unknown environment to discover a path to a nominated destination with minimum exposure to sentries' at known locations within the same environment. The sentries' locations are known initially, suspected, or discovered during navigation. The presented method estimates a cost value at each non-obstacle location that represents a risk of being visible, given the accumulated map knowledge. A global covert path is generated by propagating the estimated cost values using the distance transform algorithm. The approach has been evaluated on both simulated and real environments. A number of test cases are presented; each shows a generated path with considerable covertness compared to a short path (but perhaps risky) to the same destination.	algorithm;covert channel;distance transform;experiment;mobile robot;motion planning;robotics;sentry gun;simulation;test case;time complexity	Mohamed Marzouqi;Ray A. Jarvis	2005	2005 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2005.1545483	mobile robot;computer vision;simulation;computer science;engineering;artificial intelligence	Robotics	54.03441225867578	-25.40929547223492	193669
34ed8bb52aa7975fd3cc42b47db52b5d5315635d	knowledge sharing and cooperation of autonomous robots by intelligent data carrier system	robot sensing systems;intelligent robots;mobile robot;multiple autonomous mobile robot cooperation;idc;mobile robots;autonomous mobile robot;intelligent data carrier system;cooperative systems;local community;local communication;materials handling;transportation;multi robot systems;production facilities;knowledge sharing;intelligent systems;idc knowledge sharing multiple autonomous mobile robot cooperation intelligent data carrier system local communication;power generation;nuclear power generation;power system modeling;mobile computing;intelligent robots intelligent systems mobile robots power system modeling robot sensing systems production facilities power generation nuclear power generation transportation memory;autonomous robot;memory;mobile computing mobile robots multi robot systems cooperative systems materials handling computerised navigation;computerised navigation	"""In this paper, we propose a device for cooperation of multiple autonomous mobile robots. A device which enables local communication, named """"intelligent data carrier (IDC)"""", is proposed. In this paper, we propose an algorithm to improve efficiency of iterative transportation tasks by autonomous mobile robots. An autonomous mobile robot gives name of its latest visited destination to an IDC which is located on a junction in a work area. An IDC summarizes the information from robots and tells a direction that it effects best way to a destination which a robot wants to go. By the proposed algorithm and system, mobile robots construct information of navigation and improve the efficiency of a task automatically. We verified the effect of the proposed algorithm by simulations and experiments."""	autonomous robot	Daisuke Kurabayashi;Hajime Asama	2000		10.1109/ROBOT.2000.844098	control engineering;mobile robot;embedded system;simulation;computer science;engineering;artificial intelligence;mobile computing	Robotics	58.00748770484302	-25.194595080268027	193763
88edf998e4420284bea6b646278fa0f15d5dc1c9	a bio-mimetic joint motion planning for humanoid fingers: practical analysis	interphalangeal motion biomimetic joint motion planning humanoid finger robotic finger manipulation finger motion joint trajectory;finger motion;biomimetic joint motion planning;motion control;position control biomimetics dexterous manipulators humanoid robots motion control path planning;joint motion planning;biomimetic approach;path planning;real time;biomimetic approach joint motion planning humanoid finger;null;humanoid finger;joint trajectory;dexterous manipulators;robotic finger manipulation;humanoid robots;position control;motion analysis fingers robot kinematics humans humanoid robots motion planning strategic planning manipulators biomimetics motion control;motion planning;empirical model;interphalangeal motion;biomimetics	This paper implements a bio-mimetic joint motion planning strategy for robotic finger manipulations and shows its practical effectiveness in typical finger motions. The main feature of the proposed approach is to utilize an empirical model approximately made by the function of human finger motion for planning the joint trajectory of a robotic finger. In fact, the empirical model coordinates an interphalangeal motion in a robotic finger. By employing the joint motion planning method, it is possible to assign an adequate initial finger configuration and also plan effectively its real-time joint configurations during an operation. The practical merits of the motion planning strategy for finger operations will be discussed by experimental works.	british informatics olympiad;motion planning;real-time clock;robot	Byoung-Ho Kim	2006	2006 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2006.340294	control engineering;computer vision;finger tracking;simulation;computer science;engineering;artificial intelligence;motion planning;empirical modelling	Robotics	66.00979368179699	-24.589128034359717	193806
54f15ff48a039cde5c4b1c328692b28f81f26e21	3-d sensing for flexible linear object alignment in robot cell production system	flexible object handling;motion stereo;cell production robot system		robot	Yukiyasu Domae;Haruhisa Okuda;Yasuo Kitaaki;Yuta Kimura;Hidenori Takauji;Kazuhiko Sumi;Shun'ichi Kaneko	2010	JRM	10.20965/jrm.2010.p0100	control engineering;computer vision;simulation	Robotics	64.13792800129157	-35.17621107482664	194011
4d7006ce68a872e3c2bcf3bcfbb5972feb92d695	time-independent, spatial human coordination for humanoids	humanoid robot;three dimensions;legged locomotion;foot;joints;kinematics;three dimensional;pelvis;humanoid robots;knee;polynomial approximation humanoid robots;spatial representation;humans;aldebaran society humanoid gait generation polynomial approximations kinematic simulation anthropomorphic humanoid model humanoid robot nao;polynomial approximation;legged locomotion humans foot joints pelvis knee kinematics	The work presented here focuses on humanoid gait generation. More precisely we deliberately separate the motion generation in two distinct parts: the coordination and the stability. The goal is to highlight the human coordination, and then reduce its complexity to a minimal set of relations (twelve gait descriptors with respect to an unique gait parameter). Polynomial approximations of these relations are done and implemented into a kinematic simulation of an anthropomorphic humanoid model coming from a real humanoid robot. This simulation allows the leg coordination through the contact with the environment. After the validation of the coordination relations, they are injected into an actual humanoid robot NAO. We choose the small humanoid NAO from Aldebaran society because its size and set up permit to keep the gait coordination (in three dimensions) part primarily in gait generation by comparison with the stability part (in the frontal plane). The results are promising and authorize to plan an application of this work on a more complex humanoid, plus the study of other gaits, and more important on the gait transition.	approximation;complexity;humanoid robot;lateral thinking;molecular descriptor;nao (robot);point of view (computer hardware company);polynomial;security descriptor;simulation	Jean-Christophe Palyart Lamarche;Olivier Bruneau;Jean-Guy Fontaine	2011	2011 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6094502	three-dimensional space;computer vision;simulation;computer science;engineering;humanoid robot;artificial intelligence	Robotics	67.49510620729794	-26.775085728545797	194339
8e1afc30f6e2e9f29c1ece11aecf3be6b843e0a6	threat detection for collaborative adaptive cruise control in connected cars		We study collaborative adaptive cruise control as a representative application for safety services provided by autonomous cars. We provide a detailed analysis of attacks that can be conducted by a motivated attacker targeting the collaborative adaptive cruise control algorithm, by influencing the acceleration reported by another car, or the local LIDAR and RADAR sensors. The attacks have a strong impact on passenger comfort, efficiency and safety, with two of such attacks being able to cause crashes. We also present two detection methods rooted in physical-based constraints and machine learning algorithms. We show the effectiveness of these solutions through simulations and discuss their limitations.	algorithm;autonomous car;crash (computing);hidden markov model;machine learning;radar;sensor;simulation;velocity (software development)	Matthew Jagielski;Nicholas Jones;Chung-Wei Lin;Cristina Nita-Rotaru;Shinichi Shiraishi	2018		10.1145/3212480.3212492	simulation;computer security;radar;lidar;computer science;cruise control	Security	54.090166652367316	-27.60554110353351	194354
c1c8959d28946221dccccfdcdba48ff9ee2a276c	obstacle detection and avoidance system for visually impaired people	obstacle detection;range data;time of flight;ultrasound;visually impaired users;embedded system;sensor array;visual impairment;ultrasonic sensor	In this paper, we implemented a wearable system for visually impaired users which allows them to detect and avoid obstacles. This is based on ultrasound sensors which can acquire range data from objects in the environment by estimating the time-of-flight of the ultrasound signal. Using a hemispherical sensor array, we can detect obstacles and determine which directions should be avoided. However, the ultrasound sensors are only used to detect whether obstacles are present in front of users. We determine unimpeded directions by analyzing patterns of the range values from consecutive frames. Feedback is presented to users in the form of voice commands and vibration patterns. Our system is composed of an ARM9-based embedded system, an ultrasonic sensor array, an orientation tracker and a set of vibration motors with controller.	embedded system;feedback;framing (world wide web);sensor;wearable computer	Byeong Seok Shin;Cheol-Su Lim	2007		10.1007/978-3-540-76702-2_9	embedded system;computer vision;electronic engineering;engineering	HCI	57.35090990453676	-34.529651441449616	194674
032a4021d46c03f3275a15d850cb6af56ecfee02	nvl: a coordination language for unmanned vehicle networks	assembly;multi agent systems;industrial robots;semantic web;ontologies;flexible robot systems	"""The coordinated use of multiple unmanned vehicles over a network can be employed for numerous real-world applications. However, multi-vehicle operations are often deployed through a patchwork of separate components that informally """"glue"""" together during operation, as they are hard to program as a """"whole"""". With this aim, we developed the Networked Vehicles' Language (NVL) for coordinated control of unmanned vehicle networks. A single NVL program expresses an on-the-fly selection of multiple vehicles and their allocation to cooperative tasks, subject to time, precedence, and concurrency constraints. We present the language through an example application involving unmanned underwater vehicles (UUVs) and unmanned aerial vehicles (UAVs), the core design and implementation traits, and results from simulation and field test experiments."""	aerial photography;concurrency (computer science);experiment;null (sql);patchwork;simulation;uncrewed vehicle;unmanned aerial vehicle	Eduardo R. B. Marques;Manuel A. Ribeiro;José Pinto;João Borges de Sousa;Francisco Martins	2015		10.1145/2695664.2696029	embedded system;simulation;computer science;ontology;artificial intelligence;semantic web;multi-agent system;assembly	Robotics	57.50004563990521	-27.037310948656597	194784
7543c31f47ef44fa7def642a296ae4e0cc70f02e	service mobile robot control for tracking a moving object with collision avoidance	mobile robots cameras robot vision systems robot kinematics;mobile robots;wheelchairs collision avoidance image motion analysis mobile robots object recognition object tracking robot vision service robots;crank course service mobile robot control moving object tracking collision avoidance moving object recognition wheelchair l course;robot vision systems;cameras;robot kinematics	One of the crucial features of a service robot is the ability “to see” the environment and a target object for smooth navigation. This paper deals with a mobile robot that recognizes and tracks a moving object attached to a wheelchair in a obstacle existing environment. The experiment was conducted in three scenarios, the first one is that the robot is set to recognize and track a moving object in obstacle free environment, and the second and the third ones are the L-course and the crank course bordered by boxes as the obstacles. The third scenario was conducted five times with five different human-targets. The experimental results show that the proposed method is effective in recognizing and tracking the moving object.	continuation;crank (person);human interface device;mobile robot;robot control;service robot	Tresna Dewi;Naoki Uchiyama;Shigenori Sano	2015	2015 IEEE International Workshop on Advanced Robotics and its Social Impacts (ARSO)	10.1109/ARSO.2015.7428197	mobile robot;embedded system;computer vision;bang-bang robot;cartesian coordinate robot;simulation;articulated robot;computer science;artificial intelligence;social robot;robot control;mobile robot navigation;personal robot;robot kinematics	Robotics	59.26711197207899	-29.904911764864245	194871
602072750ce931fd592ee0ea6d968ba9746fe34c	rgb-d and laser data fusion-based human detection and tracking for socially aware robot navigation framework	trajectory control feature extraction image colour analysis mobile robots object tracking path planning robot vision sensor fusion service robots;robot trajectory rgb d data laser data data fusion human detection human tracking socially aware robot navigation framework mobile service robot position control kinodynamic rrt motion planner;navigation mobile robots sensors tracking collision avoidance robot kinematics	This paper proposes an effective socially aware navigation framework for mobile service robots in social environments. The proposed framework consists of three stages. In the first stage, RGB-D and laser data fusion-based human detection and tracking system is utilized to detect humans in the vicinity of the robot. In the second stage of framework, the extended personal space is modelled by using the human states including position and motion, and the relative motion between the human and the robot. In the third stage, the extended personal space is incorporated into the motion planning system and then a kinodynamic RRT motion planner is made use of to generate a legible trajectory of the mobile robot. The experimental results indicate that the proposed framework is able to ensure the safety of human, providing socially acceptable behaviors of the mobile service robot.	algorithm;dr-dos;experiment;humans;mobile robot;motion planning;robotic mapping;service robot;tracking system	Xuan-Tung Truong;Voo Nyuk Yoong;Trung Dung Ngo	2015	2015 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2015.7418835	control engineering;mobile robot;computer vision;simulation;engineering;social robot;robot control;mobile robot navigation;personal robot;robot calibration	Robotics	54.526494419765676	-33.31300300837231	194902
46779960e716d4eb523c31fc3ef3a1d9cee34e08	heterogeneous implementation of an adaptive robotic sensing team	design engineering;mobile robot;mobile robots;adaptive systems design engineering mobile robots multi robot systems;mobile robots adaptive robotic sensing team mobile robotic team robot design sensing capability robotic platforms cots scout;adaptive systems;multi robot systems;robot sensing systems mobile robots humans computer science design engineering materials science and technology contracts distributed computing mechanical engineering costs	When designing a mobile robotic team, an engineer is faced with many design choices. This paper discusses the design of a team consisting of two different models of robots with significantly different sensing and control capabilities intended to accomplish a similar task. Two new robotic platforms, the COTS Scout and the MegaScout are described along with their respective design considerations.	adobe scout;robot;scout;software portability;software prototyping	Bradley Kratochvil;Ian T. Burt;Andrew Drenner;Derek Goerke;Bennett Jackson;Colin McMillen;Christopher Olson;Nikolaos Papanikolopoulos;Adam Pfeifer;Sascha Stoeter;Kristen Stubbs;David Waletzko	2003		10.1109/ROBOT.2003.1242259	control engineering;mobile robot;embedded system;simulation;robotic sensing;computer science;engineering;artificial intelligence;adaptive system;mobile manipulator;robot control	Robotics	60.964041268421255	-27.561825875176766	194971
515b0f95cd6d0eef0a81cfba2197c2b94792b9d5	sensory adaptation in human balance control: lessons for biomimetic robotic bipeds	navio;psychomotor performance;muscle skeletal;reseau capteur;propiocepcion;multisensor;sensory re weighting;walking;caminata;articulo sintesis;canal bus;cuerpo;article synthese;implementation;body;weighting;sensory adaptation;canal colector;proprioception;hombre;robotics;percepcion;orientation;indexing terms;ponderacion;vestibule labyrinth;but;stimulus movement;human subjects;captador medida;posture;fin;measurement sensor;red sensores;capteur mesure;marche a pied;locomocion bipedo;biomimetique;adaptation physiological;sensation;human;sensor array;corps;robotica;bus channel;artificial intelligence;visual perception;humans;adaptation sensorielle;robotique;ponderation;ship;perception;mouvement stimulus;bipedal walking;neural networks computer;adaptacion sensorial;implementacion;balance control;postural balance;review;robot;vision;capteur multiple;locomotion bipede;leg;space perception;movimiento estimulo;homme;biomimetics;goal;navire	This paper describes mechanisms used by humans to stand on moving platforms, such as a bus or ship, and to combine body orientation and motion information from multiple sensors including vision, vestibular, and proprioception. A simple mechanism, sensory re-weighting, has been proposed to explain how human subjects learn to reduce the effects of inconsistent sensors on balance. Our goal is to replicate this robust balance behavior in bipedal robots. We review results exploring sensory re-weighting in humans and describe implementations of sensory re-weighting in simulation and on a robot.	acclimatization;biomimetics;proprioception;robot (device);self-replication;simulation;sensor (device)	Arash Mahboobin;Patrick J. Loughlin;Mark S. Redfern;Stuart O. Anderson;Christopher G. Atkeson;Jessica K. Hodgins	2008	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2008.03.013	biomimetics;robot;vision;sensation;simulation;index term;fin;visual perception;computer science;artificial intelligence;weighting;orientation;proprioception;robotics;implementation;perception;sensor array	Robotics	63.48237808195471	-32.467508644956	195211
e4251dcc080b348c49647927b66e486f7f130d27	an iterative clustering algorithm for classification of object motion direction using infrared sensor array	direction classification;robot sensing systems;robotic platform direction classification infrared sensors clustering;classification algorithm;robotic platform;infrared sensor array;histogram based iterative clustering algorithm;robotic system;infrared sensors arrays robot sensing systems classification algorithms collision avoidance;arrays;iterative methods;distance measurement;obstacle avoidance;statistical analysis;clustering;classification algorithm object motion direction classification infrared sensor array robotic system proximity estimation obstacle avoidance distance measurement histogram based iterative clustering algorithm;object motion direction classification;statistical analysis iterative methods pattern classification robots sensor arrays;robots;classification algorithms;pattern classification;collision avoidance;proximity estimation;infrared sensors;sensor arrays	Infrared sensors have been widely used in the field of robotics. This is primarily because these low cost and low power devices have a fast response rate that enhances realtime robotic systems. However, the use of these sensors in this field has been largely limited to proximity estimation and obstacle avoidance. In this paper, we attempt to extend the use of these sensors from just distance measurement to classification of direction of motion of a moving object or person in front of these sensors. A platform fitted with 3 infrared sensors is used to record distance measures at intervals of 100ms. A histogram based iterative clustering algorithm segments data into clusters, from which extracted features are fed to a classification algorithm to classify the motion direction. Experimental results validate the theory that these low cost infrared sensors can be successfully used to classify motion direction of a person in real time.	algorithm;cluster analysis;iterative method;obstacle avoidance;power semiconductor device;robot;robotics;sensor	Ankita Sikdar;Yuan F. Zheng;Dong Xuan	2015	2015 IEEE International Conference on Technologies for Practical Robot Applications (TePRA)	10.1109/TePRA.2015.7219663	computer vision;geography;machine learning;pattern recognition	Robotics	53.822183634048386	-33.92636240879295	195356
91b6109e450ffc95bd8b183d51c84ceaae44c894	online interactive building of presence	model building	This paper presents methods for cooperative mapping of partially or totally unknown area with human and robotic explorers. Mapping is supported with online modelling of presence, which will create a common understanding of the environment for both humans and robots. The studied key methods are human navigation without ready installed beacons, human and robotic SLAM, cooperative localization and cooperative map/model building for common presence. Methods are developed, tested and integrated in a European Community research project called PeLoTe.	augmented reality;dead reckoning;gyro;http 404;robot;simultaneous localization and mapping;system integration testing	Jussi Suomela;Jari Saarinen;Aarne Halme;Panu Harmo	2003		10.1007/10991459_38	simulation;computer science;heat exchanger;fluid dynamics;transition zone	Robotics	58.53393070509469	-29.701147248160048	195572
8699c0c7d2e4a7f3235877e8e199090866e984c8	a computationally distributed self-organizing algorithm for the control of manipulators in the operational space	microcontrollers;control systems;motion control;embedded control system;computational geometry;distributed computing;data exchange;operator space;kinematics;self organization;arm;centralized control;distributed computing motion control centralized control distributed control kinematics communication system control control systems arm computational geometry microcontrollers;communication system control;distributed control	The present work deals with manipulator arms characterized by the presence of an internal, totally distributed, embedded control system. More specifically, every single joint is assumed to be equipped with a simple local processing unit devoted to properly drive its motion, thus allowing to consider each pair constituted by a single joint and the associated link as a defective “1-dof-only”, separately controlled, atomic manipulator. In this perspective, the paper proposes an effective, computationally distributed, control technique that, based on a repeated data exchange among the processing units, establishes a global self-organizing behaviour among the joints which allows to control the motion of the end-effector of the overall arm in the operational space, by solely exploiting the control capabilities of every local processing unit, while not requiring any centralized global knowledge about the overall arm geometry and kinematics.	algorithm;centralized computing;coat of arms;control system;embedded system;organizing (structure);robot end effector;self-organization	Giuseppe Casalino;Alessio Turetta	2005	Proceedings of the 2005 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2005.1570741	operator space;data exchange;control engineering;microcontroller;motion control;kinematics;real-time computing;self-organization;computational geometry;computer science;networked control system;control system;artificial intelligence;control theory;arm architecture	Robotics	65.08379803664741	-26.240132702210815	195967
3f3012b93fe7cbe551ccaee7990524769655ed15	evolving robotic path with genetically optimised fuzzy planner	soft computing;fuzzy inference systems;robot navigation;robotics;hybrid computing;computer vision;robot path planning;artificial intelligence;genetic algorithms;hierarchical algorithms;fis;genetic optimisation	Path planning is one of the highly studied problems in the field of robotics. The problem has been solved using numerous statistical, soft computing and other approaches. In this paper, we evolve the robotic path using genetic algorithms (GA). The GA generates solutions for the static map which disobeys the non-holonomic constraints. Fuzzy inference system (FIS) works on the generated path and extends the problem for dynamic environment. The results of GA serve as a guide for FIS planner. The FIS system was initially generated using rules from common sense. Once this model was ready, the fuzzy parameters were optimised by another GA. The GA tried to optimise the distance from the closest obstacle, total path length and the sharpest turn at any time in the journey of the robot. The resulting FIS was easily able to execute the plan of the robot in a dynamic environment. We tested the algorithm on various complex and simple paths. All paths generated were optimal in terms of path length and smoothness. Hence, using a combination of GA along with FIS, we were able to solve the problem of robotic path planning.	benchmark (computing);complexity;experiment;genetic algorithm;inference engine;mike lesser;motion planning;real life;requirement;robot;serial ata;soft computing;test case	Rahul Kala;Ritu Tiwari;Anupam Shukla	2010	IJCVR	10.1504/IJCVR.2010.038196	simulation;genetic algorithm;computer science;artificial intelligence;machine learning;soft computing;robotics	Robotics	54.94809081746347	-24.290725537992476	196099
c01cb8740281fc83a193c7293f5af233506ee05a	robotic modeling and simulation of palletizer robot using workspace5	offline programming robotic modeling robotic simulation okura a1600 palletizer robot workspace5 simulation tool manufacturing industry robotic application system visualization robot arm movement collision detection production line pick and place application cad;cycle time;workspace5 robotic modeling simulation cad;service robots computational modeling application software computer simulation employment manufacturing industries visualization production elbow end effectors;t technology general;robotic modeling;modeling and simulation;cad;workspace5 simulation tool;simulation;pick and place application;offline programming;product line;manufacturing industries;robot programming control system cad data visualisation industrial manipulators manufacturing industries palletising;control system cad;okura a1600 palletizer robot;three dimensional;production line;qa75 electronic computers computer science;data visualisation;robot arm;robotic simulation;collision detection;palletising;robotic application system visualization;manufacturing industry;robot arm movement;simulation tool;simulation model;computer simulation;industrial manipulators;workspace5;robot programming;value added;model simulation	Employment of robots in manufacturing has been a value-added entity in a manufacturing industry. Robotic simulation is used to visualize entire robotic application system, to simulate the movement of robot arm incorporated with components consist in its environment and to detect collision between the robot and components. This paper presents result of a project in implementing a computer based model to simulate Okura A1600 palletizer robot. The application uses Okura A1600 robot for palletizing bags at the end of the production line and focuses on pick-and-place application. The project objective is to generate a computer simulated model to represent the actual robot model and its environment. The project simulates the robot's first four joints, namely as the waist, shoulder, elbow and waist and focuses on the position of the robot's end effector, regardless its orientation. Development of the model is using Workspace5 as a simulation tool. Two types of methodology are used, which are the methodology for developing the robotic workcell simulation model and the methodology for executing the robotic simulation. The output of the project will be a three-dimensional view of robot arm movement based on series of predefined geometry points, layout checking and robot's reachability by generating working envelope, collision and near miss detection, and monitoring on the cycle time upon completing a task. The project is an offline programming and no robot language is generated.	collision detection;computer simulation;envelope (motion);interference (communication);online and offline;performance;programming language;reachability;robot end effector;robotic arm;smt placement equipment	Nory Afzan Mohd Johari;Habibollah Haron;Abdul Syukor Mohamad Jaya	2007	Computer Graphics, Imaging and Visualisation (CGIV 2007)	10.1109/CGIV.2007.73	mobile robot;robot learning;computer vision;robot end effector;simulation;articulated robot;engineering;social robot;arm solution;robot control;mobile robot navigation;personal robot;manufacturing engineering;robot calibration	Robotics	66.5196395045448	-31.545635499836024	196134
7114e2f6d51d41032cf8b576f360de3e42b73b4b	a real-time trajectory control of two driving mobile robot	shh robo robot autonomous vehicle real time trajectory control two driving mobile robot trajectory following fuzzy perception concept nonholonomic mobile robot fuzzy perception reactive behavior behavior combination control architecture fuzzy behavior intelligent control system;fuzzy control;non holonomic mobile robot real time control ultrasonic sensor fuzzy controller;mobile robots;intelligent control;trajectory control fuzzy control intelligent control mobile robots real time systems;robot sensing systems mobile robots vectors robot kinematics acoustics vehicles;trajectory control;real time systems	We propose a new approach to control of mobile robot of trajectory following and fuzzy perception concept with a non-holonomic mobile robot named Robo N. The main focus of this paper is obtaining a fuzzy perception of the environment in the design of each reactive behavior and solving the problem of behavior combination to implement a fuzzy behavior based control architecture. It should be remarked that, the proposed technique of the nonholonomic constraints are considered in the design of each behavior. Furthermore, in order to improve the capabilities of the intelligent control system and its practical applicability, teleoperation and planned behaviors, together with their combination with reactive ones, have been considered. Experimental results, of an application to control the SHH-Robo Robot autonomous vehicle, demonstrate the robustness of the proposed method.	atomic robo;autonomous robot;control system;intelligent control;mobile robot;real-time clock	Byoung-Kyun Shim;Sung-Won Jung;Moon-Youl Park;Ki-Won Sung;In-Man Park;Won Jun Hwang;Sung-Hyun Han	2013	IEEE ISR 2013	10.1109/ISR.2013.6695641	mobile robot;simulation;computer science;artificial intelligence;social robot;robot control;intelligent control	Robotics	59.446523779641154	-27.688383701390745	196248
849812ecaf0e5d7d10a93f08be185d86606bb596	planning paths for package delivery in heterogeneous multirobot teams	urban delivery generalized traveling salesman problem optimal path planning unmanned aerial vehicles;path planning;road vehicles autonomous aerial vehicles computational complexity goods distribution industrial robots multi robot systems path planning;static warehouses path planning package delivery heterogeneous multirobot teams task scheduling cooperating vehicles autonomous delivery truck quadrotor microaerial vehicle np hard problem generalized traveling salesman problem heterogeneous delivery problem;urban areas;fuels;land vehicles;traveling salesman problems path planning unmanned aerial vehicles multi robot systems urban areas;planning;traveling salesman problems	This paper addresses the task scheduling and path planning problem for a team of cooperating vehicles performing autonomous deliveries in urban environments. The cooperating team comprises two vehicles with complementary capabilities, a truck restricted to travel along a street network, and a quadrotor micro-aerial vehicle of capacity one that can be deployed from the truck to perform deliveries. The problem is formulated as an optimal path planning problem on a graph and the goal is to find the shortest cooperative route enabling the quadrotor to deliver items at all requested locations. The problem is shown to be NP-hard. A solution is then proposed using a novel reduction to the Generalized Traveling Salesman Problem, for which well-established heuristic solvers exist. The heterogeneous delivery problem contains as a special case the problem of scheduling deliveries from multiple static warehouses. We propose two additional algorithms, based on enumeration and a reduction to the traveling salesman problem, for this special case. Simulation results compare the performance of the presented algorithms and demonstrate examples of delivery route computations over real urban street maps.	aerial photography;algorithm;autonomous robot;computation;heuristic;map;motion planning;np-hardness;reduction (complexity);scheduling (computing);simulation;travelling salesman problem	Neil Mathew;Stephen L. Smith;Steven Lake Waslander	2015	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2015.2461213	planning;traveling purchaser problem;2-opt;simulation;computer science;engineering;motion planning;transport engineering	Robotics	54.27740549840314	-24.754174754356	196446
fcc0a19949bc0a9c9aaffb5c4f25e44f683b2396	uncertainty estimation for a 6-dof spectral registration method as basis for sonar-based underwater 3d slam	6 degree of freedom spectral registration;phase only matched filtering;normal distribution;uncertainty;degree of freedom;normal distribution uncertainty estimation 6 dof spectral registration sonar based underwater 3d slam 6 degree of freedom spectral registration phase only matched filtering noisy sensor data 3d underwater mapping sonar imaging devices simultaneous localization and mapping framework probability mass functions;sonar imaging;sonar imaging image registration normal distribution slam robots;estimation;sonar based underwater 3d slam;sonar imaging devices;image registration;simultaneous localization and mapping;uncertainty estimation;probability mass functions;simultaneous localization and mapping framework;optimization;probability mass function;experimental evaluation;noisy sensor data;matched filter;3d underwater mapping;uncertainty sonar estimation simultaneous localization and mapping gaussian distribution optimization;slam robots;gaussian distribution;6 dof spectral registration;sonar	An uncertainty estimation method for 6 degree of freedom (6-DoF) spectral registration is introduced here. The underlying 6-DoF registration method based on Phase Only Matched Filtering (POMF) is capable of dealing with very noisy sensor data. It is hence well suited for 3D underwater mapping, where relatively inaccurate sonar imaging devices have to be employed. An uncertainty estimation method is required to use this registration method in a Simultaneous Localization and Mapping (SLAM) framework. To our knowledge, the first such method for 6-DoF spectral registration is presented here. This new uncertainty estimation method treats the POMF results as probability mass functions (PMF). Due to the decoupling in the underlying method, yaw is computed by a one-dimensional POMF leading hence to a 1D PMF; roll and pitch are simultaneously computed and hence encoded in a 2D PMF. Furthermore, a 3D PMF is generated for the translation as it is determined by a 3D POMF. A normal distribution is fitted on each of the PMF to get the uncertainty estimate. The method is experimentally evaluated with simulated as well as real world sonar data. It is shown that it indeed can be used for SLAM, which significantly improves the map quality.	3d reconstruction;coupling (computer programming);experiment;ground truth;mathematical optimization;sonar (symantec);simulation;simultaneous localization and mapping;yaws	Max Pfingsthorn;Andreas Birk;Heiko Bülow	2012	2012 IEEE International Conference on Robotics and Automation	10.1109/ICRA.2012.6224731	normal distribution;computer vision;computer science;control theory;optics;statistics	Robotics	55.51228000604571	-37.9341936203705	196533
43a0ebd965d3f348ef31424c482038ffb43cbbf1	multi-robot system for tracking and surrounding a stationary target: a decentralized and cooperative approach		Multi-Robot System (MRS) is composed of a group of robots that work cooperatively. This paper proposed a decentralized MRS for tracking and surrounding a stationary target. Currently, there are few studies related to a decentralized MRS, since most works are centralized. The robotic agents are homogeneous and hybrid with reactive and cognitive characteristics. The MRS has been implemented and validated in the robot simulator called Virtual Robot Experimentation Platform (V-Rep). In the validation, a scenario with three robots and a stationary target were defined. However, MRS is able to track and surround with n robots. In the tracking task, the robot can detect the target whose position is not known a priori. The obstacle avoidance should be considered in this task because robots and walls are obstacles and should be avoided. When the detection occurs, the V-Rep informs the target position to the robot because the environment is discretized into a grid of rectangular cells. After that, all the robots are directed to the target and the surround task is realized. In this task, a mathematical model with directs communication between the robots is defined to keep the robots equidistant therefrom and from each other.	algorithm;centralized computing;cognition;discretization;emergence;institute for operations research and the management sciences;interaction;mathematical model;minimal recursion semantics;mobile robot;obstacle avoidance;robot;self-organization;stationary process	Wagner Tanaka Botelho;Maria das Graças Bruno Marietto;Eduardo de Lima Mendes;João Carlos da Motta Ferreira;Vera Lúcia da Silva	2017	2017 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2017.8324514	grid;control engineering;task analysis;robot;equidistant;discretization;obstacle avoidance;mobile robot;engineering;robot kinematics	Robotics	57.9877678155751	-24.206998481734004	196604
0ab820efbeb6799442a7f6d81205f213ffca14aa	non-stop outdoor navigation of a mobile robot-retroactive positioning data fusion with a time consuming sensor system	robot sensing systems;sensor system;sensor systems;retroactive positioning data fusion;time consuming sensor system;internal sensor information;legged locomotion;intelligent robots;mobile robot;maximum likelihood estimation mobile robots computerised navigation position measurement sensor fusion signal processing;data processing;mobile robots;data fusion;landmark detection nonstop outdoor navigation mobile robot retroactive positioning data fusion time consuming sensor system position estimation autonomous mobile robot maximum likelihood estimation parallel processing internal sensor information external sensor information time delay sensor data process;autonomous mobile robot;maximum likelihood estimation;orbital robotics;landmark detection;time delay;navigation;maximum likelihood estimate;sensor data process;signal processing;position measurement;position estimation;dead reckoning;sensor fusion;nonstop outdoor navigation;external sensor information;robot vision systems;parallel processing;navigation mobile robots robot sensing systems orbital robotics dead reckoning sensor systems sensor fusion legged locomotion robot vision systems intelligent robots;computerised navigation	We propose a position estimation technique for nonstop outdoor navigation of an autonomous mobile robot. The proposed position estimation technique is based on maximum likelihood estimation. To cope with the parallel processing of internal and external sensor information and time delay in the sensor data process, we introduce the retroactive positioning data fusion technique. The proposed technique is implemented on our small size autonomous mobile robot. An experimental result is shown, in which our robot could navigate itself without stopping even when it takes several seconds of processing time to detect landmark from external sensor data.	mobile robot	Shoichi Maeyama;Akihisa Ohya;Shin'ichi Yuta	1995		10.1109/IROS.1995.525786	mobile robot;embedded system;parallel processing;computer vision;simulation;data processing;computer science;engineering;signal processing;sensor fusion;maximum likelihood;mobile robot navigation	Robotics	53.99136728522347	-33.93956649495633	196673
0ba20148f81ddaf56cefd722e03e0452d4cfc51c	an autonomous sensor platform vessel for marine protected area monitoring	sensors oceanographic equipment remote sensing;sensors;fish population autonomous sensor platform vessel marine protected area monitoring marine sensing average power navigation algorithm sheltered harbor control heading;fish population marine protected area autonomous marine sensing acoustic;marine protected area;autonomous;fish population;low power;remote sensing;marine sensing;acoustic;monitoring sea measurements marine animals sensor phenomena and characterization propulsion power system protection ecosystems spatial resolution costs acoustic testing;oceanographic equipment	Development of an autonomous surface vessel platform for marine sensing is presented. Much of the design characteristics are general, but a specific application related to monitoring of designated coastal marine protected areas is discussed. The sensor platform vessel described is small, approximately 35 lbs in air, and designed for low power requirements. The power requirements for propulsion are examined and show that an estimated 5 W average power is expected to be sufficient to operate the vessel at its maximum speed. Initial tests verify operation of the vessel's navigation algorithm to control heading in a sheltered harbor.	algorithm;autonomous robot;course (navigation);requirement	Kenneth E. Laws;Cyrus Bazeghi;Stephen Petersen;John F. Vesecky	2009	2009 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2009.5417546	oceanography;geology;sensor;marine protected area;autonomy;population dynamics of fisheries;remote sensing	Embedded	55.91589497454208	-30.45819274800126	196693
46a0753e3e45b1924c284a9abbffb8e9ad1e473e	gait analysis for a human with a robot walking helper	passive;proceedings paper;human;gait analysis;walking helper;robot	With the growth of elderly population in our society, intelligent walking aids will play an important role in providing functional mobility to humans. In this paper, we propose a model to compute gait of humans walking with a robot helper. This model is aimed at designing a control system for the robot walking helper. The human model includes both the single support phase and impacts. Since a human will be walking along with the robot with its help, geometrical constraints and interaction forces are included. To achieve stable walking, zero moment point (ZMP) is utilized in the analysis and friction constraint is included within the reaction force from the ground. Simulations are performed to obtain optimal gait trajectories, the human applied joint torques, and the supporting forces from the robot walking helper.	gait analysis;robot	Chun-Hsu Ko;Kuu-Young Young;Sunil Kumar Agrawal	2012		10.1007/978-3-642-33926-4_57	robot;torque;gait;control theory;gait analysis;zero moment point;reaction;control system;computer science;population	Robotics	67.74560110930477	-24.920334342979718	196879
02ff8bbdb876f01f82a78a1fc86c307d424db4a5	design and control of an indoor micro quadrotor	microrobots;data processing;mobile robots aerospace robotics microrobots;mobile robots;building exploration indoor micro quadrotor miniature flying robot micro vtol system small area monitoring;aerospace robotics;robot sensing systems remotely operated vehicles aircraft propulsion aircraft navigation laboratories military aircraft helicopters actuators cameras biomimetics	Progresses in sensor technology, data processing and integrated actuators has made the development of miniature flying robots fully possible. Micro VTOL systems represent a useful class of flying robots because of their strong capabilities for small-area monitoring and building exploration. In this paper we describe the approach that our lab has taken to micro VTOL evolving towards full autonomy, and present the mechanical design, dynamic modelling, sensing, and control of our indoor VTOL autonomous robot OS4.	amigaos 4;autonomous robot;autonomy;robotics	Samir Bouabdallah;Pierpaolo Murrieri;Roland Siegwart	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1302409	control engineering;mobile robot;data processing;aerospace engineering;computer science;engineering;artificial intelligence;aeronautics	Robotics	56.58921306626543	-30.670340430836795	197015
1d0ae29159aaff195f9c4dfdfb306a082ca331c9	real-time control: a significant test of ai technologies	software;robot sensing systems;artificial intelligence intelligent robots navigation uncertainty robotics and automation sensor arrays real time systems;intelligent robots;uncertainty;real time control;navigation;roads;robots;artificial intelligence;robotics and automation;sensor arrays;real time systems		real-time transcription	Charles R. Weisbin	1987	IEEE Expert	10.1109/MEX.1987.5006526	robot;embedded system;navigation;simulation;real-time control system;uncertainty;ant robotics;computer science;artificial intelligence;robot control;future of robotics;artificial intelligence, situated approach	Vision	57.57013788750594	-30.687649615829777	197117
524b596007ac3c534ead49e9d3f7e45d52769c16	stretch-legged walking in sagittal plane	legged locomotion;and forward;walking stability stretch legged walking sagittal plane forward walking pattern walking guide platform guide system treadmill inverse kinematics hip position ratio hip shape factor;hip;foot;guide system;stability legged locomotion robot kinematics;joints;stability;zmp;treadmill;stretch legged walking;sagittal plane;energy consumption walking guide platform zmp stretch legged walking hip position ratio hip shape factor;energy consumption;knee;robots;hip position ratio;hip shape factor;inverse kinematics;walking guide platform;legged locomotion hip robots kinematics shape stability current measurement energy measurement goniometers energy consumption;forward walking pattern;walking stability;leg;robot kinematics	This paper presents a new forward walking pattern known as stretch-legged walking. Additionally, what has been termed the Walking Guide Platform (WGP) was developed to verify the developed walking pattern. For the WGP, a robot that can move in a sagittal plane was created. Next, a guide system and treadmill were developed. Those systems minimize disturbances from other motions except the sagittal plane motion. The proposed walking pattern is divided into walking on the spot and forward walking. These are generated by solving inverse kinematics involving the addition of reference angles of the hip and ankle joints. The Hip Position Ratio(HPR) and the Hip Shape Factor(HSF) were also used to stabilize the walking. These values are dependent on the walking speed. The walking stability was judged using deviation of the ZMP and the body tilt angle. By measuring the current, a comparison in terms of the energy consumption can be made between the proposed walking pattern and a walking pattern with a bending knee.	algorithm;international conference on functional programming;inverse kinematics;multilevel model;repeatability;robot;velocity (software development);zero moment point	Min-Su Kim;Ill-Woo Park;Jung-Yup Kim;Jun-Ho Oh	2007	2007 7th IEEE-RAS International Conference on Humanoid Robots	10.1109/ICHR.2007.4813880	robot;simulation;power walking;stability;computer science;artificial intelligence;inverse kinematics;sagittal plane;transition from walking to running;zero moment point;robot kinematics;foot	Robotics	67.23368508031558	-24.424922047503895	197193
15e37a7c75d7861acc8a5a7d21156e5cfcf25b93	real-time tracking of moving objects with an active camera	moving object;filtering;vision ordenador;filtrage;control algorithm;arquitectura circuito;image processing;real time tracking;flux optique;real time;object form;filtrado;corps mobile;implantation;procesamiento imagen;circuit architecture;conception;movie camera;closed loop control;two degree of freedom;traitement image;tracking movable target;computer vision;camera motion;camara;flujo optico;design and implementation;forme objet;estimateur kalman;temps reel;cuerpo movil;architecture circuit;diseno;fixed point arithmetic;tiempo real;procesador oleoducto;design;mouvement objet image;vision ordinateur;optical flow;poursuite;moving body;linear quadratic regulator;processeur pipeline;implantacion;pipeline processor;persecucion y continuacion;camera	This article is concerned with the design and implementation of a system for real-time monocular tracking of a moving object using the two degrees of freedom of a camera platform. Figure-ground segregation is based on motion without making any a priori assumptions about the object form. Using only the first spatiotemporal image derivatives, subtraction of the normal optical flow induced by camera motion yields the object image motion. Closed-loop control is achieved by combining a stationary Kalman estimator with an optimal Linear Quadratic Regulator. The implementation on a pipeline architecture enables a servo rate of 25 Hz. We study the effects of time-recursive filtering and fixed-point arithmetic in image processing and we test the performance of the control algorithm on controlled motion of objects.	active vision;algorithm;angularjs;basis pursuit denoising;computer hardware;data cube;experiment;finite impulse response;fixed-point arithmetic;grasp;image derivatives;image gradient;image processing;infinite impulse response;optical flow;pipeline (computing);real-time clock;real-time locating system;recursion;schmidt decomposition;servo;stationary process;time complexity;top-down and bottom-up design;vergence	Kostas Daniilidis;Christian Krauss;Michael Hansen;Gerald Sommer	1998	Real-Time Imaging	10.1006/rtim.1996.0060	computer vision;design;match moving;simulation;image processing;computer science;optical flow;motion field;computer graphics (images)	Robotics	60.41801621045064	-33.73879820883579	197428
3c0fa2ddb2e778ed7ce409ab9a7486dedddd0bba	supporting training on a robotic simulator using a flexible path planner	strategic place;big constraint;flexible path planner;challenging task;international space station;robotic simulator;new approach;robot path planning;direct view;space station remote manipulator;restricted sight	Manipulating the Space Station Remote Manipulator (SSRMS) on the International Space Station (ISS) is a very challenging task. The operator does not have a direct view of the scene of operation and must rely on cameras mounted on the manipulator and at strategic places of the environment where it operates. In this paper, we describe how a new approach for robot path planning called FADPRM can be used to support the training of astronauts on such a manipulator and under this big constraint of restricted sight.	motion planning;remote manipulator;robot	Roger Nkambou;Khaled Belghith;Froduald Kabanza;Mahie Khan	2005			computer vision;simulation;mobile manipulator	Robotics	56.56813580953114	-28.452906974045842	197519
86e7e413a02eaeb10331466f87c689428386abf0	coordinating massive robot swarms		This paper addresses the problem of how to coordinate the behavior of very large numbers of microrobots in order to assemble complex, hierarchically structured physical objects. The approach is patterned after morphogenetic processes during embryological development, in which masses of simple agents (cells) coordinate to produce complex three-dimensional structures. In order to ensure that the coordination mechanisms scale up to hundreds of thousands or millions of microrobots, the swarm is treated as a continuous mass using partial differential equations. The paper presents algorithms and simulations for assembling segmented structures (artificial spines and legs) and for routing artificial neural fiber bundles. Coordinating Massive Robot Swarms	3d printing;algorithm;complexity;computer;gnu nano;haptic technology;image resolution;microbotics;mind;norm (social);optic nerve (gchq);peripheral;robot;routing;self-assembly;sensor;simulation;spatial scale;swarm	Bruce J. MacLennan	2014	IJRAT	10.4018/IJRAT.2014070101	computer vision;artificial intelligence;simulation;computer science;robot	Robotics	65.67917234079499	-26.72249316273867	197532
070be4c21cb1624307cd6486638c7b08eeec0564	an evaluation of pso-type swarm robotic search: modeling method and controlling properties	robot sensing systems;electronic mail;finite state machine mechanism pso type swarm robotic search particle swarm optimization;motion control;particle swarm optimisation finite state machines multi robot systems;signal detection;finite state machine mechanism;mobile robots;pso type swarm robotic search;orbital robotics;materials science and technology;automata;finite state machines;particle swarm optimizer;robot control;control architecture;particle swarm optimization;multi robot systems;educational institutions robot control communication system control particle swarm optimization robot sensing systems orbital robotics motion control materials science and technology mobile robots automata;target search;modeling swarm robotics particle swarm optimization target search;swarm robotics;search model;communication system control;modeling;particle swarm optimisation;finite state machine	To show the validity of swarm robots modeling and control properties influenced by resulting algorithmic parameter settings, particle swarm optimization (PSO) is extended to be tools for applying to swarm robotic search applications. For this end, a series of experimental simulations are conducted and the effects of key algorithmic parameters, i.e., communication range, detection radius, and swarm size emerge from the statistical results. In such control architecture, swarm robots are modeled at an abstract level with the extended PSO and each individual is assumed to be controlled under three-state finite state machine mechanism. Simulation results indicate the validity of modeling method. Besides, significant positive correlations between search efficiency and communication range, detection radius as well as swarm size are also found.	particle swarm optimization;robot	Zhiqi Liu;Songdong Xue;Jianchao Zeng;Jing Zhao;Guoyou Zhang	2010		10.1109/ICNSC.2010.5461520	control engineering;motion control;mobile robot;swarm robotics;multi-swarm optimization;simulation;systems modeling;computer science;engineering;artificial intelligence;automaton;robot control;finite-state machine;particle swarm optimization;detection theory	Robotics	63.21127481521146	-27.528175465656545	197655
59486f072458b3caefa2d4c0c52cb2c197142597	using gyroscopic sensors data with artificial neural networks for junction detection	electric model railroad gyroscopic sensor data artificial neural network junction detection automotive navigation system location estimation angle information sensor supplementation gps location data autonomous robot speedometer;traffic engineering computing computerised instrumentation gyroscopes neural nets;railroad junction detection gyroscopic sensor artificial neural network	Gyroscopic sensors are frequently used in automotive navigation systems in order to improve location estimation by using the angle information to supplement other sensors such as GPS location data. Gyroscopic sensors can become a major sensor for location estimation for automobiles or autonomous robots for situations where GPS data are inaccurate or cannot be received. In this paper, we assume a situation where GPS data cannot be received, e.g. in a building or tunnel, and gyroscopic sensors and speedometer are the only available sensors for location estimation. We propose applying artificial neural networks to gyroscopic sensor data in order to estimate the current location of the automotive device. We conducted an experiment using an electric model railroad to verify the accuracy of the proposed method.	artificial neural network;automotive navigation system;autonomous robot;global positioning system;gyroscope;sensor	Kenneth J. Mackin;Makoto Fujiyoshi	2012	The 6th International Conference on Soft Computing and Intelligent Systems, and The 13th International Symposium on Advanced Intelligence Systems	10.1109/SCIS-ISIS.2012.6505324	embedded system	Robotics	55.44661190864678	-34.113877735523126	197733
16176113637b657a6a989267d253abf7a0ae230e	measurement of angular motion in golf swing by a local sensor at the grip end of a golf club	sistema giratorio;camara ir;mesure deplacement;acceleration angulaire;metodo paso a paso;step by step method;estimation mouvement;velocidad rotacion;equation euler;infrared thermography;photographie ultrarapide;echantillonnage;localization;corps mobile;3 d accelerometer direct linear transformation dlt golf motion measurement gyro sensor;motion estimation;angular measurement;localizacion;image sensors;rotating system;camera ir;cinematographie ultrarapide;sampling;direct linear transformation dlt;rotation speed;captador medida;cinematografia ultrarrapida;accord frequence;root mean square error golf swing golf club grip end global coordinate system 3d acceleration angular velocity local motion sensor optical direct linear transformation dlt sports motion measurement infrared high speed camera infrared reflector translational motion angular motion measurement principle mean rmse;posture;thermographie ir;sistema coordenadas;measurement sensor;gyro sensor;capteur mesure;systeme tournant;localisation;ultrahigh speed photography;displacement measurement;tuning;vitesse rotation;mesure angle;cuerpo movil;transformation lineaire;solid dynamic;methode pas a pas;postura;high speed cinematography;euler equations;mean square error methods;golf;linear transformation;vitesse angulaire;dynamique solide;angular velocity;angular acceleration;moving body;systeme coordonnee;sport;linear systems motion control gyroscopes sensor measurements three dimensional displays accelerometers;muestreo;motion measurement;infrared camera;accelerometers;3 d accelerometer;cost;reflecteur;dinamico solido;golf motion measurement;sport accelerometers cameras image sensors mean square error methods motion measurement;cameras;transformacion lineal;coordinate system;cout;reflectors	This paper describes a novel method for measuring golf swing angular motion in a global coordinate system using the 3-D acceleration and angular velocity detected by a local motion sensor set at the grip end of a golf club. Optical direct linear transformation (DLT) is the conventional method for measuring sports motion; however, accurate localization of global coordinates and precise setting of infrared high-speed cameras in the test field are essential. Furthermore, infrared reflectors must be attached to the moving object. The system itself and the fine-tuning are expensive, but an accurately set system can provide precise positions for the moving reflectors. It is effective for measuring translational motion but not angular motion that is based on the principles of measurement. The alternative method that is proposed here is easier in terms of setting and fine-tuning, more reasonable in cost, and more accurate in measuring rotational motion compared with the DLT method. Furthermore, the system's wireless transmitter enables noninvasive measurement. When addressing the golf club, its initial angles and posture matrix are calculated using the 3-D acceleration; when the swing begins, the motion sensor measures the changing angular velocity and the acceleration. The application of step-by-step Euler transformation for each sampling interval yields the angular velocity and angle in the global coordinate system. The mean RMSE of ten trials with five subjects was 3.06°, 26.64°, and 4.43° for the 3-D angle of the club shaft.	angularjs;dlt;direct linear transformation;euler;motion detector;poor posture;sampling (signal processing);the golf club;traffic enforcement camera;transmitter;velocity (software development)	Masahiko Ueda;Hiroshi Negoro;Yosuke Kurihara;Kajiro Watanabe	2013	IEEE Transactions on Human-Machine Systems	10.1109/TSMC.2013.2266896	sampling;simulation;angular velocity;sport;coordinate system;angular acceleration;motion estimation;euler equations;quantum mechanics;linear motion	Robotics	59.252208004333	-35.78813610658711	197768
72933db9c09a69b9d6cc6f8699f3aabc1fc75104	the mit stata center dataset	data paper;stata;laser;mobile robotics;pr2;simultaneous localization and mapping;stereo;mit;willow garage;csail	This paper presents a large scale dataset of vision (stereo and RGB-D), laser and proprioceptive data collected over an extended duration by a Willow Garage PR2 robot in the 10 story MIT Stata Center. As of September 2012 the dataset comprises over 2.3TB, 38 hours and 42 kilometers (the length of a marathon). The dataset is of particular interest to robotics and computer vision researchers interested in long-term autonomy. It is expected to be useful in a variety of research areas robotic mapping (long-term, visual, RGB-D or laser), change detection in indoor environments, human pattern analysis, long-term path planning. For ease of use the original ROS ‘bag’ log files are provided and also a derivative version combining human readable data and imagery in standard formats. Of particular importance, this dataset also includes ground-truth position estimates of the robot at every instance (to typical accuracy of 2cm) using as-built floor-plans which were carefully extracted using our software tools. The provision of ground-truth for such a large dataset enables more meaningful comparison between algorithms than has previously been possible.	algorithm;computer vision;data logger;ground truth;human-readable medium;marathon;motion planning;pattern recognition;robot;robotic mapping;robotics;stata;terabyte;usability;willow	Maurice F. Fallon;Hordur Johannsson;Michael Kaess;John J. Leonard	2013	I. J. Robotics Res.	10.1177/0278364913509035	simulation;laser;computer science;engineering;artificial intelligence;stereophonic sound;simultaneous localization and mapping	Robotics	54.07790806150634	-30.509907982246567	197890
f1ca3f8e051cc75d107c8b0c0539247870b34409	dual-driver networked fire truck simulator with multimodal display including force feedback steering and rotating motion platform	force manager;groupware;force feedback wheel;collaborative virtual environment groupware;collaborative work;c programs;java3d dual driver networked fire truck simulator multimodal display force feedback steering rotating motion platform force feedback wheel collaborative virtual environment groupware double driver fire truck simulation c programs directlnput force manager;fires displays force feedback wheels vehicle driving navigation collaboration virtual environment collaborative software collaborative work;collaboration;virtual reality;vehicle driving;driving simulator;java3d;rotating motion platform;force feedback;navigation;c language;force feedback steering;displays;double driver fire truck simulation;computer displays;multimodal display;dual driver networked fire truck simulator;virtual environment;fires;virtual space;collaborative virtual environment;virtual reality c language computer displays force feedback groupware java;directlnput;collaborative software;wheels;java;haptic interface	We describe the integration of two pairs of force displays - a force-feedback wheel (FFBW) and the c Shaire ('Share Chair'), a rotary motion platform - in a dual-driver networked driving simulator which navigates through virtual space using CVE (collaborative virtual environment) groupware. We developed a double-driver (long ladder-style) fire-truck simulation with a tiller (rear steering), driven via an integrated pair of networked driving simulator stations. Such a dual-driver system is useful to turn narrow corners rapidly and smoothly in case of (simulated) emergencies. Its FFB steering wheels display simple collision force to both drivers separately when the vehicle collides with walls or other vehicles. The technique of feeding back the effect employs programs using C++ and Directlnput, escaping to an execution file called force-manager from the driving simulator, which is implemented with Java3D. Effect patterns are changed by arguments to forcemanager. The c Shaire is rotated with a servo-motor, the rotation angle controlled via internet through the CVE. A demonstration video is posted at http: //sonic.u-aizu.ac.jp/spatial-media/Videos/DualDrivingSimulator.mov.	c++;collaborative software;collaborative virtual environment;common vulnerabilities and exposures;device driver;driving simulator;haptic technology;hypertext transfer protocol;java 3d;motion simulator;multimodal interaction;rotary woofer;servo;simulation;smoothing;steering wheel;virtual reality;wheels	Tatsuya Nagai;Michael Cohen;Yoshinori Moriguchi;Yoko Murakami	2007	16th IEEE International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE 2007)	10.1109/WETICE.2007.139	embedded system;simulation;computer science;artificial intelligence;virtual reality;haptic technology;management;collaborative software	Visualization	62.68712794202164	-29.608748279723486	197891
1aa973a89ed85124a3926b92c0a3b261c3ed25ca	decentralized multi-uav flight autonomy for moving convoys search and track	unmanned aerial vehicles target tracking process control roads search problems urban areas heuristic algorithms;unmanned aerial vehicle uav finite state automata mission planning road map target search target tracking	This brief is concerned with integrated autonomous takeoff, target search, task assignment, and tracking using multiple fixed-wing unmanned aerial vehicles (UAVs) in urban environments. The problem is to design flight autonomy that is embedded onboard each UAV to enable autonomous flight coordination and distributed tasking. Control logic design based on a finite state automaton model, integrating four modes of operations, namely, the takeoff mode, the fly-to-area of operation mode, the search mode, and the tracking mode, is presented. Different from the state-of-the-art of recent research, this brief provides a preliminary research on the autonomous cooperative takeoff for miniature fixed-wing UAVs, by considering collision avoidance, communication failure, etc. To make UAVs autonomously and cooperatively search roads in the urban environments, an efficient improved search algorithm is proposed based on recent research on the coverage search in the literature. For the target tracking, using geometric relations (relative position, orientations, speed ratio, and minimal turning radius), a systematic algorithm is developed to generate an optimal online path. All the algorithms in this work are developed based on realistic miniature fixed-wing UAV dynamic models. The main focus of the brief is to test the developed control logic and also the algorithms. The proposed framework is evaluated by our 3-D multi-UAV test bed.	aerial photography;automaton;autonomous robot;distributed control system;embedded system;finite-state machine;search algorithm;simulation;testbed;unmanned aerial vehicle	Wei Meng;Zhirong He;Rong Su;Pradeep K. Yadav;Rodney Swee Huat Teo;Lihua Xie	2017	IEEE Transactions on Control Systems Technology	10.1109/TCST.2016.2601287	computer vision;simulation;engineering;aeronautics	Robotics	56.299659584824866	-26.15655373879164	198088
