id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
094b18fad8fdf94ffb7a47af68fd5aa7d786f9f5	accurate face models from uncalibrated and ill-lit video sequences	object segmentation;perceptual grouping;large spectrum;embodied approach;non-static image;different scenario;humanoid robot;proposed algorithm;human teacher;humanoid robots;actuators;robustness;spectrum;image resolution;computer vision;layout;image segmentation	We propose a face reconstruction technique that produces models that not only look good when texture mapped, but are also metrically accurate. Our method is designed to work with short uncalibrated video or movie sequences, even when the lighting is poor resulting in specularities and shadows that complicate the algorithm's task. Our approach relies on optimizing the shape parameters of a sophisticated PCA based model given pairwise image correspondences as input. All that is required is enough relative motion between camera and subject so that we can derive structure from motion. By matching the results against laser scanning data, we will show that its precision is excellent and can be predicted as a junction of the number and quality of the correspondences. This is important if one wishes to obtain the appropriate compromise between processing speed and quality of the results. Furthermore, our method is in fact not specific to faces and could equally be applied to any shape for which a shape model controlled with relatively small number of parameters exists.	algorithm;bundle adjustment;feature vector;linear model;principal component analysis;structure from motion;texture mapping;time complexity;transfer function;uncontrolled format string	Miodrag Dimitrijevic;Slobodan Ilic;Pascal Fua	2004	Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.	10.1109/CVPR.2004.26	laser scanning;iterative reconstruction;texture mapping;computer vision;structure from motion;computer science;pattern recognition;mathematics;bundle adjustment;shape parameter;statistics;principal component analysis;computer graphics (images)	Vision	59.54959524415278	-45.78513607904093	63768
67db101ac7b95315d050faf5e1260ae2e724f25d	icp stereo visual odometry for wheeled vehicles based on a 1dof motion prior	three dimensional displays iterative closest point algorithm cameras computational modeling vehicles sensitivity vectors;off road terrains icp stereo visual odometry algorithm wheeled vehicles 1dof motion prior ground vehicles outdoor environments random sample schemes single degree of freedom kinematic model iterative closest point algorithm high quality inlier selection standard linear 3d to 2d pose estimation method synthetic data publicly available datasets;stereo image processing distance measurement iterative methods mobile robots motion estimation pose estimation road vehicles robot kinematics robot vision	In this paper, we propose a novel, efficient stereo visual-odometry algorithm for ground vehicles moving in outdoor environments. To avoid the drawbacks of computationally-expensive outlier-removal steps based on random-sample schemes, we use a single-degree-of-freedom kinematic model of the vehicle to initialize an Iterative Closest Point (ICP) algorithm that is utilized to select high-quality inliers. The motion is then computed incrementally from the inliers using a standard linear 3D-to-2D pose-estimation method without any additional batch optimization. The performance of the approach is evaluated against state-of-the-art methods on both synthetic data and publicly-available datasets (e.g., KITTI and Devon Island) collected over several kilometers in both urban environments and challenging off-road terrains. Experiments show that the our algorithm outperforms state-of-the-art approaches in accuracy, runtime, and ease of implementation.	3d pose estimation;algorithm;display resolution;experiment;file spanning;iterative closest point;iterative method;mathematical optimization;planetary scanner;random sample consensus;rover (the prisoner);sampling (signal processing);stereo camera;stereo cameras;synthetic data;visual odometry	Yanhua Jiang;Huiyan Chen;Guangming Xiong;Davide Scaramuzza	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6906914	computer vision;simulation;geodesy	Robotics	54.125393771499674	-41.422463440690215	63847
627b8d1fe0c5b65985486adbb53d549233627e37	parametric blending in a boundary representation solid modeller	boundary representation;solid modelling			Tamás Várady;Janos Vida;Ralph R. Martin	1988			computer science;theoretical computer science;engineering drawing;boundary representation	Vision	66.31955409316029	-43.711637290543834	63995
41703fa6276c7e1efd774ac9321255e1465a318b	efficient joint stereo estimation and land usage classification for multiview satellite data	image resolution;geometry;semantics;stereo image processing computational geometry estimation theory geographic information systems neural nets polynomials;estimation;three dimensional displays;satellites;ground level imagery joint stereo estimation land usage classification multiview satellite data geographical region patchmatch inference framework lattice discretization local planarity scene geometry neural network classification semantic label rational polynomial coefficient satellite camera model inverse rpc model satellite imagery;cameras;satellites three dimensional displays semantics geometry cameras estimation image resolution	We propose an efficient algorithm to jointly estimate geometry and semantics for a given geographical region observed by multiple satellite images. Our joint estimation leverages an efficient PatchMatch inference framework defined over lattice discretization of the environment. Our cost function relies on the local planarity assumption to model scene geometry and neural network classification to determine semantic (e.g. land use) labels for geometric structures. By utilizing the commonly available direct (i.e. space to image) rational polynomial coefficients (RPC) satellite camera models, our approach effectively circumvents the need for estimating or refining inverse RPC models. Experiments illustrate both the computational efficiency and high quality scene geometry estimates attained by our approach for satellite imagery. To further illustrate the generality of our representation and inference framework, experiments on standard benchmarks for ground-level imagery are also included.	algorithm;artificial neural network;authorization;coefficient;computation;convolutional neural network;discretization;display resolution;experiment;loss function;overhead (computing);parsing;patchmatch;planar graph;polynomial	Ke Wang;Craig Stutts;Enrique Dunn;Jan-Michael Frahm	2016	2016 IEEE Winter Conference on Applications of Computer Vision (WACV)	10.1109/WACV.2016.7477657	computer vision;estimation;simulation;image resolution;machine learning;geometry;semantics;satellite;statistics	Vision	57.29179727041531	-46.26087119817022	64254
770ee4614d7105a25378946ca495cc6182f4623d	inertial-based scale estimation for structure from motion on mobile devices		Structure from motion algorithms have an inherent limitation that the reconstruction can only be determined up to the unknown scale factor. Modern mobile devices are equipped with an inertial measurement unit (IMU), which can be used for estimating the scale of the reconstruction. We propose a method that recovers the metric scale given inertial measurements and camera poses. In the process, we also perform a temporal and spatial alignment of the camera and the IMU. Therefore, our solution can be easily combined with any existing visual reconstruction software. The method can cope with noisy camera pose estimates, typically caused by motion blur or rolling shutter artifacts, via utilizing a Rauch-Tung-Striebel (RTS) smoother. Furthermore, the scale estimation is performed in the frequency domain, which provides more robustness to inaccurate sensor time stamps and noisy IMU samples than the previously used time domain representation. In contrast to previous methods, our approach has no parameters that need to be tuned for achieving a good performance. In the experiments, we show that the algorithm outperforms the state-of-the-art in both accuracy and convergence speed of the scale estimate. The accuracy of the scale is around 1% from the ground truth depending on the recording. We also demonstrate that our method can improve the scale accuracy of the Project Tango's build-in motion tracking.	algorithm;computer performance;experiment;gaussian blur;ground truth;mobile device;movie projector;rate of convergence;structure from motion;tango;tung-sol	Janne Mustaniemi;Juho Kannala;Simo Särkkä;Jiri Matas;Janne Heikkilä	2017	2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2017.8206303	motion blur;computer science;scale factor;robustness (computer science);artificial intelligence;computer vision;control engineering;frequency domain;inertial measurement unit;structure from motion;time domain;match moving	Robotics	53.97649058744425	-42.05331643900185	64769
ca80cc319af8234ad67e0d453e066ad0dabf2c7a	new advances in obtaining three-dimensional models from conical perspectives	image based modeling;image reconstruction;single image technique;conical perspective	In a previous work we presented algorithms which allow obtaining three-dimensional models from graphs which represent a projection in conical parallel perspectives and conical oblique perspectives of polyhedral models with normalon and quasi-normalon typology. In this paper the new advances that we have achieved in this field are presented, allowing increasing the set of models which can be reconstructed to other typologies different from the normalon and quasi-normalon ones. Moreover, we present a new technique which extends the previous work in order to be implemented to conical perspectives with three vanishing points, and the method proposed for the detection of the type of conical perspective represented by the graph, including the detection and subsequent reconstruction of graphs which represent a flat shape, has been improved. The results obtained on a total of 336 tests, with a success ratio of 100%, make the method a proposal to be considered for obtaining models from conical perspectives automatically. © 2016 Elsevier Ltd. All rights reserved.	algorithm;biological anthropology;graph (discrete mathematics);oblique projection;polyhedron	Julián Francisco Conesa Pastor;Francisco J. Mula Cruz	2016	Advances in Engineering Software	10.1016/j.advengsoft.2016.02.012	iterative reconstruction;mathematical optimization;combinatorics;mathematics;geometry	AI	67.6269323218022	-42.949490646769284	64818
896cd8c7bbb7fd868679bc3749be8ded83b10d06	parallel processing method for realtime ftv	arbitrary viewpoint;computers;image capture;realtime processing;interpolation;realtime ftv;image processing;high density;free viewpoint image generation;ftv;television cameras;time consuming interpolation;servers;television cameras image processing interpolation parallel processing;image generation;time consuming interpolation parallel processing realtime ftv high quality free viewpoint image image capture arbitrary viewpoint image quality;interpolation pixel computers parallel processing cameras servers image generation;image quality;pixel;parallel processing ftv free viewpoint image generation image based rendering realtime processing;high quality free viewpoint image;image based rendering;parallel processing;cameras	In this paper, we propose a parallel processing method to generate free viewpoint image in realtime. It is impossible to arrange the cameras in a high density realistically though it is necessary to capture images of the scene from innumerable cameras to express the free viewpoint image. Therefore, it is necessary to interpolate the image of arbitrary viewpoint from limited captured images. However, this process has the relation of the trade-off between the image quality and the computing time. In proposed method, it aimed to generate the high-quality free viewpoint image in realtime by applying the parallel processing to time-consuming interpolation part.	image quality;interpolation;parallel computing	Kazuma Suzuki;Norishige Fukushima;Tomohiro Yendo;Mehrdad Panahpour Tehrani;Toshiaki Fujii;Masayuki Tanimoto	2010	28th Picture Coding Symposium	10.1109/PCS.2010.5702500	image quality;parallel processing;computer vision;image-based modeling and rendering;image processing;interpolation;computer science;professional video camera;multimedia;pixel;server;computer graphics (images)	Robotics	65.59945065566647	-51.80645437079587	64824
728bab5fcf2702043dcdaa60eb928f5b85ed4236	requirements for camera calibration: must accuracy come with a high price?	2d camera image;measurement error;3d scenes;pixel coordinate noise;controlled experiment;image sensors;computer vision;2d camera image camera calibration pixel coordinate noise simulated camera system real world measurement 3d scenes;real world measurement;image sensors calibration cameras computer vision;simulated camera system;camera calibration;calibration;cameras;cameras calibration training data computer vision application software layout working environment noise coordinate measuring machines testing sun	Since a large number of vision applications rely on the mapping between 3D scenes and their corresponding 2D camera images, an important practical consideration for researchers is, what are the major determinants of camera calibration accuracy and what accuracy can be achieved within the practical limits of their environments. In response, we present a thorough study investigating the effects of training data quantity, measurement error, pixel coordinate noise, and the choice of camera model, on camera calibration results. Through this effort, we seek to determine whether expensive, elaborate setups are necessary, or indeed, beneficial, to camera calibration, and whether a high complexity camera model leads to improved accuracy. The results are first provided for a simulated camera system and then verified through carefully controlled experiments using real-world measurements	camera resectioning;experiment;pixel	Wei Sun;Jeremy R. Cooperstock	2005	2005 Seventh IEEE Workshops on Applications of Computer Vision (WACV/MOTION'05) - Volume 1	10.1109/ACVMOT.2005.102	smart camera;stereo camera;computer vision;camera auto-calibration;camera matrix;calibration;camera resectioning;simulation;computer science;image sensor;camera interface;three-ccd camera;digital camera back;pinhole camera model;computer graphics (images);observational error	Vision	55.85775612200681	-44.20584607843674	64975
9bc1366d5980658be94f918b54ba13e5c2f61826	planar simplification and texturing of dense point cloud maps	computational geometry;image texture;redundancy;three dimensional displays approximation algorithms robots image color analysis shape laser radar redundancy;robots;planar segments dense point cloud maps dense rgb d based slam techniques high fidelity lidar scanner real time robotics data redundancy planar surface triangulation planar surface texturing input planar points planar simplification algorithm vertex count principal geometric features texture generation algorithm colour information;mesh generation;robots computational geometry image texture mesh generation real time systems redundancy;real time systems	Dense RGB-D based SLAM techniques and high-fidelity LIDAR scanners are examples from an abundant set of systems capable of providing multi-million point datasets. These large datasets quickly become difficult to process and work with due to the sheer volume of data, which typically contains significant redundant information, such as the representation of planar surfaces with hundreds of thousands of points. In order to exploit the richness of information provided by dense methods in real-time robotics, techniques are required to reduce the inherent redundancy of the data. In this paper we present a method for efficient triangulation and texturing of planar surfaces in large point clouds. Experimental results show that our algorithm removes more than 90% of the input planar points, leading to a triangulation with only 10% of the original amount of triangles per planar segment, improving upon an existing planar simplification algorithm. Despite the large reduction in vertex count, the principal geometric features of each segment are well preserved. In addition to this, our texture generation algorithm preserves all colour information contained within planar segments, resulting in a visually appealing and geometrically accurate simplified representation.	algorithm;decimation (signal processing);level of detail;map;point cloud;real-time clock;real-time transcription;robot;robotics;simultaneous localization and mapping;texture mapping	Lingni Ma;Thomas Whelan;Egor Bondarev;Peter H. N. de With;John McDonald	2013	2013 European Conference on Mobile Robots	10.1109/ECMR.2013.6698837	robot;image texture;mesh generation;computer vision;computational geometry;computer science;artificial intelligence;planar straight-line graph;redundancy;computer graphics (images)	Robotics	56.67639373756652	-45.312690216193104	65077
2f39ca50805173ef9fcec5b93ba924c47a4006b5	dynamic shadowmap regeneration with extended depth buffers		The original shadow mapping algorithm grants that construction of the light's depth buffer and the screen rendering are sequential jobs that cannot be inter- laced. Dynamic shadow map redrawing method presented in this article is a muta- tion of the base shadowing method that allows one to construct a variable depth buffer giving the flexible way for in-place adding of primitives to the earlier rendered partial scene. A fast innovative method for re-shading the previously lightened areas of screen, which can be applied in real-time environments, will be presented.	z-buffering	Rafal Wcislo;Rafal Bigaj	2004		10.1007/1-4020-4179-9_87	computer science;engineering drawing;cartography;computer graphics (images)	Theory	66.74441731810852	-50.84120583817316	65158
7e42f2aae64bc297372e94ec53df66baf0b2f91e	vr-orientated 3d modeling and visualization of pseudo-classic building complex	virtual reality architectural cad data visualisation rendering computer graphics solid modelling;visualization buildings rendering computer graphics art cultural differences image reconstruction protection particle measurements spatial indexes image quality;cultural heritage;virtual reality;spatial index;data visualisation;3d model;discrete model;image quality;level of detail virtual reality orientated 3d modeling pseudoclassic building complex architectural technology timber frame building lod r tree spatial index image quality gpu based shader rendering occlusion culling dds texture format vertex buffer object lod cad modeling;architectural cad;rendering computer graphics;solid modelling;occlusion culling	The architectural technology and art of the timber-frame buildings are precious wealth in the Chinese cultural heritage; however there are a few relics in China and even a few literal records about that. Using the VR-orientated 3D modeling technology to reconstruct the ancient buildings is a critical approach for researching and protecting the historic relics. The LOD-CAD modeling measures those 4 discrete LOD models are established for every building is discussed particularly, and models are decomposed into several appropriate parts according to the structural feature of the buildings and limitation of data quantity. The discrete models are organized in LOD-R-tree spatial index, and a strategy of minimizing the change of rendering state is addressed for obtaining interactive frame rate. For improving the image quality of rendering GPU-based shaders are developed, and occlusion culling, DDS texture format, and vertex buffer object are employed to raise rendering efficiency	3d modeling;computer-aided design;glossary of computer graphics;graphics processing unit;hidden surface determination;image quality;literal (computer programming);r-tree;shader;spatial database;vertex buffer object	Zhiqiang Du;Dongbo Zhou;Lihua Zhang	2006	16th International Conference on Artificial Reality and Telexistence--Workshops (ICAT'06)	10.1109/ICAT.2006.150	computer vision;tiled rendering;image-based modeling and rendering;3d rendering;rendering;engineering;parallel rendering;multimedia;real-time rendering;texture memory;alternate frame rendering;software rendering;computer graphics (images)	Visualization	64.90558540707973	-51.81013965405798	65343
4e02b6debab3e5e8a1275fb6d88257d2d739a034	schlieren imaging and the real world	density sensitive flow visualization;front lighting;compressible flows			Harald Kleine	2013	J. Visualization	10.1007/s12650-013-0169-y	optics;synthetic schlieren;computer graphics (images)	Visualization	63.252885571324434	-51.69894810911232	65398
afd0bcf6b574130a4241da5b025cea1f4bacbd01	geometry synthesis		Geometry synthesis relates to geometry modeling much like texture synthesis relates to texture modeling. Textures can be created by hand, generated procedurally, or synthesized from existing textures. Likewise, geometry can be modeled by hand, and specific types of geometry can be generated procedurally. However, there are currently no techniques to generate geometry by example. Inspired by texture synthesis techniques, such as the one by [Liang et al. 2001], we present a method for geometry synthesis. Given an example of input geometry, we synthesize new output geometry that is perceived to be similar to the input geometry.	computational geometry;geometric modeling;procedural modeling;texture synthesis	Ares Lagae;Olivier Dumont;Philip Dutré	2004		10.1145/1186223.1186270	computer vision;computer graphics (images);artificial intelligence;computer science	Graphics	65.00539323207863	-46.828103279882775	65583
3599f1a0e407ec78435b7f6adc5629ddf5634f67	exploration of porous structures with illustrative visualizations	porous structures;transfer functions;volume ray casting;computer graphic;virtual navigation;transfer function;topological graph;illustrative visualization	The analysis of porous structures from CT images is emerging as a new computer graphics application that is useful in diverse scientific fields such as BioCAD and geology. These structures are very complex and difficult to analyze visually when they are presented with traditional rendering techniques. In this paper, we describe a visualization application based on illustrative techniques for rendering porous structures. We provide various interactive pore selection mechanisms and visualization styles that allow users to better perceive the connectivity between pores and how they are distributed by radii throughout the structure. The application also shows simulations of fluid intrusion or extrusion through the structure, and it allows users to navigate inside. We describe our application and discuss the experimental results with phantom models, BioCAD scaffolds, implants and rock samples. Graphical AbstractWe describe a porous structures visualization application based on illustrative techniques. It provides pore selection mechanisms, different visualization styles, simulations of fluid intrusion, and navigations inside. Display Omitted Research Highlights? The analysis of porous structures can be enhanced using a graphical model. ? A volume model of the structure alone is difficult to explore. ? The combination of a graph connectivity and a volume model provides tools to efficiently explore pore structures. ? The use of illustrative techniques such as cut-away, ghosting, edge enhancement and colormaps provides clues on the pore size and the topological distances between pores.	music visualization	Sergi Grau;Eduard Vergés;Dani Tost;Dolors Ayala	2010	Computers & Graphics	10.1016/j.cag.2010.05.001	computer vision;simulation;mathematics;transfer function;computer graphics (images)	HCI	65.49756728007375	-46.9187746452433	65618
831fbb6176b0aabd79e908caa5be763ed3bb1258	modeling and rendering of realistic feathers	different part;key feather;appropriate feather;rendering algorithm;natural phenomena;feather geometry;bidirectional texture function;feather;l-system;rendering;feather blade;bird;feather modeling;realistic rendering;parametric l-system;realistic feather;btf displays feathers photorealistically	"""We present techniques for realistic modeling and rendering of feathers and birds. Our approach is motivated by the observation that a feather is a branching structure that can be described by an L-system. The parametric L-system we derived allows the user to easily create feathers of different types and shapes by changing a few parameters. The randomness in feather geometry is also incorporated into this L-system. To render a feather realistically, we have derived an efficient form of the bidirectional texture function (BTF), which describes the small but visible geometry details on the feather blade. A rendering algorithm combining the L-system and the BTF displays feathers photorealistically while capitalizing on graphics hardware for efficiency. Based on this framework of feather modeling and rendering, we developed a system that can automatically generate appropriate feathers to cover different parts of a bird's body from a few """"key feathers"""" supplied by the user, and produce realistic renderings of the bird."""		Yanyun Chen;Ying-Qing Xu;Baining Guo;Harry Shum	2002	ACM Trans. Graph.	10.1145/566654.566628	bidirectional texture function;simulation;rendering;computer science;feather;l-system;graphics hardware;computer graphics (images)	Graphics	64.77744443584234	-48.80803800115318	65620
18d20b239bf2182b08d825e47c3f18ad927dddf9	interactive character posing by sparse coding		Character posing is of interest in computer animation. It is difficult due to its dependence on inverse kinematics (IK) techniques and articulate property of human characters . To solve the IK problem, classical methods that rely on numerical solutions often suffer from the under-determination problem and can not guarantee naturalness. Existing data-driven methods address this problem by learning from motion capture data. When facing a large variety of poses however, these methods may not be able to capture the pose styles or be applicable in realtime environment. Inspired from the low-rank motion de-noising and completion model in [LYL11], we propose a novel model for character posing based on sparse coding. Unlike conventional approaches, our model directly captures the pose styles in Euclidean space to provide intuitive training error measurements and facilitate pose synthesis. A pose dictionary is learned in training stage and based on it natural poses are synthesized to satisfy users’ constraints . We compare our model with existing models for tasks of pose de-noising and completion. Experiments show our model obtains lower de-noising and completion error. We also provide User Interface(UI) examples illustrating that our model is effective for interactive character posing.	computer animation;computer science;dictionary;inverse kinematics;motion capture;neural coding;numerical analysis;personal computer;real-time computing;sparse matrix;test set;user interface	Ranch Y. Q. Lai;Pong C. Yuen;Kelvin K. W. Lee;Jianhuang Lai	2012	CoRR		computer vision;simulation;computer science;artificial intelligence;mathematics;geometry;algorithm;computer graphics (images)	Graphics	60.858236151463835	-45.21853570769898	65629
13e735f103dfd3c4236abfd99390a611bf701d62	line reconstruction from many perspective images by factorization	image reconstruction jacobian matrices cameras layout robustness cybernetics tensile stress geometry equations;cybernetics;matrix factorization;tensile stress;hidden feature removal;occlusion;edge detection;occlusion line reconstruction perspective image matrix factorization plucker line coordinate klein identity trifocal tensor svd based factorization;singular value decomposition;trifocal tensor;geometry;line reconstruction;layout;line detection;satisfiability;hidden feature removal image reconstruction edge detection singular value decomposition;image reconstruction;svd based factorization;plucker line coordinate;robustness;jacobian matrices;cameras;perspective image;klein identity	This paper brings a new method for line reconstruction from many perspective images by factorization of a matrix containing line correspondences. No point correspondences are used. We formulate the reconstruction from line correspondences in the language of Pl ücker line coordinates. The reconstruction is posed as the factorization of 3m × n matrix S into the productS = QL of 3m × 6 projection matrixQ and6×n line matrixL, both satisfying Klein identities. The matrixS contains coordinates of lines detected in perspective images. Similarly to reconstruction from point correspondences in perspective images, the matrix S has to be properly rescaled before it can be factorized. We propose a scaling of image line coordinates based on trifocal tensors that is analogical to the scaling proposed by Sturm and Triggs for points. We propose an SVD based factorization enforcing Klein identities on Q andL in a noise-free situation. We show experiments on real data that suggest that a good reconstruction may be obtained even if data is noisy and the identities are not enforced exactly. We also discuss an extension of the method for images with occlusions.	approximation algorithm;bundle adjustment;compiler;correspondence problem;experiment;heuristic (computer science);image scaling;missing data;nonlinear system;reprojection error;singular value decomposition;sturm's theorem;the matrix;trifocal tensor;virtual reality headset	Daniel Martinec;Tomás Pajdla	2003		10.1109/CVPR.2003.1211395	iterative reconstruction;layout;computer vision;combinatorics;edge detection;cybernetics;computer science;mathematics;geometry;stress;matrix decomposition;singular value decomposition;trifocal tensor;robustness;satisfiability	Vision	54.18974791148738	-51.19185687643514	65884
6ea2085e8f7d38975dfb15a04fce389c3bd78f06	variables effecting photomosaic reconstruction and ortho-rectification from aerial survey datasets		Unmanned aerial vehicles now make it possible to obtain high quality aerial imagery at a low cost, but processing those images into a single, useful entity is neither simple nor seamless. Specifically, there are factors that must be addressed when merging multiple images into a single coherent one. While ortho-rectification can be done, it tends to be expensive and time consuming. Image stitching offers a more economical, low-tech approach. However direct application tends to fail for low-elevation imagery due to one or more factors including insufficient keypoints, parallax issues, and homogeneity of the surveyed area. This paper discusses these problems and possible solutions when using techniques such as image stitching and structure from motion for generating ortho-rectified imagery. These are presented in terms of actual Irish projects including the Boland's Mills building in Dublin's city centre, the Kilmoon Cross Farm, and the Richview buildings on the University College Dublin campus. Implications for various Irish industries are explained in terms of both urban and rural projects. 1 INTRODUCTION Ortho-rectified imagery provides a useful tool to civil engineers for planning, boundary mapping, and surveying. It can furnish information sufficiently detailed to derive measured drawings, with the added benefit of containing visual information not typically captured in standard line drawings. However, traditional ortho-rectification is a slow and labour-intensive process. Once aerial imagery has been gathered, a surveyor must collect ground control points (GCP) visible in the overhead images. This involves either using a global positioning system (GPS) with a real time kinematics system or a total station throughout the survey area. While both can provide excellent accuracy, the costs to do so are high. Alternatively, there are automatic techniques for matching and merging images. The two primary approaches to automatically generating orthomosaics are photo-stitching and Structure From Motion (SFM). Photo-stitching combines multiple images with overlapping fields of a view to create a high resolution image. While the process is very fast, lighting variance and image alignment can be problematic. In contrast, the newer SFM approach operates on a principle similar to stereo vision to generate a three-dimensional (3D) scene model. Although SFM is much more computationally expensive, it generates a 3D model, which can be used to generate an ortho-rectified image; photo-stitching cannot. UAV photography differs from traditional satellite or aerial imagery in that it is usually captured at a much lower height: normally between 30 m and 100 m. Accordingly, specific factors …	aerial photography;aerial survey;analysis of algorithms;coherence (physics);display resolution;games computers play;global positioning system;image rectification;image resolution;image stitching;map projection;matching (graph theory);orthophoto;overhead (computing);parallax;rectifier;seamless3d;stereopsis;structure from motion;unmanned aerial vehicle	Jonathan Byrne;Debra F. Laefer	2016	CoRR		computer vision;simulation;machine learning;operations research	Vision	57.892267008374596	-45.25870469361803	65968
875514825ea474b7508b71422232e5ebda3dc7cd	procedural modeling and visualization of multiple leaves		In this study, we propose an effective method of easy and intuitive modeling of various types of multiple leaves from plants, including flowering plants and trees, and of naturally visualizing them. This method consists of two processes. The first is the procedural modeling of leaf venation patterns. The proposed method enables modeling of the growth of leaf veins based on the information of auxin detected from a binary image of a leaf blade. Therefore, a contour-based method is designed to automatically obtain information on the target auxin, required for the growth, according to blade shapes. In addition, the growth of leaf veins is procedurally modeled by dividing the veins into main, lateral, and tertiary veins. To this end, we propose a two-level growth model. The second method we introduce is a color model based on convolution sums of divisor functions to naturally simulate the color patterns of leaf surfaces. This approach automatically defines various color patterns by creating color tables for consistent changes in the convolution sums. In addition, it synthesizes three layers consisting of noise and vein glow maps. Furthermore, we perform experiments to verify whether the proposed method is effective for generating various realistic leaves.	binary image;color;convolution;ecosystem;effective method;experiment;glow;image quality;lateral computing;lateral thinking;map;multitier architecture;population dynamics;procedural modeling;region of interest;simulation	Daeyeoul Kim;Jinmo Kim	2016	Multimedia Systems	10.1007/s00530-016-0503-z	theoretical computer science	AI	65.26857709396431	-47.92573273947217	66089
01fea00b526cd4a1a8edd9b3d6dbd0f75fd4f548	leather texture synthesis and rendering	random distribution;concepcion asistida;texture;computer aided design;rendu image;diagramme voronoi;restitucion imagen;computer graphics;texture synthesis;distribution aleatoire;sintesis imagen;image synthesis;chaussure;triangulacion;eclairage;textura;image rendering;conception assistee;synthese image;leather;triangulation;lighting;cuero;diagrama voronoi;distribucion aleatoria;grafico computadora;infographie;cuir;shoe;voronoi diagram;calzado;alumbrado	-A technique for simulating the surfaces of leather is described. It is based upon the random distribution of points over a 2D domain and subsequent triangulation. When illuminated using a simple lighting model, the resultant lighting variations have been shown to closely match those of real leather. Fully rendered examples are presented which illustrate the approach.	resultant;shading;simulation;texture synthesis;triangulation (geometry)	J. McCartney;B. K. Hinds;J. J. Zhang	1994	Computers & Graphics	10.1016/0097-8493(94)90119-8	probability distribution;voronoi diagram;triangulation;computer science;computer aided design;lighting;mathematics;geometry;texture;computer graphics;texture synthesis;computer graphics (images)	Graphics	66.44784124389085	-41.69354767495889	66108
c54433c0033f36289b0191bbd52567f4541532d1	motion signal processing	digital signal processing;motion control;motion capture;levels of abstraction;signal processing;dynamic time warping;human animation	Techniques from the image and signal processing domain can be successfully applied to designing, modifying, and adapting animated motion. For this purpose, we introduce multiresolution motion filtering, multitarget motion interpolation with dynamic timewarping, waveshaping and motion displacement mapping. The techniques are well-suited for reuse and adaptation of existing motion data such as joint angles, joint coordinates or higher level motion parameters of articulated figures with many degrees of freedom. Existing motions can be modified and combined interactively and at a higher level of abstraction than conventional systems support. This general approach is thus complementary to keyframing, motion capture, and procedural animation.	displacement mapping;interactivity;key frame;motion capture;motion interpolation;procedural animation;signal processing	Armin Bruderlin;Lance Williams	1995		10.1145/218380.218421	motion control;computer vision;motion capture;speech recognition;image processing;quarter-pixel motion;computer science;motion interpolation;digital signal processing;dynamic time warping;signal processing;digital image processing;motion estimation;computer graphics (images)	Graphics	61.160487307505136	-44.42958018978998	66155
bd26c4430585a4ff1d2ec07c0ed6db79e0e83a6d	fast global and partial reflective symmetry analyses using boundary surfaces of mechanical components	axisymmetry;b rep cad model;accuracy;local symmetry;cad cam;divide and conquer;reflective symmetry	Axisymmetry and planar reflective symmetry properties of mechanical components can be used throughout a product development process to restructure the modeling process of a component, simplify the computation of tool path trajectories, assembly trajectories, etc. To this end, the restructured geometric model of such components must be at least as accurate as the manufacturing processes used to produce them, likewise their symmetry properties must be extracted with the same level of accuracy to preserve the accuracy of their geometric model. The proposed symmetry analysis is performed on a B-Rep CAD model through a divide-and-conquer approach over the boundary of a component with faces as atomic entities. As a result, it is possible to identify rapidly all global symmetry planes and axisymmetry as well as local symmetries. Also, the corresponding algorithm is fast enough to be inserted in CAD/CAM operators as part of interactive modeling processes, Corresponding author: tel. +33 476574310 Email addresses: Gilles.Foucault@ujf-grenoble.fr (G. FOUCAULT), Jean-Claude.Leon@grenoble-inp.fr (J-C. LEON), Moreno.Trlin@inria.fr (M. TRLIN) Preprint submitted to Computer Aided Design March 13, 2014 *Highlights (for review)	algorithm;boundary representation;computation;computer-aided design;email;entity;geometric modeling;geometric modeling kernel;global storage architecture;interaction;leon;maximal set;new product development;powerset construction;reference architecture;shape analysis (digital geometry)	K. Li;Gilles Foucault;Jean-Claude Léon;Moreno Trlin	2014	Computer-Aided Design	10.1016/j.cad.2014.03.005	reflection symmetry;divide and conquer algorithms;pure mathematics;mathematics;geometry;accuracy and precision;engineering drawing;computer-aided technologies;statistics;mechanical engineering	Robotics	66.69595052995592	-42.30504656952445	66339
d59ad7d2f65c3b1d128445752c81bbd130f7363e	study on the method of high-precision vehicle-borne lidar point clouds data acquisition in existing railway survey		The existing railway survey is a necessary measure to master the railway situation and monitor the safety of railway operation. Compared with the existing traditional railway survey technology, using the method of non-contact measurement to obtain the line three-dimensional information along the line is a very important research topic. The application of vehicle-borne LiDAR technology in railway can effectively solve the problem. However, the accuracy of the vehicle-borne LiDAR point cloud data will be affected due to complex terrain and the electronic and electromagnetic equipment along the railway line which cannot support the requirements of the existing railway survey in this paper, we propose a novel approach to improve the accuracy of point cloud by deploying the reflective target. The method is verified by field experiment and precision analysis is performed for the experimental data. The results suggest that with the method, vehicle-borne LiDAR can meet the requirements of the existing railway survey, improve the efficiency and accuracy of collecting LiDAR data, enhance the ability to work in complex environments. Finally, research work of the paper is summarized and the prospect of the problems is presented.	data acquisition;point cloud;requirement	Wei Li;Xiaochun Ren;Fei Li;Wei Wang	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127302	experimental data;artificial intelligence;remote sensing;terrain;computer vision;point cloud;computer science;lidar;field experiment;data acquisition	Robotics	56.99443207419007	-39.39812108583407	66465
8071e25658f5128c9d10d4b1a81e574e1d06dede	adaptive extraction and representation of geometric structures from unorganized 3d point sets	unorganized data;surface reconstruction;computer graphic;visualisierung;3d point data;feature extraction;computergraphik;merkmalsextraktion;datenanalyse	The primary emphasis of this thesis concerns the extraction and representation of intrinsic properties of three-dimensional (3D) unorganized point clouds. The points establishing a point cloud as it mainly emerges from LiDaR (Light Detection and Ranging) scan devices or by reconstruction from two-dimensional (2D) image series represent discrete samples of real world objects. Depending on the type of scenery the data is generated from the resulting point cloud may exhibit a variety of different structures. Especially, in the case of environmental LiDaR scans the complexity of the corresponding point clouds is relatively high. Hence, finding new techniques allowing the efficient extraction and representation of the underlying structural entities becomes an important research issue of recent interest. This thesis introduces new methods regarding the extraction and visualization of structural features like surfaces and curves (e.g. ridge-lines, creases) from 3D (environmental) point clouds. One main part concerns the extraction of curve-like features from environmental point data sets. It provides a new method supporting a stable feature extraction by incorporating a probability-based point classification scheme that characterizes individual points regarding their affiliation to surface-, curveand volume-like structures. Another part is concerned with the surface reconstruction from (environmental) point clouds exhibiting objects that are more or less complex. A new method providing multiresolutional surface representations from regular point clouds is discussed. Following the applied principles of this approach a volumetric surface reconstruction method based on the proposed classification scheme is introduced. It allows the reconstruction of surfaces from highly unstructured and noisy point data sets. Furthermore, contributions in the field of reconstructing 3D point clouds from 2D image series are provided. In addition, a discussion concerning the most important properties of (environmental) point clouds with respect to feature extraction is presented.	cellular automaton;comparison and contrast of classification schemes in linguistics and metadata;entity;feature extraction;multiresolution analysis;point cloud	Patric Keller	2009			computer vision;theoretical computer science;data mining;mathematics	Vision	59.486338146576045	-44.523813789052255	66503
2b9328ad356c039fed7488d10df1d55c0b66e1a6	stochastic billboard clouds for interactive foliage rendering	level of detail;smooth transition;reduction method;algorithm design;stochastic search	We render tree foliage levels of detail (LODs) using a new adaptation of billboard clouds. Our contributions are a simple and efficient billboard cloud creation algorithm designed specifically for tree foliage, and a method for smooth transitions between LODs. The cloud creation algorithm performs stochastic search to find a set of billboards that approximate the base mesh. Billboard clouds offer an alternative to traditional triangle reduction methods, which break down for foliage with its small, disconnected pieces of geometry. By projecting foliage geometry onto large precomputed textures, our method shifts the bulk of the runtime rendering to the fragment processing stage. This results in higher framerates for most viewing distances, with adjustable visual accuracy. We give results for foliage from two fully detailed tree models and discuss implementation issues.	approximation algorithm;fragment processing;level of detail;precomputation;stochastic optimization	J. Dylan Lacewell;David Edwards;Peter Shirley;William B. Thompson	2006	J. Graphics Tools	10.1080/2151237X.2006.10129213	algorithm design;computer vision;simulation;computer science;level of detail;geometry;algorithm;computer graphics (images)	Graphics	67.62698170895311	-46.8442353076094	66604
35c1308e303bd1c0fd089ffecb47aa36c4258533	synchronization of images from multiple cameras to reconstruct a moving human	telepresence;teleconferencing;image motion analysis;video streaming;head cameras three dimensional displays streaming media synchronization image reconstruction encoding;temporal divergence image synchronization moving human reconstruction algorithm live reconstruction video conferencing immersive collaborative virtual environment 3d video teleimmersion prototypes visual temporal quality acquisition stage multiple image feeding jitter frame synchronization multiple camera video streams 3d reconstruction;synchronisation tele immersion telepresence 3d reconstruction;synchronisation;media;video conferencing;streaming media;three dimensional displays;synchronization;image reconstruction;digital technology and the creative economy;head;video communication cameras image motion analysis image reconstruction solid modelling synchronisation teleconferencing;reconstruction algorithm;video communication;encoding;3d video;collaborative virtual environment;tele immersion;3d reconstruction;cameras;solid modelling;frame synchronization	What level of synchronization is necessary between images from multiple cameras in order to realistically reconstruct a moving human in 3D? Live reconstruction of the human form, from cameras surrounding the subject, could bridge the gap between video conferencing and Immersive Collaborative Virtual Environments (ICVEs). Video conferencing faithfully reproduces what someone looks like whereas ICVE faithfully reproduces what they look at. While 3D video has been demonstrated in tele-immersion prototypes, the visual/temporal quality has been way below what has become acceptable in video conferencing. Managed synchronization of the acquisition stage is universally used today to ensure multiple images feeding the reconstruction algorithm were taken at the same time. However, this inevitably increases latency and jitter. We measure the temporal characteristics of the capture stage and the impact of inconsistency on the reconstruction algorithm this feeds. This gives us both input and output characteristics for synchronization. From this we determine whether frame synchronization of multiple camera video streams actually needs to be delivered for 3D reconstruction, and if not what level of temporal divergence is acceptable across the captured image frames.	3d reconstruction;algorithm;collaborative virtual environment;distortion;image processing;immersion (virtual reality);input/output;observable;real-time clock;streaming media;synchronization (computer science);television;texture mapping	Carl M. Moore;Toby Duckworth;Rob Aspin;David J. Roberts	2010	2010 IEEE/ACM 14th International Symposium on Distributed Simulation and Real Time Applications	10.1109/DS-RT.2010.15	computer vision;computer science;multimedia;frame synchronization;computer graphics (images)	Vision	59.13411349618897	-50.1625097145216	66673
2c6801308889f8f4b36856fd540841f9ddc74942	intel realsense stereoscopic depth cameras		We present a comprehensive overview of the stereoscopic Intel RealSense RGBD imaging systems. We discuss these systems’ mode-of-operation, functional behavior and include models of their expected performance, shortcomings, and limitations. We provide information about the systems’ optical characteristics, their correlation algorithms, and how these properties can affect different applications, including 3D reconstruction and gesture recognition. Our discussion covers the Intel RealSense R200 and the Intel RealSense D400 (formally RS400).	3d reconstruction;ati radeon r200 series;algorithm;gesture recognition;intel realsense;stereoscopy	Leonid Keselman;John Iselin Woodfill;Anders Grunnet-Jepsen;Achintya Bhowmik	2017	CoRR		computer vision;computer hardware;computer graphics (images)	HPC	56.857069498575214	-44.71618204670086	66840
8cf5a13e26997caac9707fab447f78334af8aa2b	reconstruction of surfaces of revolution	generators;revolution;surface of revolution;3d textured model;rotary platform;surface reconstruction image reconstruction shape remote sensing cities and towns reconstruction algorithms geometry solid modeling protection reverse engineering;computational geometry;surface fitting;surface reconstruction;revolution model 3d textured model 3d shape recovery rotary platform object space reconstruction method symmetry property contour generator surface reconstruction;symmetry;image texture;three dimensional displays;image reconstruction;solid modeling;mathematical model;object space reconstruction method;symmetry revolution 3d reconstruction;contour generator;surface fitting computational geometry image reconstruction image texture solid modelling;3d shape recovery;symmetry property;3d reconstruction;cameras;solid modelling;revolution model	In the process of reconstruction of 3D textured models of revolution from images, the precise 3D shape of the revolution must be obtained in advance. This paper addresses the problem of recovering the 3D shape of revolution by symmetry property of revolution. A specially-designed rotary platform is used to obtain images of revolution and calculate image parameters at first, and then the topmost circle of the revolution is accurately reconstructed with a object-space reconstruction method. The rotation axis of revolution is calculated from the topmost circle of the revolution. The algorithm makes use of symmetry properties of surfaces of revolutions and their silhouette to rectify images so that the resulting silhouettes exhibits bilateral symmetry. Then the rectified image is then used to recover the contour generator and the object is reconstructed. Experimental results with real images are presented, which demonstrate the effectiveness of the approach	algorithm;bilateral filter;image rectification;optic axis of a crystal;rectifier;rotary woofer	Shunyi Zheng;Ling Yang	2006	First International Multi-Symposiums on Computer and Computational Sciences (IMSCCS'06)	10.1109/IMSCCS.2006.111	computer vision;minimal surface of revolution;engineering;geometry;computer graphics (images)	Vision	55.602793528914276	-50.707698552422265	66903
4d5be0b568d7cb5c82eb5a908f327b70c9349a5f	optimized shadow mapping using the stencil buffer	shadow mapping;real time;hardware accelerator;dynamic scenes	Shadow maps and shadow volumes are common techniques for computing real-time shadows. We optimize the performance of a hardware-accelerated shadow mapping algorithm by rasterizing the light frustum into the stencil buffer, in a manner similar to the shadow volume algorithm. The pixel shader code that performs shadow tests and illumination computations is applied only to the pixels that are inside the light frustum. We also use deferred shading to further limit the operations to visible pixels. Our technique can be easily plugged into existing applications, and is especially useful for dynamic scenes that contain several local light sources. In our test scenarios, the overall frame rate was up to 2.2 times higher than for our comparison methods.	algorithm;computation;deferred shading;frustum;hardware acceleration;map;pixel;rasterisation;real-time clock;shader;shadow mapping;shadow volume;stencil buffer	Jukka Arvo;Timo Aila	2003	J. Graphics, GPU, & Game Tools	10.1080/10867651.2003.10487587	computer vision;simulation;hardware acceleration;computer science;shadow mapping;shadow volume;computer graphics (images)	Graphics	66.10079055309976	-51.49868318531404	66961
23248b5fc53e2bf94bde0d9e9e887305dc3c1340	view-dependent control of elastic rod simulation for 3d character animation	dependent control;keywords;cr categories;view;elastic simulation;i 3 7 computer graphics;animation;view dependent control;three dimensional graphics and realism;based materials;example;example based materials	This paper presents view-dependent control of elastic rod simulation for 3D character animation. Elastic rod simulation is often used in character animation to generate motion of passively deforming body parts such as hair, ear, and whiskers. Our goal is to allow artistic control of the simulation in a view-dependent way, for example to move a hair strand so that it does not hide the eye regardless of the view direction. To achieve this goal, the artist defines several example rest poses of the rod in preparation, each of which is associated with a particular view direction. In run time, the system computes the current rest pose by blending the example rest poses associated with the view directions near the current view direction, and then pulls the pose to the current rest pose. Technical contribution is in the formulation of example-based rod simulation using view direction as an input, and an algorithm to suppress undesirable increase of momentum caused by dynamically changing rest poses.	algorithm;alpha compositing;run time (program lifecycle phase);simulation;strand (programming language)	Yuki Koyama;Takeo Igarashi	2013		10.1145/2485895.2485898	anime;computer vision;simulation;computer science;view;computer graphics (images)	Graphics	63.91549367469153	-47.49846094582711	67343
1f06f0c84404afe3f4603a25f2db29cd341b2f5f	video stabilization using epipolar geometry	epipolar geometry;video stabilization;novel view synthesis;image warping	We present a new video stabilization technique that uses projective scene reconstruction to treat jittered video sequences. Unlike methods that recover the full three-dimensional geometry of the scene, this model accounts for simple geometric relations between points and epipolar lines. Using this level of scene understanding, we obtain the physical correctness of 3D stabilization methods yet avoid their lack of robustness and computational costs. Our method consists of tracking feature points in the scene and using them to compute fundamental matrices that model stabilized camera motion. We then project the tracked points onto the novel stabilized frames using epipolar point transfer and synthesize new frames using image-based frame warping. Since this model is only valid for static scenes, we develop a time-view reprojection that accounts for nonstationary points in a principled way. This reprojection is based on modeling the dynamics of smooth inertial object motion in three-dimensional space and allows us to avoid the need to interpolate stabilization for moving objects from their static surrounding. Thus, we achieve an adequate stabilization when both the camera and the objects are moving. We demonstrate the abilities of our approach to stabilize hand-held video shots in various scenarios: scenes with no parallax that challenge 3D approaches, scenes containing nontrivial parallax effects, videos with camera zooming and in-camera stabilization, as well as movies with large moving objects.	computation;correctness (computer science);digital camera;epipolar geometry;fundamental matrix (computer vision);interpolation;map projection;mobile device;parallax;robustness (computer science);virtual reality headset	Amit Goldstein;Raanan Fattal	2012	ACM Trans. Graph.	10.1145/2231816.2231824	image warping;computer vision;simulation;computer science;mathematics;epipolar geometry;image stabilization;computer graphics (images)	Graphics	57.937484172539165	-50.705710527693	67355
72810083879d9c6c67c57f58318a5c0ff8d2147e	reconstruction of sewer shaft profiles from fisheye-lens camera images	shape recognition;3d model;structure from motion	In this paper we propose a robust image and sensor based approach for automatic 3d model acquisition of sewer shafts from survey videos captured by a downward-looking fisheye-lens camera while lowering it into the shaft. Our approach is based on Structure from Motion adjusted to the constrained motion and scene, and involves shape recognition in order to obtain the geometry of the scene appropriately. The approach has been implemented and applied successfully to the practical stage as part of a commercial software.	3d modeling;commercial software;fisheye;norm (social);structure from motion	Sandro Esquivel;Reinhard Koch;Heino Rehse	2009		10.1007/978-3-642-03798-6_34	computer vision;simulation;engineering;computer graphics (images)	Vision	58.213804520855795	-49.40789652314498	67526
366ad91ca2486482b78a517d483aa9be05e57757	on the foundations of vision modeling iii. noncommutative monoids of occlusive preimages	robot navigation;computer vision;knot theory;image analysis;visual perception;point of view;retinal imaging;modeling and analysis	A significant cue for visual perception is the occlusion pattern in 2-D retinal images, which helps humans or robots navigate successfully in the 3-D environments. There have been many works in the literature on the modeling and analysis of the occlusion phenomenon, most of which are from the analytical or statistical points of view. The current paper presents a new theory of occlusion based on the simple topological definitions of preimages and a binary operation on them called “occlu.” We study numerous topological as well as algebraic structures of the resultant noncommutative preimage monoids (a monoid is a semigroup with identity). Some implications of the new theory in terms of real vision research are also addressed.	free monoid;linear algebra;machine vision;preimage attack;resultant;robot	Jianhong Shen	2005	Journal of Mathematical Imaging and Vision	10.1007/s10851-005-3600-8	computer vision;image analysis;topology;visual perception;computer science;knot theory;pure mathematics;mathematics;geometry	Vision	60.08016423306526	-46.625266761943365	67590
9131f8189961c5051ee01c01ecee3447fa9c677b	a graphical, scalable and intuitive method for the placement and the connection of biological cells		We introduce a graphical method originating from the computer graphics domain that is used for the arbitrary and intuitive placement of cells over a two-dimensional manifold. Using a bitmap image as input, where the color indicates the identity of the dierent structures and the alpha channel indicates the local cell density, this method guarantees a discrete distribution of cell position respecting the local density function. is method scales to any number of cells, allows to specify several dierent structures at once with arbitrary shapes and provides a scalable and versatile alternative to the more classical assumption of a uniform non-spatial distribution. Furthermore, several connection schemes can be derived from the paired distances between cells using either an automatic mapping or a user-dened local reference frame, providing new computational properties for the underlying model. e method is illustrated on a discrete homogeneous neural eld, on the distribution of cones and rods in the retina and on a coronal view of the basal ganglia.	alpha compositing;basal (phylogenetics);bitmap;computer graphics;ganglia;graphical user interface;list of graphical methods;reference frame (video);scalability	Nicolas P. Rougier	2017	CoRR		scalability;mathematical optimization;discrete mathematics;manifold;local reference frame;probability distribution;probability density function;bitmap;theoretical computer science;computer graphics;alpha compositing;computer science	Graphics	65.29134473482092	-47.725318216116946	67626
3df473bdc0bba76377719174238cc9db2a8a104d	weighted distance transforms for volume images digitized in elongated voxel grids	computer vision and robotics autonomous systems;3d imaging;non isotropic images;datorseende och robotik autonoma system;chamfer distance;distance transform;medial axis	Weighted distance transforms in volume (3D) images using a voxel grid with equal resolution along two axes and lower along the third are investigated. The weights (neighbour distances) in a local neighbourhood of size 3· 3· 3 are optimized by minimizing the maximum error in a cubic image. 2004 Elsevier B.V. All rights reserved.	approximation;computation;cubic function;distance transform;euclidean distance;interpolation;mathematical optimization;maxdiff;semiconductor industry;tomography;voxel	Ida-Maria Sintorn;Gunilla Borgefors	2004	Pattern Recognition Letters	10.1016/j.patrec.2003.12.006	stereoscopy;computer vision;medial axis;computer science;mathematics;geometry;distance transform;computer graphics (images)	Vision	67.10913405426396	-44.00600816720985	67636
7eebe361ddabab6bb843cde71ada22ee95c55b9e	analytical characterization of the accuracy of slam without absolute orientation measurements	state estimation;upper bound;theoretical analysis;least squares estimate;covariance matrix;pose estimation	In this paper we derive analytical upper bounds on the covariance of the state estimates in SLAM. The analysis is based on a novel formulation of the SLAM problem, which enables the simultaneous estimation of the landmark coordinates with respect to a robot-centered frame (relative map), as well a s with respect to a fixed global frame (absolute map). A study of the properties of the covariance matrix in this formulation yields analytical upper bounds for the uncertainty of both map representations. Moreover, by employing results from Least Squares estimation theory, theguaranteed accuracy of the robot pose estimates is derived as a function of the accuracy of the robot’s sensors and of the properties of the map. Contrary to previous approaches, the method presented here makes no assumptions about the availability of a sensor measuring the absolute orientation of the robot. The theoretical analysis is validated by simulation results and real-world experiments.	estimation theory;experiment;least squares;robot;sensor;simulation;simultaneous localization and mapping	Anastasios I. Mourikis;Stergios I. Roumeliotis	2006		10.15607/RSS.2006.II.028	econometrics;covariance matrix;mathematical optimization;pose;mathematics;upper and lower bounds;statistics	Robotics	54.75334155020488	-39.3905645471666	67727
9a07e47ff81b3f0ce8c16dc30fc17b14f4f612ea	a fast ransac-based registration algorithm for accurate localization in unknown environments using lidar measurements	local algorithm;kalman filters;unknown environments;lidar measurements;laser radar layout iterative algorithms kernel robustness clouds robots simultaneous localization and mapping information retrieval iterative closest point algorithm;optical radar kalman filters;dynamic environment;generic moving platform;fast ransac based registration algorithm;optical radar;huber kernel;lidar sensor;is success;extended kalman filter;extended kalman filter fast ransac based registration algorithm accurate localization unknown environments lidar measurements lidar sensor generic moving platform huber kernel;accurate localization	The problem of accurate localization using only measurements from a LIDAR sensor is analyzed in this paper. The sensor is rigidly fixed on a generic moving platform, which moves on a plane. Practical on-line applications of localization algorithms impose constraints on the execution time, problem that is addressed in this paper and compared with other existing solutions. Due to the nature of the sensor adopted, the localization algorithm is based on a fast and accurate registration algorithm, which is able to deal with noisy measurements, outliers and dynamic environments. The proposed solution relies on the RANSAC algorithm in combination with a Huber kernel in order to cope with typical nuisances in LIDAR measurements. The robust registration is successively used in combination with an extended Kalman filter to track the trajectory of the LIDAR over time, hence to solve the localization problem. Simulations and experimental results are reported to show the feasibility of the proposed approach.	algorithm;computer simulation;extended kalman filter;kernel (operating system);mathematical optimization;odometry;online and offline;random sample consensus;run time (program lifecycle phase);whole earth 'lectronic link	Daniele Fontanelli;Luigi Ricciato;Stefano Soatto	2007	2007 IEEE International Conference on Automation Science and Engineering	10.1109/COASE.2007.4341827	computer vision;mathematical optimization;geography;remote sensing	Robotics	54.04118197902782	-40.673622012234205	67920
36bb9188e401c2d6070694b4d018bb7d3485bc05	a non-rigid map fusion-based direct slam method for endoscopic capsule robots	endoscopic capsule robot;dense direct medical slam;non-rigid frame-to-model fusion	Since the development of capsule endoscopy technology, medical device companies and research groups have made significant progress to turn passive capsule endoscopes into robotic active capsule endoscopes. However, the use of robotic capsules in endoscopy still has some challenges. One such challenge is the precise localization of the actively controlled robot in real-time. In this paper, we propose a non-rigid map fusion based direct simultaneous localization and mapping method for endoscopic capsule robots. The proposed method achieves high accuracy for extensive evaluations of pose estimation and map reconstruction performed on a non-rigid, realistic surgical EsophagoGastroDuodenoscopy Simulator and outperforms state-of-the art methods.	capsule endoscopes;evaluation;license;map (higher-order function);medical devices;muscle rigidity;real-time clock;robot (device);simulators;simultaneous localization and mapping;surfel;capsule (pharmacologic)	Mehmet Turan;Yasin Almalioglu;Helder Araújo;Ender Konukoglu;Metin Sitti	2017		10.1007/s41315-017-0036-4	capsule endoscopes;artificial intelligence;robot;computer vision;endoscopy;computer science;simultaneous localization and mapping;esophagogastroduodenoscopy;pose;capsule;capsule endoscopy	Robotics	58.28982231690826	-38.1905998770528	67967
9a48f19f4099c8d4cc1b1b2bffb4cc4a81799807	improved marching tetrahedra algorithm based on hierarchical signed distance field and multi-scale depth map fusion for 3d reconstruction	depth map fusion;hierarchical signed distance field;feature matching;surface reconstruction;3d reconstruction	3D reconstruction systems are promoted by developments of both computer hardware and computing technologies. They still remain problems like high expense, low efficiency and inaccuracy. Especially for large-scale scenes, lack of full use of multi-scale depth information will cause blurring and irreal reconstruction results. To solve this problem, we construct the structure of hierarchical signed distance field (H-SDF) and design an improved marching tetrahedra algorithm for multi-scale depth map fusion. In addition, to improve efficiency, we also propose a two-phase search strategy in image feature matching: the bag-of-features model (BOF) is adopted in a coarse search to narrow search scope and then the SIFT descriptor is used in exact matching to pick reconstruction image points. Experiment results indicate that coarse search makes matching time shorter; using the H-SDF to fuse multi-scale depth maps, and isosurface extraction with improved marching tetrahedra algorithm can improve visual effect. 2017 Elsevier Inc. All rights reserved.	3d reconstruction;algorithm;bundle adjustment;computer hardware;depth map;distance transform;feature (computer vision);isosurface;map (higher-order function);marching tetrahedra;real-time clock;reconstruction conjecture;scene graph;two-phase locking;visual effects;voxel	Dan Guo;Chuanqing Li;Lu Wu;Jianzhong Yang	2017	J. Visual Communication and Image Representation	10.1016/j.jvcir.2016.12.016	3d reconstruction;computer vision;mathematical optimization;surface reconstruction;computer science;machine learning;mathematics	Vision	54.6020769712685	-47.22313079245962	68151
2ce42a4f8120f2da5a03c7f2b38a0d1c7fcb2658	automatic description of complex buildings from multiple images	image features;bayesian network;building detection and description;search space;feature grouping;three dimensional;aerial image;level of detail;three dimensional object description;building model;neighborhood search;multi view;building detection;probabilistic reasoning;aerial image analysis	We present an approach to detecting and describing compositions of buildings with flat or complex rooftops by using multiple, overlapping images of the scene. First, 3-D features are generated by using multiple images, and rooftop hypotheses are generated by neighborhood searches on those features. For robust generation of 3-D features, we present a probabilistic approach to address the epipolar alignment problem in line matching. Image-derived unedited elevation data is used to assist feature matching, and to generate rough cues of the presence of 3-D structures. These cues help reduce the search space significantly. Experimental results are shown on complex buildings.	computation;epipolar geometry;error-tolerant design;neighborhood operation;sensor;time complexity	Zu Whan Kim;Ramakant Nevatia	2004	Computer Vision and Image Understanding	10.1016/j.cviu.2004.05.004	three-dimensional space;computer vision;computer science;machine learning;level of detail;pattern recognition;bayesian network;mathematics;probabilistic logic;feature	Vision	57.78002589249684	-45.73800599246638	68361
d0cfbcad8fbf5651be8918955294b661a5bd7311	a layered approach for more robust generation of road network maps from vehicle tracking data		Nowadays, large amounts of tracking data are generated via GPS-enabled devices and other advanced tracking technologies. These constitute a rich source for inferring the structure of transportation networks. In this work, we present a novel methodology for revealing a road network map from vehicle trajectories. Specifically, we propose an enhanced and robust map construction algorithm that is based on segmenting the original tracking data according to different types of movement and then constructing the topology of the road network hierarchically. The segmentation produces separate road network layers, which are then fused into a single network. This provides a more efficient way to addresses the challenges imposed by noisy and low sampling rate trajectories. It also allows for a mechanism to accommodate automatic map maintenance on updates. Thus, the proposed approach overcomes the limitations of existing methods and introduces a map construction algorithm that is robust against heterogeneous and sparse data and capable to incorporate changes and improvements. An experimental evaluation extensively assesses the quality of the proposed methodology by constructing large parts of the road networks of four major cities, namely Athens, Berlin, Vienna, and Chicago, using as input GPS tracking data of utility vehicles and taxi fleets. Our results show significant improvements concerning the spatial accuracy and the quality of the constructed road network over the current state of the art.	algorithm;crowdsourcing;gps tracking unit;global positioning system;ground truth;mobile phone;openstreetmap;sampling (signal processing);sensor;social media;sparse matrix;trajectory optimization;vehicle tracking system	Sophia Karagiorgou;Dieter Pfoser;Dimitrios Skoutas	2017	ACM Trans. Spatial Algorithms and Systems	10.1145/3061713	computer vision;simulation	Mobile	54.668013092710765	-42.94920271373331	68419
6e5e78a86a54b3ab725a5314f99be9473662d812	3d object reconstruction processing chain for extensible virtual spaces	depth cameras;3d reconstruction	3D reconstruction of real world objects is an important content creation tool for the 3D internet. This poster shows how cheap commercial sensors can be used to reconstruct real 3D objects and import those objects within a 3D virtual world. This poster describes the implementation of a 3D content capturing processing chain using Microsoft Kinect. The capturing process includes a method for filtering and segmenting an object from the unwanted background data, a method for registering multiple scans together and a method for creating a solid surface presentation for the captured point cloud. The resulting 3D asset is imported and rendered in RealXtend Tundra 2.	3d reconstruction;kinect;point cloud;sensor;virtual world;realxtend tundra sdk	Miika Santala;Juha Hyvärinen;Seamus Hickey;Jarkko M. Vatjus-Anttila	2012		10.1145/2393132.2393178	computer vision;simulation;computer science;computer graphics (images)	Graphics	59.991975827343964	-49.93618995875961	68541
f9aec84b1d4bedac21e03d896579dfaf018dc691	automatic alignment of color imagery onto 3d laser radar data	lens distortion;3d imaging;pseudo intensity images;laser radar;data fusion;radar imaging airborne radar image colour analysis image registration optical radar radar clutter;time of day;radar clutter image color analysis 3d laser radar data airborne platforms pseudo intensity images ladar image 2d registration algorithms histogram matching data fusion interpretation;airborne platforms;optical radar;image color analysis;image colour analysis;ladar image;image registration;radar imaging;laser radar color radar imaging laser fusion airborne radar sun histograms image generation lenses augmented reality;3d laser radar data;interpretation;airborne radar;histogram matching;radar clutter;augmented reality;2d registration algorithms	We present an algorithm for the automatic fusion of city-sized, 2D color imagery to 3D laser radar imagery collected from distinct airborne platforms at different times. Our approach is to derive pseudo-intensity images from ladar imagery and to align these with color imagery using conventional 2D registration algorithms. To construct a pseudo-intensity image, the algorithm uses the color imagery's time of day and location to predict shadows in the 3D image, then determines ambient and sun lighting conditions by histogram matching the 3D-derived shadowed and non-shadowed regions to their 2D counterparts. A projection matrix is computed to bring the pseudo- image into 2D image coordinates, resulting in an initial alignment of the imagery to within 200 meters. Finally, the 2D intensity image and 3D generated pseudo-intensity image are registered using a modified normalized correlation algorithm to solve for rotation, translation, scale and lens distortion, resulting in a fused data set that is aligned to within 1 meter. Applications of the presented work include the areas of augmented reality and scene interpretation for persistent surveillance in heavily cluttered and occluded environments.	3d modeling;airborne ranger;algorithm;align (company);anisotropic filtering;augmented reality;color image;dance dance revolution extreme;distortion;histogram matching;image processing;object storage;pixel;shader;variable shadowing	Alexandru Vasile;Frederick R. Waugh;Daniel Greisokh;Richard M. Heinrichs	2006	35th IEEE Applied Imagery and Pattern Recognition Workshop (AIPR'06)	10.1109/AIPR.2006.16	computer vision;geography;optics;remote sensing	Vision	56.842309907709485	-48.15689212093	68602
26d86e5cf39bb75e60c3c29aa889e862013726ca	frame rate fusion and upsampling of eo/lidar data for multiple platforms	three dimensional displays cameras laser radar instruction sets real time systems image color analysis streaming media;ladybug;panoramic;fusion;frame rate;panoramic eo lidar fusion upsample backfill ladybug frame rate;upsample;ladybug panoramic camera frame rate fusion eo lidar data upsampling lidar point cloud image features multithreaded programming gp gpu methods velodyne 64e lidar;eo;radar imaging graphics processing units image fusion image sampling multi threading optical radar;lidar;backfill	We propose a method for fusing a LIDAR point cloud to camera data in real time, which will also backfill the myriad of data holes LIDAR creates. This is done in a way that also leverages the images features to weight how point clouds are filled. Multithreaded programing and GP-GPU methods allow us to obtain 10 fps with a Velodyne 64E LIDAR completely fused in 360o using a Ladybug panoramic camera. The method also generalizes to other kinds of point clouds such as those obtained by aerial vehicles. The primary advantage of our approach is it combines 360o fusion with upsampling in real time without mode smoothing.	aerial photography;graphics processing unit;point cloud;smoothing;thread (computing);upsampling	T. Nathan Mundhenk;Kyungnam Kim;Yuri Owechko	2014	2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops	10.1109/CVPRW.2014.117	lidar;upsampling;computer vision;fusion;computer science;frame rate;computer graphics (images)	Vision	55.3319419629868	-44.689486340865486	68619
aa23cce2d4637136e372c17976ef968481aa148a	creating coherent animations from video	animation from video;time coherent animations;non photorealistic animation;image analysis;analysis synthesis	In this paper, different techniques for the creation of time coherent figurative animations from a video input are presented. The animations are generated using an analysis-synthesis approach. Information of the scene is extracted using only a 2D RGB image. No markers or depth planes are needed. After the analysis, the image is drawn again using the extracted information. To guarantee temporal coherence when redrawing the image, different alternatives have been explored: matching and interpolation on the parameters domain and gradient descent parameter update. All methods and variations are described and illustrated with images.	coherence (physics);flash animation;gradient descent;interpolation	Javier Villegas;George Legrady	2014	IJART	10.1504/IJART.2014.060945	computer vision;image analysis;computer science;multimedia;computer graphics (images)	Vision	60.08059098772363	-50.70891113263287	68803
63b6ca928a0841aa01a0e66d73b05334163aa70a	from images to maps	ieee journals and transactions on line opera;image storage;layout image reconstruction image storage internet cameras geometry testing inspection image analysis solid modeling;mass spring system;evaluation method;geometry;testing;layout;inspection;distance measurement;springs;internet;image reconstruction image analysis geometric modeling;image reconstruction;solid modeling;transforms;merging;geometric modeling;image analysis;geometric model;distance matrix;cameras	This paper proposes a two-stage approach to reconstruct the map of a scene given tagged photographs of that scene. In the first stage, several methods are proposed that transform tag data from photographs into an intermediate distance matrix. These methods are compared against each other. In the second stage, a method based on the physical mass-spring system is proposed that transforms the distance matrix into a map. It is compared against and outperforms MDS-MAP(P) given human-tagged input photographs. Experiments are carried out on two test datasets. Ana evaluation method is described and the optimal overall reconstruction generates maps with accuracies of 47% and 66% respectively for the datasets, both scoring 40% higher than the average random reconstruction. The proposed approach is applied to three sample datasets, and upon a qualitative inspection, the resulting maps show that they are able to convey the organization of the scenes at a high level.	ana (programming language);distance matrix;high-level programming language;map;sparse matrix	Ron D. Appel;Parham Aarabi	2009	2009 Canadian Conference on Electrical and Computer Engineering	10.1109/CCECE.2009.5090281	computer vision;image analysis;simulation;computer science;geometric modeling;machine learning;computer graphics (images)	Vision	57.812659407054	-48.515153756861345	69570
c8435b22029286c9045af810f48aa96119ca0153	two-dimensional offsets and medial axis transform	medial axis transform;domain decomposition;offset curves;numerical computation;computer aided geometric design	We present a mathematical theory of the two-dimensional offset curves from the viewpoint of medial axis transform. We explore the local geometry of the offset curve in relation with the medial axis transform, culminating in the classification of points on the offset curve. We then study the domain decomposition from the viewpoint of offsets, and in particular introduce the concept of monotonic fundamental domain as a device for detecting the correct topology of offsets as well as for stable numerical computation. The monotonic fundamental domains are joined by peaks or valleys of the medial axis transform, or by what we call the critical horizonal section whose algebro-geometric properties are rigorously treated as well.	apache axis;computation;domain decomposition methods;fundamental domain;medial graph;numerical analysis;offset (computer science);sensor	Hyeong In Choi;Sung Woo Choi;Chang Yong Han;Tae-wan Kim;Song-Hwa Kwon;Hwan Pyo Moon;Kyeong Hah Roh;Nam-Sook Wee	2008	Adv. Comput. Math.	10.1007/s10444-007-9036-5	mathematical optimization;mathematics;geometry;domain decomposition methods	Vision	64.3176163035213	-40.15194591795954	69743
9809f2b03f9fe10a712f53760fd7542e7140b7c1	moving object tracking via one-dimensional optical flow using queue	moving object;gradient method;queueing theory;queueing theory gradient methods image sequences motion estimation;queue;motion estimation;ill posed problem moving object tracking one dimensional optical flow queue;image motion analysis voting tracking motion estimation robotics and automation cameras image sequences automatic control optical control robot control;integrated optics;queue moving object tracking one dimensional optical flow gradient method motion estimation;moving object tracking;optical imaging;estimation;region of interest;ill posed problem;image sequence;mathematical model;gradient methods;optical flow;tracking;adaptive optics;image sequences;one dimensional optical flow	Although optical flow is useful for tracking of a moving object, estimation by the gradient method is ill-posed problem. In order to avoid ill-posedness, we have proposed a tracking method via one dimensional optical flow (1D flow), which is calculated on the straight line (calculation axis). The calculation axes are spanned several direction based on the estimated motion. This method votes with the number of positive 1D flow and updates the calculation axes depending on the voting result. We update these axes every five frames to achieve stable estimation of motion. Hence, it is impossible to track a object which moves fast because this object moves to the outside of the region of interest. If the calculation axes are updated every frame to track a object which moves fast, then this method tends to estimate the wrong direction due to vibration of the camera or partial occlusion. We propose a tracking method via 1D flow using queue. We prepare queues of which the length is five for each direction. The number of positive flow is enqueued. Direction which has maximum value is regarded as the moving direction. We can achieve stable tracking even if a object moves fast, because the calculation axes are updated every frame and estimation of the moving direction is based on the information of the past five frames. In experiment for real image sequences, the proposed method can track a object which moves fast.	gradient method;optic axis of a crystal;optical flow;region of interest;well-posed problem	Koji Kinoshita;Kenji Murakami	2008	2008 10th International Conference on Control, Automation, Robotics and Vision	10.1109/ICARCV.2008.4795896	computer vision;mathematical optimization;estimation;simulation;computer science;gradient method;motion estimation;optical imaging;mathematical model;optical flow;mathematics;tracking;queueing theory;adaptive optics;queue;statistics;region of interest	Robotics	56.73024422795756	-41.66083437532841	69806
2f6a4660c68b378ec516d0c1ae7e3605366b1417	a comparison of ekf and sgd applied to a view-based slam approach with omnidirectional images	visual slam;slam algorithm;omnidirectional images;sgd;ekf	The problem of Simultaneous Localization and Mapping (SLAM) is essential in mobile robotics. The obtention of a feasible map of the environment poses a complex challenge, since the presence of noise arises as a major problem which may gravely affect the estimated solution. Consequently, a SLAM algorithm has to cope with this issue but also with the data association problem. The Extended Kalman Filter (EKF) is one of the most traditionally implemented algorithms in visual SLAM. It linearizes the movement and the observation model to provide an effective online estimation. This solution is highly sensitive to non-linear observation models as it is the omnidirectional visual model. The Stochastic Gradient Descent (SGD) emerges in this work as an offline alternative to minimize the non-linear effects which deteriorate and compromise the convergence of traditional estimators. This paper compares both methods applied to the same approach: a navigation robot supported by an efficient map model, established by a reduced set of omnidirectional image views.We present a series of real data experiments to assess the behavior and effectiveness of both methods in terms of accuracy, robustness against errors and speed of convergence. © 2013 Elsevier B.V. All rights reserved.	algorithm;correspondence problem;experiment;extended kalman filter;mobile robot;nonlinear system;online and offline;rate of convergence;robotics;simultaneous localization and mapping;stochastic gradient descent;vergence;visual modeling	David Valiente;Arturo Gil;Lorenzo Fernández;Óscar Reinoso	2014	Robotics and Autonomous Systems	10.1016/j.robot.2013.11.009	computer vision;simulation;computer science;artificial intelligence;machine learning;extended kalman filter;simultaneous localization and mapping	Robotics	54.63575352961001	-40.09218672260419	70158
4642f05f310812b53563969825f69208b706aa30	local interpolation of curvature-continuous surfaces	interpolation;curva bezier;modele geometrique;geometrie solide;sistema informatico;interpolacion;transformacion;geometria solidos;computer system;surface lisse;consistencia;superficie curva;smooth surface;curved surface;courbe bezier;consistance;surface courbe;systeme informatique;superficie lisa;transformation;solid geometry;consistency;geometrical model;bezier curve;modelo geometrico	Abstract   The paper discusses the local interpolation of parametric polynomial surfaces with curvature continuity over a network of arbitrary scattered points. The necessary conditions for the construction of such surfaces at an   N-  patch   node are given. The relationships between neighbouring nodes and patches are established in terms of parametric transformations and shape parameters. They are used to guarantee the consistency of the resolution. The conclusion is that, if there are only quadrangular and triangular meshes on the net, it is possible to construct locally a curvature-continuous surface on the net with   8×8   rectangular and/or degree-9 triangular Bernstein–Bezier patches without further subdivisions, and to interpolate the position vectors, normal directions and Gaussian curvatures given at the nodes. In view of the fact the any   N-  sided   polygon can be divided into   N   quadrangles or triangles, the result can be used for a net of arbitrary scattered points.	interpolation	Huaizhong Li;S.-Q. Liu	1992	Computer-Aided Design	10.1016/0010-4485(92)90029-A	topology;interpolation;solid geometry;calculus;mathematics;geometry;statistics	EDA	68.2295662129442	-40.33297201588832	70377
5060e4b835b224459269fa5e613478a1670fe881	effect of active air conditioning in medical intervention rooms on the temperature dependency of time-of-flight distance measurements		Recently, Time-of-Flight (ToF) cameras have emerged as a new mean for intra-operative image acquisition. The ToF camera features co-registered depth and intensity image data from the observed scene in video frame rate. Due to systematic distance errors, depth calibration is crucially needed. One of the sources of error that so far received little attention in literature related to ToF camera calibration is the temperature of the camera’s video chip. In this work we address the effect of active air conditioning in medically used rooms on the temperature related distance variability. The conducted experiments in which data were acquired over a long time indicate a reduction of the runtime related distance drift by up to factor five and a reduction of the measurement offset by factor three for certain examined ToF cameras in actively compared to passively climate controlled rooms. This has important implications on the ToF camera depth calibration process, for the calibration of the temperature related distance deviation in rooms with active air conditioning can be reduced to an easy to determine offset.		Sven Mersmann;David Guerrero;Heinz-Peter Schlemmer;Hans-Peter Meinzer;Lena Maier-Hein	2012		10.1007/978-3-642-28502-8_69	simulation;medicine;architectural engineering;medical emergency	ML	56.67375648061656	-46.7469384625153	70408
5ab2825b1a913f2d1e8e9bb6d22aea556177ae57	binocular motion tracking by gaze fixation control and three-dimensional shape reconstruction	reconstruction;three dimensional shape;three dimensional;motion tracking;robot vision;binocular vision;shape reconstruction;object tracking;three dimensional shape reconstruction;active vision	It is an easy task for the human visual system to gaze continuouslyat an object moving in three-dimensional (3-D) space. While tracking the object, human vision seems able to comprehend its 3-D shape with binocular vision. We conjecture that, in the human visual system, the function of comprehending the 3-D shape is essential for robust tracking of a moving object. In order to examine this conjecture, we constructed an experimental system of binocular vision for motion tracking. The system is composed of a pair of active pan–tilt cameras and a robot arm. The cameras are for simulating the two eyes of a human while the robot arm is for simulating the motion of the human body below the neck. The two active cameras are controlled so as to  x their gaze at a particular point on an object surface. The shape of the object surface around the point is reconstructed in real-time from the two images taken by the cameras based on the differences in the image brightness. If the two cameras successfully gaze at a single point on the object surface, it is possible to reconstruct the local object shape in real-time. At the same time, the reconstructed shape is used for keeping a  xation point on the object surface for gazing, which enables robust tracking of the object. Thus these two processes, reconstruction of the 3-D shape and maintaining the  xation point, must be mutually connected and form one closed loop. We demonstrate the effectiveness of this framework for visual tracking through several experiments.	binocular vision;experiment;experimental system;real-time clock;robotic arm;simulation;tracking system;video tracking	Yoshinori Satoh;Takayuki Okatani;Koichiro Deguchi	2003	Advanced Robotics	10.1163/156855303322554427	binocular vision;three-dimensional space;computer vision;active vision;computer science;video tracking;computer graphics (images)	Vision	56.77838679770635	-42.317397085913754	70560
dd6efb7461d14e97fd6ef2b2d95fb883f6fad655	polygonal mesh and quad-tree display algorithms for nonconvex crystal structures	crystalline structure;concepcion asistida;computer aided design;representation graphique;modele geometrique;quad tree;computer graphics;quad arbol;representacion grafica;cristales;crystals;cristalografia;structure cristalline;polygonal meshes;cristal;conception assistee;quad arbre;crystal structure;crystallography;infographie;graphics;cristallographie;geometrical model;estructura cristalina;modelo geometrico	Reseau polygonal et algorithmes du0027affichage utilisant les quad-arbres pour la representation de structures cristallines non convexes	algorithm;crystal structure;polygon mesh;quadtree	Cathy Sobhanpanah;Ian O. Angell	1986	Computers & Graphics	10.1016/0097-8493(86)90024-5	computer science;crystal structure;computer aided design;geometry;computer graphics (images)	Visualization	66.09696366107718	-41.21734953059195	70666
58b576657ce6248dbf2044834ce4b9a4c13614b8	vsams: video stabilization approach for multiple sensors	filtering;multiple sensors;vsams;video streaming;high spatial frequency;objective quality evaluation;sensors;video signal processing;cooperative video stabilization framework;infrared video streams;multisensory aerial data;multiple sensors video stabilization;robust boosting curves;system performance;stability;multistage smoothing;cooperative stabilization framework vsams multiple sensors multiple unstable videos streams complementary information cooperative video stabilization framework multisensory aerial data robust boosting curves stability camera path multistage smoothing multisensory uav data infrared video streams electro optical video streams subjective quality evaluation objective quality evaluation;smoothing methods;quality evaluation;cooperative stabilization framework;multiple unstable videos streams;video stabilization;multisensory uav data;robustness;camera path;lighting;video signal processing sensor fusion stability;complementary information;sensor fusion;infrared;unmanned aerial vehicles;electro optic;cameras;electro optical video streams;sensors smoothing methods lighting cameras filtering unmanned aerial vehicles robustness;subjective quality evaluation	Video Stabilization is now considered an old problem which is almost solved but there are still some connecting problems which needs research attention. One of such issues arises due to multiple unstable videos streams coming from multiple sensors which often contain complementary information. To enhance system performance, instability should be removed in a single go rather than stabilizing each sensor individually. This paper proposes a cooperative video stabilization framework, VSAMS for multisensory aerial data based on robust boosting curves which encapsulate stability of high spatial frequency information as used by flying parakeets (budgerigars). For reducing shake and jitter and preservation of actual camera path, a multistage smoothing approach is visualized. Experiments are performed on multisensory UAV data which contains infrared and electro-optical video streams. Subjective and objective quality evaluation proves effectiveness of the proposed cooperative stabilization framework.	aerial photography;control theory;cooperative mimo;instability;multistage amplifier;sensor;smoothing;streaming media;unmanned aerial vehicle	Anwaar Ul Haq;Iqbal Gondal;M. Manzur Murshed	2010	2010 International Conference on Digital Image Computing: Techniques and Applications	10.1109/DICTA.2010.76	filter;computer vision;simulation;stability;infrared;computer science;sensor;lighting;sensor fusion;computer performance;statistics;robustness;image stabilization	Robotics	61.85443094005078	-38.79526098604802	70829
0cbc8e08cc20039e185b1fb6b0348964bb03cc46	panoramic stereo videos with a single camera		We present a practical solution for generating 360° stereo panoramic videos using a single camera. Current approaches either use a moving camera that captures multiple images of a scene, which are then stitched together to form the final panorama, or use multiple cameras that are synchronized. A moving camera limits the solution to static scenes, while multi-camera solutions require dedicated calibrated setups. Our approach improves upon the existing solutions in two significant ways: It solves the problem using a single camera, thus minimizing the calibration problem and providing us the ability to convert any digital camera into a panoramic stereo capture device. It captures all the light rays required for stereo panoramas in a single frame using a compact custom designed mirror, thus making the design practical to manufacture and easier to use. We analyze several properties of the design as well as present panoramic stereo and depth estimation results.	calibration (statistics);digital camera;ray (optics);sensor;stereoscopy;visual artifact	Rajat Aggarwal;Amrisha Vohra;Anoop M. Namboodiri	2016	2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2016.408	computer stereo vision;smart camera;stereo camera;computer vision;camera auto-calibration;camera resectioning;computer graphics (images)	Vision	58.12345665947396	-50.04322056860959	70985
2e9433d318c7dbc946a42743de328193058e6e58	efficient volumetric polycube-map construction		PolyCubes provide compact representations for closed complex shapes and are essential to many computer graphics applications. Existing automatic PolyCube construction methods usually suffer from poor quality or time-consuming computation. In this paper, we provide a highly efficient method to compute volumetric PolyCube-maps. Given an input tetrahedral mesh, we utilize two novel normal-driven volumetric deformation schemes and a polycube-allowable mesh segmentation to drive the input to a volumetric PolyCube structure. Our method can robustly generate foldover-free and low-distortion PolyCube-maps in practice, and provide a flexible control on the number of corners of Polycubes. Compared with state-of-the-art methods, our method is at least one order of magnitude faster and has better mapping qualities. We demonstrate the efficiency and efficacy of our method in PolyCube construction and all-hexahedral meshing on various complex models.		Xiao-Ming Fu;Chong-Yang Bai;Yang Liu	2016	Comput. Graph. Forum	10.1111/cgf.13007	geometric primitive;computer vision;2d computer graphics;computational geometry;computer science;local feature size;theoretical computer science;geometric modeling;ray casting;language;3d computer graphics	NLP	67.84257795434578	-45.116134456340085	71061
9a3cb493f3ebb557d30aaf347d9f0033617320be	based on the profile of complex three dimensional stratum modeling	analytical models;3d modeling;block track delaunay triangulation;delaunay triangulation;computer model;three dimensional;geology solid modeling computational modeling three dimensional displays mathematical model data models analytical models;data model;2d modeling;solid modelling data visualisation geographic information systems;data visualisation;computational modeling;3d model;geology;geographic information systems;three dimensional displays;solid modeling;geological information complex three dimensional stratum modeling computer technology gradual maturity engineering geological modeling information visualization analysis system three dimensional geological modeling tool surface topography information production level surface equation method surface intersection 3d geological model;mathematical model;analytical model;solid modelling;block track delaunay triangulation 2d modeling 3d modeling;data models	With the development of computer technology and geological modeling study of the gradual maturity, 3D for the engineering geological modeling and information visualization analysis system of opportunities and challenges brought about. Have carried on the detailed introduction to the three dimensional geological modeling tool and the method. Summarized the three dimensional geological modeling basic step. Surface topography information deduce the initial construction of the geological model project. Carry out the calculation of occurrence. How to use the discrete value of the occurrence of information, production level surface equation method, And study of the surface intersection, Initial generation of 3D geological model. This paper discusses the adoption of the new access to the geological information on how to modify the initial model editor.	algorithm;capability maturity model;computer;information visualization;multivariate interpolation;topography	Ning Zhao;Rui Wang	2011	2011 2nd International Conference on Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC)	10.1109/AIMSEC.2011.6011338	computer vision;simulation;computer science	Robotics	64.64647105563438	-43.30845882954153	71062
f41a66f87a0efc7e7c39c09f4366ee85c84d1ca9	autocalibration-based partioning relationship and parallax relation for head-mounted eye trackers	eye tracking;calibration;image processing	This paper presents new methods to calibrate a head-mounted Eye Tracker (ET) automatically, as well as a new way to obtain an estimated point of regard (POR), taking account of the parallax. Calibration is performed in real time; it is easy for the user who just needs to look at one calibration pattern for a few seconds before starting. This method provides a very important couple of points which helps to use a local relationship to compute the POR instead of a global one. This approach significantly improves the precision of the points of regard when the scene camera is mounted with a short focal lens. An estimation of POR when the user looks somewhere outside the calibration distance is also proposed. This estimation is based on an ET modelling such as a stereovision system, to take account of the parallax effect. The aim of this study is to simplify the use of ET techniques for “non-initiated” people, especially here learner drivers.	binocular vision;computation;eb-eye;epipolar geometry;experience;eye tracking;focal (programming language);line level;parallax;real-time computing;stereopsis	Sacha Bernet;Christophe Cudel;Damien Lefloch;Michel Basset	2012	Machine Vision and Applications	10.1007/s00138-012-0427-3	computer vision;simulation;computer graphics (images)	Vision	55.98120743753087	-48.516618521298525	71278
5366978aba30026f88c7546c98cccd07e61b8bfc	camera calibration from periodic motion of a pedestrian		Camera calibration directly from image sequences of a pedestrian without using any calibration object is a really challenging task and should be well solved in computer vision, especially in visual surveillance. In this paper, we propose a novel camera calibration method based on recovering the three orthogonal vanishing points (TOVPs), just using an image sequence of a pedestrian walking in a straight line, without any assumption of scenes or motions, e.g., control points with known 3D coordinates, parallel or perpendicular lines, non-natural or pre-designed special human motions, as often necessary in previous methods. The traces of shoes of a pedestrian carry more rich and easily detectable metric information than all other body parts in the periodic motion of a pedestrian, but such information is usually overlooked by previous work. In this paper, we employ the images of the toes of the shoes on the ground plane to determine the vanishing point corresponding to the walking direction, and then utilize harmonic conjugate properties in projective geometry to recover the vanishing point corresponding to the perpendicular direction of the walking direction in the horizontal plane and the vanishing point corresponding to the vertical direction. After recovering all of the TOVPs, the intrinsic and extrinsic parameters of the camera can be determined. Experiments on various scenes and viewing angles prove the feasibility and accuracy of the proposed method.	approximation algorithm;camera resectioning;closed-circuit television;computer vision;sensor;shoes;tracing (software);vanishing point;viewing angle	Shiyao Huang;Xianghua Ying;Jiangpeng Rong;Zeyu Shang;Hongbin Zha	2016	2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2016.330	computer vision;camera auto-calibration;simulation	Vision	53.989551300428666	-49.78426563539347	71647
7dcc7f1193ee086f35f1491c131b304603aa56e9	g2 curves composed of planar cubic and pythagorean hodograph quintic spirals	concepcion asistida;computer aided design;curva bezier;image processing;spirale;mobile robot;procesamiento imagen;spiral;courbure;robotics;polynomial;traitement image;cubic spirals;algorithme;algorithm;algebraic geometry;fair curves;pythagorean hodograph;courbe bezier;polinomio;conception assistee;robotica;curvatura;pythagorean hodograph quintic spirals;geometria algebraica;curvature;robotique;hodografo;polynome;hodograph;espira;bezier curve;geometrie algebrique;algoritmo;hodographe	Abstract   Spiral segments are useful in the design of fair curves. They are important in CAD/CAM applications, the design of highway and railway routes, trajectories of mobile robots and other similar applications. A Pythagorean hodograph curve has the properties that its arc-length is a polynomial of its parameter, and the formula for its offset is a rational algebraic expression. Recent work demonstrated the composition of  G  2  curves by joining circular arcs and/or straight line segments with cubic Bezier spiral segments and Pythagorean hodograph quintic spiral segments. These spiral segments are members of wider classes of spiral segments which are now examined. Selecting members from these wider classes of spiral segments allows for more flexible curve design; it is not necessary to incorporate circular arcs and straight line segments when using them.	cubic function;quintic function	Desmond J. Walton;Dereck S. Meek	1998	Computer Aided Geometric Design	10.1016/S0167-8396(97)00028-9	mobile robot;topology;hodograph;image processing;algebraic geometry;computer aided design;calculus;bézier curve;mathematics;geometry;curvature;robotics;polynomial;spiral	EDA	67.25687958925313	-39.677124583505034	71738
ac86664ae00cf39529925c59c677d470a171ddd1	faster accurate reflections throught quadric mirrors	cbir;collaborative techniques;computer graphic;semantic modeling;field of view	Reflectors attract the attention of people since they reflect discontinuous images of the world and often provide unexpected information of a non-direct field of view. This is why reflections still have a lot of research attention in rendering of images in computer graphics, computer vision and optics, amongst other fields.	computer graphics;computer vision;reflection (computer graphics)	Nuno Gonçalves;Ana Catarina Nogueira	2010		10.1145/1836845.1836962	computer vision;image-based modeling and rendering;field of view;computer science;multimedia;computer graphics (images)	Vision	62.07320447051883	-50.83927366919765	71900
0a8da60168d77df8b969c10ebfa089caa2194db8	syncam: capturing sub-frame synchronous media using smartphones		Smartphones have become the de-facto capture devices for everyday photography. Unlike traditional digital cameras, smartphones are versatile devices with auxiliary sensors, processing power, and networking capabilities. In this work, we harness the communication capabilities of smartphones and present a synchronous/co-ordinated multi-camera capture system. Synchronous capture is important for many image/video fusion and 3D reconstruction applications. The proposed system provides an inexpensive and effective means to capture multi-camera media for such applications. Our coordinated capture system is based on a wireless protocol that uses NTP based synchronization and device specific lag compensation. It achieves sub-frame synchronization across all participating smartphones of even heterogeneous make and model. We propose a new method based on fiducial markers displayed on an LCD screen to temporally calibrate smart-phone cameras. We demonstrate the utility and versatility of this system to enhance traditional videography and to create novel visual representations such as panoramic videos, HDR videos, multi-view 3D reconstruction, multi-flash imaging, and multi-camera social media.	3d reconstruction;algorithm;digital camera;end-to-end principle;fiducial marker;movie projector;sensor;smartphone;social media;software system	Ishit Mehta;Parikshit Sakurikar;Rajvi Shah;P. J. Narayanan	2017	2017 IEEE International Conference on Multimedia and Expo (ICME)	10.1109/ICME.2017.8019430	computer science;3d reconstruction;artificial intelligence;computer vision;embedded system;synchronization;lag;videography;fiducial marker;liquid-crystal display;server;wireless application protocol	Mobile	54.641289462636	-44.11182841670355	71926
552f2b9a3646c5696fc722c7e0daa14d71e7d0f7	homogeneous coordinates and the principle of duality in two dimensional clipping	concepcion asistida;computer aided design;visualizacion;qualite;windows;algorithme;algorithm;visualization;visualisation;quality;fenetre;hidden line removal;conception assistee;ventana;calidad;elimination ligne cachee;algoritmo	Abstract--Most of the clipping algorithms assume that the clipping window is a regular rectangular polygonal boundary with sides parallel to the coordinate axes. But in most of the applications the clipping window is not a regular polygon. Sometimes the rectangular clipping window is rotated with respect to the coordinate system. Or the window can have more than four sides. In this case the window sides may be at an angle. Hence clipping to an arbitrary window becomes essential. In the clipping process the most essential part is to find the point of intersection after making the conventional visibility tests. This paper describes how the point of intersection of the line (to be clipped) with the window edge can be determined with a single division. It uses the principle of duality based on homogeneous coordinates.	algorithm;clipping (computer graphics);line–line intersection	A. Arokiasamy	1989	Computers & Graphics	10.1016/0097-8493(89)90045-9	line clipping;clipping;visualization;computer science;computer aided design;mathematics;geometry;algorithm;computer graphics (images)	Vision	66.69156664286449	-40.66853537318216	71996
1ab210a6974b4a9e356636505a53cca624d129e3	orthographic star coordinates	minimization;algorithms computer graphics image enhancement image interpretation computer assisted information storage and retrieval user computer interface;data visualisation data analysis;multivariate visualization data visualization three dimensional displays principal component analysis minimization nonlinear distortion visual analytics start plot;data visualisation;nonlinear distortion;data analysis;grand tour orthographic star coordinates projection technique 2d visualization domain 3d visualization domain coordinate axis affine projection sphere ellipse aspect ratio orthographic projection repeated nonlinear optimization orthographic interaction orthographic data tour sequence scatterplot tour principle component tour;three dimensional displays;principal component analysis;data visualization;visual analytics;multivariate visualization;data visualization three dimensional displays principal component analysis minimization nonlinear distortion;start plot	Star coordinates is a popular projection technique from an nD data space to a 2D/3D visualization domain. It is defined by setting n coordinate axes in the visualization domain. Since it generally defines an affine projection, strong distortions can occur: an nD sphere can be mapped to an ellipse of arbitrary size and aspect ratio. We propose to restrict star coordinates to orthographic projections which map an nD sphere of radius r to a 2D circle of radius r. We achieve this by formulating conditions for the coordinate axes to define orthographic projections, and by running a repeated non-linear optimization in the background of every modification of the coordinate axes. This way, we define a number of orthographic interaction concepts as well as orthographic data tour sequences: a scatterplot tour, a principle component tour, and a grand tour. All concepts are illustrated and evaluated with synthetic and real data.	acer;apache axis;appendix;arabic numeral 0;aspect ratio;axis vertebra;ccl22 protein, human;dataspaces;distortion;emoticon;equivalent weight;euclidean distance;gucy2c protein, human;imagery;isoelectric point;lss gene;linear programming;linear system;mcam protein, human;maple;mathematical optimization;morphing;nonlinear programming;nonlinear system;orthographic projection;principal component;projections and predictions;snord22 gene;synthetic intelligence;vanish (computer science);yottabyte;mapped	Dirk J. Lehmann;Holger Theisel	2013	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2013.182	computer vision;nonlinear distortion;computer science;theoretical computer science;geometry;orthographic projection;data analysis;data visualization;statistics;principal component analysis	Visualization	60.454201353432865	-44.40012651455267	72013
9057f09b49d1d092ba55844f9d432eac46f68399	procedural modeling of water caustics and foamy water for cartoon animation	non photorealistic rendering;procedural modeling;voronoi diagram	We propose a method for procedural modeling and animation of cartoon water effects such as water caustics, foamy wake, and longshore currents. In our method we emulate the visual abstraction of these cartoon effects by the use of Voronoi diagrams and the motion abstraction by designing relevant controlling mechanisms corresponding to each effect. Our system enables the creation of cartoon effects with minimal intervention from the animator. Through high-level initial specification, the effects are animated procedurally in the style of hand-drawn cartoons.	emulator;high- and low-level;high-level programming language;master/slave (technology);password cracking;procedural modeling;simulation;voronoi diagram;wake-on-lan	Jing Liao;Jinhui Yu;Long Jia	2010	2010 18th Pacific Conference on Computer Graphics and Applications	10.1631/jzus.C1000228	computer vision;simulation;voronoi diagram;computer science;non-photorealistic rendering;procedural modeling;computer graphics (images)	Graphics	64.28048769213393	-49.21743719545059	72187
4107e4ff2346b3ca2192eace96565ff04905a136	balancing considered harmful - faster photon mapping using the voxel volume heuristic	nearest neighbor queries;computacion informatica;simulation;grupo de excelencia;nearest neighbor query;global illumination;caustics;ciencias basicas y experimentales;kd tree;k nearest neighbor;photon mapping	Photon mapping is one of the most important algorithms for computing global illumination. Especially for efficiently producing convincing caustics, there are no real alternatives to photon mapping. On the other hand, photon mapping is also quite costly: Each radiance lookup requires to find the k nearest neighbors in a kd-tree, which can be more costly than shooting several rays. Therefore, the nearest-neighbor queries often dominate the rendering time of a photon map based renderer. In this paper, we present a method that reorganizes – i.e. unbalances – the kd-tree for storing the photons in a way that allows for finding the k-nearest neighbors much more efficiently, thereby accelerating the radiance estimates by a factor of 1.2–3.4. Most importantly, our method still finds exactly the same k-nearest-neighbors as the original method,without introducing any approximations or loss of accuracy. The impact of our method is demonstrated with several practical examples.	approximation;binary space partitioning;geometric primitive;global illumination;heuristic;k-nearest neighbors algorithm;lookup table;loss function;photon mapping;pointer (computer programming);ray tracing (graphics);reflection (computer graphics);simd;self-balancing binary search tree;speedup;traverse;vlastimil klíma;voxel	Ingo Wald;Johannes Günther;Philipp Slusallek	2004	Comput. Graph. Forum	10.1111/j.1467-8659.2004.00791.x	computer science;artificial intelligence;theoretical computer science;machine learning;k-d tree;mathematics;photon mapping;k-nearest neighbors algorithm;global illumination;caustic;computer graphics (images)	Graphics	66.43518587092423	-51.143643761185395	72287
1e479bbd87f499dd2ecfbb2f1a6340fcfd51f99c	3d facial reconstruction from a single 2d rasterstereography image	facial symmetry 3d reconstruction rasterstererography line following kernel density estimation;surface reconstruction;stereo image processing face recognition image reconstruction;surface topography;face three dimensional displays image reconstruction surface topography surface reconstruction estimation;estimation;three dimensional displays;image reconstruction;facial topography 3d facial reconstruction single 2d rasterstereography image nonintrusive technique vertebral imaging depth estimation;face	This paper presents a new 3D reconstruction approach for the human face, inspired from raster-stereography, a non-intrusive technique usually employed in vertebral imaging. The method proposes depth estimation of the facial topography based on raster grid deformations, as well as a parameter-free way to obtain the reconstructed topographic surface. An example application of the depth map reinforces the correctness of the approach.	3d reconstruction;algorithm;coherence (physics);correctness (computer science);data acquisition;depth map;encode;facial recognition system;stereoscopy;topography	Sadaf I. Behlim;Tahir Q. Syed	2014	2014 4th International Conference on Image Processing Theory, Tools and Applications (IPTA)	10.1109/IPTA.2014.7001978	iterative reconstruction;face;computer vision;estimation;surface reconstruction;mathematics;statistics;computer graphics (images)	Robotics	55.534044512182696	-51.54316461786039	72441
db7f164dbb8df47d69995ed31356d9f04197cfd6	real-time image marbleization	it software telecommunications;industry sectorselectronics;media art;journal;virtual marbling;fluid simulation;figurative marbling	We present a new real-time image marbleization method that converts an image into a marble-like appearance automatically. The approach models the marbleization process as a two-dimensional fluid dynamics problem, whereby color advection of an input image results in a marbleized image. During the fluid dynamics simulation, we add a pixel-level external force field which is tangent to salient features in the image. The forces are computed from the image characteristics without user intervention. A stylized image with marble-like appearance is easily created that maintains the basic shape of objects in the input image. The entire modeling framework is implemented on a graphics processing unit, thus enabling real-time visual feedback. This approach provides a new tool to design figurative marbling textures without mixing of colors, which are almost impossible with previous computer-generated marbling methods.	color;computer graphics;computer-generated holography;figurative system of human knowledge;force field (chemistry);graphics processing unit;marble;pixel;real-time clock;real-time transcription;simulation;volume;zhao youqin's π algorithm	Shufang Lu;Xiaogang Jin;Hanli Zhao;Yandan Zhao	2012	Multimedia Tools and Applications	10.1007/s11042-012-0989-0	fluid simulation;computer vision;feature detection;image processing;computer science;multimedia;computer graphics (images)	Graphics	64.69711479980224	-48.515239066627316	72535
492eeea7d8b4942fc9fa2483d751571ca80f8bb3	robust stereo tracking for space applications	image features;levenberg marquardt;least squares approximations;occlusion;occlusion robust stereo tracking space application 3d model based tracking virtual visual servoing m estimator least squares implementation;real time;least squares implementation;least square method;iterative algorithm;computer vision;robust stereo tracking;virtual visual servoing;m estimator;3d model;optical tracking;data extraction;stereo image processing;3d model based tracking;visual servoing least squares approximations optical tracking space vehicles stereo image processing;newton raphson;statistical techniques;visual servoing;local minima;iteratively re weighted least squares;space application;space vehicles;robustness visual servoing cameras orbital robotics robot vision systems real time systems iterative algorithms minimization methods robust stability intelligent robots;virtual worlds;pose estimation	This paper proposes a real-time, robust and efficient 3D model-based tracking algorithm for visual servoing. A virtual visual servoing approach is used for 3D tracking. This method is similar to more classical non-linear pose computation techniques. Robustness is obtained by integrating an M- estimator into the virtual visual control law via an iteratively re- weighted least squares implementation. The presented approach is also extended to the use of multiple cameras. Results show the method to be robust to occlusion, changes in illumination and miss-tracking.	algorithm;computation;hidden surface determination;least squares;nonlinear system;optimal control;real-time clock;real-time computing;usability;visual servoing	Fabien Dionnet;Éric Marchand	2007	2007 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2007.4399028	computer vision;simulation;pose;levenberg–marquardt algorithm;tracking system;computer science;maxima and minima;control theory;m-estimator;mathematics;iterative method;newton's method;visual servoing;least squares;feature	Robotics	53.76315385096129	-40.46016024991073	72666
397dd2d680dda58253c54f42d24611a9ad231324	precise omnidirectional camera calibration	shape from motion;relative position;mirrors;obstacle detection;image processing equipment;application software;mirror;software verification;motion estimation;precise omnidirectional camera calibration;testing;imaging process model;stereo matching precise omnidirectional camera calibration imaging process model rotation translation mirror 3d vision motion estimation obstacle detection misalignment correct relative position recovery shape from motion;misalignment;three dimensional;computer vision;cameras calibration mirrors testing stereo vision motion estimation motion detection software algorithms application software error correction;correct relative position recovery;omnidirectional camera;stereo matching;translation;error correction;field of view;stereo image processing;stereo vision;software algorithms;3d vision;image processing equipment cameras calibration mirrors stereo image processing computer vision motion estimation;rotation;motion detection;calibration;cameras	Recent omnidirectional camera designs aim a conventional camera at a mirror that expands the camera’s field of view. This wide view is ideal for three-dimensional vision tasks such as motion estimation and obstacle detection, but these applications require an accurate model of the imaging process. We present a full model of the imaging process, which includes the rotation and translation between the camera and mirror, and an algorithm that determines this relative position from observations of known points in a single image. We present tests of the model and of the calibration procedure for various amounts of misalignment between the mirror and camera. These tests show that the algorithm recovers the correct relative position, and that by using the full model, accurate shape-from-motion and stereo matching are possible even if the camera and mirror are severely misaligned.	algorithm;autostereogram;calibration (statistics);computer stereo vision;experiment;motion estimation;omnidirectional camera	Dennis Strelow;Jeffrey Mishler;David Ryan Koes;Sanjiv Singh	2001		10.1109/CVPR.2001.990542	translation;three-dimensional space;stereo camera;computer vision;camera auto-calibration;camera matrix;application software;calibration;camera resectioning;error detection and correction;field of view;software verification;rotation;computer science;stereopsis;motion estimation;software testing;pinhole camera model;computer graphics (images)	Vision	54.37279740638191	-48.91187691439638	72703
e20f9922de87ca40fd66fa0faa46707a3ef9e584	target tracking in industrial multi-sensor short-range radar applications using doppler and amplitude information	radar tracking;doppler effect;doppler radar;artificial intelligence;radar cross sections;target tracking	This paper treats localization and tracking of small extended targets in short-range applications with a multi-sensor Doppler radar network. It particularly addresses cases where the point target assumption is not valid. Hence, the target extensions and the fluctuating radar cross section (RCS) are considered during the raw data processing and in the tracking algorithm. Here, a metallic cuboid with a priori known alignment and backscattering properties is considered. Such target shapes often appear as raw workpieces in industrial milling and drilling applications. A multi-sensor platform for Doppler-only localization of the extended target in a bounded environment is introduced. An approach to combine additional amplitude information (AI) observed by the sensors is presented. This approach is available in the considered application, where closely-spaced sensors in their specific sensor-target geometry provide information about the alignment from amplitude evaluation. The coordinate estimates are then utilized in the tracker initialization procedure to increase the tracking reliability. Results from electromagnetic RCS simulations are given and the estimation algorithm is presented, which delivers reliable coordinate estimates from the observed AI by probability mixing. Simulation results of the initialization procedure and obtained improvement for tracking a single extended cube are shown.	algorithm;bittorrent tracker;cross section (geometry);cuboid;internationalization and localization;multipath propagation;radar;reflection (computer graphics);sensor;simulation;software propagation	Thomas J. Mittermaier;Uwe Siart;Thomas F. Eibert	2016	2016 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)	10.1109/MFI.2016.7849552	man-portable radar;computer vision;continuous-wave radar;electronic engineering;radar lock-on;engineering;fire-control radar;bistatic radar;low probability of intercept radar;pulse-doppler radar;radar imaging;remote sensing	Robotics	56.54185052077266	-39.54422336676108	72742
258504a98e0f147fd986f0b1ba085ff26a4586ee	foundry: hierarchical material design for multi-material fabrication	fabrication;3d printing;materials	We demonstrate a new approach for designing functional material definitions for multi-material fabrication using our system called Foundry. Foundry provides an interactive and visual process for hierarchically designing spatially-varying material properties (e.g., appearance, mechanical, optical). The resulting meta-materials exhibit structure at the micro and macro level and can surpass the qualities of traditional composites. The material definitions are created by composing a set of operators into an operator graph. Each operator performs a volume decomposition operation, remaps space, or constructs and assigns a material composition. The operators are implemented using a domain-specific language for multi-material fabrication; users can easily extend the library by writing their own operators. Foundry can be used to build operator graphs that describe complex, parameterized, resolution-independent, and reusable material definitions. We also describe how to stage the evaluation of the final material definition which in conjunction with progressive refinement, allows for interactive material evaluation even for complex designs. We show sophisticated and functional parts designed with our system.	composite pattern;domain-specific language;material design;progressive refinement;refinement (computing)	Kiril Vidimce;Alexandre Kaspar;Ye Wang;Wojciech Matusik	2016		10.1145/2984511.2984516	3d printing;fabrication	HCI	65.4137829978351	-47.50295828947582	72802
49c1d89d116c1bd22a6ce60d8d7bb1e2b4f8bd85	volume graphics	computational geometry;data visualisation;solid modelling	Volume graphics, which employs a volume buffer of voxels for 3D scene representation, is discussed. Volume graphics offers advantages over surface graphics: it is viewpoint independent, insensitive to scene and object complexity, and suitable for the representation of sampled and simulated data sets. Moreover, geometric objects can be mixed with these data sets. Volume graphics supports the visualization of internal structures and lends itself to the realization of block operations, constructive solid geometry modeling, irregular voxel sizes, and hierarchical representation. The problems associated with the volume buffer representation (such as discreteness, memory size, processing time, and loss of geometric representation) are discussed.<<ETX>>	constructive solid geometry;graphics;voxel	Arie E. Kaufman;Daniel Cohen-Or;Roni Yagel	1993	Computer	10.1109/MC.1993.274942	geometric primitive;computer vision;scientific visualization;2d computer graphics;computational geometry;computer science;theoretical computer science;ray casting;real-time computer graphics;function representation;computer graphics;volume rendering;3d computer graphics;computer graphics (images)	Visualization	67.80232591599086	-50.76544619555293	72818
a332329de7ca083a165ea55977f4876152ddb44b	omnivergent stereo	omnivergent stereo;omnivergent camera;traditional stereo;minimal reconstruction error;images omnivergent stereo;omnivergent virtual camera;spherical omnivergent camera;omnivergent image;panorama;multiperspective imaging;images omnivergent image;scene model;stereo reconstruction;stereo;vergence;mosaic	The notion of a virtual camera for optimal 3D reconstruction is introduced. Instead of planar perspective images that collect many rays at a fixed viewpoint, omnivergent cameras collect a small number of rays at many different viewpoints. The resulting 2D manifold of rays is arranged into two multiple-perspective images for stereo reconstruction. We call such images omnivergent images, and the process of reconstructing the scene from such images omnivergent stereo. This procedure is shown to produce 3D scene models with minimal reconstruction error, due to the fact that for any point in the 3D scene, two rays with maximum vergence angle can be found in the omnivergent images. Furthermore, omnivergent images are shown to have horizontal epipolar lines, enabling the application of traditional stereo matching algorithms, without modification. Three types of omnivergent virtual cameras are presented: spherical omnivergent cameras,center-strip cameras and dual-strip cameras.	3d reconstruction;algorithm;computer stereo vision;correspondence problem;epipolar geometry;vergence;virtual camera system	Steven M. Seitz;Adam Tauman Kalai;Harry Shum	1999	International Journal of Computer Vision	10.1023/A:1016342731674	stereo cameras;stereo camera;computer vision;geography;optics;epipolar geometry;computer graphics (images)	Vision	57.08273319712758	-50.77712223147339	72840
31cfa06655d27e055d34498d040fc23f06de22d8	automated evaluation of interest point detectors	interest points;detector;visual processing;repeatability;automated processing	Interest point detectors are important components in a variety of computer vision systems. This paper demonstrates an automated virtual 3D environment for controlling and measuring detected interest points on 2D images in an accurate and rapid manner. Real-time affine transform tools enable easy implementation and full automation of complex scene evaluations without the time-cost of a manual setup. Nine detectors are tested and compared using evaluation and testing methods based on Schmid [18]. Each detector is tested on the BSDS500 image set using rotation in the X, Y, and Z axis as well as scale in the X, Y axis. Results demonstrate the differing performance and behaviour of each detector across the evaluated transformations, which may assist computer vision practitioners in choosing the right detector for their application.	apache axis;computer vision;harris affine region detector;optic axis of a crystal;rapid prototyping;real-time web;sensor;shader;test automation;tweaking;virtual reality;while	Simon R. Lang;Martin H. Luerssen;David M. W. Powers	2013	2013 IEEE/ACIS 12th International Conference on Computer and Information Science (ICIS)	10.4018/ijsi.2014010107	computer vision;simulation;computer science;engineering drawing	Vision	56.27767750427733	-44.66918484469393	73040
39403b125087808e99c0fed493698c14b9e18490	planar rational b-spline motions	moving image;motion study;image processing;procesamiento imagen;estudio movimiento;nurbs curves;imagen movil;traitement image;image mobile;control structure;planar rational motion;etude mouvement;b spline;kinematic mapping;minimum degree;curves and surfaces;b splin;computer aided geometric design	Nonuniform rational B-spline (NURBS) curves and their associated techniques are of major importance in computer aided geometric design. The paper discusses planar rational B-spline motions. These are planar motions in which all point paths are NURBS curves. Such motions are connected with a linear control structure, which can be used to apply algorithms developed for the design of curves and surfaces directly to the design of planar motions. The first part of the paper gives a brief introduction to plane kinematics and the theory of kinematic mappings. Rational motions and the application of the corresponding control structures are discussed in detail. The second part of the paper presents a C2 interpolation scheme with rational motions of degree 4, which is the minimum degree for motions which have positions with vanishing angular velocity.	algorithm;angularjs;computer-aided design;control flow;control system;geometric design;interpolation;kinematic chain;non-uniform rational b-spline;planar (computer graphics);velocity (software development)	Michael G. Wagner	1995	Computer-Aided Design	10.1016/0010-4485(95)92152-I	b-spline;computer vision;topology;image processing;computer science;rational motion;mathematics;geometry;control flow	Robotics	67.1641210358976	-38.2688750202817	73221
88bff4ea1bad7e7345976ebf4ab273b242e9031a	a pipeline for structured light bathymetric mapping	lasers;remote sensing by laser beam;underwater vehicles;bepress selected works;underwater vehicles bathymetry calibration oceanographic equipment oceanographic techniques remote sensing by laser beam remotely operated vehicles sonar;remotely operated vehicles;feature extraction;simultaneous localization and mapping;robustness;calibration cameras feature extraction lasers robustness simultaneous localization and mapping vehicles;vehicles;lasers calibration cameras vehicles simultaneous localization and mapping feature extraction robustness;bathymetry;oceanographic equipment;oceanographic techniques;calibration;cameras;sea floor rock outcrop structured light bathymetric mapping structured light laser imaging high resolution bathymetric maps stereo cameras remotely operated vehicle in situ calibration laser system geometry sub pixel accuracy image quality water column turbidity bathymetric slam algorithm isam framework sample density high frequency multibeam sonar stereo vision submerged archaeological site;sonar	This paper details a methodology for using structured light laser imaging to create high resolution bathymetric maps of the sea floor. The system includes a pair of stereo cameras and an inclined 532nm sheet laser mounted to a remotely operated vehicle (ROV). While a structured light system generally requires a single camera, a stereo vision set up is used here for in-situ calibration of the laser system geometry by triangulating points on the laser line. This allows for quick calibration at the survey site and does not require precise jigs or a controlled environment. A batch procedure to extract the laser line from the images to sub-pixel accuracy is also presented. The method is robust to variations in image quality and moderate amounts of water column turbidity. The final maps are constructed using a reformulation of a previous bathymetric Simultaneous Localization and Mapping (SLAM) algorithm called incremental Smoothing and Mapping (iSAM). The iSAM framework is adapted from previous applications to perform sub-mapping, where segments of previously visited terrain are registered to create relative pose constraints. The resulting maps can be gridded at one centimeter and have significantly higher sample density than similar surveys using high frequency multibeam sonar or stereo vision. Results are presented for sample surveys at a submerged archaeological site and sea floor rock outcrop.	acoustic cryptanalysis;algorithm;algorithmic efficiency;bathymetry;computational complexity theory;image quality;image resolution;kalman filter;map;pipeline (computing);pixel;point cloud;remotely operated vehicle;sonar (symantec);sensor;simultaneous localization and mapping;smoothing;stereo camera;stereo cameras;stereopsis;structured light	Gabrielle Inglis;Clara Smart;Ian Vaughn;Christopher N. Roman	2012	2012 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2012.6386038	remotely operated underwater vehicle;computer vision;calibration;laser;feature extraction;computer science;bathymetry;optics;sonar;robustness;remote sensing;simultaneous localization and mapping	Robotics	55.20619152227837	-43.2601074376595	73312
be0fc0eb36bc2a545f619073f40377ad80127b5d	photometric stereo under low frequency environment illumination	low frequency;spherical harmonic;shape recovery;photometric stereo;reflection model;linear equations	The well-studied problem of photometric stereo has almost exclusively made the assumption that illumination is provided by distant point light sources. In this paper, we consider for the first time the problem of photometric shape recovery from images in which an object is illuminated by environment lighting, i.e. where the illumination is modelled as a function over the incident sphere. To tackle this difficult problem, we restrict ourselves to low frequency illumination environments in which the lighting is known and can be well modelled using spherical harmonics. Under these conditions we show that shape recovery from one or more colour images requires only the solution of a system of linear equations. For the single image case we make use of the properties of spherical harmonics under rotations. We assume homogeneous Lambertian reflectance (with possibly unknown albedo) but discuss how the method could be extended to other reflectance models. We show that our method allows accurate shape recovery under complex illumination, even when our assumptions are breached, and that accuracy increases with the number of input images.	photometric stereo	Rui Huang;William A. P. Smith	2010		10.1007/978-3-642-17274-8_14	computer vision;photometric stereo;computer science;linear equation;low frequency;spherical harmonics	Vision	55.80716127046115	-51.875095938725956	73470
ea0a2c7373da86af85f977f2a5a708273126596a	combining computer graphics with chinese traditional painting	software;painting;art;logiciel;computer graphics;chine;peinture art;arte;computer graphic;asie;chinese painting;logicial;pintura;china;peinture chinoise;infographie;asia	Abstract   Systems for generating chinese stylistic painting are described. Basic sets of parameterized primetives for drawing writing-brush-like strokes are build. Then are built up extensive sets of procedure for representing many of elements of pictures. All routines employ constrained-random perturbation. Altering the parameters in the routines, we can create a different genre of pictures using production rules to adjust the parameters in the elements of picture. We can construct various pictures.	computer graphics	Yun-Jie Pang;Yang Shu Xun;Chi Yiu	1987	Computers & Graphics	10.1016/0097-8493(87)90046-X	computer vision;painting;computer science;artificial intelligence;chine;multimedia;computer graphics;china;algorithm;computer graphics (images)	Graphics	64.13913204553421	-45.95380361789324	73499
2b33e25bb527facc94e9f33a221113d6fc4e9eb5	controlling spacecraft landings with constantly and exponentially decreasing time-to-contact	spacecraft landing control visual cue extraction theoretical analysis empirical analysis visual quantities constant ventral optic flow bioinspired landing strategies exponentially decreasing time to contact constantly decreasing time to contact;optical variables measurement;traitement du signal et de l image;optical imaging space vehicles cameras visualization optical variables measurement extraterrestrial measurements adaptive optics;visualization;optical imaging;extraterrestrial measurements;cameras;space vehicles entry descent and landing spacecraft feature extraction image sequences;space vehicles;adaptive optics	Two bioinspired landing strategies are studied. Both strategies enforce a constant ventral optic flow with constantly decreasing time-to-contact or exponentially decreasing time-to-contact. Until now these strategies have only been studied assuming the visual quantities to be known, i.e., without sensor noise and delay. In this study, the control laws executing the aforementioned landing strategies are studied both theoretically and empirically, taking into account the actual extraction of the visual cues from images.		Guido C. H. E. de Croon;Daniel Alazard;Dario Izzo	2015	IEEE Transactions on Aerospace and Electronic Systems	10.1109/TAES.2014.130135	computer vision;simulation;visualization;engineering;optical imaging;control theory;optics;adaptive optics;physics	Visualization	55.75890596733688	-39.53881704160421	73569
67ca63f8986113ea778451a8456951a27d766307	automatic nodal triangulation for finite elements	automatic mesh generation;triangular finite element;concepcion asistida;computer aided design;methode element fini;metodo elemento finito;generation automatique maille;finite element method;finite element;elemento finito triangular;generacion automatica red;conception assistee;element fini triangulaire	The production of an error-free set of punched data cards or tapes for computer programs that employ the finite-element method can be a costly and timeconsuming process because of the large number of data items frequently required. Attention has been focused recently 1-4 on methods of reducing these data requirements by the programmed generation of meshes from a knowledge of the nodal positions and geometric boundaries. In general, the following items are specified:	computer program;finite element method;mobile broadband modem;requirement	C. B. Saw;R. G. Smith	1993	Computer-Aided Design	10.1016/0010-4485(93)90089-7	engineering;computer aided design;finite element method;mathematics;engineering drawing;algorithm;mechanical engineering	EDA	67.36154778138733	-39.4512266186154	73649
78bb8c11085ec58d7cc95a027f88fd330820fbe8	seam tracking investigation via striped line laser sensor		PurposernrnrnrnrnThis paper aims to propose a set of six-axis robot arm welding seam tracking experiment platform based on Halcon machine vision library to resolve the curve seam tracking issue.rnrnrnrnrnDesign/methodology/approachrnrnrnrnrnRobot-based and image coordinate systems are converted based on the mathematical model of the three-dimensional measurement of structured light vision and conversion relations between robot-based and camera coordinate systems. An object tracking algorithm via weighted local cosine similarity is adopted to detect the seam feature points to prevent effectively the interference from arc and spatter. This algorithm models the target state variable and corresponding observation vector within the Bayes framework and finds the optimal region with highest similarity to the image-selected modules using cosine similarity.rnrnrnrnrnFindingsrnrnrnrnrnThe paper tests the approach and the experimental results show that using metal inert-gas (MIG) welding with maximum welding current of 200A can achieve real-time accurate curve seam tracking under strong arc light and splash. Minimal distance between laser stripe and welding molten pool can reach 15 mm, and sensor sampling frequency can reach 50 Hz.rnrnrnrnrnOriginality/valuernrnrnrnrnDesigning a set of six-axis robot arm welding seam tracking experiment platform with a system of structured light sensor based on Halcon machine vision library; and adding an object tracking algorithm to seam tracking system to detect image feature points. By this technology, this system can track the curve seam while welding.		Yanbiao Zou;Jinchao Li;Xiangzhi Chen	2017	Industrial Robot	10.1108/IR-11-2016-0294	structured light;simulation;engineering;cosine similarity;tracking system;welding;arc (geometry);machine vision;video tracking;computer vision;robotic arm;artificial intelligence	Robotics	59.82259630691245	-39.21942947419859	73733
4ffd5c803472878bc097970bae85738c89263f5a	shape and topology from noisy triangulated surfaces in a multiple view reconstruction toolchain			toolchain	Tilman Wekel	2014			computer vision;computer science;theoretical computer science;engineering drawing	Vision	66.71826652235256	-43.548585049381536	74135
771c99d309bb939d3034eeccab981252a3d7ef25	a three-dimensional approach to graphic design	three dimensions;three dimensional;graphic design	In our recent work we have used the two-dimensional product-delay algorithm for creating artistic graphic designs on a computer. In this paper, we present a three-dimensional approach to graphic design. This approach extends the product-delay algorithm to three dimensions and is referred to as the “product-delay-spacecurve” algorithm or simply the PDS algorithm. It is shown that the PDS algorithm can generate a rich variety of interesting geometric patterns. The methodology is illustrated with a combination of simple sine waves.		Asok K. Sen	2003	Computers & Graphics	10.1016/S0097-8493(02)00286-8	three-dimensional space;simulation;computer science;geometry;computer graphics (images)	HCI	65.19231510972381	-45.93085637823026	74136
3037399b73464e6b4aa0a9d3b53789ca2277500e	skin deformation and animation of character models based on static and dynamic ordinary differential equations				Ehtzaz Chaudhry	2016			computer vision;simulation;mathematics;computer graphics (images)	Graphics	63.648787040379595	-45.701909128574385	74249
e0e40a6fadadf50a12a39e5d7cfd500919218486	approximative occlusion culling using the hull tree	approximative occlusion;simple outer hull;inner hull;approximative rendering algorithm;outer hull;rendering load;so-called hull tree;hull tree;hierarchical data structure;real-time rendering;data structure	Occlusion culling is a common approach to accelerate real-time rendering of polygonal 3D-scenes by reducing the rendering load. Especially for large scenes, it is necessary to remove occluded objects to achieve a frame rate that provides an interactive environment. In order to benefit from the culling properly, often hierarchical data structures are used. These data structures typically create a spatial subdivision of a given scene into axis-aligned bounding boxes. These boxes can be tested quickly, but they are not very accurate. By using these boxes, the included objects are detected as visible, even if other objects occlude them (false-positives). To get perfect results, the models' original geometry included in the box has to be tested, but this would require too much computational power. To overcome this problem, original objects' approximations could be used, but typical methods for mesh simplification cannot be applied, because they do not create an outer hull for a given object.#R##N##R##N#We present a model simplification algorithm, which generates simple outer hulls, consisting of only few more triangles than a box, while preserving an object's shape better than a corresponding bounding box. This approach is then extended to a hierarchical data structure, the so-called hull tree, that can be generated for a given scene to improve the visibility tests.#R##N##R##N#Next, we present an approximative rendering algorithm, which combines the features of the hull tree with the use of inner hulls for efficient occlusion detection and global state-sorting of the visible objects.	hidden surface determination	Tim Süß;Clemens Koch;Claudius Jähn;Matthias Fischer	2011			simulation;mathematics;potentially visible set;computer graphics (images)	Vision	66.74234481179907	-49.75594109133866	74255
0edbce300a8bf8ec73e11d5dee3ac76cd6454746	precomputed visibility cuts for interactive relighting with dynamic brdfs	topology;robustness mesh generation topology shape geometry computer graphics application software conference management laboratories skeleton;general and miscellaneous mathematics computing and information science;application software;computer graphics;geometry;informing science;conference management;skeleton;shape;deformation;algorithms;robustness;mesh generation;management;alignment;99 general and miscellaneous mathematics computing and information science	This paper presents a novel PRT-based method that uses precomputed visibility cuts for interactive relighting with all-frequency environment maps and arbitrary dynamic BRDFs. Our method is inspired by the recent Lightcuts approach [24] and we parameterize distant environment lighting onto uniformly distributed sample points over the sphere. Using a binary tree structure of the points, we precompute and approximate each vertex's visibility function into clusters that we call the precomputed visibility cuts. These cuts are iteratively selected with bounded approximation error and confined cluster size. At run-time, a GPU-based relighting algorithm quickly computes the view-dependent shading color by accessing a dynamically built light tree, the precomputed visibility cuts, and a direct sampling of an arbitrary BRDF using each visibility cluster's average direction and the dynamic view direction. Compared to existing PRT techniques, our method guarantees uniform sampling of the lighting, requires no precomputed BRDF data, and can be easily extended to handle one-bounce glossy indirect transfer effects in real-time.	3d modeling;approximation algorithm;approximation error;bidirectional reflectance distribution function;binary tree;bump mapping;graphics processing unit;map;nearest-neighbor interpolation;on the fly;particle filter;paul debevec;pixel;precomputation;precomputed radiance transfer;ray tracing (graphics);real-time clock;sampling (signal processing);shader;shading;sparse matrix;tree structure	Oskar Åkerlund;Mattias Unger;Rui Wang	2007	15th Pacific Conference on Computer Graphics and Applications (PG'07)	10.1109/PG.2007.30	mesh generation;application software;shape;computer science;bioinformatics;theoretical computer science;mathematics;geometry;programming language;computer graphics;skeleton;deformation;robustness;computer graphics (images)	Graphics	66.17423208112298	-49.75300494892984	74298
61df03f88e2d2873e2ad148f34fe6ac50817a817	shape and reflectance from natural illumination	lighting environment act analogously;lighting environment;accurate reflectance estimation;bandpass filter;accurate surface orientation information;surface patch;orientation clue;real-world natural illumination environment;natural illumination;extensive experimentation	We introduce a method to jointly estimate the BRDF and geometry of an object from a single image under known, but uncontrolled, natural illumination. We show that this previously unexplored problem becomes tractable when one exploits the orientation clues embedded in the lighting environment. Intuitively, unique regions in the lighting environment act analogously to the point light sources of traditional photometric stereo; they strongly constrain the orientation of the surface patches that reflect them. The reflectance, which acts as a bandpass filter on the lighting environment, determines the necessary scale of such regions. Accurate reflectance estimation, however, relies on accurate surface orientation information. Thus, these two factors must be estimated jointly. To do so, we derive a probabilistic formulation and introduce priors to address situations where the reflectance and lighting environment do not sufficiently constrain the geometry of the object. Through extensive experimentation we show what this space looks like, and offer insights into what problems become solvable in various categories of real-world natural illumination environments.	autostereogram;bidirectional reflectance distribution function;cobham's thesis;decision problem;embedded system;experiment;photometric stereo;uncontrolled format string	Geoffrey Oxholm;Ko Nishino	2012		10.1007/978-3-642-33718-5_38	computer vision	Vision	58.46826363621953	-52.049606001331405	74323
f0a2e92bd247ce7f29f4af4433efe50acc964268	efficient and dynamic simplification of line drawings	dynamic simplification;hierarchical simplification;line drawings;picture image generation line rendering;i 3 3 computer graphics	In this paper we present a pipeline for rendering dynamic 2D/3D line drawings efficiently. Our main goal is to create efficient static renditions and coherent animations of line drawings in a setting where lines can be added, deleted and arbitrarily transformed on-the-fly. Such a dynamic setting enables us to handle interactively sketched 2D line data, as well as arbitrarily transformed 3D line data in a unified manner. We evaluate the proximity of screen projected strokes to simplify them while preserving their continuity. We achieve this by using a special data structure that facilitates efficient proximity calculations in a dynamic setting. This on-the-fly proximity evaluation also facilitates generation of appropriate visibility cues to mitigate depth ambiguities and visual clutter for 3D line data. As we perform all these operations using only line data, we can create line drawings from 3D models without any surface information. We demonstrate the effectiveness and applicability of our approach by showing several examples with initial line representations obtained from a variety of sources: 2D and 3D hand-drawn sketches and 3D salient geometry lines obtained from 3D surface representations.	3d computer graphics;3d modeling;blackwell (series);clutter;coherence (physics);compiler;computer science;data structure;eurographics;high- and low-level;ibm notes;interactivity;level of detail;line drawing algorithm;microsoft research;network switch;scott continuity;text simplification	Amit Shesh;Baoquan Chen	2008	Comput. Graph. Forum	10.1111/j.1467-8659.2008.01151.x	computer vision;computer science;computer graphics (images)	Graphics	65.6328446674635	-48.121119810315854	74380
805d5975577c1d7db208979e6e083ceb6d0a4208	dynamic view-dependent simplification for polygonal models	data visualisation;continuous level-of-detail representation;displayed triangle list updating;frame-to-frame coherence;image-space coherence;incremental updating;lighting;object-space coherence;real-time dynamic view-dependent simplification;scientific visualization;triangle selection;triangulated polygonal model;viewing direction;visibility	Presents an algorithm for performing view-dependent simplifications of a triangulated polygonal model in real-time. The simplifications are dependent on viewing direction, lighting and visibility, and are performed by taking advantage of image-space, object-space and frame-to-frame coherences. A continuous level-of-detail representation for an object is first constructed off-line. This representation is then used at run-time to guide the selection of appropriate triangles for display. The list of displayed triangles is updated incrementally from one frame to the next. Our approach is more effective than the current level-of-detail-based rendering approaches for most scientific visualization applications where there are a limited number of highly complex objects that stay relatively close to the viewer.	algorithm;amazon mechanical turk;approximation;graph operations;heuristic (computer science);interactivity;level of detail;marc (archive);merge algorithm;merge sort;nico habermann;normal (geometry);online and offline;real-time locating system;run time (program lifecycle phase);scientific visualization;the turk;viewing cone	Julie C. Xia;Amitabh Varshney	1996	Proceedings of Seventh Annual IEEE Visualization '96		computer vision;scientific visualization;visibility;computer science;lighting;computer graphics (images)	Visualization	67.14308540988085	-49.567252348448754	74459
a8101325c9219731fc3b8b7933c3221062e3f34b	appearance based object modeling using texture database: acquisition compression and rendering	tensor product;indexation;object model	Image-based object modeling can be used to compose photorealistic images of modeled objects for various rendering conditions, such as viewpoint, light directions, etc. However, it is challenging to acquire the large number of object images required for all combinations of capturing parameters and to then handle the resulting huge data sets for the model. This paper presents a novel modeling method for acquiring and preserving appearances of objects. Using a specialized capturing platform, we first acquire objects’ geometrical information and their complete 4D indexed texture sets, or bi-directional texture functions (BTF) in a highly automated manner. Then we compress the acquired texture database using tensor product expansion. The compressed texture database facilitates rendering objects with arbitrary viewpoints, illumination, and deformation.	3d modeling;algorithm;bidirectional texture function;computer animation;data acquisition;database;illumination (image);mixed reality;singular value decomposition	Ryo Furukawa;Hiroshi Kawasaki;Katsushi Ikeuchi;Masao Sakauchi	2002		10.2312/EGWR/EGWR02/257-266	tensor product;computer vision;object model;computer science;multimedia;texture atlas;texture compression;computer graphics (images)	Vision	60.8514990369524	-50.36031085799905	74672
e3f1301ffe3527dce597f94c8074234ac635febd	real-time slicing of data space	real time rendering;volume rendering	"""Real time rendering of iso contour surfaces is problematic for large complex data sets. An algorithm is presented that allows very rapid representation of an interval set surrounding an iso contour surface. The algorithm draws upon three main ideas. A fast indexing scheme is used to select only those data points near the contour surface. Hardware assisted splatting is then employed on these data points to produce a volume rendering of the interval set. Finally, by shifting a small window through the indexing scheme or data space, animated volumes are produced showing the changing contour values. In addition to allowing fast selection and rendering of the data, the indexing scheme allows a much compressed representation of the data by eliminating """"noise"""" data points."""	algorithm;contour line;data point;dataspaces;real-time transcription;time slicing (digital broadcasting);volume rendering	Roger Crawfis	1996	Proceedings of Seventh Annual IEEE Visualization '96		anime;three-dimensional space;mesh generation;computer vision;scientific visualization;data processing;computer science;theoretical computer science;isosurface;geometry;computer graphics;interactivity;alpha shape;surface;volume rendering;volume;compression;complex data type;computer graphics (images)	Visualization	68.07359816287752	-50.84605420471312	74825
4d9cfaea3257b30a2c3ac8fbf5c7df385cfd6063	an efficient image-based virtual tour system	joint multiscene rendering image based virtual tour system relative depth calculation;virtual reality;rendering computer graphics layout solid modeling animation navigation image sampling memory floors cameras history;tour into the picture;null;rendering computer graphics computer animation virtual reality;computer animation;rendering computer graphics	Tour into the picture (TIP) is a technique that makes animation of a scene from single image. The size of TIP box model, as well as the positions of foreground objects in the model can be calculated by relative depth calculation. To simulate an incline in the image, an algorithm is proposed by us to calculate the slope and the length of an incline model. After that, we present an algorithm that successfully makes integration of TIP and panorama to perform joint multi-scene rendering in our virtual tour system. Our virtual tour system shows that these techniques have achieved very satisfactory results.	algorithm;autostereogram;simulation;virtual tour	Qiushuang Zhang;Kan Zhao;Zhiqing Cao;Jiaoying Shi	2004	Third International Conference on Image and Graphics (ICIG'04)	10.1109/ICIG.2004.34	computer vision;tiled rendering;simulation;image-based modeling and rendering;computer facial animation;3d rendering;rendering;computer science;parallel rendering;virtual reality;computer animation;real-time rendering;computer graphics;software rendering;3d computer graphics;computer graphics (images)	Visualization	64.15576669123652	-49.10421395602547	74944
90543ee2c4ae57d8d1fe84689bec5e86f8346b4b	protruded displacement mapping for image-based urban representation	displacement mapping;image based rendering;graphics library	This paper introduces a displacement mapping algorithm that represents protruded shapes on the surface of an object. Two verticalsurfaces that are perpendicular to the underlying surface are added along the boundary of the polygon surface in order to represent pixels overflowing acrossthe boundary of the polygon surface. The proposed approach can accurately represent the silhouettes of protruded shapes. Using per-pixel instructions on graphics hardware, the approach is accelerated and executed in real-time. The proposed method provides an effective solution for the representation of protruding shapes such as high-rise buildings in an urban environment which can be used in location based applications of mobile electronic devices.	algorithm;displacement mapping;graphics hardware;graphics processing unit;location-based service;pixel;polygon mesh;real-time clock;real-time computing	Byounghyun Yoo	2011	IEICE Electronic Express	10.1587/elex.8.1022	computer vision;image-based modeling and rendering;displacement mapping;computer science;geometry;computer graphics (images)	Graphics	66.13677118832918	-51.0251465638408	75181
0ba9b781099aa297961eb3156f43199bc0a6a800	simultaneous self-calibration of a projector and a camera using structured light	phase shifting sinusoidal code;gray code;calibration apparatus;checker pattern board;active vision system;geometry;fundamental matrix;structured light;phase shift;reflective binary codes;computer vision;cameras calibration lenses reflective binary codes equations matrix decomposition mathematical model;intrinsic parameter;geometric calibration;radial fundamental matrix simultaneous self calibration camera structured light geometric calibration active vision system projector camera system intrinsic parameter calibration apparatus checker pattern board radial fundamental matrix extrinsic parameters gray code phase shifting sinusoidal code;projector camera system;matrix decomposition;simultaneous self calibration;lenses;mathematical model;camera calibration;radial fundamental matrix;geometry calibration cameras computer vision;calibration;cameras;camera;extrinsic parameters;active vision	We propose a method for geometric calibration of an active vision system, composed of a projector and a camera, using structured light projection. Unlike existing methods of self-calibration for projector-camera systems, our method estimates the intrinsic parameters of both the projector and the camera as well as extrinsic parameters except a global scale without any calibration apparatus such as a checker-pattern board. Our method is based on the decomposition of a radial fundamental matrix into intrinsic and extrinsic parameters. Dense and accurate correspondences are obtained utilizing structured light patterns consisting of Gray code and phase-shifting sinusoidal code. To alleviate the sensitivity issue in estimating and decomposing the radial fundamental matrix, we propose an optimization approach that guarantees the possible solution using a prior for the principal points. We demonstrate the stability of our method using several examples and evaluate the system quantitatively and qualitatively.	active vision;camera resectioning;fundamental matrix (computer vision);mathematical optimization;radial (radio);structured light;structured-light 3d scanner;video projector	Shuntaro Yamazaki;Masaaki Mochimaru;Takeo Kanade	2011	CVPR 2011 WORKSHOPS	10.1109/CVPRW.2011.5981781	gray code;computer vision;calibration;camera resectioning;structured light;active vision;computer science;mathematical model;lens;mathematics;phase;fundamental matrix;matrix decomposition;computer graphics (images)	Vision	54.12207191857602	-50.08077433935783	75310
86116b975a6613e0cc5eb26bb5319a4295269a91	sorted pipeline image composition	categories and subject descriptors according to acm ccs i 3 2 computer graphics graphics systemsdistributed networked graphics;image compositing	The core advantage of sort last rendering is the theoretical nearly linear scalability in the number of rendering nodes, which makes it very attractive for very large polygonal and volumetric models. The disadvantage of sort last rendering is that a final image composition step is necessary in which a huge amount of data has to be transferred between the rendering nodes. Even with gigabit or faster networks the image composition introduces an overhead that makes it impractical to use sort last parallel rendering for interactive applications on large clusters. This paper describes the Sorted Pipeline Composition algorithm that reduces the amount of data that needs to be transferred by an order of magnitude and results in a frame rate that is at least twice as high as the widely used binary swap image composition algorithm.	algorithm;gigabit;overhead (computing);paging;parallel rendering;scalability;volume mesh	Marcus Roth;Dirk Reiners	2006		10.2312/EGPGV/EGPGV06/119-126	tiled rendering;parallel computing;image-based modeling and rendering;fragment processing;rendering;computer science;theoretical computer science;operating system;parallel rendering;multimedia;real-time rendering;texture memory;alternate frame rendering;software rendering;computer graphics (images)	Graphics	67.51806536443083	-51.68253462555406	75361
3cfe104759f9691c728029f9c73db7d2c71211a3	swift and stable polygon growth and broken line offset	modelizacion;concepcion asistida;computer aided design;fabricacion asistida por computador;modele geometrique;trimmed offsets;modelisation;fabrication assistee;cad cam;computer aided manufacturing;offset technique;conception assistee;algorithms;modeling;offset curve;geometrical model;courbe decalee;modelo geometrico	The problem of object growing (offsetting the object boundary by a certain distance) is an important and widely studied problem. In this paper we propose a new approach for offsetting the boundary of an object described by segments which are not necessarily connected. This approach avoids many destructive special cases that arise in some heuristic-based approaches. Moreover, the method developed in this paper is stable in that it does not fail because of missing segments. Also, the time required for the computation of the offset is relatively short and therefore inexpensive, i.e. it is expected to be O( n*log n). q 1998 Elsevier Science Ltd. All rights reserved	computation;heuristic;swift (programming language)	G. Kalmanovich;Gregory Nisnevich	1998	Computer-Aided Design	10.1016/S0010-4485(98)00041-4	simulation;systems modeling;engineering;computer aided design;engineering drawing;computer-aided technologies;computer-aided manufacturing;mechanical engineering	AI	67.34950460080128	-38.955127545156486	75436
88f32b0a952b53424122054ca01e3c9308cbe9c2	3d photography using shadows in dual-space geometry	3d modeling shape from shadows;3d photography;3d model;3d scanning;dual space;dual space geometry	A simple and inexpensive approach for extracting the three-dimensional shape of objects is presented. It is based on ‘weak structured lighting’. It requires very little hardware besides the camera: a light source (a desk-lamp or the sun), a stick and a checkerboard. The object, illuminated by the light source, is placed on a stage composed of a ground plane and a back plane; the camera faces the object. The user moves the stick in front of the light source, casting a moving shadow on the scene. The 3D shape of the object is extracted from the spatial and temporal location of the observed shadow. Experimental results are presented on five different scenes (indoor with a desk lamp and outdoor with the sun) demonstrating that the error in reconstructing the surface is less than 0.5% of the size of the object. A mathematical formalism is proposed that simplifies the notation and keep the algebra compact. A real-time implementation of the system is also presented.	backplane;real-time clock;real-time computing;semantics (computer science);stereoscopy	Jean-Yves Bouguet;Pietro Perona	1999	International Journal of Computer Vision	10.1023/A:1008124523456	computer vision;dual space;mathematics;computer graphics (images)	Vision	57.66542123009979	-50.03871632260619	75555
032bc01b7f6822a4e9375741dfc37417415382bd	control of scene reconstruction using explicit knowledge	automatic control;landscape model;knowledge based system;model driven control strategy;driving simulators;model generation;image understanding;landscape planning;layout;semantic networks;driving simulator;aerospace simulation;model driven control strategy scene reconstruction explicit knowledge landscape planning environmental monitoring driving simulators realistic landscape models model generation remote sensing data aida high realism a priori knowledge object specific constraints 3d reconstruction image interpretation explicit representation procedural knowledge problem independent formalism semantic nets;planing;scene reconstruction;digital terrain models;digital terrain model;explicit knowledge;fuzzy logic;image interpretation;high realism;a priori knowledge;semantic net;realistic landscape models;image edge detection;roads;remote sensing data;image reconstruction;remote sensing;layout remote monitoring image reconstruction image edge detection planing aerospace simulation roads fuzzy logic automatic control world wide web;semantic nets;explicit representation;cartography;world wide web;procedural knowledge;object specific constraints;remote monitoring;aida;problem independent formalism;semantic networks image reconstruction knowledge based systems cartography remote sensing;knowledge based systems;3d reconstruction;control strategy;environmental monitoring	Applications such as landscape planing, environmental monitoring, and flight and driving simulators have a high demand for realistic landscape models. Quantity, precision and the type of models ask for methods which automate the model generation by evaluation of remote sensing data. The presented modelling system AIDA tackles the demand for efficient representation and high realism by integrating a priori knowledge about the appearance of the objects in the scene to derive object specific constraints for 3D–reconstruction. This requires an image interpretation to assign a meaning to the objects in the scene. For explicit representation of the declarative and procedural knowledge a problem–independent formalism based on semantic nets and rules is used. It provides both a data–driven and model–driven control strategy.	care-of address;cartography;control theory;driving simulator;exploit (computer security);geographic information system;image resolution;knowledge base;knowledge representation and reasoning;planning;semantic network;semantics (computer science);simulation;topography	Ralf R Tönjes	1996		10.1109/ACV.1996.571988	3d reconstruction;iterative reconstruction;fuzzy logic;planning;layout;landscape planning;computer vision;a priori and a posteriori;simulation;digital elevation model;computer science;explicit knowledge;knowledge-based systems;machine learning;data mining;procedural knowledge;semantic network;rmon	AI	58.37922166116309	-45.25891648603711	75577
71c7e4cf40d7be611e11e799a30aa36daf730b7d	real-time multi-view 3d reconstruction for interventional environments		This thesis addresses the topic of real-time multi-view 3D reconstruction in interventional environments. Due to the special working conditions in interventional rooms this is a very challenging topic. However, the ability to recover the 3D structure of a dynamic scene in real-time is essential for many novel and innovative interventional applications. In this thesis we take a step towards this goal by presenting the design of a multi-view reconstruction system taking into consideration the conditions typically encountered in interventional environments. Two installations of the system were created: One in a laboratory environment and one in a real interventional room. While the laboratory system was used for development and evaluation purposes, the hospital system was used to learn about the conditions which have to be taken into account in a clinical setting. These conditions which typically include a cluttered environment with complex lighting and occlusions are discussed in detail and recommendations are given for dealing with them. Based on the proposed system several applications were developed to demonstrate the benefits of real-time 3D reconstruction in interventional environments. In a first application the real-time reconstruction is used to ensure the safe operation of automated medical devices such as C-arms by detecting potential collisions between the device and its environment (staff, patient, utilities) in advance. A second application is aimed at estimating the physician’s radiation exposure by tracking his reconstruction and accumulating the radiation received by each body part over time. The promising experimental results obtained using these applications show the possible impact of our work for the medical community and illustrate the clinical value of multi-camera systems in the development of intelligent, integrated interventional suites. This is underlined by the fact that the proposed system has already been used by other researches for recovering the workflow of surgical procedures [PMW+09]. During the course of this thesis the topic of reconstruction and organization of large image collections was also investigated. This research area is gaining importance since it has become easy and affordable to acquire large image collections due to the proliferation of digital cameras. However, the huge amount of images available poses new challenges for existing algorithms. The focus of this part of the thesis therefore lies on the efficient use of large image collections. Three related problems are investigated, namely obtaining high quality reconstructions using graph-cut methods, increasing the reconstruction efficiency by clustering image collections and building a unified framework for various applications related to image organization, such as image-based navigation, image set reduction and scene summarization.	3d reconstruction;algorithm;cluster analysis;coat of arms;cut (graph theory);digital camera;display resolution;real-time clock;real-time computing;real-time transcription;sensor;unified framework	Stawros Ladikos	2011			systems engineering;3d reconstruction;simulation;radiation;engineering	Vision	55.38989399741413	-45.82676932899749	75632
081cb7a1b93370861974af457cb21c5170de86d4	heading alignment with summarized inertial pose constraints	auv north alignment inertial pose constraints inertial navigation systems gps solutions global positioning system gyrocompassing alignment incremental smoothing probabilistic model pose graph formulation inertial sensor calibration autonomous underwater vehicles;probability autonomous underwater vehicles calibration compasses global positioning system graph theory gyroscopes inertial navigation;presentation;sensors earth optimization smoothing methods rotation measurement gravity global positioning system	A discontinuity seems to exist in present aided inertial navigation systems - the operational availability of high cost inertial navigation currently depends on the availability of a valid GPS lock. In general GPS solutions can be two or more orders cheaper than their inertial sensors counterparts. This paper addresses the north alignment by gyrocompassing in the context of more modern smoothing techniques. Incremental smoothing is becoming a serious contender for in-situ state estimation. The work here presents a probabilistic model for north alignment with an analysis towards the achievable accuracy of such a system. A pose graph formulation is used to estimate inertial sensor calibration terms over a long spanning trajectory, from which a true north alignment can be extracted. The preintegral method is used to condense high rate inertial data, but allow for post integration bias correction. Results show that the proposed alignment scheme is feasible, and would for gyrocompassing alignment relaxed sensor performance constraints.	acoustic cryptanalysis;computation;course (navigation);data structure alignment;extended kalman filter;file spanning;global positioning system;incremental backup;inertial navigation system;operational availability;reflections of signals on conducting lines;robot;sensor;smoothing;statistical model;true north;underwater robotics	Dehann Fourie;Kenny Uren;George van Schoor	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907254	inertial measurement unit;computer vision;inertial reference unit;simulation;geodesy;inertial navigation system	Robotics	55.67067464033514	-38.05025385033185	75774
23cfbf9b7ea7874d79ac270ff79fde7e10296c04	reconstruction of interior walls from point cloud data with min-hashed j-linkage		"""The automatic reconstruction of the walls of an interior environment is a fundamental task in any """"scan2BIM"""" application. In this work, we address this problem resorting to an original and improved version of J-Linkage that leverages on the min-Hash technique to boost the efficiency without sacrificing the accuracy. A framework to automatically and robustly extract floor plans from large-scale point clouds is described and validated on real-word publicly available data."""	cluster analysis;clutter;curve fitting;linkage (software);maxima and minima;multistage interconnection networks;parameter (computer programming);point cloud;stepping level;video post-processing	Luca Magri;Andrea Fusiello	2018	2018 International Conference on 3D Vision (3DV)	10.1109/3DV.2018.00025	task analysis;point cloud;theoretical computer science;cluster analysis;solid modeling;data modeling;computer science	Visualization	57.611535766646604	-46.25526630380957	75817
6844a700aee36bd809d1188f6f9e81707c513f19	interactive model-based reconstruction of the human head using an rgb-d sensor	virtual avatars;nonlinear optimisation;gpgpu;3d scanning;statistical head models;model based face reconstruction	We present a novel method for the interactive markerless reconstruction of human heads using a single commodity RGB-D sensor. Our entire reconstruction pipeline is implemented on the GPU and allows to obtain high-quality reconstructions of the human head using an interactive and intuitive reconstruction paradigm. The core of our method is a fast GPU-based non-linear Quasi-Newton solver that allows us to leverage all information of the RGB-D stream and fit a statistical head model to the observations at interactive frame rates. By jointly solving for shape, albedo and illumination parameters, we are able to reconstruct highquality models including illumination corrected textures. All obtained reconstructions have a common topology and can be directly used as assets for games, films and various virtual reality applications. We show motion retargeting, retexturing and relighting examples. The accuracy of the presented algorithm is evaluated by a comparison against ground truth data.	algorithm;computer science;graphics processing unit;ground truth;interactivity;mathematical optimization;newton;nonlinear system;numerical linear algebra;online and offline;optimization problem;programming paradigm;quasi-newton method;retargeting;sensor;solver;structured light;virtual reality	Michael Zollhöfer;Justus Thies;Matteo Colaianni;Marc Stamminger;Günther Greiner	2014	Journal of Visualization and Computer Animation	10.1002/cav.1584	computer vision;simulation;computer science;artificial intelligence;general-purpose computing on graphics processing units;computer graphics (images)	Graphics	59.7235845814365	-49.2649550431504	75989
04a220575e62d548e37c628d049eb98848fc7610	compact tracking of surgical instruments through structured markers		Virtual and augmented reality surgery calls for reliable and efficient tracking of the surgical instruments in the virtual or real operating theatre. The most diffused approach uses three or more not aligned markers, attached to each instrument and surveyed by a set of cameras. However, the structure required to carry the markers does modify the instrument’s mass distribution and can interfere with surgeon movements. To overcome these problems, we propose here a new methodology, based on structured markers, to compute the six degrees of freedom of a surgical instrument. Two markers are attached on the instrument axis and one of them has a stripe painted over its surface. We also introduce a procedure to compute with high accuracy the markers center on the cameras image, even when partially occluded by the instrument’s axis or by other structures. Experimental results demonstrate the reliability and accuracy of the proposed approach. The introduction of structured passive markers can open new possibilities to accurate tracking, combining markers detection with real-time image processing.	alignment;apache axis;augmented reality;axis vertebra;diffusion;image processing;instrument - device;movement;operating room;optic axis of a crystal;real-time locating system;six degrees of separation;stripes;surgical instruments	N. Alberto Borghese;Iuri Frosio	2013	Medical & Biological Engineering & Computing	10.1007/s11517-013-1052-7	computer vision;simulation;engineering;biological engineering	Vision	59.02452712095524	-47.08725572583185	76107
f93648bfbd2af01ed93497025fb26bd158137b5f	error-free boundary evaluation based on a lazy rational arithmetic: a detailed implementation	modelizacion;problema valor limite;solid;solide;solido;free boundary;implementation;boundary value problem;evaluation method;operateur booleen;boolean operator;interseccion;arithmetique;algorithme;modelisation;algorithm;ejecucion;boolean operation;aritmetica;arithmetics;nonmanifold polyhedra;solid modeling;numerical errors;intersection;modeling;probleme valeur limite;data structure;solid modelling;algoritmo;operador de boole	A new boundary evaluation method is presented. It is based on error-free Boolean operations on polyhedral solids. W e describe, in detail, an intersection algorithm that handles , in a straightforward way , all the possible geometric cases. We also describe a general data structure that allows an unified storage of solid boundaries. The intersection algorithm always runs to completion, producing consistent solids from consistent operands. Numerical errors are handled at an algorithm independent level: an original exact arithmetic that performs only the necessary precise computations. Results from our implementation of this CSG solver are discussed.	apache axis;application domain;arithmetic logic unit;boo;cmucl;calculus of constructions;computation;computer graphics;computer science;constructive solid geometry;cubic function;data structure;delaunay triangulation;emoticon;engineering design process;euler;george sugihara;ibm research;ieee transactions on computers;intersection algorithm;lazy evaluation;linear algebra;memorandum;numerical analysis;operand;p (complexity);polyhedral;polyhedron;simulation;solid modeling;solver;springer (tank);symposium on computational geometry;winged edge;wire-frame model	Mohand Ourabah Benouamer;Dominique Michelucci;Bernard Péroche	1994	Computer-Aided Design	10.1016/0010-4485(94)90063-9	discrete mathematics;systems modeling;data structure;boundary value problem;computer science;engineering;intersection;mathematics;geometry;solid modeling;solid;implementation;algorithm	Graphics	67.52513046372478	-39.88358901758114	76334
c9d78e840a9b50849af4d4537ce68dbe86e7968d	generating high-resolution textures for 3d virtual environments using view-independent texture mapping	texture map resolution;3d virtual environment;virtual reality image texture ray tracing rendering computer graphics;image based modeling and rendering;high resolution;texture mapping;virtual reality;image information;3d virtual environments;image based modeling;image texture;lambertian reflectance properties;3d model;games;ray tracing;ray tracing high resolution textures 3d virtual environments view independent texture mapping image based modeling rendering games virtual reality 3d models texture map resolution image information lambertian reflectance properties;rendering computer graphics;3d models;virtual environment rendering computer graphics visualization runtime virtual reality image resolution surface texture reflectivity ray tracing cameras;rendering;high resolution textures;view independent texture mapping	Image based modeling and rendering techniques have become increasingly popular for creating and visualizing 3D models from a set of images. Typically, these techniques depend on view-dependent texture mapping to render the textured 3D models in which the texture of novel views is synthesized at runtime according to different view-points. This is computationally expensive and limits their application in domains where efficient computations are required, such as games and virtual reality. In this paper we present an offline technique for creating view-independent texture atlases for 3D models, given a set of registered images. The best texture map resolution is computed by considering the areas of the projected polygons in the images. Texture maps are generated by a weighted composition of all available image information in the scene.Assuming that all surfaces of the model are exhibiting Lambertian reflectance properties, ray-tracing is then employed, for creating the view-independent texture maps. Finally, all the generated texture maps are packed into texture atlases. The result is a 3D model with an associated view-independent texture atlas which can be used efficiently in any application without any knowledge of camera pose information.	3d modeling;analysis of algorithms;computation;lambertian reflectance;map;online and offline;ray tracing (graphics);rendering (computer graphics);run time (program lifecycle phase);texture atlas;texture mapping;virtual reality	Charalambos Poullis;Suya You;Ulrich Neumann	2007	2007 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2007.4284895	bidirectional texture function;image texture;texture mapping;games;ray tracing;computer vision;image-based modeling and rendering;image resolution;displacement mapping;rendering;computer science;uvw mapping;virtual reality;multimedia;texel;texture atlas;texture compression;texture filtering;projective texture mapping;computer graphics (images)	Visualization	65.0166672021111	-49.425562160297105	76627
be6134e94c57da0f6a27ae9f17a6934e1009227a	improving the translation parameter estimation of linear algorithms	parameter estimation	Abstract   An improved algorithm for finding the translation parameters of the motion of rigid objects is presented. A critical analysis of the method of  Tsai and Huang [ IEEE Trans.  PAMI-6, 1984 , 13–26] to estimate the three-dimensional motion parameters of rigid objects showed that their method is extremely sensitive to noise, as conceded by the authors themselves. It was discovered that, in the presence of noise, the estimates for the rotation parameters were more accurate and consistent than those for the translation parameters. A modified program here combines the estimates for the less noise-sensitive rotation parameters with the basic motion equations in order to solve for the translation parameters. Simulations of the two methods were performed and it was observed that the modified algorithm improved the estimates for the translation parameters. In addition, a simple algorithm for the case where the motion is a pure translation is derived. Simulations again revealed that this simple algorithm is far less noise-sensitive than that of Tsai and Huang.	algorithm;estimation theory	Sassan Pejhan;S. Ragupathi;Robert A. King	1991	J. Visual Communication and Image Representation	10.1016/1047-3203(91)90036-F	mathematical optimization;speech recognition;computer science;estimation theory;statistics	Vision	55.85261690404227	-41.378367557639415	76637
0e09033f6636217d34fc0222de46a87c108e1c06	a theory of shape by space carving	shape from silhouette;3d photography;shape from silhouettes;photorealistic reconstruction;shape representation;voxel coloring;volumetric shape representations;visual hull;metameric shapes;multi view stereo;space carving;scene modeling	In this paper we consider the problem of computing the 3D shape of an unknown, arbitrarily-shaped scene from multiple photographs taken at known but arbitrarily-distributed viewpoints. By studying the equivalence class of all 3D shapes that reproduce the input photographs, we prove the existence of a special member of this class, the photo hull, that (1) can be computed directly from photographs of the scene, and (2) subsumes all other members of this class. We then give a provably-correct algorithm, called Space Carving, for computing this shape and present experimental results on complex real-world scenes. The approach is designed to (1) capture photorealistic shapes that accurately model scene appearance from a wide range of viewpoints, and (2) account for the complex interactions between occlusion, parallax, shading, and their view-dependent effects on scene-appearance.	algorithm;correctness (computer science);interaction;parallax;shading;turing completeness	Kiriakos N. Kutulakos;Steven M. Seitz	1999	International Journal of Computer Vision	10.1023/A:1008191222954	computer vision;shape analysis;mathematics;geometry;computer graphics (images)	Vision	57.54506876557921	-51.187528373996706	76855
2e116e3ee51f3a0585110b64dd900e3e0c96a1cb	extraction and simplification of building façade pieces from mobile laser scanner point clouds for 3d street view services	building facade;morphology;feature extraction;projection image;point cloud;mobile laser scanner mls	Extraction and analysis of building façades are key processes in the three-dimensional (3D) building reconstruction and realistic geometrical modeling of the urban environment, which includes many applications, such as smart city management, autonomous navigation through the urban environment, fly-through rendering, 3D street view, virtual tourism, urban mission planning, etc. This paper proposes a building facade pieces extraction and simplification algorithm based on morphological filtering with point clouds obtained by a mobile laser scanner (MLS). First, this study presents a point cloud projection algorithm with high-accuracy orientation parameters from the position and orientation system (POS) of MLS that can convert large volumes of point cloud data to a raster image. Second, this study proposes a feature extraction approach based on morphological filtering with point cloud projection that can obtain building facade features in an image space. Third, this study designs an inverse transformation of point cloud projection to convert building facade features from an image space to a 3D space. A building facade feature with restricted facade plane detection algorithm is implemented to reconstruct façade pieces for street view service. The results of building facade extraction experiments with large volumes of point cloud from MLS show that the proposed approach is suitable for various types of building facade extraction. The geometric accuracy of building façades is 0.66 m in x direction, 0.64 in y direction and 0.55 m in the vertical direction, which is the same level as the space resolution (0.5 m) of the point cloud.	3d computer graphics;3d projection;algorithm;automation;autonomous robot;computation;experiment;feature (computer vision);feature extraction;google street view;internet;level of detail;map projection;mathematical morphology;point cloud;raster graphics;smart city;text simplification;texture filtering;virtual tour	Yan Li;Qingwu Hu;Meng Da Wu;Jianming Liu;Xuan Wu	2016	ISPRS Int. J. Geo-Information	10.3390/ijgi5120231	computer vision;geography;engineering drawing;computer graphics (images)	Robotics	56.242509379495154	-45.511002149893756	76961
67c3212af1b34deea88e941dc311aedbcbb5672d	rendering synthetic objects in natural scenes	inner product;image based modeling;brdf rendering synthetic object natural scenes light integral problem global illumination integral 2d chebyshev polynomial irradiance representation bidirectional reflectance distribution function;chebyshev polynomial;global illumination;layout chebyshev approximation lighting rendering computer graphics polynomials data structures grid computing image storage interpolation integral equations;rendering computer graphics chebyshev approximation image representation natural scenes polynomial approximation;synthetic natural hybrid rendering image based modeling image based rendering;image representation;image based rendering;chebyshev approximation;rendering computer graphics;synthetic natural hybrid rendering;natural scenes;polynomial approximation	We present a method for solving the light integral problem for synthetic diffuse objects rendered within a natural scene. The approach generates realistic shading using only a few images of the surroundings of the object to represent the ambient light. We model the global illumination integral using Chebyshev polynomials. We show that due to the orthogonality of 2D Chebyshev moments, the global illumination integral can reduce to the inner product of two vectors, representing the irradiance and the bidirectional reflectance distribution function (BRDF). The Chebyshev moments of these two functions are computed off-line and stored in the memory. The rendering of the object in the scene then becomes a simple problem of computing the inner product of the two vectors for each point.	bidirectional reflectance distribution function;chebyshev polynomials;global illumination;online and offline;polynomial;shading;synthetic intelligence	Mais Alnasser;Hassan Foroosh	2006	2006 International Conference on Image Processing	10.1109/ICIP.2006.312434	chebyshev polynomials;computer vision;image-based modeling and rendering;3d rendering;dot product;rendering;rendering equation;mathematics;geometry;photon mapping;global illumination;image-based lighting;approximation theory;computer graphics (images)	Vision	64.64240140780133	-50.28593331956232	77072
5e0afb8fa50402385c724cd9bb975d73aac3eb40	approximate image-based tree-modeling using particle flows	journal_article;image based modeling;plant models;first order;flow simulation;botanics;image based modeling plant models botanics	We present a method for producing 3D tree models from input photographs with only limited user intervention. An approximate voxel-based tree volume is estimated using image information. The density values of the voxels are used to produce initial positions for a set of particles. Performing a 3D flow simulation, the particles are traced downwards to the tree basis and are combined to form twigs and branches. If possible, the trunk and the first-order branches are determined in the input photographs and are used as attractors for particle simulation. The geometry of the tree skeleton is produced using botanical rules for branch thicknesses and branching angles. Finally, leaves are added. Different initial seeds for particle simulation lead to a variety, yet similar-looking branching structures for a single set of photographs.		Boris Neubert;Thomas Franken;Oliver Deussen	2007	ACM Trans. Graph.	10.1145/1276377.1276487	mathematical optimization;simulation;computer science;first-order logic;mathematics;geometry;programming language;computer graphics (images)	Graphics	68.18941815346689	-47.779394606554064	77302
a9bba016eead81a80ae0295f26287aa8dfd17ac8	3d gis integrated model simulation algorithm based on block model	3d spatial entity representation;octree;3d gis integrated model simulation algorithm;delaunay triangulation;geographic information system;generic algorithm;spatial data;integrable model;3d gis;biological system modeling;computational geometry;bot generation algorithm;geological block model;opengl visualization technology;opengl visualization technology 3d gis integrated model simulation algorithm block model 3d gis spatial data management 3d spatial entity representation block octree tetrahedron model bot data structure geological block model bot generation algorithm shape description linear bot coding technology geographic information system;simulation experiment;data visualisation;computational modeling;computational complexity;geographic information systems;three dimensional displays;data structures;geographic information systems geology space technology data structures data models solids computational modeling computer network management technology management shape;ten;solid modeling;bot model block model octree ten delaunay triangulation;bot data structure;shape description;linear bot coding technology;block octree tetrahedron model;data structure;block model;solid modelling computational geometry data visualisation geographic information systems octrees;bot model;octrees;3d gis spatial data management;solid modelling;data models	In order to organize and manage 3D GIS spatial data effectively, and represent 3D spatial entity integrally, a hybrid data structure model called BOT model (block octree tetrahedron model) is presented on basis of geological block model, which combines octree and tetrahedral network (TEN) structures. Using BOT generation algorithm, the block model is redivided with octree as general shape description and TEN as partial precise description, in which different gradation of grey are used to stand for different attributes of unit blocks. To reduce the memory space a linear BOT coding technology is proposed as well. The results of simulation experiments made with empirical data demonstrate that the BOT model holds merits of both octree and TEN and can represent 3D objects more effectively and precisely. Moreover, the algorithm simplifies modeling process and to a certain extent, reduces computing complexity for visualization.	algorithm;dspace;data structure;experiment;geographic information system;octree;simulation	Jiange Tao	2008	2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application	10.1109/PACIIA.2008.145	data modeling;simulation;genetic algorithm;delaunay triangulation;data structure;computer science;theoretical computer science;spatial analysis;solid modeling;computational complexity theory;computational model;octree;computer graphics (images)	AI	64.70395785753588	-43.27321340649886	77346
d7da355c4aab8ecc5582088541399f0d47e3a7df	design and evaluation of reduced marker layouts for hand motion capture		We present a method for automatically generating reduced marker layouts for marker-based optical motion capture of human hands. The employed motion reconstruction method is based on subspaceconstrained inverse kinematics, which allows for the recovery of realistic hand movements even from sparse input data. We additionally present a user-specific hand model calibration procedure that fits an articulated hand model to point cloud data of the user’s hand. Our marker layout optimization is sensitive to the kinematic structure and the subspace representations of hand articulations utilized in the reconstruction method, in order to generate sparse marker configurations that are optimal for solving the constrained inverse kinematics problem. We propose specific quality criteria for reduced marker sets that combine numerical stability with geometric feasibility of the resulting layout. These criteria are combined in an objective function that is minimized using a specialized surfaceconstrained particle swarm optimization scheme, which generates marker layouts bound to the surface of an animated hand model. Our method provides a principled way for determining reduced marker layouts based on subspace representations of hand articulations. We demonstrate the effectiveness of our motion reconstruction and model calibration methods in a thorough evaluation.	calibration;fits;inverse kinematics;joints;loss function;mathematical optimization;motion capture;movement;numerical stability;optimization problem;particle swarm optimization;point cloud;sparse matrix	Matthias Schröder;Thomas Waltemate;Jonathan Maycock;Tobias Röhlig;Helge Ritter;Mario Botsch	2018	Journal of Visualization and Computer Animation	10.1002/cav.1751	simulation;computer vision;point cloud;artificial intelligence;computer animation;geometric modeling;inverse kinematics;computer science;kinematics;numerical stability;subspace topology;particle swarm optimization	Vision	59.98410310785929	-44.860027658917716	77552
fe7a0485bb7098b2c754699ca9cdc6524d5fe628	face photo sketch synthesis via larger patch and multiresolution spline		Face photo sketch synthesis has got some researchers' attention in recent years because of its potential applications in digital entertainment and law enforcement. Some patches based methods have been proposed to solve this problem. These methods usually focus more on how to get a sketch patch for a given photo patch than how to blend these generated patches. However, without appropriately blending method, some jagged parts and mottled points will appear in the entire face sketch. In order to get a smoother sketch, we propose a new method to reduce such jagged parts and mottled points. In our system, we resort to an existed method, which is Markov Random Fields (MRF), to train a crude face sketch firstly. Then this crude sketch face sketch will be divided into some larger patches again and retrained by Non-Negative Matrix Factorization (NMF). At last, we use Multiresolution Spline and a blend trick named full-coverage trick to blend these retrained patches. The experiment results show that compared with some previous method, we can get a smoother face sketch.	alpha compositing;markov chain;markov random field;non-negative matrix factorization;norm (social);patch (computing);sketch;spline (mathematics)	Xu Yang	2015	CoRR		computer vision;computer graphics (images)	AI	61.90030355524307	-46.603581582854126	77687
ea06a73bf8bb3fda089066d0437998caee5ddbbb	3d shape recovery from real images using a symmetry prior				Vijai Jayadevan;Aaron Michaux;Edward J. Delp;Zygmunt Pizlo	2017		10.2352/ISSN.2470-1173.2017.17.COIMG-452	computer vision;real image;mathematics;artificial intelligence	Vision	55.94546417234788	-51.66860189747904	77693
9f9c454165f40a99bfe3e135e54d1b6439e2a46f	tools to perform local dense 3d reconstruction of shallow water seabed ‡	dense point clouds;low cost underwater micro robot;stereoscopic rig;underwater 3d reconstruction	Tasks such as distinguishing or identifying individual objects of interest require the production of dense local clouds at the scale of these individual objects of interest. Due to the physical and dynamic properties of an underwater environment, the usual dense matching algorithms must be rethought in order to be adaptive. These properties also imply that the scene must be observed at close range. Classic robotized acquisition systems are oversized for local studies in shallow water while the systematic acquisition of data is not guaranteed with divers. We address these two major issues through a multidisciplinary approach. To efficiently acquire on-demand stereoscopic pairs using simple logistics in small areas of shallow water, we devised an agile light-weight dedicated system which is easy to reproduce. To densely match two views in a reliable way, we devised a reconstruction algorithm that automatically accounts for the dynamics, variability and light absorption of the underwater environment. Field experiments in the Mediterranean Sea were used to assess the results.	3d reconstruction;agile software development;algorithm;anaglyph 3d;calibration;camera resectioning;coherence (physics);experiment;image processing;logistics;matching;microbotics;movement;physical object;software propagation;solutions;spatial variability;stereoscopy;thresholding (image processing);light absorption	Loïca Avanthey;Laurent Beaudoin;Antoine Gademer;Michel Roux	2016		10.3390/s16050712	computer vision;simulation;optics;remote sensing	Vision	54.471559608777696	-44.72524271675653	77802
7f382a7d6000fd229a18ba1cc2349803bff6c420	a vision-based intelligent system for packing 2-d irregular shapes	vision system;bin packing problem;chevauchement;construction navale;wood;machining;mathematical morphology;vision ordenador;two dimensional shape;inelasticite;bin packing;forme bidimensionnelle;systeme intelligent;tole;systeme vision;euro special interest group;turning;application software;defecto;intelligent systems shape computer vision surface morphology artificial intelligence two dimensional displays application software manufacturing industries textiles plastics;benchmark problem;sistema inteligente;layout problem;solution similitude;packing;irregularly shaped sheets;probleme agencement;inelasticidad;problema relleno;textil;two dimensional displays;similarity solution;intelligence artificielle;robotics;chapa;sistema complejo;shape measurement;manufacturing industries;cutting stock problem;overlap;imbricacion;two dimensional irregular packing problem;construccion naval;plastics;surface morphology;computer vision;forma bidimensional;artificial intelligent;nesting;bois;rectangular sheet packing;temps calcul;inelasticity;usinage;two dimensional irregular packing problem mathematical morphology nesting shape similarity turning function;vision based intelligent system robotic applications rectangular sheet packing euro special interest group irregularly shaped sheets artificial intelligence industrial applications 2d irregular shape packing;tournage;solucion semejanza;shape;systeme complexe;probleme decoupe;complex system;shape similarity;torneado;defect;robotic applications;turning function;intelligent systems;intelligent system;material plastico;defaut;2d irregular shape packing;robotica;problema disposicion;industrial application;probleme remplissage;artificial intelligence;vision based intelligent system;vision ordinateur;problema troquelado;vision artificielle;robotique;inteligencia artificial;industrial applications;textile;tiempo computacion;mecanizado;shipbuilding;aire superficielle;computation time;textiles;artificial vision;area superficial;vision;madera	Packing two-dimensional shapes on a surface such that no shapes overlap and the uncovered surface area is minimized is an important problem that arises in a variety of industrial applications. This paper introduces an intelligent system which tackles the most difficult instance of this problem, where two-dimensional irregular shapes have to be packed on a regularly or irregularly shaped surface. The proposed system utilizes techniques not previously applied to packing, drawn from computer vision and artificial intelligence, and achieves high-quality solutions with short computational times. In addition, the system deals with complex shapes and constraints that occur in industrial applications, such as defective regions and irregularly shaped sheets. We evaluate the effectiveness and efficiency of the proposed method using 14 established benchmark problems that are available from the EURO Special Interest Group on Cutting and Packing.	algorithm;artificial intelligence;benchmark (computing);binary image;computation;computer vision;set packing	Alexandros Bouganis;Murray Shanahan	2007	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2006.887158	bin packing problem;simulation;computer science;engineering;artificial intelligence;robotics;engineering drawing;algorithm;textile;mechanical engineering	Robotics	65.14169267664738	-38.61875748821354	77887
c3ca0e9a664de622de308c601d143b67753e3f38	recovering normal vectors and albedo under uncontrolled illumination with an rgb digital camera			digital camera;uncontrolled format string	Clara Plata;Juan Luis Nieves;Eva M. Valero;Javier Hernández-Andrés;Javier Romero	2010			digital camera;albedo;rgb color model;computer vision;artificial intelligence;computer science	Vision	56.63078142452807	-51.58500844584694	77949
0969945ea9df2cd9d49e57d6014dd44946f30f12	a framework for modeling, animating, and morphing textured implicit models	implicit surface;animacion por computador;interpolation;modele geometrique;computer graphics;texture metamorphosis;texture image;interpolacion;representation geometrique;shape metamorphosis;metamorfosis;implicit theory;metamorphosis;image texture;modelisation surface implicite;implicit surface modeling;animation;teoria implicita;theorie implicite;computer animation;grafico computadora;infographie;metamorphose;geometrical model;animation par ordinateur;modelo geometrico	This paper presents a framework for modeling, animating and morphing textured implicit models. Our hierarchical skeletal implicit surface model incorporates key-frame animation and procedural solid texturing in a unified and coherent way. Our system enables the designer to create complex special effects by synchronizing shape, animation and texture transformations.	coherence (physics);computation;generic programming;implicit surface;morphing;pentium 4;ray tracing (graphics);time complexity	Aurélien Barbier;Eric Galin;Samir Akkouche	2005	Graphical Models	10.1016/j.gmod.2004.06.006	computer vision;simulation;interpolation;computer science;metamorphosis;statistics;computer graphics (images)	Graphics	65.96795396408127	-42.63291102185769	78181
79195bf7c8adf78cda5aed9fda17ed1bff6ec0c5	research on key technique of weed locating based on binocular vision system	detectors;weed recognition system;image distortion;radial distortion;sub pixel binocular vision camera calibration image rectification;sub pixel;satisfiability;computer vision;rectified image;nonlinear distortion;image rectification;binocular vision;machine vision;feature extraction;machine vision cameras nonlinear distortion calibration lenses polynomials optical distortion spraying feature extraction approximation algorithms;agriculture;camera calibration;calibration;cameras;image rectification binocular vision system weed recognition system feature extraction image distortion camera calibration rectified image;feature extraction agriculture calibration cameras computer vision;binocular vision system	There are two aspects for locating precision of weed recognition system based on binocular vision. One is extraction of the feature points, and the other is distortion of camera lens used for image collecting. Some improvement has been made for these problems in this paper. Improving Harris operator makes the precision of feature point reach sub-pixel and rectifies image-distortion before calibrating the camera. Firstly, the one order radial distortion parameter is computed by the cross ratio invariability, and then collected image is rectified by the distortion parameter, finally, the camera is calibrated on the basis of the rectified image. The simulation results show that there is a light noise effect on the improved Harris operator, and the approach has a higher accuracy which can satisfy the need of locating precision of weed recognition system.	algorithm;binocular vision;camera resectioning;coefficient;corner detection;distortion;feature extraction;harris affine region detector;image rectification;mathematical optimization;nonlinear programming;nonlinear system;pixel;radial (radio);simulation	Wei-xing Zhu;Li-bing Xia;Feng Xiong	2008	2008 International Symposium on Computer Science and Computational Technology	10.1109/ISCSCT.2008.221	computer vision;geography;optics;computer graphics (images)	Vision	54.44139740055939	-48.473032480554366	78252
7dee7eaee30a7881dcc355eb3ad83f0db545fd0d	surface coding based on morse theory	concepcion asistida;topology;hierarchical structure;computer aided design;contours surface coding morse theory calculus of variations 3 d surfaces cross sections surface reconstruction coding system hierarchical structure;computer graphics;corte transverso;espacio 3 dimensiones;coupe transversale;surface reconstruction;reconstruction surface;codificacion;surface reconstruction shape solids ear topology image reconstruction sequences manufacturing biomedical imaging irrigation;theorie morse;espace 3 dimensions;three dimensional space;coding;conception assistee;superficie;calculus of variation;surface;cross section;reconstruccion superficie;topology computer graphics encoding;morse theory;encoding;grafico computadora;infographie;codage	Coding system requirements are briefly discussed. Classical Morse theory, which was primarily motivated by the calculus of variations, is reviewed. The limits of the theory are examined, and an extension that enables 3-D surfaces to be accurately reconstructed from cross sections is presented. The resulting coding works interactively with a range of surface reconstruction systems. The prototype coding system is applied to representing the hierarchical structure of contours.<<ETX>>	calculus of variations;cross section (geometry);interactivity;prototype;requirement;system requirements	Yoshihisa Shinagawa;Tosiyasu L. Kunii;Yannick L. Kergosien	1991	IEEE Computer Graphics and Applications	10.1109/38.90568	three-dimensional space;topology;surface reconstruction;computer aided design;mathematics;cross section;geometry;coding;computer graphics;surface;morse theory;encoding;calculus of variations	Graphics	66.22146292021742	-41.82517137498579	78328
ac20bfb38f5f52294817b854c36477177a480d80	euclidean paths: a new representation of boundary of discrete regions	algorithm performance;image processing;geometrie algorithmique;edge detection;extraction forme;computational geometry;procesamiento imagen;segmentation;traitement image;deteccion contorno;algorithme;image synthesis;algorithm;detection contour;extraccion forma;resultado algoritmo;performance algorithme;image analysis;geometria computacional;pattern extraction;segmentacion;algoritmo	The aim of this work is to provide a means to approximate the real boundary underlying the discrete boundary of a digitized 2D region. We require that the sampling of the reconstructed boundary be exactly the discrete one. To this end, we propose a new representation of the boundary of a discrete region that we call Euclidean paths. This paper fully describes the method used to build a Euclidean path and gives several examples of applications both for image analysis and image synthesis. c © 1999 Academic Press	2d computer graphics;aliasing;anti-aliasing;approximation algorithm;compositing;computation;cubic function;image analysis;image segmentation;pixel;regular grid;rendering (computer graphics);rewriting;sampling (signal processing);vertex (graph theory);voxel	Achille J.-P. Braquelaire;Anne Vialard	1999	Graphical Models and Image Processing	10.1006/gmip.1999.0488	computer vision;image analysis;edge detection;topology;image processing;computational geometry;computer science;euclidean distance;mathematics;geometry;euclidean distance matrix;segmentation;algorithm;digital geometry	Graphics	66.3558446121544	-41.0963542000702	78413
cd1fca23b0f17b122eaafdb793f9d1b5b08c43ba	an automatic system for identification of human faces using fiber grating vision sensor				Kenji Terada;Jun-Ichi Yamaguchi;Masato Nakajima	1993	JRM	10.20965/jrm.1993.p0106	artificial neural network;fiber;computer vision;artificial intelligence;grating;computer science	Vision	59.494355819611954	-42.725212806362876	78461
f9ab5d51ff920140163a18d1c9bf2684699d8155	design of cursive handwriting characters with nonlinear typeface reshaping transformation	cursive handwriting characters;splines mathematics light pens natural language processing notebook computers;splines mathematics;light pens;nonlinear typeface reshaping;smoothing splines;smoothing splines cursive handwriting characters nonlinear typeface reshaping b splines;notebook computers;b splines;omitted running style cursive handwriting character design nonlinear typeface reshaping transformation handwritten character typeface reshaping scheme handwritten character typeface reconstruction scheme handwriting motion data pen tablet device dynamic font method smoothing spline theory character aesthetic quality improvement nonlinear transformation japanese calligraphy;natural language processing;writing splines mathematics dynamics motion measurement smoothing methods data models time measurement	In this paper, we develop a scheme for reshaping and reconstructing a typeface of handwritten characters. First, we measure and store a set of handwriting motion data using the pen-tablet device, and then the corresponding characters are modeled based on so-called dynamic font method and a theory of smoothing splines. Next, in order to improve the aesthetic quality of such characters, we present a method for reshaping the typeface of characters. Such a method is developed using the nonlinear transformation based on Yasumoto's work. Moreover, we show how such a reshaped characters are reconstructed as those with the omitted running style as seen in Japanese calligraphy. The performance are demonstrated by some experiments.	experiment;nonlinear system;smoothing spline;spline (mathematics);tablet computer;theory	Hirotsugu Matsukida;Hiroyuki Fujioka	2013	2013 Eighth International Conference on Broadband and Wireless Computing, Communication and Applications	10.1109/BWCCA.2013.106	b-spline;computer vision;speech recognition;smoothing spline;computer science;computer graphics (images)	Robotics	64.01781106838187	-45.3472848148293	78492
47182ea163f4d41476d2c4286527b11d1714529d	example-based brushes for coherent stylized renderings		Painterly stylization is the cornerstone of non-photorealistic rendering. Inspired by the versatility of paint as a physical medium, existing methods target intuitive interfaces that mimic physical brushes, providing artists the ability to intuitively place paint strokes in a digital scene. Other work focuses on physical simulation of the interaction between paint and paper or realistic rendering of wet and dry paint. In our work, we leverage the versatility of example-based methods that can generate paint strokes of arbitrary shape and style based on a collection of images acquired from physical media. Such ideas have gained popularity since they do not require cumbersome physical simulation and achieve high fidelity without the need of a specific model or rule set. However, existing methods are limited to the generation of static 2D paintings and cannot be applied in the context of 3D painting and animation where paint strokes change shape and length as the camera viewport moves. Our method targets this shortcoming by generating temporally-coherent example-based paint strokes that accommodate to such length and shape changes. We demonstrate the robustness of our method with a 2D painting application that provides immediate feedback to the user and show how our brush model can be applied to the screen-space rendering of 3D paintings on a variety of examples.	algorithm;alpha compositing;coherence (physics);color;computer animation;dynamical simulation;global illumination;glossary of computer graphics;image scaling;lu decomposition;non-photorealistic rendering;real-time transcription;tablet computer;temporal logic;unbiased rendering;viewport;word lists by frequency	Ming Zheng;Antoine Milliez;Markus H. Gross;Robert W. Sumner	2017		10.1145/3092919.3092929	computer vision;computer graphics (images);robustness (computer science);viewport;artificial intelligence;rendering (computer graphics);animation;physical media;high fidelity;computer science;non-photorealistic rendering;painting	Graphics	64.50002103946721	-48.72302629778369	78601
14a5f3751c4269b9ee952b2a886c94226fcb7a95	covering minkowski sum boundary using points with applications	navegacion;concepcion asistida;02 40 dr;computer aided design;modele geometrique;estimation mouvement;motion control;polyedre;profundidad penetracion;realite virtuelle;geometrie solide;realidad virtual;complexite calcul;poliedro;path planning;estimacion movimiento;metrique minkowski;virtual reality;geometria solidos;metrico minkowski;polyhedron;motion estimation;paralelisacion;robotics;planification trajectoire;commande mouvement;control movimiento;navigation;virtual prototyping;complejidad computacion;penetration depth;computational complexity;point based representation;robot motion planning;parallelisation;solid modeling;motion planning;parallelization;conception assistee;robotica;geometric modeling;geometric model;robotique;minkowski metric;minkowski sum;profondeur penetration;penetration depth estimation;similarity function;solid geometry;minkowski sum approximation;geometrical model;modelo geometrico	Minkowski sum is a fundamental operation in many geometric applications, including robotic motion planning, penetration depth estimation, solid modeling, and virtual prototyping. However, due to its high computational complexity and several non-trivial implementation issues, computing the exact boundary of the Minkowski sum of two arbitrary polyhedra is generally a difficult task. In this work, we propose to represent the boundary of the Minkowski sum approximately using only points. Our results show that this point-based representation can be generated efficiently. An important feature of our method is its straightforward implementation and parallelization. We demonstrate that the point-based representation of the Minkowski sum boundary can indeed provide similar functionality as the mesh-based representations can. We show several applications in motion planning, penetration depth approximation and geometric modeling. An implementation of the proposed method can be obtained from our project webpage.	3d scanner;computer-aided design;experiment;fractal-generating software;minkowski addition;multiresolution analysis;octree;parallel computing;polyhedron;robustness (computer science);sampling (signal processing)	Jyh-Ming Lien	2008	Computer Aided Geometric Design	10.1016/j.cagd.2008.06.006	combinatorics;topology;geometric modeling;computer aided design;solid geometry;minkowski addition;mathematics;geometry;motion planning;virtual reality;robotics	Robotics	66.53305150754036	-39.15534134681643	78665
d41aef6ad68f330df945744cd98405052ddb9bde	mathematical foundations of arc length-based aspect ratio selection	i 3 7 computing methodologies computer graphics three dimensional graphics and realism;vectors computer graphics;inproceedings;resultant vector arc length based aspect ratio selection maximizing weighted local curvature local orientation resolution parameterization invariant form average slope;banking robustness market research visual perception visualization indexes computers	The aspect ratio of a plot can strongly influence the perception of trends in the data. Arc length based aspect ratio selection (AL) has demonstrated many empirical advantages over previous methods. However, it is still not clear why and when this method works. In this paper, we attempt to unravel its mystery by exploring its mathematical foundation. First, we explain the rationale why this method is parameterization invariant and follow the same rationale to extend previous methods which are not parameterization invariant. As such, we propose maximizing weighted local curvature (MLC), a parameterization invariant form of local orientation resolution (LOR) and reveal the theoretical connection between average slope (AS) and resultant vector (RV). Furthermore, we establish a mathematical connection between AL and banking to 45 degrees and derive the upper and lower bounds of its average absolute slopes. Finally, we conduct a quantitative comparison that revises the understanding of aspect ratio selection methods in three aspects: (1) showing that AL, AWO and RV always perform very similarly while MS is not; (2) demonstrating the advantages in the robustness of RV over AL; (3) providing a counterexample where all previous methods produce poor results while MLC works well.	design rationale;multi-level cell;resultant	Fubo Han;Yunhai Wang;Jian Zhang;Oliver Deussen;Baoquan Chen	2016	2016 IEEE Pacific Visualization Symposium (PacificVis)	10.1109/PACIFICVIS.2016.7465245	mathematical optimization;mathematics;engineering drawing;statistics	Vision	62.418623743967125	-44.33192475844168	78690
a391b2dd675998ef67306e1b1a61f173221f713b	virtual spherical lights for many-light rendering of glossy scenes	global illumination;many lights;glossy brdf;photon mapping	In this paper, we aim to lift the accuracy limitations of many-light algorithms by introducing a new light type, the  virtual spherical light  (VSL). The illumination contribution of a VSL is computed over a non-zero solid angle, thus eliminating the illumination spikes that virtual point lights used in traditional many-light methods are notorious for. The VSL enables application of many-light approaches in scenes with glossy materials and complex illumination that could previously be rendered only by much slower algorithms. By combining VSLs with the matrix row-column sampling algorithm, we achieve high-quality images in one to four minutes, even in scenes where path tracing or photon mapping take hours to converge.		Milos Hasan;Jaroslav Krivánek;Bruce Walter;Kavita Bala	2009	ACM Trans. Graph.	10.1145/1618452.1618489	computer vision;computer science;mathematics;photon mapping;optics;global illumination;computer graphics (images)	Graphics	64.00912821532594	-51.241780401280316	78822
49723f5d6cbd8cff92bba3e7f8b2dafc9c16e3e4	pillow: interactive flattening of a 3d model for plush toy design	3d model;surface model;interaction pattern;total length;physical simulation	Pillow is an interactive pattern-design system for creating plush toys. The user imports a 3D surface model into the system and specifies the segmentation boundaries interactively by drawing seam lines on the model surface. Based on this segmentation, the system generates a 2D pattern by flattening each outlined region, and then visualizes the shape of the resulting plush toy by applying a simple physics simulation. If the result is not satisfactory, the user can make different seam lines. This closed-loop framework allows users to experiment with various seam patterns before actually working on real fabric to obtain the best-looking result. The system also estimates total sewing time based on the total length of the seam lines. We implemented the system to produce plush toys and a balloon.	3d modeling;dynamical simulation;interactivity;polygonal modeling;toys	Yuki Igarashi;Takeo Igarashi	2008		10.1007/978-3-540-85412-8_1	simulation;computer graphics (images)	Graphics	65.45745877388387	-47.274364695115494	78932
1d942d3ca7373aac2d67b2849b889d4eb4f8eec8	real-time caustics in dynamic scenes with multiple directional lights	environment illumination;real time;gpu;caustics;real time rendering;dynamic scenes	We present a real-time GPU caustics rendering technique in dynamic scenes under multiple directional lights taking into account light occlusion. Our technique renders caustics cast on receiver objects as well as volumetric caustics. We precompute caustic patterns of caustic objects for several directional lights and store them in caustic images. During the rendering, we interpolate the precomputed caustic patterns based on a given light direction. One of the applications of our technique is to render approximate caustics under environment illumination. To achieve this, we propose an environment cube map segmentation technique which divides cube maps into several light regions with each region is represented using one directional light.	approximation algorithm;cube mapping;graphics processing unit;illumination (image);interpolation;map segmentation;precomputation;real-time clock;rendering (computer graphics)	Budianto Tandianus;Henry Johan;Seah Hock Soon	2010		10.1007/978-3-642-15399-0_32	computer vision;geography;optics;computer graphics (images)	Graphics	65.75498016244966	-51.213532946352565	79035
58e3446d3e8da550cfe023d13ddea4e7140b2aa9	a new approach to vanishing point detection in architectural environments	real time;vanishing points;vanishing point;building reconstruction;camera calibration;vanishing lines;geometric constraints;architecture	A man-made environment is characterized by many parallel lines and orthogonal edges. In this article, a new method for detecting the three mutually orthogonal directions of such an environment is presented. Since real-time performance is not necessary for architectural applications, such as building reconstruction, a computationally intensive approach was chosen. However, this enables us to avoid one fundamental error of most other existing techniques. Compared to theirs, our approach is furthermore more rigorous, since all conditions given by three mutually orthogonal directions are identified and utilized. We assume a partly calibrated camera with unknown focal length and unknown principal point. By examine these camera parameters, which can be determined from orthogonal directions, falsely detected vanishing points may be rejected.	vanishing point	Carsten Rother	2002	Image Vision Comput.	10.1016/S0262-8856(02)00054-9	computer vision;mathematical optimization;vanishing point;computer science;mathematics;geometry	Vision	54.956379369753186	-49.91322520552484	79091
108fe2baad0145a946d8450311f2a8254de96bb8	interactive voxelized epipolar shadow volumes	frames per second;participating media;shadows;interactive;sampling technique;epipolar space;space use;voxelization;cache coherence;analytic solution	Current algorithms for rendering shadows inside participating media hit a bottleneck when computing light visibility throughout the media. These algorithms rely either on sampling along viewing rays, often thrashing memory caches, or slower analytic solutions using object-space computations, such as shadow volumes.  We present a new cache-coherent sampling technique that computes volumetric light visibility that requires as little as one texture lookup per pixel. We efficiently voxelize shadow volumes in epipolar-space using standard parallel scan operations. The only step dependent on geometric complexity is an image-space voxelization [Eisemann and Décoret 2006] that often takes under a millisecond. This allows us to render shadows in participating media at up to 300 frames per second.	algorithm;cache coherence;coherence (physics);coherent sampling;computation;epipolar geometry;lookup table;pixel;sampling (signal processing);shadow volume;texture filtering;thrashing (computer science);volumetric lighting	Chris Wyman	2010		10.1145/1899950.1900003	sampling;computer vision;cache coherence;closed-form expression;shadow;computer science;interactivity;frame rate;statistics;computer graphics (images)	Graphics	65.82127738446657	-51.34935009724854	79177
24e15827d7595c9b31a9246e3cc598f50c5b5b19	an efficient algebraic solution to the perspective-three-point problem		In this work, we present an algebraic solution to the classical perspective-3-point (P3P) problem for determining the position and attitude of a camera from observations of three known reference points. In contrast to previous approaches, we first directly determine the cameras attitude by employing the corresponding geometric constraints to formulate a system of trigonometric equations. This is then efficiently solved, following an algebraic approach, to determine the unknown rotation matrix and subsequently the cameras position. As compared to recent alternatives, our method avoids computing unnecessary (and potentially numerically unstable) intermediate results, and thus achieves higher numerical accuracy and robustness at a lower computational cost. These benefits are validated through extensive Monte-Carlo simulations for both nominal and close-to-singular geometric configurations.	algorithmic efficiency;control theory;linear algebra;monte carlo method;numerical analysis;numerical stability;p3p;simulation	Tong Ke;Stergios I. Roumeliotis	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2017.491	mathematical optimization;simulation;mathematics;geometry	Vision	56.0662201538088	-41.07588891732964	79426
253070e1184efb2623fdd1a83b63dd73a96f7007	a comparison and evaluation of multi-view stereo reconstruction algorithms	reconstruction algorithms stereo image processing stereo vision layout taxonomy image reconstruction shape measurement educational institutions cameras image databases;image databases;reconstruction algorithms;shape measurement;layout;evaluation methodology;image reconstruction;stereo image processing;stereo vision;taxonomy;multi view stereo;ground truth;shape modeling;reconstruction algorithm;cameras	This paper presents a quantitative comparison of several multi-view stereo reconstruction algorithms. Until now, the lack of suitable calibrated multi-view image datasets with known ground truth (3D shape models) has prevented such direct comparisons. In this paper, we first survey multi-view stereo algorithms and compare them qualitatively using a taxonomy that differentiates their key properties. We then describe our process for acquiring and calibrating multiview image datasets with high-accuracy ground truth and introduce our evaluation methodology. Finally, we present the results of our quantitative comparison of state-of-the-art multi-view stereo reconstruction algorithms on six benchmark datasets. The datasets, evaluation details, and instructions for submitting new models are available online at http://vision.middlebury.edu/mview.	algorithm;benchmark (computing);ct scan;calibration (statistics);correspondence problem;ground truth;lawrence m. breed	Steven M. Seitz;Brian Curless;James Diebel;Daniel Scharstein;Richard Szeliski	2006	2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)	10.1109/CVPR.2006.19	iterative reconstruction;computer stereo vision;layout;stereo cameras;computer vision;simulation;ground truth;computer science;stereopsis;taxonomy;computer graphics (images)	Vision	54.831406310679114	-48.62474336887828	79456
6ae0d441d5903d2e479c61c37a3496ff70658a00	the scanline principle: efficient conversion of display algorithms into scanline mode		The scanline principle is a general technique for efficiently converting any display algorithm that is based on polygon scan conversion into scanline mode, i.e., the image is produced in scanline order with required memory proportional to one scanline. Based on critical-points scan conversion, the technique reduces the Z-buffer or its variants to one scanline. Current scanline depth buffers are inefficient in both time and space. The scanline principle can also transform listpriority methods, such as BSP trees, into scanline mode. The scanline mode enables efficient supersampling and averaging, and low latency in image generation, compression and transmission.	algorithm;binary space partitioning;glossary of computer graphics;scan conversion;scan line;supersampling;z-buffering	Ella Barkan;Dan Gordon	1999	The Visual Computer	10.1007/s003710050176	mathematical optimization	Graphics	67.50877331647688	-50.96447293679935	79486
59f0a8fee9719927947131205d68fad3c3ad0ba5	skinning with dual quaternions	skinning;paper;dual quaternions;animation system;blending;conference paper;real time graphics;real time animation;algorithms;computer science;rigid transformations;linear combinations;3d graphics and realism;deformable model	Skinning of skeletally deformable models is extensively used for real-time animation of characters, creatures and similar objects. The standard solution, linear blend skinning, has some serious drawbacks that require artist intervention. Therefore, a number of alternatives have been proposed in recent years. All of them successfully combat some of the artifacts, but none challenge the simplicity and efficiency of linear blend skinning. As a result, linear blend skinning is still the number one choice for the majority of developers. In this paper, we present a novel GPU-friendly skinning algorithm based on dual quaternions. We show that this approach solves the artifacts of linear blend skinning at minimal additional cost. Upgrading an existing animation system (e.g., in a videogame) from linear to dual quaternion skinning is very easy and has negligible impact on run-time performance.	algorithm;graphics processing unit;real-time computing;real-time locating system;skin (computing)	Ladislav Kavan;Steven Collins;Jirí Zára;Carol O'Sullivan	2007		10.1145/1230100.1230107	dual quaternion;simulation;rigid transformation;linear combination;computer graphics (images)	Graphics	64.32650621689608	-47.025899764766095	79891
6b13b22faaa97ab35c92d58a0dd7e13e51da194d	sampling superquadric point clouds with normals		Superquadrics provide a compact representation of common shapes and have been used both for object/surface modelling in computer graphics and as object-part representation in computer vision and robotics. Superquadrics refer to a family of shapes: here we deal with the superellipsoids and superparaboloids. Due to the strong non-linearities involved in the equations, uniform or close-to-uniform sampling is not attainable through a naive approach of direct sampling from the parametric formulation. This is specially true for more ‘cubic’ superquadrics (with shape parameters close to 0.1). We extend a previous solution of 2D closeto-uniform uniform sampling of superellipses to the superellipsoid (3D) case and derive our own for the superparaboloid. Additionally, we are able to provide normals for each sampled point. To the best of our knowledge, this is the first complete approach for close-to-uniform sampling of superellipsoids and superparaboloids in one single framework. We present derivations, pseudocode and qualitative and quantitative results using our code, which is available online.	computer graphics;computer vision;normal (geometry);pseudocode;robotics;sampling (signal processing);superellipsoid;superquadrics	Paulo Ferreira	2018	CoRR		point cloud;machine learning;superellipsoid;superquadrics;sampling (statistics);computer graphics;computer science;parametric statistics;artificial intelligence;robotics;pseudocode	Vision	59.295394770096706	-46.741066459195174	80056
e68c469563d174dc3218e4302b0829eeda046b1c	a method for dynamic selection of optimal depth measurements acquisition with random access range sensors	computers;smart sensing;3d imaging;selective sensing;image sensors;kinect;distance measurement;improvement map;robots;random processes;neptec lms laser optimal depth measurement acquisition random access range sensor dynamic location selection range data acquisition vision sensor data management data processing autonomous system decision making scene surface shape formal improvement measure field of view range sensing technology kinect multimodal imaging sensor;random processes data acquisition decision making distance measurement image sensors natural scenes;computers robots;kinect improvement map range measurement 3d imaging random access range sensors smart sensing selective sensing;data acquisition;range measurement;random access range sensors;natural scenes	It is well established that acquiring large amount of range data with vision sensors can quickly lead to important data management challenges where processing capabilities become saturated and preempt full usage of the information available for autonomous systems to make educated decisions. While sub-sampling offers a naive solution for reducing dataset dimension after acquisition, it does not capitalize on the knowledge available in already acquired data to selectively and dynamically drive the acquisition process over the most significant regions in a scene, the latter being generally characterized by variations in depth and surface shape. This paper discusses the development of a formal improvement measure and a method to automatically establish which regions within the field of view of a range sensor would provide the most improvement to a model of the scene if further acquisitions were concentrated in priority over those regions. The proposed algorithm mainly targets applications using random access range sensors, defined as sensors that can acquire depth measurements at specified azimuth and elevation within their field of view. However, the framework is developed to be independent of the range sensing technology used, and is validated with range data acquired from the popular Kinect multi-modal imaging sensor, as well as Neptec,s LMS laser random access range sensor.	3d scanner;algorithm;autonomous system (internet);brute-force search;image sensor;kinect;modal logic;random access;sampling (signal processing)	Phillip Curtis;Pierre Payeur	2013	2013 International Conference on Computer and Robot Vision	10.1109/CRV.2013.24	robot;stereoscopy;stochastic process;computer vision;simulation;computer science;artificial intelligence;image sensor;data acquisition;statistics	Robotics	57.0609619601778	-43.63510356956119	80086
7efaa31a5d025099478ef005c156b22deb4cdce1	a new approach to simultaneous localization and map building with learning: neoslam (neuro-evolutionary optimizing)	evolutionary computation;cost function;neural model;sensor model;evolutionary programming;mobile robots;robust control;robust control evolutionary computation mobile robots neurocontrollers;data association;simultaneous localization and mapping;robust performance;global optimization;neurocontrollers;evolutionary optimization;simultaneous localization and map building;simultaneous localization and mapping predictive models cost function noise robustness working environment noise optimization methods robot sensing systems robot kinematics neural networks genetic programming;evolutionary programming map building neoslam neuroevolutionary optimization simultaneous localization and mapping neoslam method global optimization problem robot pose trajectory feature positions sensor data;neural network	This paper addresses a novel approach to the solution of the Simultaneous Localization and Mapping (SLAM) problem bared on a Neuro Evolutionary Optimization (NeoSLAM) method. The proposed algorithm first casts SLAM as a global optimization problem using the cost function which represents the quality of robot pose trajectory and the feature positions in world coordinate frame. In our algorithm, the neural network trained to estimate the pose difference of the two consecutive positions accurately from the corresponding sensor data and the previous pose difference. The cost function is formulated as the importance of the full SLAM assumptions of EKF. Evolutionary Programming (EP) is used to evolve the neural model that is most consistent with the actual data measurement. Prediction and correction is simultaneously performed in our neural model that combines both the motion model and sensor model. By way of learning and evolution, our algorithm does not need prior assumption on the motion and sensor models, and therefore shows a robust performance regardless of the actual noise type. Further, our method can generate an accurate map even without the data association step, paving the way to deal with practical applications. Both the simulation and real experimental results conducted made various environments and noise/sensor types demonstrate that NeoSLAM ensures a consistently robust and accurate performance.	artificial neural network;cluster analysis;correspondence problem;ekf slam;emoticon;evolutionary algorithm;evolutionary programming;expectation propagation;experiment;extended kalman filter;global optimization;lamp (software bundle);map;mathematical optimization;maxima and minima;mobile robot;neo geo;odometry;optimization problem;optimizing compiler;sonar (symantec);sensor;simulation;simultaneous localization and mapping	Jeong-Gwan Kang;Su-Yong An;Sunhyo Kim;Se-Young Oh	2009	2009 IEEE International Symposium on Computational Intelligence in Robotics and Automation - (CIRA)	10.1109/CIRA.2009.5423192	evolutionary programming;robust control;mobile robot;computer vision;mathematical optimization;computer science;artificial intelligence;machine learning;artificial neural network;global optimization;evolutionary computation;simultaneous localization and mapping	Robotics	54.321703869503274	-40.374076135979365	80272
3ea779c3d98e74ca23dcfec17cf7d2fc95f575b5	geometric manipulation of tensor product surfaces	input device;direct manipulation;three dimensional;tensor product;design method;free form deformation;computer animation;industrial design;computer aided geometric design	Tensor product surfaces are now widely used in application areas such as industrial design and computer animation and thus the quest for more effective design methods continues. Although several methods exist for applying high-level operators such as bends, twists and free-form deformations (FFD’s), much less effort has been applied to improving direct and precise free-form shaping which is often desired. The dominant form of free-form manipulation has been control-point based. Here we offer a manipulative method that presents geometric properties (e.g. points on the surface, normal vectors, etc.), rather than control vertices or deformation lattices, and allows direct manipulation of these properties at any selected point on the surface. The difficulties of interacting with these threedimensionalgeometric entities usingboth twoand three-dimensional input devices are discussed, as are possible interactive schemes using several such devices. CR Categories: 1.3.5 [Computer Graphics]: Computational Geometry and Object Modelllng parametric surfaces; I.3.6 [Computer Graphics]: Methodology and Techniques interactive techniques, direct manipulation, constraints; J.6 [Computer-Aided Engineering]: Computer-Aided Design (CAD).	bend minimization;computation;computational geometry;computer animation;computer graphics;computer-aided design;direct manipulation interface;entity;free-form deformation;high- and low-level;input device;interaction;noise shaping;normal (geometry)	Barry Fowler	1992		10.1145/147156.147172	tensor product;three-dimensional space;computer vision;industrial design;design methods;computer science;operating system;geometry;computer animation;input device	Graphics	66.07836275480594	-45.90528522156679	80280
790d8feaba2aa9fc49ec7c715672a3e78c99fffa	a reflectance model for metallic paints using a two-layer structure surface with microfacet distributions		We present a new method that can represent the reflectance of metallic paints accurately using a two-layer reflectance model with sampled microfacet distribution functions. We model the structure of metallic paints simplified by two layers: a binder surface that follows a microfacet distribution and a sub-layer that also follows a facet distribution. In the sub-layer, the diffuse and the specular reflectance represent color pigments and metallic flakes respectively. We use an iterative method based on the principle of Gauss-Seidel relaxation that stably fits the measured data to our highly non-linear model. We optimize the model by handling the microfacet distribution terms as a piecewise linear non-parametric form in order to increase its degree of freedom. The proposed model is validated by applying it to various metallic paints. The results show that our model has better fitting performance compared to the models used in other studies. Our model provides better accuracy due to the non-parametric terms employed in the model, and also gives efficiency in analyzing the characteristics of metallic paints by the analytical form embedded in the model. The non-parametric terms for the microfacet distribution in our model require densely measured data but not for the entire BRDF(bidirectional reflectance distribution function) domain, so that our method can reduce the burden of data acquisition during measurement. Especially, it becomes efficient for a system that uses a curved-sample based measurement system which allows us to obtain dense data in microfacet domain by a single measurement. key words: metallic paint, reflectance modeling, multi-layer surface, measure-and-fit, non-parametric basis function	basis function;data acquisition;embedded system;fits;file binder;gauss–seidel method;iterative method;lambertian reflectance;layer (electronics);linear model;linear programming relaxation;nonlinear system;piecewise linear continuation;specular highlight;system of measurement	Gang Yeon Kim;Kwan H. Lee	2010	IEICE Transactions		bidirectional reflectance distribution function;degrees of freedom (statistics);iterative method;artificial intelligence;computer vision;facet (geometry);computer science;piecewise linear function;specular reflection;distribution function;data acquisition	Vision	58.71497817875632	-51.446651016501335	80448
d4cc5ac88a3cf5aa2f7883e7d3c597edf8ffac49	accuracy of reconstruction of the tree stem surface using terrestrial close-range photogrammetry	stem volume;terrestrial photogrammetry;stem surface	Airborne laser scanning (ALS) allows for extensive coverage, but the accuracy of tree detection and form can be limited. Although terrestrial laser scanning (TLS) can improve on ALS accuracy, it is rather expensive and area coverage is limited. Multi-view stereopsis (MVS) techniques combining computer vision and photogrammetry may offer some of the coverage benefits of ALS and the improved accuracy of TLS; MVS combines computer vision research and automatic analysis of digital images from common commercial digital cameras with various algorithms to reconstruct three-dimensional (3D) objects with realistic shape and appearance. Despite the relative accuracy (relative geometrical distortion) of the reconstructions available in the processing software, the absolute accuracy is uncertain and difficult to evaluate. We evaluated the data collected by a common digital camera through the processing software (Agisoft PhotoScan ©) for photogrammetry by comparing those by direct measurement of the 3D magnetic motion tracker. Our analyses indicated that the error is mostly concentrated in the portions of the tree where visibility is lower, i.e., the bottom and upper parts of the stem. For each reference point from the digitizer we determined how many cameras could view this point. With a greater number of cameras we found increasing accuracy of the measured object space point positions (as expected), with a significant positive change in the trend beyond five cameras; when more than five cameras could view this point, the accuracy began to increase more abruptly, but eight cameras or more provided no increases in accuracy. This method allows for the retrieval of larger datasets from the measurements, which could improve the accuracy of estimates of 3D structure of trees at potentially reduced costs.	algorithm;computer vision;control point (mathematics);digital camera;digital image;distortion;handheld game console;heart rate variability;motion detector;photogrammetry;stereopsis;terrestrial television;tuple space	Peter Surový;Atsushi Yoshimoto;Dimitrios Panagiotidis	2016	Remote Sensing	10.3390/rs8020123	computer vision;simulation;remote sensing	Vision	56.04750382173568	-46.773349615099704	80849
302d5beacefb250e2e232dfb2ab45980620e24db	a stack-based approach for shading of regions	curva;representation graphique;computer graphics;representacion grafica;stack;pila;courbe;curve;algorithme;algorithm;grafico computadora;infographie;ombrage infographie;pile memoire;graphics;algoritmo	-The method for shading of regions is considered as the basic study in raster graphics. A stackbased approach is presented in the paper. Without sorting of the boundary coordinates, the time and space consumed by the shading procedure are considerably saved. The facilities of the approach in 3D graphics are also illustrated. 1. I N T R O D U C T I O N Many graphics modeling systems give out image results with the objects shaded, such as complicated planar shape filling, facet shading of 3D models, texture mapping, area messuring, etc. In fact, the methods for shading of regions have been considered as one of the basic studies in the field of raster graphics. The qualified algorithms have been sought after by the Computer Graphics researchers of the past [ 1-7 ], Currently, the existing approaches for shading of regions fall into two types of algorithms. One is the seeding algorithm[ l0 ] which needs an interior point of the region input before the region is shaded. The method is applicable in interactive graphics systems while hardly to be used in automated graphics systems. The other implements shading of the region based on sorting of the ordinates on its boundary to construct an active list of the matched pairs of the ordinates. Up to now, the latter is widely applied in both interactive and automated computer graphics [ 8, 11 ]. However, the time and space needed for the shading procedures are considerably consumed mainly due to the great amount of sorting calculation or to the resolution related memory for the bit map [ 6]. The complexity of the calculation increases rapidly while the boundary of the region gets a little complicated. A new approach for shading of regions is presented in this paper. With the stack-based operations on the edges of the region, the sorting of the ordinates is no longer needed. As a result, the speed of shading is notably raised and the work space is also considerably saved. 2. C O N C E P T S , D A T A S T R U C T U R E , A N D ELEMENTAL PROCEDURES In raster graphics, a bound region is usually represented as a polygon which is further defined by a counterclockwise series of the vertices on the boundary. Each pair of the adjacent vertices is defined as an edge,	3d computer graphics;3d modeling;algorithm;neighbourhood (graph theory);raster graphics;shading;sorting;stack-oriented programming language;texture mapping	Feng Lin;Yunhe Pan	1992	Computers & Graphics	10.1016/0097-8493(92)90074-6	rasterisation;gouraud shading;stack;computer science;graphics;mathematics;geometry;curve;computer graphics;algorithm;computer graphics (images)	Graphics	66.72267118043635	-48.54245735290429	80851
efd8b81e62cda8da81888d787667e5a6f1940f67	earth documentation: overpass detection using mobile lidar	multi resolution data structure;geophysical image processing;earth documentation;system parallelism;difference operator;image resolution;multiresolution data structure earth documentation overpass detection mobile lidar geo data gps imu real time system parallelism memory access coherence multilevel detection strategy;real time;distributed computing;multi resolution data structure overpass detection stream processing;gps imu;laser radar;multilevel detection strategy;three dimensional displays laser radar trajectory vehicles clouds buildings image edge detection;memory access;memory access coherence;trajectory;optical radar;image edge detection;global positioning system;geographic information systems;three dimensional displays;clouds;mobile lidar;radar imaging;geo data;overpass detection;vehicles;multi resolution;stream processing;multiresolution data structure;data structure;buildings;radar imaging geographic information systems geophysical image processing global positioning system image resolution optical radar	This paper presents an application of using geo-data from Lidar and GPS/IMU to detect overpasses. Three characteristics make it a good example of processing large point sets in real-time: a stream paradigm that exploits system parallelism and memory-access coherence, a multi-level detection strategy that distributes computational burden across different operations, and a multi-resolution data structure that suits the need of detecting urban objects. Experimental results proved the excellent performance in terms of speed and accuracy.	computation;data structure;documentation;global positioning system;parallel computing;programming paradigm;real-time clock;sensor	Cheng Qian;Bill Gale;Jeff Bach	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5651369	lidar;computer vision;simulation;stream processing;image resolution;global positioning system;data structure;computer science;trajectory;radar imaging	Robotics	55.556886092218015	-44.49588156206988	80858
9a0e9e44567ed324a2729fe8d3e299f6ef6608a5	high-speed solder bump inspection system using a laser scanner and ccd camera	laser scanner;ccd camera	We have developed technologies which inspect the shape of solder bumps. The bumps are used to solder an LSI to a printed wiring board in high-speed workstations. The inspection system developed can measure the height, diameter, and brightness of bumps at very high speed. The bump height is measured using triangulation, in which a laser beam scans the bumps, and reflected light is detected with a position sensitive detector (PSD). The diameter and the brightness are measured using a microscope and a CCD camera. The detected results are compared with CAD data. A height measurement accuracy of ±3 μm and a diameter measurement accuracy of ±5 μm were obtained. Practical inspection systems using these techniques have been created and they can inspect 2000 bumps in 60 seconds. © 2000 Scripta Technica, Syst Comp Jpn, 31(2): 94–102, 2000	bump mapping;charge-coupled device	Hiroyuki Tsukahara;Yoji Nishiyama;Fumiyuki Takahashi;Takashi Fuse;Toru Nishino;Moritoshi Ando	2000	Systems and Computers in Japan	10.1002/(SICI)1520-684X(200002)31:2%3C94::AID-SCJ10%3E3.0.CO;2-V	laser scanning;embedded system;charge-coupled device;computer graphics (images)	Robotics	59.91722400048007	-41.240496800271636	81007
f2e961943ca3ba671f63ea0f64a011552c9484fa	a low dimensional framework for exact polygon-to-polygon occlusion queries	feedback mechanism;non photorealistic rendering;silhouette;categories and subject descriptors according to acm ccs i 3 3 computer graphics exact visibility culling;computer graphic;sampling;multi dimensional;geometry image;stippling;polygonal meshes;analytical method	Despite the importance of from-region visibility computation in computer graphics, efficient analytic methods are still lacking in the general 3D case. Recently, different algorithms have appeared that maintain occlusion as a complex of polytopes in Plücker space. However, they suffer from high implementation complexity, as well as high computational and memory costs, limiting their usefulness in practice.  In this paper, we present a new algorithm that simplifies implementation and computation by operating only on the skeletons of the polyhedra instead of the multi-dimensional face lattice usually used for exact occlusion queries in 3D. This algorithm is sensitive to complexity of the silhouette of each occluding object, rather than the entire polygonal mesh of each object. An intelligent feedback mechanism is presented that greatly enhances early termination by searching for apertures between query polygons. We demonstrate that our technique is several times faster than the state of the art.	complexity;computation;convex hull;feedback;glossary of computer graphics;greedy algorithm;heuristic;np-hardness;polygon mesh;polyhedron;silhouette edge	Denis Haumont;Otso Makinen;Shaun Nirenstein	2005		10.2312/EGWR/EGSR05/211-222	stippling;sampling;computer vision;computer science;theoretical computer science;machine learning;feedback;non-photorealistic rendering;silhouette;computer graphics (images)	Graphics	67.05173800062308	-45.173449477226605	81011
4be70bd49ec23d66f51fbc26e9dee6d0b6716d7e	virtual object overlay onto uncalibrated camera images for augmented reality	projective geometry complex reality;image base;augmented reality;uncalibrated camera	Abstract#R##N##R##N#We propose a new registration algorithm for overlaying a virtual object generated in a graphics system onto a real-world image sequence captured by an uncalibrated camera for augmented reality. In our method, a Projective Grid Space (PGS) is defined by using two base images captured from different positions with uncalibrated cameras. In the PGS, correct perspective views of a virtual object can be registered onto an image sequence captured by an uncalibrated camera in real time. Since our method is based on the projective geometry that is defined by two base images, the registration does not require any markers with known 3D positions, but several (at least eight) image feature points are needed for estimating fundamental matrices of the augmented camera with the base images. Based on this method, we constructed an augmented reality system for an uncalibrated camera without any 3D position information in the real world, which runs nearly at video rate (11 frames per second). Experimental results demonstrate the advantages of this method. © 2003 Wiley Periodicals, Inc. Syst Comp Jpn, 34(5): 47–55, 2003; Published online in Wiley InterScience (www.interscience.wiley.com). DOI 10.1002/scj.10261	augmented reality	Shunsuke Harasaki;Hideo Saito	2003	Systems and Computers in Japan	10.1002/scj.10261	computer vision;camera auto-calibration;augmented reality;simulation;computer science;computer graphics (images)	HCI	55.02537313419596	-48.273022301546234	81154
76dfbc089d0e2a38b9cc334ddcc0fa1c4e116d9b	geometry of isophote curves	object representation;analisis imagen;symmetry set;vision ordenador;isophote;singularite;plane curve;image processing;axe median;vertex;medial axe;differential geometry;level set;shape analysis;procesamiento imagen;isophot;isophote curve;surface lisse;traitement image;skeleton;computer vision;smooth surface;eje mediano;singularidad;image analysis;vision ordinateur;superficie lisa;inflexion;analyse image;medial axis;isophota;singularity	We consider the intensity surface of a 2D image, we study the evolution of the symmetry sets (and medial axes) of 1-parameter families of iso-intensity curves. This extends the investigation done on 1-parameter families of smooth plane curves (Bruce and Giblin, Giblin and Kimia, etc.) to the general case when the family of curves includes a singular member, as will happen if the curves are obtained by taking plane sections of a smooth surface, at the moment when the plane becomes tangent to the surface.	artificial consciousness;contour line;medial graph;scale space	André Diatta;Peter J. Giblin	2005		10.1007/11408031_5	singularity;vertex;computer vision;plane curve;image analysis;topology;medial axis;image processing;computer science;level set;differential geometry of curves;inflection;shape analysis;mathematics;geometry;family of curves;skeleton	Vision	66.11123703739405	-40.11828453317381	81196
07884f90c1810da8b79904db1435bd0c76d62858	motion of disturbances: detection and tracking of multi-body non-rigid motion	real time;key words tracking non rigid motion multi body motion camouflage optical flow;optical flow;water flow	We present a new approach to the tracking of very non-rigid patterns of motion, such as water flowing down a stream. The algorithm is based on a “disturbance map”, which is obtained by linearly subtracting the temporal average of the previous frames from the new frame. Every local motion creates a disturbance having the form of a wave, with a “head” at the present position of the motion and a historical “tail” that indicates the previous locations of that motion. These disturbances serve as loci of attraction for “tracking particles” that are scattered throughout the image. The algorithm is very fast and can be performed in real time. We provide excellent tracking results on various complex sequences, using both stabilized and moving cameras, showing a busy ant column, waterfalls, rapids and flowing streams, shoppers in a mall, and cars in a traffic intersection.	algorithm;tail call	Gilad Halevy;Daphna Weinshall	1999	Machine Vision and Applications	10.1007/s001380050096	computer vision;simulation;computer science;motion estimation;optical flow;control theory;motion field;linear motion	Vision	58.250685683300624	-41.680528292078655	81431
f4fbcd230326e81df6d90a4d25b7a7e93b04bd9d	generating well behaved meshes for parameterized surfaces	spline;computer aided design;parameter domain triangulation;tensile stress;iges format;surface of revolution;application software;computer graphics;well behaved mesh parameterized surface computer aided geometric design b spline nurbs tabulated cylinder trimmed surface revolution surface surface mesh generation parameter domain triangulation delaunay voronoi meshing spatial mesh refinement parametric function mesh merging iges format cad computer aided design geometric storage;mesh merging;cad;tabulated cylinder;well behaved mesh;nurbs;surface reconstruction;mesh generation spline surface topography surface reconstruction computer science application software computer errors tensile stress solid modeling graphics;surface topography;parametric function;solid modeling;trimmed surface;geometric storage;cad mesh generation computer graphics;b spline;computer science;delaunay voronoi meshing;spatial mesh refinement;mesh generation;surface mesh generation;computer errors;graphics;revolution surface;parameterized surface;computer aided geometric design	This paper gives first a survey of parametric representations that are often used in computer-aided geometric design. These include B-spline, NURBS, tabulated cylinder, trimmed surface and surface of revolution. Secondly, the paper deals with applications in surface mesh generation. The parameter domain is triangulated using Delaunay-Voronoi meshing and the spatial mesh is refined according to the error provided by the parametric function itself. We need also to merge the resulting meshes so as to obtain a single mesh of the whole model. The IGES format is used to illustrate CAD (computer-aided design) geometric storage. Some corroborative benchmarks from mechanically interesting objects will be equally provided.		H. Maharavo Randrianarivony;Guido Brunnett	2003		10.1109/GMAG.2003.1219666	b-spline;spline;mesh generation;application software;surface reconstruction;non-uniform rational b-spline;parametric equation;computer science;graphics;theoretical computer science;computer aided design;cad;surface of revolution;mathematics;solid modeling;stress;computer graphics;engineering drawing;computer graphics (images);mechanical engineering	Vision	67.20692446578896	-42.59455934424742	81608
58cbe335b4f450893e6d44f496749bdd4ea6c8b2	online reconstruction of 3d objects from arbitrary cross-sections	perspective projection;scene perception;three dimensional;barycentric coordinate;cross section;medical application;psychophysics	We describe a simple algorithm to reconstruct the surface of smooth three-dimensional multilabeled objects from sampled planar cross-sections of arbitrary orientation. The algorithm has the unique ability to handle cross-sections in which regions are classified as being inside the object, outside the object, or unknown. This is achieved by constructing a scalar function on R3, whose zero set is the desired surface. The function is constructed independently inside every cell of the arrangement of the cross-section planes using transfinite interpolation techniques based on barycentric coordinates. These guarantee that the function is smooth, and its zero set interpolates the cross-sections. The algorithm is highly parallelizable and may be implemented as an incremental update as each new cross-section is introduced. This leads to an efficient online version, performed on a GPU, which is suitable for interactive medical applications.	algorithm;barycentric subdivision;geographic coordinate system;graphics processing unit;incremental backup;merge sort;transfinite interpolation	Amit Bermano;Amir Vaxman;Craig Gotsman	2011	ACM Trans. Graph.	10.1145/2019627.2019632	three-dimensional space;computer vision;mathematical optimization;perspective;theoretical computer science;machine learning;mathematics;cross section;geometry;psychophysics;computer graphics (images)	Graphics	67.95540831317881	-49.30441712749339	81670
a49309623669064ee838befccd2778a987d587aa	material classification under natural illumination using reflectance maps	metals;manifolds;manifolds lighting shape three dimensional displays metals context cameras;shape;three dimensional displays;lighting;context;cameras	Research on visual material recognition has traditionally been based on texture analysis. Whereas older work has focused on uncluttered scenes, more recent contributions allowed for material recognition 'in the wild'. Quite some objects have untextured surfaces, however. Especially man-made examples are legion. The most obvious cue to use in such cases would be reflection information. Yet, methods to that effect are lacking. It is clear that more than an estimate of a scalar albedo is needed, and a more complete reflectance model has to be derived. Rather than using an extensive lab setup, we propose a system that only requires the 3D shape of objects and a regular, commercial camera to capture their appearance in a single image, to perform material classification under unknown illumination. To this end, we rely on a Gaussian Process Latent Variable Model (GPLVM) with a discriminative prior to learn a low-dimensional manifold suitable for material classification of reflectance maps, i.e. from a 2D image of a singlematerial sphere under natural illumination. We evaluated our method based on experiments generated from synthetic and real-life data. Although recognizing materials without texture (or object recognition) is not a trivial problem, our method achieves about 75% recognition accuracy, about 27% higher than human performance.	autostereogram;confusion matrix;experiment;gaussian process;human reliability;latent variable model;legion (software);map;nintendo ds and 3ds storage devices;outline of object recognition;real life;synthetic intelligence;texture mapping	Stamatios Georgoulis;Vincent Vanweddingen;Marc Proesmans;Luc Van Gool	2017	2017 IEEE Winter Conference on Applications of Computer Vision (WACV)	10.1109/WACV.2017.34	computer vision;manifold;shape;lighting;mathematics;geometry;computer graphics (images)	Vision	58.71779994898348	-51.882176667770935	81760
90135b474dcd9af88b56c2e98797a890ba63496f	volumic segmentation using hierarchical representation and triangulated surface	three dimensional imaging;3d imaging;hierarchical representation;physical model	This research report presents a new algorithm for segmenting three-dimensional images. It is based on a dynamic triangulated surface and on a pyramidal representation. The triangulated surface, which follows a physical modelization and which can as well modify its geometry as its topology, segments images into their components by altering its shape according to internal and external constraints. In order to speed up the whole process, an algorithm for pyramid building with any reduction factor allows us to transform the image into a set of images with progressive resolutions. This organization into a hierarchy, combined with a model that can adapt its mesh reenement to the resolution of the workspace, authorizes a fast estimation of the general forms included in the image. After that, the model searches for ner and ner details while relying successively on the diierent levels of the pyramid. Ce rapport de recherche pr esente un nouvel algorithme de segmentation d'images tridi-mensionnelles par utilisation de pyramides et de triangulation de surface dynamique. La triangulation, dot ee d'une mod elisation physique et capable de changer sa topologie, va, en se d eformant suivant certaines contraintes, segmenter l'image en ses constituants. AAn d'acc el erer le processus, un algorithme de construction de pyramide de facteur de r eduction quelconque permet de transformer l'image en un ensemble d'images de r e-solution progressive. Cette hi erarchisation, coupl ee a un mod ele capable d'adapter la pr ecision de sa maille a la r esolution de son espace de travail, permet d'estimer tr es rapidement les formes g en erales contenues dans une image. Une fois ceci fait, le mod ele recherche les d etails de plus en plus petits en s'appuyant successivement sur les dii erents niveaux de la pyramide.	algorithm;espace;hi performance filesystem;large eddy simulation;linear algebra;mathematical model;progressive scan;transformer;triangulation (geometry);workspace	Jacques-Olivier Lachaud;Annick Montanvert	1996		10.1007/BFb0015530	stereoscopy;computer vision;combinatorics;topology;physical model	Vision	65.9857266893367	-41.017530705608245	81880
937c46fdb79fb8aa01bdd596b82dbe17c0858759	dass: detail aware sketch-based surface modeling		We present a sketch-based modeling system suitable for detail editing, based on a multilevel representation for surfaces. The main advantage of this representation allowing for the control of local (details) and global changes of the model. We used an adaptive mesh (4-8 mesh) and developed a label theory to construct a manifold structure, which is responsible for controlling local editing of the model. The overall shape and global modifications are defined by a variational implicit surface (Hermite RBF). Our system assembles the manifold structures to allow the user to add details without changing the overall shape, as well as edit the overall shape while repositioning details coherently.	approximation algorithm;hermite polynomials;high-level programming language;implicit surface;level of detail;map;radial basis function;semiconductor industry;sketch;sketch-based modeling;super bit mapping;variational principle	Emilio Vital Brazil	2014	CoRR		computer vision;artificial intelligence;manifold;computer science;hermite polynomials;sketch	Graphics	66.39153378673916	-44.168343186396136	81940
35491799084c1a57a7c978e12d6ec067ebeec077	humanistic oriental art created using automated computer processing and non-photorealistic rendering	non photorealistic rendering;image segmentation;image interpolation;computer vision and image processing;rendering	In this paper, we present a new system of non-photorealistic rendering which allows landscape photographs to be automatically converted to look like Oriental paintings. Using various computer vision and image processing techniques, we can generate images with the rules and features commonly found in Oriental paintings. With such a system, anyone can create realistic Oriental paintings easily, without the years of practice that are usually required by Oriental artists.	non-photorealistic rendering;unbiased rendering	Adrian David Cheok;Zheng Shawn Lim;Roger Thomas Kok Chuen Tan	2007	Computers & Graphics	10.1016/j.cag.2007.01.003	computer vision;image-based modeling and rendering;3d rendering;rendering;computer science;non-photorealistic rendering;image segmentation;image scaling;computer graphics (images)	Graphics	64.52541789332764	-48.31671688710475	82003
82240d2b683a11375a14c10701284f2655411688	peripheral expansion of depth information via layout estimation with fisheye camera		Consumer RGB-D cameras have become very useful in the last years, but their field of view is too narrow for certain applications. We propose a new hybrid camera system composed by a conventional RGB-D and a fisheye camera to extend the field of view over 180 degrees. With this system we have a region of the hemispherical image with depth certainty, and color data in the periphery that is used to extend the structural information of the scene. We have developed a new method to generate scaled layout hypotheses from relevant corners, combining the extraction of lines in the fisheye image and the depth information. Experiments with real images from different scenarios validate our layout recovery method and the advantages of this camera system, which is also able to overcome severe occlusions. As a result, we obtain a scaled 3D model expanding the original depth information with the wide scene reconstruction. Our proposal expands successfully the depth map more than eleven times in a single shot.	color;depth map;fisheye;peripheral	Alejandro Pérez-Yus;Gonzalo López-Nicolás;Josechu J. Guerrero	2016		10.1007/978-3-319-46484-8_24	computer vision;computer graphics (images)	Vision	58.16677943245943	-50.68717599326126	82106
582064a8cde39ea067aa67cd116f34b4dbbf4765	accelerate volume splatting by using run length encoding	volume rendering;spatial coherence;image quality;run length encoding;data structure	Methods such as splat hierarchies, indexing and lists have been presented by the research society in recently years, to accelerate the splatting, a popular volume rendering algorithm. In this paper, a run length encoding (RLE) accelerated, pre-classification and pre-shade sheet buffer volume splatting algorithm is presented, which can enhance the speed of splatting without trading off image quality. This new technique saves rendering time by employing RLE mechanism so that only voxels of interest are processed in splatting. RLE based data structures are defined to exploit spatial coherence of volume and intermediate rendering images. A fast and accurate sheet buffer splatting method is used in the rendering process, which accelerates the splatting by traversing both the voxel scanline and the image scanline in sheet buffer simultaneously. Experiments practice proves that RLE can efficiently skip over transparent voxels in splatting and high speedup can be obtained by using the proposed algorithm.	algorithm;coherence (physics);data structure;image quality;run-length encoding;scan line;speedup;texture splatting;volume rendering;voxel	Jiawan Zhang;Jizhou Sun;Zhigang Sun	2003		10.1007/3-540-44860-8_94	image quality;computer vision;data structure;computer hardware;computer science;programming language;run-length encoding;volume rendering;computer graphics (images)	Visualization	67.53152373412597	-51.39374381104726	82112
c8e4189fddfd0b9bfb87ae1a4698687effc04d47	breathing life into shape: capturing, modeling and animating 3d human breathing	3d shape;breathing animation;learning;statistical model;respiration;abt black;human body modeling	"""Modeling how the human body deforms during breathing is important for the realistic animation of lifelike 3D avatars. We learn a model of body shape deformations due to breathing for different breathing types and provide simple animation controls to render lifelike breathing regardless of body shape. We capture and align high-resolution 3D scans of 58 human subjects. We compute deviations from each subject's mean shape during breathing, and study the statistics of such shape changes for different genders, body shapes, and breathing types. We use the volume of the registered scans as a proxy for lung volume and learn a novel non-linear model relating volume and breathing type to 3D shape deformations and pose changes. We then augment a SCAPE body model so that body shape is determined by identity, pose, and the parameters of the breathing model. These parameters provide an intuitive interface with which animators can synthesize 3D human avatars with realistic breathing motions. We also develop a novel interface for animating breathing using a spirometer, which measures the changes in breathing volume of a """"breath actor""""."""	align (company);ct scan;image resolution;linear model;nonlinear system	Aggeliki Tsoli;Naureen Mahmood;Michael J. Black	2014	ACM Trans. Graph.	10.1145/2601097.2601225	statistical model;computer vision;simulation;respiration;mathematics;statistics	Graphics	59.35501679446364	-48.082700897574455	82388
2ee3f173a5bd5babb3747c3b4a0e60e71b0fbd54	adaptive color classification for structured light systems	structured light systems;face detection cameras surface texture image processing hardware robustness lighting reflectivity layout stereo vision;3d face scanner;image processing;crosstalk;reflectivity;ccd sensor data;digital camera;image classification;structured light;ccd sensor data adaptive color classification structured light systems high accuracy 3d models 3d face scanner color cross talk;layout;image colour analysis crosstalk face recognition image classification;surface texture;pattern detection;3d model;face recognition;image colour analysis;stereo vision;robustness;lighting;high accuracy 3d models;face detection;adaptive color classification;cameras;color cross talk;hardware	We present a system to capture high accuracy 3D models of faces by taking just one photo without the need of specialized hardware, just a consumer grade digital camera and beamer. The proposed 3D face scanner utilizes structured light techniques: A colored pattern is projected into the face of interest while a photo is taken. Then, the 3D geometry is calculated based on the distortions of the pattern detected in the face. This is performed by triangulating the pattern found in the captured image with the projected one.	3d modeling;algorithm;central processing unit;charge-coupled device;column (database);data striping;digital camera;distortion;dynamic programming;experiment;global optimization;high- and low-level;image resolution;mathematical optimization;multi-core processor;structured light;virtual reality	Philipp Fechteler;Peter Eisert	2008	2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops	10.1109/CVPRW.2008.4563048	facial recognition system;layout;surface finish;computer vision;contextual image classification;face detection;crosstalk;structured light;image processing;computer science;stereopsis;lighting;reflectivity;robustness;computer graphics (images)	Vision	55.297857244338864	-47.7787318021861	82535
4ca77ca0fd8a96df886f9cce6a17598442955744	anisotropic simplicial meshing using local convex functions	anisotropic meshing;locally convex triangulation	We present a novel method to generate high-quality simplicial meshes with specified anisotropy. Given a surface or volumetric domain equipped with a Riemannian metric that encodes the desired anisotropy, we transform the problem to one of functional approximation. We construct a convex function over each mesh simplex whose Hessian locally matches the Riemannian metric, and iteratively adapt vertex positions and mesh connectivity to minimize the difference between the target convex functions and their piecewise-linear interpolation over the mesh. Our method generalizes optimal Delaunay triangulation and leads to a simple and efficient algorithm. We demonstrate its quality and speed compared to state-of-the-art methods on a variety of domains and metrics.	algorithm;anisotropic filtering;approximation;convex function;delaunay triangulation;hessian;hybrid functional;linear interpolation	Xiao-Ming Fu;Yang Liu;John Snyder;Baining Guo	2014	ACM Trans. Graph.	10.1145/2661229.2661235	convex analysis;subderivative;mathematical optimization;topology;computer science;mathematics;geometry;proper convex function	Graphics	68.2845084856056	-44.10642299304363	82770
5d5b305e20afc151ec70e16cd6f719872f84d87e	real time pipeline profile extraction using recursive filtering and circle location	image sampling;3d model real time pipeline profile extraction circle location pipeline profiling tool pipe finding recursive gaussian filtering hough transform;random sampling;real time;recursive filters;pipelines filtering robot vision systems cameras inspection fiber lasers semiconductor lasers image edge detection laser modes laser theory;laser beam applications feature extraction recursive filters pipelines image sampling robot vision;3d model;robot vision;feature extraction;pipelines;hough transform;laser beam applications	This paper describes a pipeline profiling tool which uses a laser to build a 3D model of the inside of a pipe. A robot travels down the pipe finding the profile in real time using a laser and a camera. The laser is used to draw a line around the edge of the pipe; this line is then extracted from acquired images using recursive Gaussian filtering. Three methods were examined for fitting a circle to the profile, two variations of the Hough transform and a random sampling method. The random sampling method was found to he the most flexible and efficient. The extracted profile points were used to construct a 3D model of a pipe section. This model can be viewed using a model viewer written using OpenCL. Results are presented showing the systcm to bc effective and robust.	3d modeling;hough transform;model viewer;monte carlo method;opencl api;recursion (computer science);sampling (signal processing)	Martin J. Johnson	2003		10.1109/ICIP.2003.1247304	hough transform;sampling;computer vision;simulation;feature extraction;computer science;pipeline transport;computer graphics (images)	Robotics	58.82843993081297	-47.51095402846735	82771
a246757d0832b1ee39d8082393567cc744cf607c	panoramic views for virtual endoscopy	virtual endoscopy;interactive visualization;colon cancer	This paper describes a panoramic projection designed to increase the surface visibility during virtual endoscopies. The proposed projection renders five faces of a cubic viewing space into the plane in a continuous fashion. Using this real-time and interactive visualization technique as a screening method for colon cancer could lead to significantly shorter evaluation time. It avoids having to fly through the colon in both directions and prevents the occlusion of potential polyps behind haustral folds.		Bernhard Geiger;Christophe Chefd'Hotel;Sandra Sudarsky	2005	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/11566465_82	computer vision;simulation;interactive visualization;computer science;colorectal cancer;computer graphics (images)	Visualization	67.15262912480982	-48.820668762849046	82878
5aafad54910d98e35ba5fab040eb49282c475320	correction of thread position mismatch in high precision cnc sewing		Due to the elasticity of thread and tissue material, the stitches made by a computer program on a CNC sewing machine are shifted from their desired positions. The mismatch leads to a visually inferior appearance of the resulting thread pattern compared to the one intended by the manufacturer. This paper introduces a camera based inspection system that helps to find and evaluate the distortion vector for each individual stitch. These vectors can facilitate the automatic reprogramming of corrected stitch positions in the CNC sewing program to minimize the final distortion. An image processing pipeline is proposed, consisting of thread detection and model-based registration, finding an assignment of thread pixels and model stitch positions. The corresponding distortion vectors are computed for every individual stitch.	computer program;distortion;elasticity (data store);image processing;image stitching;pipeline (computing);pixel	Tarek Stiebel;Dieter Geller;Dorit Merhof	2018	2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA)	10.1109/ETFA.2018.8502541		Robotics	58.575345052177106	-48.7867748534665	83055
e21547dbda62e3736741b67dc7cb32e6bd18615f	a visibility-based automatic path generation method for virtual colonoscopy	navegacion;visibilite;visibilidad;computer graphics;generacion automatica;chemin virtuel;automatic generation;navigation;generation automatique;visibility;general methods;camino virtual;virtual colonoscopy;computational efficiency;data preprocessing;grafico computadora;infographie;virtual path	In virtual colonoscopy, it is crucial to generate the camera path rapidly and accurately. Most of the existing path generation methods are computationally expensive since they require a lengthy preprocessing step and the 3D positions of all path points should be generated. In this paper, we propose a visibility-based automatic path generation method by emulating the ray propagation through the conduit of the colon. The proposed method does not require any preliminary data preprocessing steps, and it also dramatically reduces the number of points needed to represent the camera path using control points. The result is a perceivable increase in computational efficiency and easier colon navigation with the same level of accuracy.	virtual colonoscopy	Jeongjin Lee;Moon Koo Kang;Yeong-Gil Shin	2006		10.1007/11784203_39	computer vision;navigation;simulation;fast path;visibility;computer science;data pre-processing;computer graphics;computer graphics (images)	NLP	61.81283334059342	-44.6537925316401	83067
3fa41e60003b24cd91ebe4548b2b3142eb1b9b6e	deepfocal: a method for direct focal length estimation	cameras calibration training estimation neural networks testing visualization;neural nets calibration cameras computational geometry convolution estimation theory image processing;deepfocal method camera calibration raw pixel intensities internet photo collections natural images deep convolutional neural network calibration grid coplanar circles orthogonal vanishing points geometric calibration objects single view focal length estimation image preprocessing direct focal length estimation;convolutional neural network focal length estimation camera calibration	Estimating the focal length of an image is an important preprocessing step for many applications. Despite this, existing methods for single-view focal length estimation are limited in that they require particular geometric calibration objects, such as orthogonal vanishing points, co-planar circles, or a calibration grid, to occur in the field of view. In this work, we explore the application of a deep convolutional neural network, trained on natural images obtained from Internet photo collections, to directly estimate the focal length using only raw pixel intensities as input features. We present quantitative results that demonstrate the ability of our technique to estimate the focal length with comparisons against several baseline methods, including an automatic method which uses orthogonal vanishing points.	artificial neural network;baseline (configuration management);convolutional neural network;focal (programming language);pixel;preprocessor	Scott Workman;Connor Greenwell;Menghua Zhai;Ryan Baltenberger;Nathan Jacobs	2015	2015 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2015.7351024	computer vision;computer science;machine learning;computer graphics (images)	Vision	56.061355687735215	-48.42068851552795	83097
e67c76d4d687b9edbb5d05212b30c840e1f3fa74	collision-free construction of animated feathers using implicit constraint surfaces	implicit surface;feathers;potential field;implicit surfaces;animation;offset surfaces;animated character	We present a scheme for constructing complex feather geometry suitable for feature animation. The key points of our approach include the use of a potential field derived from guide geometry and an implicit constraint surface to create nonpenetrating feather geometry. Our method is frame independent and produces visually smooth animation that is free from popping and other visual artifacts. We provide details of the implementation and examples of the technique applied to an animated character with several thousand feathers.	visual artifact	Andrew J. Weber;Galen Gornowicz	2009	ACM Trans. Graph.	10.1145/1516522.1516523	anime;computer vision;simulation;computer science;feather;computer graphics (images)	Graphics	66.43630122779868	-46.761337991441735	83249
6858036acb607af18e7eb93eba959c1ba4b3007a	a multiple view stereo benchmark for satellite imagery		The availability of public multiple view stereo benchmark datasets has been instrumental in enabling research to advance the state of the art in the field and to apply and customize methods to real-world problems. Until now, no public multiple view stereo benchmark dataset has been available for satellite imaging applications. In this work, we describe a public benchmark dataset for multiple view stereo applied to three-dimensional outdoor scene mapping using commercial satellite imagery. This dataset includes fifty Digital Globe WorldView-3 panchromatic and multispectral images of a 100 square kilometer area near San Fernando, Argentina. We also provide high-resolution airborne lidar ground truth data for a 20 square kilometer subset of this area and performance analysis software to assess accuracy and completeness metrics. We report initial results from available solutions using this benchmark data and encourage continued research by making this benchmark dataset publicly available to the research community.	airborne ranger;benchmark (computing);ground truth;image resolution;multispectral image	Marc Bosch;Zachary T. Kurtz;Shea Hagstrom;Myron Z. Brown	2016	2016 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)	10.1109/AIPR.2016.8010543	satellite imagery;kilometer;multispectral image;software;remote sensing;ground truth;benchmark (computing);lidar;computer vision;computer science;artificial intelligence;solid modeling	Vision	54.9178367677305	-44.85273843110148	83338
144ede5c270b04db3206d0cef7caf42f11b266ad	clipping of b-spline surface patches at surface curves	b spline surface		b-spline	I. Applegarth;D. Catley;I. Bradley	1988			topology;b-spline;clipping (audio);mathematics	Vision	66.11498047921883	-44.29991520954424	83384
e66120111a4b6d167c101a33a4970e97651e10f1	fine-scaled 3d geometry recovery from single rgb images				Jun Li	2018				Vision	60.90831489419913	-48.26464948308487	83543
48e99510d29bc988f77701a8873889382031ff92	precomputed ambient occlusion for character skins	low frequency;spherical harmonic;real time;hardware accelerator;linear functionals;expressive imagery;transfer function;state space;non realistic modeling;character animation	We present a single-pass hardware accelerated method to compute ambient occlusion values in real-time on dynamic character skins. Ambient occlusion at a point is the cosine weighted integral of the visibility function. Assuming the scene is enclosed in a spherical area source light, ambient occlusion corresponds to the amount of light that will reach each point. Unfortunately, computing ambient occlusion is time-consuming. It requires sampling the hemisphere around each point to determine visibility. Our method takes a data driven approach to approximating ambient occlusion in real-time. It builds a set of linear functions over several subsets of poses, then produces the ambient occlusion using a blend of these functions. Because we are using linear functions our output is smooth, fast to evaluate, and easy to implement in a vertex or fragment shader.	ambient occlusion;linear function;precomputation;real-time clock;sampling (signal processing);shader	Adam G. Kirk;Okan Arikan	2006		10.1145/1179849.1179979	character animation;computer vision;real-time computing;ambient space;hardware acceleration;computer science;state space;mathematics;geometry;transfer function;low frequency;spherical harmonics;computer graphics (images)	Vision	67.42676133134734	-47.28829970456995	83767
cd4a0d6416f83b09e78abad27bd9ebb9f6a7b948	animation through space and time based on a space deformation model	animation;free form deformation;deformable model	To animate deformable objects through time and space, a new technique that will be referred to as DOGMA is proposed here. It is well suited to animation for both interactive design and real-time visualization. The concept of animation primitives based on an extension to animation of the space deformation model is introduced. Animation primitives can be added to any geometrical modeller because they are independent of the underlying geometrical model of the animated objects. It encapsulates animation through space and time under a unique formalism. A local control of deformations both through space and time is easily specified. A direct manipulation of objects is provided. At any time, animated objects are continuously computed from their corresponding animation primitives. This dispenses with the necessity for major storage of the interpolation process. A fully interactive system offers an interactive environment which enables the user to animate deformable objects in real time.		Dominique Bechmann;Nicolas Dubreuil	1993	Journal of Visualization and Computer Animation	10.1002/vis.4340040305	anime;physically based animation;computer vision;simulation;computer facial animation;skeletal animation;computer science;artificial intelligence;interactive skeleton-driven simulation;computer animation;computer graphics (images)	Graphics	66.37407021372417	-47.236406047967826	83920
1331832e329e152cb0c1e1180002ad9e2ada9bbc	a robust method for analyzing the physical correctness of motion capture data	equations of multi rigid body s motion;motion capture data;satisfiability;robust optimization;robust method;physical correctness;human motion analysis;euler equation	The physical correctness of motion capture data is important for human motion analysis and athlete training. However, until now there is little work that wholly explores this problem of analyzing the physical correctness of motion capture data. In this paper, we carefully discuss this problem and solve two major issues in it. Firstly, a new form of Newton-Euler equations encoded by quaternions and Euler angles which are very fit for analyzing the motion capture data are proposed. Secondly, a robust optimization method is proposed to correct the motion capture data to satisfy the physical constraints. We demonstrate the advantage of our method with several experiments.	correctness (computer science);euler;experiment;kinesiology;mathematical optimization;motion capture;newton;robust optimization	Yi Wei;Shihong Xia;Dengming Zhu	2006		10.1145/1180495.1180563	mathematical optimization;robust optimization;simulation;computer science;theoretical computer science;motion field;euler equations;satisfiability	AI	60.96316829680217	-45.088874923825855	83962
8e2c5c88520ae8c567efb30073a529c9851adb9a	interactive wavelet-based image compression with arbitrary region preservation	software;wavelet transforms;image compression;teleradiology;wavelets	We have developed a software module which performs 2-D and 3-D image compression based on wavelet transforms. The compression is not losless, but the software allows the user to interactively determine the degree of compression (by viewing the results) and to interactively define specific regions of the image — of any size and shape — that ar to be preserved with maximum fidelity while the rest of the image is compressed (again, viewing the results). These capabilities may be of interest in applications such as teleradiology.	ar (unix);image compression;interactive media;interactivity;teleradiology;wavelet transform	Armando Manduca	1992	1992 14th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1117/12.131095	data compression;lossy compression;computer vision;image compression;computer science;lossless compression;multimedia;texture compression;computer graphics (images)	Visualization	65.75149238839595	-49.028421527809485	83993
a72e8f5af3dedcd5185d607408b498f729ab13fa	survey of image-based representations and compression techniques	image sampling;image coding;image coding rendering computer graphics layout information geometry solid modeling cameras computer graphics computational geometry image analysis image generation;image based modeling;three dimensional;computer graphic;image based rendering ibr;image sampling reviews rendering computer graphics image coding image representation;image representation;image based rendering;image based representations;rendering computer graphics;reviews;survey;image compression image based representations image based rendering three dimensional computer graphics 3d geometry 3d computer graphics geometric information implicit geometry correspondence explicit geometry accurate geometry approximate geometry 3d scene representation plenoptic sampling analysis view dependency geometric proxies;article;mage based modeling	In this paper, we survey the techniques for image-based rendering (IBR) and for compressing image-based representations. Unlike traditional three-dimensional (3-D) computer graphics, in which 3-D geometry of the scene is known, IBR techniques render novel views directly from input images. IBR techniques can be classified into three categories according to how much geometric information is used: rendering without geometry, rendering with implicit geometry (i.e., correspondence), and rendering with explicit geometry (either with approximate or accurate geometry). We discuss the characteristics of these categories and their representative techniques. IBR techniques demonstrate a surprising diverse range in their extent of use of images and geometry in representing 3-D scenes. We explore the issues in trading off the use of images and geometry by revisiting plenoptic-sampling analysis and the notions of view dependency and geometric proxies. Finally, we highlight compression techniques specifically designed for image-based representations. Such compression techniques are important in making IBR techniques practical.	approximation algorithm;computer graphics;data compression;image;image-based modeling and rendering;sampling (signal processing)	Harry Shum;Sing Bing Kang;Shing-Chow Chan	2003	IEEE Trans. Circuits Syst. Video Techn.	10.1109/TCSVT.2003.817360	three-dimensional space;computer vision;image-based modeling and rendering;computer science;theoretical computer science;computer graphics (images)	Graphics	62.19796518165626	-49.98679144580545	84077
e05a189948b5ea1363477328148d9d29e8438644	reconstruction of 3d lines from a single axial catadioptric image using cross-ratio	nonlinear programming;edge detection;computer vision;image reconstruction;nonlinear programming computer vision edge detection image reconstruction;nonlinear optimization 3d line reconstruction single axial catadioptric image vision systems noncentral axial catadioptric system line spacial reconstruction image points distance ratio cross ratio line localization;image reconstruction mirrors cameras geometry vectors noise calibration	It has been shown, in previous work, that the 3D position of a line can be reconstructed from a single image in vision systems that do not possess a single viewpoint. We present a new method that, in a non-central axial catadioptric system, can achieve line spacial reconstruction from 3 or more image points, given the distance ratio of 3 points in the line (a fair assumption in, for example, structured environment with repetitive architectural features). We use cross-ratio as an invariant to constrain the line localization and perform the reconstruction from a set of image points through non-linear optimization. Experimental results are presented.	autostereogram;linear programming;mathematical optimization;nonlinear programming;nonlinear system	Luis Perdigoto;Helder Araújo	2012	Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)		iterative reconstruction;computer vision;feature detection;edge detection;nonlinear programming;computer science;mathematics;geometry	Vision	53.95502489770389	-50.47364376429248	84284
0a569fc8ad25c03089d1f759a2b39cf32993965b	mandalas, screws, pears, and klein bottles	curva;art;geometrie solide;solid models;curves;computer graphics;geometria solidos;courbe;curve;arte;algorithme;algorithm;solid modeling;klein bottle;superficie;surface;surfaces;grafico computadora;computer art;infographie;solid geometry;algoritmo	The goal of this article is to present an informal introduction and tutorial on the production of aesthetically pleasing solid models. The article is intended for the nonmathematical reader interested in computer art. Simple generating formulas and recipes are included.	solid modeling	Clifford A. Pickover	1993	The Visual Computer	10.1007/BF01901726	solid geometry;calculus;mathematics;geometry;computer art;surface;algorithm	Graphics	67.11731242080076	-40.278709402853764	84325
af0e11c18b52bf8851d565547515903263038ae9	geometric algorithms for the intersection of curves and surfaces	modelizacion;proyeccion ortogonal;curva;concepcion asistida;computer aided design;generic algorithm;numerical technique;geometrie algorithmique;computer graphics;computational geometry;courbe;etude methode;estudio metodo;interseccion;curve;algorithme;modelisation;algorithm;equation implicite;numerical computation;equation parametrique;orthogonal projection;conception assistee;superficie;geometric algorithm;surface;geometria computacional;method study;linear equations;system of equations;intersection;modeling;grafico computadora;infographie;parametric curve;projection orthogonale;curves and surfaces;algoritmo	The problem of finding the intersection of curves and surfaces arises in numerous computer aided design applications. The methods generally used rely on iterative numerical techniques based on the solution of a set of non-linear equations. These systems of equations are generally local and need adequate starting points in order to yield convergent solutions. This article presents two general algorithms based on geometric considerations to find the intersections of C0 curves and surfaces. The first method can be applied when one object is defined by a parametric equation and the other by an implicit equation. The second method is based on a succession of orthogonal projections from one object to the other. The same algorithm can be applied to curves and surfaces. These methods are implemented in the general framework provided by dual kriging for parametric curve and surface modelling. Finally, the conjugate tangent approach can speed up considerably the algorithm by considering alternatively tangent lines or planes in the iterative process together with orthogonal projections.	algorithm	Anis Limaiem;François Trochu	1995	Computers & Graphics	10.1016/0097-8493(95)00009-2	system of linear equations;mathematical optimization;combinatorics;systems modeling;genetic algorithm;geometric design;parametric equation;computational geometry;computer aided design;intersection;mathematics;geometry;curve;linear equation;orthographic projection;computer graphics;surface	Graphics	67.77846549878385	-40.04888909697143	84762
0db558df71f1173b920cc6a8cff6adc0b0eb7050	ray-traced reflections in real-time using heuristic based hybrid rendering	reflexive surfaces real time ray traced reflections heuristic based hybrid rendering game engines cube maps screen space local reflections reflections effect simulation real time renderer pipeline real time frame rates;rendering computer graphics computer games digital simulation ray tracing;computer graphics;virtual environments;virtual environments rendering computer graphics real time systems cameras games ray tracing visualization;visualization;image generation;games;ray tracing;rendering computer graphics;parallel processing;cameras;real time systems	Game engines typically use cube maps or screen space local reflections for simulating reflections effects at the real-time renderer pipeline. While these techniques work in many situations, they cannot deal well with reflections of reflections, reflections from covered spaces, reflections from elements outside the screen space or reflections from elements that change its shape or position in real-time. In this paper, we present a method capable of creating true real-time ray-traced reflections by using a heuristic based method and a hybrid renderer. Our solution maintain real-time frame rates by selecting, for each frame, the best reflexive surfaces to ray trace, based on the user's point of view.	cube mapping;glossary of computer graphics;heuristic;map;ray tracing (graphics);real-time clock;real-time computing;real-time locating system;real-time transcription;reflection (computer graphics);simulation	Paulo Andrade;Thales Luis Sabino;Esteban Walter Gonzalez Clua;Paulo A. Pagliosa	2014	2014 Brazilian Symposium on Computer Games and Digital Entertainment	10.1109/SBGAMES.2014.34	games;parallel processing;ray tracing;simulation;visualization;3d rendering;rendering;computer science;multimedia;computer graphics;alternate frame rendering;computer graphics (images)	Embedded	64.79523885516869	-50.42157797949501	84765
03f6343d75234458e49ff975572dd2e0de1bf41c	sketching garments for virtual characters	virtual garment;virtual characters;distance field;video game;3d model;interactive system;sketch based interfaces;shape modeling;data structure	We present a method for simply and interactively creating basic garments for dressing virtual characters in applications like video games. The user draws an outline of the front or back of the garment, and the system makes reasonable geometric inferences about the overall shape of the garment (ignoring constraints arising from physics and from the material of the garment). Thus both the garment's shape and the way the character is wearing it are determined at once. We use the distance from the 2D garment silhouette to the character model to infer the variations of the distance between the remainder of the garment and the character in 3D. The garment surface is generated from the silhouette and border lines and this varying distance information, thanks to a data-structure that stores the distance field to the character's body. This method is integrated in an interactive system in which the user sketches the garment over the 3D model of the character. Our results show that the system can be used to create both standard clothes (skirts, shirts) and other garments that may be worn in a variety of ways (scarves, panchos).	data structure;distance transform;interactivity;outline (list)	Emmanuel Turquin;Marie-Paule Cani;John F. Hughes	2006		10.1145/1185657.1185781	simulation;data structure;computer science;distance transform;programming language;computer graphics (images)	Graphics	64.3356486651858	-47.260081474606544	84828
a6baa7e2f429c67fca513a29a54495454e9e892d	fast flow-based algorithm for creating density-equalizing map projections	cartography;computer graphics;data visualization;statistical analysis	Cartograms are maps that rescale geographic regions (e.g., countries, districts) such that their areas are proportional to quantitative demographic data (e.g., population size, gross domestic product). Unlike conventional bar or pie charts, cartograms can represent correctly which regions share common borders, resulting in insightful visualizations that can be the basis for further spatial statistical analysis. Computer programs can assist data scientists in preparing cartograms, but developing an algorithm that can quickly transform every coordinate on the map (including points that are not exactly on a border) while generating recognizable images has remained a challenge. Methods that translate the cartographic deformations into physics-inspired equations of motion have become popular, but solving these equations with sufficient accuracy can still take several minutes on current hardware. Here we introduce a flow-based algorithm whose equations of motion are numerically easier to solve compared with previous methods. The equations allow straightforward parallelization so that the calculation takes only a few seconds even for complex and detailed input. Despite the speedup, the proposed algorithm still keeps the advantages of previous techniques: With comparable quantitative measures of shape distortion, it accurately scales all areas, correctly fits the regions together, and generates a map projection for every point. We demonstrate the use of our algorithm with applications to the 2016 US election results, the gross domestic products of Indian states and Chinese provinces, and the spatial distribution of deaths in the London borough of Kensington and Chelsea between 2011 and 2014.	algorithm;cartography;cessation of life;chart;computer program;data science;distortion;fits;gross domestic product;inspiration function;map projection;musculoskeletal diseases;numerical analysis;parallel computing;preparation;projections and predictions;speedup	Michael T. Gastner;Vivien Seguy;Pratyush More	2018		10.1073/pnas.1712674115	equations of motion;spatial distribution;speedup;map projection;pie chart;distortion;algorithm;gross domestic product;cartogram;computer science	Graphics	68.06007115561802	-48.3486118619573	85057
49bb0c7a761d827ac23ce2e5dcf73e051de3947f	software tools and efficient algorithms for the feature detection, feature tracking, event localization, and visualization of large sets of atmospheric data			algorithm;feature detection (computer vision);feature detection (web development);formal specification;motion estimation	Sebastian Limbach	2013				Visualization	54.41239952912918	-43.876352599672366	85261
a4a2807ac27b841f98e2822fdf2be7d7988a9b2a	curvature-approximated estimation of real-time ambient occlusion	ambient occlusion;real time;curvature;for game	We present a novel technique for computing ambient occlusion (Akenine-Möller et al., 2008) on real-time graphics hardware. Our method approximates the occlusion for a local illumination model by introducing curvature-dependent function. Using our method, we are able to acquire occlusion at lower computational cost than conventional methods such as SSAO (Bavoil et al., 2008). Our method requires a multi-pass algorithm with the graphics processing unit (GPU). In the first pass curvature is acquired, and in the second pass the occlusion is computed from the curvature. In the calculating occlusion from the curvature, we approximate the geometric shape by a quadric surface function, and then obtain a curvature dependent function which is an approximation of geometric surface. This function depends only on local variables and we are able to calculate the ambient occlusion for the local illumination model. According to our results, both the computational and storage costs are sufficiently low for the technique to be applied to current graphics hardware supported computer games.	algorithmic efficiency;approximation algorithm;computation;computer graphics;graphics hardware;graphics processing unit;hidden surface determination;list of common shading algorithms;local variable;pc game;real-time clock;screen space ambient occlusion	Tomohito Hattori;Hiroyuki Kubo;Shigeo Morishima	2012			computer science;geometry;curvature;ambient occlusion	Graphics	65.97904015747287	-50.865648450380554	85280
470d23d0e8653d7554d7d03bcb92b4e83ad5739a	optimal camera pose and placement configuration for maximum field-of-view video stitching	image stitching;optimal camera placement;sensor planning	An optimal camera placement problem is investigated. The objective is to maximize the area of the field of view (FoV) of a stitched video obtained by stitching video streams from an array of cameras. The positions and poses of these cameras are restricted to a given set of selections. The camera array is designed to be placed inside the abdomen to support minimally invasive laparoscopic surgery. Hence, a few non-traditional requirements/constraints are imposed: Adjacent views are required to overlap to support image registration for seamless video stitching. The resulting effective FoV should be a contiguous region without any holes and should be a convex polygon. With these requirements, traditional camera placement algorithms cannot be directly applied to solve this problem. In this work, we show the complexity of this problem grows exponentially as a function of the problem size, and then present a greedy polynomial time heuristic solution that approximates well to the globally optimal solution. We present a new approach to directly evaluate the combined coverage area (area of FoV) as the union of a set of quadrilaterals. We also propose a graph-based approach to ensure the stitching requirement (overlap between adjacent views) is satisfied. We present a method to find a convex polygon with maximum area from a given polygon. Several design examples show that the proposed algorithm can achieve larger FoV area while using much less computing time.	analysis of algorithms;computation (action);field of view in video games;graph - visual representation;greedy algorithm;heuristic;image registration;image stitching;large;maxima and minima;polynomial;requirement;seamless3d;streaming media;surgical procedures, laparoscopic;time complexity;registration - actclass	Alex J. Watras;Jae-Jun Kim;Hewei Liu;Yu Hen Hu;Hongrui Jiang	2018		10.3390/s18072284	engineering;electronic engineering;computer vision;image stitching;field of view;artificial intelligence	Vision	57.173956692604825	-44.864237705325976	85365
1a2f6eee8622a36b7ae9b6bb806bf2b4b522b06d	topological reconstruction of complex 3d buildings and automatic extraction of levels of detail	i 3 5 computer graphics;boundary representations;computational geometry and object modeling	This paper describes a new method allowing to retrieve the indoor and outdoor topology of a detailed 3D building model from its geometry and to extract different levels of detail (LoD) from the resulting topological description. No prior information about the initial model, except its geometric information is needed as input, and using the combinatorial maps data structure, the method recovers the topological information of the identified parts of the building. The topology is needed for most of the applications using 3D building models after the architects design it. While classical models available are mainly furnished in a Boundary Representation (B-Rep) format, we discuss how to recover the components that allow to distinguish the several parts of the building (defined as volumes) then the spatial relationships linking them.	3d modeling;boundary representation;citygml;combinatorial map;data structure;geographic information system;industry foundation classes;interoperability;level of detail;semantics (computer science);simulation;subdivision surface	Abdoulaye A. Diakité;Guillaume Damiand;Dirk Van Maercke	2014		10.2312/udmv.20141074	computer vision;theoretical computer science;mathematics;geometry	Graphics	58.92174595903639	-45.213685352453815	85370
574ade9b974875e7ce43b5cdb84c3dea12a934fb	error estimation in reconstruction of quadratic curves in 3d space	gaussian noise;nonlinear least squares;collinearity equation;perspective projection;curve reconstruction;path planning;correspondence problem;imaging system;robot vision;simulation study;digital image;curve fitting;reconstruction algorithm;error estimate;analytic solution	Many natural and man-made objects have planar and curvilinear surfaces. The images of such curves do not usually have sufficient distinctive features to apply conventional feature-based reconstruction algorithms. In this paper, we describe a method for the reconstruction of various kinds of quadratic curves in 3D space as an intersection of two cones containing the respective projected digitized curve images in the presence of Gaussian noise. The advantage of this method is that it overcomes the correspondence problem that occurs in pairs of projections of the curve. Using nonlinear least-squares curve fitting, the parameters of a curve in 2D digitized image planes are determined. From this we reconstruct the 3D quadratic curve. Relevant mathematical formulations and analytical solutions for obtaining the equation of the reconstructed curve are given. Simulation studies have been conducted to observe the effect of noise on errors in the process of reconstruction. Results for various types of quadratic curves are presented using simulation studies. These are the main contributions of this work. The angle between the reconstructed and the original quadratic curves in 3D space has been used as the criterion for the measurement of the error. The results of this study are useful for the design of a stereo-based imaging system (such as the LBW decision in cricket, the path of a missile, robotic vision, path planning, etc.) and for the best reconstruction with minimum error.		Nagarajan Sukavanam;Balasubramanian Raman;Sanjeev Kumar	2007	Int. J. Comput. Math.	10.1080/00207160601176897	gaussian noise;computer vision;closed-form expression;mathematical optimization;perspective;collinearity equation;mathematics;geometry;motion planning;non-linear least squares;correspondence problem;digital image;statistics;curve fitting	Theory	55.21832682501975	-49.644004672613114	85394
c6eeecd6251ff37dbca0d35b81cafea83f92569f	a collision detection method with applications in cad systems for the apparel industry	computer aided design;interpolation;geometrie algorithmique;deteccion;simulation;computational geometry;detection;surface lisse;colision;smooth surface;apparel industry;collision detection;human body;industrie vetement;conception assistee;clothing;triangulation;vestidura;superficie lisa;collision;cartographie topologique;topological mapping;vetement	A novel approach to collision detection is developed and applied to the problem of collision detection with the human body in a material drape simulation system. The method is shown to compare favourably, both in terms of efficiency and ease of implementation, with a number of alternative strategies.	collision detection;computer-aided design	Helmut E. Bez;A. M. Bricis;J. Ascough	1996	Computer-Aided Design	10.1016/0010-4485(95)00032-1	human body;simulation;triangulation;computational geometry;interpolation;computer science;engineering;clothing;computer aided design;mathematics;geometry;engineering drawing;collision detection;collision	EDA	66.78718812370053	-39.58526509357198	85723
9566a06324c52d525013a7fca6a4273d4ae85690	performance relighting and reflectance transformation with time-multiplexed illumination	time varying;construccion arquitectura tecnologia ambiental;computacion informatica;compositing;environmental illumination;grupo de excelencia;engineering and technology;teknik och teknologier;ciencias basicas y experimentales;reflection model;reflectance models;optical flow;performance relighting and reflectance transformation with time multiplexed illumination;relighting;image based rendering;tecnologias;high speed;image warping	We present a technique for capturing an actor's live-action performance in such a way that the lighting and reflectance of the actor can be designed and modified in postproduction. Our approach is to illuminate the subject with a sequence of time-multiplexed basis lighting conditions, and to record these conditions with a high-speed video camera so that many conditions are recorded in the span of the desired output frame interval. We investigate several lighting bases for representing the sphere of incident illumination using a set of discrete LED light sources, and we estimate and compensate for subject motion using optical flow and image warping based on a set of tracking frames inserted into the lighting basis. To composite the illuminated performance into a new background, we include a time-multiplexed matte within the basis. We also show that the acquired data enables time-varying surface normals, albedo, and ambient occlusion to be estimated, which can be used to transform the actor's reflectance to produce both subtle and stylistic effects.	multiplexing	Andreas Wenger;Andrew Gardner;Chris Tchou;Jonas Unger;Tim Hawkins;Paul E. Debevec	2005	ACM Trans. Graph.	10.1145/1073204.1073258	image warping;computer vision;image-based modeling and rendering;computer science;optical flow;optics;compositing;image-based lighting;computer graphics (images)	Graphics	58.599327641212206	-50.711312461390015	85752
652382166950e0093bde6f3d9fc396f4611b77ac	octree textures on graphics hardware	implicit surface;graphics hardware;data access;data structure	We implement an interactive 3D painting application that stores paint in an octree-like GPU-based adaptive data structure. Interactive painting of complex or unparameterized surfaces is an important problem in the digital film community. Many models used in production environments are either difficult to parameterize or are unparameterized implicit surfaces. We address this problem with a system that allows interactive 3D painting of complex, unparameterized models. The included movie demonstrates interactive painting of a 817k polygon model (as shown in Figure 1) with effective paint resolutions varying between 643 to 20483. Our implementation differs from previous work [Benson and Davis 2002; Carr and Hart 2004; DeBry et al. 2002; Lefebvre et al. 2004] in two important ways: first, it uses an adaptive data structure implemented entirely on the GPU, and second, it enables interactive performance with high quality by supporting quadlinear (mipmapped) filtering and fast, constant-time data accesses.	carr–benkler wager;data structure;display resolution;graphics hardware;graphics processing unit;implicit surface;octree;polygon mesh	Joe Michael Kniss;Aaron E. Lefohn;Robert Strzodka;Shubhabrata Sengupta;John D. Owens	2005		10.1145/1187112.1187129	data access;vector graphics;graphics pipeline;parallel computing;2d computer graphics;data structure;computer hardware;computer science;real-time computer graphics;graphics software;sparse voxel octree;programming language;computer graphics;graphics address remapping table;graphics hardware;3d computer graphics;computer graphics (images)	Graphics	66.54310044765718	-50.841128748616406	85805
d50f81ce7d115db38c70d7da55484df9667a33fb	two dual representations of morphology based on the parallel normal transport property		A familiar way to describe shapes is through their behavior under the operations of mathematical morphology. In this paper we provide a quantitative analysis of the basic operation of mathematical morphology: dilation. This operation has the important property that it transports points such that normals to surfaces are preserved. As a consequence, straight lines are eigenfunctions of morphology. A representation of the objects on a basis of these eigenfunctions should clarify the basic operation (remember how the Fourier transform illuminates linear filtering!), and finding such representations is the subject of this paper.	mathematical morphology	Leo Dorst;Rein van den Boomgaard	1994		10.1007/978-94-011-1040-2_21	algorithm	HPC	65.24445769297286	-40.29602906162347	85838
3cca78b2ff72d6973e63a5bee5895149a4a01cb4	rendering geometry with relief textures	perspective projection;gpu;ray tracing;heightfield	We propose to render geometry using an image based representation. Geometric information is encoded by a texture with depth and rendered by rasterizing the bounding box geometry. For each resulting fragment, a shader computes the intersection of the corresponding ray with the geometry using pre-computed information to accelerate the computation. Our method is almost always artifact free even when zoomed in or at grazing angles. We integrate our algorithm with reverse perspective projection to represent a larger class of shapes. The extra texture requirement is small and the rendering cost is output sensitive, so our representation can be used to model many parts of a 3D scene. CR Categories: I.3.1 [Raytracing]; I.3.1 [Color, shading, shadowing, and texture];	3d projection;algorithm;computation;minimum bounding box;precomputation;rasterisation;ray tracing (graphics);shader;shading	Lionel Baboud;Xavier Décoret	2006		10.1145/1143079.1143112	ray tracing;computer vision;perspective;3d rendering;rendering;computer science;mathematics;geometry;computer graphics (images)	Graphics	66.42812172656606	-50.73015146953222	86024
6984fc58bd5719426ce3793686717e524df5b9c0	an image-based inexpensive 3d scanner	shape from silhouette;texture mapping;surface texture;image based modeling;shape from silhouettes;shape from photoconsistency;surface texture extraction;camera calibration	An image-based model reconstruction system is described. Real images of a rigid object acquired under a simple but controlled environment are used to recover the three dimensional geometry and the surface texture. Based on a multi-image calibration method, an algorithm to extract the rotation axis of a turn-table has been developed. Furthermore, this can be extended to estimate robustly the initial bounding volume of the object to be modeled. The coarse volume obtained, is then carved using a stereo correction method which removes the disadvantages of silhouette-based reconstruction by photoconsistency. The concept of surface particles is adapted in order to extract a texture map for the model. Some existing metrics are used to measure the quality of the reconstructed models.	3d film;3d reconstruction;3d scanner;algorithm;aliasing;apache axis;bounding volume;color;computer graphics;computer-aided design;daylight;embedded system;end system;end-to-end principle;graphics pipeline;image scanner;minimum bounding box;modeling language;polygonal modeling;reflections of signals on conducting lines;resultant;specular highlight;texture filtering;texture mapping;vrml;virtual reality;voxel;wire-frame model	Ulas Yilmaz;Adem Yasar Mülayim;Volkan Atalay	2003	Int. J. Image Graphics	10.1142/S0219467803000993	image texture;texture mapping;surface finish;computer vision;camera resectioning;computer science;computer graphics (images)	Vision	60.33846322030956	-50.56664283415049	86285
ff758be64951679ba16753cb55673244b3a3c9e5	visualising an egyptian artefact in 3d: comparing rti with laser scanning	reflectance transform imaging;laser scanning;3d surface normals;polynomial texture mapping	3D digital representations of an ancient Egyptian artefact were compared for their rendering of surface detail. Normals were generated by three methods: (1) point clouds from the Arius 3D colour scanner; (2) reflectance transform imaging (RTI); (3) photometric stereo. The latter two were constructed from sets of 64 digital images taken under directional lighting in a hemispherical dome. Analysis of the 3D surface normals of corresponding sections of each object indicated that the photometric stereo method produced the best resolution of spatial detail.	digital image;normal (geometry);photometric stereo;point cloud;polynomial texture mapping;surface detail;visual artifact	Lindsay W. MacDonald	2011			computer vision;geography;optics;computer graphics (images)	Vision	60.762384491981834	-50.84038636229974	86307
a9ac7ba631afddaddb02641c2688dd6bfc4b1b17	automatic texture atlas generation from trimmed nurbs models	piecewise linear;surface representation;automatic generation;3d model;parametric surface	A Texture Atlas is a two dimensional representation of a 3D model usable for paint systems or as a sewing pattern. The field of texture atlas generation from polygonal models has been well exploited in the recent years. The developed algorithms work on piecewise linear surface representations, but not on parametric surfaces like NURBS, that are still the main surface representation in CAD systems. If a texture atlas is generated from a triangulated NURBS model, the result cannot be edited further in a CAD system, since the separation into charts is not based on the separate NURBS patches of the original model. We present a method for automatic generation of a texture atlas directly from trimmed NURBS models, while preserving the original NURBS representation. The resulting texture atlas is build of several charts, each consisting of the original NURBS patches sewn together.	3d modeling;algorithm;approximation;chart;computer-aided design;distortion;non-uniform rational b-spline;opensg;piecewise linear continuation;texture atlas	Michael Guthe;Reinhard Klein	2003	Comput. Graph. Forum	10.1111/1467-8659.00693	computer vision;piecewise linear function;parametric surface;mathematics;geometry	Vision	66.55204041257267	-43.946659550779216	86855
025057f1557f09583f31bfe1f19af813086a0d60	editing soft shadows in a digital photograph	shadow editing;digital photograph shadow modification shadow edge modeling image based shadow editing tool graphics rendering;poisson solver;poisson solver shadow editing edges discontinuities sharpness gradient domain;image texture;development tool;sharpness;gradient domain;discontinuities;soft shadow;solid modelling image texture rendering computer graphics;edges;rendering computer graphics;lighting image segmentation computer graphics data mining layout pattern analysis machine intelligence photography digital filters kernel;algorithms computer graphics image enhancement image interpretation computer assisted photography signal processing computer assisted user computer interface;solid modelling	In this article, we develop tools for shadow modification in images where a shadowed region is characterized by soft boundaries with varying sharpness along the shadow edges. Modeling shadow edges presents an interesting challenge because they can vary from infinitely sharp edges for shadows produced by a point light source to extremely soft edges for shadows produced by large area light sources. We propose an entirely image-based shadow editing tool for a single-input image. This technique for modeling, editing, and rendering shadow edges in a photograph or a synthetic image lets users separate the shadow from the rest of the image and make arbitrary adjustments to its position, sharpness, and intensity. These machine-adjustable photographs can offer interactivity that might improve images' expressiveness and help us investigate the influence of boundary sharpness on the perception of object-to-object contact, as well as understand how humans assess shadows to estimate object height above a ground plane	digital photography;interactivity;shadow volume;synthetic data;photograph	Ankit Mohan;Jack Tumblin;Prasun Choudhury	2007	IEEE Computer Graphics and Applications	10.1109/MCG.2007.30	image texture;drop shadow;edge;computer vision;computer science;multimedia;shadow mapping;shadow volume;classification of discontinuities;computer graphics (images)	Graphics	64.42485428591174	-48.6288051783561	86864
2507e97389e72713ec14e9ff889d51a3836a1da7	an algorithm for hidden line elimination	computer aided design;man machine interaction;computer graphics;perspective view;displaying techniques;machine rendering of solids;three dimensional;computer graphic;plane faced objects;three dimensional representation;automatic drawing;man machine communication;hidden line elimination;back line recognition	The algorithm presented causes the elimination of hidden lines in the representation of a perspective view of concave and convex plane-faced objects on the picture plane. All the edges of the objects are considered sequentially, and all planes which hide every point of an edge are found. The computing time increases roughly as the square of the number of edges. The algorithm takes advantage of a reduced number of concave points and automatically recognizes if only one object with no concave points is considered. In this last case, the result is obtained in a much simpler way.	algorithm;concave function	R. Galimberti	1969	Commun. ACM	10.1145/362912.362921	three-dimensional space;computer vision;perspective;computer science;computer aided design;computer graphics;algorithm;computer graphics (images)	Theory	66.29070334677715	-49.74519154183601	87185
1ea507c53dad60e64e4a3d9a52fdefeca1498612	conformal slit mapping and its applications to brain surface parameterization	conformal map;surface parameterization;linear system;signal processing;surface model;cerebral cortex	We propose a method that computes a conformal mapping from a multiply connected mesh to the so-called slit domain, which consists of a canonical rectangle or disk in which 3D curved landmarks on the original surfaces are mapped to concentric or parallel lines in the slit domain. In this paper, we studied its application to brain surface parameterization. After cutting along some landmark curve features on surface models of the cerebral cortex, we obtain multiple connected domains. By computing exact harmonic one-forms, closed harmonic one-forms, and holomorphic one-forms, we are able to build a circular slit mapping that conformally maps the surface to an annulus with some concentric arcs and a rectangle with some slits. The whole algorithm is based on solving linear systems so it is very stable. In the slit domain parameterization results, the feature curves are either mapped to straight lines or concentric arcs. This representation is convenient for anatomical visualization, and may assist statistical comparisons of anatomy, surface-based registration and signal processing. Preliminary experimental results parameterizing various brain anatomical surfaces are presented.	algorithm;anatomic structures;brain implant;cerebral cortex;computation (action);computational anatomy;conformal dimension;discretization;embedded system;embedding;feature model;imagery;lateral computing;lateral thinking;linear system;matching;map;multiplication;preparation;signal processing;turing completeness;mapped	Yalin Wang;Xianfeng Gu;Tony F. Chan;Paul M. Thompson;Shing-Tung Yau	2008	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-540-85988-8_70	conformal map;combinatorics;topology;signal processing;mathematics;geometry;linear system	Robotics	67.8733496502471	-42.34364951184498	87544
6cc1f531d2eeeb934869b89f6fe92a0801346d2e	a machine vision system for inspecting bearings	charge coupled image sensors;watthour meters;bearing inspection;ccd camera;control systems;personal computer;application software;edge detection;frame grabber;automatic optical inspection;stepper motor;regression methods;inspection;charge coupled devices;edge detection watthour meters automatic optical inspection machine bearings computer vision hough transforms statistical analysis quality control;computer vision;manufacturing processes;statistical analysis;machine vision;electromechanical kwh meters;edge detection bearing inspection computer vision electromechanical kwh meters frame grabber stepper motor hough transform regression methods quality control;hough transforms;robustness;hough transform;machine vision needles inspection microcomputers robustness charge coupled devices control systems application software manufacturing processes charge coupled image sensors;machine bearings;product quality;quality control;microcomputers;needles	In this paper we describe a machine vision system for inspecting bearings, which are an important part of electro-mechanical kWh meters. The system consists of a personal computer with a frame grabber, a black and white progressive scan CCD camera, and a mechanical device with a stepper motor controlled by a special controller connected to the RS232 port of the personal computer. The quality of a bearing depends on the eccentricity of the needle and the length of the needle that extends out of the cylinder. These two parameters are robustly and accurately defined by the Hough transform and the regression methods. The presented results show that the proposed machine vision system allows accurate, reproducible, and robust 100% inspection of bearings of electro-mechanical kWh meters and as such it may be a valuable tool for ensuring highend-product quality.	charge-coupled device;cylinder seal;distance (graph theory);emoticon;frame grabber;hough transform;machine vision;maximal set;personal computer;progressive scan;rs-232	Joze Derganc;Franjo Pernus	2000		10.1109/ICPR.2000.903026	hough transform;embedded system;computer vision;quality control;application software;simulation;edge detection;inspection;machine vision;frame grabber;computer science;microcomputer;charge-coupled device;robustness	Vision	60.45111858168404	-40.01441554103461	87894
e62fc4b171f4fb1346cabc146f78a84daf76ef2a	kinect-derived augmentation of the real world for cultural heritage	history;cultural heritage;kalman filters;kinect;qa75 electronic computers computer science;rendering computer graphics augmented reality cameras history kalman filters pose estimation;cameras three dimensional displays calibration feature extraction solid modeling kalman filters cultural differences;pose estimation augmented reality kinect cultural heritage;augmented reality;rendering computer graphics;kalman filtering kinect derived real world augmentation kinect sensor augmented reality cultural heritage applications reliable camera pose estimation reliable camera location estimation perspective n point problem rendered view jittering;cameras;pose estimation	This paper explores the use of data from the Kinect sensor for performing augmented reality, with emphasis on cultural heritage applications. It is shown that the combination of depth and image correspondences from the Kinect can yield a reliable estimate of the location and pose of the camera using a recent solution to the Perspective-n-Point problem, though noise from the sensor introduces an unpleasant jittering of the rendered view. Kalman filtering of the camera position was found to yield a much more stable view. Results show that the system is accurate enough for in situ augmented reality applications for cultural heritage.	algorithm;ar (unix);augmented reality;desktop computer;glossary of computer graphics;kalman filter;kinect;perspective-n-point;regular expression	Erkan Bostanci;Nadia Kanwal;Adrian F. Clark	2013	2013 UKSim 15th International Conference on Computer Modelling and Simulation	10.1109/UKSim.2013.10	computer vision;augmented reality;simulation;geography;computer graphics (images)	Robotics	54.111519048898444	-45.59875138345113	88078
2eae4b79d36d9cf4fd1ec4de7d4c716e3fc970ea	metrology in uncalibrated images given one vanishing point	image processing;measurement;euclidean metric measurements uncalibrated images vanishing point metrology 3d euclidean measurements image planes geometric information reference plane camera intrinsic parameters;vanishing point;metrology cameras performance evaluation euclidean distance calibration layout computer science rendering computer graphics surveillance forensics;image processing measurement	In this paper, we describe how 3D Euclidean measurements can be made in a pair of uncalibrated images, when only minimal geometric information are available in the image planes. This minimal information consists of a line in a reference plane, and the vanishing point orthogonal to it. Given such limited information, we show that the length ratio of two objects perpendicular to the reference plane can be expressed as a function of the camera intrinsic parameters. Assuming that the camera intrinsic parameters remain invariant between two views, we perform Euclidean metric measurements directly in the perspective images.	camera resectioning;euclidean distance;line level;reference architecture;vanishing point	Hassan Foroosh;Xiaochun Cao;Murat Balci	2005	IEEE International Conference on Image Processing 2005	10.1109/ICIP.2005.1530403	computer vision;camera auto-calibration;vanishing point;image processing;mathematics;geometry;measurement	Vision	54.072968875421495	-50.90813172158678	88181
753332c17d2caba71b88ef343f5e664c38fea4c7	a practical image retouching method	computer graphics interpolation;interpolation;computer graphics;shape transformation;radial basis function;fast algorithm;imageinpainting;missing data;image inpainting;shape image restoration character generation image reconstruction space technology computer graphics surface reconstruction partial differential equations extrapolation;point of view;radial basis functions image retouching method space mapping technique surface retouching problem image inpainting shape transformation;space mapping;radial basis functions	In this paper, we present a novel fast algorithm for image retouching. A space-mapping technique is used to transform a missing (or damaged) part of a surface into a different shape in a continuous manner. Experimental results are included to demonstrate the feasibility of our approach. The proposed approach shows the obvious relationship between the surface retouching problem and image inpainting. We consider shape transformation as a general type of operation for restoring missing data, and attempt to approach the well-known problem of ”fulfillment” of damaged or missing areas from a single point of view, namely, that of the space mapping technique.	algorithm;cg (programming language);circuit restoration;computation;computer-aided design;data structure;inpainting;interactive media;interactivity;missing data;space mapping;whole earth 'lectronic link	Vladimir V. Savchenko;Nikita Kojekine;Hiroshi Unno	2002		10.1109/CW.2002.1180916	computer vision;mathematical optimization;radial basis function;computer science;machine learning;mathematics;geometry;statistics	Vision	65.63943679846331	-43.941581440948106	88213
ee290d05fd5bd9e57302e560a7ff1cb1bb136d4f	coherent and importance sampled lvc bdpt on the gpu	raytracing;graphics processors;parallel processing	Bidirectional path tracing (BDPT) can render highly realistic scenes with complicated lighting scenarios. The Light Vertex Cache (LVC) based BDPT method by Davidovic et al. [Davidovič et al. 2014] provided good performance on scenes with simple materials in a progressive rendering scenario. In this paper, we propose a new bidirectional path tracing formulation based on the LVC approach that handles scenes with complex, layered materials efficiently on the GPU. We achieve coherent material evaluation while conserving GPU memory requirements using sorting. We propose a modified method for selecting light vertices using the contribution importance which improves the image quality for a given amount of work. Progressive rendering can empower artists in the production pipeline to iterate and preview their work quickly. We hope the work presented here will enable the use of GPUs in the production pipeline with complex materials and complicated lighting scenarios.	coherent;graphics processing unit;image quality;iteration;lvcmos;path tracing;requirement;sorting	Srinath Ravichandran;P. J. Narayanan	2015		10.1145/2820903.2820913	parallel processing;ray tracing;computer vision;real-time computing;simulation;computer science;operating system;computer graphics (images)	Graphics	66.62977339163503	-51.60857310555474	88303
b5f2217d40c637099ac753ed7cd18bf6b9725b9b	a calibration method for paracatadioptric camera from sphere images	sphere images;antipodal sphere images;paracatadioptric camera calibration	For paracatadioptric camera, the estimation of intrinsic parameters from sphere images is still an open and challenging problem. In this paper, we propose a calibration method for paracatadioptric camera based on sphere images, which only requires that the projected contour of parabolic mirror is visible on the image plane in one view. We have found that, under central catadioptric camera, a sphere is projected to two conics on the image plane, which are defined as a pair of antipodal sphere images. The conic that is visible on the image plane is called the sphere image, while the other invisible conic is called the antipodal sphere image. In the other aspect, according to the image formation of central catadioptric camera, these two conics can also be considered as the projections of two parallel circles on the viewing sphere by a virtue camera. That is to say, if three pairs of antipodal sphere images are known, central catadioptric camera can be directly calibrated by the calibration method based on two parallel circles. Therefore, the problem of calibrating central catadioptric camera is transferred to the estimations of sphere images and their antipodal sphere images. Based on this idea, we first initialize the intrinsic parameters of the camera by the projected contour of parabolic mirror, and use them to initialize the antipodal sphere images. Next, we study properties of several pairs of antipodal sphere images under paracatadioptric camera. Then, these properties are used to optimize sphere images and their antipodal sphere images, so as to calibrate the paracatadioptric camera. Experimental results on both simulated and real image data have demonstrated the effectiveness of our method.		Huixian Duan;Yihong Wu	2012	Pattern Recognition Letters	10.1016/j.patrec.2011.12.012	computer vision;camera auto-calibration;mathematics;geometry	Vision	55.043853760312686	-50.4621557008684	88448
ae0f276133bdec6dcfa71de4fa642d9d8f3bac43	abstraction of man-made shapes	representation;ucl;building block;shape analysis;discovery;input shaping;theses;conference proceedings;surface reconstruction;three dimensional;approximation;conference paper;npr;digital web resources;ucl discovery;curve network;symmetry detection;open access;ucl library;mesh segmentation;geometric model;book chapters;open access repository;perception;shape description;virtual environment;vision;ucl research	Man-made objects are ubiquitous in the real world and in virtual environments. While such objects can be very detailed, capturing every small feature, they are often identified and characterized by a small set of defining curves. Compact, abstracted shape descriptions based on such curves are often visually more appealing than the original models, which can appear to be visually cluttered. We introduce a novel algorithm for abstracting three-dimensional geometric models using characteristic curves or contours as building blocks for the abstraction. Our method robustly handles models with poor connectivity, including the extreme cases of polygon soups, common in models of man-made objects taken from online repositories. In our algorithm, we use a two-step procedure that first approximates the input model using a manifold, closed  envelope  surface and then extracts from it a hierarchical abstraction curve network along with suitable normal information. The constructed curve networks form a compact, yet powerful, representation for the input shapes, retaining their key shape characteristics while discarding minor details and irregularities.		Ravish Mehra;Qingnan Zhou;Jeremy Long;Alla Sheffer;Amy Ashurst Gooch;Niloy Jyoti Mitra	2009	ACM Trans. Graph.	10.1145/1618452.1618483	three-dimensional space;vision;computer vision;surface reconstruction;computer science;virtual machine;artificial intelligence;theoretical computer science;geometric modeling;machine learning;approximation;shape analysis;mathematics;geometry;perception;representation;algorithm;computer graphics (images)	Graphics	59.168810874927516	-45.365532502289724	88490
a790e4f2ae8c52cac502cea922865b0a1c250489	using a four-dimensional mesh model to represent a tool motion trajectory in five-axis machining	four dimensional mesh model;five axis machining;spatiotemporal model;workpiece transformation		optic axis of a crystal	Hirotaka Kameyama;Ikuru Otomo;Masahiko Onosato;Fumiki Tanaka	2014	IJAT	10.20965/ijat.2014.p0437	computer vision;simulation;engineering;engineering drawing	Robotics	66.9736364651231	-42.19707877333537	88688
abe0b4f5c7a779987e8f0c7c1a6a670203471eed	framework for adaptive sampling of point-based surfaces using geometry and color attributes	modelizacion;distributed system;image tridimensionnelle;complex objects;metodo adaptativo;systeme reparti;informatique mobile;mobile device;realite virtuelle;realidad virtual;detail level;digitizing;point based rendering;echantillonnage;videojuego;virtual reality;methode adaptative;numerisation;video game;niveau detail;jeu video;sampling;modelisation;sistema repartido;level of detail;adaptive method;distributed virtual environment;adaptive sampling;tridimensional image;numerizacion;point cloud;jeu ordinateur;computer games;muestreo;mobile computing;imagen color;modeling;triangle mesh;image couleur;imagen tridimensional;computer game;color image;nivel detalle	Point-based rendering has offered a powerful alternative to triangle meshes when it comes to the rendering of highly complex objects consisting of densely sampled point clouds due to its flexibility and simplicity. The technological advance of 3D scanners has made it possible to acquire color as well as geometry data of highly complex objects. However, scanning and acquisition systems often produce surfaces that are much more dense than actually required for the intended application. Mobile devices, computer games and distributed virtual environments must often operate on systems where rendering and transmission capacity is highly constrained and therefore require strict control over the level of detail used in models. In this research, we present a framework for adaptive sampling of point-based surfaces using both geometry and color information.	3d scanner;adaptive sampling;level of detail;mobile operating system;pc game;point cloud;rendering (computer graphics);sampling (signal processing);triangle mesh;virtual reality	Duck Bong Kim;Eui Chul Kang;Kwan H. Lee;Renato Pajarola	2006		10.1007/11758525_50	sampling;computer vision;simulation;systems modeling;color image;computer science;operating system;triangle mesh;level of detail;point cloud;mobile device;virtual reality;mobile computing;computer graphics (images)	Graphics	62.35721979094907	-48.31823188800235	88732
aeabc4912b7e3092e20e6cde49c314ef9617b853	pseudorandom noise for real-time volumetric rendering of fire in a production system	real time;production system;categories and subject descriptors according to acm ccs i 3 7 computer graphics three dimensional graphics and realism	This paper presents an effort at developing a robust, interactive framework for rendering 3D fire in real-time in a production environment. Many techniques of rendering fire in non real-time exist and are constantly employed by the movie industry and have directly influenced and inspired real-time fire rendering, including this paper. Macrolevel behavior of fire is characterized by wind fields, temperature and moving sources and is currently processed on the CPU while micro-level behavior like turbulence, flickering, separation and shape is created on the graphics hardware. This framework provides a set of tools for level designers to wield artistic and behavioral control over fire as part of the scene. The resulting system is able to scale well, to use as few processor cycles as possible, and to efficiently integrate into an existing production environment. We present performance statistics and assess the feasibility of achieving interactive frame rates within a 3D engine framework. The framerates we obtained vary from 42 to 168 depending on the rendering conditions, and indicate that the real-time procedural fire might not be far away.	algorithm;bottleneck (software);central processing unit;deployment environment;flicker (screen);gradient noise;graphics hardware;irrlicht 3d engine;level design;pseudorandom noise;pseudorandom number generator;pseudorandomness;real-time locating system;real-time transcription;turbulence	Y. Vanzine;D. Vrajitoru	2008		10.2312/VG/VG-PBG08/129-136	tiled rendering;simulation;image-based modeling and rendering;rendering;engineering;multimedia;real-time rendering;alternate frame rendering;software rendering;computer graphics (images)	Graphics	64.39568153678327	-51.01532043238866	88765
0a6f071a844e163dfdc062dadeee113500fce2c0	sparse representation of deformable 3d organs	principal reconstruction basis;surface reconstruction algorithm design and analysis medical services biomedical equipment image reconstruction computational modeling analytical models deformable models sampling methods computed tomography;spherical harmonics;surface representation;storage complexity deformable 3d organ sparse representation parametric representation deformable object complex surface deformed 3d organ sequence deformed organ surface correlations principal representation basis principal reconstruction basis computational complexity;storage complexity;efficient algorithm;principal representation basis;spherical harmonic;surface reconstruction;deformable objects;parametric representation;deformation;theoretical analysis;computational complexity;three dimensional displays;image representation;image reconstruction;medical image processing;complex surface;dictionaries;mathematical model;deformable object;surface representation spherical harmonics deformation orthogonal subspace pursuit;medical application;deformable 3d organ sparse representation;medical image processing image reconstruction image representation;sampling strategy;sparse representation;deformed 3d organ sequence;algorithm design and analysis;orthogonal subspace pursuit;deformed organ surface correlations;harmonic analysis	Parametric representation of deformable object with complex surface has been a challenge in various medical applications for its demanding resource consumptions. This paper proposed an efficient algorithm to construct a compact basis for a sequence of deformed 3D organ, in which those surfaces can be sparsely represented with a small number of parameters. The key idea in this paper is to explore the correlations among the deformed surfaces of an organ and extract the principle basis for representation and reconstruction. Both theoretical analysis and extensive simulations verified that the presented algorithm yields a three-order magnitude reduction in computational and storage complexity relative to traditional approaches while maintaining high precision for surface reconstruction. The proposed algorithm can be used for organ deformation tracking and optimal sampling strategy design.	algorithm;computation;enriques–kodaira classification;sampling (signal processing);simulation;sparse approximation	Dan Wang;Ahmed H. Tewfik	2009	2009 IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2009.5193195	computer vision;mathematical optimization;computer science;harmonic analysis;mathematics;geometry;spherical harmonics	Vision	62.56367756691327	-43.46490605578075	88821
318c4c25d86511690cc5df7b041a6392e8cc4ea8	fashion-gen: the generative fashion dataset and challenge		We introduce a new dataset of 293,008 high definition (1360 x 1360 pixels) fashion images paired with item descriptions provided by professional stylists. Each item is photographed from a variety of angles. We provide baseline results on 1) high-resolution image generation, and 2) image generation conditioned on the given text descriptions. We invite the community to improve upon these baselines. In this paper we also outline the details of a challenge that we are launching based upon this dataset.	baseline (configuration management);glossary of computer graphics;image resolution;pixel	Negar Rostamzadeh;Seyedarian Hosseini;Thomas Boquet;Wojciech Stokowiec;Christian Jauvin;Christopher Joseph Pal	2018	CoRR		machine learning;artificial intelligence;generative grammar;mathematics;baseline (configuration management);pixel	NLP	55.45436683801834	-47.019877003350324	88895
4aab079346f7824dc982071ce948d0d7c73d3b5a	what can be seen in three dimensions with an uncalibrated stereo rig	three dimensions;three dimensional;three dimensional reconstruction	an Abstract. This paper addresses the problem of determining the kind of three-dimensional reconstructions that can be obtained from a binocular stereo rig for which no three-dimensional metric calibration data is available. The only information at our disposal is a set of pixel correspondences between the two retinas which we assume are obtained by some correlation technique or any other means. We show that even in this case some very rich non-metric reconstructions of the environment can nonetheless be obtained. Specifically we show that if we choose five arbitrary correspondences, then a unique (up to an arbitrary projective transformation) projective representation of the environment can be constructed which is relative to the five points in three-dimensional space which gave rise to the correspondences. We then show that if we choose only four arbitrary correspondences, then an affine representation of the environment can be constructed. This reconstruction is defined up to an arbitrary affine transformation and is relative to the four points in three-dimensional space which gave rise to the correspondences. The reconstructed scene also depends upon three arbitrary parameters and two scenes reconstructed from the same set of correspondences with two different sets of parameter values are related by a projective transformation. Our results indicate that computer vision may have been slightly overdoing it in trying at all costs to obtain metric information from images. Indeed, our past experience with the computation of such information has shown us that it is difficult to obtain, requiring awkward calibration procedures and special purpose patterns which are difficult if not impossible to use in natural environments with active vision systems. In fact it is not often the case that accurate metric information is necessary for robotics applications for example where relative information is usually all what is needed.	active vision;binocular vision;computation;computer vision;pixel;robotics	Olivier D. Faugeras	1992		10.1007/3-540-55426-2_61	three-dimensional space	Vision	54.916548651251624	-50.89547148598398	88963
28a0a3e25c171d1bc1aca211bac123d6237f9963	sports scene analysis and visualization from multiple-view video	sport;games;image analysis;layout;interpolation;augmented reality;calibration;displays;homography;shape;data visualization	We introduce methods for sports scene analysis and visualization from multiple videos captured with multiple cameras. As the scene analysis, we present a method for tracking multiple soccer players. Tracking is done by integrating the tracking data from all cameras, using the geometrical relationship between cameras called homography. Integrating information from all cameras enables stable tracking on the scene, where the tracking by a single camera often fails in the case of occlusion. We also present a method for free-viewpoint visualization of a soccer game as a technique for visualizing the soccer scene. The free-viewpoint image is synthesized by view interpolation between actual cameras near the virtual viewpoint at each frame. Such free-viewpoint video can also be presented in a system of augmented reality (AR) for immersive visualization of soccer matches	augmented reality;head-mounted display;hidden surface determination;homography (computer vision);interpolation	Hideo Saito;Naho Inamoto;Sachiko Iwase	2004	2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763)		computer vision;augmented reality;homography;interpolation;computer science;sport;multimedia;computer graphics (images)	Visualization	57.59367761870735	-50.1425856391966	89015
e0bf0ebc75e5001e2c7f6f7105ecd07c58db160f	generalized symmetry and its application to 3d shape generation	concepcion asistida;computer aided design;modele geometrique;modelo 3 dimensiones;generic algorithm;modele 3 dimensions;three dimensional model;three dimensional;symetrie;symmetry;sintesis imagen;line drawings;image synthesis;conception assistee;synthese image;simetria;computer simulation;geometrical model;modelo geometrico	A new method for easily and rapidly generating three-dimensional shapes from two-dimensional line-drawings is presented. This method is based on the generalized symmetry constraint. Generalized symmetry is an extended concept of threedimensional symmetry and its axis is a 3D smooth curve. This paper first develops the definition and constraint of generalized symmetry, and then describes an algorithm which generates the three-dimensional shape of an object from its linedrawing. The generation algorithm is extended to generate generalized cylindrical objects from line-drawings. Several experiments by computer simulation verify that the algorithm can generate three-dimensional shapes from line-drawings.	algorithm;apache axis;computer simulation;experiment	Toshimitsu Tanaka;Seiichiro Naito;Tokiichiro Takahashi	1989	The Visual Computer	10.1007/BF01901484	computer simulation;three-dimensional space;combinatorics;genetic algorithm;computer science;computer aided design;mathematics;geometry;symmetry;generalized forces	Robotics	66.19737106720763	-42.13229008483441	89175
2111ffa0b2530171518a5d89c4259726b660f339	fast visualisation and interactive design of deterministic fractals	interaction design	This paper describes an interactive software tool for the visualisation and the design of artistic fractal images. The software (called AttractOrAnalyst) implements a fast algorithm for the visualisation of basins of attraction of iterated function systems, many of which show fractal properties. It also presents an intuitive technique for fractal shape exploration. Interactive visualisation of fractals allows that parameter changes can be applied at run time. This enables real-time fractal animation. Moreover, an extended analysis of the discrete dynamical systems used to generate the fractal is possible. For a fast exploration of different fractal shapes, a procedure for the automatic generation of bifurcation sets, the generalizations of the Mandelbrot set, is implemented. This technique helps greatly in the design of fractal images. A number of application examples proves the usefulness of the approach, and the paper shows that, put into an interactive context, new applications of these fascinating objects become possible. The images presented show that the developed tool can be very useful for artistic work.	fractal;interactive design	Sven Banisch;Mateu Sbert	2008		10.2312/COMPAESTH/COMPAESTH08/017-024	simulation;theoretical computer science;mathematics;fractal compression;computer graphics (images)	Graphics	66.61534402128177	-47.49843163755506	89361
8678090ddd89adc20b91dec62dc02bb5f77e094c	melody extrapolation in gttm approach		We developed a melody-morphing method in which we input melodies A and B and not only interpolate but also extrapolate other melodies between those two melodies. This is done in a systematic order according to a certain numerical measure, based on the parameters which reflect the influential features of two input melodies. The main advantage of our method is that a time-span tree is used, which is acquired from the music surface using a music theory called Generative Theory of Tonal Music (GTTM). By using our defined primitive operations of time-span trees, we can manipulate melodies like numerical expressions.	extrapolation;interpolation;morphing;numerical analysis	Masatoshi Hamanaka;Keiji Hirata;Satoshi Tojo	2009			extrapolation;interpolation;machine learning;melody;music theory;artificial intelligence;mathematics;expression (mathematics);generative theory of tonal music	NLP	64.33405447035683	-45.49856949306662	89601
22f1a1427222014e345068abadb8878e776b9a9b	measurement of three dimensional eye position using image processing: a geometric approach	image sampling;eye;fick angles;image processing;cross correlation;video signal processing;signal sampling;position measurement image processing correlation iris image sampling signal sampling geometry coils testing sampling methods;rotation vectors;television applications;geometry;measurement system;video processing;testing;correlation methods;3d measurement systems;three dimensional;geometric approach;spherical shape;polar cross correlation method;pc based system;video equipment;coils;medical image processing;three dimensional eye position measurement;oculomotor;position measurement;eye projection;video processing three dimensional eye position measurement image processing geometric approach accurate measurement human oculomotor system 3d measurement systems video systems torsional component spherical shape polar cross correlation method eye geometry eye projection image plane rotation vectors oculomotor research fick angles pc based system;3 dimensional;image plane;neurophysiology eye position measurement biomedical measurement medical image processing correlation methods video equipment television applications video signal processing;neurophysiology;correlation;human oculomotor system;sampling methods;eye geometry;iris;torsional component;video systems;accurate measurement;biomedical measurement;oculomotor research	Accurate measurement of 3-dimensional eye position is an important tool in the study of the human oculomotor system. The expense and invasive nature of existing 3-dimensional measurement systems have prompted the development of video-based systems for eye position measurement. Most video systems use some variation of the polar cross correlation method, but this technique produces inaccurate results for the torsional component of eye position if the spherical shape of the eye is not taken into account. We have extended the polar cross correlation technique by considering eye geometry and developing the formulae required to determine the projection of the eye into the image plane for all eye positions. These formulae also allow the representation of 3-dimensional eye position in Fick-angles or as rotation vectors, which are commonly used in oculomotor research. >	image processing	Steven T. Moore;Thomas Haslwanter;Ian S. Curthoys;Stuart T. Smith	1994		10.1109/ICIP.1994.413351	three-dimensional space;computer vision;image processing;computer science;mathematics;neurophysiology;computer graphics (images)	Robotics	55.563792936635714	-48.86914877524594	89725
df5afae0d3a8b39a396a37be8276e3ab2f4497b3	lighting simulation of augmented outdoor scene based on a legacy photograph	i 3 3 computer graphics augmented reality illumination consistency;i 3 3 computer graphics;augmented reality;illumination consistency	Abstract#R##N##R##N#We propose a novel approach to simulate the illumination of augmented outdoor scene based on a legacy photograph. Unlike previous works which only take surface radiosity or lighting related prior information as the basis of illumination estimation, our method integrates both of these two items. By adopting spherical harmonics, we deduce a linear model with only six illumination parameters. The illumination of an outdoor scene is finally calculated by solving a linear least square problem with the color constraint of the sunlight and the skylight. A high quality environment map is then set up, leading to realistic rendering results. We also explore the problem of shadow casting between real and virtual objects without knowing the geometry of objects which cast shadows. An efficient method is proposed to project complex shadows (such as tree's shadows) on the ground of the real scene to the surface of the virtual object with texture mapping. Finally, we present an unified scheme for image composition of a real outdoor scene with virtual objects ensuring their illumination consistency and shadow consistency. Experiments demonstrate the effectiveness and flexibility of our method.	simulation	Guanyu Xing;Xuehong Zhou;Qunsheng Peng;Yanli Liu;Xueying Qin	2013	Comput. Graph. Forum	10.1111/cgf.12217	computer vision;augmented reality;simulation;computer science;global illumination;computer graphics (images)	Robotics	58.585474897054695	-51.87778770758586	89777
b456f892b7c8325f270c4e41f17f133f6fb45c52	the quantitative aspects of color quality rendering for memory colors			color	Karin Töpfer;Robert Cookingham	2000			rendering (computer graphics);computer vision;color balance;computer science;artificial intelligence	EDA	63.14791684572428	-50.8845162425328	89805
1c3e290e6d030a1fe620edd11de5516210f13657	registration of multiview point clouds for application to ship fabrication		Ship size is increasing and demand for high precision of the final product is growing, making accurate production of parts and precise assembly increasingly important. Three dimensional scanners can be used to measure the shape of a product, but multiple scanning is required to obtain the entire shape. There is no general method to merge multiview point clouds because registration results are highly sensitive to the point cloud characteristics. This paper proposes a method for registering point clouds along with target detection and improved overlap computation. The proposed method is applied to registration of multiview point clouds, with examples to show practical performance. It is expected that the proposed method can be used in ship fabrication, reducing cost and human effort.	point cloud	Dongho Yun;Sung-In Choi;Sunghan Kim;Kwang Hee Ko	2017	Graphical Models	10.1016/j.gmod.2017.02.001	computer vision;simulation	AI	59.74916144537619	-40.11807955957579	89840
056462a3d5a78362700cd964e5d0bae4a5a9f08b	polarization imaging reflectometry in the wild		We present a novel approach for on-site acquisition of surface reflectance for planar, spatially varying, isotropic samples in uncontrolled outdoor environments. Our method exploits the naturally occurring linear polarization of incident and reflected illumination for this purpose. By rotating a linear polarizing filter in front of a camera at three different orientations, we measure the polarization reflected off the sample and combine this information with multi-view analysis and inverse rendering in order to recover per-pixel, high resolution reflectance and surface normal maps. Specifically, we employ polarization imaging from two near orthogonal views close to the Brewster angle of incidence in order to maximize polarization cues for surface reflectance estimation. To the best of our knowledge, our method is the first to successfully extract a complete set of reflectance parameters with passive capture in completely uncontrolled outdoor settings. To this end, we analyze our approach under the general, but previously unstudied, case of incident partial linear polarization (due to the sky) in order to identify the strengths and weaknesses of the method under various outdoor conditions. We provide practical guidelines for on-site acquisition based on our analysis, and demonstrate high quality results with an entry level DSLR as well as a mobile phone.	brewster's angle;circular polarization;data acquisition;digital single-lens reflex camera;display resolution;expectation propagation;global illumination;image resolution;incidence matrix;linear polarization;map;mobile phone;normal (geometry);normal mapping;pixel;polarization (waves);polarizer;reflectometry;rendering (computer graphics);uncontrolled format string	Jérémy Rivière;Ilya Reshetouski;Luka Filipi;Abhijeet Ghosh	2017	ACM Trans. Graph.	10.1145/3130800.3130894	mathematics;artificial intelligence;polarizing filter;stokes parameters;computer vision;normal;brewster's angle;refractive index;polarization (waves);linear polarization;reflectometry	Graphics	58.76349370305327	-50.93837947567666	89855
e04b89d7ee3cd0975ebc02dae8dcf6630e94628b	automating the selection of standard parallels for conic map projections	conic map projections;lambert conic projection;albers conic projection;adaptive composite map projections;equidistant conic projection;standard parallels	Conic map projections are appropriate for mapping regions at medium and large scales with east–west extents at intermediate latitudes. Conic projections are appropriate for these cases because they show the mapped area with less distortion than other projections. In order to minimize the distortion of the mapped area, the two standard parallels of conic projections need to be selected carefully. Rules of thumb exist for placing the standard parallels based on the width-to-height ratio of the map. These rules of thumb are simple to apply, but do not result in maps with minimum distortion. There also exist more sophisticated methods that determine standard parallels such that distortion in the mapped area is minimized. These methods are computationally expensive and cannot be used for real-time web mapping and GIS applications where the projection is adjusted automatically to the displayed area. This article presents a polynomial model that quickly provides the standard parallels for the three most common conic map projections: the Albers equal-area, the Lambert conformal, and the equidistant conic projection. The model defines the standard parallels with polynomial expressions based on the spatial extent of the mapped area. The spatial extent is defined by the length of the mapped central meridian segment, the central latitude of the displayed area, and the width-to-height ratio of the map. The polynomial model was derived from 3825 maps—each with a different spatial extent and computationally determined standard parallels that minimize the mean scale distortion index. The resulting model is computationally simple and can be used for the automatic selection of the standard parallels of conic map projections in GIS software and web mapping applications. & 2016 Elsevier Ltd. All rights reserved.	analysis of algorithms;coefficient;distortion;gis applications;geographic information system;lambertian reflectance;map projection;nortel meridian;on the fly;parallels desktop for mac;polynomial;real-time locating system;real-time web;web mapping	Bojan Savric;Bernhard Jenny	2016	Computers & Geosciences	10.1016/j.cageo.2016.02.020	behrmann projection;mathematical optimization;mathematics;geometry;albers equal-area conic projection	AI	67.38052528874401	-48.78768932896168	89861
78b0697394ab73beb93b4cfcc07742c8bab1c86d	locally-weighted homographies for calibration of imaging systems	lens distortion locally weighted homographies imaging system calibration linear transformation multiple view geometry linear map projective planes homography based techniques pin hole camera calibration nonlinear homographies nonparametric homography technique nonlinear homography technique nonparametric estimation;cameras nonlinear distortion lenses calibration estimation transmission line matrix methods optimization;photographic lenses calibration cameras image sensors optical distortion	A homography is traditionally formulated as a linear transformation and is used in multiple-view geometry as a linear map between projective planes (or images). Analogous to the use of homography-based techniques to calibrate a pin-hole camera, non-linear homographies extend the pinhole camera model to deal with non-linearities such as lens distortion. In this work, we propose a novel non-parametric nonlinear homography technique. Unlike a parametric non-linear mapping that can have inherent biases, this technique automatically adjusts model complexity to account for non-linearities in observed data. With this technique, we demonstrate nonparametric estimation of lens distortion from a single calibration image. We evaluate this technique on real-world lenses and show that this technique can improve the stability of cameracalibration. Furthermore, the non-parametric nature of our technique allows rectification of arbitrary sources of lens distortion.	distortion;homography (computer vision);nonlinear system;pinhole camera model;rectifier	Pradeep Ranganathan;Edwin Olson	2014	2014 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2014.6942591	homography;computer vision;mathematics;geometry;optics	Robotics	55.00940281519567	-50.69689889347653	89963
ca3660fac24caddb028f4f332b6910f52d0870a6	real-time realistic illumination and shading of stratiform clouds	real time	Realistic rendering of clouds involves solving the complex interaction of light within the cloud and with its environment. Interactive methods achieve efficient cloud rendering by ignoring several lighting effects. However, these effects are visually important, and removing them strongly reduces realism. We present a novel approach for capturing the important effects of multiple anisotropic Mie scattering within cloud layers (i.e., stratiform clouds), and the inter-reflections between the ground and the cloud base under sun and sky illumination. Our model maps well to graphics hardware, enabling the real-time rendering of animated cloud skies over landscapes.	aerial photography;cloud computing;graphics hardware;interaction;interrupt storm;minimally invasive education;point of view (computer hardware company);real-time clock;real-time transcription;reflection (computer graphics);shading;xfig	Antoine Bouthors;Fabrice Neyret;Sylvain Lefebvre	2006		10.2312/NPH/NPH06/041-050	simulation;geography;rendering;remote sensing;computer graphics (images)	Graphics	64.20116044992324	-51.1467465318704	90033
66613f74634396fcd1a46cbef32c8d6a0f720d0b	self-adaptive polygon mesh reconstruction based on ball-pivoting algorithm	balance distribution;surface reconstruction;density self adaption;polygon mesh;ball pivoting algorithm;point cloud	Accurate polygon mesh reconstruction from point cloud data is a key technique in many application domains, such as reverse engineering, computer vision, industrial inspection, and pattern recognition. In this paper, we propose a new method for reconstructing the polygon mesh from point cloud data based on the ball-pivoting algorithm. The core idea of the proposed method is to determine a suitable radius of the pivoting ball according to the principles of density self-adaption and balance distribution, which will greatly improve the accuracy and efficiency of the polygon mesh reconstruction from point cloud data, especially from uneven point cloud data. The proposed method is evaluated and compared with other existing methods in the experiments with several real point cloud datasets. The experimental results show that the proposed method has good performance, and it is robust to the uneven distribution of point cloud.		Yi An;Peng Zhao;Zhuohan Li;Cheng Shao	2016	IJCAT	10.1504/IJCAT.2016.077790	polygon mesh;mathematical optimization;point in polygon;surface reconstruction;computer science;theoretical computer science;point cloud;engineering drawing	Vision	66.85987111715242	-43.6679345410443	90072
0d1bbc1f684d3754462b0cb7bd3f6b2f28fc45e5	an evaluation of open source surface reconstruction software for robotic applications	control engineering computing;image reconstruction;public domain software;robot vision;sensors;software packages;3d point clouds;3d sensors;open source software package usability;open source surface reconstruction software evaluation;polygonal map generation;robotic applications	With the raising popularity of 3D sensors in robotic applications, e.g., RGB-D cameras or laser scanners, the demand for fast and reliable methods for surface reconstruction from 3D point clouds increases. Currently, several freely available implementations of such algorithms exist. This paper presents an evaluation of the usability of different open source software packages for polygonal map generation in robotic contexts.	algorithm;alpha shape;correctness (computer science);experiment;image noise;marching cubes;meshlab;open-source software;point cloud;robot operating system;run time (program lifecycle phase);scalability;sensor;usability	Thomas Wiemann;Hendrik Annuth;Kai Lingemann;Joachim Hertzberg	2013	2013 16th International Conference on Advanced Robotics (ICAR)	10.1109/ICAR.2013.6766566	iterative reconstruction;embedded system;simulation;surface reconstruction;engineering;sensor;public domain software;computer graphics (images)	Robotics	55.935081213337	-44.66662690923991	90173
f6b796806d099900519d4b2087f01e96165e0c26	reconstructing multiresolution mesh for web visualization based on pde resampling	surface modeling;partial differential equations;3d reconstruction;web visualization;surface approximation	Various Partial Differential Equations (PDEs) have been used in computer graphics for approximating surfaces of geometric shapes by finding solutions to PDEs, subject to suitable boundary conditions. The PDE boundary conditions are defined as 3D curves on surfaces of the shapes. We propose how to automatically derive these curves from the surface of the original polygon mesh. Analytic solutions to the PDEs used throughout this work are fully determined by finding a set of coefficients associated with parametric functions according to the particular set of boundary conditions. When large polygon meshes are used, the PDE coefficients require an order of magnitude smaller space compared to the original polygon data and can be interactively rendered with different levels of detail. It allows for an efficient exchange of the PDE shapes in 3D Cyberworlds and their web visualization. In this paper we analyze and formulate the requirements for extracting suitable boundary conditions, describe the algorithm for the automatic deriving of the boundary curves, and present its implementation as a part of the function-based extension of VRML and X3D.		Ming-Yong Pang;Yun Sheng;Alexei Sourin;Gabriela González Castro;Hassan Ugail	2011	Trans. Computational Science	10.1007/978-3-642-22336-5_3	mathematical optimization;discrete mathematics;mathematics;geometry;pde surface	Visualization	67.9207379126684	-45.689435249933986	90514
e07706b214ae760725544303a5e9e117d6627c11	glift: an abstraction for generic, efficient gpu data structures	distributed computing;ray tracing;out of core rendering;real time rendering;complex models	Recent work in shading languages and programming models for graphics hardware has given graphics processor (GPU) programmers effective abstractions for expressing computation. However, no comparable abstraction properly expresses the equally important task of data storage and access. This paper presents programmable address translation as a powerful abstraction for defining complex, point-indexable GPU data structures. This abstraction enables GPU programmers to separate algorithm and data structure definitions, greatly simplifying algorithmic development and enabling reusable and interchangeable data structures. We characterize a large body of previously published GPU data structures in terms of our abstraction and define the basic operations that these high-performance structures must support. We also present Glift, a generic template library implementation of the abstraction. We demonstrate the use of Glift in simple examples, and describe two applications not previously possible on GPUs due to the complexity of the required data structures: adaptive shadow maps and octree 3D textures. Lastly, we show that our example Glift data structures perform comparably to or better than handwritten implementations while requiring only a fraction of the programming effort. CR Categories: I.3.1 [Computer Graphics]: Methodology and Techniques—Graphics data structures and data types; I.3.1 [Computer Graphics]: Hardware Architecture—Graphics processors	algorithm;central processing unit;computation;computer data storage;computer graphics;data structure;graphics hardware;graphics processing unit;map;octree;programmer;shading language;shadow mapping	Aaron E. Lefohn	2005		10.1145/1198555.1198777	ray tracing;computer architecture;real-time computing;rendering;computer science;real-time rendering;computer graphics (images)	Graphics	67.63757333773096	-51.274943192083555	90642
9b4f82ab6200cf1f8ecfd9cbb0904df81c61ebd7	development of computed 3d imaging system form a few projections	3d imaging		3d reconstruction;stereoscopy	Norio Tamaya;Haiqing Du;Masahiro Daibo;Tatuo Hasegawa;Tomeo Minamihaha;Hiroaki Kurita;Yoshitaka Tunekawa;Kyosiro Seki	1999				ML	60.7227676488704	-47.6747104272257	91049
729a208cee24e7cd8bb73f2d4935d605bdc57af8	gnss/ins aided precise re-photographing	geophysical image processing;photogrammetry;ins;gnss;inertial navigation system gnss aided precise re photographing ins aided precise re photographing image acquisition change visualization evolution visualization visual methods image cues positioning sensors global navigation satellite system;inertial navigation;data visualisation;satellite navigation;cameras global navigation satellite systems accuracy receivers sensors real time systems buildings;re photographing;bundle block adjustment;satellite navigation data visualisation geophysical image processing inertial navigation;bundle block adjustment re photographing photogrammetry gnss ins	Re-photographing is a well-established method of acquiring new images in the same location where old photos were taken, in order to visualize changes and evolutions of the analyzed scene. According to the goal of the re-photographing procedure, different techniques can be employed, mainly based on visual methods, image cues or positioning sensors. The paper, after a review of the re-photographing procedures and techniques, presents a GNSS/INS aided method to achieve precise re-photographing results. Architectural and natural scenarios are used to test the developed method.	aerial photography;fractal antenna;geodetic datum;image sensor;photogrammetry;plug-in (computing);real time kinematic;satellite navigation;sensor;unmanned aerial vehicle	Erica Nocerino;Fabio Menna;Fabio Remondino	2012	2012 18th International Conference on Virtual Systems and Multimedia	10.1109/VSMM.2012.6365930	air navigation;computer vision;satellite navigation;gnss augmentation;computer science;gnss applications;inertial navigation system;data visualization;photogrammetry	Robotics	57.452629062417614	-44.48978370151677	91518
d9f361db083be871453edc26d0849ea9cfaa6af4	rendering (complex) algebraic surfaces	algebraic surfaces	The traditional ray-tracing technique based on a ray-surface intersection is reduced to a surface-surface intersection problem. At the core of every ray-tracing program is the fundamental question of detecting the intersecting point(s) of a ray and a surface. Usually, these applications involve computation and manipulation of non-linear algebraic primitives, where these primitives are represented using real numbers and polynomial equations. But the fast algorithms used for real polynomial surfaces are not useful to render complex polynomials. In this paper, we propose to extend the traditional ray-tracing technique to detect the intersecting points of a ray and complex polynomials. Each polynomial equation with some complex coefficients are called complex polynomials. We use a root finder algorithm based on interval arithmetic which computes verified enclosures of the roots of a complex polynomial by enclosing the zeros in narrow bounds. We also propose a new procedure to render real or complex polynomials in the real and the complex space. If we want to render a surface in the complex space, the algorithm must detect all real and complex roots. The color of a pixel will be calculated with those roots with an argument inside a selected complex space and minimum magnitude of the complex roots.	coefficient;computation;interval arithmetic;linear algebra;nonlinear system;pixel;polynomial;ray tracing (graphics);root-finding algorithm;sensor;sturm's theorem;time complexity	Juan Francisco Sanjuan-Estrada;Leocadio G. Casado;Inmaculada García	2006			computer science;algebraic surface;function field of an algebraic variety	Theory	67.46705906269604	-41.970829912660065	91545
09717bd8ee9e0a883670db0ce6fc86c8e65b9b96	a generic framework for the structured abstraction of images		Structural properties are important clues for non-photorealistic representations of digital images. Therefore, image analysis tools have been intensively used either to produce stroke-based renderings or to yield abstractions of images. In this work, we propose to use a hierarchical and geometrical image representation, called a topographic map, made of shapes organized in a tree structure. There are two main advantages of this analysis tool. Firstly, it is able to deal with all scales, so that every shape of the input image is represented. Secondly, it accounts for the inclusion properties within the image. By iteratively performing simple local operations on the shapes (removal, rotation, scaling, replacement...), we are able to generate abstract renderings of digital photographs ranging from geometrical abstraction and painting-like effects to style transfer, using the same framework. In particular, results show that it is possible to create abstract images evoking Malevitchs Suprematist school, while remaining grounded in the structure of digital images, by replacing all the shapes in the tree by simple geometric shapes.	digital image;digital photography;graphical user interface;image analysis;image scaling;jean;non-photorealistic rendering;topography;tree structure	Noura Faraj;Gui-Song Xia;Julie Delon;Yann Gousseau	2017		10.1145/3092919.3092930	computer vision;rendering (computer graphics);computer graphics (images);image processing;artificial intelligence;digital image;scaling;tree structure;computer science;geometric shape;non-photorealistic rendering;topographic map	Graphics	65.06982030249793	-47.1028990238023	91661
32b2237e9cdd3cf109dca9a9a07b6d6911fef680	interactive rendering of suggestive contours with temporal coherence	non photorealistic rendering;real time;differential geometry;line drawings;graphics hardware;interactive rendering;contours;silhouettes;temporal coherence;general line	Line drawings can convey shape using remarkably minimal visual content. Suggestive contours, which are lines drawn at certain types of view-dependent surface inflections, were proposed recently as a way of improving the effectiveness of computer-generated line drawings. This paper extends previous work on static suggestive contours to dynamic and real-time settings. We analyze movement of suggestive contours with respect to changes in viewpoint, and offer techniques for improving the quality of strokes rendered for a moving camera. We describe practical algorithms for rendering drawings with contours and suggestive contours at interactive rates. Finally, we discuss techniques for improving the visual appearance of suggestive contours, in both the static and dynamic cases.	coherence (physics);computer-generated holography;line drawing algorithm;real-time clock	Douglas DeCarlo;Adam Finkelstein;Szymon Rusinkiewicz	2004		10.1145/987657.987661	differential geometry;computer vision;computer science;non-photorealistic rendering;multimedia;graphics hardware;computer graphics (images)	Graphics	63.90915367338088	-48.9103674738452	91922
fcc4ad1dc9877bc70e1e4a1720597ca265b0e5ef	multiple view reconstruction of calibrated images using singular value decomposition	singular value decomposition;multiple views;computer vision;pattern recognition;camera network;coordinate system	Calibration in a multi camera network has widely been studied for over several years starting from the earlier days of photogrammetry. Many authors have presented several calibration algorithms with their relative advantages and disadvantages. In a stereovision system, multiple view reconstruction is a challenging task. However, the total computational procedure in detail has not been presented before. Here in this work, we are dealing with the problem that, when a world coordinate point is fixed in space, image coordinates of that 3D point vary for different camera positions and orientations. In computer vision aspect, this situation is undesirable. That is, the system has to be designed in such a way that image coordinate of the world coordinate point will be fixed irrespective of the position & orientation of the cameras. We have done it in an elegant fashion. Firstly, camera parameters are calculated in its local coordinate system. Then, we use global coordinate data to transfer all local coordinate data of stereo cameras into same global coordinate system, so that we can register everything into this global coordinate system. After all the transformations, when the image coordinate of the world coordinate point is calculated, it gives same coordinate value for all camera positions & orientations. That is, the whole system is calibrated.	algorithm;calibration (statistics);computation;computer vision;photogrammetry;singular value decomposition;stereo cameras;stereopsis	Ayan Chaudhury;Abhishek Gupta;Sumita Manna;Subhadeep Mukherjee;Amlan Chakrabarti	2010	CoRR		coordinate descent;computer vision;simulation;coordinate space;affine coordinate system;computer science;coordinate system;pattern recognition;mathematics;geometry;singular value decomposition	Vision	54.34319707399579	-49.990967816484485	92132
c07bee4f972aeb7033fdc5986feaf47cf357aac8	an interactive approach to analytical relief shading		The software currently available for analytical relief shading does not generally permit local adaptations of the light direction, the simulation of aerial perspective, and other necessary techniques developed for manual relief shading. To remedy this deficiency, a program for computer-assisted relief shading has been developed that allows users to locally adapt shading characteristics, permitting seamless interactive control over the entire process. The grey values of the image are determined by a combination of aspect-based shading for steep regions, diffuse reflection for lowlands, and a bright grey tone for flat areas. Furthermore, an algorithm for the simulation of aerial perspective is presented. Tests with the program have shown that, with minimal investment of time, the quality of analytically produced shaded relief can be improved significantly. Using the proposed techniques and software presented herein, experienced cartographers can transfer their manual relief-shading knowledge and experience ...	shading;terrain cartography	Bernhard Jenny	2001	Cartographica	10.3138/F722-0825-3142-HW05	computer vision;geography;computer graphics (images)	Vision	64.47176930429956	-48.455497175981044	92290
5b2d13b6d5f17841ef6ea4560be258a05965e9b5	an architecture for interactive tetrahedral volume rendering	volume rendering	We present a new architecture for interactive unstructured volume rendering. Our system moves all the computations necessary for order-independent transparency and volume scan conversion from the CPU to the graphics hardware, and it makes a software sorting pass unnecessary. It therefore provides the same advantages for volume data that triangle-processing hardware provides for surfaces. To address a remaining bottleneck – the bandwidth between main memory and the graphics processor – we introduce two new primitives, tetrahedral strips and tetrahedral fans. These primitives allow performance improvements in rendering tetrahedral meshes similar to the improvements triangle strips and fans allow in rendering triangle meshes. We provide new techniques for generating tetrahedral strips that achieve, on the average, strip lengths of 17 on representative datasets. The combined effect of our architecture and new primitives is a 72 to 85 times increase in performance over triangle graphics hardware approaches. These improvements make it possible to use volumetric tetrahedral meshes in interactive applications.	algorithm;application programming interface;central processing unit;colour banding;computation;computer data storage;graphics hardware;graphics processing unit;heuristic (computer science);linear approximation;linear interpolation;microcode;order-independent transparency;pc bruno;pixel;reactor (software);strips;sampling (signal processing);sierpinski triangle;sorting;texture mapping;triangle mesh;triangle strip;unstructured grid;volume rendering;volumetric display	Davis King;Craig M. Wittenbrink;Hans J. Wolters	2001		10.2312/VG/VG01/163-181	3d rendering	Graphics	67.93136457490486	-51.14415128250243	92572
29334c30f576716e5567ebdfedab5b5c0655620e	internal constraints of the trifocal tensor	fundamental matrix;epipolar geometry;pattern recognition;reconstruction algorithm	The fundamental matrix and trifocal tensor are convenient algebraic representations of the epipolar geometry of two and three view configurations, respectively. The estimation of these entities is central to most reconstruction algorithms, and a solid understanding of their properties and constraints is therefore very important. The fundamental matrix has 1 internal constraint which is well understood, whereas the trifocal tensor has 8 independent algebraic constraints. The internal tensor constraints can be represented in many ways, although there is only one minimal and sufficient set of 8 constraints known. In this paper, we derive a second set of minimal and sufficient constraints that is simpler. We also show how this can be used in a new parameterization of the trifocal tensor. We hope that this increased understanding of the internal constraints may lead to improved algorithms for estimating the trifocal tensor, although the primary contribution is an improved theoretical understanding.	algorithm;entity;epipolar geometry;fundamental matrix (computer vision);jan dietz;line level;linear algebra;outer product;trifocal tensor;whole earth 'lectronic link	Stuart B. Heinrich;Wesley E. Snyder	2011	CoRR		computer vision;mathematical optimization;topology;computer science;pattern recognition;mathematics;geometry;fundamental matrix;trifocal tensor;epipolar geometry	ML	54.1850089267021	-51.355218367108414	92641
1c823f6d7e9daf900aaab12332136c6c6d37a5df	cullide: interactive collision detection between complex models in large environments using graphics hardware	multi pass rendering;moving object;simplification;rendering systems;procedural shading;hardware systems;reflectance shading models;gpu computing;navier stokes;conjugate gradient;collision detection;level of detail;graphics hardware;interactive rendering;linear time;multigrid;mesh smoothing;fluid simulation;computer games;languages;numerical simulation	We present a novel approach for collision detection between multiple deformable and breakable objects in a large environment using graphics hardware. Our algorithm takes into account low bandwidth to and from the graphics cards and computes a potentially colliding set (PCS) using visibility queries. It involves no precomputation and proceeds in multiple stages: PCS computation at an object level and PCS computation at sub-object level, followed by exact collision detection. We use a linear time two-pass rendering algorithm to compute each PCS efficiently. The overall approach makes no assumption about the input primitives or the object's motion and is directly applicable to all triangulated models. It has been implemented on a PC with NVIDIA GeForce FX 5800 Ultra graphics card and applied to different environments composed of a high number of moving objects with tens of thousands of triangles. It is able to compute all the overlapping primitives up to image-space resolution in a few milliseconds.	algorithm;collision detection;computation;geforce fx series;graphics hardware;nokia 5800 xpressmusic;pc-fx;polygon triangulation;precomputation;time complexity;video card	Naga K. Govindaraju;Stéphane Redon;Ming C. Lin;Dinesh Manocha	2003		10.1145/1198555.1198785	computer simulation;fluid simulation;time complexity;computer vision;real-time computing;simulation;computer science;theoretical computer science;operating system;level of detail;conjugate gradient method;graphics hardware;collision detection;simplification;general-purpose computing on graphics processing units;multigrid method;computer graphics (images)	Graphics	66.6698512002578	-51.2891950244398	92679
50a495f4d4ed50c97ab0b210915ec0d0f384addc	recognizing shape features in solid models	modelizacion;concepcion asistida;computer aided design;detection forme;geometrie solide;feature recognition;computer graphics;espacio 3 dimensiones;geometria solidos;shape detection;graph matching;feature interaction;modelisation;b rep subgraphs shape features recognition graph matching 3 d solid models topology geometry feature recognition;deteccion forma;shape solid modeling application software machining data mining geometry manufacturing thin wall structures computer graphics wool;espace 3 dimensions;solid modeling;three dimensional space;conception assistee;modeling;grafico computadora;infographie;solid geometry;solid modelling	A procedure for defining and recognizing shape features 3-D solid models is presented in which a shape feature is defined as a single face or a set of continuous faces possessing certain characteristic facts in topology and geometry. The system automatically extracts these facts from an example shape feature interactively indicated by the user. The resulting representation of the shape feature can be interactively edited and parameterized. Graph matching accomplishes feature recognition. The system searches the solid model for B-rep subgraphs with the same characteristic facts as the shape feature to be recognized. When the system recognizes a shape feature, it removes the geometry associated with the feature from the original solid model to produce a simpler solid model. It then examines the simpler solid model to determine whether additional features have been revealed. The process repeats until no additional features are found.<<ETX>>	feature recognition;interactivity;matching (graph theory);solid modeling	Hiroshi Sakurai;David C. Gossard	1990	IEEE Computer Graphics and Applications	10.1109/38.59033	active shape model;feature recognition;three-dimensional space;computer vision;systems modeling;heat kernel signature;solid geometry;mathematics;geometry;solid modeling;computer graphics;feature;feature model;matching;mechanical engineering	Vision	66.27342227664515	-41.78357841150434	92892
e621bc1873f3452fb03a6e31ab2acd1a15d827cd	spatial pythagorean hodograph quintics and the approximation of pipe surfaces	approximation rationnelle;algorithme rapide;concepcion asistida;computer aided design;rational interpolation;coordenada euler;spine;coordonnee euler;rachis;piping;ajustamiento curva;pipe;best approximation;hodographe pythagorien;geometrie algorithmique;surface parametrique;rational approximation;superficie parametrica;computational geometry;polynomial interpolation;raquis;aplicacion espacial;parameterization;curva analitica;courbe analytique;parametrizacion;caneria;solucion particular;interpolacion racional;pythagorean hodograph;canalizacion;fast algorithm;approximation order;tuyauterie;conception assistee;mejor aproximacion;invariante;ajustement courbe;canalisation;geometria computacional;interpolacion polinomial;curve fitting;hodografo pythagor;analytical curve;euler coordinate;parametric surface;aproximacion racional;algoritmo rapido;solution particuliere;application spatiale;parametrisation;invariant;interpolation polynomiale;space application;particular solution;meilleure approximation;interpolation rationnelle	As observed by Farouki et al. [9], any set of C space boundary data (two points with associated first derivatives) can be interpolated by a Pythagorean hodograph (PH) curve of degree 5. In general there exists a two dimensional family of interpolants. In this paper we study the properties of this family in more detail. We introduce a geometrically invariant parameterization of the family of interpolants. This parameterization is used to identify a particular solution, which has the following properties. Firstly, it preserves planarity, i.e., the interpolant to planar data is a planar PH curve. Secondly, it has the best possible approximation order (4). Thirdly, it is symmetric in the sense that the interpolant of the “reversed” set of boundary data is simply the “reversed” original interpolant. These observations lead to a fast and precise algorithm for converting any (possibly piecewise) analytical curve into a piecewise PH curve of degree 5 which is globally C. Finally we exploit the rational frames associated with any space PH curve (Euler-Rodrigues frame) in order to obtain a simple rational approximation of pipe surfaces with a piecewise analytical spine curve and we analyze its approximation order.	algorithm;euclidean distance;euler;hermite interpolation;interpolation;order of approximation;ph (complexity);planar graph;quintic function;reflection (computer graphics);reversion (software development);simple rational approximation	Zbynek Sír;Bert Jüttler	2005		10.1007/11537908_22	canalisation;parametrization;topology;spine;computational geometry;polynomial interpolation;invariant;calculus;parametric surface;mathematics;geometry;pipe;curve fitting	Theory	68.08695470114452	-40.2769499449853	92949
07514acb7312388fe7c209754cb48ee288e06fed	a relative map approach to slam based on shift and rotation invariants	localization;slam;rotation invariance;approximate solution;indoor environment;simultaneous localization and mapping;mobile robot navigation;mapping;ekf;extended kalman filter	This paper presents a solution to the Simultaneous Localization and Mapping (SLAM) problem in the stochastic map framework based on the concept of the relative map. The idea consists in introducing a map state, which only contains relative quantities among the features invariant under shift and rotation. The estimation of this relative state is carried out through an Extended Kalman Filter. The shift and rotation invariance of the state allows us to significantly reduce the computational burden. In particular, the computational requirement is independent of the number of features. Furthermore, since the estimation process is local, it is not affected by the linearization introduced by the EKF. The cases of point features and corner features are considered. Furthermore, in the case of corners, it is considered a realistic case of an indoor environment containing structures consisting of several corners. Finally, since a relative map contains dependent elements, the information coming from all the constraints which express the elements dependency, is exploited. For this, an approximated solution with low computational requirement is proposed. Its limitation arises at the loop closure since it cannot exploit the information in this case. This is discussed in depth for the case of point features. Experimental results carried out on a real platform in our laboratory and by using the Victoria park dataset show the performance of the approach. c © 2006 Elsevier B.V. All rights reserved.	action message format;approximation algorithm;computation;computational complexity theory;experiment;extended kalman filter;many-worlds interpretation;robot;simultaneous localization and mapping;victoria (3d figure)	Agostino Martinelli;Viet Nguyen;Nicola Tomatis;Roland Siegwart	2007	Robotics and Autonomous Systems	10.1016/j.robot.2006.06.009	computer vision;simulation;computer science;artificial intelligence;extended kalman filter	Robotics	54.65077264798692	-40.73951875397842	92968
a50d9762e6eaccccd84bbe4ff379651b68b2771c	3d reconstruction and spatial auralization of the painted dolmen of antelas	software;absorption;3d modeling;sensors;source localization;acoustics;free space;virtual reality;laser range finders;visualization;head mounted displays;data acquisition;glasses	"""This paper presents preliminary results on the development of a 3D audiovisual model of the Anta Pintada (painted dolmen) of Antelas , a Neolithic chamber tomb located in Oliveira de Frades and listed as Portuguese national monument. The final aim of the project is to create a highly accurate Virtual Reality (VR ) model of this unique archaeological site, capable of providing not only visual but also acoustic immersion based on its actual geometry and physical properties. The project started in May 2006 with in situ data acquisition. The 3D geometry of the chamber was captured using a Laser Range Finder. In order to combine the different scans into a complete 3D visual model, reconstruction software based on the Iterative Closest Point (ICP ) algorithm was developed using the Visualization Toolkit (VTK ). This software computes the boundaries of the room on a 3D uniform grid and populates its interior with """"free-space nodes"""", through an iterative algorithm operating like a torchlight illuminating a dark room. The envelope of the resulting set of """"free-space nodes"""" is used to generate a 3D iso-surface approximating the interior shape of the chamber. Each polygon of this surface is then assigned the acoustic absorption coefficient of the corresponding boundary material. A 3D audiovisual model operating in real-time was developed for a VR Environment comprising head-mounted display (HMD) I-glasses SVGAPro , an orientation sensor (tracker) InterTrax 2 with 3 Degrees Of Freedom (3DOF) and stereo headphones. The auralisation software is based on a geometric model. This constitutes a first approach, since geometric acoustics have well-known limitations in rooms with irregular surfaces. The immediate advantage lies in their inherent computational efficiency, which allows real-time operation. The program computes the early reflections forming the initial part of the chamber's impulse response (IR ), which carry the most significant cues for source localisation. These early reflections are processed through Head Related Transfer Functions (HRTF ) updated in real-time according to the orientation of the user's head, so that sound waves appear to come from the correct location in space, in agreement with the visual scene. The late-reverberation tail of the IR is generated by an algorithm designed to match the reverberation time of the chamber, calculated from the actual acoustic absorption coefficients of its surfaces. The sound output to the headphones is obtained by convolving the IR with anechoic recordings of the virtual audio source.© (2008) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only."""	3d reconstruction;sonification	Paulo Dias;Guilherme Campos;Vítor M. F. Santos;Ricardo Casaleiro;Ricardo Seco;Beatriz Sousa Santos	2008		10.1117/12.766607	computer vision;simulation;engineering;computer graphics (images)	Vision	60.75308225108714	-50.95943010592035	92996
c9d0080b30dae7eecf540969d96041458e5871bd	curvature-dependent local illumination approximation for translucent materials	global illumination;human skin;artificial intelligence;subsurface scattering;photon mapping;real time rendering	Simulating sub-surface scattering is one of the most effective ways to realistically synthesize translucent materials such as marble, milk and human skin. In previous work, the method developed by Jensen et al. [2002] improved significantly on the speed of the simulation, yet still cannot produce real-time rendering. Thus, we have developed a simple local illumination model which mimics the presence of a subsurface scattering effect. Furthermore, this approach is easy implementable on the GPU and doesn't require any complicated pre-processing as is often the case in this area of research [Mertens et al. 2003].	approximation;graphics processing unit;jensen's inequality;list of common shading algorithms;preprocessor;real-time transcription;rendering (computer graphics);simulation;subsurface scattering	Hiroyuki Kubo;Mai Hariu;Shuhei Wemler;Shigeo Morishima	2009		10.1145/1599301.1599382	computer vision;subsurface scattering;computer science;artificial intelligence;photon mapping;real-time rendering;global illumination;computer graphics (images)	Graphics	64.22012443603955	-51.359859708042606	93104
07474995eb76e8623d66036b9b4800b1a6b957df	extracting objects from range and radiance images	layout cameras image segmentation geometrical optics rendering computer graphics partitioning algorithms geometry pipelines surface texture clouds;scene editing;recursive partitioning;image segmentation;top down;texture mapping;indexing terms;image based modeling;range image segmentation;image texture;large scale;feature extraction rendering computer graphics image registration image segmentation augmented reality image texture;range image;feature extraction;image registration;augmented reality object level representation image segmentation image registration texture mapping image based modeling image based rendering rendering;object level representation;point cloud;augmented reality;image based rendering;rendering computer graphics;similarity measure;article;laser range scanner;binary tree	ÐIn this paper, we present a pipeline and several key techniques necessary for editing a real scene captured with both cameras and laser range scanners. We develop automatic algorithms to segment the geometry from range images into distinct surfaces, register texture from radiance images with the geometry, and synthesize compact high-quality texture maps. The result is an object-level representation of the scene which can be rendered with modifications to structure via traditional rendering methods. The segmentation algorithm for geometry operates directly on the point cloud from multiple registered 3D range images instead of a reconstructed mesh. It is a top-down algorithm which recursively partitions a point set into two subsets using a pairwise similarity measure. The result is a binary tree with individual surfaces as leaves. Our image registration technique performs a very efficient search to automatically find the camera poses for arbitrary position and orientation relative to the geometry. Thus, we can take photographs from any location without precalibration between the scanner and the camera. The algorithms have been applied to largescale real data. We demonstrate our ability to edit a captured scene by moving, inserting, and deleting objects. Index TermsÐScene editing, object-level representation, range image segmentation, image registration, texture-mapping, imagebased modeling, image-based rendering, augmented reality.	3d pose estimation;accessibility;algorithm;algorithmic trading;augmented reality;binary tree;curve fitting;hidden surface determination;image registration;image segmentation;iterative method;map;multistage amplifier;point cloud;range imaging;range segmentation;recursion;rendering (computer graphics);similarity measure;texture mapping;time-of-flight camera;top-down and bottom-up design	Yizhou Yu;Andras Ferencz;Jitendra Malik	2001	IEEE Trans. Vis. Comput. Graph.	10.1109/2945.965349	image texture;texture mapping;computer vision;augmented reality;image-based modeling and rendering;index term;binary tree;feature extraction;computer science;image registration;top-down and bottom-up design;point cloud;multimedia;image segmentation;recursive partitioning;computer graphics (images)	Vision	54.97299984069443	-48.33948737494875	93183
0eb04935da782fe598d17dd44d116fd27c64c2fe	synthesis and rendering of seamless and non-repetitive 4d texture variations for measured optical material properties		We have lifted the one weakness of an existing fully automatic acquisition system for spatially varying optical material behavior of real object surfaces. While its expression of spatially varying material behavior with spherical dependence on incoming light as 4D texture (ABTF material model) allows flexible mapping on arbitrary 3D geometries, photo-realistic rendering and interaction in real-time, this very method of texture-like representation exposed it to common problems of texturing, striking in two levels. First, non-seamless textures create visible border artifacts. Second, even a perfectly seamless texture causes repetition artifacts due to side-by-side distribution in large numbers over the 3D surface. We solved both problems through our novel texture synthesis that generates a set of seamless texture variations randomly distributed on the surface at shading time. When compared to regular 2D textures, the inter-dimensional coherence of the 4D ABTF material model poses entirely new challenges to texture synthesis, which includes maintaining the consistency of material behavior throughout the space spanned by the spatial image domain and the angular illumination hemisphere. In addition, we tackle the increased memory consumption caused by the numerous variations through a fitting scheme specifically designed to reconstruct the most prominent effects captured in the material model.		Martin Ritz;Simon Breitfelder;Pedro Santos;Arjan Kuijper;Dieter W. Fellner	2018		10.1145/3283254.3283284	rendering (computer graphics);computer vision;computer graphics (images);texture synthesis;artificial intelligence;material properties;coherence (physics);computer science	Graphics	61.53855683545439	-51.18013790966189	93381
3bab1173e2dbef21b108a08c6572307c762c4da7	real-time adjustment of transfer function for fourier volume rendering	volume rendering;real time;data storage;transfer function;graphics processing units;fourier transforms;article	Fourier volume rendering (FVR) is a volume rendering method based on the Fourier slice theorem. With an n × n × n volume data, the FVR algorithm requires O(n2 log n) time to generate a result. Because it requires time less than O(n3) does, FVR is preferred for designing a real-time rendering algorithm with a preprocessing step. We improve upon our previous work. We demonstrate that a B-spline is significantly more useful when designing a transfer function. To design an appropriate transfer function with a spline function, additional control points are required. However, the memory space required for the proposed method increases in linear proportion to the number of control points. We show that the set of control points can be clustered into groups, ensuring the memory required is linearly proportional to the number of groups. The proposed technique supports real-time rendering after adjusting the transfer function for FVR. © 2011 SPIE and IS&T. [DOI: 10.1117/1.3653264]	algorithm;b-spline;control point (mathematics);dspace;preprocessor;projection-slice theorem;real-time clock;real-time transcription;spline (mathematics);transfer function;volume rendering	Chang-Chieh Cheng;Yu-Tai Ching	2011	J. Electronic Imaging	10.1117/1.3653264	fourier transform;computer hardware;computer science;theoretical computer science;computer data storage;transfer function;volume rendering;computer graphics (images)	Visualization	68.06435455624104	-50.79656049558046	93492
09db93fcf2dec832f84d42977b748ff813129df1	planification du placement de caméras pour des mesures 3d de précision. (planning camera placement for accurate 3d measurements)		3D measurements can be recovered from several views by triangulation. This work deals with the problem of where to place the cameras in order to obtain a minimal error in the 3D measurements, also called camera network design in photogrammetry. We pose the problem in terms of an optimization design, dividing it into two main components: 1) an analytical part dedicated to the analysis of error propagation from which a criterion is derived, 2) a global optimization process to minimizes this criterion. In this way, the approach consists of an uncertainty analysis applied to the reconstruction process from which a covariance matrix is computed. This matrix represents the uncertainty of the detection from which the criterion is derived. Moreover, the optimization has discontinuities mainly due to the unobservability of points, which leads to a combinatorial optimization process. These aspects are solved using a multicellular genetic algorithm. Experimental results are provided to illustrate the e ectiveness and e ciency of the solution.		Gustavo Olague	1998				Vision	55.55171896925249	-50.39023720120069	93506
b5094244e5c33f4d9ec2ef4098a95657e8b5000e	multi-resolution 3d reconstruction through texture matching	interpolation;estimation	In this paper we present a general and robust approach to the problem of close-range partial 3D reconstruction of objects from multi-resolution texture matching. The method is based on the progressive refininement of a parametric surface, which is described using an increasing number of radial functions.	3d reconstruction;algorithm;radial (radio)	Federico Pedersini;Augusto Sarti;Stefano Tubaro	2000	2000 10th European Signal Processing Conference		computer vision;mathematical optimization;bilinear interpolation;interpolation;stairstep interpolation;pattern recognition;mathematics;nearest-neighbor interpolation;multivariate interpolation	Vision	66.12689407214862	-44.46697019848011	93734
8948924fd9410815f4c8741ea9a9526ae74ebdbc	multi body kalman filtering with articulation constraints for humanoid robot pose and motion estimation	unconstrained estimate;articulation constraint;motion estimation;particular rigid body;unconstrained state estimate;kalman filter;articulated rigid body state;humanoid robot;correct state estimate;rigid body;articulated body;individual state;multi body kalman;articulated rigid body	unconstrained estimate;articulation constraint;motion estimation;particular rigid body;unconstrained state estimate;kalman filter;articulated rigid body state;humanoid robot;correct state estimate;rigid body;articulated body;individual state;multi body kalman;articulated rigid body		Daniel Hauschildt;Sören Kerner;Stefan Tasse;Oliver Urbann	2011		10.1007/978-3-642-32060-6_35	computer vision;mathematical optimization;articulated body pose estimation	Robotics	54.39851248591914	-40.17410480780917	93991
c66ba28cb79ea9d32c9d822d805d0d4197f26c10	omnidirectional vision systems		In this chapter, different types of omnidirectional systems are briefly introduced. Then, we focus on the central catadioptric systems and the model used to deal with this type of systems, the so-called sphere camera model. The projection of points and lines under this model are also explained as well as the relation between this model and the actual catadioptric systems. Later, we introduce the lifted coordinates, which is a tool used to deal with the non linearities present on the sphere camera model. We show two different forms to compute them. The former makes use of the G operator and the latter one uses symmetric matrix equations. Finally, a useful representation of catadioptric systems as Riemannian manifolds is presented.	graph (discrete mathematics)	Luis Puig;Josechu J. Guerrero	2013		10.1007/978-1-4471-4947-7		Robotics	54.77234878988899	-50.744448117925714	94027
5da9a5367bd70c004ad9b7e8cee95059490e33fc	the tum-dlr multimodal earth observation evaluation benchmark	photogrammetrie und bildanalyse	We present a new dataset for development, benchmarking, and evaluation of remote sensing and earth observation approaches with special focus on converging perspectives. In order to provide data with different modalities, we observed the same scene using satellites, airplanes, unmanned aerial vehicles (UAV), and smartphones. The dataset is further complemented by ground-truth information and baseline results for different application scenarios. The provided data can be freely used by anybody interested in remote sensing and earth observation and will be continuously augmented and updated.	aerial photography;aperture (software);baseline (configuration management);benchmark (computing);computer-aided design;dynamic language runtime;ground truth;image resolution;microsoft outlook for mac;mobile device;multimodal interaction;pixel;sensor;smartphone;synthetic data;unmanned aerial vehicle	Tobias Koch;Pablo d'Angelo;Franz Kurz;Friedrich Fraundorfer;Peter Reinartz;Marco Körner	2016	2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)	10.1109/CVPRW.2016.92	computer vision;simulation;computer science	Vision	54.70065819994604	-44.85543394920058	94078
a2e0de3872a3b87a942f7fc501689a5ab6369be0	improved phase-unwrapping method using geometric constraints	dual frequency;geometric constraints;phase unwrapping	Conventional dual-frequency fringe projection algorithm often suffers from phase unwrapping failure when the frequency ratio between the high frequency and the low one is too large. Zhang et.al. proposed an enhanced two-frequency phase-shifting method to use geometric constraints of digital fringe projection(DFP) to reduce the noise impact due to the large frequency ratio. However, this method needs to calibrate the DFP system and calculate the minimum phase map min  at the nearest position from the camera perspective, these procedures are are relatively complex and more time-cosuming. In this paper, we proposed an improved method, which eliminates the system calibration and min  determination in Zhang's method,meanwhile does not need to use the low frequency fringe pattern. In the proposed method,we only need a set of high frequency fringe patterns to measure the object after the high frequency min  is directly estimated by the experiment. Thus the proposed method can simplify the procedure and improve the speed. Finally, the experimental evaluation is conducted to prove the validity of the proposed method.The results demonstrate that the proposed method can overcome the main disadvantages encountered by Zhang's method.	algorithm;instantaneous phase;maxima and minima;minimum phase;structured-light 3d scanner	Guangliang Du;Minmin Wang;Canlin Zhou;Shuchun Si;Hui Li;Zhenkun Lei;YanJie Li	2016	CoRR	10.1080/09500340.2017.1284279	optics	EDA	57.04123958880386	-46.795715113818865	94127
f8ab88b6d2fc96454e7c17b6ce9c056f0ec87d21	orient-cam, a camera that knows its orientation and some applications	contraste;fabricacion asistida por computador;image processing;localization;procesamiento imagen;localizacion;traitement image;captador medida;fabrication assistee;measurement sensor;capteur mesure;localisation;video cameras;computer aided manufacturing;camera video;pattern recognition;etalonnage;reconnaissance forme;reconocimiento patron;calibration	We introduce a new type of smart cameras. These cameras have an embedded orientation sensor which provides an estimate of the orientation of the camera. In this paper, we describe our prototype orientation sensor and propose some methods for the calibration of the whole camera. We then show two applications. First, the camera is used to create oriented spherical panoramas. Second, it is used for image based localization, in which only the position of the camera has to be retrieved.	alvey;augmented reality;british machine vision conference;camera resectioning;edge detection;embedded system;handheld game console;harris affine region detector;iccv;image sensor;international journal of computer vision;internationalization and localization;jean;kalman filter;matlab;microelectromechanical systems;photogrammetry;prototype;sampling (signal processing);satellite navigation;smart tv;sparse language;sparse matrix	Bertrand Vandeportaele;Christophe Dehais;Michel Cattoen;Philippe Marthon	2006		10.1007/11892755_27	smart camera;stereo camera;computer vision;camera auto-calibration;camera matrix;calibration;camera resectioning;simulation;internationalization and localization;image processing;computer science;pattern recognition;camera interface;three-ccd camera;pinhole camera model;visual sensor network;computer graphics (images)	Vision	58.34687382464156	-42.82698828646597	94153
9920b6b24e47f662c8b535067867dfa9807e8dff	surfaces in computer aided geometric design: a survey with new results	interpolation;computer graphics;triangular patches;multidimensional surfaces;approximation;bezier patches;design of surfaces;coons patches;surfaces;representation of surfaces;contouring;computer aided geometric design	'Surfaces in Computer Aided Geometric Design' focuses on the representation and design of surfaces in a computer graphics environment. This new area has the dual attractions of interesting research problems and important applications. The subject can be approached from two points of view: The design of surfaces which includes the interactive modification of geometric information and the representation of surfaces for which the geometric information is relatively fixed. Design takes place in 3-space whereas representation can be higher dimensional. 'Surfaces in CAGD' can be traced from its inception in rectangular Coons patches and Bezier patches to triangular patches which are current research topics. Triangular patches can interpolate and approximate to arbitrarily located data and require the preprocessing steps of triangulation and derivative estimation. New contouring methods have been found using these triangular patches. Finally, multidimensional interpolation schemes have been based on tetrahedral interpolants and are illustrated by surfaces in 4-space by means of color computer graphics.	computer-aided design;geometric design	Robert E. Barnhill	1985	Computer Aided Geometric Design	10.1016/0167-8396(85)90002-0	computer representation of surfaces;interpolation;approximation;mathematics;geometry;computer graphics;surface;statistics	EDA	68.00744692481061	-42.08036230760604	94350
13c5cc70220867c63216103ec828ad3df3a2f044	table-top computed lighting for practical digital photography	dynamic reflectometry;categories and subject descriptors according to acm ccs i 3 7 computer graphics three dimensional graphics and realism i 4 1 image processing and computer vision digitization and image capture i 3 3 computergraphics picture image generation;high resolution;computational steering;low resolution;digital photography;weighted sums;relighting;3d video	We apply simplified image-based lighting methods to reduce the equipment, cost, time, and specialized skills required for high-quality photographic lighting of desktop-sized static objects such as museum artifacts. We place the object and a computer-steered moving-head spotlight inside a simple foam-core enclosure, and use a camera to quickly record low-resolution photos as the light scans the box interior. Optimization guided by interactive user sketching selects a small set of frames whose weighted sum best matches the target image. The system then repeats the lighting used in each of these frames, and constructs a high resolution result from re-photographed basis images. Unlike previous image-based relighting efforts, our method requires only one light source, yet can achieve high resolution light positioning to avoid multiple sharp shadows. A reduced version uses only a hand-held light, and may be suitable for battery-powered, field photography equipment that fits in a backpack.		Ankit Mohan;Jack Tumblin;Bobby Bodenheimer;Cindy Grimm;Reynold J. Bailey	2005		10.1145/1185657.1185742	computer vision;computational photography;simulation;image resolution;computer science;image-based lighting;computer graphics (images)	Crypto	58.490671696031576	-49.90079481050049	94435
e8cdc32b50a4d9db7cde459e117ef95015fe9b91	methods to recover constant radius rolling ball blends in reverse engineering	concepcion asistida;computer aided design;estimacion;ajustamiento curva;surface parametrique;surface fitting;retroingenierie;radio curvatura;courbure;blending;forma geometrica;algorithme;radius rolling ball blends;algorithm;qa75 electronic computers computer science;coupage;blending surface;estimation;geometrical shape;rayon courbure;conception assistee;curvatura;ajustement courbe;curvature;forme geometrique;radius of curvature;curve fitting;parametric surface;ingeniera inversa;reverse engineering shapes;mezcla;reverse engineering;algoritmo	Reverse engineering of geometric shape is the process of converting large amounts of measured data points into concise and consistent computer representations of geometry. Applications include the reproduction of engineering parts with no available documentation or CAD definition for such purposes as redesign, analysis and visualisation. Other applications include the creation of various mating surfaces for parts of the human body, for example. As described in a recent survey [18], reverse engineering typically consists of four phases: data acquisition, preprocessing, segmentation and geometric model creation. Each of these four phases is quite complicated and they are strongly interrelated. Depending on the basic assumptions made and the quality and quantity of the measured data, there is a great variety of applied algorithms and computer models, as reflected in many recent publications which investigate various aspects of reverse engineering of shape. The topic of this paper, recovering constant radius rolling ball blends, is mainly of interest when reconstructing mechanical engineering parts. From a geometric point of view, we assume that these objects are bounded by trimmed primary surfaces, which determine the basic shape of the object. These are relatively large in comparison to smaller blending surfaces which provide smooth transitions between the primary surfaces. Blends strongly depend on the primary surfaces, and are often used for reasons of aesthetics, manufacturability, stress reduction etc. As discussed in [21], there are many methods to create blends and represent them in various mathematical forms. Here we restrict our interest to the most widely used class of constant-radius rolling ball blends due to their simplicity and intuitive behaviour. Such blends are nominally generated by sweeping a rolling ball moving in contact with two adjacent primary surfaces. We assume that edge blends are small enough that they do not interfere with each other, except where they run together at the vertices; here vertex blend faces may need to be inserted to complete the object. The purpose of the current investigation is to present and compare algorithms for recovering constant radius rolling ball blends. This is a particular subproblem of the final model building phase of reverse engineering. We do not go into details concerning the various steps of preprocessing—algorithms to perform filtering, triangulation and decimation are described elsewhere [10, 17], but we assume that	algorithm;alpha compositing;computer simulation;computer-aided design;data acquisition;data point;decimation (signal processing);design for manufacturability;documentation;geometric modeling;preprocessor;reverse engineering;scientific visualization	Géza Kós;Ralph R. Martin;Tamás Várady	1999	Computer Aided Geometric Design	10.1016/S0167-8396(99)00043-6	mathematical optimization;estimation;radius of curvature;computer aided design;parametric surface;mathematics;geometry;curvature;reverse engineering;statistics;curve fitting	Graphics	66.5718954697052	-41.678926318218515	94485
30a0800cdea3de90d6c4d12f086244f4cea0a24e	robust and efficient volumetric occupancy mapping with an application to stereo vision	stereo image processing octrees probability;robot sensing systems stereo vision three dimensional displays current measurement memory management mobile robots;octree volumetric occupancy mapping octomap method spatially correlated errors temporally correlated errors stereo vision system voxel occupancy probability visibility probability stereo vision sensor sensor depth error dense range measurement data	A map of occupied and free space in a robot's environment is a common prerequisite for navigational tasks. Although the first methods for occupancy mapping relied on a 2D grid representation, 3D volumetric approaches are becoming increasingly popular. In this paper we present a new volumetric mapping approach that is based on the OctoMap method. We designed this method to be more robust against measurement errors, in particular against high temporally or spatially correlated errors usually received from a stereo vision system. For this purpose, we define a probability measure that a voxel is currently visible. An update of a voxel's occupancy probability then happens with respect to this visibility probability, allowing us to neglect measurements for voxels that are actually unobservable. Finally, we model the depth error of a stereo vision sensor, and take care of this error when performing a map update. By evaluation we show that our method produces maps with far less erroneous artifacts compared to OctoMap. Our maps also require less memory, and due to an optimized update reduction, our method is also faster than OctoMap when processing dense range measurement data.	algorithm;artifact (software development);care-of address;map;mathematical optimization;robot;sensor;stereopsis;traverse;voxel;whole earth 'lectronic link	Konstantin Schauwecker;Andreas Zell	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907758	computer stereo vision;stereo cameras;computer vision;occupancy grid mapping;remote sensing;computer graphics (images)	Robotics	54.95593780049794	-43.21704752962502	94591
33bdcfc8bd60b2cea2660c5c82876c3d32fe04c4	generation of a finite element mesh from stereolithography (stl) files	prototipificacion rapida;automatic mesh generation;litografia;concepcion asistida;lithographie;metodo adaptativo;triangulacion delaunay;computer aided design;boundary representation;delaunay triangulation;methode element fini;metodo elemento finito;stereolithography;bisection algorithm;generation automatique maille;adaptive mesh;triangulation delaunay;stereolitografia;generation maille;representation limite;methode adaptative;finite element method;finite element;stl file format;refinement method;lithography;generacion automatica red;rapid prototyping;finite element mesh;estimation erreur;estratificacion;error estimation;adaptive method;estimacion error;stereolithographie;stratification;conception assistee;representacion limite;geometric model;bisection task;methode raffinement;error estimate;tarea biseccion;mesh generation;metodo afinamiento;tâche bissection;prototypage rapide	The aim of the method proposed here is to show the possibility of generating adaptive surface meshes suitable for the finite element method, directly from an approximated boundary representation of an object created with CAD software. First, we describe the boundary representation, which is composed of a simple triangulation of the surface of the object. Then we will show how to obtain a conforming size-adapted mesh. The size adaptation is made considering geometrical approximation and with respect to an isotropic size map provided by an error estimator. The mesh can be used “as is” for a finite element computation (with shell elements), or can be used as a surface mesh to initiate a volume meshing algorithm (Delaunay or advancing front). The principle used to generate the mesh is based on the Delaunay method, which is associated with refinement algorithms, and smoothing. Finally, we will show that not using the parametric representation of the geometrical model allows us to override some of the limitations of conventional meshing software that is based on an exact representation of the geometry.	finite element method	Eric Béchet;Jean-Christophe Cuillière;François Trochu	2002	Computer-Aided Design	10.1016/S0010-4485(00)00146-9	lithography;mesh generation;computer aided design;finite element method;mathematics;geometry;image-based meshing;engineering drawing;t-vertices;algorithm	EDA	67.62134247181667	-40.842811166646804	94752
fc0c6a9dd9940e8c26143688e178502475f7c663	an efficient and high quality rasterization algorithm and architecture in 3d graphics systems	shared edge sampling high quality rasterization algorithm 3d graphics systems 3d graphic rendering rendering pipeline fixed function edge equation scan line based methods division operations anti aliasing techniques super sampling barycentric based traversal algorithm ladder start tile graphic rendering;engines;image edge detection;image color analysis;rendering computer graphics;rendering computer graphics algorithm design and analysis engines image color analysis image edge detection hardware;3d graphics tile traversal anti aliasing;algorithm design and analysis;hardware	In order to render 3-D graphics efficiently, rendering pipeline fixed function have been developed. Traditional triangle traversal techniques using edge-equation-based or scan-line-based methods may cause potential instability from the division operations. Moreover, traditional anti-aliasing techniques using the grid-based or point-sharing of edge to do super-sampling are not regular and the quality is also not good enough. This paper develops an efficient barycentric-based traversal algorithm using Ladder Start tile which is division free. Throughout the process, improved the efficiency and stability of the graphic rendering and no extra traversal position is produced to reduce the number of pixel tests. It also proposed a novel quality strategy for primitive's shared-edge sampling in antialiasing operation. The blending colors in the neighborhood of these edges according to a set of simple coverage rules, allowing area approximate, yet the fast and more robust anti-aliasing.	3d computer graphics;aliasing;alpha compositing;approximation algorithm;barycentric subdivision;color;display resolution;graphics pipeline;instability;pixel;principle of good enough;rasterisation;sampling (signal processing);scan line;spatial anti-aliasing;supersampling;tree traversal	Yeong-Kang Lai;Yu-Chieh Chung	2015	2015 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2015.7169202	embedded system;algorithm design;computer vision;tiled rendering;graphics pipeline;image-based modeling and rendering;fragment processing;3d rendering;computer hardware;rendering;computer science;operating system;parallel rendering;real-time computer graphics;real-time rendering;texture memory;computer graphics;alternate frame rendering;algorithm;software rendering;3d computer graphics;computer graphics (images)	EDA	67.61711471605622	-51.03067323238064	94882
0208267bbb7d2c70fe29118076586af1c4df85fe	panorama based point cloud reduction and registration	slam robots image matching image reconstruction image registration mobile robots optical scanners;optical scanners;image matching;three dimensional displays feature extraction surface emitting lasers octrees laser modes measurement by laser beam image resolution;mobile robots;feature based registration panorama based point cloud reduction panorama based point cloud registration 3d point cloud reconstruction laser scanners mapping system mobile robots matching process panorama images;image reconstruction;image registration;slam robots	To reconstruct environments 3D point clouds acquired by laser scanners are registered. This is an important but also time consuming part of any mapping system for mobile robots. The time needed for mapping is drastically reduced when the size of the input data is reduced. This paper examines different ways of reducing the size of point clouds without losing vital information for the matching process. We present novel point cloud reduction methods on the basis of panorama images. It is shown that the reduced point clouds are ideally suited for feature based registration on panorama images. We evaluate the presented reduction methods based on their effect on the performance of the registration algorithm.	algorithm;mobile robot;point cloud;reduction (complexity)	Hamidreza Houshiar;Dorit Borrmann;Jan Elseberg;Andreas Nüchter	2013	2013 16th International Conference on Advanced Robotics (ICAR)	10.1109/ICAR.2013.6766587	computer vision;geography;remote sensing;computer graphics (images)	Robotics	54.77754700631384	-43.384245115439484	94890
32ba65d2dd983ae9d66eba5536ead007b8b29864	shape-constrained flock animation	control force;novel shape-constrained flock animation;effective fuzzy control logic;deforming shape constraint;constraining shape;shape-constrained flock animation;flock member;flock migration;flock simulation;interactively controlling flock navigation;fuzzy control;kalman filter	We propose a novel shape-constrained flock animation system for interactively controlling flock navigation in virtual environments. This system is capable of making the spatial distribution of a flock meet static or deforming shape constraints while performing flock simulation. Such a capability can find many applications in the entertainment industry. Given a 3D constraining shape, our system first draws a set of uniform sample points through a 3D surface mosaicing process or a stratified point sampling strategy. Once correspondences between flock members and sample points have been established, points on the target shape are used as homing destinations to guide flock migration. Under a global path control scheme, an effective fuzzy control logic, which dynamically adjusts steering forces and control forces, has been developed to create visually pleasing shape-constrained flock animations. Copyright © 2008 John Wiley & Sons, Ltd.	flock;fuzzy control system;interactivity;john d. wiley;multiple homing;nearest-neighbor interpolation;sampling (signal processing);simulation;virtual reality	Jiayi Xu;Xiaogang Jin;Yizhou Yu;Tian Shen;Mingdong Zhou	2008	Journal of Visualization and Computer Animation	10.1002/cav.231	kalman filter;computer vision;simulation;computer science;artificial intelligence;machine learning;fuzzy control system;computer graphics (images)	Graphics	64.09058041977097	-38.1351380616811	94919
e000f5b6a86c8eb94dc25b80329f04cd067359de	morphological normalized binary object metamorphosis	computer animations.;image metamorphosis;mathematical morphology	The paper describes a method for binary 2D and 3D object methamorph osis using a normalized morphological interpolation function and a mask. Compar ing with the existing methods the proposed one has two important advantages: th e normalization of the interpolation function and the new formulation of the interpolator. The first one allows obtaining steady and smooth transfomation of the area (volume) of the interpolated objects. The new formulation of the interp olator introduces a mask inside which the interpolation is performed. Owing to the the mask one can define the area inside which the interpolation is perform d. The new kind of mask is also proposed it is equal to the convex hull of bo th input objects. In the paper also two examples of the interpolaton of 2D and 3 D objects are given. The method can be applied to image reconstrucion, as well as for the computer-aided animations.	call of duty: black ops;convex hull;interpolation	Marcin Iwanowski	2004		10.1007/1-4020-4179-9_90	computer vision;mathematical optimization;stairstep interpolation;mathematics;nearest-neighbor interpolation;multivariate interpolation;engineering drawing	Vision	66.8713235104597	-43.24799311988485	95321
8475a8cab9b83ef6abebfb9ed6df0f27de5a9ea2	live surface		Live Surface allows users to segment and render complex surfaces from 3D image volumes at interactive (subsecond) rates using a novel, cascading graph cut (CGC). The process consists of four steps. (1) Preprocessing for generation of a complete 3D watershed hierarchy followed by tracking of all catchment basin surfaces. (2) User selection of foreground and background seeds from two-dimensional, image cross-sections. (3) Segmentation of the volume by cascading through the 3D watershed hierarchy from the top, applying graph cut successively, at each level, only to catchment basins bordering the segmented surface from the previous level. (4) OpenGL rendering for display and update of the segmented surface at interactive rates. CGC allows the entire image volume to be segmented an order of magnitude faster than existing techniques that make use of graph cut. Segmentation and rendering, combined, is accomplished in about 0.5 seconds, allowing 3D surfaces to be displayed and updated dynamically as each additional foreground seed is deposited. CGC allows the user to control and steer the segmentation with immediate user feedback, providing a Live Surface tool for 3D image volumes similar to the Live Wire (Intelligent Scissors) tool used in 2D images.	cut (graph theory);opengl;preprocessor;rendering (computer graphics);stereoscopy;watershed (image processing)	Christopher J. Armstrong;William A. Barrett;Brian L. Price	2006		10.2312/VG/VG06/087-094		Graphics	65.7163754676673	-48.97456978201268	95466
8fdbdddf9a66ea8fd1e7e9ac9e1abc504864e5e5	robust fitting of 3d objects by affinely transformed superellipsoids using normalization	affine transformation	We present an algorithm for the robust fitting of objects given as voxel data with affinely transformed superellipsoids. Superel-lipsoids cover a broad range of various forms and are widely used in many application fields. Our approach uses the method of normalization and a new separation of the affine transformation into a shearing, an anisotropic scale and a rotation. It extends our previous work for 2D fitting problems and for fitting rectangular boxes in 3D. Our technique can be used as a valuable tool for solving this fitting task for 3D data. If the exponents describing the superellipsoids to be fitted are known in advance, the method is extremely robust even against major distortions of the object to be fitted.	curve fitting	Frank Ditrich;Herbert Süße	2007		10.1007/978-3-540-74272-2_61	mathematical optimization;combinatorics;computer science;affine transformation;mathematics;geometry	Vision	63.63332529691609	-43.80654891834919	95473
e46eea20acef51fbf2c1c55a7ae6e0a503904e65	photo2clipart: image abstraction and vectorization using layered linear gradients		We present a method to create vector cliparts from photographs. Our approach aims at reproducing two key properties of cliparts: they should be easily editable, and they should represent image content in a clean, simplified way. We observe that vector artists satisfy both of these properties by modeling cliparts with linear color gradients, which have a small number of parameters and approximate well smooth color variations. In addition, skilled artists produce intricate yet editable artworks by stacking multiple gradients using opaque and semi-transparent layers. Motivated by these observations, our goal is to decompose a bitmap photograph into a stack of layers, each layer containing a vector path filled with a linear color gradient. We cast this problem as an optimization that jointly assigns each pixel to one or more layer and finds the gradient parameters of each layer that best reproduce the input. Since a trivial solution would consist in assigning each pixel to a different, opaque layer, we complement our objective with a simplicity term that favors decompositions made of few, semi-transparent layers. However, this formulation results in a complex combinatorial problem combining discrete unknowns (the pixel assignments) and continuous unknowns (the layer parameters). We propose a Monte Carlo Tree Search algorithm that efficiently explores this solution space by leveraging layering cues at image junctions. We demonstrate the effectiveness of our method by reverse-engineering existing cliparts and by creating original cliparts from studio photographs.	approximation algorithm;automatic vectorization;bitmap;color gradient;computer graphics;feasible region;mathematical optimization;monte carlo method;monte carlo tree search;pixel;reverse engineering;search algorithm;semiconductor industry;stacking;vector graphics;vector path	Jean-Dominique Favreau;Florent Lafarge;Adrien Bousseau	2017	ACM Trans. Graph.	10.1145/3130800.3130888	mathematical optimization;vector graphics;pixel;mathematics;bitmap;color gradient;transparency (graphic);small number;vectorization (mathematics);monte carlo tree search	Graphics	63.707094735010976	-48.015244232615785	95506
6e8ba26b5f091f1a4e1d9ceb86b54f376b2cd624	chain coding representation of voxel-based objects with enclosing, edging and intersecting trees		Thrifty methods to represent and store three dimensional objects are important. Two different methods for describing voxel-based objects (VBOs) by means of edging (ETs) and intersecting (ITs) trees are demonstrated. Each tree comes from a different kind of border of the underlying VBO, and both trees are one dimensional alternative descriptors to skeletons for VBOs representation. Vertices in the trees correspond to the vertices of the VBO enclosing surface where some surface vertices have been conveniently suppressed. These descriptors are computed using a base-five digit chain code (combined with parentheses) and has been used to illustrate three dimensional curves and enclosing trees. The descriptors are invariant under rotation and translation, and preserve the VBO shape. Using either descriptor, the description of the mirror image of a VBO is easily obtained. The proposed descriptor notation is a good tool for storing VBOs, and intersecting trees providing further storage savings. Enclosing trees (EcTs) are briefly reviewed as a preamble to introduce ETs and ITs.	chain code;tree (data structure);vertex (geometry);vertex buffer object;voxel	Luis A. Martínez;Ernesto Bribiesca;Adolfo Guzmán-Arenas	2016	Pattern Analysis and Applications	10.1007/s10044-016-0540-4	combinatorics;topology;mathematics;geometry	ML	64.28095305596216	-41.381599823850316	95539
0be789f467a6117e270665bea1708fe94f735a93	a multi-resolution topological representation for non-manifold meshes	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;level of detail;ciencias basicas y experimentales;data structures;tecnologias;multi resolution;data structure;non manifold modeling	We address the problem of representing and processing 3D objects, described through simplicial meshes, which consist of parts of mixed dimensions, and with a non-manifold topology, at different levels of detail. First, we describe a multi-resolution model, that we call a non-manifold multi-tessellation (NMT), and we consider the selective refinement query, which is at the heart of several analysis operations on multi-resolution meshes. Next, we focus on a specific instance of a NMT, generated by simplifying simplicial meshes based on vertex-pair contraction, and we describe a compact data structure for encoding such a model. We also propose a new data structure for two-dimensional simplicial meshes, capable of representing both connectivity and adjacency information with a small memory overhead, which is used to describe the mesh extracted from an NMT through selective refinement. Finally, we present algorithms to efficiently perform updates on such a data structure.		Leila De Floriani;Paola Magillo;Enrico Puppo;Davide Sobrero	2004	Computer-Aided Design	10.1016/S0010-4485(03)00058-7	data structure;computer science;theoretical computer science;level of detail;engineering drawing;algorithm	EDA	68.2815002176095	-43.876168399795084	95553
2d6f84023589530cbbc6b79971dca24a23b3a9e5	exploded view diagrams of 3d grids	three dimensional displays data structures explosions solid modeling data visualization image color analysis geometry;computer graphics;computational geometry;computer graphics computational geometry;tree data structures computational geometry computer graphics interactive systems;corner point grid interactive exploded view diagrams generalized 3d grids explosion tree data structure bsp tree disjoint convex polygons	We present a system for creating interactive exploded view diagrams in generalized 3D grids. The primary difference between our approach and existing ones is that our technique neither requires geometrical information of the whole model nor any information regarding the relationship among model parts, instead our implementation depends on which grid cells are considered as object of interest, and which view angle to use. To achieve this, we introduce the Explosion Tree, a data structure closely related to a BSP tree, which supports the explosion view diagrams technique based on the relationship between disjoint convex polygons. In this paper we discuss the application of this technique to Corner-Point Grid which has been extensively used for geological modeling and flow simulation. All the data presented in this work consists of real data currently used in the industry.	binary space partitioning;data structure;diagram;planning;preprocessor;simulation	Zamir Martins Filho;Emilio Vital Brazil;Mario Costa Sousa	2015	2015 28th SIBGRAPI Conference on Graphics, Patterns and Images	10.1109/SIBGRAPI.2015.12	computer science;theoretical computer science;engineering drawing;computer graphics (images)	Visualization	64.70939640595718	-43.36979886304428	95707
a5a1770c11f509fd55c522fbdb5a744d5f9d8ed0	marching triangle polygonization for efficient surface reconstruction from its distance transform	triangle mesh surface;surface reconstruction;polygonization algorithm;3d scanned objects;scalar field;marching triangle;scalar field distance transform;distance transform;marching cube;triangle mesh	In this paper we propose a new polygonization method based on the classic Marching Triangle algorithm. It is an improved and efficient version of the basic algorithm which produces a complete mesh without any cracks. Our method is useful in the surface reconstruction process of scanned objects. It works over the scalar field distance transform of the object to produce the resulting triangle mesh. First we improve the original algorithm in finding new potential vertices in the mesh growing process. Second we modify the Delaunay sphere test on the new triangles. Third we consider new triangles configuration to obtain a more complete mesh. Finally we introduce an edge processing sequence to improve the overall Marching Triangle algorithm. We use a relevant error metric tool to compare results and show our new method is more accurate than Marching Cube which is the most widely used triangulation algorithm in the surface reconstruction process of scanned objects.	algorithm;approximation;computer graphics;consistency model;cube;delaunay triangulation;distance transform;edge detection;implicit surface;interpolation;isosurface;klee–minty cube;marching cubes;performance;point cloud;relevance;triangle mesh	Marc Fournier;Jean-Michel Dischler;Dominique Bechmann	2009		10.1007/978-3-642-04397-0_15	computer vision;scalar field;combinatorics;marching tetrahedra;topology;surface reconstruction;marching squares;computer science;triangle mesh;point cloud;mathematics;geometry;marching cubes;distance transform	Visualization	67.50438045202837	-44.60468802826142	95956
0bddd63706acd676d2cf1e14a811623646f93ada	real-time reflection on moving vehicles in urban environments	environment maps;urban environment;efficient algorithm;real time;virtual reality;real time simulation;weed control;ray tracing;image based rendering;real time rendering	In the context of virtual reality, the simulation of complex environments with many animated objects is becoming more and more common. Virtual reality applications have always promoted the development of new efficient algorithms and image-based rendering techniques for real-time interaction. In this paper, we propose a technique which allows the real-time simulation in a city of the reflections of static geometry (eg. building) on specular dynamic objects (vehicles). For this, we introduce the idea of multiple environment maps. We pre-compute a set of reference environment maps at strategic positions in the scene, that are used at run time and for each visible dynamic object, to compute local environment maps by resampling images. To efficiently manage a small number of reference environment maps, compared to the scene dimension, for each vertex of the reconstructed environment we perform a ray tracing in a heightfield representation of the scene. We control the frame rate by adaptative reconstruction of environment maps. We have implemented this approach, and the results show that it is efficient and scalable to many dynamic objects while maintaining interactive frame rates.	algorithm;heightmap;map;ray tracing (graphics);real-time clock;real-time transcription;reflection (computer graphics);run time (program lifecycle phase);scalability;simulation;virtual reality	Alexandre Meyer;Céline Loscos	2003		10.1145/1008653.1008662	ray tracing;computer vision;simulation;image-based modeling and rendering;rendering;computer science;weed control;virtual reality;computer graphics (images)	Graphics	64.89149344092596	-50.490210105836354	96153
58cbc1ce45dbdae306a016d774d011afcd6b2beb	shape and reflectance from an image sequence generated using extended sources	image sampling;optical reflection;reflectivity;photometric sampling;prior knowledge;orientation;image intensity values;computer vision;shape reflectivity image sequences image generation optical reflection light sources photometry lighting image sampling parameter estimation;specular reflection;image generation;shape;hybrid surfaces;reflectance;photometry;reflection model;image sequence;specular;reflectivity computer vision photometry;extraction algorithm;lighting;parameter estimation;hybrid surfaces computer vision reflectance image sequence lambertian specular extended light sources extraction algorithm image intensity values orientation photometric sampling;lambertian;extended light sources;light sources;image sequences	The authors present a method for determining the shapes of surfaces whose reflectance properties may vary from Lambertian to specular, without prior knowledge of the relative strengths of the Lambertian and specular components of reflection. The object surface is illuminated using extended light sources and is viewed from a single direction. Surface illumination using extended sources makes it possible to ensure the detection of both Lambertian and specular reflections. Multiple source directions are used to obtain an image sequence of the object. An extraction algorithm uses the set of image intensity values measured at each surface point to compute orientation as well as relative strengths of the Lambertian and specular reflection components. The proposed method is called photometric sampling, as it uses samples of photometric function that relates image intensity to surface orientation, reflectance, and light source characteristics. Experiments were conducted on Lambertian surfaces, specular surfaces, and hybrid surfaces, whose reflectance models are composed of both Lambertian and specular components. The results show high accuracy in measured orientations and estimated reflectance parameters. >	extended precision	Shree K. Nayar;Katsushi Ikeuchi;Takeo Kanade	1989		10.1109/ROBOT.1989.99963	computer vision;specular reflection;photometric stereo;reflectivity;optics;specular highlight;remote sensing	Robotics	56.997756037868456	-49.457955646385095	96402
8aa06ab7799cabac0c46e71f21c854d0ed2a4aa6	cumulative generation of octree models from range data	sensor phenomena and characterization;range data;testing;layout;computational modeling layout image generation polynomials mesh generation testing computer science software packages sensor phenomena and characterization computer aided manufacturing;three dimensional;polynomials;computational modeling;image generation;range image;computer aided manufacturing;software package;computer science;cumulant;mesh generation;software packages	This paper describes algorithms used to assimilate one or more range images into an octree model of the three dimensional space surrounding the subject of the range images. In addition, a software package for simulating a three dimensional sensor setup is described.	octree	Christopher I. Connolly	1984		10.1109/ROBOT.1984.1087212	layout;three-dimensional space;mesh generation;simulation;computer science;theoretical computer science;software testing;sparse voxel octree;computational model;engineering drawing;statistics;polynomial;cumulant;computer-aided manufacturing	Robotics	66.28975853040663	-42.77886010324738	96963
bd4ba557608f729fdd5b3a94df25090be3d74dda	new cnn based algorithms for the full penetration hole extraction in laser welding processes: experimental results.	pixel parallel cnn based architectures;lasers;cnn based algorithms;production engineering computing cellular neural nets feature extraction image resolution laser beam welding manufacturing processes;image resolution;real time control;real time;cellular neural network;laser welding processes;laser welding;welding;eyeris systems;laser beams;cellular neural nets;materials;eyeris systems laser welding processes cnn based algorithms full penetration hole extraction manufacturing processes cellular neural networks real time signal processing properties pixel parallel cnn based architectures;production engineering computing;analog circuits;laser beam welding;manufacturing processes;heuristic algorithms;feature extraction;signal processing;real time signal processing properties;pixel;process control;full penetration hole extraction;cellular neural networks;cellular neural networks welding signal processing algorithms process control vehicle dynamics manufacturing processes automobiles production optical control circuits	In this paper the results obtained by the use of new CNN based visual algorithms for the control of welding processes are described. The growing number of laser welding applications from automobile production to micro mechanics requires fast systems to create closed loop control for error prevention and correction. Nowadays the image processing frame rates of conventional architectures [1] are not sufficient to control high speed laser welding processes due to the fast fluctuation of the full penetration hole [3]. This paper focuses the attention on new strategies obtained by the use of the Eye-RIS system v1.2 which includes a pixel parallel Cellular Neural Network (CNN) based architecture called Q-Eye [2]. In particular, new algorithms for the full penetration hole detection with frame rates up to 24 kHz will be presented. Finally, the results obtained performing real time control of welding processes by the use of these algorithms will be discussed.	algorithm;cellular neural network;eb-eye;fiber laser;image processing;penetration test;pixel;robot welding;universal conductance fluctuations	Leonardo Nicolosi;Ronald Tetzlaff;Felix Abt;Heinrich Höfler;Andreas Blug;Daniel Carl	2009	2009 International Joint Conference on Neural Networks	10.1109/ISCAS.2009.5118362	control engineering;computer vision;electronic engineering;cellular neural network;computer science;engineering;signal processing;process control;laser beam welding	Robotics	62.34201590924826	-38.85312757734498	97540
e582bcc63e3d23f48e227424e797df947896c87b	eyeshine rendering: a real time rendering method for realistic animal eyes		In this paper, we propose a real-time rendering method considering tapetum lucidum reflection. We aim to establish a technique to express the eyeshine of animals more realistically.	real-time clock	Yuna Omae;Tokiichiro Takahashi	2017		10.1145/3145690.3145746	computer vision;computer graphics (images);rendering (computer graphics);real-time rendering;artificial intelligence;computer science;tapetum lucidum	Graphics	63.47467845601092	-50.95350416706858	97822
5847fdd94727a72f6b6dd95d013a936042cb9a87	sketch-based 3d face modeling for virtual character	virtual characters;real time;3d model;face modeling	It is very important for virtual character designers to generate 3D face models interactively and creatively in real-time. This paper investigates the use of sketch-based interface in 3D face modeling and focuses on how to map 2D sketchy features onto a 3D model. A mapping mechanism on the basis of contour lines is proposed. Representative points of the input are extracted, which retain the global and local shape originalities. Then the outer and inner contours are extracted automatically from a given 3D face model (as a template model), and a set of feature points are determined according to the 2D representative points. The displacements between the 2D representatives and the 3D feature points are calculated and used as the control parameters of model deformation. A novel face model is finally created by means of deforming the given model. The experiments show the efficiency and effectiveness	adobe freehand;contour line;experiment;interactivity;real-time locating system;requirement;sketch	Wei Jiang;Zhengxing Sun	2010	Trans. Edutainment	10.1007/978-3-642-14484-4_18	computer vision;computer science;artificial intelligence;computer graphics (images)	Vision	65.57018482519598	-46.674749943556826	98041
8bb4525fb1d8517fbce3af2618773504e2f73e91	a solution of correspondence problem for measuring 3d surface	computational techniques;structured light;correspondence problem;facial animation;laboratories facial animation	This paper deals with the correspondence problem of two grabbed images, obtained by projecting a structured light on the measuring surface, when 3D information of a given surface is needed. In our system, the constraint that codifies the pattern projected on the surface has been simplified by using a random speckle pattern, thus the correspondence problem is reduced to the local matching between two grabbed images and solved by a spatial distance computation technique. Experiments have shown the feasibility of the proposed method.	computation;correspondence problem;structured light	Yung-Sheng Chen;Bor-Tow Chen	2002	2002 IEEE International Conference on Acoustics, Speech, and Signal Processing	10.1109/ICASSP.2002.5745422	computer vision;computer facial animation;structured light;computer science;mathematics;correspondence problem;computer graphics (images)	Robotics	56.70264067551623	-49.67168299828978	98193
c4da2560dae1aa6cf251231e9d520c712c734d69	the theory, design, implementation and evaluation of a three-dimensional surface detection algorithm	three dimensional imaging;computed tomographic;three dimensional;directed graph;detection algorithm;clinical study;medical application;boundary detection;connected component;large scale problem	In many three-dimensional imaging applications the three-dimensional scene is represented by a three-dimensional array of volume elements, or voxels for short. A subset Q of the voxels is specified by some property. The objects in the scene are then defined as subsets of Q formed by voxels which are “connected” in some appropriate sense. It is often of interest to detect and display the surface of an object in the scene, specified say by one of the voxels in it.  In this paper, the problem of surface detection is translated into a problem of traversal of a directed graph, G. The nodes of G correspond to faces separating voxels in Q from voxels not in Q. It has been proven that connected subgraphs of G correspond to surfaces of connected components of Q (i.e., of objects in the scene). Further properties of the directed graph have been proven, which allow us to keep the number of marked nodes (needed to avoid loops in the graph traversal) to a small fraction of the total number of visited nodes.  This boundary detection algorithm has been implemented. We discuss the interaction between the underlying mathematical theory and the design of the working software. We illustrate the software on some clinical studies in which the input is computed tomographic (CT) data and the output is dynamically rotating three-dimensional displays of isolated organs. Even though the medical application leads to very large scale problems, our theory and design allows us to use our method routinely on the minicomputer of a CT scanner.	algorithm;ct scan;connected component (graph theory);directed graph;graph traversal;minicomputer;tomography;tree traversal;voxel	Ehud Artzy;Gideon Frieder;Gabor T. Herman	1980		10.1145/800250.807461	three-dimensional space;computer vision;combinatorics;connected component;directed graph;theoretical computer science;mathematics	Graphics	67.5073200874778	-47.97219778966768	98278
aba563e424292f0bc3de633d4425d1e80533be35	independent local mapping for large-scale slam		SLAM algorithms do not perform consistent maps for large areas mainly due to the uncertainties that become prohibitive when the scenario becomes larger and to the increase of computational cost. The use of local maps has been demonstrated to be well suited for mapping large environments, reducing computational cost and improving map consistency. This paper proposes a technique based on using independent local maps. Every time a loop is detected, these local maps are corrected using the information from local maps that overlap with them. Meanwhile a global stochastic map is kept through loop detection and minimization as it is done in the classical Hierarchical SLAM approach. This global level contains the relative transformations between local maps, which are updated once a new loop is detected. In addition, the information within the local maps is also corrected, maintaining always each local map separately. This approach requires robust data association algorithms, for instance, an adapted version of the JCBB algorithm. Experimental results show that our approach is able to obtain large maps areas with high accuracy.	algorithm;algorithmic efficiency;computation;correspondence problem;cycle detection;joint compatibility branch and bound;map;simultaneous localization and mapping	Josep Aulinas;Xavier Lladó;Yvan R. Petillot;Joaquim Salvi	2009			mathematical optimization;mathematics;robust statistics	ML	54.818946525344316	-41.28705341357789	98521
696d44841d6ef83891c72468df054dd318ebb205	a theory of differential photometric stereo for unknown isotropic brdfs	constant magnitude isocontours;geometry;computational geometry;surface gradient unknown isotropic brdf differential photometric stereo theory photometric surface reconstruction image derivatives surface geometry constant magnitude isocontours;light sources lighting equations geometry surface reconstruction image reconstruction optical variables control;differential photometric stereo theory;surface reconstruction;surface geometry;stereo image processing computational geometry image reconstruction photometry;photometry;photometric stereo;photometric surface reconstruction;image reconstruction;stereo image processing;image derivatives;unknown isotropic brdf;lighting;light sources;optical variables control;surface gradient	This paper presents a comprehensive theory of photometric surface reconstruction from image derivatives. For unknown isotropic BRDFs, we show that two measurements of spatial and temporal image derivatives, under unknown light sources on a circle, suffice to determine the surface. This result is the culmination of a series of fundamental observations. First, we discover a photometric invariant that relates image derivatives to the surface geometry, regardless of the form of isotropic BRDF. Next, we show that just two pairs of differential images from unknown light directions suffice to recover surface information from the photometric invariant. This is shown to be equivalent to determining isocontours of constant magnitude of the surface gradient, as well as isocontours of constant depth. Further, we prove that specification of the surface normal at a single point completely determines the surface depth from these isocontours. In addition, we propose practical algorithms that require additional initial or boundary information, but recover depth from lower order derivatives. Our theoretical results are illustrated with several examples on synthetic and real data.	algorithm;bidirectional reflectance distribution function;gradient;image derivatives;normal (geometry);photometric stereo;synthetic intelligence	Manmohan Krishna Chandraker;Jiamin Bai;Ravi Ramamoorthi	2011	CVPR 2011	10.1109/CVPR.2011.5995603	iterative reconstruction;computer vision;photometric stereo;surface reconstruction;photometry;computational geometry;computer science;lighting;mathematics;geometry	Vision	55.12225337383418	-51.765350562659386	98723
064726f71f692f5cd9eb693f50d983f2071a828f	technical section: interactive example-based hatching	hatching;non photorealistic rendering;pen and ink;example based;interactive illustrative rendering;hatching by example;illustrations by example;illustrative rendering;interactive example based;models;style transfer;learning hatching	We present an approach for interactively generating pen-and-ink hatching renderings based on handdrawn examples. We aim to overcome the regular and synthetic appearance of the results of existing methods by incorporating human virtuosity and illustration skills in the computer generation of such imagery. To achieve this goal, we propose to integrate an automatic style transfer with user interactions. This approach leverages the potential of example-based hatching while giving users the control and creative freedom to enhance the aesthetic appearance of the results. Using a scanned-in hatching illustration as input, we use image processing and machine learning methods to learn a model of the drawing style in the example illustration. We then apply this model to semi-automatically synthesize hatching illustrations of 3D meshes in the learned drawing style. In the learning stage, we first establish an analytical description of the hand-drawn example illustration using image processing. A 3D scene registered with the example drawing allows us to infer object-space information related to the 2D drawing elements. We employ a hierarchical style transfer model that captures drawing characteristics on four levels of abstraction, which are global, patch, stroke, and pixel levels. In the synthesis stage, an explicit representation of hatching strokes and hatching patches enables us to synthesize the learned hierarchical drawing characteristics. Our representation makes it possible to directly and intuitively interact with the hatching illustration. Amongst other interactions, users of our system can brush with patches of hatching strokes onto a 3D mesh. This interaction capability allows illustrators who are working with our system to make use of their artistic skills. Furthermore, the proposed interactions allow people without a background in hatching to interactively generate visually appealing hatching illustrations. & 2012 Elsevier Ltd. All rights reserved.	3d printing;history of computing hardware;image processing;interaction;interactivity;machine learning;pixel;principle of abstraction;semiconductor industry;synthetic intelligence;virtuosity	Moritz Gerl;Tobias Isenberg	2013	Computers & Graphics	10.1016/j.cag.2012.11.003	computer vision;simulation;computer science;non-photorealistic rendering;multimedia;computer graphics (images)	AI	65.04401887776305	-47.549758238691794	98752
15e77dbf714d0ed1c21d1e4d53e5054b942bd096	visual simulation of lightning	implicit surface;raytracing;physics based modeling;computer graphics;visual simulation;computer graphic;implicit surfaces;particle system;lightning;computer science	A method for rendering lightning using conventional raytracing techniques is discussed. The approach taken is directed at producing aesthetic images for animation, rather than providing a realistic physically based model for rendering. A particle system is used to generate the path of the lightning channel, and subsequently to animate the lightning. A technique, using implicit surfaces, is introduced for illuminating objects struck by lightning.	augmented reality;implicit surface;lightning;particle system;ray tracing (graphics);simulation	Todd R. Reed;Brian Wyvill	1994		10.1145/192161.192256	lightning;ray tracing;computer vision;simulation;computer science;particle system;computer graphics;computer graphics (images)	Graphics	64.39559878782705	-50.282387562132804	98781
46321f9e158836732306c2006547af162275dc1e	an approach to visualizing transparency in computer-generated line drawings	line drawings;brightness;data visualisation;traditional drawing techniques transparency visualization computer generated line drawings hand made line drawings brightness image generation;visualization rendering computer graphics computer graphics books copper computational modeling computer simulation brightness image generation shape;rendering computer graphics data visualisation brightness;rendering computer graphics;general line	This paper builds on principles of depicting transparency in hand-made line drawings, and develops a method to generate similar, but computer-generated, line drawings in a two-step process. In the rst step a brightness image is generated which is used as a basis for the line drawing created in the second step. Three di erent methods derived from traditional drawing techniques are shown.	computer-generated holography;line drawing algorithm	Jörg Hamel;Stefan Schlechtweg-Dorendorf;Thomas Strothotte	1998		10.1109/IV.1998.694213	visual arts;computer vision;technical drawing;scientific visualization;image-based modeling and rendering;computer science;real-time computer graphics;computer graphics;3d computer graphics;computer graphics (images)	Graphics	64.1487973763554	-49.3236332230148	98834
7bf95c608a1d35220d799560ffd72e9315444d15	shape measurement of columnar objects with specular surfaces by slit ray projection method	diffuse object;projection method;slit ray projection method;shape measurement;specular object;three dimensional shape measurement	In this paper, a method for measuring the shape of a columnar object with specular surfaces by a slit ray projection method is proposed. Although the slit ray projection method is effective for measuring the shape of an object having diffuse reflective characteristics, applying the method to an object with specular surfaces has hitherto been difficult. In this paper, a triangulation equation for a columnar object with specular surfaces is derived and used as the basis of a method for measuring the shape of an object having specular surfaces using applicable slit rays. The basic principle is that the angle of incidence of a slit ray reflected from the measured object into an image sensor is restricted specifically by the special design of the optical system. In addition to the theoretical study of the proposed principle, a system for measuring the shape of a columnar specular object and a diffuse object was created and its effectiveness was verified. © 2002 Wiley Periodicals, Inc. Syst Comp Jpn, 33(4): 5060, 2002; Published online in Wiley Interscience (www.interscience.wiley.com). DOI 10.1002/scj.1119	approximation;artificial neural network;blu-ray;digi-comp i;evolutionary systems;experiment;genetic algorithm;image sensor;incidence matrix;john d. wiley;object-based language;sensible soccer;signal processing;simulation;xfig	Mitsuru Baba;Tadataka Konishi;Hisashi Handa	2002	Systems and Computers in Japan	10.1002/scj.1119	computer vision;mathematics;geometry;projection method;specular highlight	Vision	57.429205831505165	-51.4552537255475	98968
4efbd23a95676265f2f2257c09e86d58604e2d45	automatic collage using texture synthesis	algorithme rapide;non photorealistic rendering;texture synthesis;pattern synthesis;qualite image;synthese forme;fast algorithm;image quality;calidad imagen;sintesis forma;algoritmo rapido	We present an application of texture synthesis in creating collages. We use the texture synthesis method proposed by Ashikhmin [1] to selectively copy patches of the source image onto the image to be stylized, creating an automatic collage. The underlying algorithm is fast and allows the user to iteratively improve the quality of the resulting image. We show the use of this algorithm in capturing various kinds of artistic qualities ranging from styles of famous painters to non photorealistic rendering.	algorithm;non-photorealistic rendering;texture synthesis;unbiased rendering	Stephen Ingram;Pravin Bhat	2004		10.1007/978-3-540-24678-7_15	image quality;computer vision;computer science;non-photorealistic rendering;texture synthesis;computer graphics (images)	Graphics	62.88519495034086	-48.50372509984699	99139
ca948036b707d7a78b32fd9c42ab0ed1b7c852c8	a novel hybrid kinect-variety-based high-quality multiview rendering scheme for glass-free 3d displays	three dimensional displays cameras rendering computer graphics sensors tv data mining;parameterized scene representation multi view 3d displays view generation kinect rgbd sensors image based rendering	This paper presents a new hybrid Kinect-variety-based synthesis scheme that renders artifact-free multiple views for autostereoscopic/automultiscopic displays. The proposed approach does not explicitly require dense scene depth information for synthesizing novel views from arbitrary viewpoints. Instead, the integrated framework first constructs a consistent minimal image–space parameterization of the underlying 3D scene. The compact representation of scene structure is formed using only implicit sparse depth information of a few reference scene points extracted from raw RGB depth data. The views from arbitrary positions can be inferred by moving the novel camera in parameterized space by enforcing Euclidean constraints on reference scene images under a full-perspective projection model. Unlike the state-of-the-art depth image-based rendering (DIBR) methods, in which input depth map accuracy is crucial for high-quality output, our proposed algorithm does not depend on precise per-pixel geometry information. Therefore, it simply sidesteps to recover and refine the incomplete or noisy depth estimates with advanced filling or upscaling techniques. Our approach performs fairly well in unconstrained indoor/outdoor environments, where the performance of range sensors or dense depth-based algorithms could be seriously affected due to scene complex geometric conditions. We demonstrate that the proposed hybrid scheme provides guarantees on the completeness, optimality with respect to the inter-view consistency of the algorithm. In the experimental validation, we performed a quantitative evaluation as well as subjective assessment of the scene with complex geometric or surface properties. A comparison with the latest representative DIBR methods is additionally performed to demonstrate the superior performance of the proposed scheme.	3d projection;3d television;algorithm;autostereoscopy;depth map;kinect;multiscopy;nvidia 3d vision;pixel geometry;refinement (computing);rendering (computer graphics);requirement;scene graph;sensor;sparse matrix	Mansi Sharma;Santanu Chaudhury;Brejesh Lall	2017	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2016.2564798	pattern recognition;artificial intelligence;rendering (computer graphics);autostereoscopy;computer vision;computer science;parametrization;image-based modeling and rendering;rgb color model;parameterized complexity;stereo display;depth map	Vision	53.79407668027341	-47.1015505611314	99249
6319269c0d1642544dd82983141d74af4fc2c0ba	skeleton extraction by mesh contraction	skinning;laplacian;segmentation;surface reconstruction;skeleton;computer graphic;computer vision;collision detection;shape matching;smoothing;laplacian smoothing;object extraction;virtual colonoscopy;mesh segmentation;mesh contraction;computer animation;extraction method	Extraction of curve-skeletons is a fundamental problem with many applications in computer graphics and visualization. In this paper, we present a simple and robust skeleton extraction method based on mesh contraction. The method works directly on the mesh domain, without pre-sampling the mesh model into a volumetric representation. The method first contracts the mesh geometry into zero-volume skeletal shape by applying implicit Laplacian smoothing with global positional constraints. The contraction does not alter the mesh connectivity and retains the key features of the original mesh. The contracted mesh is then converted into a 1D curve-skeleton through a connectivity surgery process to remove all the collapsed faces while preserving the shape of the contracted mesh and the original topology. The centeredness of the skeleton is refined by exploiting the induced skeleton-mesh mapping. In addition to producing a curve skeleton, the method generates other valuable information about the object's geometry, in particular, the skeleton-vertex correspondence and the local thickness, which are useful for various applications. We demonstrate its effectiveness in mesh segmentation and skinning animation.		Oscar Kin-Chung Au;Chiew-Lan Tai;Hung-Kuo Chu;Daniel Cohen-Or;Tong-Yee Lee	2008	ACM Trans. Graph.	10.1145/1360612.1360643	mesh generation;computer vision;laplace operator;surface reconstruction;computer science;laplacian smoothing;computer animation;segmentation;skeleton;t-vertices;collision detection;statistics;smoothing;computer graphics (images)	Graphics	68.18795468749607	-45.52938678695227	99323
50b2479da92c8e4ef85663c80bc34b8ff6f16b60	blister: gpu-based rendering of boolean combinations of free-form triangulated shapes	construccion arquitectura tecnologia ambiental;paper;sum of products;computacion informatica;time complexity;real time;grupo de excelencia;gpu;nvidia geforce 6800;image generation;graphics hardware;shaders;ciencias basicas y experimentales;nvidia;algorithms;depth peeling;computer science;tecnologias;csg	By combining depth peeling with a linear formulation of a Boolean expression called Blist, the Blister algorithm renders an arbitrary CSG model of n primitives in at most k steps, where k is the number of depth-layers in the arrangement of the primitives. Each step starts by rendering each primitive to produce candidate surfels on the next depth-layer. Then, it renders the primitives again, one at a time, to classify the candidate surfels against the primitive and to evaluate the Boolean expression directly on the GPU. Since Blist does not expand the CSG expression into a disjunctive (sum-of-products) form, Blister has O(kn) time complexity. We explain the Blist formulation while providing algorithms for CSG-to-Blist conversion and Blist-based parallel surfel classification. We report real-time performance for nontrivial CSG models. On hardware with an 8-bit stencil buffer, we can render all possible CSG expressions with 3909 primitives.	graphics processing unit;polygon triangulation	John Hable;Jarek Rossignac	2005	ACM Trans. Graph.	10.1145/1073204.1073306	time complexity;shader;computer science;theoretical computer science;geometry;canonical normal form;graphics hardware;algorithm;computer graphics (images)	Graphics	67.03628170069105	-50.49944555946347	99416
a2be0a4a2b37f21dae36ac66f9a06dd61c1ffeb8	efficient 6-dof slam with treemap as a generic backend	6 dof slam;mobile robots;software engineering;simultaneous localization and mapping uncertainty robot sensing systems cognition least squares approximation robotics and automation open source software mobile robots orbital robotics cameras;robot vision;treemap;simultaneous localization and mapping;slam robots mobile robots robot vision;simultaneous localization and mapping 6 dof slam treemap;point of view;slam robots;open source	Treemap is a generic SLAM algorithm that has been successfully used to estimate extremely large 2D maps closing a loop over a million landmarks in 442ms. We are currently working on an open-source implementation that can handle most variants of SLAM. In this paper we discuss the generic part of the algorithm constituting the treemap backend and the variant specific parts acting as a driver. We present their interplay from a software-engineering point of view and show results for the case of 6-DOF feature based SLAM, closing a simulated loop over 106657 3D features in 209ms.	3d computer graphics;algorithm;closing (morphology);front and back ends;map;microsoft outlook for mac;odometry;open-source software;simultaneous localization and mapping;software architecture;software engineering;treemapping	Udo Frese	2007	Proceedings 2007 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2007.364221	treemapping;mobile robot;embedded system;computer vision;simulation;computer science;engineering;artificial intelligence;simultaneous localization and mapping	Robotics	54.076578392661375	-38.20584943338459	99466
e9086bc308edfc4d2ea78bf84009e6c54a0c70cb	consistency based calibration approach for visual-laser scanner	optimisation;optical scanners;nonlinear optimization framework consistency based calibration approach visual laser scanner robotics community color depth sensors collision avoidance robotic path planning rigid body transformation complimentary sensors extrinsic calibration;conference paper;robot vision;calibration three dimensional displays lasers visualization feature extraction sensors cameras;robot vision calibration optical scanners optimisation;calibration	Recently, the robotics community has widely used color-depth (RGB-D) sensors for various applications, such as collision avoidance, navigation and robotic path planning. To effectively utilize the benefit of depth and color modalities, it is important to know the relative pose between these sensors. In this paper we proposed a theoretical and practical approach to estimate the rigid body transformation between these complimentary sensors (extrinsic calibration). The proposed work is based upon the exploitation of some common characteristics, between theses different modalities, by integrating a consistency criteria in the nonlinear optimization framework. The calibration procedure does not require any calibration object and directly operate on the visual correspondences. We have presented calibration results on low-cost built visual-laser scanner for indoor and outdoor environments. We have also compared our approach with the existing work and found the results to be more accurate.	color depth;mathematical optimization;motion planning;nonlinear programming;nonlinear system;open-source software;robot;robotics;sensor;simultaneous localization and mapping	Usman Qayyum;Jonghyuk Kim	2013	2013 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2013.6739870	computer vision;calibration;simulation;engineering;optics;robot calibration	Robotics	53.76320310565326	-42.26117026446062	99520
8caf38efd1d2bb655c89ecbf0038c1a2b5920fdc	differential point rendering	differential geometry;hardware accelerator;generic point	We present a novel point rendering primitive, called Differential Point (DP), that captures the local differential geometry in the vicinity of a sampled point. This is a more general point representation that, for the cost of a few additional bytes, packs much more information per point than the traditional point-based models. This information is used to efficiently render the surface as a collection of local neighborhoods. The advantages to this representation are manyfold: (1) it delivers a significant reduction in the number of point primitives that represent a surface (2) it achieves robust hardware accelerated per-pixel shading – even with no connectivity information (3) it offers a novel point-based simplification technique that has a convenient and intuitive interface for the user to efficiently resolve the speed versus quality tradeoff. The number of primitives being equal, DPs produce a much better quality of rendering than a pure splatbased approach. Visual appearances being similar, DPs are about two times faster and require about 75% less disk space in comparison to splatting primitives.	brookgpu;byte;c++;computation;disk space;glossary of computer graphics;ibm notes;informatics;level of detail;multiresolution analysis;non-uniform rational b-spline;pixel;rendering (computer graphics);rhinoceros;sampling (signal processing);shader;shading;sparse matrix;text simplification;texture mapping;tuple space;visual computing	Aravind Kalaiah;Amitabh Varshney	2001		10.2312/EGWR/EGWR01/139-150	differential geometry;computer vision;discrete mathematics;hardware acceleration;computer science;theoretical computer science;generic point;mathematics;geometry;computer graphics (images)	Graphics	67.26065523269494	-49.986065098854	99565
60df2ef956bcf2ef72c18cf1a7a5fbdcf114d071	simultaneous pose and reliability estimation using convolutional neural network and rao-blackwellized particle filter			artificial neural network;convolutional neural network;particle filter	Naoki Akai;Luis Yoichi Morales Saiki;Hiroshi Murase	2018	Advanced Robotics	10.1080/01691864.2018.1509726		Robotics	54.29002412328809	-38.01912028210355	99577
0abea6559d9db31865ee357e5cf9a4b2bf426283	automatic unstructured grid generation based on iterative point insertion	automatic mesh generation;insertion;discretisation;grid generation;intersections;generation automatique maille;tetraedro;three dimensional shape;volume;discretization;adaptive grid;tetrahedron;discretizacion;simulated annealing;forma tridimensional;maillage non structure;generacion automatica red;volumen;recuit simule;forme tridimensionnelle;unstructured grid;insercion;tetraedre;surface;surfaces;triangulation;intersection	Unstructured grid generation is concerned with discretizing surfaces and volumes in 3D space by triangles and tetrahedra. The tetrahedra discretize a volume in a surface's interior or surrounding a surface on its outside. This paper presents a new technique for unstructured grid generation based on intersecting lines with a given geometry and inserting grid points yielding an adapted grid whose point density decreases with increasing distance to the geometry. The technique is completely automatic. Unstrukturierte Diskretisierungsverfahren dienen der diskreten Beschreibung von Flächen und Volumina in Form von Dreiecken und Tetraedern. Tetraeder werden zur Diskretisierung eines Volumens benutzt, das auf der Innen- oder Außenseite einer vorgegebenen Fläche liegt. Diese Arbeit behandelt ein automatisches Verfahren zur Generierung von Tetraedern. Das Verfahren basiert auf einem Schnittalgorithmus, der Geraden mit einer vorgegebenen Fläche schneidet und iterative Punkte einfügt. Die resultierende Punktdichte nimmt mit Zunehmender Distanz zur Fläche ab.	discretization;intersection (euclidean geometry);iteration;iterative method;mesh generation;unstructured grid	Bernd Hamann;H. J. Thornburg;G. Hong	1995	Computing	10.1007/BF02238098	unstructured grid;topology;alpha-numeric grid;discretization;mathematics;geometry;surface	HPC	65.94953106328286	-40.70233261833052	99626
3cc9ae2c2e6179441ce51854dd7407d7e6aec3db	graceful planes and lines	discrete 3d modeling;discrete scheme;triangular shape;polyedre;modelo 3 dimensiones;computer graphics;poliedro;modele 3 dimensions;schema discret;three dimensional shape;three dimensional model;polyhedron;esquema discreto;triangular mesh;forme triangulaire;geometria discreta;forma tridimensional;3d model;mesh of triangles;forme tridimensionnelle;geometrie discrete;discrete geometry;forma triangular;discrete triangles;grafico computadora;discrete planes;triangle mesh;infographie;discrete lines	In the framework of the theory of arithmetic geometry (Reveill. es, G/ eom/ etrie Discr. ete, Calcul en Nombres Entiers et Algorithmique, Th. ese d’/ etat, Universit/ e Louis Pasteur, Strasbourg, 1991), we propose an approach to discretize polyhedra by meshes of discrete triangles. We propose a general discretization scheme based on reducing the 3D problem to a 2D problem. We introduce new classes of discrete planes and lines called graceful planes and graceful lines. Naive planes and graceful lines are used to construct as thin as possible triangular mesh discretization admitting an analytical description. The interiors of the triangles are portions of naive planes, while the sides are graceful lines. These primitives serve as an optimal ground for obtaining thin tunnel-free discretizations, within the adopted generation scheme. We also extend our considerations to arbitrary surfaces and curves. c © 2002 Elsevier Science B.V. All rights reserved.	discretization;graceful exit;polyhedron	Valentin E. Brimkov;Reneta P. Barneva	2002	Theor. Comput. Sci.	10.1016/S0304-3975(01)00061-5	discrete geometry;combinatorics;topology;computer science;triangle mesh;mathematics;geometry	Theory	67.6837988283192	-40.049934232923775	99640
234b90534416ea9de156f80234048aaf84603c56	automatic 3d modeling of archaeological objects	frequency domain analysis;computer vision;3d model;three dimensional displays solid modeling iterative closest point algorithm conferences frequency domain analysis computer vision pattern recognition;three dimensional displays;solid modeling;pattern recognition;profitability;iterative closest point algorithm;conferences	A wide-spread use of 3D models in archeology application requires low cost equipment and technically simple modeling procedures. In this context methods for automatic 3D modeling based on fully automatic techniques for 3D views registration will play a central role. This paper proposes a very robust procedure which does not require special equipment or skill in order to make 3D models. The results of this paper, originally conceived to address the costs issues of heritage's modeling, can be profitably exploited also in other modeling applications.	3d modeling	Marco Andreetto;Nicola Brusco;Guido M. Cortelazzo	2003	2003 Conference on Computer Vision and Pattern Recognition Workshop	10.1109/CVPRW.2003.10006	computer vision;simulation;computer science;machine learning;solid modeling;frequency domain;profitability index;computer graphics (images)	Vision	57.91485591247307	-47.40106521173795	99893
4c782bad4122746c02588a740fd4c90d25e4897c	multiresolution constraints for designing subdivision surfaces via local smoothing	wavelet transforms solid modelling computer graphics;computer graphics;multiresolution modeling;subdivision surface;wavelet transforms;smoothing methods;optimal surface shape multiresolution constraints subdivision surfaces local smoothing multiresolution modeling variational smoothing wavelet based framework local smooth filtering;geometric constraints;solid modelling	Subdivision surfaces provide an efficient means of representing surfaces of arbitrary topological type. In recent years, multiresolution modeling with variational smoothing has played an important role in controlling such surfaces. This paper presents a new model of multiresolution constraints that can be applied to subdivision surfaces. The advantage of this model is that different geometric constraints can be imposed on the surfaces at different resolution levels. The model employs the wavelet-based framework of Lounsbery, et al. (1997), to represent the subdivision surfaces in a hierarchical fashion. In the proposed framework, local smooth filtering is used to obtain the optimal surface shape at each resolution level. Controlling the number of iterations for the local smoothing operations allows us to modify the smoothness of the subdivision surfaces even when the same set of constraints is given. Several design examples are included to demonstrate the capability of this model.	smoothing;subdivision surface	Shigeo Takahashi	1999		10.1109/PCCGA.1999.803360	computer vision;mathematical optimization;computer science;mathematics;geometry;computer graphics;subdivision surface;wavelet transform	Vision	68.11319037907887	-45.45691187512724	99901
f043824a1d6ae1eb2ae1d5c1845c0a050efdf345	visual multiple target tracking from a descending aerial platform		A real-time visual multiple target tracker is demonstrated onboard a descending multirotor. Measurements of moving ground targets are generated using the Kanade-Lucas-Tomasi (KLT) tracking method. Homography-based image registration is used to align the measurements into the same coordinate frame, allowing for the detection of independently moving objects. The recently developed Recursive-RANSAC algorithm uses the visual measurements to estimate targets in clutter. Altitude-dependent tuning increases track continuity and coverage during the descent of the vehicle. The algorithm requires no operator interaction and increases the situation awareness of the unmanned aerial system. Real-time tracking efficiency is analyzed on GPUs and CPUs. Tracking results are presented and discussed using the MOTA and MOTP metrics.		Parker C. Lusk;Randal W. Beard	2018	2018 Annual American Control Conference (ACC)	10.23919/ACC.2018.8431915	control engineering;computer science;kalman filter;clutter;feature extraction;multirotor;image registration;computer vision;artificial intelligence	Robotics	53.78921149118318	-38.794882917223546	100214
689aa04403897f5d0e1983d845c1784da0d651ce	special issue on virtual representations and modeling of large-scale environments (vrml)		In recent years computer vision has reached a level of maturity in structure from motion and multi-view stereo techniques that enables the reconstruction of large-scale environments. At the same time the progress made in computer graphics and network technology allows for effective visualization and delivery of such visual representations. We now start to see computer vision methods at work in our everyday lives. The next step is to research computer vision methods using large-scale visual databases for realworld 3D modeling. Despite the enormous progress there are still many challenges left. The current state of the art in large-scale structure from motion with millions of images faces the challenges of:	3d modeling;capability maturity model;computer graphics;computer vision;database;structure from motion;vrml	Jan-Michael Frahm;Marc Pollefeys;Frank Dellaert;Jana Kosecka	2012	Computer Vision and Image Understanding	10.1016/j.cviu.2011.11.001	human–computer interaction;computer science;multimedia;computer graphics (images)	Vision	54.35436129112212	-45.56019238111731	100515
50b942401cb90487485a7181bbbd0bdab2ebe4f0	from sketch to solid: an algebraic cross-section criterion for the realizability of a wireframe sketch	calcul scientifique;analisis numerico;05c10;17 08;polyedre;non linear systems;34g20;poliedro;51n99;polyhedron;analyse numerique;algorithme;52bxx;algorithm;computacion cientifica;numerical analysis;computer aided sketching;26d99;93c10;realizability;cross section test;geometric modeling;cross section;68u05;68u07;52b70;scientific computation;non linear system;11e39;algoritmo	An intermediate step in the construction of a polyhedron from a partial-view sketch is the derivation of a realizable wireframe sketch, i.e., a complete sketch which is guaranteed to be the projection of a polyhedron. This paper presents a robust realizability-test based on the classical “cross-section criterion” that was developed in a geometric “ruler-and-compass” framework.	linear algebra;polyhedron;wire-frame model	Sofia Kyratzi;Nickolas S. Sapidis	2009	Computing	10.1007/s00607-009-0058-3	combinatorics;nonlinear system;numerical analysis;geometric modeling;mathematics;cross section;geometry;algorithm;polyhedron	Theory	67.86423139531361	-40.11529059482483	100540
9f247e7f9b86d1861c019bd92712bece8b3dc03a	complex motion, first international workshop, iwcm 2004, günzburg, germany, october 12-14, 2004. revised papers	order tensor;planar surface patch;novel representation;motion field;projective space;spatio-temporal orientation tensors;practical computation;usual orientation tensor;normal matrix algebra;proposed representation;normal matrix	This paper presents a novel representation for 3D shapes in terms of planar surface patches and their boundaries. The representation is based on a tensor formalism similar to the usual orientation tensor but extends this concept by using projective spaces and a fourth order tensor, even though the practical computations can be made in normal matrix algebra. This paper also discusses the possibility of estimating the proposed representation from motion field which are generated by a calibrated camera moving in the scene. One method based on 3D spatio-temporal orientation tensors is presented and results from this method are included.			2006		10.1007/978-3-540-69866-1		Vision	54.63336057022504	-50.72589113612509	100568
6b94d8c798caa42eb97aeb6f35e3068a92708ac8	light transport refocusing for unknown scattering medium	optical focusing image sensors light propagation light scattering;geometrical conditions light transport refocusing method depth estimation scattering properties propagated visible light rays 2d light source 2d image sensor 4d light transport shallow depth deep depth plane depth from focus method milk water type scattering medium acrylic type scattering medium optical conditions;scattering media cameras light sources lenses visualization	In this paper we propose a new light transport refocusing method for depth estimation as well as for investigation inside scattering media with unknown scattering properties. Propagated visible light rays through scattering media are utilized in our proposed refocusing method. We use 2D light source to illuminate the scattering media and 2D image sensor for capturing transported rays. The proposed method that uses 4D light transport can clearly visualize shallow depth, as well as deep depth plane of the medium. We apply our light transport refocusing method for depth estimation using conventional depth-from-focus method and for clear visualization by descattering the light rays passing through the medium. To evaluate the effectiveness we have done experiments using acrylic and milk-water type scattering medium in various optical and geometrical conditions. Finally, we show up the results of depth estimation and clear visualization, as well as with numeric evaluation.	experiment;image sensor;light transport theory;ray (optics)	Md. Abdul Mannan;Seiichi Tagawa;Toru Tamaki;Hajime Nagahara;Yasuhiro Mukaigawa;Yasushi Yagi	2014	2014 22nd International Conference on Pattern Recognition	10.1109/ICPR.2014.750	multiangle light scattering;light scattering;scattering	Vision	60.0790499572641	-52.072640407488414	100876
da2d9c6dd4711c3eae1495e84d2fad71e3d24de1	a robust approach for automatic detection and segmentation of cracks in underground pipeline images	curvature evaluation;mathematical morphology;north america;3d visualization;linear filtering;statistical evaluation;automatic detection;crack detection;geometric modeling;geometric model;pipe crack detection	Cracks in underground pipeline images are indicative of the condition of buried infrastructures like sewers and water mains. This paper presents a three step method to identify and extract crack-like structures from pipe images whose contrast have been enhanced. The proposed method is based on mathematical morphology and curvature evaluation that detects crack-like patterns in a noisy environment. Careful observation reveals that the cracks resemble a tree-like geometry in most cases which can be a usable feature for registration between successive images of the same region taken from various depths in the thickness of the buried pipe (3D visualization). In this study, segmentation is performed with respect to a precise geometric model to define crack-like patterns. Cracks in pipe images can be defined as clearly visible patterns (darkest in the image), locally linear and branching in a piece-wise fashion. First, the cracks are enhanced by mathematical morphology with respect to their spatial properties. In order to differentiate cracks from analogous background patterns, cross-curvature evaluation followed by linear filtering is performed. We discuss its implementation on 225 pipe images taken from various cities in North America and statistically evaluate its accuracy and robustness with respect to varying pipe background color, crack geometries and background noise.		Shivprakash Iyer;Sunil K. Sinha	2005	Image Vision Comput.	10.1016/j.imavis.2005.05.017	computer vision;computer science;geometric modeling	Vision	59.56344909241409	-48.491656213070975	100971
c679693783c8dc2d82feb350563bf03e294c9681	an efficient image morphing technique for camera phones	camera phone		morphing	Tarek K. Alameldin;Tina Bajwa;Gaurav Verma	2005			morphing;camera phone;computer graphics (images);computer vision;stereo camera;artificial intelligence;computer science	HCI	60.9493330295827	-47.64587810382203	101003
ec7c70892895b91b7ad12e53f5285e75676400bb	automatic reconstruction of tree skeletal structures from point clouds	urban environment;panoramas;tree structure;global optimization;laser scanning;point cloud;user interaction;equirectangular;laplace beltrami	Trees, bushes, and other plants are ubiquitous in urban environments, and realistic models of trees can add a great deal of realism to a digital urban scene. There has been much research on  modeling  tree structures, but limited work on  reconstructing  the geometry of real-world trees -- even then, most works have focused on reconstruction from photographs aided by significant user interaction. In this paper, we perform active laser scanning of real-world vegetation and present an automatic approach that robustly reconstructs skeletal structures of trees, from which full geometry can be generated. The core of our method is a series of  global optimizations  that fit skeletal structures to the often sparse, incomplete, and noisy point data. A significant benefit of our approach is its ability to reconstruct multiple overlapping trees simultaneously without segmentation. We demonstrate the effectiveness and robustness of our approach on many raw scans of different tree varieties.	point cloud	Yotam Livny;Feilong Yan;Matt Olson;Baoquan Chen;Hao Zhang;Jihad El-Sana	2010	ACM Trans. Graph.	10.1145/1882261.1866177	laser scanning;computer vision;mathematical optimization;simulation;equirectangular projection;computer science;machine learning;point cloud;mathematics;geometry;tree structure;global optimization;computer graphics (images)	Graphics	56.23677234604156	-46.13048603192912	101151
9fb2199c9592e04dfd28413494ec806707f44af3	visual odometry aided by a sun sensor and inclinometer	error growth;wiley periodicals;visual odometry;sun sensor;inclinometer measurement;inclinometer data;localization improvement;visual odometry path estimate;stereo visual odometry pipeline;field testing;error term	In this paper, we present a novel approach to localization for planetary rovers, in which sun sensor and inclinometer measurements are incorporated directly into a stereo visual odometry pipeline. Utilizing the absolute orientation information provided by the sun sensor significantly reduces the error growth of the visual odometry path estimate. The measurements have minimal computation, power, and mass requirements, providing a localization improvement at nearly negligible cost. We describe the mathematical formulation of error terms for the stereo camera, sun sensor, and inclinometer measurements, as well as the bundle adjustment framework for determining the maximum likelihood vehicle transformation. Improved localization accuracy is demonstrated through extensive experimental results from a 10 kilometre traversal of a Mars analogue site on Devon Island in the Canadian High Arctic.	algorithm;autonomous car;bundle adjustment;computation;internationalization and localization;mer;planetary scanner;requirement;rover (the prisoner);sensor;stereo camera;traverse;visual odometry	Andrew Lambert;Paul Timothy Furgale;Tim D. Barfoot;John Enright	2011	2011 Aerospace Conference	10.1002/rob.21412	computer vision;simulation;visual odometry;odometry;remote sensing	Robotics	54.399740037772325	-41.74870326071757	101341
13c0fb2ba6ffe39085a467e29e21de3b4f710eea	dimensional reduction of high-frequency accelerations for haptic rendering	vibrations;bepress selected works;computer and information science;three dimensional;measurement based modeling;haptic rendering;haptic feedback;virtual environment;frequency domain;data och informationsvetenskap;haptic feedback vibrations measurement based modeling;dimensional reduction;high frequency	Haptics research has seen several recent efforts at understanding and recreating real vibrations to improve the quality of haptic feedback in both virtual environments and teleoperation. To simplify the modeling process and enable the use of single-axis actuators, these previous efforts have used just one axis of a threedimensional vibration signal, even though the main vibration mechanoreceptors in the hand are know to detect vibrations in all directions. Furthermore, the fact that these mechanoreceptors are largely insensitive to the direction of high-frequency vibrations points to the existence of a transformation that can reduce threedimensional high-frequency vibration signals to a one-dimensional signal without appreciable perceptual degradation. After formalizing the requirements for this transformation, this paper describes and compares several candidate methods of varying degrees of sophistication, culminating in a novel frequency-domain solution that performs very well on our chosen metrics.	apache axis;computation;computational resource;computer data storage;elegant degradation;haptic technology;hardware acceleration;real-time clock;requirement;stationary process;virtual reality	Nils Landin;Joseph M. Romano;William McMahan;Katherine J. Kuchenbecker	2010		10.1007/978-3-642-14075-4_12	three-dimensional space;computer vision;simulation;computer science;virtual machine;artificial intelligence;operating system;vibration;high frequency;haptic technology;frequency domain	Robotics	60.88795624098003	-43.7688229612059	101406
043d5b09f47851c63a89c95e3531c6e09493e93c	multiresolution sphere packing tree: a hierarchical multiresolution 3d data structure	sphere packing;msp tree;image processing;spatial data structure;selective refinement;multiresolution;energy minimization;data structure	Sphere packing arrangements are frequently found in nature, exhibiting efficient space-filling and energy minimization properties. Close sphere packings provide a tight, uniform, and highly symmetric spatial sampling at a single resolution. We introduce the Multiresolution Sphere Packing Tree (MSP-tree): a hierarchical spatial data structure based on sphere packing arrangements suitable for 3D space representation and selective refinement. Compared to the commonly used octree, MSP-tree offers three advantages: a lower fanout (a factor of four compared to eight), denser packing (about 24% denser), and persistence (sphere centers at coarse resolutions persist at finer resolutions). We present MSP-tree both as a region-based approach that describes the refinement mechanism succintly and intuitively, and as a lattice-based approach better suited for implementation. The MSP-tree offers a robust, highly symmetric tessellation of 3D space with favorable image processing properties.	alexander horned sphere;data structure;energy minimization;fan-out;image processing;max;octree;persistence (computer science);refinement (computing);regular map (graph theory);sampling (signal processing);set packing;space-filling curve	Jiro Inoue;Andrew J Stewart	2008		10.1145/1364901.1364954	mathematical optimization;combinatorics;data structure;image processing;mathematics;geometry;energy minimization;sphere packing	Graphics	67.29532017275073	-49.76465299400096	101520
51943ea41fbab5c3b4c9fc66f68a21c11618c8ee	animal gaits from video	time varying;3d animation;binary image;animation from motion video data;3d model;radial basis function;principal component analysis;interpolation keyframing;intuitive interfaces for animation	We present a method for animating 3D models of animals from existing live video sequences such as wild life documentaries. Videos are first segmented into binary images on which Principal Component Analysis (PCA) is applied. The time-varying coordinates of the images in the PCA space are then used to generate 3D animation. This is done through interpolation with Radial Basis Functions (RBF) of 3D pose examples associated with a small set of key-images extracted from the video. In addition to this processing pipeline, our main contributions are: an automatic method for selecting the best set of key-images for which the designer will need to provide 3D pose examples. This method saves user time and effort since there is no more need for manual selection within the video and then trials and errors in the choice of key-images and 3D pose examples. As another contribution, we propose a simple algorithm based on PCA images to resolve 3D pose prediction ambiguities. These ambiguities are inherent to many animal gaits when only monocular view is available.  The method is first evaluated on sequences of synthetic images of animal gaits, for which full 3D data is available. We achieve a good quality reconstruction of the input 3D motion from a single video sequence of its 2D rendering. We then illustrate the method by reconstructing animal gaits from live video of wild life documentaries.	3d modeling;algorithm;binary image;interpolation;motion capture;planning;principal component analysis;radial (radio);radial basis function;synthetic intelligence;video	Laurent Favreau;Lionel Revéret;Christine Depraz;Marie-Paule Cani	2004		10.1145/1028523.1028560	computer vision;radial basis function;simulation;binary image;computer science;artificial intelligence;machine learning;computer animation;principal component analysis;computer graphics (images)	Vision	59.965848309071625	-45.47303762800186	101554
42916ed38afb883634ddfb19dde94fbc2638d0d0	depth image-based representation and compression for static and animated 3-d objects	animacion por computador;rendu image;octree;image coding;octarbol;image coding animation layout rendering computer graphics computer graphics pixel mpeg 4 standard data structures region 8 laboratories;data compression;restitucion imagen;depth image;computer graphics;image based representation;representation image;octarbre;mpeg 4 animation framework extension;mpeg 4 animation framework extension afx;indexing terms;computer graphic;adaptive arithmetic coding depth image based representation image compression animated 3d objects static 3d objects computer graphics animation framework extension image based rendering simple texture point texture octree image data structures photorealistic representation;image texture;photorealistic representation;compression image;arithmetic codes;image compression;compact representation;data structures;image representation;image rendering;compression;image based rendering;computer animation;rendering computer graphics;afx;grafico computadora;data structure;image representation image coding computer animation rendering computer graphics image texture data structures arithmetic codes data compression;infographie;line of sight;compresion imagen;animation par ordinateur	This paper describes a new family of three-dimensional (3-D) representations for computer graphics and animation, called depth image-based representations (DIBR), which have been adopted into MPEG-4 Part16: Animation Framework eXtension (AFX). Idea of the approach is to build a compact and photorealistic representation of a 3-D object or scene without using polygonal mesh. Instead, images accompanied by depth values for each pixel are used. This type of representation allows us to build and render novel views of objects and scene with an interactive rate. There are many different methods for the image-based rendering with depths, and the DIBR format is designed to efficiently represent the information necessary for such methods. The main formats of the DIBR family are SimpleTexture (an image together with depth array), PointTexture (an image with multiple pixels along each line of sight), and OctreeImage (octree-like data structure together with a set of images containing viewport parameters). In order to store and transmit the DIBR object, we develop a compression algorithm and bitstream format for OctreeImage representation.	afx windows rootkit 2003;algorithm;bitstream format;data compression;data structure;glossary of computer graphics;mipmap;octree;pixel;polygon mesh;viewport	Leonid Levkovich-Maslyuk;Alexey V. Ignatenko;Alexander Zhirkov;Anton Konushin;In Kyu Park;Mahnjin Han;Yuri Bayakovski	2004	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2004.830676	data compression;image texture;computer vision;image-based modeling and rendering;index term;data structure;image compression;computer science;computer animation;multimedia;computer graphics;compression;octree;computer graphics (images)	Graphics	61.265170594901775	-49.94607536824126	101688
ac322299fa0e2abc1bed4ac2345c6836865ecf73	local iterative dlt soft-computing vs. interval-valued stereo calibration and triangulation with uncertainty bounding in 3d reconstruction	possibility;interval valued;computer vision;stereo;camera calibration	The use of stereo vision for 3D data gathering is affected by constraints in the position of the cameras, the quality of the optical elements and the numerical algorithms for calibration and matching. Also, there is not a wide agreement on the best procedure for bounding the 3D errors within an uncertainty volume. In this work, this problem is solved by implementing the whole set of computations, including calibration and triangulation, with interval data. This is in contrast with previous works that rely on Direct Linear Transform (DLT) as a camera model. To keep better with real lens aberrations, a local iterative modification is proposed that provides an on-demand set of calibration parameters for each 3D point, comprising those nearest in 3D space. In this way, the estimated camera parameters are closely related with camera aberrations at the lens area through which that 3D point is imaged. To further reduce the triangulation uncertainty volume, a Soft Computing approach is proposed that represents each 3D point uncertainty as a cloud of crisp points compatible with interval-valued calibration data.Real data from previous works in related research areas is used to judge whether the new approach improves the precision and accuracy of other crisp and interval-valued estimations without degrading precision, and it is concluded that the new technique is able to significantly improve the uncertainty volumes.	3d reconstruction;dlt;iterative method;soft computing	José Otero;Luciano Sánchez	2015	Neurocomputing	10.1016/j.neucom.2014.11.087	triangulation;computer vision;camera auto-calibration;mathematical optimization;camera resectioning;computer science;mathematics;stereophonic sound	Vision	56.53338998511197	-47.664599422548335	101712
b8449711a316aeb5c1b8299ffa52ae1dcc8053e6	interactive editing of deformable simulations	edit;physically based;interactive;animation;contact	We present an interactive animation editor for complex deformable object animations. Given an existing animation, the artist directly manipulates the deformable body at any time frame, and the surrounding animation immediately adjusts in response. The automatic adjustments are designed to respect physics, preserve detail in both the input motion and geometry, respect prescribed bilateral contact constraints, and controllably and smoothly decay in space-time. While the utility of interactive editing for rigid body and articulated figure animations is widely recognized, a corresponding approach to deformable bodies has not been technically feasible before. We achieve interactive rates by combining spacetime model reduction, rotation-strain coordinate warping, linearized elasticity, and direct manipulation. This direct editing tool can serve the final stages of animation production, which often call for detailed, direct adjustments that are otherwise tedious to realize by re-simulation or frame-by-frame editing.	bilateral filter;direct manipulation interface;elasticity (data store);simulation;smoothing	Jernej Barbic;Funshing Sin;Eitan Grinspun	2012	ACM Trans. Graph.	10.1145/2185520.2185566	anime;physically based animation;computer vision;simulation;computer science;artificial intelligence;computer animation;multimedia;interactivity;computer graphics (images)	Graphics	66.36524662162962	-46.93039898287775	101782
5d1b17df897375222dcf9012d69bf38aeaf17506	3d estimation using panoramic stereo	mirrors;image sensors;mirrors stereo image processing image sensors;passive monitoring;pipelines 3d estimation omni directional sensors single lens camera stereo panoramic imaging system double lobed mirror surface 3d points 2d projections surveillance security passive monitoring automatic monitoring peace keeping tasks corrosion detection deposit detection;field of view;stereo image processing;mathematical model;panoramic image;lenses cameras mirrors surveillance security computerized monitoring corrosion pipelines containers mathematical model	Omni-directional sensors are useful an obtaining a 360” field of view with a single lens camera. In our past research [ I ] we described a n approach t o designing a stereo panoramic imaging sys tem using a doublelobed mirror surface. This paper extends our earlier work by relating 3 0 points t o t h e 2D projections obtained by our system. Applications of the sys tem include surveillance and security, automatic and passive monitoring f o r peace-keeping tasks , and f a s t detection of corrosion and deposits in pipelines and industrial containers. Experimental results verifying the mathematical modeling are also provided.	mathematical model;pipeline (computing);sensor;verification and validation	Jonathan Baldwin;Anup Basu	2000		10.1109/ICPR.2000.905283	stereo camera;computer vision;field of view;image sensor;mathematical model	Robotics	58.06125521777562	-40.84493590962889	101818
12f7045cdc22ea2688ccfeeaa52fde937170ab3e	morphing multirésolution de courbes. (multiresolution morphing for curves)			morphing	Mélanie Cornillac	2010				Vision	66.1214375840382	-44.3175328776955	101992
4317fcafe161e7714965045e63455f7bb291a6ff	fractal active shape models	active shape model	Active Shape Models often require a considerable number of training samples and landmark points on each sample, in order to be efficient in practice. We introduce the Fractal Active Shape Models, an extension of Active Shape Models using fractal interpolation, in order to surmount these limitations. They require a considerably smaller number of landmark points to be determined and a smaller number of variables for describing a shape, especially for irregular ones. Moreover, they are shown to be efficient when few training samples are available.	active shape model;fasm;fractal compression;interpolation;landmark point	Polychronis Manousopoulos;Vasileios Drakopoulos;Theoharis Theoharis	2007		10.1007/978-3-540-74272-2_80	active shape model;computer vision;topology;fractal analysis;computer science;mathematics;geometry	Vision	62.6732211102063	-43.72615087240563	102083
4d42e15586aa700e1763e890ebcb87835b5e10eb	measurement and analysis of long-tunnel cross-sectional deformation using multi-sensor integration	change detection;pos;yangtze river;data collection;sensor integration;measurement system;laser scanner;three dimensional;tunnel measurement;deformation monitoring;cross sectional area;time domain;cross section;laser scanning;multi sensor integration;evaluation model;coordinate system	A long tunnel is a typical linear man-made infrastructure. The shape, especially the cross-sectional shape, and geometric parameters of the tunnel are very important for the safety of transportation. A multi-sensor integration approach is presented to survey the shape of the tunnel dynamically. With efficient collection of high-precision spatial points of structure surface, a laser scanner is widely used for measuring the structure’s three-dimensional geometric and deformation. In this article, two laser scanners and other position and orientation sensors, such as DGPS, IMU, and DMI, are integrated to form a MSI measuring system.With position and orientation sensors, the position and orientation of the laser scanners could be acquired dynamically, even in the tunnel where a GPS signal is out of reach. For fusing data collected from different sensors, data are generalized into a unified coordinate system. In our study, data from the laser scanner are first converted from the laser scanner coordinate system to the vehicle coordinate system. Then, vehicle coordinates are converted into geodetic coordinates by referencing the IMU coordinate. Calibrations are carried out in advance to obtain the parameters of conversion between coordinate systems. A time-domain tunnel deformation evaluation model is created on the basis of cross-sectional area change detection, where matching-based deformation detection (MDD) algorithm has been proposed for calculating the deformation area of two crosssectional polygons. This article also reports a test to use MSI measuring system for Wuhan Yangtze River highway tunnel measurement. Results of the precision analysis verify the reliability of the proposed tunnel deformation evaluation model and the validity of the MDD algorithm.	algorithm;cross-sectional data;differential gps;direct media interface;geodetic datum;global positioning system;integrated circuit layout design protection;model-driven engineering;reference ellipsoid;repeatability;sensor;total correlation;tunneling protocol	Qingquan Li;Qingzhou Mao;Qin Zou;Liang Zhang	2010	Annals of GIS	10.1080/19475683.2010.492128	laser scanning;computer vision;mathematics;cross section;statistics;remote sensing	Robotics	57.113889877236545	-39.85683340943426	102271
585acc7d23f7ef631ee7c197e4d77a0127a1a79b	sketch-based pipeline for mass customization	participating media;shadows;area lights;voxelization	We present a novel application workflow to physically produce personalized objects by relying on the sketch-based input metaphor. This is achieved by combining different sketch-based retrieval and modeling aspects and optimizing the output for 3D printing technologies. The workflow starts from a user drawn 2D sketch that is used to query a large 3D shape database. A simple but powerful sketch-based modeling technique is employed to modify the result from the query. Taking into account the limitations of the additive manufacturing process we define a fabrication constraint deformation to produce personalized 3D printed objects.	3d printing;personalization;sketch;sketch-based modeling;utility functions on indivisible goods	Kristian Hildebrand;Marc Alexa	2013		10.1145/2504459.2504506	computer vision;shadow;sketch-based modeling;computer science;multimedia;computer graphics (images)	HCI	65.2682987173576	-48.1426171155859	102281
0bf6d3cfed43b715eea8fb9be28f1cb8a888abd0	a differential volume rendering method with second-order difference for time-varying volume data	second order;time varying;volume rendering;differential volume rendering;flow animation;time varying volume data;second order difference;comparative method;cfd;ray casting;volume data	The differential volume rendering method is a ray casting based method for time-varying volume data. In the differential volume rendering method, the changed voxels between consecutive time steps are extracted to form differential files in advance. When the dataset is to be rendered, changed voxels are projected onto the image plane to determine the positions of changed pixels. Only the changed pixels, instead of all pixels on the image, are updated by casting new rays in each time step. The main overhead of the differential volume rendering method is the determination of changed pixels. In this paper, we propose a two-level differential volume rendering method, in which the determination of changed pixels is accelerated by the aid of the second-order-difference. Since changed voxels in two consecutive differential files may partially overlap in the space, the projection computation spent on the overlapped area is redundant. We use this property to extract the difference of changed voxels between consecutive differential files to form the second-order-difference. Based on the second-order-difference, the changed pixels can be determined more efficiently. The experimental results show that the proposed method outperforms the comparative methods for all test datasets in most cases. In addition, the rendering time can be predicted once the data files are loaded in each time step.	computation;image plane;overhead (computing);pixel;ray casting;rendering (computer graphics);sampling (signal processing);volume rendering;voxel;window of opportunity	Shih-Kuan Liao;Chin-Feng Lin;Yeh-Ching Chung;Jim Z. C. Lai	2003	J. Vis. Lang. Comput.	10.1016/S1045-926X(03)00020-X	computer vision;computational fluid dynamics;computer science;ray casting;comparative method;volume rendering;second-order logic;computer graphics (images)	Visualization	67.58370491125291	-50.43795561203277	102336
09953c55c54ae5ce4cab5c726c03ce0f53923ced	connect the dots: the reconstruction of region boundaries from contour sampling points		Twodimensional contour reconstruction from a set of points is a very common problem not only in computer vision. I.e. in graph theory one may ask for the minimal spanning tree or the shortest Hamiltonian graph. In psychology the question arises under which circumstances people are able to recognize certain contours given only a few points. In the context of discrete geometry, there exist a lot of algorithms for 2D contour reconstruction from sampling points. Here a commonly addressed problem is to define an algorithm for which it can be proved that the reconstuction result resembles the original contour if this has been sampled according to certain density criteria. Most of these algorithms can not properly deal with background noise like humans can do. This paper gives an overview of the most important algorithms for contour reconstruction and shows that a relatively new algorithm, called ‘cleaned refinement reduction’ is the most robust one with regard to significant background noise and even shows a reconstruction ability being similar to the one of a child at the age of 4.	contour line;sampling (signal processing)	Peer Stelldinger	2010		10.1007/978-3-642-32313-3_1	computer vision;electronic engineering;cartography	Vision	63.07672732210124	-47.059076285633765	102337
d6a4b48c09ab8f26571fa65e0e8fa179ce58a4f2	interpolating movements using cagd tools	interpolation;engineering graphics;cad;moving vortices;interpolation cad engineering graphics;null;scattered data;quaternionic version;cagd tools interpolating movements quaternionic functions quaternionic version scattered data moving vortices;interpolating movements;interpolation quaternions scattering acceleration earth history computer graphics visualization testing;cagd tools;quaternionic functions	The idea is to perform interpolations with quaternions or quaternionic functions each one of whom represents a movement. We present several antecedents of different methods to perform interpolations with quaternions and other antecedents of the its use considering the fact that they represent movements for example to define surfaces in different ways. The paper is however focused on the quaternionic version of Sibson interpolant on the surface of the sphere where the scattered data are moving vortices of some fluid.	computer-aided design;interpolation;vortex	Leonardo Traversoni	2007	Computer Graphics, Imaging and Visualisation (CGIV 2007)	10.1109/CGIV.2007.54	computer vision;pure mathematics;mathematics;geometry	Graphics	67.41531532701973	-41.829593191794864	102425
34f4d94c6a323ecf6a4fef95caf2583ed68ec3f9	on-line dense point cloud generation from monocular images with scale estimation		This paper introduces an approach for on-line marker-based three dimensional modeling with scale estimation and heightmap construction from monocular images. The presented system is also capable of an off-line marker-less 3D reconstruction from monocular images with increased detail. This method is designed for the flexible use with an Unmaned Aerial Vehicle (UAV); this means that, despite being tested with a Parrot AR.Drone 1.0, it is easily portable to other more capable UAV models. The followed approach was an adaptation of the patch-based Multiview Stereo (PMVS) algorithm for on line point cloud generation. The system achieved 1.05 processed images per second on average, slightly surpassing the planed objective of 1 processed image per second. The height estimation error ranges between 1-1.5% with a manual marker detection and 4-5% with automatic marker detection, which seems accurate enough for autonomous navigation and path planning. As future work, tests with a better UAV, processing time reduction, marker-less height map construction, autonomous indoor navigation and collaborative on-line 3D modeling are planned.	point cloud	Ander Larranaga-Cepeda;Gabriel Ramírez-Torres;Carlos Alberto Motta-Avila	2014		10.1007/978-3-319-13647-9_34	computer vision	Vision	54.78648069927383	-42.67325593833462	102537
65cca73d5160d205a8ae7d4d984d97ffed7cfd9e	coherence aware gpu-based ray casting for virtual colonoscopy	ray casting	In this paper, we propose a GPU-based volume ray casting for virtual colonoscopy to generate high-quality rendering imageswith a large screen size. Using the temporal coherence for ray casting, the empty space leaping can be efficiently done by reprojecting first-hit points of the previous frame; however, these approaches could produce artifacts such as holes or illegal starting positions due to the insufficient resolution of first-hit points. To eliminate these artifacts, we use a triangle mesh of first-hit points and check the intersection of each triangle with the corresponding real surface. Illegal starting positions can be avoided by replacing a false triangle cutting the real surface with five newly generated triangles. The proposed algorithm is best fit to the recent GPU architecture with Shader Model 4.0 which supports not only fast rasterization of a triangle mesh but also many flexible vertex operations. Experimental results on ATI 2900 with DirectX10 show perspective volume renderings of over 24fps on 1024T 1024 screen size without any loss of image quality. Copyright # 2008 John Wiley & Sons, Ltd.	algorithm;coherence (physics);curve fitting;directx;display size;graphics processing unit;image quality;john d. wiley;rasterisation;sierpinski triangle;triangle mesh;virtual colonoscopy;volume ray casting	Taek-Hee Lee;Yeong-Gil Shin	2009	Journal of Visualization and Computer Animation	10.1002/cav.273	computer vision;simulation;visualization;computer science;ray casting;directx;computer graphics (images)	Visualization	65.80669768048939	-51.977269272480605	102735
264b0552f234b27b4a5fef1406c4b6e04da5056e	statistical modeling and performance characterization of a real-time dual camera surveillance system	vision system;statistical analysis surveillance computer vision video signal processing real time systems image processing equipment;calibration errors statistical modeling performance characterization real time dual camera surveillance system computer vision system accuracy requirements computational requirements systematic engineering methodology real time people detection system real time people zooming system system modules tuning parameters statistical inference automatic control parameter setting high resolution zoomed in image omni directional camera video high resolution foveal camera tilt parameters pan parameters geometry lighting conditions background color background contrast sensor noise;image processing equipment;video signal processing;surveillance;surveillance system;real time;statistical model;computer vision;performance characterization;statistical analysis;cameras computer vision application software real time systems uncertainty colored noise face detection computer applications systems engineering and theory machine vision;real time systems	Rapid improvement in computing power, cheap sensing and more flexible algorithms are facilitating increased development of real-time video surveillance and monitoring systems. The deployment of video understanding systems in certain critical applications in the real world can be done only if performance guarantees can be provided for these systems. This work emphasizes on how to systematically design such a system, which matches user defined requirements. It will be illustrated that by judiciously choosing the system modules and by performing a careful analysis of the influence of various tuning parameters on the system it is possible to perform proper statistical inference, to automatically set control parameters and to quantify performance limits. This work focuses on engineering a dual-camera real-time people detection and zooming system that meets given application requirements. The goal of the system is to continuously provide an image of the entire scene as well as a high resolution zoomed-in image of a person’s head at any location of the monitored area. An omni-directional camera video is processed to detect people and to precisely control a high-resolution foveal camera, which has pan, tilt and zoom capabilities. The pan and tilt parameters of the foveal camera and its uncertainties are shown to be functions of the underlying geometry, lighting conditions, background color/contrast, relative position of the person with respect to both cameras as well as of sensor noise and calibration errors. The uncertainty in the estimates is used to adaptively estimate the zoom parameter that guarantees with a user specified probability, αZ , that the detected person’s face/head is contained and zoomed within the image. The higher the probability αZ the more conservative the zoom factor would be. We set αZ to 0.95 in our current system. In the second part it will be shown how the existing system designed and analyzed by following rigorous systematic engineering principles can be extended to relax the system operating conditions with minimal re-design and analysis efforts. The key conclusion is that by choosing appropriate modules and suitable statistical representations, we are able to re-use existing system design and performance analysis results. While the original system was designed for indoor (static illumination) settings the final system is extended to deal with dynamic illumination changes in a quasi outdoor setting. It is shown that extensive re-use of the original system and its performance characterization results can be achieved. The system operates reliably during days and night conditions in an office building lobby.	algorithm;closed-circuit television;image noise;image resolution;profiling (computer programming);real-time clock;requirement;software deployment;statistical model;systems design;web colors	Michael Greiffenhagen;Visvanathan Ramesh;Dorin Comaniciu;Heinrich Niemann	2000		10.1109/CVPR.2000.854840	smart camera;statistical model;computer vision;simulation;machine vision;computer science;statistics;computer graphics (images)	Robotics	55.9674969465291	-43.71959456676968	103266
a884d2f6114f2741292cd739995f3a3243004c8b	curvature-domain shape processing	nonlinear least squares;computational geometry;signal filtering and prediction;i 3 5 computer graphics;computational geometry and object modeling;optimization;geometry processing;problem solving	We propose a framework for 3D geometry processing that provides direct access to surface curvature to facilitate advanced shape editing, filtering, and synthesis algorithms. The central idea is to map a given surface to the curvature domain by evaluating its principle curvatures, apply filtering and editing operations to the curvature distribution, and reconstruct the resulting surface using an optimization approach. Our system allows the user to prescribe arbitrary principle curvature values anywhere on the surface. The optimization solves a nonlinear least-squares problem to find the surface that best matches the desired target curvatures while preserving important properties of the original shape. We demonstrate the effectiveness of this processing metaphor with several applications, including anisotropic smoothing, feature enhancement, and multi-scale curvature editing.	algorithm;anisotropic diffusion;filter (signal processing);geometry processing;least squares;mathematical optimization;nonlinear system;random access;smoothing	Michael Eigensatz;Robert W. Sumner;Mark Pauly	2008	Comput. Graph. Forum	10.1111/j.1467-8659.2008.01121.x	computer vision;mathematical optimization;topology;computational geometry;computer science;artificial intelligence;theoretical computer science;mathematics;geometry;non-linear least squares;algorithm;computer graphics (images)	Graphics	66.83263254450951	-46.17186594009478	103329
00bc67a235e4f195dd0c272d5f9f8076b2c13232	artistic eye: recognizing key viewing points of popular sites	art;composition;photographs;cross domain image match	Figure 1. (a) [Left] We introduce cross domain image matching into our system, (b) [Middle] allowing camera parameters of artworks to be obtained and reconstructed together with photographs. Once reconstruction is done, we calculate the key viewing score additionally (the score values are encoded by intensity from low to high). This will then be completed by a navigation system (c) [Right] together, to direct users to these viewpoints.	c process control;emoticon;image registration	Chih-Hsiang Hsu;I-Chao Shen;Wen-Huang Cheng;Shih-Wei Sun	2013		10.1145/2462456.2465719	composition;computer vision;multimedia	Vision	58.366787105388646	-51.15030649287413	103350
757f92cd4d2b265b018432f7ac2a387f2286871c	quasi-rigid objects in contact	steering behaviors;high resolution;model combination;rigid body;surface representation;path planning;laser range scanning;real time animation;vehicle motion;dynamic simulation;point cloud;online search;deformable model	We investigate techniques for modeling contact between quasi-rigid objects - solids that undergo modest deformation in the vicinity of a contact, while the overall object still preserves its basic shape. The quasi-rigid model combines the benefits of rigid body models for dynamic simulation and the benefits of deformable models for resolving contacts and producing visible deformations. We argue that point cloud surface representations are advantageous for modeling rapidly varying, wide area contacts. Using multi-level computations based on point primitives, we obtain a scalable system that efficiently handles complex contact configurations, even for high-resolution models obtained from laser range scans. Our method computes consistent and realistic contact surfaces and traction distributions, which are useful in many applications.	computation;image resolution;point cloud;scalability;simulation;traction teampage	Mark Pauly;Dinesh K. Pai;Leonidas J. Guibas	2004		10.1145/1028523.1028539	computer vision;dynamic simulation;rigid body;simulation;image resolution;computer science;online search;point cloud;motion planning;computer graphics (images)	Robotics	62.0435700961171	-47.520348249167256	103655
f9a60041668cd5155c8d0fcba5cdb70e6cc7ee2e	'pencigraphy' with agc: joint parameter estimation in both domain and range of functions in same orbit of the projective-wyckoff group	projective group action orbit;pencigraphy;group action;agc;turning;turn off;parameter estimation cameras layout algebra optical films sensor arrays optical sensors extraterrestrial measurements turning spatial resolution;photometry parameter estimation automatic gain control motion estimation cameras optical images group theory;motion estimation;layout;group theory;ideal spotmeter pencigraphy agc parameter estimation projective wyckoff group static scene fixed center of projection projective group action orbit automatic gain control automatic shutter auto iris modern digitizers characteristic response function camera projective coordinate transformed version;fixed center of projection;auto iris;ideal spotmeter;static scene;response function;algebra;photometry;projective wyckoff group;coordinate transformation;automatic shutter;optical images;modern digitizers;optical sensors;parameter estimation;projective coordinate transformed version;extraterrestrial measurements;characteristic response function;sensor arrays;cameras;optical films;camera;automatic gain control;spatial resolution	Consider a static scene and xed center of projection , about which a camera is free to zoom, pan, tilt, and rotate about its optical axis. With an ideal camera, the resulting images are in the same orbit of the projective group-action, and each pixel of each image provides a measurement of a ray of light passing through a common point in space. Unfortunately, most modern cameras have a built in automatic gain control (AGC), automatic shutter, or auto-iris, which, in many cases cannot be turned oo. Many modern digi-tizers to which cameras are connected have their own AGC which also cannot be disabled. With AGC, the characteristic response function of the camera varies, making it impossible to accurately describe one image as a projective coordinate transformed version of another. This paper proposes not only a solution to this problem, but a means of turning AGC into an asset, so that even in cases where AGC could be disabled, pencigra-phers of the future will be turning AGC on.	apache axis;automatic gain control;estimation theory;frequency response;movie projector;pixel;ray (optics)	Sleve Mann	1996		10.1109/ICIP.1996.560417	computer vision;automatic gain control;control theory;mathematics;group theory	Vision	54.45775899205566	-50.512344159184934	103782
5127cd9e1517b1d1ce872e41d8392db291d61dcc	mirror surface reconstruction from a single image	smooth mirror surface;transparent surface reconstruction;partial differential equation;mirrors;optimisation image reconstruction least squares approximations;mirrors surface reconstruction image reconstruction shape cameras geometry three dimensional displays;reconstruction;geometry;surface reconstruction;journal article;shape;three dimensional displays;image reconstruction;single image mirror surface reconstruction image reconstruction image location differential geometry analysis sparse correspondence optimization problem nonlinear least squares method;single image;cameras	This paper tackles the problem of reconstructing the shape of a smooth mirror surface from a single image. In particular, we consider the case where the camera is observing the reflection of a static reference target in the unknown mirror. We first study the reconstruction problem given dense correspondences between 3D points on the reference target and image locations. In such conditions, our differential geometry analysis provides a theoretical proof that the shape of the mirror surface can be recovered if the pose of the reference target is known. We then relax our assumptions by considering the case where only sparse correspondences are available. In this scenario, we formulate reconstruction as an optimization problem, which can be solved using a nonlinear least-squares method. We demonstrate the effectiveness of our method on both synthetic and real images. We then provide a theoretical analysis of the potential degenerate cases with and without prior knowledge of the pose of the reference target. Finally we show that our theory can be similarly applied to the reconstruction of the surface of transparent object.	abnormal degeneration;autostereogram;ct scan;call of duty: black ops;experiment;generic drugs;jacobian matrix and determinant;mathematical optimization;maxima and minima;non-linear least squares;nonlinear system;optimization problem;physical object;reconstruction conjecture;regular language description for xml;solutions;sparse matrix;synthetic intelligence	Miaomiao Liu;Richard I. Hartley;Mathieu Salzmann	2013	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2014.2353622	iterative reconstruction;computer vision;surface reconstruction;shape;mathematics;geometry;partial differential equation	Vision	55.017386760245174	-52.00353777032331	103841
a0d30c49ba929e355120ab9e4f852e59e0975a00	building variable resolution occupancy grid map from stereoscopic system — a quadtree based approach	quadtree based grid map building variable resolution occupancy grid map stereoscopic system quadtree based approach intelligent vehicle field distributed binary ternary variables grid mapping methods array based fixed resolution maps column disparity spaces quadtree structure stereovision measurements;visual perception grid computing road vehicles stereo image processing traffic engineering computing;stereo image processing;traffic engineering computing;visual perception;three dimensional displays stereo image processing probability image resolution accuracy sensor systems;grid computing;road vehicles	In intelligent vehicle field, occupancy grid maps are popular tools for representing the environment. Usually, occupancy grids, mapping the environment as a field of uniformly distributed binary/ternary variables, are generated by various kinds of sensors (e.g. lidar, radar, monocular/binocular vision system). In literature, most of proposed occupancy grid mapping methods create array-based fixed-resolution maps in either cartesian, polar, or column/disparity spaces. The problems of such maps are accuracy deficiency and prohibitive memory cost when trying to increase the resolution. This paper addresses these issues by presenting a novel variable resolution occupancy grid map based on quadtree structure from stereovision measurements. In the proposed method, a quadtree-based grid map with a settled resolution is calculated from a stereoscopic system at first. Then, the previously created map adapts its resolution to actual stereo measurements by merging or splitting nodes in the quadtree structure. The principal advantage of the proposed method is the ability to improve map's accuracy. Meanwhile, compared with some existing methods, the stereo-vision based occupancy grid mapping algorithm is improved. Experimental results with real datasets demonstrate that the accuracy of grid map created by our method is promoted from decimeter to centimeter.	algorithm;angular defect;binocular disparity;binocular vision;map;quadtree;radar;sensor;stereopsis;stereoscopy	You Li;Yassine Ruichek	2013	2013 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2013.6629556	computer vision;simulation;geography;occupancy grid mapping;computer graphics (images)	Robotics	54.71140847538323	-42.909921170648936	104069
bdd51399499a1c725fd07aaff8ef300d1ec35c88	flexible shape measurement system for chemical plant using magnetic sensors	ccd camera;cameras measurement by laser beam charge coupled devices receivers temperature measurement three dimensional displays magnetic field measurement;magnetic sensor;computer vision;pipe measurement;point cloud;point cloud computer vision pipe measurement magnetic sensor ccd camera	We propose a flexible computer vision system using magnetic sensors. The system enables a flexible free scanning of a CCD camera and a laser slit using 3D magnetic sensors. Many numbers of views of each model from different angles can be taken on measuring the configuration between a CCD camera and a laser slit projector simultaneously. The information of different views is combined to reconstruct the 3D object on a computer display. In this paper, the application for pipe measurement is introduced. Experimental results show the feasibility of our system.	charge-coupled device;computer monitor;computer vision;pipeline (unix);sensor;system of measurement;video projector	Kumiko Yoshida;Kikuhito Kawasue	2014	2014 11th International Conference on Informatics in Control, Automation and Robotics (ICINCO)	10.5220/0005097707580763	computer vision;computer science;engineering;point cloud;charge-coupled device;computer graphics (images)	Robotics	59.42210282423338	-41.57158662611272	104104
e3a01b2bfa9f4b533bf971f99a812eed6ce2db34	interpolatory ternary subdivision surfaces	producto tensorial;mascara;concepcion asistida;subdivision surfaces;computer aided design;tecnologia electronica telecomunicaciones;modele geometrique;sistema experto;computacion informatica;methode element fini;metodo elemento finito;algoritmo adaptativo;transformacion fourier discreta;subdivision surface;discrete fourier transformation;produit tensoriel;base connaissance;courbure;adaptive refinement;finite element method;surface reconstruction;interpolatory subdivision;element fini quadrilateral;transformation fourier discrete;tensor product;refinement method;adaptive algorithm;reconstruction surface;algorithme adaptatif;surface modeling;ciencias basicas y experimentales;surface model;discrete fourier transform;quadrilateral finite element;conception assistee;curvatura;base conocimiento;curvature;masque;subdivision;reconstruccion superficie;systeme expert;methode raffinement;tecnologias;grupo a;metodo afinamiento;mask;elemento finito cuadrilateral;c2 continuity;geometrical model;knowledge base;expert system;modelo geometrico	This paper proposes an interpolatory ternary subdivision for quadrilateral meshes that produces C2 continuous limit surfaces for regular meshes while achieves G1 continuity with bounded curvature at extraordinary vertices. The subdivision splits each quad into nine by inserting two E-vertices onto each edge and four F-vertices onto each face, and connecting them along vertical and horizontal directions respectively. The regular subdivision masks of the scheme are obtained as tensor products of the masks of the interpolatory ternary subdivision for curves while irregular geometric rules are established based on discrete Fourier transformation. For efficient practical use, an adaptive refinement algorithm is developed based on the decomposition of intermediate meshes into divisible and indivisible subsets for each refinement.	interpolation;subdivision surface	Guiqing Li;Weiyin Ma	2006	Computer Aided Geometric Design	10.1016/j.cagd.2005.05.001	knowledge base;finite subdivision rule;computer aided design;calculus;mathematics;geometry;expert system;subdivision surface	Graphics	68.25086790729601	-40.42566892005724	104294
8d36d4fe31426c0fcdd1823886c70b16b6854766	cutting cubesvisualizing implicit surfaces by adaptive polygonization	implicit surface;concepcion asistida;computer aided design;approximation lineaire;surface implicite;octree;piecewise linear approximation;singularite;visualizacion;algoritmo adaptativo;cube;cubo;linear approximation;polygonization;polygonisation;poligonizacion;grafismo;graphisme;blend surfaces;sintesis imagen;modelisation geometrique;image synthesis;adaptive algorithm;visualization;algorithme adaptatif;implicit surfaces;visualisation;aproximacion lineal;singularidad;conception assistee;graphism;synthese image;geometric modeling;singularity	A method for visualizing implicit surfaces is discussed. This method makes as few assumptions as possible concerning the surface and representation of its defining function. The surface may contain singularities, for instance, because it has self-intersections or it is reducible. A userdefined part of space is filled by a set of cubes, cutting pieces (called facets) off the surface. The set of cubes is controlled by an octree converging to the surface. The set of resulting facets can be taken as a piecewise linear approximation, which is sufficiently close to the given surface with respect to criteria specified by the user. Finally, some examples obtained with this method are presented.	implicit surface;linear approximation;olap cube;octree;piecewise linear continuation	Michael F. W. Schmidt	1993	The Visual Computer	10.1007/BF01901946	combinatorics;visualization;topology;computer aided design;mathematics;geometry;algorithm;computer graphics (images)	Graphics	67.69445997186529	-40.81684456232744	104377
5540e5e13ecc46d92fe816c57c669e35df55025b	diffusion generated motion of curves on surfaces	implicit surface;espacio 3 dimensiones;calculation;courbure;natural extension;three dimensional;methode calcul;algorithme;technique calcul;implicit surfaces;espace 3 dimensions;three dimensional space;calculation methods;higher dimensions;diffusion generated motion;euclidean space;algorithms;curvature;curvature motion;diffusion;diffusion transport;closest point representation	We present a new method for computing the curvature-driven motion of a curve constrained to move on a given surface. It is based on the Diffusion Generated Motion algorithm, and retains both the novel simplicity of that method, as well as the natural extension to curves with junctions, to general geometric motion laws, and to higher dimensions. The result is an extremely simple algorithm for curvature-dependent motion on surfaces, wherein the only evolution operation is linear diffusion in three-dimensional Euclidean space. 2007 Elsevier Inc. All rights reserved.	algorithm	Barry Merriman;Steven J. Ruuth	2007	J. Comput. Physics	10.1016/j.jcp.2007.03.034	three-dimensional space;mathematical analysis;topology;complex harmonic motion;motion estimation;mathematics;geometry;motion field;linear motion	Graphics	67.06326278789844	-43.018939357580706	104748
e7dd335515a8a42d794d001383b8e79df5cf0ecd	the autonomous duck: exploring the possibilities of a markov chain model in animation	markov chain model;random walk	This document reports the construction of a framework for the generation of animations based in a Markov chain model of the different poses of some drawn character. The model was implemented and is demonstrated with the animation of a virtual duck in a random walk. Some potential uses of this model in interpolation and generation of in between frames are also explored.	interpolation;markov chain	Javier Villegas	2009		10.1007/978-3-642-11577-6_34	markov chain;simulation;computer science;markov model;random walk;computer graphics (images)	Graphics	64.0300387328249	-46.70937288512664	104795
2530c0d2c859fec04634a0a5b5cbb49797e74da1	multi-view reconstruction for projector camera systems based on bundle adjustment	relative position;stereo image processing calibration cameras image reconstruction optical projectors;iterative algorithms;calibration errors;stereo range scanner;minimization methods;shape measurement;layout;surface reconstruction;data mining;cameras shape measurement iterative algorithms iterative closest point algorithm calibration layout cities and towns minimization methods surface reconstruction parameter estimation;optical projectors;shape;calibration errors multiview reconstruction projector camera systems bundle adjustment 3d shape alignment stereo range scanner;multiview reconstruction;three dimensional displays;projector camera systems;image reconstruction;stereo image processing;cities and towns;cost effectiveness;shape modeling;iterative closest point algorithm;parameter estimation;calibration;cameras;bundle adjustment;3d shape alignment	Range scanners using projector-camera systems have been studied actively in recent years as methods for measuring 3D shapes accurately and cost-effectively. To acquire an entire 3D shape of an object with such systems, the shape of the object should be captured from multiple directions and the set of captured shapes should be aligned using algorithms such as ICPs. Then, the aligned shapes are integrated into a single 3D shape model. However, the captured shapes are often distorted due to errors of intrinsic or extrinsic parameters of the camera and the projector. Because of these distortions, gaps between overlapped surfaces remain even after aligning the 3D shapes. In this paper, we propose a new method to capture an entire shape with high precision using an active stereo range scanner which consists of a projector and a camera with fixed relative positions. In the proposed method, minimization of calibration errors of the projector-camera pair and registration errors between 3D shapes from different viewpoints are simultaneously achieved. The proposed method can be considered as a variation of bundle adjustment techniques adapted to projector-camera systems. Since acquisition of correspondences between different views is not easy for projector-camera systems, a solution for the problem is also presented.	algorithm;bundle adjustment;camera resectioning;distortion;multiview video coding;stereo camera;video projector	Ryo Furukawa;Kenji Inose;Hiroshi Kawasaki	2009	2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops	10.1109/CVPRW.2009.5204318	iterative reconstruction;layout;computer vision;calibration;cost-effectiveness analysis;surface reconstruction;shape;computer science;mathematics;geometry;bundle adjustment;estimation theory;computer graphics (images)	Vision	53.89282089962259	-49.61141743938109	104798
d997007c08da3443671006b174918a3b63a95ea7	geometrical degeneracy removal by virtual disturbances - an application to surface reconstruction from point slice samples	diagramas de voronoi;triangulacion de delaunay;delaunay triangulation;info eu repo semantics conferenceobject;estereolitografia;reconstruccion superficial;geometria procesamiento de datos;surface reconstruction;coordinate measuring machine;medical image;degeneration;degeneracion matematicas;conferenceobject;topological methods;voronoi diagram;info eu repo semantics publishedversion	Abstract: In surface reconstruction from slice samples (typical in medical imaging, coordinate measurement machines, stereolithography, etc.) the available methods attack the geometrical and topological properties of the surface. Topological methods classify the transitions occurred in the 2-manifold between two consecutive slices i and i + 1. Geometrical methods synthesize the surface based on local proximity of the contours in consecutive slices. Superimposed 2D Voronoi Diagrams V Di and V Di+1 for slices i and i + 1, respectively, present topological problems if, for example, a site of V Di lies on an site or an edge of V Di+1. The usual treatment of this problem in literature is to apply a geometrical disturbance to either V Di or V Di+1, thus eliminating the degeneracy. In contrast, this article presents the implementation of a method which identifies the degenerate situation, constructs un-instantiated topological constructs, choses a geometrical instantiation based on a virtual disturbance introduced to the actual configuration. The algorithm was successfully applied to remove non-manifold topologies produced by well known algorithms in surface reconstruction.	algorithm;degeneracy (graph theory);degenerate energy levels;downstream (software development);iteration;medical imaging;universal instantiation;voronoi diagram	Oscar E. Ruiz;Eliana Vásquez;Sebastián Peña Serna;Miguel Granados	2008			surface reconstruction;delaunay triangulation;voronoi diagram;artificial intelligence;geometry;computer graphics (images)	Vision	66.89116490505236	-40.82494669254151	104923
2f8d350a27ed20395b59e64bc6f7bdbbfb443fa1	self-calibration of a 1d projective camera and its application to the self-calibration of a 2d projective camera	planar motion;1d camera;camera model;image sequence;vision geometry;self calibration;cubic polynomial self calibration 1d projective camera 2d projective camera point correspondences internal parameter determination trifocal tensor;camera calibration;calibration;cameras;tensors cameras calibration;tensors	We introduce the concept of self-calibration of a 1D project ive camera from point correspondences, and describe a method for uniquely determining the t wo internal parameters of a 1D camera based on the trifocal tensor of three 1D images. The me thod requires the estimation of the trifocal tensor which can be achieved linearly with no ap proximation unlike the trifocal tensor of 2D images, and solving for the roots of a cubic polynomi al in one variable. Interestingly enough, we prove that a 2D camera undergoing a planar motion r educes to a 1D camera. From this observation, we deduce a new method for self-calibrati ng a 2D camera using planar motions. Both the self-calibration method for a 1D camera and its appl ications for 2D camera calibration are demonstrated on real image sequences.	camera resectioning;cubic function;trifocal tensor	Olivier D. Faugeras;Long Quan;Peter F. Sturm	2000	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.879801	stereo camera;computer vision;camera auto-calibration;camera matrix;calibration;camera resectioning;tensor;computer science;mathematics;geometry;trifocal tensor;pinhole camera model	Vision	53.7796598092069	-50.52790401064538	105183
d79f318aa57389ca351058143febb25c772833ab	accuracy analysis of uav remote sensing imagery mosaicking based on structure-from-motion		Structure-From-Motion (SFM) method is based on the same scene and different angles of the captured sequence of image, then calculate the feature points in the photogrammetric coordinate system of three-dimensional coordinates and camera parameters. SFM can directly generated orthophoto map just by captured overlapping images, but mosaicking accuracy has not to be verified. The purpose of this study is that verify the feasibility and accuracy of SFM method in UAV image mosaic. The process of UAV imagery mosaicking based on SFM method was elaborated, and the test image was mosaicked with UAV imagery processing software which based on SFM. The result: (1) UAV imagery mosaicking based on SFM algorithm has low accuracy on geographic positioning because of the low precision POS. But the distance\area measurement with high accuracy, the perimeter accuracy is above 96.6% and the area accuracy is above 93.2%. (2) The image had high accuracy after geometric correction using ground points. When 5 ground points were used, the mean value of absolute error was 0.60 m. The study showed: (1) the accuracy of perimeter and area can basically meet the accuracy requirements of distance\area measurement in agricultural applications. (2) the orthophoto map was rectified by ground control point can significantly improve the geo-location precision of the image.	algorithm;approximation error;control point (mathematics);geolocation;image stitching;orthophoto;perimeter;photogrammetry;point of sale;requirement;standard test image;structure from motion;unmanned aerial vehicle	Haojie Pei;Peng Wan;Changchun Li;Haikuan Feng;Guijun Yang;Bo Xu;Qinglin Niu	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8128353	computer vision;measurement uncertainty;artificial intelligence;remote sensing;photogrammetry;coordinate system;structure from motion;perimeter;computer science;standard test image;control point;orthophoto	Robotics	56.82583624652986	-45.44692554214152	105253
e6239ca1cbcd37261f94cbd287473c9ac8a67325	naive ray-tracing: a divide-and-conquer approach	memory management;global illumination;ray tracing;data structure;divide and conquer;dynamic scenes;rendering	We present an efficient ray-tracing algorithm which, for the first time, does not store any data structures when performing spatial subdivisions, and directly computes intersections inside the scene. This new algorithm is often faster than comparable ray-tracing methods at rendering dynamic scenes, and has a similar level of performance when compared to static ray-tracers. Memory management is made minimal and deterministic, which simplifies ray-tracing engineering, as spatial subdivision data structures are no longer considered in the graphics pipeline. This is possible with a modification of Whitted's naive ray-tracing algorithm by using a divide-and-conquer approach, and by having a sufficient collection of rays in order to reduce the complexity of naive ray-tracing. In particular, the algorithm excels at spontaneously solving large Ray/Primitive intersection problems.	algorithm;data structure;graphics pipeline;memory management;ray tracing (graphics);space partitioning;subdivision surface	Benjamin Mora	2011	ACM Trans. Graph.	10.1145/2019627.2019636	ray tracing;computer vision;divide and conquer algorithms;data structure;rendering;computer science;theoretical computer science;programming language;global illumination;memory management;computer graphics (images)	Graphics	66.55619097889917	-50.99176071211092	105265
1e8415bff91c13c771d13547ce7c2cec0a3a546b	a novel multivariable algorithm for detecting and tracing metal mobile objects employing a simple rfid setup		Radio Frequency Identification (RFID) is a solution for automated inventory and object detection applications. However, if RFID tags are attached to metal objects, detection errors may occur due to Foucault currents and interferences caused by multiple simultaneous reflections. Errors may increase if metal objects are moving. The paper presents a novel algorithm using RFID lowlevel reader variables, such as RSSI (Received Signal Strength Indicator), phase angle, and Doppler shift, to detect and trace metal objects.The algorithmwas designed to identify if a tag is static or moving and, in the latter case, to compute its speed and direction. The algorithm differs from previous approaches since it uses a simple setup with one commercial portal reader coupled with one single element antenna. Experiments employed one tag located on one metal moving object and 12 static interferer tags, in both outdoor and indoor locations. Results show that the algorithm identifies static tags with no errors. For moving tags, the algorithm shows a maximum 12% error.The algorithm correctly estimates direction and computes object speed. Test conditions emulate fork lift speeds when carrying objects in an industrial warehouse.	algorithm;approximation error;doppler effect;inventory;object detection;radio frequency;radio-frequency identification;reflection (computer graphics)	Wendy Navarro;Juan Carlos Velez Diaz;Norelli Schettini;Maria Calle	2015	IJDSN	10.1155/2015/409617	embedded system;real-time computing;simulation	Mobile	57.58623856445332	-38.407358336512324	105337
d33ad1f037e87338ddebd140daea4c224a22de7f	a comparison of weighted average methods for computing normals to marching cubes isosurfaces	marching cube		marching cubes	Adam Huang;Gregory M. Nielson	2003			artificial intelligence;computer science;computer vision;isosurface;marching tetrahedra;marching squares;geometry;marching cubes;weighted arithmetic mean	HPC	67.07372878472822	-44.35047495866709	105366
12fa15a146f41c2258249b18fef02fd9f0d9f66d	text replacement on cylindrical surfaces: a semi-automatic approach		Image-based customization that incorporates personalized text strings into photorealistic images in a natural and appealing way has been of great interest lately. We describe a semi-automatic approach for replacing text on cylindrical surfaces in images of natural scenes or objects. The user is requested to select a boundary for the existing text and align a pair of edges for the sides of the cylinder. The algorithm erases the existing text, and instantiates a 3-D cylinder forward projection model to render the new text. The parameters of the forward projection model are estimated by optimizing a carefully designed cost function. Experimental results show that the text-replaced images look natural and appealing.	algorithm;align (company);cylinder seal;cylinder-head-sector;loss function;personalization;semiconductor industry;string (computer science)	Hengzhou Ding;Raja Bala;Zhigang Fan;Charles A. Bouman;Jan P. Allebach	2012		10.1117/12.914247	simulation;computer science;multimedia	AI	64.60111473226628	-47.45557828105144	105696
ea50d45f57468aeb92bb068bc22a996d69829517	a robust localization algorithm in topological maps with dynamic noises	moving object;topology;local algorithm;programming and algorithm theory;localization;corps mobile;topologie;robust control;localizacion;robotics;cartographie;topologia;captador medida;cartografia;measurement sensor;capteur mesure;localisation;robustesse;cuerpo movil;robotica;control robusta;cartography;robustness;rapport signal bruit;robotique;moving body;relacion senal ruido;signal to noise ratio;commande robuste;measurement noise;robustez;design methodology	Purpose – The paper's purpose is to propose a localization algorithm for topological maps constituted by nodes and edges in a graph form. The focus is to develop a robust localization algorithm that works well even under various dynamic noises.Design/methodology/approach – For robust localization, the authors propose an algorithm which utilizes all available data such as node information, sensor measurements at the current time step (which are used in previous algorithms) and edge information, and sensor measurements at previous time steps (which have not been considered in other papers). Also, the algorithm estimates a robot's location in a multi‐modal manner which increases its robustness.Findings – Findings show that the proposed algorithm works well in topological maps with various dynamics which are induced by the moving objects in the map and measurement noises from cheap sensors.Originality/value – Unlike previous approaches, the proposed algorithm has three key features: usage of edge data, inclus...	algorithm;map	Kyungmin Lee;Nakju Lett Doh;Wan Kyun Chung;SeoungKyou Lee;Sang Yep Nam	2008	Industrial Robot	10.1108/01439910810893608	robust control;simulation;internationalization and localization;design methods;computer science;artificial intelligence;robotics;signal-to-noise ratio;robustness	Robotics	55.56355049946633	-40.09932425142005	105738
c66ee950c20a215c2fdd044a38e8e93d46d563df	lamp: 3d layered, adaptive-resolution, and multi-perspective panorama - a new scene representation	image based modeling and rendering;image processing;layered representation;large scale;visual representation;image sequence;multi image processing;spatio temporal image;image based rendering;multi resolution;depth map;epipolar plane image;scale dependence	1 Abstract A compact visual representation, called the 3D Layered, Adaptive-resolution and Multi-perspective Panorama (LAMP), is proposed for representing large-scale 3D scenes with large variations of depths and obvious occlusions. Two kinds of 3D LAMP representations are proposed: the relief-like LAMP and the image-based LAMP. Both types of LAMPs concisely represent almost all the information from a long image sequence. Methods to construct LAMP representations from video sequences with dominant translation are provided. The relief-like LAMP is basically a single extended multi-perspective panoramic view image. Each pixel has a pair of texture and depth values, but each pixel may also have multiple pairs of texture-depth values to represent occlusion in layers, in addition to adaptive resolution changing with depth. The image-based LAMP, on the other hand, consists of a set of multi-perspective layers, each of which has a pair of 2D texture and depth maps, but with adaptive time-sampling scales depending on depths of scene points. Several examples of 3D LAMP construction for real image sequences are given. The 3D LAMP is a concise and powerful representation for image-based rendering.	glossary of computer graphics;lamp (software bundle);map;pixel;sampling (signal processing)	Zhigang Zhu;Allen R. Hanson	2004	Computer Vision and Image Understanding	10.1016/j.cviu.2004.03.011	image texture;computer vision;feature detection;image-based modeling and rendering;image processing;computer science;computer graphics (images)	Vision	60.88494372937153	-50.22628260401168	105771
0dd9b1ae28d2a2c0bb5ec103bd6ae1c03ca42a97	real-time view morphing of video streams	video streaming;real time;3d photography;3d camera;3d shape acquisition	This sketch describes a real-time virtual video camera application based on view morphing. This system takes video input from multiple cameras aimed at the same subject from different angles. After performing real-time pattern matching, the system generates synthetic views for a virtual camera that can pan between any two real views. The approach of this paper differs from the more common “depth from stereo” method for generating virtual views in that it does not attempt to reconstruct the 3D structure of the original scene. Instead it takes two 2D images and directly generates the 2D output image by performing only planar operations. At the heart of the system are algorithms and data structures that support the fast inter-image correlation needed for the completely automated, real-time view morphing.	algorithm;data structure;morphing;pattern matching;real-time clock;real-time locating system;real-time transcription;streaming media;synthetic intelligence;virtual camera system	Karl Timm	2003		10.1145/965400.965462	computer vision;real-time computing;computer science;video capture;video tracking;multimedia;video processing;multiview video coding;computer graphics (images)	Vision	58.6747248700382	-49.83816753489229	105776
9db2ffc2ed7f76bc112004fe5b4e6379290dc7df	point-based computer graphics	uncertainty;computer graphics;geometry;filters;layout;surface reconstruction;computer graphic;computer graphics rendering computer graphics surface reconstruction layout uncertainty clouds pipelines image reconstruction geometry filters;image reconstruction;clouds;pipelines;rendering computer graphics	This course introduces points as a powerful and versatile graphics primitive. Speakers present their latest concepts for the acquisition, representation, modeling, processing, and rendering of point sampled geometry along with applications and research directions. We describe algorithms and discuss current problems and limitations, covering important aspects of point based graphics.	computer graphics	Hanspeter Pfister;Markus H. Gross	2004	IEEE Computer Graphics and Applications	10.1109/MCG.2004.15	3d reconstruction;iterative reconstruction;layout;computer vision;vector graphics;graphics pipeline;scientific visualization;2d computer graphics;image-based modeling and rendering;vectorization;surface reconstruction;uncertainty;rendering;computer science;theoretical computer science;ray casting;computer graphics lighting;real-time computer graphics;geometry;pipeline transport;real-time rendering;computer graphics;alternate frame rendering;volume rendering;statistics;software rendering;3d computer graphics;computer graphics (images)	Visualization	67.48295677503138	-51.242103918614724	105784
2c35ea624a53056bf9abacad28e372761d561c2e	efficient clothing fitting from data	e commerce;limit set;computer graphic;weighted sums;principal component analysis;real time application;vecg;3d graphics	A major drawback of shopping for clothes on-line is that the customer cannot try on clothes and see if they fit or suit them. One solution is to display clothing on an avatar, a 3D graphical model of the customer. However the normal technique for modeling clothing in computer graphics, cloth dynamics, suffers from being too processor intensive and is not practical for real time applications. Hence, retailers normally rely on a fixed set of body models to which clothes are pre-fitted. As the customer has to choose from this limited set the fit is typicallly not very representative of how the real clothes will fit. We propose a method that uses a compromise between these two methods. We generate a set of example avatars by performing Principal Component Analysis on a dataset of avatars. Clothes are pre-fitted to these examples off-line. Instead of asking the customer to choose from the set of examples we are able to represent the users avatar as a weighted sum of the examples, we then fit clothes as the same weighted sum over the clothes fitted to the examples.	avatar (computing);computer graphics;curve fitting;graphical model;online and offline;principal component analysis;real-time computing;weight function	Marco Gillies;Daniel Ballin;Balázs Csanád Csáji	2004			e-commerce;limit set;simulation;computer science;artificial intelligence;operating system;3d computer graphics;principal component analysis;computer graphics (images)	Graphics	62.27109546946924	-46.80979371447546	105806
1475d2d2dcb3017a928a6b4f8865c51665ff8ce9	two-layer sparse compression of dense-weight blend skinning	skinning;linear blend skinning;dictionary learning;skinning from examples;sparse coding	Weighted linear interpolation has been widely used in many skinning techniques including linear blend skinning, dual quaternion blend skinning, and cage based deformation. To speed up performance, these skinning models typically employ a sparseness constraint, in which each 3D model vertex has a small fixed number of non-zero weights. However, the sparseness constraint also imposes certain limitations to skinning models and their various applications. This paper introduces an efficient two-layer sparse compression technique to substantially reduce the computational cost of a dense-weight skinning model, with insignificant loss of its visual quality. It can directly work on dense skinning weights or use example-based skinning decomposition to further improve its accuracy. Experiments and comparisons demonstrate that the introduced sparse compression model can significantly outperform state of the art weight reduction algorithms, as well as skinning decomposition algorithms with a sparseness constraint.	algorithm;algorithmic efficiency;linear interpolation;neural coding;skin (computing);sparse matrix	Binh Huy Le;Zhigang Deng	2013	ACM Trans. Graph.	10.1145/2461912.2461949	speech recognition;neural coding;computer graphics (images)	Graphics	63.03698023860175	-46.76753200562907	105935
e91534e9f901f6cce79d72ec63929d72211a4254	shape inspection of 3-d objects using time-coded pattern projection and newly developed image sensor systems		"""This paper describes the accurate shape inspection method of 3-D objects. To make measurement more precisely, we introduce a newly developed composite image sensor system. The image u n i t of the proposed system has two different type image sensors, area and line types. i t is so dcsigncd that i ts pixel composition is overlapped optically, so i t is possible t o obtain two images provided by two image sensors on the same plane respectively. In the measuring process, f i rs t , seven Gray coded light patterns are projected on the objects one aft e r another and each image is inputted by the area sensor and range data are calculated a t an accuracy of 2mm along the Z direction. Then the most thin light s t r ipe pattern is projected and only marked regions extracted from the area image are scanned by the line sensor and range data are calculated a t an accuracy of 0.3mm. The advantage of proposed system is that the measurement accuracy in marked regions can be improved up to 7 times better than that of conventional ranging systems and amount of image data is much reduced and acquisition time is also shortened. 3-D shape measurement is a very important and useful technology in the fields of recognition of parts' shapes, robot vision o r shape of human body, e t ~ ' ) ~ ' ~ . Especially shape measurements using image processing techniques have such advantage that non contact, high speed, automatic, reliable, etc, so many effective methods have been investigated""""'. B u t , they have a serious drawback that thc accuracy of their methods is order of mm i n the X-Y plane and order of cm along the Z direction, so that the improvement of the accuracy is one of the significant research theme. To improve the accuracy and to shorten the measurement time. Sato and inokuchi5' proposed range finder with a liquid crystal shut ter and improved input times within 3 seconds and also improved the accuracy by double precision method and interpolations of space code. Recently, Uesugie' proposed a new ranging system using s l i t light scanning m~th od. But, they use a NTSC type TV camera, so the accuracy of system is restricted by t h ~ resolution of NTSC formats. If higher resolutiori is required, specially constructcd image input systems must be introduced. But they a re expensive and amount of image data are increased abruptly and much more times a re necessary in image processing. In this paper, to enable highly accurate shape inspection of 3-D objects in a short time. we introduce a newly developed composite image sensor system and a time-coded stripe type pattern projection method using liquid crystal shutter. The image input unit of this system has two different type image sensors, area and line types, and i t s pixel composition is overlapped optically. The area image sensor is used t o obtain ranging image and t o extract regions necessary for shape inspection. A rough ranging image of objects is obtained by changing seven types of s t r ipe projection patterns one af ter another. Then marked regions are extracted in the area image by image processing methods and mechanically scanned by the line sensor a t an accuracy of seven times better than that of the area sensor. Using both area and line image data, 3-D shape measurement is established effectively. S Y S T E M C O N F I G U R A T I O N 3 D P A T T E R N P R O J E C T I O N Figure 1 shows the setup of projector and imaging system for the time-coded pattern projection method. In our system, the composite image sensor is used instead of a NTSC type TV camera. A liquid crystal shut ter generates Gray coded s tr ipe light patterns on the surface of objects quickly. Numbers of stripes of the shutter is 128, so seven light patterns are projected one af ter another and each images is inputted and stored in frame memories within 3 . .g. 1 Setup of t h e image inpu I lm,lg(> ol' ;lr~ area st,risor. F t unit . k'ig.4 I Fig.5 A binary coded image."""	3d scanner;data striping;double-precision floating-point format;image processing;image sensor;movie projector;ntsc;pixel;projection method (fluid dynamics);stripes;video projector	Saburo Okada;Tetsuhiro Sumimoto;Hidekazu Miyauchi;Masaaki Imade;Hideki Yamamoto	1990			artificial intelligence;mathematics;computer vision;chemical reaction;distillation;anhydrous;catalysis;anode;ethanol;acetaldehyde;electrolyte	Vision	60.469404172384095	-39.99120508254453	105955
644d192e048ee1b62752a48efa46c72e5983ae95	freight train gauge-exceeding detection based on three-dimensional stereo vision measurement	3d reconstruction;freight train gauge-exceeding detection;stereo vision measurement;stripe extraction	We present a method for freight train gauge-exceeding detection based on three-dimensional (3D) stereo vision measurement. To reach high measurement accuracy under large-scale situation, the factors which influence the 3D measurement error are analyzed in detail. Algorithm to accurately extract the laser stripe feature projected by the measurement system is described. With the obtained stripe features, the 3D structure of the freight train can be reconstructed with nonlinear optimization procedure. Specially designed targets are used to identify the global coordinate system for gauge-exceeding detection. A prototype has been developed and the reliability and accuracy have been demonstrated by external field experiment.	3d computer graphics;active vision;algorithm;epipolar geometry;image processing;magnetic stripe card;mathematical optimization;nonlinear programming;nonlinear system;pixel;polygonal modeling;prototype;stereopsis;stripes;structured light;system of measurement	Yixin Zhang;Shun Wang;Xuping Zhang;Fei Xie;Jiaqi Wang	2012	Machine Vision and Applications	10.1007/s00138-012-0444-2	computer vision;simulation	Robotics	56.271792176673706	-43.16056144802552	105993
52eb8e7d079320b08961f23f1f1fc2c4cddaab60	pen-based styling design of 3d geometry using concept sketches and template models	3d sketching;pen computing;style design;industrial production;system design;physically based deformation;camera calibration;surfacing	This paper describes a new approach to industrial styling design that combines the advantages of pen-based sketching with concepts from variational design to facilitate rapid and fluid development of 3D geometry. The approach is particularly useful for designing products that are primarily stylistic variations of existing ones. The input to the system is a 2D concept sketch of the object, and a generic 3D wireframe template. In the first step, the underlying template is aligned with the input sketch using a camera calibration algorithm. Next, the user traces the feature edges of the sketch on the computer screen; user's 2D strokes are processed and interpreted in 3D to modify the edges of the template. The resulting wireframe is then surfaced, followed by a user-controlled refinement of the initial surfaces using physically-based deformation techniques. Finally, new design edges can be added and manipulated through direct sketching over existing surfaces. Our preliminary evaluation involving several industrial products have demonstrated that with the proposed system, design times can be significantly reduced compared to those obtained through conventional software.	algorithm;camera resectioning;computer monitor;refinement (computing);tracing (software);variational principle;wire-frame model	Levent Burak Kara;Chris M. D'Eramo;Kenji Shimada	2006		10.1145/1128888.1128909	industrial production;camera resectioning;simulation;systems design;computer graphics (images)	Graphics	65.89121619245044	-46.509726013949496	106338
b8e5039b8e25b21f0bdde25bdc4e21abefa2b569	a visible polygon reconstruction algorithm	image synthesis;reflectance;reconstruction algorithm;data structure	An algorithm for determining visible lines or visible surfaces in polygonal form, at object resolution, is presented. The original scene must consist of nonintersecting planar polygons. The procedure relies on image coherence, since the sampling is dependent on the complexity of the image. The reconstruction method is based on an elaborate data structure, which allows the polygonal output to be easily obtained. The polygonal output is useful for smooth shaded or textured images, as well as for the creation of shadows.	algorithm;data structure;sampling (signal processing);shading	Stuart Sechrest;Donald P. Greenberg	1982	ACM Trans. Graph.	10.1145/357290.357294	computer vision;data structure;computer science;reflectivity;optics;programming language	Graphics	64.90421548123572	-50.075050983687	106399
b94b0c9a6a26b667a8019de0ac2012b19e1c9ce9	solar cell powering with integrated global positioning system for mm3 size robots	micro robotics solar cell powering gps;silicon;crystalline silicon solar cells;solar cells;microrobots;multi segment solar cells;powering;thin film;solar cell powering;4 mm;amorphous silicon;global position system;thin film amorphous silicon solar cells;mobile robots;elemental semiconductors;robotics;hpr mr;energy transfer;large scale;photodiodes;solar cells amorphous semiconductors elemental semiconductors global positioning system image sequences microrobots mobile robots multi robot systems photodiodes position measurement silicon;gps;global positioning system;solar cell;2 65 mm;multi robot systems;robot position;position measurement;photovoltaic cells global positioning system robots photodiodes testing crystallization semiconductor thin films amorphous silicon decoding image segmentation;robot orientation;micro robotics;amorphous semiconductors;3 mm;positional information;384 mm solar cell powering integrated global system global positioning system microrobots multi segment solar cells crystalline silicon solar cells thin film amorphous silicon solar cells image sequences photodiodes robot position robot orientation energy transfer 2 65 mm 4 mm 3 mm 512 mm;384 mm;micro engineering;integrated global system;512 mm;silicon solar cell;image sequences	A new concept of a solar cell powering with integrated Global Positioning System (GPS) for microrobots is proposed. The main idea is to use a projector to transfer energy and to provide global positioning information to the robots that are equipped with multi-segment solar cells on their top. First tests with a 3000 ANSI lumens beamer projecting a white image showed a scavenged power of 7.1 and 27.8 muW/mm2 for commercially available crystalline silicon solar cells and for thin film amorphous silicon solar cell respectively. Regarding the Global Positioning System, the projector sends regularly a sequence of 17 images and the robot decodes them using two independent solar cell segments acting as photodiodes in order to calculate its own position and orientation inside a defined arena. First experimental results on a large scale prototype are presented. For 2.65 times 2.65 mm2 photodiodes the x, y and angular resolution are 4 mm, 3 mm and 6 degrees respectively inside an arena of 512times384 mm2  and the duration of the sequence is 0.85 s	angularjs;global positioning system;microbotics;prototype;robot;solar cell;video projector	A. Boletis;Walter Driesen;Jean-Marc Breguet;Alberto Brunete	2006	2006 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2006.282191	electronic engineering;global positioning system;electrical engineering;artificial intelligence;optics;robotics	Robotics	59.91302188378827	-38.33718654603732	106481
926a57579bc140b599ba6518556d4eb99ef347a1	fast local motion estimation algorithm using elementary motion detectors	real time;computational complexity;directx;signal processing;parameter estimation;modeling;computer hardware;motion estimation;sensors;video	This paper presnts a fast local motion estimation algorithm based on so called elementary motion detectors or EMDs. EMDs, modeling insects visual signal processing systems, have low computational complexity aspects and can thus be key components to realize such a fast local motion estimation algorithm. The contribution of the presented work is to introduce dual parameter estimators or DPEs by configuring EMDs so that they can estimate local motions in terms of both direction and speed mode parameters simultaneously. The estimated local motion vectors are displayed as arrows superimposed over video image frames. The developed algorithm is implmented in a DirectShow application by using Mircosofts DirectX runtime library and is evaluated using various types of video image sequences. It is found to be able to estimate local motion vectors in real time even in moderate PC computing platforms and hece no high profile hardware devices are needed for its real time operation.© (2003) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	algorithm;motion detector;motion estimation;sensor	Eiji Nakamura;Takehito Nakamura;Katsutoshi Sawada	2003			computer vision;simulation;systems modeling;video;image processing;quarter-pixel motion;computer science;sensor;signal processing;motion estimation;directx;estimation theory;computational complexity theory;algorithm;computer graphics (images)	Vision	57.52216382718743	-41.8038116475468	106794
439f57d45bcd89598bddf56b4517eea0e5de2967	flexible calibration: minimal cases for auto-calibration	contraste;proyeccion;vision ordenador;perspectiva;selfcalibration;flexible;projective reconstruction auto calibration euclidean reconstruction complexity;autocalibration;perspective;parametre intrinseque;computer vision;reconstruction image;transformation projective;reconstruccion imagen;calibration computer aided software engineering image reconstruction cameras electrical capacitance tomography nonlinear equations ear computer vision layout councils;image reconstruction;projection;imaging;image sequence;formation image;vision ordinateur;etalonnage;secuencia imagen;formacion imagen;projective reconstruction;matematik;calibration;sequence image;bundle adjustment	This paper deals with the concept of auto-calibration, i.e. methods to calibrate a camera on-line. In particular, w e deal with minimal conditions on the intrinsic parameters needed to make a Euclidean reconstruction, called flexible calibration. The main theoretical results are that it is onl y needed to know that one intrinsic parameter is constant. The method is based on an initial projective reconstruction, which is upgraded to a Euclidean one. The number of images needed increases with the complexity of the constraints, but the number of points needed is only the number needed in order to obtain a projective reconstruction. The theoretical results are exemplified in a number of experiments. An algorithm, based on bundle adjustments and a linear initialization method are presented and experiment s are performed on both synthetic and real data.	algorithm;bell test experiments;camera resectioning;experiment;online and offline;synthetic intelligence	Anders Heyden;Kalle Åström	1999		10.1109/ICCV.1999.791241	iterative reconstruction;medical imaging;computer vision;calibration;perspective;simulation;projection;mathematics;geometry;bundle adjustment	Vision	53.948993497321446	-51.19135865358413	107396
bb9c9652895d362eeadd6f5c6516d1837e71d90e	correction to a novel text-independent speaker verification method based on the global speaker model	speaker verification;intelligent systems;intelligent systems computer science;computer science	"""3) The registration function which assimilates the existing prototype model and the most recently acquired range image. 4) The NBV system which presents three separate methods for determining the NBV position from the current state of the model. 5) The graphical user interface with which the user can call the NBV system, view the images acquired at each iteration, review statistics pertaining to reconstruction, or examine the ideal or reconstructed model. 6) The application which reads in a reconstructed model file and outputs an IRIS Inventor format voxel rendering. 7) The IRIS Explorer module map which reads in a reconstructed model file and outputs an IRIS Inventor format surface rendering. A solution to the next best view problem for automated cad model acquisition of free-form objects using range cameras , """" in A perspective for range finding techniques for computer vision, """" IEEE Trans. Generation of volume/sur-face octree from range data, """" in Proc. IEEE Comput. A method for registering overlapping range images of arbitrarily shaped surfaces for 3-d object reconstruction , """" in Registration of multiple range views for automatic 3-d model building, """" in Proc. Building 3-d models from un-registered range images, """" in Proc. A survey of sensor planning in computer vision, """" IEEE Trans. Abstract—This correspondence introduces a new text-independent speaker verification method, which is derived from the basic idea of pattern recognition that the discriminating ability of a classifier can be improved by removing the common information between classes. In looking for the common speech characteristics between a group of speakers, a global speaker model can be established. By subtracting the score acquired from this model, the conventional likelihood score is normalized with the consequence of more compact score distribution and lower equal error rates. Several experiments are carried out to demonstrate the effectiveness of the proposed method."""	computer vision;experiment;graphical user interface;iteration;octree;pattern recognition;prototype;range imaging;real-time clock;real-time computing;speaker recognition;voxel	Yongzhi Zhang;X. Zhu;David Zhang	2000	IEEE Trans. Systems, Man, and Cybernetics, Part A	10.1109/TSMCA.2000.895929	natural language processing;speech recognition;intelligent decision support system;computer science;artificial intelligence;machine learning;intelligent verification	Vision	57.232212044942315	-48.00133785266974	107690
70c72fef21a2da9bba68167b86bc5018300c3319	shadow volumes on programmable graphics hardware	hardware accelerator;graphics hardware;programmable graphics hardware;real time application	One of the best choices for fast, high quality shadows is the shadow volume algorithm. However, for real time applications the extraction of silhouette edges can significantly burden the CPU, especially with highly tessellated input geometry or when complex geometry shaders are applied. In this paper we show how this last, expensive part of the shadow volume method can be implemented on programmable graphics hardware. This way, the originally hybrid shadow volumes algorithm can now be reformulated as a purely hardware-accelerated approach. The benefits of this implementation is not only the increase in speed. Firstly, all computations now run on the same hardware resulting in consistent precision within all steps of the algorithm. Secondly, programmable vertex transformations are no longer problematic when applied to shadow casting objects.	algorithm;blackwell (series);central processing unit;computation;display resolution;eurographics;graphics hardware;graphics processing unit;hardware acceleration;memory management;non-photorealistic rendering;opengl;shader;shading;shadow volume;transformation matrix;unbiased rendering;vertex (geometry);video card	Stefan Brabec;Hans-Peter Seidel	2003	Comput. Graph. Forum	10.1111/1467-8659.00691	graphics pipeline;parallel computing;hardware acceleration;computer hardware;computer science;operating system;graphics hardware;computer graphics (images)	Graphics	66.69061260315885	-51.39154071410799	107695
157996069bad21916c092617e841d23ec8f4ccd9	depth extraction using lateral or axial camera motion: an integration of depth from motion and stereo	energy resolution;cameras displacement measurement robot vision systems computer vision equations laboratories data engineering velocity measurement layout energy resolution;lateral camera motion;temporal gradient analysis;spatial variables measurement;image matching;camera translations depth extraction axial camera motion lateral camera motion image sequence stereo processing depth measurements temporal gradient analysis spatial gradient analysis integrated method stereo matching process experiments mean error;mean error;motion estimation;correspondence problem;layout;data engineering;integrated method;spatial variables measurement image sequences motion estimation image matching stereo image processing feature extraction cameras;camera translations;computer vision;camera motion;stereo matching;displacement measurement;depth measurements;stereo matching process;feature extraction;image sequence;stereo image processing;gradient analysis;experiments;a priori information;depth extraction;axial camera motion;stereo processing;velocity measurement;high efficiency;robot vision systems;spatial gradient analysis;cameras;image sequences	In this paper, we present an integrated methodology to extract depth from a sequence of images. The method combines the ability of the stereo processing to acquire highly accurate depth measurements and the efficiency of the spatial and temporal gradient analysis. As a result of this integration, depth measurements of high quality are obtained a t speed approximately ten-times higher than tha t of the stereo processing. Without any a priori information of the locations of the points in the scene, the correspondence problem in the stereo processing is computationally expensive. In our approach, we use the spatial and temporal gradient analysis, which has been shown to provide depth with high efficiency but limited accuracy, to guide the matching process of stereo. Experiments for lateral and axial camera translations have acquired depth results with mean error of less than 3 percent. ’	analysis of algorithms;correspondence problem;display resolution;gradient;lateral thinking	Arun K. Dalmia;Mohan Manubhai Trivedi	1995		10.1109/ICIP.1995.529734	computer stereo vision;layout;computer vision;gradient analysis;information engineering;feature extraction;computer science;motion estimation;mean squared error;correspondence problem;computer graphics (images)	Vision	54.736770630800564	-48.582801908180876	107906
95d676064c36f0980d731216e5f256e3a8f3b371	overlapping radiosity: using a new function base with local disk support		"""This paper focuses on a new radiosity approach. Using a new geometrical model that describes any surface with an atlas of \disk-like patches"""", i.e. a set of pieces covering the surface and overlapping each other, we express the radiosity function in a new function base. This leads to a new radiosity system where overlapping areas are taken into account. The classical radiosity approach appears now as a particular limit case of this new \overlapping radiosity""""."""	radiosity (computer graphics);rendering equation	Didier Arquès;Sylvain Michelin;Benoît Piranda	2000			artificial intelligence;computer graphics (images);computer vision;radiosity (computer graphics);computer science	Graphics	66.51727107082183	-48.1520188032665	108087
7f5416ef21bf1c02792cccab88e52dad111dd614	detection of circular defects on varnished or painted surfaces by image fusion	varnish filtering theory image fusion image texture iterative methods object detection paints production engineering computing;paints;image fusion;surface texture circular defects detection varnished surfaces painted surfaces image fusion circular geometry illumination conditions defect symmetry image series iterative algorithm multidimensional correlation filter;surface texture;image fusion lighting inspection painting production instruments shape geometry quality control humans;iterative algorithm;musical instruments;production engineering computing;image texture;iterative methods;a priori knowledge;varnish;quality control;filtering theory;object detection	Varnishing and painting are quite delicate processes susceptible to failures. This becomes especially critical whenever an aesthetic finish is decisive for the final product. Such is the case, for example, in production of furniture, musical instruments, and paper, among many others. Dozens of different defects with very varied shapes can affect varnished or painted surfaces. However, an important group of them presents a mere circular geometry. Circular defects can have very different sizes and are only partially visible under certain illumination conditions. These characteristics complicate the quality control of varnished or painted surfaces, for which an automated solution does not exist. On the contrary, this work is performed by human operators, which yields to a long, expensive and subjective inspection process. In order to implement an automated surface inspection, different lighting directions and a priori knowledge on the defect symmetry are combined. The image series, resulting of sampling the illumination space, presents the complete information of defects, but distributed on its pictures. To collect all this information, an iterative algorithm based on a multidimensional correlation filter is proposed, which enables a reliable identification of circular defects with arbitrary diameters. Moreover, the successful detection and identification of these defects is not affected by the surface texture	algorithm;galaxy morphological classification;human computer;image fusion;inverse filter;iterative method;robustness (computer science);sampling (signal processing);software bug;spatial variability	Ana Pérez Grassi;Miguel Angel Abian Perez;Fernando Puente León;Rosa Maria Perez Campos	2006	2006 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems	10.1109/MFI.2006.265630	computer vision;engineering;optics;engineering drawing	Robotics	61.23963671259392	-41.230846787836995	108142
54505db0eeab8b75a65d06818a295bd9b43172db	portholes and planes: faster dynamic evaluation of potentially visible sets	portal rendering;visibility;3d environment;lookup table;temporal coherence;virtual environment;occlusion culling;potentially visible set	We describe a simple and efficient dynamic occlusion- culling algorithm for computing potentially visible sets (PVS) in densely occluded virtual environments. Our method is an optimization of a widely used technique in which a 3D environment is divided into cells and portals. Our algorithm computes the PVS in approximately half the time of previous portal methods at the expense of producing a slightly relaxed PVS. In addition, our algorithm enables fast culling of objects within cells using inexpensive object-space methods by using a lookup table to compute the diminished object-space view frustum. The algorithm takes advantage of temporal coherence, is easy to implement, and is particularly well suited for applications that need to compute a PVS for use in non-rendering tasks such as AI.	algorithm;coherence (physics);hidden surface determination;lookup table;mathematical optimization;portal rendering;portals;viewing frustum;virtual reality	Timothy Roden;Ian Parberry	2005	Computers in Entertainment	10.1145/1063723.1063732	computer vision;simulation;hidden surface determination;lookup table;visibility;computer science;virtual machine;operating system;potentially visible set;computer graphics (images)	Graphics	66.70014498400222	-50.97957859165566	108373
7b37abb8d9ef6aee02b1b88322c463d8ee21e36d	geometric abstraction from noisy image-based 3d reconstructions		Creating geometric abstracted models from image-based scene reconstructions is difficult due to noise and irregularities in the reconstructed model. In this paper, we present a geometric modeling method for noisy reconstructions dominated by planar horizontal and orthogonal vertical structures. We partition the scene into horizontal slices and create an inside/outside labeling represented by a floor plan for each slice by solving an energy minimization problem. Consecutively, we create an irregular discretization of the volume according to the individual floor plans and again label each cell as inside/outside by minimizing an energy function. By adjusting the smoothness parameter, we introduce different levels of detail. In our experiments, we show results with varying regularization levels using synthetically generated and real-world data.	3d reconstruction from multiple images;discretization;energy minimization;experiment;geometric modeling;level of detail;mathematical optimization;matrix regularization;optimization problem;point cloud;scene graph	Thomas Holzmann;Christof Hoppe;Stefan Kluckner;Horst Bischof	2014	CoRR		simulation;artificial intelligence;machine learning;mathematics	Robotics	67.9515549196815	-43.98980370248772	108380
c995663418d185906a2034d61ca6cca5ece0ff3a	convex object surface mapping for wide field of view video representation	convex object surface mapping;wide field of view video;video representation	This paper proposes a novel video representation method for videos capturing events held in a wide field. Such events can be captured with high resolution due to the recent development of video capturing technologies. Despite the development of these technologies, representation methods for wide field-of-view (wide-FOV) video are limited in number. Our work aims at simultaneously achieving (1) high visibility for regions of interest (ROIs), (2) easy overviewing, and (3) intuitive comprehension of the relative positions of video objects. Because of these advantages, the proposed method is especially suitable for showing wide-FOV videos on small display devices such as tablets and smartphones. To achieve the abovementioned aims, we propose a convex object surface mapping technique that provides high ROI visibility and easy overviewing. In addition, by using an elliptic cylinder or an oval as a convex object, the convex object surface mapping enables intuitive comprehension of the relative positions of video objects. The efficacy of the proposed method was verified through objective and subjective experiments.	convex set;cylinder seal;experiment;image resolution;region of interest;smartphone;tablet computer	Dan Mikami;Daisuke Ochi;Ayumi Matsumoto;Akira Kojima	2013		10.1145/2505483.2505488	computer vision;video tracking;mathematics;multimedia;computer graphics (images)	HCI	58.78649191668218	-50.59580225408261	108410
a427593d11f6cfbe5f62748e544191bf7ed00351	dimensionality reduction for point feature slam problems with spherical covariance matrices	multiple step slam;computacion informatica;grupo de excelencia;journal article;least squares;dimensionality reduction;ciencias basicas y experimentales	The main contribution of this paper is the dimensionality reduction for multiple-step 2D point feature based Simultaneous Localization and Mapping (SLAM), which is an extension of our previous work on one-step SLAM (Wang, Huang, Frese & Dissanayake 2013). It has been proved that SLAM with multiple robot poses and a number of point feature positions as variables is equivalent to an optimization problem with only the robot orientations as variables, when the associated uncertainties can be described using spherical covariance matrices. This reduces the dimension of original problem from 3m + 2n to m only (where m is the number of poses and n is the number of features). The optimization problem after dimensionality reduction can be solved numerically using the unconstrained optimization algorithms. While dimensionality reduction may not provide computational saving for all nonlinear optimization problems, for some SLAM problems we can achieve benefits such as improvement on time consumption and convergence. For the special case of two-step SLAM when the orientation information from odometry is not incorporated, an algorithm that can guarantee to obtain the globally optimal solution (in the maximum likelihood sense) is derived. Simulation and experimental datasets are used to verify the equivalence between the reduced nonlinear optimization problem and the original full optimization problem, as well as the proposed new algorithm for obtaining the globally optimal solution for two-step SLAM.	algorithm;blue (queue management algorithm);cognition;dimensionality reduction;hilbert–huang transform;mathematical optimization;maxima and minima;nonlinear programming;nonlinear system;numerical analysis;odometry;optimization problem;robot;simulation;simultaneous localization and mapping;turing completeness	Heng Wang;Shoudong Huang;Kasra Khosoussi;Udo Frese;Gamini Dissanayake;Bingbing Liu	2015	Automatica	10.1016/j.automatica.2014.10.114	mathematical optimization;combinatorics;machine learning;mathematics;least squares;dimensionality reduction	Robotics	56.4778449488383	-40.83990445582726	108425
a9d38820460031d5dd5a2e190e8f65a2d007b460	an analysis and implementation of the harris corner detector				Javier Sánchez;Nelson Monzón López;Agustín Salgado de la Nuez	2018	IPOL Journal	10.5201/ipol.2018.229	corner detection;computer science;optics	Vision	60.47649419685713	-47.34320335840735	108598
7f10e2489e843597f9d258762c4bd247e8890072	volumetric feature recognition for machining components with freeform surfaces	feature recognition;spatial relationships	Abstract   This paper describes a procedure for the extraction of features of a part containing a combination of 2.5D features and freeform surfaces. This work invokes a previous algorithm that was designed to recognize machining features from 2.5D parts destined to be machined on a 3-axis milling machine. The essence of that algorithm was a volume decomposition based on a recursive descent into the part, yielding a feature graph that captured both the geometry and the spatial relationships of the features. This work augments the previous algorithm with the ability to handle a limited class of components having freeform surfaces. Freeform features are defined similar to the 2.5D features as comprising a planar contour, but substituting a bottom freeform surface for the depth. Covering faces, defined as projection of the freeform surface on the faces of the bounding box of the surface, are used as equivalent planar faces for performing the recursive descent. Inter-feature open edges are used to signal the relationship between the freeform feature and other neighboring features. Examples of molds and components that were machined using the proposed algorithms are also presented.	feature recognition;freeform surface modelling	V. Sundararajan;Paul K. Wright	2004	Computer-Aided Design	10.1016/S0010-4485(03)00065-4	spatial relation;feature recognition;computer vision;engineering;pattern recognition;mathematics;engineering drawing;mechanical engineering	EDA	65.2716728750043	-42.321694708331016	108679
d82834d95e6c7ba61f9c76391f32f8e3d2a3a271	a graph-based approach to surface reconstruction	surface reconstruction;scattered data;surface description graph;euclidean minimum spanning tree;triangulation	A new approach to the reconstruction of a surface from an unorganized set of points in space is presented. The point set m a y f o r example be obtained with a laser scanner or a manual digitizing tool, and is the only source of information about the shape of the acquired object. The basic idea is to calculate the Euclidean minimum spanning tree (EMST) of the given points. The EMST is then augmented to the so-called surface description graph (SDG). Finally the wire frame defined by the SDG are filled with triangles. The advantage of our approach is that also highly non-convex and even disconnected surfaces are reconstructed quite reliably. This is demonstrated for a variety of data sets.	file spanning;information source;minimum spanning tree	Robert Mencl	1995	Comput. Graph. Forum	10.1111/j.1467-8659.1995.cgf143_0445.x	euclidean minimum spanning tree;combinatorics;topology;surface reconstruction;triangulation;mathematics;geometry	Vision	67.71014069866503	-43.87394529257188	108848
2d9bffab2b3f66cbc9edc38f8286a6517305f543	efficient visibility heuristics for kd-trees using the rtsah	raytracing;methodology and techniques;graphics data structures and data types;i 3 7 computer graphics;three dimensional graphics and realism;i 3 6 computer graphics	Acceleration data structures such as kd-trees aim at reducing the per-ray cost which is crucial for rendering performance. The de-facto standard for constructing kd-trees, the Surface Area Heuristic (SAH), does not take ray termination into account and instead assumes rays never hit a geometric primitive. The Ray Termination Surface Area Heuristic (RTSAH) is a cost metric originally used for determining the traversal order of the voxels for occlusion rays that takes ray termination into account. We adapt this RTSAH to building kd-trees that aim at reducing the per-ray cost of rays. Our build procedure has the same overall computational complexity and considers the same finite set of splitting planes as the SAH. By taking ray termination into account, we favor cutting off child voxels which are not or hardly visible to each other. This results in fundamentally different and more qualitative kd-trees compared to the SAH.		Matthias Moulin;Niels Billen;Philip Dutré	2015		10.2312/sre.20151164	simulation;computer science;theoretical computer science;computer graphics (images)	Vision	66.25779518591618	-50.29206548319982	108911
2f54fcc932193fc7a70cbed7dc7f93f707c3f65b	real-time tracking with non-rigid geometric templates using the gpu	frames per second;data parallel;paper;human computer interaction;video streaming;image processing;data parallel processor;video information;nonrigid geometric template;real time tracking;video signal processing;real time;video streaming computer graphic equipment computer vision digital signal processing chips human computer interaction parallel architectures tracking video signal processing;computer graphic equipment;video tracking;central processing unit streaming media graphics parallel processing application software computer vision image processing information filtering information filters pipelines;null;nvidia geforce 6800;computer vision;parallel processing architecture real time tracking nonrigid geometric template real time video stream human computer interaction computer vision video information image processing filter graphics processing unit graphics pipeline processor data parallel processor;large scale;parallel architectures;parallel processing architecture;nvidia;graphic processing unit;digital signal processing chips;opengl;vector field;graphics processing unit;graphics pipeline processor;image processing filter;parallel processing;tracking;real time video stream	The tracking of features in real-time video streams forms the integral part of many important applications in human-computer interaction and computer vision. Unfortunately tracking is a computationally intensive task, since the video information used by the tracker is usually prepared by applying a series of image processing filters. Thus it is difficult to realize a real-time tracker using only the CPU of a standard PC. Over the last few years, commodity graphics processing units (GPU) have evolved from fixed graphics pipeline processors into more flexible and powerful data-parallel processors. These stream processors are capable of sustaining computation rates of greater than ten times that of a single CPU. GPUs are inexpensive and are becoming ubiquitous (desktops, laptops, PDAs, cell phones). They are now capable to greatly relieve the CPU especially for large-scale parallel processing tasks, which map well to the architecture of the GPU. In this paper, we present a system, which uses a gradient vector field to track features with flexible geometric templates. Our implementation is specifically designed to suit the parallel processing architecture of the GPU. It is capable to achieve real-time performance with frame rates of around 30 frames per second	approximation;central processing unit;computation;computer graphics;computer vision;desktop computer;floor and ceiling functions;force field (chemistry);gradient;graphics pipeline;graphics processing unit;human–computer interaction;image processing;laptop;map;mobile phone;parallel computing;personal digital assistant;pipeline (computing);real-time clock;real-time computing;real-time transcription;simulation;stream processing;streaming media	Julius Fabian Ohmer;Frédéric Maire;Ross Brown	2006	International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)	10.1109/CGIV.2006.75	computer vision;computer hardware;computer science;computer graphics (images)	Visualization	56.36501189043274	-43.89347654609064	109179
d83975d1500ddda3a371ded99ee47178a329a4c3	tangential distance fields for mesh silhouette problems	tangent space surface representations;i 3 5 computational geometry and object modelling geometric algorithms languages and systems;tangential distance field;distance field;hierarchy and geometric transformations;mesh triangles	Aabstract#R##N##R##N#We consider a tangent-space representation of surfaces that maps each point on a surface to the tangent plane of the surface at that point. Such representations are known to facilitate the solution of several visibility problems, in particular, those involving silhouette analysis. In this paper, we introduce a novel class of distance fields for a given surface defined by its tangent planes. At each point in space, we assign a scalar value which is a weighted sum of distances to these tangent planes. We call the resulting scalar field a ‘tangential distance field’ (TDF). When applied to triangle mesh models, the tangent planes become supporting planes of the mesh triangles. The weighting scheme used to construct a TDF for a given mesh and the way the TDF is utilized can be closely tailored to a specific application. At the same time, the TDFs are continuous, lending themselves to standard optimization techniques such as greedy local search, thus leading to efficient algorithms. In this paper, we use four applications to illustrate the benefit of using TDFs: multi-origin silhouette extraction in Hough space, silhouette-based view point selection, camera path planning and light source placement.		Matt Olson;Hao Zhang	2009	Comput. Graph. Forum	10.1111/j.1467-8659.2008.01306.x	local tangent space alignment;computer vision;mathematical optimization;tangent vector;topology;computer science;mathematics;geometry;distance transform;tangential and normal components	Theory	67.91778435812749	-43.42621823900137	109429
4a585b69cc6d29e48f27cd486b6e99552422d8a1	lod generation for urban scenes	categories and subject descriptors i35 computer graphics compu tational geometry and object modeling additional key words and phrases urban reconstruction;levels of detail;urban scenes;abstraction;markov random field;min cut formulation;arrangement of planes;city modeling;iconization;urban reconstruction;3d reconstruction	We introduce a novel approach that reconstructs 3D urban scenes in the form of levels of detail (LODs). Starting from raw datasets such as surface meshes generated by multiview stereo systems, our algorithm proceeds in three main steps: classification, abstraction, and reconstruction. From geometric attributes and a set of semantic rules combined with a Markov random field, we classify the scene into four meaningful classes. The abstraction step detects and regularizes planar structures on buildings, fits icons on trees, roofs, and facades, and performs filtering and simplification for LOD generation. The abstracted data are then provided as input to the reconstruction step which generates watertight buildings through a min-cut formulation on a set of 3D arrangements. Our experiments on complex buildings and large-scale urban scenes show that our approach generates meaningful LODs while being robust and scalable. By combining semantic segmentation and abstraction, it also outperforms general mesh approximation approaches at preserving urban structures.	algorithm;approximation;experiment;fits;level of detail;markov chain;markov random field;maxima and minima;minimum cut;polygon mesh;scalability	Yannick Verdie;Florent Lafarge;Pierre Alliez	2015	ACM Trans. Graph.	10.1145/2732527	3d reconstruction;computer vision;computer science;machine learning;abstraction;computer graphics (images)	Graphics	58.050622919480496	-45.98789479007518	109626
318b848c8fe529bb8ea6543d695d1035b42190da	real-time ultrasoundsimulation for medical training	004 informatik	This thesis presents a real-time capable GPU-based ultrasound simulator suitable for medical education. Two different models are presented in the following. A 2D version has been implemented in order to simulate IVUS without modelling complex 3D geometry and a 3D version which is able to synthesize realistic looking ultrasound images in real-time. This includes ultrasound specific artifacts, which are essential for the interpretation of this data. The focus of this thesis is on the more general 3D version, that can simulate all common ultrasound modalities and is based on a convolution-enhanced ray-tracing approach which uses a deformable mesh model. This method advances the state of the art for real-time capable ultrasound simulators by following the path of the ultrasound pulse, which enables better simulation of ultrasound-specific artifacts. We evaluate our proposed method by comparison it to recent generative slicing-based strategies as well as real ultrasound images. Therefore, a gelatin ultrasound phantom containing syringes filled with different media is scanned with a real transducer. The obtained images are then compared to images which are simulated using a slicing-based technique and our proposed method. The particular benefit of our method is the accurate simulation of ultrasound-specific artifacts like range distortion, refraction and acoustic shadowing. Several benchmark scenarios are evaluated regarding simulation time, to show the performance and the bottleneck of our method. While being computationally more intensive than slicing techniques, our simulator is able to produce high-quality images in real-time, tracing over 5000 rays through mesh models with more than 2 000 000 triangles.	acoustic cryptanalysis;artifact (software development);benchmark (computing);bottleneck (engineering);convolution;distortion;graphics processing unit;phantom reference;ray tracing (graphics);real-time clock;real-time locating system;real-time transcription;simulation;transducer	Benny Bürger	2014			computer vision;simulation;engineering;biological engineering	Graphics	63.01145762894062	-49.94878477469862	109636
737bf0226d6afba654c63a95fa33f9143b2c35e8	hardware support for adaptive subdivision surface rendering	generic algorithm;hardware systems;cad;subdivision surface;data management;curves surfaces;triangular mesh;data storage;graphics hardware;data access;geometric modeling;rendering hardware;triangle mesh	Adaptive subdivision of triangular meshes is highly desirable for surface generation algorithms including adaptive displacement mapping in which a highly detailed model can be constructed from a coarse triangle mesh and a displacement map. The communication requirements between the CPU and the graphics pipeline can be reduced if more detailed and complex surfaces are generated, as in displacement mapping, by an adaptive tessellation unit which is part of the graphics pipeline. Generating subdivision surfaces requires a large amount of memory in whicmultiple arbitrary accesses are required to neighbouring vertices to calculate the new vertices. In this paper we present a meshing scheme and new architecture for the implementation of adaptive subdivision of triangular meshes that allows for quick access using a small memory making it feasible in hardware, while at the same time allowing for new vertices to be adaptively inserted. The architecutre is regular and characterized by an efficient data management that minimizes the data storage and avoids the wait cycles that would be associated with the multiple data accesses required for traditional subdivision. This architecture is presented as an improvement for adaptive displacement mapping algorithms, but could also be used for adaptive subdivision surface generation in hardware.	algorithm;blue (queue management algorithm);central processing unit;computer data storage;displacement mapping;fifo (computing and electronics);graphics pipeline;locality of reference;recursion;requirement;subdivision surface;triangle mesh;wafer-scale integration;wait state	Montserrat Bóo;Margarita Amor;Michael C. Doggett;Johannes Hirche;Wolfgang Straßer	2001		10.1145/383507.383522	data management;computer science;theoretical computer science;triangle mesh;subdivision surface;computer graphics (images)	Graphics	68.29219619863385	-50.7498516095345	110274
31835e0de882a58ed92ee50be2b85fc0548000bc	interactive modeling of topologically complex geometric detail	surface structure;construccion arquitectura tecnologia ambiental;computacion informatica;topological complexity;grupo de excelencia;volumetric rendering;volumetric texture;ciencias basicas y experimentales;interaction model;tecnologias;modeling	Volume textures aligned with a surface can be used to add topologically complex geometric detail to objects in an efficient way, while retaining an underlying simple surface structure.Adding a volume texture to a surface requires more than a conventional two-dimensional parameterization: a part of the space surrounding the surface has to be parameterized. Another problem with using volume textures for adding geometric detail is the difficulty in rendering implicitly represented surfaces, especially when they are changed interactively.In this paper we present algorithms for constructing and rendering volume-textured surfaces. We demonstrate a number of interactive operations that these algorithms enable.		Jianbo Peng;Daniel Kristjansson;Denis Zorin	2004	ACM Trans. Graph.	10.1145/1015706.1015773	computer vision;systems modeling;computer science;mathematics;geometry;transformational grammar;volume rendering;computer graphics (images)	Graphics	66.67008843971095	-46.3639019104411	110316
6b6fa87688f1e0ddb676a9ce5d18a7185f98d0c5	calibrate multiple consumer rgb-d cameras for low-cost and efficient 3d indoor mapping		Traditional indoor laser scanning trolley/backpacks with multi-laser scanner, panorama cameras, and an inertial measurement unit (IMU) installed are a popular solution to the 3D indoor mapping problem. However, the cost of those mapping suits is quite expensive, and can hardly be replicated by consumer electronic components. The consumer RGB-Depth (RGB-D) camera (e.g., Kinect V2) is a low-cost option for gathering 3D point clouds. However, because of the narrow field of view (FOV), its collection efficiency and data coverages are lower than that of laser scanners. Additionally, the limited FOV leads to an increase of the scanning workload, data processing burden, and risk of visual odometry (VO)/simultaneous localization and mapping (SLAM) failure. To find an efficient and low-cost way to collect 3D point clouds data with auxiliary information (i.e., color) for indoor mapping, in this paper we present a prototype indoor mapping solution that is built upon the calibration of multiple RGB-D sensors to construct an array with large FOV. Three time-of-flight (ToF)-based Kinect V2 RGB-D cameras are mounted on a rig with different view directions in order to form a large field of view. The three RGB-D data streams are synchronized and gathered by the OpenKinect driver. The intrinsic calibration that involves the geometry and depth calibration of single RGB-D cameras are solved by homography-based method and ray correction followed by range biases correction based on pixel-wise spline line functions, respectively. The extrinsic calibration is achieved through a coarse-to-fine scheme that solves the initial exterior orientation parameters (EoPs) from sparse control markers and further refines the initial value by an iterative closest point (ICP) variant minimizing the distance between the RGB-D point clouds and the referenced laser point clouds. The effectiveness and accuracy of the proposed prototype and calibration method are evaluated by comparing the point clouds derived from the prototype with ground truth data collected by a terrestrial laser scanner (TLS). The overall analysis of the results shows that the proposed method achieves the seamless integration of multiple point clouds from three Kinect V2 cameras collected at 30 frames per second, resulting in low-cost, efficient, and high-coverage 3D color point cloud collection for indoor mapping applications.	cost efficiency;data quality;electronic component;field of view in video games;ground truth;holography;homography (computer vision);iteration;iterative closest point;kinect;mobile mapping;open-source software;pixel;point cloud;prototype;seamless3d;sensor;sparse matrix;terrestrial television;visual odometry	Chi Chen;Bisheng Yang;Shuang Song;Mao Tian;Jianping Li;Wenxia Dai;Lina Fang	2018	Remote Sensing	10.3390/rs10020328	geology;point cloud;remote sensing;computer vision;simultaneous localization and mapping;visual odometry;artificial intelligence;inertial measurement unit;laser scanning;rgb color model;iterative closest point;field of view	HCI	54.38886970381662	-43.9622323822115	110330
e3660fe5d4d2726230c9bd7e56cdc07d0d0a4616	planar metric rectification by algebraically estimating the image of the absolute conic	absolute conic;image plane;new metric rectification method;closed form algebraic solution;planar metric rectification;fitting scheme;world plane;homography matrix;ellipse fitting process;metric rectification;image processing	A new metric rectification method for planar homography is proposed based on a closed form algebraic solution of the image of the absolute conic on the image plane. Our solution allows shape measurement to be made directly on the image plane without explicitly computing the homography matrix or recoreringing the rectified image. We show that the invariance property of the relationship between the circular points and the absolute conic under projective transformation can effectively do planar metric rectification. In this approach, the image of the absolute conic is solved algebraically to achieve metric rectification based only on the vanishing line and the image of one arbitrary circle on the world plane extracted automatically from the image plane. The process of conic solving introduces no errors and the performance of the method is mainly dependent on the robustness of the straight line and ellipse fitting processes. The fitting scheme suggested in the paper is robust and give good results in most cases.	camera resectioning;curve fitting;homography (computer vision);image plane;image rectification	Yisong Chen;Horace Ho-Shing Ip	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1333712	homography;computer vision;mathematical optimization;topology;image processing;computer science;mathematics;geometry;conic section;image rectification;conic constant	Vision	53.830900348523755	-50.79813443813781	110392
04d190a3868204db28e26a45201bb8becfa155ee	style-based motion synthesis	image motion analysis;best approximation;real time;motion synthesis;human body tracking;computer vision;motion capture;optical tracking;principal component analysis;human body;animation;motion models;computer animation;i 3 7 computer graphics three dimensional graphics and realism animation;animation techniques;principal component	Representing motions as linear sums of principal components has become a widely accepted animation technique. While powerful, the simplest version of this approach is not particularly well suited to modeling the specific style of an individual whose motion had not yet been recorded when building the database: it would take an expert to adjust the PCA weights to obtain a motion style that is indistinguishable from his. Consequently, when realism is required, the current practice is to perform a full motion capture session each time a new person must be considered. In this paper, we extend the PCA approach so that this requirement can be drastically reduced: for whole classes of cyclic and noncyclic motions such as walking, running or jumping, it is enough to observe the newcomer moving only once at a particular speed or jumping a particular distance using either an optical motion capture system or a simple pair of synchronized video cameras. This one observation is used to compute a set of principal component weights that best approximates the motion and to extrapolate in real-time realistic animations of the same person walking or running at different speeds, and jumping a different distance.	blackwell (series);displacement mapping;eurographics;extrapolation;gaussian process;inverse kinematics;isomap;motion capture;nonlinear system;principal component analysis;real-time clock;real-time locating system;real-time transcription;solver;video post-processing	Raquel Urtasun;Pascal Glardon;Ronan Boulic;Daniel Thalmann;Pascal Fua	2004	Comput. Graph. Forum	10.1111/j.1467-8659.2004.00809.x	computer vision;simulation;computer science;artificial intelligence;machine learning;motion estimation;principal component analysis;computer graphics (images)	Vision	60.08690886576535	-45.733653773986866	110602
b3afaff55ea9d5271e4d31abd4f0dd6e60be28d7	bresenham algorithm: implementation and analysis in raster shape	bresenham algorithm;numerical result;display;opengl;computation speed;error produced	One of the most important aspect that have to solve in raster objects is to describe the structure of the individual objects and their coordinate locations within the scene. We required to implement the graphics output primitives. The Output primitives are very important since the performance of the graphics depend on the Primitives. Point positions and straight-line segments are the simplest geometric primitives. We focus on these parts in this research. In this paper we will implement and analysis how accurate and efficient raster line-generating algorithm, develop by Bresenham, that uses only incremental integer calculations. The implementation will be expanded to display circles and other curves. The analysis will be focus on numerical results, error produced, computation speed, and display. The language that used in this implementation is C++ with OpenGL.	bresenham's line algorithm;c++;computation;geometric primitive;numerical analysis;opengl;raster graphics	Ford Lumban Gaol	2013	JCP	10.4304/jcp.8.1.69-78	computer vision;computer science;theoretical computer science;bresenham's line algorithm;computer graphics (images)	Graphics	67.04179082606571	-48.76601831834802	110653
6a75892f45b72f8765379134e8d2a4ed6a04f1b0	continuous distance-dependent level of detail for rendering heightmaps	three dimensional;level of detail;graphics hardware;source code	This paper presents a technique for GPU-based rendering of heightmap terrains, which is a refinement of several existing methods with some new ideas. It is similar to the terrain clipmap approaches [Tanner et al. 98, Losasso 04], as it draws the terrain directly from the source heightmap data. However, instead of using a set of regular nested grids, it is structured around a quadtree of regular grids, more similar to [Ulrich 02], which provides it with better level-of-detail distribution. The algorithm's main improvement over previous techniques is that the LOD function is the same across the whole rendered mesh and is based on the precise three-dimensional distance between the observer and the terrain. To accomplish this, a novel technique for handling transition between LOD levels is used, which gives smooth and accurate results. For these reasons the system is more predictable and reliable, with better screen-triangle distribution, cleaner transitions between levels, and no need for stitching meshes. This also simplifies integration with other LOD systems that are common in games and simulation applications. With regard to the performance, it remains favourable compared to similar GPU-based approaches and works on all graphics hardware supporting Shader Model 3.0 and above. Demo and complete source code is available online under a free software license.	algorithm;clipmap;free software license;graphics hardware;graphics processing unit;heightmap;image stitching;level of detail;quadtree;refinement (computing);shader;simulation;tanner graph	Filip Strugar	2009	J. Graphics, GPU, & Game Tools	10.1080/2151237X.2009.10129287	three-dimensional space;computer vision;simulation;computer science;operating system;heightmap;level of detail;graphics hardware;algorithm;source code;computer graphics (images)	Graphics	66.69725780068858	-49.67336326446512	110744
7234e2ed78d585dcc1d9c16d0b8cf2e8a007f9b0	constructive shell representations for freeform surfaces and solids	sculptured surfaces;modelizacion;concepcion asistida;computer aided design;modelisation arbre csg;solid;representation tridimensionnelle;solide;computational solid geometry constructive shell representations freeform surfaces 2d r sets 3d euclidean space finite union solid modeling algebraic forms algebraic patches thick shells exact csg representations freeform solids;solido;solid modeling polynomials equations shape control embedded computing mathematical model weight control thickness control computational geometry binary trees;computer graphics;modelisation hybride;computational geometry;modelisation;computational geometry solid modelling;solid modeling;conception assistee;superficie;euclidean space;surface;csr;three dimensional representation;modeling;grafico computadora;infographie;representacion tridimensional;solid modelling;modelisation brep	We usually model freeform surfaces (mathematically, 2D r-sets embedded in 3D Euclidean space E/sup 3/) as a finite union of patches represented in the traditional parametric or the recently developed algebraic forms. The article introduces a new representation scheme for freeform surfaces called constructive shell representation (CSR), that draws on recent research on algebraic patches. CSRs of surfaces that constitute boundaries of solids are very useful for solid modeling. They represent thick shells derived from freeform surfaces and provide a means to compute exact CSG representations of freeform solids.<<ETX>>	constructive solid geometry;embedded system;freeform surface modelling;linear algebra;solid modeling	Jai Menon	1994	IEEE Computer Graphics and Applications	10.1109/38.267468	freeform surface modelling;combinatorics;systems modeling;computational geometry;euclidean space;mathematics;geometry;solid modeling;solid;computer graphics;surface;corporate social responsibility	Graphics	67.00574433582602	-41.51936456972173	110798
3699aeaeb5b35f3063ecbafe1c94adc4555b8f56	a gradient mesh tool for non-rectangular gradient meshes		The gradient mesh tool, implemented in vector graphics software like Adobe Illustrator, is a popular tool for creating and manipulating complex colour gradients. The mesh-based tool is restricted to rectangular gradient meshes, making it hard for the user to work with more complicated shapes such as shapes with holes. We propose a new gradient mesh tool that supports non-rectangular meshes, with native support for a wide range of different shapes. A user study indicates that our tool is easier to use when drawing colour gradients inside complicated shapes.	adobe illustrator;gradient descent;graphics software;polygon mesh;usability testing;vector graphics editor	John Kasper Svergja;Henrik Lieng	2017		10.1145/3102163.3102172	computer vision;vector graphics;computer graphics (images);computer science;color gradient;polygon mesh;software;artificial intelligence	Graphics	65.36318365940791	-47.39139530162202	110880
cefe2a6b29a5cc91e94b128676fd6d105227919c	vehicle collision reconstruction with 3-d inertial navigation and gnss	computer crashes;trajectory;accidents;vehicle crash testing;vehicles;accelerometers;vehicle dynamics	Complex and fatal road vehicle crashes are often a matter of dispute in forensic investigation. The proposed algorithms and methods, utilizing data from inertial measurement units and satellite navigation, enable road-vehicle trajectory reconstruction in 3-D suitable for postaccident forensic analysis. This paper provides an estimate of the reliability of this approach and its relation to component specifications. We start by describing an appropriate type of the strap-down inertial navigation system before providing a detailed performance analysis when the system is integrated with global navigation satellite systems. In addition, we present custom hardware and embedded software solutions, as well as experimental evaluation in real-world case study, capturing typical crash scenario performed at an approved safety performance assessment laboratory. In our experiments, strap-down inertial mechanization was used for short-term vehicle trajectory reconstruction using sensor readings and compared with ground-truth position captured on video. We have used reference equipment to validate the approach and the experiment resulted in a positioning accuracy on a decimeter level.	accident analysis;algorithm;camera resectioning;discrepancy function;embedded software;experiment;ground truth;image plane;inertial navigation system;item unique identification;maximal set;observable;online and offline;satellite navigation;telematics;video content analysis	Srdjan Tadic;Rade Stancic;Lazar V. Saranovac;Predrag Ivanis	2017	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2016.2619018	embedded system;vehicle dynamics;simulation;engineering;trajectory;inertial navigation system;computer security;accelerometer;physics;quantum mechanics	Robotics	56.34363900495784	-38.297538661493874	111111
a6180b3e58fc252762a3764d2dcd382474787952	the floating column algorithm for shaded, parallel display of function surfaces without patches	hand held device;parallel rendering;functionally defined terrains;time varying;interpolation;floating column;displays clustering algorithms rendering computer graphics graphics pixel workstations image resolution image sampling frequency software algorithms;image resolution;perspective projection;real time;texture mapping;computer graphic equipment;sampling frequency;mathematical software packages;image texture;graphics hardware;antialiasing;function display;local supersampling;floating horizon;sampling methods;computer animation;real time systems rendering computer graphics parallel algorithms image texture interpolation image resolution computer graphic equipment sampling methods antialiasing computer animation;rendering computer graphics;height fields;real time systems;parallel algorithms	ÐThe floating column algorithm is a new method for the shaded rendering of function surfaces. Derived from the monochromatic floating horizon algorithm, it uses the partial derivatives of the function to compute surface normals, thus enabling intensity or normal-interpolation shading. Current rendering methods require tiling the surface with patches, so higher resolution patching is required for zoom-in views or interactive modification or time-varying surfaces. The new algorithm requires no patching and uses only constant space, so it can be implemented on graphics cards and hand-held devices. Each pixel-column is displayed independently of the others, and this ªindependent column modeº makes the algorithm inherently parallel in image-space, so it is suitable for multiprocessor workstations and clusters and it is scalable in the resolution size. Furthermore, the sampling frequency of the surface can be controlled locally, matching local surface features, distance, or artifact elimination requirements. Space-efficient supersampling for antialiasing is also possible. The new algorithm, which allows orthogonal and perspective projections, produces pixel-wide strips which can be displayed in software or hardware. Various extensions are described, including shadows and texture mapping. These properties, together with the algorithm's parallelism, make it potentially useful for the real-time display of functionally defined textured terrains and the animated display of time-varying surfaces.	algorithm;graphics;interpolation;mobile device;monochrome;multiprocessing;normal (geometry);parallel computing;patch (computing);pixel;real-time transcription;requirement;strips;sampling (signal processing);scalability;shading;shadow (os/2);spatial anti-aliasing;supersampling;texture mapping;tiling window manager;video card;workstation	Dan Gordon	2002	IEEE Trans. Vis. Comput. Graph.	10.1109/2945.981853	image texture;texture mapping;sampling;computer vision;perspective;image resolution;computer hardware;interpolation;computer science;parallel rendering;parallel algorithm;computer animation;graphics hardware;sampling;computer graphics (images)	Graphics	67.84964248329226	-51.181950642032405	111131
cbf5e7952334335fbf94f11e213dec684081fda6	rational radial distortion models with analytical undistortion formulae	radial distortion;camera calibration;polynomial approximation	|The common approach to radial distortion is by the means of polynomial approximation, which introduces distortion-speci c parameters into the camera model and requires estimation of these distortion parameters. The task of estimating radial distortion is to nd a radial distortion model that allows easy undistortion as well as satisfactory accuracy. This paper presents a new class of rational radial distortion models with easy analytical undistortion formulae. Experimental results are presented to show that with this class of rational radial distortion models, satisfactory and comparable accuracy is achieved.	approximation;consistency model;distortion;polynomial;radial (radio);radial basis function	Lili Ma;Yangquan Chen;Kevin L. Moore	2003	CoRR		distortion;computer vision;mathematical optimization;mathematical analysis;camera resectioning;computer science;mathematics;geometry	ML	54.18903937759217	-49.24941719625976	111630
400f51fd9f1a693c0eecd550c482a8dbd2b9f4a9	fast and faithful geometric algorithm for detecting crest lines on meshes	computer graphics;surface topography;spline;application software;cubic spline;tensor product;surface reconstruction;polynomials;industrial relations	A new geometry-based finite difference method for a fast and reliable detection of perceptually salient curvature extrema on surfaces approximated by dense triangle meshes is proposed. The foundations of the method are two simple curvature and curvature derivative formulas overlooked in modern differential geometry textbooks and seemingly new observation about inversion-invariant local surface-based differential forms.	approximation algorithm;computational geometry;finite difference method;sensor	Shin Yoshizawa;Alexander G. Belyaev;Hideo Yokota;Hans-Peter Seidel	2007	15th Pacific Conference on Computer Graphics and Applications (PG'07)	10.1109/PG.2007.24	gaussian curvature;differential geometry;mathematical optimization;combinatorics;finite difference method;mathematics;geometry;curvature	Vision	65.83257206103619	-43.467892014472596	111782
9373dd49da77a5fd3fab4548197590697b8f2524	bounded radiosity - illumination on general surfaces and clusters	form factor;energy transfer;random walk;radiosity;error bound;monte carlo;computational efficiency;importance;rendering	Traditionally, Radiosity algorithms have been restricted o scenes made from planar patches. Most algorithms for computing form factors and the subdivision criterion for hi erarchical methods implicitly assume planar patches. In this paper, we present a new radiosity algorithm that is so lely based on simple geometric information about surface elements, namely their bounding boxes and cone of no rmals. Using this information allows to compute efficient error bounds that can be used for the subdivision or acle and for computing the energy transfer. Due to the simple interface to geometric objects, our algorithms n ot only allows for computing illumination on general curved surfaces, but it can also directly be applied to a hier archy of clusters. Several examples demonstrate the advantages of the new approach.	algorithm;approximation;archy;computation;computer form factor;eurographics;minimum bounding box;radiosity (computer graphics);subdivision surface;time complexity	Marc Stamminger;Philipp Slusallek;Hans-Peter Seidel	1997	Comput. Graph. Forum	10.1111/1467-8659.00168	energy transfer;mathematical optimization;radiosity;form factor;rendering;computer science;theoretical computer science;mathematics;random walk;statistics;monte carlo method;computer graphics (images)	Graphics	66.16380322378812	-45.55817166930115	112271
f9fc46b4de0599a317df859a5bad87e79e7c2902	geometric processing of volumetric objects	volumetric objects;processing;coding;high pass filter;curvature tensor;riemannian geometry	This paper introduces techniques of Riemannian geometry for processing and visualising volumetric graphical objects. A family of non-linear high-pass filters, based on the curvature tensor, is introduced and used to study the local redundancy on objects. It is shown how to reconstruct an object from geometric nonredundant regions and applications are presented and discussed.	nonlinear system;volume	Romildo Silva;Jonas Gomes;Cicero Mota	2001			riemannian geometry;computer vision;computer science;pure mathematics;mathematics;geometry;riemann curvature tensor;high-pass filter;computer graphics (images)	Vision	66.10939196478601	-44.6785695829236	112287
ed37557760560d601b2c8c72221103a4f5842108	correcting unsynchronized zoom in 3d video	least squares regressions;least squares approximations;video signal processing cameras least squares approximations regression analysis;video signal processing;unsynchronized zoom;stereo video quality;scaling;optical imaging;three dimensional displays;synchronization;least square;vertical parallax;cropping;mathematical model;cameras motion estimation degradation image motion analysis laboratories geometrical optics calibration;regression analysis;vertical parallax 3d video unsynchronized zoom stereoscopic camera setup stereo video quality cropping scaling least squares regressions;3d video;stereoscopic camera setup;cameras;adaptive optics	When capturing 3D video with a stereoscopic camera setup, it is important for the cameras to be precisely aligned and synchronized. This is particularly difficult in transitions such as zooming where the camera parameters must be changed in unison, or else the perceived 3D effect will be degraded. In this paper we study the problem of unsynchronized zooming in 3D video. First, we present a subjective study that shows that the perceived quality of stereo video is greatly reduced if the two views are zoomed by different amounts. Next, we present a method for correcting zoom mismatch by applying cropping and scaling to ones of the views. Our method involves finding matching points between the left and right views, and performing least-squares regressions to estimate the amount of scaling and cropping required to make the views consistent. Experiments were performed on videos with digitally introduced zoom mismatch and videos with optical unsynchronized zoom. In both cases the results show that our method is highly accurate and produces videos without size differences or vertical parallax between the two views.	algorithm;align (company);image scaling;least squares;parallax;scale-invariant feature transform;software regression;stereoscopy;unison;zooming user interface	Colin Doutre;Mahsa T. Pourazad;Alexis M. Tourapis;Panos Nasiopoulos;Rabab Kreidieh Ward	2010	Proceedings of 2010 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2010.5537923	synchronization;computer vision;scaling;computer science;cropping;digital zoom;optical imaging;mathematical model;mathematics;adaptive optics;least squares;regression analysis;statistics;computer graphics (images)	Visualization	53.91576274858417	-49.11304808947069	112330
41ae4a7f01236ccd67a95cdde97198e6c8acadba	efficient computation of enclosed volume and surface area from the same triangulated surface representation	incremental computation;surface representation;shape parameters;marching cubes;medicinsk bildbehandling;isosurface;digital boundary;medical image processing;shape parameter;lookup table;volume measurement;surface tracking;computational efficiency;marching cube;data structure;shell structure;surface area;boundary measurement;rendering	We demonstrate that the volume enclosed by triangulated surfaces can be computed efficiently in the same elegant way the volume enclosed by digital surfaces can be computed by digital surface integration. Although digital surfaces are effective and efficient for visualization and volume measurement, their drawback is that surface area measurements derived from them are inaccurate. On the other hand, triangulated surfaces give more accurate surface area measurements, but volume measurements and visualization are less efficient. Our data structure (called t-shell) for representing triangulated digital surfaces retains advantages and overcomes difficulties of both the digital and the triangulated surfaces. We create a lookup table with area and volume contributions for each of the 256 Marching Cubes configurations. When scanning the shell (e.g., while creating it), the surface area and volume are incrementally computed by using the lookup table and the current x co-ordinate, where the sign of the x component of the triangle normal indicates the sign of the volume contribution. We have computed surface area and volume for digitized mathematical phantoms, physical phantoms, and real objects. The experiments show that triangulated surface area is more accurate, triangulated volume follows digital volume closely, and that the values get closer to the true value with decreasing voxel size.	computation (action);data structure;digital geometry;experiment;imagery;lookup table;marching cubes;mathematics;oxygen 100 % gas for inhalation;phantoms, imaging;physical object;volume measurement;voxel	Ingela Nyström;George J. Grevera;Bruce Elliot Hirsch;Jayaram K. Udupa	2011	Computerized medical imaging and graphics : the official journal of the Computerized Medical Imaging Society	10.1016/j.compmedimag.2010.11.001	combinatorics;topology;data structure;computer science;mathematics;geometry;marching cubes	Visualization	67.83722092756551	-46.81161377794576	112448
cd78182e4aca92efc65ba968ca1f0874fbcde60a	fpga-based implementation of estimating saturated pixel values in raw image			field-programmable gate array;pixel;raw image format	Jun Fu;Yungang Wu;Xuanqin Mou;Wenbo Ji;Ping Wang	2016			pixel;field-programmable gate array;computer vision;artificial intelligence;computer science	Vision	58.43431536032232	-42.64941575582091	112892
c4c48ea0e76ea96897e93c768d464f871bf95aa5	an automated system for plant-level disease rating in real fields	cls rater plant level disease rating cercospora leaf spot sugar beet plants sugar yield reduction agricultural domain sugar beet cultivars computer vision system plant images tractor mounted camera multiscale super pixel extraction feature representation across super pixel global appearance variations within super pixel local appearance variations bagging m5p regress day lighting weather conditions;image color analysis feature extraction diseases sugar industry soil testing histograms;plant diseases agriculture biology computing botany cameras computer vision encoding feature extraction image coding image fusion image representation learning artificial intelligence	"""Cercospora leaf spot (CLS) is the most serious disease in sugar beet plants that significantly reduces the sugar yield throughout the world. Therefore the current focus of the researchers in agricultural domain is to find sugar beet cultivars that are highly resistant to CLS. To measure their resistance, CLS is manually observed and rated in a large variety of sugar beet by different human experts over a period of a few months. Unfortunately, this procedure is laborious and subjective. Therefore, we propose a novel computer vision system, CLS Rater, to automatically and accurately rate CLS of plant images in the real field to the """"USDA scale"""" of 0 to 10. Given a set of plant images captured by a tractor-mounted camera, CLS Rater extracts multi-scale super pixels, where in each scale a novel histogram of importances feature representation is proposed to encode both the within-super pixel local and across-super pixel global appearance variations. These features at different super pixel scales are then fused for learning a bagging M5P regress or that estimates the rating for each plant image. We test our system on the field data collected over a period of two months under different day lighting and weather conditions. Experimental results show CLS Rater to be highly consistent with a rating error of 0.65, which demonstrates higher consistency than the rating standard deviation of 1.31 by the human experts."""	common language infrastructure;computer vision;encode;f-spot;pixel	Muhammad Jamal Afridi;Xiaoming Liu;J. Mitchell McGrath	2014	2014 22nd International Conference on Pattern Recognition	10.1109/ICPR.2014.35	computer vision;simulation	Vision	58.2906714963852	-47.15852083482386	112950
d3d0c342e62100584fb95c7495d30ed42e89d381	random sampling nonlinear optimization for camera self-calibration with modeling of intrinsic parameter space	random sampling;parameter space;nonlinear optimization;gaussian distribution	This paper presents a framework for random sampling nonlinear optimization for camera self-calibration with modeling of the camera intrinsic parameter space. The focal length is modeled using a Gaussian distribution derived from the results of the Kruppa equations, while the optical center is modeled based on the assumption that the optical center is close to the image center but deviates from it due to some manufacturing imprecision. This model enables us to narrow the search range of parameter space and therefore reduce the computation cost. In addition, a random sampling strategy is utilized in order to avoid local optima, where the samples are drawn according to this model. Experimental results are presented to show the effectiveness of the proposed nonlinear optimization algorithm, even in the under-constrained case involving only two frames.	nonlinear programming	Houman Rastgar;Eric Dubois;Liang Zhang	2010		10.1007/978-3-642-17277-9_20	normal distribution;sampling;mathematical optimization;nonlinear programming;control theory;mathematics;parameter space;statistics	Vision	54.11367654005326	-49.57634110328411	113108
a1fd5a579f2aef06c2a3dda5c6f1886560bf1243	calibration of kinematic body sensor networks: kinect-based gauging of data gloves “in the wild”	joints kinematics calibration thumb sensors data gloves bones;sensors;joints;kinematics;thumb;bones;data gloves;calibration	Our hands generic precision and agility is yet unmatched by technology, hence the quantitative study of its daily life kinematics is fundamental to neurology/prosthetics & robotics and creative industries. State-of-the-art solutions capturing hand movements ‘in the wild’ requires wearable body sensor networks: data gloves. Yet, fast-accurate calibration is challenging due to variability in hand anatomy and complexity of finger joints. We present here novel methods for calibration using streaming information from depth cameras (Microsoft Kinect). Our low-cost system calibrates the data glove by observing a user wiggling their hands while wearing data gloves. Using inverse kinematics we reconstruct in real-time hand configuration, enabling augmented reality by superimposing the virtual and real hand veridically. We achieve accuracies of ±5 degrees RMSE over all 21 joints, almost 20% more accurate than standard calibration methods and accurately capture touching of fingertips and thumb — our benchmark test unmatched by other calibration methods.	augmented reality;benchmark (computing);heart rate variability;inverse kinematics;kinect;real-time locating system;robotics;wearable computer;wired glove	Alexandre P. Vicente;A. Aldo Faisal	2013	2013 IEEE International Conference on Body Sensor Networks	10.1109/BSN.2013.6575526	computer vision;kinematics;calibration;simulation;sensor	Robotics	58.78456859265233	-38.55093106381256	113220
50491ec7e2e5e949e3c5929381d17ca4562ee733	computer vision – eccv 2018		We present a practical method for geometric point light source calibration. Unlike in prior works that use Lambertian spheres, mirror spheres, or mirror planes, our calibration target consists of a Lambertian plane and small shadow casters at unknown positions above the plane. Due to their small size, the casters’ shadows can be localized more precisely than highlights on mirrors. We show that, given shadow observations from a moving calibration target and a fixed camera, the shadow caster positions and the light position or direction can be simultaneously recovered in a structure from motion framework. Our evaluation on simulated and real scenes shows that our method yields light estimates that are stable and more accurate than existing techniques while having a considerably simpler setup and requiring less manual labor. This project’s source code can be downloaded from: https://github. com/hiroaki-santo/light-structure-from-pin-motion.	european conference on computer vision;lambertian reflectance;shadow volume;structure from motion	Vittorio Ferrari;Martial Hebert;Cristian Sminchisescu;Yair Weiss	2018		10.1007/978-3-030-01219-9		Vision	56.34640464580804	-49.449596145159944	113329
3fd139bf053fbf3922294bcfc50c28bccb0b3164	editing object behaviour in video sequences	segmentation;inpainting;graph cut;video editing;spatio temporal;i 4 8 image processing and computer vision scene analysis time varying imagery;i 3 4 computer graphics graphics utilities graphics editors	Abstract#R##N##R##N#While there are various commercial-strength editing tools available today for still images, object-based manipulation of real-world video footage is still a challenging problem. In this system paper, we present a framework for interactive video editing. Our focus is on footage from a single, conventional video camera. By relying on spatio-temporal editing techniques operating on the video cube, we do not need to recover 3D scene geometry. Our framework is capable of removing and inserting objects, object motion editing, non-rigid object deformations, keyframe interpolation, as well as emulating camera motion. We demonstrate how movie shots with moderate complexity can be persuasively modified during post-processing.		Volker Scholz;Sascha El-Abed;Hans-Peter Seidel;Marcus A. Magnor	2009	Comput. Graph. Forum	10.1111/j.1467-8659.2009.01413.x	computer vision;cut;post-production;computer science;video tracking;multimedia;video processing;segmentation;inpainting;computer graphics (images);non-linear editing system	Vision	59.810861771993835	-50.41038208073706	113439
0061737d3761e20c4b8b229b65c35819b3df8904	stereoscopic line drawing using depth maps	non photorealistic rendering;3d imaging;line drawings;stereoscopic 3d;image processing methods;depth map	Motivated by the success of the recent stereoscopic 3D films, there is a growing demand for techniques for creating and editing 3D contents. Several researchers have attempted to improve existing 2D image processing methods in order to apply them to the stereoscopic 3D images.	3d film;depth map;image processing;line drawing algorithm;stereoscopic video game;stereoscopy	Yeong-Seok Kim;Ji-yong Kwon;In-Kwon Lee	2012		10.1145/2342896.2343026	stereoscopy;computer vision;computer science;non-photorealistic rendering;multimedia;computer graphics (images)	Graphics	63.005527332269025	-50.09444221124993	113628
028cb1a125f061701e4306565cc333a8867f8ef9	data-driven interactive quadrangulation	polygon quadrangulation;quad meshing;retopology	We propose an interactive quadrangulation method based on a large collection of patterns that are learned from models manually designed by artists. The patterns are distilled into compact quadrangulation rules and stored in a database. At run-time, the user draws strokes to define patches and desired edge flows, and the system queries the database to extract fitting patterns to tessellate the sketches' interiors. The quadrangulation patterns are general and can be applied to tessellate large regions while controlling the positions of the singularities and the edge flow. We demonstrate the effectiveness of our algorithm through a series of live retopology sessions and an informal user study with three professional artists.	algorithm;squaregraph;usability testing	Giorgio Marcias;Kenshi Takayama;Nico Pietroni;Daniele Panozzo;Olga Sorkine-Hornung;Enrico Puppo;Paolo Cignoni	2015	ACM Trans. Graph.	10.1145/2766964	simulation;computer science;computer graphics (images)	Graphics	65.96592535193874	-46.71569211256868	113668
47e908bad4864125aaeb3fe6706ad66cd1e4ec03	shape and motion under varying illumination: unifying structure from motion, photometric stereo, and multiview stereo	image motion;spatial intensity variation;image motion analysis;multiview stereo;albedo;image sequence analysis;image shape;image texture;distant illumination;lighting image motion analysis stereo image processing image texture image sequences image reconstruction video cameras albedo;textured surface;stereo matching;video cameras;photometric stereo;image reconstruction;image sequence;stereo image processing;textureless surface;stereo vision;affine camera parameter;multi view stereo;affine camera parameter image shape image motion photometric stereo multiview stereo optical flow computation image sequence lambertian object distant illumination spatial intensity variation temporal intensity variation surface orientation image reconstruction textured surface textureless surface;optical flow;image texture analysis;lighting;shape lighting photometry optical computing iterative algorithms surface reconstruction surface texture cameras optical variables control image motion analysis;temporal intensity variation;structure from motion;optical flow computation;surface orientation;lambertian object;image sequences	♦ Motion cue constrains 3D positions inaccurately for low textured pixels ♦ Photometric cue reveals normals accurately even for moving scenes, despite the noisy motion estimation ♦ Combing both cues recovers moving shape densely Constraints on brightness-varying flow Our formulation extends [Irani99] and applies to features, edges, and textureless regions. Our formulation also subsumes Structure from Motion, Multi-view Stereo, and Photometric Stereo as special cases:	motion estimation;photometric stereo;pixel;structure from motion	Li Zhang;Brian Curless;Aaron Hertzmann;Steven M. Seitz	2003		10.1109/ICCV.2003.1238405	iterative reconstruction;image texture;stereo camera;computer vision;structure from motion;photometric stereo;computer science;stereopsis;optical flow;lighting;albedo;computer graphics (images)	Vision	54.04699520885901	-51.91442456594132	113836
cd289247e3fa3ac1ef4d396e360478062c50185e	interactive inspection of solids: cross-sections and interferences	first occurrence;interferences;numerical technique;internal structure;efficient implementation;clipping;cross section	To reduce the cost of correcting design errors, assemblies of mechanical parts are modeled using CAD systems and verified electronically before the designs are sent to manufacturing. Shaded images are insufficient for examining the internal structures of assemblies and for detecting interferences. Thus, designers must rely on expensive numerical techniques that compute geometric representations of cross-sections and of intersections of solids. The solid-clipping approach presented here bypasses these geometric calculations and offers realtime rendering of cross-sections and interferences for solids represented by their facetted boundaries. In its simplest form, the technique is supported by contemporary highend graphics workstations. Its variations, independently developed elsewhere, have already been demonstrated. Our implementation is based on the concept of a cutvolume interactively manipulated to remove obstructing portions of the assembly and reveal its internal structure. For clarity, faces of the cut-volume which intersect a single solid are hatched and shaded with the color of that solid. Interference areas between two or more solids are highlighted. Furthermore, to help users find the first occurrence of an interference along a search direction, we have developed an adaptive subdivision search based on a projective approach which guarantees a sufficient condition for object disjointness. The additional performance cost for solid-clipping and interference highlighting is comparable to the standard rendering cost. An efficient implementation of the disjointness test requires a minor extension of the graphics functions currently supported on commercial hardware. CR Categories and Subject Descriptions: 1.3.3 [Computer Graphics]: Picture/Image Generation -Display Algorithms; 1.3.5 [Computational Geometry and Object Modeling]: Solid Representation; 1.3.7 [Three-Dimensional Graphics and Realism]: Visible Surface Algorithms; J.6 [Computer Aided Engineering]: Computer Aided Design.	algorithm;computation;computational geometry;computer-aided design;facet (geometry);interactivity;interference (communication);numerical analysis;real-time computer graphics;sensor;shading;solid modeling;subdivision surface;workstation	Jarek Rossignac;Abe Megahed;Bengt-Olaf Schneider	1992		10.1145/133994.134092	computer vision;simulation;computer science;clipping;theoretical computer science;mathematics;cross section;geometry;computer graphics (images)	Graphics	66.74838421738474	-48.19057140830064	113865
11b8f0bdf3f1a4b83a0d17cddbfb3b92eb96a1e5	a fragment culling technique for rendering arbitrary portals	convex polygon	Portal-based rendering traditionally describes techniques that involve rendering scenes that have been partitioned into cells connected by portals. The partition information is exploited to determine visibility information. Recently, portal-based rendering has also been used to describe scenes composed from cells and transformative portals. Interesting scenes can be composed by using cell topologies that would never emerge from scene partitioning. Although some constraints have been removed to allow for scene composition, many still exist. The surfaces of portals are necessarily planar and convex polygons, usually with a low maximum number of vertices. These constraints are imposed to simplify clipping that would otherwise become geometrically complex. In this paper, we analyze a technique to simulate complex geometric clipping using fragment culling and integrate this into an algorithm to render arbitrary portals. Finally we provide some examples of interesting portal-based environments that are enabled by our algorithm.	portals	Nick Lowe;Amitava Datta	2003		10.1007/3-540-44860-8_95	computer vision;computer science;computer graphics (images)	EDA	66.72444248247669	-48.21451673130329	113878
fdd18e4b6c2d26aadc906ccdd6d8966d2b9c6023	paxel: a generic framework to superimpose high-frequency print patterns using projected light		"""In this paper, we propose <italic>Paxel</italic>, a generic framework for modeling the interaction between a projector and a high-frequency <italic>pattern surface</italic>. Using this framework, we present two different application setups [cf. <xref rid=""""fig1"""" ref-type=""""fig"""">Fig. 1(a)</xref>]: a novel <italic>color-changing effect</italic>, created with a single projected image and only when the projection surface is changed from a <italic>pattern surface</italic> to a <italic>uniform white surface</italic>. The observed effect relies on the spatially different reflectance properties of these two surfaces. Using this approach, one can alter color proprieties of the projected image such as hue or chroma. Furthermore, for a specific color range, defined by a <italic>full color-changing sub-gamut</italic>, one can embed two completely different images, within a single static projection, from which either one will be revealed depending on the surface. The second application allows the creation of color images using a single channel projector. For this application, we present a full color projection created using a 365-nm ultraviolet projector in combination with fluorescent pigments [cf. <xref rid=""""fig1"""" ref-type=""""fig"""">Fig. 1(b)</xref>], enabling new display possibilities, such as projection through participating media, e.g., fog, while hiding the scattering of the projection light outside of the visible spectrum. Both presented approaches create effects that might be striking to the observer, making this framework useful for art exhibitions, advertisements, entertainment, and visual cryptography. Finally, in <xref rid=""""sec6"""" ref-type=""""sec"""">Section VI</xref>, we provide an in-depth analysis of the reproducible colors based on input parameters, used in the presented algorithm, such as pattern layout, dot size of the pattern, and the number of the clusters formed by k-means algorithm (<xref rid=""""sec4b"""" ref-type=""""sec"""">Section IV-B</xref>)."""	advertisements;algorithm;color;cross-reference;distance fog;dual;embedding;exhibitions;generic drugs;grayscale;image quality;ink (substance);k-means clustering;mathematical optimization;morphologic artifacts;pattern language;preparation;projections and predictions;real-time transcription;registration;video projector;visual cryptography;visual effects;message	Petar Pjanic;Anselm Grundh&#x00F6;fer	2018	IEEE Transactions on Image Processing	10.1109/TIP.2018.2824120	computer vision;artificial intelligence;projector;surface finish;scattering;mathematics;hue;reflectivity;visual cryptography;visible spectrum;communication channel	Vision	60.71326006878261	-51.70685008208906	113895
1bb0c8956c89bdebdf05cc387b1d35c251881f68	roto++: accelerating professional rotoscoping using shape manifolds	video segmentation;shape models;manifold models;rotoscoping	Rotoscoping (cutting out different characters/objects/layers in raw video footage) is a ubiquitous task in modern post-production and represents a significant investment in person-hours. In this work, we study the particular task of professional rotoscoping for high-end, live action movies and propose a new framework that works with roto-artists to accelerate the workflow and improve their productivity. Working with the existing keyframing paradigm, our first contribution is the development of a shape model that is updated as artists add successive keyframes. This model is used to improve the output of traditional interpolation and tracking techniques, reducing the number of keyframes that need to be specified by the artist. Our second contribution is to use the same shape model to provide a new interactive tool that allows an artist to reduce the time spent editing each keyframe. The more keyframes that are edited, the better the interactive tool becomes, accelerating the process and making the artist more efficient without compromising their control. Finally, we also provide a new, professionally rotoscoped dataset that enables truly representative, real-world evaluation of rotoscoping methods. We used this dataset to perform a number of experiments, including an expert study with professional roto-artists, to show, quantitatively, the advantages of our approach.	baseline (configuration management);experiment;feedback;interpolation;key frame;programming paradigm;solver;uncompressed video;usability testing	Wenbin Li;Fabio Viola;Jonathan Starck;Gabriel J. Brostow;Neill D. F. Campbell	2016	ACM Trans. Graph.	10.1145/2897824.2925973	computer vision;simulation;computer science;machine learning;mathematics;multimedia;algorithm;computer graphics (images)	Graphics	59.99461419298114	-49.14838208797734	113921
a5d5895aaf752a81722cd88adac21068cdbe11f0	a new easy camera calibration technique based on circular points	computer vision;camera calibration	A new easy technique for calibrating a camera based on circular points is proposed. The proposed technique only requires the camera to observe a newly designed planar calibration pattern (referred to as the model plane hereinafter) which includes a circle and a pencil of lines passing through the circle抯 center, at a few (at least three) different unknown orientations, then all the five intrinsic parameters can be determined linearly. The main point of the proposed technique is that it does not need know metric measurement on the model plane and the correspondences between points on the model plane and image one, hence it can be done fully automatically. The proposed technique is particularly useful for those people who are not familiar with computer vision. Experiments with simulated data as well as with real images show that the new technique is robust and accurate.	camera resectioning	Xiaoqiao Meng;Hua Li;Zhanyi Hu	2000		10.5244/C.14.50	stereo camera;computer vision;camera auto-calibration;camera matrix;camera resectioning;computer science;pinhole camera model	Vision	56.03143800822277	-49.112278746064106	113955
b9f110ff9be422fbc0c0b8068bb471c53dacfb5f	simplex and diamond hierarchies: models and applications		Hierarchical spatial decompositions are a basic modeling tool in a variety of application domains. Several papers on this subject deal with hierarchical simplicial decompositions generated through simplex bisection. Such decompositions, originally developed for finite elements, are extensively used as the basis for multiresolution models of scalar fields, such as terrains, and static or time-varying volume data. They have also been used as an alternative to quadtrees and octrees as spatial access structures and in other applications. In this state of the art report, we distinguish between approaches that focus on a specific dimension and those that apply to all dimensions. The primary distinction among all such approaches is whether they treat the simplex or clusters of simplexes, called diamonds, as the modeling primitive. This leads to two classes of data structures and to different query approaches. We present the hierarchical models in a dimension–independent manner, and organize the description of the various applications, primarily interactive terrain rendering and isosurface extraction, according to the dimension of	application domain;bayesian network;data structure;finite element method;information extraction;isosurface;octree;quadtree;terrain rendering	Kenneth Weiss;Leila De Floriani	2010		10.2312/egst.20101064	computer vision;combinatorics;discrete mathematics;topology;computer science;theoretical computer science;mathematics;geometry;algorithm;computer graphics (images)	Visualization	64.65361190714283	-42.87385713525186	114167
f2c35e8b4d09009e40923924fc0e23d8e0e079db	content-aware model resizing based on surface deformation	feature preserving;scaling;deformation;surface deformation;feature preservation;resizing;3d meshes	Model resizing is a common operation when we adapt available models to suit different surrounding scenes. Uniform scaling is not ideal in such scenario, since it will result in loss of features and unwanted distortions. In this work, we propose a novel method for content-aware mesh resizing. Unlike uniform scaling, significant features can be well preserved after scaling. Compared with the seminal work by Kraevoy et al., our method does not need an auxiliary regular grid, and directly deforms the mesh models according to local sensitivity to geometric scaling. The method is efficient, easy-to-implement and produces reasonable scaling results.		Kun-Peng Wang;Cai-Ming Zhang	2009	Computers & Graphics	10.1016/j.cag.2009.03.004	mathematical optimization;resizing;scaling;computer science;artificial intelligence;mathematics;geometry;deformation	Vision	68.02342156689677	-46.126583959403916	114392
6d4c665e425605f103a21d31c313634efff78bd6	estimation of surface normal vectors based on 3d scanning from heating approach	infrared cameras;laser sources;infrared radiation;3d scanning;scanning;calibration;3d image capture;cameras	"""ABSTRACT The Scanning From Heating is a 3D scanning approach initially developed to realise 3D acquisition of transparent or specular surfaces. A laser source is used to create a local heating point. An infrared camera is used to observe the IR radiation emitted by the scene. The 2D coordinates of the heated point are computed in the 2D image of the camera. Knowing the parameters of the system (which are obtained by a previous calibration), the 3D coordinates of the point are computed using triangulation method. In th is article we will present an extension of this technique. We propose here to analyse the shape of the hot spot observed by the IR camera, and, from the analysis to determine information on the local orientation of the surface at each measured point. Keywords: 3D Digitization, 3D Scanning of spec ular surfaces, Scanning From Heating 1. INTRODUCTION 3D scanning by active triangulation is a well-known approach, which led to a significant number of commercial solutions. The main idea is to project a complex pattern on th e surface under scanning, and analyzes the deformation of this pattern in the image provided by the camera. The main objective of a non-contact 3D scanning is to provide a location in 3D space of points of the surface of an object. But the knowledge of the normal vector to the su rface is an interesting additional info rmation. The surface normal vector indeed gives information on local variations of surface orie ntation and provides a great help to improve the accuracy of the reconstruction [1] or during the steps of interpolatio n [2], filtering, shape analys is or segmentation [3]. Generally, the local orientation of the surface at an analysed point is computed using the coordinates of points that are presented in its neighborhood. But the main problem is that the relevance of the results remains linked to the configuration of sampling. We can find in the literature some approaches that are able to determine the orientation of the surface at each point. In [4] Stockman proposes to use a grid. In [5] th e authors use two patterns consisting of parallel lines, [6] an hexagonal grid, or more recently [7] the authors propose a unique pattern consisting of colored diamonds. The results are highly relevant and seem to be an interesting solution. However, like all approaches by projecti ng structured light scanning , these solutions are limited to diffuse surfaces and remain problematic for surfaces having pa rticular optical characteristics, such as specular surfaces or transparent objects. The aim of this paper is to present an extension of a 3D scanning techniques called """"Scanning From Heating (SFH) [8] for the extraction of the vector normal to the surface at each measured point. In the next section, we will explain how we propose to determine the orientation information using SFH. Results of reconstruction and interpolation will be presented in part 3. Finally we conclude and present future works."""	3d scanner;normal (geometry)	Olivier Aubreton;Gonen Eren;Youssef Bokhabrine;Alban Bajard;Frédéric Truchetet	2012		10.1117/12.908568	computer vision;calibration;infrared;telecommunications;optics;physics;quantum mechanics;remote sensing	Vision	59.0622438834297	-48.61767497060303	114535
28e2367f1003cb9bc2ceabd2665433691970f0fd	normal vector generation for sampled data using fourier filtering	digital signal processing;computer graphics;surface shading;visualization	Abstract#R##N##R##N#A three-dimensional surface is a useful graphic representation of a two-dimensional function which has been sampled on a regular grid. Shading the surface to simulate the effects of direct lighting makes visible small changes in the surface orientation, and enhances realism when the data represents a physical surface such as terrain. Shading interpolation calculations and surface patch generation techniques require the specification of a surface normal vector (or related slope information) at each sample point. These normal vectors are usually generated by averaging local data such as the normal vectors of the surfaces of a triangular mesh connecting the points. This paper describes a technique which uses Fourier filtering to generate normal vectors for two-dimensional sampled data. Images and analysis of frequency spectra are included to show how this technique preserves detail which is lost using the averaging method. Performance figures show that this enhancement of detail in the final image can be achieved for only a small increase in computation time.	normal (geometry)	Michael E. Goss;Ivor P. Page	1993	Journal of Visualization and Computer Animation	10.1002/vis.4340040106	computer vision;visualization;computer science;theoretical computer science;digital signal processing;mathematics;computer graphics;computer graphics (images)	Visualization	66.03946089544814	-49.817208787284834	114593
1b52041848edc46e4d05e707ee59a7c7ab649eb5	plate refractive camera model and its applications	causticity optics;distortion;refraction;cameras;imaging systems	In real applications, a pinhole camera capturing objects through a planar parallel transparent plate is frequently employed. Due to the refractive effects of the plate, such an imaging system does not comply with the conventional pinhole camera model. Although the system is ubiquitous, it has not been thoroughly studied. This paper aims at presenting a simple virtual camera model, called a plate refractive camera model, which has a form similar to a pinhole camera model and can efficiently model refractions through a plate. The key idea is to employ a pixel-wise viewpoint concept to encode the refraction effects into a pixel-wise pinhole camera model. The proposed camera model realizes an efficient forward projection computation method and has some advantages in applications. First, the model can help to compute the caustic surface to represent the changes of the camera viewpoints. Second, the model has strengths in analyzing and rectifying the image caustic distortion caused by the plate refraction effects. Third, the model can be used to calibrate the camera’s intrinsic parameters without removing the plate. Last but not least, the model contributes to putting forward the plate refractive triangulation methods in order to solve the plate refractive triangulation problem easily in multiviews. We verify our theory in both synthetic and real experiments.		Longxiang Huang;Xu Zhao;Shen Cai;Yuncai Liu	2017	J. Electronic Imaging	10.1117/1.JEI.26.2.023020	computer vision;refraction;distortion;telecommunications;computer science;optics	Vision	59.175604799384814	-51.82642385782823	114649
33a02fca48ceacf7d420c6f98de2d34af9a76ce9	visual simulation of texture/non-texture image synthesis	algebraic approach;fractals;texture synthesis;computational geometry image texture digital simulation fractals graph grammars;pattern generation;computational geometry;visual simulation;image texture;image synthesis;construct validity;image generation;graph grammar;graph products;double pushout construction;graph grammars;l system;graph productions;pattern generation visual simulation texture image synthesis nontexture image synthesis image modeling fractals algebraic approach graph grammars double pushout experimental results graph production;simulation tool;image modeling;digital simulation	We propose a new and effective image modeling dual technique which is capable of simulating both texture image synthesis and non-texture images like fractals. The technique uses the algebraic approach of graph grammars theory as a new simulation tool for both texture and non-texture image synthesis via its graph production, derivation and double-pushout construction. Validation of our approach is given by discussion and an illustration of some experimental results. An investigation of the relationships between the generated patterns and their corresponding graph grammars is also discussed.	augmented reality;simulation	Hussein Karam;Aboul Ella Hassanien;Masayuki Nakajima	2000		10.1109/CGI.2000.852351	image texture;computer vision;combinatorics;discrete mathematics;fractal;computational geometry;computer science;theoretical computer science;construct validity;l-system;mathematics;geometry;texture synthesis	EDA	65.8517565562526	-42.55351750665614	114805
191d2b150301fa3808cc7b2b05497a88129a77e2	3d reconstruction using labeled image regions	categories and subject descriptors according to acm ccs i 2 10 artificial intelligence vision and scene understanding modeling and recovery of physical attributes;monograph or book;3d model;i 3 3 computer graphics picture image generation display algorithms;3d scene reconstruction;reconstruction algorithm;3d reconstruction	In this paper we present a novel algorithm for reconstructing 3D scenes from a set of images. The user defines a set of polygonal regions with corresponding labels in each image using familiar 2D photo-editing tools. Our reconstruction algorithm computes the 3D model with maximum volume that is consistent with the set of regions in the input images. The algorithm is fast, uses only 2D intersection operations, and directly computes a polygonal model. We implemented a user-assisted system for 3D scene reconstruction and show results on scenes that are difficult or impossible to reconstruct with other methods.	3d computer graphics;3d modeling;3d reconstruction;algorithm;cell (microprocessor);computer vision;correctness (computer science);polygon mesh;reconstruction conjecture	Remo Ziegler;Wojciech Matusik;Hanspeter Pfister;Leonard McMillan	2003		10.2312/SGP/SGP03/248-259	3d reconstruction;computer vision;computer science;artificial intelligence;machine learning;computer graphics (images)	Graphics	66.79636827199731	-49.35772762495496	114875
2ee25bbbbecd349186aafe63c35f2442d6ba7142	removing the artifacts from artwork cross-section images	painting materials image restoration image segmentation art scanning electron microscopy;painting;art;cultural heritage image processing image enhancement;image segmentation;image processing;scanning electron microscopy;cultural heritage;image restoration;materials;image enhancement;image processing methods;cross section;infrared;user interaction	In this paper we propose a method for automatic removal of artifacts from artwork cross-section images. Cross-section images of minute samples are acquired during the painting material research of an artwork before actual conservation is performed. Such images are unfortunately damaged by the artifacts from grinding of the resin in which the sample is embedded. Removing those artifacts can improve the outcome of image segmentation and other image processing methods. The proposed algorithm can also simplify an analysis of un-derdrawings by reducing the canvas structure after infrared acquisition. Despite the idea is not entirely original, the application to cultural heritage data is novel and the implementation does not require user interaction.	algorithm;embedded system;human–computer interaction;image processing;image segmentation;resin	Miroslav Benes;Barbara Zitová;Jan Blažek;Janka Hradilová;David Hradil	2011	2011 18th IEEE International Conference on Image Processing	10.1109/ICIP.2011.6116478	image texture;image restoration;computer vision;infrared;image processing;painting;computer science;cultural heritage;cross section;image segmentation;image formation;digital image;computer graphics (images)	Robotics	63.20368234158825	-49.234228277784936	114879
46a6b81f91c5cb7d3dc211ab2e68349fbd6da54c	parametric 3d object representation and applications	object representation;computer graphics;level of detail control;parametric 3d object representation;3d object rendering;spline surface fitting shape surface reconstruction application software computer graphics clouds uncertainty design automation solid modeling;splines mathematics;computer graphic;b spline surface;level of detail;unstructured point cloud data;b spline surface modelling technique;image representation;3d object rendering parametric 3d object representation b spline surface modelling technique computer graphics unstructured point cloud data level of detail control;parameter space;3d representation;splines mathematics computer graphics image representation;point cloud	Despite intensive research, 3D representation is still an open research issue in computer graphics. In this paper, we propose a novel B-spline surface modelling technique. Unlike previous work, our approach deals with unstructured point cloud data. By representing objects in a common parameter space, one of the most challenging problems, i.e. automatic dense correspondence between objects, is solved with little effort. Supporting level of detail (LOD) control, our approach is particularly efficient for 3D object rendering. Furthermore, the representation is compact - over 90% compression rate is achieved. It also allows efficient 3D objects comparison and metamorphosis.	b-spline;computer graphics;level of detail;open research;point cloud	Li Bai;Yi Song	2007	Computer Graphics, Imaging and Visualisation (CGIV 2007)	10.1109/CGIV.2007.20	computer vision;computer science;theoretical computer science;function representation;computer graphics (images)	Graphics	66.73592246866681	-45.288209836887184	114909
5a53fc4fa4fff81e6d3306e2511a3ba05a49f080	post-production facial performance relighting using reflectance transfer	real time;potential difference;interactive lighting design;reflectance transfer;image based relighting	We propose a novel post-production facial performance relighting system for human actors. Our system uses just a dataset of view-dependent facial appearances with a neutral expression, captured for a static subject using a Light Stage apparatus. For the actual performance, however, a potentially different actor is captured under known, but static, illumination. During post-production, the reflectance field of the reference dataset actor is transferred onto the dynamic performance, enabling image-based relighting of the entire sequence. Our approach makes post-production relighting more practical and could easily be incorporated in a traditional production pipeline since it does not require additional hardware during principal photography. Additionally, we show that our system is suitable for real-time post-production illumination editing.		Pieter Peers;Naoki Tamura;Wojciech Matusik;Paul E. Debevec	2007	ACM Trans. Graph.	10.1145/1276377.1276442	computer vision;real-time computing;voltage;computer science;multimedia;computer graphics (images)	Graphics	59.28607448810336	-49.618783428216545	114954
92255a4a1bcc7c94135139681e0837ea9429d833	distortion measure of trilinear mapping. application to 3-d grid generation	grid generation;grid untangling;shape recovery;trilinear mapping;distortion measures;hexahedral grid generation		distortion;mesh generation	L. V. Branets;Vladimir A. Garanzha	2002	Numerical Lin. Alg. with Applic.	10.1002/nla.302	mesh generation;mathematical optimization;topology;mathematics	HPC	67.06834246214538	-43.5227625088709	115031
a30fbdcf8cf49552c0a358a61a4906a9cee781dc	marching cubes: a high resolution 3d surface construction algorithm	high resolution;computed tomography;surface reconstruction;information presentation;computer graphic;medical image;magnetic resonance;linear interpolation;surface model;solid modeling;single photon emission computed tomography;marching cube;divide and conquer	We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.	algorithm;ct scan;database normalization;gradient descent;image resolution;linear interpolation;marching cubes;olap cube;resonance;scan line;shading;solid modeling;tomography	William E. Lorensen;Harvey E. Cline	1987		10.1145/37401.37422	computer vision;divide and conquer algorithms;marching tetrahedra;image resolution;surface reconstruction;marching squares;computer science;isosurface;magnetic resonance imaging;point cloud;mathematics;geometry;marching cubes;solid modeling;computed tomography;linear interpolation;computer graphics (images)	Graphics	67.52836391408563	-44.62748796896232	115412
0b00040f6e7d7314f99a55e7683a2cc35be843a5	3d reconstruction and virtual forming in rotationally symmetric space	augmented reality;image reconstruction;pottery;stereo image processing;3d object reconstruction;augmented reality images;rotationally symmetric space;virtual clay;virtual forming;virtual pottery	For reconstructing 3D objects and for generating arbitrary views of the scene, accurate calibration of multiple cameras is very important. We introduce rotationally symmetric space, and show that in rotationally symmetric space, cameras can be calibrated and 3D points can be reconstructed just from a single basis line reliably. The proposed method is applied for deforming virtual clay in rotationally symmetric space and for generating augmented reality images of virtual pottery.	3d reconstruction;augmented reality;virtual reality	Masaya Taki;Jun Sato	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1334155	3d reconstruction;iterative reconstruction;pottery;computer vision;augmented reality;computer science;mathematics;symmetric space;geometry;computer graphics (images)	Visualization	57.35739115263547	-49.85956754229096	115436
88da7accbb3c582ad722ed2b47596310888728f1	scanning and animating characters dressed in multiple-layer garments		Despite the development of user-friendly interfaces for modeling garments and putting them onto characters, preparing a character dressed in multiple layers of garments can be very time-consuming and tedious. In this paper, we propose a novel scanning-based solution for modeling and animating characters wearing multiple layers of clothes. This is achieved by making use of real clothes and human bodies. We first scan the naked body of a subject by an RGBD camera, and a statistical body model is fit to the scanned data. This results in a skinned articulated model of the subject. The subject is then asked to put on one piece of garment after another, and the articulated body model dressed up to the previous step is fit to the newly scanned data. The new garment is segmented in a semi-automatic fashion and added as an additional layer to the multi-layer garment model. During runtime, the skinned character is controlled based on the motion capture data and the multi-layer garment model is controlled by blending the movements computed by physical simulation and linear blend skinning, such that the cloth preserves its shape while it shows realistic physical motion. We present results where the character is wearing multiple layers of garments including a shirt, coat and a skirt. Our framework can be useful for preparing and animating dressed characters for computer games and films.		Pengpeng Hu;Taku Komura;Daniel Holden;Yueqi Zhong	2017	The Visual Computer	10.1007/s00371-017-1388-3	simulation;computer graphics (images)	Graphics	61.82697803343052	-49.863268478712264	115456
3030c0221fc3927b4e2c727bdac58082744fce12	online automatic measurement of deflection for automobile based on digital image	photogrammetry;image processing;camera calibration deflection for automobile image measuring photogrammetry;spatial variables measurement;measurement systems;automatic optical inspection;automatic test equipment;ccd image sensors;cameras automobiles digital images roads calibration computers;vehicle dynamics automatic optical inspection automatic test equipment automobile industry ccd image sensors computerised instrumentation image processing measurement systems photogrammetry road safety spatial variables measurement;computerised instrumentation;vehicle offset measurement online automatic deflection measurement road vehicles traffic safety big deflection avoidance limit offset product lines automobile companies digital image system high precision deflection measurement ccd imaging system image processing algorithm photogrammetry processing algorithm deflection measurement system;road safety;vehicle dynamics;automobile industry	It is an essential requirement to keep vehicles running along straight line on road for automobiles and it is also a key guarantee for traffic safety. However, because of certain errors during manufacture and assembly for automobile, there are some vehicles with big deflection lean to certain direction while running on flat road. To avoid vehicles with big deflection exceeding the limit offset coming down from product lines and selling to customers, automobile companies must pay a great attention to measurement of deflection for vehicles. In this paper, the development of a digital image system for the automatic measurement of deflection for automobile is reported. Such system facilitates automatic, efficient, robust and high precision measuring of deflection for vehicles. The digital image approach is described fully, with emphasis upon dedicated CCD imaging system, the image processing algorithms and the photogrammetry processing algorithms. Finally, the results of experimental testing of deflection measuring system in practical automobile company are presented. From analysis of the system and results, we can see that such digital image processing technique is available for measuring the offset of vehicles and such digital image system have the advantages of high accuracy, automatization, high efficiency and robustness.	algorithm;charge-coupled device;digital image processing;photogrammetry	Changjun Chen;Gang Wang;Yong Liu;Yaohua He	2013	Proceedings of 2013 IEEE International Conference on Vehicular Electronics and Safety	10.1109/ICVES.2013.6619600	embedded system;computer vision;simulation;engineering	Robotics	59.9539014288047	-39.93458427417136	115466
8d756aabd3b02cabba0d6ade506acd3122effed5	the hand as a shading probe	homeland security;aerosol contaminants;biomedical and genomic	To render computer graphics (CG) objects realistically in the real world, it is important to match their shadings to the scene. Existing methods to achieve such realism are not applicable to realtime consumer augmented reality (AR). Debevec's method requires a mirrored sphere, which ordinary consumers do not have [Debevec 1998]. Karsh's method requires user annotation, which makes it difficult to use in a realtime application [Karsch et al. 2011].	augmented reality;cel shading;computer graphics	Yasuhiro Yao;Harumi Kawamura;Akira Kojima	2013		10.1145/2503385.2503503	homeland security;computer vision;simulation;computer science;artificial intelligence;operating system;computer graphics (images)	Graphics	62.92713767655585	-50.957701219498624	115474
a80a0dd8da412cc0eba428e77d4deb68af6a83fb	a spectral reflectance measuring system which corrects for lateral diffusion error & effects of adjacent surface colors	spectral reflectance;measurement system		color;lateral thinking	David L. Spooner	2002			artificial intelligence;computer vision;computer science;lateral diffusion;reflectivity;optics	Vision	59.77348628828325	-42.87008081416917	115546
7dca97ab3bd86c60205fc75c87330d715fbe21e0	using photometric stereo to refine the geometry of a 3d surface model	photometric stereo;surface model	In this paper we aim at refining the geometry of 3D models of real objects by adding surface bumpiness to them. 3D scanners are usually not accurate enough to measure fine details, such as surface roughness. Photometric stereo is an appropriate technique to recover bumpiness. We use a number of images taken from the same viewpoint under varying illumination and an initial sparse 3D mesh obtained by a 3D scanner. We assume the surface to be Lambertian, but the lighting properties are unknown. The novelty of our method is that the initial sparse 3D mesh is exploited to calibrate light sources and then to recover surface normals. The importance of refining the geometry of a bumpy surface is demonstrated by applying the method to synthetic	3d modeling;3d scanner;lambertian reflectance;normal (geometry);photometric stereo;sparse matrix;synthetic intelligence	Zsolt Jankó	2007			computer vision;photometric stereo;computer science	Vision	58.217076002488135	-51.746265198496026	115610
642ae2218e292037c2b581c24c4407157a88b72c	first-person palm pose tracking and gesture recognition in augmented reality		We present an Augmented Reality solution to allow users to manipulate and inspect 3D virtual objects freely with their bare hands on wearable devices. To this end, we use a head-mounted depth camera to capture the RGB-D hand images from egocentric view, and propose a unified framework to jointly recover the 6D palm pose and recognize the hand gesture from the depth images. The random forest is utilized to regress for the palm pose and classify the hand gesture simultaneously via a spatial-voting framework. With a real-world annotated training dataset, the proposed method shows to predict the palm pose and gesture accurately. The output of the forest is used to render the 3D virtual objects, which are overlaid onto the hand region in input RGB images with camera calibration parameters to provide seamless virtual and real scene synthesis.	augmented reality;gesture recognition	Daniel Thalmann;Hui Liang;Junsong Yuan	2015		10.1007/978-3-319-29971-6_1	computer vision	Vision	54.78606533841237	-46.57902023480411	115630
72cfe20874a33bf19a448fa45dcd59a04708044b	real-time rendering of realistic-looking grass	grass;light transport;btf;bidirectional texture function;global illumination;computational complexity;interactive rendering;depth map;real time application;real time rendering	The absence of accurately rendered grass in real-time applications such as games and simulation systems can be directly attributed to the massive amounts of geometry required to model grass patches. This in turn is responsible for the drastic increase in the computational complexity of light transport for global illumination. Our work attempts to fill the void by presenting an image-based algorithm for interactive rendering of realistic-looking grass. A bidirectional texture function (BTF) is constructed and employed in combination with a view-dependent depth map to synthesize a grass texture for given viewing and illumination conditions. In addition to the visual effects captured by BTFs, our method is able to produce grass silhouettes as well as account for external occluders such as rocks and other objects scattered over a grass field.	algorithm;bidirectional texture function;computational complexity theory;depth map;global illumination;illumination (image);real-time locating system;real-time transcription;rendering (computer graphics);simulation;the void (virtual reality);visual effects	Musawir A. Shah;Jaakko Kontinnen;Sumanta N. Pattanaik	2005		10.1145/1101389.1101403	bidirectional texture function;computer vision;simulation;computer science;real-time rendering;computational complexity theory;global illumination;depth map;computer graphics (images)	Graphics	64.24829780887934	-51.1161943732816	115751
ff0a09f9474d0cdd7cbd8c0e615e7d8562412e03	potential benefits of combining anomaly detection with view planning for uav infrastructure modeling	uav;intrusion detection;view planning;infrastructure monitoring;structure from motion	This paper presents a novel method for UAV-based 3D modeling of large infrastructure objects, such as pipelines, canals and levees, that combines anomaly detection with automatic on-board 3D view planning. The study begins by assuming that anomaly detections are possible and focuses on quantifying the potential benefits of the combined method and the view planning algorithm. A simulated canal environment is constructed, and several simulated anomalies are created and marked. The algorithm is used to plan inspection flights for the anomaly locations, and simulated images from the flights are rendered and processed to construct 3D models of the locations of interest. The new flights are compared to traditional flights in terms of flight time, data collected and 3D model accuracy. When compared to a low speed, low elevation traditional flight, the proposed method is shown in simulation to decrease total flight time by up to 55%, while reducing the amount of image data to be processed by 89% and maintaining 3D model accuracy at areas of interest.		R. Abraham Martin;Landen Blackburn;Joshua Pulsipher;Kevin Franke;John D. Hedengren	2017	Remote Sensing	10.3390/rs9050434	intrusion detection system;computer vision;structure from motion;simulation;remote sensing	Robotics	58.548270541920786	-44.388247756475046	116001
48ad5874462750ce0002fabcd4288f9aa2a59410	viewpoint-driven simplification using mutual information	simplification;model generation;viewpoint selection;video game;info eu repo semantics article;level of detail;polygonal meshes;mutual information;information theoretic	In this paper, a new viewpoint-based simplification approach is proposed for polygonal meshes. This approach is driven by an information-theoretic measure, viewpoint mutual information. Our algorithm applies the best half-edge collapse as a decimation criterion and uses the variation in mutual information to measure the collapse error. Compared to purely geometric simplification algorithms, the models produced by our method are closer to the original model as far as visual similarity is concerned. Our method also achieves a higher simplification in hidden interiors by being able to remove them leaving the visible surfaces of the mesh intact. Models generated by CAD applications can benefit from this feature, since these models are usually constructed by assembling smaller objects that can become partially hidden during joining operations. The main application of our approach is for video games where models come from CAD applications in which visual similarity is the most important requirement.	level of detail;mutual information;viewpoint	Pascual Castelló;Mateu Sbert;Miguel Chover;Miquel Feixas	2008	Computers & Graphics	10.1016/j.cag.2008.05.005	computer vision;simulation;computer science;artificial intelligence;theoretical computer science;level of detail;mathematics;geometry;mutual information;simplification;algorithm;statistics;computer graphics (images)	Robotics	66.82829447761614	-44.58981313576579	116370
055f3728e568224cb17032db92c2c3d1d9ac999c	voronoi diagram depth sorting for polygon visibility ordering	depth sorting;transparency rendering;computer graphic;visual inspection;visibility determination;voronoi diagram	Visibility determination is one of the oldest problems in computer graphics. The visibility, in terms of back-to-front polygon visibility ordering, can be determined by updating a priority list as the viewpoint moves. A new list-priority algorithm, utilizing a property of Voronoi diagrams, is proposed in this paper. In the preprocessing phase, the 3D space is divided into Voronoi cells in order to cluster polygons that can be assigned a fixed set of priority orders within the cluster. and during the post-processing phase, the clusters and contained polygons are depth-sorted correctly. The most time-consuming work is undertaken during the pre-processing phase that only has to be executed once for the scene. All the polygons in a cluster are pre-computed to obtain the view independent priority order within the cluster. Thus, a relatively simple task is left in the post-processing phase, which is only to sort the clusters repeatedly when the viewpoint is changed. One reason to explore list-priority algorithm is because they offer flexibility that hardware configuration (such as Z-buffer approach) do not possess. One example is that of rendering with the correct treatment of the translucency effects. Translucency is an important graphics effect that can be used to increase the realism of the rendered scene or to enable more effective visual inspection in visualization.	algorithm;computer graphics;hidden surface determination;precomputation;preprocessor;sorting;video post-processing;visual inspection;voronoi diagram;z-buffering	Shinichi Fukushige;Hiromasa Suzuki	2006		10.1145/1174429.1174506	computer vision;voronoi diagram;visibility polygon;computer science;painter's algorithm;polygon;z-buffering;geometry;computer graphics (images);visual inspection	Graphics	66.72074297721481	-49.849272371234825	116489
02538f22ed29232967e772e3b9adaf405b7452b1	controlled-distortion constrained global parametrization	parametrization;geometric modeling	The quality of a global parametrization is determined by a number of factors, including amount of distortion, number of singularities (cones), and alignment with features and boundaries. Placement of cones plays a decisive role in determining the overall distortion of the parametrization; at the same time, feature and boundary alignment also affect the cone placement. A number of methods were proposed for automatic choice of cone positions, either based on singularities of cross-fields and emphasizing alignment, or based on distortion optimization.  In this paper we describe a method for placing cones for seamless global parametrizations with alignment constraints. We use a close relation between variation-minimizing cross-fields and related 1-forms and conformal maps, and demonstrate how it leads to a constrained optimization problem formulation. We show for boundary-aligned parametrizations metric distortion may be reduced by cone chains, sometimes to an arbitrarily small value, and the trade-off between the distortion and the number of cones can be controlled by a regularization term. Constrained parametrizations computed using our method have significantly lower distortion compared to the state-of-the art field-based method, yet maintain feature and boundary alignment. In the most extreme cases, parametrization collapse due to alignment constraints is eliminated.	constrained optimization;constraint (mathematics);distortion;map;mathematical optimization;optimization problem;seamless3d	Ashish Myles;Denis Zorin	2013	ACM Trans. Graph.	10.1145/2461912.2461970	parametrization;mathematical optimization;topology;computer science;geometric modeling;mathematics;geometry	Graphics	67.92826697965599	-43.519525591389424	116498
96a5b561d411268c89c2ee7f907a530261ff5a9d	shape from shading by model inclusive learning method with simultaneous estimation of parameters		The problem of recovering shape from shading is important in computer vision and robotics. It is essentially an ill-posed problem and several studies have been done. In this paper, we present a versatile method of solving the problem by neural networks. The proposed method introduces the concept of the model inclusive learning with simultaneous estimation of unknown parameters. In the method a mathematical model, which we call ‘image-formation model’, expressing the process that the image is formed from an object surface, is introduced and is included in the learning loop of a neural network. The neural network is trained so as to recover the shape with simultaneously estimating unknown parameters in the image-formation model. The performance of the proposed method is demonstrated through experiments.	photometric stereo;shading	Yasuaki Kuroe;Hajimu Kawakami	2017		10.1007/978-3-319-68612-7_20	machine learning;artificial intelligence;photometric stereo;artificial neural network;estimation theory;computer science;robotics	Vision	56.54257736059643	-51.9490554912123	116870
4c6cf31769ec101cbef2bb985dec0d46428b484f	do-it-yourself single camera 3d pointer input device		We present a new algorithm for single camera 3D reconstruction, or 3D input for human-computer interfaces, based on precise tracking of an elongated object, such as a pen, having a pattern of colored bands. To configure the system, the user provides no more than one labelled image of a handmade pointer, measurements of its colored bands, and the camera's pinhole projection matrix. Other systems are of much higher cost and complexity, requiring combinations of multiple cameras, stereocameras, and pointers with sensors and lights. Instead of relying on information from multiple devices, we examine our single view more closely, integrating geometric and appearance constraints to robustly track the pointer in the presence of occlusion and distractor objects. By probing objects of known geometry with the pointer, we demonstrate acceptable accuracy of 3D localization.		Bernard Llanos;Yee-Hong Yang	2018	2018 15th Conference on Computer and Robot Vision (CRV)	10.1109/CRV.2018.00038	computer science;computer vision;3d reconstruction;pointer (computer programming);artificial intelligence;input device;colored;feature extraction;colors of noise;projection (linear algebra)	Vision	56.43764731200851	-47.46450167539383	117039
53ca22c9f4712ef5264aabe6f4b5dd31736fa5cb	an interactive facial animation system	facial animation	In this paper an interactive facial animation system is described The system is built on top of the facial animation system developed by Keith Waters which uses a muscle based face model We built an interactive facial animation system on top of it to produce keyframe animations of a synthetic face model The user creates keyframes interactively by either giving prede ned universal expressions to the face or a meaningful combination of these expressions blended naturally on the face model or giving expressions to the face by moving the muscle vectors de ned on the face model The user might also change the orientation of the face for a keyframe by rotating it in x and y directions To create intermediate frames we use cosine interpolation	interactivity;keith waters;key frame;synthetic data;whittaker–shannon interpolation formula	Fatih Erol;Ugur Güdükbay	2001			computer facial animation;computer graphics (images);computer animation;interpolation;facial motion capture;artificial intelligence;computer vision;computer science;expression (mathematics)	Graphics	64.73608204957182	-46.144942543301504	117059
0a40c168d1a0cd3a7388aba242e39a1672a9e75e	introducing the cut-out star target to evaluate the resolution performance of 3d structured-light systems	projection systems;cameras	Structured light depth map systems are a type of 3D system where a structured light pattern is projected into the object space and an adjacent receiving camera is used to capture the image of the scene. By using the distance between the camera and the projector together with the structured pattern you can estimate the depth of objects in the scene from the camera. It is important to be able to compare two systems to see how one compares to another. Accuracy, resolution, and speed are three aspects of a structured light system that are often used for performance evaluation. It would be ideal if we could use the accuracy and resolution measurements to answer questions such as how close two cubes can be together and be resolved as two objects. Or, determine how close a person must be to the structured light system in order to determine how many fingers this person is holding up. It turns out, from our experiments, a systems ability to resolve the shape of an object is dependent on a number of factors such as the shape of an object, its orientation and how close it is to other adjacent objects. This makes the task of comparing the resolution of two systems difficult. Our goal is to choose a target or a set of targets from which we make measurements that will enable us to quantify, on the average, the comparative resolution performance of one system to another without having to make multiple measurements on scenes with a large set of object shapes, orientations and proximities to each other. In this document we will go over a number of targets we evaluated and will focus on the “Cut-out Star Target” that we selected as being the best choice. Using this target we will show our evaluation results of two systems. The metrics we used for the evaluation were developed during this work. These metrics will not directly answers the question of how close two objects can be to each other and still be resolve, but it will indicate which system will perform better over a large set of objects, orientations and proximities to other objects. © (2013) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	structured light	Tom Osborne;Vikas Ramachandra;Kalin Atanassov;Sergio Goma	2013		10.1117/12.2008560	computer vision;simulation;optics;physics	HPC	55.97502235592023	-47.62686434176154	117095
3e881e9eec48a4dc4d939813e676afd0ba492171	the jal triangulation: an adaptive triangulation in any dimension	adaptive meshing;adaptive mesh;adaptive refinement;euclidean space;triangulation;sampling methods;cell decomposition;spatial sampling	Spatial sampling methods have acquired great popularity due to the number of applications that need to triangulate portions of space in various dimensions. One limitation of the current techniques is the handling of the final models, which are large, complex and need to register neighborhood relationships explicitly. Additionally, most techniques are limited to Euclidean bidimensional or tridimensional spaces and many do not handle well adaptive refinement. This work presents a novel method for spatial decomposition based on simplicial meshes (the J 1 triangulation) that is generally defined for Euclidean spaces of any dimension and is intrinsically adaptive. Additionally it offers algebraic mechanisms for the decomposition itself and for definition of neighbrs that allow to recover all the information on the resulting mesh via a set of rules. This way it is possible to balance the cost of storage and manipulation by calculating the needed information instead of storing it. Results additionally show good quality meshes with efficient calculation.	delaunay triangulation;refinement (computing);sampling (signal processing)	Antônio Castelo Filho;Luis Gustavo Nonato;Marcelo Siqueira;Rosane Minghim;Geovan Tavares	2006	Computers & Graphics	10.1016/j.cag.2006.07.025	sampling;combinatorics;discrete mathematics;delaunay triangulation;triangulation;euclidean space;mathematics;geometry	Vision	67.95868003470879	-49.13865814867552	117187
57d55f4ab1c4d5071ae0e8241390bc13d692210e	curvature-based stroke rendering	edge enhancement;line rendering;edge detection;npr;line stylization;curvature;stroke	This paper describes an algorithm that renders lines that have various thicknesses and have sharp tapered ends. This algorithm does not require any special information on each local point of a line. The thickness is determined by curvature and lengths from both ends. Therefore the algorithm is applicable in a variety of line rendering situations, such as 3D rendering engines for high quality cel-animation-like effects, reuse of geometrical data designed by CAD for advertising purposes, edge enhancement in a photo retouching process with edge detection methods and so on. In addition, using the generated varying thicknesses, we have developed algorithms for shading and embossing effects.	3d rendering;algorithm;computer-aided design;display resolution;edge detection;edge enhancement;image embossing;rendering (computer graphics);shading;thickness (graph theory);web browser engine	Suguru Saito;Akane Kani;Youngha Chang;Masayuki Nakajima	2007	The Visual Computer	10.1007/s00371-007-0165-0	computer vision;edge detection;stroke;computer science;edge enhancement;curvature;computer graphics (images)	Graphics	64.65777500036877	-48.1996518352087	117356
edf6e7754287c3e0021ef04666b9dca3ca97dfa2	hardware accelerated soft shadows using penumbra quads	shadow mapping;real time;dynamic geometry;hardware accelerator;dynamic environment;shadow algorithm;graphics hardware;soft shadow;programmable graphics hardware	Shadow mapping is a commonly used technique for generating hard shadows in real time. However, existing shadow map based algorithms cannot render full soft shadows penumbras onto arbitrary dynamic geometry by utilizing only consumer level programmable graphics hardware. In this paper we introduce a new fully hardware accelerated penumbra map algorithm which stores additional penumbra information into separate penumbra maps. The method is capable of generating approximate soft shadows on both sides of the hard shadow boundaries at real time frame rates. The shadow generation requires neither graphics hardware read backs nor processing with the CPU while it is able to handle arbitrary shadow receivers and dynamic environments. The algorithm also has a straightforward implementation on programmable graphics hardware.	approximation algorithm;central processing unit;graphics hardware;list of interactive geometry software;map;shadow mapping	Jukka Arvo;Jan Westerholm	2004			real-time computing;hardware acceleration;computer hardware;computer science;shadow mapping;shadow volume;graphics hardware;computer graphics (images)	Graphics	66.2389199572823	-51.19531191021889	117403
34fdba1e77c28ade842a6be6e5c265d15534bc8e	a comparative study of stereo, vergence, and focus as depth cues for active vision	focusing;uncertainty focusing layout surface fitting machine vision calibration image analysis educational institutions quantization estimation error;quantization;distance measurement stereo image processing;uncertainty;depth cues;surface fitting;layout;systematic calibration errors;performance characterization;distance measurement;vergence;focus;machine vision;stereo image processing;stereo vision;random quantization errors;error sensitivity;range estimation;image analysis;systematic calibration errors stereo vision error sensitivity performance characterization vergence focus depth cues active vision range estimation random quantization errors standard derivation;estimation error;standard derivation;calibration;quantization error;active control;active vision	The performances of the binocular cues of stereo, vergence, and the monocular cue of focus for range estimation using an active vision system are compared. The performance of each cue is characterized by its sensitivity to errors in the imaging parameters. The effect of random quantization errors is expressed in terms of the standard derivation of the resulting depth error. The effect of systematic calibration errors on estimation using each cue is studied. Performance characterization of each cue is shown to be useful for active control of the imaging parameters to improve the accuracy of the estimated range. Methods to integrate the use of the cues in order to overcome their individual limitations are discussed. >	active vision;depth perception;vergence	Subhodev Das;Narendra Ahuja	1993		10.1109/CVPR.1993.340989	computer vision;image analysis;simulation;quantization;machine vision;computer science	Vision	57.62414233759478	-43.440671981783815	117427
d6e33102e289d0de763fb3d266df18b653f6472d	visual target tracking in clay pigeon shooting sports: estimation of flight parameters and throwing range	unbemannte luftfahrzeuge	This paper presents a method to estimate the trajectory and the flight distance of thrown pigeon clays. The basic principle is to measure the beginning of the flight with a camera system in order to forecast the further flight down to the ground impact. The demand of such advanced measuring methods arises from sporting clays competition regulations, where the launching machines have to be adjusted towards specific throwing angles and ranges. The presented method uses a wide-baseline stereo camera system (32 m camera distance) to measure the 3D clay disc positions, and the flight parameters are then identified by aerodynamic and kinematic considerations. This allows to estimate the whole path and the throwing distance, especially without a need to measure the ground impact itself. Applying this method to sporting clays facilities, the launching machines can be adjusted easier and more precisely, being advantageous especially for competitions. Additionally, it becomes possible to obtain the theoretical throwing distance on small sports areas bounded by nets or walls where a ground impact is not measurable.	baseline (configuration management);camera resectioning;extrapolation;goto;integrated circuit layout design protection;mathematical optimization;removable media;requirement;stereo camera;tourist guy	Franz Andert;Simon Freudenthal;Stefan Levedag	2016		10.5220/0005674602950302	simulation;computer science;computer graphics (images)	Robotics	57.226984235362025	-39.09013014907054	117478
176346e7325ef01dde5047aeb3c1f6e711c9dadf	a multi-view stereo benchmark with high-resolution images and multi-camera videos		Motivated by the limitations of existing multi-view stereo benchmarks, we present a novel dataset for this task. Towards this goal, we recorded a variety of indoor and outdoor scenes using a high-precision laser scanner and captured both high-resolution DSLR imagery as well as synchronized low-resolution stereo videos with varying fields-of-view. To align the images with the laser scans, we propose a robust technique which minimizes photometric errors conditioned on the geometry. In contrast to previous datasets, our benchmark provides novel challenges and covers a diverse set of viewpoints and scene types, ranging from natural scenes to man-made indoor and outdoor environments. Furthermore, we provide data at significantly higher temporal and spatial resolution. Our benchmark is the first to cover the important use case of hand-held mobile devices while also providing high-resolution DSLR camera images. We make our datasets and an online evaluation server available at http://www.eth3d.net.	algorithm;align (company);benchmark (computing);digital single-lens reflex camera;image resolution;image scanner;mobile device;overfitting;sampling (signal processing);server (computing);tango	Thomas Schöps;Johannes L. Schönberger;Silvano Galliani;Torsten Sattler;Konrad Schindler;Marc Pollefeys;Andreas Geiger	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2017.272	computer vision;artificial intelligence;computer science;computer graphics (images);laser scanning;benchmark (computing);ranging;mobile device;image resolution	Vision	54.55330460841831	-45.0643011335455	117509
b16ebf548269cd0df49214b304141f4494721f16	new results in signal processing and compression of polygon meshes	isosurface extraction;graphics application;adaptive isosurface extraction signal processing polygon mesh compression graphics application shape approximation internet access 3d model complex virtual environment electronic shopping collaborative cad multiplayer video game scientific visualization 3d shape representation mesh smoothing mesh denoising mesh editing mesh transmission mesh animation topological method combinatorial method constrained energy minimization diffusion differential equation linear anisotropic mesh filtering bilevel isosurface compression space optimized texture map volume warping;internet access;linear anisotropic mesh filtering;data compression;complex virtual environment;bilevel isosurface compression;shape approximation;video signal processing;constrained energy minimization;collaborative cad;texture mapping;collaboration;differential equation;adaptive isosurface extraction;isosurfaces;mesh transmission;video game;polygon mesh compression;scientific visualization;image texture;assembly;topological method;image texture mesh generation feature extraction internet computer animation differential equations smoothing methods image denoising data compression;smoothing methods;3d model;signal processing video signal processing shape isosurfaces graphics internet virtual environment assembly collaboration games;internet;shape;mesh animation;polygonal meshes;feature extraction;signal processing;games;mesh denoising;mesh editing;multiplayer video game;diffusion differential equation;mesh smoothing;combinatorial method;differential equations;image denoising;space optimized texture map;virtual environment;computer animation;volume warping;mesh generation;3d shape representation;electronic shopping;graphics	Polygon meshes, which are used in most graphics applications, require considerable amounts of storage, even when they only approximate precise shapes with limited accuracy. To support internet access to 3D models of complex virtual environments or assemblies for electronic shopping, collaborative CAD, multi-player video games, and scientific visualization, representations of 3D shapes must be compressed by several orders of magnitude. Furthermore, several closely related methods have been proposed in recent years to smooth, de-noise, edit, compress, transmit, and animate very large polygon meshes, based on topological and combinatorial methods, signal processing techniques, constrained energy minimization, and the solution of diffusion differential equations. This talk is an overview of some of my recent results in this area: Linear Anisotropic Mesh Filtering, Bi-Level Isosurface Compression, Space-Optimized Texture Maps, and Volume Warping for Adaptive Isosurface Extraction. Proceedings of the Shape Modeling International 2003 (SMI03) 0-7695-1909-1/03 $17.00 © 2003 IEEE	3d modeling;approximation algorithm;computer-aided design;energy minimization;graphics;image warping;internet access;isosurface;polygon mesh;scientific visualization;signal processing;virtual reality	Gabriel Taubin	2003		10.1109/SMI.2003.1199600	computer vision;static mesh;computer science;volume mesh;theoretical computer science;computer graphics (images)	Visualization	61.8146014717055	-48.83728838196477	117693
3f8641edc3a08bc77df672119384f1abc9feddf2	how symbolic computation can benefit computer-aided geometric design	bezier surface;concepcion asistida;symbolic computation;computer aided design;curva bezier;programming language;ajustamiento curva;computer graphic;calculo simbolico;surface bezier;courbe bezier;conception assistee;ajustement courbe;fortran;curve fitting;calcul symbolique;curves and surfaces;bezier curve;computer aided geometric design	Computer-Aided Geometric Design (CAGD) is one of the most important fields in Computer Graphics. Usually, CAGD is handled in traditional programming languages, such as Fortran, Pascal or C. By contrast, this paper supports the idea that Symbolic Computation Systems (SCS) should be used instead. To this aim, the paper shows how some mathematical expressions for BEzier curves and surfaces can be easily translated to the Mathematica programming language. Then, they are used to prove symbolically some mathematical properties related to these geometric entities.		Andrés Iglesias	2000		10.1007/3-540-44990-6_16	discrete mathematics;symbolic computation;computer science;bézier surface;bézier curve;mathematics;geometry;programming language;algorithm;statistics;curve fitting;algebra	EDA	67.55795830146211	-40.05262522208859	117697
832bee43abf0791c467391023d09efb1152cc998	a framework for recovering affine transforms using points, lines or image brightnesses	computational geometry;computational geometry image reconstruction image motion analysis filtering;motion estimation;filtering and prediction theory computational geometry image reconstruction brightness deformation motion estimation;filtering and prediction theory;brightness;first order;deformation;image reconstruction;affine transformation;optical flow affine transform recovery points lines image brightness image deformations relative motion 3d structure inference first order deformations deformed patches gaussian filter gaussian derivative filter deformed filter local method scale changes;optical flow;3d structure	Image deformations due to relative motion between an observer and an object may be used to infer 3-D structure. Up to rst order these deformations can be written in terms of an aane transform. Here, a new framework for measuring aane transforms which correctly handles the problem of corresponding deformed patches is presented. In this framework, points, lines or image brightnesses may be used to derive the aane transform between image patches. No correspondence is required. The patches are ltered using gaussians and derivatives of gaussians and the lters deformed according to the aane transform. The problem of nd-ing the aane transform is therefore reduced to that of nding the appropriate deformed lter to use. The method is local and can handle large aane deformations. Experiments demonstrate that this technique can nd scale changes and optical ow in situations where other methods fail.	computational anatomy;experiment	R. Manmatha	1994		10.1109/CVPR.1994.323821	iterative reconstruction;computer vision;topology;affine coordinate system;computational geometry;computer science;affine geometry of curves;motion estimation;first-order logic;optical flow;affine transformation;harris affine region detector;mathematics;geometry;affine shape adaptation;affine combination;deformation;brightness;hessian affine region detector	Vision	54.119772749003566	-52.03136280358342	117834
2267601007e80b9a53ada4270ae3b1c2797f87aa	real-time simulation of time-of-flight sensors	application development;time of flight;3d imaging;building block;real time;data processing;photonic mixing device;gpu programming;real time simulation;hardware accelerator;motion blur;sensor simulation;interactive simulation;graphic processing unit;hardware design;high performance;real time application	Today’s time-of-flight (TOF) sensors measure full-range distance information by estimating the elapsed time between emission and receiving of active light in real-time. Such sensors are inexpensive, compact, and they have a high performance, which especially fits real-time applications, e.g. in the fields of automotive, robotics, 3D imaging, and visualization. The simulation of such sensors is an essential building block for hardware design and application development. Therefore, the simulation data must capture the major sensor characteristics.#R##N##R##N#This paper introduces a simulation approach, which is motivated by physics, for the Photonic Mixing Device (PMD) sensor which is a specific type of time-of-flight sensor. Dynamic motion blurring and resolution artifacts such as flying pixels as well as the typical deviation error are prominent effects of real world systems. Flying pixels arise when an area of inhomogeneous depth is covered by a single PMD-pixel whereas the deviation error is based on the anharmonic properties of the optical signal. The modeling of these artifacts is essential for an authentic simulation approach. We present a detailed comparison between a real PMD-device and the simulation data regarding the sensor characteristics.#R##N##R##N#The proposed algorithms are implemented in a hardware accelerated solution which makes use of the programmability of modern Graphics Processing Units (GPUs). This way, an interactive simulation feedback is provided for applications and further data processing. The simulation takes place in real-time and thus all required control mechanisms are accessible in real-time, too.	real-time transcription;sensor;simulation	Maik Keller;Andreas Kolb	2009	Simulation Modelling Practice and Theory	10.1016/j.simpat.2009.03.004	stereoscopy;time of flight;real-time computing;simulation;hardware acceleration;data processing;computer science;electrical engineering;operating system;rapid application development;general-purpose computing on graphics processing units;computer graphics (images)	Mobile	57.6883373092545	-42.67642602470053	117944
3895395ada7786e88277536d804fff11b0a6ebd6	calibration of an active binocular head	recursive least square;calibration head cameras magnetic flux leakage proposals lenses parameter estimation recursive estimation kinematics focusing;stereo image processing active vision calibration noise recursive estimation least squares approximations;recursive estimation;least squares approximations;prediction error;indexing terms;three dimensional;object tracking;stereo image processing;3d vision applications active binocular head calibration iis head four stage calibration process motorized focus lens camera model mfl camera model constant nominal extrinsic parameters simple head eye relation camera orientation camera position camera parameter estimates nonlinear recursive least square estimator kinematic parameters;calibration;noise;active vision	In this paper we show how an active binocular head the IIS head can be easily calibrated with very high accuracy Our calibration method can also be applied to many other binocular heads In addition to the proposal and demonstration of a four stage calibration process there are three major contributions in this paper First we propose a MFL Motorized Focus Lens camera model which assumes constant nominal extrinsic parameters The advantage of having constant extrinsic parameters is to have a simple head eye relation Second a calibration method for the MFL camera model is proposed in this paper which separates the estimation of the image center and e ective focal length from the estimation of the camera orientation and position This separation has been proved to be crucial otherwise the estimates of camera parameters would be very noise sensitive Thirdly we show that once the parameters of the MFL camera model is calibrated a nonlinear recursive least square estimator can be used to re ne all the kinematic parameters Real experiments have shown that the proposed method can achieve accuracy of one pixel prediction error and pixel epipolar error even when all the joints including the left and right focus motors are moved simultaneously This accuracy is good enough for many D vision applications such as D navigation D object tracking and even D reconstruction	binocular vision;camera resectioning;epipolar geometry;experiment;focal (programming language);internet information services;message format language;nonlinear system;pixel;principle of good enough;recursion;recursive least squares filter	Sheng-Wen Shih;Yi-Ping Hung;Wei-Song Lin	1998	IEEE Trans. Systems, Man, and Cybernetics, Part A	10.1109/3468.686704	three-dimensional space;computer vision;camera auto-calibration;calibration;camera resectioning;simulation;index term;active vision;computer science;noise;mean squared prediction error;video tracking;mathematics;statistics	Vision	56.378501677703504	-39.38127972110099	118081
1e41ae925f1f351bc2c34f6d80865eb0e8e26873	collision-streams: fast gpu-based collision detection for deformable models	sound synthesis;streaming algorithm;interactive audio;collision detection;front tracking;deformable model	We present a fast GPU-based streaming algorithm to perform collision queries between deformable models. Our approach is based on hierarchical culling and reduces the computation to generating different streams. We present a novel stream registration method to compact the streams and efficiently compute the potentially colliding pairs of primitives. We also use a deferred front tracking method to lower the memory overhead. The overall algorithm has been implemented on different GPUs and we have evaluated its performance on non-rigid and deformable simulations. We highlight our speedups over prior CPU-based and GPU-based algorithms. In practice, our algorithm can perform inter-object and intra-object computations on models composed of hundreds of thousands of triangles in tens of milliseconds.	central processing unit;collision detection;computation;graphics processing unit;overhead (computing);simulation;streaming algorithm	Min Tang;Dinesh Manocha;Jiang Lin;Ruofeng Tong	2011		10.1145/1944745.1944756	simulation;computer science;theoretical computer science;streaming algorithm;collision detection;computer graphics (images)	Visualization	67.36504957954175	-51.63478119838927	118101
0c91bceb8aed0cc225cd8942073952c54ed0b75d	a stochastic algorithm for automatic hand pose and motion estimation	hand pose estimation;unscented kalman filter;optoelectronic cameras;hand motion analysis	In this paper, a novel, robust, and simple method for automatically estimating the hand pose is proposed and validated. The method uses a multi-camera optoelectronic system and a model-based stochastic algorithm. The approach is marker-based and relies on an Unscented Kalman Filter. A hand kinematic model is introduced for constraining relative marker’s positions and improving the algorithm robustness with respect to outliers and possible occlusions. The algorithm outputs are 3D coordinate measures of markers and hand joint angle values. To validate the proposed algorithm, a comparison with ground truths for angular and 3D coordinate measures is carried out. The comparative analysis shows the advantages of using the model-based stochastic algorithm with respect to standard processing software of optoelectronic cameras in terms of implementation simplicity, time consumption, and user effort. The accuracy is remarkable, with a difference of maximum 0.035r a d and 4m m with respect to angular and 3D Cartesian coordinates ground truths, respectively.	algorithm;angularjs;cartesian closed category;estimated;hand joint structure;kalman filter;motion estimation;movement;neurological rehabilitation;numerous;obstruction;patients;physical object;qualitative comparative analysis;real-time clock;real-time computing;real-time locating system;tomographic reconstruction;virtual reality	Francesca Cordella;Francesco Di Corato;Bruno Siciliano;Loredana Zollo	2017	Medical & Biological Engineering & Computing	10.1007/s11517-017-1654-6	cartesian coordinate system;robustness (computer science);artificial intelligence;computer vision;kalman filter;mathematics;outlier;kinematics;algorithm;motion estimation	Vision	54.37853601654952	-42.008413720340975	118128
69fdc2511d001033018816bb23f45b73c4c2a561	dynamic magnetometer calibration and alignment to inertial sensors by kalman filtering	magnetometers;calibration;gyroscopes;magnetic sensors;accelerometers;acceleration	Magnetometer and inertial sensors are widely used for orientation estimation. Magnetometer usage is often troublesome, as it is prone to be interfered by onboard or ambient magnetic disturbance. The onboard soft-iron material distorts not only the magnetic field, but also the magnetometer sensor frame coordinate and the cross-sensor misalignment relative to inertial sensors. It is desirable to conveniently put magnetic and inertial sensors information in a common frame. Existing methods either split the problem into successive intrinsic and cross-sensor calibrations, or rely on stationary accelerometer measurements which are infeasible in dynamic conditions. This brief formulates the magnetometer calibration and alignment to inertial sensors as a state estimation problem, and collectively solves the magnetometer intrinsic and cross-sensor calibrations, as well as the gyroscope bias estimation. Sufficient conditions are derived for the problem to be globally observable, even when no accelerometer information is used at all. An extended Kalman filter is designed to implement the state estimation and comprehensive test data results show the superior performance of the proposed approach. It is immune to acceleration disturbance and applicable potentially in any dynamic conditions.	distortion;extended kalman filter;gyroscope;mutual exclusion;observable;recursion;sensor;stationary process;test data	Yuanxin Wu;Danping Zou;Peilin Liu;Wenxian Yu	2018	IEEE Transactions on Control Systems Technology	10.1109/TCST.2017.2670527	control engineering;electronic engineering;control theory;physics	Mobile	56.232512859072024	-38.02753398985502	118187
ac5b3d3751707245b66a61a549a92144841b73c2	a sketch-based interface for detail-preserving mesh editing	construccion arquitectura tecnologia ambiental;computacion informatica;sketch based model editing;differential geometry;grupo de excelencia;shape deformation;deformations;laplacian surface editing;ciencias basicas y experimentales;shape modeling;tecnologias;sketching	In this paper we present a method for the intuitive editing of surface meshes by means of view-dependent sketching. In most existing shape deformation work, editing is carried out by selecting and moving a  handle , usually a set of vertices. Our system lets the user easily determine the handle, either by silhouette selection and cropping, or by sketching directly onto the surface. Subsequently, an edit is carried out by sketching a new, view-dependent handle position or by indirectly influencing differential properties along the sketch. Combined, these editing and handle metaphors greatly simplify otherwise complex shape modeling tasks.		Andrew Nealen;Olga Sorkine-Hornung;Marc Alexa;Daniel Cohen-Or	2005	ACM Trans. Graph.	10.1145/1073204.1073324	differential geometry;simulation;computer science;mathematics;geometry;computer graphics (images)	Graphics	66.04356057958918	-46.47316402087571	118223
7436063822e85533ce00d13a5382b082ba063de4	a novel framework of robust video watermarking based on statistical model		This paper is to investigate a novel framework of robust video watermarking based on the statistical model with robustness against multiple attacks. The main contribution is threefold. First, the Laplacian distribution is proposed to model each naive video frame, referring to as the original frame; meanwhile the noisy frame, referring to as the one with adding Gaussian-distributed noise, is modeled using the Gaussian distribution. Second, we propose a novel mechanism of embedding watermark by artificially adding noise or not, corresponding to watermark bit 1 or 0. Third, it is proposed to cast the problem of watermark extraction into the framework of hypothesis testing theory. In the ideal context, with knowing all the model parameters, the Likelihood Ratio Test (LRT) is smoothly established with verifying the feasibility of the designed watermark extraction based on the statistical models. In the case of estimating model parameters, we propose to design the Generalized Likelihood Ratio Test (GLRT) to deal with the practical problem of watermark extraction. Finally, compared with some prior arts, extensive experimental results show that our proposed novel framework of robust video watermarking can achieve the high video quality with robustness against various attacks such as re-scaling, cropping, and compression.	statistical model	Li Li;Xin Li;Tong Qiao;Xiaoyu Xu;Shanqing Zhang;Chin-Chen Chang	2018		10.1007/978-3-030-00015-8_14	real-time computing;statistical hypothesis testing;robustness (computer science);computer science;watermark;digital watermarking;video quality;estimation theory;likelihood-ratio test;artificial intelligence;statistical model;pattern recognition	Vision	62.987720733173454	-38.16473972335386	118257
1b9b564d751916f95c5f33796f1a2b4776cdc03a	an empirical evaluation of a gpu radiosity solver	empirical evaluation	This paper presents an empirical evaluation of a GPU radiosity solver which was described in the authors previous work. The implementation is evaluated in regard to rendering times in comparision with a classical CPU implementation. Results show that the GPU implementation outperforms the CPU algorithm in most cases, most importantly, in cases where the number of radiosity elements is high. Furthermore, the impact of the projection – which is used for determining the visibility – on the quality of the rendering is assessed. Results gained with a hemispherical projection performed in a vertex shader and with a real non-linear hemispherical projection are compared against the results of the hemicube method. Based on the results of the evaluation, possible improvements for further research are pointed out.	algorithm;central processing unit;graphics processing unit;hemicube (computer graphics);nonlinear system;radiosity (computer graphics);shader;solver	Guenter Wallner	2010			computational science;computer science;computer graphics (images)	Graphics	66.50530082924104	-51.81696080299713	118395
f25191895f492eb89f9e6d7d60fab9961093a6c3	numerical parameterization of curves and surfaces	implicit surface;curva;concepcion asistida;computer aided design;numerical method;surface parametrique;texture mapping;forma normal;courbe;parameterization;foot point;courbure;parametrization;implicit theory;interseccion;curve;parametrizacion;normalform;metodo numerico;intersection curve;methode maille;mesh method;teoria implicita;conception assistee;superficie;normal form;curvatura;curvature;surface;metodo malla;forme normale;theorie implicite;intersection;implicit curve;parametric surface;mesh generation;parametric curve;parametrisation;methode numerique;curves and surfaces	A method for parameterizing nearly arbitrary implicit plane/space curves and surfaces is introduced. The parameterizations are of class Cn−1 if the given curves/surfaces are of class Cn. The computation of points and derivatives is performed numerically. These parameterizations can be used for controlled determination of points on curves and surfaces and for the application of developed techniques for parametric curves and surfaces (mesh generation, texture mapping, curve integrals, surface integrals . . .) to implicit curves and surfaces. The idea of the normalform of a curve/surface introduced in recent papers makes it possible to apply the numerical parameterization to nearly arbitrary curves and surfaces.  2000 Elsevier Science B.V. All rights reserved.	algorithm;approximation;b-spline;bézier curve;carrier-to-noise ratio;computation;emoticon;implicit curve;implicit surface;interactivity;mesh generation;numerical analysis;numerical method;pipelines;schmidt decomposition;sensor;texture mapping	Erich Hartmann	2000	Computer Aided Geometric Design	10.1016/S0167-8396(99)00050-3	parametrization;geometric design;topology;computer aided design;calculus;differential geometry of curves;mathematics;geometry;family of curves	Graphics	68.1457334731217	-40.09613495020586	118448
d800589cf973fa6a9a4cdd2b3cab595e9dc5b25f	recovering partial 3d wire frame descriptions from stereo data				Stephen Pollard;John Porrill;John E. W. Mayhew	1990		10.5244/C.4.8	computer vision;computer graphics (images)	AI	60.583189631503714	-47.939760001018016	118565
6faff86ccf602d4d818ac24e2b68174156dd4833	single dimension relationships in relational cad	verification;machining;too path;5 axis;swept volume	Geometric approaches to CAD provide limited wlpport for changes to a computer model. Access to only positional information allows little design intent to be captured. Initial support is provided by ‘snap-to’ hnctions, exact dimensioning and pre-defined components. However this elementary design information is ignored after component creation. Hence, basic geometric systems only reflect a designer’s intent upon initial model construction thlough cannot continue to reflect that intent during subsequent modification. To facilitate change parametric approaches can require knowledge of a final model design and specific mathematical relationships. Paramelric representation, expressing the model through sets of functions with variable parameters, caters best for families of design[2] (e.g. a ball bearing with a single radial parameter can describe the complete model). To produce such a model, the full and exact specification of the parametric constraints is required meaning that the system must cjoncentrate on the late design phases.[3] The relational approach captures design intent as the model is constructed allowing a designer to move from initial concept models through to the final design. Generally a directed graph is used when model relationships are stored. The use of such directional, hierarchical data-structures to control these relationships introduces parent-child dependencies meaning twoway relationships cannot be supported. The relational approach advances on related research systems by providing bi-directional and structural relationships. Structural relationships refer to related groups of objects which, at a higher conceptual level, may be considered as a single component. For example, a series of steps may be considered as a staircase. It is not that a. series of objects cannot be created within a parametric system. however relationships utilising ihe number of objects in the series are not yet supported.[ I]	align (company);bi-directional text;computer simulation;computer-aided design;directed graph;hierarchical database model;numerical weather prediction;radial (radio)	J. R. Paul Hanna;Richard J. Millar;S. Ewart	1999		10.1145/304012.304054	computer vision;verification;engine displacement;machining;mathematics;geometry	Graphics	64.98243437125814	-41.82619369724418	118737
6efd3abb2044c90e78dcde7d4e8f0b696c1a931d	robust fairing via conformal curvature flow	conformal geometry;surface fairing;digital geometry processing;shape spaces;spin geometry;geometric modeling;discrete differential geometry;quaternions	We present a formulation of Willmore flow for triangulated surfaces that permits extraordinarily large time steps and naturally preserves the quality of the input mesh. The main insight is that Willmore flow becomes remarkably stable when expressed in curvature space -- we develop the precise conditions under which curvature is allowed to evolve. The practical outcome is a highly efficient algorithm that naturally preserves texture and does not require remeshing during the flow. We apply this algorithm to surface fairing, geometric modeling, and construction of constant mean curvature (CMC) surfaces. We also present a new algorithm for length-preserving flow on planar curves, which provides a valuable analogy for the surface case.	algorithm;geometric modeling	Keenan Crane;Ulrich Pinkall;Peter Schröder	2013	ACM Trans. Graph.	10.1145/2461912.2461986	conformal geometry;willmore energy;mathematical analysis;topology;geometric modeling;mean curvature flow;mean curvature;mathematics;geometry;discrete differential geometry;quaternion	Graphics	68.14797672163627	-43.041592132611335	118803
a28c5513a0f03eea53314e01e87c83f8f6039ea8	structure completion for facade layouts	structure completion;facade modeling;inpainting;urban reconstruction	We present a method to complete missing structures in facade layouts. Starting from an abstraction of the partially observed layout as a set of shapes, we can propose one or multiple possible completed layouts. Structure completion with large missing parts is an ill-posed problem. Therefore, we combine two sources of information to derive our solution: the observed shapes and a database of complete layouts. The problem is also very difficult, because shape positions and attributes have to be estimated jointly. Our proposed solution is to break the problem into two components: a statistical model to evaluate layouts and a planning algorithm to generate candidate layouts. This ensures that the completed result is consistent with the observation and the layouts in the database.	algorithm;automated planning and scheduling;database;statistical model;well-posed problem	Lubin Fan;Przemyslaw Musialski;Ligang Liu;Peter Wonka	2014	ACM Trans. Graph.	10.1145/2661229.2661265	computer vision;mathematical optimization;computer science;mathematics;inpainting	Graphics	57.029013456876136	-46.102703858683014	119000
402efb0e452b569210345bb57d7cba1f526384ae	animage-based approach to the reconstruction of ancient architectures by extracting and arranging 3d spatial components	digital reconstruction 3d virtual world 3d spatial components vision and scene understanding;divya udayan j hyung seok kim jee in kim an image based approach to the reconstruction of ancient architectures by extracting and arranging 3d spatial components	The objective of this research is the rapid reconstruction of ancient buildings of historical importance using a single image. The key idea of our approach is to reduce the infinite solutions that might otherwise arise when recovering a 3D geometry from 2D photographs. The main outcome of our research shows that the proposed methodology can be used to reconstruct ancient monuments for use as proxies for digital effects in applications such as tourism, games, and entertainment, which do not require very accurate modeling. In this article, we consider the reconstruction of ancient Mughal architecture including the Taj Mahal. We propose a modeling pipeline that makes an easy reconstruction possible using a single photograph taken from a single view, without the need to create complex point clouds from multiple images or the use of laser scanners. First, an initial model is automatically reconstructed using locally fitted planar primitives along with their boundary polygons and the adjacency relation among parts of the polygons. This approach is faster and more accurate than creating a model from scratch because the initial reconstruction phase provides a set of structural information together with the adjacency relation, which makes it possible to estimate the approximate depth of the entire structural monument. Next, we use manual extrapolation and editing techniques with modeling software to assemble and adjust different 3D components of the model. Thus, this research opens up the opportunity for the present generation to experience remote sites of architectural and cultural importance through virtual worlds and real-time mobile applications. Variations of a recreated 3D monument to represent an amalgam of various cultures are targeted for future work.	3d modeling;3d reconstruction;apache axis;approximation algorithm;augmented reality;autostereogram;component-based software engineering;digital effects (studio);extrapolation;graph (discrete mathematics);integrated development environment;interaction;mobile app;point cloud;polygonal modeling;population;real-time locating system;virtual tour;virtual world	J. Divya Udayan;HyungSeok Kim;Jee-In Kim	2014	Frontiers of Information Technology & Electronic Engineering	10.1631/FITEE.1400141	computer vision;simulation;computer science;machine learning;mathematics;algorithm;computer graphics (images)	Graphics	58.044470781791084	-47.827804122507814	119061
3de2e06cd9983d9493b96dfd95b5c332d9551720	incremental radiosity: an extension of progressive radiosity to an interactive image synthesis system	turn off;image synthesis;global illumination;visual feedback	"""Traditional radiosity methods can compute the illumination for a scene independent of the view position. However, if any part of the scene geometry is changed, the radiosity process will need to be repeated from scratch. Since the radiosity methods are generally expensive computationally, the traditional methods do not lend themselves to interactive uses where the geometry is constantly changing. This paper presents a new radiosity algorithm to incrementally render scenes with changing geometry and surface attributes. In other words, the question to be asked is """"What is the minimum recomputation I need to do if I turn off a light source, change the color of a surface, add or move an object?"""" Because a modeling change generally exhibits some coherence and affects only parts of an image, the proposed method may drastically reduce the rendering time and therefore allow interactive manipulation. In addition, since the method is conducted incrementally and view-independently, the rendering process can start before the modeling process is completed. The traditional paradigm of modeling-then-rendering is changed to rendering-while-modeling. This approach not only gives the user better visual feedback but also effectively utilizes CPU time otherwise wasted in the modeling process."""	algorithm;central processing unit;color;programming paradigm;radiosity (computer graphics);rendering (computer graphics)	Shenchang Eric Chen	1990		10.1145/97879.97894	computer vision;radiosity;simulation;computer science;global illumination;computer graphics (images)	Graphics	65.78764522278598	-50.339347300738666	119072
f311c1675666efdcf54b720a47cc95fe48941568	direct calibration of a laser ablation system in the projective voltage space	mirror;laser;robotics;navigation;dlt	Laser ablation is a widely adopted technique in many contemporary medical applications. However, it is new to use a laser to cut bone and perform general osteotomy surgical tasks with it. In this paper, we propose to apply the direct linear transformation algorithm to calibrate and integrate a laser deflecting tilting mirror into the affine transformation chain of a sophisticated surgical navigation system, involving next generation robots and optical tracking. Experiments were performed on synthetic input and real data. The evaluation showed a target registration error of 0.3mm ± 0.2mm in a working distance of 150 mm.		Adrian Schneider;Simon Pezold;Kyung-won Baek;Dilyan Marinov;Philippe C. Cattin	2015		10.1007/978-3-319-24553-9_34	computer vision;navigation;simulation;laser;robotics	Vision	59.04208258803335	-38.78586144612849	119374
01bbba6e86032c040abad34012799b1d4056f9b1	progressive medial axis filtration	scale axis;shape filtering;medial axis	The Scale Axis Transform provides a parametric simplification of the Medial Axis of a 3D shape which can be seen as a hierarchical description. However, this powerful shape analysis method has a significant computational cost, requiring several minutes for a single scale on a mesh of few thousands vertices. Moreover, the scale axis can be artificially complexified at large scales, introducing new topological structures in the simplified model. In this paper, we propose a progressive medial axis simplification method inspired from surface optimization techniques which retains the geometric intuition of the scale axis transform. We compute a hierarchy of simplified medial axes by means of successive edge-collapses of the input medial axis. These operations prevent the creation of artificial tunnels that can occur in the original scale axis transform. As a result, our progressive simplification approach allows to compute the complete hierarchy of scales in a few seconds on typical input medial axes. We show how this variation of the scale axis transform impacts the resulting medial structure.	apache axis;computational complexity theory;level of detail;mathematical optimization;medial graph;optic axis of a crystal;progressive enhancement;shape analysis (digital geometry)	Noura Faraj;Jean-Marc Thiery;Tamy Boubekeur	2013		10.1145/2542355.2542359	topology;medial axis;mathematics;geometry	Vision	66.2956988528167	-45.03806423568642	119395
4e4f19e1c0e0ed0ff2c91820d226a6c8735d1255	real-time rendering framework in the virtual home design system	light volume;deferred lighting;soft shadow;scene management	This paper introduces a home design system with its great functions and framework design, including the scene management based on the Cell&Portal system, improved variance shadow mapping and the recently popular real-time rendering framework called deferred lighting. In the implementation details, we put in some useful improvements, such as compressing the Geometry Buffer and Lighting Buffer to decrease the video memory and bandwidth occupation with which the multi-render-target limitation has been dislodged, using the light volume stencil culling which is similar to the shadow volume algorithm to identify the lit pixels and modifying the physically correct shading model based on Fresnel term to adapt to the deferred lighting framework.	real-time transcription	Pengyu Zhu;Mingmin Zhang;Zhigeng Pan	2013	Trans. Edutainment	10.1007/978-3-642-37042-7_15	computer vision;simulation;geography;rendering;volumetric lighting;per-pixel lighting;image-based lighting;computer graphics (images)	Graphics	64.85966153665363	-51.56383308823482	119463
c0788bd13df137a2f16a8fafda11d21c08e88f45	two-dimensional fitting of brightness profiles in galaxy images with a hybrid algorithm	exponential function;euclidean distance;optimization problem;optical imaging;evolution strategies;evolution strategy;quasi newton method;point of view;galaxy brightness;hybrid algorithm	Fitting brightness profiles of galaxies in one dimension is frequently done because it suffices for some applications and is simple to implement, but many studies now resort to two-dimensional fitting, because many well-resolved, nearby galaxies are often poorly fitted by standard one-dimensional models. For the fitting we use a model based on de Vaucoleurs and exponential functions that is represented as a set of concentric generalized ellipses that fit the brightness profile of the image. In the end, we have an artificial image that represents the light distribution in the real image, then we make a comparison between such artificial image and the original to measure how close the model is to the real image. The problem can be seen as an optimization problem because we need to minimize the difference between the original optical image and the model, following a normalized Euclidean distance. In this work we present a solution to such problem from a point of view of optimization using a hybrid algorithm, based on the combination of Evolution Strategies and the Quasi-Newton method. Results presented here show that the hybrid algorithm is very well suited to solve the problem, because it can find the solutions in almost all the cases and with a relatively low cost.	curve fitting;euclidean distance;evolution strategy;galaxy;hybrid algorithm;image;mathematical optimization;newton's method;optimization problem;quasi-newton method;time complexity	Juan-Carlos Gomez;Olac Fuentes;Ivanio Puerari	2005		10.1007/11552451_24	optimization problem;mathematical optimization;quasi-newton method;hybrid algorithm;computer science;calculus;exponential function;optical imaging;euclidean distance;mathematics;geometry;evolution strategy	Vision	62.87368820612736	-43.04053505951267	119563
38cbee56b6eae6bfc7a8b238b0ea35ba11a52446	efficient visualization of large—scale data on hierarchical meshes	large scale;multi resolution	A multi-resolution approach is presented for data on a large class of hierarchical and nested grids. It is based on a procedural interface and a set of hierarchical and adaptive visualization methods. Such a method consists of a recursive traversal of mesh elements from the grid hierarchy combined with an adaptive stopping according to some error indicator which is closely related to the visual impression of data smoothness. During this traversal user data is only temporarily and locally addressed on single elements. No in advance mapping onto prescribed formats is necessary. The user only has to supply a set of element access routines as an interface to his specific data structures. As no extra storage is required, also large, economically stored computational grids can be handled on workstations with moderate local memory. Significant examples illustrate the applicability and efficiency on different types of	data structure;recursion;tree traversal;workstation	R. Neubauer;Mario Ohlberger;Martin Rumpf;R. Schwörer	1997		10.1007/978-3-7091-6876-9_12	grid;tree traversal;impression;theoretical computer science;recursion;visualization;polygon mesh;hierarchy;data structure;computer science	HPC	67.91404496038925	-49.573972488307376	119575
75525b808f0e6c609182bcef0ec4121ad4e024b9	oriented geometric objects in computer graphics and numerical control	computer graphic;numerical control	Abstract#R##N##R##N#Conventional natural - language as well as computer - oriented descriptions of geometric constructions by means of geometric relationships (parallelism, tangency, etc.) and attributes (INSIDE, NEAR, MIDDLE, X-LARGE, Y-SMALL, etc.) do not offer a clear and efficient method for selecting a specific object out of a number of possible alternatives. This paper describes a systematic solution to the problem based upon the notions of orientation of geometric objects, of smooth transitions from one object to another (referred to as coherent tangency), and upon locality. Using the notions of object orientation and coherent tangency, some tangent constructions in a plane are developed. The method is shown to employ a minimum set of attributes - at most one, characterizing the intrinsic parameters of geometric objects.		J. Barbic;F. Dacar;M. Spegel	1984	Comput. Graph. Forum	10.1111/j.1467-8659.1984.tb00094.x	computer vision;discrete mathematics;topology;computer science;theoretical computer science;mathematics;geometry;numerical control;algorithm;computer graphics (images)	Graphics	64.4768620381205	-42.05943992070066	120065
505f4515c045044b3abb261d6434c9067b2bfa24	infrared marker based augmented reality system for equipment maintenance	gear box maintenance;augmented reality cameras layout infrared detectors prototypes infrared imaging virtual reality computer aided manufacturing cadcam light emitting diodes;mechanical engineering computing;mechanical engineering computing augmented reality infrared detectors maintenance engineering;project;maintenance engineering;tracking camera;proof of concept;distance measurement;3d model;milling machine;three dimensional displays;air filter replacement;project augmented reality infrared marker;video image;equipment maintenance;transmission line matrix methods;augmented reality;infrared;infrared camera;3d models;infrared marker;calibration;milling machine infrared marker augmented reality equipment maintenance infrared camera tracking camera 3d models video image air filter replacement gear box maintenance;infrared detectors;cameras	In this paper, we propose augmented reality (AR) applications for equipment maintenance. The system is based on the projection and detection of infrared markers. We use an infrared projector to project markers onto the surface of the equipment to be maintained. These markers are invisible to the human-eye, but they could be clearly identified by the infrared camera. As a proof of concept, we have implemented a prototype camera system consisting of a conventional camera (scene camera) and an infrared camera (tracking camera). The systempsilas viewpoint could be calculated and the visible image is captured simultaneously when using such a camera system. Some 3D models are overlaid on top of a video image. We demonstrate several applications of our method, including air filter replacement and gear-box maintenance for a milling machine.	3d modeling;augmented reality;prototype;video projector	Tianren Wang;Yue Liu;Yongtian Wang	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.8	maintenance engineering;smart camera;stereo camera;computer vision;camera auto-calibration;augmented reality;calibration;camera resectioning;simulation;infrared;project;computer science;management;proof of concept;computer graphics (images)	Visualization	59.417760574487396	-41.67842772284598	120294
55db3f6bbabb410e775d0c4675964fce226e653e	automatic comic-like image layout system preserving image order and important regions	viewing system;tree enumeration;cropping;image layout;comic	In this paper, we present a practical and automatic comic-like image layout system for event photos or event movies. We focus on the comic-like layout with cropping. The comic-like layouts allow viewers to track events in time sequential order like comic books, in which event images are cropped and arranged in panels from top left to bottom right on a screen so that the resultant layout has variety of image shapes and gives a pleasant impression. The main drawback of the conventional method is that an important region such as a face or a salient object area is sometimes cropped. In order to avoid excessive cropping of important regions while maintaining the image order, our system achieves adaptive layout to input images by generating all possible templates suitable for comic and deciding appropriate templates based on our proposed layout evaluation. In the demo, we will show that our full automatic system generates comic-like layouts immediately. Furthermore, the system allows a user to select his/her favorite layout from the multiple ones with different looks.	book;image and object order rendering;resultant;web design	Emi Myodo;Satoshi Ueno;Koichi Takagi;Shigeyuki Sakazawa	2011		10.1145/2072298.2072461	computer vision;computer science;cropping;comprehensive layout;computer graphics (images)	Vision	62.120479775314095	-48.81896339262298	120368
03682e97ebfdf6f1a3ba08ada217e9df81c08c92	pointshop 3d: an interactive system for point-based surface editing	interaction point;point based graphics;texture mapping;computational geometry;parameterization;image editing;color image processing;color computer graphics;interactive system;surface sculpting;two dimensional;surface painting;resampling method;dynamic adaptation;interactive computer graphics;3d content creation;interaction technique	We present a system for interactive shape and appearance editing of 3D point-sampled geometry. By generalizing conventional 2D pixel editors, our system supports a great variety of different interaction techniques to alter shape and appearance of 3D point models, including cleaning, texturing, sculpting, carving, filtering, and resampling. One key ingredient of our framework is a novel concept for interactive point cloud parameterization allowing for distortion minimal and aliasing-free texture mapping. A second one is a dynamic, adaptive resampling method which builds upon a continuous reconstruction of the model surface and its attributes. These techniques allow us to transfer the full functionality of 2D image editing operations to the irregular 3D point setting. Our system reads, processes, and writes point-sampled models without intermediate tesselation. It is intended to complement existing low cost 3D scanners and point rendering pipelines for efficient 3D content creation.	3d scanner;aliasing;displacement mapping;display resolution;distortion;filter (signal processing);graphics pipeline;image editing;interaction technique;interactivity;pixel;plasma cleaning;point cloud;ray tracing (graphics);realms of the haunting;rendering (computer graphics);resampling (statistics);texture mapping	Matthias Zwicker;Mark Pauly;Oliver Knoll;Markus H. Gross	2002		10.1145/566570.566584	parametrization;texture mapping;computer vision;two-dimensional space;computational geometry;computer science;geometry;multimedia;interaction technique;computer graphics (images)	Graphics	64.96873525924134	-49.84886209727513	120431
d5a98f4428ab58afc5099c18a294936ef78090cf	four points in two or three calibrated views: theory and practice	multi view geometry;theory and practice;army research laboratory;kruppa constraint;ransac;structure and motion;structure from motion;algebraic curves;minimal methods	Suppose two perspective views of four world points are given and that the intrinsic parameters are known but the camera poses and the world point positions are not. We prove that the epipole in each view is then constrained to lie on a curve of degree ten. We derive the equation for the curve and establish many of the curve’s properties. For example, we show that the curve has four branches through each of the image points and that it has four additional points on each conic of the pencil of conics through the four image points. We show how to compute the four curve points on each conic in closed form. We show that orientation constraints allow only parts of the curve and find that there are impossible configurations of four corresponding point pairs. We give a novel algorithm that solves for the essential matrix given three corresponding points and one of the epipoles. We then use the theory to create the most efficient solution yet to the notoriously difficult problem of solving for the pose of three views given four corresponding points. The solution is a search over a one-dimensional parameter domain, where each point in the search can be evaluated in closed form. The intended use for the solution is in a hypothesise-and-test architecture to solve for structure and motion.	algorithm;camera resectioning;correspondence problem;essential matrix;hp 48 series;implicit curve;kernel (linear algebra);polynomial;quadratic equation;quartic function;system of linear equations	David Nistér;Frederik Schaffalitzky	2005	International Journal of Computer Vision	10.1007/s11263-005-4265-x	computer vision;mathematical optimization;combinatorics;ransac;structure from motion;computer science;machine learning;mathematics;geometry;algebraic curve	Vision	54.10338044204259	-50.43007551430992	120519
2095c596c6b6cea417ea0aeef5a69dc7421e87b9	real-time image mosaicing from a video sequence	panoramic images videos real time image mosaicing video sequence robust image registration method panoramic image video alignment parameters pseudo motion vectors optical flows pixel software system low cost pc;video signal processing;real time;motion estimation;journal article;video sequences image registration motion estimation robustness parameter estimation optical computing image motion analysis pixel software systems displays;motion vector;image registration;optical flow;panoramic image;microcomputer applications;real time systems video signal processing image sequences image registration motion estimation microcomputer applications;image mosaicing;real time systems;image sequences	This paper describes a fast and robust image registration method that can be used to create a panoramic image/video from video sequences. To estimate alignment parameters for image registration, the method computes pseudo motion vectors that are rough estimates of optical ows at each selected pixels. Using the proposed method, we implemented a software system that can, with a low-cost PC, create and display panoramic images/videos in real-time.	image registration;pixel;real-time clock;real-time web;software system	Masakatsu Kourogi;Takeshi Kurata;Junichi Hoshino;Yoichi Muraoka	1999		10.1109/ICIP.1999.819564	image texture;computer vision;feature detection;image processing;computer science;image registration;digital image processing;motion estimation;optical flow;multimedia;video post-processing;standard test image;computer graphics (images)	Vision	54.80470756269771	-48.577229398990816	120800
5956c8e2cabdbbc47f6b3c9fb655ebadc4f9715f	evaluation of the viewpoint shift for a fisheye lens based on stereo geometry	geometry;optical imaging;three dimensional displays;lenses;calibration;cameras;adaptive optics	Many studies have developed methods of making three-dimensional measurements from fisheye images. Most of these methods assume a single-viewpoint model. However, the viewpoint of a fisheye lens shifts along the optical axis according to the incident angle between the optical axis and the incident light ray. The author previously analyzed the error resulting from using the single-viewpoint model for three-dimensional measurements from fisheye images and clarified that the error is not negligible under some conditions. In particular, the errors in stereo measurements were remarkable. This implies that some knowledge about the viewpoint shift can be obtained from the stereo matching coordinates on stereo images. The present paper obtains an interesting relation of the shift magnitude at a couple of incident angles from a pair of coordinates. Moreover, the relations of shift magnitudes are integrated to obtain an important hint for the calibration of the viewpoint-shifting model.	apache axis;computer stereo vision;fisheye;ray (optics);view model;viewpoint;word lens	Nobuyuki Kita	2016	2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)	10.1109/DICTA.2016.7797038	computer vision;calibration;optical imaging;lens;geometry;adaptive optics	Robotics	56.24157293092676	-50.14280010008504	120891
5a74fc5d710c07062d1fc0651071d19ee768420c	rectifying transformations that minimize resampling effects	impedance;minimized resampling effects;image matching stereo image processing;image matching;image distortions;local area;computational geometry;oversampling;rectifying transformation;epipolar geometry;image rectification;stereo matching;cameras computer science impedance computational geometry joining processes calibration;undersampling;local area image rectification rectifying transformation minimized resampling effects stereo image warping epipolar lines scan lines image distortions stereo matching pixel loss undersampling oversampling;stereo image processing;scan lines;joining processes;epipolar lines;pixel loss;computer science;calibration;cameras;stereo image warping	Image rectification is the process of warping a pair of stereo images in order to align the epipolar lines with the scan-lines of the images. Once a pair of images is rectified, stereo matching can be implemented in an efficient manner. Given the epipolar geometry, it is straightforward to define a rectifying transformation, however, many transformations will lead to unwanted image distortions. In this paper, we present a novel method for stereo rectification that determines the transformation that minimizes the effects of resampling that can impede stereo matching. The effects we seek to minimize are the loss of pixels due to under-sampling and the creation of new pixels due to over-sampling. To minimize these effects we parameterize the family of rectification transformations and solve for the one that minimizes the change in local area integrated over the area of the images.	align (company);approximation algorithm;computation;computer stereo vision;distortion;epipolar geometry;image rectification;optimization problem;oversampling;pixel;rectifier;sampling (signal processing);scan line;structure from motion	Joshua Gluckman;Shree K. Nayar	2001		10.1109/CVPR.2001.990463	computer vision;calibration;oversampling;scan line;computational geometry;computer science;electrical impedance;mathematics;fundamental matrix;image rectification;undersampling;epipolar geometry;computer graphics (images)	Vision	56.86936924293441	-51.78433933868449	120900
affd07365a9966f6b4bd4fcb63d21a45f1e6a585	calibration of a structure light based windshield inspection system	optical distortion;vision system;lens distortion;robot sensing systems;sensor systems;pixel to pixel strategy;three dimensional optic measurement system;working environment noise;measurement systems;structured light;windshield inspection system;testing;inspection;three dimensional;lens resolution;three dimensional displays;automotive components;pixel;lenses;lens resolution structure light calibration windshield inspection system three dimensional optic measurement system pixel to pixel strategy lens distortion;measurement systems calibration inspection lenses;optical sensors;3d vision;meteorology;calibration;cameras;structure light calibration;calibration automotive components inspection costs sensor systems optical distortion optical sensors cameras testing working environment noise	Three dimensional optic measurement system's accuracy is highly related with the field of inspection. Increasing of field inspection costs increasing camera / projector pixel area on the test surface. Small surface changes within one pixel area cannot be directly detected, which will lower the system accuracy. A pixel-to-pixel strategy is developed to solve this problem. Increasing field of inspection also costs a longer standoff distance. The random image noise from the environment, uncertainties functions by lens distortion and resolution variation are all amplified. Therefore, a more complicated calibration model for each pixel is proposed to calibrate the system. In traditional structured light vision systems, a single sensor usually detects around 10,000 – 50,000 mm2, and the 3D vision sensor in this paper needs to detect around 2,400,000 mm2. Larger detection range gives more challenge to finish the calibration tasks. This paper proposes a clear calibration procedure to a large field of inspection structured light system. Last the comparison with the CMM measured results is used to prove that the calibration tasks have been successfully achieved.	capability maturity model;correspondence problem;distortion;error analysis (mathematics);image noise;iterative method;nvidia 3d vision;pixel;point cloud;sensor;structured light;system of measurement;transformation matrix;video projector	Chi Zhang;Ning Xi;Jing Xu;Quan Shi	2010	2010 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2010.5509195	distortion;three-dimensional space;computer vision;calibration;structured light;inspection;machine vision;computer science;engineering;system of measurement;lens;software testing;optics;pixel;remote sensing	Robotics	55.69245648213758	-43.9749189710923	120906
455bf23434a723e0f14c03db908756d8fb26414e	computing skeletons in three dimensions	objet;curva;three dimensions;esqueleto;digital topology;technology;analisis forma;volume;shape analysis;object;courbe;teknikvetenskap;calculo automatico;simple points;curve;volume image;voxel;skeleton;computing;calcul automatique;afinamiento;curve skeleton;shape representation;engineering and technology;volumen;teknik och teknologier;pattern recognition;superficie;squelette;amincissement;surface;surfaces;pattern analysis;topology preservation;objeto;thinning;surface skeleton;analyse forme;thinning algorithm	Skeletonization will probably become as valuable a tool for shape analysis in 3D, as it is in 2D. We present a topology preserving 3D skeletonization method which computes both surface and curve skeletons whose voxels are labelled with the D6 distance to the original background. The surface skeleton preserves all shape information, so (close to) complete recovery of the object is possible. The curve skeleton preserves the general geometry of the object. No complex computations, large sets of masks, or extra memory are used, which make implementations e$cient. Resulting skeletons for geometric objects in a number of 2 Mbyte images are shown as examples. ( 1999 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.	3d computer graphics;call of duty: black ops;central processing unit;computation;iteration;iterative method;megabyte;mind;pattern recognition;shape analysis (digital geometry);synthetic data;thickness (graph theory);topological skeleton;variable shadowing;voxel;workstation	Gunilla Borgefors;Ingela Nyström;Gabriella Sanniti di Baja	1999	Pattern Recognition	10.1016/S0031-3203(98)00082-X	computer science;mathematics;geometry;surface;digital topology	Vision	66.292290842399	-40.85250509546686	120920
b7adb98a68760cd5765bef23db9aab368a1ed788	optimised de bruijn patterns for one-shot shape acquisition	moving object;active stereo;shape acquisition;structured light;coded structured light	Coded structured light is an optical technique based on active stereovision which allows shape acquisition. By projecting a suitable set of light patterns onto the surface of an object and capturing images with a camera, a large number of correspondences can be found and 3D points can be reconstructed by means of triangulation. One-shot techniques are based on projecting an unique pattern so that moving objects can be measured. A major group of techniques in this field define coloured multi-slit or stripe patterns in order to obtain dense reconstructions. The former type of patterns is suitable for locating intensity peaks in the image while the latter is aimed to locate edges. In this paper, we present a new way to design coloured stripe patterns so that both intensity peaks and edges can be located without loss of accuracy and reducing the number of hue levels included in the pattern. The results obtained by the new pattern are quantitatively and qualitatively compared to similar techniques. These results also contribute to a comparison between the peak-based and edge-based reconstruction strategies. q 2005 Elsevier B.V. All rights reserved.	de bruijn graph;magnetic stripe card;stereopsis;stripes;structured light	Jordi Pagès;Joaquim Salvi;Christophe Collewet;Josep Forest	2005	Image Vision Comput.	10.1016/j.imavis.2005.05.007	computer vision;structured light;computer science;computer graphics (images)	Vision	58.958380044419556	-48.65760049283614	121159
76008cac24e458acf4ff3f4176b652fcdf627a7e	a neural network for 3d gaze recording with binocular eye trackers	point estimation;3d calibration;anaglyphs;geometric approach;self organized map;eye tracking;visual attention;3d display;artificial neural network;neural network	Using eye tracking for the investigation of visual attention has become increasingly popular during the last few decades. Nevertheless, only a small number of eye tracking studies have employed 3D displays, although such displays would closely resemble our natural visual environment. Besides higher cost and effort for the experimental setup, the main reason for the avoidance of 3D displays is the problem of computing a subject’s current 3D gaze position based on the measured binocular gaze angles. The geometrical approaches to this problem that have been studied so far involved substantial error in the measurement of 3D gaze trajectories. In order to tackle this problem, we developed an anaglyph-based 3D calibration procedure and used a well-suited type of artificial neural network—a parametrized selforganizing map (PSOM)—to estimate the 3D gaze point from a subject’s binocular eye-position data. We report an experiment in which the accuracy of the PSOM gaze-point estimation is compared to a geometrical solution. The results show that the neural network approach produces more accurate results than the geometrical method, especially for the depth axis and for distant stimuli.	anaglyph 3d;artificial neural network;assistive technology;backplane;binocular vision;distortion;experiment;eye tracking;nvidia 3d vision;optic axis of a crystal;user interface;virtual reality	Kai Essig;Marc Pomplun;Helge J. Ritter	2006	IJPEDS	10.1080/17445760500354440	computer vision;simulation;stereo display;eye tracking;computer science;machine learning;point estimation;artificial neural network	HCI	59.31601685016204	-45.75364665577681	121236
7df905efcd902a900769f291de8766df06cfac9f	true single view point cone mirror omni-directional catadioptric system	optical distortion;mirrors;image formation;computer vision;shape;degeneration;geometric optics model;solid modeling;stereo image processing;lenses;mirrors cameras optical distortion geometrical optics solid modeling lenses computational intelligence society shape power system modeling optical feedback;degenerate conic section;geometric optics model single view point cone mirror omni directional catadioptric system pinhole camera model geometric optics image formation degenerate conic section;single view point cone mirror omni directional catadioptric system;power system modeling;pinhole camera model;off the shelf;geometric optics;optical feedback;cameras;stereo image processing computer vision;computational intelligence society;geometrical optics	1 This work has been supported in part by NSF-IIS-0083209, ARO/MURI-DAAH04-96-1-0007, NSF-CDS-97-03220, DARPA-ITO-DABT63-99-1-0017, and Advanced Network and Services. Special thanks to members of MOOSE Project: V. J. Kumar, Kostas Daniilidis, Elli Angelopoulou, Oleg Naroditsky, and Geoffrey Egnal for their invaluable comments and support. Also grateful thanks to members of GRASP Lab for their wonderful feedback and help. Abstract	cone;experiment;grasp;geometric modeling;ibm notes;indium tin oxide;moose;peripheral;prototype	Shih-Schon Lin;Ruzena Bajcsy	2001		10.1109/ICCV.2001.937610	geometrical optics;computer vision;computer science;geometry	Vision	55.23427975857387	-50.01101666933399	121281
50bf86afd21c5b6e8f330270ce3639a6caf31dda	dynamic hybrid approaching for robust hand-eye calibration		The hand-eye calibration problem is to compute the relative pose between a robot platform (hand) and a camera (eye) mounted rigidly on the robot platform. To solve the problem, the motion pairs of the robot platform movement and the corresponding camera movement are collected and then use a linear algorithm or nonlinear minimization algorithm to find the optimal solution from the collected motion pairs. Because there are noises in the motion pairs, the previous method uses the motion pairs directly can’t effectively reduce the impact of the noise. In this paper, we focus on how to ease the impact of the noises of the motion pairs. We use active vision approach to hybrid the robot platform movement and camera movement with different credibility and generate a series of special motion pairs, this can dynamically get a more accurate initial estimation of the relative pose between the robot platform and the camera. Then we use a recursive way to filter matching points and update the estimation of the relative pose, which can improve the robustness of our hand-eye calibration algorithm effectively. Both virtual and real experiments show the superiority of our approach over the previous methods.		Chen Meng;Wei Feng;Jinchang Ren	2018		10.1007/978-3-030-00563-4_73	calibration;computer vision;robustness (computer science);nonlinear system;artificial intelligence;active vision;computer science	Vision	54.09952108731723	-41.302729807057794	121619
3e9a17bb53aa6b34c2c6991f4d13d5326c92b953	labeling streets in interactive maps using embedded labels	visualization;automated label placement;interactive maps	We consider the problem of labeling linear objects (such as streets) in interactive maps where the user can pan, zoom, and rotate continuously. Our labels contain text (such as street names). They are embedded into the objects they label, i.e., they follow the curvature of the objects, they do not move with respect to the map background, but they scale in order to maintain constant size on the screen. To the best of our knowledge, this is the first work that deals with curved labels in interactive maps.  Our objective is to label as many streets as possible and to select label positions of high quality while forbidding labels to overlap at street crossings. We present a simple but effective algorithm that takes curvature and crossings into account and produces aesthetical labelings. On average over all interaction types, our implementation reaches interactive frame rates of more than 85 frames per second.	algorithm;display resolution;embedded system;map;sequence labeling	Nadine Schwartges;Alexander Wolff;Jan-Henrik Haunert	2014		10.1145/2666310.2666494	computer vision;visualization;computer science;cartography;computer graphics (images)	HCI	61.762778899105264	-48.59388344516944	121695
1be46c64cbf827d047eaf9c2c903601700f8633a	determination and classification of triangular quadric patches	approximation rationnelle;quadratic approximation;concepcion asistida;computer aided design;curva bezier;modele geometrique;aproximacion cuadratica;gaussian curvature;ajustamiento curva;geometrie algorithmique;computer graphics;quadric;bezier patch;conic at infinity;rational approximation;computational geometry;approximation quadratique;affine quadric classification;courbe bezier;steiner surface;projective space;conception assistee;rational triangular quadratic;ajustement courbe;geometria computacional;curve fitting;aproximacion racional;projective quadric classification;grafico computadora;infographie;geometrical model;bezier curve;modelo geometrico	A method for determining, if a given rational triangular Bdzier patch of degree 2 lies on a quadric surface, and if so, for establishing the quadric's affine type, is presented. First, the question whether the patch is a quadric patch is solved by means of the related Veronese surface in five-dimensional projective space. Once established that the patch lies on a quadric the Gaussian curvature in one of the corner points of the patch is used for a rough classification yielding the projective type of the quadric. Then, the quadric's affine type is obtained by means of the quadric's intersection with the plane at infinity. An easy algorithm for the method is finally presented, together with several examples. © 1998 Elsevier Science B.V. Kevwords: Rational triangular quadratic B6zier patch; Steiner surface: Quadric: Projectiw~ quadric classification: Gaussian curvature; Affine quadric classification: Conic at infinity	algorithm;steiner tree problem;substructural type system	Gudrun Albrecht	1998	Computer Aided Geometric Design	10.1016/S0167-8396(98)00008-9	gaussian curvature;projective space;discrete mathematics;quadric;topology;computational geometry;computer aided design;bézier surface;bézier curve;mathematics;geometry;computer graphics;roman surface;plücker coordinates;curve fitting	Theory	68.12741232478331	-40.02393585892753	121712
46e9622e6a2a0b0843063f9efb3ca80d8ac8e894	contour interpolation by straight skeletons	piecewise linear;geographic information system;surface reconstruction;robust performance;piecewise linear interpolation	In this paper we present an efficient method for interpolating a piecewise-linear surface between two parallel slices, each consisting of an arbitrary number of (possibly nested) polygons that define 'material' and 'non-material' regions. This problem has applications to medical imaging, geographic information systems, etc. Our method is fully automatic and is guaranteed to produce non-self-intersecting surfaces in all cases regardless of the number of contours in each slice, their complexity and geometry, and the depth of their hierarchy of nesting. The method is based on computing cells in the overlay of the slices that form the symmetric difference between them. Then, the straight skeletons of the selected cells guide the triangulation of each face of the skeletons. Finally, the resulting triangles are lifted up in space to form an interpolating surface. We provide some experimental results on various complex examples to show the good and robust performance of our algorithm.	contour line;interpolation;straight skeleton	Gill Barequet;Michael T. Goodrich;Aya Levi-Steiner;Dvir Steiner	2004	Graphical Models	10.1016/j.gmod.2004.05.001	mathematical optimization;discrete mathematics;surface reconstruction;piecewise linear function;mathematics;geometry;geographic information system	Vision	68.18151704040841	-43.955468968815595	121758
9d0e75429457dd96d0719dac1ee16cf542fbef70	navigation in highly polygon-populated ship environments using the visibility octree	coarseness;vo;visibility octree;ship;external research report;visibility approximation	This work is focused on the interactive navigation through highly#R##N#polygon-populated ship environments. A conservative visibility#R##N#algorithm is presented that hierarchically computes visibility for#R##N#different observer positions and stores it in a new octree based#R##N#structure, the Visibility Octree (VO) The VO is used during the#R##N#navigation. Its main contribution is the ability to provide an#R##N#effective control over the coarseness of the visibility#R##N#approximation. Some results are presented for indoor ship scenes that#R##N#show that the VO is efficient on densely occluded scenes.	octree;population	Carlos Saona-Vázquez;Isabel Navazo;Pere Brunet	1998			computer vision;simulation;geography;computer graphics (images)	HCI	58.26515224541292	-44.39359918358227	121793
a74010e3164d2b2cf64b8fbf4bf12aee1b894189	accurate scanconversion of triangulated surfaces	new scanconversion technique;surface depth;triangulated surfaces;acceptable depth-accuracy;triangulated surface;wrong surface;accurate scanconversion;pixel classification;erroneous classification;curved surface;surface data;planar face;adjacent triangle	Scanconverting a planar face produces depth-values for pixels totally or partly covered by the projection of that face. State-of-the-art hardware-supported scan conversion techniques use sub pixel adjustment and extended precision calculations to achieve an acceptable depth-accuracy despite numeric round-off errors. Unfortunately, this depth-accuracy only holds for the interior pixels of the face. During the scanconversion of the boundaries of polyhedral solids or of the tesselations of curved surfaces, significantly larger depth-errors may occur at pixels traversed by the projection of the bounding edges. These errors are due to the use of the wrong surface equations resulting from an erroneous classification of pixels with respect to the projections of faces. They may lead to logical mistakes of serious consequences for hidden-surface removal and for solid-modeling applications. To address this problem, a new scanconversion technique is presented, which exploits surface data and face/face adjacency information to infer face-projections. For simplicity, the exposition is confined to triangular faces of manifolds, where each edge is adjacent to two triangles. At pixels covered by the projection of an edge, the surface depth computed in the standard manner is compared to the depth of the surface supporting the adjacent triangle. Pixel classification is obtained by taking into account the result of this comparison and the orientations of both faces.	extended precision;hidden surface determination;pixel;polyhedron;round-off error;scan conversion;solid modeling	Jarek Rossignac	1991		10.2312/EGGH/EGGH91/116-137	computer vision;topology;mathematics;geometry	Graphics	67.42028903484646	-44.251262041138865	122001
dbb9d39e129c9d0df92214ce9b79908a435630e7	implicit linear interval estimations	implicit surface;interval estimation;enumeration;implicit curves;collision detection;affine arithmetic;implicit surfaces;linear interval estimation;interval arithmetic;rendering	Visualization and collision detection are two of the most important problems connected with implicit objects. Enumeration algorithms can be used either directly or as preprocessing step for many algorithms solving these problems. In general, enumeration algorithms based on recursive space subdivision are reliable tools to encounter those parts in space, where the object might be located. But the bad performance and the huge number of computed enclosing cells, if high precision is required, are grave drawbacks. Implicit Linear Interval Estimations (ILIEs) introduced in this paper are implicit interval (hyper-)planes providing oriented tight bounds of the object within given cells. It turns out that the use of ILIEs highly improves the performance of the classical enumeration algorithm and the quality of the results. The theoretical background as well as a fast and simple technique to compute ILIEs are presented. The applicability of ILIEs is demonstrated by means of a modified enumeration algorithm that has been implemented and tested for implicit surfaces.	algorithm;collision detection;implicit surface;preprocessor;recursion;subdivision surface	Katja Bühler	2002		10.1145/584458.584479	mathematical optimization;combinatorics;discrete mathematics;interval estimation;rendering;computer science;affine arithmetic;mathematics;geometry;interval arithmetic;enumeration;collision detection;algorithm;computer graphics (images)	Graphics	67.25971590789524	-45.00004591713221	122105
d5657622b04a8abcd488966d32f75fd8c457fc94	an efficient feathering system with collision control	i 3 5 computer graphics computational geometry and object modeling geometric algorithms;geometric algorithms;i 3 5 computer graphics;期刊论文;computational geometry and object modeling;i 3 5 computer graphics computational geometry and object modeling geometric algorithms languages and systems;languages;and systems;categories and subject descriptors according to acm ccs	We present an efficient interactive system for dressing a naked bird with feathers. In our system, a skeleton associated with guide feathers is used to describe the distribution of the body feathers. The special skeleton can be easily built by the user, given a 3D bird model as input. To address the problem of interpenetrations among feathers, the growth priority between the feather roots is defined, with which we obtain the growth order from a greedily constructed directed acyclic graph. Each feather is then adjusted in that order by a height field based collision resolution process. The height field not only provides an efficient way to detect the collision but also enables us to finely control the degree of collision during feather adjustments. The results show that our approach is capable of resolving the collisions among thousands of feathers in a few seconds. If model animation is desired, the feathers can be adjusted on the fly at interactive framerates. Details of our implementation are provided with several examples to demonstrate the effectiveness of our system.	feathering	Le Liu;Xiaosheng Li;Yanyun Chen;Xuehui Liu;Jian J. Zhang;Enhua Wu	2015	Comput. Graph. Forum	10.1111/cgf.12766	computer vision;simulation;computer science;artificial intelligence;theoretical computer science;geometry;language;algorithm;computer graphics (images)	OS	66.44664473008189	-47.08274057949592	122169
ba1aa8a6893777ff5d23f29d75b7d427848dba72	person to camera distance measurement based on eye-distance	person to camera distance eye detection eye distance;measurement by laser beam;image processing;distance measure;eye detection;image processing ccd image sensors distance measurement;charge coupled devices;ccd image sensors;accuracy;distance measurement;eye distance;person to camera distance;pixel;distance measuring system;face;person to camera distance measurement;cameras distance measurement face detection eyes computer science electronic mail ultrasonic variables measurement optical reflection charge coupled image sensors image storage;cameras;distance measuring system person to camera distance measurement eye distance	This paper presents a novel person to camera distance measuring system based on eye-distance. The distance between centers of two eyes is used for measuring the person to camera distance. The variation in eye-distance (in pixels) with the changes in camera to person distance (in inches) is used to formulate the distance measuring system. The system starts with computing the distance between two eyes of a person and then person to camera distance is measured. The proposed distance measurement system is relatively simple and inexpensive to implement as it does not require any other external distance measuring tools. Experimental results show the effectiveness of the system with an average accuracy of 94.11%.	algorithm;charge-coupled device;pixel;real-time clock;robotics;system of measurement;video projector	Khandaker Abir Rahman;Md. Shafaeat Hossain;Mohammad Al-Amin Bhuiyan;Tao Zhang;Mohammed Hasanuzzaman;Haruki Ueno	2009	2009 Third International Conference on Multimedia and Ubiquitous Engineering	10.1109/MUE.2009.34	face;computer vision;camera auto-calibration;image processing;computer science;accuracy and precision;pixel;computer graphics (images)	Robotics	59.25304630149599	-40.9907777496735	122338
7bdbd1d6f329d5aae2075e788fb5837bc7ea14ad	off-line teaching system using an image scanner			image scanner	Yasuhisa Maikawa;Mitsuaki Amano	1990	JRM	10.20965/jrm.1990.p0056	computer vision;scanner;artificial intelligence;computer science;structured-light 3d scanner	Robotics	60.616631295851306	-47.19413225143579	122365
4b8d5ab5ffd8e2445112452662a038dcece42b8b	on stereo-rectification of pushbroom images	pleiades satellite;pushbroom;stereo rectification;stereo image processing computer vision image reconstruction image resolution;remote sensing;computer vision pushbroom image stereo rectification image stereo pairs pinhole cameras stereo matching algorithms pushbroom earth observation satellites satellite calibration data local stereo rectification large earth images fully automatic 3d reconstruction chain pleiades earth observation satellite image resolution;pleiades satellite pushbroom stereo rectification epipolar remote sensing;satellites stereo vision cameras earth remote sensing sensors approximation methods;epipolar	Image stereo pairs obtained from pinhole cameras can be stereo-rectified, thus permitting to test and use the many standard stereo matching algorithms of the literature. Yet, it is well-known that pushbroom Earth observation satellites produce image pairs that are not stereo-rectifiable. Nevertheless, we show that by a new and adequate use of the satellite calibration data, one can perform a precise local stereo-rectification of large Earth images. Based on this we built a fully automatic 3D reconstruction chain for the new Pléiades Earth observation satellite. It produces 1/10 pixel accurate Earth image stereo pairs at a high resolution. Examples will be made available online to the computer vision community.	3d reconstruction;algorithm;computer stereo vision;computer vision;google earth;image rectification;image resolution;pattern matching;pixel	Carlo de Franchis;Enric Meinhardt;Julien Michel;Jean-Michel Morel;Gabriele Facciolo	2014	2014 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2014.7026102	computer stereo vision;stereo cameras;stereo camera;computer vision;computer science;epipolar geometry	Vision	55.20768895777838	-47.68519623311753	122395
f3ea13beb6678913a1677bad00c536e9bfa068ee	deforming a high-resolution mesh in real-time by mapping onto a low-resolution physical model	high resolution;ucl;surgical simulation;real time;low resolution;discovery;theses;conference proceedings;digital web resources;ucl discovery;open access;ucl library;soft tissue;book chapters;physical model;open access repository;ucl research	For interactive surgical simulation the physical model of the soft tissue needs to be solved in real-time. This limits the attainable model density to well below the desired mesh density for visual realism. Previous work avoids this problem by using a high-resolution visual mesh mapped onto a low-resolution physical model. We apply the same approach and present an computationally cheap implementation of a known algorithm to avoid texture artefacts caused by the mapping. We also introduce a spline-based algorithm to prevent groups of high-resolution vertices, mapped to the same low-resolution triangle, from exhibiting movements in which the underlying low-resolution structure can be recognised. The resulting mapping algorithm is very efficient, mapping 54,000 vertices in 8.5 ms on the CPU and in 0.88 ms on the GPU. Consequently, the density of the high-resolution visual mesh is limited only by the detail of the CT data from which the mesh was generated.	real-time clock	Hans de Visser;Olivier Comas;David Conlan;Sébastien Ourselin;Josh Passenger;Olivier Salvado	2008		10.1007/978-3-540-70521-5_15	simulation;image resolution;computer science;artificial intelligence;database;t-vertices;algorithm;computer graphics (images)	Graphics	67.96876670797549	-47.48588659694801	122536
eac34cc1b966a8f9a1bb4545d637ba0a07bd8298	relative kinematics of an anchorless network		Abstract The estimation of the coordinates of nodes their proximity (or distance) measurements, is a principal challenge in numerous fields. Conventionally, when localizing a static network of immobile nodes, non-linear dimensionality reduction techniques are applied on the measured distances to obtain the relative coordinates up to a rotation and translation. In this article, we consider an anchorless network of mobile nodes, where the distance measurements between the mobile nodes are time-varying. In such an anchorless framework, where the absolute knowledge of any node position, motion or reference frame is absent, we aim to estimate the relative positions using the measured time-varying distances. To this end, we derive a data model which relates the time-varying distances to the time-varying relative positions of an anchorless network. Given this data model, we estimate the relative (position, velocity) and higher order derivatives, which are collectively termed as the relative kinematics of the anchorless network. The derived data model is inherently ill-posed, however under certain immobility constraints, we propose closed-form solutions to recursively estimate the relative kinematics. For the sake of completeness, we also estimate the absolute node kinematics, given reference anchors. Theoretical bounds are derived, and simulations are conducted to benchmark the performance of proposed solutions.		Raj Thilak Rajan;Geert Leus;Alle-Jan van der Veen	2019	Signal Processing	10.1016/j.sigpro.2018.11.005	algorithm;mathematical optimization;completeness (statistics);reference frame;recursion;mathematics;data model;derived data;dimensionality reduction;kinematics	Robotics	56.80816187350437	-40.74208814531539	122759
289a64e0206a7c580b2315c43dee538339bcc16a	stream compaction for deferred shading	parallel sorting;prefix sum;cuda;gpgpu;ray tracing;stream compaction	The GPU leverages SIMD efficiency when shading because it rasterizes a triangle at a time, running the same shader on all of its fragments. Ray tracing sacrifices this shader coherence, and the result is that SIMD units often must run different shaders simultaneously resulting in serialization. We study this problem and define a new measure called heterogeneous efficiency to measure SIMD divergence among multiple shaders of different complexities in a ray tracing application. We devise seven different algorithms for scheduling shaders onto SIMD processors to avoid divergence. In all but simply shaded scenes, we show the expense of sorting shaders pays off with better overall shading performance.	algorithm;central processing unit;data compaction;deferred shading;graphics processing unit;raster graphics;ray tracing (graphics);simd;scheduling (computing);serialization;shader;sorting;vergence	Jared Hoberock;Victor Lu;Yuntao Jia;John C. Hart	2009		10.1145/1572769.1572797	parallel computing;real-time computing;computer science;deferred shading;computer graphics (images)	Arch	67.10586060834666	-51.76337349732584	122912
09771a8250fd8a2675efbc891d7ffad2c203f047	conveying 3d shape with texture: recent advances and experimental findings	high resolution;efficient algorithm;texture synthesis;shape perception;b spline surface;distortion;shape representation;principal directions;carrying capacity;vector field	If we could design the perfect texture pattern to apply to any smooth surface in order to enable observers to more accurately perceive the surface's shape in a static monocular image taken from an arbitrary generic viewpoint under standard lighting conditions, what would the characteristics of that texture pattern be? In order to gain insight into this question, our group has developed an efficient algorithm for synthesizing a high resolution texture pattern, derived from a provided 2D sample, over an arbitrary doubly curved surface in such a way that the orientation of the texture is constrained to follow a specified underlying vector field over the surface, at a per-pixel level, without evidence of seams or projective distortion artifacts. In this paper, we report the findings of a recent experiment in which we attempt to use this new texture synthesis method to assess the shape information carrying capacity of two different types of directional texture patterns (unidirectional and bi-directional) under three different orientation conditions (following the first principal direction, following a constant uniform direction, or swirling sinusoidally in the surface). In a four alternative forced choice task, we asked participants to identify the quadrant in which two B-spline surfaces, illuminated from different random directions and simultaneously and persistently displayed, differed in their shapes. We found, after all subjects had gained sufficient training in the task, that accuracy increased fairly consistently with increasing magnitude of surface shape disparity, but that the characteristics of this increase differed under the different texture orientation conditions. Subjects were able to more reliably perceive smaller shape differences when the surfaces were textured with a pattern whose orientation followed one of the principal directions than when the surfaces were textured with a pattern that either gradually swirled in the surface or followed a constant uniform direction in the tangent plane regardless of the surface shape characteristics. These findings appear to support our hypothesis that anisotropic textures aligned with the first principal direction may facilitate shape perception, for a generic view, by making more, reliable information about the extent of the surface curvature explicitly available to the observer than would be available if the texture pattern were oriented in any other way.	algorithm;anisotropic filtering;b-spline;binocular disparity;distortion;high-dynamic-range rendering;image resolution;pixel;texture synthesis	Victoria Interrante;Sunghee Kim;Haleh Hagh-Shenas	2002		10.1117/12.469515	computer vision;mathematics;geometry;engineering drawing	Vision	62.39264758531039	-44.34294893578682	123047
2597d44c253a803df0f4bcbb4169f4ce60161b4f	efficient culling techniques for interactive deformable nurbs surfaces on gpu	nurbs;deformable surfaces;real time and interactive methods;culling techniques;programvaruteknik	NURBS (Non-uniform rational B-splines) surfaces are the standard freeform representation in ComputerAided Design (CAD) applications. Rendering NURBS surfaces accurately while they are interactively manipulated and deformed is a challenging task. In order to achieve it, the elimination from pipeline in early stages of back-facing surfaces or surface pieces is a key advantage. Furthermore, an effective interactive manipulation implies that all the culling computations should be performed for each frame, facing the possibility of fast changes in occlusion information. In this paper, different interactive culling strategies for NURBS surfaces are presented and analyzed. These culling techniques are based on the exploitation of the geometric properties presented in a NURBS surface, that allow easily to find bounds for it in screen space for each frame. Furthermore, the culling overhead for our proposals is small compared to the computational saving, outperforming a proposal without culling. An implementation of these strategies using current GPUs is presented, achieving real-time and interactive rendering rates of complex parametric models.	collision detection;computation;computer-aided design;convex hull;directx;glossary of computer graphics;graphics processing unit;interactivity;non-uniform rational b-spline;overhead (computing);rasterisation;real-time clock;real-time computing;semiconductor consolidation;speedup	Raquel Concheiro;Margarita Amor;Emilio J. Padrón;Michael C. Doggett	2016		10.5220/0005677200150025	computer vision;non-uniform rational b-spline;computer science;computer graphics (images)	Graphics	66.87549655462045	-51.449045422148586	123270
1413d54d40efaef9b58d58950fd16d828d67608c	the modelcamera: a hand-held device for interactive modeling	image sampling;hand held device;frames per second;triangulated mesh modelcamera hand held scene modeling device interactive modeling computer graphics applications complex real world scenes digital video camera laser pointers image frame registration frame rendering;computer graphic;interactive systems image registration rendering computer graphics video cameras mesh generation image sampling;video cameras;laser pointer;image registration;layout laser modes computer graphics costs laser feedback application software digital cameras rendering computer graphics computer science pipelines;interaction model;digital video;quality model;rendering computer graphics;mesh generation;interactive systems	An important goal of automated modeling is to provide computer graphics applications with high quality models of complex real-world scenes. Prior systems have one or more of the following disadvantages: slow modeling pipeline, applicability restricted to small scenes, no direct color acquisition, and high cost. We describe a hand-held scene modeling device that operates at five frames per second and that costs $2,000. The device consists of a digital video camera with 16 laser pointers attached to it. As the operator scans the scene, the pointers cast blobs that are detected and triangulated to provide sparse, evenly spaced depth samples. The frames are registered and merged into an evolving model, which is rendered continually to provide immediate operator feedback.	color depth;computer graphics;digital video;display resolution;mobile device;polygon triangulation;sparse matrix	Voicu Popescu;Elisha Sacks;Gleb Bahmutov	2003		10.1109/IM.2003.1240261	mesh generation;computer vision;computer science;image registration;multimedia;frame rate;computer graphics (images)	Graphics	59.73321393104017	-50.62920563190448	123277
fe050fb398d99aca83947857ab18562b972d922c	progressive images: applying mesh processing to images	dual pieces;image feature hierarchy;progressive image;progressive mesh;image simplification	Recently the application of signal and image processing techniques to polygonal meshes has attracted much attention in graphics. In this paper, the interesting reverse direction is considered; application of mesh processing techniques to images. We present a multiresolution representation of an image, called a progressive image, which is based on the progressive mesh representation. By applying mesh simplification to an image, we obtain a continuous hierarchy of image features from large to small scales. Multiresolution detail representation and the concept of dual pieces play an important role in performing feature processing with a progressive image. We demonstrate that a progressive image can be successfully applied to graphics problems concerning images, such as high dynamic range compression and painterly rendering.	geometry processing	Yunjin Lee;Jong-Guk Im;Seungyong Lee	2006	International Journal of Shape Modeling	10.1142/S0218654306000901	computer vision;pyramid;feature detection;image processing;computer science;digital image processing;engineering drawing;t-vertices;computer graphics (images)	Vision	64.46565254896996	-46.81577482409266	123307
679c1b4c7f009d84b53c6611114b0b3cb6433100	point set surface editing techniques based on level-sets	point set surface;global scalar-field free-form deformation;manipulatethe point-set surface;powerful local surface editingand;free-form deformation;level-set methods;novel point-set methodology;global free-form;global editing;point set surface editing;sculpted point-set geometry;point-sampled geometry;inter- action techniques;point-sampled surface;geometric modeling;computational geometry;level set;computer science;solid modeling;computer graphics;least squares approximation;prototypes;scalar field;level set method;geometry;topology;digital topology	In this paper we articulate a new modeling paradigm for both local and global editing on complicated point set surfaces of arbitrary topology. In essence, the proposed technique leads to a novel point-set methodology that can unify the topological advantage of the level-set methods and the simplicity of point-sampled surfaces. Any user-specified region of a point set surface in our system can be embedded into a grid-based level-set framework. The super-imposed grid structure enables both powerful local surface editing and global scalar-field free-form deformation anywhere across the point-sampled geometry. Furthermore, the underlying level-set representation, coupled with the concept of digital topology, greatly facilitates the topological modification of the sculpted point-set geometry whenever necessary during shape deformation. We have developed a variety of editing toolkits that can allow users to directly manipulate the point-set surface through interactive sketching, smoothing, embossing, and global free-form deformations with ease. We demonstrate the usefulness and efficacy of our prototype system for the point-sampled geometry via many examples	algorithm;digital topology;embedded system;free-form deformation;graphics;haptic technology;image embossing;list of toolkits;programming paradigm;prototype;sampling (signal processing);smoothing;unsharp masking	Xiaohu Guo;Jing Hua;Hong Qin	2004	Proceedings Computer Graphics International, 2004.	10.1109/CGI.2004.1309192	computer vision;scalar field;computational geometry;computer science;level set;theoretical computer science;geometric modeling;mathematics;geometry;prototype;solid modeling;computer graphics;least squares;level set method;digital topology;computer graphics (images)	Graphics	66.74527440348612	-46.10926614816199	123453
1940457bd72b7f08382a8ac2c06e30ce58eea005	efficient storage and progressive rendering of multi-resolution mesh	graphics system;multi resolution;visual processing	A multi-resolution model often costs more storage space, its communications from the CPU to the graphics system is the bottleneck of the visualization process. In this paper, a multi-resolution mesh and a primitive are proposed. The primitive is used both in the storage stage and in the rendering stage, decreasing the storage size of model and the transmission amount of vertices to the graphics system. The efficiency is measured by means of tests and results compared with the previous, obtaining better storage space cost and transmission cost.		Tong-zhu Fang;Zheng Tian	2007		10.1007/978-3-540-77255-2_97	simulation;computer hardware;rendering;computer science;texture memory;software rendering;computer graphics (images)	Visualization	68.03224826864677	-50.972891502487116	123457
18cdaf5f89b3a4fa16efc38acc6dc2eb901b16e7	progressive virtual beam lights	i 3 7 computer graphics three dimensional graphics and realism ray tracing;simulation;i 6 8 simulation and modeling simulation monte carlo;i 3 7 computer graphics;ray tracing;i 6 8 simulation and modeling;three dimensional graphics and realism;monte carlo	A recent technique that forms virtual ray lights (VRLs) from path segments in media, reduces the artifacts common to VPL approaches in participating media, however, distracting singularities still remain. We present Virtual Beam Lights (VBLs), a progressive many-lights algorithm for rendering complex indirect transport paths in, from, and to media. VBLs are efficient and can handle heterogeneous media, anisotropic scattering, and moderately glossy surfaces, while provably converging to ground truth. We inflate ray lights into beam lights with finite thicknesses to eliminate the remaining singularities. Furthermore, we devise several practical schemes for importance sampling the various transport contributions between camera rays, light rays, and surface points. VBLs produce artifact-free images faster than VRLs, especially when glossy surfaces and/or anisotropic phase functions are present. Lastly, we employ a progressive thickness reduction scheme for VBLs in order to render results that converge to ground truth.	algorithm;clamping (graphics);converge;converged storage;ground truth;importance sampling;memory footprint;progressive scan;ray (optics);sampling (signal processing);thickness (graph theory);vpl research;virtual private lan service	Jan Novák;Derek Nowrouzezahrai;Carsten Dachsbacher;Wojciech Jarosz	2012	Comput. Graph. Forum	10.1111/j.1467-8659.2012.03136.x	ray tracing;computer vision;simulation;computer science;statistics;monte carlo method;computer graphics (images)	Graphics	62.9085206701656	-49.90325211637911	123458
f5c3650e6f2804a345ae3dd4ae2af96ca7c4c201	synchronization and self-calibration for helmet-held consumer cameras, applications to immersive 3d modeling and 360 video	360 video structure from motion bundle adjustment video synchronization surface reconstruction;cameras three dimensional displays image reconstruction distortion synchronization calibration approximation methods;surface reconstruction;distortion;video synchronization;three dimensional displays;synchronization;image reconstruction;approximation methods;360 video;structure from motion;calibration;cameras;bundle adjustment	This paper presents the first 3D reconstruction system using unsynchronized and helmet-held consumer cameras, without the use of a calibration pattern. Our assumptions are easy to meet in practice: the cameras have the same setting (frequency, image resolution, field-of-view, roughly equiangular). First, the time offsets between cameras are estimated without accurate calibration as input. Second, both inter-camera rotations and intrinsic parameters are refined using structure-from-motion and bundle adjustment. We experiment both synchronization and self-calibration on four GoPro cameras mounted on a helmet, such that the resulting multi-camera is assumed to be central and provides a 360 degree field-of-view in the horizontal plane. A surface is also estimated from a multi-camera video acquired by walking in a city.		Maxime Lhuillier;Thanh-Tin Nguyen	2015	2015 International Conference on 3D Vision	10.1109/3DV.2015.56	computer vision;simulation;computer science;three-ccd camera;computer graphics (images)	Vision	54.25824922274982	-47.6969688890267	123765
8169f045315f4e688013977162d1d35ce0dc0fd2	real-time cloth rendering with fiber-level detail		Modeling cloth with fiber-level geometry can produce highly realistic details. However, rendering fiber-level cloth models not only has a high memory cost but it also has a high computation cost even for offline rendering applications. In this paper we present a real-time fiber-level cloth rendering method for current GPUs. Our method procedurally generates fiber-level geometric details on-the-fly using yarn-level control points for minimizing the data transfer to the GPU. We also reduce the rasterization operations by collectively representing the fibers near the center of each ply that form the yarn structure. Moreover, we employ a level-of-detail strategy to minimize or completely eliminate the generation of fiber-level geometry that would have little or no impact on the final rendered image. Furthermore, we introduce a simple self-shadow computation method that allows lighting with self-shadows using relatively low-resolution shadow maps. We also provide a simple distance-based ambient occlusion approximation as well as an ambient illumination precomputation approach, both of which account for fiber-level self-occlusion of yarn. Finally, we discuss how to use a physical-based shading model with our fiber-level cloth rendering method and how to handle cloth animations with temporal coherency. We demonstrate the effectiveness of our approach by comparing our simplified fiber geometry to procedurally generated references and display knitwear containing more than a hundred million individual fiber curves at real-time frame rates with shadows and ambient occlusion.		Kui Wu;Cem Yuksel	2017	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2017.2731949	frame rate;rendering (computer graphics);artificial intelligence;computer vision;precomputation;computation;shadow mapping;computer science;data modeling;yarn;ambient occlusion	Graphics	66.03386566157668	-51.24497652958198	123799
7dd24da4b8d56eedb4a9f44e7cb9ed270a1d23a2	a comparison of ellipse fitting methods and implications for multiple-view geometry estimation	geometry;cost function equations shape approximation methods maximum likelihood estimation training;conceptual relationship ellipse fitting methods general multiple view geometry estimation problems	After summarising the conceptual relationship between some old and new techniques for fitting ellipses to data, we conduct a thorough experimental comparison of the discussed methods. The newer techniques promise consistency, unbiasedness, or hyper-accuracy, but our experiments reveal that in practice the performance of these estimators is difficult to distinguish from the performance of established estimators. Since the newer techniques could potentially be extended to other estimation problems, we discuss what implications our experimental findings have for solving more general multiple-view geometry estimation problems.	curve fitting;experiment;fits;fundamental matrix (computer vision);homography (computer vision);the australian;well-posed problem	Zygmunt L. Szpak;Wojciech Chojnacki;Anton van den Hengel	2012	2012 International Conference on Digital Image Computing Techniques and Applications (DICTA)	10.1109/DICTA.2012.6411722	econometrics;mathematical optimization;mathematics;statistics	Visualization	54.83417575186912	-49.94055234883459	123809
30c3525c00f6126abcfae20a7e211df830b28e1a	practical volumetric sculpting	implicit surface;shape estimation;iterative refinement;input device;design process;interactive sculpture;local deformations;scalar field;spatial relationships;binary tree	for rapid shape prototyping. The sculpted shape is the isosurface of a scalar field spatially sampled. The user can deposit material wherever he desires in space and then iteratively refine it, using a tool to add, remove, paint, or smooth some material. We allow the use of free-form tools that can be designed inside the application. We also propose a technique to mimic local deformations so that we can use the tool as a stamp to make imprints on an existing shape. We focus on the rendering quality too, exploiting lighting variations and environment textures that simulate good-quality highlights on the surface. Both greatly enhance the shape estimation, which is a crucial step in this iterative design process, in our opinion. The use of stereo also greatly eases the understanding of spatial relationships. Our current implementation is based on GLUT and can run the application both on Unix-based systems, such as Irix and Linux, and on Windows systems. We obtain interactive response times, strongly related to the size of the tool. The performance issues and limitations are discussed.	basic stamp;digital sculpting;irix;isosurface;iterative design;iterative method;linux;microsoft windows;opengl utility toolkit;simulation;unix	Eric Ferley;Marie-Paule Cani;Jean-Dominique Gascuel	2000	The Visual Computer	10.1007/PL00007216	spatial relation;computer vision;scalar field;design process;binary tree;computer science;artificial intelligence;geometry;quantum mechanics;input device;computer graphics (images)	HCI	65.38685354514976	-47.90137399745453	123964
823dcccf4180cb6b2ed1cc318e7e693008f3913b	approximating character biomechanics with real-time weighted inverse kinematics	character animation;real time;inverse kinematics	In this paper we show how the expensive, offline dynamic simulations of character motions can be approximated using the cheaper weighted inverse kinematics (WIK)-based approach. We first show how a dynamics-based approach can be used to produce a motion that is representative of a real target actor using the motion of a different source actor and the biomechanics of the target actor. This is compared against a process that uses WIK to achieve the same motion mapping goal without direct biomechanical input. The parallels between the results of the two approaches are described and further reasoned from a mathematical perspective. Thus we demonstrate how character biomechanics can be approximated with real-time WIK. Copyright © 2007 John Wiley & Sons, Ltd.	inverse kinematics;real-time clock	Michael Meredith;Steve C. Maddock	2007	Journal of Visualization and Computer Animation	10.1002/cav.191	character animation;computer vision;simulation;computer science;artificial intelligence;inverse kinematics;computer graphics (images)	Visualization	60.624407867679196	-45.2644336280145	124359
2b361dc42a6c2e57631d9a6ae4546a3a03596fd9	distance transforms for three-dimensional grids with non-cubic voxels	computer vision and robotics autonomous systems;fcc;image tridimensionnelle;bcc;grille cubique centree face;error function;cube;cubico;distance transformation;cubo;datorseende och robotik autonoma system;transformation distance;non cubic voxels;geometria discreta;three dimensional;voxel;euclidian distance;cubique;grille 3 dimensions;distance euclidienne;grille cubique centree corps;geometrie discrete;discrete geometry;funcion error;face centered cubic;tridimensional image;body centered cubic;voxel non cubique;fonction erreur;distance transform;transformacion distancia;cubics;imagen tridimensional;fcc bcc	Distance transforms on the face-centered cubic (fcc) grid and the body-centered cubic (bcc) grid are examined. Since the voxels on the fcc and bcc grids are better approximations of a Euclidean ball than the cube, the distance transforms (DTs) on these grids can be less rotation dependent than those in Z^3, which is a desirable feature. Optimal (according to the error function) weights are calculated and integer approximations of these weights are found. Also, the two-dimensional city block distance is generalized to the fcc and bcc grids by considering a unit distance between gridpoints whose corresponding voxels share a face. A method to compute the DTs is presented. The results are evaluated both theoretically and by actually computing some DTs.	cubic function;voxel	Robin Strand;Gunilla Borgefors	2005	Computer Vision and Image Understanding	10.1016/j.cviu.2005.04.006	discrete geometry;combinatorics;cubic crystal system;topology;mathematics;geometry	Vision	66.69738856479422	-42.78530908512522	124385
b0dc0f4137253d7e21a04c183969912a873204d3	efficient raytracing of deforming point-sampled surfaces	edge detection;hierarchical systems;computational geometry;surface topography;data structures;animation;algorithmic languages;temporal coherence;data structure	We present efficient data structures and caching schemes to accelerate ray-surface intersections for deforming point-sampled surfaces. By exploiting spatial and temporal coherence of the deformation during the animation, we are able to improve rendering performance by a factor of two to three compared to existing techniques. Starting from a tight bounding sphere hierarchy for the undeformed object, we use a lazy updating scheme to adapt the hierarchy to the deformed surface in each animation step. In addition, we achieve a significant speedup for ray-surface intersections by caching per-ray intersection points. We also present a technique for rendering sharp edges and corners in point-sampled models by introducing a novel surface clipping algorithm.	algorithm;bounding sphere;cache (computing);coherence (physics);data structure;lazy evaluation;ray tracing (graphics);speedup	Bart Adams;Richard Keiser;Mark Pauly;Leonidas J. Guibas;Markus H. Gross;Philip Dutré	2005	Comput. Graph. Forum	10.1111/j.1467-8659.2005.00892.x	anime;computer vision;edge detection;data structure;computer science;theoretical computer science;geometry;programming language;algorithm;computer graphics (images)	Graphics	66.53536682630316	-50.824664222554986	124474
78c526192352fd1f9be83bde3f093cc4acaea553	the application of computer vision to the removal of tie-wires in a live-line maintenance robotics manipulation	image processing;perspective projection;three dimensional;computer vision;robot manipulator;image analysis	This paper presents a computer vision application for the detection of a tie-wire in a live-line maintenance operation for the replacement of insulators. The tie-wire is wrapped around the electrical conductor and must be unwrapped by a special tool fixed to the end effector of a manipulator. The computer vision algorithm uses pyramidal image reduction, edge image analysis, and inverse perspective projection to count the number of tie-wire turns around the conductor and compute the three-dimensional coordinates of each turn (or the distance between adjacent turns).	3d projection;algorithm;computer vision;fly-by-wire;image analysis;robot end effector;robotics	Denis Laurendeau;Y. Trottier;Denis Poussart;Jean Lessard	1990	Machine Vision and Applications	10.1007/BF01240387	neighborhood operation;three-dimensional space;computer vision;feature detection;perspective;image analysis;simulation;image processing;computer science;computer graphics (images)	Vision	61.873737031993336	-39.7106838316402	124496
b3a7c34b2f08f18b1b0237d0bc8d0b8f17ef494c	evaluation of registration methods for sparse 3d laser scans	three dimensional displays trajectory measurement iterative closest point algorithm accuracy optimization buildings;measurement;pose estimation 3d laser scans registration method autonomous micro aerial vehicle mav light weight 3d laser scanner omnidirectional obstacle perception local egocentric map collision avoidance 3d mapping;accuracy;trajectory;three dimensional displays;optimization;pose estimation autonomous aerial vehicles collision avoidance image registration optical scanners;iterative closest point algorithm;buildings	The registration of 3D laser scans is an important task in mapping applications. For the task of mapping with autonomous micro aerial vehicles (MAVs), we have developed a light-weight 3D laser scanner. Since the laser scanner is rotated quickly for fast omnidirectional obstacle perception, the acquired point clouds are particularly sparse and registration becomes challenging. In this paper, we present a thorough experimental evaluation of registration algorithms in order to determine the applicability of both the scanner and the registration algorithms. Using the estimated poses of the MAV, we aim at building local egocentric maps for both collision avoidance and 3D mapping. We use multiple metrics for assessing the quality of the different pose estimates and the quality of the resulting maps. In addition, we determine for all algorithms optimal sets of parameters for the challenging data. We make the recorded datasets publicly available and present results showing both the best suitable registration algorithm and the best parameter sets as well as the quality of the estimated poses and maps.	3d film;3d scanner;aerial photography;algorithm;autonomous robot;ground truth;map;mathematical optimization;motion capture;point cloud;sparse matrix;surfel;velocity obstacle;visual odometry;mpv	Jan Razlaw;David Droeschel;Dirk Holz;Sven Behnke	2015	2015 European Conference on Mobile Robots (ECMR)	10.1109/ECMR.2015.7324196	computer vision;simulation;trajectory;accuracy and precision;measurement;statistics	Robotics	54.177634782942455	-41.77048244135015	124501
0a86eff6051151bae60039fd3ccb081824b63de7	a cad system for color design of a car	color design;realistic image;crt monitor;parallel computer	We have developed a color CAD system which enables a color designer to evaluate and create body colors of a car on a graphic display and put this system into practical use. The system has three features ; generating realistic images comparable to photography to satisfy the car designer's needs, through close analysis of the physical phenomena taking place in the real environment, reproducing the desired colors very accurately on a CRT monitor, through analysis of the CRT colorimetric characteristics of reproducing the specified colors in response to the input signals, and utilizing a parallel computer to generate realistic images at a high speed and to control colors through interactive operation. Application of the CAD system reported here to the field of color design made it possible to fully evaluate and create body colors by means of computer graphics,replacing the conventional method which requires the painting of clay models or prototype cars.	caddie;cathode ray tube;color;computer graphics;computer monitor;computer-aided design;parallel computing;prototype	Tetsuya Oshima;Shinji Yuasa;Ken-ichi Sakanoshita;Yoshinori Ogata	1992	Comput. Graph. Forum	10.1111/1467-8659.1130381	cathode ray tube;computer vision;simulation;color quantization;computer science;computer graphics (images)	Graphics	64.44237070580616	-50.95322032723584	124601
3e05853345552ad5f5528c305989cdecdeec417d	characterization and detection of building patterns in cartographic data: two algorithms	graph theory;delaunay triangulation;spatial data mining;minimum spanning tree;pattern recognition	Building patterns are important features in applications like automated generalization and spatial data mining. Many previous work has however focused on a few specific patterns (i.e. collinear pattern), while many others are less discussed. This paper proposes a comprehensive typology of available building patterns through the study of existing maps, and discusses their characteristics. This typology includes collinear, curvilinear, align-along-road, grid-like and unstructured patterns. Two algorithms are presented to detect align-along-road and unstructured building patterns, which are tested against a topographic dataset of the Netherlands.	algorithm;align (company);biological anthropology;data mining;map;topography	Xiang Zhang;Tinghua Ai;Jantien E. Stoter	2010		10.1007/978-3-642-25926-5_8	combinatorics;machine learning;pattern recognition;mathematics;bowyer–watson algorithm	ML	59.56383527296351	-44.39322801096396	124625
3b4f75df9f4e62e8f1eaf8b765649d2164b330ad	fusing the real and the virtual: a depth-camera based approach to mixed reality	kinect mixed reality augmented reality image based lighting occlusions depth camera;image based lighting;depth camera;edge detection;smoothing method;low frequency;real time;virtual reality;kinect;dynamic environment;smoothing methods;image edge detection;image color analysis;image edge detection image color analysis smoothing methods lighting cameras virtual reality real time systems;lighting;augmented reality;mixed reality;off the shelf;occlusions;cameras;real time systems	The seamless integration of the real and the virtual content is the ultimate yet unreached goal of Mixed Reality applications. Among others it requires mutual blocking and lighting between real and virtual objects. In this paper we present our approach of applying a low-cost depth camera, such as Kinect, allowing for an easy acquisition of depth images. However, as the quality of the raw input data is insufficient for this purpose, we apply a series of filter and optimization operations. This allows us to realize mutual real-time lighting and rigid interaction in a dynamic environment. Our approach produces an acceptable quality of images of low-frequency scenes at interactive frame rates on an off-the-shelf desktop computer.	blocking (computing);desktop computer;kinect;mathematical optimization;mixed reality;real-time clock;seamless3d	Philipp Lensing;Wolfgang Broll	2011	2011 10th IEEE International Symposium on Mixed and Augmented Reality	10.1109/ISMAR.2011.6143892	computer vision;augmented reality;edge detection;computer science;lighting;virtual reality;mixed reality;multimedia;low frequency;image-based lighting;computer graphics (images)	Visualization	59.2074855473806	-50.21403057985148	124855
9752a25ccb872895a823bb2515bd648f22d63c0d	image-based lighting	rendering computer graphics lighting layout microscopy probes cameras computer graphics pixel solid modeling dynamic range;reflection mapping technique image based lighting realistic rendered appearances real world illumination light probe image synthetic objects real world scene;rendering computer graphics realistic images;realistic images;rendering computer graphics	This tutorial shows how image-based lighting can illuminate synthetic objects with measurement of real light, making objects appear as if they're actually in a real world scene.	image-based lighting	Paul E. Debevec	2002	IEEE Computer Graphics and Applications	10.1109/38.988744	high-dynamic-range rendering;computer vision;tiled rendering;scientific visualization;2d computer graphics;image-based modeling and rendering;3d rendering;rendering;computer science;volumetric lighting;computer graphics lighting;real-time computer graphics;multimedia;real-time rendering;computer graphics;per-pixel lighting;alternate frame rendering;global illumination;software rendering;3d computer graphics;image-based lighting;computer graphics (images)	Visualization	63.375202506732506	-51.02578612455316	124935
041edc9023dc1607763a028e37ab5eb7bb543796	geodesic distance descriptors		The Gromov-Hausdorff (GH) distance is traditionally used for measuring distances between metric spaces. It was adapted for non-rigid shape comparison and matching of isometric surfaces, and is defined as the minimal distortion of embedding one surface into the other, while the optimal correspondence can be described as the map that minimizes this distortion. Solving such a minimization is a hard combinatorial problem that requires precomputation and storing of all pairwise geodesic distances for the matched surfaces. A popular way for compact representation of functions on surfaces is by projecting them into the leading eigenfunctions of the Laplace-Beltrami Operator (LBO). When truncated, the basis of the LBO is known to be the optimal for representing functions with bounded gradient in a min-max sense. Methods such as Spectral-GMDS exploit this idea to simplify and efficiently approximate a minimization related to the GH distance by operating in the truncated spectral domain, and obtain state of the art results for matching of nearly isometric shapes. However, when considering only a specific set of functions on the surface, such as geodesic distances, an optimized basis could be considered as an even better alternative. Moreover, current simplifications of approximating the GH distance introduce errors due to low rank approximations and relaxations of the permutation matrices. Here, we define the geodesic distance basis, which is optimal for compact approximation of geodesic distances, in terms of Frobenius norm. We use the suggested basis to extract the Geodesic Distance Descriptor (GDD), which encodes the geodesic distances information as a linear combination of the basis functions. We then show how these ideas can be used to efficiently and accurately approximate the metric spaces matching problem with almost no loss of information. We incorporate recent methods for efficient approximation of the proposed basis and descriptor without actually computing and storing all geodesic distances. These observations are used to construct a very simple and efficient procedure for shape correspondence. Experimental results show that the GDD improves both accuracy and efficiency of state of the art shape matching procedures.	approximation algorithm;basis function;computation;computational complexity theory;dimensionality reduction;distance (graph theory);distortion;game design document;generalized multidimensional scaling;gradient;hausdorff dimension;isometric projection;linear programming relaxation;low-rank approximation;map;matrix multiplication;maxima and minima;precomputation;shape context;spectral method;truncation	Gil Shamai;Ron Kimmel	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2017.386	combinatorics;topology;mathematics;geometry	Vision	61.224634446327116	-41.95275350421567	125289
e7828f7b0a669a40ba2ecc644485cbe10127896b	frequency domain estimation of 3-d rigid motion based on range and intensity data	robustness frequency domain estimation 3d rigid motion range data intensity data video rate registered range data sensor technology rigid motion parameter estimation 3d motion estimation optical flow fourier transform 3d intensity function registered time sequences unsupervised method memory occupancy data reduction 2d functions;memory occupancy;sensor technology;range data;fourier transform;video rate registered range data;unsupervised method;frequency domain analysis;2d functions;intensity data;frequency estimation;motion estimation;rigid motion parameter estimation;surface texture;estimation algorithm;registered time sequences;frequency domain analysis frequency estimation motion estimation fourier transforms parameter estimation robustness surface texture solids informatics optical sensors;3d rigid motion;image registration;fourier transforms;3d intensity function;robustness;informatics;optical flow;profitability;frequency domain estimation;optical sensors;data reduction;3d motion estimation;parameter estimation;frequency domain;solids;image sequences;data reduction frequency domain analysis motion estimation image registration parameter estimation image sequences fourier transforms	Video rate registered range and intensity data are at reach of current sensor technology This wealth of data can be pro tably exploited in order to estimate rigid motion parameters as the approaches to D motion estimation based on the optical ow of both types of data indicate This work introduces an alternative for D motion estimation based on the Fourier transform of the D intensity function implicitly described by the registered time sequences of range and intensity data The pro posed procedure can lead to an unsupervised method for D rigid motion estimation This method has several advantages related to the fact that it uses the total available information and not sets of features With respect to memory occupancy the use of a time sequence of a D intensity function represents a con siderable data reduction with respect to a pair of time sequences of D functions The proposed technique which extends to the D case previous frequency do main estimation algorithms developed for the planar case retain their robustness Introduction and problem statement Current sensor technology is able to supply real time sequences of registered image and intensity data This wealth of data can be pro tably exploited in order to estimate motion parameters as the methods of indicate This work proposes an original frequency domain tech nique for estimating the D rigid motion parameters with a number of potentially interesting characteris tics This method does not use features but the whole information given by a D textured surface to which the data are equivalent The use of a D textured surface is memory wise more e cient than using a D textured image jointly with a D range data image Furthermore the fact that this method is not based on features leaves open the possibility of using simpli ed structure models The use of the whole available infor mation makes this procedure very robust a property tipical of the D motion estimation techniques based on frequency domain Let x x IR be a D object and let x be a rigidly translated and rotated version of x these data can be obtained from registered range and intensity data captured at di erent times It can be shown that without lack of generality x and x relate as	algorithm;motion estimation;naruto shippuden: clash of ninja revolution 3;point process;time series;unsupervised learning	Luca Lucchese;Gianfranco Doretto;Guido M. Cortelazzo	1997		10.1109/IM.1997.603855	fourier transform;computer vision;speech recognition;computer science;motion estimation;frequency domain;statistics	Robotics	60.646894655337015	-49.3924849261577	125311
fbbb55fcbbc0ed4be4c4b6a0dbd56deaa793391d	volumetric parameterization of complex objects by respecting multiple materials	complex objects;volumetric parameterization;higher order;tensor product;trivariate b spline modeling and generation;solid modeling;model acquisition for simulation;triangle mesh;harmonic function	In this paper we present a methodology to create higher order parametric trivariate representations such as B-splines or T-splines, from closed triangle meshes with higher genus or bifurcations. The input can consist of multiple interior boundaries which represent inner object material attributes. Fundamental to our approach is the use of a midsurface in combination with harmonic functions to decompose the object into a small number of trivariate tensor-product patches that respect material attributes. The methodology is applicable to thin solid models which we extend using the flexibility of harmonic functions and demonstrate our technique, among other objects, on a genus-1 pelvis data set containing an interior triangle mesh separating the cortical part of the bone from the trabecular part. Finally, a B-spline representation is generated from the parameterization. Keywords—trivariate b-spline modeling and generation; volumetric parameterization; model acquisition for simulation	b-spline;simulation;t-spline;triangle mesh;volumetric display	Tobias Martin;Elaine Cohen	2010	Computers & Graphics	10.1016/j.cag.2010.03.011	tensor product;mathematical optimization;harmonic function;higher-order logic;computer science;triangle mesh;mathematics;geometry;solid modeling	Graphics	68.06237639841578	-44.39269204032825	125459
1cc9f8ea2d32081356fa2e80fc21bc53edc7ec79	a pivotable head mounted camera system that is aligned by three-dimensional eye movements	degree of freedom;parallel mechanism;two degree of freedom;three dimensional;vestibulo ocular reflex;proof of concept;camera motion;eye movement;oculomotor;camera motion device;eye tracking;visual field;calibration;mobile user;health care	"""The first proof of concept of an eye movement driven head camera system was recently presented. This innovative device utilized voluntary and reflexive eye movements, which were registered by video-oculography and computed online, as signals to drive servo motors which then aligned the camera along the user's gaze direction. However, with just two degrees of freedom, this camera motion device could not compensate for roll motions around the optical axis of the system. Therefore a new three-degree-of-freedom camera motion device that is able to reproduce the whole range of possible eye movements has now been implemented. In doing so, it allows a freely mobile user to aim the optical axis of the head mounted camera system at the target(s) in the visual field at which he/she is looking, while the ocular reflexes minimize image shaking by naturally counter-rolling the """"gaze in space"""" of the camera during head and visual scene movements as well as during locomotion. A camera guided in this way mimics the natural exploration of a visual scene and acquires video sequences from the perspective of a mobile user, while the oculomotor reflexes naturally stabilize the camera on target during head and target movements. Various documentation and teaching applications in health care, industry, and research are conceivable. This work presents the implementation of the new camera motion device and its, integration into a head camera setup including the eye tracking device."""	apache axis;documentation;eye tracking;servo;tracking system;video-oculography	Philipp Wagner;Klaus Bartl;Wolfgang Günthner;Erich Schneider;Thomas Brandt;Heinz Ulbrich	2006		10.1145/1117309.1117354	stereo camera;computer vision;camera auto-calibration;simulation;geography;eye tracking;eye tracking on the iss;optics	HCI	56.892637412603975	-42.933531772880336	125636
1feb75519f1491f95b78c2e09a16442c54ce23e2	geometric texture synthesis and transfer via geometry images	geometry images;texture synthesis;image texture;qa75 electronic computers computer science;texture transfer;qa76 computer software	In this paper, we present an automatic method which can transfer geometric textures from one object to another, and can apply a manually designed geometric texture to a model. Our method is based on geometry images as introduced by Gu et al. The key ideas in this method involve geometric texture extraction, boundary consistent texture synthesis, discretized orientation and scaling, and reconstruction of synthesized geometry. Compared to other methods, our approach is efficient and easy-to-implement, and produces results of high quality.	discretization;display resolution;image scaling;texture synthesis	Yu-Kun Lai;Shi-Min Hu;D. X. Gu;Ralph R. Martin	2005		10.1145/1060244.1060248	bidirectional texture function;image texture;computer vision;computer science;texture atlas;texture compression;texture synthesis;texture filtering;projective texture mapping;computer graphics (images)	Graphics	67.20826085141012	-45.718211680730576	126290
8d5da58f9779f004acc7e5b31ae2b75216e4a6ec	smooth statistical modeling of bivariate non-monotonic data by a three-stage lut neural system		The present paper introduces a new statistical data modeling algorithm based on artificial neural systems. This procedure allows abstracting from datasets by working on their probability density functions. The proposed method strives to capture the overall structure of the analyzed data, exhibits competitive computational runtimes and may be applied to non-monotonic real-world data (building on a previously developed isotonic neural modeling algorithm). An outstanding feature of the proposed method is the ability to return a smoother model compared to other modeling algorithms. Smooth models could have applications in the fields of engineering and computer science. In fact, the present research was motivated by an image contour resampling problem that arises in shape analysis. The features of the proposed algorithm are illustrated and compared to the features of existing algorithms by means of numerical tests on shape resampling.	3d modeling;algorithm;artificial neural network;bivariate data;command-line interface;computation;computer science;cubic hermite spline;cubic function;data modeling;emoticon;interpolation;isotonic regression;lifting scheme;lookup table;matlab;model m keyboard;numerical analysis;shape analysis (digital geometry);spline (mathematics);stationary process;statistical model;time complexity	Simone G. O. Fiori;Nicola Fioranelli	2017	Neural Computing and Applications	10.1007/s00521-017-3215-1	machine learning;artificial intelligence;bivariate analysis;probability density function;shape analysis (digital geometry);data modeling;resampling;monotonic function;statistical model;computer science;lookup table	ML	62.7684996866462	-44.83356287048644	126296
54e60c4c4705076ea4d7439a31df13fb5981b4bf	stochastic glossy global illumination on the gpu	shadow mapping;texture synthesis;moving texture;surface geometry;global illumination;graphic processing unit;importance sampling;vector field	This paper presents an algorithm for the glossy global illumination problem, which runs on the Graphics Processing Unit (GPU). In order to meet the architectural limitations of the GPU, we apply randomization in the iteration scheme. Randomization allows to use that set of the possible light interactions, which can be efficiently computed by the GPU, and makes it unnecessary to read back the result to the CPU. Instead of tessellating the surface geometry, the radiance is stored in texture space, and is updated in each iteration. The visibility problem is solved by hardware shadow mapping after hemicube projection. The shooter of the iteration step is selected by a custom mipmapping scheme, realizing approximate importance sampling. The variance is further reduced by partial analytic integration.	approximation algorithm;central processing unit;global illumination;graphics processing unit;hemicube (computer graphics);importance sampling;interaction;iteration;iterative method;mipmap;sampling (signal processing);shadow mapping;texture mapping;visibility (geometry)	Attila Barsi;László Szirmay-Kalos;Gábor Szijártó	2005		10.1145/1090122.1090153	computer vision;mathematical optimization;vector field;importance sampling;mathematics;shadow mapping;global illumination;texture synthesis;statistics;computer graphics (images)	Vision	66.05886622310476	-51.43327689650223	126398
d04a77f307e6e99291a7f848dde27665ece49fa4	extending gklt tracking - feature tracking for controlled environments with integrated uncertainty estimation	kanade lucas tomasi;feature tracking;prior knowledge;uncertainty estimation	Guided Kanade-Lucas-Tomasi (GKLT) feature tracking offers a way to perform KLT tracking for rigid scenes using known camera parameters as prior knowledge, but requires manual control of uncertainty. The uncertainty of prior knowledge is unknown in general. We present an extended modeling of GKLT that overcomes the need of manual adjustment of the uncertainty parameter. We establish an extended optimization error function for GKLT feature tracking, from which we derive extended parameter update rules and a new optimization algorithm in the context of KLT tracking. By this means we give a new formulation of KLT tracking using known camera parameters originating, for instance, from a controlled environment. We compare the extended GKLT tracking method with the original GKLT and the standard KLT tracking using real data. The experiments show that the extended GKLT tracking performs better than the standard KLT and reaches an accuracy up to several times better than the original GKLT with an improperly chosen value of the uncertainty parameter.	algorithm;experiment;kanade–lucas–tomasi feature tracker;mathematical optimization;microsoft outlook for mac;motion estimation;precondition;tomasi–kanade factorization;uncertainty principle	Michael Trummer;Christoph Munkelt;Joachim Denzler	2009		10.1007/978-3-642-02230-2_47	computer vision;computer science;machine learning;data mining	Vision	53.952475931989724	-41.092541137612535	126420
b8d00a176e656196c4fce9e7b3c428b6fe56606e	assessing the influence of temperature variations on the geometrical properties of a low-cost calibrated camera system by using computer vision procedures	analytical camera model;temperature variations;camera calibration;intrinsic parameters;extrinsic parameters	This paper estimates temperature influence on geometrical properties of both a single camera and a calibrated camera system, assuming low-cost CCD cameras. It does not cover the effect of temperature on the camera’s electronics. Firstly, the influence of temperature change on camera parameters was modelled and integrated into an existing analytical camera model. A modified camera model enables quantitative assessment regarding the influence of temperature variations for a single camera. Temperature variations also directly influence the accuracies of calibrated cameras. The inability to analytically determine the calibration method error magnitude, led us to experimentally estimate errors regarding calibrated cameras. Finally, the total error regarding calibrated cameras was derived by combining the numerical error of the calibration method with those errors originating from temperature variations. The results show that the influence of temperature variations decreases when increasing the distances of the observed objects from the cameras. On a typical building site, the temperature influence is reflected in the image as an error of less than one pixel.	camera resectioning;charge-coupled device;computer vision;experiment;linear model;numerical analysis;numerical error;outline of object recognition;pixel	Peter Podbreznik;Bozidar Potocnik	2011	Machine Vision and Applications	10.1007/s00138-011-0330-3	computer vision;camera auto-calibration;camera resectioning;computer science	Vision	56.4709616815938	-49.09399662572507	126428
17b30cf446a0e2eea2cfabb60fdc223be6a692e0	warping of a spherical representation of image-based models on gpu	real time;texture mapping;image interpolation;gpu;image based modeling;spherical depth image;image based rendering;pre warping;image warping	Image warping techniques are frequently used to render 3D scenes from images with depth information for VR applications. In this paper, we first propose a spherical representation of image-based models call the Spherical Depth Image (SDI). With two Warping Equations, at runtime we then pre-warp the image onto a view-dependent plane to get an intermediate image, which is further rendered onto the target image plane using standard texture mapping. Compared with other representations, SDI is sampled uniformly and completely, therefore it can reduce much unnecessary rendering overhead and the resultant rendered image is hole-free. To speed up the computation and utilize hardware's rasterization function for image interpolation, we transport the pre-warping process into GPU's Vertex Shader. Besides, high quality rendering effect in Pixel Shader can also be achieved as traditional geometry based methods. Finally, we overcome the approach's limitation of viewing region, and design a real-time walkthrough system with LOD representations of the SDIs.	cognitive walkthrough;computation;display resolution;graphics processing unit;image plane;image warping;interpolation;overhead (computing);pixel;rasterisation;real-time transcription;resultant;run time (program lifecycle phase);shader;texture mapping	Jiaofeng Zhu;Youquan Liu;Kai Bao;Yuanzhang Chang;Enhua Wu	2009		10.1145/1670252.1670272	image warping;image texture;texture mapping;image restoration;computer vision;feature detection;image-based modeling and rendering;binary image;image processing;computer science;theoretical computer science;image-based lighting;image scaling;computer graphics (images)	Graphics	66.19525628748984	-51.194364013448464	126510
08e13cfc2643c76a049357d436423054b7e6ad99	sub-pixel shadow mapping	shadow mapping;participating media;shadows;aliasing;real time;area lights;voxelization	The limited resolution of shadow maps may result in erroneous shadowing, yielding artificially jagged edges (Figure 1) and temporally crawling shadows even using perspective optimization techniques. Dai et al. [2008] propose an explicit storage of geometry within shadow map texels to avoid aliasing. Each texel stores the coordinates of the closest triangle only, potentially leading to false negatives in the intersection computation while incurring large memory consumption. These artifacts are reduced by intersecting the triangles stored in numerous neighboring texels, resulting in significant performance hit while still missing some intersections.  We introduce Sub-Pixel Shadow Maps (SPSM) for real-time shadow mapping with sub-pixel precision. Our technique is based on the storage of a fixed-size partial representation of the scene geometry using conservative rasterization, combined with an original reconstruction of shadow edges.	aliasing;computation;map;mathematical optimization;pixel;rasterisation;real-time clock;shadow mapping;texel (graphics)	Pascal Lecocq;Pascal Gautron;Jean-Eudes Marvie;Gaël Sourimant	2013		10.1145/2504459.2504483	aliasing;computer vision;shadow;computer science;shadow mapping;shadow volume;computer graphics (images)	Graphics	66.19629228703992	-51.33009635671172	126557
0138bdb8fa2e6dbd5f6f8ca3d8f83eafb09b0b9e	manufacturing feature instances: which ones to recognize?	integrated feature based systems;combinatorics;user defined features;computational geometry;interactive feature manipulation;algebraic geometry;computational complexity;feature extraction;computer aided manufacturing;manufacturing;algorithms;technical report;design by features;geometric constraints;systems integration methodology;manufacturing system;computer integrated manufacturing	Manufacturing features and feature-based representations have become an integral part of research on manufacturing systems, largely due to their ability to model correspondences between design information and manufacturing operations. However, several research challenges still must be addressed in order to place feature technologies into a solid scientific and mathematical framework. One challenge is the issue of alternatives in feature-based planning. Even after one has decided upon an abstract set of features to use for representing manufacturing operations, the set of feature instances used to represent a part is by no means unique. For a complex part, many (sometimes infinitely many) different manufacturing operations can potentially be used to manufacture various portions of the part. Some of these feature instances will appear in useful manufacturing plans, and others will not. In order to reduce the number of alternative manufacturing plans that must be examined, we require a systematic means of specifying which feature instances are of interest. This paper addresses the issue of alternatives by introducing the notion of primary feature instances, which we contend are sufficient to generate all manufacturing plans of interest. To substantiate our argument, we describe how various instances in the primary feature set can be used to produce the desired plans. Furthermore, we discuss how this formulation overcomes computational difficulties faced by previous work, and present some complexity results for this approach in the domain of machined parts. “Also with: Nationaf Institute of Standards and Technology, Manufacturing Systems Integration Division Building 220, Room A-127, Gaithersburg, MD 20899. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advanta$e, the ACM copyright notice and the title of the publication and Its date appear, and notice is given that copying is by permission of the Association of Computing Machinery.To copy otherwise, or to republish, requires a fee and/or specific permission. Solid Modeling ’95, Salt Lake City, Utah USA	computation;feature recognition;floor and ceiling functions;solid modeling;system integration	Satyandra K. Gupta;William C. Regli;Dana S. Nau	1995		10.1145/218013.218052	feature extraction;algebraic geometry;computational geometry;computer science;technical report;theoretical computer science;machine learning;mathematics;computer-integrated manufacturing;manufacturing;computational complexity theory	Robotics	63.825879925435004	-41.29146223346054	127304
7ed9d1fb75d6108eb5ab61e3a6340fc6f7d54e76	a hardness measuring method based on hough fuzzy vertex detection algorithm	fuzzy c means algorithm;vickers hardness number fuzzy hough transform indentation;hough transforms hardness testing automatic testing vickers hardness indentation deformation edge detection physics computing fuzzy set theory;edge detection;detection algorithms pollution measurement surface contamination materials testing surface texture equations immune system manufacturing processes quality control manufactured products;automatic testing;indentation;fuzzy set theory;physics computing;vickers hardness;deformation;detection algorithm;hough transforms;hough transform;hardness testing;rough polished specimens automatic vickers hardness measurement hough fuzzy vertex detection algorithm surface contaminations specimen texture indentation edge pixels weighted fuzzy c means algorithm indentation deformation hardness test process local maximum detection specular polished specimens	This paper proposes the use of a new automatic Vickers hardness measuring method called Hough fuzzy vertex detection algorithm (HFVDA). To overcome the unavoidable effects of vertex detection due to surface contaminations or specimen texture, HFVDA transforms all the indentation edge pixels into the Hough space. Within the Hough space, a weighted fuzzy c-means algorithm along with local maximum detection is proposed to find the indentation edge lines. Inasmuch as indentation deformation usually occurs in the hardness test process, an approach that overcomes the measurement inaccuracy due to indentation deformation is also proposed in this paper. It shows that HFVDA is able to find the indentation vertices and calculate the hardness number with high accuracy for either specular-polished or rough-polished specimens.	algorithm;biological specimen;clustering high-dimensional data;computational hardness assumption;cubic function;fuzzy cognitive map;hough transform;linear equation;maxima and minima;nonlinear system;parabolic antenna;pixel;usability testing	Leehter Yao;Chih-Heng Fang	2006	IEEE Transactions on Industrial Electronics	10.1109/TIE.2006.874259	hough transform;indentation hardness;edge detection;computer science;mathematics;fuzzy set;forensic engineering;engineering drawing;deformation;vickers hardness test	Vision	60.288160044368134	-41.00338797985476	127352
5605434b47b852f438f147b1e726a87432f927c6	efficient texture mapping by homogeneous patch discovery	texture synthesis;mesh parameterization;texture mapping	Texture mapping algorithms use mesh parameterization methods to find an optimal map for the vertices of a 3D model in texture space. These techniques vary in the properties they try to optimize such as stretch and skewness of the texture when mapped onto the surface. While most of them do well in terms of quality, they tend to be computationally intensive for large mesh models, which limits their use in interactive applications. We propose a greedy alternative that is significantly faster than current algorithms and achieves comparable quality. We use a priority queue to store polygons and use tangential vectors to guide the texture over the surface. Our algorithm is simple to implement and can texture over a million polygons per second on a typical desktop. The algorithm does not impose any constraints on the mesh topology and we do not require the model to be cut into patches before texturing. Stretch and distortion measures are stable across models and are comparable to current algorithms. We also propose a method to generate self tile-able textures for use in conjunction with our texture mapping algorithm. We present qualitative and quantitative results in comparison with several other texture mapping algorithms. The efficiency and robustness of our algorithm makes it useful in interactive modeling applications and texture mapping large mesh models such as heritage monuments.	desktop computer;distortion;greedy algorithm;mesh networking;mesh parameterization;priority queue;texture mapping	R. Vikram Pratap Singh;Anoop M. Namboodiri	2012		10.1145/2425333.2425370	texture mapping;computer vision;mathematical optimization;displacement mapping;computer science;relief mapping;uvw mapping;texture atlas;texture compression;engineering drawing;texture filtering	Graphics	67.99193400502641	-46.33679648780008	127364
c85b7d4cc3523ed8a9e43f498587631133c1191b	fast visualization of complex 3d models using displacement mapping	point based rendering;real time;3d model;graphics hardware;triangle mesh;ray casting	We present a simple method to render complex 3D models at interactive rates using real-time displacement mapping. We use an octree to decompose the 3D model into a set of height fields and display the model by rendering the height fields using per-pixel displacement mapping. By simply rendering the faces of the octree voxels to produce fragments for ray-casting on the GPU, and with straightforward transformation of view rays to the displacement map’s local space, our method is able to accurately render the object’s silhouettes with very little special handling. The algorithm is especially suitable for fast visualization of high-detail point-based models, and models made up of unprocessed triangle meshes that come straight from range scanning. This is because our method requires much less preprocessing time compared to the traditional triangle-based rendering approach, which usually needs a large amount of computation to preprocess the input model into one that can be rendered more efficiently. Unlike the point-based rendering approach, the rendering efficiency of our method is not limited by the number of input points. Our method can achieve interactive rendering of models with more than 300 millions points on standard graphics hardware.	3d modeling;3d scanner;algorithm;aliasing;computation;displacement mapping;graphics hardware;graphics processing unit;heightmap;map;mipmap;octree;out-of-core algorithm;pixel;point in polygon;polygonal modeling;preprocessor;ray casting;real-time clock;rendering (computer graphics);texture atlas;texture memory;triangle mesh;voxel;work breakdown structure	The-Kiet Lu;Kok-Lim Low;Jianmin Zheng	2009		10.1145/1555880.1555891	computer vision;tiled rendering;unbiased rendering;simulation;image-based modeling and rendering;3d rendering;rendering;computer science;triangle mesh;parallel rendering;ray casting;real-time rendering;texture memory;alternate frame rendering;graphics hardware;volume rendering;software rendering;computer graphics (images)	Graphics	67.21369891087447	-50.81535421734731	127403
ed1125050aeb587e1294c408760afebe1b78c385	advances towards next-generation flexible multi-projector display walls	tiled display;high resolution;photometric calibration;large scale;geometric calibration;reconfigurable displays;next generation;ubiquitous pixels;multi projector displays;tiled displays	Multi-projector displays provide a large-scale and a high-resolution view at the same time. Today, projectors are commodity products, making such displays are affordable, but several challenges must be overcome in order to make this technology available to everyday users. We present several advances in the area of multiprojector displays. These employ projectors with enhanced capabilities, methodologies for efficiently and inexpensively calibrating and maintaining displays composed of these units, and the ability to handle imperfect and uncalibrated devices when performing geometric and photometric registration of imagery across multiple projectors. These are the first steps in realizing the goal of truly ubiquitous pixels, where users can be completely oblivious to the type and number of devices providing the display.	image resolution;movie projector;pixel;video projector	Ezekiel S. Bhasker;Ray Juang;Aditi Majumder	2007		10.1145/1278240.1278251	computer vision;simulation;image resolution;computer science;computer graphics (images)	HCI	55.22244029552894	-45.469932806402554	127583
1df329c7cca483ed3b3f9354666d5716b5bcd4b5	robust generation of 3d models from video footage of urban scenes		There are a large number of potential applications for a system that is capable of automatically reconstructing texture–mapped 3D models directly from video footage of a scene. The structure from motion problem has been the focus of a great deal of research effort in recent years, however the subsequent creation of surface meshes from the sparse 3D point clouds produced by structure from motion algorithms has received much less attention. If the goal of a fully automated model generation system is to be realised, then a reliable method of fitting surface meshes to these point clouds must be found. This thesis presents work concerning the construction and improvement of surface meshes, using the data generated by structure from motion algorithms, with a view to the creation of a system capable of automatically generating 3D models directly from video footage of large–scale urban scenes. A technique for robustly creating surface meshes from sparsely populated 3D point clouds is presented. Image–consistent triangulation is used within the framework of a simulated annealing algorithm to iteratively modify an initial naive mesh. This method copes well with data contaminated by outliers, it produces a simplified mesh, particularly for urban scenes where planar surfaces are prevalent, and it is likely to converge successfully to a global minimum. The algorithm is shown to be capable of producing meshes that accurately represent the scene even in the presence of significant numbers of outliers. Because the meshing technique is reliant on the scene being sufficiently represented by points, a method for augmenting the initial point clouds is developed. By exploiting the presence of adjacent planar facets in the scene, new points are added to the point cloud in crucial areas such as along edges and on corners. This method proceeds by robustly identifying, and fitting planes to, sets of coplanar points in the point cloud. Suitable candidate plane–pairs are identified and points are created along the lines of intersection. A number of measures are necessary to ensure that only valid intersections are made and that the resulting points lie on the surface of the scene. Additionally, a new robust estimation algorithm is created to address a number of issues associated with identifying multiple populations of coplanar points where points may be shared between populations. It is shown that point clouds augmented in this way prior to meshing can, depending on the prior representation by the initial point cloud, result in substantially higher quality models being produced.	3d modeling;algorithm;converge;maxima and minima;point cloud;polygon mesh;population;simulated annealing;sparse matrix;structure from motion;texture mapping	Oliver Daniel Cooper	2005				Vision	56.05809230481759	-46.160724518226736	127612
2673286c31753c2d8d90aa4fea27aaa763af2976	inverse volume rendering with material dictionaries	scattering;inverse rendering;material dictionaries	Translucent materials are ubiquitous, and simulating their appearance requires accurate physical parameters. However, physically-accurate parameters for scattering materials are difficult to acquire. We introduce an optimization framework for measuring bulk scattering properties of homogeneous materials (phase function, scattering coefficient, and absorption coefficient) that is more accurate, and more applicable to a broad range of materials. The optimization combines stochastic gradient descent with Monte Carlo rendering and a material dictionary to invert the radiative transfer equation. It offers several advantages: (1) it does not require isolating single-scattering events; (2) it allows measuring solids and liquids that are hard to dilute; (3) it returns parameters in physically-meaningful units; and (4) it does not restrict the shape of the phase function using Henyey-Greenstein or any other low-parameter model. We evaluate our approach by creating an acquisition setup that collects images of a material slab under narrow-beam RGB illumination. We validate results by measuring prescribed nano-dispersions and showing that recovered parameters match those predicted by Lorenz-Mie theory. We also provide a table of RGB scattering parameters for some common liquids and solids, which are validated by simulating color images in novel geometric configurations that match the corresponding photographs with less than 5% error.	coefficient;color;dictionary;gnu nano;mathematical optimization;minimally invasive education;monte carlo method;scattering parameters;simulation;slab allocation;stochastic gradient descent;volume rendering	Ioannis Gkioulekas;Shuang Zhao;Kavita Bala;Todd E. Zickler;Anat Levin	2013	ACM Trans. Graph.	10.1145/2508363.2508377	mathematical optimization;simulation;optics;scattering;computer graphics (images)	Graphics	61.49593395545545	-51.709633730590774	127729
e6d9865add9ce2a650e9da06e1013e1318cd2f08	planar spirals that match g2 hermite data	hermite interpolation;image processing;geometrie algorithmique;interpolation hermite;computational geometry;procesamiento imagen;pairing;traitement image;algorithme;algorithm;interpolacion hermite;spirals;forme spirale;g 2;geometria computacional;spiral shape;emparejamiento;forma espiral;appariement;algoritmo	Abstract   A method for creating an extended spiral from a segment of a given spiral is described. The extended spiral can match a wider variety of  G  2  Hermite data in the plane than the given spiral. The extended spiral is composed of a segment of the given spiral and circular arcs joined to it in a  G  2  manner. Extended spirals created from some given spirals, such as the clothoid, can match any given  G  2  Hermite data that can be matched by a general spiral. Extended spirals created from other spirals, such as the Tschirnhausen cubic, can match a restricted set of the  G  2  Hermite data that can be matched by a general spiral.		Dereck S. Meek;Desmond J. Walton	1998	Computer Aided Geometric Design	10.1016/S0167-8396(97)00020-4	combinatorics;archimedean spiral;image processing;computational geometry;hermite interpolation;calculus;pairing;mathematics;geometry;spiral;algebra	EDA	66.69145938063284	-39.943510103312455	127842
5eb43d2c6d25342170bb8ca91dc8f1b725defda8	interactive approximate rendering of reflections, refractions, and caustics	environment maps;interactive recursive reflections;paper;optical refraction rendering computer graphics optical reflection layout lighting computer graphics ray tracing geometry costs hardware;raytracing;image caustics;algorithms computer graphics image enhancement image interpretation computer assisted imaging three dimensional lighting refractometry user computer interface;complex ray object intersections;computational geometry;gpu;interactive recursive refractions;object impostor technique;global illumination image rendering;object impostor technique interactive approximate rendering image caustics global illumination image rendering complex ray object intersections gpu iterative computing scheme interactive recursive reflections interactive recursive refractions;image texture;iterative methods;global illumination;interactive application;caustics;interactive rendering;ray tracing;rendering computer graphics computational geometry image texture iterative methods ray tracing realistic images;realistic images;iterative computing scheme;computer science;interactive approximate rendering;refraction;rendering computer graphics;reflection;gpu interactive rendering reflection refraction caustics;rendering	Reflections, refractions, and caustics are very important for rendering global illumination images. Although many methods can be applied to generate these effects, the rendering performance is not satisfactory for interactive applications. In this paper, complex ray-object intersections are simplified so that the intersections can be computed on a GPU, and an iterative computing scheme based on the depth buffers is used for correcting the approximate results caused by the simplification. As a result, reflections and refractions of environment maps and nearby geometry can be rendered on a GPU interactively without preprocessing. We can even achieve interactive recursive reflections and refractions by using an object-impostor technique. Moreover, caustic effects caused by reflections and refractions can be rendered by placing the eye at the light. Rendered results prove that our method is sufficiently efficient to render plausible images interactively for many interactive applications	alias;aliasing;approximation algorithm;buffers;caustic substance;caustics;computation (action);concave function;effective method;global illumination;graphics hardware;graphics processing unit;handling (psychology);interactive media;interactivity;intersection of set of elements;iterative method;level of detail;malignant fibrous histiocytoma;map;numerous;photon mapping;photons;physical object;pixel;preprocessor;ray tracing (graphics);recursion;reflection (computer graphics);reflection mapping;texel (graphics);z-buffering	Wei Hu;Kaihuai Qin	2007	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2007.14	ray tracing;computer vision;computational geometry;computer science;multimedia;computer graphics (images)	Visualization	65.46259769996443	-50.811432352506685	127924
1817e2285bfa850d01d92b65b0fd2e1525c727c9	scenegrok: inferring action maps in 3d environments	object semantics;3d scenes;scene understanding	With modern computer graphics, we can generate enormous amounts of 3D scene data. It is now possible to capture high-quality 3D representations of large real-world environments. Large shape and scene databases, such as the Trimble 3D Warehouse, are publicly accessible and constantly growing. Unfortunately, while a great amount of 3D content exists, most of it is detached from the semantics and functionality of the objects it represents. In this paper, we present a method to establish a correlation between the geometry and the functionality of 3D environments. Using RGB-D sensors, we capture dense 3D reconstructions of real-world scenes, and observe and track people as they interact with the environment. With these observations, we train a classifier which can transfer interaction knowledge to unobserved 3D scenes. We predict a likelihood of a given action taking place over all locations in a 3D environment and refer to this representation as an action map over the scene. We demonstrate prediction of action maps in both 3D scans and virtual scenes. We evaluate our predictions against ground truth annotations by people, and present an approach for characterizing 3D scenes by functional similarity using action maps.	3d computer graphics;3d reconstruction from multiple images;database;ground truth;map;sensor;sketchup 3d warehouse;statistical classification	Pat Hanrahan	2014	ACM Trans. Graph.	10.1145/2661229.2661230	computer vision;scene statistics;data mining;computer graphics (images)	Graphics	55.25187903506092	-45.837119900720026	127961
13998724ca32fc0b31acd65b547b91c26e968e31	fast polygonization of implicit surfaces	marching cube	Our work is centered on the use of implicit surfaces in intera ctive applications (at least 10 frames per sec) running on high-end consumer architectur e (modeling, simulation, deformable body animation, games). We focus on the Marching Cubes algorithm that we tried to implement in an optimized way. We restrict our wor k to blended iso-surfaces generated by skeletons, since this kind of implicit surface s is the most handy to use for animations. Our implementation optimizations deal with the following f eatures: simplifying the field function, accelerating its evaluation for each point (voxe l-based technique), generating automatically the triangles for any case of the Marching Cub es. Another point we have considered concerns tesselation ambiguities often result ing in holes appearing in the surface. We have coded a library which is very easy to use and can b e downloaded freely. All these optimizations allow us to sample implicit surface s composed of 200 points in 45 ms on a 450 MHz Pentium II Xeon.	algorithm;automatic programming;handy board;implicit surface;marching cubes;simulation	Frédéric Triquet;Philippe Meseure;Christophe Chaillou	2001			computer graphics (images);xeon;voxel;architecture;artificial intelligence;pentium;computer vision;marching tetrahedra;animation;computer science;marching cubes;restrict	Graphics	66.91010888748008	-50.651812933265965	127964
4fd5981e68adddfd940464a6532b67d8eaba4806	meaningful mesh segmentation guided by the 3d short-cut rule	3d short cut rule;minimal rule;rule based;skeleton;meaningful mesh segmentation;mesh segmentation;hierarchical model	Extended from the 2D silhouette-parsing short-cut rule [25], a 3D short-cut rule, which states “ as long as a cutting path mainly crosses local skeleton and lies in concave regions, the shorter path is (other things being equal) the better ” , is defined in the paper. Guided by the 3D short-cut rule, we propose a hierarchical model decomposition paradigm, which integrates the advantages of the skeleton-driven and minima-rule-based meaningful segmentation. Our method defines geometrical and topological functions of skeleton to locate initial critical cutting points, and then employs salient contours with negative minimal principal curvature values to determine natural boundary curves among parts. Sufficient experiments have been carried out on many meshes, and have shown that our framework could provide more perceptual results than pure skeleton-driven or minima-rule-based algorithm.	algorithm;computable function;computation;concave function;cut rule;decomposition (computer science);experiment;hierarchical database model;logic programming;maxima and minima;parsing;programming paradigm;rule 184;skeleton (computer programming)	Zhi-Quan Cheng;Bao Li;Gang Dang;Shiyao Jin	2008		10.1007/978-3-540-79246-8_19	rule-based system;computer vision;computer science;machine learning;mathematics;skeleton;engineering drawing;hierarchical database model	AI	65.21134253945245	-42.34453210665123	128191
8fa6a8f5a02db5e8097e393ef6538524902027e6	adaptive data compression for robot perception	adaptive data compression;paper concern;prunes redundant data;non-parametric representation;mobile robot;gaussian process regression;laser data;robot perception;decimation factor;synthetic data;arbitrary location;adaptive subsampling	This paper concerns the creation of an efficient, continuous, non-parametric representation of surfaces implicit in 3D laser data as typically recorded by mobile robots. Our approach explicitly leverages the probabilistic nature of Gaussian Process regression to provide for a principled, adaptive subsampling which automatically prunes redundant data. The algorithm places no restriction on the complexity of the underlying surfaces and enables predictions at arbitrary locations and densities. We present results using real and synthetic data and show that our approach attains decimation factors in excess of two orders of magnitude without significant degradation in fidelity of the workspace reconstructions.	active window;algorithm;chroma subsampling;computational complexity theory;computer-aided design;cubic function;data compression;decimation (signal processing);elegant degradation;gaussian process;implicit surface;kriging;mobile robot;offset binary;point cloud;smith–waterman algorithm;stationary process;synthetic data;workspace	Mike Smith;Ingmar Posner;Paul Newman	2011		10.5591/978-1-57735-516-8/IJCAI11-457	computer vision;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;statistics	ML	55.229805780134654	-43.69795822722204	128206
5cd2ba921e7cc7d6aac8e9251dba665a2e632b61	optimizing a triangular mesh for shape reconstruction from images	automatic mesh generation;traitement signal;image tridimensionnelle;triangulacion delaunay;triangular shape;optimisation;tecnologia electronica telecomunicaciones;delaunay triangulation;image processing;optimizacion;generation automatique maille;polyhedral representation;triangulation delaunay;3 d reconstruction;procesamiento imagen;mesh optimization;triangular mesh;forme triangulaire;traitement image;triangular mesh generation;reconstruction image;generacion automatica red;reconstruccion imagen;feature extraction;image reconstruction;shape reconstruction;signal processing;pattern recognition;forma triangular;tridimensional image;optimization;reconnaissance forme;extraction caracteristique;tecnologias;reconocimiento patron;grupo a;procesamiento senal;imagen tridimensional	In reconstructing 3-D from images based on feature points, one usually defines a triangular mesh that has these feature points as vertices and displays the scene as a polyhedron. If the scene itself is a polyhedron, however, some of the displayed edges may be inconsistent with the true shape. This paper presents a new technique for automatically eliminating such inconsistencies by using a special template. We also present a technique for removing spurious occluding edges. All the procedures do not require any thresholds to be adjusted. Using real images, we demonstrate that our method has high capability to correct inconsistencies. key words: triangular mesh generation, Delaunay triangulation, polyhedral representation, mesh optimization, 3-D reconstruction	delaunay triangulation;mathematical optimization;mesh generation;optimizing compiler;polygon mesh;polyhedron	Atsutada Nakatsuji;Yasuyuki Sugaya;Kenichi Kanatani	2005	IEICE Transactions	10.1093/ietisy/e88-d.10.2269	iterative reconstruction;computer vision;delaunay triangulation;image processing;feature extraction;computer science;triangle mesh;signal processing;mathematics;geometry	Vision	66.09837111015472	-41.343572423567366	128446
8cd49fa803a8871a6e7fd5b0c0fbba0eab8c913d	arbitrary view and focus image generation: rendering object-based shifting and focussing effect by linear filtering	focusing;nonlinear filters;near focused image;focussing effects;image segmentation;view point;input images shifting effects focussing effects virtual view image differently focused images near focused image far focused image near objects far objects view point focus depth virtual camera linear filtering;image reconstruction rendering computer graphics digital filters virtual reality;virtual view image;virtual reality;testing;layout;linear filtering;image generation;shifting effects;differently focused images;image reconstruction;focus depth;digital filters;maximum likelihood detection;focusing image generation rendering computer graphics layout cameras image segmentation maximum likelihood detection nonlinear filters testing humans;humans;input images;rendering computer graphics;far objects;far focused image;cameras;near objects;virtual camera	This paper presents a novel method to render shifting (parallax) and focussing effects on object in a scene for generating a virtual view image with arbitrary focus. Two differently focused images of the same scene—near-focused image and far-focused image—are used as input under the assumption that a scene has near and far objects. The proposed method can freely handle the shifting and the focussing effect on each object according to the view point and the focus depth of the virtual camera only by linear filtering of the input images without any segmentation or modeling of the objects. Experimental results using real images are shown to test the performance of the method.	glossary of computer graphics;object-based language;parallax;virtual camera system	Akira Kubota;Kiyoharu Aizawa	2002		10.1109/ICIP.2002.1038067	iterative reconstruction;layout;computer vision;digital filter;computer science;linear filter;virtual reality;multimedia;software testing;image segmentation;computer graphics (images)	Vision	58.648691263845414	-51.37987155238608	128540
82013c8634814f498fef9549a878e0528d564588	physically-based driven tree animations	categories and subject descriptors according to acm ccs i 3 5 computational geometry and object modelling physically based modelling;i 3 7 three dimensional graphics and realism animation;i 3 6 methodology and techniques interaction techniques	Simulating dynamic natural wind effects on trees remains a challenging task in Computer Graphics. From an animator’s point of view it is a cumbersome and tedious task to create this ef fect due to the complexity of the tree shape, the numerous protruding branches and the wide variety of fo liage. In this paper we present a novel method to create controllable animations of trees. Our approach borrows from several ideas from video textures, computer-assisted animation and motion graphs. It combines re-seque ncing of existing material with the automatic generation of new data. Furthermore, the animator can direct the an im tion at each arbitrary moment using a goal based motion algorithm. First, a small set of motion data is gathe red from a physically-based driven tree animation. Next, an optimised motion graph is constructed from the acquir ed data indicating all possible transitions from one tree pose to another. By creating in-between frames for all p airs of keyframes we ensure smooth transitions. Finally, by walking on the motion graph new non-identical animatio ns are synthesised. The resulting animations are smooth, controllable by the animator and suitable for different production targets including 3D virtual environments (e.g., games) and 2D stylised animation.	algorithm;computer animation;computer graphics;digital video;eurographics;fo (complexity);flash animation;key frame;point of view (computer hardware company);simulation;tom;virtual reality	William Van Haevre;Fabian Di Fiore;Frank Van Reeth	2006		10.2312/NPH/NPH06/075-082	physically based animation;computer vision;simulation;computer facial animation;computer science;computer animation;computer graphics (images)	Graphics	64.32299888502486	-47.082725033230886	128840
1ce2a18dcdfdb71e2017b56032a05091fddaa484	video mosaicing based on structure from motion for distortion-free document digitization	high resolution imager;structure from motion	This paper presents a novel video mosaicing method capable of generating a geometric distortion-free mosaic image using a hand-held camera. For a document composed of curved pages, mosaic images of virtually flattened pages are generated. The process of our method is composed of two stages : real-time stage and off-line stage. In the realtime stage, image features are automatically tracked on the input images, and the viewpoint of each image as well as the 3-D position of each image feature are estimated by a structure-from-motion technique. In the offline stage, the estimated viewpoint and 3-D position of each feature are refined and utilized to generate a geometric distortion-free mosaic image. We demonstrate our prototype system on curved documents to show the feasibility of our approach.	distortion;structure from motion	Akihiko Iketani;Tomokazu Sato;Sei Ikeda;Masayuki Kanbara;Noboru Nakajima;Naokazu Yokoya	2007		10.1007/978-3-540-76390-1_8	computer vision;structure from motion;computer science;multimedia;computer graphics (images)	Vision	57.61090726553608	-48.884910670655174	128921
2c4cfe6f2cee8e8def4261d17d6d9e4c5538fec7	mobile surface reflectometry	stereoscopic;reflectometry;mobile device;i 4 1 image processing and computer vision digitization and image capture reflectance;0801 artificial intelligence and image processing;svbrdf;software engineering;journal article;i 3 7 computer graphics three dimensional graphics and realism colour;registration;2d 3d tracking;color correction;shadowing and texture;shading	"""We present two approaches for acquiring spatially varying reflectance of planar samples using a mobile device. For samples with rough specular BRDF, we propose to employ the back camera and flash pair on any typical mobile device for freeform handheld reflectance acquisition using dense backscattering measurements under flash illumination. For samples with highly specular BRDF, we instead employ a 10"""" tablet for illuminating the sample with extended illumination while employing the front camera for reflectance acquisition. With this setup, we also exploit the tablet's LCD screen polarization for diffuse-specular separation."""	bidirectional reflectance distribution function;handheld game console;mobile device;polarization (waves);reflectometry;tablet computer	Jérémy Rivière;Pieter Peers;Abhijeet Ghosh	2014		10.1145/2614217.2630589	stereoscopy;computer vision;shading;computer science;operating system;mobile device;computer graphics (images)	Vision	58.70986970087387	-50.29968760274411	128961
487ddae625d56e476031dc68eaef541becde42eb	bézier representation for cubic surface patches	modelizacion;patch;concepcion asistida;computer aided design;polyedre;geometrie algorithmique;computer graphics;poliedro;computational geometry;polyhedron;algorithme;modelisation;algorithm;geometria algoritmica;conception assistee;superficie;surface;parche;modeling;grafico computadora;infographie;algoritmo	The paper describes a new method for creating rectangular Bkzier surface patches on an implicit cubic surface. Traditional techniques for representing surfaces have relied on parametric representations of surfaces, which, in general, 9enerate surfaces of implicit degree 8 in the case of rectangular Bkzier surfaces with rational biquadratic parameterization. The method constructs low-degree algebraic surface patches by reducing the implicit degree from 8 to 3. The construction uses a rectangular biquadratic Bkzier control polyhedron that is embedded within a tetrahedron and satisfies a projective constraint. The control polyhedron and the resultin9 cubic surface patch satisfy all of the standard properties of parametric Bbzier surfaces, including interpolation of the corners of the control polyhedron and the convex-hull property.	bézier curve;convex hull;cubic function;embedded system;interpolation;polyhedron;quartic function	Suresh K. Lodha;Joe D. Warren	1992	Computer-Aided Design	10.1016/0010-4485(92)90019-7	systems modeling;bézier triangle;computational geometry;computer science;computer aided design;bézier surface;mathematics;geometry;computer graphics;surface;engineering drawing;algorithm;polyhedron	Graphics	67.85737097427788	-40.384224807208206	129073
9e271bf17e64ad7598b315a96179496a44474b4d	mobile 3d gaze tracking calibration	object tracking calibration;mobile;interpolation;magnetic heads;visual angle mobile 3d gaze tracking calibration mobile eye tracker external tracking system 3d gaze vector calibration points varying distance pupil position head position head orientation eye position measurement eye coordinate system;gaze tracking;calibration tracking head magnetic heads three dimensional displays interpolation mobile communication;three dimensional displays;mobile gaze tracking calibration;mobile communication;head;calibration;tracking	We present a new calibration method to combine a mobile eye tracker with an external tracking system to obtain a 3D gaze vector. Our method captures calibration points of varying distances, pupil positions and head positions/orientations. With these data we can determine the eye position relative to the user's head position without separate manual eye-position measurements. For this approach, it is not necessary to know the orientation of the eye coordinate system in advance. In addition to the calibration of the external tracking system calibration, we can calibrate the head-tracked eye tracker in a one-step process, requiring the user to look at the calibration points. No extra calibration of the eye tracker is necessary, if the raw pupil position in the eye-camera is available from the eye tracker. The calibrated system allows us to estimate the 3D gaze vector for a user who can move freely within the range of the external tracking system. Our evaluation shows that the average accuracy of the visual angle is better than one degree in a self evaluation and approximately two degrees under unrestrained head movement.	eye tracking;mobile 3d graphics api;tracking system	Christian Scheel;Oliver G. Staadt	2015	2015 12th Conference on Computer and Robot Vision	10.1109/CRV.2015.30	computer vision;calibration;simulation;mobile telephony;interpolation;computer science;mobile technology;eye tracking on the iss;tracking;head	Vision	57.51563688794678	-38.73861192977149	129188
de9f177bc082b5aff4057e1df469f6d8d924449b	hair smash	rgb d;blendshapes;face animation;depth sensors	We present techniques to smash render hair under hats and headsets in animated shots that produce significant savings in time and disk space. Techniques are discussed to smash both the fine render hairs and the Level of Detail (LOD) hairs where low resolution proxy tubes riding on guide curves are substituted for fine render hairs. Precise collision resolution is ensured for those tight fitting collision objects. This procedural hair smash technique was used in the feature films Turbo, Penguins of Madagascar, and HOME, and allowed the automated creation of a large number (hundreds) of hair variations with ease. These variations are stored in a library and are used to generate the smashed hair on individual characters in a shot at render time.	disk space;hash table;headset (audio);image resolution;level of detail;library (computing)	Colleen O'Hagan;Arunachalam Somasundaram;Jason P. Weber	2015		10.1145/2775280.2792543	computer graphics (images)	Graphics	64.47665811061677	-49.673787888697966	129449
fdaad243b71ed09379abb466f4c457aade3e6a8d	capturing and viewing gigapixel images	tone mapping;culling;shaders;very high resolution;rasterization;high dynamic range;hardware	"""We present a system to capture and view """"Gigapixel images"""": very high resolution, high dynamic range, and wide angle imagery consisting of several billion pixels each. A specialized camera mount, in combination with an automated pipeline for alignment, exposure compensation, and stitching, provide the means to acquire Gigapixel images with a standard camera and lens. More importantly, our novel viewer enables exploration of such images at interactive rates over a network, while dynamically and smoothly interpolating the projection between perspective and curved projections, and simultaneously modifying the tone-mapping to ensure an optimal view of the portion of the scene being viewed."""	gigapixel image	Johannes Kopf;Matthew Uyttendaele;Oliver Deussen;Michael F. Cohen	2007	ACM Trans. Graph.	10.1145/1276377.1276494	rasterisation;computer vision;tone mapping;simulation;shader;computer science;culling;computer graphics (images)	Graphics	60.084920565643074	-50.25895147865701	129451
1bbd6c4ae37ab1da9ba4e8c97e85ec7798efa19e	estimating the fundamental matrix by transforming image points in projective space	fundamental matrix;epipolar geometry;projective space;nonlinear optimization	This paper proposes a novel technique for estimating the fundamental matrix by transforming the image points in projective space. We therefore only need to perform nonlinear optimization with one parameterization of the fundamental matrix, rather than considering 36 distinct parameterizations as in previous work. We also show how to preserve the characteristics of the data noise model from the original image space.	fundamental matrix (computer vision);map;mathematical optimization;nonlinear programming;nonlinear system	Zhengyou Zhang;Charles T. Loop	2001	Computer Vision and Image Understanding	10.1006/cviu.2001.0909	computer vision;projective space;duality;mathematical analysis;topology;eight-point algorithm;nonlinear programming;computer science;blocking set;mathematics;geometry;fundamental matrix;image rectification;essential matrix;state-transition matrix;epipolar geometry	Vision	54.07305709293497	-51.13989523605277	130233
1014f4d5b624fb3b384745cef1adff5830d0695e	the research of 3d visualization techniques for the test of laser energy distribution	lasers;3d visualizations;digital image processing;computer programming;opengl	In the process of laser transmission in the atmosphere, the complexity and instability of the atmospheric composition that seriously interfere with, even change, the performance of the laser beam. The image of laser energy distribution can be captured and analyzed through infrared CCD and digital image processing technology. The basic features of laser energy density distribution, such as the location and power of the peak point and other basic parameters could be acquired; laser energy density distribution can display in real time continuous multi-frame; the 3D visualization of pseudo-color for laser energy density distribution could be displayed, that reflect the relative size and position of the energy distribution in the different regions of the laser spot, using the VC++, windows APIs and OpenGL programming. The laser energy density distribution can be observed from all angles. © (2013) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.	volume rendering	Lixin Liu;Bo Wang	2013		10.1117/12.2030556	computer vision;simulation;computer science;computer graphics (images)	HCI	61.95513376179148	-51.98995520031353	130290
621e008cfb8b4e2d4d6c0d190ae0ee1831146376	a simple and accurate camera-sensor calibration for surgical endoscopes and microscopes	surgical endoscopes;surgical microscopes;hand eye calibration;thesis;핸드 아이 캘리브레이션;수술 현미경;수술 내시경;카메라 캘리브레이션;camera calibration	Augmented reality (AR) has become a key technology for surgical navigation system, which is the technology to overlay virtual objects on real one. In AR system, camera-sensor calibration is one of major factors to affect the accuracy. In order to perform camera-sensor calibration, it has been a common method to move a camera to establish and solve an AX = XB type. However, in the clinical environments, endoscopes and microscopes are commonly used and moving manually those cameras leads to inconvenience and inaccuracy due to heavy weight and large size. In addition, since optical tracking system has spatial error which increases with the distance, moving the camera which requires large motion to make necessary orientations between a calibration pattern and the camera makes the system affected by the spatial error. Therefore, we propose a method to solve the camera-sensor matrix. It is not mathematically strong to the noise, but possible to reduce the effect of the spatial error of optical tracking system effectively, and to provide users more convenient method. The proposed method can be easily performed by mounting an additional marker on the calibration pattern, which produces AX = BYC type formula. Through experiments, we compared the AX = BYC solution with the AX = XB solution in terms of the accuracy. As a result, we found the proposed method is more convenient, accurate, and stable than the conventional method.		Seongpung Lee;Hyunki Lee;Hyunseok Choi;Jaesung Hong	2014		10.1007/978-3-319-10437-9_11	computer vision;engineering;optics;surgery	Robotics	55.48504263735191	-46.80706547935951	130297
931567a5b573251abf337f41df8cca6a74c5fd95	a modular hybrid slam for the 3d mapping of large scale environments	omnivision slam localization 3d mapping mining sensor fusion;3d mapping;omnivision;mining;image matching;path planning;localization;slam;image fusion;conference paper;iterative methods;robot vision;iterative closest point algorithm lasers global positioning system cameras vehicles robot vision systems;image registration;slam robots image fusion image matching image registration iterative methods path planning robot vision;simultaneous localisation and mapping modular hybrid slam 3d mapping underground mining environment modular mapping solution global positioning systems gps motion model simplification physical odometry hybrid 3d mapping approach omnidirectional vision fusion 3d range data fusion vision based bearing only localization scan matching icp algorithm iterative closest point algorithm depth information registration algorithm localization drift;sensor fusion;slam robots	Underground mining environments pose many unique challenges to the task of creating extensive, survey quality 3D maps. The extreme characteristics of such environments require a modular mapping solution which has no dependency on Global Positioning Systems (GPS), physical odometry, a priori information or motion model simplification. These restrictions rule out many existing 3D mapping approaches. This work examines a hybrid approach to mapping, fusing omnidirectional vision and 3D range data to produce an automatically registered, accurate and dense 3D map. A series of discrete 3D laser scans are registered through a combination of vision based bearing-only localization and scan matching with the Iterative Closest Point (ICP) algorithm. Depth information provided by the laser scans is used to correctly scale the bearing-only feature map, which in turn supplies an initial pose estimate for a registration algorithm to build the 3D map and correct localization drift. The resulting extensive maps require no external instrumentation or a priori information. Preliminary testing demonstrated the ability of the hybrid system to produce a highly accurate 3D map of an extensive indoor space.	3d scanner;algorithm;global positioning system;hybrid system;iterative closest point;iterative method;level of detail;map;mobile operating system;modular design;odometry;simultaneous localization and mapping;six degrees of separation;underground	Jared Le Cras;Jonathan Paxman	2012	2012 12th International Conference on Control Automation Robotics & Vision (ICARCV)	10.1109/ICARCV.2012.6485300	computer vision;mining;simulation;internationalization and localization;computer science;image registration;machine learning;motion planning;sensor fusion;iterative method;image fusion	Robotics	54.1239097914814	-41.650491982891175	130647
862fd58c2cb1bd3bae2ac7809b78b27239cb4e66	road surface segmentation based on vertically local disparity histogram for stereo camera		In this paper, we propose a road surface segmentation technique which is accurate and suitable for hardware implementation. The road surface is segmented by detecting the boundary between road and obstacle, based on the disparity histogram which we define as VLDH (Vertically Local Disparity Histogram). On each pixel of disparity image, VLDH is computed from the disparities of vertically local neighbourhood pixels. The major advantage is the feasibility of the pipeline processing on image processing hardware for stereo camera. The direct advantage on processing time is confirmed based on implementation into FPGA. Experimental result also shows that the accuracy of the proposed method is better than the conventional method.	binocular disparity;bump mapping;edge detection;field-programmable gate array;fork (software development);image processing;merge algorithm;pipeline (computing);pixel;sensor;stereo camera	Shinji Kakegawa;Haruki Matono;Hideaki Kido;Takeshi Shima	2018	Int. J. Intelligent Transportation Systems Research	10.1007/s13177-017-0140-8	computer vision;simulation;histogram matching;computer graphics (images)	Robotics	57.6637314201091	-44.088325003117966	130706
3ec4f6ccf9596d8281ab3821241b4c29490ba30e	interactive background blurring	depth of field;defocusing;shallow focus;image refocusing;foreground background	Photographers usually take a shallow focus image to highlight the main subject in the picture and blur the distractions in the background region. Softening these distractions can not only produce special vision effect but also keep the privacy for people in the background. In this work, we develop a brand new defocusing algorithm to simulate the blur effect in the background caused by a wide aperture camera. We also design an easy-to-use interactive interface for user to segment foreground/background objects, adjust the depth of field for images, and assign camera settings. Techniques including lazy snapping, alpha matting, depth information generation and defocusing are integrated in the system. The experimental results show the effectiveness of the proposed methodology.	algorithm;gaussian blur;image;lazy evaluation;simulation;softening;user interface	Chih-Yu Yan;Ming-Chun Tien;Ja-Ling Wu	2009		10.1145/1631272.1631422	computer vision;foreground-background;depth of field;computer graphics (images)	HCI	62.43042363459945	-51.33808054919371	130731
04c4f5ab321ebab104ec2076509b8aa37641c4cf	line reconstruction using prior knowledge in single non-central view		Line projections in non-central systems contain more geometric information than central systems. The four degrees of freedom of the 3D line are mapped to the line-image and the 3D line can be theoretically recovered from 4 projecting rays (i.e. line-image points) from a single non-central view [3]. If the non-central system is properly calibrated we obtain a metric reconstruction of the 3D line. In practice, extraction of line-images is considerably more difficult and the resulting reconstruction is imprecise and sensitive to noise. In this paper we explore the reconstruction accuracy improvements when we impose geometrical constraints [1] exploiting prior knowledge. In particular, when the lines of the scene are arranged in two orthogonal directions and we know prior information about the direction of one of this directions (typically the vertical direction), the complexity of line fitting reduces, the accuracy of the metric reconstruction improves, and the extraction procedure is simplified.	compiler;line fitting	Jesus Bermudez-Cameo;Cédric Demonceaux;Gonzalo López-Nicolás;Josechu J. Guerrero	2016			computer vision;computer science;artificial intelligence;plucker;extractor;exploit;vertical direction;unconstrained method	Vision	56.00079039217774	-49.947678270655324	130957
a487a2efbfa255c947d293121284ef237e9b98e9	algorithm for generating a digital straight line on a triangular grid	triangular grid computer graphics digital straight line hexagonal tesselation line generation plotter algorithm;computer graphics;hexagonal tesselation;computer graphic;line generation;plotter algorithm;triangular grid;digital straight line	An algorithm is presented for generating the optimum straight-line approximation for a plotter constrained to move a unit distance at a time in one of six equi-spaced directions. The algorithm facilitates the drawing of digital straight lines on a triangular grid.	algorithm;approximation;plotter	Herbert Freeman	1979	IEEE Transactions on Computers	10.1109/TC.1979.1675305	computer science;theoretical computer science;computer graphics;computer graphics (images)	Visualization	66.76180811754146	-48.477082039268154	131099
1fb21c39161f3ec2c2e2802922e1076d88c5ef90	linear interval estimations for parametric objects - theory and application	interval estimation;non photorealistic rendering;shear warp projection;interactive volume rendering	The new concept of parametrized bounding volumes for parametric objects is proposed to replace the common compact bounding volumes like axis aligned bounding boxes and parallelepipeds. Linear Interval Estimations (LIEs) are developed as a realization of the discussed ideas. Two reliable methods for the computation of LIEs are introduced based on a new understanding of the use of affine arithmetics and a special application of Taylor Models. The particular structure of LIEs allows an effective intersection test of LIEs with rays, boxes and other LIEs. The test gives besides of a possible location of the intersection in object space information about affected parts in the parameter spaces of the enclosed objects. A subdivision algorithm for the intersection of two parametric surface patches with remarkable experimental results is presented as a possible application.	archicad library part	Katja Bühler	2001	Comput. Graph. Forum	10.1111/1467-8659.00520	intersection;combinatorics;discrete mathematics;bounding interval hierarchy;interval estimation;topology;computer science;mathematics;non-photorealistic rendering;geometry;bounding volume hierarchy;algorithm;statistics;computer graphics (images)	NLP	68.13229201357976	-41.96167704985541	131365
a735235c595a3854156d40df01bbc848fd132edb	a distortion correction algorithm for fish-eye panoramic image of master-slave camera	distortion correction;master slave camera;distortion cameras;distortion;abstracts indexes erbium computational efficiency computers visualization;midpoint circle algorithm master slave camera distortion correction;midpoint circle algorithm;distortion correction algorithm hardware resources embedded camera platform incremental calculation circle circumference pixel positions mca midpoint circle algorithm gravity direction fish eye panoramic camera ptz dome camera master slave camera system fish eye panoramic image;cameras	The Master-Slave camera that composed of a fish-eye panoramic camera and a PTZ dome camera has been applied in many fields. Since the fish-eye panoramic camera's incline towards the gravity direction in Master-Slave camera system, the captured panoramic image has obvious horizontal distortion. In order to correct this particular type of distortion, a distortion correction method is proposed based on Midpoint Circle Algorithm (MCA). This method aims to determine the pixel positions along a circle circumference based on incremental calculation of decision parameters, and both of the vertical and horizontal are rectilinearised. Experimental results demonstrate that the proposed distortion correction method is efficient and effective. The proposed algorithm can be applied on embedded camera platform without any extra hardware resources due to its low computational cost.	algorithmic efficiency;computation;distortion;embedded system;midpoint circle algorithm;pan–tilt–zoom camera;pixel	Chenglin Zuo;Yu Liu;Yongle Li;Bin Wang;Wei Xu;Maojun Zhang	2013	2013 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)	10.1109/ICMEW.2013.6618301	computer vision;camera auto-calibration;camera resectioning;distortion;telecommunications;computer science;midpoint circle algorithm;mathematics;pinhole camera model;computer graphics (images)	Robotics	54.829531300934285	-48.72763124497923	131400
ead236a6c0aeac8f824918554a8f1e69fc5db2e7	experimental tool for generating ground truths for skewed page images	performance evaluation;page segmentation;algorithms;ground truth	We describe a new tool called GROTTO to generate ground truths for skewed page images, which can be used for performance evaluation of page segmentation algorithms. Some of these algorithms are claimed to be more or less insensitive to skew. However, this fact is usually only supported by a visual comparison of what one obtains and what one should obtain. As a result, the evaluation is both subjective, that is, prone to errors and tedious. Our tool allows users to quickly and easily produce many suÆciently accurate ground truths that can be employed in practice and therefore it facilitates automatic performance evaluation. The main idea is to utilize the ground truths available for upright images, that is, for those without skew, and the concept of the representative square in order to produce the ground truths for skewed images. The usefulness of our tool is demonstrated through a number of experiments described.	algorithm;binary space partitioning;dr. goldfoot and the girl bombs;experiment;image registration;offset binary;performance evaluation;pixel;software bug;visual comparison	Oleg Okun;Ari Vesanen;Matti Pietikäinen	2001		10.1117/12.410845	simulation;ground truth;computer science;artificial intelligence;computer graphics (images)	Robotics	61.26797571039017	-49.18096437935642	131457
eeaceaa0cb12ac7813bdae0fe45bff10f66d8797	3d model generation of cattle using multiple depth-maps for ict agriculture		This paper proposes new system that generates 3D models of cattle from their multiple depth-maps for estimating their BCS (body condition scores). Various works of the agriculture are almost tedious and the use of advanced ICT is possible to improve such works. Currently, the authors have been studying such an ICT agriculture research whose targets are beef cattle. The goal of this study is to capture 3D shape information of cattle accurately for the estimation of their BCS. BCS are important data for checking whether cattle grow appropriately. However, it is very difficult to capture such information even using a commercial 3D scanner because cattle are animals and always moving. Then, the authors propose the use of multiple depth-maps of a cow simultaneously captured by multiple Kinect sensors at a different viewpoint to generate its 3D model. The problems in this case are the calibration of Kinect sensors and the synchronization of their depth-maps capturing. This paper describes how the authors solve these problems, and it shows several results of actually obtained 3D models of cattle using the proposed system.	3d modeling	Naoto Maki;Shohei Nakamura;Shigeru Takano;Yoshihiro Okada	2017		10.1007/978-3-319-61566-0_72	beef cattle;data mining;distributed computing;synchronization;agriculture;scanner;computer science;information and communications technology	NLP	54.83659231192842	-45.74280367504709	131716
24ac10cb68f175329b0140bb5dee3c0bc6d2733d	real-time approximate subsurface scattering on graphics hardware	tone mapping;high dynamic range images;image resolution;display devices;image quality high dynamic range images tone mapped images luminance brightness adjustment;luminance;tone mapped images;high dynamic range imaging;brightness;brightness adjustment;image colour analysis;image quality;brightness layout displays tv dynamic range photography image quality computer graphics visualization printing;image resolution brightness display devices image colour analysis	This paper presents an image-space approximation technique for real-time subsurface scattering. We first create transmitted irradiance samples on shadow maps and then estimate single scattering efficiently using a method similar to shadow mapping, with adaptive deterministic sampling. We incorporate this single-scattering with a recently proposed technique for multiple scattering. We demonstrate that our technique produces high-quality images of animated scenes. We archived hundreds of frames per second on graphics hardware without lengthy preprocessing.	approximation;archive;graphics hardware;map;preprocessor;real-time clock;real-time transcription;sampling (signal processing);shadow mapping;subsurface scattering	Hyunwoo Ki;Jihye Lyu;Kyoungsu Oh	2007	15th Pacific Conference on Computer Graphics and Applications (PG'07)	10.1109/PG.2007.12	image quality;computer vision;tone mapping;image resolution;computer science;luminance;brightness;display device;computer graphics (images)	Graphics	64.19316003506	-51.94754229711027	132211
9730ebbcad1d7290a43f7bf9a481230138468d42	primitive and point configuration texture model and primitive estimation using mathematical morphology	mathematical morphology;estimation method;optimal estimation;size distribution	A model for texture description, called “Primitive and Point Configuration (PPC) texture model,” and an estimation method of the primitive, which is an elementary object for configuring a texture, are proposed in this paper. The PPC texture model regards that a texture is composed by arranging grains that are derived from one or a few primitives by some modification. The primitive shape is estimated by the principle that the primitive resembling the grains best should be the optimal estimation. This estimation is achieved by finding the structuring element that minimizes the integral of the size distribution function of a target texture.	mathematical morphology;morphological skeleton;structuring element	Akira Asano;Takeshi Ohkubo;Mitsuji Muneyasu;Takao Hinamoto	2003		10.1007/3-540-45103-X_25	optimal estimation;computer vision;mathematical optimization;mathematical morphology;computer science;mathematics;geometry	Vision	59.25582831090303	-47.59754532433764	132385
eb2255746cc8271bca9484a11f9ac60b9a46de40	degrade : a new color shading tool		Pictures or nature rarely present uniform colored regions. Most drawings include shaded and/or color shaded surfaces. Therefore for any graphic designer the color shading tool is of major importance. The tools included in a graphics library have to respect two important conditions: they have to be fast and they have to be intuitive. Most color shading tools don't conciliate these two constraints. This paper presents a new model of color shading. Its implementation uses the fastest computation techniques up-to-date. Four examples of pictures drawn with D EGRAD E, the new color shading tool, are then presented.	algorithm;computation;cone;dspace;fastest;graphics library;shading	Vincent Boyer;Jean-Jacques Bourdin	2001			computer graphics (images);artificial intelligence;computer vision;shading;computer science	Graphics	66.35538140591706	-49.098942907712996	132835
00733ea36859d2e2ed26d1770c4439dff58dd0d5	locally-weighted elastic comparison of planar shapes		Registration of curves is a necessary component of statistical shape analysis. The goal of registration is to align collections of shapes so that common features are appropriately matched for further comparison and subsequent analyses. Traditional methods for registration typically rely on optimizing an energy functional over a set of appropriate shape-preserving transformations (i.e., rotations and reparameterizations). These functionals typically rely on the standard L^2 metric. In certain applications, it may make sense to use a more flexible metric which can align shapes most preferably with respect to a local shape feature (i.e., a certain curve segment selected from the overall shape). In this work, we define a weighted shape metric which allows for emphasis on local shape features. Registration can be performed with respect to this metric. We demonstrate the registration procedure using simulated curves as well as real data, and show the dependence of the optimal rotation and re-parameterization on the specified weights, as well as the resulting deformation path from one shape to another.		Justin Strait;Sebastian Kurtek;Steven MacEachern	2018	2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)	10.1109/CVPRW.2018.00076	deformation (mechanics);computer vision;statistical shape analysis;elasticity (economics);energy functional;artificial intelligence;computer science;registration procedure;planar	Vision	63.90256770176811	-42.64200389709373	132970
577cc24e9fd5d107cbce4548567044ba9e0607c8	a minimal solution for the extrinsic calibration of a camera and a laser-rangefinder	sensor fusion calibration cameras iterative methods laser ranging pose estimation;lasers;calibration cameras equations lasers three dimensional displays vectors sensors;minimal problems;sensors;laser rangefinder;plane pose estimation camera extrinsic calibration 2d laser rangefinder checkerboard pattern camera coordinates depth readings lrf reference frame displacement estimation 3d space plane line correspondences p3p problem linear equation system hypothesis generator ransac paradigm random sample consensus;laser ranging;iterative methods;vectors;three dimensional displays;euclidean registration;sensor fusion;extrinsic calibration;calibration;cameras;sensor fusion extrinsic calibration laser rangefinder euclidean registration minimal problems;pose estimation	This paper presents a new algorithm for the extrinsic calibration of a perspective camera and an invisible 2D laser-rangefinder (LRF). The calibration is achieved by freely moving a checkerboard pattern in order to obtain plane poses in camera coordinates and depth readings in the LRF reference frame. The problem of estimating the rigid displacement between the two sensors is formulated as one of registering a set of planes and lines in the 3D space. It is proven for the first time that the alignment of three plane-line correspondences has at most eight solutions that can be determined by solving a standard p3p problem and a linear system of equations. This leads to a minimal closed-form solution for the extrinsic calibration that can be used as hypothesis generator in a RANSAC paradigm. Our calibration approach is validated through simulation and real experiments that show the superiority with respect to the current state-of-the-art method requiring a minimum of five input planes.	algorithm;angioplasty, balloon, laser-assisted;calibration;displacement mapping;estimated;experiment;linear system;muscle rigidity;numerical stability;p3p;programming paradigm;psychologic displacement;random sample consensus;reading (activity);reference frame (video);simulation;synthetic data;system of linear equations;registration - actclass;sensor (device)	Francisco Vasconcelos;João Pedro Barreto;Urbano Nunes	2012	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2012.18	computer vision;camera auto-calibration;calibration;simulation;pose;laser;computer science;sensor;mathematics;sensor fusion;iterative method	Vision	54.190622591628134	-41.86466476265701	133918
36884e301358a4b11826c45d9778b72ca14a6fa1	scene segmentation by velocity measurements obtained with a cross-shaped template	real test scene;basic object;cross-shaped template;single object;whole object;velocity measurement;reference edge;scene segmentation;velocity value;poorest result;basic tenant;visual characteristic	This paper presents a method of segmenting a scene into its basic objects on the basis of motion. The velocities of points are approximated by associating them to sets of reference edges in the scene. These measurements are then used to group the points, A basic tenant of this work is that all points of a single object have the same velocity values. Accordingly, points with the same velocity measurements are grouped together. Since the motion of an object is independent of its other visual characteristics, whole objects (not surfaces or edges) are initially included in one segment. The program successfully grouped points from internally generated scenes with 100% accuracy. Points from real test scenes were grouped correctly 90% of the time on the average. The poorest result was 42% accuracy The best was 100%.	approximation algorithm;velocity (software development)	J. Potter	1975			computer vision;simulation;mathematics;computer graphics (images)	Robotics	55.89096441067021	-47.749367258374846	134067
9ee310bdffb0bbd5e924e9d71e4f067214731641	velocity field construction for contour following tasks represented in nurbs form	field theory;approximation rationnelle;forma libre;spline surface topography surface reconstruction motion control velocity control error correction encoding tracking potential energy manipulators;non uniform rational b splines nurbs;spline;manipulators;interpolation;velocity control;theorie champ;motion control;velocity field construction;sintesis control;rational approximation;free form;non uniform rational b spline;metric;surface reconstruction;nonuniform rational b splines;surface topography;splines mathematics;velocity field;teoria campo;approximation nurbs;splines mathematics control system synthesis interpolation motion control;forme libre;aproximacion esplin;control system synthesis;spline approximation;approximation spline;error correction;synthese commande;direction field theory;distance metric;courbe niveau;aproximacion nurbs;contour following tasks;erreur poursuite;tracking error;metrico;b spline;nonuniform rational b splines velocity field construction contour following tasks nurbs form motion controller design distance metric;curva nivel;potential energy;error persecusion;aproximacion racional;encoding;control synthesis;metrique;tracking;b splin;contour line;velocity field direction field theory non uniform rational b splines nurbs;motion controller design;nurbs form	Recently, a number of studies on encoding desired contour by velocity field have been reported. Since the constructed velocity field is a function of position only, the design of motion controllers for contour following can place emphasis on the reduction of contour errors rather than the reduction of tracking errors. However, very often a distance metric needs to be computed when constructing velocity fields. Though finding the corresponding distance metric for line or circle contour following tasks is relatively easy, it is not so easy to find for free form contours such as non-uniform rational B-splines (NURBS). In order to cope with this problem, this note exploits the idea of direction field theory to construct the velocity fields for free form contour following tasks. Detailed proofs of the theorems related to the proposed approach are given. Simulation results demonstrate the effectiveness of the proposed approach.	contour line;motion controller;non-uniform rational b-spline;quantum field theory;simulation;velocity (software development)	Ming-Yang Cheng;Ying-hui Wang	2009	IEEE Transactions on Automatic Control	10.1109/TAC.2009.2029293	mathematical optimization;topology;metric;mathematics;geometry	Robotics	67.19153298350321	-38.204657157882885	134190
1a78fdeeca5c996f0d54dfe24d4fe24005508c8b	multiresolution triangle strips	computer graphics.;real time rendering;. multiresolution;triangle strip;computer graphic;level of detail;data structure	Most of the previous multiresolution models use exclusively the triangle graphic primitive both in the data structure and in the rendering stage. Only a few models use another graphic primitive in this rendering process and just one uses the triangle fan as the basic primitive of the model. In this paper we present the first multiresolution model, Multiresolution Triangle Strips, that uses the triangle strip in the data structure and in the rendering stage. Each triangle strip is represented as a graph and all levels-of-detail of this strip are stored in it. The extraction algorithm traverses the graph to obtain the triangle strip at the demanded resolution. The use of this primitive speeds up the rendering process as the number of vertices sent to the graphic system is reduced.	algorithm;data structure;directed graph;level of detail;multiresolution analysis;strips;tree traversal;triangle fan;triangle strip	Oscar Belmonte;Inmaculada Remolar;José Ribelles;Miguel Chover;Cristina Rebollo;Marcos Fernández	2001			rendering (computer graphics);triangle mesh;triangle fan;vertex (geometry);real-time rendering;computer vision;level of detail;artificial intelligence;computer science;triangle strip;data structure	Graphics	67.94088580895101	-50.04588344723776	134379
da2756650e2fb2e9c05dd73a0cba2ba2126b79bb	the kgbr viewpoint-lighting ambiguity and its resolution by generic constraints	computer graphics;planar geometry viewpoint lighting ambiguity kgbr orthographic projecting affine camera lambertian reflectance functions albedo properties generalized bas relief;three dimensional;geometry cameras light sources art equations reflectivity photometry ear humans painting;computer vision;british columbia;affine transformation;computer graphics computer vision	We describe a novel viewpoint-lighting ambiguity which we call the KGBR. This ambiguity assumes orthographic projection or an affine camera, and uses Lambertian reflectance functions including cast/attached shadows and multiple light sources. A KGBR transform alters the geometry (by a three-dimensional affine transformation) and albedo properties of objects. If two objects are related by a KGBR transform then for any viewpoint and lighting of the first object there exists a corresponding viewpoint and lighting of the second object so that the images are identical up to an affine transformation. The Generalized Bas Relief (GBR) ambiguity [1] is obtained as a special case of the KGBR. We describe generic viewpoint and lighting assumptions [5] and show that either, or both, resolve this ambiguity by biasing towards objects with planar geometry. In Proceedings International Conference on Computer Vision. Vancouver, British Columbia. 2001.	biasing;columbia (supercomputer);computer vision;lambertian reflectance;orthographic projection;shading;subpixel rendering;technical standard;viewpoint	Alan L. Yuille;James M. Coughlan;Scott Konishi	2001		10.1109/ICCV.2001.937650	three-dimensional space;computer vision;computer science;affine transformation;mathematics;geometry;computer graphics;computer graphics (images)	Vision	55.70272364396876	-51.71372127623493	134404
a9586ed7b89d184985968bac2c743493fff35c56	ray tracing deformed generalized cylinders	ray tracing	Generalized cylinders are objects defined by sweeping a 2D contour along a 3D trajectory. We introduce deformed generalized cylinders in which different contours can be defined along the trajectory. The representation of a deformed generalized cylinder is suitable for directly ray tracing its shape; it need not be converted into another representation. A suitable algorithm and some resulting images are presented.	algorithm;cylinder seal;ray tracing (graphics)	Erik de Voogt;Aadjan van der Helm;Willem F. Bronsvoort	2000	The Visual Computer	10.1007/s003710050208	distributed ray tracing;ray tracing;computer science	Graphics	67.41588391519862	-42.32008075015645	134534
7b700ac34a89cda1118399554325cd03aa134f20	efficient modeling of entangled details for natural scenes		Digital landscape realism often comes from the multitude of details that are hard to model such as fallen leaves, rock piles or entangled fallen branches. In this article, we present a method for augmenting natural scenes with a huge amount of details such as grass tufts, stones, leaves or twigs. Our approach takes advantage of the observation that those details can be approximated by replications of a few similar objects and therefore relies on mass-instancing. We propose an original structure, the Ghost Tile, that stores a huge number of overlapping candidate objects in a tile, along with a pre-computed collision graph. Details are created by traversing the scene with the Ghost Tile and generating instances according to user-defined density fields that allow to sculpt layers and piles of entangled objects while providing control over their density and distribution.	approximation algorithm;geometry instancing;precomputation;procedural programming;sculpt 3d;simulation;unified framework;wang tile	Eric Guérin;Eric Galin;François Grosbellet;Adrien Peytavie;Jean-David Génevaux	2016	Comput. Graph. Forum	10.1111/cgf.13023	computer vision;simulation;computer science;artificial intelligence;mathematics;geometry;curve;computer graphics;surface;algorithm;3d computer graphics;computer graphics (images)	Graphics	66.13170254181139	-50.45450910322906	134593
71d4073576c1a6688bc8fedc419c7fbb0617d835	rotational coordinate transformation for visual-inertial sensor fusion		Visual and inertial sensors are used collaboratively in many applications because of their complementary properties. The problem associated with sensor fusion is relative coordinate transformations. This paper presents a quaternion-based method to estimate the relative rotation between visual and inertial sensors. Rotation between a camera and an inertial measurement unit (IMU) is represented by quaternions, which are separately measured to allow the sensor to be optimized individually. Relative quaternions are used so that the global reference is not required to be known. The accuracy of the coordinate transformation was evaluated by comparing with a ground-truth tracking system. The experiment analysis proves the effectiveness of the proposed method in terms of accuracy and robustness.		Hongsheng He;Yan Li;Jindong Tan	2016		10.1007/978-3-319-47437-3_42	coordinate system;robustness (computer science);rotation matrix;quaternion;tracking system;inertial frame of reference;inertial measurement unit;physics;control theory;sensor fusion	Robotics	55.34529893201282	-38.35257175311924	134892
fea6ae30117709b84a6d5c49b83533e28419d400	constrained texture mapping via approximate voronoi base domain		In this paper, we propose an approximate Voronoi base domain method to address constrained texture mapping problem. In particular, we generate approximate Voronoi base domains on the input texture image plane and planar embedding of mesh surface. Then, we propose to leverage the triangulations of constraint points on both sides, and yield the same topology for the two approximate Voronoi base domains. Based on the equivalent topology, we are able to employ generalized barycentric coordinates between pairwise Voronoi cells of the two approximate Voronoi base domains. The proposed method is highly efficient, and it allows to edit constraints in real time. Experimental results show the improved effectiveness and robustness of the proposed method for constraint texture mapping.	approximation algorithm;barycentric subdivision;common gateway interface;image plane;image resolution;planar graph;poptropica;texture mapping;voronoi diagram	Peng Cheng;Jiaye Wang;Chunyan Miao;Changhe Tu	2018		10.1145/3208159.3208188	voronoi diagram;mathematical optimization;robustness (computer science);computer science;image plane;delaunay triangulation;pairwise comparison;texture mapping;embedding;planar	Robotics	68.14295437891258	-44.16857827467667	134926
e42d5c805a886ece3c17de42e39acedd1aeb8e5f	acquiring multispectral light transport using multi-primary dlp projector	image color analysis;lighting;switches;cameras;light sources;reverse engineering;wheels	Acquiring the light transport (LT) of a scene is important for various applications such as radiometric analysis, image-based relighting, and controlling appearance of the scene. The multispectral LT, i.e. the LT in multiple primary colors enables us not only to enhance the color gamut but also to investigate wavelength-dependent interactions between light and a scene. In this paper, we propose a method for acquiring the multispectral LT by using a single off-the-shelf multi-primary DLP (Digital Light Processing) projector; it does not require any self-built equipment, geometric registration, and temporal synchronization. Specifically, based on the rapid color switch due to a rotating color wheel in the projector, we present a method for estimating the spectral properties of the projector in a non-destructive manner, and a method for acquiring the images of a scene illuminated only by one of the primary colors. We conducted a number of experiments by using real images, and confirmed that our method works well and the acquired multispectral LT is effective for radiometric analysis and image-based relighting.	color;digital light processing;experiment;interaction;light transport theory;multispectral image	Kayano Maeda;Takahiro Okabe	2016	2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)	10.1109/IPTA.2016.7820966	computer vision;network switch;computer science;lighting;reverse engineering;computer graphics (images)	Vision	58.658181793333156	-50.493181655231865	134942
d236c7d5d1a83616005e67b160228cf9fbb7d2f5	maximizing likelihood function for parameter estimation in point clouds via groebner basis		Nowadays, surface reconstruction from point clouds generated by laser scanning technology has become a fundamental task in many fields, such as robotics, computer vision, digital photogrammetry, computational geometry, digital building modeling, forest planning and operational activities. The point clouds produced by laser scanning, however, are limited due to the occurrence of occlusions, multiple reflectance and noise, and off-surface points (outliers), thus necessitating the need for robust fitting techniques. These techniques require repeated parameter estimation while eliminating outliers. Employing maximum likelihood estimation, the parameters of the model are estimated by maximizing the likelihood function, which maps the parameters to the likelihood of observing the given data. The transformation of this optimization problem into the solution of a multivariate polynomial system via computer algebra can provide two advantages. On the one hand, since all of the solutions can be computed, a single solution that provides global maximum can be selected. On the other hand, once the symbolic result has been computed, it can be used in numerical evaluations in a split second, which reduces the computation time. In our presentation, we applied Groebner basis to solve the maximization of the likelihood function in various robust techniques. A numerical example with data from a real laser scanner experiment illustrates the method. Computations have been carried out in the Mathematica environment.	estimation theory;gröbner basis	Joseph L. Awange;Béla Paláncz;Robert H. Lewis	2014		10.1007/978-3-662-44199-2_56	mathematical optimization;combinatorics;mathematics;quasi-maximum likelihood;statistics	Vision	55.66234328713218	-50.368960149261184	135111
17e0a2d4437f05d3e59b80b10269594caf717392	fast mapping using the log-hough transformation	environment maps;iterative algorithms;intellectual property;mobile robot;optical scanners;edge detection;path planning;laser scanner;mobile robots;data mining;line finding log hough transformation fast environment mapping laser scanners mobile robots coordinate system;edge detection optical scanners mobile robots path planning hough transforms iterative methods optical sensors;iterative methods;log hough transformation;robot kinematics mobile robots navigation data mining iterative algorithms equations joining processes change detection algorithms process control intellectual property;navigation;laser scanners;process control;joining processes;hough transforms;hough transform;line finding;optical sensors;fast environment mapping;change detection algorithms;coordinate system;robot kinematics	Environment mapping is a very complex procedure that requires high CPU performance. For the last few years, laser scanners have become more and more important for mobile robots. Using their data requires many transformations between di erent coordinate systems. This new approach deals with a mapping within the coordinate system of the scanner, therefore it is very fast. The Log-Hough Transformation performs line nding in scans in a very e cient way, which speeds up mapping.	3d scanner;algorithm;cartography;central processing unit;dornier do-960;hough transform;mobile robot;reflection mapping;sensor	Björn Giesler;René Graf;Rüdiger Dillmann;Carl F. R. Weiman	1998		10.1109/IROS.1998.724843	mobile robot;computer vision;simulation;computer science;artificial intelligence;process control;computer graphics (images)	Robotics	60.9379551672758	-38.22727644995417	135241
3eb5f2b0ad0b807212212d49b20b90e4b1769313	blendforces: a dynamic framework for facial animation	animation;facial animation;i 3 3 computer graphics;i 3 3 computer graphics animation facial animation;categories and subject descriptors according to acm ccs	In this paper we present a new paradigm for the generation and retargeting of facial animation. Like a vast majority of the approaches that have adressed these topics, our formalism is built on blendshapes. However, where prior works have generally encoded facial geometry using a low dimensional basis of these blendshapes, we propose to encode facial dynamics by looking at blendshapes as a basis of forces rather than a basis of shapes. We develop this idea into a dynamic model that naturally combines the blendshapes paradigm with physics-based techniques for the simulation of deforming meshes. Because it escapes the linear span of the shape basis through time-integration and physics-inspired simulation, this approach has a wider expressive range than previous blendshape-based methods. Its inherent physically-based formulation also enables the simulation of more advanced physical interactions, such as collision responses on lip contacts.	brainfuck;coherence (physics);computer graphics;dynamical simulation;encode;emoticon;eurographics;facial recognition system;fundamental interaction;galaxy morphological classification;ground truth;john d. wiley;mathematical model;motion capture;nonlinear system;physically based animation;programming paradigm;retargeting;semantics (computer science);smart battery system	Vincent Barrielle;Nicolas Stoiber;Cedric Cagniart	2016	Comput. Graph. Forum	10.1111/cgf.12836	anime;computer vision;computer facial animation;computer science;computer animation;multimedia;computer graphics (images)	Graphics	63.51627078567621	-45.766244708879505	135431
b33c6760f52d3e47347c975b714db8c22014a9e8	gpu texture level of abstraction in 3d scenes		We present a method to dynamically control the texture level of abstraction in 3D scene. Level of abstraction consists in visualizing the necessary and sufficient information in an image. Texture generation is generally realized by a designer in a high resolutions with a low level of abstraction. Our model manages texture level of abstraction through offline and online segmentation and lets the designer define the number of colors in the object texture.	abstraction layer;color;graphics processing unit;online and offline	Jordane Suarez;Farès Belhadj;Vincent Boyer	2012		10.2312/conf/EG2012/posters/029-030	computer vision;computer science;communication;computer graphics (images)	Graphics	65.20461341282078	-49.11835657436098	135551
166e67021cd3cef7087e60c064578a0768203146	a hierarchical factorization method for efficient radiosity calculations		The radiosity problem can be expressed as a linear system, where light interactions between patches of the scene are considered. Its resolution has been one of the main subjects in Computer Graphics, which has led to the development of methods focused on different goals. For instance, in inverse lighting problems, it is convenient to solve the radiosity equation thousands of times for static geometries. Also, this calculation needs to consider many (or infinite) light bounces to achieve accurate global illumination results. Several methods have been developed to solve the linear system by finding approximations or other representations of the radiosity matrix, because the full storage of this matrix is memory demanding. Some examples are hierarchical radiosity, progressive refinement approaches, or wavelet radiosity, which may become slow for many bounces. Recently, new direct methods have been developed based on matrix factorization.#R##N##R##N#This paper introduces a novel and efficient error-bounded factorization method based on the use of multiple singular value decompositions and the Z-order curve to sort the patches of the model. This technique accelerates the factorization of in-core matrices, and allows to work with out-of-core matrices passing only one time over them. Using this method, the inverse of the radiosity matrix can be efficiently approximated, reducing the memory and time resources needed to compute radiosity with infinite bounces. In the experimental analysis, the presented method is applied to scenes up to 163 K patches. After a precomputation stage, it is used to solve the radiosity problem for fixed geometries at interactive times.	radiosity (computer graphics)	José Pedro Aguerre;Eduardo Fernández	2016	Computers & Graphics	10.1016/j.cag.2016.08.003	mathematical optimization;radiosity;theoretical computer science;mathematics;computer graphics (images)	Graphics	66.31425517119003	-50.7619112378567	135603
69155d0852cf46e45c52c0e0b6e965b77ff1c0be	spatial planning: a configuration space approach	moving object;manipulators;vector spaces;theorems;general and miscellaneous mathematics computing and information science;decomposition;uses;degree of freedom;spatial planning;geometric forms;computational geometry;collisions;geometric algorithms;data processing;robotics;position finding;three dimensional;configuration space;obstacle avoidance;mathematical models;robots;processing 990200 mathematics computers;convex sets;pattern recognition;artificial intelligence;algorithms;collision avoidance;robotics computational geometry obstacle avoidance;points mathematics	This paper presents algorithms for computing constraints on the position of an object due to the presence of ther objects. This problem arises in applications that require choosing how to arrange or how to move objects without collisions. The approach presented here is based on characterizing the position and orientation of an object as a single point in a configuration space, in which each coordinate represents a degree of freedom in the position or orientation of the object. The configurations forbidden to this object, due to the presence of other objects, can then be characterized as regions in the configuration space, called configuration space obstacles. The paper presents algorithms for computing these configuration space obstacles when the objects are polygons or polyhedra.	algorithm;polyhedron	Tomás Lozano-Pérez	1983	IEEE Transactions on Computers	10.1109/TC.1983.1676196	robot;configuration space;three-dimensional space;computer vision;mathematical optimization;theorem;pose;data processing;vector space;computational geometry;computer science;object-oriented design;mathematical model;mathematics;geometry;obstacle avoidance;degrees of freedom;decomposition;robotics	Robotics	63.74167192778127	-39.189518221569045	135717
322a173e7d1921e77eaa006431097073057663d0	adaptive isocurve-based rendering for freeform surfaces	splines;i 3 5 computer graphics computational geometry and object modeling curve surface solid and object representation;direct freeform surface rendering;surface rendering;i 3 7 computer graphics three dimensional graphics and realism color shading shadowing and texture;murbs;surface coverage;scan conversion;surface area	Freeform surface rendering is traditionally performed by approximating the surface with polygons and then rendering the polygons. This approach is extremely common because of the complexity in accurately rendering the surfaces directly. Recently several papers presented methods that render surfaces as sequences ofisocurves. These methods each have deficiencies in their ability to guarantee a complete coverage of the rendered surface, in their ability to prevent processing the same pixel multiple times, or in their ability to produce an optimal surface coverage under some prescribed norm. In this article, an algorithm is introduced that alleviates the difficulties in all these areas. This algorithm can be combined with a fast curve-rendering method tomakesurface rendering without polygonal approximation practical.	algorithm;approximation;freeform surface modelling;pixel	Gershon Elber;Elaine Cohen	1996	ACM Trans. Graph.	10.1145/231731.231736	freeform surface modelling;spline;terrain rendering;computer vision;tiled rendering;2d computer graphics;image-based modeling and rendering;3d rendering;rendering;computer science;rendering equation;polygonal modeling;surface area;ray casting;real-time computer graphics;mathematics;geometry;computer graphics;volume rendering;3d computer graphics;computer graphics (images)	Graphics	67.2663638243048	-48.47826833369021	135732
2eca81b991bd01c5924d9dda0dda8f83b0689eff	3d reconstruction using silhouettes from unordered viewpoints	delaunay triangulation;3d model;object reconstruction;dual space;article;3d reconstruction	In this paper, we present a novel approach for reconstructing an object surface from its silhouettes. The proposed approach directly estimates the differential structure of the surface, and results in a higher accuracy than existing volumetric approaches for object reconstruction. Compared with other existing differential approaches, our approach produces relatively complete 3D models similar to volumetric approaches, with the topology conforming to what is observed from the silhouettes. In addition, the method neither assumes nor depends on the spatial order of viewpoints. Experimental results on both synthetic and real world data are presented, and comparison is made with other existing approaches to demonstrate the superiority of the proposed approach.	3d reconstruction;algorithm;genus (mathematics);photo-consistency;refinement (computing);shading;synthetic intelligence	Chen Liang;Kwan-Yee Kenneth Wong	2010	Image Vision Comput.	10.1016/j.imavis.2009.09.012	3d reconstruction;computer vision;topology;delaunay triangulation;dual space;mathematics;geometry	Vision	56.66660898660464	-50.56253538247738	135999
82d25ba3e7785f467f0ecbbc9fce30e47d757aa1	video stabilization and rolling shutter distortion reduction	video signal processing;cameras jitter nonlinear distortion damping conferences motion estimation iir filters;affine transformation rolling shutter distortion video stabilization;video signal processing affine transforms jitter;affine transformation;affine transforms;interframe transformation fidelity metric video stabilization rolling shutter distortion reduction six parameter affine model vertical scaling distortion translational jitter rotational jitter;jitter	This paper presents an algorithm that stabilizes video and reduces rolling shutter distortions using a six-parameter affine model that explicitly contains parameters for translation, rotation, scaling, and skew to describe transformations between frames. Rolling shutter distortions, including wobble, skew and vertical scaling distortions, together with both translational and rotational jitter are corrected by estimating the parameters of the model and performing compensating transformations based on those estimates. The results show the benefits of the proposed algorithm quantified by the Interframe Transformation Fidelity (ITF) metric.	algorithm;distortion;image scaling;integrated test facility;movie projector;scalability	Wei Hong;Dennis Wei;Aziz Umit Batur	2010	2010 IEEE International Conference on Image Processing	10.1109/ICIP.2010.5649595	computer vision;jitter;computer science;control theory;affine transformation;mathematics	Robotics	53.9344808787351	-49.067677450661414	136214
2dc248288b02b151a039dd2d68de4e4f12817dab	video textures fractal modeling	autocorrelation function;incremental fourier synthesis algorithm;fractals;acf;incremental fourier synthesis algorithm natural video texture synthesis three dimensional extended self similar fractal model 3 d ess process autocorrelation function acf;video signal processing;texture synthesis;extended self similarity;correlation methods;three dimensional;3 d ess process;image texture;video signal processing correlation methods fourier transforms fractals image texture;fractal model;natural video texture synthesis;fourier transforms;fractals autoregressive processes solid modeling electronic switching systems clouds algorithm design and analysis video compression geometry autocorrelation fires;video texture synthesis extended self similarity fractal model video texture;three dimensional extended self similar fractal model;video texture synthesis;video texture	In this paper we propose a new method for natural video textures synthesis, using a three-dimensional (3-D) extended self-similar (ESS) fractal model. The autocorrelation functions (ACFs) of original texture increments are estimated, and a synthetic 3-D-ESS process whose increments have the same ACFs of the corresponding given ones is generated using a 3-D incremental Fourier synthesis algorithm. Experimental results for the analysis and synthesis of natural video textures are provided	algorithm;autocorrelation;fast fourier transform;fourier analysis;fractal;self-similarity;synthetic data	Patrizio Campisi;Emanuele Maiorana;Alessandro Neri	2007	IEEE Signal Processing Letters	10.1109/LSP.2006.890100	image texture;fourier transform;three-dimensional space;computer vision;speech recognition;autocorrelation;fractal;mathematics;texture synthesis;computer graphics (images)	Vision	61.23723696271293	-46.23869810394662	136245
9fe5e8f047ca3c60f0aa191cd81f42598cb7c843	consistent parametrization by quinary subdivision for remeshing and mesh metamorphosis	remeshing;multiresolution modeling;parameterization;computer graphic;metamorphosis;multiple objectives;mesh dissection;geometry processing	The vertex correspondence establishment among multiple objects is a versatile operation in computer graphics and geometry processing. We propose a systematic method called recursive quinary subdivision to efficiently find a dissection for a meshed object of genus-zero with little user input. The process can be easily extended to multiple objects, taking into account the alignment of extra feature points for applications such as mesh metamorphosis, to derive a common dissection. Based on the dissection and the parameterization associated with each resulting patch, uniform or adaptive remeshing can be performed to yield a set of semi-regular meshes. Moveover, geometric details can be easily resampled and stored as normal maps. We demonstrate the mesh metamorphosis application between two or more objects based on the vertex correspondence established by the common dissection and parameterization.	computer graphics (computer science);geometry processing;map;mesh parameterization;normal mapping;recursion;semiconductor industry;subdivision surface	Jian Liang Lin;Jung-Hong Chuang;Cheng-Chung Lin;Chih-Chun Chen	2003		10.1145/604471.604502	parametrization;simulation;computer science;geometry;metamorphosis;computer graphics (images)	Graphics	67.87226120369313	-44.70656099301737	136779
c671cf5585ea8d8f168a2271299ca316402e2016	a prism-based single-lens stereovision system: from trinocular to multi-ocular	ccd camera;prism;stereovision;stereo vision;multi ocular;camera calibration;trinocular	This paper investigates a passive stereovision system which employs one single CCD camera and one pyramid-like glass prism. Its trinocular variety is first presented: each image captured by this system can be split into three sub-images and these sub-images are taken as the images simultaneously captured by three virtual cameras which are generated by the prism. Two different approaches are developed to model this system: one bases on a conventional camera calibration technique and the other bases on geometrical analysis of ray sketching. The second approach is a relatively simpler but is sufficiently accurate as compared to the calibration based approach. Then the knowledge on this trinocular system is extended to build a single-lens multi-ocular stereovision system. Experiments are conducted to validate this system. The ideas presented in this paper are believed novel.	stereopsis	Yong Xiao;Kah Bin Lim	2007	Image Vision Comput.	10.1016/j.imavis.2007.01.002	computer vision;computer science;stereopsis;computer graphics (images)	Robotics	56.93893421431691	-49.984687809125326	136796
dec06cb35283fff290ed29f78a7f9496f72911c1	enhanced illumination of reconstructed dynamic environments using a real-time flame model	flames;real time;cultural heritage;three dimensional;dynamic environment;shadow algorithm;3d model;nurbs surface;real time animation;real time application;navier stokes equation;real time rendering	The goal of interactive walkthroughs in three dimensional computer reconstructions is to give people a sensation of immersion in different sites at different periods. Realism of these walkthroughs is achieved not only with detailed 3D models but also with a correct illumination regarding the means of lighting in those times. Working on the enhancement of the visual appearance of the computer reconstruction of the Gallo-Roman forum of Bavay, we propose a model that reproduces the shape, animation and illumination of simple flames produced by candles and oil lamps in real-time. Flame dynamics is simulated using a Navier-Stokes equation solver animating particle skeletons. Its shape is obtained using those particles as control points of a NURBS surface. The photometric distribution of a real flame is captured by a spectrophotometer and stored into a photometric solid. This one is used as a spherical texture in a pixel shader to compute accurately the illumination produced by the flame in any direction. Our model is compatible with existing shadow algorithms and designed to be easily incorporated in any cultural heritage real-time application.	3d modeling;algorithm;control point (mathematics);immersion (virtual reality);interactive storytelling;navier–stokes equations;pixel;real-time clock;real-time computing;real-time locating system;shader;solver	Flavien Bridault;Michel Leblond;François Rousselle	2006		10.1145/1108590.1108596	three-dimensional space;computer vision;flame;simulation;non-uniform rational b-spline;computer science;cultural heritage;real-time rendering;computer graphics (images)	Graphics	64.626014646426	-50.434965689268076	136821
fa0008cc99a6ce03eb47d3eb74f8163c9aa1b151	development of an ar based method for augmentation of 3d cad data onto a real ship block image		Abstract This paper proposes a method for augmenting a 3D CAD model of a ship block onto an image using an augmented reality technique. A two-dimensional image that captures a ship block is obtained using a digital camera. The image is processed to extract a feature of the block for establishing the correspondence between the block in the image and the 3D CAD model. In this work, a rectangular planar region is used as the feature in the image, which is then compared with face components in the CAD model. Once the correspondence is found, the initial pose of the block is computed using the correspondence information, and the CAD model is then augmented onto the image using the initial pose. Next, a registration process is employed to reduce the registration error further using a Lie Algebra-based method, which iteratively approximates the correct pose while reducing the error. As an option, a manual procedure is provided to allow a user to select the corresponding face for initial pose estimation. Real examples are used for testing the proposed method.	ar (unix);computer-aided design	Daewoon Kim;Jung Seo Park;Kwang Hee Ko	2018	Computer-Aided Design	10.1016/j.cad.2017.12.003	mathematical optimization;computer vision;digital camera;pose;mathematics;lie algebra;augmented reality;planar;artificial intelligence	EDA	55.19261713520091	-47.9468850722279	136930
58fd8409a8d514b04bb703d3d4728f465e45a3ec	estimating scale of a scene from a single image based on defocus blur and scene geometry	optical imaging system;image recognition;human vision;single view scale estimation defocus blur scene geometry optical imaging system optical lens human vision;geometry;layout;defocus blur;data mining;large scale;imaging system;eyes;optical imaging;scene geometry;single view scale estimation;lenses;humans;optical lens;layout geometry humans image recognition geometrical optics optical imaging lenses large scale systems eyes data mining;3d structure;large scale systems;geometrical optics	Using an imaging system in which the image plane can be tilted with respect to the optical axis of the lens, the image of a large-scale scene that appears to be a miniature to human eyes can be captured. This phenomenon suggests that the image contains information regarding the scale of the scene and that human vision can extract this information and recognize the scene scale from a single image. In this study, we consider how human vision can perform this single-view scale estimation. Although it is obvious that the existence of defocus blur in the image that simulates a shallow DOF plays an essential role in the scale estimation, we propose that this alone is not sufficient to explain the estimation mechanism. By incorporating a few assumptions, we theoretically show that scale estimation is made possible when (1) the 3D structure of the scene can be recovered from the image and furthermore, (2) the structure is combined with the defocus blur. Further, we present a simple algorithm for scale recognition and demonstrate its working using a real image.	algorithm;autostereogram;box blur;gaussian blur;image plane;optic axis of a crystal	Takayuki Okatani;Koichiro Deguchi	2007	2007 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2007.383217	image restoration;computer vision;gaussian blur;lens;computer graphics (images)	Vision	56.05747917257708	-51.65759300677467	136951
924e378c66cf3926c942465f94e8376412279240	ray tracing with cones	anti aliasing;texture mapping;procedural modeling;level of detail;ray tracing;light propagation	A new approach to ray tracing is introduced. The definition of a “ray” is extended into a cone by including information on the spread angle and the virtual origin. The advantages of this approach, which tries to model light propagation with more fidelity, include a better method of anti-aliasing, a way of calculating fuzzy shadows and dull reflections, a method of calculating the correct level of detail in a procedural model and texture map, and finally, a procedure for faster intersection calculation.	aliasing;graphics pipeline;level of detail;ray tracing (graphics);reflection (computer graphics);software propagation;spatial anti-aliasing;texture mapping	John Amanatides	1984		10.1145/800031.808589	cone tracing;distributed ray tracing;texture mapping;ray tracing;computer vision;computer science;level of detail;beam tracing;procedural modeling;computer graphics (images)	Graphics	64.86143025473768	-50.454376454145276	137160
5fdf3f35220a42902c5466848c790808171789b6	programmable rendering of line drawing from 3d scenes	line drawing;style;line drawings;3d model;nonphotorealistic rendering npr	This article introduces a programmable approach to nonphotorealistic line drawings from 3D models, inspired by programmable shaders in traditional rendering. This approach relies on the assumption generally made in NPR that style attributes (color, thickness, etc.) are chosen depending on generic properties of the scene such as line characteristics or depth discontinuities, etc. We propose a new image creation model where all operations are controlled through user-defined procedures in which the relations between style attributes and scene properties are specified. A view map describing all relevant support lines in the drawing and their topological arrangement is first created from the 3D model so as to ensure the continuity of all scene properties along its edges; a number of style modules operate on this map, by procedurally selecting, chaining, or splitting lines, before creating strokes and assigning drawing attributes. Consistent access to properties of the scene is provided from the different elements of the map that are manipulated throughout the whole process. The resulting drawing system permits flexible control of all elements of drawing style: First, different style modules can be applied to different types of lines in a view; second, the topology and geometry of strokes are entirely controlled from the programmable modules; and third, stroke attributes are assigned procedurally and can be correlated at will with various scene or view properties. We illustrate the components of our system and show how style modules successfully encode stylized visual characteristics that can be applied across a wide range of models.	3d modeling;color;encode;line drawing algorithm;scott continuity;shader;thickness (graph theory)	Stéphane Grabli;Emmanuel Turquin;Frédo Durand;François X. Sillion	2010	ACM Trans. Graph.	10.1145/1731047.1731056	computer vision;investor profile;machine learning;algorithm;computer graphics (images)	Graphics	65.1818533582072	-47.70395504031736	137331
6ca5b85777d65120e5dae02ace0d8ee5d1365e0b	an improved adaptive ray casting algorithm		Ray casting is frequently used as a means of rendering volume data. While this results in realistic images, the computational cost associated with ray casting is high. (Levoy 1990) has proposed a method of performing adaptive ray-casting. In this paper, we propose a relatively straightforward improvement to this algorithm which, under simulation, casts only 1/2 the rays used in the orignal algorithm on the average.	algorithm;point in polygon	Renben Shu;Alan Liu;Kuan-Tsae Huang	1991		10.1007/978-4-431-68147-2_14	ray casting;rendering (computer graphics);algorithm;computer science	Vision	66.5101327714478	-51.0932570210132	137416
d3c7adbc7821e633c72bd1a7c42f55ca263f7b8c	adaptive keyframing animation on the gpu using triangle strips	scientific application;deforming mesh adaptive keyframing animation gpu triangle strips deforming surface polygonal mesh view dependent method interactive rendering strip based approach level of detail;view dependent method;simplification;polygonal mesh;image resolution;motion pictures;computer graphics;triangle strips;institute;real time;multiresolution modeling;gpu;image;deformable models;runtime;video game;strip based approach;init;deforming surface;visualization;adaptation model;level of detail;shape;deforming mesh;interactive rendering;polygonal meshes;games;imaging;animation;multiresolution models;new;rendering computer graphics computer animation interactive systems mesh generation;simplification gpu animation multiresolution models level of detail triangle strip;strips;computer animation;rendering computer graphics;technologies;graphics processing unit;mesh generation;interactive systems;adaptive keyframing animation;triangle strip;animation strips hardware computer graphics motion pictures games spatial resolution shape runtime deformable models;hardware;spatial resolution	Deforming surfaces are present in scientific applications, movies and video games. In these fields, polygonal meshes are preferred to represent them. However, these meshes are usually complex and contain much more detail than is necessary for a given frame. A possible solution to efficiently manage such a large amount of information consists in using multiresolution modeling or level of detail. However, most of the work carried out in this respect has focused on managing static meshes, and only a few take advantage of using optimized primitives such as triangle strips or the new capabilities of current GPUs. In this paper, we present a view-dependent method for interactive rendering of keyframing animations in the GPU. Our strip-based approach is capable of managing the level of detail of this type of deforming meshes. We demonstrate the successful use of this method on the GPU. We can generate adaptive levels of detail during all frames of an animation in real-time while providing, at the same time, accurate approximations.	approximation;central processing unit;glossary of computer graphics;graphics hardware;graphics processing unit;key frame;level of detail;modeling language;parallel computing;polygon mesh;real-time locating system;rendering (computer graphics);strips;shader;static mesh;triangle strip	Francisco Ramos;Miguel Chover;Oscar Ripolles	2010	2010 International Conference on Computational Science and Its Applications	10.1109/ICCSA.2010.45	medical imaging;computer vision;simulation;image resolution;computer science;artificial intelligence;computer graphics (images)	Graphics	65.73252774580952	-49.31723173014106	137452
fd50d0983276c07281966d16619e41e2d4e0effb	three-dimensional interpretation of quadrilaterals	three dimensional;line drawings	"""Quadrilaterals are figures with which everybody becomes familiar in his/her very early stage of education. By studying these seemingly simple figures we can obtain some insights into the nature of the general problem of interpreting image contours. This paper discusses in detail how quadrilaterals are interpreted three-dimensionally, and draws feasible inferences about the general properties of the human system of processing line drawings. First the rectan-gularity regularity is proposed to be the prime constraint in the visual interpretation of quadrilaterals. The subjective """"image center' 1 and focal length (finite and infinite) are determined together with rectangle orientation. Secondly, interpretation of quadrilater-als as faces of a rectangular polyhedron is examined at both the geometrical level and the perceptual level. Finally the gravity regularity is proposed to derive constraints on the rectangle orientation by analyzing the relation among the camera, the ground and the rectangles supported by the ground."""	focal (programming language);polyhedron	Gang Xu;Saburo Tsuji	1989			three-dimensional space;combinatorics;computer science;mathematics;geometry;algorithm	Vision	64.84665315025207	-40.674637859829666	137835
2848bc907232085fef625ae7bbdb552441f08933	real-time recursive specular reflections on planar and curved surfaces using graphics hardware	texture;real-time rendering;environment mapping.;recursive specular reflections;texture mapping;ray tracing;graphics hardware;real time;real time rendering;specular reflection	Real-time rendering of recursive reflections have previously been done using different techniques. However, a fast unified approach for capturing recursive reflections on both planar and curved surfaces, as well as glossy reflections and interreflections between such primitives, have not been described. This paper describes a framework for efficient simulation of recursive specular reflections in scenes containing both planar and curved surfaces. We describe and compare two methods that utilize texture mapping and environment mapping, while having reasonable memory requirements. The methods are texture-based to allow for the simulation of glossy reflections using image-filtering. We show that the methods can render recursive reflections in static and dynamic scenes in real-time on current consumer graphics hardware. The methods make it possible to obtain a realism close to ray traced images at interactive frame rates.	amiga reflections;approximation algorithm;beam tracing;bidirectional reflectance distribution function;fastest;graphics hardware;map;real-time transcription;recursion (computer science);reflection (computer graphics);reflection mapping;requirement;simulation;texture mapping;time complexity	Kasper Høy Nielsen;Niels Jørgen Christensen	2002			artificial intelligence;rendering (computer graphics);computer vision;computer graphics (images);reflection mapping;real-time computer graphics;specular highlight;texture mapping;ray tracing (graphics);global illumination;real-time rendering;computer science	Graphics	65.81610219181108	-51.108143648023834	137887
4da8177538cdfc741f8f36688c35ed9c25bf0ee3	geometric primitives based deformation techniques for arbitrary meshes	geometric primitives;real time;nurbs surface;generic point;geometric modeling;free form deformation;interactive mesh editing;geometric model;constrained free form deformations;nurbs surfaces	We present an approach to deform arbitrary meshes based on geometric primitives. The basic idea is to predefine a certain set of geometric primitives, such as points, curves, spheres, cubes and deform the specific areas of the objects aligning those of the given geometric primitives. In general, point and curve primitives are able to provide sharp corners and ridge features; sphere primitives are able to achieve smoothing effects and provide semi-sharp features; and cube primitives are able to handle sharp corners, sharp edges and flat faces with the corners, edges and faces of the cubes respectively. We used the Bézier-shaped displacement reference curves to determine the new position of the vertices on the deforming surfaces. The proposed approach is fast and robust, and can support real-time interactive mesh editing and handle arbitrary meshes thanks to re-sampling and subdivision operations.	bézier curve;displacement mapping;geometric primitive;olap cube;real-time clock;robustness (computer science);sampling (signal processing);semiconductor industry;smoothing;subdivision surface	Leilei Li;Sanyuan Zhang;Xinyu Zhang;Xiuzi Ye	2004		10.1145/1044588.1044638	geometric primitive;computer science;geometric modeling;geometry	Graphics	68.03338268055438	-44.47908240990367	138027
010b9e7bf13d139f98bcb4539760d8633fccf0e3	projection-based visualization of tangential deformation of nonrigid surface by deformation estimation using infrared texture	projection based mixed reality;deformable surface;user interaction	In this paper, we propose a projection-based mixed reality system that visualizes the tangential deformation of a nonrigid surface by superimposing graphics directly onto the surface by projected imagery. The superimposed graphics are deformed according to the surface deformation. To achieve this goal, we develop a computer vision technique that estimates the tangential deformation by measuring the frame-by-frame movement of an infrared (IR) texture on the surface. IR ink, which can be captured by an IR camera under IR light, but is invisible to the human eye, is used to provide the surface texture. Consequently, the texture does not degrade the image quality of the augmented graphics. The proposed technique measures individually the surface motion between two successive frames. Therefore, it does not suffer from occlusions caused by interactions and allows touching, pushing, pulling, and pinching, etc. The moving least squares technique interpolates the measured result to estimate denser surface deformation. The proposed method relies only on the apparent motion measurement; thus, it is not limited to a specific deformation characteristic, but is flexible for multiple deformable materials, such as viscoelastic and elastic materials. Experiments confirm that, with the proposed method, we can visualize the surface deformation of various materials by projected illumination, even when the user’s hand occludes the surface from the camera.	computer vision;experiment;graphics;image quality;interaction;interpolation;mixed reality;motion estimation;movie projector;moving least squares;real-time clock	Parinya Punpongsanon;Daisuke Iwai;Kosuke Sato	2014	Virtual Reality	10.1007/s10055-014-0256-y	computer vision;computer graphics (images)	Vision	62.04133364112804	-51.405448556070745	138340
444d55e24be212b767dda96ddd6686952b468919	mapping by seeing - wearable vision-based dead-reckoning, and closing the loop	distance estimation;a priori knowledge;wearable computer;optical flow;dead reckoning	We introduce, characterize and test a vision-based dead-reckoning system for wearable computing that allows to track the user’s trajectory in an unknown and non-instrumented environment by integrating the optical flow. Only a single inexpensive camera worn on the body is required, which may be reused for other purposes such as HCI. Result show that distance estimates are accurate (6-12%) while rotation tends to be underestimated. The accumulation of errors is compensated by identifying previously visited locations and “closing the loop”; it results in greatly enhanced accuracy. Opportunistic use of wireless signatures is used to identify similar locations. No a-priori knowledge of the environment such as map is needed, therefore the system is well-suited for wearable computing. We identify the limitations of this approach and suggest future improvements.	antivirus software;closing (morphology);closing the loop;dead reckoning;human–computer interaction;optical flow;propagation of uncertainty;tree accumulation;wearable computer	Daniel Roggen;Reto Jenny;Patrick de la Hamette;Gerhard Tröster	2007		10.1007/978-3-540-75696-5_2	dead reckoning;embedded system;computer vision;a priori and a posteriori;simulation;wearable computer;computer science;optical flow	HCI	55.52277265285558	-38.50535002046685	138414
e4066400b45baf19befe35441dd5bbf8f23eea6b	direct rendering of deformable volume data	analisis imagen;image tridimensionnelle;volume rendering;morfometria;volume;encefalo;algorithme;morphometry;algorithm;reconstruction image;volumen;deformation;encephale;reconstruccion imagen;image reconstruction;tridimensional image;image analysis;analyse image;deformacion;morphometrie;imagen tridimensional;algoritmo;brain vertebrata	In this paper, we present a new deformable volume rendering algorithm. The volume deformation is modeled by a landmark-based volume morphing method uisng Hardy's scattered data interpolation. The algorithm is able to directly render the deformed volume without going through the expensive volume construction process. Piecewise linear approximation of the deformation function by adaptive space subdivision and template-based block projection are used to speed up the rendering process. Our algorithm can render the morphing of a 256 3 volume in seconds, instead of minutes and hours with the traditional morphing-rendering pipeline	algorithm;graphics pipeline;linear approximation;morphing;multivariate interpolation;piecewise linear continuation;subdivision surface;volume rendering	Shiaofen Fang;Rajagopalan Srinivasan	1997		10.1117/12.273929	computer vision;geography;cartography;computer graphics (images)	Visualization	68.27340360135024	-49.2775319862683	138485
0dc0bfe8c45bb80cd7044f6a44fa7f4bc42c1205	ping-pong robotics with high-speed vision system	manipulators;motion control;image segmentation;humanoid robot arm ping pong robotics high speed vision system visual feedback low sampling rate dynamic motion control multithreshold segmentation algorithm stereo vision 3d ball position estimation motion planning manipulator iterative methods;trajectory cameras machine vision robot kinematics image color analysis;robot vision;humanoid robots;stereo image processing;trajectory control humanoid robots image segmentation manipulators motion control robot vision stereo image processing;trajectory control	The performance of vision-based control is usually limited by the low sampling rate of the visual feedback. We address Ping-Pong robotics as a widely studied example which requires high-speed vision for highly dynamic motion control. In order to detect a flying ball accurately and robustly, a multi-threshold segmentation algorithm is applied in a stereo-vision running at 150Hz. Based on the estimated 3D ball positions, a novel two-phase trajectory prediction is exploited to determine the hitting position. Benefiting from the high-speed visual feedback, the hitting position and thus the motion planning of the manipulator are updated iteratively with decreasing error. Experiments are conducted on a 7 degrees of freedom humanoid robot arm. A successful Ping-Pong playing between the robot arm and human is achieved with a high successful rate of 88%.	algorithm;automated planning and scheduling;humanoid robot;motion estimation;motion planning;navier–stokes equations;robotic arm;robotics;sampling (signal processing);stereopsis;two-phase commit protocol;two-phase locking	Hailing Li;Haiyan Wu;Lei Lou;Kolja Kühnlenz;Ole Ravn	2012	2012 12th International Conference on Control Automation Robotics & Vision (ICARCV)	10.1109/ICARCV.2012.6485142	control engineering;motion control;computer vision;structure from motion;simulation;computer science;humanoid robot;artificial intelligence;arm solution;control theory;robot control;image segmentation	Robotics	55.67498008297779	-39.0533723095919	138495
aafe4d93796ef443844ce593f6e03a16384afb15	dataset and pipeline for multi-view light-field video		The quantity and diversity of data in Light-Field videos makes this content valuable for many applications such as mixed and augmented reality or post-production in the movie industry. Some of such applications require a large parallax between the different views of the Light-Field, making the multi-view capture a better option than plenoptic cameras. In this paper we propose a dataset and a complete pipeline for Light-Field video. The proposed algorithms are specially tailored to process sparse and wide-baseline multi-view videos captured with a camera rig. Our pipeline includes algorithms such as geometric calibration, color homogenization, view pseudo-rectification and depth estimation. Such elemental algorithms are well known by the state-of-the-art but they must achieve high accuracy to guarantee the success of other algorithms using our data. Along this paper, we publish our Light-Field video dataset that we believe may be of special interest for the community. We provide the original sequences, the calibration parameters and the pseudo-rectified views. Finally, we propose a depth-based rendering algorithm for Dynamic Perspective Rendering.	algorithm;augmented reality;baseline (configuration management);data compression;elemental;image rectification;light field;parallax;real-time clock;real-time computing;requirement;sparse matrix	Neus Sabater;Guillaume Boisson;Benoit Vandame;Paul Kerbiriou;Frederic Babon;Matthieu Hog;Remy Gendrot;Tristan Langlois;Olivier Bureller;Arno Schubert;Valerie Allie	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)	10.1109/CVPRW.2017.221	artificial intelligence;rendering (computer graphics);computer vision;computer science;parallax;light field;augmented reality	Vision	54.459141877207465	-46.6379035105494	138888
235620c56eb506f13236a9707c1fe4f75e60c312	3d cnn based phantom object removing from mobile laser scanning data	qa75 electronic computers computer science szamitastechnika;szamitogeptudomany	In this paper we introduce a new deep learning based approach to detect and remove phantom objects from point clouds produced by mobile laser scanning (MLS) systems. The phantoms are caused by the presence of scene objects moving concurrently with the MLS platform, and appear as long, sparse but irregular point cloud segments in the measurements. We propose a new 3D CNN framework working on a voxelized column-grid to identify the phantom regions. We quantitatively evaluate the proposed model on real MLS test data, and compare it to two different reference approaches.	deep learning;imaging phantom;phantom reference;point cloud;reference implementation;sparse matrix;test data	Balázs Nagy;Csaba Benedek	2017	2017 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2017.7966417	computer vision;simulation;computer science;computer graphics (images)	Robotics	55.08059169859592	-46.87044474466929	138951
fc9044b564a18c74a3d9d5f67eea0463040dd6ca	realistic 2d facial animation from one image	matting;realistic expression;texture synthesis;two dimensional facial animation;warping;pseudo depth	In this paper we present a novel complete framework for creating realistic facial animation given only one neutral facial image as an input data. Our approach is carried on in a two-dimensional image space, instead of three-dimensional space. In addition, we employ an advanced computer vision method (digital image matting) as well as conventional image processing techniques (texture synthesis and image warping) in order to express more realistic facial animations. The major contribution of this work is showing how facial animation with a variety of realistic expressions can be generated very efficiently, where not only main facial components (e.g., eyeball, eyebrow and lip) but also pseudo-depth values obtained from their alpha mattes are utilized in our system. Simulations with real image confirm that our scheme produces high quality facial animations with an ease.		Jaehwan Kim;Il-Kwon Jeong	2011		10.1007/978-3-642-24500-8_27	computer vision;facial motion capture;computer science;multimedia;computer graphics (images)	Graphics	65.52389895711907	-46.29414201875881	139083
129856e6b12afb2f7bf0b27e2d912b26d8bbfd4d	bdam - batched dynamic adaptive meshes for high performance terrain visualization	communication model;graphics hardware;tree structure;terrain visualization;dynamic adaptation;high performance	This paper describes an efficient technique for out-of-core rendering and management of large textured terrain surfaces. The technique, called Batched Dynamic Adaptive Meshes (BDAM) , is based on a paired tree structure: a tiled quadtree for texture data and a pair of bintrees of small triangular patches for the geometry. These small patches are TINs and are constructed and optimized off-line with high quality simplification and tristripping algorithms. Hierarchical view frustum culling and view-dependent texture and geometry refinement is performed at each frame through a stateless traversal algorithm. Thanks to the batched CPU/GPU communication model, the proposed technique is not processor intensive and fully harnesses the power of current graphics hardware. Both preprocessing and rendering exploit out-of-core techniques to be fully scalable and to manage large terrain datasets.	blackwell (series);central processing unit;core data;display resolution;eurographics;frustum;glossary of computer graphics;graphics hardware;graphics processing unit;hidden surface determination;level of detail;online and offline;out-of-core algorithm;preprocessor;quadtree;refinement (computing);rendering (computer graphics);scalability;stateless protocol;tree structure	Paolo Cignoni;Fabio Ganovelli;Enrico Gobbetti;Fabio Marton;Federico Ponchio;Roberto Scopigno	2003	Comput. Graph. Forum	10.1111/1467-8659.00698	simulation;models of communication;computer science;theoretical computer science;tree structure;graphics hardware;computer graphics (images)	Visualization	68.29242142758325	-50.98324972993638	139363
80cc746cb000ab17732addc08c1b2dd22abec739	a new spring model for modeling deformable objectsn				Il-Kwon Jeong;In-Ho Lee	2003				Vision	63.58708362307493	-45.40301320603171	139493
d02a383a47788f96c340352f25125b7bfc54c48b	a geometric correction method using stereo vision for projected images	geometric correction;stereo image processing cameras computer vision feature extraction optical projectors;sift projector camera system stereo vision geometric correction phase only correlation;image deformation geometric correction method stereo vision projected image projector display surface 3d measurement technique stereo camera correspondence search technique phase only correlation;optical projectors;computer vision;sift;projector camera system;feature extraction;stereo image processing;stereo vision;graphic processing unit;graphics processing unit;3d measurement;cameras;phase only correlation	This paper proposes a geometric correction method using stereo camera for projected images. When we use a projector in the various places, a projected image is deformed due to the shape of a display surface, the positional relationship between a projector and a display surface, etc. Addressing this problem, we propose a geometric correction method for projected images, which employs 3D measurement technique with the stereo camera. The proposed method enables us to automatically correct the deformation of projected images during the projection of ordinary images. In our method, we employ the correspondence search technique based on Phase-Only Correlation (POC) to obtain dense 3D shape of the display surface. A set of experiments demonstrates that the proposed method is effective for correcting deformation of projected images.	distortion;experiment;real-time clock;stereo camera;stereopsis;video projector	Koichi Ito;Toru Takahashi;Takafumi Aoki	2011	The First Asian Conference on Pattern Recognition	10.1109/ACPR.2011.6166635	computer vision;mathematics;optics;computer graphics (images)	Vision	55.151699529454824	-48.60499235291876	139638
13ced9c1e6506b4ec7f3a6e10890dc7264cbefb9	ekf based pose estimation using two back-to-back stereo pairs	drift pose ekf multiple cameras stereo;nonlinear filters;long sequence drift ekf pose estimation back to back stereo pairs robot motion multiple cameras extended kalman filter;kalman filters;indexing terms;robots;stereo image processing;drift;cameras robot vision systems filters stereo vision motion estimation service robots augmented reality industrial training layout calibration;stereo;ekf;stereo image processing cameras kalman filters nonlinear filters robots;extended kalman filter;pose;multiple cameras;cameras;pose estimation	In this work, we solve the pose estimation problem for robot motion by placing multiple cameras on the robot. In particular, we use four cameras arranged as two back-to-back stereo pairs combined with the extended Kalman filter (EKF). The reason for using multiple cameras is that the pose estimation problem is more constrained for multiple cameras than for a single camera. Back-to-back cameras are used since they provide more information. Stereo information is used in self initialization and outlier rejection. Different approaches to solve the long-sequence-drift have been suggested. Both the simulations and the real experiments show that our approach is fast, robust, and accurate.	3d pose estimation;experiment;extended kalman filter;rejection sampling;robustness (computer science);simulation	Mohammad Ehab Ragab;Kin Hong Wong;Junzhou Chen;Michael Ming-Yuen Chang	2007	2007 IEEE International Conference on Image Processing	10.1109/ICIP.2007.4379540	stereo cameras;computer vision;simulation;pose;computer science;control theory;extended kalman filter	Robotics	53.87397357478114	-40.349224524233485	139973
826ebe460664bbabc34597cc29e0614ae0cf58e7	animating character images in 3d space	animated character	In this extended abstract, we present a system that allows the user to animate character images in 3D space by applying an existed 3D character model with motion data. The character model with skeleton rigged is used as a template model to fit the silhouette of the character image. After assigning some corresponding points between the character image and template model, the system then fits the model to the image and transfer the colors and patterns of the image to the model as the textures. Finally, the user can apply any motion data to animate the fitted 3D character model in 3D space.	color;fits	Bing-Yu Chen;Shih-Chiang Dai;Shuen-Huei Guan;Tomoyuki Nishita	2009		10.1145/1599301.1599302	computer vision;computer science;mathematics;computer graphics (images)	Graphics	64.6580297863236	-46.97444976483421	140100
4985c765df2d33285c62e5dcb795f18018ebbcda	deformation styles for spline-based skeletal animation	space deformation;skeletal subspace deformation;skeletal animation;existing deformation technique;designable deformation;skeletal animation system;pose-dependent deformation behavior;animation system;spline-based skeletal animation;deformation style;spline-aligned deformation;real time	We present a novel skinned skeletal animation system based on spline-aligned deformations for providing high quality and fully designable deformations in real-time. Our ambition is to allow artists the easy creation of abstract, pose-dependent deformation behaviors that might directly be assigned to a large variety of target objects simultaneously. To achieve this goal, we introduce the usage of deformation styles and demonstrate their applicability by our animation system. We therefore enhance spline-skinned skeletal animation with two sweep-based free-form-deformation (FFD) variants. The two FFD variants are pose-dependent, driven by three textures and three curves, which can be designed by the artist. As the three textures are similar to height-maps, their creation is very intuitive. Once designed, the deformation styles can be directly applied to any number of targets for imitating material behaviors of cloth, metal or even muscles. Our GPU based implementation shows promising results for real-time usage, as about 30 Million vertices per second can be animated. The basic spline-skinning even reaches more than twice the speed and gets close to the performance of skeletal subspace deformation (SSD). Furthermore, our method can easily be combined along with other existing deformation techniques as pose space deformation or SSD.	display resolution;free-form deformation;graphics processing unit;map;pose space deformation;real-time computing;real-time locating system;real-time transcription;skeletal animation;solid-state drive;spline (mathematics);vertex (graph theory)	Sven Forstmann;Jun Ohya;Artus Krohn-Grimberghe;Ryan McDougall	2007			computer vision;real-time computing;simulation;skeletal animation;computer science;artificial intelligence;geometry;computer graphics (images)	Graphics	64.52064124796348	-47.37143643854258	140367
096bc709599951b377ebfcf5bfa1706f2ded7cc8	visibility preprocessing for interactive walkthroughs	superset visibility;hidden surface removal;graph connectivity;architectural simulation;linear program	The number of polygons comprising interesting architectural models is many more than can be rendered at interactive frame rates. However, due to occlusion by opaque surfaces (e.g., walls), only a small fraction of a typical model is visible from most viewpoints.We describe a method of visibility preprocessing that is efficient and effective for axis-aligned or axial architectural models. A model is subdivided into rectangular cells whose boundaries coincide with major opaque surfaces. Non-opaque portals are identified on cell boundaries, and used to form an adjacency graph connecting the cells of the subdivision. Next, the cell-to-cell visibility is computed for each cell of the subdivision, by linking pairs of cells between which unobstructed sightlines exist.During an interactive walkthrough phase, an observer with a known position and view cone moves through the model. At each frame, the cell containing the observer is identified, and the contents of potentially visible cells are retrieved from storage. The set of potentially visible cells is further reduced by culling it against the observer's view cone, producing the eye-to-cell visibility. The contents of the remaining visible cells are then sent to a graphics pipeline for hidden-surface removal and rendering.Tests on moderately complex 2-D and 3-D axial models reveal substantially reduced rendering loads.	apache axis;cognitive walkthrough;graphics pipeline;hidden surface determination;portals;preprocessor;rendering (computer graphics);subdivision surface	Seth J. Teller;Carlo H. Séquin	1991		10.1145/122718.122725	computer vision;hidden surface determination;computer science;linear programming;connectivity;mathematics;geometry;computer graphics (images)	Graphics	66.98349389178925	-48.409768935724934	140444
5d81967b38d9cfabfefb86c19d2dbc7424a42dfd	the primal seas: water on playstation 2	environment maps;3d photography;3d camera;sea surface;3d shape acquisition;sea water;real time rendering	In this sketch we present a variety of water and sea effects seen in the PlayStation®2 game Primal™ (released Q1 2003), culminating in a sea surface with a real-time rendered parabolic environment map and refracted undersea view.	parabolic antenna;playstation 3;real-time locating system;reflection mapping;synthetic environment for analysis and simulations	Andrew Ostler	2003		10.1145/965400.965475	seawater;computer science;real-time rendering	AI	63.09606747270475	-51.12727051714565	140545
d6dde1249eeb997f7afb2286531e5ec8f3775ab1	an algorithm for filling regions on graphics display devices	additional key words and phrases: polygons;graphics display devices;fill algorithms;shading	The display of shaded polygons, either by lines, crosshatching, dots, or continuous color patterns is a task frequently used in many application areas of computer graphics. In applications such as the production of hidden surface images, cartography, and animation, algorithm efficiency is important. In this paper, a new fill algorithm is presented which will fill an arbitrary polygon in the plane.-'No sorting is required and the algorithm is suitable for microprocessor or hardware implementation.	algorithm;algorithmic efficiency;cartography;computer graphics;hidden surface determination;microprocessor;shading;sorting	Jeffrey M. Lane;R. Magedson;M. Rarick	1983	ACM Trans. Graph.	10.1145/357323.357326	computer vision;2d computer graphics;computer hardware;real-time computer graphics;computer graphics (images)	Graphics	67.06505903642032	-50.703157343702536	140614
ca6410a7fcc579483a6df16bec6ea1fa25ae3f9d	facets: a new algorithm for extracting 3-d surface from volume data	surface reconstruction;software engineering;three dimensional;scientific visualization;computational science;medical image;scientific programming;geometric model;volume data	Three dimensional surface reconstruction from volume data is very useful in medical imaging, scientific visualization and geometric modeling. Given a set of uniform sampled 3-D volume data, the problem of surface construction is to interpolate or approximate the three dimensional surface from it. A simple and efficient method, Facets, is proposed to extract the accurate and continuous surface with consistent topology.	approximation algorithm;geometric modeling;interpolation;medical imaging;scientific visualization	Yun Wang	1995		10.1145/1122018.1122042	computer science;data science;theoretical computer science	Visualization	67.74567402110948	-46.25434612935709	140774
a775b9309291b58066ce78a269b174845cdcb769	a quick algorithm to track welding line based on computer vision	binarization;welding line location;robotic welding arc welding edge detection image segmentation;arc welding;welding torch location;image segmentation;binary image;edge detection;compute vision;tig welding robot welding line tracking algorithm computer vision edge detection binarization target area segmentation welding torch location welding line location maximal variance;real time;welding pipe and tube;welding;tig welding robot;data mining;computer vision;maximal variance;image edge detection;pixel;welding line tracking algorithm;robots;maximal variance between class;tig welding;region growing tig welding compute vision welding pipe and tube maximal variance between class;welding computer vision image edge detection robot kinematics image segmentation target tracking automotive engineering computational intelligence algorithm design and analysis cameras;region growing;robotic welding;cameras;noise;target area segmentation	In this paper, we propose an algorithm to track welding line of TiG welding in welding pipe or tube. The proposed algorithm consists of detecting edge, binarization, segmenting target area, locating welding torch and locating welding line. Firstly, we use prewitt operator to form the edge of image which is acquired from industrial camera. Secondly, we achieve the binary image by using maximal variance between-class, then segment the image based on region growing and get the target area including welding torch, welding pool and welding line. Finally, the center of welding torch and welding line is computed and the difference of them is used to control the action of motor to track welding line. Experimental results indicate that all steps of the proposed algorithm consume less than 80ms while location is accurate, and the proposed real-time algorithm can be used for TiG welding robot in practice.	algorithm;binary image;computer vision;maximal set;prewitt operator;property (philosophy);real-time locating system;region growing;robot welding;sensor;torch	Yigang Wang;Jialin Cui;Shengli Fan	2009	2009 Second International Symposium on Computational Intelligence and Design	10.1109/ISCID.2009.84	robot;robot welding;computer vision;arc welding;edge detection;binary image;computer science;noise;region growing;image segmentation;gas tungsten arc welding;pixel;welding	Robotics	59.98166050719771	-39.79798427474259	140784
9e8f81c719b139b5993dbcf3ad2437b0f9453dc6	unicube for dynamic environment mapping	hardware filtering graphics sampling methods degradation reflection mirrors shape strips shadow mapping;lookup vector;computer graphics;equal area strip;real time filtering;isocube mapping;unicube mapping;real time systems computer graphics;dynamic environment;hardware support;filtering quality unicube mapping dynamic environment mapping equal area strip;three dimensional displays;solid modeling;sampling pattern;unicube;mathematical model;filtering quality;spherical surface;cube mapping;face;six face structure;rectilinear structure;rendering computer graphics;nonrectilinear property;real time filtering dynamic environment mapping unicube cube mapping graphics applications hardware support spherical surface six face structure isocube mapping nonrectilinear property filtering quality rectilinear structure sampling pattern lookup vector;graphics applications;hardware;real time systems;dynamic environment mapping	Cube mapping is widely used in many graphics applications due to the availability of hardware support. However, it does not sample the spherical surface evenly. Recently, a uniform spherical mapping, isocube mapping, was proposed. It exploits the six-face structure used in cube mapping and samples the spherical surface evenly. Unfortunately, some texels in isocube mapping are not rectilinear. This nonrectilinear property may degrade the filtering quality. This paper proposes a novel spherical mapping, namely unicube mapping. It has the advantages of cube mapping (exploitation of hardware and rectilinear structure) and isocube mapping (evenly sampling pattern). In the implementation, unicube mapping uses a simple function to modify the lookup vector before the conventional cube map lookup process. Hence, unicube mapping fully exploits the cube map hardware for real-time filtering and lookup. More importantly, its rectilinear partition structure allows a direct and real-time acquisition of the texture environment. This property facilitates dynamic environment mapping in a real time manner.	cube dosage form;cube mapping;face;graphics;lookup table;real-time clock;reflection mapping;regular grid;sampling (signal processing);texel (graphics)	Tze-Yui Ho;Liang Wan;Andrew Chi-Sing Leung;Ping-Man Lam;Tien-Tsin Wong	2011	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2009.205	face;cube mapping;computer vision;displacement mapping;computer science;theoretical computer science;relief mapping;mathematical model;mathematics;geometry;solid modeling;computer graphics;data cube;statistics;computer graphics (images)	Visualization	67.67513432626247	-51.339148934774855	140871
db2f9f7098ce667953f967c99b7911c290425daa	shellcam: interactive geometry-aware virtual camera control	virtual camera control model;gpu algorithms virtual camera control model interactive navigation 3d user interfaces;gpu algorithms;3d navigation shellcam interactive geometry aware virtual camera control pan and zoom navigation arbitrary 3d object camera object distance logarithmic zoom motion moving least square approach smooth object aware 3d motion gpu standard rasterization pipeline inconsistent geometry complex topology 3d inspection task transparent swap;cameras three dimensional displays geometry inspection solid modeling computational modeling graphics processing units;3d user interfaces;video cameras computational geometry data visualisation graphics processing units least squares approximations topology user interfaces;interactive navigation	We introduce ShellCam, a geometry-aware virtual camera control model which defines a smooth motion subspace enabling Pan&Zoom navigation on arbitrary 3D objects. The basic idea is to define a scale-dependent offset shell around the visible geometry which provides, at any point, a meaningful tangent direction for panning and helps computing the camera-object distance to rule accurately a logarithmic zoom motion. We define the underlying motion space as a visualization hull and evaluate it on-the-fly using a moving least-squares approach. As a result, ShellCam provides smooth object-aware 3D motions, combining rotations and translations, based on a simple 2D user input such as typically produced by mouse motions. We also provide an efficient GPU implementation which makes use of the standard rasterization pipeline to compute this 3D motion efficiently. Our approach is robust to inconsistent geometry such as point clouds or polygon soups, works on shapes with complex topology, does not require any pre-computation and can be used on dynamic data. ShellCam offers a convenient control for 3D inspection tasks and a transparent swap with other control models for more general 3D navigation. Last, our model is straightforward to integrate in any 3D application.	computation;dynamic data;graphics processing unit;moving least squares;point cloud;polygon soup;precomputation;rasterisation;virtual camera system	Tamy Boubekeur	2014	2014 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2014.7025813	computer vision;simulation;computer science;computer graphics (images)	Visualization	66.27338344935274	-49.54114393476069	141052
6ecc6613c881e805a406790c63e760a64e7f93d4	homological invariants and holorgraphic representations of topological structures in cellular spaces	abstract structures;topological spaces;graph theory;topology;higher order operators;modeling tools;physical simulations;topological space;heart;simplicial complex;holorgraphic representations;physics based modeling;combinational methods;computer graphics;graph theoretic representation;expressional power;solid modeling computational modeling shape heart research and development computer graphics virtual environment rendering computer graphics physics computing computer simulation;computational geometry;topological structures;virtual environments;homotopy;holorgraphic geometric modeling;physics computing;dynamic environments;higher order;computer graphic;invariance;multi dimensional;algebraic geometry;dynamic environment;computational modeling;research and development;homological invariants;shape;computational geometry invariance topology computer graphics;analytical flexibility;combinatorial structures;cellular spaces;solid modeling;analytical expressions;analytic algebraic geometry;homotopy homological invariants holorgraphic representations topological structures cellular spaces holorgraphic geometric modeling computational shape representations computer graphics virtual environments image based rendering computer aided geometric design physical simulations physically based modeling topological feature identification interaction modes static environments dynamic environments abstract structures analytical expressions modeling tools combinational methods analytic algebraic geometry graph theoretic representation combinatorial structures analytical flexibility expressional power scalability higher order multi dimensional variables higher order operators holors simplicial complexes;computational shape representations;of research and development;geometric modeling;simplicial complexes;geometric model;scalability;virtual environment;image based rendering;higher order multi dimensional variables;rendering computer graphics;topological feature identification	Geometric modeling and computational representations of shapes have been subject to intense research for more than three decades. Interestingly, these subjects are still at the heart of a continuous activity of research and development in computer graphics, virtual environments, image-based rendering, computer-aided geometric design and physical simulations. Currently, geometric and physically-based modeling still face two main challenges: (1) the identification of topological features, and (2) the representation of the modes of interaction between them, both in static and dynamic environments. Current methods have offered many different forms of associating abstract structures with analytical expressions. The variety of modeling tools, from combinational methods to analytic algebraic geometry, not only reflects the richness of ideas in this domain of study but also the desire to improve, enhance and simplify. It is within this realm that we introduce a new framework, called holorgraphic geometric modeling (HGM). This framework combines the advantages of the graph-theoretic representation of combinatorial structures with the analytical flexibility, expressional power and scalability of higher-order, multi-dimensional variables and operators in the form of holors. HGM not only complements the combinatorial structures in geometric modeling but also enhances and reveals new concepts and ideas in the process of developing robust, flexible and scalable domains of formulation for simplicial complexes, cellular spaces, and homotopy in general.	spaces	George Baciu;Tosiyasu L. Kunii	2000		10.1109/CGI.2000.852324	computer simulation;combinatorics;discrete mathematics;algebraic geometry;computational geometry;computer science;graph theory;theoretical computer science;geometric modeling;mathematics;geometry;topological space	Logic	65.94191743727941	-45.312955673854844	141266
e00ab75a8aa637d9c4c5c020e9f2c54b31528031	3d actionslam: wearable person tracking in multi-floor environments	wearable systems;t technology;location aware computing;simultaneous localization and mapping;indoor tracking;pedestrian dead reckoning;tk7885 computer engineering computer hardware	We present 3D ActionSLAM, a stand-alone wearable system that can track people in previously unknown multi-floor environments with sub-room accuracy. ActionSLAM stands for action-based simultaneous localization and mapping: It fuses dead reckoning data from a foot-mounted inertial measurement unit with the recognition of location-related actions to build and update a local landmark map. Simultaneously, this map compensates for position drift errors that accumulate in open-loop tracking by means of a particle filter. To evaluate the system performance, we analyzed 23 tracks with a total walked distance of 6,489 m in buildings with up to three floors. The algorithm robustly (93 % of runs converged) mapped the areas with a mean landmark positioning error of 0.59 m. As ActionSLAM is fully stand-alone and not dependent on external infrastructure, it is well suited for patient tracking in remote health care applications. The algorithm is computationally light-weight and runs in real-time on a Samsung Galaxy S4, enabling immediate location-aware feedback. Finally, we propose visualization techniques to facilitate the interpretation of tracking data acquired with 3D ActionSLAM.	3d film;activity recognition;algorithm;chart;dead reckoning;dynamic range;experiment;heat map;location awareness;particle filter;real-time clock;simultaneous localization and mapping;smartphone;wearable computer	Michael Hardegger;Daniel Roggen;Gerhard Tröster	2014	Personal and Ubiquitous Computing	10.1007/s00779-014-0815-y	embedded system;computer vision;simulation;tracking system;computer science;artificial intelligence;simultaneous localization and mapping	HCI	55.548353337010134	-38.52496290481676	141279
ed85621ec89550052e347743c7d71958679c4189	multiresolution hierarchies on unstructured triangle meshes	hierarchical structure;constrained energy minimization;computer graphic;level of detail;boundary condition;polygonal meshes;multiresolution hierarchies;unstructured mesh;geometric modeling;triangle meshes;geometric model;energy minimization;discrete fairing;triangle mesh	Theuseof polygonalmeshesfor therepresentationof highly complex geometricobjectshasbecomethe de factostandardin most computergraphicsapplications.Especiallytrianglemeshesarepreferreddueto theiralgorithmicsimplicity, numericalrobustness, and efficient display. The possibility to decomposea given triangle meshinto a hierarchyof differently detailedapproximationsenablessophisticatedmodelingoperationslikethemodificationof the globalshapeunderpreservationof thedetail features. So far, multiresolutionhierarchieshave beenproposedmainly for mesheswith subdi vision connecti vity. This typeof connecti vity resultsfrom iteratively applyinga uniform split operatorto an initially givencoarsebasemesh.In this paperwe demonstratehow a similar hierarchicalstructurecanbederivedfor arbitrarymeshes with norestrictionsontheconnecti vity. Sincesmooth(subdi vision) basisfunctionsareno longeravailablein this generalizedcontext, weuseconstrainedenergy minimizationto associatesmoothgeometry with coarse levels of detail. As the energy minimizationrequiresoneto solve aglobalsparsesystem,we investigatetheeffect of variousparametersandboundaryconditionsin orderto optimize theperformanceof iterative solvingalgorithms. Another crucial ingredientfor an effective multiresolutiondecompositionof unstructuredmeshesis the flexible representation of detail information.We discussseveralapproaches.	iterative method;level of detail;multiresolution analysis;triangle mesh;typeof	Leif Kobbelt;Jens Vorsatz;Hans-Peter Seidel	1999	Comput. Geom.	10.1016/S0925-7721(99)00032-2	mathematical optimization;combinatorics;static mesh;volume mesh;geometric modeling;mathematics;geometry	Graphics	68.18847824803811	-44.709450654959724	141372
467f7e313e9902ad084defcbecbcb603a4e02813	high quality hatching	virtual machine;non photorealistic rendering;computacion informatica;line rendering;line shading;grupo de excelencia;computer graphic;image generation;ciencias basicas y experimentales;polygonal meshes;line and curve generation;high quality hatching;time use	Hatching lines are often used in line illustrations to convey tone and texture of a surface. In this paper we present methods to generate hatching lines from polygonal meshes and render them in high quality either at interactive rates for on-screen display or for reproduction in print. Our approach is based on local curvature information that is integrated to form streamlines on the surface of the mesh. We use a new algorithm that provides an even distribution of these lines. A special processing of these streamlines ensures high quality line rendering for both intended output media later on. While the streamlines are generated in a preprocessing stage, hatching lines are rendered either for vector-based printer output or on-screen display, the latter allowing for interaction in terms of changing the view parameters or manipulating the entire line shading model at run-time using a virtual machine.	algorithm;display resolution;list of common shading algorithms;polygon mesh;preprocessor;printer (computing);rendering (computer graphics);virtual machine	Johannes Zander;Tobias Isenberg;Stefan Schlechtweg-Dorendorf;Thomas Strothotte	2004	Comput. Graph. Forum	10.1111/j.1467-8659.2004.00773.x	computer vision;computer science;virtual machine;operating system;non-photorealistic rendering;computer graphics (images)	Graphics	65.46212753466274	-48.35297367247221	141529
07268b9a7b2ff566bb287926c50e217a761c081f	signal-specialized parameterization for piecewise linear reconstruction	piecewise linear;surface parameterization;approximation error;computer graphics;texture mapping;taylor expansion;categories and subject descriptors according to acm ccs i 3 7 computer graphics color;graphics hardware;shadowing and texture;shading	We propose a metric for surface parameterization specialized to its signal that can be used to create more efficient, high-quality texture maps. Derived from Taylor expansion of signal error, our metric predicts the signal approximation error - the difference between the original surface signal and its reconstruction from the sampled texture. Unlike previous methods, our metric assumes piecewise-linear reconstruction, and thus makes a good approximation to bilinear reconstruction employed in graphics hardware. We achieve significant savings in texture area for a desired signal accuracy compared to the signal-specialized parameterization metric proposed by Sander et al. in the 2002 Eurographics Workshop on Rendering.	approximation error;bilinear filtering;eurographics;graphics hardware;map;texture mapping	Geetika Tewari;John Snyder;Pedro V. Sander;Steven J. Gortler;Hugues Hoppe	2004		10.1145/1057432.1057440	texture mapping;computer vision;mathematical optimization;approximation error;shading;piecewise linear function;computer science;taylor series;geometry;computer graphics;texture compression;graphics hardware;texture filtering;computer graphics (images)	Vision	66.42192540783121	-44.75778508867488	141598
3ab0b30e1deddc281bb98eeee2e0dd86fe5e6312	simple and efficient compression of animation sequences	motion synthesis;categories and subject descriptors according to acm ccs i 3 7 computer graphics animation;motion capture;linear prediction coding;geometry compression;principal component analysis;animation;path following	"""We present a new geometry compression method for animations, which is based on the clustered principal component analysis (CPCA). Instead of analyzing the set of vertices for each frame, our method analyzes the set of paths for all vertices for a certain animation length. Thus, using a data-driven approach, it can identify mesh parts, that are """"coherent"""" over time. This usually leads to a very efficient and robust segmentation of the mesh into meaningful clusters, e.g. the wings of a chicken. These parts are then compressed separately using standard principal component analysis (PCA). Each of this clusters can be compressed more efficiently with lesser PCA components compared to previous approaches. Results show, that the new method outperforms other compression schemes like pure PCA based compression or combinations with linear prediction coding, while maintaining a better reconstruction error. This is true, even if the components and weights are quantized before transmission. The reconstruction process is very simple and can be performed directly on the GPU."""	coherence (physics);graphics processing unit;linear predictive coding;mike lesser;principal component analysis;quantization (signal processing);vertex (geometry)	Mirko Sattler;Ralf Sarlette;Reinhard Klein	2005		10.1145/1073368.1073398	anime;computer vision;real-time computing;motion capture;computer science;artificial intelligence;theoretical computer science;machine learning;principal component analysis;computer graphics (images)	Graphics	62.63116910640563	-45.83845068994007	141621
1e4d631cdeb3c18f948e25595ed9f50b99d1965e	a practical approach for 3d building modeling from uncalibrated video sequences	auto calibration;3d model;3d building model;scene constraints;structure from motion;3d reconstruction	This paper presents an approach for reconstructing a realistic 3D model of a building from its uncalibrated video sequences taken by a hand-held camera. The novelty of this approach lies in the integration of some prior scene knowledge in the auto-calibration stage of the structure from motion (SFM) problem. The line parallelism and plane orthogonality are transformed into the constraints on the absolute quadric during camera auto-calibration. This make some critical cases solvable and the reconstruction more Euclidean. The approach is implemented and validated using simulated data and real image data. The experimental results in the end of the paper show the effectiveness of our approach.	camera auto-calibration;decision problem;mobile device;parallel computing;polygonal modeling;structure from motion	Yong Liu;Chengke Wu;Hung-Tat Tsui	2002	Int. J. Image Graphics	10.1142/S0219467802000639	3d reconstruction;computer vision;structure from motion;simulation;computer science;mathematics;computer graphics (images)	Vision	53.917611289378904	-48.1998169683559	141677
02bff69bace0e9e2056c50c195693f4fb8d63875	graphics recognition recent advances		As a complement to quantitative evaluation methods for raster–to–graphics conversion, we discuss in this paper some qualitative elements which should be taken into account when choosing the different steps of one’s vectorization method. We stress the importance of having robust methods and stable implementations, and we base ourselves extensively on our own implementations and tests, concentrating on methods designed to have few, if any, parameters.	automatic vectorization;graphics	Rémy Mullot;Jean-Marc Ogier;Claude Cariou;JoÎ l Gardes;Yves Lecourtier	2000		10.1007/3-540-40953-X	computer graphics (images);graphics;computer science	AI	63.7253813220566	-44.903145757645476	141752
e2b3ac011240c742792a3b4be658153940b0f978	a 3d scanning system for biomedical purposes	laser beam;metodo cuadrado menor;contraste;image tridimensionnelle;methode moindre carre;direct linear transformation;modele geometrique;least squares method;elliptical fourier descriptors;genie biomedical;analyse fourier;data smoothing;etude experimentale;saisie donnee;optical measurement;laser light sectioning;scanneur;biomedical scanners;escaner;forma geometrica;haz laser;scanner;reconstruction image;biomedical engineering;reconstruccion imagen;biomedical scanner;mesure optique;toma dato;3d scanning;image reconstruction;shape features;medical imaging;geometrical shape;metrologia superficie;transformation lineaire;metrologie surface;medida optica;coste;lissage donnees;linear transformation;fourier analysis;tridimensional image;analisis fourier;efds;etalonnage;ingenieria biomedica;forme geometrique;faisceau laser;3d geometric modelling;camera calibration;surface metrology;alisadura datos;biological objects;data acquisition;estudio experimental;calibration;imagen tridimensional;transformacion lineal;geometrical model;cout;modelo geometrico	The use of three-dimensional (3D) scanning systems for acquiring the external shape features of biological objects has recently been gaining popularity in the biomedical field. A simple, low cost, 3D scanning system is presented, which employs the laser light-sectioning technique for data acquisition. A Direct Linear Transformation least squares algorithm is used for camera calibration and Elliptical Fourier Descriptors (EFDs) are used for data smoothing and planar section reconstruction. Results for an experiment demonstrating the validity of the EFD approach are presented. Overall, results presented for three objects scanned with the proposed system demonstrate the validity of the chosen approach. This is an expanded version of a paper presented at the 3rd IEEE International Workshop on Medical Measurements and Applications, 9 10 May 2008, Ottawa, ON, Canada.	3d scanner	B. D. Bradley;A. D. C. Chan;M. J. D. Hayes	2009	IJAMC	10.1504/IJAMC.2009.026851	iterative reconstruction;medical imaging;computer vision;calibration;camera resectioning;input/output;computer science;linear map;fourier analysis;data acquisition;least squares;smoothing;direct linear transformation	Crypto	58.371693927871604	-42.91491062980061	141881
eec3d552a3f71d66d296d1598a8fbcea0874baec	non-delaunay-based curve reconstruction	triangulacion delaunay;octree;delaunay triangulation;octarbol;triangulation delaunay;echantillonnage;octarbre;courbure;surface reconstruction;sampling;reconstruction surface;theorie algorithme;algorithm theory;estructura datos;curvatura;curvature;structure donnee;reconstruccion superficie;muestreo;data structure	A new non-Delaunay-based approach is presented to reconstruct a curve, lying in 2or 3-space, from a sampling of points. The underlying theory is based on bounding curvature to determine monotone pieces of the curve. Theoretical guarantees are established. The implemented algorithm, based heuristically on the theory, proceeds by iteratively partitioning the sample points using an octree data structure. The strengths of the approach are (a) simple implementation, (b) efficiency – experimental performance compares favorably with Delaunaybased algorithms, (c) robustness – curves with multiple components and sharp corners are reconstructed satisfactorily, and (d) potential extension to surface reconstruction.		Sumanta Guha;Paula Josiah;Anoop Mittal;Son Dinh Tran	2002		10.1007/3-540-36136-7_8	sampling;combinatorics;topology;surface reconstruction;delaunay triangulation;data structure;computer science;mathematics;geometry;curvature;octree	Robotics	68.05892612430414	-43.09730874582166	142132
2e5edda56da9034abc2ce068f519338ac6c041e4	conservative volumetric visibility with occluder fusion	spacetime constraints;real time;motion synthesis;markov chain monte carlo;plausible motion;ray tracing;data structure	Visibility determination is a key requirement in a wide range of graphics algorithms. This paper introduces a new approach to the computation of volume visibility, the detection of occluded portions of space as seen from a given region. The method is conservative and classifies regions as occluded only when they are guaranteed to be invisible. It operates on a discrete representation of space and uses the opaque interior of objects as occluders. This choice of occluders facilitates their extension into adjacent opaque regions of space, in essence maximizing their size and impact. Our method efficiently detects and represents the regions of space hidden by such occluders. It is the first one to use the property that occluders can also be extended into empty space provided this space is itself occluded from the viewing volume. This proves extremely effective for computing the occlusion by a set of occluders, effectively realizing occluder fusion. An auxiliary data structure represents occlusion in the scene and can then be queried to answer volume visibility questions. We demonstrate the applicability to visibility preprocessing for real-time walkthroughs and to shadow-ray acceleration for extended light sources in ray tracing, with significant acceleration in both cases.	algorithm;computation;data structure;graphics;hidden surface determination;preprocessor;ray tracing (graphics);real-time locating system;software walkthrough;viewing frustum	Gernot Schaufler;Julie Dorsey;Xavier Décoret;François X. Sillion	2000		10.1145/344779.344886	ray tracing;computer vision;data structure;markov chain monte carlo;computer science;mathematics;geometry;programming language;statistics;computer graphics (images)	Graphics	65.66373977724422	-51.04627430432723	142282
527949e460a547c3aca50e3d6f5c1531acc05b58	the double sphere camera model		Vision-based motion estimation and 3D reconstruction, which have numerous applications (e.g., autonomous driving, navigation systems for airborne devices and augmented reality) are receiving significant research attention. To increase the accuracy and robustness, several researchers have recently demonstrated the benefit of using large field-of-view cameras for such applications. In this paper, we provide an extensive review of existing models for large field-of-view cameras. For each model we provide projection and unprojection functions and the subspace of points that result in valid projection. Then, we propose the Double Sphere camera model that well fits with large field-of-view lenses, is computationally inexpensive and has a closed-form inverse. We evaluate the model using a calibration dataset with several different lenses and compare the models using the metrics that are relevant for Visual Odometry, i.e., reprojection error, as well as computation time for projection and unprojection functions and their Jacobians. We also provide qualitative results and discuss the performance of all models.	3d reconstruction;airborne ranger;analysis of algorithms;augmented reality;autonomous car;autonomous robot;computation;emoticon;fits;fisheye;map projection;motion estimation;polynomial;reprojection error;time complexity;virtual reality headset;visual odometry	Vladyslav C. Usenko;Nikolaus Demmel;Daniel Cremers	2018	2018 International Conference on 3D Vision (3DV)	10.1109/3DV.2018.00069	machine learning;3d reconstruction;computer vision;robustness (computer science);motion estimation;artificial intelligence;computation;visual odometry;subspace topology;augmented reality;computer science;lens (optics)	Vision	54.70932493120113	-41.95615914604104	142344
cdf892add0ababc74bdd189a7f0808ce22b55c52	a two dimensional optical input to one dimensional serial pulse transformation	optical elements;optical elements image sequences;image processing parallel processing optical computing;detectors optical imaging optical reflection optical diffraction optical pulses adaptive optics optical refraction;optical path length two dimensional optical input one dimensional serial pulse transformation confocal parabolic reflectors spatial position 1d sequenced serial string 2d array final output detector time based serial data;image sequences	A method of transforming a two dimensional input image into a one dimensional time sequenced serial string at the speed of light is described. The image is transformed into serial information by varying the optical path length (OPL) relative to the position of the images pixel in space. The light traverses each pixel and enters an optical system which has varying OPL associated with each pixel. The OPL associated with each pixel will be modified with respect to every other pixel based on position. This modification allows a transformation into a timed sequence of pulses. This paper gives the computations for the various OPLs needed. It starts with a one dimensional system then expands to a two dimensional system.	computation;open programming language (opl);pixel	George Hulse	2012	2012 IEEE International Conference on Electro/Information Technology	10.1109/TIP.2013.2289933	computer vision;mathematics	Robotics	58.97145887626807	-47.4862735216255	142360
975480bc686c726d8a2fb128d9b56acccaff9b42	a prior-knowledge based casted shadows prediction model featuring openstreetmap data		We present a prior-knowledge based shadow prediction model, focused on outdoors scene, which allows to predict pixels, on the camera, which are likely to be part of shadows casted by surrounded buildings. We employ a geometrical approach which models surrounding buildings, their shadow and the camera. One innovative aspect of our method is to retrieve building datas automatically from OpenStreetMap, a community project providing free geographic data. We provide both qualitative and quantitative results in two different contexts to assess performance of our prediction model. While our method cannot achieve pixel precision easily alone, it opens opportunities for more elaborate shadow detection algorithms and occlusion-aware models.	algorithm;camera resectioning;computer vision;depth map;distortion;openstreetmap;pixel	M. Rogez;Laure Tougne;Lionel Robinault	2013			simulation;computer graphics (images)	AI	56.4492996204103	-45.77154847533513	142394
7eb369c0953dbcb21dba47bbedba6ac488d775c5	a progressive global illumination solution considering perceptual factors	global illumination	image synthesis usually involves some iterative methods for solving the global illumination problem. The fully converged solution may be quite time consuming for complex scenes, but taking into account basic properties of human perception such as poor sensitivity to the absolute luminance values, high quality images can be obtained on the order of single minutes or seconds using physically-based partial solutions. In this sketch, we describe a progressive technique designed along these guidelines. We use a hybrid of stochastic and deterministic techniques. At first, a Monte Carlo Photon Tracing algorithm is used in which photons are bucketed directly into a mesh (making immediate image display possible). To reduce the problems of low-frequency noise at early stages of computation [1], the adaptive filtering of illumination at the mesh vertices is performed, taking into account illumination in the local neighborhood. If we were to relay on the neighborhood relations between the mesh elements, the result would strongly depend on the geometrical model and would not provide complete information for separate objects. Instead, we build a static and balanced 3D kd-tree structure for all vertices. The filtering is used at the intermediate stages of computation, and filter size is adaptively reduced as variance of the illumination estimate decreases for a given vertex. Figure 1a shows the result of the particle tracing phase after 6 seconds of computations (Pentium-200 MHz) for the scene containing over 17,000 polygons. The appearance of images obtained at the first stage of lighting simulation approximates well the final images with the exception of views that contain many areas with strong direct lighting. To overcome these drawbacks, deterministic calculations of direct lighting are performed. In contrast to traditional approaches, the adaptive mesh subdivision for the determin-istic calculations of direct lighting can be based upon predicted visible differences using the available stochastically-derived estimates of indirect illumination. Here we introduce perceptually-based mesh splitting criteria. For each mesh ver-tex we transform the stimulus luminance values to predicted perceived brightness using Stevens' power law, and a decision on the mesh splitting is made based on the local differences in brightness. Figure 1b shows a result of this stage of lighting simulation which took about 30 seconds. The next stage of computation replaces the finished direct computations with additional stochastic particle tracing, which is then performed until a criterion accuracy is reached (Figure 1c). The final images can be rendered using ray tracing. Another way …	adaptive filter;algorithm;computation;display resolution;global illumination;inferring horizontal gene transfer;iterative method;monte carlo method;ray tracing (graphics);relay;rendering (computer graphics);simulation;stochastic process;subdivision surface;tree structure;ver (command)	Vladimir Volevich;Jerzy Sas;Karol Myszkowski;Andrei Khodulev;Edward A. Kopylov	1998		10.1145/280953.282229	computer science;global illumination	Graphics	63.907711917027875	-49.869402450972636	142449
4ab29c67d9f8b14e790e5f381a081eddea09f73c	stroke-based stylization by learning sequential drawing examples		Abstract Among various traditional art forms, brush stroke drawing is one of the widely used styles in modern computer graphic tools such as GIMP, Photoshop and Painter. In this paper, we develop an AI-aided art authoring ( A 4 ) system of non-photorealistic rendering that allows users to automatically generate brush stroke paintings in a specific artist’s style. Within the reinforcement learning framework of brush stroke generation proposed by Xie et al. (2012), the first contribution in this paper is the application of regularized policy gradient method, which is more suitable for the stroke generation task; the other contribution is to learn artists’ drawing styles from video-captured stroke data by inverse reinforcement learning . Through experiments, we demonstrate that our system can successfully learn artists’ styles and render pictures with consistent and smooth brush strokes.		Ning Xie;Yang Yang;Heng Tao Shen;Tingting Zhao	2018	J. Visual Communication and Image Representation	10.1016/j.jvcir.2017.12.012	mathematics;computer vision;rendering (computer graphics);machine learning;reinforcement learning;artificial intelligence;painting;stroke	ML	64.91652023995636	-47.39153757673828	142483
2cb13f1a84d67ccc2e2be07fa2370637972f24bc	slam-based dense surface reconstruction in monocular minimally invasive surgery and its application to augmented reality	augmented reality;minimally invasive surgery;slam;surface reconstruction	BACKGROUND AND OBJECTIVE While Minimally Invasive Surgery (MIS) offers considerable benefits to patients, it also imposes big challenges on a surgeon's performance due to well-known issues and restrictions associated with the field of view (FOV), hand-eye misalignment and disorientation, as well as the lack of stereoscopic depth perception in monocular endoscopy. Augmented Reality (AR) technology can help to overcome these limitations by augmenting the real scene with annotations, labels, tumour measurements or even a 3D reconstruction of anatomy structures at the target surgical locations. However, previous research attempts of using AR technology in monocular MIS surgical scenes have been mainly focused on the information overlay without addressing correct spatial calibrations, which could lead to incorrect localization of annotations and labels, and inaccurate depth cues and tumour measurements. In this paper, we present a novel intra-operative dense surface reconstruction framework that is capable of providing geometry information from only monocular MIS videos for geometry-aware AR applications such as site measurements and depth cues. We address a number of compelling issues in augmenting a scene for a monocular MIS environment, such as drifting and inaccurate planar mapping.   METHODS A state-of-the-art Simultaneous Localization And Mapping (SLAM) algorithm used in robotics has been extended to deal with monocular MIS surgical scenes for reliable endoscopic camera tracking and salient point mapping. A robust global 3D surface reconstruction framework has been developed for building a dense surface using only unorganized sparse point clouds extracted from the SLAM. The 3D surface reconstruction framework employs the Moving Least Squares (MLS) smoothing algorithm and the Poisson surface reconstruction framework for real time processing of the point clouds data set. Finally, the 3D geometric information of the surgical scene allows better understanding and accurate placement AR augmentations based on a robust 3D calibration.   RESULTS We demonstrate the clinical relevance of our proposed system through two examples: (a) measurement of the surface; (b) depth cues in monocular endoscopy. The performance and accuracy evaluations of the proposed framework consist of two steps. First, we have created a computer-generated endoscopy simulation video to quantify the accuracy of the camera tracking by comparing the results of the video camera tracking with the recorded ground-truth camera trajectories. The accuracy of the surface reconstruction is assessed by evaluating the Root Mean Square Distance (RMSD) of surface vertices of the reconstructed mesh with that of the ground truth 3D models. An error of 1.24 mm for the camera trajectories has been obtained and the RMSD for surface reconstruction is 2.54 mm, which compare favourably with previous approaches. Second, in vivo laparoscopic videos are used to examine the quality of accurate AR based annotation and measurement, and the creation of depth cues. These results show the potential promise of our geometry-aware AR technology to be used in MIS surgical scenes.   CONCLUSIONS The results show that the new framework is robust and accurate in dealing with challenging situations such as the rapid endoscopy camera movements in monocular MIS scenes. Both camera tracking and surface reconstruction based on a sparse point cloud are effective and operated in real-time. This demonstrates the potential of our algorithm for accurate AR localization and depth augmentation with geometric cues and correct surface measurements in MIS with monocular endoscopes.		Long Chen;Wen Tang;Nigel W. John;Tao Ruan Wan;Jian Jun Zhang	2018	Computer methods and programs in biomedicine	10.1016/j.cmpb.2018.02.006	3d reconstruction;computer vision;artificial intelligence;point cloud;stereoscopy;simultaneous localization and mapping;computer science;monocular;depth perception;augmented reality;surgery;video camera	Vision	53.9540369911559	-46.68793548339726	142637
b1586d672313e0e4d2e5cb9ba29a3aadcabf7fb0	optimized mobile rendering techniques based on local cubemaps	shadows;reflections;local cubemap;refractions	Local cubemaps (LC) were introduced for the first time more than ten years ago for rendering reflections [Bjorke 2004]. Nevertheless it is only in recent years that major game engines have incorporated this technique. In this paper we introduce a generalized concept of LC and present two new LC applications for rendering shadows and refractions. We show that limitations associated with the static nature of LC can be overcome by combining this technique with other well-known runtime techniques for reflections and shadows.  Rendering techniques based on LC allow high quality shadows, reflections and refractions to be rendered very efficiently which makes them ideally suited to mobile devices where runtime resources must be carefully balanced [Ice Cave Demo 2015].	amiga reflections;display resolution;game engine;mobile device;reflection (computer graphics)	Roberto Lopez Mendez;Sylwester Bala	2016		10.1145/2945078.2945113	computer vision;shadow;refraction;computer graphics (images)	EDA	64.83934171182139	-51.35400036130383	142682
41809fa0596d32daa7f4a404eef4c44e019c100e	multiresolution splatting for indirect illumination	shadow mapping;high resolution;low frequency;low resolution;global illumination;interactive application;hardware assisted rendering;interactive rendering;numerical approximation;multi resolution	Global illumination provides a visual richness not achievable with the direct illumination models used by most interactive applications. To generate global effects, numerous approximations attempt to reduce global illumination costs to levels feasible in interactive contexts. One such approximation, reflective shadow maps, samples a shadow map to identify secondary light sources whose contributions are splatted into eye-space. This splatting introduces significant overdraw that is usually reduced by artificially shrinking each splat's radius of influence. This paper introduces a new, multi-resolution approach for interactively splatting indirect illumination. Instead of reducing GPU fill rate by reducing splat size, we reduce fill rate by rendering splats into a multi-resolution buffer. This takes advantage of the low-frequency nature of diffuse and glossy indirect lighting, allowing rendering of indirect contributions at low resolution where lighting changes slowly and at high resolution near discontinuities. Because this multi-resolution rendering occurs on a per-splat basis, we can significantly reduce fill rate without arbitrarily clipping splat contributions below a given threshold---those regions simply are rendered at a coarse resolution.	approximation;global illumination;glossary of computer graphics;graphics processing unit;illumination (image);image resolution;interactivity;map;multiresolution analysis;shadow mapping;texture splatting;volume rendering	Greg Nichols;Chris Wyman	2009		10.1145/1507149.1507162	computer vision;image resolution;computer science;computer graphics (images)	Graphics	65.03153209466858	-51.56921684489774	142712
c5bbcfdef6add92d817ea7f1c0d192edbba6ad52	hardware-accelerated parallel-split shadow maps	shadow mapping;anti aliasing;hardware accelerator;image based rendering	Shadow mapping is well known for its generality and efficiency, thus it has been extensively employed for real-time shadow rendering in diverse applications. However, it suffers from inherent aliasing problem due to its image-based nature. In this paper, we present the parallel-split shadow maps scheme which produces high-quality shadows especially in large-scale and complex scenes. Our scheme splits the view frustum into parts using planes parallel to the view plane, and then generates a shadow map for each part. A fast and robust splitting strategy based on the analysis of shadow-map aliasing is proposed, which results in a moderate aliasing distribution over the depth range. Hardware-accelerated processing is developed to eliminate extra rendering passes which surpass that of standard shadow mapping when synthesizing scene-shadows.	aliasing;graphics hardware;hardware acceleration;map;real-time clock;real-time locating system;shadow mapping;shadow volume;viewing frustum	Fan Zhang;Hanqiu Sun;Leilei Xu;Kitlun Lee	2008	Int. J. Image Graphics	10.1142/S0219467808003064	computer vision;image-based modeling and rendering;hardware acceleration;shadow and highlight enhancement;computer science;shadow mapping;shadow volume;computer graphics (images)	Graphics	65.81349545547225	-51.62091184440889	142849
4419d5279f38eda7a7cab0c36c48f50402982add	on enhancing the speed of splatting using both object- and image-space coherence	optimization technique;volume rendering;image quality;test methods	Splatting is an object-order volume rendering algorithm that produces images of high quality, and several optimization techniques have been proposed. This paper presents new techniques that accelerate splatting algorithms by exploiting both object-space and image-space coherence. In particular, we propose two visibility test methods suitable for octree-based splatting. The first method, based on dynamic image-space range tree, offers an accurate occlusion test, and does not trade off image quality. The second one, based on image-space quadtree, uses an approximate occlusion test that is faster than the first algorithm is. Although the approximate visibility test may produce visual artifacts in rendering, the introduced error is usually found very little. Tests with several datasets of useful sizes and complexities showed considerable speedups with respect to the splatting algorithm, enhanced with octree only. Considering that they are very easy to implement, and need little additional memory, our techniques will be used as very effective splatting methods.	approximation algorithm;central processing unit;compiler;computation;data structure;display resolution;image quality;mathematical optimization;octree;quadtree;range tree;tree traversal;visual artifact;volume rendering;voxel	Rae Kyoung Lee;Insung Ihm	2000	Graphical Models	10.1006/gmod.2000.0524	image quality;computer vision;computer science;theoretical computer science;mathematics;test method;volume rendering;computer graphics (images)	Visualization	66.45377567481648	-52.052516233885676	143061
af66b78b04e1022c566ca801ac6eeb0dfa1e300c	mobile robot geometry initialization from single camera	robot localization;cost function;maximum likelihood;mobile robot;euclidean distance;3d structure	Using external cameras to achieve robot localization has been widely proposed in the area of Intelligent Spaces. Recently, an online approach that simultaneously obtains robot’s pose and its 3D structure using a single external camera has been developed [8]. Such proposal relies on a proper initialization of pose and structure information of the robot. The present paper proposes a solution to initialization which consists of retrieving 3D structure and motion of a rigid object from a set of point matches measured by the camera. A batch Structure from Motion (SFM) approach is proposed along a short path. By incorporating odometry information available in the robot, the ambiguity generated by a single view in the solution is solved. We propose to describe robot’s motion and image detection as statistical processes in which the uncertainty is properly modelled. Using a Gaussian equivalence of the processes involved, the SFM cost function is expressed as a Maximum Likelihood optimization. The paper shows the improvements of the approach in the presence of the usual odometry drift noise, compared with those using Euclidean distance as a likelihood. The proposed method is assessed on synthetic and real data.	approximation;dead reckoning;euclidean distance;hessian;image registration;loss function;mathematical optimization;mobile robot;odometry;robotic mapping;spaces;sparse matrix;structure from motion;synthetic data;turing completeness	Daniel Pizarro-Perez;Manuel Mazo;Enrique Santiso;Hideki Hashimoto	2007		10.1007/978-3-540-75404-6_9	mobile robot;computer vision;mathematical optimization;simulation;computer science;artificial intelligence;euclidean distance;maximum likelihood;statistics;robot calibration	Robotics	54.078303748486526	-40.88604518081166	143217
49306a269587a4594b8aed8cd4e609ef48926758	automated reprojection-based pixel shader optimization	possible caching decision;procedural shaders;temporal reprojection;complex shaders;automated approach;procedural shading;cached entry;code optimization;general tool;performance trade-offs;general strategy;pixel shader optimization;real-time rendering;temporal data reprojection;temporal data;real time rendering;parametric model	We present a framework and supporting algorithms to automate the use of temporal data reprojection as a general tool for optimizing procedural shaders. Although the general strategy of caching and reusing expensive intermediate shading calculations across consecutive frames has previously been shown to provide an effective trade-off between speed and accuracy, the critical choices of what to reuse and at what rate to refresh cached entries have been left to a designer. The fact that these decisions require a deep understanding of a procedure's semantic structure makes it challenging to select optimal candidates among possibly hundreds of alternatives. Our automated approach relies on parametric models of the way possible caching decisions affect the shader's performance and visual fidelity. These models are trained using a sample rendering session and drive an interactive profiler in which the user can explore the error/performance trade-offs associated with incorporating temporal reprojection. We evaluate the proposed models and selection algorithm with a prototype system used to optimize several complex shaders and compare our approach to current alternatives.	cache (computing);map projection;mathematical optimization;pixel;prototype;selection algorithm;shader;shading;virtual reality headset	Pitchaya Sitthi-amorn;Jason Lawrence;Lei Yang;Pedro V. Sander;Diego F. Nehab;Jiahe Xi	2008	ACM Trans. Graph.	10.1145/1457515.1409080	computer vision;simulation;parametric model;computer science;program optimization;temporal database;real-time rendering;statistics;computer graphics (images)	Graphics	65.51579427978163	-49.716223474139525	143273
167a0da7b07b5485bcedcda880e271f3995e0ae0	data association in o(n) for divide and conquer slam	indexing terms;data association;simulation experiment;computational complexity;linear time;map estimation;divide and conquer	In this paper we show that all processes associated to the move-sense-update cycle of EKF SLAM can be carried out in time linear in the number of map features. We describe Divide and Conquer SLAM, an EKF SLAM algorithm where the computational complexity per step is reduced fromO(n) to O(n) (the total cost of SLAM is reduced from O(n) to O(n)). In addition, the resulting vehicle and map estimates have be tter consistency properties than standard EKF SLAM in the sense that the computed state covariance more adequately represe nts the real error in the estimation. Both simulated experiments and the Victoria Park Dataset are used to provide evidence of the advantages of this algorithm.	algorithm;computational complexity theory;ekf slam;experiment;extended kalman filter;simultaneous localization and mapping;victoria (3d figure)	Lina María Paz;José E. Guivant;Juan D. Tardós;José Neira	2007		10.15607/RSS.2007.III.036	time complexity;divide and conquer algorithms;index term;computer science;theoretical computer science;machine learning;computational complexity theory;algorithm	Robotics	55.27819801718677	-41.16163032116476	143334
7c53f75ba38ada71b4772a722e57942bd04e4a85	kinectfusion rapid 3d reconstruction and interaction with microsoft kinect	3d interaction;real time;feature tracking;3d model;feature extraction;augmented reality;3d reconstruction	Using a Microsoft Kinect camera, the KinectFusion system enables a low-cost way for a user to digitally reconstruct a whole room and its contents within seconds. As the space is explored, new views of the arbitrary scene and objects are revealed and these are fused into a single 3D model. The 6DoF pose of the camera is tracked in real-time using a method which directly uses the point-based depth data of Kinect, and requires no feature extraction or feature tracking. Once the 3D pose of the camera is known, each depth measurement from the sensor can be integrated into a volumetric representation. Kinect Fusion enables many Augmented Reality applications and 3D interaction such as multi-touch on arbitrary shaped surfaces.	3d interaction;3d reconstruction;augmented reality;feature extraction;kinect;motion estimation;multi-touch;polygonal modeling;real-time clock	David Molyneaux	2012		10.1145/2282338.2282342	3d reconstruction;computer vision;augmented reality;simulation;feature extraction;computer science;computer graphics (images)	HCI	54.82310897735234	-46.6693563320824	143458
7e01a401cf8d3f1006a062d176c0ba8fb0da2565	self calibration of multiple lidars and cameras on autonomous vehicles	point cloud;extrinsic calibration;3d data fitting	Autonomous navigation is an important field of research and, given the complexity of real world environments, most of the systems rely on a complex perception system combining multiple sensors on board, which reinforces the concern of sensor calibration. Most calibration methods rely on manual or semi-automatic interactive procedures, but reliable fully automatic methods are still missing. However, if some simple objects could be detected and identified automatically by all the sensors from several points of view, then automatic calibration would be possible on the fly. The idea proposed in this paper is to use a ball in motion in front of a set of uncalibrated sensors allowing them to detect its center along the successive positions. This set of centers generates a point cloud per sensor, which, by using segmentation and fitting techniques, allows the calculation of the rigid body transformation among all pairs of sensors. This paper proposes and describes such a method with results demonstrating its validity. Solution for the automatic calibration of multiple LIDAR, Cameras and other 3D sensors, with minor user intervention.Applicable both in static sensor-rich setups and in mobile systems, such as autonomous cars and other ADAS contexts.Accessible methodology for the community since it uses standard algorithms and libraries in a ROS framework and a simple ball.	autonomous robot	Marcelo Pereira;David Silva;Vítor M. F. Santos;Paulo Dias	2016	Robotics and Autonomous Systems	10.1016/j.robot.2016.05.010	computer vision;simulation;computer science;point cloud	Robotics	55.00166600761182	-40.454636814186884	143506
2500c19f3b9ca73f6627c5c323d40acef574c298	interactive scene flow editing for improved image-based rendering and virtual spacetime navigation	user interface;scene flow;view interpolation;interactivity;stereo;optical flow;image based rendering	High-quality stereo and optical flow maps are essential for a multitude of tasks in visual media production, e.g. virtual camera navigation, disparity adaptation or scene editing. Rather than estimating stereo and optical flow separately, scene flow is a valid alternative since it combines both spatial and temporal information and recently surpassed the former two in terms of accuracy. However, since automated scene flow estimation is non-accurate in a number of situations, resulting rendering artifacts have to be corrected manually in each output frame, an elaborate and time-consuming task. We propose a novel workflow to edit the scene flow itself, catching the problem at its source and yielding a more flexible instrument for further processing. By integrating user edits in early stages of the optimization, we allow the use of approximate scribbles instead of accurate editing, thereby reducing interaction times. Our results show that editing the scene flow improves the quality of visual results considerably while requiring vastly less editing effort.	approximation algorithm;binocular disparity;map;mathematical optimization;optical flow;virtual camera system	Kai Ruhl;Martin Eisemann;Anna Hilsmann;Peter Eisert;Marcus A. Magnor	2015		10.1145/2733373.2806251	computer vision;image-based modeling and rendering;rendering;computer science;optical flow;multimedia;interactivity;user interface;stereophonic sound;computer graphics (images)	Vision	59.78527671973825	-50.01469103535867	143533
329ea447ad5b7e8427059a2134ba449330da1168	geometry representations with unsupervised feature learning	atomic measurements;geometry;shape;three dimensional displays;feature extraction;image reconstruction;dictionaries;unsupervised learning big data computer graphics geometry interpolation radial basis function networks;geometry dictionaries three dimensional displays atomic measurements shape feature extraction image reconstruction;big geometry data geometry representations dictionary learning;3d geometry data geometry representations unsupervised feature learning local geometry patches extraction patch geometry radial basis function interpolation big geometry data	Geometry data in massive amounts can be generated thanks to the modern capture devices and mature geometry modeling tools. It is essential to develop the tools to analyze and utilize this big data. In this paper, we present an exploration of analyzing geometries via learning local geometry features. After extracting local geometry patches, we parameterize each patch geometry by a radial basis function based interpolation. We use the resulting coefficients as discrete representations of the patches. These are then fed into feature learning algorithms to extract the dominant components explaining the overall patch database. This simple approach allows us to handle general representations such as point clouds or meshes with noise, outliers, and missing data. We present features learned on several patch databases to illustrate the utility of such an analysis for geometry processing applications.	algorithm;big data;coefficient;database;feature learning;geometric modeling;geometry processing;interpolation;machine learning;missing data;mixing (mathematics);patch (computing);point cloud;radial (radio);radial basis function;smoothing;unsupervised learning	Yeo-Jin Yoon;Alexander Lelidis;A. Cengiz Öztireli;Jung-Min Hwang;Markus H. Gross;Soo-Mi Choi	2016	2016 International Conference on Big Data and Smart Computing (BigComp)	10.1109/BIGCOMP.2016.7425812	computer vision;local feature size;machine learning;pattern recognition;mathematics;digital geometry	Robotics	63.85639621164555	-44.34546821858217	143615
1922e74c10e6d5d51a9421906e5a0804591d7a4e	gpugi: global illumination effects on the gpu	paper;nvidia;algorithms;opengl;computer science;hlsl;3d graphics and realism;nvidia geforce 6800 gt;directx;tutorial	In this tutorial we explain how global illumination rendering methods can be implemented on Shader Model 3.0 GPUs. These algorithms do not follow the conventional local illumination model of DirectX/OpenGL pipelines, but require global geometric or illumination information when shading a point. In addition to the theory and state of the art of these approaches, we go into the details of a few algorithms, including mirror reflections, reflactions, caustics, diffuse/glossy indirect illumination, precomputation aided global illumination for surface and volumetric models, obscurances and tone mapping, also giving their GPU implementation in HLSL or Cg language.	algorithm;cg (programming language);directx;global illumination;graphics pipeline;graphics processing unit;high-level shading language;list of common shading algorithms;opengl;precomputation;programming language;reflection (computer graphics);shader;tone mapping;volume mesh	László Szirmay-Kalos;László Szécsi;Mateu Sbert	2006		10.2312/egt.20061069	transform, clipping, and lighting;computational science;simulation;computer science;graphics hardware;general-purpose computing on graphics processing units;computer graphics (images)	Graphics	66.3434970978651	-51.7076476664388	143957
99ede4fd8bc7f042f2e9b5715dd5e95c0fc027e3	object independent ar space generation		We presents a method to generate and track AR space using plane geometry information in AR environment. Our method calculates the major plane correspondences between frames and defines the relation. Using this relationship, we can create the virtual space that is unaffected by object position changes in images and can be used for AR tracking.	video tracking;virtual reality	Jinwoo Jeon;Woontack Woo	2017	2017 International Symposium on Ubiquitous Virtual Reality (ISUVR)	10.1109/ISUVR.2017.21	artificial intelligence;computer vision;computer science;computer graphics (images);plane (geometry)	Visualization	57.5299379353016	-50.055212857253004	143966
0c4ef6d3d9f24d2830dc6199b265bb462e4fc36b	improving point cloud accuracy obtained from a moving platform for consistent pile attack pose estimation	tecnologia industrial tecnologia mecanica;tecnologia electronica telecomunicaciones;scanning while moving;autoloading;datavetenskap datalogi;datavetenskap;3d perception;computer science;93c85;tecnologias;grupo a	We present a perception system for enabling automated loading with waistarticulated wheel loaders. To enable autonomous loading of piled materials, using either above-ground wheel loaders or underground load-haul-dump vehicles, 3D data of the pile shape is needed. However, using common 3D scanners, the scan data is distorted while the wheel loader is moving towards the pile. Existing methods that make use of 3D scan data (for autonomous loading as well as tasks such as mapping, localisation, and object detection) typically assume that each 3D scan is accurate. For autonomous robots moving over rough terrain, it is often the case that the vehicle moves a substantial amount during the acquisition of one 3D scan, in which case the scan data will be distorted. We present a study of auto-loading methods, and how to locate piles in real-world scenarios with nontrivial ground geometry. We have compared how consistently each method performs for live scans acquired in motion, and also how the methods perform with different view points and scan configurations. The system described in this paper uses a novel method for improving the quality of distorted 3D scans made from a vehicle moving over uneven terrain. The proposed method for improving scan quality is capable of increasing the accuracy of point clouds without assuming any specific features of the environment (such as planar walls), without resorting to a “stop-scan-go” approach, and without relying on specialised and expensive hardware. Each new 3D scan is registered to the preceding using the normal-distributions transform (NDT). After each registration, a mini-loop closure is performed with a local, per-scan, graph-based SLAM method. To verify the impact of the quality improvement, we present data that shows how autoloading methods benefit from the corrected scans. The presented methods are validated on data from an autonomous wheel loader, as well as with simulated data. The proposed scan-correction method increases the accuracy of both the vehicle trajectory and the point cloud. We also show that it increases the reliability of pile-shape measures used to plan an efficient attack pose when performing autonomous loading.	3d film;3d scanner;autonomous robot;ct scan;convex function;flood fill;ground truth;maxima and minima;mobile device;object detection;point cloud;sensor;simultaneous localization and mapping;surround sound;virtual reality	Hakan Almqvist;Martin Magnusson;Achim J. Lilienthal	2014	Journal of Intelligent and Robotic Systems	10.1007/s10846-013-9957-9	embedded system;computer vision;simulation;computer science;engineering	Robotics	54.48926858045613	-41.68736842380307	144282
e80eee433a7e66f715445c5d55ef7d33a77252c3	rendering the unfolded cerebral cortex	volume rendering;cerebral cortex;spatial relationships;deformable model;volume data	Classical volume rendering is computed by casting a bundle of parallel rays from a flat viewing plane onto the volume data set, and produces as such a spatially limited view of the objects in the data set. The method described in this paper is able to generate an overall planar view of an object that is topologically compatible with the sphere, by firing rays from a nearby surrounding surface and by unfolding this surface in a 2D plane, without introducing major distortions. It has been devised to facilitate the interpretation of the cerebral cortex. An initial surface consisting of two hemi-ellipsoids, one to cover the top and another one to surround the bottom of the brain, is interactively defined and deformed via a deformable model approach towards a dilated version of the cortical surface of the brain. During deformation, the nodes on the surface are continuously redistributed, to maintain a near homothetic mapping with the plane. Once the surface has converged to the dilated brain surface, rays are casted from the nodes, according to the normal of the surface at the node. The shading result, computed at the intersection of the rays with the original brain surface, is mapped via the near homothetic mapping to the plane. With this approach sulci can be followed in their entirety, so that it is much easier to derive their spatial relationship and to recognize them.	distortion;interactivity;shading;unfolding (dsp implementation);volume rendering	Junfeng Guo;Ioan Alexandru Salomie;Rudi Deklerck;Jan Cornelis	1999		10.1007/10704282_32	spatial relation;computer vision;radiology;computer science;mathematics;volume rendering;computer graphics (images)	Vision	67.5049982897336	-47.77197779263232	144289
45073bb33119e5ba30b4ff8a1fa7909627d06ba0	sensing and recognizing surface textures using a gelsight sensor	robot vision image recognition image sensors image texture;image recognition;local binary pattern;image sensors;image texture;local binary pattern tactile sensing texture recognition;tactile sensing;robot vision;robot sensing systems histograms surface texture databases surface treatment microstructure;surface texture sensing material recognition sandpaper wood fabric tactile textures hellinger distance metric multiscale pyramid local binary patterns visual texture analysis height map compliant sensor robots gelsight sensor surface texture recognition;texture recognition;article	Sensing surface textures by touch is a valuable capability for robots. Until recently it was difficult to build a compliant sensor with high sensitivity and high resolution. The GelSight sensor is compliant and offers sensitivity and resolution exceeding that of the human fingertips. This opens the possibility of measuring and recognizing highly detailed surface textures. The GelSight sensor, when pressed against a surface, delivers a height map. This can be treated as an image, and processed using the tools of visual texture analysis. We have devised a simple yet effective texture recognition system based on local binary patterns, and enhanced it by the use of a multi-scale pyramid and a Hellinger distance metric. We built a database with 40 classes of tactile textures using materials such as fabric, wood, and sandpaper. Our system can correctly categorize materials from this database with high accuracy. This suggests that the GelSight sensor can be useful for material recognition by robots.	algorithm;categorization;computer vision;database;feature extraction;fiber optic sensor;heightmap;image resolution;local binary patterns;map;robot;robotics	Rui Li;Edward H. Adelson	2013	2013 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2013.164	image texture;computer vision;local binary patterns;computer science;image sensor;texture compression;texture filtering;computer graphics (images)	Vision	58.8450324654547	-41.538029991214096	144355
a8f89b521a22849b2e1629c8585f6638c807e6ac	automatic shape adaptation for parametric solid models	automatic shape adaptation;dimension promotion;corresponding face;shape frame;期刊论文	Adaptation, as is well known, plays a fundamental role in Case-Based Design. However, after decades of efforts, automatic adaptation approach is still rare. In common design works, the first thing one will usually do is choosing a start-up model (a candidate model) of moderate complexity based on a simple query model possessing primary design constraints. To enable the candidate model to smartly adapt its shape to that of the query model according to the embedded constraints, a novel automatic shape adaptation approach is proposed in this paper. First, to determine the corresponding faces between two non-preregistered models as relevant elements, a shape frame concept and its quantitative descriptor are defined. Second, to unify the representation of seemingly different but inherently consistent dimensions, a promotion method is adopted. Third, based on the corresponding faces and the promoted dimension representation, the corresponding dimensions between the two parametric solid models are identified. Finally, the parametric information is smoothly transferred from the query model to the candidate model as design constraints, and the shape of the candidate model is automatically adapted to the query model. Besides that, a prototype system is also implemented to verify the effectiveness of the automatic shape adaptation approach. Automatic shape adaptation is achieved based on corresponding faces and dimensions.A new method of determining corresponding faces is put forward.An algorithm to identify corresponding dimensions by constraint graph is proposed.		Wanbin Pan;Xiang Chen;Shuming Gao	2015	Computer-Aided Design	10.1016/j.cad.2014.11.001	active shape model;computer vision;simulation;mathematics;engineering drawing	EDA	65.09110067231143	-44.63714918739199	144359
43a028c58464fd922812fb132f45e5e85be43500	adaptive 4-8 texture hierarchies	texture;general and miscellaneous mathematics computing and information science;large data set visualization;adaptive mesh;data;performance;geometry;tiles low pass filters filtering cutoff frequency geometry surface texture emulation costs mesh generation data structures;informing science;low pass filter;computing;image texture;real time optimization;data visualisation;rendering system;level of detail;level of detail techniques;view dependent visualization;adaptive textures;data access;algorithms;and information science;level of detail technique quadtree style refinement low pass filtering 4 8 texturing hierarchies real time optimally adapting meshes view dependent multiresolution mesh generation data structure large data set visualization out of core algorithms;real time systems data visualisation image texture rendering computer graphics mesh generation quadtrees;rendering computer graphics;mesh generation;data structure;quadtrees;general and miscellaneous mathematics;out of core algorithms large data set visualization level of detail techniques view dependent visualization adaptive textures;real time systems;out of core algorithms	We address the texture level-of-detail problem for extremely large surfaces such as terrain during realtime, view-dependent rendering. A novel texture hierarchy is introduced based on 4-8 refinement of raster tiles, in which the texture grids in effect rotate 45 degrees for each level of refinement. This hierarchy provides twice as many levels of detail as conventional quadtree-style refinement schemes such as mipmaps, and thus provides per-pixel view-dependent filtering that is twice as close to the ideal cutoff frequency for an average pixel. Because of this more gradual change in low-pass filtering, and due to the more precise emulation of the ideal cutoff frequency, we find in practice that the transitions between texture levels of detail are not perceptible. This allows rendering systems to avoid the complexity and performance costs of per-pixel blending between texture levels of detail. The 4-8 texturing scheme is integrated into a variant of the Real-time Optimally Adapting Meshes (ROAM) algorithm for viewdependent multiresolution mesh generation. Improvements to ROAM included here are: the diamond data structure as a stream-lined replacement for the triangle bintree elements, the use of low-pass- filtered geometry patches in place of individual triangles, integration of 4-8 textures, and a simple out-of-core data access mechanism for texture and geometry tiles.	alpha compositing;core data;data access;data structure;emulator;level of detail;low-pass filter;mesh generation;mipmap;out-of-core algorithm;pixel;quadtree;roam;real-time clock;refinement (computing)	Lok M. Hwa;Mark A. Duchaineau;Kenneth I. Joy	2004	IEEE Visualization 2004	10.1109/VISUAL.2004.4	image texture;data access;mesh generation;computer vision;computing;data structure;performance;computer science;theoretical computer science;level of detail;texture;texture atlas;mipmap;texture compression;texture filtering;data visualization;statistics;data;computer graphics (images)	Visualization	67.74467916322726	-50.1877673912269	144455
93c726d4f564e2bba05ad47c1f7195995ae52925	visualization methods of vector data on a digital earth system	stencil shadow volume algorithm visualization methods vector data digital earth system geometry based approaches texture based approaches rendering perspective reparameterization;texture based approaches;texture;digital earth;rendering computer graphics data visualisation geophysics computing image texture;geometry based approaches;vector data render;visualization methods;earth;geometry;data model;image texture;data visualisation;geophysics computing;digital earth system vector data render texture geometry;geographic information systems;three dimensional displays;data visualization;digital earth system;on the fly;rendering computer graphics geometry three dimensional displays data visualization geographic information systems earth data models;vector data;perspective reparameterization;point of view;rendering computer graphics;stencil shadow volume algorithm;data models;rendering	With the rapid development of Digital Earth System, vector data has been widely used as an important data model. Visualization methods to vector data on a Digital Earth System have got more attention. So far, the existing methods can be divided into geometry-based and texture-based approaches basically, and each kind of method applies to different areas with serious shortages in practice. For instance, the texture-based approaches require high memory and the accuracy of the vector data which is unpleasant when zoom in, while the geometry-based approaches have to increase the number of geometric primitives in order to avoid rendering artifacts. To remedy these deficiencies, M. Schneider, M. Guthe and R. klein proposed a texture-based method in 2005 which creates textures on-the-fly and a perspective reparameterization which is applied taking into account the current point-of-view, and then they presented a geometry-based method in 2007 which is based on the stencil shadow volume algorithm. Both of these methods have been greatly improved compared to the previous methods. In this paper, we analyse these two methods and compare their advantages and disadvantages, then conclude with a discussion of their suitable range in practice and give ideas for future improvement.	algorithm;central processing unit;data model;earth system science;graphics hardware;graphics processing unit;high memory;requirement;shadow volume;texture mapping	Yunfei Xu;Zhengwei Sui;Jingnong Weng;Xiaolu Ji	2010	2010 18th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2010.5567902	computer vision;computer science;theoretical computer science;computer graphics (images)	Visualization	67.03322626794824	-52.07836864268014	144687
64406ba2f1463360a866d1aeac24eb01c5678bdd	exploiting motion priors in visual odometry for vehicle-mounted cameras with non-holonomic constraints	visual odometry;urban environment;random sampling;computer model;motion estimation;three dimensional;data association;visual motion;urban areas;three dimensional displays;probability distribution;vehicles cameras proposals motion estimation wheels urban areas three dimensional displays;urban area;vehicles;proposals;cameras;wheels	This paper presents a new method to estimate the relative motion of a vehicle from images of a single camera. The biggest problem in visual motion estimation is data association; matched points contain many outliers that must be detected and removed so that the motion can be estimated accurately. A very established method for robust motion estimation in the presence of outliers is the five-point RANSAC algorithm. Five-point RANSAC operates by generating motion hypotheses from randomly-sampled minimal sets of five-point correspondences. These hypotheses are then tested against all data points and the motion hypothesis that after a given number of iterations returns the largest number of inliers is taken as the solution to the problem. A typical drawback of RANSAC is that the number of iterations required to find a suitable solution grows exponentially with the number of outliers, often requiring thousands of iterations for typical data from urban environments. Another problem is that - due to its random nature - sometimes the found solution is not the “best” solution to the motion estimation problem. In this paper, we describe an algorithm for relative motion estimation in the presence of outliers, which does not rely on RANSAC. Contrary to RANSAC, motion hypotheses are not generated from randomly-sampled point correspondences, but from a “proposal distribution” that is built by exploiting the vehicle non-holonomic constraints. We show that not only is the proposed algorithm significantly faster than RANSAC, but that the returned solution may also be better in that it favors the underlying motion model of the vehicle, thus overcoming the typical limitations of RANSAC. Additionally, the proposed algorithm provides the likelihood of the motion estimate, which can be very useful in all those applications where a probability distribution of the position of the vehicle is required (e.g., SLAM). Finally, the performance of the proposed method is compared to that of the standard five-point RANSAC on real images collected from a vehicle moving in a cluttered, urban environment.	algorithm;correspondence problem;data point;estimation theory;iteration;motion estimation;random sample consensus;randomness;run time (program lifecycle phase);sampling (signal processing);simultaneous localization and mapping;visual odometry;web page;whole earth 'lectronic link	Davide Scaramuzza;Andrea Censi;Kostas Daniilidis	2011	2011 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6095123	computer simulation;probability distribution;three-dimensional space;sampling;computer vision;ransac;simulation;computer science;visual odometry;motion estimation;motion field;computer graphics (images)	Robotics	54.05255445209472	-40.70414713964441	144704
fe3f236524e4c6c529297cc82169daf5c94d461e	motion capture and estimation of dynamic properties for realistic tree animation		The realistic animation of real-world trees is a challenging task because natural trees have various morphology and internal dynamic properties. In this paper, we present an approach to model and animate a specific tree by capturing the motion of its branches. We chose Kinect V2 to record both the RGB and depth of motion of branches with markers. To obtain the three-dimensional (3D) trajectory of branches, we used the mean-shift algorithm to track the markers from color images generated by projecting a textured point cloud onto the image plane, and then inversely mapped the tracking results in the image to 3D coordinates. Next, we performed a fast Fourier transform on the tracked 3D positions to estimate the dynamic properties (i.e., the natural frequency) of the branches. We constructed static tree models using a space colonization algorithm. Given the dynamic properties and static tree models, we demonstrated that our approach can produce realistic animation of trees in wind fields.	motion capture	Shaojun Hu;Peng He;Dongjian He	2017		10.1007/978-3-319-69487-0_2	point cloud;fast fourier transform;image plane;simulation;computer vision;rgb color model;animation;trajectory;motion capture;artificial intelligence;computer science;interactive skeleton-driven simulation	Graphics	60.4082690233275	-45.61492465362408	144708
8bd340546ee2c2131b33a1c0ff66d4a442095972	spectral reflection modeling for image rendering of water paint surfaces				Shogo Nishi;Shoji Tominaga	2008			rendering (computer graphics);computer vision;computer graphics (images);computer science;artificial intelligence	Graphics	63.1972374769041	-51.092017094755896	144722
d378776a1d09b6a51efd243c51afbdc79adc3e8a	designing quad-dominant meshes with planar faces	computer graphics i 3 5 computational geometry and object modeling	We study the combined problem of approximating a surface by a quad mesh (or quad-dominant mesh) which on the one hand has planar faces, and which on the other hand is aesthetically pleasing and has evenly spaced vertices. This work is motivated by applications in freeform architecture and leads to a discussion of fields of conjugate directions in surfaces, their singularities and indices, their optimization and their interactive modeling. The actual meshing is performed by means of a level set method which is capable of handling combinatorial singularities, and which can deal with planarity, smoothness, and spacing issues.	mathematical optimization;planar graph	Mirko Zadravec;Alexander Schiftner;Johannes Wallner	2010	Comput. Graph. Forum	10.1111/j.1467-8659.2010.01776.x	topology;computer science;geometry;computer graphics (images)	Graphics	66.9706913219657	-46.04480999873196	144728
6aa60f6d0f984d0c747fda16c6f172f967701c5c	passive reconstruction of high quality textured 3d models of works of art	texture synthesis;cultural heritage;wavelet decomposition;veric ation;3d model;stereo matching;deformable model;3d reconstruction	A wide-spread use of 3D models in cultural heritage application requires low cost equipment and simple modeling procedures. In this context, passive 3D reconstruction methods allow to build 3D models from a set of calibrated cameras, without the need of expensive machinery. Unfortunately the surfaces characteristics often lead to bad quality reconstructions. Recent efforts attempt to combine together information from different passive methods in order to improve the overall quality of the result. The combination of stereo matching and silhouette information has recently received considerable attention. Typically the major contribution to the appearance of the model comes from texture, rather than from geometry. The straightforward application of the photographs over the model can lead to artifacts, due to errors in 3D reconstructions, which must be minimized. This work, building on recent results, proposes a variation of an algorithm for 3D geometry recovery from stereo and silhouette information within a classical deformable model framework, which improves the quality of the shape. In order to avoid visible texture artifacts, it also proposes a new algorithm for texture synthesis based on wavelet decomposition. Experimental verification shows the effectiveness of the proposed solution with respect to robustness, computational speed and quality of the final result.	3d modeling;3d reconstruction from multiple images;algorithm;computer stereo vision;display resolution;information retrieval;texture mapping;texture synthesis;wavelet	Nicola Brusco;Luca Ballan;Guido M. Cortelazzo	2005		10.2312/VAST/VAST05/021-028	3d reconstruction;computer vision;simulation;computer science;cultural heritage;artificial intelligence;texture synthesis;computer graphics (images)	Vision	58.166289738484274	-51.80978491629421	144834
5c7860ae69dbacf620c4f1d86236e30ddc567685	interactive animation of 4d performance capture	databases;natural dynamics;sensitivity and specificity;interpolation;image motion analysis;natural dynamics interactive animation 4d performance capture 4d parametric motion graph representation actor performance capture multiple camera studio 4d model database mesh sequence reconstruction high level movement control mesh sequence blending approach parametric motion space surface shape motion similarity four dimensional parametric motion graph real time interactive character animation;4d performance capture character animation 3d video real time animation multiview reconstruction video based animation 4d modeling;solid modelling computer animation data visualisation image motion analysis image representation;imaging three dimensional;motion similarity;computer graphics;parametric motion space;4d model database;high level movement control;video based animation;mesh sequence reconstruction;locomotion;4d performance capture;mesh sequence blending approach;signal processing computer assisted;animation real time systems databases aerospace electronics interpolation mesh generation shape;data visualisation;image enhancement;numerical analysis computer assisted;interactive animation;4d parametric motion graph representation;shape;image interpretation computer assisted;multiview reconstruction;image representation;real time interactive character animation;real time animation;multiple camera studio;animation;reproducibility of results;aerospace electronics;four dimensional parametric motion graph;character animation;artificial intelligence;algorithms;pattern recognition automated;actor performance capture;surface shape;humans;subtraction technique;user computer interface;computer animation;mesh generation;3d video;4d modeling;solid modelling;real time systems	A 4D parametric motion graph representation is presented for interactive animation from actor performance capture in a multiple camera studio. The representation is based on a 4D model database of temporally aligned mesh sequence reconstructions for multiple motions. High-level movement controls such as speed and direction are achieved by blending multiple mesh sequences of related motions. A real-time mesh sequence blending approach is introduced, which combines the realistic deformation of previous nonlinear solutions with efficient online computation. Transitions between different parametric motion spaces are evaluated in real time based on surface shape and motion similarity. Four-dimensional parametric motion graphs allow real-time interactive character animation while preserving the natural dynamics of the captured performance.	alpha compositing;cpu (central processing unit of computer system);central processing unit;computation (action);computer animation;current source device component;graph (abstract data type);graph - visual representation;hertz (hz);high- and low-level;mathematical optimization;motion capture;nonlinear system;pierre robin syndrome;real-time clock;real-time computing;real-time locating system;real-time transcription;sequence alignment;solutions	Dan Casas;Margara Tejera;Jean-Yves Guillemaut;Adrian Hilton	2013	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2012.314	anime;character animation;mesh generation;computer vision;simulation;skeletal animation;interpolation;shape;computer science;computer animation;computer graphics;data visualization;statistics;computer graphics (images)	Visualization	61.44953240533785	-46.2675668889638	144848
569e71554716b03bdb3b03491c239ceeb78cb92b	color constancy using 3d scene geometry	3d scene geometry;image segmentation;color constancy;layout geometry light sources solid modeling image segmentation lighting large scale systems testing error correction color;geometry;computational geometry;universiteitsbibliotheek;hard segmentation;estimation;three dimensional displays;image color analysis;image colour analysis;soft segmentation;pixel;ill posed problem;light source estimation;image segmentation computational geometry image colour analysis;median angular error color constancy 3d scene geometry hard segmentation soft segmentation light source estimation remote scene illumination color;remote scene illumination color;median angular error;light sources	The aim of color constancy is to remove the effect of the color of the light source. As color constancy is inherently an ill-posed problem, most of the existing color constancy algorithms are based on specific imaging assumptions such as the grey-world and white patch assumptions. In this paper, 3D geometry models are used to determine which color constancy method to use for the different geometrical regions found in images. To this end, images are first classified into stages (rough 3D geometry models). According to the stage models, images are divided into different regions using hard and soft segmentation. After that, the best color constancy algorithm is selected for each geometry segment. As a result, light source estimation is tuned to the global scene geometry. Our algorithm opens the possibility to estimate the remote scene illumination color, by distinguishing nearby light source from distant illuminants. Experiments on large scale image datasets show that the proposed algorithm outperforms state-of-the-art single color constancy algorithms with an improvement of almost 14% of median angular error. When using an ideal classifier (i.e, all of the test images are correctly classified into stages), the performance of the proposed method achieves an improvement of 31% of median angular error compared to the best-performing single color constancy algorithm.	algorithm;angularjs;autostereogram;experiment;illumination (image);scene statistics;signal-to-noise ratio;well-posed problem	Rui Lu;Arjan Gijsenij;Theo Gevers;Vladimir Nedovic;De Xu;Jan-Mark Geusebroek	2009	2009 IEEE 12th International Conference on Computer Vision	10.1109/ICCV.2009.5459391	computer vision;estimation;chromatic adaptation;color model;lightness;color normalization;computational geometry;computer science;mathematics;geometry;color balance;image segmentation;color constancy;pixel;computer graphics (images)	Vision	56.96192837905772	-51.28325706773495	145212
0ee56ee5f645232419642e575d8c061ebcd812c1	hierarchical z-buffer visibility	octree;spatial coherence;pyramid;temporal coherence;z buffer	An ideal visibility algorithm should a) quickly reject most of the hidden geometry in a model and b) exploit the spatial and perhaps temporal coherence of the images being generated. Ray casting with spatial subdivision does well on criterion (a), but poorly on criterion (b). Traditional Z-buffer scan conversion does well on criterion (b), but poorly on criterion (a). Here we present a hierarchical Z-buffer scan-conversion algorithm that does well on both criteria. The method uses two hierarchical data structures, an object-space octree and an image-space Z pyramid, to accelerate scan conversion. The two hierarchical data structures make it possible to reject hidden geometry very rapidly while rendering visible geometry with the speed of scan conversion. For animation, the algorithm is also able to exploit temporal coherence. The method is well suited to modelswith high depth complexity, achieving orders of magnitude acceleration in some cases compared to ordinary Z-buffer scan conversion. CR	algorithm;coherence (physics);data structure;eisenstein's criterion;emoticon;hidden surface determination;hierarchical database model;octree;ray casting;scan conversion;space partitioning;subdivision surface;z-buffering	Ned Greene;Michael Kass;Gavin S. P. Miller	1993		10.1145/166117.166147	computer vision;computer science;z-buffering;pyramid;octree;computer graphics (images)	Graphics	66.55938107880033	-50.922605923509614	145247
d33b48e817a7e8e85b935f8c826f9ea4164bced3	current experience with transfinite interpolation	computer aided design;modele geometrique;polynomial interpolation;conception assistee;ajustement courbe;surface;surfaces;interpolacion polinomial;curve fitting;interpolation polynomiale;geometrical model;modelo geometrico	"""Gordon methods for transfinite interpolation may be extended so as to allow interpolation of derivative information at arbitrary mesh lines. These results are reviewed and applications and examples are presented. © 1999 Elsevier Science B.V. All rights reserved. 1. I n t r o d u c t i o n This paper discusses some current experience with the problem of constructing a suitable surface which interpolates a given rectangular mesh in R 3. The problem is of central importance to the field of geometric modeling and has numerous application. Instead of building surfaces as conglomerates of individual patches, as was and still is common practice, Gordon (1968, 1969a, 1969b), introduced a technique whereby certain methods of univariate polynomial spline interpolation are extended so as to allow a rectangular mesh to be interpolated as a single surface. For a number reasons, which include the inability to assign derivative values at arbitrary mesh points, reliance on a scheme of cardinal interpolation, and lack of local control, Gordon methods seem to have fallen by the wayside. Although the Gordon methods dispense with the difficulty of having to specil3 large amounts of data for each surface patch, they provide no good methods to specify lhis same data should it be essential. The present papers builds on the results of (Walker. 1998) in which the Gordon methods are extended so as to avoid some disadvantage. In particular it is shown in (Walker, 1998) that any two univariate interpolation schemes may be extended to a bivariate mesh interpolation method, according to the method set out by Gordon. In the case of univariate schemes based on cardinal polynomial blending functions of odd degree, the result is known and appears in (Gordon, 1968). The general result is very simply proved, and. although perhaps part of the folklore of CAGD, it has not appear and is important in that 0167-8396/99/$ -see front matter © 1999 Elsevier Science B.V. All rights rcserxed. Pll: St) 167-8396198 )00033-8 78 M. Walker /Compu te r Aided Geometric"""" Design 16 (1999) 7 ~ 8 3 it opens the door to an investigation of bivariate interpolation schemes based on various univariate, perhaps non-polynomial , methods. Also in (Walker, 1998), it was shown that with the extended Gordon methods it is possible to construct surfaces which interpolate not only the given mesh but also prescribed derivatives of arbitrary order in directions across mesh lines. Unlike the previous, this result has no reflection in any of the literature surrounding Gordon 's work In this paper, we report on experience applying the above results. In Section 2, definitions and notation are introduced together with a review of the results in (Walker, 1998) for the sake of completeness. In Section 3, two applications are discussed, assigning tangent values across mesh lines and the G k attachment of one surface along a mesh line to a curve in another."""	alpha compositing;amiga walker;attachments;bivariate data;computer-aided design;geometric modeling;patch (computing);polynomial;spline interpolation;transfinite interpolation	Marshall Walker	1999	Computer Aided Geometric Design	10.1016/S0167-8396(98)00033-8	spline interpolation;combinatorics;bilinear interpolation;birkhoff interpolation;interpolation;polynomial interpolation;computer aided design;calculus;inverse quadratic interpolation;bicubic interpolation;mathematics;geometry;linear interpolation;nearest-neighbor interpolation;surface;statistics;trilinear interpolation	Theory	68.20241080778743	-40.75199803337175	145364
a53729dd2ea748faedd1ab7a89bd5b2c5e865186	polynomial shape from shading	minimization;polynomial system;line search;shading ambiguities;shape from shading;semidefinite programming relaxation procedure;polynomials shape light sources boundary conditions equations computer vision cameras calibration software systems humans;numerical technique;shape recognition;shading ambiguities polynomial shape polyhedral objects semidefinite programming relaxation procedure exact line search iterative procedure;polynomials;iterative methods;shape;boundary condition;pixel;exact line search iterative procedure;shape recognition iterative methods polynomials;polyhedral objects;polynomial shape;semidefinite programming relaxation;light sources	We examine the shape from shading problem without boundary conditions as a polynomial system. This view allows, in generic cases, a complete solution for ideal polyhedral objects. For the general case we propose a semidefinite programming relaxation procedure, and an exact line search iterative procedure with a new smoothness term that favors folds at edges. We use this numerical technique to inspect shading ambiguities.	iterative method;line search;linear programming relaxation;numerical analysis;photometric stereo;polyhedron;semidefinite programming;shading;system of polynomial equations	Ady Ecker;Allan D. Jepson	2010	2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2010.5540219	mathematical optimization;combinatorics;photometric stereo;shape;boundary value problem;mathematics;geometry;iterative method;line search;pixel;polynomial	Vision	55.20810988365171	-51.723427696627056	145392
36b336ab225f3e10f3a0468247702e70f680f41b	computer modeling of surfaces with arbitrary shapes	modelizacion;concepcion asistida;computer aided design;fabricacion asistida por computador;curva bezier;modele mathematique;computer graphics;computer model;solid modeling computer modelling of surfaces arbitrary shapes local mathematical procedure cubic bezier curves composite mosaic independently parameterized tensor product bezier patches;modelo matematico;modelisation;tensor product;fabrication assistee;courbe bezier;computer aided manufacturing;solid modeling;mathematical model;conception assistee;superficie;surface;curve fitting;modeling;grafico computadora;infographie;shape polynomials mathematical model ice surface laboratories computer aided manufacturing cadcam machining solid modeling;solid modelling curve fitting;solid modelling;bezier curve	A detailed description is given of a local mathematical procedure for constructing a geometrically C/sup 1/ surface by interpolating a grid of cubic Bezier curves that meet in a quite general fashion (for example, they need not meet rectangularly). The constructed surface is a composite mosaic of independently parameterized tensor-product Bezier patches of different degrees (maximum of 6*6). Adjacent patches can be made either C/sup 1/ or C/sup 0/ continuous, as desired. The overall surface can have almost any shape that arises in practice, including the closed surfaces used in solid modeling. Because of its locality, the procedure can be applied at different times in different locations of a surface-to-be; for example, it can be used to combine preexisting smaller surfaces.<<ETX>>	computer simulation;cubic function;interpolation;locality of reference;solid modeling	Ramon F. Sarraga	1990	IEEE Computer Graphics and Applications	10.1109/38.50675	tensor product;simulation;systems modeling;computer aided design;bézier curve;mathematical model;mathematics;geometry;solid modeling;computer graphics;surface;statistics;curve fitting;computer-aided manufacturing;mechanical engineering	Graphics	67.1576278665298	-41.70094118163705	145893
a91a9d405e633e4021dfa11a9046e5a3b420b6e3	stochastic mesh-based multiview reconstruction	stochastic mesh based multiview reconstruction;probability;computer graphics;probability density function;texture mapping;geometry;computational geometry;model fit inaccuracy;3d polygonal models;multiple views;stochastic processes image reconstruction photometry cameras computer science sampling methods solids geometry computer graphics rendering computer graphics;stochastic processes;photometry;free form deformations stochastic mesh based multiview reconstruction 3d polygonal models sampling techniques texture mapped semi regular polygonal mesh constructive solid geometry visual hull silhouette prisms model fit inaccuracy probability density function photometric consistency;polygonal meshes;image reconstruction;texture mapped semi regular polygonal mesh;constructive solid geometry;visual hull;free form deformation;photometric consistency;technical report;computer science;model fitting;sampling methods;rendering computer graphics;sampling techniques;computational geometry probability computer graphics;cameras;silhouette prisms;solids;free form deformations	A method for reconstruction of 3D polygonal models from multiple views is presented. The method uses sampling techniques to construct a texture-mapped semi-regular polygonal mesh of the object in question. Given a set of views and segmentation of the object in each view, constructive solid geometry is used to build a visual hull from silhouette prisms. The resulting polygonal mesh is simplified and subdivided to produce a semi-regular mesh. Regions of model fit inaccuracy are found by projecting the reference images onto the mesh from different views. The resulting error images for each view are used to compute a probability density function, and several points are sampled from it. Along the epipolar lines corresponding to these sampled points, photometric consistency is evaluated. The mesh surface is then pulled towards the regions of higher photometric consistency using free-form deformations. This sampling-based approach produces a photometrically consistent solution in much less time than possible with previous multi-view algorithms given arbitrary camera placement.	algorithm;camera resectioning;constructive solid geometry;contour advection;epipolar geometry;graphics hardware;incidence matrix;iteration;iterative reconstruction;lambertian reflectance;level of detail;normal (geometry);pixel;polygon mesh;requirement;sampling (signal processing);semiconductor industry;silhouette edge;sliver polygon;subdivision surface;texture mapping;visual hull	John Isidoro;Stan Sclaroff	2002		10.1109/TDPVT.2002.1024120	mesh generation;computer vision;mathematics;geometry;laplacian smoothing;t-vertices;computer graphics (images)	Vision	66.78756847015096	-45.13655328006241	146241
7a13869b2ccdd428cdc827b24dc8f5eb8931c86a	skewed mirror symmetry for depth estimation in 3d line-drawings	espejo;regularite;miroir;polyedre;image processing;modelo 3 dimensiones;info eu repo semantics conferenceobject;regularidad;sketch understanding;mirror;poliedro;planes of symmetry;modele 3 dimensions;regularity;procesamiento imagen;three dimensional model;polyhedron;grafismo;graphisme;traitement image;mirror symmetry;three dimensional;line drawings;graphics interpretation;geometric modelling;reconocimiento grafico;pattern recognition;graphism;reconnaissance graphique;reconnaissance forme;reconocimiento patron;depth estimation;graphics recognition;perceptual reasoning;3d reconstruction;graphical recognition;qa76 computer software	We aim to reconstruct three-dimensional polyhedral solids from axonometric-like line drawings. A new approach is proposed to make use of planes of mirror symmetry detected in such sketches. Taking account of mirror symmetry of such polyhedra can significantly improve the reconstruction process. Applying symmetry as a regularity in optimisation-based reconstruction is shown to be adequate by itself, without the need for other inflation techniques or regularities. Furthermore, symmetry can be used to reduce the size of the reconstruction problem, leading to a reduction in computing time.	analysis of algorithms;axonometric projection;computer science;mathematical optimization;planar graph;polyhedron;reconstruction conjecture;recursion;sketch	Ana Piquer Vicent;Ralph R. Martin;Pedro Company	2003		10.1007/978-3-540-25977-0_13	3d reconstruction;three-dimensional space;computer vision;image processing;rotational symmetry;computer science;mathematics;geometry;algorithm;polyhedron;mirror symmetry	Vision	65.7130606049677	-41.46809556307849	146422
831d7f8a04bdc08bf8151ca652b00a033d068908	determining characteristic views of a 3d object by visual hulls and hausdorff distance	databases;object representation;relative position;image recognition;object recognition;3d object representation;image resolution;image matching;image resolution computational geometry visual databases image representation image matching mesh generation;characteristic views;geometry;computational geometry;layout;data mining;view resolution characteristic views visual hull hausdorff distance 3d object representation private databases image matching 3d mesh isocahedron;3d model;image representation;field of view;visual hull;hausdorff distance;databases data acquisition data mining object recognition image recognition layout solids digital images geometry cameras;isocahedron;mesh generation;data acquisition;digital images;cameras;view resolution;solids;3d mesh;visual databases;private databases	Nowadays, with the exponential growing of 3D object representations in private databases or on the web, it is all the more required to match these objects from some views. To improve the results of their matching, we work on the characteristic views of an object. The aim of this study is to find how many characteristic views are required and what relative positions are optimal. This is the reason why the visual hulls are used. From some 2D masks, the nearest possible 3D mesh from the original object is computed. OpenGL views are used to build the visual hulls of 3D models from a given collection and then the distance between the visual hulls and the models are measured thanks to the Hausdorff distance. Then the best view parameters are deduced to reduce the distance. These shots show that three orthogonal views give results very close to the ones given by twelve views on a isocahedron. Some other results on the view resolution and the field of view are discussed.	3d modeling;approximation;database;digital library;hausdorff dimension;image resolution;library (computing);opengl;time complexity;variable shadowing;visual hull	Adrien Theetten;Jean-Philippe Vandeborre;Mohamed Daoudi	2005	Fifth International Conference on 3-D Digital Imaging and Modeling (3DIM'05)	10.1109/3DIM.2005.31	polygon mesh;layout;mesh generation;hausdorff distance;computer vision;image resolution;field of view;computational geometry;computer science;cognitive neuroscience of visual object recognition;pattern recognition;solid;mathematics;geometry;data acquisition;digital image	Vision	56.80020437801313	-50.94350973964726	146498
286923b1600e05ac9262add6819e084ef7c8b547	3d point cloud segmentation oriented to the analysis of interactions	graph theory;histograms;image segmentation;computer graphics;two dimensional displays;shape;three dimensional displays;image color analysis;image colour analysis;labeling;conference lecture	Given the widespread availability of point cloud data from consumer depth sensors, 3D point cloud segmentation becomes a promising building block for high level applications such as scene understanding and interaction analysis. It benefits from the richer information contained in real world 3D data compared to 2D images. This also implies that the classical color segmentation challenges have shifted to RGBD data, and new challenges have also emerged as the depth information is usually noisy, sparse and unorganized. Meanwhile, the lack of 3D point cloud ground truth labeling also limits the development and comparison among methods in 3D point cloud segmentation. In this paper, we present two contributions: a novel graph based point cloud segmentation method for RGBD stream data with interacting objects and a new ground truth labeling for a previously published data set [1]. This data set focuses on interaction (merge and split between `object' point clouds), which differentiates itself from the few existing labeled RGBD data sets which are more oriented to Simultaneous Localization And Mapping (SLAM) tasks. The proposed point cloud segmentation method is evaluated with the 3D point cloud ground truth labeling. Experiments show the promising result of our approach.	3d computer graphics;experiment;graph (abstract data type);ground truth;high-level programming language;image segmentation;interaction;mean squared error;noise (electronics);point cloud;sensor;simultaneous localization and mapping;sparse matrix;voxel	Xiao Lin;Josep R. Casas;Montse Pardàs	2016	2016 24th European Signal Processing Conference (EUSIPCO)	10.1109/EUSIPCO.2016.7760379	computer vision;computer science;data mining;scale-space segmentation;connected-component labeling;computer graphics (images)	Vision	53.99991478427425	-46.86250934177306	146794
7a212fd6d2f8bd9a2be32622c1059b7a0191f7e2	depth from scattering	analysis of outdoor imagery;image understanding;estimation of depth;scattering;light scattering particle scattering rayleigh scattering atmosphere atmospheric modeling image analysis atmospheric waves layout computational modeling lighting;image reconstruction;physics based vision;outdoor scenes atmospheric scattering image understanding autonomous vehicles depth cues;image reconstruction scattering	Light power is a ected when it crosses the atmosphere; there is a simple, albeit non-linear, relationship between the radiance of an image at any given wavelength and the distance between object and viewer. This phenomenon is called atmospheric scattering and has been extensively studied by physicists and meterologists. We present the rst analysis of this phenomenon from an image understanding perspective: we investigate a group of techniques for extraction of depth cues solely from the analysis of atmospheric scattering e ects in images. Depth from scattering techniques are discussed for indoor and outdoor environments, and experimental tests with real images are presented. We have found that depth cues in outdoor scenes can be recovered with surprising accuracy and can be used as an additional information source for autonomous vehicles.	autonomous robot;computer vision;depth perception;information source;nonlinear system	Fábio Gagliardi Cozman;Eric Krotkov	1997		10.1109/CVPR.1997.609419	iterative reconstruction;computer vision;scattering	Vision	56.26288538862145	-51.8280420837319	147183
e75a61921d6379ac614f2bed2bd7fff80ec8141e	csculpt: a system for collaborative sculpting	collaborative modeling;digital sculpting and painting	Collaborative systems are well established solutions for sharing work among people. In computer graphics these workflows are still not well established, compared to what is done for text writing or software development. Usually artists work alone and share their final models by sending files. In this paper we present a system for collaborative 3D digital sculpting. In our prototype, multiple artists concurrently sculpt a polygonal mesh on their local machines by changing its vertex properties, such as positions and material BRDFs. Our system shares the artists' edits automatically and seamlessly merges these edits even when they happen on the same region of the surface. We propose a merge algorithm that is fast-enough for seamless collaboration, respects users' edits as much as possible, can support any sculpting operation, and works for both geometry and appearance modifications. Since in sculpting artists alternatively perform fine adjustments and large scale modifications, our algorithm is based on a multiresolution edit representation that handles concurrent overlapping edits at different scales. We tested our algorithm by modeling meshes collaboratively in different sculpting sessions and found that our algorithm outperforms prior works on collaborative mesh editing in all cases.	bidirectional reflectance distribution function;computer graphics;digital sculpting;genus (mathematics);merge algorithm;multiresolution analysis;polygon mesh;prototype;seamless3d;software development	Claudio Calabrese;Gabriele Salvati;Marco Tarini;Fabio Pellacini	2016	ACM Trans. Graph.	10.1145/2897824.2925956	computer science;multimedia;computer graphics (images)	Graphics	65.627775222032	-48.96947687640346	147283
05e0849165594e2d2f3cd4ab61a1eb7fbc30970e	progressive refinement rendering of implicit surfaces	implicit surface;low resolution;implicit surfaces;polygonal meshes;lipschitz continuity;lipschitz bounds;progressive refinement;ray casting	The visualisation of implicit surfaces can be an inefficient task when such surfaces are complex and highly detailed. Visualising a surface by first converting it to a polygon mesh may lead to an excessive polygon count. Visualising a surface by direct ray casting is often a slow procedure. In this paper we present a progressive refinement renderer for implicit surfaces that are Lipschitz continuous. The renderer first displays a low resolution estimate of what the final image is going to be and, as the computation progresses, increases the quality of this estimate at an interactive frame rate. This renderer provides a quick previewing facility that significantly reduces the design cycle of a new and complex implicit surface. The renderer is also capable of completing an image faster than a conventional implicit surface rendering algorithm based on ray casting.	algorithm;aliasing;anti-aliasing filter;b-spline;color gradient;computation;cone tracing;image resolution;implicit surface;lookup table;luminous studio;monoid factorisation;network switch;pixel;polygon (computer graphics);polygon mesh;power of two;progressive refinement;ray casting;refinement (computing);region of interest;rendering (computer graphics);scan line;spatial anti-aliasing;subdivision surface;xsa	Manuel N. Gamito;Steve C. Maddock	2007	Computers & Graphics	10.1016/j.cag.2007.04.011	mathematical optimization;image resolution;computer science;ray casting;mathematics;geometry;lipschitz continuity	Graphics	67.41564355049105	-50.31818507376561	147292
7ac31c9d68c708ef59b4aad0177bfa6d51007353	a single camera motion capture system dedicated to gestures imitation	3d articulated structures;cost function;degree of freedom;image sequence analysis;degenerated quadrics;colour distribution;camera motion;3d model;humanoid robots;degeneration;particle filter;single camera motion capture system;image sequence;reference distribution single camera motion capture system gestures imitation 3d articulated structures monocular perspective image sequence particle filter degenerated quadrics colour distribution;gestures imitation;reference distribution;cameras particle filters humanoid robots particle tracking robot vision systems humans motion analysis light emitting diodes shape measurement image analysis;image sequences gesture recognition humanoid robots;gesture recognition;image sequences;monocular perspective image sequence	This article describes a method to track 3D articulated structures from a monocular perspective image sequence using a particle filter. This structure is composed of a set of linked degenerated quadrics (cones) which are truncated by pairs of planes also modelled as degenerated quadrics. This set of truncated cones is connected by joints containing one or more degrees of freedom. The method is based upon the estimation of the contours of the structure's silhouette projected on the image plane, to validate each of the particles which correspond to proposed configurations. This validation is performed using a criterion that combines a measure based on the contours, a measure of similarity between the colour distribution around a point on the structure and a reference distribution, and other criteria that reinforce the overall cost function. The results show the feasibility of the approach when using a single camera to track a 3D model containing eight degrees of freedom	3d projection;approximation;contour line;experiment;humanoid robotics project;humanoid robot;image plane;kinesiology;loss function;motion capture;particle filter;peterson's algorithm;polygonal modeling;silhouette edge;superquadrics	Paulo Menezes;Frédéric Lerasle;Jorge Dias;Raja Chatila	2005	5th IEEE-RAS International Conference on Humanoid Robots, 2005.	10.1109/ICHR.2005.1573605	computer vision;simulation;particle filter;computer science;humanoid robot;artificial intelligence;gesture recognition;mathematics;degrees of freedom;computer graphics (images)	Robotics	53.842179638043056	-50.25913897477156	147461
52b1657f857be25573d0851ed2d17417d77bfd64	raster-scan hidden surface algorithm techniques	curve drawing;partitioning;line tracking;raster devices;incremental plotters;general line	Two new techniques are presented for reducing the number of depth calculations in hidden surface elimination. Two new algorithms using the techniques are compared with three existing algorithms and it is shown by examples that the new techniques reduce the number of multiplications involved in the depth calculations. A technique for increasing the parallelism of operations is also presented. This allows the calculation to be done more rapidly in hardware and is particularly useful for generating line drawings rather than the usual TV raster scan images in the common raster-scan hidden surface algorithms.	algorithm;hidden surface determination;parallel computing;raster scan	Griffith Hamlin;C. William Gear	1977		10.1145/563858.563895	computer science;theoretical computer science;algorithm;computer graphics (images)	Graphics	67.19540177148588	-50.50580264901676	147536
837d25a760139ba2d8ec1c45f5010cc5a0bc7014	laziness is a virtue: motion stitching using effort minimization		Given two motion-capture sequences that are to be stitched together, how can we assess the goodness of the stitching? The straightforward solution, Euclidean distance, permits counter-intuitive results because it ignores the effort required to actually make the stitch. The main contribution of our work is that we propose an intuitive, first-principles approach, by computing the effort that is needed to do the transition (laziness-effort, or ’L-score’). Our conjecture is that, the smaller the effort, the more natural the transition will seem to humans. Moreover, we propose the elastic L-score which allows for elongated stitching, to make a transition as natural as possible. We present preliminary experiments on both artificial and real motions which show that our L-score approach indeed agrees with human intuition, it chooses good stitching points, and generates natural transition paths.	euclidean distance;experiment;image stitching;motion capture	Lei Li;James McCann;Christos Faloutsos;Nancy S. Pollard	2008		10.2312/egs.20081028	simulation;engineering;nanotechnology;engineering drawing	ML	63.753003278486055	-42.456942767097075	147603
1d021bae2e694f33d514f6aa7db82443e52cdc85	diminishable visual markers on fabricated projection object for dynamic spatial augmented reality	3d;telepresence;human surrogate;autostereoscopic;display;cone	Spatial augmented reality (SAR) is a projection technology to add optical illusion onto static objects. Generally, in SAR, images are projected on complex everyday surfaces other than a flat projection screen. Thus, geometric correction of images is essential. Many studies have examined geometric correction of projection images on nonplanar surfaces. If a projection surface shape is known, it is possible to correct images geometrically by calibrating intrinsic parameters of the projector and extrinsic parameters (position and pose relationships) between the projector and surfaces. However, it is difficult to directly apply previous geometric correction methods to dynamically moving surfaces, because these methods generally assumed only static surfaces.	augmented reality;camera resectioning;projection screen;video projector	Hirotaka Asayama;Daisuke Iwai;Kosuke Sato	2015		10.1145/2818466.2818477	autostereoscopy;computer vision;cone;computer science;geometry;3d computer graphics;computer graphics (images)	HCI	58.669764249838565	-50.338798175818305	147805
6115fb6b5541b50c46f36e28d335dbef3ad08bf2	geospatial management and utilization of large-scale urban visual reconstructions	image motion analysis;augmented reality geospatial management large scale urban visual reconstructions geospatial utilization large scale structure from motion reconstructions point grey ladybug 3 omnidirectional camera custom backpack system differential gps sensor sparse point cloud reconstructions offline process geospatial database multiple crowd sourced databases openstreetmap flickr instagram;image reconstruction cameras global positioning system databases buildings receivers feature extraction;computer vision;global positioning system;visual databases augmented reality global positioning system image motion analysis image reconstruction;image reconstruction;computer vision structure from motion augmented reality;augmented reality;structure from motion;visual databases	In this work we describe our approach to efficiently create, handle and organize large-scale Structure-from-Motion reconstructions of urban environments. For acquiring vast amounts of data, we use a Point Grey Ladybug 3 omni directional camera and a custom backpack system with a differential GPS sensor. Sparse point cloud reconstructions are generated and aligned with respect to the world in an offline process. Finally, all the data is stored in a geospatial database. We incorporate additional data from multiple crowd-sourced databases, such as maps from OpenStreetMap or images from Flickr or Instagram. We discuss how our system could be used in potential application scenarios from the area of Augmented Reality.	aerial photography;algorithm;ar (unix);augmented reality;component-based software engineering;crowdsourcing;differential gps;flickr;global positioning system;goto;instagram;map;online and offline;openstreetmap;point cloud;sparse matrix;spatial database	Clemens Arth;Jonathan Ventura;Dieter Schmalstieg	2013	2013 Fourth International Conference on Computing for Geospatial Research and Application	10.1109/COMGEO.2013.10	computer vision;augmented reality;simulation;geography;computer graphics (images)	Visualization	55.57423315840539	-45.32430630710628	148113
1af6cdd2697539f39417096bd63e792d379a8fd9	dynamic sprites	physics based animation	Traditional methods for creating dynamic objects and characters from static drawings involve careful tweaking of animation curves and/or simulation parameters. Sprite sheets offer a more drawing-centric solution, but they do not encode timing information or the logic that determines how objects should transition between poses and cannot generalize outside the given drawings. We present an approach for creating dynamic sprites that leverages sprite sheets while addressing these limitations. In our system, artists create a drawing, deform it to specify a small number of example poses, and indicate which poses can be interpolated. To make the object move, we design a procedural simulation to navigate the pose manifold in response to external or user-controlled forces. Powerful artistic control is achieved by allowing the artist to specify both the pose manifold and how it is navigated, while physics is leveraged to provide timing and generality. We used our method to create sprites with a range of different dynamic properties.	encode;interpolation;simulation;sprite (computer graphics);texture atlas;tweaking	Ben Jones;Jovan Popovic;James McCann;Wilmot Li;Adam W. Bargteil	2013		10.1145/2522628.2522631	computer vision;simulation;computer science;artificial intelligence;computer graphics (images)	Graphics	66.74248551669724	-46.7961838774937	148203
98df68367d8153da350c202ed81d65681adb3cac	3d calibration test-field for digital cameras mounted on unmanned aerial systems (uas)				Valeria-Ersilia Oniga;Norbert Pfeifer;Ana-Maria Loghin	2018	Remote Sensing	10.3390/rs10122017		Robotics	58.95113398814722	-42.64765661859029	148678
17af8692a48b4e67f858237bd2fb08cf733dc121	a perceptual heuristic for shadow computation in photo-realistic images	expressive imagery;non realistic modeling	Perceptual research in photo-realistic rendering has mainly focused on the limitations of the human visual system to predict visible differences between the pixels of a radiometrically correct image and an approximation of the same image [Daly 1993]. However, research in perceptual psychology and vision suggests that image interpretation is inherently a higher-level, feature-based process. Furthermore, applications rarely demand a direct comparison to a radiometrically correct image, so approximations can be less strict. We propose a novel approach to perception that is geared towards these conditions for observing images.	approximation;computation;global illumination;heuristic;pixel	Peter Vangorp;Olivier Dumont;Toon Lenaerts;Philip Dutré	2006		10.1145/1179849.1179977	computer vision;simulation;computer science;machine learning;computer graphics (images)	Vision	63.048274713943485	-50.81604304315242	148696
e85bfbb2dce4241a67cb68ffc99b83b18848263b	very high speed multi resolution sheet-of-light range imaging	range image;multi resolution;high speed	Sheet-of-light range measurement is a commonly used method in todays industrial applications. This paper describes a new way of using an existing image sensor and turns it into a fast programmable sheet-of-light range sensor. The system is capable of measuring up to 4 Mranglels.	image sensor;range imaging	Anders Åström;Erik Åstrand	1996			computer vision	Robotics	57.60753914839115	-42.667004227010175	148846
11c75bab8f95dd8d44be111bae98328e16402d32	combinatorial bidirectional path-tracing for efficient hybrid cpu/gpu rendering	color shading shadowing and texture;i 3 7 computer graphics three dimensional graphics and realism;i 6 8 simulation and modeling type of simulation;monte carlo	This paper presents a reformulation of bidirectional path-tracing that adequately divides the algorithm into processes efficiently executed in parallel on both the CPU and the GPU. We thus benefit from high-level optimization techniques such as double buffering, batch processing, and asyncronous execution, as well as from the exploitation of most of the CPU, GPU, and memory bus capabilities. Our approach, while avoiding pure GPU implementation limitations (such as limited complexity of shaders, light or camera models, and processed scene data sets), is more than ten times faster than standard bidirectional path-tracing implementations, leading to performance suitable for production-oriented rendering engines.	algorithm;batch processing;bidirectional search;central processing unit;computation;graphics processing unit;high- and low-level;high-level programming language;interleaved memory;layout engine;mathematical optimization;memory bus;multiple buffering;path tracing;population;shader;web browser engine	Anthony Pajot;Loïc Barthe;Mathias Paulin;Pierre Poulin	2011	Comput. Graph. Forum	10.1111/j.1467-8659.2011.01863.x	computer vision;simulation;rendering;computer science;theoretical computer science;operating system;statistics;software rendering;monte carlo method;computer graphics (images)	Graphics	66.64333358709497	-51.36802444794685	148936
17c01338e60d1d7bba2fa14f893692455cfe2e45	an inspect measurement system for moving objects	surface measurement 3 d image acquisition fringe pattern analysis fringe pattern profilometry image reconstruction industrial inspection;semiconductor manufacturing inspect measurement system moving object measurement noncontact optical imaging inspection stationary object metrology 3d surface profile reconstruction phase measuring profilometry sinusoidal pattern projection phase measurement translation geometry effect height calculation error imaging and numerical surface profilometry with error compensation technology nonlinear perspective geometry effect first order equation taylor series expansion phase shift algorithm optimization procedure height information computation;surface topography measurement error compensation geometry imaging measurement errors numerical analysis optimisation series mathematics;article;image reconstruction surface reconstruction imaging gratings semiconductor device measurement inspection metrology	Noncontact optical imaging is frequently used in the inspection and metrology of stationary objects, including in particular the reconstruction of the 3-D surface profile. A technique, known as phase-measuring profilometry, involves projecting a sinusoidal pattern and then inferring the height of various points on the object by measuring the resulting phase changes at the respective locations. However, this method cannot be directly applied to systems involving moving objects, as the translation and the perspective geometry effect manifest as errors in the height calculations. In this paper, we report on an imaging and numerical surface profilometry with error compensation technology (INSPECT) measurement system that is tailored for moving objects. We model the imaging system that considers the nonlinear perspective geometry effect, and simplify to a first-order equation using Taylor series expansion. With this, we generalize the conventional phase shift algorithm, and develop the optimization procedures that can compute the height information effectively. We apply this technology to the INSPECT measurement system in semiconductor manufacturing and show significant improvement in accuracy and robustness.		Fuqin Deng;Chang Liu;Wuifung Sze;Jiangwen Deng;Kenneth S. M. Fung;Edmund Y. Lam	2015	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2014.2329387	computer vision;engineering;optics;engineering drawing	Vision	56.20761704416767	-49.781561665066015	149071
36bcbd66717e17e96ffdc5cc8c4b65f1dfb393a2	a framework for polysensometric multidimensional spatial visualization	data visualisation;image recognition;sensor fusion;3d model refinement;automated software system;fusion visualization;information engineering based tool;multidimensional space;multiple sensors;polymorphic visual information fusion framework;polysensometric data classification metrics;polysensometric multidimensional spatial visualization	Typically any single sensor instrument suffers from physical/observation constraints. This paper discusses a generalized framework, called polymorphic visual information fusion framework (PVIF) that can enable information from multiple sensors to be fused and compared to gain broader understanding of a target of observation in multidimensional space. An automated software system supporting comparative cognition has been developed to form 3D models based on the datasets from different sensors, such as XPS and LSCM. This fusion framework not only provides an information engineering based tool to overcome the limitations of individual sensor's scope of observation but also provides a means where theoretical understanding surrounding a complex target can be mutually validated by comparative cognition about the object of interest and 3D model refinement. Some polysensometric data classification metrics are provided to measure the quality of input datasets for fusion visualization.	3d modeling;algorithm;cognition;constraint (mathematics);graphics;ibm notes;image processing;information engineering;least squares conformal map;open xml paper specification;refinement (computing);sensor;software system;theory	Javed I. Khan;Xuebin Xu;Yongbin Ma	2004	Proceedings. International Conference on Computer Graphics, Imaging and Visualization, 2004. CGIV 2004.	10.1109/CGIV.2004.1323978	computer vision;computer science;data science;data mining	Visualization	59.452625211081504	-44.542395376259684	149088
03991ce8681c2d38e28384c87016dca78e07dfab	parameter free torsion estimation of curves in 3d images	lattices;skeleton;splines mathematics;smoothing methods;trajectory;estimation;three dimensional displays	Curvature and torsion of discrete curves are important quantities in numerous applications in 3D image processing. Classical algorithms based on high order derivatives lead to high errors when computing torsion of 3D curves with discrete data of low resolution. To face this challenge we present a discrete parameter free approach to calculate the torsion values without fitting continuous curves on the discrete data. The proposed approach does not require prior knowledge and is of complexity O(nlog(n)). Preliminary results obtained with the proposed algorithm are compared to reference data (ground truth) of analytically known test curves. Results are also given for tomographic 3D images.	algorithm;discrete mathematics;ground truth;image processing;image resolution;torsion (gastropod)	Christoph Blankenburg;Christian Daul;Joachim Ohser	2016	2016 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2016.7532524	mathematical optimization;estimation;discrete mathematics;fundamental theorem of curves;computer science;trajectory;lattice;mathematics;geometry;family of curves;skeleton;statistics	Vision	62.82894647871027	-42.97203411523685	149169
73e4fc2e3eec22049e7c6c06e63cb32e8810150a	a quantitative perceptual model for tactile roughness		This paper proposes a model mapping texture geometry to tactile roughness. A set of fabricated stimuli is used to derive a perceptual space, which is matched with a quantitative model based on simulated skin strain variation.		Chelsea Tymms;Esther P. Gardner;Denis Zorin	2018	ACM Trans. Graph.		computer vision;perception;artificial intelligence;surface finish;computer science	Graphics	61.91286999143203	-45.721331993756564	149495
7e231e9cc4524745ff7179d27b6f9c33f0d6d43c	identification and matching of planes in a pair of uncalibrated images	plane identification;stereovision;region segmentation;dense matching	In this paper, we propose a new method to simultaneously achieve segmentation and dense matching in a pair of stereo images. In contrast to conventional methods that are based on similarity or correlation techniques, this method is based on geometry, and uses correlations only on a limited number of key points. Stemming from the observation that our environment is abundant in planes, this method focuses on segmentation and matching of planes in an observed scene. Neither prior knowledge about the scene nor camera calibration are needed. Using two uncalibrated images as inputs, the method starts with a rough identification of a potential plane, defined by three points only. Based on these three points, a plane homography is then calculated and, used for validation. Starting from a seed region defined by the original three points, the method grows the current region by successive move/confirmation steps until occlusions and/or surface discontinuity occur. In this case, the homography-based mapping of points between the two images will not be valid anymore. This condition is detected by the correlation, used in the confirmation process. In particular, this method grows a region even across different colors as long as the region is planar. Experiments on real images validated our method and showed its capability and performance.	algorithm;approximation;camera resectioning;color;epipolar geometry;experiment;homography (computer vision);image segmentation;matching (graph theory);mock object;nl (complexity);nl-complete;numerical aperture;overgrowth;planar (computer graphics);reflections of signals on conducting lines;ski combinator calculus;seeds (cellular automaton);stemming	Boubakeur Boufama;David J. O'Connell	2003	IJPRAI	10.1142/S0218001403002794	computer vision;computer science;stereopsis;geometry	Vision	54.91513153433436	-50.122676949535034	149515
27b50937e82eafdb0e5d067a08f7a848124ecaa1	adequate inner bound for geometric modeling with compact field functions	field functions;traitement du signal et de l image;composition operators;intelligence artificielle;blending;vision par ordinateur et reconnaissance de formes;implicit surfaces;traitement des images;details;synthese d image et realite virtuelle;geometric modeling;csg	Recent advances in implicit surface modeling now provide highly controllable blending effects. These effects rely on the field functions of R → R in which the implicit surfaces are defined. In these fields, there is an outside part in which blending is defined and an inside part. The implicit surface is the interface between these two parts. As recent operators often focus on blending, most efforts have been made on the outer part of field functions and little attention has been paid on the inner part. Yet, the inner fields are important as soon as difference and intersection operators are used. This makes its quality as crucial as the quality of the outside. In this paper, we analyze these shortcomings, and deduce new constraints on field functions such that differences and intersections can be seamlessly applied without introducing discontinuities or field distortions. In particular, we show how to adapt state of the art gradient-based union and blending operators to our new constraints. Our approach enables a precise control of the shape of both the inner or outer field boundaries. We also introduce a new set of asymmetric operators tailored for the modeling of fine details while preserving the integrity of the resulting fields.	alpha compositing;analytic signal;distortion;geometric modeling;gradient;implicit surface;interactive visualization;maximal set;precomputation;scott continuity;smoothing	Florian Canezin;Gaël Guennebaud;Loïc Barthe	2013	Computers & Graphics	10.1016/j.cag.2013.05.024	computer vision;computer science;artificial intelligence;geometric modeling;mathematics;geometry;algorithm;computer graphics (images)	Graphics	66.94836770247981	-44.52769568232997	149534
0a90c317792cc0750df876b1507236a4d07380b8	artistic vision: painterly rendering using computer vision techniques	painting;non photorealistic rendering;image segmentation;image processing;computer vision;image moments;medial axis	We present a method that takes a raster image as input and produces a painting-like image composed of strokes rather than pixels. Our method works by first segmenting the image into features, finding the approximate medial axes of these features, and using the medial axes to guide brush stroke creation. System parameters may be interactively manipulated by a user to effect image segmentation, brush stroke characteristics, stroke size, and stroke frequency. This process creates images reminiscent of those contemporary representational painters whose work has an abstract or sketchy quality. Our software is available at http://www.cs.utah.edu/npr/ArtisticVision.	approximation algorithm;computer vision;image segmentation;interactive media;medial graph;pixel;raster graphics	Bruce Gooch;Greg Coombe;Peter Shirley	2002		10.1145/508530.508545	visual arts;computer vision;feature detection;medial axis;image processing;painting;computer science;non-photorealistic rendering;multimedia;image segmentation;computer graphics (images)	Vision	65.16472598858205	-47.430803920469074	149814
f1e9a3168829c5dbfdcaf07313c303f236292e85	optical parameter extraction using differential evolution rendering in the loop	loop;rendering;differential evolution;illumination	"""Image synthesis is highly dependent on rendering algorithm and optical properties of scenario objects. The goal of this work is to develop a methodology to obtain some illumination parameters of a real scenario represented by an acquired image, and use these parameters for a virtual scenario rendering with the same objects as the original. The proposed methodology consists, first, in acquiring an image of the working scenario, and by using a DE (Differential Evolution) algorithm to render images that gradually approximate to the real acquired image, by some virtual scenario parameter modification based on the DE optimization. We call it """" ED Rendering in the loop """". Finally we use the obtained parameters to render an image to compare it with similar methods."""	approximation algorithm;bump mapping;color;differential evolution;experiment;global illumination;heuristic;mathematical optimization;preprocessor	Mauricio Olguín-Carbajal;Ricardo Barrón;José Luis Oropeza Rodríguez	2011	Polibits		computer vision;unbiased rendering;simulation;image-based modeling and rendering;3d rendering;rendering;computer science;real-time rendering;image-based lighting;computer graphics (images)	Vision	65.82636574921123	-50.82121361838548	149898
5a5d758cec4159b1eaa9df15152473dfb26f4360	surface geometric constraints for stereo in belief propagation	iterative algorithms;systematic error;belief propagation surface reconstruction stereo vision layout iterative algorithms image reconstruction context modeling geometry computer science inference mechanisms;geometry;contextual information;inference mechanisms;layout;surface reconstruction;belief propagation;image reconstruction;stereo vision;computer science;geometric constraints;context modeling	Belief propagation has been shown to be a powerful inference mechanism for stereo correspondence. However the classical formulation of belief propagation implicitly imposes the frontal parallel plane assumption in the compatibility matrix for exploiting contextual information, since the priors perfer no depth (disparity) change in surrounding neighborhoods. This results in systematic errors for slanted or curved surfaces. To eliminate these errors we propose to use contextual information geometrically, and show how to encode surface differential geometric properties in the compatibility matrix for stereo correspondence. This enforces consistency for both depth and surface normal, extending the traditional formulation beyond consistency for (constant) depth. With such geometric contextual information, the belief propagation algorithm shows dramatic improvement on generic non-frontal parallel scenes. Several such examples are provided.	algorithm;belief propagation;binocular disparity;encode;normal (geometry);software propagation	Gang Li;Steven W. Zucker	2006	2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)	10.1109/CVPR.2006.299	iterative reconstruction;layout;computer vision;surface reconstruction;computer science;stereopsis;theoretical computer science;machine learning;systematic error;mathematics;geometry;context model;statistics;belief propagation	Vision	54.149495347789546	-52.0720049570278	150353
18183ace6beab86bb0d9a505bfeb6ab7bb3b840b	simple divergence-free fields for artistic simulation	physics based modeling;computer graphic;incompressible flow;flow field;particle system;object model	We discuss tools for calculating divergence-free fields for artistic particle simulations. We introduce a simple, fast divergence-free noise function which can be used for turbulence. We also describe how the interpolation technique used by the noise function can be used for calculating artist-controlled divergence-free fields. The artist can create realistic unbounded flow fields without the complexity or memory cost of voxel-grid methods. CR Categories: I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling Physically based modeling.	3d modeling;computation;computational geometry;computer graphics;interpolation;simulation;turbulence;voxel	Mayur K. Patel;Noah Taylor	2005	J. Graphics Tools	10.1080/2151237X.2005.10129206	simulation;object model;computer science;theoretical computer science;particle system;programming language;incompressible flow;computer graphics (images)	Graphics	65.21895939733886	-50.7184939923082	150436
250e296b4b4c1b7ac0229e57d6638fe81188121e	collision detection: a survey	phase detection;performance evaluation;surgical simulation;detection algorithms;computer graphics;testing;testing object detection performance evaluation argon phase detection computational modeling detection algorithms facial animation computer graphics surgery;argon;computer graphic;computational modeling;collision detection;facial animation;surgery;object detection	A process of determining whether two or more bodies are making contact at one or more points is called collision detection or intersection detection. Collision detection is inseparable part of the computer graphics, surgical simulations, and robotics. There are varieties of methods for collision detection. We will review some of the most common ones. Algorithms for contact determination can be grouped into two general parts: broad-phase and narrow-phase. This paper provides a comprehensive classification of a collision detection literature into the two phases. Moreover, we have attempted to explain some of the existing algorithms which are not easy to interpret. Also, we have tried to keep sections self-explanatory without sacrificing depth of coverage.	algorithm;bounding volume hierarchy;collision detection;computer graphics;fully buffered dimm;polyhedron;robotics;sandy bridge;sensor;separable polynomial;simulation;space partitioning;terminate (software)	Sinan Kockara;Tansel Halic;Kamran Iqbal;Coskun Bayrak;Richard Rowe	2007	2007 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2007.4414258	phase detector;computer vision;simulation;object-class detection;computer facial animation;computer science;software testing;computer graphics;argon;computational model;collision detection;computer graphics (images)	Robotics	61.94942285380239	-40.84747572925221	150462
3fa30e5b1406603f8fbdc3954370e5044220fa69	estimation of 3d shape and reflectance using multiple moire images and shading model	shape from shading;moire technique;reflectance;expectation maximization;photometric stereo;em algorithm	We consider a method of determining the shape of object and the reflectance of its surface simultaneously using the Moiré technique and shape from shading. If the object surface has multiple reflectance, it must be classified to different reflectance. This classification is formulated as a simple clustering problem. By applying expectation-maximization(EM) algorithm, shape and reflectance can be estimated, and classification can be performed. However, as the relationship between the position of the light source and the gradient of the object surface gives rise to ambiguities in the reflectance, classification may fail. To solve this problem, we capture multiple Moiré images and propose a method of estimation using these images. The usefulness of the proposed method is confirmed by results obtained from simulation and real image experiments.	cluster analysis;expectation–maximization algorithm;experiment;gradient;list of common shading algorithms;photometric stereo;simulation	Shoichi Naganuma;Norio Tagawa;Akihiro Minagawa	2003		10.1145/952532.952717	computer vision;photometric stereo;expectation–maximization algorithm;computer science;machine learning	Vision	57.51337745279376	-51.99639949590904	150481
91bdb185e4732f2b8c10cd5b274731b52021a694	high-speed processing for obtaining three-dimensional distance image and its application	stereoscopic image;charge coupled image sensors;ccd camera;image recognition;mirrors;robots 3d distance image acquisition handicapped aids pattern recognition computer vision triangulation ccd camera laser emitting semiconductor scanning mirrors image recognition stereoscopic image range finders;real time processing;computerised pattern recognition;charge coupled devices;three dimensional;video cameras ccd image sensors computer vision computerised pattern recognition distance measurement;ccd image sensors;computer vision;distance measurement;handicapped aids;video cameras;displays;laser emitting semiconductor;robots;3d distance image acquisition;scanning mirrors;semiconductor lasers;pattern recognition;cross section;circuits;range finders;triangulation;charge coupled devices velocity measurement charge coupled image sensors semiconductor lasers mirrors circuits costs image recognition displays robots;velocity measurement;high speed	A high-speed method of 3-D distance acquisition based on the triangulation principle is presented. This method uses conventional devices such as a CCD camera, a laser emitting semiconductor, and scanning mirrors; however, new circuits have been developed for detecting the position of spot image on the CCD. This development enables the high speed measurement and reduces the cost of the apparatus. Experiments showed that the apparatus and the method gave the practical measuring accuracy and speed, and it was found that the system is useful for image recognition. This method can easily display the stereoscopic image and cross-sectional figure of the object body. The method of real time processing has also been developed with the view to apply the device to the range finders for robots and blind persons. >		Yutaka Tanaka;Hideki Tsukaoka;Hidetoshi Takeda;Kazuo Honda;Takaaki Sarai	1991		10.1109/IROS.1991.174477	robot;three-dimensional space;computer vision;electronic circuit;triangulation;computer science;cross section;optics;charge-coupled device;semiconductor laser theory;computer graphics (images)	Robotics	59.40766318134405	-40.96696082960022	150559
10fe51b7b8335e4de214e6390218cdc95d360e84	fusing laser point cloud and visual image at data level using a new reconstruction algorithm	laser point cloud fusion occlusion reasoning z buffer algorithm missing laser points laser scan trace false edge quadrangle mesh camera viewing volume camera coordinate system 3d laser points lidar data color image false depth assignment unmanned ground vehicle visual information camera reconstruction algorithm data level visual image;hidden feature removal;optical scanners;laser radar cameras image reconstruction three dimensional displays laser fusion visualization;mobile robots;remotely operated vehicles;optical radar;image colour analysis;image reconstruction;radar imaging;telerobotics;cameras;telerobotics cameras cloud computing hidden feature removal image colour analysis image reconstruction mobile robots optical radar optical scanners radar imaging remotely operated vehicles;cloud computing	Camera and LIDAR provide complementary information for robots to perceive the environment. In this paper, we present a system to fuse laser point cloud and visual information at the data level. Generally, cameras and LIDARs mounted on the unmanned ground vehicle have different viewports. Some objects which are visible to a LIDAR may become invisible to a camera. This will result in false depth assignment for the visual image and incorrect colorization for laser points. The inputs of the system are a color image and the corresponding LIDAR data. Coordinates of 3D laser points are first transformed into the camera coordinate system. Points outside the camera viewing volume are clipped. A new algorithm is proposed to recreate the underlying object surface of the potentially visible laser points as quadrangle mesh by exploiting the structure of the LIDAR as a priori. False edge is eliminated by constraining the angle between the laser scan trace and the radial direction of a given laser point, and quadrangles with non-consistent normal are pruned. In addition, the missing laser points are solved to avoid large holes in the reconstructed mesh. At last z-buffer algorithm is used to work for occlusion reasoning. Experimental results show that our algorithm outperforms the previous one. It can assign correct depth information to the visual image and provide the exact color to each laser point which is visible to the camera.	algorithm;color image;computation;geographic coordinate system;normal (geometry);point cloud;quadrangle (geography);radial (radio);robot;time complexity;triangle mesh;unmanned aerial vehicle;viewing frustum;viewport;z-buffering	Lipu Zhou	2013	2013 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2013.6629655	computer vision;geography;optics;remote sensing	Robotics	57.25606767615598	-50.568325958635995	150634
a18de03539a03dcebabd7e903df1e23bf4498d2f	seeing through the face: a morphological approach in physical anthropology	sufficient accuracy;physical anthropology;facial model;human face;different system;new interdiscipline;morphological approach;dimensional surface;new system;human facial morphology;software solution;dimensional model	For decades, morphological research on human faces was performed either on the living subject, or by means of 2D photographs. Within the last few years and with the development of new systems we are now able to produce three dimensional models of human faces. The methods and tools for data acquisition, processing, and analysis of 3D shape and form are part of a new interdiscipline: Virtual Anthropology. We are combining several approaches to study sexual dimorphism in human facial morphology and to compare the perfomance and accuracy of different systems producing 3D facial models. With the Breuckmann optoTop-He®, we have a scanning system that is capable of performing three dimensional surface scans of almost every surface in realtime. FaceGen Modeller® and PhotoModeler 2010® on the other hand are software solutions that allow us to produce 3D models of human faces based only on several 2D photographs. The aim of this study is to examine if software using 2D images, although much cheaper than a full scale scanning system, can create 3D models of sufficient accuracy for scientific and other purposes. The results are important for both anthropological and forensic applications.	3d modeling;biological anthropology;data acquisition;facegen;full scale;galaxy morphological classification;photomodeler	Tobias Paul;Fred L. Bookstein;Gerhard W. Weber	2012		10.1145/2491599.2491605	computer vision;geography;communication;computer graphics (images)	Graphics	58.202348732532904	-47.59711029226841	150668
5238905bce16fdff70795d8a4e113d49cde4f896	image space gathering	bilateral filtering;photon volumes;nvidia quadro fx 5800;paper;depth of field;global illumination;soft shadow;nvidia;algorithms;opengl;computer science;parallel architecture;distributed ray tracing;3d graphics and realism;photon mapping;cg	"""Soft shadows, glossy reflections and depth of field are valuable effects for realistic rendering and are often computed using distribution ray tracing (DRT). These """"blurry"""" effects often need not be accurate and are sometimes simulated by blurring an image with sharper effects, such as blurring hard shadows to simulate soft shadows. One of the most effective examples of such a blurring algorithm is percentage closer soft shadows (PCSS). That technique, however, does not naturally extend to shadows generated in image space, such as those computed by a ray tracer, nor does it extend to glossy reflections or depth of field. This limitation can be overcome by generalizing PCSS to be phrased in terms of a gather from image space textures implemented with cross bilateral filtering. This paper demonstrates a framework to create visually compelling and phenomenologically accurate approximations of DRT effects based on repeatedly gathering from bilaterally weighted image space texture samples. These gathering and filtering operations are well supported by modern parallel architectures, enabling this technique to run at interactive rates."""	algorithm;approximation;bilateral filter;distributed ray tracing;global illumination;ray tracing (graphics);reflection (computer graphics);simulation	Austin Robison;Peter Shirley	2009		10.1145/1572769.1572784	computer vision;simulation;computer science;computer graphics (images)	Graphics	66.26354772945096	-51.86722721683774	150930
5f79553b49c4ea763c6bbe22f8c39ea230b1a2a6	evaluación optimizada de arboles csg de sólidos triangulados de forma libre	boundary representations;categories and subject descriptors according to acm ccs i 3 3 computer graphics constructive solid geometry csg		constructive solid geometry	Carlos J. Ogáyar;Francisco R. Feito-Higueruela;Rafael Jesús Segura;Marilina Rivero	2008		10.2312/LocalChapterEvents/CEIG/CEIG08/237-240	computer science;engineering drawing;algorithm;computer graphics (images)	Crypto	64.29922464842625	-46.640269140342724	151247
9c240e69c4f504ed782f26b899a6c94e762ab30f	stylization of lighting effects for images	image morphing;lighting control;art;stylization;enhancement;lighting image color analysis pixel image edge detection art three dimensional displays visualization;image processing;visual contrast image lighting effect artistic style graphical art;image processing light shadow stylization enhancement;lighting control image enhancement image morphing;automatic generation;light;visualization;image enhancement;image edge detection;shadow;three dimensional displays;image color analysis;pixel;lighting	We propose a new model to stylize lighting effects in 2D images. Our stylizations are based on well-known artistic styles ranging from Chiaroscuro to comics. Lighting has always been used in graphical art to give realism to an illustration or to enhance visual contrasts between objects in a scene. This allows creating a global atmosphere. Giving an input image, our model automatically generates a lighting map of the image which may be modified by the user to determine different types of shadows or light effects like highlights. Following graphical arts styles, we propose six stylizations. Our model is flexible and specifically designed to help users and even amateur users, to semi-automatically stylize the different kinds of light effects in an image.	depth map;graphical user interface;semiconductor industry;specular highlight	Catherine Sauvaget;Vincent Boyer	2010	2010 Sixth International Conference on Signal-Image Technology and Internet Based Systems	10.1109/SITIS.2010.18	computer vision;shadow;visualization;image processing;computer science;lighting;light;pixel;image-based lighting;computer graphics (images)	HCI	64.24665928782092	-48.81221443626382	152108
9728206700029a184a44d1901a9b43362fc214b3	volumetric view planning for 3d reconstruction with multiple manipulators	manipulators;sensors;view planning;machine vision;3d reconstruction;industrial robot	Purpose – This paper aims to propose a new view planning method which can be used to calculate the next-best-view (NBV) for multiple manipulators simultaneously and build an automated three-dimensional (3D) object reconstruction system, which is based on the proposed method and can adapt to various industrial applications. Design/methodology/approach – The entire 3D space is encoded with octree, which marks the voxels with different tags. A set of candidate viewpoints is generated, filtered and evaluated. The viewpoint with the highest score is selected as the NBV. Findings – The proposed method is able to make the multiple manipulators, equipped with “eye-in-hand” RGB-D sensors, work together to accelerate the object reconstruction process. Originality/value – Compared to the existed approaches, the proposed method in this paper is fast, computationally efficient, has low memory cost and can be used in actual industrial productions where the multiple different manipulators exist. And, more notably, a new algorithm is designed to speed up the generation and filtration of the candidate viewpoints, which can guarantee both speed and quality.	3d reconstruction;algorithm;algorithmic efficiency;experiment;iteration;motion planning;octree;parallel computing;requirement;sensor;utility;voxel	Liangzhi Li;Nanfeng Xiao	2015	Industrial Robot	10.1108/IR-05-2015-0110	3d reconstruction;computer vision;simulation;machine vision;computer science;sensor;engineering drawing	Robotics	59.4181493526273	-39.91221650779533	152143
b7384620e1d2281744736db128e69783ac02cb5c	animating chinese landscape paintings and panorama using multi-perspective modeling	painting;texture images chinese landscape painting panorama multi perspective modeling fly through animations tip spidery mesh interface local model global model virtual camera rendering;local model;art;modeling technique;multi perspective modeling;panorama;tip spidery mesh interface;layout;animation painting layout cameras rendering computer graphics solid modeling shape buildings computer vision humans;chinese landscape painting;image texture;computer vision;texture images;shape;global model;fly through animations;solid modeling;animation;image texture computer animation art rendering computer graphics;humans;panoramic image;computer animation;rendering computer graphics;cameras;buildings;virtual camera;rendering	This paper describes a multi-perspecrive modeling technique for making fly-through animations from a single large landscape painting or panorama. These images have sub-scenes thai are taken from different perspective views. The technique constrricts a simple global model for the entire input image and bnilds a local model for each subscene using the TIP spidery mesh intel3pace. Animation is generated by switching smoothly between a local model and [he global model while moving a virtual camera along an animation path. Novel views are rendered by mapping the te.rrrire images, exiracied from ihe original image, onio the active model. The rtsefrtlness of the technique is demonstrated with two animation examples from a Chinese landscape painting and a spherical panoramic image.	smoothing;virtual camera system	Nelson Siu-Hang Chu;Chiew-Lan Tai	2001		10.1109/CGI.2001.934664	image texture;layout;computer vision;rendering;painting;shape;computer science;computer animation;multimedia;solid modeling;computer graphics (images)	Graphics	64.36941078833884	-48.54673631426315	152281
88bac7788f1ea9baa0168b657a3f82099f8ef5b9	automatic detection and decoding of photogrammetric coded targets	photogrammetry image coding;decoding computed tomography object detection industries cameras educational institutions three dimensional displays;decoding photogrammetry coded targets;automated coded target detection method automatic decoding photogrammetric coded targets close range photogrammetry	Close-range Photogrammetry is widely used in many industries because of the cost effectiveness and efficiency of the technique. In this research, we introduce an automated coded target detection method which can be used to enhance the efficiency of the Photogrammetry.	photogrammetry	Udaya Wijenayake;Sung-In Choi;Soon-Yong Park	2014	2014 International Conference on Electronics, Information and Communications (ICEIC)	10.1109/ELINFOCOM.2014.6914413	computer vision;photogrammetry;computer graphics (images)	Robotics	58.7806134900241	-43.73045834536819	152445
63054b3b0fbc57af6480a443335ff08e1b46392e	the conditions of convexity for bernstein-bézier surfaces over triangles	baricentro;convex surface;concepcion asistida;linear condition;surface convexe;computer aided design;curva bezier;modele geometrique;barycentre;convexite;convexity condition;regime lineaire;convexidad;b nets;barycentric coordinate;barycenter;sistema coordenadas;courbe bezier;bernstein polynomial;conception assistee;geometric model;regimen lineal;systeme coordonnee;convexity;polinomio bernstein;triangular bezier surface;polynome bernstein;superficie convexa;geometrical model;coordinate system;bezier curve;modelo geometrico	This paper derives a convexity condition for Bernstein-Bezier surfaces defined on triangles. The condition for triangular Bezier surfaces to be convex is a linear sufficient condition on the control points. This condition is stronger than that for B-nets to be weak convex, but weaker than known linear conditions. The inequalities in this condition are symmetric with respect to the three barycentric coordinates. Moreover, geometric interpretations are provided. Example shows that this method is feasible and effective in geometric modeling.	bézier curve;phil bernstein	Zhi Liu;Jieqing Tan;Xiaoyan Chen;Xiang Lin	2010	Computer Aided Geometric Design	10.1016/j.cagd.2010.05.004	center of mass;mathematical optimization;topology;computer aided design;mathematics;geometry	EDA	68.18859754077401	-39.97124463085173	152689
9dbbd36db5d9d0ddc4fd9a29aa885bef610b6267	surface design using cyclide patches	forma libre;dupin cyclide;algebraic degree;machining;computer aided design;condition initiale;modele geometrique;condition aux limites;boundary conditions;mando numerico;machine outil;free form;commande numerique;carreau surface;element fini quadrilateral;sintesis imagen;image synthesis;forme libre;usinage;geometric modelling;condicion inicial;deformation;degeneration;cyclide dupin;methode maille;mesh method;initial condition;quadrilateral finite element;conception assistee;synthese image;metodo malla;digital control;surface patch;machine tools;elemento finito cuadrilateral;geometrical model;modelo geometrico	Cyclide surfaces have low algebraic degree, exact NURBS representations and circular lines of curvature. Geometric modelling applications of the cyclide include blending of quadric surface intersections, piping layouts and cable harnesses. In this paper, we describe a scheme for smoothly composing a topologically rectangular network of cyclide patches. It is a two-step process. First, a cyclide quadrilateral mesh is constructed to approximate the target shape. Then, cyclide patches corresponding to the quadrilateral mesh are constructed. There is tangent plane continuity across the patch boundaries. Computations are based on the geometry of the cyclide and it is easy to detect degenerate cyclide patches, i.e. parabolic cyclide, cone, cylinder and sphere. We discuss issues related to global and local shape modification, and portability. Implemented examples are also included. Finally, we describe a simple strategy for NC machining of composite cyclide surfaces. Advantages are highlighted and implemented examples included.	alpha compositing;approximation algorithm;computation;computer-aided design;cylinder seal;linear algebra;non-uniform rational b-spline;parabolic antenna;scott continuity;smoothing;software portability	Y. L. Srinivas;Vinod Kumar;Debasish Dutta	1996	Computer-Aided Design	10.1016/0010-4485(95)00036-4	topology;digital control;machining;boundary value problem;engineering;machine tool;computer aided design;mathematics;geometry;engineering drawing;initial value problem;deformation;mechanical engineering	Graphics	68.00718914141291	-39.88831525654119	152715
7550cd88364905f9b3bb4090d24b41c4ea07f705	a novel approach of 3d face reconstruction using ellipse fitting	detection algorithm;face modeling;cross section;ellipse fitting	The problem of reconstructing the 3D face using one image captured from a viewpoint arises in many fields of science and engineering, this paper propose the novel approach for reconstructing the 3D face by using ellipse fitting technique from only one 2.5D image. The 2.5D face image is captured from any viewpoint between -45 degree and +45 degree. The cross section across the head is fitted by ellipse, and then the semimajor axis vectors are corrected to the nose tip and ridge by the nose ridge detection algorithm, the nose tip and ridge are localized. The mirror of real face is computed from the symmetry plane passing the nose ridge, the nose tip and the point on the center line of face. Finally, 3D face is reconstructed using the real face and its mirror face. This proposed method has the advantages: 1) the only one 2.5D image from a viewpoint between -45 degree and +45 degree is used; 2) the generic face model is not required in the system. The 135 3D virtual face samples were reconstructed in the experiment. The results show the feasibility of the proposed method.	2.5d;algorithm;cross section (geometry);curve fitting;degree (graph theory);optic axis of a crystal;ridge detection	Charoenpong Theekapun;Hiroyuki Hase;Shogo Tokai	2007			computer vision;mathematics;cross section;geometry;computer graphics (images)	Vision	55.38139432282003	-50.46519038801228	152733
d22cd84fa622da73295a1e5d63f9777b252506f2	curved-solid-object input-system using conformal projection method	interfase usuario;vision ordenador;interpolation;user interface;computer graphics;interpolacion;espacio 3 dimensiones;projection method;intelligence artificielle;superficie curva;computer vision;curved surface;espace 3 dimensions;three dimensional space;artificial intelligence;surface courbe;interface utilisateur;vision ordinateur;inteligencia artificial;grafico computadora;infographie	Abstract#R##N##R##N#One of the important themes in computer graphics is the method of designing an easy data-input system of 3D objects. The authors proposed, in a previous paper, a polyhedron input system using a projection plane based on a conformal projection method. This paper proposes a new input algorithm for a curved object using the projection plane. Some examples are included.		Masayuki Nakajima;Takeshi Agui;Chiharu Hanyuda	1988	Systems and Computers in Japan	10.1002/scj.4690191010	computer vision;oblique projection;projection plane;projection;interpolation;computer science;artificial intelligence;dykstra's projection algorithm;parallel projection;3d projection;image plane;orthographic projection;planar projection;graphical projection;statistics;projection;computer graphics (images)	NLP	65.30591525969858	-40.97978943384846	152797
81d632cc9f3d249aea12ab86c4bc7da5062fc165	motion estimation from map quality with millimeter wave radar	range data;mobile robot;path planning;motion estimation;mobile robots;spatial distribution;scan matching;simultaneous localization and mapping;radar applications;77 ghz motion estimation map quality millimeter wave radar simultaneous localization and mapping mobile robot point cloud maps range bearing measurements scan matching techniques vehicle motion;millimeter wave radar motion estimation millimeter wave technology simultaneous localization and mapping intelligent robots mobile robots millimeter wave measurements rendering computer graphics marine vehicles laser radar;point cloud;millimeter wave;slam robots millimetre wave devices mobile robots motion estimation path planning radar applications;millimetre wave devices;slam robots	"""Simultaneous localization and mapping (SLAM) builds maps of a priori unknown environments. Whilst this key mobile robotic competency continues to receive substantial attention, less attention has been paid to assessing the quality of the resulting maps. This paper proposes a way to quantify the intrinsic quality of point-cloud maps built from a stream of range bearing measurements. It does so by considering both the temporal and spatial distribution of the points within the map. One of the causes of unsatisfactory maps is the execution of unmodelled or poorly sensed vehicle manoeuvres. In this paper we show that by maximizing the quality of the map as a function of a motion parameterization, the vehicle motion can be recovered while correcting the map at the same time. In contrast to typical scan matching techniques, we do not rely on segmentation of the measurement stream into two separate """"scans""""; Instead we treat the measurement sequence as a continuous signal. We illustrate the efficacy of this approach by processing range data from a 77 GHz millimeter wave radar that completes 2 rotations per second. We show that despite this acquisition speed being commensurate with vehicle rotation rates, we are able to extract the underlying vehicle motion and yield crisp, well aligned point clouds"""	continuous signal;map;motion estimation;point cloud;radar;robot;simultaneous localization and mapping;while	Manjari Chandran;Paul Newman	2006	2006 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2006.281673	mobile robot;computer vision;simulation;computer science;artificial intelligence;remote sensing	Robotics	55.055194983613745	-40.555827038510266	152812
a262a61785edf49b25ec7305dd8a3556a6e8480c	interactive hdr lighting of dynamic participating media	environment maps;model selection;time varying;participating media;optimization technique;volume density objects;real time;gpu;lighting;high dynamic range	In this paper, we present two optimization techniques to light and render volumetric data of inhomogeneous participating media. Both are independent of the lighting model selected. We use an implementation of the ray marching algorithm to approximate the Radiance Transfer Equation. The system can calculate single scattering in time-varying isotropic participating media with the incident field being modeled as a high dynamic range (HDR) environment map. We can use dynamic lighting (with certain restrictions) and free camera movement without using any precomputations while achieving interactive frame rates.	approximation algorithm;computer graphics lighting;data compression;distance transform;graphics processing unit;high dynamic range;high-dynamic-range imaging;high-dynamic-range rendering;institute for creative technologies;interaction;light field;local interconnect network;map;mathematical optimization;overhead (computing);paul debevec;precomputation;real-time clock;reflection mapping;self-shadowing;shading;volume ray casting	Fernando Navarro;Diego Gutierrez;Francisco J. Serón	2008	The Visual Computer	10.1007/s00371-008-0299-8	simulation;computer science;lighting;mathematics;multimedia;model selection;statistics;computer graphics (images)	Visualization	64.93263837084046	-51.61601151939758	153028
42f32d63d6d9b426a981042c72ddec0c6595685a	an algorithm for rendering vertexes and edges of polyhedron with high order geometric continuity	curva bezier;polyedre;geometrie algorithmique;computer graphics;poliedro;computational geometry;surface rendering;polyhedron;surface lisse;higher order;computer graphic;smooth surface;surface plane;courbe bezier;geometric algorithm;geometria computacional;superficie lisa;plane surface;grafico computadora;infographie;superficie plana;bezier curve	The surface rendering for simultaneously connecting with several neighboring surfaces with high order geometric continuous is quite complicated in the computer graphics and CAGD. This paper proposed a new simple geometric algorithm for generating and rendering the smooth connecting surfaces for the vertexes and edges of the polyhedron. The rectangular Bezier surfaces are generated to connect the two adjacent planes, and the triangular Bezier surfaces are generated to connect its several neighboring surfaces with high order geometric continuity. The control net points of the connecting surfaces are calculated by the geometric drawing method according to the geometric continuity connection condition or the share common plane condition. All the surfaces and planes can be connected smoothly with G2 geometry continuity in the polyhedron. The algorithm can be popularized to the situation of higher order geometric continuous connection easily.	algorithm;polyhedron;scott continuity	Xiaolin Lu	2006		10.1007/11751540_21	combinatorics;higher-order logic;topology;geometric transformation;computational geometry;computer science;bézier curve;mathematics;geometry;computer graphics;polyhedron	Graphics	68.21739963188313	-41.51242435006918	153048
c201320ece333c5d3d06705f530c20e61e371431	on the structure of nonlinearities in pose graph slam	conference proceeding	Pose graphs have become an attractive representation for solving Simultaneous Localization and Mapping (SLAM) problems. In this paper, we analyze the structure of the nonlinearities in the 2D SLAM problem formulated as the optimizing of a pose graph. First, we prove that finding the optimal configuration of a very basic pose graph with 3 nodes (poses) and 3 edges (relative pose constraints) with spherical covariance matrices, which can be formulated as a six dimensional least squares optimization problem, is equivalent to solving a one dimensional optimization problem. Then we show that the same result can be extended to the optimizing of a pose graph with “two anchor nodes” where every edge is connecting to one of the two anchor nodes. Furthermore, we prove that the global minimum of the resulting one dimensional optimization problem must belong to a certain interval and there are at most 3 minima in that interval. Thus the globally optimal pose configuration of the pose graph can be obtained very easily through the bisection method and closed-form formulas.	bisection method;least squares;mathematical optimization;maxima and minima;optimization problem;simultaneous localization and mapping	Heng Wang;Gibson Hu;Shoudong Huang;Gamini Dissanayake	2012		10.15607/RSS.2012.VIII.054	combinatorics;discrete mathematics;topology;computer science	Robotics	56.91319298580328	-40.90738420164039	153067
3d453c190217fbf8811edca41f549cb189b7f05d	towards automatic band-limited procedural shaders	and texture;color;i 3 7 computer graphics three dimensional graphics and realism color shading shadowing and texture;i 3 7 computer graphics;shadowing;three dimensional graphics and realism;i 3 7 computer graphics three dimensional graphics and realism color;shading;categories and subject descriptors according to acm ccs	Procedural shaders are a vital part of modern rendering systems. Despite their prevalence, however, procedural shaders remain sensitive to aliasing any time they are sampled at a rate below the Nyquist limit. Antialiasing is typically achieved through numerical techniques like supersampling or precomputing integrals stored in mipmaps. This paper explores the problem of analytically computing a band-limited version of a procedural shader as a continuous function of the sampling rate. There is currently no known way of analytically computing these integrals in general. We explore the conditions under which exact solutions are possible and develop several approximation strategies for when they are not. Compared to supersampling methods, our approach produces shaders that are less expensive to evaluate and closer to ground truth in many cases. Compared to mipmapping or precomputation, our approach produces shaders that support an arbitrary bandwidth parameter and require less storage. We evaluate our method on a range of spatially-varying shader functions, automatically producing antialiased versions that have comparable error to 4×4 multisampling but can be over an order of magnitude faster. While not complete, our approach is a promising first step toward this challenging goal and indicates a number of interesting directions for future work.	shader	Jonathan Dorn;Connelly Barnes;Jason Lawrence;Westley Weimer	2015	Comput. Graph. Forum	10.1111/cgf.12747	computer vision;shading;simulation;shader;computer science;artificial intelligence;mathematics;geometry;volume rendering;render target;algorithm;statistics;computer graphics (images)	NLP	65.38652840684097	-51.67226582733427	153199
6a64c1f54ca3989f67e4e441b95c17b9387b1807	improvements to surface reconstruction by the crust algorithm	surface reconstruction;scattered data;computer graphic;computer vision;manifold extraction;solid modeling;voronoi diagram	There is a wide range of applications, such as solid modeling, computer graphics or computer vision, for which surface reconstruction of scattered data points in space is important. Many algorithms were developed in the past depending on the field of application and related properties of the data. This paper presents some improvements to the already existing one-pass CRUST algorithm build on Delaunay tetrahedronization and Voronoi diagrams.	algorithm;computer graphics;computer vision;data point;delaunay triangulation;solid modeling;voronoi diagram	Michal Varnuska;Ivana Kolingerová	2003		10.1145/984952.984968	3d reconstruction;computer vision;simulation;surface reconstruction;voronoi diagram;computer science;mathematics;geometry;solid modeling;computer graphics (images)	Visualization	64.18823707914558	-44.24400975805469	153297
1c48bb1952241ea455426b1b47ab920e2a92f8d8	tour into the picture using a vanishing line and its extension to panoramic images	image based modeling rendering;tour into the picture;projective geometry;image based modeling;vanishing line;vanishing point;panoramic image	Tour into the picture (TIP) proposed by Horry et al.13 is a method for generating a sequence of walk-through images from a single reference picture (or image). By navigating a 3D scene model constructed from the picture, TIP produces convincing 3D effects. Assuming that the picture has one vanishing point, they proposed the scene modeling scheme called spidery mesh. However, this scheme has to go through major modification when the picture contains multiple vanishing points or does not have any well-defined vanishing point. Moreover, the spidery mesh is hard to generalize for other types of images such as panoramic images. In this paper, we propose a new scheme for TIP which is based on a single vanishing line instead of a vanishing point. Based on projective geometry, our scheme is simple and yet general enough to address the problems faced with the previous method. We also show that our scheme can be naturally extended to a panoramic image.	3d modeling;interactivity;line level;quicktime;streaming media;vrr;vanishing point	Hyung Woo Kang;Soon Hyung Pyo;Ken-ichi Anjyo;Sung Yong Shin	2001	Comput. Graph. Forum	10.1111/1467-8659.00506	computer vision;projective geometry;topology;vanishing point;mathematics;geometry	Vision	63.56946472512864	-48.414659876199295	153327
8939f888e724e2aca8338d64192bc265dc324245	efficient feature-based image registration by mapping sparsified surfaces		With the advancement in the digital camera technology, the use of high resolution images and videos has been widespread in the modern society. In particular, image and video frame registration is frequently applied in computer graphics and film production. However, conventional registration approaches usually require long computational time for high resolution images and video frames. This hinders the application of the registration approaches in the modern industries. In this work, we first propose a new image representation method to accelerate the registration process by triangulating the images effectively. For each high resolution image or video frame, we compute an optimal coarse triangulation which captures the important features of the image. Then, we apply a surface registration algorithm to obtain a registration map which is used to compute the registration of the high resolution image. Experimental results suggest that our overall algorithm is efficient and capable to achieve a high compression rate while the accuracy of the registration is well retained when compared with the conventional grid-based approach. Also, the computational time of the registration is significantly reduced using our triangulation-based approach.	algorithm;algorithmic efficiency;computer graphics;digital camera;frame grabber;image registration;image resolution;iterative closest point;polygon triangulation;time complexity;triangulation (geometry)	Chun Pang Yung;Gary P. T. Choi;Ke Chen;Lok Ming Lui	2018	J. Visual Communication and Image Representation	10.1016/j.jvcir.2018.07.005	digital camera;mathematics;computer vision;grid;artificial intelligence;triangulation (social science);computer graphics;data compression ratio;image registration	Vision	54.26594362214031	-47.14322699264008	153370
cd158d5b0dd72f9d2973b9b840dfca5aab700ae9	automatic assembly feature recognition and disassembly sequence generation	engineering design;tree data structure;algorithms;feature recognition	Abstract: This thesis is concerned not with geometric features on a single component but rather withthose that arise from the spatial adjacency of two, or more, components in an assembly.From a review of the literature on the nature and use of assembly features, it is concludedthat the majority of assembly features involve sets of spatially adjacent faces. Threeprinciple types of adjacency relationships proposed in CHAPTER 3.1 are identified and analgorithm is presented for identifying assembly...	disassembler;feature recognition	Raymond Chun Wai Sung	2001	J. Comput. Inf. Sci. Eng.		feature recognition;computer vision;computer science;engineering;machine learning;tree;engineering drawing;engineering design process;mechanical engineering	AI	64.47334194970254	-42.63133560715097	153383
67d60c7196323ee64e9c4be9dbcf8a7b2b957bcd	a surround view image generation method with low distortion for vehicle camera systems using a composite projection		This paper proposes a surround view image generation method for vehicle camera systems. To assist the driver during parking, a view with easy comprehension of distance and direction between the vehicle and objects is desirable. However, the conventional method of using an equidistant projection for generating a surround image of wide field of view causes image distortion, with straight lines appearing curved. This prevents the driver from correctly understanding the distance and direction of objects. Our proposed method uses a composite projection that combines two projection models: perspective projection and equidistant projection. This strategy can generate an image without distortion by using perspective projection near the vehicle and provides a wide field of view using equidistant projection. The experiments demonstrate the generation from parking scene images, using our proposed method, of a surround image with a wide field of view and no distortion near the vehicle.	3d projection;distortion;experiment;glossary of computer graphics	Kunio Nobori;Norimichi Ukita;Norihiro Hagita	2017	2017 Fifteenth IAPR International Conference on Machine Vision Applications (MVA)	10.23919/MVA.2017.7986882	artificial intelligence;computer vision;mathematics;azimuthal equidistant projection;3d projection;planar projection;graphical projection;projection plane;oblique projection;parallel projection;orthographic projection	Vision	57.55906881152976	-50.46847093088749	153407
653478bba3b003b7615c7532c5a144190810b5fd	curvature and torsion estimators based on parametric curve fitting	convergence analysis;geometry compression and predictors;estimation method;weighted least square;differential geometry;computer vision;least squares;geometry compression;geometry processing;parametric curve;curvature estimation	Many applications of geometry processing and computer vision rely on geometric properties of curves, particularly their curvature. Several methods have already been proposed to estimate the curvature of a planar curve, most of them for curves in digital spaces. This work proposes a new scheme for estimating curvature and torsion of planar and spatial curves, based on weighted least–squares fitting and local arc–length approximation. The method is simple enough to admit a convergence analysis that take into acount the effect of noise in the samples. The implementation of the method is compared to other curvature estimation methods showing a good performance. Applications to prediction in geometry compression are presented both as a practical application and as a validation of this new scheme.	approximation;computer vision;curve fitting;geometry processing;least squares;torsion (gastropod)	Thomas Lewiner;João D. Gomes;Hélio Lopes;Marcos Craizer	2005	Computers & Graphics	10.1016/j.cag.2005.08.004	total curvature;gaussian curvature;differential geometry;computer vision;mathematical optimization;topology;fundamental theorem of curves;parametric equation;asymptotic curve;differential geometry of curves;mathematics;geometry;torsion of a curve;curvature;least squares	Vision	62.70884137521801	-42.84899433993975	153468
b58fc309ecd710e6b35779cc94f8a40ac222aabd	inverse light design for high-occlusion environments		Lighting design is a demanding but very important task in computer cinematography, games and architectural design. Computer-assisted lighting design aims at providing the designers with tools to describe the desired outcome and derive a suitable lighting configuration to match their goal. In this paper, we present an automatic approach to the inverse light source emittance and positioning problem, based on a layered linear / non-linear optimization strategy and the introduction of a special light source indexing according to the compatibility of each individual luminary position with the desired illumination. Our approach is independent of a particular light transport model and can quickly converge to an appropriate and plausible light configuration that approximates the desired illumination and can handle environments with high occlusion.	converge;illumination (image);light transport theory;linear programming;mathematical optimization;nonlinear programming;nonlinear system;position and momentum space;user interface	Anastasios Gkaravelis;Georgios Papaioannou;Konstantinos Kalampokis	2015		10.5220/0005291400260034	computer science;computer graphics (images);computer vision;artificial intelligence;occlusion;architectural lighting design	EDA	58.787925901986235	-46.68797425093196	153595
9889926617501596f65391c1219c16df58bc5331	reflectance function estimation and shape recovery from image sequence of a rotating object	iterative method;3d singular surface point location;matte surfaces;shading information;reflectance function estimation;collinear light source;iterative methods image sequences brightness reflectivity series mathematics rotation;reflectivity;rotating object;computational intelligence;brightness values;real image sequences;shape recovery;reflectivity shape image sequences brightness light sources photometry calibration optical variables control laboratories computational intelligence;surfacedepth;real image sequences reflectance function estimation shape recovery image sequence rotating object surface recovery collinear light source 3d singular surface point location brightness values shading information first order taylor series approximation iterative method surfacedepth surface orientation specular surfaces matte surfaces;surface recovery;iterative methods;brightness;first order;shape;photometry;series mathematics;image sequence;specular surfaces;first order taylor series approximation;rotation;calibration;surface orientation;light sources;optical variables control;image sequences;taylor series	In this paper we describe a technique for surface recovery of a rotating object illuminated under a collinear light source (where the light source lies on or near the optical axis). We show that the surface reeectance function can be directly estimated from the image sequence without any assumption on the reeectance property of the object surface. From the image sequence, the 3D locations of some singular surface points are calculated and their brightness values are extracted for the estimation of the reeectance function. We also show that the surface can be recovered by using shading information in two images of the rotating object. Iteratively using the rst-order Taylor serious approximation and the estimated reeectance function, the depth and orientation of the surface can be recovered simultaneously. The experimental results on real image sequences of both matte and specular surfaces demonstrate that the technique is feasible and robust.	approximation;matte display;optic axis of a crystal;shading	Jiping Lu;James J. Little	1995		10.1109/ICCV.1995.466803	computer vision;photometric stereo;computational intelligence;mathematics;geometry;iterative method	Vision	54.816891219295435	-51.18034873903476	153654
edcf59aaaff759c1b2907faaa47f0665bc0a3373	texture mapping subdivision surfaces with hard constraints	subdivision surfaces;texture mapping;parameterization;deformation	We propose a texture mapping technique that allows user to directly manipulate texture coordinates of subdivision surfaces through adding feature correspondences. After features, or constraints, are specified by user on the subdivision surface, the constraints are projected back to the control mesh and a polygon matching/embedding algorithm is performed to generate polygon regions that embed texture coordinates of control mesh into different regions. After this step, some Steiner points are added to the control mesh. The generated texture coordinates exactly satisfy the input constraints but with high distortions. Then a constrained smoothing algorithm is performed to minimize distortions of the subdivision surface via updating texture coordinates of the control mesh. Finally, an Iterative Closest Point (ICP)-based deformation algorithm is performed to remove subdivision errors caused by the added Steiner points.	algorithm;computation;distortion;ibm notes;interactivity;iterative closest point;iterative method;map;robustness (computer science);seamless3d;smoothing;steiner tree problem;subdivision surface;texture mapping	Yanlin Weng;Dongping Li;Yiying Tong	2013	The Visual Computer	10.1007/s00371-013-0794-4	parametrization;texture mapping;computer vision;mathematical optimization;displacement mapping;computer science;mathematics;geometry;subdivision surface;texture filtering;deformation;projective texture mapping	Graphics	68.08000384901335	-44.3687785167555	153836
28bfa026b0ff5e523f65e5876d34f582a3bed76f	finite-resolution computational geometry	computers;windings;topology;standards;rubber;application software;computer graphics;finite resolution;geometry;computational geometry;computer graphic;visualization;petroleum;computational modeling;solid modeling;computational geometry computer graphics topology algorithm design and analysis concrete solid modeling application software;algorithms;geometric algorithm;terminology;reviews;power system stability;titanium;algorithm design and analysis;concrete;continued fraction	Geometric algorithms are usually designed with continuous parameters in mind. When the underlying geometric space is intrinsically discrete, as is the case for computer graphics problems, such algorithms are apt to give invalid solutions if properties of a finite-resolution space are not taken into account. In this paper we discuss an approach for transforming geometric concepts and algorithms from the continuous domain to the discrete domain. As an example we consider the discrete version of the problem of finding all intersections of a collection of line segments. We formulate criteria for a satisfactory solution to this problem, and design an interface between the continuous domain and the discrete domain which supports certain invariants. This interface enables us to obtain a satisfactory solution by using plane-sweep and a variant of the continued fraction algorithm.	computational geometry;computer graphics;invariant (computer science);mind;sweep line algorithm	Daniel H. Greene;F. Frances Yao	1986	27th Annual Symposium on Foundations of Computer Science (sfcs 1986)	10.1109/SFCS.1986.19	natural rubber;titanium;continued fraction;algorithm design;combinatorics;application software;visualization;concrete;computational geometry;computer science;theoretical computer science;mathematics;solid modeling;electromagnetic coil;computer graphics;terminology;computational model;petroleum;algorithm;algebra	Theory	63.113709195740746	-41.06827961852028	153866
34007610fe4553ad4d5e4c79067b901063d765c0	interactive reconstruction of industrial sites using parametric models	parametric model;image segmentation;3d model;multi view reconstruction;interaction model;model fitting;interactive segmentation	We present a new interactive modeling technique for reconstructing 3D objects from multiple images. We specifically address the problems that arise in industrial environments during camera orientation, image segmentation and modeling. An accurate camera orientation is ensured by using coded markers and surveyed points from a total station. Interactive segmentations of edges and regions in the images are used as input for fitting parametric models to the scene. We provide an intuitive interface which allows modeling artificial objects without having extensive knowledge about 3D modeling or photogrammetry.	3d modeling;image segmentation;interactivity;photogrammetry	Irene Reisner-Kollmann;Anton L. Fuhrmann;Werner Purgathofer	2010		10.1145/1925059.1925079	computer vision;simulation;parametric model;computer science;mathematics;image segmentation;statistics;computer graphics (images)	Vision	57.947728955644074	-47.79767333164476	153978
6539e4b0c560eeaa9c284bd2289fd44f40456d38	erep: an editable, high-level representation for geometric design and analysis	high-level representation;geometric design	We propose a high-level, generative, textual representation for featurebased solid modeling, which we call Erep. We argue that such a representation should be independent of an underlying core solid modeler, and give some criteria it should satisfy. Such an Erep allows archiving geometric designs in a form that is both editable and translatable to any solid modeling system. Furthermore, the representation serves as a global schema by which to federate different modeling systems, and is extensible in a natural way to a representation from which to derive analysis representations and process plans. By federating with finite-element analysis packages, in particular, our approach offers closing the design-analysis feedback loop that previously required a manual link. 'Supported in part by ONR Contract N00014-90-J-1599, NSF Grant CCR 86-19817, and NSF Grant ECD 88-03017. t While on leave in the Department of Computer Sciences, Purdue University. Partially supported by a NATO Scientific Programme fellowship and by a fellowship of the Spanish Ministerio de Ed ucaci6n y Ciencia	archive;closing (morphology);computer science;explanatory combinatorial dictionary;federated identity;feedback;finite element method;geometric design;high- and low-level;ibm notes;solid modeling	Christoph M. Hoffmann;Robert Juan	1992			programming language;textual representation;generative grammar;schema (psychology);solid modeling;geometric design;computer science;feedback loop	Graphics	63.91433266696069	-41.517208776321446	153995
48e24b3017b491cd3ca25219a3b398b25c5df6f9	inbetweening for computer animation utilizing moving point constraints	computer graphics;evaluation criteria;merging;transformation;computer animation	This paper presents an approach to computerized inbetweening which allows the animator more control over an interpolation sequence than existing keyframe techniques. In our approach, the animator specifies in addition to a set of keyframe constraints, a set of new constraints called moving points. Moving points are curves in space and time which constrain both the trajectory and dynamics of certain points on the keyframes. The sets of keyframes and moving points form a constraint or patch network specification of the desired dynamics. Several algorithms are presented for inbetweening or completing such a patch network. By measuring these algorithms with respect to a set of evaluation criteria, the algorithm which best meets our interpolation needs is selected.	algorithm;computer animation;inbetweening;interpolation;key frame;patch (computing)	William T. Reeves	1981		10.1145/800224.806814	transformation;interpolation;computer vision;simulation;computer science;geometry;computer animation;computer graphics;computer graphics (images)	Graphics	65.6590610039099	-46.08747292029472	154043
d81cf85102335dac5ac87241f032018018530152	seeing behind the scene: analysis of photometric properties of occluding edges by the reversed projection blurring model	observability;focusing;layout photometry cameras solid modeling geometrical optics brightness focusing image analysis lenses information technology;observability photometric properties occluding edges reversed projection blurring model surface edges occluding edge surface edge brightness blurring model real world environments;blurring model;optical transfer function;surface edges;occluding edge;information technology;layout;optical transfer function computer vision;photometric properties;computer vision;brightness;surface edge;photometry;solid modeling;lenses;real world environments;occluding edges;image analysis;reversed projection blurring model;cameras;scene analysis;geometrical optics	This paper analyzes photometric properties of occluding edges and proves that (1) we can observe surface edges on the farther object located close to the occluding edge even if they are occluded by the nearer object, (2) the image of an occluding edge coincides with that of a surface edge on the nearer object if the brightness of the farther object is uniform around the occluding edge. First, we propose a blurring model named the reversed projection blurring model to analyze photometric properties of blurring phenomena of an occluding edge. Using this model, the theoretical proof of the two properties mentioned above is given. Finally, experimental results in real world environments demonstrate the validity of our blurring model as well as the observability of the photometric properties of occluding edges. >		Naoki Asada;Hisanaga Fujiwara;Takashi Matsuyama	1995		10.1109/ICCV.1995.466793	layout;geometrical optics;computer vision;image analysis;observability;photometry;computer science;optical transfer function;lens;mathematics;solid modeling;information technology;brightness;computer graphics (images)	Vision	56.1783271068882	-51.9545522228944	154062
889588c91489995cc8df0b0e90860cf5c9b128a4	a spline approximation of a large set of points.	approximation method;spline function;least square;spline interpolation	This paper presents a spline approximation method for the representation of a large set of points. The representation should be smooth with preserving important shape characteristics given by the points. Because of a large size of the set, the standard spline interpolation cannot be used. The proposed method is based on a least squares minimization of the distances of the points from the spline function subject to the conditions of smoothness of the representation. The spline approximation produces accurate and suitable representation of the points. The proposed approach has been veriied on both synthetic and real data sets of points.	approximation;least squares;shape context;spline (mathematics);spline interpolation;synthetic data	Radim Halír;Jana Kostková	2000			spline interpolation;b-spline;spline;mathematical optimization;perfect spline;smoothing spline;monotone cubic interpolation;interpolation;computer science;cubic hermite spline;hermite spline;geometry;thin plate spline;polyharmonic spline;least squares;m-spline;statistics	Vision	62.87419693923021	-42.92899821933912	154089
978a27d5ba11daa06c7288b6e71a7ecff4a57cb2	reconstruction of sculpture from uncalibrated image profiles	computers;conference_paper;computer graphics;computational geometry;motion estimation;solid modelling motion estimation image reconstruction computational geometry octrees image sequences;camera motion;image reconstruction cameras motion estimation surface reconstruction shape solid modeling information geometry data mining equations;image reconstruction;octree carving sculpture reconstruction uncalibrated image profiles sculpture profiles model reconstruction epipolar tangents motion estimation circular motion image sequence;octrees;solid modelling;image sequences	Profiles of a sculpture provide rich information about its geometry, and can be used for model reconstruction under known camera motion. By exploiting correspondences induced by epipolar tangents on the profiles, a successful solution to motion estimation has been developed for the case of circular motion. Arbitrary general views can then be incorporated to refine the model built from circular motion.	epipolar geometry;motion estimation	Kwan-Yee Kenneth Wong;Roberto Cipolla	2001		10.1109/ICIP.2001.959080	iterative reconstruction;computer vision;computational geometry;computer science;motion estimation;mathematics;geometry;motion field;computer graphics;computer graphics (images)	Vision	53.83509335629672	-51.06519544259212	154220
e633c6e8e5736bb007563fba4146779801cfcd23	evolution of vertex and pixel shaders	genetique;rendu image;representation graphique;ombre;restitucion imagen;genetica;polygone;customization;personnalisation;langage evolue;algoritmo genetico;genetics;polygon;sombra;graphics hardware;shadow;genome;image rendering;personalizacion;algorithme genetique;grafo curva;poligono;genetic algorithm;lenguaje evolucionado;genoma;user interaction;high level language;graphics;real time rendering	In real-time rendering, objects are represented using polygons or triangles. Triangles are easy to render and graphics hardware is highly optimized for rendering of triangles. Initially, the shading computations were carried out by dedicated hardwired algorithms for each vertex and then interpolated by the rasterizer. Todays graphics hardware contains vertex and pixel shaders which can be reprogrammed by the user. Vertex and pixel shaders allow almost arbitrary computations per vertex respectively per pixel. We have developed a system to evolve such programs. The system runs on a variety of graphics hardware due to the use of NVIDIA’s high level Cg shader language. Fitness of the shaders is determined by user interaction. Both fixed length and variable length genomes are supported. The system is highly customizable. Each individual consists of a series of meta commands. The resulting Cg program is translated into the low level commands which are required for the particular graphics hardware.	algorithm;computation;graphics hardware;high-level programming language;interpolation;pixel;polygon (computer graphics);rasterisation;real-time locating system;shader;shading language	Marc Ebner;Markus Reinhardt;Jürgen Albert	2005		10.1007/978-3-540-31989-4_23	multiple render targets;simulation;shader;computer science;artificial intelligence;operating system;polygon;real-time rendering;volume rendering;genetics;render target;vertex;algorithm;software rendering;computer graphics (images)	Graphics	65.63100147571605	-48.95818875378355	154426
8905f8ae1780f803f0d5399dd28190416dba2c04	a method for determining movements of a deformable body from spatial coordinates of markers		Abstract#R##N##R##N#In this article, we present a numerical method to compute the relative displacement of a body that deforms during movement. It is assumed that a group of markers is attached to the body's surface, and that their spatial positions are obtained by an optical measurement system. The measured coordinates of markers are perturbed by measurement inaccuracies and by the deformation of the body. The mathematical objective is to find the best match between two subsequent images. The proposed numerical method has the same properties in treating random-type perturbations as a standard least-squares technique, but it is more efficient in minimizing the effect of the body's deformations. The method can be utilized in determining human movements from inaccurate optical measurements. © 2001 John Wiley & Sons, Inc.		Jadran Lenarcic;Vincenzo Parenti-Castelli	2001	J. Field Robotics	10.1002/rob.8111	classical mechanics;geometry;optics	Robotics	55.647773023909274	-49.16638567899733	154527
e98c414cc4cb7b5fd54f82f33f49d35dbb28df56	turtle geometry in computer graphics and computer-aided design	computer aided design;tecnologia electronica telecomunicaciones;iterated function system;computacion informatica;programming language;young children;grupo de excelencia;computer graphic;turtle geometry;ciencias basicas y experimentales;affine transformation;fractal;subdivision scheme;tecnologias;graduate student;bezier curve	LOGO is a programming language incorporating turtle graphics, originally devised for teaching computing to young children in elementary and middle schools. Here, we advocate the use of LOGO to help introduce some of the basic concepts of computer graphics and computer-aided design to undergraduate and graduate students in colleges and universities. We shall show how to motivate affine coordinates and affine transformations, fractal curves and iterated function systems, relaxation methods and subdivision schemes from elementary notions in turtle geometry and turtle programming. q 2004 Elsevier Ltd. All rights reserved.	apl;b-spline;computer graphics;computer-aided design;control flow;fractal;iterated function system;iteration;linear programming relaxation;programming language;programming paradigm;relaxation (iterative method);schematic;spline (mathematics);subdivision surface;turtle geometry;turtle graphics	Ron Goldman;Scott Schaefer;Tao Ju	2004	Computer-Aided Design	10.1016/j.cad.2003.10.005	simulation;fractal;computer science;engineering;computer aided design;bézier curve;affine transformation;mathematics;geometry;turtle graphics;iterated function system;computer graphics (images);mechanical engineering	EDA	66.97269716245575	-39.87008147563091	154744
8f226c275ddc38ff69910b921223e1f9b1def8c3	modeling varying camera-imu time offset in optimization-based visual-inertial odometry		Combining cameras and inertial measurement units (IMUs) has been proven effective in motion tracking, as these two sensing modalities offer complementary characteristics that are suitable for fusion. While most works focus on global-shutter cameras and synchronized sensor measurements, consumer-grade devices are mostly equipped with rolling-shutter cameras and suffer from imperfect sensor synchronization. In this work, we propose a nonlinear optimization-based monocular visual inertial odometry (VIO) with varying camera-IMU time offset modeled as an unknown variable. Our approach is able to handle the rollingshutter effects and imperfect sensor synchronization in a unified way. Additionally, we introduce an efficient algorithm based on dynamic programming and red-black tree to speed up IMU integration over variablelength time intervals during the optimization. An uncertainty-aware initialization is also presented to launch the VIO robustly. Comparisons with state-of-the-art methods on the Euroc dataset and mobile phone data are shown to validate the effectiveness of our approach.	algorithm;dynamic programming;experiment;mathematical optimization;mobile phone;movie projector;nonlinear programming;nonlinear system;odometry;red–black tree	Yonggen Ling;Linchao Bao;Zequn Jie;Fengming Zhu;Ziyang Li;Shanmin Tang;Yongsheng Liu;Wei Liu;Tong Zhang	2018		10.1007/978-3-030-01240-3_30	nonlinear programming;computer vision;inertial measurement unit;odometry;synchronization;inertial frame of reference;dynamic programming;initialization;computer science;artificial intelligence;match moving	Vision	53.974886703857536	-42.203454840098516	154825
ec33125144d776eeb128b087b05f4ee43c0e9d99	truncated signed distance function volume integration based on voxel-level optimization for 3d reconstruction			3d reconstruction;shadow volume;voxel	Fei Li;Yunfan Du;Rujie Liu	2016			3d reconstruction;voxel;signed distance function;mathematical optimization;mathematics	Vision	61.15837481709057	-47.93924933601076	155090
a12e4c336828b747fe274e523c459b3d7fc624e4	teleoperating robonaut: a case study	mean error;motion estimation;three dimensional;human motion;conditional probability	In this paper, we present a non-intrusive method for human motion estimation from a monocular video camera for the teleoperation of ROBONAUT (ROBOtic astroNAUT). ROBONAUT is an anthropomorphic robot developed at NASA JSC, which is capable of dextrous, humanlike maneuvers to handle common extravehicular activity tools. The human operator is represented using an articulated three-dimensional model consisting of rigid links connected by spherical joints. The shape of a link is described by a triangular mesh and its motion by six parameters: one three-dimensional translation vector and three rotation angles. The motion parameters of the links are estimated by maximizing the conditional probability of the frame-to-frame intensity differences at observation points. The algorithm was applied to real test sequences of a moving arm with very encouraging results. Specifically, the mean error for the derived wrist position (using the estimated motion parameters) was 0.57 0.31 cm. The motion estimates were used to remotely command a robonaut simulation developed at NASA JSC.	3d modeling;algorithm;experiment;kinesiology;motion estimation;polygon mesh;robonaut;run-time infrastructure (simulation);simulation	G. Martinez;Ioannis A. Kakadiaris;Darby Magruder	2002		10.5244/C.16.74	three-dimensional space;computer vision;simulation;conditional probability;motion estimation;control theory;mathematics;mean squared error;statistics	Robotics	53.92912535928181	-39.308278657513114	155107
022471e7f3459835e9065fb78f4f128be846ad05	geometric surface smoothing via anisotropic diffusion of normals	image processing;geometric surface;feature preserving surface smoothing;surface smoothing;level set surface models;computational geometry;geometric surface smoothing;visualization;natural generalization;level set surface model;data visualisation;geometric surface processing;image filtering;smoothing complex;well-founded formulation;complex shape;solid modelling;anisotropic diffusion;object modeling;noisy surface;sharp geometric features;surface fairing;anisotropic diffusion of normals;changing topology;intrinsic laplacian of curvature;level sets;level set;geometric modeling	This paper introduces a method for smoothing complex, noisy surfaces, while preserving (and enhancing) sharp, geometric features. It has two main advantages over previous approaches to feature preserving surface smoothing. First is the use of level set surface models, which allows us to process very complex shapes of arbitrary and changing topology. This generality makes it well suited for processing surfaces that are derived directly from measured data. The second advantage is that the proposed method derives from a well-founded formulation, which is a natural generalization of anisotropic diffusion, as used in image processing. This formulation is based on the proposition that the generalization of image filtering entails filtering the normals of the surface, rather than processing the positions of points on a mesh.	anisotropic diffusion;filter (signal processing);image processing;smoothing	Tolga Tasdizen;Ross T. Whitaker;Paul Burchard;Stanley Osher	2002	IEEE Visualization, 2002. VIS 2002.		edge-preserving smoothing;computer vision;mathematical optimization;image processing;computational geometry;computer science;level set;mathematics;geometry;data visualization;smoothing	Visualization	67.93977024507652	-45.60757017324899	155168
2fd6e2dbdc8a21cec9ced83735ba3f5f99065dd6	self-calibration of a rotating camera with a translational offset	contraste;vision ordenador;fixed point theorem;rotation methods;systematic error;localization;error sistematico;punto fijo;movie camera;localizacion;robotics;matrix algebra;indexing terms;image sensors;theoreme point fixe;teorema punto fijo;computer vision;cameras calibration robot vision systems layout optical sensors computer vision parameter estimation head computer errors robot sensing systems;fixed point;calibration computer vision image sensors cameras matrix algebra measurement errors;camara;estimation erreur;localisation;bias;error estimation;point fixe;estimacion error;robotica;vision ordinateur;etalonnage;robotique;camera calibration;calibration;fix point;cameras;measurement errors;erreur systematique;camera;image image transformation rotating camera self calibration purely rotational movement unknown translational offset unknown camera rotations algorithmic simplicity systematic errors homographic matrix computer vision	Camera self calibration, based on a purely rotational movement of the camera, receives the most attention among different camera self-calibration methods due to its algorithmic simplicity. The existing purely rotational methods, however, assume camera rotates around its optical center, therefore yielding no translation offset. This assumption is not realistic, since in practice, the precise location of the optical center is often unknown, and the rotation is often performed about an unknown but fixed point near the optical center. The conventional methods tend to ignore the offset, and therefore, could lead to significant errors with the estimated camera parameters. In this paper, we introduce a new rotation-based camera self-calibration method, which explicitly accounts for the unknown translation offset. To this end, the problem is mathematically formulated and solved for differently taking the translation into consideration. To obtain the camera parameters with unknown camera rotations, our algorithm requires the camera to rotate around an unknown but fixed axis twice, by the same yet unknown angle. This is not an unreasonable assumption for precalibrating a camera on an active head. Experiments with both synthetic and real data show that the systematic errors caused by ignoring the translational offset will be effectively eliminated by our approach.	algorithm;apache axis;bundle adjustment;camera resectioning;encoder;experiment;fixed point (mathematics);homography (computer vision);isometric projection;numerical stability;photogrammetry;pixel;robotics;social inequality;synthetic data	Qiang Ji;Songtao Dai	2004	IEEE Transactions on Robotics and Automation	10.1109/TRA.2003.820921	computer vision;camera auto-calibration;calibration;camera resectioning;simulation;index term;internationalization and localization;computer science;systematic error;bias;image sensor;mathematics;fixed point;fixed-point theorem;optics;robotics;pinhole camera model;observational error	Robotics	54.01263495342044	-49.829609325275825	155179
1eb9bbe29a7acde28855046aa2d0ec79510080b3	range image denoising using a constrained local gaussian model for 3d object query service in the smart space	local gaussian model;linear system;range image processing;noise reduction;surface smoothing	A position and direction is a fundamental information for U-Business as an anywhere service. A mobile device camera image can increase an accuracy of the positioning, and a range image provides significant information in an occlusion scene. U-Business service queries the information with the range image for a precision position or a target object. We present a method for smoothing heavy noisy surfaces acquired by mobile 3D imaging devices to obtain the stable curvature. The smoothing is performed in a way that finds centers of probability distributions, which maximizes the likelihood of observed points with smooth constraints. The smooth constraints are derived from the unit tangent vector equality. This provides a way of obtaining smooth surfaces and stable curvatures. We achieve the smoothing by solving the regularized linear system. The unit tangent vector equality involves consideration of geometric symmetry, and it minimizes the variation of differential values that are a factor of curvatures. The proposed algorithm has two apparent advantages. The first thing is that the surfaces in a scene with various signals-to-noise ratio are smoothed, and then they can earn suitable curvatures. The second is that the proposed method works on heavy noisy surfaces, for example, a stereo camera image. Experiments on range images demonstrate that the proposed method yields the smooth surfaces from the input with various signals-to-noise ratio and the stable curvatures obtained from the smooth surfaces.	3d reconstruction;algorithm;experiment;image registration;linear system;mobile 3d graphics api;mobile device;moving least squares;noise reduction;polynomial basis;range imaging;smoothing;stereo camera;stereoscopy	Jeong-Heon Kim;Kwang Nam Choi	2012	Personal and Ubiquitous Computing	10.1007/s00779-012-0575-5	computer vision;mathematical optimization;computer science;noise reduction;linear system;smoothing	Vision	56.30766801657306	-46.769122088869736	155241
de9fb2b78f478324a77cd8de0281a386740cd99b	a multi-frame adaptive 3d non-rigid registration for augmented reality			augmented reality	Antonio Carlos dos Santos Souza	2014			computer vision;augmented reality;artificial intelligence;computer science	Vision	60.40832941042724	-47.806132714532474	155273
5bf7c24ba864fb7266acc6b54dea3423658aaa28	real-time synthesis of 3d animations by learning parametric gaussians using self-organizing mixture networks	autoapprentissage;modelizacion;animacion por computador;processus gauss;valor elevado;interfase usuario;interfaz grafica;3d animation;mouvement corporel;estimation mouvement;motion control;high dimensionality;melange loi probabilite;graphical interface;user interface;learning model;real time;estimacion movimiento;mixed distribution;motion estimation;valeur elevee;probabilistic approach;autodidactismo;commande mouvement;self learning;modelisation;control movimiento;enfoque probabilista;approche probabiliste;human motion;interpolation method;temps reel;commande vectorielle;control vectorial;autoorganizacion;tiempo real;character animation;high value;vector control;mezcla ley probabilidad;self organization;interface utilisateur;gaussian process;reseau neuronal;computer animation;proceso gauss;movimiento corporal;modeling;interface graphique;red neuronal;autoorganisation;body movement;neural network;animation par ordinateur	In this paper, we present a novel real-time approach to synthesizing 3D character animations of required style by adjusting a few parameters or scratching mouse cursor. Our approach regards learning captured 3D human motions as parametric Gaussians by the self-organizing mixture network (SOMN). The learned model describes motions under the control of a vector variable called the style variable, and acts as a probabilistic mapping from the low-dimensional style values to high-dimensional 3D poses. We have designed a pose synthesis algorithm and developed a user friendly graphical interface to allow the users, especially animators, to easily generate poses by giving style values. We have also designed a style-interpolation method, which accepts a sparse sequence of key style values and interpolates it and generates a dense sequence of style values for synthesizing a segment of animation. This key-styling method is able to produce animations that are more realistic and natural-looking than those synthesized by the traditional key-framing technique.		Yi Wang;Hujun Yin;Lizhu Zhou;Zhi-Qiang Liu	2006		10.1007/11893257_75	simulation;computer science;artificial intelligence;computer animation;artificial neural network;statistics;computer graphics (images)	ML	60.85355398558444	-45.615708459102706	155529
382afd87262dd67e2e21f2df1e0febc18ffd0c5e	development of high-speed camera circuits for diffraction imaging flow cytometer	3 d morphology features high speed camera circuits diffraction imaging flow cytometer biological cells time delay integration principle image blur conventional ccd cameras master control circuit driver circuit signal processing circuit synchronization line charge transfer flowing cells image acquisition system;medical image processing biomedical measurement ccd image sensors cellular biophysics;high speed image acquisition of cell flow cytometer fcm time delay integration tdi ccd;ccd image sensors;medical image processing;charge coupled devices cameras diffraction noise field programmable gate arrays timing;cellular biophysics;biomedical measurement	In this study we present design and test results of high-speed camera circuits used in a diffraction imaging flow cytometer for detection and analysis of the biological cells based on a time-delay-integration (TDI) principle. The TDI camera design can eliminate image blur which often occurs with conventional CCD cameras for imaging flowing objects. We have developed the master control circuit, driver circuit, signal processing circuit, and the method of synchronization between the line charge transfer in TDI-CCD and flowing cells. Based on these results, a TDI-CCD image acquisition system was built to allow acquisition of high-contrast diffraction image data from the flowing cells and extract their 3-D morphology features for further analysis.	charge-coupled device;driver circuit;experiment;gaussian blur;master control;mathematical morphology;signal processing;time delay and integration;traffic enforcement camera	Junyu Wang;Yuanming Feng;Jun Q. Lu	2012	2012 IEEE International Conference on Virtual Environments Human-Computer Interfaces and Measurement Systems (VECIMS) Proceedings	10.1109/VECIMS.2012.6273230	computer vision;image processing;computer science;time delay and integration;computer graphics (images)	EDA	62.39849491536936	-38.842045349242994	155663
0915e49050ca555c07329abea55c05f3304e93fe	a unified theory of uncalibrated stereo for both perspective and affine cameras	motion analysis;lens distortion;linear algebra;affine projection;fundamental matrix;nonmetric vision;epipolar geometry;uncalibrated images;projective reconstruction;structure and motion;3d reconstruction	This paper addresses the recovery of structure and motion from uncalibrated images of a scene under full perspective or under affine projection. Particular emphasis is placed on the configuration of two views, while the extension to $N$ views is given in Appendix. A unified expression of the fundamental matrix is derived which is valid for any projection model without lens distortion (including full perspective and affine camera). Affine reconstruction is considered as a special projective reconstruction. The theory is elaborated in a way such that everyone having knowledge of linear algebra can understand the discussion without difficulty. A new technique for affine reconstruction is developed, which consists in first estimating the affine epipolar geometry and then performing a triangulation for each point match with respect to an implicit common affine basis.	3d projection;basis (linear algebra);distortion;epipolar geometry;fundamental matrix (computer vision);linear algebra	Zhengyou Zhang;Gang Xu	1998	Journal of Mathematical Imaging and Vision	10.1023/A:1008341803636	3d reconstruction;distortion;affine geometry;affine space;computer vision;complex space;topology;affine coordinate system;affine involution;computer science;affine plane;linear algebra;affine geometry of curves;affine hull;affine arithmetic;affine transformation;harris affine region detector;mathematics;geometry;fundamental matrix;affine shape adaptation;affine combination;epipolar geometry;hessian affine region detector	Vision	53.999652250601905	-50.86022588750698	155748
c2e296266d2adfeb2a04e25dc2033653575ba313	on-line tool wear measurement for ball-end milling cutter based on machine vision	ball end cutter;machine vision;tool wear;sub pixel edge detection;milling process;on line measurement	Cutting tool wear is known to affect tool life, surface quality and production time. In this paper, a new online tool wear measuring algorithm is proposed to acquire tool wear using machine vision in order to establish on-line tool wear monitoring model for assessing degree of wear and remaining useful tool life. The algorithm first adopts machine vision to acquire tool wear images from CCD camera on-line for ballend cutter. Tool tip points are determined and wear detection areas are optimized within captured tool wear images. Tool wear images before machining and in machining process are captured to compare the corresponding image column for judging whether this image column has emerged wear. Then the initial detection of wear edge points with pixel accuracy is given to scan pixel columns within the constructed wear detection areas in vertical direction. The exact detection algorithm of wear edge points with subpixel accuracy is proposed to increase the precision of detected wear edge points. The tool wear can be computed based on the detected wear edge points. Experimental work and validation of the established on-line tool wear measurement method are performed in a five-axis milling center by using stainless steel 1Cr18Ni9Ti and ball-end cutter of cemented carbide. The obtained measurement results by using the proposed method are compared with those gotten by measuring directly with microscope. The proposed method is shown to be reliable and effective for on-line tool wear measurement. 2013 Elsevier B.V. All rights reserved.	algorithm;charge-coupled device;column (database);cutter expansive classification;experiment;machine vision;mathematical optimization;online and offline;optic axis of a crystal;pixel;simulation;tooltip	Jilin Zhang	2013	Computers in Industry	10.1016/j.compind.2013.03.010	computer vision;machine vision;computer science;engineering;artificial intelligence;forensic engineering;engineering drawing	Robotics	60.17901727610984	-41.01814557129812	155765
d2102882538b85ddf2b36e36e755f84738741796	fluorescent immersion range scanning	high resolution;surface properties;fluorescent dye;3d scanning;refractive index;transparent surfaces	The quality of a 3D range scan should not depend on the surface properties of the object. Most active range scanning techniques, however, assume a diffuse reflector to allow for a robust detection of incident light patterns. In our approach we embed the object into a fluorescent liquid. By analyzing the light rays that become visible due to fluorescence rather than analyzing their reflections off the surface, we can detect the intersection points between the projected laser sheet and the object surface for a wide range of different materials. For transparent objects we can even directly depict a slice through the object in just one image by matching its refractive index to the one of the embedding liquid. This enables a direct sampling of the object geometry without the need for computational reconstruction. This way, a high-resolution 3D volume can be assembled simply by sweeping a laser plane through the object. We demonstrate the effectiveness of our light sheet range scanning approach on a set of objects manufactured from a variety of materials and material mixes, including dark, translucent and transparent objects. CR Categories: I.3.3 [Computer Graphics]: Picture/Image Generation—Digitizing and scanning;	3d scanner;ct scan;computer graphics;diffuse reflection;image resolution;immersion (virtual reality);ray (optics);reflection (computer graphics);sampling (signal processing)	Matthias B. Hullin;Martin Fuchs;Ivo Ihrke;Hans-Peter Seidel;Hendrik P. A. Lensch	2008	ACM Trans. Graph.	10.1145/1360612.1360686	computer vision;image resolution;optoelectronics;refractive index;optics	Graphics	60.722324406470776	-51.67646447619974	155806
62875a4bb06e8bf7d4dad0df7ed0c5907227f35b	illustrating surfaces in volume	feature detection;image processing;volume rendering;graphics hardware;interactive rendering;volume visualization	This paper presents a novel framework for illustrating surfaces in a volume. Surfaces are illustrated by drawing only feature lines, such as silhouettes, valleys, ridges, and surface hatching strokes, and are embedded in volume renderings. This framework promises effective illustration of both surfaces and volumes without occluding or cluttering each other. A two-step approach has been taken: the first step depicts surfaces; the second step performs volume rendering, at the same time embedding surfaces from the first step.  We introduce Procedurally Perturbed Image Processing (PIP), a new method for enhancing both feature detection and depiction of surfaces. We also present implementation strategies, especially those leveraging modern graphics hardware, for delivering an interactive rendering system. Our implementation results have shown that this mixed form of rendering improves volume visualization and is efficient.	embedded system;feature detection (computer vision);feature detection (web development);graphics hardware;image processing;rendering (computer graphics);scientific visualization;volume rendering	Xiaoru Yuan;Baoquan Chen	2004		10.2312/VisSym/VisSym04/009-016	computer vision;tiled rendering;rendering;computer science;parallel rendering;multimedia;real-time rendering;software rendering;computer graphics (images)	Visualization	64.60769444901742	-48.267606339373515	155923
41862830d45101e7cd43c7a1bce1641ae0f9aefa	how to draw a sphere. 1	second order;sphere drawing;matrix algebra rendering computer graphics computational geometry subroutines;mathematics;motion pictures;texture mapped sphere;second order surfaces;special purpose program;texture mapping;geometry;computational geometry;computer crime;matrix algebra;matrix mathematics;sphere rendering algorithm;moon;planets;propulsion;lighting;rendering computer graphics;h infinity control;texture mapped sphere special purpose program sphere drawing matrix mathematics sphere rendering algorithm second order surfaces;h infinity control mathematics geometry equations moon planets motion pictures propulsion computer crime lighting;subroutines	I have written a special-purpose program that is highly optimized for drawing spheres. This program involves quite a variety of interesting tricks, but when I started to write about them, I realized that lot of matrix mathematics background is necessary to understand the sphere-rendering algorithm. I consider the matrix mathematics necessary to manipulate (and ultimately render) second-order surfaces. I wanted an algorithm that drew a texture-mapped sphere arbitrarily scaled, translated, and placed into perspective. It had to work for any view of the sphere and needed to be fast. >		James F. Blinn	1995	IEEE Computer Graphics and Applications	10.1109/38.364968	planet;texture mapping;computer vision;propulsion;computational geometry;computer science;natural satellite;artificial intelligence;subroutine;pure mathematics;lighting;mathematics;geometry;second-order logic;algorithm;matrix;computer graphics (images)	Visualization	64.96324495990831	-45.03347607178994	155976
0f284b83ed176656b81c57f6ac82fbd195fa367d	computing the antipenumbra of an area light source	three dimensions;plu cker coordinates;computer graphic;aspect graph;global illumination;polygonal meshes;geometric algorithm;discontinuity meshing;radiosity;three dimensional graphics and realism;stabbing lines;object model	We define the antiumbra and the antipenumbra of a convex area light source shining through a sequence of convex areal holes in three dimensions. The antiumbra is the volume from which all points on the light source can be seen. The antipenumbra is the volume from which some, but not all, of the light source can be seen. We show that the antipenumbra is, in general, a disconnected set bounded by portions of quadric surfaces, and describe an implemented time algorithm that computes this boundary, where is the total number of edges comprising the light source and holes. The antipenumbra computation is motivated by a visibility scheme in which we wish to determine the volume visible to an observer looking through a sequence of transparent convex holes, or portals, connecting adjacent cells in a spatial subdivision. Knowledge of the antipenumbra should also prove useful for rendering shadowed objects. Finally, we have extended the algorithm to compute the planar and quadratic surfaces along which the rate of areal variation in the visible portion of the light source changes discontinuously due to occlusion. These surfaces are relevant in polygon meshing schemes for global illumination and shadow computations. CR	algorithm;computation;global illumination;portals;space partitioning;subdivision surface	Seth J. Teller	1992		10.1145/133994.134029	three-dimensional space;radiosity;object model;computer science;theoretical computer science;mathematics;geometry;global illumination;computer graphics (images)	Graphics	66.78078113687735	-48.16293018825389	156215
559e0f638d577348ff69533aba5f222afc921d9a	research of acquisition method for pavement surface texture based on photometric stereo techniques	texture;structural engineering computing image reconstruction image texture least squares approximations roads solid modelling stereo image processing;topography;pavement surface topography acquisition method pavement surface texture photometric stereo techniques 3d reconstruction technique pavement texture detection platform camera lighted sources tripod least square method surface height recovery tangent plane method 3d model asphalt pavement;equations mathematical model light sources surface topography vectors three dimensional displays cameras;mathematical models;photometry;surface course pavements;pavement maintenance	A 3D reconstruction technique was applied to acquire pavement surface texture since the traditional method can't achieve the balance between accuracy and economy. In this study, a simple pavement texture detection platform consisting of a camera, lighted sources and tripod was developed basing on four sources photometric stereo technique. Then the pictures captured by detection platform were analyzed by least square method to extract the normals of points in the pavement surface. When these normals were calculated, they were used to recover surface heights of pavements by tangent plane method. The experimental result shows that the 3D model of asphalt pavement recovered by photometric stereo technique is efficiency to reveal the pavement surface topography both in macro-scale and micro-scale.	3d reconstruction;photometric stereo;polygonal modeling;topography;tripod	Jinyu Lei;Enjun Wang;Juan Zeng;Weifeng Wang;Jianbo Wu	2014	17th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2014.6957921	computer vision;geography;optics;computer graphics (images)	Vision	55.988174070029984	-50.525486959388154	156229
907d4a5de572006276db5e0044cbc18d7959568a	relative affine structure: theory and application to 3d reconstruction from perspective views	3d reconstruction affine framework perspective views relative affine structure image sequence;structuration theory;perspective views;computer vision;machine vision;image reconstruction;image sequence;image reconstruction machine vision;computer vision image reconstruction;affine framework;relative affine structure;3d reconstruction	We propose an aane framework for perspective views, captured by a single extremely simple equation based on a viewer-centered invariant we call relative aane structure. Via a number of corollaries of our main results we show that our framework uniies previous work | including Euclidean, projective and aane | in a natural and simple way. Finally, the main results were applied to a real image sequence for purpose of 3D reconstruction from 2D views.	3d reconstruction	Amnon Shashua;Nassir Navab	1994		10.1109/CVPR.1994.323870	3d reconstruction;iterative reconstruction;computer vision;topology;machine vision;computer science;harris affine region detector;mathematics;geometry;affine shape adaptation	Vision	53.892232437171984	-51.10967467834391	156436
e770a73d6af5779c0ff97ebab359b57884c7a13e	extracting structure from an affine view of a 3d point set with one or two bilateral symmetries	computer vision;symmetry;affine structure	We demonstrate that the structure of a 3D point set with a single bilateral symmetry can be reconstructed from an uncalibrated affine image, modulo a Euclidean transformation, up to a four parameter family of symmetric objects that could have given rise to the image. If the object has two orthogonal bilateral symmetries, the shape can be reconstructed modulo similarity. Both results are demonstrated using real images with uncalibrated cameras.	bilateral filter	Roger Fawcett;Andrew Zisserman;Michael Brady	1993		10.5244/C.7.35	discrete mathematics;topology;mathematics;geometry;affine shape adaptation	Vision	53.9983593803789	-51.19160215676885	156595
5683decaa21009525883de7b18d15ae72b80f3c2	the minimum of gdop for satellite navigation system		Geometric Dilution of Precision (GDOP) represents the magnification positioning error in satellite navigation, smaller GDOP represents high positioning accuracy. The analytic results of relevant methods to derive the minimum of GDOP by geocentric coordinate system cannot be achieved in reality, because it does not think fully about the satellite visibility constrains. This article employs the elevation angle to express the satellite visibility, and on basis of the local Cartesian coordinates coordinate system, the essay derives the minimum of GDOP with constraint of four satellites visible. Based on the information track of Beidou satellite navigation system, the minimum of GDOP is verified by using the STK simulation software.	dilution of precision (navigation);satellite navigation	Xuetao Yang;Jianchao Du;Weibin Li	2017		10.1007/978-3-319-78130-3_46	cartesian coordinate system;elevation;geodesy;geocentric coordinates;magnification;coordinate system;dilution of precision;satellite navigation;satellite;mathematics	Robotics	56.1927885673303	-39.666814137632755	156665
9abae1bea31e1819f0392588eb1571e015e2dde7	an image analysis and photogrammetric engineering integrated shadow detection model		A model of automatically detecting the building shadows in high resolution aerial remote sensing image is introduced in this paper. The space coordinates of the shadows are first computed using photogrammetric engineering. To do this, digital surface model (DSM) and the sun zenith and azimuth angles are used. By camera model, the scanning line and the camera position are calculated for each space shadow. A contour driven height field ray tracing is proposed to determine the visibility of a shadow. For a visible shadow, its projecting in the image, called measured shadow, is calculated by collinearity equations. Then by image analysis the reference segmentation threshold is obtained from the intensity distribution of the measured shadows. At last, the image segmentation is implemented to get the precise image shadow areas.	image analysis;photogrammetry	Yan Li;Peng Gong;Tadashi Sasagawa	2004		10.1007/3-540-26772-7_41	computer vision;remote sensing;computer graphics (images)	SE	57.21592693421392	-48.37095681554704	156667
91398d785636d95d86426d80eb688509bb7ad723	identification of scene locations from geotagged images	visual context;geotag;stereo vision;image metadata	Due to geotagging capabilities of consumer cameras, it has become easy to capture the exact geometric location where a picture is taken. However, the location is not the whereabouts of the scene taken by the photographer but the whereabouts of the photographer himself. To determine the actual location of an object seen in a photo some sophisticated and tiresome steps are required on a special camera rig, which are generally not available in common digital cameras. This article proposes a novel method to determine the geometric location corresponding to a specific image pixel. A new technique of stereo triangulation is introduced to compute the relative depth of a pixel position. Geographical metadata embedded in images are utilized to convert relative depths to absolute coordinates. When a geographic database is available we can also infer the semantically meaningful description of a scene object from where the specified pixel is projected onto the photo. Experimental results demonstrate the effectiveness of the proposed approach in accurately identifying actual locations.	digital camera;embedded system;geotagging;pixel;spatial database;stereoscopy	Jong-Seung Park;Ramesh Jain	2013	TOMCCAP	10.1145/2422956.2422961	computer vision;computer science;stereopsis;operating system;geotagging;multimedia;computer graphics (images)	Vision	56.08539161975147	-45.72906496623756	156904
0e728c6b357d531dc36f9eedfa9b6dc7b880ff69	piecewise algebraic surface computation and smoothing from a discrete model	implicit surface;producto tensorial;ajustement surface;modelizacion;image tridimensionnelle;concepcion asistida;computer aided design;modele geometrique;ajustamiento curva;cubico;surface fitting;produit tensoriel;implicit theory;surface lisse;surface reconstruction;voxel;smooth surface;modelisation;tensor product;algebraic geometry;reconstruction surface;cubique;smoothing methods;algebraic surfaces;discrete model;smoothing;methode lissage;teoria implicita;surface smoothing;alisamiento;conception assistee;tridimensional image;geometric modeling;ajustement courbe;geometria algebraica;geometric model;superficie lisa;reconstruccion superficie;external research report;curve fitting;theorie implicite;modeling;article;lissage;cubics;imagen tridimensional;geometrical model;geometrie algebrique;modelo geometrico	This paper describes a constrained smoothing method for implicit surfaces defined on a voxelization. This method is suitable for computing a closed smooth surface that approximates an initial set of face connected voxels. The implicit surface is defined as the zero-set of a tensor-product uniform cubic Bspline. The smoothing process is based on increasing the Bspline continuity from C^2 to C^3 on the boundary faces of the voxels. The final surface is guaranteed to pierce a predefined subset of voxels.	computation;linear algebra;smoothing	Jordi Esteve;Pere Brunet;Alvar Vinacua	2008	Computer Aided Geometric Design	10.1016/j.cagd.2007.09.005	topology;algebraic geometry;geometric modeling;computer aided design;calculus;mathematics;geometry;statistics;algebra	Graphics	68.20368766895024	-40.733570381086864	157021
e1ec090a5b7c91cd37872b9e05d1b531f842285b	fast shadowing algorithm for linear light sources	ray oriented buffer;linear light;shadow algorithm;shadowing;space segmentation;analytic rendering	This paper presents a fast shadowing algorithm for linear light sources that uses a ray-oriented buffer. Space segmentation by the buffer guarantees that if a point is included in a subspace, all light rays toward the point are also contained in the subspace. Each cell of the buffer stores a list of objects that lie within or intersect the subspace allocated to the cell. Therefore, candidate objects, those that may cast shadows onto a point, are determined by referring to the cell where the point is mapped. In addition, whether each candidate object actually casts shadows or not is tested with the bounding-volume of the shadow space to reduce the number of objects subjected to expensive light clipping. The bounding-volumes are also stored in the buffer. For efficiently generating the ray-oriented buffer, we present the cylindrical scan-conversion algorithm. The algorithm preconverts objects' surfaces to trapezia to decrease the light clipping cost, then connects the trapezia to the buffer cells. Due to the above improvements, our algorithm achieves over 10 times faster shadow generation compared to the conventional methods. Experimental results confirm that our method can generate realistic images with soft shadows in a few minutes.	algorithm;bounding volume;ray (optics);scan conversion	Toshimitsu Tanaka;Tokiichiro Takahashi	1995	Comput. Graph. Forum	10.1111/j.1467-8659.1995.cgf143_0205.x	computer vision;mathematics;computer graphics (images)	Graphics	66.5114718510283	-50.574737145457554	157106
1a9841969967eb28fca4e7cda7c48940185f033a	real-world relativity: image-based special relativistic visualization	real-world relativity;image generation;image-based special relativistic visualization;doppler effect;image-based method;special relativity;plenoptic function;relativistic aberration;novel rendering technique;image-based rendering;relativistic effect;searchlight effect;bya standard camera;interactive viewingof relativistic panorama;howthe relativistic effect;scientific visualization;light;geometry;snapshots;color;relativistic effects;data visualisation;rendering;visualization;brightness;movies;image based rendering	This paper describes a novel rendering technique for special relativistic visualization. It is an image-based method which allows to render high speed flights through real-world scenes filmed by a standard camera. The relativistic effects on image generation are determined by the relativistic aberration of light, the Doppler effect, and the searchlight effect. These account for changes of apparent geometry, color and brightness of the objects. It is shown how the relativistic effects can be taken into account by a modification of the plenoptic function. Therefore, all known image-based nonrelativistic rendering methods can easily be extended to incorporate relativistic rendering. Our implementation allows interactive viewing of relativistic panoramas and the production of movies which show super-fast travel. Examples in the form of snapshots and film sequences are included.	color;doppler effect;emoticon;glossary of computer graphics;numerical relativity;snapshot (computer storage)	Daniel Weiskopf;Daniel Kobras;Hanns Ruder	2000	Proceedings Visualization 2000. VIS 2000 (Cat. No.00CH37145)	10.1145/375213.375260	snapshot;computer vision;scientific visualization;image-based modeling and rendering;visualization;doppler effect;rendering;computer science;light;multimedia;relativistic quantum chemistry;special relativity;brightness;data visualization;quantum mechanics;computer graphics (images)	Visualization	63.0758557563148	-51.85269505182256	157283
43c5627cfa3e4f0448f21940f60e212c1eef43fb	300's liquid battlefield: fluid simulation spartan style	poisson disk;network simulator;blue noise;sampling;production scheduling;fluid simulation	This sketch will give insight into the methods Scanline used for creating the liquid battlefield scenes of Zach Snyder's 300. From massive parallel network simulation to rendering, we'll explore the innovative techniques that made it possible to bring these scenes to life with a relatively small team and a short production schedule.	fluid animation;scan line;simulation;spartan	Stephan Trojansky;Thomas Ganshorn;Oliver Pilarski	2007		10.1145/1278780.1278894	fluid simulation;sampling;computer vision;real-time computing;simulation;colors of noise;computer hardware;computer science;artificial intelligence;operating system;network simulation;scheduling;statistics;computer graphics (images)	Graphics	64.65404954526954	-51.33774512324531	157288
70bfae101c8d1fccf26368d54bddddbd3c03f09d	point-based rendering techniques	hardware acceleration;point based rendering;hardware accelerator;level of detail;triangle mesh;data structure	The increasing popularity of points as rendering primitives has led to a variety of different rendering algorithms, and the different implementations compare like apples to oranges. In this paper, we revisit and compare a number of recently developed point-based rendering implementations within a common testbed. Also we briefly summarize a few proposed hierarchical multiresolution point data structures and discuss their advantages. Based on a common viewdependent level-of-detail (LOD) rendering framework, we then examine different hardware accelerated point rendering algorithms. Experimental results are given with respect to performance timing and rendering quality for the different approaches. Additionally, we also compare the point-based rendering techniques to a basic triangle mesh approach. r 2004 Elsevier Ltd. All rights reserved.	algorithm;data structure;experiment;graphics;level of detail;mesh generation;numerical analysis;observable;pbr theorem;prospective search;rendering (computer graphics);selection algorithm;testbed;throughput;triangle mesh	Miguel Sainz;Renato Pajarola	2004	Computers & Graphics	10.1016/j.cag.2004.08.014	tiled rendering;simulation;image-based modeling and rendering;data structure;hardware acceleration;rendering;computer science;theoretical computer science;operating system;parallel rendering;programming language;alternate frame rendering;software rendering;computer graphics (images)	Graphics	67.40732323562955	-51.89533073493622	157495
a981fb6fc1559de0a42cc3af3f8eaec55f7e3e7b	an easy-to-implement benchmarking tool for mobile tablet-pc visual pose estimation	smart mobile device;benchmarking tool;visual pose estimation;tablet pc	Recently, researchers are interested in mobile device based computer vision applications. An accurate visual pose estimation is a common and important subtask. To quantitatively evaluate the accuracy, ground truth visual pose datasets are needed. However, the lack of inexpensive and easy benchmarking tool for mobile device based visual poses estimation makes it difficult, if not impossible, to quantitatively evaluate the estimated visual poses. In this paper, a novel and easy-to-implement experimental setup is proposed to generate ground truth visual pose data for handheld tablet-PC. The tablet-PC screen is leveraged to display a calibration pattern every time the on-board camera captures an image. The tablet-PC screen image is captured by another camera and is used to estimate the visual pose of the tablet-PC. An experimental environment is setup for parameter calibration and pose accuracy verification. Extensive experimental results with quantitative analysis demonstrate the accuracy and the generality of our tool.	3d pose estimation;computer vision;ground truth;handheld game console;mobile device;on-board data handling;tablet computer	Xiaoqiang Zhang;Yanning Zhang;Tao Yang;Ting Chen;Yee-Hong Yang	2015		10.1145/2837126.2837144	computer vision;simulation;3d pose estimation;computer science;computer graphics (images)	Vision	54.00813338193567	-45.301891161094986	157609
978a83ddf48c59f18529d69a9a1d0f0428881db0	efficient depth peeling via bucket sort	bucket sort;read modify write;efficient algorithm;graphics hardware;max min blending;ground truth;depth peeling;multiple render target mrt;histogram equalization;order independent transparency oit	In this paper we present an efficient algorithm for multi-layer depth peeling via bucket sort of fragments on GPU, which makes it possible to capture up to 32 layers simultaneously with correct depth ordering in a single geometry pass. We exploit multiple render targets (MRT) as storage and construct a bucket array of size 32 per pixel. Each bucket is capable of holding only one fragment, and can be concurrently updated using the MAX/MIN blending operation. During the rasterization, the depth range of each pixel location is divided into consecutive subintervals uniformly, and a linear bucket sort is performed so that fragments within each subintervals will be routed into the corresponding buckets. In a following fullscreen shader pass, the bucket array can be sequentially accessed to get the sorted fragments for further applications. Collisions will happen when more than one fragment is routed to the same bucket, which can be alleviated by multi-pass approach. We also develop a two-pass approach to further reduce the collisions, namely adaptive bucket depth peeling. In the first geometry pass, the depth range is redivided into non-uniform subintervals according to the depth distribution to make sure that there is only one fragment within each subinterval. In the following bucket sorting pass, there will be only one fragment routed into each bucket and collisions will be substantially reduced. Our algorithm shows up to 32 times speedup to the classical depth peeling especially for large scenes with high depth complexity, and the experimental results are visually faithful to the ground truth. Also it has no requirement of pre-sorting geometries or post-sorting fragments, and is free of read-modify-write (RMW) hazards.	2d-plus-depth;algorithm;alpha compositing;blend modes;bucket sort;depth peeling;graphics processing unit;ground truth;layer (electronics);max;multiple render targets;pixel;rasterisation;read-modify-write;routing;sequential access;shader;sorting;speedup	Fang Liu;Meng-Cheng Huang;Xuehui Liu;Enhua Wu	2009		10.1145/1572769.1572779	leaky bucket;proxmap sort;bucket sort;computer science;theoretical computer science;algorithm;computer graphics (images)	Theory	66.0390033854198	-51.955521726891725	157671
1780528a389bced739e7ce85163729f97d095e57	an efficient integer-based skeletonization algorithm	medial axis transform;simplification;performance evaluation;raster;vectorization;skeleton;symmetric axis transform;vector;skeletonization	"""The problem of generating vector representation of a raster image has been the question of present interest for decades. Although, there are many approaches to this problem, most of them su!er from sophisticated computations and irrational memory usage. We introduce here a new skeletonization algorithm that is very e$cient in terms of time and memory consumption. Starting from the description of our approach to the concept of skeleton on raster grid, we present a comprehensive explanation of the algorithm. Its main idea consists of generating a special polyline for each raster line considering them in top-to-bottom direction; skeleton is constructed from points of these polylines. The skeletons obtained by our algorithm allow the precise reconstruction of the initial raster shapes; therefore they may re#ect some artifacts possible on raster grid. For this reason, we also present here two algorithms of simpli""""cation and our approach to defects """"ltering on a stage of skeleton generation. The time of simpli""""cation by presented algorithms depends linearly on the number of input points that makes these methods fast and e$cient. The paper concludes with performance evaluation and discussion of possible implementations of the introduced techniques. ( 2000 Elsevier Science Ltd. All rights reserved."""	algorithm;computation;performance evaluation;raster graphics;topological skeleton	Denis V. Ivanov;E. Kuzmin;S. Burtsev	2000	Computers & Graphics	10.1016/S0097-8493(99)00136-3	skeletonization;computer vision;raster graphics;vector;computer science;vectorization;geometry;programming language;skeleton;simplification;algorithm;computer graphics (images)	AI	67.29791481403461	-47.8089888172494	157707
1afe60c79ee0e3bc71f3f3cc99a0291a16cf2874	more optimal strokes for npr sketching	cluster algorithm;visibility and occlusion culling;large scale data visualization;cluster sampling;number of clusters;normalized cut	Sketching is a drawing style where approximations and successive refinement in the drawing process are evident. The approximation of contours in sketching involves multiple overlapping strokes that are relatively long in regions of low curvature and shorter in high-curvature areas, yet unimportant high-curvature details are omitted in the initial stages of a sketch. Rendering contours with a single long stroke does not capture the feel of a sketch, and a simple strategy of breaking strokes at curvature maxima is easily confused by unimportant details and noise. We address the contour breaking problem for sketching by clustering samples of the contour based on proximity and orientation, making use of a global clustering algorithm (normalized cuts). The strokes generated by this approach qualitatively resemble those produced by real artists, and the successive approximation effect seen in sketching can be simulated by employing our approach at a succession of scales (increasing the number of clusters).	algorithm;approximation;cluster analysis;contour line;maxima;refinement (computing);succession	John P. Lewis;Nickson Fong;Xuexiang Xie;Seah Hock Soon;Feng Tian	2005		10.1145/1101389.1101398	simulation;computer science;cluster sampling;statistics;computer graphics (images)	ML	63.32737318295559	-47.116006886796484	157769
a968dba25e795f2a5d12c09ae367c0c20e4e8358	simple and efficient normal encoding with error bounds	categories and subject descriptors according to acm ccs i 4 2 image processing and computer vision compression coding approximate methods i 3 6 computer graphics methodology and techniques graphics data structures and data types	Normal maps and bump maps are commonly used techniques to make 3D scenes more realistic. Consequently, the efficient storage of normal vectors is an important task in computer graphics. This work presents a fast, lossy compression/decompression algorithm for arbitrary resolutions. The complete source code is listed in the appendix and is ready to use.		Christoph Schinko;Torsten Ullrich;Dieter W. Fellner	2011		10.2312/LocalChapterEvents/TPCG/TPCG11/063-065	s3 texture compression;2d computer graphics;computer science;theoretical computer science;real-time computer graphics;algorithm	EDA	67.2900335110346	-50.16173133030559	157829
11c020f54fecd8d9f423df9c17b12371a1f29f37	computation of skinning weight using spline interface		Among many approaches for object and character deformation, closed-form skinning methods, such as Linear Blend Skinning (LBS) and Dual Quaternion Skinning (DQS), are widely used as they are fast and intuitive. The quality of these skinning methods highly depends on specifying appropriate skinning weights to vertices, which requires the intensive efforts of professional artists in production animation.	computation;location-based service;spline (mathematics)	Seungbae Bang;Sung-Hee Lee	2018		10.1145/3230744.3230801	computer vision;animation;computer graphics (images);computation;artificial intelligence;vertex (geometry);dual quaternion;spline (mathematics);skinning;computer science	Graphics	65.66052105421949	-45.597962193725905	158123
7cf0fe934095dd077fbaf750f43d26d77c096369	morphing billboards for accurate reproduction of shape and shading of articulated objects with an application to real-time hand tracking			morphing;real-time locating system;shading	Nils Petersen;Didier Stricker	2012		10.1201/b12753-7	shading;morphing;computer graphics (images);computer vision;artificial intelligence;computer science	Vision	61.19997178145044	-47.74920266727403	158155
e8171e43971764663ed87b856eee5da15c1e3801	gpu-based trimming and tessellation of nurbs and t-spline surfaces	t-spline surface;t-spline model;gpu-based tessellation;run-time tessellation;nurbs and t- spline surfaces;gpu-based trimming;required resolution;trimming;rendering apis;new method;efficient trimming;nurbs and t-spline surfaces;new rendering algorithm;gpu-based algorithms;irregular mesh data structure;data structure;level of detail;character animation	As there is no hardware support neither for rendering trimmed NURBS -- the standard surface representation in CAD -- nor for T-Spline surfaces the usability of existing rendering APIs like OpenGL, where a run-time tessellation is performed on the CPU, is limited to simple scenes. Due to the irregular mesh data structures required for trimming no algorithms exists that exploit the GPU for tessellation. Therefore, recent approaches perform a pretessellation and use level-of-detail techniques. In contrast to a simple API these methods require tedious preparation of the models before rendering and hinder interactive editing. Furthermore, due to the tremendous amount of triangle data smooth zoom-ins from long shot to close-up are not possible, In this paper we show how the trimming region can be defined by a trim-texture that is dynamically adapted to the required resolution and allows for an efficient trimming of surfaces on the GPU. Combining this new method with GPU-based tessellation of cubic rational surfaces allows a new rendering algorithm for arbitrary trimmed NURBS and T-Spline surfaces with prescribed error in screen space on the GPU. The performance exceeds current CPU-based techniques by a factor of up to 1000 and makes real-time visualization of real-world trimmed NURBS and T-Spline models possible on consumer-level graphics cards.	graphics processing unit;non-uniform rational b-spline;spline (mathematics);t-spline;tessellation (computer graphics)	Michael Guthe;Ákos Balázs;Reinhard Klein	2005		10.1145/1187112.1187190	character animation;computer vision;tessellation;t-spline;data structure;computer science;trimming;level of detail;programming language;computer graphics (images)	Vision	67.11653974418034	-50.5507547836155	158452
3f310432f81d27ed45a0127264c18519e8e30e87	reflections on the generalized bas-relief ambiguity	stereo image processing image reconstruction computational geometry computer graphics photometry;computer graphics;stereo image processing generalized bas relief ambiguity general nonconvex surfaces gbr ambiguity euclidean geometry uncalibrated photometric stereo image reconstruction computational geometry computer graphics photometry;computational geometry;photometry;photometric stereo;image reconstruction;stereo image processing;euclidean geometry;reflection stereo vision photometry image reconstruction lighting light sources kernel surface reconstruction radiometry computer vision;matematik	Prior work has argued that when a Lambertian surface in fixed pose is observed in multiple images under varying distant illumination, there is an equivalence class of surfaces given by the generalized bas-relief (GBR) ambiguity that could have produced these images. In contrast, this paper shows that for general nonconvex surfaces, interreflections completely resolve the GBR ambiguity. In turn, the full Euclidean geometry can be recovered from uncalibrated photometric stereo for which the light source directions and strengths are unknown. Further, we show that surfaces with a translational symmetry do not lend enough constraints to be disambiguated by inter reflections.	lambertian reflectance;photometric stereo;reflection (computer graphics);subpixel rendering;turing completeness	Manmohan Krishna Chandraker;Fredrik Kahl;David J. Kriegman	2005	2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)	10.1109/CVPR.2005.299	iterative reconstruction;computer stereo vision;euclidean geometry;computer vision;photometric stereo;photometry;computational geometry;computer science;mathematics;geometry;computer graphics;computer graphics (images)	Vision	54.8633494238015	-51.618898544643194	158539
1c42993aa0ed167002c1187f31743a8fb4192a57	the dlr multisensory hand-guided device: the laser stripe profiler	deformations assessment dlr laser stripe profiler dlr multisensory hand guided device 3d modeling reconstruction process laser plane self calibration optical filtering robust stripe segmentation algorithm miscalibration;image segmentation;optical filters;calibration optical filters laser modes biomedical optical imaging optical sensors image reconstruction filtering robustness computer vision image segmentation;ccd image sensors;3d model;ccd image sensors laser beam applications modelling image segmentation image reconstruction calibration filtering theory sensor fusion;image reconstruction;institut fur robotik und mechatronik bis 2012;sensor fusion;laser beam applications;calibration;filtering theory	This paper presents the DLR Laser Stripe Profiler as a component of the DLR multisensory Hand-Guided Device for 3D modeling. After modeling the reconstruction process, we propose a novel method for laser plane self-calibration based on the assessment of the deformations the miscalibration leads to. In addition, the requirement for absence of optical filtering implies the development of a robust stripe segmentation algorithm. Experiments demonstrate the validity and applicability of the approaches.	3d modeling;algorithm;dynamic language runtime;experiment;magnetic stripe card;stripes	Klaus H. Strobl;Wolfgang Sepp;Eric Wahl;Tim Bodenmüller;Michael Suppa;Javier F. Seara;Gerd Hirzinger	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1308105	iterative reconstruction;computer vision;calibration;simulation;computer science;engineering;optical filter;sensor fusion;image segmentation;optics	Robotics	55.978592669247085	-48.004088930545485	158548
4f611f614629366506226fb60438f8f4b5c55315	efficient absolute orientation revisited		Absolute orientation estimation is the determination of the similarity transformation between two sets of corresponding $\pmb{3}\mathbf{D}$ points, a task arising frequently in computer vision and robotics. We have recently proposed an absolute orientation algorithm based on the Fast Optimal Attitude Matrix (FOAM) algorithm from astronautics and demonstrated that it is more efficient computationally compared to widely-used approaches involving costly eigen- and singular-value matrix decompositions. In this work, we compare our FOAM-based solution with several more algorithms derived from attitude estimation techniques and show that further computational savings are possible by employing an algorithm grounded on the Optimal Linear Attitude Estimator (OLAE) method.		Manolis I. A. Lourakis;George Terzakis	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8594296	quaternion;computer vision;estimator;computer science;matrix similarity;astronautics;matrix decomposition;matrix (mathematics);symmetric matrix;algorithm;artificial intelligence;robotics	Robotics	56.29432913294097	-40.74082351435883	158605
99dfd58c91bf38efa2888494eaf67e3d4593030a	halftoning colour volume datasets based on subdivision	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;rapid prototyping;digital halftoning;ciencias basicas y experimentales;volume datasets;tecnologias;coloured models;quantization error	The algorithm for halftoning 2D gray scale images based on subdivision was extended to the processing of colour volume datasets. Two main improvements were made. The first is adding a procedure to deal with cases with large errors so as to reduce the total quantizing error. The second is randomizing the directions in which errors are propagated, assuring the even distribution of the halftoned binary voxels. In addition, a method used to process large volume datasets was also proposed. The new algorithm is simple in principle, but produces good halftoning results, especially in the boundary regions. It is especially applicable in the data preparation for the rapid forming of coloured models and heterogeneous objects.	subdivision surface	Dong-Xing Wang;Dong-ming Guo;Zhen-yuan Jia;Lian-hui Jiang	2004	Computer-Aided Design	10.1016/j.cad.2004.02.008	quantization;computer science;error diffusion;engineering drawing;algorithm;computer graphics (images)	EDA	67.50618210960673	-44.863964766425354	158878
3aba2583d04f249df9f2cd5aa79524260fe17f80	geometrically valid view rendering from sparse correspondence			sparse	Moulay A. Akhloufi;Paul Cohen;Vladimir Polotski	1999			rendering (computer graphics);computer vision;artificial intelligence;computer graphics (images);computer science	Vision	57.719388622630944	-51.225897253568796	158921
3b3d62e3040989bdeda0be1c08be64b89369f5e6	machine vision mensuration	machine vision		machine vision	Robert M. Haralick	1987	Computer Vision, Graphics, and Image Processing	10.1016/S0734-189X(87)80143-3	computer vision;computer science	Vision	58.92637502655257	-42.67253474518029	159084
97786203ba7cf433479a80b3c91b843df39fe01c	3d modeling from multiple views with integrated registration and data fusion	robot sensing systems;surface mapping;coloured three dimensional representation;frequency registration;object modeling;integrable model;frequency domain analysis;image fusion;structured light;data fusion;layout costs image reconstruction iterative closest point algorithm frequency domain analysis calibration robot sensing systems frequency estimation clouds computer vision;three dimensional;scene reconstruction;multiple views;3d model;a priori knowledge;frequency domain based registration algorithm;three dimensional displays;image color analysis;image colour analysis;image representation;feature extraction;image reconstruction;image registration;integrated image registration;frequency domain based registration algorithm 3d modeling system integrated image registration data fusion coloured three dimensional representation surface mapping;frequency domain;meteorology;3d modeling system;solid modelling;data fusion scene reconstruction object modeling structured light frequency registration;solid modelling frequency domain analysis image colour analysis image fusion image registration image representation;object model	This paper presents an integrated modeling system capable of generating coloured three dimensional representations of a scene observed from multiple viewpoints. Emphasis is given to the integration of the components and to the algorithms used for acquisition, registration and final surface mapping. First, a sensor operating with structured light is used to acquire 3D and colour data of a scene from multiple views. Second, a frequency-domain based registration algorithm computes the transformation between pairs of views from the raw measurements and without a priori knowledge on the transformation parameters. Finally, the registered views are merged together and refined to create a rich 3D model of the objects. Real world modeling examples are presented and analyzed to validate the operation of the proposed integrated modeling system.	3d modeling;algorithm;structured light	Alain Boyer;Phillip Curtis;Pierre Payeur	2009	2009 Canadian Conference on Computer and Robot Vision	10.1109/CRV.2009.39	computer vision;object model;system model;computer science;pattern recognition;frequency domain;computer graphics (images)	Vision	57.1093887896172	-49.31073612892357	159132
1c69cf6afc9b36205ab77651d0d9fab4d75a6353	fast and resolution independent line integral convolution	texture synthesis;phase shift;scientific visualization;vector field visualization;line integral convolution;vector data;computer animation;vector field;periodic motion filtering;high spatial resolution;decay of correlations	Line Integral Convolution (LIC) is a powerful technique for generating striking images and animations from vector data. Introduced in 1993, the method has rapidly found many application areas, ranging from computer arts to scientific visualization. Based upon locally filtering an input texture along a curved stream line segment in a vector field, it is able to depict directional information at high spatial resolutions. We present a new method for computing LIC images. It employs simple box filter kernels only and minimizes the total number of stream lines to be computed. Thereby it reduces computational costs by an order of magnitude compared to the original algorithm. Our method utilizes fast, error-controlled numerical integrators. Decoupling the characteristic lengths in vector field grid, input texture and output image, it allows computation of filtered images at arbitrary resolution. This feature is of significance in computer animation as well as in scientific visualization, where it can be used to explore vector data by smoothly enlarging structure of details. We also present methods for improved texture animation, again employing box filter kernels only. To obtain an optimal motion effect, spatial decay of correlation between intensities of distant pixels in the output image has to be controlled. This is achieved by blending different phase-shifted box filter animations and by adaptively rescaling the contrast of the output frames. CR Categories: I.3.3 [Computer Graphics]: Picture/Image generation; I.3.6 [Computer Graphics]: Methodology and Techniques; I.4.3 [Image Processing]: Enhancement Additional	algorithm;alpha compositing;computation;computer animation;computer graphics;coupling (computer programming);image processing;line integral convolution;numerical analysis;pixel;scientific visualization;smoothing	Detlev Stalling;Hans-Christian Hege	1995		10.1145/218380.218448	computer vision;scientific visualization;vector field;line integral convolution;computer science;theoretical computer science;geometry;computer animation;phase;texture synthesis;computer graphics (images)	Graphics	65.88070472845865	-50.14351257627542	159189
07e76bcc30a4820264092bb8f0d0808f623e95ce	connectivity shapes	graph theory;natural embedding;implicit geometry;data visualisation;shape compression;polygon meshes;mesh connectivity;mesh generation	We describe a method to visualize the connectivity graph of a mesh using a natural embedding in 3D space. This uses a 3D shape representation that is based solely on mesh connectivity --- the connectivity shape. Given a connectivity, we define its natural geometry as a smooth embedding in space with uniform edge lengths and describe efficient techniques to compute it. Our main contribution is to demonstrate that a surprising amount of geometric information is implicit in the connectivity.We also show how to generate connectivity shapes that approximate given 3D shapes. Potential applications of connectivity shapes to modeling and mesh coding are described.	approximation algorithm	Martin Isenburg;Stefan Gumhold;Craig Gotsman	2001	Proceedings Visualization, 2001. VIS '01.		mesh generation;combinatorics;topology;graph theory;mathematics;geometry;data visualization	Visualization	68.25234141905393	-45.04136820012325	159217
ad9a756b5ff032c4e598cc61496f284f989e1bb4	shape context preserving deformation of 2d anatomical illustrations	shape deformation;shape context;illustrative visualization;anatomical illustration;i 3 3 computer graphics picture image generation	In this paper we present a novel 2D shape context preserving i mage manipulation approach which constructs and manipulates a 2D mesh with a new differential mesh editin g algorithm. We introduce a novel shape context descriptor and integrate it into the deformation frame work, facilitating shape-preserving deformation for 2D anatomical illustrations. Our new scheme utilizes an analo gy based shape transfer technique in order to learn shape styles from reference images. Experimental results s how that visually plausible deformation can be quickly generated from an existing example at interactive frame rat s. An experienced artist has evaluated our approach and his feedback is quite encouraging.	3d projection;algorithm;algorithmic efficiency;blackwell (series);computation;computer graphics;eurographics;frame language;graphics processing unit;ibm notes;linear system;rendering (computer graphics);shading;shape context;simulation;volume rendering	Wei Chen;Xiao Liang;Ross Maciejewski;David S. Ebert	2009	Comput. Graph. Forum	10.1111/j.1467-8659.2008.01300.x	active shape model;computer vision;computer science;computer graphics (images)	Graphics	66.97902002131084	-46.13995057223099	159286
e5a553b8bc5c75161fdc4529d569a03b1a6bde4d	topology-adaptive modeling of objects using surface evolutions based on 3d mathematical morphology	mathematical morphology;information systems;hardware and architecture;theoretical computer science;pseudo curvature flow;topology adaptive object modeling;computational theory and mathematics;surface evolution;level set method	Fukuoka-shi, 812–8581 Japan じた曲面が必ず得られるという特長がある. 変形可能曲面の問題点として,曲面変形の過程で分 裂や統合といった位相の変化を生じることができず, 任意の位相の物体をモデリングすることが困難であ ることが挙げられる.この問題の解決のため,ブレン ディング(blending)と呼ばれる形状表現を用いて曲 面変形を行う位相適応型のモデリング手法 [6] が提案 され,穴をもつ物体のモデリングが可能になった.し かし,この手法は単一の閉曲面モデルに穴を生成する もので,複数の物体からなるシーンへの適用は困難で ある. これに対し,等高面法(Level Set Method)[7]~[9] を用いたモデリング手法(以下,等高面モデリング手 法)が提案されている [10].この手法は穴のある物体 だけでなく複数の物体からなるシーンなど,任意の位 相の物体をモデリングすることができる.等高面法は, 運動方程式に従う曲面の形状進化(surface evolution) を追跡するため,曲面を一つ次元の高い 4次元空間内 のある補助関数のゼロ等高面とみなし,この補助関数 に関する方程式を解析する方法である.これにより, 分裂などで微分不可能な点が生じた後の曲面の追跡や 曲面の自己交差の回避が可能になる.しかし,距離変 換の反復や次元の追加を伴い,計算量や記憶容量の点	mathematical morphology	Kenji Hara;Hongbin Zha;Tsutomu Hasegawa	2002	Systems and Computers in Japan	10.1002/scj.1152	mathematical morphology;computer science;electrical engineering;artificial intelligence;theoretical computer science;machine learning;mathematics;geometry;information system;level set method;algorithm;statistics	Vision	65.7019472725472	-43.255091303517844	159465
70351083c8c1ccb6a202dfb2aa3608bf52083bd1	material classification based on training data synthesized using a btf database		To cope with the richness in appearance variation found in real-world data under natural illumination, we propose to synthesize training data capturing these variations for material classification. Using synthetic training data created from separately acquired material and illumination characteristics allows to overcome the problems of existing material databases which only include a tiny fraction of the possible real-world conditions under controlled laboratory environments. However, it is essential to utilize a representation for material appearance which preserves fine details in the reflectance behavior of the digitized materials. As BRDFs are not sufficient for many materials due to the lack of modeling mesoscopic effects, we present a high-quality BTF database with 22,801 densely measured view-light configurations including surface geometry measurements for each of the 84 measured material samples. This representation is used to generate a database of synthesized images depicting the materials under different view-light conditions with their characteristic surface geometry using image-based lighting to simulate the complexity of real-world scenarios. We demonstrate that our synthesized data allows classifying materials under complex real-world scenarios.	automatic identification and data capture;bidirectional texture function;data compression;database;image-based lighting;mesoscopic physics;noether's theorem;simulation;software release life cycle;synthetic data;synthetic intelligence	Michael Weinmann;Juergen Gall;Reinhard Klein	2014		10.1007/978-3-319-10578-9_11	data mining;database;world wide web	Graphics	61.12446369075982	-51.1474626323431	159513
5a11ba25cd048f384a83882a5a4dc25db9493b80	massive city-scale surface condition analysis using ground and aerial imagery		Automated visual analysis is an effective method for understanding changes in natural phenomena over massive city-scale landscapes. However, the view-point spectrum across which image data can be acquired is extremely wide, ranging from macro-level overhead (aerial) images spanning several kilometers to micro-level front-parallel (streetview) images that might only span a few meters. This work presents a unified framework for robustly integrating image data taken at vastly different viewpoints to generate large-scale estimates of land surface conditions. To validate our approach we attempt to estimate the amount of post-Tsunami damage over the entire city of Kamaishi, Japan (over 4 million square-meters). Our results show that our approach can efficiently integrate both micro and macro-level images, along with other forms of meta-data, to efficiently estimate city-scale phenomena. We evaluate our approach on two modes of land condition analysis, namely, city-scale debris and greenery estimation, to show the ability of our method to generalize to a diverse set of estimation tasks.	aerial photography;closed-circuit television;computational resource;effective method;experiment;file spanning;gaussian process;global positioning system;google street view;image resolution;mobile device;overhead (computing);unified framework	Ken Sakurada;Takayuki Okatani;Kris M. Kitani	2014		10.1007/978-3-319-16865-4_4	computer vision	Vision	56.430501113438964	-44.4460102117516	159573
83ddb672abe1cd14ca8223ed7714be5fd27a01bc	automatic generation of sphere hierachies from cad data	path planning data structures computational geometry robots;path planning;computational geometry;automatic generation;geometric modelling;collision detection;factor analysis;data structures;robots;motion planning;geometric model;branching factor analysis automatic generation sphere hierarchies cad data collision detection motion planning geometric model;solid modeling algorithm design and analysis performance evaluation testing binary trees shape measurement laboratories data engineering data structures road accidents;data structure	A sphere hierarchy is a data structure that approximates the shape of a given object using a collection of spheres. They can be used for collision detection, motion planning and other related applications. This paper presents an algorithm for constructing an efficient sphere hierarchy from a geometric model of an object, as supplied by a CAD system or geometric modeller and it presents a branching factor analysis based on a general measure of the efficiency of a sphere hierarchy.	computer-aided design	Joe Pitt-Francis;Roy Featherstone	1998		10.1109/ROBOT.1998.676414	data structure;computer science;artificial intelligence;theoretical computer science;geometry;motion planning;engineering drawing	Robotics	65.7485958415892	-39.76040890426043	159585
9562647e9d2918c07e376e9d0f1a06e346fd0bef	federated information fusion technology for sins/cns/smns integrated navigation system	cns;gyroscopes;estimation theory;optimum estimation theory;integrated navigation system;information fusion technology;sins cns smns integrated navigation;stored reference;inertial navigation;measurement uncertainty;satisfiability;missiles;silicon compounds image segmentation image sensors equations error correction missiles aircraft navigation computer errors layout earth;navigation;smns information fusion integrated navigation system sins cns;estimation;missiles estimation theory gyroscopes inertial navigation;silicon compounds;sins;mathematical model;information fusion;navigation system;primary navigation errors;cruise missiles;smns;cruise missiles information fusion technology sins cns smns integrated navigation primary navigation errors optimum estimation theory;aircraft navigation	The integrated principle of SINS/CNS/SMNS is investigated, and a federated information fusion method for the integrated navigation system is founded. On account of primary navigation errors of SINS aroused by the errors of initial position, attitude alignment and inertia sensors, a novel independent navigation scheme of using CNS and SMNS to update SINS is proposed. When the cruise missile had been flying 25 km off the earth's surface, making use of the measurement information of CNS, the mathematical platformpsilas error angles of SINS were deduced. Then, utilizing optimum estimation theory, the gyroscope drifts have been acquired, and accumulated errors of velocity and position are updated. At the end of flight-path, in order to ulteriorly correct the errors of SINS, utilizing SMNS to acquire the real-time image, it had been matched with the stored reference image of corresponding region in computer. The simulating results show that the federated information fusion of using CNS and SMNS to revise SINS is reasonable and feasible, and this independent integrated navigation system can satisfy high precise navigation demand of cruise missiles.	cns;estimation theory;gyroscope;real-time transcription;sensor;simulation;velocity (software development)	Xinlong Wang;Jie Yu;Shan Ma	2008	2008 IEEE Pacific-Asia Workshop on Computational Intelligence and Industrial Application	10.1109/PACIIA.2008.254	computer vision;estimation;navigation;simulation;cruise missile;gyroscope;mathematical model;inertial navigation system;estimation theory;statistics;measurement uncertainty;satisfiability	Robotics	56.462569860824274	-38.68733576334863	159601
0913157371300faddbb0f7c6aa1789c1770cb164	an improved rendering technique for active-appearance-model-based automated age progression	post production;stereo 3d	Age progression is the process of creating images that suggest how a person may appear in a certain amount of time based on the effects of the aging process. Traditionally these images have been created manually by forensic artists who use both art and science to guide how representations appear, whether drawn or photo-manipulated. Automated age-progression seeks to use algorithmic methods to create accurate images of how the individual in a photo could appear after aging effects. It is still a fairly young area of research, but one promising technique suggested so far has been to use parametrically driven face models such as Active Appearance Models to modify the face appearance in an image based on a data-driven model of face aging. These can be successful but tend to suffer from reconstructed texture artifacts.	active appearance model;algorithm;color gradient;compression artifact	Eric Patterson;Amrutha Sethuram;Karl Ricanek	2013		10.1145/2503385.2503451	computer vision;simulation;post-production;computer science;computer graphics (images)	Graphics	62.77017142043893	-49.68125075027184	159703
02679ab8be328b902c1094f9742731ca501cfc1d	inverse global illumination: recovering reflectance models of real scenes from photographs	hierarchical partitioning;radiance;image based modeling and rendering;high resolution;global illumination;specular reflection;polygonal meshes;reflection model;reflectance recovery;geometric model;radiosity;brdf models;synthetic data;high dynamic range;image based rendering;albedo maps;high light;rendering	In this paper we present a method for recovering the reflectance properties of all surfaces in a real scene from a sparse set of photographs, taking into account both direct and indirect illumination. The result is a lighting-independent model of the scene’s geometry and reflectance properties, which can be rendered with arbitrary modifications to structure and lighting via traditional rendering methods. Our technique models reflectance with a lowparameter reflectance model, and allows diffuse albedo to vary arbitrarily over surfaces while assuming that non-diffuse characteristics remain constant across particular regions. The method’s input is a geometric model of the scene and a set of calibrated high dynamic range photographs taken with known direct illumination. The algorithm hierarchically partitions the scene into a polygonal mesh, and uses image-based rendering to construct estimates of both the radiance and irradiance of each patch from the photographic data. The algorithm computes the expected location of specular highlights, and then analyzes the highlight areas in the images by running a novel iterative optimization procedure to recover the diffuse and specular reflectance parameters for each region. Lastly, these parameters are used in constructing high-resolution diffuse albedo maps for each surface. The algorithm has been applied to both real and synthetic data, including a synthetic cubical room and a real meeting room. Rerenderings are produced using a global illumination system under both original and novel lighting, and with the addition of synthetic objects. Side-by-side comparisons show success at predicting the appearance of the scene under novel lighting conditions. CR Categories: I.2.10 [Artificial Intelligence ]: Vision and Scene Understanding—modeling and recovery of physical attributes I.3.7 [ Computer Graphics]: Three-dimensional Graphics and Realism—color, shading, shadowing, and texture I.3.7 [ Computer Graphics]: Three-Dimensional Graphics and Realism— Radiosity I.4.8 [ Image Processing]: Scene Analysis—Color, photometry, shading	algorithm;artificial intelligence;computer graphics;geometric modeling;global illumination;high dynamic range;image processing;image resolution;iterative method;map;mathematical optimization;polygon mesh;radiosity (computer graphics);shading;sparse language;sparse matrix;specular highlight;synthetic data;synthetic intelligence	Yizhou Yu;Paul E. Debevec;Jitendra Malik;Tim Hawkins	1999		10.1145/311535.311559	computer vision;image-based modeling and rendering;computer science;computer graphics (images)	Graphics	58.1397652099873	-51.779313400939216	159712
a90718f6e8c74df8ed7870e13437caf3bac13129	"""a comment on """"a novel approach for the registration of weak affine images"""""""	affine subgroups;weak affine transform;area preserving affine transform;affine transform;image registration	In the recent paper (Li and Zhang, 2012) a mapping model of weak affine transform (WAT) was proposed for registering images of flat scenes. We show that such a model may cause inaccuracies when registering images with non-uniform scaling differences, even if they seemingly behave according to this model. Mathematical reason of this is that WAT is neither invertible nor closed. We explain why mapping models forming a group should be preferably used for registration and show some examples of models belonging to affine subgroups. 2013 Elsevier B.V. All rights reserved.	image registration;image scaling	Jan Flusser;Barbara Zitová	2013	Pattern Recognition Letters	10.1016/j.patrec.2013.04.024	affine geometry;affine space;complex space;combinatorics;discrete mathematics;affine coordinate system;affine involution;computer science;affine plane;image registration;affine geometry of curves;affine hull;affine transformation;harris affine region detector;mathematics;geometry;affine shape adaptation;affine combination;affine group	Vision	54.48107811841574	-51.94404616881267	159835
8c85b032fd1458cad3708811aa44289469c5315f	rapid and authentic rendering of translucent materials using depth-maps from multi-viewpoint	training;virtual reality;welding;visualization;real time graphics	We present a real-time rendering method of translucent materials with complex shape by estimating object's thickness between light source and view point precisely. Wang et al. [2010] has already proposed a real-time rendering method treating arbitrary shapes, but it requires such huge computational costs and graphics memories that it is very difficult to implement in a practical rendering pipe-line. Inside a translucent object, the energy of incident light attenuates highly depends on the object's optical thickness. Translucent Shadow Maps (TSM) [2003] is able to compute object's thickness using depth map at light position. However, TSM is not able to calculate thickness accurately in concave objects.	concave function;depth map;graphics;optical fiber;ray (optics);real-time clock;shadow mapping;thickness (graph theory)	Takahiro Kosaka;Tomohito Hattori;Hiroyuki Kubo;Shigeo Morishima	2012		10.1145/2407156.2407206	computer vision;visualization;rendering;computer science;virtual reality;welding;computer graphics (images)	Graphics	63.17184825017267	-51.14096330309462	159912
e6aec48546da43f626440702eeb5ce1b320f6aa5	processing terrain point cloud data	adaptive splines;41a15;65d18;surface reconstruction;point clouds;65d17;hausdorff metric;compression	Terrain point cloud data are typically acquired through some form of Light Detection And Ranging sensing. They form a rich resource that is important in a variety of applications including navigation, line of sight, and terrain visualization. Processing terrain data has not received the attention of other forms of surface reconstruction or of image processing. The goal of terrain data processing is to convert the point cloud into a succinct representation system that is amenable to the various application demands. The present paper presents a platform for terrain processing built on the following principles: (i) measuring distortion in the Hausdorff metric, which we argue is a good match for the application demands, (ii) a multiscale representation based on tree approximation using local polynomial fitting. The basic elements held in the nodes of the tree can be efficiently encoded, transmitted, visualized, and utilized for the various target applications. Several challenges emerge because of the variable resolution of the data, missing data, occlusions, and noise. Techniques for identifying and handling these challenges are developed.	approximation;distortion;hausdorff dimension;image processing;missing data;point cloud;polynomial;terrain rendering	Ronald A. DeVore;Guergana Petrova;Matthew Hielsberg;Luke Owens;Billy Clack;Alok Sood	2013	SIAM J. Imaging Sciences	10.1137/110856009	hausdorff distance;terrain rendering;computer vision;mathematical optimization;simulation;surface reconstruction;machine learning;point cloud;mathematics;compression	Robotics	56.695506035848155	-45.37360447111899	159926
1616704882c80d6d741462ebd667cdcba26335d4	the synthesis of trees in chinese landscape painting using silhouette and texture strokes	and texture generation.;texture strokes;silhouette;non-photorealistic rendering npr;brush;curvature map;ts'un;chinese landscape painting;three dimensional;non photorealistic rendering	"""d for more than three thousand years, Chinese painting emphasizes """"implicit meaning"""", and painters’ using a minimal number of brush strokes to express their deepest feelings. Landscapes of the most important themes in Chinese painting. Trees are the essential painting objects. This resents a set of novel methods to automatically draw trees in Chinese ink painting from 3D al models. Outline rendering and texture generation uses the information of the silhouette, shade ntation of three-dimensional model’s surface to draw a particular tree. Four reference maps are ed to analyze the information for the bark texture. These methods can draw various styles of bark y defining the texture patterns. Finally, this paper demonstrates some results obtained with our ds: Non-Photorealistic Rendering (NPR), Chinese Landscape Painting, TS’UN, Texture Strokes, te, Curvature Map, Brush, and Texture Generation."""	3d modeling;map;non-photorealistic rendering;tree (data structure)	Der-Lor Way;Yu-Ru Lin;Zen-Chung Shih	2002			silhouette;computer graphics (images);computer vision;non-photorealistic rendering;artificial intelligence;computer science;painting	Graphics	64.66386027301733	-46.805415271835855	159973
7fe26513f9c927dadca58cf138cc944ebf363f19	calibration method for stereovision measurement of high-temperature components using two infrared cameras	edge detection;stereovision;infrared image;ceramic spherical calibration		stereopsis	Le Song;Zihui Zhang	2013	IJAT	10.20965/ijat.2013.p0163	computer vision;optics;remote sensing	Robotics	59.62421132956165	-42.936196891532205	160448
33ca1182b91c3983c018da295d4826608176871e	visually navigating the rms titanic with slam information filters	underwater vehicles;information filtering;visual navigation;data association;simultaneous localization and mapping;linear equations;inertial sensor;covariance estimation	This paper describes a vision-based, large-area, simultaneous localization and mapping (SLAM) algorithm that respects the low-overlap imagery constraints typical of underwater vehicles while exploiting the inertial sensor information that is routinely available on such platforms. We present a novel strategy for efficiently accessing and maintaining consistent covariance bounds within a SLAM information filter, thereby greatly increasing the reliability of data association. The technique is based upon solving a sparse system of linear equations coupled with the application of constant-time Kalman updates. The method is shown to produce consistent covariance estimates suitable for robot planning and data association. Real-world results are presented for a vision-based 6-DOF SLAM implementation using data from a recent ROV survey of the wreck of the RMS Titanic.	algorithm;correspondence problem;kalman filter;linear equation;simultaneous localization and mapping;system of linear equations	Ryan M. Eustice;Hanumant Singh;John J. Leonard;Matthew R. Walter;Robert Ballard	2005		10.15607/RSS.2005.I.008	estimation of covariance matrices;computer vision;simulation;computer science;artificial intelligence;mathematics;linear equation;statistics;simultaneous localization and mapping	Robotics	54.63163943222067	-38.65370563364797	160472
3f982e605d7b0dc8ad4721a48cf160b68f1b1a26	a strategy to support application's dependent features interpretation	problem complexity;geometric model	Products have different meanings, according to technological viewpoints. They tend to be constituted by an aggregate of specific models linked by functional constraints. Each model fulfils functionalities through specific shapes, that can have multiple interpretations. In this paper a product is considered as an initial gross shape that has been sequentially altered through the introduction of form features. Then, the strategy to recognize the form features is to reconstruct the gross shape step by step, after each detection of an alteration by a form feature. This has the advantage of reducing the problem complexity since it removes progressively the feature's interactions. Some applications, such as FEA, need to interpret the product depending on the viewpoint applied: some features are to be removed, others are to be replaced by idealized ones. This abstraction process has two parts: simplification and idealization. The simplification is based on the described strategy and c leans out the initial model from any non-pertinent feature. The second one idealizes the resulting objects according to analysis goal.		Abdelaziz Bouras;Mohamed Belaziz;A. Tehari;G. Wahu;Jean-Marc Brun	1999	J. Intelligent Manufacturing	10.1023/A:1008964413512	feature recognition;mathematical optimization;simulation;computer science;artificial intelligence;geometric modeling;machine learning;mathematics;algorithm	Robotics	64.93836936042267	-42.14860834684584	160476
7fedd79347eedecb5059b8d5c069c6424f17174d	avenue: automated site modeling in urban environments	urban environment;urban planning;model system;mobile robot;mobile agents;texture mapping;geometry;mobile robots;layout;urban environments;3 d modeling system;photometry buildings solid modeling layout cities and towns urban planning graphics geometry mobile agents gold;gold;new york city;site modeling;model building;mobile robots image reconstruction image registration;photometry;image reconstruction;image registration;solid modeling;next best view;cities and towns;geometric model;photometric texture mapping;next best view urban environments site modeling 3 d modeling system 3 d geometric models photometric texture mapping;buildings;graphics;3 d geometric models	This paper is an overview of the AVENUE project at Columbia University. AVENUE's main goal is to automate the site modeling process in urban environments. The rst component of AVENUE is a 3-D modeling system which constructs complete 3-D geometric models with photometric texture mapping acquired from di erent viewpoints. The second component is a planning system that plans the Next-BestView for acquiring a model of the site. The third component is a mobile robot we have built that contains an integrated sensor suite for automatically performing the site modeling task. We present results for modeling buildings in New York City.	3d modeling;columbia (supercomputer);mobile robot;texture mapping	Peter K. Allen;Ioannis Stamos;Atanas Gueorguiev;Ethan Gold;Paul Blaer	2001		10.1109/IM.2001.924477	mobile robot;computer vision;simulation;radiology;computer science;urban planning;geometry;computer graphics (images)	Robotics	57.785251382833756	-47.48321322784499	160561
3d72c7cba497fef55c8875e502f9d774939f3c0d	merging multiple b-spline surface patches in a virtual reality environment	modeling and simulation;blending matrices;real time;merging of b;virtual reality;b spline surface;merging of b spline surfaces;virtual reality environment;computational efficiency;haptic interaction	Although a number of different algorithms have been described in the literature for merging two or more B-spline/Bézier curves and stitching B-spline surfaces, these techniques are not suitable for virtual reality applications that require the user to effortlessly combinemultiple dissimilar patches in real-time to create the final object shape. This paper presents a novel approach formerging arbitrary B-spline surfaceswithin a very low tolerance limit. The technique exploits blending matrices that are independent of the control point positions and, hence, can be pre-calculated prior to haptic interaction. Once determined, the precalculated blending matrices are used to generate discrete points on the B-spline surface. When two or more surfaces are merged, these discrete point matrices are combined to form a single matrix that represents the resultant shape. By using the inverse of the revised blending matrices and the combined discrete point matrix, a new set of control points can be directly computed. The merged surface can be made to have C0, C1 or higher connectivity at the joining edge. A brief study comparing the proposed merging techniquewith a commercially available CAD system is presented and the results show improved computational efficiency, accuracy, and robustness. Crown Copyright© 2010 Published by Elsevier Ltd. All rights reserved.	algorithm;alpha compositing;bézier curve;collision detection;computation;computational complexity theory;computer-aided design;control point (mathematics);crown group;non-uniform rational b-spline;real-time transcription;requirement;resultant;scott continuity;spline (mathematics);virtual reality	Harish Pungotra;George K. Knopf;Roberto Canas	2010	Computer-Aided Design	10.1016/j.cad.2010.05.006	computer vision;computer science;engineering;modeling and simulation;virtual reality;engineering drawing;computer graphics (images)	Graphics	66.69511696679899	-44.35766085372445	160678
abc16fb9195c68cacea9f361c8f7607b5ebc87c5	minimisation of alignment error between a camera and a laser range finder using nelder-mead simplex direct search	optimisation;error reduction;light detection and ranging;alignment error;light detection and ranging alignment error laser range finder nelder mead simplex direct search 2d image coordinates sensor fusion lidar optimisation calibration parameter reprojected data error reduction;search methods;search method;laser radar;contracts;minimization methods;usa councils;laser ranging;calibration parameter;cameras calibration sensor fusion laser radar minimization methods search methods mechanical variables measurement optimization methods intelligent vehicles usa councils;reprojected data;laser range finder;optical radar;nelder mead simplex direct search;intelligent vehicles;pixel;transforms;sum of squares;reference data;nelder mead;2d image coordinates;optimization;search problems;sensor fusion calibration cameras laser ranging optical radar optimisation search problems;sensor fusion;direct search;mechanical variables measurement;calibration;cameras;lidar;optimization methods	Presented in this paper is a novel method to calibrate the co-ordinate systems used by two separate sensor devices for the purposes of sensor fusion. In this example the sensors are a camera and a LIDAR device which are observing the same scene from different viewpoints. Using a synthetic set of corresponding 2D image co-ordinates and 3D LIDAR measurements as reference data the task of aligning re-projected measurements with reference measurements was posed as an optimisation problem. The objective of the optimisation is to find a set of calibration parameters (external offsets and internal camera parameters) which minimise the sum of squared errors between the reference image co-ordinates and the re-projected data. The re-projected data is obtained by transforming the reference LIDAR measurements using the calibration parameters and the errors are defined as the straight-line distance between each reference and re-projected pixel pair. Using the Nelder-Mead simplex search method calibration parameters were found in under a second such that the sum of squared errors across a data set of 200 points was less than 0.19 i.e. average error per pixel of 0.031px. The method finds both internal and external calibration factors and makes no assumptions about the model. Furthermore if a second optimisation pass is made the error can be reduced to almost zero using only 4 reference pairs assuming these points are selected correctly.	align (company);data point;distortion;image sensor;mathematical optimization;maxima and minima;nelder–mead method;pixel;reference implementation;simplex algorithm;synthetic intelligence;test card	Thomas James Osgood;Yingping Huang;Ken Young	2010	2010 IEEE Intelligent Vehicles Symposium	10.1109/IVS.2010.5548126	computer vision;geography;optics;remote sensing	Vision	54.19254947433423	-49.546424166986746	160763
0dd1018c04d766989c08a151d810f1875e9a3322	mesh generation methods over plane and curved surfaces	ruled;structured and unstructured meshes;. surface mesh g eneration;quadric and revolution surfaces;multiblock methods;advancing front;transfinite interpolation;surface of revolution;two dimensions;mesh generation	In this paper, a set of mesh generation methods over plane and curved surfaces is presented. The surfaces can be plane, just defined by their boundary (as cylinders or cones), quadrics, surfaces of revolution or a combination of these by means of a multiblock definition. The basic method for plane surfaces and those defined by their boundary is based on a advancing front / algebraic combined technique for two dimensions. Quadrics and surfaces of revolution are transformed from the real space into a parametric plane, in which the previous basic method can be applied and, later, the inverse transformation is done to obtain the final mesh.	linear algebra;mesh generation;shanks transformation	Alejandro Díaz-Morcillo;Agustín Bernal-Ros;Luis Nuño	1998			geometry;laplacian smoothing;mesh generation;surface of revolution;mathematics	Robotics	68.0974793786154	-41.57628901396516	160795
b8a3f5868e3e9f0cb2c2e7d458dd015a3de5d829	incremental updating of 3d topological maps to describe videos	combinatorial maps;video processing;3d topological maps	A topological map is an efficient mathematical model for representing an image subdivision where all cells and adjacency relations between elements are represented. It has been proved to be a very good tool for video processing when video is seen as a 3D image. However the construction of a topological map for representing a video needs the availability of the complete image sequence. In this paper we propose a procedure for online updating a topological map in order to build it as the video is produced, allowing to use it in real time.	iteration;map;mathematical model;mathematical optimization;microsoft windows;noise reduction;online algorithm;parallel computing;quantum superposition;real-time clock;speedup;stereoscopy;streaming media;subdivision surface;surfel;video processing;window function	Guillaume Damiand;Sylvain Brandel;Donatello Conte	2015		10.1007/978-3-319-26145-4_22	generalized map;computer vision;computer science;theoretical computer science;machine learning;quasi-open map;mathematics;video processing	Vision	61.676767318068045	-49.48545222359933	160865
1b67a3d3ebe9f84fabd0af64561428a0730fd131	prisad: a partitioned rendering infrastructure for scalable accordion drawing	computational geometry;data visualisation;rendering (computer graphics);prisad;priseq;pritree;sequencejuxtaposer;treejuxtaposer;dataset traversal;incorrect visual representation;information visualization;pixel based drawing;progressive rendering;real time rendering;rendering infrastructure;rubber sheet navigation;scalable accordion drawing	We present PRISAD, the first generic rendering infrastructure for information visualization applications that use the accordion drawing technique: rubber sheet navigation with guaranteed visibility for marked areas of interest. Our new rendering algorithms are based on the partitioning of screen space, which allows us to handle dense dataset regions correctly. The algorithms in previous work led to incorrect visual representations because of overculling, and to inefficiencies due to overdrawing multiple items in the same region. Our pixel based drawing infrastructure guarantees correctness by eliminating overculling, and improves rendering performance with tight bounds on overdrawing. PRITree and PRISeq are applications built on PRISAD, with the feature sets of TreeJuxtaposer and SequenceJuxtaposer, respectively. We describe our PRITree and PRISeq dataset traversal algorithms, which are used for efficient rendering, culling, and layout of datasets within the PRISAD framework. We also discuss PRITree node marking techniques, which offer order-of-magnitude improvements to both memory and time performance versus previous range storage and retrieval techniques. Our PRITree implementation features a five fold increase in rendering speed for nontrivial tree structures, and also reduces memory requirements in some real world datasets by up to eight times, so we are able to handle trees of several million nodes. PRISeq renders fifteen times faster and handles datasets twenty times larger than previous work.	algorithm;correctness (computer science);glossary of computer graphics;information visualization;item unique identification;pixel;rendering (computer graphics);requirement;scalability;tree traversal	James Slack;Kristian Hildebrand;Tamara Munzner	2005	IEEE Symposium on Information Visualization, 2005. INFOVIS 2005.	10.1057/palgrave.ivs.9500118	terrain rendering;computer vision;tiled rendering;scientific visualization;image-based modeling and rendering;information visualization;3d rendering;rendering;computational geometry;computer science;theoretical computer science;operating system;parallel rendering;data mining;tree structure;real-time rendering;texture memory;alternate frame rendering;volume rendering;data visualization;software rendering;computer graphics (images)	Visualization	67.57901045678189	-50.738945320155565	160954
3c50bf0897e64809e463d45ebba314213aa1b36c	gpu-based tiled ray casting using depth peeling	unstructured mesh;ray casting	In this paper we propose several significant improvements to the hardware ray casting algorithm for unstructured meshes proposed byWeiler et al [14]. In their work, ray casting computation is entirely performed in the GPU by advancing intersections against the mesh while evaluating the volume rendering integral. Our contributions can be divided into three categories. First, we propose an alternate representation for mesh data in 2D textures that is more compact and efficient, compared to the 3D textures used in the original work. Second, we use a tile-based subdivision of the screen that allows computation to proceed only at places where it is required, thus reducing fragment processing in the GPU. Finally, we do not introduce imaginary cells that fill space caused by non-convexities of the mesh. Instead, we use a depth-peeling approach that captures when rays re-enter the mesh, which is much more general and does not require a convexification algorithm. We report results on an ATI 9700 Pro, the same hardware used by Weiler et al in their work. Due to the use of the 2D textures and the tiling, our technique is actually much faster than their work, while at the same time being more general, since it can render true non-convex meshes, as compared to their work, which is limited to convex (or convexified) ones. On the Blunt Fin, our code renders between 400 Ktet/sec to 1.3 Mtet/sec. GPU-based Tiled Ray Casting using Depth Peeling ∗ Fábio F. Bernardon UFRGS Christian A. Pagot UFRGS Jõao L. D. Comba UFRGS Cláudio T. Silva University of Utah	algorithm;arithmetic logic unit;computation;convex hull;data structure;debugging;depth peeling;documentation;fragment processing;geforce 9 series;graphics processing unit;high-level shading language;imaginary time;point in polygon;ray casting;rendering (computer graphics);shader;subdivision surface;tiling window manager;volume rendering	Fábio F. Bernardon;Christian Azambuja Pagot;João Luiz Dihl Comba;Cláudio T. Silva	2006	J. Graphics Tools	10.1080/2151237X.2006.10129227	simulation;computer science;ray casting;geometry;computer graphics (images)	Graphics	66.894955523843	-51.3348512110141	161060
c09a970f3f9a7bddf4bd34d63d09b1d029e189ce	perceptually-driven decision theory for interactive realistic rendering	environment maps;human vision;mesh simplification;visual quality;computer graphic;perceptually based rendering;graphics hardware;decision theory;decision theoretic;visual perception;perceptual metric	In this paper we introduce a new approach to realistic rendering at interactive rates on commodity graphics hardware. The approach uses efficient perceptual metrics within a decision theoretic framework to optimally order rendering operations, producing images of the highest visual quality within system constraints. We demonstrate the usefulness of this approach for various applications such as diffuse texture caching, environment map prioritization and radiosity mesh simplification. Although here we address the problem of realistic rendering at interactive rates, the perceptually-based decision theoretic methodology we introduce can be usefully applied in many areas of computer graphics.	computer graphics;decision theory;global illumination;graphics hardware;level of detail;radiosity (computer graphics);reflection mapping	Reynald Dumont;Fabio Pellacini;James A. Ferwerda	2003	ACM Trans. Graph.	10.1145/636886.636888	computer vision;tiled rendering;image-based modeling and rendering;decision theory;rendering;visual perception;computer science;parallel rendering;mathematics;multimedia;alternate frame rendering;graphics hardware;software rendering;computer graphics (images)	Graphics	63.90955878278169	-50.26407391799278	161457
5608c79a4e2f42e78ffba09873282f6ddddc4454	accurate computation of optical flow by using layered motion representations	motion analysis;transparent motions optical flow layered motion representations image motion analysis image regions parametric motion model motion boundaries;optical computing image motion analysis motion estimation nonlinear optics pixel motion analysis particle beam optics spatial coherence layout tires;particle beam optics;nonlinear optics;image motion analysis;transparent motions;spatial coherence;optical computing;motion estimation;motion boundaries;layout;parametric motion model;flow field;pixel;image regions;optical flow;tires;layered motion representations;global motion	This paper presents a framework combining two prevailing approaches t o motion analysis: optical f low which describes motion at each point, and methods that define global motions for [arger regions. Image motion is represented b y layers, image regions whose coherent motion can be approximated b y some parametric motion model. The motion at every point is obtained b y the parametric motion estimate of the entire layer, corrected b y a residual f low field which captures the diflerence between the real image motion and the layer's motion model. The new approach is able to construct accurate flow fields in the presence of multip le motions, motion boundaries, and transparent motions.	approximation algorithm;coherence (physics);computation;optical flow	Steven C. Hsu;P. Anandan;Shmuel Peleg	1994		10.1109/ICPR.1994.576427	layout;nonlinear optics;computer vision;structure from motion;computer science;complex harmonic motion;motion estimation;constant of motion;optical flow;motion system;optical computing;motion field;pixel;linear motion	Vision	54.55113416560629	-52.041892637443745	161525
63e91c505183cda2d35dfa85e93b53c1e960bed3	next generation image based lighting using hdr video	video capture;time of flight camera;texture mapping;spatial variation;data capture;computer graphic;computer vision;media engineering;development theory;field of view;dynamic range;next generation;computational photography;high dynamic range;data structure;structure from motion;mediateknik	We present an overview of our recently developed systems pipeline for capture, reconstruction, modeling and rendering of real world scenes based on state-of-the-art high dynamic range video (HDRV). The reconstructed scene representation allows for photo-realistic Image Based Lighting (IBL) in complex environments with strong spatial variations in the illumination. The pipeline comprises the following essential steps:  1.) Capture - The scene capture is based on a 4MPixel global shutter HDRV camera with a dynamic range of more than 24 f-stops at 30 fps. The HDR output stream is stored as individual un-compressed frames for maximum flexibility. A scene is usually captured using a combination of panoramic light probe sequences [1], and sequences with a smaller field of view to maximize the resolution at regions of special interest in the scene. The panoramic sequences ensure full angular coverage at each position and guarantee that the information required for IBL is captured. The position and orientation of the camera is tracked during capture.  2.) Scene recovery - Taking one or more HDRV sequences as input, a geometric proxy model of the scene is built using a semi-automatic approach. First, traditional computer vision algorithms such as structure from motion [2] and Manhattan world stereo [3] are used. If necessary, the recovered model is then modified using an interaction scheme based on visualizations of a volumetric representation of the scene radiance computed from the input HDRV sequence. The HDR nature of this volume also enables robust extraction of direct light sources and other high intensity regions in the scene.  3.) Radiance processing - When the scene proxy geometry has been recovered, the radiance data captured in the HDRV sequences are re-projected onto the surfaces and the recovered light sources. Since most surface points have been imaged from a large number of directions, it is possible to reconstruct view dependent texture maps at the proxy geometries. These 4D data sets describe a combination of detailed geometry that has not been recovered and the radiance reflected from the underlying real surfaces. The view dependent textures are then processed and compactly stored in an adaptive data structure.  4.) Rendering - Once the geometric and radiometric scene information has been recovered, it is possible to place virtual objects into the real scene and create photo-realistic renderings as illustrated above. The extracted light sources enable efficient sampling and rendering times that are fully comparable to that of traditional virtual computer graphics light sources. No previously described method is capable of capturing and reproducing the angular and spatial variation in the scene illumination in comparable detail.  We believe that the rapid development of high quality HDRV systems will soon have a large impact on both computer vision and graphics. Following this trend, we are developing theory and algorithms for efficient processing HDRV sequences and using the abundance of radiance data that is going to be available.	algorithm;angularjs;computer graphics;computer vision;data structure;display resolution;global illumination;high dynamic range;high-dynamic-range rendering;image-based lighting;metric;map;movie projector;next-generation network;sampling (signal processing);scene graph;semiconductor industry;structure from motion;texture mapping;virtual machine	Jonas Unger;Stefan Gustavson;Joel Kronander;Per Larsson;Gerhard Bonnet;Gunnar Kaiser	2011		10.1145/2037826.2037906	texture mapping;spatial variability;computer vision;dynamic range;computational photography;structure from motion;simulation;image-based modeling and rendering;data structure;field of view;rendering;computer science;development theory;video capture;automatic identification and data capture;image-based lighting;computer graphics (images)	Vision	59.86286457755265	-50.129235631297455	161534
cfe265362342618412230249060eba3557324ee5	efficient ray tracing affine ifs attractors	fractals;iterated function system;ray tracing;complex scenes;realistic image synthesis	This paper describes a method for ray tracing of fractals specified by affine iterated function systems (IFS) codes, i.e., affine IFS attractors. A ray-attractor intersection routine uses the idea of object instancing with modifications that allow IFS objects to be ray-traced at pixel size accuracy in an extremely efficient manner. Another advantage of our approach is that IFS specification may include non-invertible affine mappings. Consequently, visualisation of IFS attractors is very efficient and done with low memory requirements.	ray tracing (graphics)	Tomek Martyn	2001	Computers & Graphics	10.1016/S0097-8493(01)00094-2	ray tracing;combinatorics;discrete mathematics;fractal;mathematics;geometry;iterated function system	Graphics	66.68299968409193	-47.94769178764207	161541
5c5c06dd9c845f2eb9de5d2c4e48347f9b14daf5	rational and affine expressions for image description	image processing;computer graphics;representation image;fractal geometry;procesamiento imagen;traitement image;geometrie fractale;image generation;image representation;fractal;grafico computadora;infographie;generation image	"""Culik 11, K . and S . Dube, Rational and affine expressions for image description, Discrete Applied Mathematics 41 (1993) 85-120 . In this paper, the representation, generation and inference of images using automata-theoretic techniques is investigated . It is shown that highly complex images, including """"fractal"""" (self-similar) images, can be manipulated by the application of these techniques . Languages and relations over sonic alphabet are interpreted as images by treating strings as rational coordinates . In particular rational relations, specified by rational expressions, are considered . It is shown how texture of an image can be defined by probabilistic finite generators. Affine expressions are introduced as a generalization of both rational expressions and the IFS method to define images . Finally . Iwo efficient methods to implement rational expressions are presented ."""	algorithm;amplifier;automata theory;automaton;data compression;discrete mathematics;finite-state machine;formal language;fractal;grayscale;regular expression;self-similarity;wavelet;zooming user interface	Karel Culik;Simant Dube	1993	Discrete Applied Mathematics	10.1016/0166-218X(93)90031-I	combinatorics;discrete mathematics;fractal;image processing;mathematics;geometry;algorithm	Vision	64.45318232281366	-45.021993559906015	161627
b56de69c598ebdf9a53e5c4c16fa11e07a3e24b1	face/off: live facial puppetry	high resolution;real time;psi_visics;structured light;integrated optics;three dimensional;face tracking;animation;facial animation;face modeling;facial expression;interactive computer graphics;completely integrable system	We present a complete integrated system for live facial puppetry that enables high-resolution real-time facial expression tracking with transfer to another person's face. The system utilizes a real-time structured light scanner that provides dense 3D data and texture. A generic template mesh, fitted to a rigid reconstruction of the actor's face, is tracked offline in a training stage through a set of expression sequences. These sequences are used to build a person-specific linear face model that is subsequently used for online face tracking and expression transfer. Even with just a single rigid pose of the target face, convincing real-time facial animations are achievable. The actor becomes a puppeteer with complete and accurate control over a digital face.	facial recognition system;image resolution;online and offline;puppeteer;real-time clock;structured light	Thibaut Weise;Hao Li;Luc Van Gool;Mark Pauly	2009		10.1145/1599470.1599472	anime;three-dimensional space;computer vision;facial motion capture;simulation;computer facial animation;structured light;image resolution;computer science;facial expression;face hallucination;computer graphics (images)	Vision	59.08443774576766	-49.4815762228335	161655
144e03da29fae5468db495d67c32428c7f2390f5	real-time visualization of animated trees	real time visualization;real time;near field;vertex animation;tree structure;graphics processors;forest visualization;tree modeling;point rendering	Realistic visualization of plants and trees has recently received increased interest in various fields of applications. Limited computational power and the extreme complexity of botanical structures have called for tradeoffs between interactivity and realism. In this paper we present methods for the creation and real-time visualization of animated trees. In contrast to other previous research, our work is geared toward near-field visualization of highly detailed areas of forestry scenes with animation. We describe methods for rendering and shading of trees by utilizing the programmable hardware of consumer-grade graphics cards. We then describe a straightforward technique for animation of swaying stems and fluttering foliage that can be executed locally on a graphics processor. Our results show that highly detailed tree structures can be visualized at real-time frame rates and that animation of plant structures can be accomplished without sacrificing performance.	central processing unit;computation;download;graphics processing unit;interactivity;real-time clock;real-time transcription;rendering (computer graphics);shading;video card	Daniel Wesslén;Stefan Seipel	2005	The Visual Computer	10.1007/s00371-005-0295-1	computer vision;scientific visualization;simulation;information visualization;near and far field;computer science;computer animation;tree structure;computer graphics (images)	Graphics	65.094059291495	-51.024852038686	161689
d4165b9ed2d3ad5f0d2b789853cb0608222c3afc	behavior of the beta-splines with values of the parameters beta2 negative	concepcion asistida;spline;computer aided design;modele geometrique;geometrie solide;capsula convexa;esplin;vertex;sistema informatico;geometria solidos;negation;computer system;enveloppe convexe;point controle;settore mat 08 analisi numerica;control point;conception assistee;beta spline;systeme informatique;vertice;punto control;negacion;convex hull;solid geometry;geometrical model;modelo geometrico	Abstract   In this paper we study the behavior of the beta-spline functions in the case the parameter  β  2 ( i ) is negative. We prove that a negative value   β  ̂     2   (i)   exists so that if   β     2   (i) >   β  ̂     2   (i) ∀i  , the beta-spline functions N   i  ( u ) are positive. Moreover, if the control vertices are such that  x  0  ⩽ ⋯ ⩽  x   m −1 , we have proved that the design curve keeps the properties already proved in the case  β  2 ( i ) ⩾ 0.	spline (mathematics)	Flavia de Tisi;Milvia Rossini	1992	Computer Aided Geometric Design	10.1016/0167-8396(92)90040-V	spline;vertex;convex hull;computer aided design;solid geometry;calculus;negation;mathematics;geometry;algorithm	Theory	68.04413427688355	-39.754673701167754	161918
7184098219f39427d20e48db76b9f63d4b685e98	a standalone markerless 3d tracker for handheld augmented reality	pocket pc;feature tracking;computer vision;fixed point;graphics hardware;pattern recognition;handheld device;augmented reality	This paper presents an implementation of a markerless tracking technique targeted to the Windows Mobile Pocket PC platform. The primary aim of this work is to allow the development of standalone augmented reality applications for handheld devices based on natural feature tracking. In order to achieve this goal, a subset of two computer vision libraries was ported to the Pocket PC platform. They were also adapted to use fixed point math, with the purpose of improving the overall performance of the routines. The port of these libraries opens up the possibility of having other computer vision tasks being executed on mobile platforms. A model based tracking approach that relies on edge information was adopted. Since it does not require a high processing power, it is suitable for constrained devices such as handhelds. The OpenGL ES graphics library was used to perform computer vision tasks, taking advantage of existing graphics hardware acceleration. An augmented reality application was created using the implemented technique and evaluations were done regarding tracking performance and accuracy.	algorithm;ar (unix);augmented reality;computer vision;fixed point (mathematics);graphics hardware;graphics library;handheld game console;hardware acceleration;library (computing);microsoft windows;mobile device;motion estimation;opengl es;personal computer;pocket pc;pose (computer vision);vxl;windows mobile	Joao Paulo Silva do Monte Lima;Veronica Teichrieb;Judith Kelner	2009	CoRR		embedded system;computer vision;augmented reality;computer science;pattern recognition;mobile device;fixed point;graphics hardware;computer graphics (images)	Vision	56.12997888625686	-43.68697849955616	162333
34b8c13852413eb2d973a7615de4bcdac86d65f8	watertight trimmed nurbs	t splines;booleans;nurbs;nurbs surface;surface intersection	This paper addresses the long-standing problem of the unavoidable gaps that arise when expressing the intersection of two NURBS surfaces using conventional trimmed-NURBS representation. The solution converts each trimmed NURBS into an untrimmed T-Spline, and then merges the untrimmed T-Splines into a single, watertight model. The solution enables watertight fillets of NURBS models, as well as arbitrary feature curves that do not have to follow isoparameter curves. The resulting T-Spline representation can be exported without error as a collection of NURBS surfaces. CR Categories: I.3.5 [Computer Graphics]: Computational geometry and object modeling—Curve, surface, solid, and object representations		Thomas W. Sederberg;G. Thomas Finnigan;Xin Li;Hongwei Lin;Heather Ipson	2008	ACM Trans. Graph.	10.1145/1360612.1360678	t-spline;topology;non-uniform rational b-spline;computer science;mathematics;geometry;programming language	Graphics	67.87194462766024	-42.44878040139333	162438
0a16413b9d08833bf1ee4a9554397ce380a681e6	grasp moduli spaces and spherical harmonics	computer vision and robotics autonomous systems;manipulators;datorseende och robotik autonoma system;multidimensional scaling grasp moduli spaces spherical harmonics object representation smooth differentiable functions point cloud data spectral analysis smooth surfaces shape space;shape three dimensional displays vectors harmonic analysis surface reconstruction robot kinematics	In this work, we present a novel representation which enables a robot to reason about, transfer and optimize grasps on various objects by representing objects and grasps on them jointly in a common space. In our approach, objects are parametrized using smooth differentiable functions which are obtained from point cloud data via a spectral analysis. We show how, starting with point cloud data of various objects, one can utilize this space consisting of grasps and smooth surfaces in order to continuously deform various surface/grasp configurations with the goal of synthesizing force closed grasps on novel objects. We illustrate the resulting shape space for a collection of real world objects using multidimensional scaling and show that our formulation naturally enables us to use gradient ascent approaches to optimize and simultaneously deform a grasp from a known object towards a novel object.	closest point method;converge;global optimization;gradient descent;image scaling;iterative closest point;iterative method;kriging;mathematical optimization;missing data;multidimensional scaling;numerical analysis;point cloud;probabilistic turing machine;robot;shape table;spectral density estimation;statistical model;times ascent	Florian T. Pokorny;Yasemin Bekiroglu;Danica Kragic	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6906886	mathematical analysis;topology;mathematics;geometry	Robotics	60.22950795876723	-44.8217528641655	162478
cc841ce7d65d2691ac595b86af5e72238762b535	scalable 3d visualization via synchronous data hiding. (visualisation 3d adaptée par insertion synchronisée de données cachées)		The principal objective of this thesis is to unify disparate 3D information and then realize scalable visualization in a client/server environment that is heterogeneous in terms of network, computing and memory resources. For scalability we are exploiting the multiresolution nature of the discrete wavelet transform (DWT) from the state of the art JPEG2000 codec. The data unification is being carried out through DWT domain blind data hiding that may either be fully or adaptively synchronous. A typical surface based 3D visualization requires at least two sets of data: a 2D intensity image, called texture, with a corresponding 3D shape rendered in the form of a range image, a shaded 3D model and/or a mesh of points. A range image, also sometimes called a depth image, is an image in which the pixel value reflects the distance from the sensor to the imaged surface. The texture is a corresponding 2D color image which is overlaid onto a model produced from the depth map by triangulation. For data hiding, the range data is first subjected to DWT while the texture data is input to the JPEG2000 encoder. The JPEG2000 coding pipeline of texture is interrupted at some stage after the DWT step and the DWT domain range coefficients are embedded in the all or a subset of texture subbands. The embedded data is reintroduced to the JPEG2000 pipeline at the same step where the interruption was made. Since the JPEG2000 format is conserved during the process, the resultant code can be sent across any communication channel like any other JPEG2000 file. The resolution scalability of wavelets and the synchronized character of our techniques enable a 3D visualization even with fewer than original resolution bands as a result of partial or delayed data transfer. The method thus enables to effect a visualization from a fraction of data in the form of the lowest subband, of a particular resolution level. In the first phase of this work the thrust was on the perceptual transparency and that is why least significant bit (LSB) embedding was employed for both the synchronous and adaptively synchronous cases. The second phase concerns robustness and that is a why spread spectrum (SS) strategy is utilized in embedding. During the latter phase the imperceptibility has not been ignored at all as the embedding is removable. Examples from the two main areas of terrain and face visualization have been taken as case studies to prove the utility of our methods. In the third and final phase we take a broader aspect of the problem when we try to render the underlying tile components of a heterogeneous tessellation, seamlessly. This seamless joining of tiles is ensured through special DWT domain smoothing functions.	3d modeling;channel (communications);client–server model;codec;coefficient;color image;depth map;discrete wavelet transform;embedded system;encoder;interrupt;jpeg 2000;least significant bit;most significant bit;pixel;range imaging;removable media;resultant;scalability;seamless3d;server (computing);shading;smoothing;tessellation (computer graphics);thrust;unification (computer science);volume rendering	Khizar Hayat	2009				Visualization	68.08284647250134	-50.371674921193325	162501
402786b3003eaa7ed9f4f00cd39f2b7056e7ce99	scattered data fitting with bivariate splines	510 mathematik;scattered data	We describe scattered data fitting by bivariate splines, i.e., splines defined w.r.t. triangulations in the plane. These spaces are powerful tools for the efficient approximation of large sets of scattered data which appear in many real world problems. Bernstein-Bezier techniques can be used for the efficient computation of bivariate splines and for analysing the complex structure of these spaces. We report on the classical approaches and we describe interpolation and approximation methods for bivariate splines that have been developed recently. For the latter methods, we give illustrative examples treating sets of geodetic data (consisting of up to 106 points).	bivariate data;curve fitting;spline (mathematics)	Frank Zeilfelder	2002		10.1007/978-3-662-04388-2_10	mathematical optimization;interpolation;bivariate analysis;geodetic datum;computation;lagrange polynomial;spline (mathematics);curve fitting;hermite interpolation;mathematics	Vision	62.94641749290061	-42.67330020853346	162919
b47c51f041e92f085156f22655c77209a5979a74	standalone edge-based markerless tracking of fully 3-dimensional objects for handheld augmented reality	mobile;pocket pc;handheld;feature tracking;computer vision;fixed point;graphics hardware;markerless tracking;handheld device;3 dimensional;augmented reality	This paper presents a markerless tracking technique targeted to the Windows Mobile Pocket PC platform. The primary aim of this work is to allow the development of standalone augmented reality applications for handheld devices based on natural feature tracking of fully 3-Dimensional objects. In order to achieve this goal, a model-based tracking approach that relies on edge information was adopted. Since it does not require high processing power, it is suitable for constrained devices such as handhelds. The OpenGL ES graphics library was used to detect the visible edges in a given frame, taking advantage of graphics hardware acceleration when available. In addition, a subset of two computer vision libraries was ported to the Pocket PC platform in order to provide some required algorithms to the markerless mobile solution. They were also adapted to use fixed-point math, with the purpose of improving the overall performance of the routines. The port of these libraries opens up the possibility of having other computer-vision tasks being executed on mobile platforms. An augmented reality application was created using the implemented technique and evaluations were done regarding tracking performance, accuracy and robustness. In most of the tests, the frame rates obtained are suitable for handheld augmented reality and a reasonable estimation of the object pose was provided.	algorithm;augmented reality;computer vision;fixed-point arithmetic;graphics hardware;graphics library;handheld game console;hardware acceleration;library (computing);microsoft windows;mobile device;motion estimation;opengl es;personal computer;pocket pc;windows mobile	Joao Paulo Silva do Monte Lima;Veronica Teichrieb;Judith Kelner;Robert W. Lindeman	2009		10.1145/1643928.1643960	embedded system;computer vision;augmented reality;computer science;operating system;mobile device;computer graphics (images)	Visualization	56.13825511433533	-43.70094015534035	163019
d80ecb21424d328ef72a798843acbbb89041b685	feature-preserving simplification of texture-mapped models	oceans;texture mapped model;mesh generation computational geometry computer graphics;computer graphics;real time;texture mapping;computational geometry;error metric;half edge collapse operation;surface texture;low polygon count approximation;sea surface;graphical models;progressive mesh;level of detail;shape;solid modeling;web graphics;surface data transmission;feature preservation;merging;bandwidth;solid modeling shape real time systems graphics oceans sea surface surface texture bandwidth graphical models merging;multi resolution;feature preserving multiresolution simplification algorithm;mesh generation;texture attribute preservation;web graphics feature preserving multiresolution simplification algorithm half edge collapse operation texture mapped model error metric low polygon count approximation shape preservation texture attribute preservation mesh generation surface data transmission;graphics;shape preservation;real time systems	A feature-preserving multi-resolution simplification algorithm based on half-edge collapse operation for texture-mapped models is proposed. A new error metric based on the geometric importance the texture-attribute importance of a half-edge is presented. It can generate a low-polygon-count approximation model with shape preservation and texture attributes preservation. In addition, the half-edge based scheme is more efficient in memory usage and convenient for generating progressive meshes with texture attributes for real-time transmission of various surface data on the Web. The visual comparisons showing that the proposed algorithm results in higher quality approximations of original models with texture attribute preservation even at very low levels of detail than other algorithms in the literature	algorithm;approximation;level of detail;progressive meshes;real-time clock;text simplification;texture mapping;world wide web	Xiuwen Liu;Cui Xie;Yicheng Jin	2006	International Conference on Computer Graphics, Imaging and Visualisation (CGIV'06)	10.1109/CGIV.2006.44	computer vision;computer science;theoretical computer science;computer graphics (images)	Visualization	67.57780610818048	-49.47037372076682	163139
1a6fd26c42de9defef3745618b32d64db410bb4a	efficient octree-based volumetric slam supporting signed-distance and occupancy mapping	simultaneous localization and mapping;octrees;planning;resource management;real-time systems;pipelines	We present a dense volumetric simultaneous localisation and mapping (SLAM) framework that uses an octree representation for efficient fusion and rendering of either a truncated signed distance field (TSDF) or an occupancy map. The primary aim of this letter is to use one single representation of the environment that can be used not only for robot pose tracking and high-resolution mapping, but seamlessly for planning. We show that our highly efficient octree representation of space fits SLAM and planning purposes in a real-time control loop. In a comprehensive evaluation, we demonstrate dense SLAM accuracy and runtime performance on-par with flat hashing approaches when using TSDF-based maps, and considerable speed-ups when using occupancy mapping compared to standard occupancy maps frameworks. Our SLAM system can run at 10–40 Hz on a modern quadcore CPU, without the need for massive parallelization on a GPU. We, furthermore, demonstrate a probabilistic occupancy mapping as an alternative to TSDF mapping in dense SLAM and show its direct applicability to online motion planning, using the example of informed rapidly-exploring random trees (RRT$^*$).	central processing unit;control system;distance transform;experiment;fits;graphics processing unit;image resolution;match moving;motion planning;octree;parallel computing;real-time clock;real-time locating system;run time (program lifecycle phase);simultaneous localization and mapping;smoothing;unmanned aerial vehicle	Emanuele Vespa;Nikolay Nikolov;Marius Grimm;Luigi Nardi;Paul H. J. Kelly;Stefan Leutenegger	2018	IEEE Robotics and Automation Letters	10.1109/LRA.2018.2792537	control engineering;occupancy;rendering (computer graphics);computer vision;probabilistic logic;engineering;simultaneous localization and mapping;motion planning;hash function;octree;signed distance function;artificial intelligence	Robotics	55.275987802663245	-42.509421701595706	163390
e0720367b1da0689b6aa9c6dcc2593da87486eb3	patch-type segmentation of voxel shapes using simplified surface skeletons		We present a new method for decomposing a 3D voxel shape into disjoint segments using the shape’s simplified surface-skeleton. The surface skeleton of a shape consists of 2D manifolds inside its volume. Each skeleton point has a maximally inscribed ball that touches the boundary in at least two contact points. A key observation is that the boundaries of the simplified foreand background skeletons map one-to-one to increasingly fuzzy, soft convex, respectively concave, edges of the shape. Using this property, we build a method for segmentation of 3D shapes which has several desirable properties. Our method segments both noisy shapes and shapes with soft edges which vanish over low-curvature regions. Multiscale segmentations can be obtained by varying the simplification level of the skeleton. We present a voxel-based implementation of our approach and illustrate it on several realistic	concave function;edge detection;level of detail;multiscale turbulence;one-to-one (data model);sensor;voxel	Dennie Reniers;Alexandru Telea	2008	Comput. Graph. Forum	10.1111/j.1467-8659.2008.01330.x	computer vision;topology;shape analysis;mathematics;geometry;topological skeleton	Vision	68.13764747575637	-43.600319083298594	163395
a24cc2a0f8384b960cc54c602cf060c89712b0bf	a mathematical model of deforming manifolds and their visualizations by cg animation	example based texture synthesis;high dimensionality;dynamic equation;mathematical model;super resolution	It is becoming an important field in computer art to visualize High Dimensional Manifolds. [Banchoff 1990] [Kusabuka and AlgorithmicArt 2006] In this research, we will find the dynamics equation which express deforming motion of the α dimensional manifold r, and visualize many interesting motions of the deformed manifold r(t) by CG animation.	computer animation;mathematical model	Ippei Takauchi;Yuta Hara;Hiromu Saito;Ryo Asakura;Motofumi Hattori	2010		10.1145/1836845.1837004	computer vision;computer science;mathematical model;mathematics;geometry;statistics;superresolution;computer graphics (images)	Graphics	61.3886253806318	-45.87013679458556	163728
7f9fb19263d1d7e8d2e6f94b90f5dc545c9efb25	constant time queries on uniformly distributed points on a hemisphere	color index;time;computer graphic;uniform distribution	A set of uniformly distributed points on a hemisphere is generated using a popular me based on triangle subdivision. In applications, each data point (for example, representing a d tion from a point on a surface) is typically associated with additional information (for example radiance value). Given an arbitrary query point on the hemisphere we require the nearest point from the given distribution. An algorithm is presented that finds the data point in cons time, independently of the number of original points in the distribution. A portion of the hemisp is rendered such that each point in the distribution has an associated set of quadrilaterals rend with a unique color index for that point. The frame-buffer for the rendered hemisphere portion be stored in off-screen memory. Any query point can be ‘rendered’ into this off-screen frame b projected to a ‘pixel’ location, and the color index stored at this pixel location found. This co index is a lookup into an array of the original data points. This algorithm is presented in detail, an illustrative implementation in OpenGL is described.	algorithm;data point;framebuffer;lookup table;opengl;pixel;subdivision surface	Mel Slater	2002	J. Graphics, GPU, & Game Tools	10.1080/10867651.2002.10487553	computer science;theoretical computer science;color index;mathematics;geometry;uniform distribution;statistics;computer graphics (images)	Theory	67.46120237131174	-50.017623749123416	163730
b48f955413eec14052ba58fc15d5c8216fc88355	color calibration of an acquisition device - method, quality and results		Color calibrated acquisition is of strategic importance when high quality imaging is required, such as for work of art imaging. The aim of calibration is to correct raw acquired image for the various acquisition device signal deformation, such as noise, lighting uniformity, white balance and color deformation, due, for a great part, to camera spectral sensitivities. We first present reference color data computation obtained from camera’s spectral sensitivities and reflectance of reference patches, taken form Gretag MacBeth Color Chart DC. Then we give a color calibration method based on linear regression. We finally evaluate the quality of applied calibration and present some resulting calibrated images.	acquired image;calibration;calibration (statistics);circuit complexity;color balance;computation;computation (action);display resolution;linear regression body surface area formula for infants and children	Virginie Vurpillot;Arnaud Legrand;Alain Trémeau	2007			color calibration;spall;computer vision;lamina;artificial intelligence;polycarbonate;lamination (geology);computer science;coating;brittleness;composite material	Vision	59.95365654358631	-43.38308750616332	163790
f1a6999e9dc759a6705aa9010f45d6f4378ae21f	the use of three- and four-dimensional surface harmonics for rigid and nonrigid shape recovery and representation	least squares approximations;time dependent;range data;spherical harmonics;spherical harmonic;surface fitting;linear least square;shape recovery;medical image processing computer vision image reconstruction image representation surface fitting least squares approximations;left ventricle;computer vision;3d surface harmonics four dimensional surface harmonics three dimensional surface harmonics nonrigid shape recovery rigid shape recovery shape representation spherical harmonics surface harmonics oblate spheroidal harmonics prolate spheroidal harmonics cylindrical harmonics time dependence surface fitting real data samples synthetic data samples linear least squares approach heart ventricle 4d surface harmonics;surface harmonics;shape representation;nonrigid motion;image representation;image reconstruction;medical image processing;indexation;shape surface fitting heart art geometry scattering computer science equations frequency low frequency noise;harmonic function;coordinate system	The use of spherical harmonics for rigid and nonrigid shape representation is well known. This paper extends the method to surface harmonics defined on domains other than the sphere and to four-dimensional spherical harmonics. These harmonics enable us to represent shapes which cannot be represented as a global function in spherical coordinates, but can be in other coordinate systems. Prolate and oblate spheroidal harmonics and cylindrical harmonics are examples of surface harmonics which we find useful. Nonrigid shapes are represented as functions of space and time either by including the time-dependence as a separate factor or by using four-dimensional spherical harmonics. This paper compares the errors of fitting various surface harmonics to an assortment of synthetic and real data samples, both rigid and nonrigid. In all cases we use a linear least-squares approach to find the best fit to given range data. It is found that for some shapes there is a variation among geometries in the number of harmonics functions needed to achieve a desired accuracy. In particular, it was found that four-dimensional spherical harmonics provide an improved model of the motion of the left ventricle of the heart. >		Art Matheny;Dmitry B. Goldgof	1995	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.464561	computer vision;spin-weighted spherical harmonics;table of spherical harmonics;mathematics;geometry;fuzzy sphere;vector spherical harmonics;solid harmonics;spherical harmonics;zonal spherical harmonics;spherical harmonic lighting	Vision	62.82723489042397	-43.10308406724672	163809
8994b2b3947a95f377044962b384a63202f94e9c	interpolation and polynomial fitting in the spd manifold	interpolation;matrix algebra generalisation artificial intelligence interpolation learning artificial intelligence;matrix algebra;interpolation commutative lie group log euclidean framework optimization medical imaging machine learning tensor analysis riemannian manifolds spd matrix symmetric positive definite matrix spd manifold polynomial fitting;manifolds measurement polynomials interpolation splines mathematics vectors symmetric matrices;generalisation artificial intelligence;learning artificial intelligence	Generalizing to Riemannian manifolds classical methods to approximate data (e.g. averaging, interpolation and regularization) has been a theoretical challenge that has also revealed to be computationally very demanding and often unsatisfactory. One particular manifold that shows up in numerous scientific areas that use tensor analysis, including machine learning, medical imaging, and optimization, is the set of symmetric positive definite (SPD) matrices. In this work, we show that when the SPD matrices are endowed with the Log-Euclidean framework, certain optimization problems, such as interpolation and best fitting polynomial problems, can be solved explicitly. This contrasts with what happens in general non-Euclidean spaces. In the Log-Euclidean framework, the SPD manifold has the structure of a commutative Lie group and when equipped with the Log-Euclidean metric it becomes a flat Riemannian manifold. Explicit expressions for polynomial curves in the SPD manifold are therefore obtained easily, and this enables the complete resolution of the proposed problems.	approximation algorithm;best practice;euclidean distance;fits;interpolation;linear least squares (mathematics);machine learning;manifold alignment;mathematical optimization;medical imaging;nonlinear system;polynomial;smoothing;spline (mathematics)	Luís Machado;Fatima Silva Leite	2013	52nd IEEE Conference on Decision and Control	10.1109/CDC.2013.6760037	spline interpolation;mathematical optimization;combinatorics;mathematical analysis;interpolation;mathematics;linear interpolation;manifold alignment	Vision	62.74255323551179	-42.46102998622585	164090
4a6e6dafc091e2e2167d8ae84c69de3d7eeccf83	voxblox: incremental 3d euclidean signed distance fields for on-board mav planning		Micro Aerial Vehicles (MAVs) that operate in unstructured, unexplored environments require fast and flexible local planning, which can replan when new parts of the map are explored. Trajectory optimization methods fulfill these needs, but require obstacle distance information, which can be given by Euclidean Signed Distance Fields (ESDFs). We propose a method to incrementally build ESDFs from Truncated Signed Distance Fields (TSDFs), a common implicit surface representation used in computer graphics and vision. TSDFs are fast to build and smooth out sensor noise over many observations, and are designed to produce surface meshes. We show that we can build TSDFs faster than Octomaps, and that it is more accurate to build ESDFs out of TSDFs than occupancy maps. Our complete system, called voxblox, is available as open source and runs in real-time on a single CPU core. We validate our approach on-board an MAV, by using our system with a trajectory optimization local planner, entirely on-board and in real-time.	aerial photography;approximation;central processing unit;computational complexity theory;computer graphics;data structure;euclidean distance;image noise;implicit surface;map;mathematical optimization;minimum bounding box;on-board data handling;open-source software;polygon mesh;priority queue;ray casting;real-time cmix;real-time clock;serialization;trajectory optimization;voxel	Helen Oleynikova;Zachary Taylor;Marius Fehr;Roland Siegwart;Juan I. Nieto	2017	2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2017.8202315	occupancy;computer vision;artificial intelligence;computer graphics;euclidean geometry;polygon mesh;multi-core processor;computer science;trajectory optimization;signed distance function	Robotics	55.39908776010721	-42.30455622650628	164227
728c940e5cdfcd6c5347b431612aa9339e86dcaa	a vision-based approach for surface roughness assessment at micro and nano scales	vision system;ccd camera;cavity resonators;rough surfaces surface roughness optical filters optical microscopy charge coupled devices charge coupled image sensors instruments filtering data analysis computer vision;surface topography measurement;surface roughness;measurement system;data filtering;image acquisition and analysis;optical microscope;surface topography;ccd image sensors;computer vision;rough surfaces;conference paper;arrays;surface topography measurement ccd image sensors computer vision data analysis optical microscopes surface roughness;data analysis;image acquisition;micro and nano scale regions machine vision surface roughness measurement image acquisition and analysis;machine vision;micro and nano scale regions;industrial application;surfaces;surface roughness measurement;correlation;3d vision;nanoscale region vision based approach surface roughness assessment ccd camera video based optical microscope stylus instrument data filtering data analysis cavity graphs technique roughness measurement systems microscale region;optical microscopes	This paper presents a vision-based approach for valid assessment of surface roughness in both micro-scale and nano-scale regions. To enable data comparisons, three sets of surface data in the micro and nano regions are acquired by using a CCD camera, a video-based optical microscope and a stylus instrument. Data filtering and analysis procedures are applied to the acquired data. Results for computation of roughness parameters by using vision data provide adequate values for assessment of surface roughness in the manner as similar as stylus based technique. No obvious changes in the computed roughness parameter values are resulted from the micro and nano regions. In the nano region, a cavity graphs technique provides distinguishable forms of graphs that tend to more gradual increase of the cavity percentage to denote the collection of the macro surface details. In addition, an auto correlation technique applied in the nano region succeeds to discriminate the surface irregularities relationship with respect to their periodicity and randomness. The overall acquired results indicate that vision systems are a valid source of data for reliable surface roughness evaluation in both micro/nano-scale regions. The results are very useful in achieving commercial 3D vision based micro-nano roughness measurement systems for industrial applications.	autocorrelation;charge-coupled device;computation;gnu nano;nvidia 3d vision;quasiperiodicity;randomness;stylus (computing);system of measurement	Ghassan A. Al-Kindi;Bijan Shirinzadeh;Yongmin Zhong	2008	2008 10th International Conference on Control, Automation, Robotics and Vision	10.1109/ICARCV.2008.4795819	computer vision;surface roughness;machine vision;computer science	Robotics	58.9787307424542	-41.755494560192346	164368
9bb2bff2f7dce8cd55f5f6d29e46e2b62946aaca	animations from nasa's exploration of outer space: use of computer graphics with satellite data	satellite data;computer graphic;space use		computer graphics	Jeff Hall	1996		10.1145/253607.253740	computer vision;simulation;computer science;3d computer graphics;computer graphics (images)	Visualization	63.31130713876497	-50.98871362362475	165234
a72627029fd403091c373fa4ddc21082d9df8c64	reproducing 2d implicit curves with sharp features		Implicit curves play an essential role in the societies of medicine, meteorology, geology, geo-physics, visualization and so on. In this paper, we propose an algorithm to visualize implicit curves and reproduce their sharp features in 2D plane. To access the subdivision cells of a user-defined 2D domain, our algorithm first creates a quadtree by using a top-down and adaptive quad-tree construction technique. In each cell, the method locates exact one feature point of the numerical field defined by the implicit function defining an implicit curve. A discrete optimization technique is employed to calculate the feature points. A dual mesh is subsequently constructed for the quadtree by taking the feature points as its vertices. Our algorithm approximates local part of the implicit curve in each cell of the dual mesh with a modified version of the marching squares method. Collecting all the approximations in the cells, our method finally reproduces the implicit curve with sharp features. Experiments show that our method can efficiently extract the sharp features of implicit curves, and it can work with various implicit curves with or without sharp features robustly.		Jingjie Zhao;Jidong Wang;Ruibin Zhao;Mingyong Pang	2018	2018 International Conference on Cyberworlds (CW)	10.1109/CW.2018.00032	mathematical optimization;computer vision;vertex (geometry);artificial intelligence;visualization;implicit function;discrete optimization;quadtree;computer science;marching squares	Robotics	67.92989428886196	-48.87480060085767	165244
7804a81a300c14adf62610002bb7c8c7fe1556e8	efficient collision determination for dynamic scenes using coherent separating axis	collision determination;index terms—collision detection;separating axis;response simulation.;collision detection;real time;indexing terms	We present an efficient algorithm for collision determination of dynamic objects undergoing rigid motion or general deformation. Our technique deals with triangulated models, and it requires no further assumption of the objects’ geometry and topology. Particularly, it efficiently handles non-convex, or even polygon-soup models, enduring any deformation process. Furthermore, it requires no complex pre-processing, making it suitable for dynamic settings such as games or production line simulation. The proposed technique is based on a dynamic binary space partitioning process, which is accelerated by a temporal coherent separating axis algorithm. For stable contact determination of complex geometry, we first obtain a velocity-related penetration vector pair for every intersected triangle pair by tracing the movement on the separating axis, then propagate the process to the whole contact region. Our method shows realtime performance and good stability for moderate complex environment.	apache axis;approximation algorithm;binary space partitioning;coherent;collision detection;computation;convex function;instability;mathematical optimization;optic axis of a crystal;polygon soup;preprocessor;real-time clock;real-time computing;simulation;velocity (software development)	Lu Chen;Wei Hua;Zhong Ren;Hujun Bao	2007	IJVR		beam (structure);human–computer interaction;latching switch;coincident;collision detection;polarization (waves);computer science;beam steering;diagonal;artificial intelligence;reciprocal;topology;computer vision	Robotics	61.26633038482933	-43.17363630214874	165277
54078ce1d937545861d451f546180294d221cd24	recovery of 3d shape based on generalized symmetry	computer graphics;three dimensional shape;forma tridimensional;symetrie;symmetry;algorithme;algorithm;reconstruction image;forme tridimensionnelle;reconstruccion imagen;image reconstruction;simetria;grafico computadora;infographie;algoritmo	Abstract#R##N##R##N#With the widening range of applications of computer graphics, simple methods of feeding graphic information into computers which matches the human senses are demanded. This paper proposes a method of reconstructing a 3D (three-dimensional) shape from a line drawing by using generalized symmetry. Generalized symmetry is an extended concept of skewed symmetry and represents the synmetrical characteristics of an object in terms of its curvilinear symmetrical axes. First, this paper defines generalized symmetry and describes its property; then it describes an algorithm which reconstructs the 30 shape of an object satisfying the generalized symmetry from an orthographically projected image of the object and such additional information as auxiliary lines. This algorithm produces a description of a 3D shape by using a line drawing and a small amount of additional information. This paper also demonstrates a computer simulation of the reconstruction of a complex 3D shape (such as one described by the generalized cylinder) drawn by using a data tablet.		Toshimitsu Tanaka;Seiichiro Naito;Tokiichiro Takahashi;Isao Masuda	1989	Systems and Computers in Japan	10.1002/scj.4690200302	iterative reconstruction;computer science;mathematics;geometry;symmetry;computer graphics;algorithm	Robotics	66.01426430805911	-41.23404659878934	165471
b9cbf31b6409e630a1484be43bb19d9bf970e208	a practical analytic single scattering model for real time rendering	environment maps;light transport;finite element simulation;precomputed radiance transfer;construccion arquitectura tecnologia ambiental;participating media;computacion informatica;light scattering;real time;texture mapping;grupo de excelencia;layered materials;ease of use;global illumination;diffusion theory;ciencias basicas y experimentales;reflection models;programmable graphics hardware;lookup table;subsurface scattering;tecnologias;monte carlo;bssrdf;realistic image synthesis;real time rendering	Uma perspectiva que se torna mais confortável para o indivíduo lidar com o excesso da informação, é a reinvenção do espaço e do tempo. Existe a oportunidade de considerar esta reinvenção, um ponto de partida para o desenho e concepção de novas cidades e/ou regiões que possuam um alter ego digital, urbanizado e pensado de forma a facilitar a interacção entre indivíduos e, entre estes e as organizações. É que espaço e tempo, constituem-se como dois dos maiores referenciais para o ser humano.	controller (control theory);unified model	Bo Sun;Ravi Ramamoorthi;Srinivasa G. Narasimhan;Shree K. Nayar	2005	ACM Trans. Graph.	10.1145/1073204.1073309	texture mapping;simulation;subsurface scattering;usability;lookup table;computer science;light scattering;optics;real-time rendering;global illumination;monte carlo method;computer graphics (images)	Graphics	63.138403871762435	-51.81719093409787	165782
fd9997e3c887d5ae59348c4b3385f0df8fd8e9a2	on the characterization of a speed-boat motion for real-time motion cueing		Motion platforms are not uncommon for car and flight VR simulators. However, the same is not true about watercraft. This paper presents an experimental characterization of a speed-boat in order to understand the nature and magnitude of a typical small watercraft motion. Unlike other studies, this work focuses on realtime simulation instead of on boat design issues. The purpose of the study is to guide the future process of designing and parameterizing a suitable motion platform for a VR application. The characterization is performed by placing two accelerometers, two gyroscopes, one GPS logger, one digital compass, and one digital anemometer on a speed-boat at several ranges of motion and maneuvering. We analyze tilt, speed, wind, steering, angular speed, acceleration and angular acceleration at both frequency and time domains. Characterization results show that at least a 3-DoF heave-pitch-roll motion platform should be used.	angularjs;data logger;gps tracking unit;global positioning system;motion simulator;real-time computing;real-time transcription;simulation	Sergio Casas;Inmaculada Coma;José V. Riera;Marcos Fernández	2013			artificial intelligence;computer vision;computer graphics (images);computer science	Robotics	56.25141375082116	-38.43505873087546	166041
80ff6ad15a7b571f9577058c49a935b44baa0db1	ftp-sc: fuzzy topology preserving stroke correspondence		Stroke correspondence construction is a precondition for vectorized 2D animation inbetweening and remains a challenging problem. This paper introduces the FTP-SC, a fuzzy topology preserving stroke correspondence technique, which is accurate and provides the user more effective control on the correspondence result than previous matching approaches. The method employs a two-stage scheme to progressively establish the stroke correspondence construction between the keyframes. In the first stage, the stroke correspondences with high confidence are constructed by enforcing the preservation of the so-called “fuzzy topology” which encodes intrinsic connectivity among the neighboring strokes. Starting with the high-confidence correspondences, the second stage performs a greedy matching algorithm to generate a full correspondence between the strokes. Experimental results show that the FTP-SC outperforms the existing approaches and can establish the stroke correspondence with a reasonable amount of user interaction even for keyframes with large geometric and spatial variations between strokes. CCS Concepts •Computing methodologies → Animation; Parametric curve and surface models;	computer graphics;data dependency;eurographics;fuzzy mathematics;greedy algorithm;inbetweening;interpolation;john d. wiley;key frame;precondition	Wenwu Yang;Seah Hock Soon;Quan Chen;Hong-Ze Liew;Daniel Sýkora	2018	Comput. Graph. Forum	10.1111/cgf.13518	theoretical computer science;fuzzy logic;animation;computer science;computing methodologies;file transfer protocol	Graphics	66.98205369239096	-45.79716926967663	166101
af79052bf620db06ec72c4d6bd731c3e4aa8b6b9	analytic pca construction for theoretical analysis of lighting variability in images of a lambertian object	eigenvalues and eigenfunctions;object recognition;radiance;illumination;spherical harmonics;best approximation;spherical harmonic;image analysis principal component analysis lighting eigenvalues and eigenfunctions computer vision face harmonic analysis robustness humans rendering computer graphics;eigenvalues;irradiance;computer vision;recognition;theoretical analysis;principal component analysis;lighting;irradiance analytic principal component analysis spherical harmonics lighting variability five dimensional subspace convex lambertian object surface normal vectors principal eigenmodes principal eigenvalues radiance;lambertian;eigenvectors;principal component;principal component analysis eigenvalues and eigenfunctions lighting object recognition computer vision	We analyze theoretically the subspace best approximating images of a convex Lambertian object taken from the same viewpoint, but under different distant illumination conditions. Since the lighting is an arbitrary function, the space of all possible images is formally infinite-dimensional. However, previous empirical work has shown that images of largely diffuse objects actually lie very close to a five-dimensional subspace. In this paper, we analytically construct the principal component analysis for images of a convex Lambertian object, explicitly taking attached shadows into account, and find the principal eigenmodes and eigenvalues with respect to lighting variability. Our analysis makes use of an analytic formula for the irradiance in terms of spherical-harmonic coefficients of the illumination and shows, under appropriate assumptions, that the principal components or eigenvectors are identical to the spherical harmonic basis functions evaluated at the surface normal vectors. Our main contribution is in extending these results to the singleviewpoint case, showing how the principal eigenmodes and eigenvalues are affected when only a limited subset (the upper hemisphere) of normals is available and the spherical harmonics are no longer orthonormal over the restricted domain. Our results are very close, both qualitatively and quantitatively, to previous empirical observations and represent the first essentially complete theoretical explanation of these observations. Our analysis is also likely to be of interest in other areas of computer vision and imagebased rendering. In particular, our results indicate that using complex illumination for photometric problems in computer vision is not significantly more difficult than using directional sources.	basis function;coefficient;computer vision;heart rate variability;lambertian reflectance;normal (geometry);normal mode;principal component analysis;spherical basis	Ravi Ramamoorthi	2002	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/TPAMI.2002.1039204	computer vision;eigenvalues and eigenvectors;lighting;mathematics;geometry;spherical harmonics;principal component analysis	Vision	60.84818790356048	-43.842987837370615	166238
83db8b26d423a3bfdc252748112d32c5b5d8f51e	markerless tracking system for augmented reality in the automotive industry		Markerless tracking system for augmented reality targeting the automotive sector.System evaluation during the Volkswagen/ISMAR Tracking Challenge 2014.Additional studies in similar competition scenarios created by the authors.System suitable for tracking vehicle exterior / parts and high precision tracking. This paper presents a complete natural feature based tracking system that supports the creation of augmented reality applications focused on the automotive sector. The proposed pipeline encompasses scene modeling, system calibration and tracking steps. An augmented reality application was built on top of the system for indicating the location of 3D coordinates in a given environment which can be applied to many different applications in cars, such as a maintenance assistant, an intelligent manual, and many others. An analysis of the system was performed during the Volkswagen/ISMAR Tracking Challenge 2014, which aimed to evaluate state-of-the-art tracking approaches on the basis of requirements encountered in automotive industrial settings. A similar competition environment was also created by the authors in order to allow further studies. Evaluation results showed that the system allowed users to correctly identify points in tasks that involved tracking a rotating vehicle, tracking data on a complete vehicle and tracking with high accuracy. This evaluation allowed also to understand the applicability limits of texture based approaches in the textureless automotive environment, a problem not addressed frequently in the literature. To the best of the authors knowledge, this is the first work addressing the analysis of a complete tracking system for augmented reality focused on the automotive sector which could be tested and validated in a major benchmark like the Volkswagen/ISMAR Tracking Challenge, providing useful insights on the development of such expert and intelligent systems.	augmented reality;tracking system	Joao Paulo Silva do Monte Lima;Rafael Alves Roberto;Francisco Simões;Mozart W. S. Almeida;Lucas Silva Figueiredo;João Marcelo X. N. Teixeira;Veronica Teichrieb	2017	Expert Syst. Appl.	10.1016/j.eswa.2017.03.060	tracking system;intelligent decision support system;computer vision;simulation;augmented reality;computer science;artificial intelligence;automotive industry	HCI	55.6160645022229	-40.522732790702335	166307
005170c55c73a17f71800438b1ecd0c7e13b401f	a fast algorithm for building the octree for a three-dimensional object from its multiple images	robot path planning pattern recognition obstacle shape octree motion planning data structure;octree;path planning;shape measurement robot vision systems solid modeling robot kinematics electric variables measurement path planning data structures interference machine vision registers;trees mathematics pattern recognition robots;shape measurement;interference;trees mathematics;three dimensional;obstacle shape;registers;data structures;machine vision;robot path planning;fast algorithm;solid modeling;robots;motion planning;pattern recognition;data structure;robot vision systems;electric variables measurement;robot kinematics	In a robot vision system, not only measurement of any obstacle in the workspace but also registration of obstacle shape acquired by the measurement in a solid model are required. For this point of view, the octree representation is adopted as the solid model representing the workspace and a fast algorithm for measuring and registering obstacle shape in the octree is proposed. The octree is constructed hierarchically by a set of cubic regions in the workspace, and its data structure is suitable for checking an interference between a moving robot and its obstacles and searching for a free region in the robot path-planning.	algorithm;cubic function;data structure;interference (communication);motion planning;octree;robot;solid modeling;workspace	Hiroshi Noborio;Shozo Fukuda;Suguru Arimoto	1988		10.1109/ICPR.1988.28382	computer vision;simulation;data structure;computer science;machine learning;motion planning;octree	Robotics	61.01828335384808	-38.138174524947715	166425
a52bfd8b4ad4c9257b01856a6673a7045e6554de	camera-augmented mobile c-arm (camc) application: 3d reconstruction using a low-cost mobile c-arm	ccd camera;projective geometry;optical tracking;3d reconstruction;x rays	High-end X-ray C-arm gantries have recently been used for 3D reconstruction. Low-cost mobile C-arms enjoy the advantage of being readily available and are often used as interventional imaging device, but do not guarantee the reproducibility of their motion. The calibration and reconstruction process used for high-end C-arms cannot be applied to them. Camera-Augmented Mobile C-arm (CAMC) is the solution we propose. A CCD camera is attached to the (motorized) mobile C-arm in order to calibrate the C-arm’s projection geometry on-line. The relationship between X-ray and camera projection geometry is characterized in an off-line calibration process. We propose the notion of Virtual Detector (VD), which enables us to describe both optical and X-ray geometry as pinhole cameras with fixed intrinsic parameters. We have conducted experiments in order to compare the results of CAMC calibration with the calibration method used for high-end C-arms and using an optical tracking system (Polaris from Northern Digital, Inc.).	3d reconstruction;camera resectioning;charge-coupled device;coat of arms;computation;experiment;modality (human–computer interaction);motion estimation;online and offline;phantom reference;precomputation;radiography;real-time clock;region of interest;tracking system;x-ray (amazon kindle)	Nassir Navab;Matthias Mitschke;Oliver Schütz	1999		10.1007/10704282_75	3d reconstruction;computer vision;projective geometry;computer science;mathematics;geometry;charge-coupled device	Vision	55.09424054750479	-46.619867877302575	166540
2acedca741d004629588f577a686d5d87d4b0810	techniques for accelerated view-dependent mesh refinement	hierarchical data structure;level of detail;mesh refinement;data structure	View-dependent mesh refinement techniques typically pre-compute a hierarchical data structure that is queried at run-time to produce an approximation of a given mesh. This approximation, or level-of-detail (LOD), can be used in place of the original object so long as the viewpoint does not change. This should result in no loss of visible detail, yet should be less computationally expensive. The approach of existing techniques is to collapse or expand nodes in the hierarchical data structure level by level. We propose a new method for fast generation of view-dependent level-of-details when the frame-to-frame coherence is low, such as when an object moves or rotates at a rapid rate with respect to the viewpoint. Our method is based on two new techniques for aggressive detection of visible parts of the merge tree data structure. The jump split and jump collapse move the active nodes front up or down the tree many generations at a time, reducing the number and expense of iterations required to refine the mesh.	adaptive mesh refinement;analysis of algorithms;approximation;data structure;hierarchical database model;iteration;level of detail;merge algorithm;refinement (computing);tree (data structure)	James Strauss;Amitava Datta	2003			simulation;data structure;computer science;theoretical computer science;level of detail;t-vertices	Graphics	66.70504754622328	-50.69961316674402	166573
a8bed0492284694907da855dac9160cf38430ff9	sketching mls image deformations on the gpu	nvidia geforce 8800 gtx;paper;image processing;cuda;nvidia;algorithms;i 3 5 computer graphics computational geometry and object modeling boundary representations	Abstract#R##N##R##N#In this paper, we present an image editing tool that allows the user to deform images using a sketch-based interface. The user simply sketches a set of source curves in the input image, and also some target curves that the source curves should be deformed to. Then the moving least squares (MLS) deformation technique [SMW06] is adapted to produce realistic deformations while satisfying the curves' positional constraints. We also propose a scheme to reduce image fold-overs in MLS deformations. Our system has a very intuitive user interface, generates physically plausible deformations, and can be easily implemented on the GPU for real-time performance.	graphics processing unit	Yanlin Weng;Xiaohan Shi;Hujun Bao;Jun Zhang	2008	Comput. Graph. Forum	10.1111/j.1467-8659.2008.01324.x	computer vision;image processing;computer science;theoretical computer science;algorithm;computer graphics (images)	Vision	66.3387463743722	-50.20553093894341	166620
4416e23f06a9625eed7b05265ff336a868ba1740	real time ray tracing of point-based models	access point;caching;real time;normal mapping;irradiance;global illumination;soft shadow;lightmap;ray tracing;data structure;real time rendering	Mirroring the development of rendering algorithms for polygonal models, z-buffer style rendering for point-based models has given way recently to more advanced methods. A fast raycasting based approach [Wald and Seidel 2005] shows shadows, but does not demonstrate reflective effects. The more general raytracing approach [Linsen et al. 2007] is substantially slower.  We advance the state of the art by ray tracing point models in real time. Our system relies on an efficient way of storing and accessing point data structures on the GPU. We hope that this leads the way for future work towards more realistic global illumination effects including soft shadows, simultaneous reflection & refraction, and caustics.	algorithm;data structure;disk mirroring;global illumination;graphics processing unit;ray casting;ray tracing (graphics);z-buffering	Sriram Kashyap;Rhushabh Goradia;Parag Chaudhuri;Sharat Chandran	2010		10.1145/1730804.1730976	distributed ray tracing;ray tracing;computer vision;path tracing;data structure;3d rendering;computer science;programming language;real-time rendering;irradiance;normal mapping;global illumination;computer graphics (images)	Graphics	66.14142445212315	-51.350204065842235	166659
3d980d86b21350bf4b931713ee85e4de6c694971	adaptive display algorithm for interactive frame rates during visualization of complex virtual environments	visibility space;constrained optimization;global illumination;hidden surface removal;level of detail;algorithmic triage;image quality;radiosity;virtual environment;hierarchical model	We describe an adaptive display algorithm for interactive frame rates during visualization of very complex virtual environments. The algorithm relies upon a hierarchical model representation in which objects are described at multiple levels of detail and can be drawn with various rendering algorithms. The idea behind the algorithm is to adjust image quality adaptively to maintain a uniform, user-specified target frame rate. We perform a constrained optimization to choose a level of detail and rendering algorithm for each potentially visible object in order to generate the “best” image possible within the target frame time. Tests show that the algorithm generates more uniform frame rates than other previously described detail elision algorithms with little noticeable difference in image quality during visualization of complex models. CR	algorithm;constrained optimization;hierarchical database model;image quality;level of detail;mathematical optimization;virtual reality	Thomas A. Funkhouser;Carlo H. Séquin	1993		10.1145/166117.166149	image quality;computer vision;constrained optimization;radiosity;simulation;hidden surface determination;computer science;virtual machine;level of detail;global illumination;hierarchical database model;computer graphics (images)	Graphics	64.08414820627094	-50.171964597776665	166876
29023eb4b6a04ceb82e2007bb25f15bfc7993e80	a new approach to the preparation of models for fe analyses	detail removal;concepcion asistida;shape changes;computer aided design;modele geometrique;digitized model;idealisation;polyedre;component shape;idealization;poliedro;digitizing;cad;generation maille;digitised models;polyhedron;modele polyedrique;numerisation;finite element;model preparation;polyhedral model;geometric modelling;finite element fe analysis;conception assistee;numerizacion;finite element analysis;element fini;mesh generation;fea;elemento finito;changement forme;geometrical model;modelo geometrico	Most of the time, preparing a model for a FE analysis from a CAD model requires tedious tasks of geometric modelling to generate the component shape suited for that analysis. Detail removal, and shape idealisation treatments are among the operations required to obtain the component shape for a given analysis. Here, it is intended to describe how an appropriate geometric model and a set of geometric operators may signi®cantly improve the eciency of the FE model preparation phase. The geometric model proposed is based on a polyhedral representation of a component associated to a set of three categories of operators enabling: skin detail removal, topological changes, manifold changes (dimension reduction). These operators are associated to mechanical data to control the component shape changes. The above sets of treatments also accept a large variety of data as input: tessellated models produced by CAD systems, digitised models or pre-existing ®nite element models.	3d modeling;computer-aided design;concurrency and coordination runtime;dimensionality reduction;earliest deadline first scheduling;geometric modeling;high-level programming language;naruto shippuden: clash of ninja revolution 3;polyhedron;polytope model;simulation	Jean-Claude Léon;Lionel Fine	2005	IJCAT	10.1504/IJCAT.2005.006485	simulation;engineering;computer aided design;finite element method;shape analysis;geometry;engineering drawing	Graphics	67.07422855915753	-41.79610721317837	166932
34ac77601901851d9f7403fb13bdd08fd4211f18	visionary collaborative outdoor reconstruction using slam and sfm	cloud visionary collaborative outdoor reconstruction slam client scalable sfm engine structure from motion;j 7 computer applications computers in other systems real time;augmented and virtual realities;h 5 1 information interfaces and presentation multimedia information systems artificial;j 7 computer applications computers in other systems real time h 5 1 information interfaces and presentation multimedia information systems artificial augmented and virtual realities i 4 8 image processing and computer vision sceneanalysis tracking;simultaneous localization and mapping servers cloud computing collaboration three dimensional displays image reconstruction cameras;collaboration;slam robots cloud computing computer vision image motion analysis image reconstruction;servers;three dimensional displays;image reconstruction;simultaneous localization and mapping;i 4 8 image processing and computer vision sceneanalysis tracking;cameras;cloud computing	In this position paper, we argue about a concept for collaborative outdoor reconstruction using SLAM clients and a scalable SfM engine running in the cloud. Based on previous observations and results, we discuss issues like illumination changes, overall scalability or the dacay of buildings, having a serious impact on the practical feasibility of such a system. Revisiting ideas and insights from work on outdoor reconstruction and localization done in the last couple of years, we outline an idea for collaborative and vivid reconstruction of the world, potentially through the cameras of millions of mobile devices.	cloud computing;internationalization and localization;mobile device;scalability;simultaneous localization and mapping	Philipp Fleck;Dieter Schmalstieg;Clemens Arth	2016	2016 IEEE 9th Workshop on Software Engineering and Architectures for Realtime Interactive Systems (SEARIS)	10.1109/SEARIS.2016.7551588	computer vision;simulation;computer science;computer graphics (images)	Visualization	54.446385157491974	-45.464449016600774	167147
613b36cd3dce42ec5c5b86ef31ae308575dc1c55	modeling of real 3d object using photographs		The goal of this work is to create several functions for processing of two input images of one object to uncover a geometry of the scene. There are well-known techniques how to compute a fundamental matrix and reconstruct 3D coordinates. Several techniques were tested to find the method that is fast and rather precise. The functions are implemented in the environment of Borland C++ Builder. Calibrated cameras and start in a situation when several points are marked correctly in both pictures are assumed.	adobe flash builder;c++;c++builder;fundamental matrix (computer vision);image	Katerina Darilkova	2005			computer vision;artificial intelligence;fundamental matrix (computer vision);computer science	Graphics	57.9145479869394	-50.59106671679831	167161
26b96bd53694a405404cde4a455c620c5fd929c1	approximate svbrdf estimation from mobile phone video		We describe a new technique for obtaining a spatially varying BRDF (svBRDF) of a flat object using printed fiducial markers and a cell phone capable of continuous flash video. Our homography-based video frame alignment method does not require the fiducial markers to be visible in every frame, thereby enabling us to capture larger areas at a closer distance and higher resolution than in previous work. Pixels in the resulting panorama are fit with a BRDF based on a recursive subdivision algorithm, utilizing all the light and view positions obtained from the video. We show the versatility of our method by capturing a variety of materials with both one and two camera input streams and rendering our results on 3D objects under complex illumination. CCS Concepts •Computing methodologies → Reflectance modeling; Computational photography; Texturing;	algorithm;align (company);bidirectional reflectance distribution function;computation;computational photography;dictionary;feature extraction;fiducial marker;flash video;for loop;glossary of computer graphics;homography (computer vision);image resolution;image stitching;list of 3d rendering software;matching (graph theory);mobile phone;oblique projection;optical flow;pixel;printer (computing);printing;requirement;sampling (signal processing);self-similarity;sparse matrix;subdivision surface;tripod	Rachel A. Albert;Dorian Yao Chan;Dan B. Goldman;James F. O'Brien	2018		10.2312/sre.20181168	rendering (computer graphics);computer vision;mobile phone;pixel;panorama;computational photography;artificial intelligence;computer science;fiducial marker;homography;subdivision	Graphics	59.83282163895173	-50.05550578789554	167251
01cfdbfedf3e6fd9f2f438a34d50e7b5f81c8a09	knowledged-based support for 3d object reconstruction	knowledge base	Several methods have been proposed to reconstruct houses from aerial images, most of them using rather specific models. These methods can not be applied when dealing with european-style houses and when a high level of detail is required. It is necessary to include additional domain specific knowledge in order to increase robustness and speed up the extraction process. We present a system that works with rules instead of parameterizable shape models. This allows a larger variability of the objects to be extracted but also results in a more complex structure of the knowledge base and in a more sophisticated reasoning control. In the application section we demonstrate the use of such a system for reconstructing an object made up of planar surfaces from an aerial image.	aerial photography;approximation algorithm;color;event-driven programming;high-level programming language;knowledge base;level of detail;robustness (computer science);semantic network;semiconductor industry;spatial variability;top-down and bottom-up design	Wolfram Willuhn;Frank Ade	1996			artificial intelligence;machine learning;computer science;knowledge base	Vision	58.576756975634346	-45.313584052388784	167349
3bcbc218f717e477e7f8d2dd71771210e4e25f8b	a procedure for checking the topological consistency of a 2-d or 3-d finite element mesh	3-d finite element mesh;topological consistency;optional side;optional edge;two-dimensional mesh;dimensional mesh;brick-shaped element;center node;three-dimensional finite element mesh;three dimensional;finite element methods;shape;displays;graphics;mechanical engineering;arithmetic;stress	This paper describes procedures for checking the topological consistency of two- or three-dimensional finite element meshes. Two-dimensional meshes may include mixtures of triangles, quadrilaterals and other polygons, with optional side and center nodes. Three dimensional meshes may include tetrahedra and brick-shaped elements, with optional edge, face or center nodes.	finite element method	Kenneth Preiss	1979	16th Design Automation Conference		three-dimensional space;discrete mathematics;extended finite element method;shape;computer science;volume mesh;graphics;finite element method;mathematics;geometry;stress;mixed finite element method;engineering drawing	EDA	68.2329476755852	-42.198839444196025	167446
4ce1a28ecc33d7b84dc3ddf12a4aed4bd0a6f6bc	combining scene and auto-calibration constraints	auto calibration;image processing;computational techniques;hip;vanishing points;geometry;layout;programmable logic arrays;scene features;layout cameras calibration read only memory equations geometry hip programmable logic arrays ear h infinity control;single views;image planes;constraint combination;ear;stereo pairs;scene planes;imaged scene structure;h infinity control;camera characteristics;rectified planes;read only memory;calibration;calibration of cameras;cameras;constraint combination auto calibration single views stereo pairs calibration of cameras imaged scene structure vanishing points rectified planes scene planes scene features camera characteristics image planes;image processing calibration	We presenta simpleapproach to combiningsceneand auto-calibrationconstraints for thecalibration of cameras fromsingleviewsandstereopairs. Calibration constraints are provided by imaged scenestructure, such as vanishing pointsof orthogonaldirections,or rectifiedplanes. In addition, constraints are available from the nature of the camerasandthemotionbetweenviews.Weformulatethese constraintsin termsof thegeometryof theimagedabsolute conic and its relationshipto pole-polarpairs and the imagedcircular pointsofplanes.Threesignificantadvantages result: first, constraints fromscenefeatures,camera characteristicsand auto-calibration constraints provide linear equationsin theelementsof theimageof theabsoluteconic. This meansthat constraints mayeasilybe combined,and their solutionis straightforward. Second,thedegeneracies that occur whenconstraints are not independentmay be easilyidentified. Lastly, the constraints from sceneplanes and image planesmaybe treateduniformly. Examplesof variouscasesof constraint combinationanddegeneracyas well ascomputationaltechniquesare presented.	vanishing gradient problem	David Liebowitz;Andrew Zisserman	1999		10.1109/ICCV.1999.791233	layout;computer vision;calibration;vanishing point;image processing;computer science;mathematics;geometry;read-only memory	Vision	54.39586671830136	-50.64149017683099	167458
8a31fdb5bda742195f391b2f66014c6dc5f09f80	3d freeform surfaces from planar sketches using neural networks	forma libre;image tridimensionnelle;vision ordenador;image processing;neural networks;multilayer perceptrons;free form;procesamiento imagen;multilayer perceptron;surface reconstruction;traitement image;computer vision;conference paper;perceptron multicouche;reconstruction image;reconstruction surface;forme libre;mlp neural network;red multinivel;g600 software engineering;reconstruccion imagen;sketch based interfaces;image reconstruction;tridimensional image;w200 design studies;vision ordinateur;multilayer network;reconstruccion superficie;reseau multicouche;reseau neuronal;freeform surfaces;red neuronal;imagen tridimensional;neural network	A novel intelligent approach into 3D freeform surface reconstruction from planar sketches is proposed. A multilayer perceptron (MLP) neural network is employed to induce 3D freeform surfaces from planar freehand curves. Planar curves were used to represent the boundaries of a freeform surface patch. The curves were varied iteratively and sampled to produce training data to train and test the neural network. The obtained results demonstrate that the network successfully learned the inverse-projection map and correctly inferred the respective surfaces from fresh curves.	3d computer graphics;adobe freehand;artificial neural network;control point (mathematics);freeform surface modelling;google reader;hidden markov model;java object oriented neural engine;map projection;memory-level parallelism;microsoft windows;multilayer perceptron;netbeans ide;planar graph;quad flat no-leads package;randomness	Usman Khan;Abdelaziz Terchi;Sungwoo Lim;David K. Wright;Sheng Feng Qin	2006		10.1007/11893257_73	iterative reconstruction;computer vision;surface reconstruction;computer science;artificial intelligence;machine learning;multilayer perceptron;artificial neural network;computer graphics (images)	Vision	62.17933097760016	-44.677042106271756	167497
2ba9477cd8fa90486b14317ee181e486c3c4958b	telecentric optics for focus analysis	optical distortion;focusing;depth from focus;vision techniques;focus setting;focusing lenses calibration optical variables control apertures layout geometrical optics optical distortion optical imaging machine vision;commercial lenses;motion estimation;layout;aperture placement;photometric properties;telecentric lenses;computer vision;optical focusing;defocus;optical imaging;constant magnification imaging;magnification invariance;machine vision;lenses;optical focusing lenses motion estimation computer vision;phase based shift detection algorithm;geometric properties;optical configuration;phase based motion estimation;focus analysis;calibration;telecentric optics;depth from focus defocus;apertures;optical variables control;geometrical optics;magnification invariance telecentric optics focus analysis magnification variations focus setting vision techniques depth from focus defocus optical configuration geometric properties photometric properties telecentric lenses phase based shift detection algorithm;magnification variations	Magnification variations due to changes in focus setting pose problems for vision techniques, such as, depth from focus and defocus. The magnification of a conventional lens can be made invariant to defocus by simply adding an aperture at an analytically derived location. The resulting optical configuration is called “telecentric.” It is shown that most commercially available lenses can be turned into telecentric ones. The procedure for calculating the position of the additional aperture and a detailed analysis of the photometric and geometric properties of telecentric lenses are presented. Experiments are reported that use a phase-based shift detection algorithm to demonstrate the magnification invariance of telecentric lenses.	algorithm;experiment;image sensor;pixel;step detection;telecentric lens	Masahiro Watanabe;Shree K. Nayar	1997	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.643894	layout;geometrical optics;aperture;computer vision;calibration;machine vision;computer science;motion estimation;optical imaging;lens;computer graphics (images)	Vision	56.33786806780824	-49.78245864402124	168074
3c948b1ae545a6505b89097dd6fcd16ab139ccd3	structure from motion from three affine views	image motion analysis image reconstruction tensors;image motion analysis;minimal trifocal tensor structure from motion reconstruction affine views image sequences 1d projective camera relative camera orientations infinity 1d trifocal tensor;cameras tensile stress h infinity control algorithm design and analysis computer science reflection;image reconstruction;point of view;structure from motion;tensors	We describe a new method for Structure From Motion from three affine views. The central idea of the method is to explore the intrinsic three-view properties instead of previous two-view ones. The first key observation is that an affine camera is indeed essentially a one-dimensional projective camera operating on the plane at infinity : we prove that the essential motion—relative camera orientations—is entirely encoded by the infinity 1D trifocal tensor. From a practical point of view, this analysis allows the development of two new algorithms of SFM from three views. One based on entirely the minimal trifocal tensor and another on affine three-view constraints. Both algorithms are novel as all previous SFM from three views have been heavily based on only two-view constraint to extract Euclidean structure. These algorithms have been demonstrated on real image sequences.	algorithm;structure from motion;trifocal tensor	Long Quan;Maxime Lhuillier	2002		10.1109/ICPR.2002.1047387	iterative reconstruction;computer vision;structure from motion;topology;tensor;computer science;affine plane;mathematics;geometry;affine shape adaptation;motion field;trifocal tensor	Vision	53.79501750576444	-50.917132273007006	168097
c6f75c21e021c748a6c9a28d50b8c6106855b100	spatio-temporal laser to visual/inertial calibration with applications to hand-held, large scale scanning	stereo image processing calibration cameras image reconstruction laser ranging optical scanners portable instruments;spatiotemporal calibration spatio temporal laser visual calibration inertial calibration large scale scanning laser range finder stereo camera inertial measurement unit continuous time batch estimation hand held scanning device 3d image reconstructions image based point cloud coloring;measurement by laser beam calibration three dimensional displays cameras laser modes visualization estimation	This work presents a novel approach to spatio-temporal calibration of a laser range finder (LRF) with respect to a combination of a stereo camera and an inertial measurement unit (IMU). Spatial calibration between an LRF and a camera has been extensively studied, but so far the temporal relationship between the two has largely been neglected. While this may be sufficient for applications where the setup is mounted on a vehicle, which imposes bounds on the dynamics, we aim for employment on a hand-held scanning device, where angular velocities can easily exceed hundreds of degrees per second. Employing a continuous-time batch estimation framework, this work demonstrates that the transformation between the LRF and the visual/inertial setup-but also its temporal relationship-can be estimated accurately. In contrast to the majority of established calibration approaches, our approach does not require an overlap in the field of view of the LRF and camera, allowing for previously infeasible sensor configurations to be calibrated. Preliminary results for a novel hand-held scanning device suggest improvements in 3D reconstructions and image based point cloud coloring, especially for highly dynamic motions.	angularjs;clock drift;graph coloring;handheld game console;loss function;mobile device;optimization problem;point cloud;sensor;stereo camera	Jörn Rehder;Paul A. Beardsley;Roland Siegwart;Paul Timothy Furgale	2014	2014 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2014.6942599	computer vision;optics;physics;remote sensing	Robotics	54.307033393604904	-44.7999456875969	168338
12b9c5dbb6c0f7eec064fdfdf80d23c5699b0db9	3-dimensional reconstruction on tagged packages via rfid systems		Nowadays, 3D reconstruction has been introduced in monitoring the package placement in logistic industry-related applications. Existing 3D econstruction methods are mainly based on computer vision or sensor-based approaches, which are limited by the line-of-sight or battery life constraint. In this paper, we propose RF-3DScan to perform 3D reconstruction on tagged packages via passive RFID, by attaching multiple reference tags onto the surface of the packages. The basic idea is that by moving the antenna along straight lines within a constrained 2-dimensional space, the antenna obtains the RF-signals of the reference tags attached on the packages. By extracting the phase differences to build the angle profile for each tag, RF-3DScan can compare the angle profiles of the different reference tags and derive their relative positions, then further determine the package orientation and stacking for 3D reconstruction. We implement RF- 3DScan and evaluate its performance in real settings. The experiment results show that the average identification accuracy of the bottom face is about 92.5%, and the average estimation error of the rotation angle is about 4.08&#186;.	3d reconstruction;computer vision;line-of-sight (missile);radio frequency;radio-frequency identification;stacking	Yanling Bu;Lei Xie;Jia Liu;Bingbing He;Yinyin Gong;Sanglu Lu	2017	2017 14th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)	10.1109/SAHCN.2017.7964911	3d reconstruction;computer science;battery (electricity);stacking;distributed computing;embedded system;computer hardware;mobile telephony	Visualization	57.531091197023244	-38.29759535833752	168403
3a48335b88f799b36e9a129d9e73e47092554960	on the priority approach to hidden-surface algorithms (preliminary report)	finite element methods;complexity theory;technological innovation;performance evaluation;paints;application software;computer graphics;efficient algorithm;bismuth;computational modeling application software image generation computer graphics computer displays layout paints aerospace simulation testing performance evaluation;testing;layout;observers;aerospace simulation;computer graphic;surface treatment;computational modeling;image generation;periodic structures;displays;computer displays;transforms;mathematical model;joining processes;terminology;algorithm design and analysis;buildings;space vehicles;real time systems	The task of eliminating invisible parts when generating an image is one of the central problems in computer graphics. One approach achieves the desired obscuring effect by assigning priority numbers to the faces of an object. Image generation can be speeded up significantly in these priority schemes if priority information of the faces can be partly computed in advance, before a viewing position is specified. These observations were first made by Schumacker and are utilized to advantage in simulation applications. However, the priority calculations are usually done manually, for lack of an adequate theoretical understanding. In this paper we study the underlying mathematical structure of these priority orders, and present efficient algorithms for handling some special classes of geometrical configurations.	algorithm	F. Frances Yao	1980		10.1109/SFCS.1980.32	layout;priority inheritance;algorithm design;combinatorics;application software;simulation;computer science;theoretical computer science;finite element method;bismuth;mathematical model;mathematics;software testing;computer graphics;terminology;computational model;algorithm	Theory	62.59139837787952	-41.07219010783342	168453
4180b0ff4bfa0034e674826843a896b50dd2ae46	hybrid tree reconstruction from inhomogeneous point clouds	reconstruction;trees;point clouds	Trees are an important asset for natural-looking digital environments. We propose a novel method to automatically reconstruct tree geometry from inhomogeneous point clouds created by a laser scanner. While previous approaches focus either on dense or sparse point clouds, our hybrid method allows for the reconstruction of a tree from an inhomogeneous point cloud without further preprocessing. Using principal curvatures as indicators for branches, we detect ellipses in branch cross-sections and create branch skeletons for dense regions. For sparse regions we approximate branch skeletons with a spanning tree. Branch widths are obtained from the ellipse fitting in dense regions and propagated to the sparse regions, to create geometry for the whole tree. We demonstrate the effectiveness of our approach in several real-world examples.	approximation algorithm;curve fitting;file spanning;martin kay;point cloud;preprocessor;procedural modeling;sampling (signal processing);spanning tree;sparse matrix;tree (data structure)	Fabian Aiteanu;Reinhard Klein	2014	The Visual Computer	10.1007/s00371-014-0977-7	mathematical optimization;combinatorics;computer science;point cloud;mathematics;geometry	Vision	63.411083147805684	-43.75309473391278	168511
e21dbe71055cdac1604b87d0d66b8c61e09b7b65	image georeferencing using lidar data	automatic control;high resolution;conjugate point;reference frame;laser radar;surface reconstruction;large scale;semantic information;urban areas;redundancy;global positioning system;image reconstruction;feature integration;performance analysis;urban area;space technology;laser radar surface reconstruction space technology image reconstruction automation large scale systems urban areas automatic control redundancy global positioning system;large scale systems;automation	LIDAR technology is increasingly becoming an industry-standard tool for collecting high resolution data about physical surfaces. LIDAR is characterized by directly collecting numerical 3D coordinates of object space points. Still, the discrete and positional nature of LIDAR datasets makes it difficult to derive semantic surface information. Furthermore, reconstructed surfaces from LIDAR data lack any inherent redundancy that can be utilized to enhance the accuracy of acquired data. In comparison to LIDAR systems, photogrammetry produces surfaces rich in semantic information that can be easily identified in the captured imagery. The redundancy associated with photogrammetric intersection results in highly accurate surfaces. However, the extended amount of time needed by the photogrammetric procedure to manually identify conjugate points in overlapping images is a major disadvantage. The automation of the matching problem is still an unreliable task especially when dealing with large scale imagery over urban areas. Also, photogrammetric surface reconstruction demands adequate control in the form of control points and/or GPS/INS units. In view of the complementary characteristics of LIDAR and photogrammetric systems, a more complete surface description can be achieved through the integration of both datasets. The advantages of both systems can be fully utilized only after successful registration of the photogrammetric and LIDAR data relative to a common reference frame. The adopted registration methodology has to define a set of basic components, mainly: registration primitives, mathematical function, and similarity assessment. This paper presents the description and implementation of a registration approach that utilizes straightline features derived from both datasets as the registration primitives. LIDAR lines are used as control for the imagery and are directly incorporated in the photogrammetric triangulation. The performance analysis is based on the quality of fit between the LIDAR and photogrammetric models including derived orthophotos.	control point (mathematics);global positioning system;image resolution;matching (graph theory);numerical analysis;photogrammetry;redundancy (engineering);reference frame (video);tuple space	Ayman F. Habib;Mwafag S. Ghanma;Edson A. Mitishita;Eui-Myoung Kim;Changjae Kim	2005	Proceedings. 2005 IEEE International Geoscience and Remote Sensing Symposium, 2005. IGARSS '05.	10.1109/IGARSS.2005.1525322	iterative reconstruction;reference frame;lidar;computer vision;simulation;image resolution;surface reconstruction;global positioning system;automation;automatic control;space technology;redundancy;remote sensing	Visualization	56.27543689136109	-47.482543965152146	168708
74cf1492c9e4bc1a364884688e30efe60e3a33c5	research on constructing 3-d pipeline connection model by using opengl	3d modeling;3d pipeline connection model;computer graphics;construction industry;data visualisation;visualization;computational modeling;digital city;3d pipe;three dimensional displays;pipelines;application program interfaces;solid modeling;opengl visualization 3d pipe;pipelines application program interfaces computer graphics data visualisation government data processing management information systems;management information systems;opengl;pipelines visualization management information systems cities and towns computer science software engineering research and development management technology management engineering management geographic information systems;management information system;3d pipeline complexity connection;government data processing;3d pipeline complexity connection 3d pipeline connection model opengl 3d modeling visualization digital city pipeline management information system;pipeline management information system	3-D modeling and visualization of pipeline is an indispensable and important component that constructed digital city and implementation of pipeline management information system. This paper describes the basic steps that constructed 3-D pipeline connection by using the initial points set, and especially discusses the key issues of constructed the 3-D pipeline complexity connection by using OpenGL. At last, the author proved the theory mentioned in this article by experiment, it shows that 3-D geometric transformation and datum plane rotation can realize the visualization of 3-D pipeline complexity connection efficiently and conveniently, and this technology have achieved good effect in the practical application.	opengl	Huaqing Mao;Fuling Bian	2008		10.1109/CSSE.2008.1430	graphics pipeline;simulation;visualization;computer science;theoretical computer science;management information systems;database;pipeline transport;solid modeling;computer graphics;computational model;computer graphics (images)	HCI	64.71106054502306	-43.19395517571871	168714
86e656d1f0e0b88e5a6108872d26f65255c26429	geometric modeling of broad-leaf plants leaf based on bb-spline	b;surface interpolation;leaf;curve interpolation;nurbs surfaces;reverse engineering	Realistic rendering of plants has practical value for digital plant research, where plant leaves play an important role in the construction of virtual plants. The fact is that plant leaves are diversified in structure and geometric shape, which usually makes the realistic rendering of plants leaves very difficult. Many existed modeling and simulation methods have been focused on the organs of plantmodels, inwhich leaves aremodeled using simple 2D polygons and the thickness of leaves are neglected. Such models are far from realistic. This paper proposes a new modeling method of broad-leaf plants, based on the theory of reverse engineering. A leaf model is established by acquiring data on the characteristic points from the leaf of the sample part and combining the advantages ofOpenGL andNURBS functions. © 2011 Elsevier Ltd. All rights reserved.	geometric modeling;global illumination;reverse engineering;simulation;spline (mathematics);thickness (graph theory)	Xiaogang Wang;Li Li;Wenting Chai	2013	Mathematical and Computer Modelling	10.1016/j.mcm.2011.10.064	leaf;geometry;reverse engineering	Graphics	66.48705241862795	-43.854791566547505	168744
df21fb2c7bdc18b8f4ffc19203bffc592e417291	natural pose generation from a reduced dimension motion capture data space	motion capture data;motion capture;range of motion;principal component analysis;inverse kinematics;human animation	Human animation from motion capture data is typically limited to whatever movement was performed by the actor. A method to create a wider range of motion in the animation utilizes the motion capture database to synthesize new poses. This paper proposes a method to generate original natural poses based on the characteristics of natural poses based on motion capture data. Principal Component Analysis is used to transform the data into a reduced dimensional space. An unconstrained pose data set is created by calculating the position of the human skeleton based on the reduced dimensional space. Constrained pose data can be created using interpolation and iteration on the unconstrained pose data. We show some example results of the generated poses and compare these poses to poses created with iterative inverse kinematics methods. Results show that our method is more accurate and more natural than iterative inverse kinematics methods.	dataspaces;motion capture	Reza Ferrydiansyah;Charles B. Owen	2009		10.1007/978-3-642-10331-5_49	computer vision;motion capture;simulation;range of motion;computer science;inverse kinematics;principal component analysis;computer graphics (images)	Robotics	60.185803721599996	-45.02447036179716	168748
a1a9bfc787109876583f263bc900b5e67e4c3c4a	viewpoint invariant matching via developable surfaces	depth information;consumer depth camera;image data;real world scene;geometry data;viewpoint invariant;dominant scene plane;different viewpoint;different object;rgbd image;developable surface;developable scene surface	depth information;consumer depth camera;image data;real world scene;geometry data;viewpoint invariant;dominant scene plane;different viewpoint;different object;rgbd image;developable surface;developable scene surface	viewpoint	Bernhard Zeisl;Kevin Köser;Marc Pollefeys	2012		10.1007/978-3-642-33868-7_7	computer vision;mathematics;computer graphics (images)	Vision	56.22258019603105	-50.913322817220326	168929
235b898dac8ebc31119d352d43b4a435df87f011	animating by example	corresponding part;example-driven synthesis approach;prototype system;source animation;corresponding portion;target character;dolphin animation;animating example;source mesh;full angel animation video;animation	In this paper, we propose an example-driven synthesis approach to create 3D animation of a target character. Our approach consists of the following steps: (a) a sketch-based mapping between parts of the sources and corresponding portions of the target; (b) calculating the affine matrix of the source mesh for each vertex; (c) deforming the target based on the deformations of the corresponding parts of the sources by means of mean value coordinates. We provide new research contributions on all these topics and integrate them into our newly developed prototype animating system. Our approach is general and does not require the sources and target to share the same number of vertices or triangles, or to have matching connectivity. In our system, source animations can be any 3D animations and the target can even be unstructured or point cloud. Our approach is intuitive and is able to produce highly authentic 3D animations. We demonstrate our approach by constructing a full angel animation video from parts of kid and dolphin animations. Other animating examples produced from our prototype system are also given in the paper to illustrate our approach. Copyright © 2007 John Wiley & Sons, Ltd.		Difei Lu;Xiuzi Ye;Guomin Zhou	2007	Journal of Visualization and Computer Animation	10.1002/cav.180	anime;computer vision;simulation;computer science;artificial intelligence;computer graphics (images)	Visualization	64.6995748254269	-46.69881616168382	169104
89b7ce5436769fc0fb5897f6e48a0240690fb062	geometric algebra of points, lines, planes and spheres for computer vision and robotics	projective and affine geometry;computer vision;visually guided robotics;3d rigid motion;incidence algebra;geometric algebra;clifford geometric algebra	This paper introduces conformal geometric algebra (CGA) for applications in computer vision and robotics. The authors show that CGA deals with our intuition and insight of the geometry and it helps us to reduce considerably the computational burden of the problems. The CGA can be applied not only to describe the geometry of the space, but to handle the algebra of incidence, as well as conformal transformations, to deal with kinematics or projective geometry problems. The authors show with real and simulated applications that this system can be of great advantage in robotics and computer vision.	computation;computer vision;conformal geometric algebra;entity;experiment;incidence matrix;odometry;robot;robotics	Eduardo Bayro-Corrochano;Luis Eduardo Falcón	2005	Robotica	10.1017/S0263574705001657	geometric algebra;projective geometry;topology;incidence algebra;universal geometric algebra;pure mathematics;mathematics;geometry;conformal geometric algebra	Robotics	53.825358814216905	-48.471174022469135	169353
52f7c159636b466590fbfa2dacdc5689583415e2	matching delauny triangulations by probabilistic relaxation	bayesian framework;delaunay triangulation;computer vision;radar imaging;voronoi tessellation;support function	Abs t rac t . This paper describes a Bayesian framework for matching Delaunay triangulations. Relational structures of this sort are ubiquitous in intermediate level computer vision, being used to represent both Voronoi tessellations of the image plane and volumetric surface data. Our matching process is realised in terms of probabilistic relaxation. The novelty of our method stems from its use of a support function specified in terms of face-units of the graphs under match. In this way we draw on more expressive constraints than is possible at the level of edge-units alone. In order to apply this new relaxation process to the matching of realistic imagery requires a model of the compatibility between faces of the data and model graphs. We present a particularly simple compatibility model that is entirely devoid of free parameters. It requires only knowledge of the number of nodes, edges and faces in the model graph. The resulting matching scheme is evaluated on radar images.	computer vision;delaunay triangulation;image plane;linear programming relaxation;radar	Andrew M. Finch;Richard C. Wilson;Edwin R. Hancock	1995		10.1007/3-540-60268-2_316	support function;combinatorics;topology;delaunay triangulation;voronoi diagram;centroidal voronoi tessellation;pitteway triangulation;point set triangulation;mathematics;geometry;constrained delaunay triangulation;radar imaging;surface triangulation;bowyer–watson algorithm	Vision	58.85191747645251	-45.08520182418203	169375
2e364e45c0e1d719746055853b932ea5a578466c	a 3d-cnn approach for the spatio-temporal modeling of surface deterioration phenomena		The modeling of spatio-temporal changes on the surface of materials is an open problem with important applications in domain such as computer graphics and cultural heritage. Significant progress has been achieved over the years and the results of several methods look realistic up to a certain degree. Nonetheless, the proposed approaches are not directly connected to physical measurements in most cases. In this paper, we propose a method that uses 3D surface measurements on bronze panels that are artificially aged and models the variations that occur over time due to the different physiochemical processes that take place. The input of our algorithm is the 3D point cloud of a material's surface while the output is a prediction of this point cloud in other time instances. At the core of the method lies a module that maps the point cloud of a material's surface into 3D occupancy grids and a 3D Convolutional Neural Network (CNN) that captures geometric changes over time. The training of the 3D-CNN is performed using registered point clouds from bronze panels that are artificially aged and scanned in three time instants. In order to measure the convergence of the training process, aside the minimization of the the 3D-CNN cost function, a complementary approach is proposed using the Normal Distribution Function of the generated surface. The experimental evaluation of the method demonstrates its potential.	3d computer graphics;algorithm;convolutional neural network;loss function;map;point cloud	Nikos Dimitriou;Stavros Papadopoulos;Anastasios Drosou;Dimitrios Tzovaras	2018	2018 IEEE 13th Image, Video, and Multidimensional Signal Processing Workshop (IVMSP)	10.1109/IVMSPW.2018.8448952	open problem;convolutional neural network;point cloud;feature extraction;computer vision;solid modeling;normal distribution;computer graphics;artificial intelligence;computer science;convergence (routing)	Vision	59.32380846846285	-51.641546861342924	169438
5f3420f0aea4617b43f0b272bbf48c5f2d9d110b	ray-space360: an extension of ray-space for omnidirectional free viewpoint		Conventional 3DoF (Degree of Freedom) systems provide only rotational view transformation. 6DoF VR systems offer a more realistic VR by supporting view transformation for translational movement. This paper proposes ray-space 360 which supports both rotational and translational view transformation simultaneously. Ray-space360 is an extension of ray-space [1–3] to an omnidirectional view in order to support a new camera structure in a square form for ray-space360 configuration. Ray-space360 also provides a way to use the intersection to connect independent ray-spaces. Thanks to its low complexity, the proposed system can provide real-time service with a low performance processor such as a mobile processor. This paper presents the result of 4DoF ray-space360 which provides view transformation of yaw, pitch, x, and z axes. The ray-space360 can be extended to 6DoF simply by stacking cameras.	glossary of computer graphics;mobile processor;real-time clock;stacking;yaws	Hyunmin Jung;Hyuk-Jae Lee;Chae-Eun Rhee	2018	2018 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2018.8351480	degrees of freedom (statistics);computational science;mobile processor;stacking;electronic engineering;omnidirectional antenna;solid modeling;computer science	Embedded	61.11151481949201	-44.04514542510619	169733
d71a9c8b41f648e412f11528bc060efc4c19cb4e	ship-hull geometry representation with b-spline surface patches	modelizacion;concepcion asistida;computer program;computer aided design;casco buque;ship design;hull form;forma geometrica;b spline surface;modelisation;aproximacion esplin;hulls;hull;spline approximation;approximation spline;geometrical shape;vehicle design;conception assistee;naval architecture;forme geometrique;b spline;coque navire;programa computador;modeling;programme ordinateur	A program for the representation of ship-hull geometry by means of B-spline curves and surfaces has been developed. Lines on the hull surface running along the length of the ship and sections with transverse planes are interpolated by B-splines. The vectors tangent to longitudinal ship lines on their intersections with transverse sections are also interpolated by B-splines. B-spline surface patches are generated between consecutive transverse sections. Tangent-vector continuity is preserved across the patches. Bias functions applied to tangent vectors enhance design flexibility. Special features, such as knuckles and plane areas, are easily incorporated. Interaction with the program is accomplished through a suitable user interface.	b-spline	Leonidas Bardis;Maria-Eleni Vafiadou	1992	Computer-Aided Design	10.1016/0010-4485(92)90058-I	simulation;engineering;naval architecture;computer aided design;hull;geometry;engineering drawing;mechanical engineering	EDA	68.06251209727901	-38.94855740317663	169977
abbcf3f441ddb72e0480226d7e42379964d2afda	procedural wang tile algorithm for stochastic wall patterns		The game and movie industries always face the challenge of reproducing materials. This problem is tackled by combining illumination models and various textures (painted or procedural patterns). Generating stochastic wall patterns is crucial in the creation of a wide range of backgrounds (castles, temples, ruins...). A specificWang tile set was introduced previously to tackle this problem, in a non-procedural fashion. Long lines may appear as visual artifacts. We use this tile set in a new procedural algorithm to generate stochastic wall patterns. For this purpose, we introduce specific hash functions implementing a constrained Wang tiling. This technique makes possible the generation of boundless textures while giving control over the maximum line length. The algorithm is simple and easy to implement, and the wall structure we get from the tiles allows to achieve visuals that reproduce all the small details of artist painted walls.	algorithm;artifact (software development);castles;hash function;illumination (image);procedural programming;tile-based video game;tiling window manager;visual artifact;wang tile	Alexandre Derouet-Jourdan;Marc Salvati;Theo Jonchier	2017	CoRR		visual artifact;artificial intelligence;tile;computer vision;computer science;hash function;wang tile;theoretical computer science;algorithm	Graphics	63.7637799757015	-48.21294051976286	170400
0dda5bcd88e907150d9eb7d459061dc30e86a4d7	dense disparity maps in real-time with an application to augmented reality	similarity accumulator;concurrent computing;dense disparity maps;application software;real time;binocular stereo camera system;layout;three dimensional;proper occlusions;visualization;augmented reality layout cameras object detection real time systems image edge detection visualization educational institutions concurrent computing application software;image edge detection;area matching;stereo image processing;stereo correspondence;augmented reality;stereo image pair;similarity accumulator dense disparity maps binocular stereo camera system augmented reality stereo image pair proper occlusions stereo correspondence area matching;cameras;object detection;real time systems augmented reality stereo image processing;virtual worlds;real time systems	This work presents a technique for computing dense disparity maps from a binocular stereo camera system. The methods are applied in an Augmented Reality setting for combining real and virtual worlds with proper occlusions. The proposed stereo correspondence technique is based on area matching and facilitates an efficient strategy by using the concept of a three-dimensional similarity accumulator , whereby occlusions are detected and object boundaries are extracted correctly. The main contribution of this paper is the way we fill the accumulator using absolute differences of images and computing a mean filter on these difference images. This is where the main advantages of the accumulator approach can be exploited, since all entries can be computed in parallel and thus extremely efficient. Additionally, we perform an asymmetric correction step and a post-processing of the disparity maps that maintains objec t edges.	accumulator (computing);augmented reality;binocular disparity;binocular vision;closing (morphology);computation;image rectification;image resolution;map;mathematical morphology;median filter;method (computer programming);pixel;real-time computing;real-time transcription;stereo camera;sum of absolute differences;time complexity;video post-processing;virtual world	Jochen Schmidt;Heinrich Niemann;Sebastian Vogt	2002		10.1109/ACV.2002.1182186	layout;three-dimensional space;computer vision;augmented reality;application software;simulation;visualization;concurrent computing;computer science;computer graphics (images)	Vision	55.16424306307849	-48.56722199806414	170415
1c030f3c43300255b0c316e8b481db746ca28f42	direct sensor orientation of a land-based mobile mapping system	health research;uk clinical guidelines;biological patents;pedestrian safety;poison control;europe pubmed central;injury prevention;citation search;safety literature;mobile mapping systems;traffic safety;injury control;direct georeferencing;home safety;injury research;safety abstracts;human factors;uk phd theses thesis;occupational safety;safety;life sciences;mounting parameters;safety research;direct sensor orientation;accident prevention;violence prevention;bicycle safety;camera calibration;poisoning prevention;uk research reports;medical journals;falls;ergonomics;suicide prevention;europe pmc;biomedical research;bioinformatics	A land-based mobile mapping system (MMS) is flexible and useful for the acquisition of road environment geospatial information. It integrates a set of imaging sensors and a position and orientation system (POS). The positioning quality of such systems is highly dependent on the accuracy of the utilized POS. This limitation is the major drawback due to the elevated cost associated with high-end GPS/INS units, particularly the inertial system. The potential accuracy of the direct sensor orientation depends on the architecture and quality of the GPS/INS integration process as well as the validity of the system calibration (i.e., calibration of the individual sensors as well as the system mounting parameters). In this paper, a novel single-step procedure using integrated sensor orientation with relative orientation constraint for the estimation of the mounting parameters is introduced. A comparative analysis between the proposed single-step and the traditional two-step procedure is carried out. Moreover, the estimated mounting parameters using the different methods are used in a direct geo-referencing procedure to evaluate their performance and the feasibility of the implemented system. Experimental results show that the proposed system using single-step system calibration method can achieve high 3D positioning accuracy.	assisted gps;axis vertebra;cns disorder;calibration;emoticon;estimated;geo (microformat);geomatics;global positioning system;gray platelet syndrome;large;methyl methanesulfonate;mobile mapping;national supercomputer centre in sweden;natural science disciplines;numerous;optic axis of a crystal;photogrammetry;qualitative comparative analysis;rop chemical;receiver operator characteristics;tuple space;weakness;format;funding grant;receptor operated channel;sensor (device)	Jiann-Yeou Rau;Ayman F. Habib;Ana Paula Kersting;Kai-Wei Chiang;Ki-In Bang;Yi-Hsing Tseng;Yu-Hua Li	2011		10.3390/s110707243	embedded system;gps/ins;camera resectioning;simulation;telecommunications;computer science;bioinformatics;engineering;suicide prevention;electrical engineering;human factors and ergonomics;injury prevention;forensic engineering;computer security	Robotics	57.67710981003445	-39.71872039149184	170540
e9514015edba5b27bf53bc2759bdb973f2e6319e	efficient estimation of target detection quality		The capability of determining the quality of target detections is important for applications using smart cameras, such as autonomous robotics and surveillance. We propose to estimate the quality of target detections by integrating the target location uncertainty over polygonal domains, which represent the fields of view of the cameras. We define a framework based on numerical integration that easily accommodates multiple models for uncertainty and fields of view. We perform quadrature-based integration combined with importance sampling to provide accurate quality estimations while reducing the computational cost. The proposed method outperforms alternative approaches in terms of estimation accuracy and execution time. We validate the proposed approach with a recent distributed multi-camera multi-target tracker and improved it by considering realistic fields of view. Results demonstrate the effectiveness of the proposed method in decreasing the state estimation error.	algorithmic efficiency;autonomous robot;computation;importance sampling;numerical analysis;numerical integration;robotics;run time (program lifecycle phase);sampling (signal processing);sensor	Juan Carlos SanMiguel;Andrea Cavallaro	2017	2017 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2017.8296414	computer vision;numerical integration;importance sampling;object detection;smart camera;computer science;multiple models;robotics;artificial intelligence	Robotics	53.959951427073165	-39.09018214363605	170574
b0754d7f3a6948f0205ae6177a0ee5e340f36b41	gpu-accelerated generation and rendering of multi-level voxel representations of solid models		Abstract Solid models traditionally use boundary-representation (B-rep) to define and model their geometry. However, performing modeling operations such as Boolean operations or computing point membership classification with B-rep is computationally intensive, since B-reps do not have volumetric information. Voxelized representations, on the other hand, can be extended to include volumetric information of solid models. However, in order to use voxelized representations for solid modeling, efficient methods for voxelizing a B-rep solid model needs to be developed. In this paper, we present GPU-accelerated methods for creating and rendering a multi-level voxelization of a solid model that can be used for modeling operations. We describe two GPU-accelerated algorithms; one for creating a multi-level voxelization given a B-rep of a solid model and another for ray casting to render the multi-level voxelization of the solid model. We describe compact and flat data structures that can be used to store the multi-level voxelization data and can be efficiently retrieved in parallel by GPU-algorithms for rendering and modeling operations. The GPU-accelerated multi-level voxelization method can generate models with an effective voxel count of up to 8 billion voxels. In addition, the GPU voxelization algorithm is more than 40x faster than the CPU implementation in generating the voxelization. Finally, we outline a few applications for the voxel representation, which include fast point-membership classification, volume computation, and collision detection.	graphics processing unit;solid modeling;voxel	Gavin Young;Adarsh Krishnamurthy	2018	Computers & Graphics	10.1016/j.cag.2018.07.003	voxel;computer science;computer vision;ray casting;rendering (computer graphics);artificial intelligence;computation;collision detection;solid modeling;data structure;central processing unit	Graphics	68.01297799662703	-50.75274155362397	170576
4bdd31f675ad95998be04af311e9e5d0eeef0065	creating virtual buddha statues through observation	texture mapping;computer vision;range image;digital preservation;pattern recognition;geometric model;literature survey;conferences computer vision pattern recognition;conferences	This paper overviews our research on digital preservation of cultural assets and digital restoration of their original appearance. Geometric models are digitally achieved through a pipeline consisting of scanning, registering and merging multiple range images. We have developed a robust simultaneous registration method and an efficient and robust voxel-based integration method. On the geometric models created, we have to align texture images acquired from a color camera. We have developed two texture mapping methods. In an attempt to restore the original appearance of historical heritage objects, we have synthesized several buildings and statues using scanned data and literature survey with advice from experts.	align (company);circuit restoration;pipeline (computing);texture mapping;voxel	Katsushi Ikeuchi;Atsushi Nakazawa;Ko Nishino;Takeshi Oishi	2003	2003 Conference on Computer Vision and Pattern Recognition Workshop	10.1109/CVPRW.2003.10001	texture mapping;computer vision;computer science;geometric modeling;multimedia;computer graphics (images)	Vision	57.84424200504422	-48.033507097218504	170594
1273b3f1df63899926ceb122d859944e6d7d55c4	real-time correction of intensity nonlinearities in imaging systems	memory management;image processing;real time;polynomials;imaging system;display systems;pixel;imaging;approximation methods;humans;real time systems display systems image processing imaging systems;prom;prom pixel approximation methods polynomials imaging memory management humans;read only memory;imaging systems;real time systems	An analysis of two-dimensional imaging systems with general intensity nonlinearities is presented and several methods for real-time correction are discussed. Exact correction for measurement purposes and approximate correction for the human observer are described, and system implementation is by digital hardware, primarily using programmable read-only memories (PROM's). Calibration techniques for these systems are given, and estimates of computing time and required system complexity are made. Experimental application of these techniques is discussed.	approximation algorithm;digital electronics;programmable read-only memory;real-time clock;real-time transcription	Alexander A. Sawchuk	1977	IEEE Transactions on Computers	10.1109/TC.1977.5009271	embedded system;computer vision;image processing;computer science;operating system;read-only memory;pixel;polynomial;memory management;computer graphics (images)	Visualization	58.00198911566542	-48.49738412165858	170607
8ded1f5e93ceb75c72e97142faa67139c6ced639	performance analysis of 3-d shape measurement projector-camera system with short baseline arrangement	visual perception calibration cameras mathematical analysis measurement errors optical projectors shape measurement stereo image processing;shape measurement;mathematical analysis;optical projectors;parameter uncertainty 3d shape measurement projector camera system structured light technique binocular stereovision system calibration triangulation algorithm short baseline arrangement stereovision system fringe projection profilometry fpp projecting imaging model 3d measurement error analysis mathematical model phase distribution map;stereo image processing;visual perception;cameras equations mathematical model optical imaging accuracy analytical models;calibration;cameras;measurement errors	Many well studied works for accurate 3-D shape measurement which based on structured light technique have been presented in last decades. Among them, one common way is utilizing the binocular stereovision like model to get 3-D information. In this model, projector is always treated like a camera, thus making the projector-camera based system unified with a well-established traditional binocular stereovision system. After calibrating projector and camera, 3-D shape information is obtained by performing conventional triangulation algorithm. However, as we all know that, there is a short baseline problem which highly limits the measurement accuracy in a short baseline arrangement stereovision system. The other widely used method is fringe projection profilometry (FPP). In this work, we present a new and different projecting-imaging model for 3-D measurement error analysis. We first explore the exact mathematical model that exists between the height of an object's surface, the phase distribution map and the parameters of the setup. Then, some practical considerations are taken into account to improve the measurement accuracy. Finally, we study the problem how uncertainty of the parameters in the proposed model affects final measurement accuracy, especially focus on the length of baseline analysis between the projector and the camera. According to the parameters analysis, some experimental results are presented to demonstrate its validity.	algorithm;baseline (configuration management);binocular vision;error analysis (mathematics);experiment;fixed-priority pre-emptive scheduling;heightmap;image plane;mathematical model;numerical analysis;pixel;profiling (computer programming);stereopsis;structured light;structured-light 3d scanner;system of measurement;thematic map;video projector	Jianyang Liu;Youfu Li	2013	2013 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2013.6739669	computer vision;calibration;visual perception;optics;computer graphics (images);observational error	Robotics	56.026155465845015	-49.22555814179666	170619
590bbac92a96d05fd272330f68f6359e0f99db97	volumetric ambient occlusion for real-time rendering and games	paper;fuzzy membership function;global illumination effects;volumetric ambient occlusion;particle measurements;computer graphics;graphics and multimedia;economic forecasting;real time;physically founded rendering equation;computational geometry;gpu;layout;lighting equations layout rendering computer graphics particle measurements economic forecasting light sources real time systems computational efficiency image quality;fuzzy set theory;computer graphic;global illumination;graphics and multimedia volumetric ambient occlusion obscurance gpu importance sampling computer graphics;rendering equation;real time graphics;obscurance;rendering computer graphics computational geometry fuzzy set theory real time systems;image quality;games;mathematical model;algorithms;lighting;computer science;importance sampling;rendering computer graphics;computational efficiency;surface tangent sphere;surface tangent sphere volumetric ambient occlusion real time rendering games gpu global illumination effects real time systems physically founded rendering equation fuzzy membership function;light sources;real time rendering;real time systems;rendering	This new algorithm, based on GPUs, can compute ambient occlusion to inexpensively approximate global-illumination effects in real-time systems and games. The first step in deriving this algorithm is to examine how ambient occlusion relates to the physically founded rendering equation. The correspondence stems from a fuzzy membership function that defines what constitutes nearby occlusions. The next step is to develop a method to calculate ambient occlusion in real time without precomputation. The algorithm is based on a novel interpretation of ambient occlusion that measures the relative volume of the visible part of the surface's tangent sphere. The new formula's integrand has low variation and thus can be estimated accurately with a few samples.	ambient occlusion;approximation algorithm;global illumination;graphics processing unit;precomputation;real-time clock;real-time computing;real-time transcription;rendering equation	László Szirmay-Kalos;Tamás Umenhoffer;Balázs Tóth;László Szécsi;Mateu Sbert	2010	IEEE Computer Graphics and Applications	10.1109/MCG.2010.19	image quality;layout;games;computer vision;simulation;rendering;computational geometry;importance sampling;computer science;rendering equation;economic forecasting;mathematical model;lighting;fuzzy set;computer graphics;global illumination;computer graphics (images)	Visualization	65.23853726894247	-50.41169380239568	171066
b01f1e1719b55f5b2b3c03cfbd6adf752d4def4d	three dimensional representations of usgs digital elevation model data using java-3d: implementation and performance issues	digital elevation model;three dimensional	This paper investigates performance issues that arise when displaying large 3 dimensional geographic data sets in an OpenGL/Java3D environment. Five possible schemes for the rendering of Digital Elevation Models from the United States Geological Survey are tested for memory usage and rendering processor efficiency. These implementations exercise and compare Java3d geometry alternatives including, interleaved data sets, indexed geometry, geometry strips, and primitive versus object based data formats. Of the schemes tested, the use of interleaved, primitive data formats in TriangleStrips was found to use the least memory and have the fastest rendering times.	digital elevation model;fastest;java 3d;object-based language;opengl;strips	Mark Pendergast	2003			simulation;computer science;theoretical computer science;computer graphics (images)	Graphics	68.22332079536993	-51.61390525635462	171142
c523b7fcedb4048fca556b20b7bbe4779a645317	an anti-aliasing technique for voxel-based massive model visualization strategies	large data sets;visual quality;level of detail;interactive rendering	CAD models of industrial installations usually have hundreds of millions of triangles. For this reason they cannot be interactively rendered in the current generation of computer hardware. There are many different approaches to deal with this problem, including the Far Voxels algorithm, which uses a hierarchical level-of-detail structure. In this structure, voxels are used to create a coarse representation of the model when required. This strategy yields interactive rates for large data sets because it deals well with levels of detail, culling, occlusion and out-of-core model storage. The Far Voxels algorithm, however, has a severe alias problem when it is used to represent small or thin objects, which is especially visible during transitions between different levels of detail. This paper presents a new version of the Far Voxels algorithm that improves visual quality during model navigation.	aliasing;anti-aliasing filter;back-face culling;central processing unit;computer hardware;computer-aided design;hidden surface determination;interactivity;level of detail;out-of-core algorithm;rendering (computer graphics);voxel	Gustavo N. Wagner;Alberto Barbosa Raposo;Marcelo Gattass	2007		10.1007/978-3-540-76858-6_29	computer vision;simulation;computer science;level of detail;computer graphics (images)	Graphics	67.33354127894407	-50.91192093391805	171259
43506ce2fd101288a8f73317dae737829becb30b	a dynamic multi-projection-contour approximating framework for the 3d reconstruction of buildings by super-generalized optical stereo-pairs	3d reconstruction;artificial bee colony algorithm;remote sensing;super-generalized stereo-pairs	In this paper, a novel framework of the 3D reconstruction of buildings is proposed, focusing on remote sensing super-generalized stereo-pairs (SGSPs). As we all know, 3D reconstruction cannot be well performed using nonstandard stereo pairs, since reliable stereo matching could not be achieved when the image-pairs are collected at a great difference of views, and we always failed to obtain dense 3D points for regions of buildings, and cannot do further 3D shape reconstruction. We defined SGSPs as two or more optical images collected in less constrained views but covering the same buildings. It is even more difficult to reconstruct the 3D shape of a building by SGSPs using traditional frameworks. As a result, a dynamic multi-projection-contour approximating (DMPCA) framework was introduced for SGSP-based 3D reconstruction. The key idea is that we do an optimization to find a group of parameters of a simulated 3D model and use a binary feature-image that minimizes the total differences between projection-contours of the building in the SGSPs and that in the simulated 3D model. Then, the simulated 3D model, defined by the group of parameters, could approximate the actual 3D shape of the building. Certain parameterized 3D basic-unit-models of typical buildings were designed, and a simulated projection system was established to obtain a simulated projection-contour in different views. Moreover, the artificial bee colony algorithm was employed to solve the optimization. With SGSPs collected by the satellite and our unmanned aerial vehicle, the DMPCA framework was verified by a group of experiments, which demonstrated the reliability and advantages of this work.	3d modeling;3d reconstruction;aerial photography;approximation algorithm;artificial bee colony algorithm;bees;calcium-sensing receptor;computer stereo vision;contour line;experiment;matching;mathematical optimization;numerous;projections and predictions;simulation;unmanned aerial vehicle	Yiming Yan;Nan Su;Chunhui Zhao;Liguo Wang	2017		10.3390/s17092153	artificial bee colony algorithm;3d reconstruction;engineering;parameterized complexity;binary number;mathematical optimization;artificial intelligence;computer vision	Vision	56.14865061317813	-50.6298178737873	171331
c7d121f7a79e655b6898394c83b604af56baf289	penumbra masks	novel area;conservative area;general penumbra detection method;physically-based shadow;modified occlusion map;penumbra mask;planar polygonal light source;potential penumbra;various soft shadow algorithm;area light source	Computation of physically-based shadows can be significantly accelerated by limiting computations into regions where penumbras appear. In this paper, we present a general penumbra detection method that efficiently bounds regions where penumbras occur in a shared projection plane of an area light source. We introduce a novel area filling operator, which allows effective and conservative area masking with respect to all viewpoints, i.e., sampling points within a planar polygonal light source. The area filling operator uses a point sprite rendering technique on a set of silhouette boundaries to create a penumbra mask, which is essentially a modified occlusion map. We show how to efficiently test the geometry and screen-space pixels against the penumbra mask. An important advantage of our method is that we can separate lit and umbra regions, and thus drive various soft shadow algorithms to focus their computational efforts into potential penumbras. Due to the relative simplicity of computations, penumbra masks can be efficiently generated with graphics hardware. As an example, we accelerate shadow map supersampling to demonstrate significant speedups that utilizations of penumbra masks provide.	algorithm;benchmark (computing);computation;flood fill;glossary of computer graphics;graphics hardware;lookup table;mask (computing);pixel;projection plane;real-time transcription;sampling (signal processing);self-shadowing;shader;shadow mapping;sprite (computer graphics);supersampling;texture filtering;variable shadowing;verification and validation	Jukka Arvo	2006	The Visual Computer	10.1007/s00371-006-0378-7	computer science;computer graphics (images)	Graphics	66.07011833293643	-51.26070627204154	171455
21b2651d3760b72b53f05257752a8fa4e080353c	constructaide: analyzing and visualizing construction sites through photographs and building models	progress monitoring;architectural visualization;augmented reality;image based rendering;structure from motion	We describe a set of tools for analyzing, visualizing, and assessing architectural/construction progress with unordered photo collections and 3D building models. With our interface, a user guides the registration of the model in one of the images, and our system automatically computes the alignment for the rest of the photos using a novel Structure-from-Motion (SfM) technique; images with nearby viewpoints are also brought into alignment with each other. After aligning the photo(s) and model(s), our system allows a user, such as a project manager or facility owner, to explore the construction site seamlessly in time, monitor the progress of construction, assess errors and deviations, and create photorealistic architectural visualizations. These interactions are facilitated by automatic reasoning performed by our system: static and dynamic occlusions are removed automatically, rendering information is collected, and semantic selection tools help guide user input. We also demonstrate that our user-assisted SfM method outperforms existing techniques on both real-world construction data and established multi-view datasets.	automated reasoning;interaction;structure from motion	David A. Forsyth	2014	ACM Trans. Graph.	10.1145/2661229.2661256	computer vision;augmented reality;structure from motion;simulation;image-based modeling and rendering;computer science;computer graphics (images)	Graphics	58.1018320185091	-47.737097666458695	171528
8f4246f8b42a3b5e477c2aa54bb7062517456088	rgb-d sensor data correction and enhancement by introduction of an additional rgb view	robot sensing systems cameras three dimensional displays calibration geometry estimation reliability;auxiliary sensor rgb d sensor data data correction data enhancement red green blue depth rgb view robotics microsoft kinect time of flight cameras 3d colored point clouds robot vision multi camera system regular rgb camera;image sensors;image enhancement;robot vision;image colour analysis;robot vision cameras image colour analysis image enhancement image sensors;cameras	RGB-D sensors are becoming more and more vital to robotics. Sensors such as the Microsoft Kinect and time of flight cameras provide 3D colored point-clouds in real time can play a crucial role in Robot Vision. However these sensors suffer from precision deficiencies, and often the density of the point-clouds they provide is insufficient. In this paper, we present a multi-camera system for correction and enhancement of the data acquired from an RGB-D sensor. Our system consists of two sensors, the RGB-D sensor (main sensor) and a regular RGB camera (auxiliary sensor). We perform the correction and the enhancement of the data acquired from the RGB-D sensor by placing the auxiliary sensor in a close proximity to the target object and taking advantage of the established epipolar geometry. We have managed to reduce the relative error of the raw point-cloud from a Microsoft Kinect RGB-D sensor by 74.5 % and increase its density up to 2.5 times.	approximation error;epipolar geometry;kinect;outline of object recognition;point cloud;robotics;sensor	Artashes Mkhitaryan;Darius Burschka	2013	2013 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2013.6696484	computer vision;engineering;image sensor format;image sensor;remote sensing;visual sensor network;computer graphics (images)	Robotics	54.14599982448988	-44.112907418090685	171536
87796851f3a91b771784519dc8dfda2682dce5f5	a touch-enabled system for multi-resolution modeling and 3d painting	multiresolution modeling;virtual reality;shape deformation;three dimensional;force feedback;haptic rendering;polygonal meshes;visual feedback;multi resolution	We presentanintuitive system,inTouch, for interacti vely editingandpaintinga polygonal meshusing a force feedbackdevice. An artist or a designercan usethis systemto create andrefinea three-dimensional multiresolutionpolygonalmesh.Theappearancecanbefurther enhancedby directly painting onto its surface. The systemallows usersto naturally create complex formsandpatternsaidednot only by visualfeedbackbut alsoby their senseof touch.	haptic technology	Stephen A. Ehmann;Arthur D. Gregory;Ming C. Lin	2001	Journal of Visualization and Computer Animation	10.1002/vis.252	three-dimensional space;computer vision;simulation;computer science;artificial intelligence;virtual reality;multimedia;haptic technology;computer graphics (images)	Visualization	66.0179960226245	-47.07780903486448	171570
09d3b3c042f816abf2ec637ad4ed26e52b1b7f6d	multidimensional scaling in the poincaré disk		Multidimensional scaling (MDS) is a class of projective algorithms traditionally used to produce twoor three-dimensional visualizations of datasets consisting of multidimensional objects or interobject distances. Recently, metric MDS has been applied to the problems of graph embedding for the purpose of approximate encoding of edge or path costs using node coordinates in metric space. Several authors have also pointed out that for data with an inherent hierarchical structure, hyperbolic target space may be a more suitable choice for accurate embedding than Euclidean space. In this paper we present the theory and the implementation details of MDS-PD, a metric MDS algorithm designed specifically for the Poincaré disk model of the hyperbolic plane. Our construction is based on an approximate hyperbolic line search and exemplifies some of the particulars that need to be addressed when applying iterative optimization methods in a hyperbolic space model. MDS-PD can be used both as a visualization tool and as an embedding algorithm. We provide several examples to illustrate the utility of MDSPD.	approximation algorithm;consistency model;experiment;file spanning;gradient descent;graph embedding;iterative method;line search;mathematical optimization;multidimensional scaling;numerical analysis;synthetic intelligence;vii	Andrej Cvetkovski;Mark Crovella	2011	CoRR			ML	63.37773405214357	-40.3158174565818	171947
b5e48a5c2b4836bbeb2b361cf65746d12166504a	improvement of panorama-based annotation overlay using omnidirectional vision and inertial sensors	omnidirectional vision;layout image sensors augmented reality application software wearable computers robustness throughput cameras parameter estimation delay estimation;image alignment;real time;annotation overlay;image sensors;journal article;panoramic images panorama based annotation overlay omnidirectional vision inertial sensors wearable computers augmented reality;portable computers;image registration;wearable computer;panoramic image;augmented reality ar;augmented reality;image registration portable computers augmented reality image sensors;inertial sensor;inertial sensors	Annotation overlay on live video frames is an essential feature of augmented reality (AR), and is a well-suited application for wearable computers. A novel method of annotation overlay and its real-time implementation is presented. This method uses a set of panoramic images captured by omnidirectional vision at various points of environment and annotations attached on the images. The method overlays the annotations according to the image alignment between the input frames and the panoramic images. It uses inertial sensors not only to produce robust results of image registration but also to improve processing throughput and delay.	augmented reality;image registration;real-time clock;real-time computing;sensor;throughput;wearable computer	Masakatsu Kourogi;Takeshi Kurata;Katsuhiko Sakaue;Yoichi Muraoka	2000	Digest of Papers. Fourth International Symposium on Wearable Computers	10.1109/ISWC.2000.888492	inertial measurement unit;computer vision;augmented reality;wearable computer;computer science;image registration;image sensor;multimedia;computer graphics (images)	Vision	54.194827664045505	-44.26144479267887	172020
b2c0d59c7b13ee12237ca66f21a6a01a8a2d0237	efficient voronoi diagram construction for planar freeform spiral curves	moebius transformation;planar freeform curve;medial axis;voronoi diagram;spiral curve;maximal disk	We present a real-time algorithm for computing the Voronoi diagram of planar freeform piecewise-spiral curves. The efficiency and robustness of our algorithm is based on a simple topological structure of Voronoi cells for spirals. Using a Möbius transformation, we provide an efficient search for maximal disks. The correct topology of Voronoi diagram is computed by sampling maximal disks systematically, which entails subdividing spirals until each belongs to a pair/triple of spirals under a certain matching condition. The matching pairs and triples serve as the basic building blocks for bisectors and bifurcations, and their connectivity implies the Voronoi structure. We demonstrate a real-time performance of our algorithm using experimental results including the medial axis computation for planar regions under deformation with nontrivial self-intersections and the Voronoi diagram construction for disconnected planar freeform curves.	algorithm;apache axis;computation;maximal set;medial graph;real-time clock;sampling (signal processing);voronoi diagram	Jaewook Lee;Yong-Jun Kim;Myung-Soo Kim;Gershon Elber	2016	Computer Aided Geometric Design	10.1016/j.cagd.2016.02.008	combinatorics;weighted voronoi diagram;power diagram;topology;voronoi diagram;medial axis;centroidal voronoi tessellation;mathematics;geometry;möbius transformation;spiral	Robotics	68.18066385683846	-42.940293025052505	172194
a061863a937e6f689349a9943a0554355895b536	towards a 3d virtual studio forhuman appearance capture		This paper introduces the concept of a “3D Virtual Studio” for human appearance capture, akin to the motion capture studio for human motion tracking. Ultimately the 3D Virtual Studio should enable video-realistic reconstruction of a moving person from any viewpoint. A mesh-based stereo technique is presented to reconstruct a moving person from multiple camera views. This technique optimises a surface mesh to match stereo and silhouette data in a constrained coarse-to-fine framework, recovering sub-pixel image correspondence in the presence of inexact camera calibration. We compare this approach for scene reconstruction to conventional shape from silhouette and multiple view stereo. We then demonstrate view-dependent rendering and show improved resolution with the recovered image correspondence. We then demonstrate how this approach can be used to capture the dynamic shape and appearance of a computer graphics model of a person.	3d construction kit;camera resectioning;computer graphics;kinesiology;motion capture;pixel;polygon mesh;rendering (computer graphics);virtual studio	Jonathan Starck;Adrian Hilton	2003			silhouette;rendering (computer graphics);virtual studio;camera resectioning;computer graphics (images);computer graphics;computer vision;studio;motion capture;match moving;computer science;artificial intelligence	Vision	57.7520608908861	-49.99693859407479	172496
a3c5bb2d6926fbcbe795f3423375059a924dde30	bendylights: artistic control of direct illumination by curving light rays	and texture;computer graphics i 3 7 color;shadowing;shading	In computer cinematography, artists routinely use non-physical lighting models to achieve desired appearances. This paper presents BendyLights, a non-physical lighting model where light travels nonlinearly along splines, allowing artists to control light direction and shadow position at different points in the scene independently. Since the light deformation is smoothly defined at all world-space positions, the resulting non-physical lighting effects remain spatially consistent, avoiding the frequent incongruences of many non-physical models. BendyLights are controlled simply by reshaping splines, using familiar interfaces, and require very few parameters. BendyLight control points can be keyframed to support animated lighting effects. We demonstrate BendyLights both in a realtime rendering system for editing and a production renderer for final rendering, where we show that BendyLights can also be used with global illumination.	global illumination	William B. Kerr;Fabio Pellacini;Jonathan D. Denning	2010	Comput. Graph. Forum	10.1111/j.1467-8659.2010.01742.x	computer vision;shading;rendering;computer science;volumetric lighting;per-pixel lighting;image-based lighting;computer graphics (images)	Vision	64.59877009351735	-48.45426900565049	172632
8b2b99f15fb09491cb07bc6efe6517c117bf7c29	constructing regularity feature trees for solid models	modelizacion;regularite;vision ordenador;agua abajo;modele geometrique;image processing;geometrie solide;regularidad;etude experimentale;structure arborescente;regularity;retroingenierie;procesamiento imagen;geometria solidos;traitement image;symetrie;symmetry;computer vision;modelisation;qa75 electronic computers computer science;estructura arborescente;solid modeling;tree structure;pattern recognition;aval;vision ordinateur;downstream;geometric model;reconnaissance forme;reconocimiento patron;simetria;geometric constraints;modeling;estudio experimental;ingeniera inversa;solid geometry;geometrical model;reverse engineering;qa76 computer software;modelo geometrico	Approximate geometric models, e.g. as created by reverse engineering, describe the approximate shape of an object, but do not record the underlying design intent. Automatically inferring geometric aspects of the design intent, represented by feature trees and geometric constraints, enhances the utility of such models for downstream tasks. One approach to design intent detection in such models is to decompose them into regularity features. Geometric regularities such as symmetries may then be sought in each regularity feature, and subsequently be combined into a global, consistent description of the model’s geometric design intent. This paper describes a systematic approach for finding such regularity features based on recovering broken symmetries in the model. The output is a tree of regularity features for subsequent use in regularity detection and selection. Experimental results are given to demonstrate the operation and efficiency of the algorithm.	approximation algorithm;boundary representation;computer science;computer-aided design;constructive solid geometry;display resolution;downstream (software development);experiment;feature recognition;fitness approximation;geometric design;graphics;level of detail;maximal set;polyhedron;refinement (computing);request for tender;reverse engineering;sensor;solid modeling;zero suppression	Ming Li;Frank C. Langbein;Ralph R. Martin	2006		10.1007/11802914_19	computer vision;downstream;systems modeling;image processing;computer science;artificial intelligence;geometric modeling;solid geometry;mathematics;geometry;tree structure;symmetry;solid modeling;algorithm;reverse engineering	Robotics	65.94649685278854	-41.52261935993226	172726
eb837fe9d5b656e2dab02a8e7dc7aa7c0e44267b	accuracy of point light target coordinate determination by dissectoral tracking system	lasers;tracking system;kalman filter;navigation systems;computing systems;navigation system	"""Dissectoral tracking systems are employed for coordinate determination and for tracking minor-dimensional light targets in optical coupling devices, laser location and navigation systems. To analyze the accuracy of coordinate determination of minor dimensional point light target by dissectoral tracking system, are suggested. There has been examined the robustness and stability of the algorithm to deviation of the model parameters from nominal value and the accuracy of coordinate determination at different target contrasts, speed movement at the relationship signal/noise and dissectoral tracking system parameters. The results are obtained by statistical simulation of the Kalman filter with a computer. INTRO P UC TIO N Having such characteristics as great scale of linearity of the light parameters, high fastacting and reliability of operation, possibility of space scanning on any law the dissector is almost an ideal data unit for television tracking systems. The dissector tracking systems find wide application in coordinates determination and tracking light objects of small sizes in the devices of optical communication and laser location. The first available articles in English language were1'2'3'4. These pioneer works were for me, a young engineer in those years, a connecting bridge between the theory, practice and my own considerations and ideas. Written in a good engineer style they are interesting even today. In particular, main types of tracking microrasters, the principles automatic control scheme construction were considered, the quality characteristics of the system operation were investigated. Rapid development of computer techniques has reduced the gap between the theoretical prerequisites and the engineer realization. Last years the main stress was laid on modeling and algorithmic development of dissector tracking systems. They suppose that the apparatus part will be always realized. The aim of present paper is the analysis (in the aspect of possible realization ) of the accuracy of a point light object coordinates determination by dissector tracking system limited by the signal and the date unit properties and by the system parameters as a whole. MODEL OF OBSERVED SIGNAL AND USEFUL MESSAGE A light object is considered to be a point one when its sizes of the image on the dissector photocathode are commensurable with the aperture of the dissector and limited by the optics resolution, and the function of the image brightness distribution is unimodal and has an express maximum. The work of such systems comes about through noise and includes 2 modes : target detection and it's tracking. On successful finishing searching mode tracking microraster is located near the image center position. In the tracking the target image is scanned about the aperture of dissector from tracking microraster law. In this case the video signal. that shows up the mixture of a legitimate signal with information about position of the image center of the target and noise shapes on the load. The characteristic property of dissector lies in the fact that the intensity of the fluctuational current at outlet depends on the average value of lighting conditions. The total current of the dissector can be represented by the additive sum5 z(t) = AS(X(t),t) + N0Q) + N(t), where: A the amplitude in the maximum of signal function; 0819419559/95/$6.00 SPIE Vol. 2591 / 25 Downloaded From: http://proceedings.spiedigitallibrary.org/ on 06/29/2016 Terms of Use: http://spiedigitallibrary.org/ss/TermsOfUse.aspx s(.) non-linear function, approximating the shape of the videosignal: N0 (t) white Gaussian noise of phone: N(t) non-stationary white Gaussian """"signal noise"""": x(t) vector of state ofvariables, striking the motion path x of the light center on photocathode. Gaussian noise N0 (i) and N (i) are assume be statistical independed, because they are formed by free light, flux background and signal. The quality of a tracking system operation at low contrasts of the object is characterized by the value of the dispersion of the coordinates estimate and by the tracking disruption possibility if is known that the accuracy of coordinates determination is limited by the value of the ratio between the signal amplitude and the mean quadratic value of the noise at the phone level (SNR). (2) where = N04fnoise dispersion at the band frequency Ef The electric contrast at the object brightness (more than the phone brightness) is determined by A K0= , (3) A + where i1is a constant constituent of the phone current. From (2) and (3) it is seen that: K i• ° (4) 1—K0 °bf The equation (4) shows the connection between SNRand contrast K0 . At point object contrasts5 K0 < 0.5 the nonstationary constituent can be neglected at Z(t). The dimensions of the tracking microraster are commensurable with the point object image size on dissector photcathode. That's why, let is calculate tracking disruption is the case when the coordinates determination error in any direction s niore than a half of the cruciform microraster size i.e. (')-X(t) L/, where, L is the size of the tracking microraster. Lets use the value of the ratio: where n is a total number of tests; n,, is a number of failed test as the estimate of the possibility of tracking dispersion. Investigate the quality of a dissector tracking system operation at small SNR and the object contrasts. Lets represent the device motion trajectory in space on X and V coordinates as an independent one and as made up of quasidetermined Xkd (t), Ykd(t) and random X1(t) and Y1(t) constituents. X(t) = Xkd (t) + x31(t) (5) YQ) = +"""	algorithm;automatic control;composite video;denial-of-service attack;digraphs and trigraphs;evanescent field;image noise;image resolution;kalman filter;linear function;noise (electronics);nonlinear system;signal-to-noise ratio;simulation;stationary process;tracking system;uc browser;utility functions on indivisible goods	Yuri V. Martishevcky	1995		10.1117/12.228984	kalman filter;computer vision;laser;tracking system;physics	Vision	59.373421349794526	-40.884256648526446	172838
e20ca1526b4480742679ff12a8837338786f0bbd	analysis, 3d reconstruction, & animation of faces. (analyse, reconstruction 3d, & animation du visage)			3d reconstruction;visage	Charlotte Ghys	2010				Graphics	61.09110069690635	-47.22091841047504	173184
13f12804cff9d4de0ed82aea89ecb79eb18e9835	tensor field design in volumes		3D tensor field design is important in several graphics applications such as procedural noise, solid texturing, and geometry synthesis. Different fields can lead to different visual effects. The topology of a tensor field, such as degenerate tensors, can cause artifacts in these applications. Existing 2D tensor field design systems cannot be used to handle the topology of a 3D tensor field. In this paper, we present to our knowledge the first 3D tensor field design system. At the core of our system is the ability to edit the topology of tensor fields. We demonstrate the power of our design system with applications in solid texturing and geometry synthesis.	graphics;texture mapping;visual effects	Jonathan Palacios;Lawrence Roy;Prashant Kumar;Chen-Yuan Hsu;Weikai Chen;Chongyang Ma;Li-Yi Wei;Eugene Zhang	2016		10.1145/3130800.3130844	topology;tensor field;cartesian tensor;tensor;pure mathematics;mathematics;geometry;texture synthesis	Graphics	66.28032486420712	-45.159031533043155	173296
08b5b9b833923a16835c9a45271e00c888a61842	from segmented images to good quality meshes using delaunay refinement	time varying;space time;computer vision;3d model;medical image;machine learning;higher dimensions;geometric model;point of view	This paper surveys Delaunay-based meshing techniques for curved objects, and their application in medical imaging and in computer vision to the extraction of geometric models from segmented images. We show that the so-called Delaunay refinement technique allows to mesh surfaces and volumes bounded by surfaces, with theoretical guarantees on the quality of the approximation, from a geometrical and a topological point of view. Moreover, it offers extensive control over the size and shape of mesh elements, for instance through a (possibly non-uniform) sizing field. We show how this general paradigm can be adapted to produce anisotropic meshes, i.e. meshes elongated along prescribed directions. Lastly, we discuss extensions to higher dimensions, and especially to space-time for producing time-varying 3D models. This is also of interest when input images are transformed into data points in some higher dimensional space as is common practice in machine learning.	3d modeling;approximation;computer vision;data point;delaunay triangulation;machine learning;medical imaging;polygon mesh;programming paradigm;refinement (computing);ruppert's algorithm;static mesh	Jean-Daniel Boissonnat;Jean-Philippe Pons;Mariette Yvinec	2008		10.1007/978-3-642-00826-9_2	computer vision;mathematical optimization;mathematics;geometry	Graphics	67.83897172404743	-45.293660758495825	173499
6ae772b0d9cc6573c4ddf869bc28aca2e2723cb9	segmentation-based skinning	weightassignment;skinning;weight assignment algorithm;algorithm;rigging;mesh segmentation;computer animation;article	Skeleton-driven animation is popular by its simplicity and intuitive control of the limbs of a character. Linear blend skinning (LBS) is up to date the most efficient and simple deformation method; however, painting influence skinning weights is not intuitive, and it suffers the candy-wrapper artifact. In this paper, we propose an approach based on mesh segmentation for skinning and skeleton-driven computer animation. We propose a novel and fast method, based in watershed segmentation to deal with characters in T-Pose and arbitrary poses, a simple weight assign algorithm based in the rigid skinning obtained with the segmentation algorithm for the LBS deformation method, and finally, a modified version of the LBS that avoids the loss of volume in twist rotations using the segmentation stage output values.		Jorge E. Ramirez;Antonio Susín	2017	Journal of Visualization and Computer Animation	10.1002/cav.1687	computer vision;computer science;computer animation;computer graphics (images)	Visualization	64.4735588614625	-47.05727206822281	173720
f47364e1d230112bda8988d9eab68936d3f9acd0	planar segmentation from point clouds via graph laplacian regularized k-planes	graph theory;iterative methods computer graphics graph theory image segmentation;image segmentation;computer graphics;segmentation;iterative methods;point clouds;planar segmentation 3d point cloud graph laplacian regularized k planes method piece wise planar surface segmentation urban building point cloud linear projection model planar surfaces graph laplacian regularization objective function iterative updating algorithm synthetic data set real data set planar surface extraction point clouds;point clouds segmentation piece wise planar surfaces graph laplacian;graph laplacian;piece wise planar surfaces	Extracting planar surfaces from 3D point clouds is an important and challenging step for generating building models as the obtained data are always noisy, missing and unorganised. In this paper, we present a novel graph Laplacian regularized K-planes method for segmenting piece-wise planar surfaces of urban building point clouds. The core ideas behind our model are from two aspects: 1) a linear projection model is utilized to fit planar surfaces globally, 2) a graph Laplacian regularization is applied to preserve smoothness of each plane locally. The two terms are combined as an objective function, which is minimized via an iterative updating algorithm. Comparative experiments on both synthetic and real data sets are performed. The results demonstrate the effectiveness and efficiency of our method.	algorithm;experiment;iterative method;laplacian matrix;loss function;matrix regularization;optimization problem;point cloud;synthetic intelligence	Wei Sui;Lingfeng Wang;Huai-Yu Wu;Chunhong Pan	2013	2013 2nd IAPR Asian Conference on Pattern Recognition	10.1109/ACPR.2013.15	mathematical optimization;combinatorics;geometric graph theory;graph embedding;graph bandwidth;laplacian matrix;planar straight-line graph;mathematics;geometry	Vision	57.900612312572186	-46.236988862289145	173797
82aafdc3a7903f182d103dd56f3b7ce38f65490b	light scattering simulations using complex subsurface models	local illumination modeling;light scattering;surface modeling;brdf;reflectance measurement;multilayer interference		computer simulation	Morgan T. Schramm;Jay S. Gondek;Gary W. Meyer	1997			freeform surface modelling;computer science;bidirectional reflectance distribution function;light scattering	Vision	62.89007614766838	-51.728336768317604	174227
d2c11dce879c18586cdfe96daf512ef7fe093d63	system for reconstruction of three-dimensional micro objects from multiple photographic images	shape from silhouette;digital microscope;localization;triangular mesh;data acquisition system;marching cubes;three dimensional;micro objects;3d model;mesh generation;marching cube;3d shape reconstruction	We introduce a system to reconstruct a three-dimensiojnal (3D) polygonal model of 3D micro objects with outer dimensions ranging from several hundred microns to several millimeters from multiple twodimensional (2D) images of an object taken from different views. The data acquisition system consists of a digital microscope that captures still images at a resolution of 1600 × 1200 pixels and a computercontrolled turntable. We employ the shape-from-silhouette (SFS) method to construct a voxel-based 3D model from silhouette images. The concave shapes are further carved by using the space carving technique. In order to make the resulting model compatible with a commercial CAD/CAM system, the voxel model is converted into a triangular mesh using the marching cubes algorithm. Because the mesh generated from the voxel model by using the marching cubes algorithm inherits the staircase effect, the mesh is adjusted to recover the object precisely by using silhouette images. Finally, we evaluate the accuracy of the proposed method. The reconstructed models of complex micro objects indicate the effectiveness of the 3D shape reconstruction system for micro objects. © 2011 Elsevier Ltd. All rights reserved.	3d modeling;3d printing;algorithm;canny edge detector;clustered file system;color;computer graphics;computer-aided design;concave function;data acquisition;edge detection;hough transform;marching cubes;maxima and minima;microfabrication;minimum bounding box;olap cube;octree;pixel;polygon mesh;polygonal modeling;robustness (computer science);shading;utility functions on indivisible goods;voxel	Koutarou Atsushi;Hidetada Sueyasu;Yusuke Funayama;Takashi Maekawa	2011	Computer-Aided Design	10.1016/j.cad.2011.01.019	computer vision;marching tetrahedra;computer science;isosurface;mathematics;marching cubes;engineering drawing;computer graphics (images)	Graphics	63.256303234739875	-47.501026329487985	174527
35f7ce68607bc14ec514077846c418d127a3bdda	on modelling and rendering ocean scenes	optical phenomena;displacement mapping;ray tracing;illumination			Jean-Christophe Gonzato;Bertrand Le Saëc	2000	Journal of Visualization and Computer Animation	10.1002/(SICI)1099-1778(200002)11:1%3C27::AID-VIS214%3E3.0.CO;2-5	distributed ray tracing;ray tracing;displacement mapping;optical phenomena;computer science;computer graphics (images)	Visualization	63.283811228024234	-51.54427901289737	174689
074d4629e631cb0af56c4c3565dbfed508738086	geometry and image based view quality comparison for 3d models	view quality;3d model;best view;entropy	In this work we present image-based approach to the best view selection for 3D objects. The proposed method is based on entropy measured in image domain. Several 3D models are used in the experiment. The results are compared to the well-known geometrical method based on perspective frustum entropy, a special case of viewpoint entropy.	3d modeling;entropy (information theory);frustum;whole earth 'lectronic link	Jan Lacko;Zuzana Cernekova;Marian Maricak	2010		10.1145/1925059.1925090	computer vision;entropy;mathematical optimization;mathematics;geometry	Vision	57.30490796234835	-51.04086613855618	174692
da723b9094ddcbf51c5981f7bf4b46433297b91f	kinematic analysis of complex therapeutic movements of the upper limb	kinematic analysis;digital camera;upper limb	Summary. The paper presents the results of kinematic analysis of therapeutic movements of the upper limb, according to PNF method recommendations. Real trajectories of upper limb movements were recorded using the photogrammetric method. The measuring site consisted of a set of 8 digital cameras, two computer workstations, a set of markers, calibrating dice and light sources. On the basis of the recorded images and calculations performed with the use of specialized software, model trajectories of the analyzed movements and values of relative angular translocations and angular velocity in individual joints of the limb were defined.		Robert Michnik;Jacek Jurkojc;Z. Rak;A. Mezyk;Zbigniew Paszenda;Wieslaw Rycerski;Jan Janota;Jacek Brandt	2008		10.1007/978-3-540-68168-7_63	simulation;geography;anatomy;cartography	HCI	57.92991647388979	-39.13337070733847	174860
5980117470fca8221b50429acec8246ac8959b1c	on minimum spanning tree streaming for image analysis		This work addresses minimum spanning tree (MST) construction in streaming for images. We study the problem of computation a MST on streaming in which image columns from a continuous stream are processed in blocks of a given size. The correctness of proposed algorithm is proved and confirmed in the case of morphological segmentation of remote sensing images.		Leonardo Gigli;Santiago Velasco-Forero;Beatriz Marcotegui	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451715	computer vision;image segmentation;computation;correctness;pattern recognition;artificial intelligence;minimum spanning tree;computer science	Robotics	61.71992326983286	-49.38581185105558	175401
5d12b8a56daf1189d270f25decdac58e220eb4aa	a dimensionality paradigm for surface interrogations	concepcion asistida;computer aided design;modele geometrique;geometrie solide;geometria solidos;superficie curva;curved surface;surface vorokoi;conception assistee;surface courbe;solid geometry;geometrical model;modelo geometrico	We propose a paradigm for analyzing problems involving complex curved surfaces in a manner suit.able for practical implementation. Rather than deriving closed-form expressions for certain surfaces and problems, we propose to reformulate the problem in a higher dimensional space with more variables but simpler equations, thus avoiding complex symbolic manipulation and numerically delicate operations.	numerical analysis;programming paradigm	Christoph M. Hoffmann	1990	Computer Aided Geometric Design	10.1016/0167-8396(90)90013-H	topology;computer aided design;solid geometry;calculus;mathematics;geometry	Graphics	67.4536789392251	-40.36307424418866	175485
cbc9721fccdcdad49afe1512df0501c209a743e7	how to build and customize a high-resolution 3d laserscanner using off-the-shelf components		3D laserscanners are well suited sensors for different perception tasks like navigation and object recognition. However, ready-to-use 3D laserscanners are expensive and offer a low resolution as well as a small field of view. Therefore, many groups design their own 3D laserscanner by rotating a 2D laserscanner. Since this whole process is done frequently, this paper aims at fostering other groups’ future research by offering a list of necessary hardware including an online-accessible mechanical drawing, and available software. As it is possible to align the rotation axis and the 2D laserscanner in many different ways, we present an approach to optimize these orientations. A corresponding Matlab toolbox can be found at our website. The performance of the 3D laserscanner is shown by multiple matched point clouds acquired in outdoor environments.		Stefan Schubert;Peer Neubert;Peter Protzel	2016		10.1007/978-3-319-40379-3_33	3d reconstruction;software;point cloud;matlab;toolbox;computer vision;field of view;artificial intelligence;technical drawing;computer science	Robotics	57.538870161018636	-47.354375261873315	175572
9aa0644cac84c9dbc57f7f59d82da42a3d8f8d13	learning motion style synthesis from perceptual observations	space time	This paper presents an algorithm for synthesis of human moti on in specified styles. We use a theory of movement observation (Laban Movement Anal ysis) to describe movement styles as points in a multi-dimensional perceptua l sp ce. We cast the task of learning to synthesize desired movement styles as a r egression problem: sequences generated via space-time interpolation of motio n capture data are used to learn a nonlinear mapping between animation parameters a nd movement styles in perceptual space. We demonstrate that the learned model c an apply a variety of motion styles to pre-recorded motion sequences and it can ex trapolate styles not originally included in the training data.	algorithm;comstock–needham system;interpolation;nonlinear system;theory	Lorenzo Torresani;Peggy Hackney;Christoph Bregler	2006			cognitive psychology;computer vision;perceptual learning;communication	ML	61.19422519784251	-45.440436450202334	175718
b479981f308efbc1368495207513d852c8a597db	a differential geometry approach to camera-independent image correspondence		Abstract Projective geometry is a standard mathematical tool for image-based 3D reconstruction. Most reconstruction methods establish pointwise image correspondences using projective geometry. We present an alternative approach based on differential geometry using oriented patches rather than points. Our approach assumes that the scene to be reconstructed is observed by any camera, existing or potential, that satisfies very general conditions, namely, the differentiability of the surface and the bijective projection functions. We show how the notions of the differential geometry such as diffeomorphism, pushforward and pullback are related to the reconstruction problem. A unified theory applicable to various 3D reconstruction problems is presented. Considering two views of the surface, we derive reconstruction equations for oriented patches and pose equations to determine the relative pose of the two cameras. Then we discuss the generalized epipolar geometry and derive the generalized epipolar constraint (compatibility equation) along the epipolar curves. Applying the proposed theory to the projective camera and assuming that affine mapping between small corresponding regions has been estimated, we obtain the minimal pose equation for the case when a fully calibrated camera is moved with its internal parameters unchanged. Equations for the projective epipolar constraints and the fundamental matrix are also derived. Finally, two important nonlinear camera types, the axial and the spherical, are examined.		József Molnár;Ivan Eichhardt	2018	Computer Vision and Image Understanding	10.1016/j.cviu.2018.02.005	mathematics;computer vision;projective geometry;mathematical optimization;artificial intelligence;pushforward (differential);fundamental matrix (computer vision);pullback;affine transformation;epipolar geometry;differential geometry;nonlinear system	Vision	54.24092597848098	-51.07258987077883	175847
d9f97a69a753efc998c5bebb8d8c8ca6a2f0ff98	statistical method for sub-pixel interpolation function estimation	function fitting;interpolation;three dimensional models;measurement;sub pixel interpolation;image matching;stereo vision systems;interpolation function estimation statistical method sub pixel interpolation distance estimation stereo vision systems function fitting;interpolation fitting accuracy optimization measurement pixel mathematical model;statistical method;distance estimation;data distribution;stereo image processing image matching interpolation statistical analysis;function optimization;fitting;accuracy;depth perception;statistical analysis;pixel;stereo image processing;interpolation function estimation;stereo vision;distance perception;mathematical model;algorithms;optimization;stereoscopic models;functional requirement	Depth accuracy is one of the most important characteristics for sensors used in distance estimation. Stereo-vision systems employ sub-pixel interpolation to achieve such accuracy. Literature in this domain is usually dedicated to simple window based stereo solutions. There are currently several new stereo algorithms developed to counter pixel level errors, but they neglect sub-pixel results. We propose the use of function fitting to generate interpolation functions optimized for each algorithm type. Dedicated interpolation functions require the mathematical model of the algorithm. In the proposed methodology of generating the interpolation function the explicit model of the stereo algorithm is replaced by modeling the data distribution resulted from a pre-defined input. Several transformations are also proposed to reduce the dimensionality of the fitting data without loosing any information. The most accurate match for the fitting data-set was a sinusoidal function, a novel shape for sub-pixel interpolation. The function shows a significant improvement compared to legacy solutions, by reducing the error magnitude by several factor for both synthetic and real scenarios. sf]Y	3d modeling;algorithm;curve fitting;interpolation;legacy system;mathematical model;pixel;sensor;stereopsis;synthetic data;synthetic intelligence	István Haller;Cosmin D. Pantilie;Tiberiu Marita;Sergiu Nedevschi	2010	13th International IEEE Conference on Intelligent Transportation Systems	10.1109/ITSC.2010.5625173	spline interpolation;computer vision;mathematical optimization;bilinear interpolation;interpolation;stairstep interpolation;inverse quadratic interpolation;bicubic interpolation;mathematics;nearest-neighbor interpolation;multivariate interpolation;statistics;trilinear interpolation	Vision	63.000958228708576	-43.00969983705905	175945
76409ca4546f3418149e533acfbfe6187e01db09	mediated reality using computer graphics hardware for computer vision	computer graphics;real time;wearable computers;head tracking;virtual reality;graphics hardware mediated reality computer graphics hardware computer vision head tracking systems image registration algorithms computer generated information multiscale gaussian pyramid body borne computer 3d computer graphics hardware repetitive image projections wearable computer;computer graphic;computer vision;graphics hardware;image registration;wearable computer;computer graphics hardware computer vision filtering wearable computers acceleration image resolution cameras iterative algorithms interpolation;wearable computers computer graphics computer vision virtual reality;3d graphics	Wearable, camera based, head–tracking systems use spatial image registration algorithms to align images taken as the wearer gazes around their environment. This allows for computer–generated information to appear to the user as though it was anchored in the real world. Often, these algorithms require creation of a multiscale Gaussian pyramid or repetitive re–projection of the images. Such operations, however, can be computationally expensive, and such head–tracking algorithms are desired to run in real–time on a body borne computer. In this paper, we present a method of using the 3D computer graphics hardware that is available in a typical wearable computer to accelerate the repetitive image projections required in many computer vision algorithms. We apply this “graphics for vision” technique to a wearable camera based head–tracking algorithm, implemented on a wearable computer with 3D graphics hardware. We perform an analysis of the acceleration achieved by applying graphics hardware to computer vision to create a Mediated Reality.	3d computer graphics;3d projection;algorithm;align (company);analysis of algorithms;apache axis;chipset;computer vision;computer-mediated reality;estimation theory;gaussian blur;graphics hardware;graphics processing unit;hardware acceleration;iswc;image registration;international symposium on wearable computers;interpolation;norm (social);opengl;pixel;texture mapping;tracking system;wearable computer	James Fung;Felix Tang;Steve Mann	2002		10.1109/ISWC.2002.1167222	3d reconstruction;computer vision;graphics pipeline;computing;scientific visualization;2d computer graphics;simulation;image-based modeling and rendering;wearable computer;computer science;computer graphics lighting;real-time computer graphics;virtual reality;graphics software;output device;computer graphics;general-purpose computing on graphics processing units;software rendering;3d computer graphics;computer graphics (images)	Vision	55.99544423285664	-44.26217002363497	176105
50312296d1d93995823bcaf5fe260ddbdae56f20	real-time geometric motion blur for a deforming polygonal mesh	facial muscle;simulating wrinkle;anatomy-based face model;motion blur;swept volume;deforming polygonal mesh;facial expression;layered structure;real-time geometric motion blur;geometric wrinkle model;silhouette of motion;data structures;skeleton;tracking;animation;mesh generation;real time systems;computer science;layout;computational geometry;application software;computer animation;computational modeling;solid modeling;real time;software quality;image resolution	Motion blur is an important method for increasing the visual quality of real-time applications. This is especially true in the area of interactive applications, where designers often seek to add graphical flair to their programs. In many cases, these applications use animated characters, where a polygonal mesh is wrapped around an animated skeleton. As the skeleton moves, the mesh deforms. In this paper, we present a method for adding a geometric motion blur to a deforming polygonal mesh. The scheme we present keeps track of a character's motion silhouette, and uses this to create a polygonal mesh. When this mesh is inserted into the scene, it gives the appearance of an artistic motion blur for an object or particular character. This method is generic enough to work on nearly any type of moving polygonal model, and also approximates swept volumes.	algorithm;computation;direct3d;gaussian blur;graphical user interface;graphics hardware;graphics pipeline;ibm notes;motion capture;motion compensation;neighbourhood (graph theory);overhead (computing);polygon mesh;real-time clock;real-time computer graphics;real-time locating system;real-time transcription;rendering (computer graphics);vertex (graph theory);video card	Nathaniel Jones;John Keyser	2005	International 2005 Computer Graphics	10.1109/CGI.2005.1500358	layout;anime;mesh generation;computer vision;application software;simulation;image resolution;computational geometry;computer science;laplacian smoothing;computer animation;tracking;solid modeling;programming language;computational model;skeleton;software quality;computer graphics (images)	Graphics	65.83196688703588	-48.61396847598119	176201
369c8cce7e274f568bd8c35d0182bbb5ea1f533d	empirical study on designing of gaze tracking camera based on the information of user’s head movement	empirical study;gaze tracking;accuracy;optimal viewing angle and dof of camera lens;user convenience and interest	Gaze tracking is the technology that identifies a region in space that a user is looking at. Most previous non-wearable gaze tracking systems use a near-infrared (NIR) light camera with an NIR illuminator. Based on the kind of camera lens used, the viewing angle and depth-of-field (DOF) of a gaze tracking camera can be different, which affects the performance of the gaze tracking system. Nevertheless, to our best knowledge, most previous researches implemented gaze tracking cameras without ground truth information for determining the optimal viewing angle and DOF of the camera lens. Eye-tracker manufacturers might also use ground truth information, but they do not provide this in public. Therefore, researchers and developers of gaze tracking systems cannot refer to such information for implementing gaze tracking system. We address this problem providing an empirical study in which we design an optimal gaze tracking camera based on experimental measurements of the amount and velocity of user's head movements. Based on our results and analyses, researchers and developers might be able to more easily implement an optimal gaze tracking system. Experimental results show that our gaze tracking system shows high performance in terms of accuracy, user convenience and interest.	adaboost;desktop computer;existential quantification;experiment;eye tracking;ground truth;head movements;illuminator (backlight);lens (device);movement;pinhole camera model;specification;spectroscopy, near-infrared;tracking system;ultrasonics (sound);velocity (software development);viewing angle;wearable computer;webcam;empirical study	Weiyuan Pan;Dong-Wook Jung;Hyo Sik Yoon;Dong Eun Lee;Rizwan Ali Naqvi;Kwan Woo Lee;Kang Ryoung Park	2016		10.3390/s16091396	computer vision;simulation;accuracy and precision;multimedia;empirical research;statistics	Mobile	57.46708334175159	-39.1582796981943	176272
8735e8ff2c2e722f9fa651f3e1f670d701b5427c	three-dimensional object metamorphosis through energy minimization	3d animation;shortest path algorithm;surface reconstruction;three dimensional;computer graphic;energy minimization	ÐThis paper presents a technique for smoothly blending some categories of three-dimensional polygonal objects. Polygon blending is usually considered a two-part process: generating vertex correspondences and interpolating between corresponding vertices to create the intermediate polygons. This paper considers the problem of automatic vertex correspondence determination. The proposed algorithm is based on the work of Sederberg and Greenwood [Computer Graphics 26(2), 25±34, 1992]. The resulting solution tends to associate regions of the two objects which look alike. # 1998 Elsevier Science Ltd. All rights reserved.	algorithm;alpha compositing;apache axis;computer graphics;energy minimization;interpolation;smoothing;user interface	Ioannis Korfiatis;Yakup Paker	1998	Computers & Graphics	10.1016/S0097-8493(98)00007-7	three-dimensional space;computer vision;dijkstra's algorithm;surface reconstruction;computer science;artificial intelligence;theoretical computer science;mathematics;geometry;computer animation;energy minimization;algorithm;computer graphics (images)	Graphics	65.89343447555693	-46.2060693593511	176662
df581316e2ed592bd955999a46638a926d572fa3	data-driven season characteristic enhancement of natural image	image enhancement;image colour analysis;edit propagation;natural image enhancement data driven season characteristic enhancement input image season scenes season objects color appearance input scene color style color transfer approach user scribbles geometric information context sensitive object retrieval repeated elements based modification duplication scheme user specified object modification target scene illumination;image color analysis libraries image segmentation lighting springs semantics estimation;repeated elements;color transfer;natural scenes image colour analysis image enhancement image retrieval;repeated elements edit propagation color transfer;natural scenes;image retrieval	We present a system of creating new scenes in different seasons from an input image captured in a particular season by stylizing it according to similar images in our library which includes a vast number of different season scenes and objects. Firstly, we transfer the color appearance of the input scene in accordance with the color style of other seasons scenes by using color transfer approach. Secondly, user scribbles are used to guide the detection of repeated elements in the input image and geometric information of these detected elements are obtained. Then context-sensitive objects of specified class that match most of the required properties are retrieved from our library and edited according to the geometric information of the specified elements in the scene, such as inserting new objects into the scene or replacing objects by new ones. After that, a repeated-elements-based modification duplication scheme is proposed and implemented to semi-automatically propagate the user-specified objects modification. Finally, blending is applied to the inserted objects to achieve consistency with the target scene in illumination. The main contribution of this work is that we present a complete system to create new scenes of different seasons.	alpha compositing;color mapping;context-sensitive grammar;google map maker;image editing;preprocessor;resultant;semiconductor industry;transfer-based machine translation;user interface	Feng Ding;Jianwei Li;Dongqing Zou;Xiaowu Chen	2013	2013 Seventh International Conference on Image and Graphics	10.1109/ICIG.2013.186	computer vision;color image;image retrieval;computer science;multimedia;computer graphics (images)	Vision	64.0806030706911	-48.18582608175048	176782
9605cbe6e580a1de43cf0b6f2a49a59ceb955c8d	research the intelligent design and simulation system of tujia brocade		Protection and inheriting of the traditional brocade crafts are the focusing problems of the current social. Computer aided design is one of the directions of inheriting the traditional brocade crafts. In this paper, we focus on the Tujia brocade, which is one of the famous Chinese traditional brocade, to research the layout- designing and appearance-simulation techniques. We propose an intelligent design and simulation model of Tujia brocade. The design combination technique based on pattern and skeleton is used to design a digital layout of Tujia brocade. We employ the Octree to quantitate the color map of designed layout and extract the main color map based on kmeans cluster. We render each region, which is segmented by main color map, with yarn structure template based on cubic convolution interpolation algorithm. Finally, we can generate out the appearance of designed layout with good fabric material. To demonstrate the applicability and validity, our method generates several Tujia brocade layouts and simulates its appearance. We also analyze the designed and simulate results compared with some traditional methods.	algorithm;color mapping;computer-aided design;convolution;cubic function;interpolation;k-means clustering;octree;simulation	Tao Hu;Jun Li;Li Zhu;Jing Wang;Xiaoyan Li;Xuemin Chen	2017	2017 3rd IEEE International Conference on Cybernetics (CYBCON)	10.1109/CYBConf.2017.7985804	interpolation;computer graphics (images);k-means clustering;octree;computer aided design;computer vision;artificial intelligence;skeleton (computer programming);engineering	EDA	64.43365898328211	-46.56133808980515	177041
adc1d5d53cd214afa47994dadbefd33eeee7a2e5	research and implement of virtual human's walking model in maintenance simulation	modelizacion;animacion por computador;interfase usuario;teleenseignement;trajectoire;walking;mise a jour;estimation mouvement;caminata;analisis estadistico;realite virtuelle;realidad virtual;legged locomotion;maintenance;red petri;user interface;estimacion movimiento;locomotion avec jambes;divertissement;virtual reality;motion estimation;probabilistic approach;actualizacion;modelisation;posture;marche a pied;trajectory;statistical analysis;locomocion bipedo;enfoque probabilista;approche probabiliste;analyse statistique;postura;mantenimiento;interface utilisateur;trayectoria;teleensenanza;bipedal walking;remote teaching;computer animation;petri net;modeling;human animation;entertainment;locomotion bipede;reseau petri;updating;animation par ordinateur	This paper presents a set of technologies to generate human animations based on captured motion data. Firstly, original coarse motion data need to be normalized as standard data set. Secondly, spatial and temporal characteristics of human locomotion are calculated according to experience equations, anthropometric statistics data and user-defined interface parameters. Trajectory of human's root site is scaled and rotated to fit real walking distance and direction. Then, a simulation structure based on place/transition Petri Net is designed and conducted to start, run, pause and end simulation loop. During the update phase of the loop, position and posture of virtual figure in each frame are generated through interpolating from scaled motion data.	simulation;virtual actor	Xiaojun Lu;Yan Li;Hangen He;Yunxiang Ling	2006		10.1007/11736639_125	computer vision;entertainment;simulation;systems modeling;computer science;artificial intelligence;trajectory;motion estimation;virtual reality;computer animation;advertising;user interface;petri net	Robotics	60.71818616684729	-45.6002987833903	177082
8f3b7207238f6ec38d48029dc96503b2bc6f9178	optical-model-based analysis of consecutive images	moving image;analisis imagen;surface reflection;representation tridimensionnelle;object shape;computer graphics;reflexion superficielle;image optique;imagen movil;computer graphic;image mobile;light source;reflexion superficial;image sequence;source lumineuse;fuente luminosa;imagen optica;image analysis;three dimensional representation;secuencia imagen;optical flow;grafico computadora;analyse image;optical image;reflection coefficient;infographie;representacion tridimensional;sequence image	Abstract   Most existing algorithms for analyzing a moving scene use a 3-dimensional geometric model consisting of an object and a viewer and disregard optical processes. So, they cannot be applied to realistic scenes, such as those with light sources. This paper therefore presents a comprehensive image analysis based on a 3-dimensional optical model that includes light sources as well as the object and the viewer. The optical model provides a photometric constraint describing the geometric relationship between light sources and surface shape, and the constraint serves as the basis for a new algorithm that estimates optical flow, object shape, surface reflection coefficients, and illuminant direction from consecutive images. It is shown that the parameter is not just a correction term in estimating optical flow but also a photometric term having physical meaning. This is proved by showing that incident light source and surface reflection coefficients can be estimated using the parameter. The analysis can provide enough parameters for regeneration of a scene using computer-graphics techniques.		Naoki Mukawa	1997	Computer Vision and Image Understanding	10.1006/cviu.1996.0500	computer vision;image analysis;computer science;optical flow;reflection coefficient;computer graphics;computer graphics (images)	Vision	57.06578489648815	-50.98714450504634	177365
20bc4145bfa389f40768a7206ba6e5515925af29	a category-level 3-d object dataset: putting the kinect to work	three dimensional;shape;detectors;image sensors	Recent proliferation of a cheap but quality depth sensor, the Microsoft Kinect, has brought the need for a challenging category-level 3D object detection dataset to the fore. We review current 3D datasets and find them lacking in variation of scenes, categories, instances, and viewpoints. Here we present our dataset of color and depth image pairs, gathered in real domestic and office environments. It currently includes over 50 classes, with more images added continuously by a crowd-sourced collection effort. We establish baseline performance in a PASCAL VOC-style detection task, and suggest two ways that inferred world size of the object may be used to improve detection. The dataset and annotations can be downloaded at http://www.kinectdata.com.	baseline (configuration management);color;crowdsourcing;kinect;object detection;structured-light 3d scanner	Allison Janoch;Sergey Karayev;Yangqing Jia;Jonathan T. Barron;Mario Fritz;Kate Saenko;Trevor Darrell	2011	2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)	10.1007/978-1-4471-4640-7_8	three-dimensional space;computer vision;detector;simulation;shape;computer science;viola–jones object detection framework;image sensor;mathematics;geometry;computer graphics (images)	Vision	54.66036506765013	-45.35716153976274	177415
5b33e6edcecfd94d5e92f325f5044225804124c4	utilization of a terrestrial laser scanner for the calibration of mobile mapping systems	mobile mapping system;boresight;lever arm;terrestrial laser scanner;calibration	This paper proposes a practical calibration solution for estimating the boresight and lever-arm parameters of the sensors mounted on a Mobile Mapping System (MMS). On our MMS devised for conducting the calibration experiment, three network video cameras, one mobile laser scanner, and one Global Navigation Satellite System (GNSS)/Inertial Navigation System (INS) were mounted. The geometric relationships between three sensors were solved by the proposed calibration, considering the GNSS/INS as one unit sensor. Our solution basically uses the point cloud generated by a 3-dimensional (3D) terrestrial laser scanner rather than using conventionally obtained 3D ground control features. With the terrestrial laser scanner, accurate and precise reference data could be produced and the plane features corresponding with the sparse mobile laser scanning data could be determined with high precision. Furthermore, corresponding point features could be extracted from the dense terrestrial laser scanning data and the images captured by the video cameras. The parameters of the boresight and the lever-arm were calculated based on the least squares approach and the precision of the boresight and lever-arm could be achieved by 0.1 degrees and 10 mm, respectively.	behavior;cns disorder;calibration;estimated;extraction;galileo (satellite navigation);inertial navigation system;least squares;methyl methanesulfonate;mobile mapping;point cloud;satellite navigation;scanner device component;sparse matrix;terrestrial television;sensor (device)	Seunghwan Hong;Ilsuk Park;Ji-Sang Lee;Kwangyong Lim;Yoonjo Choi;Hong-Gyoo Sohn	2017		10.3390/s17030474	computer vision;calibration;torque;optics;physics;remote sensing	Robotics	57.20387223753077	-39.65432169816128	177466
560fa68a810be3018d1d8f18dfa2b8a49b7563a5	generation of 3-d delaunay meshes for complex geometries using iterative refinement	iterative refinement		delaunay triangulation;iterative method;iterative refinement;refinement (computing)	Nancy Hitschfeld-Kahler;Stephan Müller;Wolfgang Fichtner	1992			mathematical optimization;iterative refinement;polygon mesh;delaunay triangulation;mathematics	HPC	66.88502333976814	-43.572058475173804	177547
88b1e75350c6c078ba9d18b0dd7ca99b0bba7b1e	sketch-based modeling with few strokes	modeling technique;free form surfaces;sketch based interfaces modeling;interface model;cross section;interaction model;parametric surface	We present a novel sketch-based system for the interactive modeling of a variety of free-form 3D objects using just a few strokes. Our technique is inspired by the traditional illustration strategy for depicting 3D forms where the basic geometric forms of the subjects are identified, sketched and progressively refined using few key strokes. We introduce two parametric surfaces, rotational and cross sectional blending, that are inspired by this illustration technique. We also describe orthogonal deformation and cross sectional oversketching as editing tools to complement our modeling techniques. Examples with models ranging from cartoon style to botanical illustration demonstrate the capabilities of our system.	3d computer graphics;alpha compositing;sketch;sketch-based modeling	Joseph Jacob Cherlin;Faramarz F. Samavati;Mario Costa Sousa;Joaquim A. Jorge	2005		10.1145/1090122.1090145	simulation;sketch-based modeling;computer science;parametric surface;mathematics;cross section;geometry;computer graphics (images)	Graphics	66.1761947283119	-46.03070767543806	177564
5fdc2f85105f7be335f928b2a5b4ede93cd03027	photometric stereo with non-parametric and spatially-varying reflectance	variational approximation;stereo image processing approximation theory;photometry reflectivity shape parametric statistics computer graphics lighting power system modeling stereo vision rendering computer graphics face recognition;isotropic reflectance function photometric stereo images nonparametric reflectance spatially varying reflectance bivariate approximation;reflectivity;isotropic reflectance function;materials;approximation theory;shape;photometric stereo;image color analysis;reflection model;stereo image processing;mathematical model;pure data;optimization;spatially varying reflectance;bivariate approximation;nonparametric reflectance;photometric stereo images;light sources	We present a method for simultaneously recovering shape and spatially varying reflectance of a surface from photometric stereo images. The distinguishing feature of our approach is its generality; it does not rely on a specific parametric reflectance model and is therefore purely ldquodata-drivenrdquo. This is achieved by employing novel bi-variate approximations of isotropic reflectance functions. By combining this new approximation with recent developments in photometric stereo, we are able to simultaneously estimate an independent surface normal at each point, a global set of non-parametric ldquobasis materialrdquo BRDFs, and per-point material weights. Our experimental results validate the approach and demonstrate the utility of bi-variate reflectance functions for general non-parametric appearance capture.	approximation;normal (geometry);parametric model;photometric stereo	Neil Gordon Alldrin;Todd E. Zickler;David J. Kriegman	2008	2008 IEEE Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2008.4587656	computer vision;photometric stereo;shape;mathematical model;mathematics;geometry;reflectivity;approximation theory	Vision	58.07397500272719	-51.88800149392612	177576
6cd0fa13d0d689556eacf49b778b96f6e9639d1d	agustín de betancourt's double-acting steam engine: geometric modeling and virtual reconstruction			geometric modeling	José Ignacio Rojas-Sola;Belén Galán-Moral;Eduardo De la Morena-De la Fuente	2018	Symmetry	10.3390/sym10080351		Vision	65.71326070719022	-43.761617356572685	177715
5263970c6cc528d1e7fea3680862a129f6f26575	virtual-real fusion with dynamic scene from videos	background modeling;augmented virtual reality;motion tracking;projective texture mapping;3d reconstruction	In this paper, we introduce a method to augment virtual environment with multiple videos. Our goal is to make a virtual-real fusion system that fuses dynamic imagery with 3D models in a real-time display, so as to help observers visualize dynamic videos simultaneously in the context of 3D models. 3D models in virtual environment are reconstructed using multiple view vision methods. Based on this, images can be registered through feature matching among images. Foreground objects in videos lead to distortions when video images are simply projected to static models. Detection and tracking of those objects are needed, and then several ordinary 3D models are used to represent those objects. Both geometry and appearance are taken into account to recover characteristic of different objects. This paper focuses on the integration of these components into a prototype system and the presentation of results shows the benefits of an virtual-real fusion system.	3d modeling;camera resectioning;circuit complexity;distortion;global illumination;image;poor posture;prototype;real-time locating system;seamless3d;stationary process;tree (data structure);unmanned aerial vehicle;video processing;virtual reality	Chengwei Pan;Yisong Chen;Guoping Wang	2016	2016 International Conference on Cyberworlds (CW)	10.1109/CW.2016.17	3d reconstruction;computer vision;computer science;multimedia;projective texture mapping;computer graphics (images)	Vision	58.45915251670886	-50.310402422224314	177727
0493b4278668713626c27280e49ea7250b66ebc0	modeling textured motion : particle, wave and sketch	moving object;visual perception inner representation;image motion analysis;textured motion phenomena;generic model;dictionaries motion analysis snow rivers animation image motion analysis graphics rendering computer graphics visual perception image texture analysis;dimension reduction;image sequence analysis;image representations;visual perception inner representation textured motion phenomena unified motion equation statistical learning algorithm gabor dictionary fourier base dictionary image model motion model cartoon animation symbolic visualization;image model;image texture;statistical learning algorithm;data visualisation;visualization;statistical learning;gabor dictionary;image representation;motion model;animation;fourier analysis;visual perception;image texture analysis;symbolic visualization;computer animation;rendering computer graphics;cartoon animation;image modeling;fourier base dictionary;natural scenes;unified motion equation;fourier analysis image texture image motion analysis image sequences computer animation data visualisation rendering computer graphics image representation natural scenes;image sequences	In this paper, we present a generative model for textured motion phenomena, such as falling snow, wavy river and dancing grass, etc. Firstly, we represent an image as a linear superposition of image bases selected from a generic and over-complete dictionary. The dictionary contains Gabor bases for point/particle elements and Fourier bases for wave-elements. These bases compete to explain the input images. The transform from a raw image to a base or a token representation leads to large dimension reduction. Secondly, we introduce a unified motion equation to characterize the motion of these bases and the interactions between waves and particles, e.g. a ball floating on water. We use statistical learning algorithm to identify the structure of moving objects and their trajectories automatically. Then novel sequences can be synthesized easily from the motion and image models. Thirdly, we replace the dictionary of Gabor and Fourier bases with symbolic sketches (also bases). With the same image and motion model, we can render realistic and stylish cartoon animation. In our view, cartoon and sketch are symbolic visualization of the inner representation for visual perception. The success of the cartoon animation, in turn, suggests that our image and motion models capture the essence of visual perception of textured motion.	algorithm;dictionary;dimensionality reduction;generative model;interaction;machine learning;non-photorealistic rendering;raw image format;sketch;stylish;superposition principle	Yizhou Wang;Song-Chun Zhu	2003		10.1109/ICCV.2003.1238343	image texture;anime;computer vision;visualization;visual perception;computer science;motion estimation;computer animation;multimedia;fourier analysis;motion field;data visualization;dimensionality reduction;computer graphics (images)	Vision	61.3091983382635	-46.067972822121405	177782
ed36488a1d69f72314c327447fb3966e52da2918	table tennis robot with stereo vision and humanoid manipulator ii: visual measurement of motion-blurred ball	minimisation;cameras robots three dimensional displays machine vision trajectory visualization image edge detection;least squares approximations;manipulators;multi threading;image motion analysis;velocity control;motion control;velocity control graphics processing units humanoid robots image motion analysis image reconstruction least squares approximations manipulators minimisation mobile robots motion control multi threading object tracking robot vision sport sports equipment stereo image processing;sports equipment;table tennis robot vision system latency reduction multithread technique gpu based image processing flying trajectory weighted least square method image reconstruction ball velocity 3d location circle fitting motion parameters foreground object bounding rectangle motion width estimation directional derivatives l2 norm minimization motion direction motion blurred images table tennis ball motion tracking motion blurred ball visual measurement humanoid manipulator stereo vision;mobile robots;robot vision;humanoid robots;image reconstruction;graphics processing units;object tracking;stereo image processing;sport	In this paper a stereo-vision based framework is presented to track the motion of a table-tennis ball in motion-blurred images. In the proposed approach, first the motion direction is identified by minimizing L2 norm of directional derivatives of the blurred image and the motion width is estimated using the bounding rectangle of the foreground object. Then more accurate motion parameters of the ball are obtained based on circle fitting. Finally 3D location and velocity of the ball are reconstructed from a single image pair and weighted least-square method is utilized to estimate the flying trajectory of the ball. The proposed method is implemented in an actual robot table tennis system. GPU-based image processing and multi-thread technique are used to reduce the latency of the vision system. The obtained results verifies the effectiveness of the proposed method.	algorithm;autostereogram;curve fitting;gaussian blur;graphics processing unit;image processing;minimum bounding rectangle;robot;stereopsis;velocity (software development)	Hong Liu;Zhiqi Li;Bin Wang;Yang Zhou;Qi Zhang	2013	2013 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2013.6739835	motion control;computer vision;minimisation;simulation;computer science;artificial intelligence;sport;mathematics;computer graphics (images)	Robotics	56.018008150983185	-41.42401506983514	178053
bc9ac10da70be98c2059452b509a9704c6fec63f	estimating surface shape and extending known structure using specular reflections	surface normal;known structure;light source position;shape estimation;surface shape unambiguously;scene geometry;standard structure;specular reflections;image sequence;estimating surface shape;structure extension;reflection;specular reflection	In this paper a method for the shape estimation and structure extension of a surface using information from specularities is proposed. The structure of the scene is obtained from an image sequence using standard structure and motion techniques. If there are specularities in the scene, there may be parts where the scene geometry cannot be determined. The method proposed in this paper extends the known structure over these regions. Methods for determining the light source position are introduced and together with the reflections, this gives constraints on the surface normals. These constraints are complemented by a smoothness condition in order to estimate the surface shape unambiguously. The viability of the proposed method is demonstrated in experiments with the real data from image sequences.	experiment;normal (geometry);reflection (computer graphics);sensor;spline (mathematics)	Jan Erik Solem;Anders Heyden	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1334496	computer vision;specular reflection;reflection;mathematics;geometry;motion field	Vision	53.95616653916425	-50.935919310072336	178383
e46c4015b78343d68cc865bb0adf7eb0beb2b3d4	hierarchical quad meshing of 3d scanned surfaces				Dennis R. Bukenberger;Hendrik P. A. Lensch	2018	Comput. Graph. Forum	10.1111/cgf.13497	computer vision;computer science;artificial intelligence	HCI	65.7383503237659	-43.693787617931186	178685
158841cf2ef9df53094359a794ba741cf7d418c5	evaluation of object surface edge profiles detected with a 2-d laser scanning sensor	automation;greenhouse crop;pesticide spray equipment;surface contour detection;variable rate	Canopy edge profile detection is a critical component of plant recognition in variable-rate spray control systems. The accuracy of a high-speed 270° radial laser sensor was evaluated in detecting the surface edge profiles of six complex-shaped objects. These objects were toy balls with a pink smooth surface, light brown rectangular cardboard boxes, black and red texture surfaced basketballs, white smooth cylinders, and two different sized artificial plants. Evaluations included reconstructed three-dimensional (3-D) images for the object surfaces with the data acquired from the laser sensor at four different detection heights (0.25, 0.50, 0.75, and 1.00 m) above each object, five sensor travel speeds (1.6, 2.4, 3.2, 4.0, and 4.8 km h-1), and 8 to 15 horizontal distances to the sensor ranging from 0 to 3.5 m. Edge profiles of the six objects detected with the laser sensor were compared with images taken with a digital camera. The edge similarity score (ESS) was significantly affected by the horizontal distances of the objects, and the influence became weaker when the objects were placed closer to each other. The detection heights and travel speeds also influenced the ESS slightly. The overall average ESS ranged from 0.38 to 0.95 for all the objects under all the test conditions, thereby providing baseline information for the integration of the laser sensor into future development of greenhouse variable-rate spray systems to improve pesticide, irrigation, and nutrition application efficiencies through watering booms.		Tingting Yan;Xiaochan Wang;Heping Zhu;Peter Ling	2018		10.3390/s18114060		Robotics	59.79431438585427	-42.71503887132099	178836
3064b6c87d24b0edc156e4a8a987711a7056e82e	visually-complete aerial lidar point cloud rendering	pbr;point based rendering;procedural geometry;visually complete;gpu;aerial lidar;point cloud;2 5d	Aerial LiDAR (Light Detection and Ranging) point clouds are gathered by a downward scanning laser on a low-flying aircraft. Due to the imaging process, vertical surface features such as building walls, and ground areas under tree canopies are totally or partially occluded, resulting in gaps and sparsely sampled areas. These gaps produce unwanted holes and uneven point distributions that often produce artifacts when visualized using point-based rendering (PBR) techniques. We show how to extend PBR by inferring the physical nature of LiDAR points for visual realism and added comprehension. More specifically, the class of object a point is related to augments the point cloud in pre-processing and/or adapts the online rendering, to produce visualizations that are more complete and realistic. We provide examples of point cloud augmentation for building walls and ground areas under tree canopies. We show how different types of procedurally generated geometry can be used to recover building walls. These methods are generic and can be applied to any aerial LiDAR data set with buildings and trees. Our work also incorporates an out-of-core strategy for hierarchical data management and GPU-accelerated PBR with extended deferred shading. The combined system provides interactive visually-complete rendering of virtually unlimited-size LiDAR point clouds. Experimental results show that our rendering approach adds only a slight overhead to PBR and provides comparable visual cues to visualizations generated by off-line pre-computation of 3D polygonal urban models.	aerial photography;computation;deferred shading;graphics processing unit;hierarchical database model;online and offline;out-of-core algorithm;overhead (computing);pbr theorem;point cloud;precomputation;preprocessor;procedural generation	Zhenzhen Gao;Luciano Nocera;Ulrich Neumann	2012		10.1145/2424321.2424359	computer vision;computer science;point cloud;cartography;remote sensing;computer graphics (images)	Graphics	66.89730002949305	-50.337479482246636	179227
32a071ad1d044f8a1f9996fa1813cf7c2bed55ae	high accuracy tof and stereo sensor fusion at interactive rates	stereo depth data;interactive rate;ground truth dataset;megapixel depth map;data fidelity measure;individual method;stereo sensor fusion;fundamental limitation;high accuracy;local model work;higher computational cost;tof interreflection	We propose two new GPU-based sensor fusion approaches for time of flight (TOF) and stereo depth data. Data fidelity measures are defined to deal with the fundamental limitations of both techniques alone. Our algorithms combine TOF and stereo, yielding megapixel depth maps, enabling our approach to be used in a movie production scenario. Our local model works at interactive rates but yields noisier results, whereas our variational technique is more robust at a higher computational cost. The results show an improvement over each individual method with TOF interreflection remaining an open challenge. To encourage quantitative evaluations, a ground truth dataset is made publicly available.	algorithm;algorithmic efficiency;computation;depth map;depth perception;gradient;graphics processing unit;ground truth;photo-consistency;pixel;sensor web;variational principle;visual computing	Rahul Nair;Frank Lenzen;Stephan Meister;Henrik Schäfer;Christoph S. Garbe;Daniel Kondermann	2012		10.1007/978-3-642-33868-7_1	computer vision;simulation;computer science;computer graphics (images)	Vision	54.2384725020198	-46.36949568188303	179305
366a243fad9f3c2e950519cd8e320802408b5640	realistic computer graphics and free form surfaces	trazado rayos;concepcion asistida;computer aided design;rendu image;trace rayon;computer graphic;algorithme;algorithm;algorritmo;ray tracing;image rendering;conception assistee	Abstract   An image generation approach in computer graphics leading to images of considerable optical quality is ray tracing, deduced from geometric optics. Crucial for the efficiency of ray tracing is to find quickly an intersection point closest to a ray's origin. This requires to restrict the candidate patches of a given scene as well as to find the intersections of a ray with a patch. We survey approaches to solve these two problems, and present a new method, based on space sweep and patch subdivision. Its advantages are subdivision adapted to the distribution of rays and consideration of ray coherence. This implies that useless subdivisions are avoided.	computer graphics	Heinrich Müller	1988	Computer Aided Geometric Design	10.1016/0167-8396(88)90002-7	distributed ray tracing;ray tracing;computer aided design;geometry;beam tracing	Graphics	66.64063165540483	-48.528463944942445	179344
17e47b16958ed02c74a38cb29b629800f45dd388	a flexible technique based on fundamental matrix for camera self-calibration with variable intrinsic parameters from two views	variable intrinsic parameters;fundamental matrix;self calibration;unknown 3 d scene;absolute conic;unknown 3d	Self-calibrate cameras with varying focal length.Automatic estimation of the intrinsic parameters of the camera.Works freely in the domain of self-calibration without any prior knowledge about the scene or on the cameras. We propose a new self-calibration technique for cameras with varying intrinsic parameters that can be computed using only information contained in the images themselves. The method does not need any a priori knowledge on the orientations of the camera and is based on the use of a 3 D scene containing an unknown isosceles right triangle. The importance of our approach resides at minimizing constraints on the self-calibration system and the use of only two images to estimate these parameters. This method is based on the formulation of a nonlinear cost function from the relationship between two matches which are the projection of two points representing vertices of an isosceles right triangle, and the relationship between the images of the absolute conic. The resolution of this function enables us to estimate the cameras intrinsic parameters. The algorithm is implemented and validated on several sets of synthetic and real image data.	camera resectioning;fundamental matrix (computer vision)	Bouchra Boudine;Sébastien Kramm;Nabil El Akkad;Abdelaziz Bensrhair;Abderrahim Saaidi;Khalid Satori	2016	J. Visual Communication and Image Representation	10.1016/j.jvcir.2016.05.003	computer vision;mathematical optimization;computer science;mathematics;geometry;fundamental matrix	Vision	53.82541103566379	-49.99237650482249	179394
4e7cd13d371a5b347a0a55503603808eb5461b8f	rendering the intersections of implicit surfaces	implicit surface;octree based recursive space subdivision techniques implicit surface intersection rendering intersection curves;boolean operations;computer graphics testing rendering computer graphics space technology tree graphs robustness cameras books equations solids;intersections;contour maps;journal article;intervals;implicit surfaces;contours;octrees rendering computer graphics;curvature;rendering computer graphics;octrees	"""mplicit surfaces have uses in areas as diverse as mathematics, science, and solid model-ing. We discuss algorithms to locate and render the intersection curves of implicit surfaces. The general surface intersection problem is large and complex, and within this general context our aims are quite modest. We wish to construct piecewise linear approximations to the intersection curves for rendering purposes. Our intersection algorithms have a number of applications: rendering the intersection curves of two implicit surfaces, aiding the visual-ization of individual surfaces, and plotting functions on implicit surfaces. Our algorithms can trim one surface against another, and they work best with surfaces that are at least C 1 continuous. We are concerned with intersecting arbitrary implicit surfaces that might consist of numerous uncon-nected sections. We focus on the graphical applications. The """" Related Work """" sidebar discusses other approaches. The equations of implicit surfaces are of the form f(x, y, z) − α = 0, (1) where f(x, y, z) is a scalar field and α is a constant. According to Equation 1, implicit surfaces are the iso-valued surfaces of scalar fields. A simple example is the equipotential surface of numerous point charges. Algorithm 1 in Figure 1 is a top-level view of the algorithm that renders the intersection curves of two implicit surfaces. Here, the user specifies a viewing cube in which to search for and plot surface intersections. The algorithm works by recursively subdividing this cube down to a maximum user-specified subdivision level, that is, plotDepth. We refer to nodes at plotDepth as plotting nodes. The algorithm doesn't use adaptive subdivision as in Bloomenthal 1 because this would increase the algorithm's complexity. 2 With constant subdivision, low subdivision depths render quickly and help establish the viewing and other parameters before rendering at higher resolution and with a higher plotDepth value. During subdivision, we use interval arithmetic techniques to discard those nodes that don't contain one or both of the surfaces. 3 Since our algorithms work for both algebraic and nonalgebraic implicit surfaces, we can only use intervals to provide an exclusion test for a surface in a node. Any nodes that might contain both surfaces are subdivided, and their child nodes recursively checked in the same manner down to plotDepth. In Algorithm 1, depth is the recursion depth, initially set to zero; x, y, and z are the coordinates of a node corner, initially set to one of …"""	algorithm;approximation;graphical user interface;implicit surface;interval arithmetic;linear algebra;piecewise linear continuation;recursion;rendering (computer graphics);solid modeling;subdivision surface;tree (data structure);viewing frustum	Kevin G. Suffern;Ronald J. Balsys	2003	IEEE Computer Graphics and Applications	10.1109/MCG.2003.1231180	interval;terrain rendering;computer vision;tiled rendering;scientific visualization;clipping;image-based modeling and rendering;3d rendering;rendering;computer science;rendering equation;polygonal modeling;parallel rendering;geometry;curvature;sparse voxel octree;computer graphics;alternate frame rendering;contour line;software rendering;3d computer graphics;octree;computer graphics (images)	Graphics	67.55064525387763	-48.10283903526211	179541
c529781a85679f93790025b7905f822ea16c6c8b	high-quality reflections, refractions, and caustics in augmented reality and their contribution to visual coherence	photonics;artificial;kernel;raytracing;h 5 1 information interfaces and presentation multimedia information systems rendering computer graphics;interactive rendering speed augmented reality visual coherence high quality rendering system ray tracing based rendering technique visual quality caustics effect refraction effect reflection effect depth of field effect antialiasing gpu photon mapping;augmented;visualization;graphics processing units;i 3 7 computer graphics three dimensional graphics and realism raytracing h 5 1 information interfaces and presentation multimedia information systems artificial augmented and virtual realities;and virtual realities;i 3 7 computer graphics three dimensional graphics and realism 8212;ray tracing;lighting;augmented reality;rendering computer graphics photonics ray tracing lighting visualization cameras kernel;rendering computer graphics;cameras;rendering computer graphics augmented reality graphics processing units ray tracing	In this paper we present a novel high-quality rendering system for Augmented Reality (AR). We study ray-tracing based rendering techniques in AR with the goal of achieving real-time performance and improving visual quality as well as visual coherence between real and virtual objects in a final composited image. A number of realistic and physically correct rendering effects are demonstrated, that have not been presented in real-time AR environments before. Examples are high-quality specular effects such as caustics, refraction, reflection, together with a depth of field effect and anti-aliasing. We present a new GPU implementation of photon mapping and its application for the calculation of caustics in environments where real and virtual objects are combined. The composited image is produced on-the-fly without the need of any preprocessing step. A main contribution of our work is the achievement of interactive rendering speed for high-quality ray-tracing algorithms in AR setups. Finally we performed an evaluation to study how users perceive visual quality and visual coherence with different realistic rendering effects. The results of our user study show that in 40.1% cases users mistakenly judged virtual objects as real ones. Moreover we show that high-quality rendering positively affects the perceived visual coherence.	3d reconstruction;algorithm;aliasing;augmented reality;bmc remedy action request system;color bleeding (computer graphics);compositing;control theory;field effect (semiconductor);global illumination;glossary of computer graphics;graphics processing unit;iso 10303;informatics;match moving;photon mapping;preprocessor;ray tracing (graphics);real-time clock;reflection (computer graphics);rendering (computer graphics);simulation;spatial anti-aliasing;specular highlight;usability testing;visual basic[.net]	Peter Kán;Hannes Kaufmann	2012	2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)	10.1109/ISMAR.2012.6402546	ray tracing;computer vision;augmented reality;computer science;multimedia;computer graphics (images)	Visualization	62.423555939577426	-52.049660023404975	179739
28759889a8e39b12792026a4f185f2883bbf936e	differential geometry from the frenet point of view: boundary detection, stereo, texture and color		Frenet frames are a central construction in modern differential geometry, in which structure is described with respect to an object of interest rather than with respect to external coordinate systems. The Cartan moving frame model specifies how these frames adapt when they are transported along the object. We consider this as a model for integrating local information with information in a neighborhood for curve detection, stereo, texture, and color. These different objects results in a series of geometric compatibility constructions useful within a number of different optimization and probabilistic inference techniques.	edge detection;mathematical optimization;point of view (computer hardware company)	S. Zucker	2006		10.1007/0-387-28831-7_22	computer vision;topology;geometry	Vision	59.20806916486966	-47.607898073675216	179745
a50268a82fbdc3d44dd884192d364d55adfd27e1	carve in, carve out: a bimodal carving through voxelization and functional partitioning		We propose in this paper a novel technique for pattern-guided carving on an orientable 2-manifold surface. Its novelty lies in processing the surface in voxel space using certain theories and deductions of digital geometry. The carving pipeline designed by us is bimodal in nature, as it can generate both ‘negative’ and ‘positive’ carvings by carve in and carve out alongside the specified pattern. The 2D pattern is easily mapped to the 3D surface, as we consider the thinnest voxelized model. We perform functional partition of the voxelized surface and use a local optimization with these components in order to achieve a realistic carving. Necessary theoretical foundations, implementation details, and experimental results have been furnished to adjudge the merit of the proposed technique.	digital geometry;line drawing algorithm;mathematical optimization;seam carving;simulation;voxel space;well-formed element	Piyush Kanti Bhunre;Partha Bhowmick	2018	The Visual Computer	10.1007/s00371-018-1527-5	artificial intelligence;voxel;novelty;computer vision;local search (optimization);digital geometry;computer science;carving	Graphics	66.63060156117437	-45.55582756664264	179909
3e22fb932dff67ac98d6412ffdaaf98ac86dd9ec	three-dimensional realization of anomalous pictures--an application of picture interpretation theory to toy design	concepcion asistida;computer aided design;representation graphique;unfolded surface;image processing;etude experimentale;representacion grafica;juguete;anomalous picture;procesamiento imagen;traitement image;three dimensional;feasibility;line drawings;optical illusion;programme utilitaire;ilusion visual;jouet;interactive system;utility program;toy;conception assistee;realizability;illusion visuelle;interpretation of line drawing;estudio experimental;practicabilidad;faisabilite;graphics;impossible object;programa utilitario	Anomalous pictures are naively regarded as pictures of impossible objects, but some of them are realizable as three-dimensional polyhedral objects. This paper presents an interactive system for generating the unfolded surfaces of those objects, thus offering toy material from which children can make ''impossible objects''.		Kokichi Sugihara	1997	Pattern Recognition	10.1016/S0031-3203(96)00138-0	three-dimensional space;computer vision;simulation;image processing;computer science;graphics;artificial intelligence;optical illusion;mathematics;geometry;algorithm;impossible object	Vision	65.13631812459172	-40.880787277105476	179947
5ff0d3e9510204259ec8872a8b2a5e887bfb4a1c	a geometrical approach for vision based attitude and altitude estimation for uavs in dark environments	sensors;real time;unmanned aerial vehicle;structured light;three dimensional;estimation;three dimensional displays;field of view;low light;cameras estimation laser modes equations sensors three dimensional displays;experience base;laser modes;cameras	This paper presents a single camera and laser system dedicated to the realtime estimation of attitude and altitude for unmanned aerial vehicles (UAV) under low illumination conditions to dark environments. The fisheye camera allows to cover a large field of view (FOV). The approach, close to structured light systems, uses the geometrical information obtained by the projection of a laser circle onto the ground plane and perceived by the camera. We propose some experiments based on simulated data and real sequences. The results show good agreement with the ground truth values from the commercial sensors in terms of its accuracy and correctness. The results also prove its suitability for autonomous take-off and landing as well as for the case of low altitude manoeuvre in dark, GPS signal deficient unknown environments with no prebuilt map. It also provides room for additional payload to be used for different applications due to it being inexpensive and use of light weight micro-camera and laser system.	aerial photography;autonomous robot;correctness (computer science);experiment;field of view in video games;fisheye;global positioning system;ground truth;sensor;structured light;unmanned aerial vehicle	Ashutosh Natraj;Cédric Demonceaux;Pascal Vasseur;Peter F. Sturm	2011	2012 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6094681	three-dimensional space;computer vision;estimation;simulation;structured light;field of view;computer science;sensor;optics;statistics	Robotics	54.67863995222277	-38.06619737734332	180002
d42ff36c5b37b622e8fa562c850f14bbbf8613bb	system calibration and error rectification of binocular active visual platform for parallel mechanism	parallel mechanism;dynamic system;error rectification;stereo vision;geometric model;visual system;calibration;3d reconstruction;dynamic properties	This paper presents a novel binocular active visual platform for monitoring the workspace of a parallel mechanism. Its cameras are mounted on two independent controlled kinematic chains which moving along a circular orbit. The system is designed for precise kinematic calibration of the end-effector on the parallel mechanism and other deepening application. At first, the geometric model of the platform and the 3D reconstruct model based stereo vision are established. Then, in order to eliminate the influence of monitoring accuracy because of the own accuracy of visual system, A dynamic system calibration and error rectification method is proposed. Experiment results show that the approach is effective with respect to dynamic property and calibration accuracy.	binocular vision;image rectification	Liqiang Zhao;Lingfu Kong;Xiaoyong Qiao;Yanhong Zhou	2008		10.1007/978-3-540-88513-9_79	3d reconstruction;computer vision;calibration;simulation;visual system;computer science;stereopsis;geometric modeling;dynamical system;computer graphics (images)	Vision	56.83449119740754	-42.163291355559416	180012
8d81749b592b1d785f1ee4f706ef0dc02f8245e3	reconstruction and restoration interpolation of surfaces over scattered data			circuit restoration;interpolation	Gonzalo A. Ramos;Wayne H. Enright	2001			computer vision;interpolation;artificial intelligence;mathematics	Robotics	65.9059381602231	-44.344977580995085	180047
55eeaa351c256abc6569b52a4b63c8818e5ab2c6	application of computer graphics for design and delivery of conformal radiation therapy	conformal radiation therapy;computer graphics		computer graphics	Marc L. Kessler;Daniel L. McShan;Benedick A. Fraass	1999		10.1145/311625.312120		Visualization	61.33069214278117	-47.959310831775305	180137
300084dd55cc71c044dc41a9d39273da5080c197	mlpf algorithm for tracking fast moving target against light interference	probability density function;interference;state estimation;mathematical model;target tracking;monte carlo methods	In order to deal with the difficulty of tracking the fast moving aerial targets with light interference, we propose an improved particle tracking algorithm named multi-layers particle filter (MLPF). In MLPF, the particles are divided into three categories: the main particles (M-particles), the subordinate particles (S-particles) and the regenerate particles (R-particles). In the phase of resampling and state estimating, only M-particles are involved, then the R-particles are generated and considered as new S-particles in the next cycle. To a certain extent, our algorithm maintains the diversity of particles and reduces the computation time. Besides, MLPF has significant improvements on overcoming the tracing error after the sudden disappearance of the target and solving the degradation of particles. We demonstrate effectiveness of our proposed algorithm through systematic experiments. Experimental results show MLPF has better tracking effect compared to the traditional particle filter (PF) when the target is moving fast and affected by light interference. In the first experiment, the running time has been reduced from 47s to 21s while the precision increased from 64% to 96%. And for the second experiment, the running time has been reduced from 237s to 121s while precision increased from 46% to 89%.	aerial photography;algorithm;computation;context of computational complexity;elegant degradation;experiment;interference (communication);neat particles;particle filter;resampling (statistics);time complexity	Libo Zhang;Yuanqiang Cai;Zakir Ullah;Tiejian Luo	2016	2016 23rd International Conference on Pattern Recognition (ICPR)	10.1109/ICPR.2016.7900250	probability density function;simulation;mathematical model;mathematics;interference;statistics;monte carlo method	Vision	58.4149356572667	-40.907895136420926	180161
011f8f289bf77d0af68c03c935fa9ef22d6e2183	day and night image stitching and rendering	image stitching;local invariant feature matching;rendering	We present a new method to day and night image stitching and rendering for exploring the space-time continuum within a two-dimensional still photograph. Our method is based on a two-scale decomposition of the input images. Homography matrix is calculated by matching feature points of detail layer pairs, which can avoid impact of illumination. Then detail layers and base layers are stitched together, respectively. We mapped the stitched base layer to a radiance map and then rendered it as time-lapse effect based on human vision system. Compared with previous method, our method is easier to implement and has a larger viewing angle. © 2018, Springer International Publishing AG.	day and night (cellular automaton);image stitching	Jeng-Shyang Pan;Lei Liang;Mao-Hsiung Hung;Yongjun Zhuang	2017		10.1007/978-3-319-68527-4_3	rendering (computer graphics);computer science;machine vision;computer graphics (images);radiance;image stitching;viewing angle;homography	Vision	60.98033816592261	-50.49995461568208	180320
ffc562c7f30e1215badf01090d34d358dfee0aca	incremental bvh construction for ray tracing	bounding volume hierarchies;ray tracing	We propose a new method for incremental construction of Bounding Volume Hierarchies (BVH). Despite the wide belief that the incremental construction of BVH is inefficient we show that our method incrementally constructs a BVH with quality comparable to the best SAH builders. We illustrate the versatility of the proposed method using a flexible parallelization scheme that opens new possibilities for combining different BVH construction heuristics. We demonstrate the usage of the method in a proof-ofconcept application for real-time preview of data streamed over the network. We believe that our method will renew the interest in incremental BVH construction and it will find its applications in ray tracing based remote visualizations and fast previews or in interactive scene editing applications handling very large data sets.	bounding volume hierarchy;heuristic (computer science);parallel computing;ray tracing (graphics);real-time web;streaming media	Jirí Bittner;Michal Hapala;Vlastimil Havran	2015	Computers & Graphics	10.1016/j.cag.2014.12.001	ray tracing;computer science;theoretical computer science;operating system;algorithm;computer graphics (images)	Graphics	67.35451458908622	-51.7796359830446	180366
539d7910061fa1f647fabf2beaac9c7ed7be96a6	approximation of subdivision surfaces for interactive applications	high resolution;real time;subdivision surface;poisson disk;low resolution;visual quality;automatic generation;blue noise;sampling;interactive application;adaptive sampling;on the fly;real time application	Subdivision surfaces are undoubtedly the most flexible smooth geometric representation. By only manipulating a carefully designed low-resolution mesh, an high-resolution smooth version is automatically generated using a set of local recursive rules applied on each coarse polygon. However, while being intensively used in CAD and SFX industries, they have not yet gained a significant interest for interactive and real-time applications. In fact, their recursive definition imposes a non-trivial CPU overhead, difficult to hide in interactive applications. We propose a new efficient approximation of subdivision surfaces which offers a very close appearance compared to the true subdivision surface while being at least one order of magnitude faster than true subdivision rendering. Our technique uses enriched polygons, equipped with edge vertices, and replaces them on-the-fly with low degree polynomials for interpolating positions and normals. By systematically projecting the vertices of input mesh at their limit position on the subdivision surface, the visual quality of the approximation is good enough for imposing only a single subdivision step on the CPU, allowing real-time performances even for million polygons output. Additionally, the parametric nature of the approximation allows an efficient adaptive sampling for both adaptive rendering and displacement mapping.	adaptive sampling;approximation;central processing unit;computer-aided design;displacement mapping;image resolution;interpolation;normal (geometry);overhead (computing);performance;polynomial;principle of good enough;real-time clock;real-time locating system;recursion;recursive definition;sfx (software);sampling (signal processing);subdivision surface;vertex (geometry)	Tamy Boubekeur;Christophe Schlick	2007		10.1145/1278780.1278810	mathematical optimization;image resolution;computer science;mathematics;geometry;subdivision surface;statistics;computer graphics (images)	Graphics	67.53493188489507	-47.400670968426674	180409
c4282026966d18bb8dec003e276c81d75b4f52be	fitting superellipses	computer vision;error analysis;image representation;optimization;curve fitting	In the literature, methods for fitting superellipses to data tend to be computationally expensive due to the non-linear nature of the problem. This paper describes and tests several fitting techniques which provide different trade-offs between efficiency and accuracy. In addition, we describe various alternative error of fits (EOF) that can be applied by most superellipse fitting methods. keywords: curve, superellipse, fitting, error measure	analysis of algorithms;computation;curve fitting;end-of-file;fits;hidden surface determination;mathematical optimization;nonlinear system;time complexity	Paul L. Rosin	2000	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.865190	computer vision;econometrics;mathematical optimization;mathematics;statistics;curve fitting	Vision	62.621302064193635	-43.119048144856585	180501
89834382b6feb70639940b917df0678349639c25	high-frequency shadows for real-time rendering of trees	real time;soft shadow;high frequency;real time rendering	We present a fast and simple method for adding high-frequency shadows into the foliage of trees rendered in real-time. When leaves of a tree project shadows onto other leaves, determining the relationships between cast shadows and the corresponding occluders is a visually difficult task. We present a method based on this assumption to quickly determine shadows cast by leaves onto other leaves. To this end, we simulate the presence of these shadows rather than projecting them exactly. The characteristics of these simulated shadows (movement, parallax, size, softness, and color) evolve realistically when the lighting conditions change. Our method is fast and supports soft shadows.	real-time transcription	Kevin Boulanger;Kadi Bouatouch;Sumanta N. Pattanaik	2010	J. Graphics, GPU, & Game Tools	10.1080/2151237X.2010.10390648	computer vision;real-time computing;simulation;computer science;high frequency;real-time rendering;computer graphics (images)	Graphics	64.3109100460356	-50.56667182359861	180530
855732bb0e8bdc8a5a7ababba6c1c803e9a8a511	recovering 3d motion and structure from stereo and 2d token tracking cooperation	real data 3d motion recovering synthetic data structure recovering stereo 2d token tracking cooperation kinematics optical flow image motion stereo matches kinematic screw;image motion;image motion analysis;tracking equations retina kinematics image segmentation cameras image motion analysis fasteners artificial intelligence image resolution;image segmentation;image resolution;2d token tracking cooperation;kinematics;three dimensional;computer vision;3d motion recovering;real data;structure recovering;computerised picture processing computer vision;stereo matching;retina;stereo;computerised picture processing;artificial intelligence;fasteners;optical flow;three dimensional structure;synthetic data;stereo matches;cameras;tracking;kinematic screw	\\.e investigate the relat,ionships that exist bet\veen the threetliiiiciisional structure and kinematics of a line inoving rigidly i n h l ~ a c e a i i d the two-dimensional st,ructure and kineniat,ics (optical f l m v ) of it.6 image in one or t,wo can1era.s. \\.c rtiil)lisli t l ic frintlauiental cqiiatioiis t h a t rclatc it.s tliree(liiiiciihional motion to its observed image inotioii. IYe tlieii as\1111ic tha t stereo niatclies ha.ve been established Iiet.ween ima.ge scgii ici its aiitl show how tlie estimation of the optical flows i n the ~ \ v o iiiiages can be usctl to coinpute part. of the kincrrmtic screw of I I i v corrcspoildiiig 3D line. The equations are linear and provide ;i v c r y hiinplc \\-ay to estiii1at.e the full kinematic screlv. i f several l i i i r h 0 1 t lir same object arc avaihbc. Esperiniriital results using Yyiitlirtic a n d real data are presented.	kinematic chain	Nassir Navab;Rachid Deriche;Olivier D. Faugeras	1990		10.1109/ICCV.1990.139584	three-dimensional space;computer vision;kinematics;simulation;image resolution;computer science;inverse kinematics;optical flow;tracking;image segmentation;stereophonic sound;synthetic data;computer graphics (images)	Vision	54.26676716177401	-51.153680191974104	180710
6e51b572b59c0d02dc6b821958fa627974f15aad	efficient constellation-based map-merging for semantic slam		Data association in SLAM is fundamentally challenging, and handling ambiguity well is crucial to achieve robust operation in real-world environments. When ambiguous measurements arise, conservatism often mandates that the measurement is discarded or a new landmark is initialized rather than risking an incorrect association. To address the inevitable “duplicate” landmarks that arise, we present an efficient map-merging framework to detect duplicate constellations of landmarks, providing a high-confidence loop-closure mechanism specifically applicable to semantic SLAM. This approach uses an incrementally-computable approximation of landmark uncertainty that only depends on local information in the SLAM graph, avoiding expensive recovery of the full system covariance matrix. This enables a search based on geometric consistency (GC) (rather than full joint compatibility (JC)) that inexpensively reduces the search space to a handful of “best” hypotheses. Furthermore, we reformulate the commonly-used interpretation tree to allow for more efficient integration of clique-based pairwise compatibility, accelerating the branch-and-bound max-cardinality search. This produces a highly extensible framework that significantly accelerates the branch-and-bound max-cardinality search. Our method is demonstrated to match the performance of full JC methods at significantly-reduced computational cost, facilitating robust object-based loop-closure over large SLAM problems.		Kristoffer M. Frey;Ted J. Steiner;Jonathan P. How	2018	CoRR		control engineering;clique;engineering;merge (version control);conservatism;covariance matrix;ambiguity;extensibility;pattern recognition;artificial intelligence;pairwise comparison;graph	AI	54.78273429270844	-41.29989106865352	181309
a00345830ccc23d2655279c28059d7712889fc70	plane-based multi-view inpainting for image-based rendering in large scenes		Image-Based Rendering (IBR) allows high-fidelity free-viewpoint navigation using only a set of photographs and 3D reconstruction as input. It is often necessary or convenient to remove objects from the captured scenes, allowing a form of scene editing for IBR. This requires multi-view inpainting of the input images. Previous methods suffer from several major limitations: they lack true multi-view coherence, resulting in artifacts such as blur, they do not preserve perspective during inpainting, provide inaccurate depth completion and can only handle scenes with a few tens of images. Our approach addresses these limitations by introducing a new multi-view method that performs inpainting in intermediate, locally common planes. Use of these planes results in correct perspective and multi-view coherence of inpainting results. For efficient treatment of large scenes, we present a fast planar region extraction method operating on small image clusters. We adapt the resolution of inpainting to that required in each input image of the multi-view dataset, and carefully handle image resampling between the input images and rectified planes. We show results on large indoors and outdoors environments.	3d reconstruction;gaussian blur;image scaling;image-based modeling and rendering;inpainting;rendering (computer graphics)	Julien Philip;George Drettakis	2018		10.1145/3190834.3190846	artificial intelligence;inpainting;computer science;3d reconstruction;rendering (computer graphics);computer vision;image-based modeling and rendering;image scaling;coherence (physics);planar	Vision	59.25874488883987	-50.86199971736266	181406
06d4f6cd5917b5ace8fa507853ef9551cd1602e6	resolution independent real-time vector-embedded mesh for animation	rendering computer graphics image color analysis three dimensional displays real time systems image resolution memory management animation;antialiasing vector embedded resolution independent shading vector representations	High-resolution textures are determinant of not only high rendering quality in gaming and movie industries, but also of burdens in memory usage, data transmission bandwidth, and rendering efficiency. Therefore, it is desirable to shade 3D objects with vector images such as scalable vector graphics (SVG) for compactness and resolution independence. However, complicated geometry and high rendering cost limit the rendering effectiveness and efficiency of vector texturing techniques. In order to overcome these limitations, this paper proposes a real-time resolution-independent vector-embedded shading method for 3D animated objects. Our system first decomposes a vector image consisting of layered close coloring regions into unifying-coloring units for mesh retriangulation and 1D coloring texture construction, where coloring denotes color determination for a point based on an intermediate medium such as a raster/vector image, unifying denotes the usage of the same set of operations, and unifying coloring denotes coloring with the same-color computation operations. We then embed the coloring information and distances to enclosed unit boundaries in retriangulated vertices to minimize embedded information, localize vertex-embedded shading data, remove overdrawing inefficiency, and ensure fixed-length shading instructions for data compactness and avoidance of indirect memory accessing and complex programming structures when using other shading and texturing schemes. Furthermore, stroking is the process of laying down a fixed-width pen-centered element along connected curves, and our system also decomposes these curves into segments using their curve-mesh intersections and embeds their control vertices as well as their widths in the intersected triangles to avoid expensive distance computation. Overall, our algorithm enables high-quality real-time Graphics Processing Unit (GPU)-based coloring for real-time 3D animation rendering through our efficient SVG-embedded rendering pipeline while using a small amount of texture memory and transmission bandwidth.	algorithm;automatic vectorization;computation;computer animation;convex hull;design tool;diffusion curve;displacement mapping;embedded system;embedment;game engine;glossary of computer graphics;graph coloring;graphics pipeline;graphics processing unit;map;mathematical optimization;optimization mechanism;pixel;real-time clock;real-time transcription;resolution independence;sampling (signal processing);scalability;scalable vector graphics;shade 3d;shader;shading;spatial anti-aliasing;sprite (computer graphics);texture mapping;texture memory;vertex (geometry)	Chih-Yuan Yao;Kuang-Yi Chen;Hong-Nian Guo;Cheng-Chi Li;Yu-Chi Lai	2017	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2016.2555738	artificial intelligence;software rendering;computer science;3d rendering;computer vision;rasterisation;rendering (computer graphics);texture memory;alternate frame rendering;sub-pixel resolution;tiled rendering	Graphics	66.27116374480521	-50.807886479262905	181627
546d34ab0e88b35106f9053251435ac54dba1ad7	image-based model updating	prior information;image based modeling;optimization problem;camera motion;large scale;3d model;automatic detection;problem complexity;terrain modeling;geometric model;image sensor;image warping	This paper presents a novel image-based approach for updating the geometry of 3D models. The technique can cope with large-scale models, using a single imaging sensor to which an arbitrary motion is applied. Current approaches usually do not fully take advantage of strong prior information, often available in the form of an initial model. The approach is thus novel in that geometric anomalies are quickly detected, significantly reducing problem complexity. Hence, given a geometric model and known camera motion, the image warping can be calculated and intensity patterns can be predicted. If predictions do not match observations, the model is assumed to be incorrect. The updating is then cast as an optimization problem where differences between observations and predictions are minimized. The algorithm is tested against both synthetic and real imaging data to update a terrain model. Results show that the algorithm can automatically detect and correct geometrical problems of different types and sizes.	3d modeling;algorithm;autostereogram;geometric modeling;image sensor;image warping;mathematical optimization;optimization problem;real-time clock;synthetic intelligence	Philippe Simard;Frank P. Ferrie	2002		10.5244/C.16.17	image warping;optimization problem;computer vision;simulation;computer science;geometric modeling;machine learning;image sensor;motion field	Robotics	56.24703072116429	-50.91125418560856	181672
5c0bd0f5bab6ab4164a73be83fbac456096902d0	optical tracking velocimetry (otv): leveraging optical flow and trajectory-based filtering for surface streamflow observations				Flavia Tauro;Fabio Tosi;Stefano Mattoccia;Elena Toth;Rodolfo Piscopia;Salvatore Grimaldi	2018	Remote Sensing	10.3390/rs10122010		Mobile	60.85659742845087	-48.040058334275145	181890
2db2af51237197cf744351e705c664db1abb2cae	depicting stylized materials with vector shade trees	vector graphics;material depiction;shade trees;gradient mesh;artistic guidelines	Vector graphics represent images with compact, editable and scalable primitives. Skillful vector artists employ these primitives to produce vivid depictions of material appearance and lighting. However, such stylized imagery often requires building complex multi-layered combinations of colored fills and gradient meshes. We facilitate this task by introducing vector shade trees that bring to vector graphics the flexibility of modular shading representations as known in the 3D rendering community. In contrast to traditional shade trees that combine pixel and vertex shaders, our shade nodes encapsulate the creation and blending of vector primitives that vector artists routinely use. We propose a set of basic shade nodes that we design to respect the traditional guidelines on material depiction described in drawing books and tutorials. We integrate our representation as an Adobe Illustrator plug-in that allows even inexperienced users to take a line drawing, apply a few clicks and obtain a fully colored illustration. More experienced artists can easily refine the illustration, adding more details and visual features, while using all the vector drawing tools they are already familiar with. We demonstrate the power of our representation by quickly generating illustrations of complex objects and materials.	3d rendering;adobe illustrator;alpha compositing;book;experience;gradient descent;line drawing algorithm;pixel;plug-in (computing);scalability;shader;shading;vector graphics	Jorge Lopez-Moreno;Stefan Popov;Adrien Bousseau;Maneesh Agrawala;George Drettakis	2013	ACM Trans. Graph.	10.1145/2461912.2461972	computer vision;vector graphics;computer science;algorithm;computer graphics (images)	Graphics	65.4297269623972	-47.51577336281668	181987
f3668077ea6fe4f45d7f07a21a24d97264e06865	geometric modeling of multi-material printed objects		We introduce a set of tools for interactive modeling of multi-material objects. We use non-manifold surface meshes to define complex objects, which can have multiple connected solid regions of different materials. Our suite of tools can create and edit non-manifold surfaces, while maintaining a consistent labeling of distinct regions. We also introduce a technique for generating approximate material gradients, using a set of thin layers with varying material properties. We demonstrate our approaches by printing physical objects with a multi-material printer.	3d printing;approximation algorithm;geometric modeling;gradient;nobuyuki otsu;polygon mesh;print job;printer (computing);schmidt decomposition;solver;sound blaster 16	Tyson Brochu;Ryan Schmidt	2017		10.2312/egsh.20171011	3d computer graphics;computer vision;image-based modeling and rendering;computer graphics (images);geometric modeling;polygonal modeling;artificial intelligence;solid modeling;sketch-based modeling;computer science	Graphics	65.78717218072956	-47.48873152619524	182221
d4c82afd2fb0ea71b8ddfb599c4e66404093c146	a system for high-volume acquisition and matching of fresco fragments: reassembling theran wall paintings	fragment matching;large scale;wall paintings;3d scanning;secondary motion;character animation;frescoes;3d acquisition;musculoskeletal simulation	Although mature technologies exist for acquiring images, geometry, and normals of small objects, they remain cumbersome and time-consuming for non-experts to employ on a large scale. In an archaeological setting, a practical acquisition system for routine use on  every  artifact and fragment would open new possibilities for archiving, analysis, and dissemination. We present an inexpensive system for acquiring all three types of information, and associated metadata, for small objects such as fragments of wall paintings. The acquisition system requires minimal supervision, so that a single, non-expert user can scan at least 10 fragments per hour. To achieve this performance, we introduce new algorithms to robustly and automatically align range scans, register 2-D scans to 3-D geometry, and compute normals from 2-D scans. As an illustrative application, we present a novel 3-D matching algorithm that efficiently searches for matching fragments using the scanned geometry.		Benedict J. Brown;Corey Toler-Franklin;Diego F. Nehab;Michael Burns;David P. Dobkin;Andreas Vlachopoulos;Christos Doumas;Szymon Rusinkiewicz;Tim Weyrich	2008	ACM Trans. Graph.	10.1145/1360612.1360683	character animation;computer vision;computer graphics (images)	Graphics	59.98143540009693	-49.51322193750881	182508
6491d98eba17bd2dd3759a6ed1e5229ec5de659c	automated camera calibration for image-guided surgery using intensity-based registration	lens distortion;edge detection;distortion;feature extraction;lenses;algorithms;image guided intervention;camera calibration;augmented reality;video;calibration;cameras;image guided surgery	In this paper we present a novel approach for the calibration of video cameras in an augmented reality image-guided surgery system. Whereas most calibration algorithms rely on the extraction of features such as points or lines, our proposed calibration algorithm determines the intrinsic and extrinsic camera calibration parameters by maximising the similarity between the real view of a calibration object and the synthetic view of the same calibration object. Our new method offers a number of advantages over existing calibration techniques: First, our calibration algorithm does not require the identification of fiducials such as points or lines in the video images. As a result of this the algorithm does require any feature extraction such as a corner or edge detection. Instead the algorithm uses the image intensities directly. Second, the calibration algorithm is model-based, which means that different camera or lens distortion models can be easily integrated into the algorithm. We have applied the calibration algorithm for the calibration of a head-mounted augmented reality system for image-guided neurosurgery. Our results show that the proposed calibration algorithm can lead to improved accuracy compared to conventional feature-based calibration techniques.© (2002) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	camera resectioning	Daniel Rueckert;Calvin R. Maurer	2002		10.1117/12.466951	computer vision;camera auto-calibration;simulation;computer science;computer graphics (images)	Vision	54.65016899042491	-48.504807028153714	182614
7013cc05323b40fb9356e0255aaa219181167b97	flexible multi-camera network calibration for human gesture monitoring	human gesture monitoring;relative position;stereo image processing calibration cameras computer vision gesture recognition;multi camera networks;multicamera network calibration;red light;computer vision;calibration humans monitoring cameras application software computer vision bars conferences robot sensing systems information technology;motion capture;design and implementation;stereo image processing;weighted camera graph;camera calibration;camera network;weighted camera graph multicamera network calibration human gesture monitoring pair wise stereo;calibration;gesture recognition;3d reconstruction;cameras;3d reconstruction camera calibration multi camera networks bundle adjustment motion capture;bundle adjustment;pair wise stereo	This paper presents the design and implementation of a flexible and easy-to-use multi-camera acquisition setup for markerless human gesture monitoring in unconstrained environments. A robust 2-stage framework is proposed to achieve full calibration of a variable number of synchronized cameras separated by long baselines. In the first stage, the intrinsic parameters are computed for each camera independently. In the second stage, the cameras are registered based on their relative positioning by waving a red light emitting device to produce a set of feature points. Matches are regrouped by camera pair such that pair-wise stereo relations can be found for as many pairs as possible before being scaled to create a consistent weighted camera graph which is used to link all cameras. Experimental results demonstrate the accuracy of the calibration that is achieved and the suitability of the proposed approach for almost any multi-camera configurations. An application is presented for volumetric-reconstruction of human beings to validate the implementation.	camera resectioning;stereo camera	Silvain Bériault;Pierre Payeur;Gilles Comeau	2007	2007 International Workshop on Robotic and Sensors Environments	10.1109/ROSE.2007.4373980	computer vision;simulation;computer science;computer graphics (images)	Vision	56.91950240657204	-38.76078515636753	182741
7231009d9eda2c87d5edd42afaa1ef2d958ae059	a practical microcylinder appearance model for cloth rendering	cloth rendering;anisotropic brdf;appearance modeling;weaving pattern;microcylinders	This article introduces a practical shading model for cloth that can simulate both anisotropic highlights as well as the complex color shifts seen in cloth made of different colored threads. Our model is based on extensive Bidirectional Reflectance Distribution Function (BRDF) measurements of several cloth samples. We have also measured the scattering profile of several different individual cloth threads. Based on these measurements, we derived an empirical shading model capable of predicting the light scattering profile of a variety of threads. From individual threads, we synthesized a woven cloth model, which provides an intuitive description of the layout of the constituent threads as well as their tangent directions. Our model is physically plausible, accounting for shadowing and masking by the threads. We validate our model by comparing predicted and measured light scattering values and show how it can reproduce the appearance of many cloth and thread types, including silk, velvet, linen, and polyester. The model is robust, easy to use, and can simulate the appearance of complex highlights and color shifts that cannot be fully handled by existing models.	bidirectional reflectance distribution function;color;file shadowing;list of common shading algorithms;robustness (computer science);simulation;specular highlight	Iman Sadeghi;Oleg Bisker;Joachim De Deken;Henrik Wann Jensen	2013	ACM Trans. Graph.	10.1145/2451236.2451240	computer graphics (images)	Graphics	60.93689296971463	-51.745879900105805	183048
4953123712d22648524917b1e07cf74265905086	photometric stereo in a scattering medium	scattering backscatter cameras light sources surface reconstruction three dimensional displays media;fluorescence photometric stereo scattering medium	Photometric stereo is widely used for 3D reconstruction. However, its use in scattering media such as water, biological tissue and fog has been limited until now, because of forward scattered light from both the source and object, as well as light scattered back from the medium (backscatter). Here we make three contributions to address the key modes of light propagation, under the common single scattering assumption for dilute media. First, we show through extensive simulations that single-scattered light from a source can be approximated by a point light source with a single direction. This alleviates the need to handle light source blur explicitly. Next, we model the blur due to scattering of light from the object. We measure the object point-spread function and introduce a simple deconvolution method. Finally, we show how imaging fluorescence emission where available, eliminates the backscatter component and increases the signal-to-noise ratio. Experimental results in a water tank, with different concentrations of scattering media added, show that deconvolution produces higher-quality 3D reconstructions than previous techniques, and that when combined with fluorescence, can produce results similar to that in clear water even for highly turbid media.	3d reconstruction from multiple images;approximation algorithm;backscatter (email);box blur;deconvolution;fluorescence imaging;gaussian blur;linear system;need to know;normal (geometry);object point;ptb-associated splicing factor;photometric stereo;photometry;signal-to-noise ratio;simulation;software propagation;turbidity measurement	Zak Murez;Tali Treibitz;Ravi Ramamoorthi;David J. Kriegman	2015	2015 IEEE International Conference on Computer Vision (ICCV)	10.1109/TPAMI.2016.2613862	photometric stereo;computer science	Vision	59.9040762349561	-51.78622090477322	183345
1cba555d81aea87b1bcd11eed689688ab0846327	stable position and pose estimation of industrial parts using evaluation of observability of 3d vector pairs	vector pair;bin picking;point cloud data;position and pose estimation		3d pose estimation	Shuichi Akizuki;Manabu Hashimoto	2015	JRM	10.20965/jrm.2015.p0174	computer vision;mathematical optimization;3d pose estimation;engineering;control theory	Robotics	54.725301755711406	-40.06134592318141	183378
0e9ee959e00ea5f93261e747f544886138942fa5	a non local multifocus image fusion scheme for dynamic scenes		In order to overcome the limited depth of field of usual photographic devices, a common approach is multi-focus image fusion (MFIF). From a stack of images acquired with different focus settings, these methods aim at fusing the content of the images of the stack to produce a final image that is sharp everywhere. Such methods can be very efficient, but when a global geometric alignment of images is out-of-reach, or when some objects are moving, the final image shows ghosts or other artefacts. In this paper, we propose a generic method to overcome these limitations. We first select a reference image, and then, for each image of the stack, reconstruct an image that shares the geometry of the reference and the sharpness content of the image at hand. The reconstruction is achieved thanks to a specially crafted modification of the PatchMatch algorithm, adapted to blurred images, and to a dedicated postprocessing for correcting reconstruction errors. Then, from the new image stack, MFIF is performed to produce a sharp result. We show the efficiency of the result on a database of challenging cases of hand-held shots containing moving objects.		Cristian Ocampo-Blandon;Yann Gousseau;Saïd Ladjal	2018	2018 25th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2018.8451819	iterative reconstruction;computer vision;robustness (computer science);depth of field;artificial intelligence;pattern recognition;image fusion;computer science	Vision	57.348577883590586	-50.80028814715313	183605
9f33b263bbfc453fabfc3bdb7b434f38d4586a44	extending the point distribution model using polar coordinates	polynomial regression;deformable objects;computational complexity;polar coordinate;optimization model;point distribution model	The Point Distribution Model (PDM) has already proved useful for many tasks involving the location or tracking of deformable objects. A principal limitation lies in the fact that non-linear variation must be approximated by a combination of linear variations, resulting in a non-optimal model which can produce implausible object shapes. The Polynomial Regression PDM improves on the PDM by allowing polynomial deformation. However, computational complexity is greatly increased, and the model still fails for objects in which bending or pivot- ing occurs. We propose an extension to the PDM which selectively uses polar coordinates at little computational cost, and give examples to show that models produced are both more compact and less likely to generate implausible shapes than either of the above methods. We also give an algorithm which automatically classifies model landmark points into the Cartesian or polar domain, based on training set analysis.	point distribution model	Tony Heap;David C. Hogg	1995		10.1007/3-540-60268-2_289	point distribution model;computer vision;mathematical optimization;polar coordinate system;spherical coordinate system;computer science;polynomial regression;mathematics;geometry;log-polar coordinates;computational complexity theory;statistics	Vision	62.605492434504946	-43.70826315727795	183686
413b883b7246716646988c29d1c8e72f62f0f2bd	image-based visual servoing with light field cameras	visual servoing feature extraction manipulators robot vision stereo image processing;field of view occlusions light field cameras light field image jacobians compact light field feature representation feature detection enhancement standard visual servoing control loop custom mirror based light field camera robotic arm stereo image monocular image field of view constraints;visual servoing computer vision for automation;cameras jacobian matrices visual servoing geometry feature extraction	This paper proposes the first derivation, implementation, and experimental validation of light field image-based visual servoing. Light field image Jacobians are derived based on a compact light field feature representation that is close to the form measured directly by light field cameras. We also enhance feature detection and correspondence by enforcing light field geometry constraints, and directly estimate the image Jacobian without knowledge of point depth. The proposed approach is implemented over a standard visual servoing control loop, and applied to a custom-mirror-based light field camera mounted on a robotic arm. Light field image-based visual servoing is then validated in both simulation and experiment. We show that the proposed method outperforms conventional monocular and stereo image-based visual servoing under field-of-view constraints and occlusions.	bottleneck (software);control system;feature detection (computer vision);feature detection (web development);jacobian matrix and determinant;light field;matlab;mathematical optimization;real-time clock;robot;robotic arm;simulation;specular highlight;visual servoing	Dorian Tsai;Donald G. Dansereau;Thierry Peynot;Peter I. Corke	2017	IEEE Robotics and Automation Letters	10.1109/LRA.2017.2654544	computer vision;optics;visual servoing;computer graphics (images)	Robotics	53.94120222676208	-42.421456664754245	183698
8e5a8ebd5b681f6c19043567da6868163d0870b6	generation of orthogonal grids on curvilinear trimmed regions in constant time	modelizacion;symbolic computation;grid generation;singularite;calcul formel;generation maille;langage java;interseccion;calculo formal;computer algebra system;calculo simbolico;grid;modelisation;rejilla;singularidad;grille;lenguaje java;intersection;mesh generation;computer algebra;modeling;calcul symbolique;java language;singularity	We propose a new algorithm for the generation of orthogonal grids on regions bounded by arbitrary number of polynomial inequalities. Instead of calculation of the grid nodes positions for a particular region, we perform all calculations for general polynomials given with indeterminate coefficients. The first advantage of this approach is that the calculations can be performed only once and then used to generate grids on arbitrary regions and of arbitrary mesh size with constant computational costs. The second advantage of our algorithm is the avoidance of singularities, which occur while using the existing algebraic grid generation methods and lead to the intersection of grid lines. All symbolic calculation can be performed with general purpose Computer Algebra Systems, and expressions obtained in this way can be translated in Java/C++ code.		Dmytro Chibisov;Victor G. Ganzha;Ernst W. Mayr;Evgenii V. Vorozhtsov	2005		10.1007/11555964_9	mesh generation;discrete mathematics;symbolic computation;theoretical computer science;mathematics;algorithm;algebra	Theory	67.54359192537282	-39.82140149411349	184060
829b4140b532cd61fc591a1a7920c0ebd6b851b9	3-d model building for computer vision	concepcion asistida;computer aided design;vision ordenador;fabricacion asistida por computador;modelo 3 dimensiones;modele 3 dimensions;cad;remplissage;three dimensional model;3 d models;filling;computer vision;surface filling;fabrication assistee;model building;computer aided manufacturing;estructura datos;cagd;conception assistee;superficie;b splines;surface;vision ordinateur;structure donnee;multiresolution 3 d data;b spline;data structure;relleno	This paper presents a Computer-Aided Geometric Design (CAGD) based approach for building 3-D models which can be used for the recognition of 3-D objects for industrial machine vision applications. The objects are designed using the Alpha_1 CAGD system developed at the University of Utah. A new method is given which uses the CAGD design and allows the points on the surface of the object to be sampled at the desired resolution, thus allowing the construction of multiresolution 3-D models. The resulting data structure of points includes coordinates of the points in 3-D space, surface normals and information about the neighboring points.	3d modeling;computer vision;computer-aided design;data structure;geometric design;machine vision;normal (geometry)	Bir Bhanu;Chih-Cheng Ho;Tom Henderson	1987	Pattern Recognition Letters	10.1016/0167-8655(87)90077-8	b-spline;computer vision;data structure;computer science	Robotics	66.18916833095378	-41.99784825168859	184062
3098269a588cc91faa861ddd62fa25c2aab3d99d	a flexible scene representation for 3d reconstruction using an rgb-d camera	image fusion;image sequences flexible scene representation 3d reconstruction rgb d camera truncated signed distance function tsdf volumetric model fusion algorithm kinectfusion flexible 3d scene representation;image colour analysis;image representation;image reconstruction;image sequences image colour analysis image fusion image reconstruction image representation;three dimensional displays cameras solid modeling image reconstruction image color analysis color accuracy;image sequences	Updating a global 3D model with live RGB-D measurements has proven to be successful for 3D reconstruction of indoor scenes. Recently, a Truncated Signed Distance Function (TSDF) volumetric model and a fusion algorithm have been introduced (KinectFusion), showing significant advantages such as computational speed and accuracy of the reconstructed scene. This algorithm, however, is expensive in memory when constructing and updating the global model. As a consequence, the method is not well scalable to large scenes. We propose a new flexible 3D scene representation using a set of planes that is cheap in memory use and, nevertheless, achieves accurate reconstruction of indoor scenes from RGB-D image sequences. Projecting the scene onto different planes reduces significantly the size of the scene representation and thus it allows us to generate a global textured 3D model with lower memory requirement while keeping accuracy and easiness to update with live RGB-D measurements. Experimental results demonstrate that our proposed flexible 3D scene representation achieves accurate reconstruction, while keeping the scalability for large indoor scenes.	3d modeling;3d reconstruction;algorithm;graphics processing unit;scalability;scale-invariant feature transform;volume mesh	Diego Thomas;Akihiro Sugimoto	2013	2013 IEEE International Conference on Computer Vision	10.1109/ICCV.2013.348	iterative reconstruction;computer vision;pattern recognition;mathematics;image fusion;computer graphics (images)	Vision	54.07047817939252	-47.05901072693928	184125
81f6a1101cc1a986ecd545678d7f9b21032e419e	automated yield estimation in viticulture by computer vision			computer vision	Scarlett Liu	2017				Vision	59.22242629755859	-42.91855776348082	184251
aa0ff8fd0c47f86ab70d9d49ff80b2ea6480c1b8	best approximate general ellipses on integer grids	elipsoide;curva;nombre entier;best approximation;robust algorithm;computer graphics;ellipse;courbe;elliptic function;maillage;curve;algorithme;algorithm;integer;celdarada;algorithme robuste;ellipsoide;entero;mejor aproximacion;grid pattern;funcion eliptica;ellipsoid;grafico computadora;infographie;fonction elliptique;algoritmo;meilleure approximation	The deenition of a best approximation for circles introduced by McIlroy 7] is generalized for general ellipses (i.e. ellipses not aligned with the coordinate axes) on integer grids. For any given ellipse this deenition yields a unique set of grid points, which is connected , thin, and does not contain sharp corners except at octant changes. The deenition is octant independent and solves the problems of ambiguity and octant changes. The best approximation of an elliptical arc is equal to the union of the best approximations of its subarcs. For circles it is equivalent to the deenition of McIlroy. An incremental and robust algorithm is given which eeciently computes the best approximation of general ellipses according to this deenition. Hardware implementations of this algorithm will be able to compete with all ellipse-rendering algorithms known so far.	approximation algorithm;robustness (computer science)	Dieter W. Fellner;Christoph Helmberg	1994	Computers & Graphics	10.1016/0097-8493(94)90088-4	integer;mathematical optimization;combinatorics;elliptic function;mathematics;ellipsoid;geometry;curve;computer graphics;algorithm;ellipse	Theory	68.10417831543471	-39.96248155942315	184330
5d0c160bc5f8728f0a7f9c8271eca2d24e765de6	piecewise-linear interpolation between polygonal slices	dynamic programming;piecewise linear;branching surfaces;surface fitting;geometric hashing;tiling;dynamic program;slice interpolation;surface reconstruction;medical image;minimum spanning tree;robust performance;cross section;triangulation;curve matching;polyhedra	In this paper we present a new technique for piecewise-linear surface reconstruction from a series of parallel polygonal cross-sections. This is an important problem in medical imaging, surface reconstruction from topographic data, and other applications. We reduce the problem, as in most previous works, to a series of problems of piecewise-linear interpolation between each pair of successive slices. Our algorithm uses a partial curve matching technique for matching parts of the contours, an optimal triangulation of 3-D polygons for resolving the unmatched parts, and a minimum spanning tree heuristic for interpolating between non simply connected regions. Unlike previous attempts at solving this problem, our algorithm seems to handle successfully any kind of data. It allows multiple contours in each slice, with any hierarchy of contour nesting, and avoids the introduction of counter-intuitive bridges between contours, proposed in some earlier papers to handle interpolation between multiply connected regions. Experimental results on various complex examples, involving actual medical imaging data, are presented, and show the good and robust performance of our algorithm.	algorithm;file spanning;heuristic;linear interpolation;medical imaging;minimum spanning tree;topography	Gill Barequet;Micha Sharir	1994		10.1145/177424.177562	mathematical optimization;combinatorics;surface reconstruction;piecewise linear function;triangulation;minimum spanning tree;dynamic programming;mathematics;cross section;geometry;polyhedron	Vision	67.97968967114832	-43.37141947863927	184656
2d25659a78b7bb7accfe9458df546b09a651198f	location m estimator with optimal edge detector for quality inspection of surface mount device capacitor	surface mount device;offline process;edge detection;average distance;chip;canny edge detector;quality inspection;mlcc;machine vision;location m estimation;robust regression;isef edge detector	Quality inspection of surface mount capacitor is an offline process and usually done by inspecting some capacitors in a lot using compound microscopes. We propose to use location M estimator with any edge detection methods to inspect the basic dimensions of multi-layer ceramic chip capacitors (MLCC) like width, length, separation distance between two end terminations and the local deviations on the termination boundaries. Usually the distances are calculated by an average distance. The average operator is not robust to outliers in the data. In this paper, we propose to use the combination of location M estimator with any type of edge detection technique which will remove the need of a specific optimal edge detection technique and thus can result into easy hardware realization to inspect the basic dimensions of MLCC.	edge detection;layer (electronics);online and offline;surface-mount technology	Jayesh D. Chauhan;Chintan K. Modi;Kunal J. Pithadiya	2010		10.1145/1741906.1742043	embedded system;computer vision;electronic engineering;engineering	Vision	60.13609849727265	-40.65031670909841	184720
2ab9c223d75d53f00f1b0233a67222d25efa60b5	silsketch: automated sketch-based editing of surface meshes	3d model;general terms sketch based modeling deformations laplacian surface editing differential geometry sketching;feature preservation;mesh deformation;categories and subject descriptors according to acm ccs i 3 5 computer graphics computational geometry and object modeling modeling packages;i 3 6 methodology and techniques interaction techniques	We introduce an over-sketching interface for feature-preserving surface mesh editing. The user sketches a stroke that is the suggested position of part of a silhouette of the displayed surface. The system then segments all image-space silhouettes of the projected surface, identifies among all silhouette segments the best matching part, derives vertices in the surface mesh corresponding to the silhouette part, selects a sub-region of the mesh to be modified, and feeds appropriately modified vertex positions together with the sub-mesh into a mesh deformation tool. The overall algorithm has been designed to enable interactive modification of the surface --- yielding a surface editing system that comes close to the experience of sketching 3D models on paper.	3d modeling;algorithm;norm (social);polygon mesh;sketch	Johannes Zimmermann;Andrew Nealen;Marc Alexa	2007		10.1145/1384429.1384438	computer vision;computer science;computer graphics (images)	Graphics	65.9185800852218	-46.59762736902363	184829
26c92a321f611cb7d9df6784820a8208f72e897a	3-d modeling of indoor scenes by fusion of noisy range and stereo data	polyhedral modeling;stereo data;3 d modeling;numeric fusion;fuses;planar faces;laser rangefinder;kalman filters;scene interpretation;computational geometry;reference frame;scene interpretation computer vision computational geometry sensor fusion noisy range data extended kalman filtering 3 d modeling indoor scenes stereo data laser rangefinder photometric data stereovision system planar faces polyhedral modeling numeric fusion mobile robot localization;random variables;layout;noisy range data;geometric feature;computer vision;three dimensional displays layout calibration fuses surface emitting lasers laser fusion laser modes photometry random variables kalman filters;laser fusion;polyhedral model;photometry;three dimensional displays;computer vision computational geometry;indoor scenes;random variable;mobile robot localization;extended kalman filtering;stereovision system;sensor fusion;surface emitting lasers;extended kalman filter;calibration;laser modes;photometric data	Geometric modeling of real 3-D scenes can be greatly helped by fusing of multiple and different sensor data. This paper presents a method that merges and fuses two kinds of 3-D data, a surface one obtained with a Laser range finder, and a photometric one produced by a Stereovision system. It gives a description of indoor scenes with a set of planar faces, a first step toward polyhedral modeling. Noisy geometrical features are represented by random variables whose variance is known. Extended Kalman Filtering techniques are used for numeric fusion of features into higher level ones (from points or pixels to 3-D lines, from 3-D lines to planes) and for identification of the transformation linking the sensors’ reference frames (calibration). This latter h u e receives particular atkntion, and a methodology is presented for iterative and automatic relative calibration. Experimental results show that this description is sufficiently accurate and reliable to feed higher level processes, such as mobile robot localization or scene interpretation.	3d modeling;geometric modeling;iterative method;kalman filter;mobile robot;pixel;polyhedron model;robotic mapping;stereopsis	Pierrick Grandjean;Arnaud Robert De Saint Vincent	1989		10.1109/ROBOT.1989.100063	random variable;computer vision;simulation;computational geometry;computer science;optics;statistics	Robotics	56.00140622877694	-48.660832922038225	184839
0adae31c9e8f62ff4d7348ab1a463bb29da79c6a	a user-editable c1-continuous 2.5d space deformation method for 3d models	deformation modeling;deformation editing;c1 continuity;biological modeling;space deformation;3d spline	Shape deformation methods are important in such fields as geometric modeling and computer animation. In biology, modeling of shape, growth, movement and pathologies of living microscopic organisms or cells require smooth deformations, which are essentially 2D with little change in depth. In this paper, we present a 2.5D space deformation method. The 3D model is modified by deforming an enclosing control grid of prisms. Spline interpolation is used to satisfy the smoothness requirement. We implemented this method in an editor which makes it possible to define and modify the deformation with the mouse in a user-friendly way. The experimental results show that the method is simple and effective.	2.5d;3d modeling	Elisa de Cássia Silva Rodrigues;Anamaria Gomide;Jorge Stolfi	2011	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2011.11.032	topology;mathematics;geometry	ECom	67.1136120275024	-46.43652787038114	184927
5fafd8b2606af8b5b15d3cb3d25e6ea00ef50329	continuous extrinsic online calibration for stereo cameras	stereo image processing automobiles calibration cameras image reconstruction image sensors kalman filters mobile robots motion measurement nonlinear filters robot vision;cameras calibration three dimensional displays robot vision systems vehicles feature extraction;vehicle motion sequences 3d reconstruction stereo images continuous online extrinsic parameter recalibration autonomous vehicle vehicle coordinate system 6 dof transformation camera sensors unscented kalman filter ukf extrinsic stereo camera calibration vehicle motion measurement inertial measurement unit imu stereo camera calibration state observability	Accurate stereo camera calibration is crucial for 3D reconstruction from stereo images. In this paper, we propose an algorithm for continuous online recalibration of all extrinsic parameters of a stereo camera, which is rigidly mounted on an autonomous vehicle. The algorithm estimates the six degrees-of-freedom (6-DoF) of the transformation from the vehicle coordinate system to the coordinate system of the stereo camera and at the same time the relative 6-DoF transformation between the two camera sensors. Salient points in the environment that are observed by both cameras are tracked over time in 3D space. An Unscented Kalman Filter (UKF) is applied to recursively estimate the extrinsic stereo camera calibration and the 3D position of all observed points. The projections of the points and the measured vehicle motion, which is estimated using an inertial measurement unit (IMU), are given as input. The observability of the stereo camera calibration states is analyzed to identify critical vehicle motion sequences. Results with real world data show that the algorithm is capable of continuously estimating the stereo camera calibrations in spite of large initial errors and varying extrinsic parameters.	3d reconstruction;algorithm;angularjs;apache axis;autonomous robot;camera resectioning;fisher information;kalman filter;pitch (music);recursion;sensor;six degrees of separation;stereo camera	Georg R. Mueller;Hans-Joachim Wünsche	2016	2016 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2016.7535505	computer stereo vision;stereo cameras;stereo camera;computer vision;camera auto-calibration;camera resectioning;simulation;geography;control theory;epipolar geometry	Robotics	53.91160916140072	-39.783923033777484	184976
2885f803e4222bf90354e93b97ca598786a652f8	canned lightsources		Complex luminaries and lamp geometries can greatly increas e the realism of synthetic images. Unfortunately, the correct rendering of illumination from complex lamps requires costly global illumination algorithms to simulate the indi rect illumination reflected or refracted by parts of the lamp. Currently, this sim ulation has to be repeated for every scene in which a lamp is to be used, and even for multiple instances of a lamp within a single scene. In this paper, we separate the global illumination simulati on of the interior lamp geometry from the actual scene rendering. The lightfield pro duced by a given lamp is computed using any of the known global illumination a lgorithms. Afterwards, a discretized version of this lightfield is stored away for later use as a lightsource. We describe how this data can be efficiently uti lized to illuminate a given scene using a number of different rendering algorithm s, such as ray-tracing and hardware-based rendering.	algorithm;canned response;data structure;database;discretization;global illumination;illumination (image);precomputation;ray tracing (graphics);rendering (computer graphics);simulation;synthetic intelligence	Wolfgang Heidrich;Jan Kautz;Philipp Slusallek;Hans-Peter Seidel	1998		10.1007/978-3-7091-6453-2_27		Graphics	64.7315596476045	-51.076428478080665	185080
244a765350392c9b6828a1079eb6ab93388154ee	a survey of spline-based volumetric data modeling framework and its applications		"""The strategic technical vision of this thesis proposal is to seek to systematically trailblaze a novel vol-umetric modeling framework/methdology to represent 3D solids. The rapid advances in 3D scanning and acquisition techniques have given rise to the explosive increase of volumetric digital models in recent years. The strong need to explore more efficient and robust 3D modeling techniques has become prominent. Although the traditional surface representation (e.g., triangle meshes) has many attractive properties, it is incapable of expressing the solid interior space and materials. Such a serious drawback overshadows many potential modeling and analysis applications. Consequently, volumetric modeling techniques become the well-known solution to this problem. Nevertheless, many unsolved research issues still remain outstanding when developing an efficient modeling paradigm for existing 3D models, including complex geometry (fine details and extreme concaveness), arbitrary topology, heterogenous materials, large-scale data storage and processing, etc. In this thesis proposal, we concentrate on the challenging research issue of developing a spline-based modeling framework, which aims to convert the conventional data (e.g., surface meshes) to tensor-product trivariate splines. This methodology can represent both boundary/volumetric geometry and real volumet-ric physical attributes in a compact and continuous matter. The regularly-defined tensor-product structure enables our newly-developed methods to be embedded into the CAD-design industry standards such as NURBS and B-splines seamlessly. These properties make our techniques highly preferable in many physically-based applications including mechanical analysis, shape deformation and editing, reverse engineering , hexahedral meshing, virtual surgery training, etc. Using tensor-product trivariate splines to reconstruct existing 3D objects is highly challenging, which always involves component-aware decomposition, volumetric parameterization, and trivariate spline approximation. This thesis proposal seeks accurate and efficient technical solutions to these fundamental and important problems, and demonstrates their efficiencies in modeling 3D objects of arbitrary topology. First, in order to achieve a """" from surface model to trivariate splines """" transformation, we define our new splines upon a novel parametric domain called generalized poly-cubes (GPCs), which comprise a set of regular cube-like domains topologically glued together. We then further improve our trivariate splines to support arbitrary topology by allowing the divide-and-conquer scheme, i.e., the user can decompose the model into components and represent them using trivariate spline volumetric patches. We design algorithms and prove valuable properties for our powerful merging strategy that can glue tensor-product spline solids together, while preserving many attractive modeling advantages. We also develop an effective method to reconstruct discrete volumetric datasets (e.g., volumetric …"""	3d modeling;3d scanner;algorithm;approximation;computer data storage;computer-aided design;data modeling;effective method;embedded system;hexahedron;image-based meshing;non-uniform rational b-spline;olap cube;polygon mesh;programming paradigm;reverse engineering;spline (mathematics);surgery simulator;triangle mesh;whole earth 'lectronic link	Bo Li	2013	CoRR		computer vision;simulation;computer science;computer graphics (images)	Graphics	66.64851166038574	-44.804375114891066	185154
4b566057569df5610522736abc9e3cf7e03a0faa	volumetric obscurance	shadows;gpu;interactive;ambient occulusion	Obscurance and Ambient Occlusion (AO) are popular techniques in both film and games that model how ambient light is shadowed. While it is largely a solved problem for static scenes, for dynamic scenes it is still difficult to compute at interactive rates. Recent attempts to compute AO in screen space for dynamic scenes either have poor performance or suffer from under-sampling problems. We formulate the problem as a 3D volumetric integral, which maps more naturally to graphics hardware. This integral can be solved using line samples to improve the under-sampling problems that plague other techniques. Following the idea of line integrals to its logical conclusion, we show results using area samples that use a simple statistical model of the depth buffer that allows us to use a single sample. We also discuss strategies for generating point, line, and area sample patterns along with ways to incorporate the surface normal into the volume obscurance calculation.	ambient occlusion;capacitor plague;glossary of computer graphics;graphics hardware;map;normal (geometry);sampling (signal processing);statistical model;volumetric display;z-buffering	Brad Loos;Peter-Pike J. Sloan	2010		10.1145/1730804.1730829	computer vision;shadow;simulation;computer science;artificial intelligence;mathematics;geometry;interactivity;computer graphics (images)	Graphics	64.90175676747688	-51.79233740585058	185257
6575c61855ccf3e8565c30c3e58607e4f1ccb88f	triangle-based view interpolation without depth-buffering	view interpolation;epipolar geometry;graphics hardware;linear time	In this paper, we propose a triangle-based view interpolati on algorithm which can correctly resolve the visibility problem without depth-buffering. The algor ithm is especially useful when depth information is not available, such as in the case of real-world photograp hs. By subdividing the reference image into variable-sized triangles, view interpolation can be done e ffici ntly using existing graphics hardware. We derive the drawing order between each pair of neighboring tr angles from the epipolar geometry. Using this drawing order, a graph can be built and topological sorting i s applied on the graph to obtain the complete drawing order of all triangles in linear time.	algorithm;chi;computer science;epipolar geometry;execution unit;geo warping;graph (discrete mathematics);graphics hardware;image warping;interpolation;pixel;time complexity;topological sorting;visibility (geometry);z-buffering	Chi-Wing Fu;Tien-Tsin Wong;Pheng-Ann Heng	1998	J. Graphics, GPU, & Game Tools	10.1080/10867651.1998.10487495	time complexity;computer vision;combinatorics;computer science;stairstep interpolation;mathematics;geometry;nearest-neighbor interpolation;graphics hardware;epipolar geometry;computer graphics (images)	Graphics	66.66327471627814	-49.247807229275715	185286
504661ed16c472e583fddf987070e451c4195d0d	collection of visual data in climbing experiments for addressing the role of multi-modal exploration in motor learning efficiency		Understanding how skilled performance in human endeavor is acquired through practice has benefited markedly from technologies that can track movements of the limb, body and eyes with reference to the environment. A significant challenge within this context is to develop time efficient methods for observing multiple levels of motor system activity throughout practice. Whilst, activity can be recorded using video based systems, crossing multiple levels of analysis is a substantive problematic within the computer vision and human movement domains. The goal of this work is to develop a registration system to collect movement activity in an environment typical to those that individuals normally seek to participate (sports and physical activities). Detailed are the registration system and procedure to collect data necessary for studying skill acquisition processes during difficult indoor climbing tasks, practiced by skilled climbers. Of particular interest are the problems addressed in trajectory reconstruction when faced with limitations of the registration process and equipment in such unconstrained setups. These include: abrupt movements that violate the common assumption of the smoothness of the camera trajectory; significant motion blur and rolling shutter effects; highly repetitive environment consisting of many similar objects.	computer vision;gaussian blur;hill climbing;modal logic;movie projector;programming paradigm;simultaneous localization and mapping;tactile imaging;visual odometry;while	Adam Schmidt;Dominic Orth;Ludovic Seifert	2016		10.1007/978-3-319-48680-2_59	computer vision;simulation;computer science;machine learning	ML	56.93425944536666	-43.213953326653616	185591
180630f47f61b4c6029a46ee1a60dc7d69be0c27	review of 3d object representation techniques for automatic object recognition	differential geometry;geometric model;computer vision;finite element;algebraic surfaces;object recognition	We present a critical review of the representation available for model-based object recognition. The choice of representation has a direct impact on the ability of the system to match objects, particularly in environments where noise or occlusion are presented. This review provides a set of criteria for object representation in recognition systems and this forms the basis upon which a qualitative critical review has been formulated. Initially well established techniques for object representation are reviewed. In particular object centered representations and viewer centered representations are addressed. The primary issue which afflicts these representations is the domain of objects which they can effectively represent. Free-form representations, which overcome this problem, are also examined. In particular, parametric representations including splines, implicit algebraic surfaces and finite element techniques, and geometric models which are based on differential geometry are considered. Ultimately, only representations, which possess an elegant blend of efficiency, accuracy and large representational domain are successful in providing a recognition system with the information required to achieve the level of scene understanding required in modern computer vision.	outline of object recognition	George J. Mamic;Mohammed Bennamoun	2000			computer vision;image processing;computer science;artificial intelligence;finite element method;mathematics;3d single-object recognition;algorithm	Vision	63.800043893405395	-44.22007395369229	185970
621845e04ba0ec63f7c518e7357ea848cfbf3e25	geometric continuity of parametric curves: three equivalent characterizations	spline shape control sufficient conditions design automation computer graphics application software equations;modelizacion;concepcion asistida;computer aided design;continuity;geometrie solide;computer graphics;computational geometry;geometria solidos;parametrization;continuite;parametrizacion;modelisation;espacio euclides;conception assistee;arc length parameterization geometric continuity parametric curves smoothness parametric continuity reparameterization equivalent parameterization beta constraints;curve fitting;espace euclide;modeling;grafico computadora;infographie;continuidad;solid geometry;parametric curve;parametrisation;curve fitting computational geometry;euclid space	Some of the important basic results on geometric continuity of curves are presented in a self-contained manner. The paper covers parametric representation and smoothness, parametric continuity, reparameterization and equivalent parameterization, beta-constraints, and arc-length parameterization.<<ETX>>	parametric polymorphism;scott continuity	Brian A. Barsky;Tony DeRose	1989	IEEE Computer Graphics and Applications	10.1109/38.41470	parametrization;mathematical optimization;combinatorics;geometric design;computational geometry;solid geometry;mathematics;geometry	Visualization	68.09998385716693	-40.677217670705026	186071
c61ed37a533f2ef9d20c19e362ed1de334e23d7e	shader space navigator: a turbo for an intuitive and effective shading process	shader;shading network;nearest neighbor search;rendering	In this paper, we first point out difficulties faced by CG artists in the shading process: (1) a lot of technical details on shaders required, (2) long rendering time, and (3) repeated cumbersome trial-and-errors. To make them overcome such difficulties, we propose Shader Space Navigator, a system that efficiently searches for shaders similar to a given query shader. With Shader Space Navigator, CG artists find quality shaders from the database that are very close to the final result shader, and thus complete the shading process easily by slightly tuning some attributes of those shaders. As a result, the CG artists can create their final shaders in an intuitive and efficient way thereby avoiding a large number of time-consuming rendering processes.	cg artist;shader;shading	Jae-Ho Lee;Min-Hee Jang;Du-Yeol Kim;Sang Wook Kim;Min-Ho Kim;Jin-Sung Choi	2009		10.1145/1529282.1529489	computer vision;multiple render targets;simulation;shader;rendering;computer science;unified shader model;nearest neighbor search;shading language;deferred shading;hlsl2glsl;computer graphics (images)	Graphics	66.65997948543288	-51.43338219799362	186258
969dec3106362f6f3a705dbfcd60fa091a94b6aa	a method for generating volumetric features from surface features	process planning	Form features may be represented both as surfaces and as volumes. Volumetric features are neeessary in automated process planning for relating a feature to the extent of material to be removed from a ~ and for capturing the global chamcteristics of a part, such as tool accessibility. In this paper, a method witl be presented for generating volumetric features from surface features, based on the technique of face extension. The implementation is currently limited to polyhedral parts. Examples will be given to illustrate the algorithm.	accessibility;algorithm;polyhedron	Xin Dong;Michael J. Wozny	1991		10.1145/112515.112542	computer vision;mathematics	Robotics	65.23635787496481	-44.2055965144347	186284
c3000c8a1139521dfeffefd8a4e3a180f771315f	multidimensional velocity filters for visual scene analysis in automotive driver assistance systems	velocity filter;collision avoidance systems;transfer function;signal processing;cost effectiveness;visual scene signal processing;scene analysis;driver assistance system;sampling theorem	Automotive scenery often contains objects that can be classified by object speed and movement direction. These features can be extracted from video data by linear n-D filters, which have already been analyzed in the past. While soundness of results was convincing, interest in those systems declined due to the reduced computational abilities of contemporary computers. Modern hardware allows realization of velocity filters, if the n-D system is carefully adapted to the analysis problem. The present paper analyzes the premises for application of velocity filters in the domain of automotive driver assistance systems, i.e. with respect to detectability of objects and implementability in a cost effective way. Especially the influence of the frame rate and the temporal violation of the sampling theorem are analyzed. Transfer functions for n-D filters working in a vision-based blind spot collision avoidance system are presented and discussed, and promising approaches for future application fields are proposed.		Jörg Velten;Sam Schauland;Anton Kummert	2008	Multidim. Syst. Sign. Process.	10.1007/s11045-008-0051-6	nyquist–shannon sampling theorem;computer vision;simulation;cost-effectiveness analysis;computer science;electrical engineering;machine learning;signal processing;control theory;transfer function;algorithm	Vision	57.777564776460736	-41.63285981849041	186381
c5f6149cb3e8900fb45d15c08fd64e64a765b1d1	parametrized recurrent systems for image generation	geometrie algorithmique;computer graphics;computational geometry;fractal geometry;geometrie fractale;sintesis imagen;image synthesis;image generation;fractal;synthese image;geometria computacional;grafico computadora;infographie;generation image	Abstract   We introduce Parametrized Recurrent Systems (PRS) as a tool for image generation. They are an extension of Mutually Recursive Function Systems allowing variable transformations (depending on parameters). A special case of PRS are MRFS with pasting, a very natural and convenient practical tool for image design. PRS cannot be step by step simulated by MRFS, however, we show that every PRS can be converted into an MRFS with the same number of transformations that generates the same image (attractor).		Karel Culik;Jarkko Kari	1993	Inf. Process. Lett.	10.1016/0020-0190(93)90167-8	fractal;computational geometry;pure mathematics;mathematics;geometry	DB	64.5413781183685	-45.01942081516957	186500
eb81068ce2c5705348af4e907ec4c57e4d4d483d	the application of parallel projections to three-dimensional object location in industrial assembly	three dimensional	Abstract   Flexible industrial assembly under visual control requires fast and simple picture processing. Parallel projection optics can help to achieve this because it provides constant size images, high immunity to ambient illumination and easy combination of the results from multiple cameras to determine the position of objects in 3-D space. This paper describes the optical system itself, a simple method of calibration, and the application of the system to a simple problem in 3-D assembly.		B. M. Jones;Peter Saraga	1981	Pattern Recognition	10.1016/0031-3203(81)90058-3	three-dimensional space;computer vision;simulation;computer science	Robotics	56.96394135500787	-47.536789927558	186858
5012c2b9fff18d9c4598bf6308420bad26bfb871	fast kd -tree construction for 3d-rendering algorithms like ray tracing	computer graphic;cost optimization;ray tracing;kd tree;datavetenskap datalogi;graphic processing unit;surface area heuristic;computer science;data structure;high speed;real time rendering	Many computer graphics rendering algorithms and techniques use ray tracing for generation of natural and photo-realistic images. The efficiency of the ray tracing algorithms depends, among other techniques, upon the data structures used in the background. kd-trees are some of the most commonly used data structures for accelerating ray tracing algorithms. Data structures using cost optimization techniques based upon Surface Area Heuristics (SAH) are generally considered to be best and of high quality. During the last decade, the trend has been moved from off-line rendering towards real time rendering with the introduction of high speed computers and dedicated Graphical Processing Units (GPUs). In this situation, SAH-optimized structures have been considered too slow to allow real-time rendering of complex scenes. Our goal is to demonstrate an accelerated approach in building SAH-based data structures to be used in real time rendering algorithms. The quality of SAH-based data structures heavily depends upon split-plane locations and the major bottleneck of SAH techniques is the time consumed to find those optimum split locations. We present a parabolic interpolation technique combined with a golden section search criteria for predicting kd-tree split plane locations. The resulted structure is 30% faster with 6% quality degradation as compared to a standard SAH approach for reasonably complex scenes with around 170k polygons.	algorithm;computer graphics;data structure;display resolution;elegant degradation;graphics processing unit;heuristic (computer science);interpolation;mathematical optimization;online and offline;parabolic antenna;ray tracing (graphics);real-time clock;rendering (computer graphics);web search engine	Sajid Hussain;Håkan Grahn	2007		10.1007/978-3-540-76856-2_67	ray tracing;computer vision;simulation;data structure;rendering;computer science;theoretical computer science;k-d tree;alternate frame rendering;computer graphics (images)	Graphics	67.14408011951367	-51.725730861058416	187003
cbe5f0a747e467ba39b703765ea924810033f2c5	multi-scale rendering of scratched materials using a structured sv-brdf model	surface microstructure;glints;anisotropic brdf;multi scale;normal distribution function;specular highlights;real time rendering;rendering	We introduce a Spatially-Varying BRDF model tailored to the multi-scale rendering of scratched materials such as metals, plastics or finished woods. Our approach takes advantage of the regular structure of scratch distributions to achieve high performance without compromising visual quality. We provide users with controls over the profile, micro-BRDF, density and orientation of scratches, while updating our material model at interactive rates. The BRDF for a single scratch is simulated using an optimized 2D ray-tracer and compactly stored in a three-component 2D texture. In contrast to existing models, our approach takes into account all interreflections inside a scratch, including Fresnel effects. At render time, the SV-BRDF for the scratch distribution under a pixel or ray footprint is obtained by linear combination of individual scratch BRDFs. We show how to evaluate it using both importance and light sampling, in direct and global illumination settings.	ambiguous name resolution;angularjs;archive;bidirectional reflectance distribution function;computation;global illumination;illumination (image);institute for creative technologies;map;prism (surveillance program);pixel;ray tracing (graphics);reflection (computer graphics);rendering (computer graphics);sampling (signal processing);science, industry and business library;simulation;systemverilog	Boris Raymond;Gaël Guennebaud;Pascal Barla	2016	ACM Trans. Graph.	10.1145/2897824.2925945	computer vision;rendering;computer science;optics;specular highlight;real-time rendering;computer graphics (images)	Graphics	61.973595899579344	-51.72186889980955	187333
4d1d20881147c701795ec90479b6a61e79ccbce4	volumetric mapping of genus zero objects via mass preservation		In this work, we present a technique to map any genus zero solid object onto a hexahedral decomposition of a solid cube. This problem appears in many applications ranging from finite element methods to visual tracking. From this, one can then hopefully utilize the proposed technique for shape analysis, registration, as well as other related computer graphics tasks. More importantly, given that we seek to establish a one-to-one correspondence of an input volume to that of a solid cube, our algorithm can naturally generate a quality hexahedral mesh as an output. In addition, we constrain the mapping itself to be volume preserving allowing for the possibility of further mesh simplification. We demonstrate our method both qualitatively and quantitatively on various 3D solid models.	3d modeling;algorithm;baseline (configuration management);computer graphics;computer vision;finite element method;hexahedron;level of detail;one-to-one (data model);resolution (logic);robustness (computer science);shape analysis (digital geometry);solid modeling;video tracking	Romeil Sandhu;Ayelet Dominitz;Yi Gao;Allen R. Tannenbaum	2012	CoRR		theoretical computer science;mathematics;geometry	Graphics	68.174527037529	-45.27669898942095	187469
cfe3a42025196c0a227a834458e6dd8ae3241f8f	on the one-parameter dual spherical motions	lie algebra;e study s map;coordonnee spherique;cercle;concepcion asistida;computer aided design;algebra lie;spherical coordinate;equation euler;groupe lie;coordenada esferica;cinematica;courbure;euler savary formula;algebre lie;kinematics;congruencia;sistema coordenadas;disteli s formulae;grupo lie;ligne geometrique;coordinate transformation;ecuacion euler;cinematique;circulo;axodes;conception assistee;curvatura;lie group;curvature;transformation of coordinates;systeme coordonnee;circle;changement coordonnee;congruence;line geometry;linea geometrica;coordinate system;cambio coordenadas;euler equation	Based on E. Studyu0027s dual line coordinates, explicit expressions were developed for the differential properties of one-parameter dual spherical motions that are coordinate systems independent. This eliminates the need of laborious coordinate transformations necessary in the determination of the canonical systems. With the proposed technique, the Disteli formulae of the axodes were derived and the connections between kinematic geometry of a line trajectory were researched. Meanwhile, a ruled analogy of the curvature circle of a curve in planar kinematics was extended into general spatial kinematics. Then a lot of efforts have been directed to establish dual versions of the Euler-Savary equations of a line trajectory resulting in two different expressions depending on the axodes. As a result, theoretical expressions for the direction of a line congruence were revealed. Finally, an example illustrating the application of the obtained formulae was introduced.	angularjs;apache axis;embedded system;frame language;invariant (computer science);landline;optic axis of a crystal	Rashad A. Abdel-Baky;Reem A. Al-Ghefari	2011	Computer Aided Geometric Design	10.1016/j.cagd.2010.09.007	lie algebra;topology;coordinate system;computer aided design;calculus;mathematics;geometry;algebra	Graphics	67.54927636680944	-38.55876874932265	187473
1350a9dc56279ff0a9c37b894f6155297ad8cd42	walkthrough in large environments using concatenated panoramas	image sampling;computers;virtual reality;usa councils;virtual reality image sampling;three dimensional displays;walkthrough systems panorama based virtual reality systems image sampling image transformations coefficients scheduling mechanism prototype concatenated panorama;concatenated codes layout rendering computer graphics image sampling virtual reality image generation hardware large scale systems videos space technology;correlation;rendering computer graphics;cameras	Recently panorama-based virtual reality systems have a key issue that is how to achieve continuous walkthrough between the two adjacent panoramas. In order to solve this issue, we firstly take images in the sampling points of the transition path, and then the coefficients of image transformations among these images are estimated directly from these images. Finally, the images in the non-sampling points are synthesized from those images in the sampling points using image transformation techniques. The architecture and Scheduling mechanism of the prototype concatenated panorama system are also described in this paper.	coefficient;cognitive walkthrough;concatenation;prototype;sampling (signal processing);virtual reality	Xianghua Ying;Kun Peng;Hongbin Zha	2009	2009 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2009.5420659	computer vision;computer science;virtual reality;multimedia;correlation;computer graphics (images)	Robotics	61.083150199496025	-49.71742047878296	187533
0ab3590ce22390683f659778369e0f6fb11db449	underwater 3d reconstruction based on physical models for refraction and underwater light propagation	computer vision;underwater light propagation;doctoral thesis;dissertation;doktorarbeit;refractive camera model;3d reconstruction	In recent years, underwater imaging has gained a lot of popularity partly due to the availability of off-the-shelf consumer cameras, but also due to a growing interest in the ocean floor by science and industry. Apart from capturing single images or sequences, the application of methods from the area of computer vision has gained interest as well. However, water affects image formation in two major ways. First, while traveling through the water, light is attenuated and scattered, depending on the light’s wavelength causing the typical strong green or blue hue in underwater images. Second, cameras used in underwater scenarios need to be confined in an underwater housing, viewing the scene through a flat or dome-shaped glass port. The inside of the housing is filled with air. Consequently, the light entering the housing needs to pass a water-glass interface, then a glass-air interface, thus is refracted twice, affecting underwater image formation geometrically. In classic Structure-from-Motion (SfM) approaches, the perspective camera model is usually assumed, however, it can be shown that it becomes invalid due to refraction in underwater scenarios. Therefore, this thesis proposes an adaptation of the SfM algorithm to underwater image formation with flat port underwater housings, i. e., introduces a method where refraction at the underwater housing is modeled explicitly. This includes a calibration approach, algorithms for relative and absolute pose estimation, an efficient, non-linear error function that is utilized in bundle adjustment, and a refractive plane sweep algorithm. Finally, if calibration data for an underwater light propagation model exists, the dense depth maps can be used to correct texture colors. Experiments with a perspective and the proposed refractive approach to 3D reconstruction revealed that the perspective approach does indeed suffer from a systematic model error depending on the distance between camera and glass and a possible tilt of the glass with respect to the image sensor. The proposed method shows no such systematic error and thus provides more accurate results for underwater image sequences.	3d reconstruction;autostereogram;bundle adjustment;color;computer vision;image formation;image sensor;map;nonlinear system;software propagation;structure from motion;sweep line algorithm	Anne Jordt	2014			computer vision;simulation;geography;optics	Vision	59.559512884010495	-51.881501944459686	187575
ebc0e497530d33d7e26d7771a25c6df9bcf7dccc	approximate thin plate spline mappings	approximation method;shape deformation;computer vision;large scale;radial basis function;matrix completion;machine learning;function approximation;approximate solution;coordinate transformation;synthetic data;thin plate spline;eigenvectors	The thin plate spline (TPS) is an e ective tool for modeling coordinate transformations that has been applied successfully in several computer vision applications. Unfortunately the solution requires the inversion of a p p matrix, where p is the number of points in the data set, thus making it impractical for large scale applications. As it turns out, a surprisingly good approximate solution is often possible using only a small subset of corresponding points. We begin by discussing the obvious approach of using the subsampled set to estimate a transformation that is then applied to all the points, and we show the drawbacks of this method. We then proceed to borrow a technique from the machine learning community for function approximation using radial basis functions (RBFs) and adapt it to the task at hand. Using this method, we demonstrate a signi cant improvement over the naive method. One drawback of this method, however, is that is does not allow for principal warp analysis, a technique for studying shape deformations introduced by Bookstein based on the eigenvectors of the p p bending energy matrix. To address this, we describe a third approximation method based on a classic matrix completion technique that allows for principal warp analysis as a by-product. By means of experiments on real and synthetic data, we demonstrate the pros and cons of these di erent approximations so as to allow the reader to make an informed decision suited to his or her application.	approximation algorithm;approximation error;computer vision;experiment;machine learning;radial (radio);radial basis function;synthetic data;thin plate spline	Gianluca Donato;Serge J. Belongie	2002		10.1007/3-540-47977-5_2	computer vision;mathematical optimization;radial basis function;combinatorics;function approximation;eigenvalues and eigenvectors;computer science;coordinate system;machine learning;mathematics;thin plate spline;statistics;synthetic data	Vision	62.92386414922915	-41.947349204810635	187617
5b106e9afce6a59fe0b5cf16beb3878570ee93d2	a fast algorithm for voxel-based deterministic simulation of x-ray imaging	x ray imaging;personal computer;perspective projection;07 05 tp;87 57 gg;fast algorithm;video recording;ray tracing;monte carlo;87 59 hp;minimum bounding rectangle;deterministic simulation;x rays	Deterministic method based on ray tracing technique is known as a powerful alternative to the Monte Carlo approach for virtual X-ray imaging. The algorithm speed is a critical issue in the perspective of simulating hundreds of images, notably to simulate tomographic acquisition or even more, to simulate X-ray radiographic video recordings. We present an algorithm for voxel-based deterministic simulation of X-ray imaging using voxel-driven forward and backward perspective projection operations and minimum bounding rectangles (MBRs). The algorithm is fast, easy to implement, and creates high-quality simulated radiographs. As a result, simulated radiographs can typically be obtained in split seconds with a simple personal computer.	algorithm;radiography;simulation;voxel	Ning Li;Hua-Xia Zhao;Sang-Hyun Cho;Jung-Gil Choi;Myoung-Hee Kim	2008	Computer Physics Communications	10.1016/j.cpc.2007.11.008	ray tracing;mathematical optimization;perspective;deterministic simulation;minimum bounding rectangle;computer science;theoretical computer science;mathematics;monte carlo method;computer graphics (images)	Theory	66.26565135014019	-51.83792302113438	187693
7afc2f9d35aedc575aca60c6cf52d2bfe75517a3	integrating visual cues for the reconstruction of visible surfaces	shape from shading;cognitive modeling with heuristics;three dimensional;computer vision;machine learning;learning strategy;visual cues;heuristics	"""As research in Computer Vision has progressed, it has been realized that the information available from a single """"shape-from"""" algorithm is not sufficient to solve the general vision problem. This paper describes an ongoing research project that integrates three """"shape-from"""" modules, namely: the shape-from-stereo, shape-from-shading, and shape-from-texture. Each of these visual sensing methodologies provides three-dimensional information for the surfaces in the scene."""	algorithm;computer vision;photometric stereo;shading	Ignatios Vakalis	1989		10.1145/75427.1030307	three-dimensional space;computer vision;simulation;photometric stereo;sensory cue;computer science;heuristics;machine learning	Vision	58.83098211024756	-43.376227870840815	187697
ce47ea6f6033c68ea16776e64aa652bb0c36f471	localized guided liquid simulations in bifrost		"""A guided liquid simulation [Nielsen and Bridson 2011] re-simulates a thin surface layer of an existing liquid simulation at higher resolution, or simulates just a thin layer near the surface of an animated input sequence produced e.g. by hand or by spectral wave methods. The movement of the simulated surface layer is guided by the underlying animation and this technique has been used to achieve high surface detail and art-directed water effects on several movies including """"Hobbit - The Desolation of Smaug"""" and """"Tintin - Secret of the Unicorn"""". Despite the successful application of guided simulations in production, the method as originally proposed requires a fair amount of manual setup time and can be computationally costly in scenarios where the area of focus (such as a moving ship) covers a large and non-regular area over time. In this talk we present an outline of a novel set of algorithms facilitating localized guided simulations, where the guided simulation takes place only within a - possibly animated - local region specified by the user. We have implemented our algorithms in Autodesk Maya's procedural Bifrost framework and integrated them with Bifrost's adaptive FLIP solver. We demonstrate with several examples the benefits of our approach in terms of computational efficiency and ease of use. Additionally our tool was utilized by Moving Picture Company (MPC) to create high resolution art-directed water simulations on Pirates of the Caribbean - Dead Men Tell No Tales."""	algorithm;autodesk maya;flip-flop (electronics);image resolution;simulation;solver;surface detail;tell-tale;the adventures of tintin:;usability	Michael Bang Nielsen;Konstantinos Stamatelos;Adrian Graham;Marcus Nordenstam;Robert Bridson	2017		10.1145/3084363.3085030	simulation;computer graphics (images);artificial intelligence;computer vision;animation;smaug;surface layer;computer science;flip;solver;fluid simulation	Graphics	63.862629003242276	-49.82590302517593	188007
71a8df254768be74a524d04fb758d501bd459144	deep shading buffers on commodity gpus	stochastic rasterization;computer graphics;pixel shading;conservative rasterization;decoupled sampling	Real-time rendering with true motion and defocus blur remains an elusive goal for application developers. In recent years, substantial progress has been made in the areas of rasterization, shading, and reconstruction for stochastic rendering. However, we have yet to see an efficient method for decoupled sampling that can be implemented on current or near-future graphics processors. In this paper, we propose one such algorithm that leverages the capability of modern GPUs to perform unordered memory accesses from within shaders. Our algorithm builds per-pixel primitive lists in canonical shading space. All shading then takes place in a single, non-multisampled forward rendering pass using conservative rasterization. This pass exploits the rasterization and shading hardware to perform shading very efficiently, and only samples that are visible in the final image are shaded. Last, the shading samples are gathered and filtered to create the final image. The input to our algorithm can be generated using a variety of methods, of which we show examples of interactive stochastic and interleaved rasterization, as well as ray tracing.	algorithm;central processing unit;gaussian blur;glossary of computer graphics;graphics processing unit;multisample anti-aliasing;pixel;rasterisation;ray tracing (graphics);real-time transcription;sampling (signal processing);shader;shading;stochastic process	Petrik Clarberg;Jacob Munkberg	2014	ACM Trans. Graph.	10.1145/2661229.2661245	rasterisation;computer vision;gouraud shading;computer hardware;computer science;computer graphics;deferred shading;computer graphics (images)	Graphics	65.75760918744386	-51.58716362316837	188316
108659484113016ceb55c608f8bfc1fb07bf724d	brdf and geometry capture from extended inhomogeneous samples using flash photography	digital camera;laser scanner;ease of use;surface geometry;photometric stereo;very high resolution	We present a technique which allows capture of 3D surface geometry and a useful class of BRDFs using extremely simple equipment. A standard digital camera with an attached flash serves as a portable capture device, which may be used to sample geometry to very high resolution, as well as supplying samples over a large portion of the 4D space on which the BRDF is defined. Importantly, it allows capture of extended samples which may have spatially varying (inhomogeneous) BRDF. We demonstrate the system by capturing the geometry of complex materials with varying albedo and BRDF. We show in-situ capture of materials such as a brick wall and a human hand. The limitations of the system are that samples should be roughly planar, and that the BRDF should have some diffuse component in order that a first approximation to the normals can be computed. However, given the simplicity and ease of use of the system (it takes a few minutes to carefully capture a hand), and the ability to capture extended surfaces without any range capture device such as a laser scanner we argue that it is a valuable addition to the range of real-world BRDF capture systems in the literature. We extend standard photometric stereo techniques by moving both the camera and the light source. By incorporating automatic parallax correction we allow the capture of surfaces which are quite far from planar.	bidirectional reflectance distribution function;digital camera;image resolution;order of approximation;parallax;photometric stereo;planar (computer graphics);usability	James A. Paterson;David Claus;Andrew W. Fitzgibbon	2005	Comput. Graph. Forum	10.1111/j.1467-8659.2005.00863.x	laser scanning;computer vision;photometric stereo;usability;computer science;computer graphics (images)	Graphics	60.40618894188478	-51.1787909832246	188475
00d181e20b857461022952561fc99f9ddf42bd41	recognition and reconstruction of buildings from multiple aerial images	model based approach;aerial image;aerial imagery;optical imaging;automatic detection;surface model;indexation;digital elevation map	We present a model-based approach to the automatic detection and reconstruction of buildings from aerial imagery. Buildings are first segmented from the scene in an optical image followed by a reconstruction process that makes use of a corresponding digital elevation map (DEM). Initially, each segmented DEM region likely to contain a building rooftop is indexed into a database of parameterized surface models that represent different building shape classes such as peaked, flat, or curved roofs. Given a set of indexed models, each is fit to the elevation data using a robust iterative procedure that determines the precise position and shape of the building rooftop. The indexed model that converges to the data with the lowest residual fit error is then added to the scene by extruding the fit rooftop surfaces to a local ground plane.The approach is based on the observation that a significant amount of rooftop variation can be modeled as the union of a small set of parameterized models and their combinations. By first recognizing the rooftop as one of the several potential rooftop shapes and fitting only these surfaces, the technique remains robust while still capable of reconstructing a wide variety of building types. In contrast to earlier approaches that presuppose a particular class of rooftops to be reconstructed (e.g., flat roofs), the algorithm is capable of reconstructing a variety of building types including peaked, flat, multi-level flat, and curved surfaces. The approach is evaluated on two datasets. Recognition rates for the different building rooftop classes and reconstruction accuracy are reported.	aerial photography	Christopher O. Jaynes;Edward M. Riseman;Allen R. Hanson	2003	Computer Vision and Image Understanding	10.1016/S1077-3142(03)00027-4	computer vision;optical imaging	Vision	58.03598734871686	-45.671033715818275	188482
5e72e3cb152ec70b082ebd6b80502576a5c89ff7	determining generative models of objects under varying illumination: shape and albedo from multiple images using svd and integrability	illumination models;generic model;singular value decomposition;iterative algorithm;photometric stereo;linear transformation;eigenvectors	We describe a method of learning generative models of objects from a set of images of the object under different, and unknown, illumination. Such a model allows us to approximate the objects' appearance under a range of lighting conditions. This work is closely related to photometric stereo with unknown light sources and, in particular, to the use of Singular Value Decomposition (SVD) to estimate shape and albedo from multiple images up to a linear transformation (Hayakawa, 1994). Firstly we analyze and extend the SVD approach to this problem. We demonstrate that it applies to objects for which the dominant imaging effects are Lambertian reflectance with a distant light source and a background ambient term. To determine that this is a reasonable approximation we calculate the eigenvectors of the SVD on a set of real objects, under varying lighting conditions, and demonstrate that the first few eigenvectors account for most of the data in agreement with our predictions. We then analyze the linear ambiguities in the SVD approach and demonstrate that previous methods proposed to resolve them (Hayakawa, 1994) are only valid under certain conditions. We discuss alternative possibilities and, in particular, demonstrate that knowledge of the object class is sufficient to resolve this problem. Secondly, we describe the use of surface consistency for putting constraints on the possible solutions. We prove that this constraint reduces the ambiguities to a subspace called the generalized bas relief ambiguity (GBR) which is inherent in the Lambertian reflectance function (and which can be shown to exist even if attached and cast shadows are present (Belhumeur et al., 1997)). We demonstrate the use of surface consistency to solve for the shape and albedo up to a GBR and describe, and implement, a variety of additional assumptions to resolve the GBR. Thirdly, we demonstrate an iterative algorithm that can detect and remove some attached shadows from the objects thereby increasing the accuracy of the reconstructed shape and albedo.	approximation algorithm;generative model;iterative method;lambertian reflectance;photometric stereo;singular value decomposition;subpixel rendering	Alan L. Yuille;Daniel Snow;Russell Epstein;Peter N. Belhumeur	1999	International Journal of Computer Vision	10.1023/A:1008180726317	computer vision;photometric stereo;eigenvalues and eigenvectors;mathematics;geometry;iterative method;linear map;singular value decomposition	Vision	55.95394205428671	-51.96788641872947	188511
881a38db55efa0183e91064c5e4bd190b714ef9d	benchmarking close-range structure from motion 3d reconstruction software under varying capturing conditions	photogrammetry;software comparison;benchmark;multi view 3d reconstruction;structure from motion	Structure from Motion 3D reconstruction has become widely used in recent years in a number of fields such as industrial surface inspection, archeology, cultural heritage preservation and geomapping. A number of software solutions have been released using variations of this technique. In this paper we analyse the state of the art of these software applications, by comparing the resultant 3D meshes qualitatively and quantitatively. We propose a number of testing scenarios using different lighting conditions, camera positions and image acquisition methods for the best in-depth analysis and discuss the results, the overall performance and the problems present in each software. We employ distance and roughness metrics for evaluating the final reconstruction results.	3d reconstruction;feature recognition;geotagging;ground truth;memento pattern;pipeline (computing);resultant;structure from motion;zephyr	Ivan Nikolov;Claus B. Madsen	2016		10.1007/978-3-319-48496-9_2	computer vision;simulation;computer science;computer graphics (images)	Vision	55.310670475250106	-46.98464654515209	188534
8727ad58d629ab5cf6df1b5ac0073ac470d77a6c	conservative z-prepass for frustum-traced irregular z-buffers		This paper presents a pipeline to accelerate frustum traced irregular z-buffers (IZBs). The IZB proposed by Wyman et al. is used to render accurate hard shadows for real-time applications such as video games, while it is expensive compared to shadow mapping. To improve the performance of hard shadows, we use a two-pass visibility test by integrating a conservative shadow map into the pipeline of the IZB. This paper also presents a more precise implementation of the conservative shadow map than the previous implementation. In our experiments for 4K screen resolution, the performance of the hard shadow computation is improved by more than double on average using the two-pass visibility test, though there is still room for optimization.	computation;display resolution;experiment;frustum;mathematical optimization;real-time locating system;shadow mapping;z-buffering	Yusuke Tokuyoshi;Tomohiro Mizokuchi	2018		10.1145/3230744.3230755	visibility;computer vision;still room;computer graphics (images);display resolution;shadow mapping;computation;artificial intelligence;frustum;shadow;computer science	EDA	66.43448980822522	-51.48748283832464	188644
b957343fdcee89022a0a7080c046691ff0edce27	automatic surface generation with a voxel-based skeleton defining topological constraints	automatic mesh generation;subdivision surfaces;sketch;control polyhedron;voxel;geometrical modeling;discrete geometry;multiresolution;topological skeleton	Shape design is often performed by starting from a basic surface and by refining it afterward by adding details. In order to construct this first approximation surface, we present in this article a method to generate a basic polyhedron from a volumic voxel-based skeleton. This approach preserves the topology described by the discrete skeleton in a 3D grid considering the 26-adjacency: if a cycle is sketched, then there is a hole in the resulting surface, and if a closed hull is designed, then the output has a cavity. We verify the same properties for connected components. This surrounding basic polyhedron is computed with simple geometrical rules, and it is a good starting point for 3D shape design from a discrete voxel skeleton. In order to add multiresolution features to our approach, we use this rough mesh as the control polyhedron of a subdivision surface, according to the Loop scheme dedicated to triangulated surfaces. We show that the resulting set of smooth refined meshes is well suited for further modifications in the frame of a 3D modeling software.	voxel	Jean-Luc Mari	2010	International Journal of Shape Modeling	10.1142/S021865431000133X	discrete geometry;topology;mathematics;geometry;topological skeleton;voxel;engineering drawing;subdivision surface	Vision	67.87761118007948	-42.557583847433435	188653
783694c19ee8af92465c9a472c11dd37de22d846	high-quality and memory-efficient volumetric integration of depth maps using plane priors		Volumetric integration method is widely used to fuse depth maps in dense 3D reconstruction systems. High memory footprint is one of its main disadvantages. We introduce a method to de-noise depth maps and save memory usage during volumetric integration of depth maps with the use of plane priors. We develop a new planar region detection method with the use of depth gradients and then de-noise the planar region of depth maps. During volumetric integration we allocate the voxels and integrate depth maps with the use of plane priors as well. Extensive experiments show that our method saves approximately 30% memory footprint and has higher reconstruction quality compared with some of the current state-of-the-art systems. These characteristics enable our method to be used for 3D scanning on mobile devices which have limited memory resources.		Yangdong Liu;Wei Gao;Zhanyi Hu	2018	2018 24th International Conference on Pattern Recognition (ICPR)	10.1109/ICPR.2018.8545525	3d reconstruction;computer vision;voxel;memory footprint;memory management;prior probability;high memory;simultaneous localization and mapping;artificial intelligence;planar;computer science	Vision	54.341070369363656	-46.841447642528045	188885
9171cfd2a5ca9436f92fed5f822f823c6bdaa6f6	handling cycles in conformational behaviour visualization	interpolation	A simulation of conformational behaviour of molecules produces series of rapidly changing shapes of a particular molecule. Animated visualization of the process requires continuous morphing from one shape into another. Recently we proposed a method applicable on acyclic structures, in this paper we focus on smooth interpolation between different shapes of cycles.	directed acyclic graph;interpolation;morphing;real-time computing;requirement;simulation;z-matrix (chemistry)	Aleš Křenek	2000			computer vision;computer graphics (images);visualization;artificial intelligence;computer science	Visualization	66.70638221516194	-47.357231453371135	189060
0f6ee83bb9329f68ae575894d6e550658116bb32	automatically mimicking unique hand-drawn pencil lines	non photorealistic rendering;pencil rendering;image processing;non photorealistic rendering npr;natural media simulation;user study;arm movement;line drawings;statistical analysis;mathematical model;dynamic optimization yielding voluntary arm movement trajectory;models;dynamic optimization	In applications such as architecture, early design sketches containing accurate line drawings often mislead the target audience [Schumann et al., 1996]. Approximate human-drawn sketches are typically accepted as a better way of demonstrating fundamental design concepts. To this end we have designed an algorithm that creates lines that perceptually resemble human-drawn lines. Our algorithm works directly with input point data and a physicallybased mathematical model of human arm movement. Our algorithm generates unique lines of arbitrary length given the end points of a line, without relying on a database of humandrawn lines. We found that an observational analysis obtained through various user studies of human lines made a bigger impact on the algorithm than a statistical analysis. Additional studies have shown that the algorithm produces lines that are perceptually indistinguishable from that of a hand-drawn straight pencil line. A further expansion to the system resulted in mimicked dashed lines.	algorithm;analysis of algorithms;computer-generated holography;display resolution;experiment;graphite;interactivity;mathematical model;principle of good enough;rectifier;texture synthesis;usability testing;victoria (3d figure)	Zainab AlMeraj;Brian Wyvill;Tobias Isenberg;Amy Ashurst Gooch;Richard Guy	2009	Computers & Graphics	10.1016/j.cag.2009.04.004	computer vision;simulation;image processing;computer science;artificial intelligence;mathematical model;mathematics;geometry;algorithm;statistics;computer graphics (images)	Graphics	63.98958481972599	-48.82109962335125	189185
354a04f2a4809dd12f7db0ff1d25c3d1cf2869af	simplifying massive contour maps	massive high-resolution dems;realistic assumption;practical algorithm;contour map;massive contour map	We present a simple, efficient and practical algorithm for constructing and subsequently simplifying contour maps from massive high-resolution DEMs, under some practically realistic assumptions on the DEM and contours.	algorithm;contour line;image resolution;map	Lars Arge;Lasse Deleuran;Thomas Mølhave;Morten Revsbæk;Jakob Truelsen	2012		10.1007/978-3-642-33090-2_10	computer vision;mathematics;geometry;algorithm	ML	65.8357351859718	-50.76981275610368	189338
3c43843e880a10dbabed53a102c31fdcd91e2fec	typeface styling with ramp responses	lut tables;linear filtering;color image processing	Linear filters are standard tools of the artist in image, video and audio processing. This work demonstrates that they can also be used for vector graphics, in particular for typeface design. Serifs and other features of a typeface can be created and edited; gross effects are possible, too. In the software prototype, the user can freely define the shapes that the └ type and the ┘ type of convex axis-aligned rectangular corners should have after filtering. Corners of the types ┐ and ┌ will have the corresponding shapes, rotated by 180° degrees. The two target shapes can be edited as cubic Bézier paths. The result on a given text in a selected typeface is computed as vector graphics and displayed at an interactive rate.	bézier curve;cubic function;optic axis of a crystal;prototype;ramp simulation software for modelling reliability, availability and maintainability;software prototyping;vector graphics	Jörn Loviscach	2012		10.1145/2342896.2342933	computer vision;computer science;artificial intelligence;machine learning;linear filter;mathematics;geometry;computer graphics (images)	Graphics	64.79726047048108	-45.49112996689509	189410
50c8c844f4dd857ac94a7cecff7e09b5d50b9c0a	on-the-fly scene acquisition with a handy multi-sensor system	sensor system;multiple sensors;pmd;depth data;normal distribution;normal distributions transform;prior knowledge;photonic mixer device;ndt;sift;3d environment;scale invariant feature transform;multi sensor systems;registration;on the fly;pipeline colour;spectral correspondences;scene acquisition	We present a scene acquisition system which allows for fast and simple acquisition of arbitrarily large 3D environments. We propose a small device which acquires and processes frames consisting of depth and color information at interactive rates. This allows the operator to control the acquisition process on the fly. However, no user input or prior knowledge of the scene are required. In each step of the processing pipeline color and depth data are used in combination in order to gain from different strengths of the sensors. A novel registration method is introduced that combines geometry and color information for enhanced robustness and precision. We evaluate the performance of the system and present results from acquisition in different environments.	handy board;on the fly;sensor	Benjamin Huhle;Philipp Jenke;Wolfgang Straßer	2008	IJISTA	10.1504/IJISTA.2008.021288	computer vision;simulation;computer science;scale-invariant feature transform;statistics	Graphics	57.05689318179595	-43.89295142636654	189467
8c8148e872fd46340ae9e3cac3378745ad8983c1	direct geometrical map to low-level grid map registration for robust online localization		In autonomous driving, robustness and precision can be increased through additional information sources in the form of prior maps. To benefit from these maps, precise localization is necessary. Localization enables the vehicle to drive along planned trajectories using map information like lane geometry and static environment information. State-of-the-art localization methods often use feature based maps or rely on dense appearance based maps for direct, association free matching. In this paper we combine both ideas. We solve the localization problem by matching dense measurement grids from LiDAR sensors directly against a geometrical, feature based map. Reflectivity and occupancy grids are obtained from multiple Li-DAR sensors. In order to avoid information reduction through feature extraction, the low-level grids are registered directly against a high-level geometrical map (Fig. 1). This new concept is solved using an exhaustive search in combination with a multi-level-resolution search. Real-time capable registration is achieved by exploiting the computational power of modern GPUs. To realize an online localizer, a Kalman Filter (KF) fuses the registration results with odometry information, obtained from serial production sensors. To ensure a fixed runtime, the registration resolution is adapted based on the state uncertainty. The robustness and accuracy of the developed methods is evaluated in extensive experiments. The localization proved to be accurate and robust against challenging situations like difficult maneuvers or missing localization features in the map. Thus, our new approach is well suited for autonomous driving applications.		Ulrich Berger;Stefan Orf;Maximilian Muffert;Johann Marius Zöllner	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8569784		Robotics	54.34387741705686	-40.93660723047445	189535
8f0e62f0c88e2283ab1bbfc813231807727ba1eb	using isophotes and shadows to interactively model normal and height fields	non photorealistic rendering;isophotes;sketching	We introduce an interactive modeling tool for designing (a) a smooth 3D normal field from the isophotes of a discretely shaded 2D image and (b) lifting the normal field into a smooth height field given a cast shadow. Block or cartoon shading is a visual style in which artists depict a smoothly shaded 3D object using a small number of discrete brightness values, manifested as regions or bands of constant color. In our approach, artists trace isophotes, or curves of constant brightness, along the boundaries between constant color bands. Our algorithm first estimates light directions and computes 3D normals along the object silhouette and at intersections between isophotes from different light sources. We then propagate these 3D normals smoothly along isophotes, and subsequently throughout the interior of the shape. We describe our user interface for editing isophotes and correcting unintended normals produced by our algorithm. We also describe a technique for lifting the generated normal field into a height field given the boundary of the shadow cast by the object. We validate our approach with a perceptual experiment and comparisons to ground truth data. Finally, we present a set of 3D renderings created using our interface.	3d computer graphics;algorithm;contour line;emoticon;ground truth;heightmap;interactivity;lifting scheme;shading;smoothing;user interface	Qiuying Xu;Songrun Liu;Yotam I. Gingold;Karan Singh	2016	Computers & Graphics	10.1016/j.cag.2016.02.004	computer vision;simulation;computer science;mathematics;non-photorealistic rendering;geometry;computer graphics (images)	Graphics	64.26638959395177	-48.716584937795105	189637
3a52433443f0bb2008ccddfa67b4b90d86526fa9	visualization of seifert surfaces	topology;physics based modeling;seifert surface;computational geometry;surface fitting;data visualisation;visualization shape strips books inspection topology;seifertview tool seifert surface visualization schematic surface images knot theory braid representation seifert algorithm closed oriented surfaces genus visualization;image representation;computational geometry data visualisation image representation surface fitting topology;knot theory;algorithms computer graphics computer simulation image enhancement image interpretation computer assisted imaging three dimensional information storage and retrieval models theoretical numerical analysis computer assisted reproducibility of results sensitivity and specificity user computer interface	The genus of a knot or link can be defined via Seifert surfaces. A Seifert surface of a knot or link is an oriented surface whose boundary coincides with that knot or link. Schematic images of these surfaces are shown in every text book on knot theory, but from these it is hard to understand their shape and structure. In this paper, the visualization of such surfaces is discussed. A method is presented to produce different styles of surface for knots and links, starting from the so-called braid representation. Application of Seifert's algorithm leads to depictions that show the structure of the knot and the surface, while successive relaxation via a physically based model gives shapes that are natural and resemble the familiar representations of knots. Also, we present how to generate closed oriented surfaces in which the knot is embedded, such that the knot subdivides the surface into two parts. These closed surfaces provide a direct visualization of the genus of a knot. All methods have been integrated in a freely available tool, called SeifertView, which can be used for educational and presentation purposes.	algorithm;braid;embedded system;embedding;genus (mathematics);imagery;knot (unit);linear programming relaxation;part dosing unit;schematic	Jarke J. van Wijk;Arjeh M. Cohen	2006	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2006.83	combinatorics;seifert surface;topology;computational geometry;knot theory;mathematics;geometry;data visualization	Visualization	66.71798529212867	-46.07915555939944	189663
574bd8837b1a60233120c5703f82f7fd9f0f32ea	toward a real-time tracking of dense point-sampled geometry	trees mathematics computer graphics geometry image matching image reconstruction image resolution object tracking real time systems;image resolution;computer graphics;image matching;geometry;trees mathematics;3d processing computer vision;octrees tracking shape vectors heuristic algorithms partitioning algorithms real time systems;image reconstruction;object tracking;real reconstructed data sets real time tracking dense point sampled geometry temporal deformations tracking arbitrary densely sampled point based surfaces intuitive resolution efficient resolution point matching problem space partition trees discrete space multiresolution concerns voxel adjacency relations distance function simulated reconstructed data sets point clouds tracking process;real time systems	In this paper, we address the problem of tracking temporal deformations between two arbitrary densely sampled point-based surfaces. We propose an intuitive and efficient resolution to the point matching problem within two frames of a sequence. The proposed method utilizes two distinct space partition trees, one for each point cloud, which both are defined on a unique discrete space. Our method takes advantage of multi-resolution concerns, voxel adjacency relations, and a specific distance function. Experimental results obtained from both simulated and real reconstructed data sets demonstrate that the proposed method can handle efficiently the tracking process even for very large point clouds. Moreover, our method is easy to implement and very fast, which provides possibilities for real-time tracking applications.	point cloud;real-time clock;voxel	François Destelle;Céline Roudet;Marc Neveu;Albert Dipanda	2012	2012 19th IEEE International Conference on Image Processing	10.1109/ICIP.2012.6466875	iterative reconstruction;computer vision;image resolution;computer science;theoretical computer science;video tracking;mathematics;geometry;computer graphics	Robotics	53.8984824759527	-47.55990577294451	189690
760bafc957cb488db2d4cfe09200ccf649d0ee86	occlusion-resistant camera design for acquiring active environments	image sampling;automatic;image segmentation;hidden feature removal;real time;light field;image segmentation cameras data acquisition hidden feature removal image sampling;x ray like vision;higher order;cameras layout image reconstruction computer vision motion estimation sensor arrays algorithm design and analysis motion segmentation stereo image processing image segmentation;image segmentation occlusion resistant camera design active environment acquisition device x ray like vision reflected ray image sampling;occlusion resistant camera design;background;reflected ray;light fields;theoretical analysis;acquisition device;acquisition;active environment;light fields acquisition dynamic occlusions automatic background;data acquisition;occlusions;dynamic;cameras;x rays	In this article, we present a detailed theoretical analysis and a prototype implementation of a family of cameras designed with the explicit goal of detecting and removing interfering dynamic occluders in real time, during live capture, as opposed to fixing the resulting artifacts a posteriori. Such an early-acquisition approach improves efficiency: more valid samples are acquired faster without worrying about moving occluders. One option for designing a camera to be unaffected by moving occluders is to sample through the occluder, but true x-ray-like vision is technically impractical. Another option is to sample around the occluder using a camera with a large effective aperture, but such an approach requires a bulky acquisition device. Yet another possibility of sampling around an occluder is to rely on second and higher order reflected rays that indirectly sample surfaces not directly visible. However, devising an acquisition device sufficiently sensitive and efficient to capture large environments using reflected rays will remain challenging for the foreseeable future.	diagnostic radiologic examination;morphologic artifacts;prototype;radiation;sampling (signal processing);sensor;yet another	Daniel G. Aliaga;Yi Xu;Voicu Popescu	2007	IEEE Computer Graphics and Applications	10.1109/MCG.2007.132	computer vision;higher-order logic;computer science;light field;image segmentation;data acquisition;automatic transmission;computer graphics (images)	Graphics	61.189684717695044	-50.19296792792107	189979
d3e7e06635bf2185c1d143a5b55f25fdfedbc246	distance to objects built with set operations in constructive solid modeling	constructive modeling;shape and solid modeling	We present in this paper methods to compute the signed Euclidean distance to surfaces obtained by the intersection (respectively union or difference) of two solids (in two or three dimensions). These implementations can replace min/max or R-functions traditionally used to model set operations used with implicit surfaces.	euclidean distance;implicit surface;maxima and minima;solid modeling	Pierre-Alain Fayolle;Alexander A. Pasko	2010			combinatorics;discrete mathematics;mathematics;geometry;constructive solid geometry	Vision	68.132451613466	-42.00088022901188	189996
2d8b4d267e8bd31dc3fe55e77357e8b7e0855982	auto-colorization of 3d models from images		Color is crucial to achieve more realism and better visual perception. However, majority of existing 3D model repositories are colorless. In this paper, we propose an automatic scheme for 3D model colorization taking advantage of large availability of realistic 2D images with similar appearance. Specifically, we establish a region-based correspondence between a given 3D model and its 2D image counterpart. Then we employ a PatchMatch based approach to synthesize the texture images. Subsequently, we quilt the texture seams via multi-view coverage. Finally, the texture coordinates are obtained by projecting back to the 3D model. Our method yields satisfactory results in most situations even when there exists an inconsistency between the 3D model and the corresponding image. Results obtained through a cross-over experiment validate the effectiveness and generality of our method.	3d modeling;color;patchmatch;polygonal modeling;quilt;texture mapping	Juncheng Liu;Zhouhui Lian;Jianguo Xiao	2017		10.1145/3145749.3149432	computer vision;artificial intelligence;generality;computer science;visual perception;texture synthesis	Vision	57.402368253062164	-51.329056104307384	190076
4f8fd05b8c4d96d02d63085b841db18fdda0b148	footstep navigation for dynamic crowds	oscillations;human movement;animation system;solid state drives;walkthrough scene editing;cache aware;collision detection;flash drives;side effect;cache coherent layouts;hard disk drives;walkthrough rendering;out of core applications;solid state devices;dynamic data layouts;cache oblivious	The majority of previous crowd 'steering algorithms model each character as an oriented particle that moves by choosing a force or velocity vector. In many cases, orientation is heuristically chosen to be the same as the particle's velocity. This approach has the two key disadvantages:  Limited locomotion constraints: Vector commands do not account for constraints of real human movement. Trajectories may have discontinuous velocities, oscillations, awkward orientations, or may try to move a character unnaturally, and these side-effects make it harder to animate the character intelligently. or example, a character moving forward cannot easily step to the right when its left foot is in the air (swing phase).  Limited navigation control: It is common to assume that an animation system will automatically know how to interpret a vector-based steering decision. However a vector does not have enough information to indicate appropriate subtle maneuvers, such as side-stepping versus reorienting the torso, stepping backwards versus turning around, stopping and starting, planting a foot to change momentum quickly, or carefully placing footsteps in exact locations. These details are critical to depicting a character's local steering intelligence, and thus it is appropriate for steering to have better control.	algorithm;heuristic;stepping level;velocity (software development)	Shawn Singh;Mubbasir Kapadia;Glenn Reinman;Petros Faloutsos	2011		10.1145/1944745.1944783	computer vision;cache-oblivious algorithm;real-time computing;simulation;computer science;solid-state;artificial intelligence;operating system;programming language;oscillation;collision detection;side effect;computer graphics (images)	AI	62.67821865718114	-45.2940319315095	190102
46441432161a9674636ac2a196f60a3a1f48cbf4	camera stability analysis and geo-referencing	reliability engineering;automatic testing;stability analysis digital cameras calibration reliability engineering character generation image reconstruction automatic testing feature extraction digital images optical design;digital cameras;feature extraction;image reconstruction;character generation;stability analysis;optical design;digital images;calibration	In photogrammetry, the fundamental objective is to generate reliable and accurate three-dimensional information from two-dimensional imagery. In order to generate such information, the internal metric characteristics of cameras that are implemented in photogrammetric applications have to be modeled and carefully estimated. These internal characteristics are customarily known as the Interior Orientation Parameters (IOP). Once the IOP are estimated, they should not significantly change over time and must be reliable. Hence, it would be beneficial to establish a meaningful procedure to analyze the stability of the IOP from a photogrammetric point of view. The paper will introduce three quantitative methods for testing camera stability, where the degree of similarity between reconstructed bundles from two sets of IOP is evaluated. Each of these three methods of stability analysis limits the position and orientation of the bundles in a different way. Hence, this paper will prove that each method will be applicable for a specific georeferencing technique depending on similar constraints imposed by the stability methods and different geo-referencing techniques. Keywords-photogrammetry, digital cameras, interior orientation parameters, camera stability, geo-referencing	bundle adjustment;digital camera;geo (microformat);global positioning system;horner's method;interoperability;photogrammetry;simulation;tree rearrangement;tuple space	Ayman F. Habib;Anoop M. Pullivelli	2005	Proceedings. 2005 IEEE International Geoscience and Remote Sensing Symposium, 2005. IGARSS '05.	10.1109/IGARSS.2005.1525325	iterative reconstruction;computer vision;von neumann stability analysis;calibration;image analysis;image resolution;feature extraction;computer science;pattern recognition;digital imaging;digital image;computer graphics (images)	Robotics	55.97872869906952	-47.764601080059464	190353
1e41fa65cca218d65dd6aa126f539d2854f54d33	a framework of view-dependent planar scene active camouflage	image formation	Active camouflage is a technique for occluding objects disappear from the observer. Current implementations make assumptions on the viewpoints of both the observer and the camouflaged target. In this work, we present a framework of view-dependent planar scene camouflage. The cameras representing the observer and the occluding object are placed in general positions. The images captured by the object camera are transformed to the observer viewpoint to generate globally consistent visual data for transparent camouflage. Experimental results are presented for real scene images using a projector-camera system.	augmented reality;video projector;virtual reality	Huei-Yung Lin;Wen-Nung Lie;Min-Liang Wang	2008	2008 Canadian Conference on Computer and Robot Vision	10.1002/ima.20176	computer vision;computer science;optics;image formation;computer graphics (images)	Vision	57.81900775570693	-50.84793518235883	190398
10547cc80d31c12737739971c316443fce53f9ac	single-view matching constraints	satisfiability;engineering and technology;teknik och teknologier	A single-view matching constraint is described which represents a necessary condition which 6 points in an image must satisfy if they are the images of 6 known 3D points under an arbitrary projective transformation. Similar to the well-known matching constrains for two or more view, represented by fundamental matrices or trifocal tensors, single-view matching constrains are represented by tensors and when multiplied with the homogeneous image coordinates the result vanishes when the condition is satisfied. More precisely, they are represented by 6-th order tensors on R which can be computed in a simple manner from the camera projection matrix and the 6 3D points. The single-view matching constraints can be used for finding correspondences between detected 2D feature points and known 3D points, e.g., on an object, which are observed from arbitrary views. Consequently, this type of constraint can be said to be a representation of 3D shape (in the form of a point set) which is invariant to projective transformations when projected onto a 2D image.	fundamental matrix (computer vision);trifocal tensor;whole earth 'lectronic link	Klas Nordberg	2007		10.1007/978-3-540-76856-2_39	discrete mathematics;topology;mathematics;geometry;satisfiability	Vision	54.005449062270415	-51.24284216489267	190490
1447f4c775a812f1808e97ab45be2dccf61bf328	ar deepcaloriecam v2: food calorie estimation with cnn and ar-based actual size estimation		In most of the cases, the estimated calories are just associated with the estimated food categories, or the relative size compared to the standard size of each food category which are usually provided by a user manually. In addition, in the case of calorie estimation based on the amount of meal, a user conventionally needs to register a size-known reference object in advance and to take a food photo with the registered reference object. In this demo, we propose a new approach for food calorie estimation with CNN and Augmented Reality (AR)-based actual size estimation. By using Apple ARKit framework, we can measure the actual size of the meal area by acquiring the coordinates on the real world as a three-dimensional vector, we implemented this demo app. As a result, it is possible to calculate the size more accurately than in the previous method by measuring the meal area directly, the calorie estimation accuracy has improved.	augmented reality;depth perception;technical standard	Ryosuke Tanno;Takumi Ege;Keiji Yanai	2018		10.1145/3281505.3281580	computer vision;calorie;deep learning;computer science;augmented reality;food energy;artificial intelligence	EDA	54.74894569162753	-45.867437302786435	190552
bca7132c725218249a575b480f1d016eca8546e5	rapid scene reconstruction on mobile phones from panoramic images	delaunay triangulation;computer model;image reconstruction three dimensional displays cameras mobile handsets solid modeling computational modeling feature extraction;three dimensional;scene reconstruction;mobile phone;computational modeling;3d model;three dimensional displays;feature extraction;image reconstruction;solid modeling;field of view;mobile handsets;panoramic image;augmented reality;3d reconstruction;cameras	Rapid 3D reconstruction of environments has become an active research topic due to the importance of 3D models in a huge number of applications, be it in Augmented Reality (AR), architecture or other commercial areas. In this paper we present a novel system that allows for the generation of a coarse 3D model of the environment within several seconds on mobile smartphones. By using a very fast and flexible algorithm a set of panoramic images is captured to form the basis of wide field-of-view images required for reliable and robust reconstruction. A cheap on-line space carving approach based on Delaunay triangulation is employed to obtain dense, polygonal, textured representations. The use of an intuitive method to capture these images, as well as the efficiency of the reconstruction approach allows for an application on recent mobile phone hardware, giving visually pleasing results almost instantly.	3d modeling;3d reconstruction;algorithm;augmented reality;delaunay triangulation;mobile phone;online and offline;smartphone	Qi Pan;Clemens Arth;Edward Rosten;Gerhard Reitmayr;Tom Drummond	2011	2011 10th IEEE International Symposium on Mixed and Augmented Reality	10.1109/ISMAR.2011.6092370	3d reconstruction;iterative reconstruction;three-dimensional space;computer vision;augmented reality;simulation;delaunay triangulation;field of view;feature extraction;computer science;solid modeling;computational model;computer graphics (images)	Vision	54.72266851025137	-46.73786195310886	190584
3890065d4a81eeba9e071dcf01eacae7f33660df	mesh segmentation driven by gaussian curvature	numerical stability;gaussian curvature;texture mapping;computer graphic;mesh segmentation;gauss map	Mesh parameterization is a fundamental problem in computer graphics as it allows for texture mapping and facilitates many mesh processing tasks. Although there exists a variety of good parameterization methods for meshes that are topologically equivalent to a disk, the segmentation into nicely parameterizable charts of higher genus meshes has been studied less. In this paper we propose a new segmentation method for the generation of charts that can be flattened efficiently. The integrated Gaussian curvature is used to measure the developability of a chart, and a robust and simple scheme is proposed to integrate the Gaussian curvature. The segmentation approach evenly distributes Gaussian curvature over the charts and automatically ensures a disklike topology of each chart. For numerical stability, we use an area on the Gauss map to represent Gaussian curvature. The resulting parameterization shows that charts generated in this way have less distortion compared to charts generated by other methods.	chart;computer graphics;distortion;genus (mathematics);genus–differentia definition;geometry processing;mesh parameterization;numerical stability;programming paradigm;region growing;texture mapping;thresholding (image processing)	Hitoshi Yamauchi;Stefan Gumhold;Rhaleb Zayer;Hans-Peter Seidel	2005	The Visual Computer	10.1007/s00371-005-0319-x	texture mapping;gaussian curvature;mathematical optimization;topology;computer science;mathematics;geometry;numerical stability;computer graphics (images)	Vision	67.99388412235733	-44.73417319276455	190642
