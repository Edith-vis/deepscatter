id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
05049b221aee56a196f0ee8aac61123cf67ed16d	cross-platform parallel debugging and performance analysis tools	developpement logiciel;distributed system;debugging;puesta a punto programa;systeme reparti;ordinateur parallele;estudio comparativo;reseau ordinateur;ingenieria logiciel;software engineering;parallel computation;analisis programa;debogage;computer network;etude comparative;programme utilitaire;calculo paralelo;sistema repartido;utility program;desarrollo logicial;analyse performance;software development;comparative study;performance analysis;ordenador paralelo;red ordenador;parallel computer;genie logiciel;program analysis;analyse programme;calcul parallele;programa utilitario;analisis eficacia	Versatile and easy-to-use parallel debuggers and performance analysis tools are crucial for the development of correct and efficient high performance applications. Although vendors of HPC platforms usually offer debugging and performance tools in some form, it is desirable to have the same interface across multiple platforms so that the user does not have to learn a different tool for each platform. Furthermore, a tool should have an easy-to-use interface that intuitively supports the debugging and performance analysis tasks the user needs to carry out, as well as the parallel programming language and paradigm being used. This paper describes a survey and evaluation of cross-platform debugging and performance analysis tools. In addition, we describe a current project which is developing a cross-platform API for accessing hardware performance counters. This paper necessarily represents a snapshot in time and as such will become out-of-date as new tools and new versions of existing tools are released. Current information and up-to-date evaluations of parallel debugging and performance analysis tools may be found at the Parallel Tools Library web site at http ://www. nhse. org/pt lib/.	debugging	Shirley Browne	1998		10.1007/BFb0056583	program analysis;computer science;software development;comparative research;algorithmic program debugging;programming language;background debug mode interface;debugging;algorithm	HPC	-27.018870499525487	41.23530425196784	42219
200c057ac0fcfe01b17d1f6683650a73cfb1dc23	distributed algorithms and causally consistent observations (abstract)	causally consistent observations;distributed algorithm	"""Observing an asynchronous distributed system which consists of processes that communicate solely by messages, is non-trivial { not only from a technical point of view (instrumentation, intrusiveness), but also because of inherent conceptual problems: Since event notiication messages sent to an observer are subject to unknown delays, it is generally not possible to observe all processes simultaneously. However, if we simply deny the existence of global time, does it then still make sense to consider global predicates (i.e., predicates of the global state) of a distributed system? This is a serious question since such predicates may reeect important properties of a distributed computation. Examples include deadlock, objects being garbage, and whether the number of mobile agents of a certain type circulating in a system is greater than a given threshold k. Fortunately, there exist several algorithmic means to guarantee that an observer gets at least a causally consistent view (i.e., a linearly ordered sequence of events with respect to the causality relation) of a distributed computation. These solutions can easily be generalized in such a way that not only a single observer, but each process within the system gets a causally consistent view of all events it learns about. A simple, although not very eecient solution consists in preventing direct or indirect message overtakings { either by generalizing the sequence number approach known from FIFO channel implementations, or by using a handshake communication scheme as in synchronous communications 4]. Such a realization of the so-called causal order message delivery property, however, does not solve all conceptual problems with global predicates: If two or more causally consistent observers monitor a single computation, they may or may not agree on the value of such a predicate { which, for example, makes the notion of global (or \distributed"""") breakpoints rather doubtful! Fortunately, there exist observer independent predicates (i.e., \objective facts""""), forming a non-trivial class 1]. The well-known stable predicates (i.e., the \monotone facts"""") are a subset of these predicates. Many (perhaps too many?) distributed algorithms to detect such stable predicates (i.e., to decide whether the predicate already holds) have been reported in the literature. A prominent example is termination detection 3], for which a surprising variety of algorithms with various characteristics have been published in recent years. A distributed computation is said to be terminated when all processes are passive and no message is in transit. However, since a passive process may be …"""	breakpoint;causal filter;causality;computation;deadlock;distributed algorithm;distributed computing;existential quantification;fifo (computing and electronics);mobile agent;whole earth 'lectronic link	Friedemann Mattern	1995		10.1007/3-540-60029-9_30	distributed algorithm;distributed computing;computer science	Logic	-22.90964299455578	43.584033640804186	42681
2ecde6ce84ef50a81f3a803879dee84aff003f18	communicating mobile processes	qa 76 software;data type;formal semantics;computer programming	07-Aug-2003 Copyright P.H.Welch 2 Introduction Motivation and Applications CSP and occam-π Mobility and location / neighbour awareness Simplicity, dynamics, performance and safety occam-π Processes, channels, (PAR) networks and (ALT) choice Mobile data types Mobile channel types Mobile process types Performance Some applications Operating and field-programmable embedded systems (RMoX) In-vivo In-silico modelling (UK ‘Grand Challenge’ 3) ‘Nannite’ assemblies (TUNA) Summary Communicating Mobile Processes	2.5d;concurrency (computer science);digital millennium copyright act;embedded system;field-programmability;grand challenges;jcsp;java;kroc;linux;mobile agent;occam-π;overhead (computing);scalability;video-in video-out	Peter H. Welch;Fred R. M. Barnes	2004		10.1007/11423348_10	parallel computing;data type;computer science;theoretical computer science;operating system;communicating sequential processes;formal semantics;computer programming;distributed computing;programming language;computer security;algorithm	SE	-28.95418687676409	35.73758113945461	42702
13d1befcf3a9042fd5c63cec15fce34128b1b089	locking and reference counting in the mach kernel	operating system;design rationale;reference counting	for a 16-bit uniprocessor. Under the weight of changing Abstract needs and technology, Unix has been modified to provide a staggering number of different mechanisms for managing obThe Mach operating system can be used as a system software kernel which can support a variety of operating jects and resources. In addition to pipes, Unix versions now system environments. Key elements of the Mach design support facilities such as System V streams, 4.2BSD sockets, which allow it to efficiently support system software include pty’s, various forms of semaphores, shared memory and a integrated virtual memory management and interprocess commind-boggling array of ioctl operations on special files and munication, multiple threads of control within one address devices. The result has been scores of additional system calls space, support for transparent system trap callout and an object programming facility integrated with the Mach IPC and options with less than uniform access to different mechanisms. Mach is currently available both from CMU resources within a single Unix system and within a network of and commercially on a wide range of uniprocessor and mulUnix machines. tiprocessor hardware. The Mach operating system kernel developed at Carnegie Mellon University [1] was designed to operate on both	16-bit;bsd;ioctl;kernel (operating system);mach;memory management;operating system;reference counting;semaphore (programming);shared memory;single unix specification;system call;thread (computing);uniprocessor system	David L. Black;Avadis Tevanian;David B. Golub;Michael W. Young	1991			kernel (linear algebra);reference counting;mach number;parallel computing;computer science	OS	-24.997784266278384	38.44790356980584	42990
4d1c73263453be09dede47c8e88b65720c32b505	a process algebraic framework for modeling resource demand and supply	resource partitioning;selected works;real time;real time embedded system;schedulability analysis;demand and supply;real time scheduling;bepress;process algebra	As real-time embedded systems become more complex, resource partitioning is increasingly used to guarantee real-time performance. Recently, several compositional frameworks of resource partitioning have been proposed using real-time scheduling theory with various notions of real-time tasks running under restricted resource supply environments. However, these approaches are limited in their expressiveness in that they are capable of describing resource-demand tasks, but not resource supplies. This paper describes a process algebraic framework for reasoning about resource demand and supply inspired by the timed process algebra ACSR. In ACSR, realtime tasks are specified by enunciating their consumption needs for resources. To also accommodate resource-supply processes we define PADS where, in addition to ACSR-like resource requests, we can specify availability of a resource in a given time step. Using PADS, we define a supply-demand relation where a pair (S; T) belongs to the relation if the demand process T can be scheduled under supply S. We develop a theory of compositional schedulability analysis as well as a technique for synthesizing an optimal supply process for a set of tasks. We illustrate our technique via a number of examples. Comments The 8th International Conference on Formal Modeling and Analysis of Timed Systems (FORMATS 2010), IST Austria, Klosterneuburg, Austria , 8-10 September, 2010. This conference paper is available at ScholarlyCommons: http://repository.upenn.edu/cis_papers/449 A Process Algebraic Framework for Modeling Resource Demand and Supply Anna Philippou, Insup Lee, Oleg Sokolsky, and Jin-Young Choi 1 Department of Computer Science, University of Cyprus, Nicosia, Cyprus 2 Department of Computer and Info. Science, University of Pennsylvania, Philadelphia, PA, U.S.A. 3 Department of Computer Science, Korea University, Seoul, Korea Abstract. As real-time embedded systems become more complex, resource partitioning is increasingly used to guarantee real-time performance. Recently, several compositional frameworks of resource partitioning have been proposed using real-time scheduling theory with various notions of real-time tasks running under restricted resource supply environments. However, these real-time schedulingbased approaches are limited in their expressiveness in that, although capable of describing resource-demand tasks, they are unable to model resource supply. This paper describes a process algebraic framework for reasoning about resource demand and supply inspired by the timed process algebra ACSR. In ACSR, realtime tasks are specified by enunciating their consumption needs for resources. To also accommodate resource-supply processes we define PADS where, given a resource CPU, the complimented resource CPU denotes for availability of CPU for the corresponding demand process. Using PADS, we define a supply-demand relation where a pair (S, T ) belongs to the relation if the demand process T can be scheduled under supply S. We develop a theory of compositional schedulability analysis as well as a technique for synthesizing an optimal supply process for a set of tasks. We illustrate our technique via a number of examples. As real-time embedded systems become more complex, resource partitioning is increasingly used to guarantee real-time performance. Recently, several compositional frameworks of resource partitioning have been proposed using real-time scheduling theory with various notions of real-time tasks running under restricted resource supply environments. However, these real-time schedulingbased approaches are limited in their expressiveness in that, although capable of describing resource-demand tasks, they are unable to model resource supply. This paper describes a process algebraic framework for reasoning about resource demand and supply inspired by the timed process algebra ACSR. In ACSR, realtime tasks are specified by enunciating their consumption needs for resources. To also accommodate resource-supply processes we define PADS where, given a resource CPU, the complimented resource CPU denotes for availability of CPU for the corresponding demand process. Using PADS, we define a supply-demand relation where a pair (S, T ) belongs to the relation if the demand process T can be scheduled under supply S. We develop a theory of compositional schedulability analysis as well as a technique for synthesizing an optimal supply process for a set of tasks. We illustrate our technique via a number of examples.	approximation algorithm;central processing unit;computer science;embedded system;linear algebra;process calculus;real-time clock;real-time computing;real-time locating system;scheduling (computing);scheduling analysis real-time systems;theory	Anna Philippou;Insup Lee;Oleg Sokolsky;Jin-Young Choi	2010		10.1007/978-3-642-15297-9_15	niche differentiation;process calculus;real-time computing;computer science;operating system;distributed computing;supply and demand;programming language	Embedded	-30.64329339432675	35.322340425393975	43440
29c4121623821dac1e2a22614273722c5bdc3ad4	job scheduling policy for high throughput grid computing	workload;calcul grille;systeme temps partage;haute performance;ordonnancement opportuniste;gestion labor;resource allocation;resource manager;resource management;distributed computing;time sharing;opportunistic scheduling;gestion recursos;gestion tâche;charge travail;alto rendimiento;gestion ressources;calculo repartido;sistema tiempo parcelado;asignacion recurso;time sharing system;task scheduling;allocation ressource;high throughput;carga trabajo;grid computing;high performance;job scheduling;calcul reparti;high throughput computing	The growing computational power requirements of grand challenge applications has promoted the need for merging high throughput computing and grid computing principles to harness computational resources distributed across multiple organisations. This paper identifies the issues in resource management and scheduling in the emerging high throughput grid computing context. We also survey and study the performance of several space-sharing and time-sharing opportunistic scheduling policies that have been developed for high throughput computing.	computational resource;crew scheduling;grand challenges;grid computing;high-throughput computing;job shop scheduling;requirement;scheduling (computing);seamless3d;throughput;time-sharing;virtual organization (grid computing)	Jemal H. Abawajy	2005		10.1007/11564621_21	high-throughput screening;real-time computing;resource allocation;computer science;resource management;job scheduler;operating system;distributed computing;utility computing;time-sharing;grid computing	HPC	-27.920230372220914	44.24541222101413	43445
5870a3196fe728b4d105e1617621eed14b43bf43	system for controlled testing of sensor networks	micaz hardware platform;software;sensor systems and applications;control systems;controlled testing;pins;sensor systems;software prototyping;application software;prototypes;control systems system testing sensor systems application software computer architecture wireless sensor networks sensor systems and applications software prototyping hardware operating systems;telecommunication computing;testing;tinyos operating system software;wireless sensor networks operating systems computers telecommunication computing testing;computer architecture;sensor nodes;system testing;pulse width modulation;operating systems computers;tinyos operating system software wireless sensor networks controlled testing sensor nodes micaz hardware platform;wireless sensor networks;operating systems;hardware	In this paper, we first identify the need for a system which can accurately reproduce sensed input or stimuli for fair evaluation of wireless sensor network applications. We then present an architecture for a system that utilizes sensor nodes to not only provide the required stimuli but also allow control over sensor nodes that are executing the application under test. In our architecture, each sensor node executing the application under test is paired with a stimuli generating node called the stimuli node. Our architecture, to the best of our knowledge, is the first to provide the benefits of both hardware-based and software-based approaches. We also showcase a prototype implementation of the architecture using the MICAz hardware platform and TinyOS operating system software. Evaluation results for the prototype in a network setting are then presented to demonstrate that this architecture is a viable stimuli system for testing wireless sensor networks applications.	algorithm;operating system;prototype;sensor node;system under test;tinyos	Anbu Elancheziyan;Jeffrey Wildman;Jaudelice Cavalcante de Oliveira;Steven Weber	2010	2010 44th Annual Conference on Information Sciences and Systems (CISS)	10.1109/CISS.2010.5464780	embedded system;application software;real-time computing;wireless sensor network;sensor node;computer science;control system;pulse-width modulation;prototype;software testing;key distribution in wireless sensor networks;system testing	Mobile	-33.06049375019963	39.89785282272427	43688
9adc61118629a8f96b9e05fc259ff5bf205113ad	architecture to support performance monitoring in object based distributed systems	distributed system;performance monitoring;software components performance monitoring object based distributed systems client server paradigm object based software design communication networks;software performance evaluation;computer networks quality of service object oriented programming software performance evaluation;object oriented programming;computer networks;resource use;current distribution;monitoring application software electrical capacitance tomography communication networks costs intelligent networks network servers software design communication system software programming;client server;community networks;software component;quality of service	Current distributed systems are based largely on the client server paradigm that has a relatively simple structure. Technological advances, particularly in object based software design and communication networks, has facilitated both the distribution and execution of software components. However this new environment poses a number of unique problems, such as charging for resources used, finding suitable components by name and by function and binding their network addresses so that it appears as if these components exist in the local machine. This paper presents a number of solutions to these problems. The solutions at this stage are clearly not definitive, but rather are proposed to stimulate further debate and research.	client–server model;component-based software engineering;distributed computing;object-based language;programming paradigm;server (computing);software design;telecommunications network	D. Ressmann;A. Platt;S. Rumsby	2001		10.1109/FTDCS.2001.969631	software distribution;connascence;verification and validation;computing;real-time computing;software sizing;computer science;microsoft transaction server;software design;software framework;component-based software engineering;software development;software design description;object-oriented design;middleware;software construction;software as a service;distributed computing;resource-oriented architecture;artificial intelligence systems integration;software deployment;software quality;software system;computer engineering	Networks	-33.6063959179085	44.73955708163388	43741
8e51878a5d84314409813346a49da6af69cf4b7a	emergence: a paradigm for robust and scalable distributed applications	emergence science;self-adjusting systems;distributed systems;communication strategy;non-deterministic behaviour;autonomic systems;emergence;election algorithm;fault tolerant computing;communication complexity;emergence advocates simple communication;natural system;fault tolerance;scalability;resulting algorithm;adaptive system;distributed computing;higher-level self-regulatory behaviour;simple rule-sets;self-stabilisation;distributed processing;low communication complexity;emergent election algorithm;distributed application;fault tolerant;computer science;communication model;robustness;application software;distributed system;low latency;algorithm design and analysis;satisfiability;non functional requirement;adaptive systems	Natural distributed systems are adaptive, scalable and fault-tolerant. Emergence science describes how higher-level self-regulatory behaviour arises in natural systems from many participants following simple rule-sets. Emergence advocates simple communication models, autonomy and independence, enhancing robustness and self-stabilization. High-quality distributed applications such as autonomic systems must satisfy the appropriate nonfunctional requirements which include scalability, efficiency, robustness, low-latency and stability. However the traditional design of distributed applications, especially in terms of the communication strategies employed, can introduce compromises between these characteristics. This paper discusses ways in which emergence science can be applied to distributed computing, avoiding some of the compromises associated with traditionally-designed applications. To demonstrate the effectiveness of this paradigm, an emergent election algorithm is described and its performance evaluated. The design incorporates nondeterministic behaviour. The resulting algorithm has very low communication complexity, and is simultaneously very stable, scalable and robust.	autonomic computing;autonomy;communication complexity;distributed computing;emergence;fault tolerance;non-functional requirement;nondeterministic algorithm;programming paradigm;robustness (computer science);scalability;self-stabilization	Richard John Anthony	2004	International Conference on Autonomic Computing, 2004. Proceedings.	10.1109/ICAC.2004.29	fault tolerance;real-time computing;computer science;theoretical computer science;adaptive system;operating system;machine learning;database;distributed computing;computer security;computer network	HPC	-24.99762393349423	44.694174753626314	43940
47164d6796341be3d53f2efb75e424fc23d1b380	supporting worker independence in collaboration transparency	groupware;real time;computer suppoted cooperative work;collaboration transparency;technical report departmental;historical collection till dec 2001;object oriented;group awareness;usability;cooperative work;java	Conventional collaboration-transparency systems, which provide real-time shared use of legacy single-user applications, are inefficient in their use of network resources and lack support for key groupware principles: concurrent work, relaxed WYSIWIS, and group awareness. We present an alternative implementation approach to collaboration transparency that provides many features previously seen only in collaboration-aware applications. Our approach is based on an object-oriented replicated architecture where selected single-user interface objects are dynamically replaced by multi-user extensions. The replacement occurs at run-time and is transparent to the single-user application and its developers. As an instance of this approach, we describe its incorporation into a new Java-based collaboration-transparency system for serializable, Swing-based Java applications, called Flexible JAMM (Java Applets Made Multiuser). We conducted an empirical study to evaluate the effectiveness of Flexible JAMM versus a representative conventional collaboration-transparency system, Microsoft NetMeeting. Completion times were significantly faster in a loosely-coupled task using Flexible JAMM, and were not adversely affected in a tightly-coupled task, which had been a concern. Accuracy was unaffected by the system used. Participants greatly preferred Flexible JAMM.	collaborative software;java applet;multi-user;open collaboration;real-time clock;serializability;swing (java);user interface;wysiwis	James Begole;Mary Beth Rosson;Clifford A. Shaffer	1998		10.1145/288392.288588	simulation;usability;human–computer interaction;computer science;knowledge management;operating system;programming language;object-oriented programming;java	HCI	-30.663363477003372	40.11314210358952	44053
4202894a1d83e6d384ad7c3524daf47759971817	refined quorum systems	byzantine failures;distributed algorithms;consensus;arbitrary failures;lower bounds;quorum systems;distributed storage;complexity;shared memory emulations;optimality results;quorums	It is considered good distributed computing practice to devise object implementations that tolerate contention, periods of asynchrony and a large number of failures, but perform fast if few failures occur, the system is synchronous and there is no contention. This paper initiates the first study of quorum systems that help design such implementations by encompassing, at the same time, optimal resilience, as well as optimal best-case complexity. We introduce the notion of a refined quorum system (RQS) of some set S as a set of three classes of subsets (quorums) of S: first class quorums are also second class quorums, themselves being also third class quorums. First class quorums have large intersections with all other quorums, second class quorums typically have smaller intersections with those of the third class, the latter simply correspond to traditional quorums. Intuitively, under uncontended and synchronous conditions, a distributed object implementation would expedite an operation if a quorum of the first class is accessed, then degrade gracefully depending on whether a quorum of the second or the third class is accessed. Our notion of refined quorum system is devised assuming a general adversary structure, and this basically allows algorithms relying on refined quorum systems to relax the assumption of independent process failures, often questioned in practice. We illustrate the power of refined quorums by introducing two new optimal Byzantine-resilient distributed object implementations: an atomic storage and a consensus algorithm. Both match previously established resilience and best-case complexity lower bounds, closing open gaps, as well as new complexity bounds we establish here. Each of our algorithms is representative of a different class of architectures, highlighting the generality of the refined quorum abstraction.	adversary (cryptography);asynchronous i/o;best, worst and average case;british undergraduate degree classification;chandra–toueg consensus algorithm;closing (morphology);distributed computing;distributed object;fault tolerance;first-class function;quorum (distributed computing)	Rachid Guerraoui;Marko Vukolic	2007		10.1145/1281100.1281120	distributed algorithm;complexity;real-time computing;consensus;distributed data store;computer science;theoretical computer science;distributed computing;byzantine fault tolerance;algorithm	Theory	-22.851411919494637	45.48053052656002	44210
5412468cac5613762699d107dd519da94541017c	safe programmable speculative parallelism	code calcul;parallelisme;recouvrement arriere;semantica operacional;rollback freedom;anticipacion;anticipation;compilateur;algorithmique;computation code;analyse statique;securite;semantica formal;operational semantics;recubrimiento atras;purity;value speculation;ejecucion programa;paralelisacion;formal semantics;program verification;satisfiability;compiler;program execution;analisis estatica;semantique formelle;verificacion programa;parallelism;codigo computacion;semantique operationnelle;paralelismo;speculation;algorithmics;algoritmica;execution programme;parallelisation;safety;speculative execution;parallelization;rollback recovery;static analysis;verification programme;seguridad;empirical evaluation;speculative parallelism;languages;especulacion;compilador	Execution order constraints imposed by dependences can serialize computation, preventing parallelization of code and algorithms. Speculating on the value(s) carried by dependences is one way to break such critical dependences. Value speculation has been used effectively at a low level, by compilers and hardware. In this paper, we focus on the use of speculation by programmers as an algorithmic paradigm to parallelize seemingly sequential code.  We propose two new language constructs, speculative composition and speculative iteration. These constructs enable programmers to declaratively express speculative parallelism in programs: to indicate when and how to speculate, increasing the parallelism in the program, without concerning themselves with mundane implementation details.  We present a core language with speculation constructs and mutable state and present a formal operational semantics for the language. We use the semantics to define the notion of a correct speculative execution as one that is equivalent to a non-speculative execution. In general, speculation requires a runtime mechanism to undo the effects of speculative computation in the case of mis predictions. We describe a set of conditions under which such rollback can be avoided. We present a static analysis that checks if a given program satisfies these conditions. This allows us to implement speculation efficiently, without the overhead required for rollbacks.  We have implemented the speculation constructs as a C# library, along with the static checker for safety. We present an empirical evaluation of the efficacy of this approach to parallelization.	algorithm;algorithmic paradigm;compiler;computation;computer hardware;immutable object;iteration;operational semantics;overhead (computing);parallel computing;piaget's theory of cognitive development;programmer;programming paradigm;rollback (data management);serialization;speculative execution;static program analysis;undo	Prakash Prabhu;G. Ramalingam;Kapil Vaswani	2010		10.1145/1806596.1806603	compiler;speculation;parallel computing;real-time computing;computer science;formal semantics;anticipation;programming language;operational semantics;algorithmics;static analysis;speculative multithreading;satisfiability;speculative execution	PL	-19.63516992142548	33.2444765808352	44216
160d3e46c8b9d2d725b15b87f29b7f07908c6d79	practically self-stabilizing paxos replicated state-machine		We present the first (practically) self-stabilizing replicated state machine for asynchronous message passing systems. The scheme is based on a variant of the Paxos algorithm and ensures that starting from an arbitrary configuration, the replicated state-machine eventually exhibits the desired behaviour for a long enough execution regarding all practical considerations.	algorithm;finite-state machine;message passing;paxos (computer science);self-stabilization	Peva Blanchard;Shlomi Dolev;Joffroy Beauquier;Sylvie Delaët	2014		10.1007/978-3-319-09581-3_8	paxos	OS	-22.407395834050153	43.89917331804319	44254
43c209c7cd05987b8c60d98ed0c16c4508555af4	pooss: a parallel object-oriented stable storage	parallelisme;pooss;prisma;gestion fichier;stockage donnee;file management;computer architecture;data storage;parallelism;paralelismo;architecture ordinateur;object oriented;manejo archivos;almacenamiento datos;oriente objet;arquitectura ordenador;orientado objeto	Abstract   This article describes the design and implementation of a parallel object-oriented stable storage (POOSS) system in the context of the PRISMA project.  The main issues of the POOSS system include atomic access of generic objects, fault tolerance, parallelism, and the issues in designing a fast disk file system. These issues are approached by constructing the POOSS system as a hierarchical one, with each layer attacking different issues, resulting in a system which is easier to understand, implement and maintain.  The multiple layers of the POOSS system are interfaced by a restricted set of UNIX compatible routines. By exposing the internal interfaces of different layers to external users, the POOSS system is able to provide the application programs with multiple services of a different nature: the normal local file service, the parallel global file service, the parallel stable file service, and the parallel object-oriented stable file service. Implemented in a 100-node parallel machine environment, the POOSS system could not only process multiple files simultaneously, but also be partitioned into multiple independent subsystems.  The performance measurement of the current implementation has shown good results for the system and also identified bottlenecks, candidates for further optimizations.	stable storage	Chengzheng Sun;Louis O. Hertzberger;Ben J. A. Hulshof;Rogier H. H. Wester	1991	Future Generation Comp. Syst.	10.1016/0167-739X(91)90003-G	self-certifying file system;embedded system;parallel computing;computer science;stub file;operating system;fstab;unix file types;computer data storage;database;distributed computing;open;programming language;object-oriented programming;file system fragmentation;computer security	Arch	-26.210294014627202	43.198897447604075	44316
1e2cfd1c95836aa15190bf24f69fa2dc400acec8	analysis and caching of dependencies	reference counting;dependence analysis;storage management;lambda calculus;garbage collection;tags	We address the problem of dependency analysis and caching in the context of the &lambda;-calculus. The dependencies of a &lambda;-term are (roughly) the parts of the &lambda;-term that contribute to the result of evaluating it. We introduce a mechanism for keeping track of dependencies, and discuss how to use these dependencies in caching.	cache (computing);dependence analysis;jones calculus;lambda calculus;ruth teitelbaum;strictness analysis	Martín Abadi;Butler W. Lampson;Jean-Jacques Lévy	1996		10.1145/232627.232638	reference counting;real-time computing;dependency theory;computer science;lambda calculus;database;garbage collection;programming language;world wide web;dependence analysis	NLP	-19.513446209940184	34.07801025286751	44539
4bf5b6d6658c6038f542f2c9d1f464f6ba572d7e	object-oriented representation, analysis, and scheduling of signal transition graphs	protocols;state assignment;signal transition graphs;asynchronous communication protocols;protocol specifications;cyclic graphs;design environment;scheduling validation;logic design;object-oriented foundation;graph theory;asynchronous circuits;high-level specifications;object-oriented methods	The authors present components of a design environment for specification and validation of asynchronous communication protocols. As novel contributions they propose an object-oriented foundation of the design environment and efficient algorithms for the signal transition graphs used as high-level specifications of communication protocols. These algorithms validate important properties of cyclic graphs as required to synthesize correctly logic circuits from protocol specifications. Results are presented for initial marking and scheduling validation of protocol specifications	scheduling (computing);signal transition	Uwe F. Baake;Sorin A. Huss	1993			communications protocol;logic synthesis;real-time computing;design methods;logic gate;computer science;graph theory;theoretical computer science;asynchronous communication;signal processing;distributed computing;object-oriented programming;petri net	Theory	-33.171846838342034	32.618321871989025	45066
23104e76757ceef5cc7f51256a787f267d855b5b	record-replay debugging for concurrent scoop programs	cluster computing;object oriented programming;memory access;concurrent programs	We report on the implementation of a record-replay tool for programs written in SCOOP, an object-oriented programming model for concurrency. The tool enables developers to reproduce the nondeterministic execution of a concurrent program, a necessary prerequisite for debugging and testing. The implementation is based on Choi and Srinivasan’s approach of using logical thread schedules, which represent classes of physical schedules that are equivalent with respect to memory accesses.	central processing unit;concurrency (computer science);concurrent computing;deadlock;debugging;lock (computer science);programming model;runtime system;scoop;schedule (computer science);scheduling (computing)	Benjamin Morandi;Sebastian Nanz;Bertrand Meyer	2011	CoRR		parallel computing;real-time computing;computer science;programming language;concurrent object-oriented programming	SE	-24.58907775885669	35.539934768386495	45116
a750235d200b53e04003d82330a92b27eb3cda52	a layered approach to polygon processing for safety-critical embedded systems		Embedded systems have become ubiquitous in everyday life, and especially in the automotive industry. Modern cars are not only the result of mechanical engineering, but they also contain complex computer systems, which sometimes consist of more than 50 interacting embedded devices. New applications challenge their design by introducing a new class of problems that are based on a detailed analysis of the environmental situation. This situation analysis relies on models and algorithms of the domain of computational geometry. The basic model is usually an Euclidean plane, which contains polygons to represent the objects of the environment. Primitive operations of computational geometry are used to model the spatial behaviour: For example, checking whether two objects collide is equivalent to checking whether their corresponding geometric objects have a non-empty intersection. Usual implementations of computational geometry algorithms cannot be directly used for safety-critical systems. First, a strict analysis of their correctness is indispensable and second, nonfunctional requirements with respect to the limited resources must be considered. This thesis proposes a layered approach to a polygon-processing system. On top of rational numbers, a geometry kernel is formalised at first. Subsequently, geometric primitives form a second layer of abstraction that is used for plane sweep and polygon algorithms. These layers do not only divide the whole system into manageable parts but make it possible to model problems and reason about them at the appropriate level of abstraction. This structure is used for the verification as well as the implementation of the developed polygon-processing library. The application area of safety-critical systems is paid attention by the development of a verification framework based on the interactive theorem prover HOL. Its main goal is to provide different levels of abstraction for verification tasks and to give a tool set that can be generally applied for specifying and verifying polygon-processing algorithms: Besides a formalised geometry kernel, other common geometric operations of the application domain are defined, and various theorems for them are proven so that future work can be built on this basis. The implementation also benefits from the layered approach. Its structure is closely related to the formalisation and resembles the developed theories: On top of the verified geometry kernel, geometric primitives are implemented that are used for the software library. To apply the developed polygon-processing library in embedded systems, additional nonfunctional requirements are implemented by the different layers of the system: Conservative simplification heuristics to limit the problem sizes and thus the execution time, while retaining the correctness, are an inherent part of the library. Moreover, in contrast to general-purpose implementa-	abstraction layer;application domain;automated theorem proving;computation;computational geometry;computer;correctness (computer science);defense in depth (computing);embedded system;formal specification;general-purpose markup language;geometric primitive;hol (proof assistant);heuristic (computer science);interaction;level of detail;library (computing);non-functional requirement;principle of abstraction;proof assistant;run time (program lifecycle phase);sweep line algorithm;theory;verification and validation	Jens Brandt	2007			computer science;theoretical computer science;engineering drawing;algorithm	Embedded	-30.70749169996842	35.705867574091215	45132
178cc101712ad40e77e2cba0d865e490e090f095	synthesizing runtime enforcer of safety properties under burst error		We propose a game-based method for synthesizing a runtime enforcer for a reactive system to ensure that a set of safety-critical properties always holds even if errors occur in the system due to design defect or environmental disturbance. The runtime enforcer does not modify the internals of the system or provide a redundant implementation; instead, it monitors the input and output of the system and corrects any erroneous output signal that may cause a safety violation. Our main contribution is a new algorithm for synthesizing a runtime enforcer that can respond to violations instantaneously and guarantee the safety of the system under burst error. This is in contrast to existing methods that either require significant delay before the enforcer can respond to violations or do not handle burst error. We have implemented our method in a synthesis tool and evaluated it on a set of temporal logic specifications. Our experiments show that the enforcer synthesized by our method can robustly handle a wide range of properties under burst error.	algorithm;benchmark (computing);burst error;computation;experiment;input/output;mathematical optimization;programming tool;software bug;temporal logic	Meng Da Wu;Haibo Zeng;Chao Wang	2016		10.1007/978-3-319-40648-0_6	embedded system;real-time computing;engineering;distributed computing	Embedded	-23.36998172253094	37.761325204469486	45346
1e7d728888aa6712f1ed5ce601321217081fd993	scalable on-the-fly detection of the first races in parallel programs	debugging;parallel programming;on the fly analysis;first race;on the fly;scalability;parallel programs;race detection	Detecting races is important for debugging shared-memory parallel programs, because the races result in unintended nondeterministic executions of the programs. Most on-thefly techniques to detect the races cause the central bottlenecks of serializing all accesses of each thread to a shared variable. The amount of such bottlenecks can be reduced in case of detecting the first races that may cause the other races. This paper presents a new scalable on-the-fly technique which reduces the central bottlenecks to serializing at most two accesses of each thread to a shared variable for detecting the first races in parallel programs. It is important to detect the first races efficiently, because the removal of the Iirst races can make other races disappear. This technique, therefore, makes on-the-fly race detection more efficient and practical.	debugging;nondeterministic algorithm;scalability;sensor;serialization;shared variables;shared memory;transponder timing	Jeong-Si Kim;Yong-Kee Jun	1998		10.1145/277830.277914	parallel computing;real-time computing;scalability;computer science;distributed computing;programming language;debugging	Arch	-20.81000487995292	39.143474130365156	45372
3ea9b0b5d99428938de76102ba8daa30585cac44	design, implementation, and evaluation of optimizations in a javatm just-in-time compiler		The Java language incurs a runtime overhead for exception checks and object accesses, which are executed without an interior pointer in order to ensure safety. It also requires type inclusion test, dynamic class loading, and dynamic method calls in order to ensure flexibility. A ‘Just-In-Time’ (JIT) compiler generates native code from Java byte code at runtime. It must improve the runtime performance without compromising the safety and flexibility of the Java language. We designed and implemented effective optimizations for a JIT compiler, such as exception check elimination, common subexpression elimination, simple type inclusion test, method inlining, and devirtualization of dynamic method call. We evaluate the performance benefits of these optimizations based on various statistics collected using SPECjvm98, its candidates, and two JavaSoft applications with byte code sizes ranging from 23 000 to 280 000 bytes. Each optimization contributes to an improvement in the performance of the programs. Copyright © 2000 John Wiley u0026 Sons, Ltd.	compiler;just-in-time compilation	Kazuaki Ishizaki;Motohiro Kawahito;Toshiaki Yasue;Mikio Takeuchi;Takeshi Ogasawara;Toshio Suganuma;Tamiya Onodera;Hideaki Komatsu;Toshio Nakatani	2000	Concurrency - Practice and Experience	10.1002/1096-9128(200005)12:6%3C457::AID-CPE485%3E3.0.CO;2-0	computer architecture;parallel computing;common subexpression elimination;compiler correctness;interprocedural optimization;computer science;just-in-time compilation;programming language;java;inline expansion;functional compiler;partial redundancy elimination	PL	-19.593805887151454	35.54106183426332	45650
6e0616e9bf7d237caf2b79e6ab6b938bac418129	causal modeling of a video-on-demand system using predicate/transition net formalism	resource allocation;natural extension;parallel machine scheduling;time formalisms video on demand system causal modeling high level net model fifo queues bunching property parallel machine scheduling resource allocation mechanism request service refusal by choice feature predicate transition net formalism reachability analysis stochastic net theoretical methods performance analysis;video on demand;performance analysis;motion pictures video on demand network servers watches resource management delay digital systems laboratories mechanical factors parallel machines;interactive television;causal models;reachability analysis	We give a high-level net model for a specific video on demand system. This system has some very interesting modeling features: FIFO queues, the bunching property, parallel machine scheduling and a complicated resource allocation mechanism. The bunching property is the feasibility of several requests being served together by one resource. The resource allocation mechanism for this video on demand system has a special refusal by choice feature which means that the resource is not necessarily allocated even though it is available. The predicate/transition net formalism has been used in the modeling and reachability analysis in studying the properties of the model. The causal model developed here allows a natural extension for the use of time or stochastic net theoretical methods for performance analysis.	causal filter;semantics (computer science)	Tino Pyssysalo;Leo Ojala	1996		10.1109/EURMIC.1996.546490	real-time computing;simulation;computer science;theoretical computer science	Robotics	-26.631326030643553	34.4987308298656	46165
551e176e58e7bdae164b277160ec0a73c2783900	programming android - java programming for the new generation of mobile devices		Classes 45 Interfaces 46 Exceptions 48 The Java Collections Framework 52 Garbage Collection 55 Scope 56 Java Packages 56 Access Modifiers and Encapsulation 57 Idioms of Java Programming 59 Type Safety in Java 59 Using Anonymous Classes 62 Modular Programming in Java 65 Basic Multithreaded Concurrent Programming in Java 68 Synchronization and Thread Safety 68 Thread Control with wait() and notifyO Methods 71 Synchronization and Data Structures 73 3. The Ingredients of an Android Application 75 Traditional Programming Models Compared to Android 75 Activities, Intents, and Tasks 77 Other Android Components 78 Service 79 Content Providers 79 BroadcastReceiver 82 Static Application Resources and Context 82 Application Manifests 83 A Typical Source Tree 84 Initialization Parameters in AndroidManifest.xml 84 Resources 87 The Android Application Runtime Environment 88 The Dalvik VM 89 Zygote: Forking a New Process 89 Sandboxing: Processes and Users 89 Component Life Cycles 90 vi | Table of		Zigurd Mednieks;Laird Dornin;Blake Meike;Masumi Nakamura	2011				PL	-28.150965939433163	36.724491654539655	46190
77554e2dc454ff50b4763a7d99031e9d41dd03fb	modeling adaptable multimedia and self-modifying protocol execution	adaptive protocols;real time;model adaptation;adaptive protocol;interactive multimedia;research paper;distributed environment;multimedia synchronization;communication protocol;interactive multimedia self modifying protocols reconfigurable petri nets rpn multimedia synchronization adaptive protocols;petri net;user interaction;self modifying protocols;communicating finite state machine;finite state machine;reconfigurable petri nets rpn	Over the years, researchers have tried to extend Petri net to model multimedia. The focus of the research flows from the synchronization of multimedia without user interactions, to interactions in distributed environments. The issues in concern are the flexibility and compactness of the model when applied to model a system under change. Most existing models lack the power to model a system under change during execution. Petri net extensions have been developed to facilitate user interactions (UI) in distributed environments, however they require sophisticated pre-planning to lay out detailed schedule changes. On the other hand, there has been active research on self-modifying protocols or adaptive protocols in recent years. Plenty of models have been developed to model communication protocol execution, to name a few, finite state machines, communicating finite state machines, Petri nets. However, there exist no suitable models to simulate protocols that are self-modifying or adaptive during execution. In this paper, we propose a Reconfigurable Petri Net (RPN) for adaptable multimedia. A RPN comprises of a novel mechanism called modifier. This modifier can create a new change or delete an existing mechanism (e.g. arc, place, token, transition, etc.) of the net. In a way, modifier embraces controllability, reconfigurability, and programmability into the Petri net, and enhances the real-time adaptive modeling power. This development allows a RPN to have a greater modeling power over other extended Petri nets. The paper includes both the model and theory required to establish the technique's validity. Examples are also shown how RPN can be used to model interactive multimedia, and simulate self-modifying protocols. A simulator has been developed using Visual C++ under Windows NT to show that RPN is feasible. 1 Corresponding author	adaptive grammar;alternating bit protocol;c++;communicating finite-state machine;communications protocol;concurrency (computer science);existential quantification;image scaling;interaction;item unique identification;kinetic data structure;modifier key;petri net;real-time clock;real-time computing;reconfigurability;reconfigurable computing;reverse polish notation;run time (program lifecycle phase);self-modifying code;simulation;turing machine;user interface;video;windows nt;zooming user interface	Steven Guan;Sok-Seng Lim	2004	Future Generation Comp. Syst.	10.1016/S0167-739X(03)00127-4	embedded system;communications protocol;parallel computing;real-time computing;computer science;operating system;database;distributed computing;interactive media;finite-state machine;computer security;petri net;distributed computing environment	Robotics	-32.24025718206269	34.60939099109643	46241
1fa89ac6981ca1803da01dadfd332cfeda03849c	impact of loop transformations on software reliability		Application-level correctness is a useful and widely accepted concept for many kinds of applications in this modern world. The results of some applications, such as multimedia, may be incorrect due to transient hardware faults or soft-errors, but they are still acceptable from a user's perspective. Thus, it is worthwhile to develop approaches to guarantee application-level correctness in software, instead of hardware, to reduce cost and save energy. Many previous research efforts presented solutions to identify parts of programs that may potentially cause unacceptable results, and placed error detectors to improve reliability. On the other hand, we observe that loop transformations have the ability to improve reliability. By applying suitable loop transformations, some critical instructions may become non-critical. In this paper we propose a metric to analyze the reliability impact of each loop transformation. Thus, we can guide a compiler to optimize programs not only for reliability improvement, but for energy saving. The experimental results show that our analysis perfectly matches the results of fault injection, and achieves a 39.72% energy saving while improving performance by 52.16% when compared with [1]. To our knowledge, this is the first work that considers a software reliability by loop transformations.	compiler;correctness (computer science);fault injection;loop optimization;sensor;software quality;software reliability testing	Jason Cong;Cody Hao Yu	2015	2015 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)		reliability engineering;embedded system;electronic engineering;real-time computing;electronic design automation;computer science;electrical engineering;software reliability testing;theoretical computer science;operating system;processor register;algorithm;software quality;software fault tolerance;measurement;statistics	EDA	-22.045400257118263	38.985248968499455	46259
97b3e51b4ff8c298536f40a6591885799ec823a8	dependency-driven distribution of synchronous programs	synchronous programming	In this paper, we describe an automatic synthesis procedure that distributes synchronous programs on a set of desynchronized processing elements. Our distribution procedure consists of three steps: First, we translate the given synchronous program to synchronous guarded actions. Second, we analyze their data dependencies and represent them in a so-called action dependency graph (ADG). Third, the ADG is subsequently partitioned into of sub-graphs where cuts can be made horizontal (for a pipelined execution) or vertical (for a concurrent execution). Finally, we generate for each sub-graph a corresponding component and automatically synthesize a communication infrastructure between these com-	broadcast relay station;data dependency;raid	Daniel Baudisch;Jens Brandt;Klaus Schneider	2010		10.1007/978-3-642-15234-4_17	real-time computing;computer science;distributed computing;algorithm	DB	-28.155273564141464	34.38245993184745	46464
2d71afea66be39dc76e12aac95d8e23172baece8	software dependability in the tandem guardian system	tolerancia falta;sistema operativo;detection erreur;software performance evaluation software fault tolerance operating systems computers system recovery back up procedures;system reliability;evaluation systeme;deteccion error;reliability;fiabilite systeme;operational phase;computer systems design;measurement;software measurement;software measurement operating systems fault tolerant systems hardware failure analysis fault tolerance data analysis checkpointing software reliability programming;major defects;improvement;loose processor coupling;evaluacion sistema;fault categorization;software performance evaluation;field failure data;software fault tolerance;indexing terms;system failures;checkpointing;fiabilidad sistema;recurrence;failure analysis;error analysis;back up procedures;data analysis;system evaluation;system recovery;operating system;modeling tandem guardian operating system field failure data software dependability operational software software faults major defects processor failures backup processes software failures process pair technique software fault tolerance reliability improvement checkpointing restart loose processor coupling previously reported fault recurrence;processor failures;fault tolerant systems;recurrencia;fault detection;fault tolerance;amelioration;tandem guardian operating system;process pair technique;software failures;previously reported fault recurrence;mejoria;software dependability;systeme exploitation;fiabilite logiciel;error detection;fiabilidad logicial;software faults;fault model;computer systems performance;modeling;software reliability;tandem guardian system;programming;restart;operational software;operating systems computers;tolerance faute;backup processes;diagnostico error;diagnostic erreur;operating systems;hardware;error diagnostic	Abstmct_Based on extensive field failure data for Tandem's GUARDIAN operating system, this paper discusses evaluation of the dependability of operational software. Software faults considered are major defects that result in processor failures and invoke backup processes to take over. The paper categorizes the underlying causes of software failures and evaluates the effectiveness of the process pair technique in tolerating software faults. A model to describe the impact of software faults on the reliability of an overall system is proposed. The model is used to evaluate the significance of key factors that determine software dependability and to identify areas for imProvement. An analysis of the data shows that about 77% of processor failures that are initially considered due to software are confirmed as software problems. The analysis shows that the use of process pairs to provide checkpointing and restart (originally intended for tolerating hardware faults) allows the system to tolerate about 75% of reported software faults that result in processor failures. The loose coupling between processors, which results in the backup execution (the processor state and the sequence of events) being different from the original execution, is a major reason for the measured software fault tolerance. Over two-thirds (72%) of measured software failures are recurrences of previonsly reported faults. Modeling, based on the data, shows that, in addition to reducing the number of software faults, software dependabifity can be enhanced by reducing the recurrence rate.	application checkpointing;backup;central processing unit;dependability;loose coupling;operating system;recurrence relation;software fault tolerance	Inhwan Lee;Ravishankar K. Iyer	1995	IEEE Trans. Software Eng.	10.1109/32.387474	reliability engineering;embedded system;programming;failure analysis;fault tolerance;real-time computing;error detection and correction;systems modeling;index term;computer science;engineering;software reliability testing;operating system;reliability;fault model;data analysis;software maintenance;software measurement;fault detection and isolation;software quality;software fault tolerance;measurement;statistics;avionics software	SE	-22.72353851788887	41.39620874136437	46730
c79b33fc0d791a87d56fd1807c30eff1c4d5f6cc	stackless preemptive multi-threading for tinyos	microcontrollers;wireless sensor network applications;multi threading;software maintenance;telecommunication computing;tosthreads stackless preemptive multithreading tinyos embedded microcontroller platforms unstacked c source to source transformation legacy code wireless sensor network applications;embedded systems;unstacked c;tosthreads;stackless preemptive multithreading;tinyos;wireless sensor networks embedded systems microcontrollers multi threading operating systems computers software maintenance telecommunication computing;source to source transformation;operating systems computers;embedded microcontroller platforms;wireless sensor networks;legacy code;instruction sets context libraries random access memory programming transforms wireless sensor networks	Programming support for multi-threaded applications on embedded microcontroller platforms has attracted a considerable amount of research attention in the recent years. This paper is focused on this problem, and presents UnStacked C, a source-to-source transformation that can translate multithreaded programs into stackless continuations. The transformation can support legacy code by not requiring any changes to application code, and only modifications to the underlying threading library. We describe the details of UnStacked C in the context of the TinyOS operating system for wireless sensor network applications. We present a modified implementation of the TOSThreads library for TinyOS, and show how existing applications programmed using TOSThreads can be automatically transformed to use stackless threads with only modifications in the build process. By eliminating the need to allocate individual thread stacks and by supporting lazy thread preemption, UnStacked C enables a considerable saving of memory used and power consumed, respectively.	compiler;continuation;embedded system;event-driven programming;finite-state machine;lazy evaluation;legacy code;library (computing);memory footprint;microcontroller;operating system;preemption (computing);programming model;sensor node;source transformation;stackless python;thread (computing);thread pool;tinyos	William P. McCartney;Nigamanth Sridhar	2011	2011 International Conference on Distributed Computing in Sensor Systems and Workshops (DCOSS)	10.1109/DCOSS.2011.5982136	microcontroller;embedded system;real-time computing;wireless sensor network;multithreading;computer science;operating system;software maintenance;legacy code;computer network	Embedded	-20.80360069761237	36.643214424266304	46858
44769c77fbf3a9a2eefcbf71ffe0b8b55e70ff2c	a preliminary study of the impact of software engineering on greenit	environmental factors;power aware computing;programming languages;software maintenance;greenit;hanoi towers problem;os-level library;powerapi;algorithmic choices;energy consumption;energy leaks;legacy software;runtime energy monitoring framework;software engineering;software solutions optimization;energy;experimentation;measurement;monitoring;performance;power model	GreenIT has emerged as a discipline concerned with the optimization of software solutions with regards to their energy consumption. In this domain, most of state-of-the-art solutions offer limited or constraining approaches to monitor the energy consumption of a device or a process. In this paper, we therefore report on a runtime energy monitoring framework we developed to easily report on the energy consumption of system processes. Concretely, our approach adopts an OS-level library, called PowerAPI, which estimates the power consumption of processes according to different dimensions (CPU, network, etc.). In order to better understand potential energy leaks of legacy software, we use this library to study the impact of programming languages and algorithmic choices on the energy consumption. This preliminary study is based on an empirical evaluation of a eight implementations of the Towers of Hanoi problem.	algorithm;application server;central processing unit;java;legacy system;mathematical optimization;operating system;programming language;resource leak;run time (program lifecycle phase);server (computing);software engineering	Adel Noureddine;Aurelien Bourdon;Romain Rouvoy;Lionel Seinturier	2012	2012 First International Workshop on Green and Sustainable Software (GREENS)		embedded system;real-time computing;simulation;energy;performance;computer science;operating system;potential energy;programming language;software maintenance;legacy system;quantum mechanics;measurement	SE	-23.282458542027843	39.017088624929656	46972
3295ec1404eca0da7e82c08f63905076809bd35e	analysis and reduction of memory inefficiencies in java strings	lenguaje programacion;virtual machine;gestion memoire;memory management;programming language;componente logicial;java programming;footprint analysis and reduction;analisis cuantitativo;storage management;java virtual machine;performance;application server;ramasse miettes;chaine caractere;composant logiciel;langage java;machine virtuelle;garbage collection;recogemigas;gestion memoria;col;analyse quantitative;duplication;cadena caracter;garbage collector;software component;duplicacion;langage programmation;quantitative analysis;design;lenguaje java;experimentation;maquina virtual;languages;java language;character string;java;string	"""This paper describes a novel approach to reduce the memory consumption of Java programs, by focusing on their """"string memory inefficiencies"""". In recent Java applications, string data occupies a large amount of the heap area. For example, about 40% of the live heap area is used for string data when a production J2EE application server is running. By investigating the string data in the live heap, we identified two types of memory inefficiencies -- """"duplication"""" and """"unused literals"""". In the heap, there are many string objects that have the same values. There also exist many string literals whose values are not actually used by the application. Since these inefficiencies exist as live objects, they cannot be eliminated by existing garbage collection techniques, which only remove dead objects. Quantitative analysis of Java heaps in real applications revealed that more than 50% of the string data in the live heap is wasted by these inefficiencies. To reduce the string memory inefficiencies, this paper proposes two techniques at the Java virtual machine level, """"StringGC"""" for eliminating duplicated strings at the time of garbage collection, and """"Lazy Body Creation"""" for delaying part of the literal instantiation until the literal's value is actually used. We also present an interesting technique at the Java program level, which we call """"BundleConverter"""", for preventing unused message literals from being instantiated. Prototype implementations on a production Java virtual machine have achieved about 18% reduction of the live heap in the production application server. The proposed techniques could also reduce the live heap of standard Java benchmarks by 11.6% on average, without noticeable performance degradation."""	application server;benchmark (computing);data deduplication;database;elegant degradation;enterprise software;garbage collection (computer science);java platform, enterprise edition;java virtual machine;lazy evaluation;literal (mathematical logic);mathematical optimization;programme level;prototype;server (computing);string (computer science);universal instantiation;xml	Kiyokuni Kawachiya;Kazunori Ogata;Tamiya Onodera	2008		10.1145/1449764.1449795	binomial heap;garbage;parallel computing;heap;min-max heap;computer science;binary heap;operating system;heap overflow;garbage collection;programming language	PL	-20.410607615242185	35.263256003146786	47019
7e651bbe07a2bfb84c92ddd00550c64e3fbc1eeb	experience and reflection on the development of a holonic job shop scheduling system	workload;multiagent system;gestion labor;concepcion sistema;job shop scheduling;holonic system design;mas;object oriented programming;agent logiciel;multi agent systems mas;holon;software agents;atelier multigamme;multi agent systems;gestion tâche;object oriented;system design;scheduling;agent intelligent;logiciel libre;charge travail;intelligent agent;distributed manufacturing;oriente objet;software libre;job shop;agente inteligente;task scheduling;carga trabajo;sistema multiagente;orientado objeto;conception systeme;ordonnancement;reglamento;systeme multiagent;open source software	In this paper, we describe the development of a holonic job shop scheduling system that is based on Object-Oriented (O-O) and Multi-Agent Systems (MAS) approaches. In particular, this paper focuses on the holonic architecture (created primarily for system analysis purposes), the multi-agent architecture (created primarily for system design purposes) and the agent platform (Foundation for Intelligent Physical Agents Open Source (FIPA-OS)). On the basis of our experience with this development project, we then reflect on the approach and provide some suggestions for the developers of the holonic systems.	agent architecture;algorithm;centralisation;distributed control system;experience;high- and low-level;holon (philosophy);interrupt;inventory;job shop scheduling;job stream;microsoft windows 98;multi-agent system;operating system;overhead (computing);randomness;reboot (computing);rendering (computer graphics);scheduling (computing);system analysis;systems design	Scott S. Walker;Robert W. Brennan;Douglas H. Norrie	2006	IJCAT	10.1504/IJCAT.2006.010077	job shop scheduling;real-time computing;simulation;computer science;engineering;artificial intelligence;object-oriented programming;intelligent agent	AI	-28.060212424005538	40.02689773644147	47032
03e444946ebb42be18c48e660f891550a5f34371	the mutual exclusion problem: part i - a theory of interprocess communication	interprocess communication;mutual exclusion;concurrent systems;concurrent programs	A novel formal theory of concurrent systems that does not assume any atomic operations is introduced. The execution of a concurrent program is modeled as an abstract set of operation executions with two temporal ordering relations: “precedence” and “can causally affect”. A primitive interprocess communication mechanism is then defined. In Part II, the mutual exclusion is expressed precisely in terms of this model, and solutions using the communication mechanism are given.	algorithm;concurrency (computer science);concurrent computing;inter-process communication;linearizability;mutual exclusion;processor register;safe semantics;semantics (computer science);shared register;theory	Leslie Lamport	1986	J. ACM	10.1145/5383.5384	parallel computing;real-time computing;mutual exclusion;computer science;distributed computing;critical section;programming language;inter-process communication	Theory	-26.53776215484073	33.23176342633312	47187
45222a71af144c2013b3aac002f5a5e7e1c7e247	petri net models for describing multimedia synchronization requirements	synchronization constraints;performance evaluation;formal model;object composition;time stream;synchronisation;extended object composition;petri net models;dynamic timed;time stream petri net models multimedia synchronization multimedia communication synchronization constraints object composition extended object composition dynamic timed;multimedia communication;multimedia synchronization;petri nets;petri net;streaming media protocols jitter indium tin oxide multimedia communication graphics hard disks cameras humans motion pictures;quantitative evaluation;performance evaluation multimedia communication synchronisation petri nets	Synchronization constitutes an important research field in multimedia communication. The xynchronization problem has been addressed in the literature in two distinct levels: specification and design. On the specification level, several formal models have been proposed, which are mostly variations of the Petri net model. Although some models are deemed to be better than others in some aspects, there has not been a comprehensive comparison of these specijkation models. This paper provides a critical review of the existing Petri net specification approaches for specifying synchronization constraints, including object composition, extended object composition, dynamic timed, and time stream petri net models, and applies them to the specification of an interesting, relatively straightforward synchronization example for a qualitative and quantitative evaluation of their strengths and weaknesses.	formal methods;object composition;petri net;requirement	Son T. Vuong;Kendra Cooper;Mabo Robert Ito	1995		10.1109/ICNP.1995.524841	real-time computing;computer science;theoretical computer science;distributed computing;synchronization;petri net	SE	-33.22255345568899	35.30462409488165	47743
97994944493974cbd8b347423456af1bc8397c34	a simple protocol offering both atomic consistent read operations and sequentially consistent read operations	protocols;total order;sequential consistency asynchronous distributed systems atomic consistency combination of consistency criteria linearizability message passing np completeness shared memory abstraction;sequential consistency;multiprocessing programs;combination of consistency criteria;atomic consistency;data integrity;real time;np completeness;np completeness protocol atomic consistent read operation sequentially consistent read operation concurrent object data consistency criteria multiprocessing program asynchronous distributed system message passing shared memory abstraction;complete sharing;data structures;shared memory abstraction;data structures data integrity protocols multiprocessing programs message passing;message passing;asynchronous distributed system;asynchronous distributed systems;protocols computer science merging message passing np complete problem;linearizability	"""A concurrent object is an object that can be concurrently accessed by several processes. Two well-known consistency criteria for such objects are atomic consistency (also called linearizability) and sequential consistency. Both criteria require that all the operations on the concurrent objects can be totally ordered in such a way that each read operation obtains the last value written into the corresponding object. They differ in the meaning of the word """"last"""" that refers to physical time for atomic consistency, and to logical time for sequential consistency. This paper investigates the merging of these consistency criteria in a multiprocess program. The proposed combination offers two read operations to the processes, namely, an atomic read operation and a sequentially consistent read operation. While the first provides a process with the last """"physical"""" value of an object, the second provides it with a value that is approximate with respect to real-time but whose semantics is perfectly well defined. A protocol that implements the combination on top of an asynchronous distributed system is described. The protocol provides a better understanding of the similarities and differences between these consistency criteria. Moreover, the protocol is generic in the sense that it can be tailored to provide only one of these consistency criteria."""	approximation algorithm;concurrency (computer science);concurrent computing;distributed computing;linearizability;real-time clock;sequential consistency	Michel Raynal;Matthieu Roy;Ciprian Tutu	2005	19th International Conference on Advanced Information Networking and Applications (AINA'05) Volume 1 (AINA papers)	10.1109/AINA.2005.64	communications protocol;message passing;real-time computing;linearizability;np-complete;data structure;computer science;consistency model;data integrity;database;distributed computing;eventual consistency;programming language;sequential consistency;total order	PL	-24.363321155507244	41.07325141649854	47765
bb6cc627e6d24edb803c18020619fd1f5f464450	the design and implementation of real-time corba 2.0: dynamic scheduling in tao	systeme temps reel;dynamic programming;metodo adaptativo;empirical study;programacion dinamica;calculateur embarque;methode empirique;real time;metodo empirico;empirical method;logicial personalizado;dynamic scheduling quality of service middleware yarn real time systems processor scheduling open source software adaptive scheduling research and development runtime;methode adaptative;standard corba middleware distributed real time system embedded system dynamic qos requirement object management group real time corba 2 0 specification tao dynamic scheduling framework;systeme ouvert;qualite service;dynamical system;intergiciel;systeme dynamique;embedded systems;design and implementation;object oriented;scheduling;temps reel;adaptive method;logiciel libre;distributed object management;boarded computer;programmation dynamique;tiempo real;open systems distributed object management middleware dynamic scheduling quality of service embedded systems;oriente objet;software libre;middleware;real time system;sistema tiempo real;sistema dinamico;quality of service;open systems;sistema abierto;orientado objeto;object request broker;calculador embarque;service quality;ordonnancement;real time corba;reglamento;dynamic scheduling;open source software;open source;calidad servicio	In an emerging class of open distributed real-time and embedded (DRE) systems with stringent but dynamic QoS requirements, there is a need to propagate QoS parameters and enforce task QoS requirements across multiple endsystems in a way that is simultaneously efficient and adaptable. The object management group's (OMG) real-time CORBA 2.0 specification (RTC2) defines a dynamic scheduling framework for propagating and enforcing QoS parameters dynamically in standard CORBA middleware. We make two contributions to research on middleware for open DRE systems. First, it describes the design and capabilities of the RTC2 dynamic scheduling framework provided by TAO, which is our open-source CORBA standards-based object request broker (ORB). Second, it describes and summarize the results of empirical studies we have conducted to validate our RTC2 framework in the context of open DRE systems. The results of those experiments show that a range of policies for adaptive scheduling and management of distributable threads can be enforced efficiently in standard middleware for open DRE systems.	common object request broker architecture;context switch;correctness (computer science);earliest deadline first scheduling;embedded system;experiment;interoperability;middleware;open-source software;operating system;quality of service;real-time clock;real-time transcription;requirement;rollercoaster tycoon 2;scheduling (computing);separation of mechanism and policy;software propagation;tao;the times;ical	Yamuna Krishnamurthy;Irfan Pyarali;Christopher D. Gill;Louis Mgeta;Yuanfang Zhang;Stephen Torri;Douglas C. Schmidt	2004	Proceedings. RTAS 2004. 10th IEEE Real-Time and Embedded Technology and Applications Symposium, 2004.	10.1109/RTTAS.2004.1317256	embedded system;real-time computing;real-time operating system;computer science;operating system;empirical research	Embedded	-28.913952434282198	41.27348081318259	47989
10b32bf5d5e4e1b7e8871322d850598cdb5186bc	enabling constant-time interface method dispatch in embedded java processors	java bytecode;interfaces;method dispatch;data type;object oriented programming languages;java	This paper describes an approach that enables the fast constant-time and memory-efficient runtime handling of interface data types as found in several object-oriented programming languages like Java. It extends an idea presented by League et al. [22] to attach an itable to a class object to obtain an interface object. A practical implementation of this approach based on an automated rather than a manual type conversion is presented. Its practibility in the context of Java is evaluated by an adaptation in the SableVM [15]. Several measures for its improvement have been derived and implemented. The adoption of the resulting technique for the implementation of interface method dispatches within SHAP [26, 32], a small-footprint embedded implementation of a Java bytecode processor, is described. This realization currently also contains a tradeoff compromising some generality of the support for interface typecasts while it ensures both a small memory demand as well as a fast constant-time interface method dispatch. The loss of generality is shown to be a minimal practical impact under the measures taken before.	central processing unit;dynamic dispatch;embedded java;embedded system;instance (computer science);java bytecode;programming language;type conversion	Thomas B. Preußer;Martin Zabel;Rainer G. Spallek	2007		10.1145/1288940.1288969	embedded system;method;parallel computing;real-time computing;jsr 94;java concurrency;data type;computer science;operating system;java modeling language;interface;strictfp;interface;embedded java;real time java;programming language;object-oriented programming;java;generics in java;scala;java annotation	PL	-21.508024168603374	35.44615873146201	48606
0e0318984c4628a77fae949f2ef46c75d1ccc6d9	visualizing reference patterns for solving memory leaks in java	garbage collection;memory leaks;memory management	Many Java programmers believe they do not have to worry about memory management because of automatic garbage collection. In fact, many Java programs run out of memory unexpectedly after per- forming a number of operations. A memory leak in Java is caused when an object that is no longer needed cannot be reclaimed because another object is still referring to it. Memory leaks can be dicult to solve, since the complexity of most programs prevents us from manually verifying the validity of every reference. In this paper we show a new methodology for nding the causes of mem- ory leaks. We have identied a basic memory leak scenario which ts many important cases. In this scenario, we allow the programmer to identify a period of time in which temporary objects are expected to be created and released. Using this information we are able to identify objects that persist beyond this period and the references which are hold- ing on to them. Scaling this methodology to real-world systems brings additional challenges. We propose a novel combination of visual syntax and reference pattern extraction to manage this additional complexity. We also describe how these techniques can be applied to a wider class of memory problems, including the exploration of large data structures. These techniques have been implemented and have been proven success- ful on large projects.	java;memory leak	Wim De Pauw;Gary Sevitsky	2000	Concurrency - Practice and Experience	10.1002/1096-9128(20001210)12:14%3C1431::AID-CPE542%3E3.0.CO;2-2	program analysis;data structure;computer science;operating system;database;garbage collection;programming language;memory leak	PL	-20.13550868325155	34.81327294856369	48851
58e54fd547378f9463e31a4e0e46fea7b2e9d023	08441 abstracts collection - emerging uses and paradigms for dynamic binary translation			binary translation	Bruce R. Childers;Jack W. Davidson;Koen De Bosschere;Mary Lou Soffa	2008			computer architecture;binary translation;computer science	NLP	-23.034892053259373	38.28217995541277	49175
eb354e70f8d1d54dc1570abcf3cccc0ca4fbad0d	migrating legacy systems to the web: an experience report	cobol;internet;client-server systems;information resources;software libraries;software maintenance;user interfaces;internet;microfocus object cobol;microsoft active server pages;microsoft internet information server;vbscript;web browser shell;web-enabled infrastructure;world wide web-enabled client-server architectures;application logic components;centralised mainframe-oriented software development;core legacy applications;database components;dynamic load libraries;legacy systems migration;past investments;server components;user interface;wrappers	A key to successfully moving to the Internet while salvaging past investments in centralised, mainframe-oriented software development is migrating core legacy applications towards Web-enabled client-server architectures. This paper presents the main results and lessons learned from a migration project aimed at integrating an existing COBOL system into a Web-enabled infrastructure. The original system has been decomposed into its user interface and server (application logic and database) components. The user interface has been migrated into a Web browser shell using Microsoft Active Server Pages (ASP) and VBScript. The server component has been wrapped with dynamic load libraries written in Microfocus Object COBOL, loaded into Microsoft Internet Information Server (IIS), and accessed by the ASP pages	legacy system;world wide web	Lerina Aversano;Gerardo Canfora;Aniello Cimitile;Andrea De Lucia	2001		10.1109/.2001.914979	computer science;web api;operating system;software engineering;database;programming language;user interface;world wide web;application server	Logic	-33.48942028210091	42.44258779619559	49323
6716c695d3cf32d40d6b019d917d63b90495aab9	open problems in the distributed control systems domain		This special issue of Parallel and Distributed Computing Practices focuses on the topic of  Engineering Distributed Control Systems (DCSs) . The guest editorial discusses open problems in the DCS domain. The articles contained in this issue are selected papers from the Joint Workshop on Parallel and Distributed Real-time Systems, a forum for presentation of engineering techniques relevant to control systems that are distributed or parallel. Many difficulties confront those who must engineer the emerging generation of real-time computing systems. Such systems have rigorous Quality of Service (QoS) objectives. They must behave in a dependable manner, must respond to threats in a timely fashion and must provide continuous availability, even within hazardous environments. Furthermore, resources should be utilized in an efficient manner, and scalability must be provided to address the ever-increasing complexity of scenarios that confront such systems. The difficulties in engineering such systems arise from several phenomena, one of the most difficult being the dynamic environments in which they must function. Unfortunately, the classical paradigms for engineering real-time systems do not address this phenomenon. New paradigms, techniques and tools are needed! This article provides a justification of this viewpoint. Control systems perform actions in response to conditions detected in the environment that they inhabit. A typical control system consists of sensors that monitor external conditions and software that filters, correlates and evaluates the sensor data. Events detected by the evaluation software activate software that initiates responses via actuators and guides the actions to successful completion. The processing performed by a control system depends on the environment in several ways. The load of the  sensing  path is primarily a function of the number of items detected in the environment. The load of the  actuation  path depends on the rate at which environmental events occur and are detected by the  sensing  path. Thus, the characteristics of the control systemu0027s environment should be a fundamental consideration in the definition of a successful engineering paradigm. Real-time control systems, as their name implies, function in the  real-world . What is the characteristic of their environment? Occasionally, one may encounter a fully deterministic real-world system. One may also, perhaps, find a real-world system that predictably follows a statistical distribution. However, it is often the case that the real-world environment is dynamic; it cannot be modeled by a deterministic model, or even by a stochastic model based on a time-invariant statistical distribution. The environments of many control systems are dynamic. An individual software entity may therefore have large variations in its execution times (we have observed variations of three orders of magnitude among lower bounds and upper bounds on execution times of software paths through real-world control systems!). This makes analysis of timing conformance very difficult. Therefore, paradigms for the engineering of real-world distributed control systems should allow for dynamic behavior. Most of the existing paradigms are based on worst case assumptions regarding execution times and resource usage, and have assumed that all system behavior follows a statically known pattern. When applying the techniques to systems that function in unknown environments, it is sometimes impossible to obtain some of the parameters required by the models! Paradigms are needed to allow the modeling of systems that work in dynamic environments. On a separate note let me add two comments about the developments in the journal. First, on the next pages you will find short self-introductions prepared by six members of the Editorial Board. We plan to proceed with such introductions until all of the members are presented. Second, a new initiative is being introduced in the Calls for Papers and Participation area: Software Reviews. Dr. Hong Shen and Dr. Domenico Talia will be running this section. If you are interested in participating by submitting software for review or reviewing it, please contact them directly. Lonnie R. Welch Ohio University	distributed control system	Lonnie R. Welch	1998	Scalable Computing: Practice and Experience		real-time computing;simulation;system of systems;computer science;operations management	HPC	-24.59425138613047	42.63491350501243	49532
956dcc70c3425b6aa85f49bfda642e3ae5fc5fd5	data flow computing model: application for parallel computer systems diagnosis	tratamiento paralelo;continuous function;tolerance aux pannes logiciel;traitement parallele;redundancia;computer model;sistema informatico;flot donnee;software fault tolerance;fonction continue;computer system;flujo datos;fault tolerant system;redundancy;diagnostic panne;funcion continua;fault diagnostic;diagnostico pana;sistema tolerando faltas;parallel computer;systeme tolerant les pannes;systeme informatique;encaminamiento;systeme parallele;parallel system;forwarding;data flow;parallel processing;sistema paralelo;redondance;acheminement	This paper concerns the issue of recovery of a fault-tolerant parallel system without spares. A fault-tolerant system must be able to proceed its operation despite the occurrence of faults. In such a system recovery can be considered as a support function that retains the fault tolerant features of the system. We present here a data flow model that comprises functional blocks and activating signs in accordance with message flow in a parallel system. A fault in a system occurs according to the continuity of message routing providing the communication between processes and enables the fault diagnosis. Messages in a system are generated and processed in message routing.	dataflow architecture;parallel computing	Liberios Vokorokos	2001	Computers and Artificial Intelligence		continuous function;embedded system;data flow diagram;parallel processing;fault tolerance;parallel computing;real-time computing;computer science;redundancy;algorithm;software fault tolerance	AI	-19.942797456019985	43.06177969756104	49535
167b1c46aea15a88ccdded7ff24711ae9b027004	implementing distributed ada		The target environment thus consists of three chassis. Each chassis has 8Mb of W memory, which is avaitable to all processors within the chassis. In addhion, each chassis contains at least two 68030 processors, and at least one R3000 processor. Fhdly, each chassis contains 256Kb of memory that is commonly available to all other chassis, forming a common block of interchassis memory. This memory is to be used by a host computer (executing avionics simulation models) for communicating with the various target computers described above.	ada;avionics;central processing unit;chassis;computer;host (network);r3000;simulation	Patrick Rogers;Marc Pitarys	1992		10.1145/143557.144005	software engineering;programming language;computer science	Arch	-26.770353185014187	38.32844314145026	49665
b3ff3db7d5e84d81773b1dddd253ef6e6b94b663	the derivation of graph marking algorithms from distributed termination detection protocols	distributed system;sistema operativo;algoritmo paralelo;systeme reparti;parallel algorithm;metodologia;termination detection;probleme terminaison;methodologie;algorithme parallele;sistema repartido;coloration graphe;ordered by external client;operating system;informatique theorique;coloracion diagrama;estructura datos;termination problem;systeme exploitation;structure donnee;methodology;graph coloration;data structure;problema terminacion;wiskunde en informatica wiin;computer theory;informatica teorica	Abstract   We show that on-the-fly garbage collection algorithms can be obtained by transforming distributed termination detection protocols. Virtually all known on-the-fly garbage collecting algorithms are obtained by applying the transformation. The approach leads to a novel and insightful derivation of, e.g., the concurrent garbage collection algorithms of Dijkstra et al. and of Hudak and Keller. The approach also leads to several new, highly parallel algorithms for concurrent garbage collection. We also analyze a garbage collecting system due to Hughes from our current perspective.	algorithm;item unique identification	Gerard Tel;Richard B. Tan;Jan van Leeuwen	1988	Sci. Comput. Program.	10.1016/0167-6423(88)90024-X	data structure;computer science;artificial intelligence;methodology;parallel algorithm;programming language;algorithm	Theory	-20.77143294302956	42.87785202871668	49939
7e91775afbb6c9136447d3908f39c13eb4b67443	functional programming for concurrent and distributed computing	distributed computing;functional programming	There are at least two approaches to the design of languages for parallel computing. One approach is to use functional or relational languages which are easy to read, write, transform and verify. The more conventional approach is to use procedural languages which give a programmer a high degree of control over the run-time behaviour of a program. There is a need to reconcile these two approaches in a language which permits both simplicity and efficiency.	distributed computing;functional programming;parallel computing;procedural programming;programmer;run time (program lifecycle phase)	F. Warren Burton	1987	Comput. J.	10.1093/comjnl/30.5.437	distributed algorithm;concurrent computing;reactive programming;functional reactive programming;computer science;theoretical computer science;concurrency control;end-user computing;distributed computing;programming paradigm;distributed design patterns;inductive programming;programming language;functional programming;concurrent object-oriented programming;autonomic computing	PL	-26.365292068741837	33.76775762288385	50080
7eb5712746fc60016b374fd467849acab7716f79	an object-oriented middleware for our metasystem on internet	virtual machine;client server systems;application program interfaces distributed object management client server systems internet;internet;object oriented;application program interfaces;distributed object management;middleware;uniform program interface object oriented middleware metasystem internet geographically distributed heterogeneous resources software layer virtual machine single image space system transparent data transfer;middleware internet parallel processing resource management object oriented modeling virtual machining prototypes hardware space technology computer networks;geographic distribution;data transfer	A metasystem is composed geographicaUv distributed heterogeneous resources that can be reached over the network. An essential sofware layer; often called middleware, maps heterogeneous hosts into a single coherent virtual machine, giving the user the power of a unique computing environment. In this paper; an object-oriented middleware for the metasystem based on Internet is described in detail. It mash the hardware details, giving the user a single-image space system with transparent data transfer and rm$orni program interface.	autostereogram;coherence (physics);internet;mash-1;map;meta-system;middleware;virtual machine	Xiaolin Gui;Depei Qian;G. He;X. S. Dong	2000		10.1109/TOOLS.2000.885907	middleware;computer science;message oriented middleware;middleware;database;distributed computing;world wide web	HPC	-33.51703990394048	44.246126966574856	50528
22859449083c9cda62b992e1f5e5edb4917fb8ce	sisco: providing a cooperation filter for a shared information space	databases;cooperation filter;information space;test bed;multi user;information gathering;design and implementation;awareness;shared information space;shared desktop;object oriented database	A rationale for the extension of database technology to support collaboration through the provision of awareness information gathering and presentation is presented. The design and implementation of SISCO, a transparent cooperation filter for a multi-user generic object-oriented database is described. By trapping all accesses made to the shared objects, from both cooperation-aware and unaware database clients, awareness information is gathered. By making the filter responsible for the cooperation mechanisms, the underlying database is left unaltered. SISCO-D is based on a desktop-based browser, but is cooperation aware. The shared browser forms a test-bed for the investigation of awareness presentation techniques.	database;design rationale;desktop computer;multi-user;testbed	John A. Mariani	1997		10.1145/266838.267357	awareness;computer science;knowledge management;database;distributed computing;testbed	DB	-31.35083563486453	44.29070231984302	50665
e983b833354a3e92ca885ad2d20ee4948cb48999	energy consumption analysis for two embedded java virtual machines	java programming;java virtual machine;memory access;embedded java virtual machine;energy consumption;java opcode;energy cost	Abstract In this paper we present a general framework for estimating the energy consumption of an embedded Java virtual machine (JVM). We have designed a number of experiments to find the constant overhead and establish an energy consumption cost for individual Java opcodes for two JVMs. The results show that there is a basic constant overhead for every Java program, and that a subset of Java opcodes have an almost constant energy cost. We also show that memory access is a crucial energy consumption component.	embedded java;embedded system;experiment;java virtual machine;opcode;overhead (computing)	Sébastien Lafond;Johan Lilius	2007	Journal of Systems Architecture	10.1016/j.sysarc.2006.10.003	java card;parallel computing;real-time computing;jsr 94;java concurrency;computer science;operating system;strictfp;embedded java;real time java;java;scala;java applet;java annotation	Embedded	-20.563059580990192	36.49448605569275	50889
82f87372572450d9b6138e48ea07f38389a6d713	synchronization in multimedia languages for distributed systems	distributed system	The rising popularity of multimedia content on the web has led to the development of special-purpose languages for multimedia authoring and presentations. Examples of such languages include SMIL [1], VRML [2], and MPEG4 [3]. These languages support the description of a multimedia presentation containing multiple media sources including both natural and synthetic media as well as media stored in files or streamed live over the network. Some mechanism for specifying the layout of the media on the screen is given as well as a set of primitives for synchronizing the various elements of the presentation. For example, in SMIL we can specify that two video clips be displayed in parallel or that one audio clip be started when another clip finishes. Some of these languages allow for a limited amount of user interactions. A SMIL 2.0 presentation might allow a user to choose a soundtrack in one of several different languages by clicking on a particular area of the presentation. This is accomplished through the incorporation of the events defined in a scripting language such as JavaScript. While these are well suited for the description of multimedia presentations on the Web, they are of limited use for creating more general distributed multimedia applications since general-purpose programming is only available in the form of scripting languages that have limited power. To support the construction of more largescale applications approaches such as the use of special multimedia libraries along with a general-purpose language as in the case of Java and JMF [4] or the extension of middleware such as Corba [5] have been proposed. Besides lacking certain essential characteristics for the development of advanced distributed multimedia applications that will be noted below, the use of libraries and/or middleware to achieve synchronization and perform other media related services results in a less wellspecified approach than can be achieved by directly extending existing general purpose languages with multimedia constructs with precisely specified semantics. This latter is the approach we follow in our work on multimedia languages that we will describe here. The language that we want to design should support general-purpose computation; therefore the multimedia constructs whose semantics we will describe should be added to an existing general purpose language such as C, C++ or Java. This is the approach taken by the reactive language Esterel [6]. Reactivity is a very important property for a multimedia language. A reactive system is one which responds to stimuli from the environment [7]. In a multimedia system such stimuli might include user interactions as well as (for example) events generated by the contents of some media stream. The multimedia system must be able to interact with the environment within a short, predefined time period. When used in this context, the difference between reactive systems and interactive systems is that while both may interact with the environment, the latter do not have such a time constraint. The way in which the environment interacts with the multimedia system is through the generation of signals. A signal can be either synchronous (e.g. the reading of some sensing device) or asynchronous (e.g. the recognition of a particular face in a video stream). Our approach to multimedia languages greatly increases the power and flexibility of synchronization by providing synchronization constructs which can be applied not just between media streams, but also between media streams and (synchronous or asynchronous) signals. In fact, in our approach multimedia streams are just a particular type of signal. The rest of this paper is organized as follows. Section 2 describes the fundamental concepts of signals and streams. Section 3 introduces the various synchronization mechanisms. Section 4 describes the language constructs. Section 5 discusses related research while section 6 describes future research.	asynchronous i/o;c++;common object request broker architecture;computation;distributed computing;esterel;general-purpose language;general-purpose markup language;interaction;java media framework;javascript;library (computing);middleware;streams;scripting language;streaming media;synchronized multimedia integration language;synthetic intelligence;vrml;video clip;world wide web	Angela Guercio;Arvind K. Bansal;Timothy Arndt	2005			multimedia;general-purpose language;distributed computing;distributed concurrency control;streams;computer science;real-time computing;distributed object;common object request broker architecture;scripting language;data synchronization;distributed design patterns	PL	-33.10034790142011	35.943690327745784	50914
b3d8160562b94eed15da0c1e854a6e7f78e2aa18	characterization of silent stores	avoidable writebacks silent stores store instructions benchmarks critical silent stores;storage management;software performance evaluation;partial differential equations acceleration pipelines differential equations maxwell equations drives computer aided instruction image coding modems writing;software performance evaluation storage management;source code	The recent discovery that many store instructions are silent creates new opportunities for computer architects. A silent store does not change the state of the system because it writes a value that already exists at the write address, and can safely be eliminated from the dynamic instruction stream. We analyze silent stores in several benchmarks in the context of their high-level source code and explain why they occur. We also introduce the concept of critical silent stores and show that their removal is sufficient for eliminating avoidable writebacks. Finally, we show that frequently occurring stores are highly likely to be silent and that selectively squashing them can drastically reduce the total number of silent stores. This paper explores and illuminates several aspects of store value locality.	benchmark (computing);high- and low-level;locality of reference	Gordon B. Bell;Kevin M. Lepak;Mikko H. Lipasti	2000		10.1109/PACT.2000.888338	parallel computing;real-time computing;computer hardware;computer science;operating system;programming language;source code	Arch	-19.319660708023566	37.91358414995946	51149
bbf0174071484d8413ff4fcfdbc46981bb40abcb	a framework for workload allocation in distributed transaction processing systems	base donnee repartie;architecture systeme;charge systeme;distributed database;distribucion carga;carga sistema;routing;sistema informatico;distributed transactions;base repartida dato;computer system;classification;transaction;distribution charge;load distribution;arquitectura sistema;systeme informatique;encaminamiento;information system;system architecture;clasificacion;systeme information;acheminement;system load;sistema informacion	Ever-increasing demands for high transaction rates, limitations of high-end processors, high availability, and modular growth considerations are all driving forces toward distributed architectures for transaction processing. However, a prerequisite to taking advantage of the capacity of a distributed transaction processing system is an effective strategy for workload allocation. The distribution of the workload should not only achieve load balancing, but also support an efficient transaction processing with a minimum of intersystem communication. To this end, adaptive schemes for transaction routing have to be employed that are highly responsive to workload fluctuations and configuration changes. Adaptive allocation schemes are also important for simplifying system administration, which is a major problem in distributed transaction processing systems. In this article we develop a taxonomic framework for workload allocation, in particular, transaction routing, in distributed transaction processing systems. This framework considers the influence of the underlying system architecture (e.g., shared nothing, shared disk) and transaction execution model as well as the major dependencies between workload, program, and data allocation. The main part of the framework covers structural (or architectural) and implementational alternatives for transaction routing to help identify key factors and basic tradeoffs in the design of appropriate allocation schemes. Finally, we show how existing schemes fit our taxonomy. The framework substantially facilitates a comparison of the different schemes and can guide the development of new, more effective protocols.	adaptive grammar;central processing unit;distributed operating system;distributed transaction;high availability;load balancing (computing);routing;shared nothing architecture;system administrator;systems architecture;taxonomy (general);transaction processing system	Erhard Rahm	1992	Journal of Systems and Software	10.1016/0164-1212(92)90126-5	embedded system;routing;real-time computing;biological classification;distributed transaction;computer science;weight distribution;operating system;database;online transaction processing;distributed database;transaction processing system;information system;systems architecture	DB	-19.642629855514336	45.96374653580407	51160
9f19f6c5ebf4de345dff65c3036684a5eb2becf0	inaccuracies in program profilers	sistema operativo;evaluation performance;optimisation;systeme unix;performance evaluation;optimizacion;call graph;unix system;evaluacion prestacion;ejecucion programa;program execution;operating system;run time performance evaluation;lisp language;execution programme;systeme exploitation;optimization;lisp;sistema unix;execution profiling;timing	Abstract#R##N##R##N#Run-time program profiling is a valuable tool in understanding software efficiency. Techniques for obtaining profiles make assumptions that may result in misleading data. In the paper we illustrate flaws in two profiling systems: the Unix ‘Gprof’ family (including the packages ‘monitor’, ‘prof’ and ‘profil’), and the TI Explorer metering package for Lisp.		Carl Ponder;Richard J. Fateman	1988	Softw., Pract. Exper.	10.1002/spe.4380180506	embedded system;real-time computing;computer science;operating system;lisp;programming language	SE	-22.38611943069455	36.29351424495495	51316
0122b7ef6c077b7e19367e942cb9629f29a055b3	scientific engineering of distributed java applications		Software deployment refers to the set of activities regarding the movement of the software from the development environment to the final delivery environment. These activities cover the release, installation, activation, adaptation, deactivation, update, removal and retirement of software components in a set of hosts. The deployment of services in distributed systems is still an open problem, despite the fact of the several research efforts and standards that have covered this activity in the lifecycle of systems. The substitution of programs by assemblies of components, which is typical of service oriented architectures, has made this situation even worse. In this article, we describe a framework for the resolution of dependencies between services implementations and its application to the Java-based service model for services gateways (OSGi). This framework performs the recursive identification and resolution of dependencies between services in OSGi platforms, including the resolution of native dependencies. The framework requirements and its architecture are presented. It is being applied to an industrial case study about the distributed deployment of services on heterogeneous platforms.	.net framework;centralized computing;common object request broker architecture;component-based software engineering;distributed computing;embedded system;enterprise javabeans;intrusion detection system;java media framework;java virtual machine;kernel (operating system);library (computing);middleware;osgi;operating system;provisioning;recursion;requirement;server (computing);service-oriented architecture;software deployment	Jan van Leeuwen	2003		10.1007/b95352	computational science;software engineering;real time java;programming language	SE	-33.02180746311169	42.95310696663398	51421
6c664eba02c37d0b02c2064512c9030f9f11911e	composing locks by decomposing deadlocks	processor architecture;shared memory;concurrent programming;deadlock detection;deadlock avoidance;deadlock detection and recovery;runtime systems;speculative parallelism and coarse grain speculation;data races;concurrent programs;runtime system;program analysis;coarse grained;parallel programs	The evolution of processor architectures from multi-core to many-core requires programmers to use concurrency to achieve performance. Unfortunately, shared memory parallel programs are difficult to implement correctly, and so is detecting concurrency bugs (e.g., data races, deadlocks, order violations, atomicity violations). In practice, the most common concurrency bugs are a) data races that arise due to unguarded or improperly guarded memory updates and b) deadlocks that arise due to circular dependencies among locks. While data races can be ameliorated by appropriate synchronization (a challenging problem in itself), deadlocks require fairly complex deadlock avoidance techniques, which may fail when the order of lock acquisitions is not known a priori. Furthermore, due to the potential for deadlocks, programmers cannot arbitrarily compose lock based codes without knowing the internal locking structure. Hence, composability is limited by deadlocks. The goal of this research is to achieve composability of lock based codes.	atomicity (database systems);circular dependency;code;composability;concurrency (computer science);concurrent computing;deadlock;debugging;emoticon;guard (computer science);lock (computer science);manycore processor;multi-core processor;programmer;sensor;shared memory;software bug;synchronization (computer science)	Hari K. Pyla	2011		10.1145/2048147.2048176	program analysis;shared memory;parallel computing;real-time computing;concurrent computing;microarchitecture;computer science;distributed computing;programming language;deadlock prevention algorithms	DB	-19.922827710139217	39.7514702916695	51559
2dec544cc7016ef6e96d51be5fe79217fceb9b03	a new intelligent programmable logic controller based on switched networks	switched network;switched networks computer peripheral equipment intelligent control local area networks programmable controllers;plc;switched network plc industrial ethernet;hardware ports computers power supplies timing automation computer architecture switches;industrial ethernet;intelligent plc based on industrial ethernet intelligent programmable logic controller switched network ethernet based automation equipments ethernet i o architecture hardware design communication module control objects remote i o interfaces distributed i o system architecture dual processor reset signals power supply supervisor ddr double data rate design iplcbie	This paper studies the design of a new intelligent PLC (Programmable Logic Controller) based on the switched network. It proposes a new solution for the Ethernet-based automation equipments and the related applications, which is used to control a variety of industrial processes in distributed locations. The points we discuss mainly involve Ethernet I/O architecture and the hardware design of communication module. For the field part, the scope of our control objects includes the remote I/Os and the interfaces with other equipments of this level, typically distributed I/Os & devices. For the devices of the architecture, we focus on discussing the hardware design of the communication module in our architecture. The design includes the system architecture with a new dual processer, reset signals and power supply supervisor, DDR (Double Data Rate) design, which has acted the kernel part in information exchange of IPLCBIE (Intelligent PLC based on Industrial Ethernet).	double data rate;information exchange;input/output;loadable kernel module;power supply;programmable logic device;systems architecture	Borui Wang;Guangfu Wang	2013	2013 Ninth International Conference on Natural Computation (ICNC)	10.1109/ICNC.2013.6818258	control engineering;embedded system;real-time computing;synchronous ethernet;ethernet flow control;engineering;ata over ethernet;ethernet global data protocol;industrial ethernet;carrier ethernet;ethernet over sdh;network interface controller	Robotics	-32.41414320359622	38.48266726561532	51580
b297082ce8b91e37306c4c91ca2c0e5ead4711b6	lfu-k: an effective buffer management replacement algorithm	replacement;base donnee;formal specification;remplacement;implementation;database;buffer management;base dato;probabilistic approach;buffer system;sistema amortiguador;specification formelle;identificacion sistema;especificacion formal;system identification;enfoque probabilista;approche probabiliste;estimacion parametro;least frequently used;reemplazo;parameter estimation;estimation parametre;implementacion;probability model;systeme tampon;trace driven simulation;identification systeme	This paper introduces a new approach to database disk buffering, called the LFU-K method. The LFU-K page replacement algorithm is an improvement to the Least Frequently Used (LFU) algorithm. The paper proposes a theoretical-probability model for formal description of LFU-K algorithm. Using this model we evaluate estimations for the LFU-K parameters. This paper also describes an implementation of LFU-2 policy. As we demonstrate by trace-driven simulation experiments, the LFU-2 algorithm provides significant improvement over conventional buffering algorithms for the shared-nothing database systems.	database;decision problem;experiment;least frequently used;mbc-55x;multiprocessing;omega;page replacement algorithm;parallel database;reference model;shared nothing architecture;simulation;web cache	Leonid B. Sokolinsky	2004		10.1007/978-3-540-24571-1_60	least frequently used;simulation;system identification;computer science;bicarbonate buffering system;artificial intelligence;formal specification;database;fsa-red algorithm;estimation theory;programming language;implementation;algorithm	DB	-19.8044477533996	45.33181794744614	51735
86c75033e0b2ddf590846786574cbdb5c600fd28	a methodology for testing cpu emulators	software testing;emulation;fuzzing;automatic test generation	A CPU emulator is a software system that simulates a hardware CPU. Emulators are widely used by computer scientists for various kind of activities (e.g., debugging, profiling, and malware analysis). Although no theoretical limitation prevents developing an emulator that faithfully emulates a physical CPU, writing a fully featured emulator is a very challenging and error prone task. Modern CISC architectures have a very rich instruction set, some instructions lack proper specifications, and others may have undefined effects in corner cases. This article presents a testing methodology specific for CPU emulators, based on fuzzing. The emulator is “stressed” with specially crafted test cases, to verify whether the CPU is properly emulated or not. Improper behaviors of the emulator are detected by running the same test case concurrently on the emulated and on the physical CPUs and by comparing the state of the two after the execution. Differences in the final state testify defects in the code of the emulator. We implemented this methodology in a prototype (named as EmuFuzzer), analyzed five state-of-the-art IA-32 emulators (QEMU, Valgrind, Pin, BOCHS, and JPC), and found several defects in each of them, some of which can prevent proper execution of programs.	central processing unit;cognitive dimensions of notations;computer scientist;corner case;debugging;ia-32;jpc;malware analysis;profiling (computer programming);prototype;software system;terminal emulator;test case;undefined behavior;valgrind	Lorenzo Martignoni;Roberto Paleari;Alessandro Reina;Giampaolo Fresi Roglia;Danilo Bruschi	2013	ACM Trans. Softw. Eng. Methodol.	10.1145/2522920.2522922	emulation;computer architecture;parallel computing;real-time computing;fuzz testing;computer science;software engineering;flash memory emulator;software testing;programming language	OS	-21.973707505628752	37.79541816167652	51766
388bd16cb160c33fc004f8bafaf4bc1d38ad2072	using scoping rules as a distributed coordination language	distributed application;directed graphs;distributed system;distributed coordination;programming language;distributed processing;distributed computing;object oriented programming parallel languages parallel programming directed graphs programming theory distributed processing;distributed programs;parallel programming;coordination language;object oriented programming;distributed objects;programming theory;computer languages distributed computing computer networks organizing modems object oriented programming crystallization sockets functional programming associative memory;object oriented;parallel languages;scheme scoping rules distributed coordination language directed graph distributed application graph lexical scoping high level programming languages distributed programming systems associative binding object oriented binding closures complexity	Keywords: coordination languages, Scheme, distributed systems, lexical scoping, distributed objects. Essential to coordinating a distributed application is organizing and traversing the distributed application graph. Lexical scoping performs this function among modern high-level programming languages, but does not have the same distinction in distributed programming systems, where it competes with various forms of associative and object-oriented binding. We will show that distributed lexical scop-ing, combined with closures, provides a powerful means of coordinating communication in distributed computations and can significantly reduce the complexity for developing certain types of applications visa -vis other coordination paradigms/languages. These results are not dependent on a particular programming language, and can be combined with existing paradigms.	computation;distributed computing;distributed object;high- and low-level;high-level programming language;linkage (software);organizing (structure);scheme;scop;scope (computer science);virtual instrument software architecture	Matthew Fuchs	1997		10.1109/HICSS.1997.667281	computer science;theoretical computer science;distributed computing;distributed object;programming paradigm;programming language;object-oriented programming;comparison of multi-paradigm programming languages	PL	-27.956372455491575	32.5006632816596	52008
9c51c53062f897fe3360c9800cbad361635a3488	a message-passing paradigm for object management	message passing	Many researchers believe that object-oriented languages are well suited for some of the programming tasks associated with the building of an office information system (OIS). To lend support to this thesis, we shall concentrate our attention on an object-oriented programming environment, named Oz, which has been effectively employed to capture certain aspects of OISs more simply and naturally than with conventional languages. After pointing out some of the limitations of Oz, we introduce additional facilities into it which further enhance its capabilities, especially with respect to the management of office data. 1 . I N T R O D U C T I O N One of the means of evaluating the utility of a programming language is to measure the effort associated with the programming of particular applications. It has been argued that by this standard, object-oriented languages are appropriate for the implementation of OISs (NIER85). A straightforward way to defend such a proposition is to demonstrate that essential characteristics of OISs can be captured more readily by the object protocol of a given object-oriented language than by the constructs associated with conventional programming languages. This was the impetus for developing Oz, a prototype object-oriented programming environment implemented at the University of Toronto (NIER83, MOON84, TWAI84]. While Oz bears comparison to general purpose systems such as Smalltalk, it is distinguished by features which reflect its intended use as a tool for building OISs. These features in turn reflect the designers view of what an OIS is. This requires some elaboration. In the office place of today, an OIS has come to refer to an aggregation of software often including word processing, graphics, electronic mail, database management and spreadsheets. In the more sophisticated of these systems, such as Lotus 1-2-3 and Symphony, a certain level of integration is achieved by allowing data flow among the constituent programs. Research in OIS is directed towards more than just the development of integrated software tools with increased functionality and ease of use. These tools assist the office worker in performing his tasks. However, they are passive in that they do not initiate or control the processing of office tasks [LOCH83, This research was supported in part by the Natural Sciences and Engineering Research Council of Canada under grants G1359 and G1360. Author's address: Computer Systems Research Institute, University of Toronto, Toronto, Ontario, Canada, M5S 1A4 (416/9786610). CSNET: weiser.toronto®csnet-relay.	apl;database;dataflow;email;graphics;hardware description language;information system;integrated development environment;integrated software;lotus 1-2-3;message passing;programming language;prototype;smalltalk;spreadsheet;symphony;usability	Gul A. Agha	1985	IEEE Database Eng. Bull.		message passing;database;computer science;message broker;distributed computing	DB	-26.378449286594595	40.305438301568	52499
f78713dfc17520146a6ca83c0a26eb6decb40f14	the process agent model and message passing in a distributed processing vr system	distributed virtual reality;network protocol;agent modeling;real time;distributed processing;system performance;design and implementation;group dead reckoning;message passing;networked virtual reality;distributed interactive simulation;client server model	This paper deals with the design and implementation of a low cost, distributed Virtual Reality system. The conceptual mode1 of the system addresses the dependency of the visual update rate on simulation computation The Process Agent Model is introduced to make the details of distributed processing and network communications transparent to the high level processes. Processes residing on the same machine communicate with one another directiy by means of method calls. “Agents It are used for communication between remote processes. An agent intercepts messages on behalf of the process which it represents, and via the nehvork, these messages are forwarded to the authentic remote process. A network protocol which is suited to real-time VR applications is discussed, allowing for the transmission of both guaranteed and non-guaranteed message types. The network employs an intelligent queuing mechanism, based. on message type and target process, for the firtering of redundant and aged messages. This jltering contributes to a reduction of bandwidth utilisation A qualitative ptirformance analysis of the prototype system reveals three factors influencing system performance: division of computational load, network lag and system overhead.	communications protocol;computation;distributed computing;high-level programming language;message passing;overhead (computing);process (computing);prototype;real-time clock;simulation;virtual reality	Warren Blumenow;George Spanellis;Barry Dwolatzky	1997		10.1145/261135.261166	communications protocol;message passing;real-time computing;computer science;operating system;distributed computing;computer performance;client–server model	Networks	-30.16244404195989	45.455011746647884	52508
cb3f691485e2494ec177b91b12216b5aff3fa957	concepts and notations for concurrent programming	general and miscellaneous mathematics computing and information science;communications;programming language;message passing;concurrent programs;technical report;computer science;synchronization 990200 mathematics computers;programming;parallel processing;programming languages	Much has been learned in the last decade about concurrent programming..This patmr identifies the major concepts of concurrent programming and describes some of the more importam language notations for writing concurrent programs. The roles of processes, communication, and synchronization are discussed. Language notations for expressing concurrent execution and for specifying process interaction are surveyed. Synchronization primitives based on shared variables and on message passing are described. Finally, three general classes of concurrent programming languages are identified and compared.	concurrent computing;message passing;programming language;shared variables	Gregory R. Andrews;Fred B. Schneider	1983	ACM Comput. Surv.	10.1145/356901.356903	concurrent constraint logic programming;fourth-generation programming language;parallel processing;programming;first-generation programming language;futures and promises;message passing;declarative programming;very high-level programming language;programming domain;reactive programming;computer science;technical report;theoretical computer science;extensible programming;third-generation programming language;functional logic programming;database;programming paradigm;symbolic programming;inductive programming;fifth-generation programming language;programming language theory;programming language;second-generation programming language;comparison of multi-paradigm programming languages;concurrent object-oriented programming;parallel programming model	PL	-26.190790980968323	32.56836813164649	52633
445774972234163ba5ef4589a76d886fe2e97189	sessions and pipelines for structured service programming	process calculus;qa75 electronic computers computer science;client server;service oriented computing	Service-oriented computing is calling for novel computational models and languages with primitives for client-server interaction, orchestration and unexpected events handling. We present CaSPiS, a process calculus where the notions of session and pipelining play a central role. Sessions are two-sided and can be equipped with protocols executed by each side. Pipelining permits orchestrating the flow of data produced by different sessions. The calculus is also equipped with operators for handling (unexpected) termination of the partner’s side of a session. Several examples are presented to provide evidence for the flexibility of the chosen set of primitives. Our main result shows that in CaSPiS it is possible to program a “graceful termination” of nested sessions, which guarantees that no session is forced to hang forever after the loss of its partner.	client–server model;computational model;dataflow;graphics pipeline;pipeline (computing);process calculus;risk management;server (computing);service-oriented device architecture	Michele Boreale;Roberto Bruni;Rocco De Nicola;Michele Loreti	2008		10.1007/978-3-540-68863-1_3	process calculus;real-time computing;computer science;theoretical computer science;service-oriented architecture;distributed computing;programming language;client–server model	PL	-28.248114130634058	33.153891737444575	52847
d551f3a3fd9cb9a059fdae0585e42d824d0bb7d7	thread-based benchmarking deployment	institutional repositories;filigranage;digital watermarking;lenguaje programacion;sistema operativo;watermarking;electronic journal;interfase usuario;collaborative work;steganographie;fedora;red www;programming language;filigrana;user interface;aplicacion cliente servidor;reseau web;vital;page web dynamique;serveur reseau;computer programming;steganography;network servers;esteganografia;internet;computer programming languages;operating system;application client serveur;langage programmation;world wide web;algorithms;systeme exploitation;interface utilisateur;image watermarking;vtls;ils;client server application;operating systems	Information and knowledge are actually well and easily distributed thanks to electronic journals, news, mailinglists and forums. It is however more difficult to deploy algorithmic and programming collaboration: the heterogeneity of the programming languages and the operating systems used by researchers constitutes a major problem to the design of a common testing platform. Current solutions exist to develop collaborative work. Generally, these solutions impose specific programming languages and/or operating systems to developers. Some others specific rules have to be respected. These heavy constrains slow down the usage of collaborative programming platforms. The OpenWatermark project proposes a modern architecture for cooperative programming exchanges that takes all these aspects into account. Developers work with their favorite programming languages and operating systems as long as the OpenWatermark platform supports them. In this paper, we will present the OpenWatermark platform (www.openwatermark.org) and its application to the benchmarking of image watermarking algorithms.	algorithm;digital watermarking;operating system;pair programming;programming language;software deployment	Sebastien Lugan;Benoit M. Macq	2004		10.1117/12.538692	fourth-generation programming language;reactive programming;computer science;extensible programming;operating system;computer programming;database;programming paradigm;inductive programming;world wide web;concurrent object-oriented programming	OS	-27.50230566844677	41.66052881442336	53024
478ce1ef5a30f296515a9e5d7b208f590ad84336	the timely computing base model and architecture	distributed system;computer architecture real time systems timing fault tolerant systems large scale systems computer networks distributed computing explosives reliability theory;partial synchrony models;real time systems timely computing base large scale unpredictable unreliable infrastructures timeliness properties synchronous time model asynchronous time model architectural construct programming model software component timely function execution time related services dependable timely applications timeliness assurance synchrony models distributed systems;programming model;synchronisation;large scale;fault tolerant computing;parallel architectures;fault tolerant computing distributed programming parallel architectures real time systems synchronisation;distributed programming;timely computing base;computer science;distributed systems;article;partial synchrony;real time systems	Current systems are very often based on largescale, unpredictable and unreliable infrastructures. However, users of these systems increasingly require services with timeliness properties. This creates a difficult-to-solve contradiction with regard to the adequate time model: synchronous, or asynchronous? In this paper, we propose an architectural construct and programming model, which address this problem. We assume the existence of a component that is capable of executing timely functions, however asynchronous the rest of the system may be. We call this component the Timely Computing Base, and it can be used by the other components to execute a set of simple but crucial time-related services. We also show how to use it to build dependable and timely applications exhibiting varying degrees of timeliness assurance, under several synchrony	algorithm;asynchronous i/o;asynchronous circuit;computation;computational model;correctness (computer science);dependability;enterprise architecture framework;error detection and correction;fail-safe;failure detector;fault tolerance;hoc (programming language);programming model;real-time clock;real-time computing;real-time locating system;refinement (computing);sensor;shutdown (computing);systems design;timing failure;trusted computing base	Paulo Veríssimo;Antonio Casimiro	2002	IEEE Trans. Computers	10.1109/TC.2002.1024739	embedded system;synchronization;parallel computing;real-time computing;computer science;theoretical computer science;operating system;distributed computing;programming paradigm	Embedded	-24.97390257527682	44.0426986399507	53631
f0b4e45f3bbca85effa3939fef5f34855923808e	morpheus: support from ao-requirements to ao-software architecture	articulo;morpheus support from ao requirements to ao software architecture		ambient occlusion;software architecture	Elena M Navarro;Patricio Letelier;Isidro Ramos	2007			computer architecture;software architecture;computer science	Arch	-32.38173839404934	45.724504478603805	53637
329086b767663ccdc7395e5038c339b2b9d5730a	ivory - an object oriented framework for physics based information visualization	interactive systems physics computing data visualisation java client server systems virtual reality languages;information model;java data visualization application software libraries data mining multidimensional systems computer science plugs haptic interfaces object oriented modeling;virtual reality languages;object oriented framework;client server systems;information visualization;physics computing;three dimensional;data visualisation;client server;object oriented;graph layout;time varying data;interactive systems;scripting language;nt 4 ivory object oriented framework java platform independent framework physics based visualization information visualization applications multidimensional graph layout client server setup thin clients vrml 2 exports vrml plugged in www browser visual metaphors advanced plug in mechanism script language ivml interactive visualization examples haptic interface;java;haptic interface	We present IVORY a newly developed, platform-independent framework for physics based visualization. IVORY is especially designed for information visualization applications and multidimensional graph layout. It is fully implemented in Java 1.1 and its architecture features client server setup, which allows us to run the visualization even on thin clients. In addition, VRML 2.0 exports can be viewed by any VRML plugged-in WWW browser. Individual visual metaphors are invoked into IVORY via an advanced plug-in mechanism, where plug-ins can be implemented by any experienced user. The configuration of IVORY is accomplished using a script language, called IVML. Some interactive visualization examples, such as the integration of a haptic interface illustrate the performance and versatility of our system. Our current implementation supports NT 4.0.	client–server model;graph drawing;haptic technology;information model;information visualization;interactive visualization;java version history;plug-in (computing);scripting language;server (computing);thin client;vrml;vtk;www	Thomas C. Sprenger	1998		10.1109/INFVIS.1998.729562	three-dimensional space;information visualization;human–computer interaction;information model;computer science;operating system;database;scripting language;haptic technology;programming language;object-oriented programming;java;world wide web;data visualization;client–server model	DB	-30.631473161843243	40.358827057799175	53672
44dae9f446f1b348f199e71f499728c217af0388	a database architecture for scalability and high availability	high availability		high availability;scalability	Andreas Weininger	2010			database;high availability;scalability;data architecture;computer science	DB	-29.92559570971118	45.96298674069243	53757
465f721ec85fc024ff7ea2073fb4c6646fd375a9	the jaeos project and the μarm emulator	os courseware;arm emulation;accessibility	As operating systems evolve, so must operating systems projects. Most operating systems courseware systems are based on the significantly out of date MIPS architecture, and only one of these supports multiprocessors. This paper introduces μARM, a pedagogically undergraduate-appropriate ARM7tdmi-based system emulator/architecture. Furthermore, we present JaeOS, a specification for a multi-layer OS supporting multiprocessing, VM, thread synchronization, external devices (disks, terminals, tape, printers, and network interfaces) and a file system. Traditional OS projects like Nachos[5] or OS/161[10] provide students with a significant starting code base. Students then modify existing OS modules or add new ones. With μARM/JaeOS students undergo a pedagogically different experience of starting only with a hardware emulator and ending with a completely student written OS capable of running student written C programs.	arm7;emulator;layer (electronics);multiprocessing;operating system;synchronization (computer science)	Marco Melletti;Michael Goldweber;Renzo Davoli	2015		10.1145/2729094.2742596	embedded system;real-time computing;computer science;accessibility;operating system;software engineering;basic direct access method;programming language;world wide web	OS	-28.413675340487906	38.9862088226525	53772
fa7315fb8ad23ece170f8f7c5180052beda6e51b	space and time-efficient memory layout for multiple inheritance	concurrent threads;synchronization;multiple inheritance;object oriented language implementation	Traditional implementations of multiple inheritance bring about not only an overhead in terms of run-time but also a significant increase in object space. For example, the number of compiler-generated fields in a certain object can be as large as quadratic in the number of its subobjects. The problem of efficient object layout is compounded by the need to support two different semantics of multiple inheritance: shared, in which a base class inherited along distinct paths occurs only once in the derived class, and repeated, in which this base has multiple distinct occurrences in the derived. In this theoretical and foundational paper, we introduce two new techniques to optimize memory layout for multiple inheritance. The main ideas behind these techniques are the inlining of virtual bases and bidirectional memory layout. Our techniques never increase time overhead, and usually even decrease it. We show that in some example hierarchies, more than ten-fold reduction in the space overhead can be achieved. We analyze the complexity of the algorithms to apply these techniques, and give theorems to estimate the efficacy of this application. For concreteness, techniques and examples are discussed in the context of C++.	algorithm;c++;compiler;inline expansion;multiple inheritance;overhead (computing);tuple space	Peter F. Sweeney;Joseph Gil	1999		10.1145/320384.320408	multiple inheritance;synchronization;computer science;theoretical computer science;distributed computing;programming language;algorithm	PL	-19.158198771903788	32.416107818710614	53883
cd16ce35a327ff04e9866b8c95dd1d43b05e3b0d	self-adaptive failure detector for peer-to-peer distributed system considering the link faults		Nowadays, the distributed computing is prevailing in artificial intelligence applications due to the limited computation capacity of single computing node. Generally, distributed computing system contains large scale of computing node, and therefore system breakdown is regarded as usual matter. To enhance the system availability and performance, failure detection dominates important status to recover the system. The traditional failure detector simply equates the link fault with the node fault problem, which greatly affects the resource utilization, fault locating and fast repair. We present a self-adaptive Link-based Failure Detection Agreement DLFDA with an improved node fault detection algorithm, which can accurately distinguish the node fault and link fault. DLFDA can dynamically adjust the detection structure to increase the coverage of the link fault detection, while using Gossip protocol to distribute fault diagnosis results to other system members, which extensively reduces the damage of the system performance. Finally, the experimental results show that our method can meet the requirements of theoretical design.		Yanzhang He;Xiaohong Jiang;Changbo Dai;Zikun Fan	2017		10.1007/978-3-319-67952-5_6	failure detector;applications of artificial intelligence;computation;real-time computing;gossip protocol;peer-to-peer;fault detection and isolation;distributed computing;computer science	Robotics	-24.0686449287346	45.163969971316604	53994
33697900d1330e0953dd893e344801522054a475	utilitiy accrual scheduling with real-time java	developpement logiciel;soft real time system;systeme temps reel;utility accrual;real time;customization;personnalisation;langage java;soft real time;scheduling algorithm;desarrollo logicial;scheduling;temps reel;software development;personalizacion;utility accrual scheduling;tiempo real;lenguaje java;real time java;real time system;sistema tiempo real;ordonnancement;reglamento;java language	Graceful performance degradation during overload conditions is the primary objective of soft real-time systems. Utility accrual soft real-time scheduling algorithms allow speci cation of highly customized temporal system behavior during overload. Such algorithms are typically found in realtime supervisory systems where signi cant run-time uncertainty exists. This paper outlines an investigation of several utility accrual scheduling algorithms implemented in a Real-Time Java (RTJ) environment. These alternate schedulers are constructed, tested, and evaluated under the MIT FLEX/RTJ Compiler Infrastructure. The scheduling framework for this environment and its associated scheduling primitives are described and the corresponding performance characteristics are pro led. Furthermore, we outline the architecture of an experimental distributed Real-time Java scheduler.	algorithm;compiler;elegant degradation;real time java;real-time clock;real-time computing;scheduling (computing)	Shahrooz Feizabadi;William S. Beebee;Binoy Ravindran;Peng Li;Martin C. Rinard	2003		10.1007/978-3-540-39962-9_59	fair-share scheduling;fixed-priority pre-emptive scheduling;embedded system;real-time computing;real-time operating system;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;round-robin scheduling;scheduling	Embedded	-27.143287263333722	37.827543189046935	54188
33c447fc34ec921ddcd25f6ab1c1e143036e9706	a data flow monitoring service based on runtime verification for autosar	minimisation;rtos;automotive electronics;runtime verification;monitoring runtime automata doped fiber amplifiers multicore processing real time systems;data flow graphs;runtime;public domain software;automata;embedded systems;formal verification;monitoring;public domain software automotive electronics computerised monitoring data flow computing data flow graphs embedded systems error detection formal verification minimisation multiprocessing systems operating system kernels;autosar embedded software error detection runtime verification rtos;multicore processing;data flow computing;autosar;multiprocessing systems;error detection;operating system kernels;computerised monitoring;doped fiber amplifiers;embedded software;real time systems;time overheads data flow monitoring service runtime verification autosar error detection service multicore real time in vehicle embedded system data flow graph real time tasks expected communication pattern violation detection formal models service time overhead minimization rtos kernel embedded monitors open source rtos trampoline arm7 mcu memory overheads	This paper presents the design and implementation of an error detection service for multicore real-time in-vehicle embedded systems. The service aims at monitoring the data flows in a graph of communicating real-time tasks and detecting violation of the expected communication patterns. The service is not based on any specific system model. The monitors are automatically generated from formal models of the monitored system and the expected communication patterns. To minimize the time overhead of the service, the monitors are embedded in the RTOS kernel. The implementation targets an AUTOSAR-like platform based on the open-source RTOS Trampoline. Measures made on an ARM7 MCU show that the time and memory overheads are compatible with the stringent constraints of the application domain.	arm7;autosar;application domain;dataflow architecture;embedded system;error detection and correction;experiment;kernel (operating system);linux;mathematical optimization;memory footprint;microcontroller;multi-core processor;open-source software;overhead (computing);performance evaluation;prototype;real-time clock;real-time locating system;real-time operating system;requirement;runtime verification;scheduling (computing);sensor;system call;timed automaton;worst-case execution time	Sylvain Cotard;Sébastien Faucou;Jean-Luc Béchennec;Audrey Queudet;Yvon Trinquet	2012	2012 IEEE 14th International Conference on High Performance Computing and Communication & 2012 IEEE 9th International Conference on Embedded Software and Systems	10.1109/HPCC.2012.220	multi-core processor;embedded system;minimisation;parallel computing;real-time computing;real-time operating system;error detection and correction;embedded software;formal verification;computer science;operating system;distributed computing;automaton;runtime verification;public domain software;statistics	Embedded	-23.71194275961875	36.9024379170287	54231
9dcd3224666e9b37d2912c6376ebe9a0d0f49095	dynamic fault tolerance in dcma-a dynamically configurable multicomputer architecture	fault tolerant computer system;dynamic fault tolerance;fault tolerance fault tolerant systems costs operating systems computer architecture computer networks personal communication networks workstations high speed networks hardware;fault tolerant;application software;intermittent faults;high speed networks;real time operating system;high performance networks;pci bus;fault tolerant system;fault tolerant computing;operating system;transient faults;dynamically configurable multicomputer architecture;posix compliant unix interface dynamic fault tolerance dynamically configurable multicomputer architecture fault tolerant computer system pci bus intermittent faults transient faults application software real time operating system;posix compliant unix interface;dynamic adaptation;off the shelf;dynamic configuration	This paper introduces a new architecture for a fault-tolerant computer system which connects high-end PCs or workstations by a high-speed network. To achieve platform independence, coupling is based on the widely used PCI-bus. In contrast to commercially available fault-tolerant systems we strongly emphasize mechanisms for tolerating transient and intermittent faults. To keep hardware costs low the system is built with off-the-shelf computers and their extensions are kept as small as possible. To reduce the operational costs the system can be dynamically adapted to different demands on fault tolerance on a program-by-program basis. Adaptation is done transparently to the application software by the operating system. We use a commercially available real-time operating system with a POSIX-compliant UNIX-interface. The bandwidth of fault tolerance reaches from a non-redundant system of stand-alone computers, a master/checker configuration to a TMR-system. The high-performance network allows the system to operate as a parallel multicomputer, too.		Holger Küfner;H. Baehring	1996		10.1109/RELDIS.1996.559691	embedded system;fault tolerance;parallel computing;real-time computing;real-time operating system;computer science;operating system;software fault tolerance	Arch	-25.76567193578087	42.966865837421565	54292
a2b45eb6f3ba609509f560ee1f251745416ad016	on correcting the intrusion of tracing non-deterministic programs by software	outil logiciel;no determinismo;programa paralelo;evaluation performance;software tool;performance evaluation;evaluacion prestacion;sistema informatico;computer system;non determinism;non determinisme;herramienta controlada por logicial;systeme informatique;parallel programs;parallel program;programme parallele	Abs t r ac t . This paper describes a performance evaluation technique of parallel programs based on software tracing. The interest of the proposed method is to enable post-mortem correction of the intrusion of software tracing of non deterministic programs (probe effect), by use of RECORD -REPLAY debugging techniques. In the first phase (RECORD), a primary trace is collected with a very low perturbation. This primary trace is used to force deterministic re-executions of parallel programs during subsequent replayed phases. The method proposed in the paper takes the initial RECORD execution as a reference and collects performance traces during a replayed execution. The dates of performance traces are then corrected post mortem in order to compensate the intrusion caused by the performance tracing and by the deterministic re-execution m'echanism.	debugging;performance evaluation;probe effect;tracing (software)	Florin Teodorescu;Jacques Chassin de Kergommeaux	1997		10.1007/BFb0002721	real-time computing;computer science;operating system;algorithm	Metrics	-20.729842205690968	41.17214588586311	54356
2abbf508977f2aed93257db76164944baabf185e	agent based fault tolerance for the mobile environment	fault tolerant;fault tolerant system;mobile agent	This paper presents a fault-tolerance scheme based on mobile agents for the reliable mobile computing systems. Mobility of the agent is suitable to trace the mobile hosts and the intelligence of the agent makes it efficient to support the fault tolerance services. This paper presents two approaches to implement the mobile agent based fault tolerant service and their performances are evaluated and compared with other fault-tolerant schemes.	fault tolerance	Taesoon Park	2010	IEICE Transactions		embedded system;fault tolerance;real-time computing;computer science;mobile agent;distributed computing;mobile computing	Mobile	-29.541298316531247	46.33501161504344	54719
85b8361ac61b502dd4f414a6dc0033960155b330	using sun's java real-time system to manage behavior-based mobile robot controllers		Implementing a robot controller that can effectively manage limited resources in a deterministic, real-time manner is challenging. Behavior-based architectures that decompose autonomy into levels of intelligence are popular due to their robustness but do not provide real-time features that enforce timing constraints or support determinism. We propose an architecture and approach for using the real-time features of the Real-Time Specification for Java (RTSJ) in a behavior-based mobile robot controller to show that timing constraints affect performance. This is accomplished by extending a real-time aware architecture that explicitly enumerates timing requirements for each behavior. It is not enough to reduce latency. The usefulness of this approach is demonstrated via an implementation on Solaris 10 and the Sun Java Real-Time System (Java RTS). Experimental results are obtained using a K-team Koala robot performing path following with four composite behaviors. Experiments were conducted using several task period sets in three cases: real-time threads with the real-time garbage collector, real-time threads with the nonreal-time garbage collector, and non-real-time threads with the non-real-time garbage collector. Results show that even if latency and determinism are improved, the timing of each individual behavior significantly affects task performance.		Andrew McKenzie;Shameka Dawson;Fei Hu;Monica Anderson	2011	J. Robotics	10.1155/2011/525724	embedded system;real-time computing;simulation;java concurrency	Embedded	-27.5991811909459	37.74213811016255	54723
d1c031a2d68a5e2167dfe91cf4202f7abe2301a4	longhorn ties platform apps to core operating system	operating system	Will Microsoft's New OS Be a Developer's Dream-Come-True?	operating system	Alexander Wolfe	2004	ACM Queue	10.1145/1028893.1028907	embedded system;real-time computing;computer science;operating system	OS	-32.05405722510117	41.78790940720473	54884
86d5c020657dec5c79462aaf446e19a2b15f3574	using filtered cartesian flattening and microrebooting to build enterprise applications with self-adaptive healing	resource constraint;side effect;adaptive applications;heuristic algorithm	Building enterprise applications that can self-adapt to el iminate component failures is hard. Existing approaches for building a daptive applications exhibit significant limitations, such as requiring develop ers to manually handle healing side-effects, such as lock release, thread synchro ization, and transaction cancellation. Moreover, these techniques require develop ers to write the complex recovery logic needed to self-adapt without exceeding reso urce constraints. This paper provides two contributions to R&D on self-adapti ve applications. First, it describes a microrebooting technique called Refr esh that uses (1) feature models and a heuristic algorithm to derive a new and corr e t application configuration that meets resource constraints and (2) an app lic tion’s component container to shutdown the failed subsystems and reboot the s ubsy tem with the new component configuration. Second, we present results fro m experiments that evaluate how fast Refresh can adapt an enterprise applicati on to eliminate failed components. These results show that Refresh can reconfigure and reboot failed application subsystems in approximately 150ms. This level of performance enables Refresh to significantly improve enterprise applicat ion recovery time compared to standard system or application container rebootin g.	algorithm;enterprise software;experiment;heuristic (computer science);shutdown (computing);synchro	Jules White;Brian Dougherty;Harrison D. Strowd;Douglas C. Schmidt	2009		10.1007/978-3-642-02161-9_13	embedded system;real-time computing;computer science;distributed computing	OS	-22.40231570706479	37.94154482265009	55249
d1d3165a0131c3e32dcd5812b04f04f4fb86294c	storage management in process networks using the lexicographically maximal preimage	automatic control;extended linearization model;intelligent networks signal processing application software mathematical model communication system control automatic control array signal processing computer network management computer science electronic mail;interprocess communication;matrix representation;electronic mail;mathematics computing;memory management;kpn;lexicographically maximal preimage;application software;storage management;process network;array signal processing;mathematics computing storage management program compilers linear programming integer programming signal processing;parametric integer linear programming;integer programming;signal processing;storage capacity;polytope manipulation;computer network management;linear model;parametric integer linear programming storage management lexicographically maximal preimage compaan compiler signal processing application matlab kpn kahn process network matrix representation memory management interprocess communication elm controller derivation extended linearization model ehrhart theory polytope manipulation;linear programming;mathematical model;signal processing application;ehrhart theory;intelligent networks;computer science;elm controller derivation;kahn process network;communication system control;data flow;program compilers;matlab;compaan compiler;integer linear program;inter process communication	At the Leiden Embedded Research Center, we are developing a compiler called Compaan that automatically translates signal processing applications written in Matlab into Kahn Process Networks (KPNs). In general, these signal processing applications are data-flow intensive, requiring large storage capacities, usually represented by matrices. An important issue in Compaan is the derivation of a memory management mechanism that allows for efficient inter-process communication. This mechanism has previously been published and is called the Extended Linearization Model (ELM). The controller needed in the ELM is derived using the Ehrhart theory, leading to a computational intensive procedure. In this paper, we present a new approach to derive the ELM controller, based on the notion of Lexicographically Maximal Preimage. Using polytope manipulations and parametric integer linear programming techniques, we get less computational intensive and easier to be derived controller implementation for the ELM. The Compaan tool-chain [9] automatically transforms digital signal processing applications, written in a subset of Matlab, into Kahn Process Networks [8]. These KPNs represent the input applications in a parallel distributed way, making them suitable for mapping onto parallel architectures. These networks can be converted to VHDL and quickly synthesized to FPGAs [7] or mapped onto some parallel signal processing architecture [11] at a high level of abstraction to obtain first-order performance numbers. The process of converting a signal processing application to a Kahn Process Network is done in three steps. The first tool, i.e., MatParser, performs an array data-flow analysis that transforms Matlab code into single assignment code (SAC). The second tool, i.e., DgParser, converts the SAC into a mathematical model based on polytopes called polyhedral reduced dependence graphs (PRDG). Using polytope manipulations, the third tool, i.e., Panda, converts the PRDG into a process network (PN). Given the three steps, Compaan abstracts a Matlab program into concurrent processes that communicate with each other via -dimensional arrays. Each occurrence of this communication can be abstracted to an instance of the classical Producer/Consumer pair. If the Producer process writes data (into the array) and the Consumer process reads data (from the array) in the same order, then a FIFO between Producer and Consumer is enough in order to ensure a correct translation form Matlab to a Kahn Process Network. There can, however, be a problem when a token is needed more than once by the Consumer. As soon as a token is read from a FIFO by the Consumer process, it cannot be read by another iteration of the Consumer. Therefore, if another iteration needs the same information, it has to be send either another time by the Producer, or it has to be stored temporarily by the Consumer until all iterations that need to read the same token have taken place. This means that the token can be released from the local memory such that the corresponding location can be reused. If such situation occurs, we say that the Producer iteration has multiplicity; the token produced by that iteration is consumed by more than one Consumer iteration.	assignment (computer science);compiler;data-flow analysis;dataflow;digital signal processing;fifo (computing and electronics);field-programmable gate array;first-order predicate;high-level programming language;integer programming;inter-process communication;iteration;kahn process networks;lexicographical order;linear programming;matlab;mathematical model;maximal set;memory management;polyhedron;toolchain;vhdl	Alexandru Turjan;Bart Kienhuis	2003		10.1109/ASAP.2003.1212831	embedded system;computer architecture;parallel computing;integer programming;computer science;linear programming;electrical engineering;theoretical computer science;operating system;signal processing;automatic control;distributed computing;programming language;algorithm;algebra;inter-process communication	Embedded	-33.023775751978306	33.58182379170277	55415
2e5e24e57f094de8238b0b5504a95bc0404690a2	experiences in porting a virtual reality system to java	distributed agents;virtual reality;flexible manipulator;serialization;networking;real time application;native calls;java	Practical experience in porting a large virtual reality system from C/C++ to Java indicates that porting this type of real-time application is both feasible, and has several merits. The ability to transfer objects in space and time allows useful facilities such as distributed agent support and persistence to be added. Reflection and type comparisons allow flexible manipulations of objects of different types at run-time. Native calls and native code compilation reduce or remove the overhead of interpreting code.Problems encountered include difficulty in achieving cross-platform code portability, limitations of the networking libraries in Java, and clumsy coding practices forced by the language.	c++;compiler;computer programming;java;library (computing);machine code;overhead (computing);persistence (computer science);real-time computing;real-time transcription;software portability;virtual reality	Shaun Bangay	2001		10.1145/513867.513875	real-time computing;java concurrency;serialization;computer science;operating system;strictfp;real time java;virtual reality;programming language;java;java annotation;computer graphics (images)	PL	-25.337782629024982	36.90507770690804	55481
7500265e56ef7292069c3eab85972091001dd127	agent-based simulation system agnes* for networks modeling: review and researching	agent based simulation;simulation;mas;sensor network;wireless sensor network;agent;multi agent simulation;sensor networks;network model;program agent;distributed simulation;simulation model;agent programming	Multi-agent simulation package AGNES is presented that is designed for fault-tolerant distributed simulation of large networks. Its usability is shown on the simulation model of message delivering in a wireless sensor network.	distributed computing;fault tolerance;simulation;usability	Dmitry Podkorytov;Alexey S. Rodionov;Hyunseung Choo	2012		10.1145/2184751.2184883	embedded system;simulation;wireless sensor network;computer science;artificial intelligence;network simulation;distributed computing;network traffic simulation	Mobile	-30.083601380602314	46.371512907550645	55528
36d06f7337d75410f4361e1153f847a05e4d80b2	a context-aware multi-model remote controller for electronic home devices	sensibilidad contexto;informatica movil;batterie;modelizacion;interfase usuario;a domicilio;remote control;secondary cell;context aware;equipement menager;informatique mobile;red local;domestic appliances;red www;personal digital assistant;a domicile;interoperabilite;interoperabilidad;acumulador electroquimico;plugicial;user interface;plug and play;reseau web;audio video;automatizacion domestica;telecommande;orientado servicio;remote operation;assistant numerique personnel;intergiciel publication souscription;modelisation;battery;home network;local network;bateria;internet;intergicial editor suscriptor;zigbee;teleaccion;contexto;accumulateur electrochimique;household;contexte;menage;gui;at home;handheld device;world wide web;interface utilisateur;information gateway;open service gateway initiative;oriente service;control remoto;interoperability;sensibilite contexte;plugiciel;equipo domestico;lonworks;domotique;plug in software;mobile computing;familia;pasarela informacion;reseau local;auxiliar personal digital;passerelle d information;modeling;publish subscribe middleware;context;teleoperation;heterogeneous network;service oriented;home automation;upnp	In the past few years, household remote control products have continuously emerged, and more equipment could be controlled at remote distance. With continuous growth in the number of home remote control devices, the number of remote controllers at home is increasing. In addition, with the increase of PC and notebook computer demands, technologies for controlling computer devices or digital home appliances within the home networks have been launched, such as UPnP (Universal Plug and Play), OSGI (Open Service Gateway Initiative), HAVI (Home Audio/Video Interoperability), and Jini. Because there are too many standards of home network, it is difficult to define a universal standard conformed to others. Many researches have focused on linking the various protocols of these devices, but most of them used the Web or PDAs to control the devices. In such situation, users must rely on computer equipment and face the battery problem of handheld devices. This study aims to develop a cross-heterogeneous network remote control system. In order to relieve the problem of excessive remote controllers, we built a context-aware multi-model remote controller for electronic home devices to relieve the user of a nuisance of enormous amount of remote controllers.	access control;context awareness;control system;home automation;interoperability;laptop;mobile device;osgi;personal digital assistant;remote control;universal plug and play;user interface;world wide web;jini	Chin-Feng Lai;Yueh-Min Huang;Han-Chieh Chao	2009	The Journal of Supercomputing	10.1007/s11227-009-0313-6	local area network;universal plug and play;embedded system;interoperability;home automation;teleoperation;the internet;systems modeling;heterogeneous network;computer science;operating system;mobile device;graphical user interface;distributed computing;user interface;mobile computing;world wide web;computer security;battery;remote control	HCI	-29.942524595472186	43.639567936999704	55529
d77ea11f7099a45a0e3ce4f1873a02ab338e723e	java performance tuning - efficient and effective tuning strategies: covers java sdk 1.4, includes j2ee performance tuning (2. ed.)	performance tuning		java development kit (jdk);java platform, enterprise edition;java performance;performance tuning;software development kit	Jack Shirazi	2003			parallel computing;real-time computing;computer science;operating system	HPC	-32.08784215477388	42.663986305813005	55611
3e3d7cd7d7a94d9fe3ae95573cfd761fa775e03c	ethercom: a studyof audio processes and synchronization	operating system	Ethercom is a project which introduces many s.spects of network communication, process synchronization, and scheduling at a level suitable for an undergraduate e operating systems or networks course. The project requires a Unix workstation equipped with a microphone and speaker. The project is developed in stages starting from simple 1/0 to the audio device. The final development is two-way corn. munication over a network using lightweight processes and asynchronous 1/0. When they have completed the project, students can sit at their workstations and converse with counterparts at remote sites. Variations and enhancements for the basic project are suggested including a monitor implement ation of communication. Libraries of simplified routines for 1/0 and network communication are also available via anonymous ftp.	division by zero;microphone;operating system;scheduling (computing);synchronization (computer science);unix;workstation	Richard Rybacki;Kay A. Robbins;Steven Robbins	1993		10.1145/169070.169446	real-time computing;aes11;computer science;data synchronization;audio signal flow;frame synchronization	Security	-28.619785124133866	39.25836751118842	55618
14130a9cdb635756e0775a5f5935a3eaa54a46c1	optimistic replication for internet data services	sistema operativo;algorithm performance;optimistic replication;sistema informatico;distributed computing;simultaneidad informatica;computer system;concurrency;operating system;resultado algoritmo;algorithme reparti;performance algorithme;systeme exploitation;algoritmo repartido;systeme informatique;distributed algorithm;simultaneite informatique	We present a new replication algorithm that supports replication of a large number of objects on a diverse set of nodes. The algorithm allows replica sets to be changed dynamically on a per-object basis. It tolerates most types of failures, including multiple node failures, network partitions, and sudden node retirements. These advantages make the algorithm particularly attractive in large cluster-based data services that experience frequent failures and configuration changes. We prove the correctness of the algorithm and show that its performance is near-optimal. This report originally appeared in the 14th International Conference in Distributed Computing (DISC), October 2000, Toledo, Spain. The proceedings of the conference are published as Lecture Notes in Computer Science No. 1914, Springer Verlag.	algorithm;correctness (computer science);distributed computing;lecture notes in computer science;optimistic replication;springer (tank)	Yasushi Saito;Henry M. Levy	2000		10.1007/3-540-40026-5_20	distributed algorithm;parallel computing;real-time computing;concurrency;computer science;distributed computing	HPC	-20.568311993638382	43.396848651436116	55625
bcd8ef381e5a91a5741a32b74f31d9681aaea86a	an approach to the design of distributed systems with b amn	distributed system;abstract machine;message passing;reactive system	In this paper, we describe an approach to the design of distri buted systems with B AMN. The approach is based on the action-system formalism which provid es a framework for developing state-based parallel reactive systems. More specifically, we use the socalled CSP approach to action systems in which interaction between subsystems is by synchronised me ssage passing and there is no sharing of state. We show that the abstract machines of B may be regarded s action systems and show how reactive refinement and decomposition of action systems may be applie d to abstract machines. The approach fits in closely with the stepwise refinement method of B. We illust rate the approach by the abstract specification of an email service as a single machine and it’s subseq uent refinement into a store-and-forward network.	abstract machine;distributed computing;email;fits;refinement (computing);semantics (computer science);stepwise regression;store and forward;top-down and bottom-up design	Michael J. Butler	1997		10.1007/BFb0027291	parallel computing;real-time computing;computer science;distributed computing	Embedded	-28.6973739572636	33.65262591387236	55937
0206d1311a3590cdfc6998aaf9c47815539f196d	procol: a protocol-constrained concurrent object-oriented language	proceso secuencial comunicante;tratamiento paralelo;lenguaje programacion;sistema operativo;protocole transmission;traitement parallele;programming language;communicating sequential process;transmission message;orientado objecto;message transmission;protocolo transmision;operating system;object oriented;langage programmation;oriente objet;systeme exploitation;processus sequentiel communiquant;parallel processing;transmision mensaje;transmission protocol	Abstract   PROCOL is a simple concurrent object-oriented language supporting a distributed, incremental and dynamic object environment. Its communication is based on unidirectional messages. Objects are only bound during actual message transfer and not during the processing of the message. This short-duration object binding promotes parallelism. In communications both client and server have to be specified, either by object instance identifiers, or by type. Therefore client-server mappings may be 1−1,  n −1, or 1− n , though only one message is transffered. A novel feature of PROCOL is explicit access control: communication is subject to a protocol defined for each object. This protocol is a specification of the occurrence and sequencing of the interaction between the object and its communication partners. The use of such protocols fosters structured, safer and potentially verifiable communication between objects.		Jan van den Bos	1989	Inf. Process. Lett.	10.1016/0020-0190(89)90047-1	parallel processing;real-time computing;computer science;distributed computing;data transfer object;programming language;object-oriented programming	DB	-28.46194678412913	33.64941804060438	56577
c76a28756bb3fe575938c52d669593cdf571e69c	design of an integrated programming an operating system part i: system considerations and the monitor	operating system	The present paper considers the underlying design concepts of IBSYS/IBJOB, an integrated programming and operating system.#R##N##R##N#The historical background and over-all structure of the system are discussed.#R##N##R##N#Flow of jobs through the IBJOB processor, as controlled by the monitor, is also described.	operating system	A. Sidney Noble	1963	IBM Systems Journal	10.1147/sj.22.0153	control engineering;embedded operating system;real-time computing;computer science;engineering;operating system;computer engineering	Embedded	-28.48287141819494	38.41976475858842	56698
fef6fd549947790c28c67c16003d17706b4c331a	physics aware programming paradigm and runtime manager	text;simulation;electronic dissertation;error analysis;numerical algorithm and problems;distributed systems;application transparent adaptation		programming paradigm	Yeliang Zhang	2007			computer science;theoretical computer science;distributed computing;programming language	EDA	-28.613681292078443	46.055750971242304	56753
7c652f258166f05ae11cbd0ea37b37dc6afe4d03	web-based simulation in simjava using remote method invocation	protocols;computer languages;atherosclerosis;aging;packaging;web based simulation;java packaging educational programs material storage network servers atherosclerosis protocols aggregates aging computer languages;network servers;aggregates;remote method invocation;material storage;java development kit;educational programs;technical report;java	An investigation is underway regarding technologies to support the design, development and use of distributed, web-based simulations. As part of this investigation the Simjava simulation-support package has been extended to utilize the Remote Method Invocation facilities of the Java Development Kit (JDK) 1.1. Current efforts with Simjava are described and future research directions are outlined.	java development kit (jdk);java remote method invocation;web application;web-based simulation	Ernest H. Page;Robert L. Moose;Sean P. Griffin	1997		10.1145/268437.268543	communications protocol;packaging and labeling;real-time computing;simulation;web-based simulation;computer science;technical report;database;programming language;java;world wide web	HCI	-33.65347218595408	46.12082138499031	56801
64115c1357a1ce5701d045e42e4e174293a08ddb	rtsl: a language for real-time schedulability analysis	timing constraints;timing behavior;state space methods;timing exceptions;processor scheduling;scheduling discipline;generalized schedulability analysis technique;formal semantics;schedulability analysis;automatic generation;functional behavior;real time specification language;failure analysis;processor scheduling real time systems timing time factors algorithm design and analysis algebra scheduling algorithm dynamic scheduling state space methods failure analysis;finite state machines;scheduling algorithm;time factors;algebra;specification languages;scheduling;state based analysis;state space;real time scheduling;generalized approach;finite state machines specification languages real time systems scheduling process algebra formal logic;formal logic;finite state systems;reachable state space;process algebra;real time schedulability analysis;algorithm design and analysis;dynamic scheduling;state based analysis real time specification language real time schedulability analysis generalized approach process algebra rtsl functional behavior timing behavior timing constraints scheduling discipline formal semantics reachable state space finite state systems timing exceptions generalized schedulability analysis technique;real time systems;timing;rtsl;time constraint	This paper develops a generalized approach to schedulability analysis that is mathematically founded in a process algebra called RTSL. Within RTSL one may describe the functional behavior, timing behavior, timing constraints (or deadlines), and scheduling discipline for real-time systems. The formal semantics of RTSL then allows the reachable state space ofjnite state systems to be automatically generated and searched for timing exceptions. We provide a generalized schedulability analysis technique to perform this state-based analysis.	process calculus;real-time clock;real-time computing;scheduling (computing);scheduling analysis real-time systems;semantics (computer science);state space	Andre N. Fredette;Rance Cleaveland	1993		10.1109/REAL.1993.393489	real-time computing;computer science;theoretical computer science;operating system;distributed computing;finite-state machine;scheduling	Embedded	-26.271005354429008	34.32456359824196	56912
54cf751a9ed0f3f3b323ddc6c83e493d35f9a6c2	a compositinal proof theory for fault tolerant real-time distributed systems	distributed system;control systems;triple modular redundant;reliability;mathematics;formal specification;fault tolerant;proof theory;fault tolerant systems real time systems mathematics distributed computing control systems aircraft aerospace control patient monitoring condition monitoring hospitals;real time;distributed processing;distributed computing;hospitals;software fault tolerance;program verification;predicate;theorem proving;fault tolerant computing;compositional proof theory;aerospace control;condition monitoring;fault tolerant systems;failure hypothesis;fault tolerant real time distributed systems;patient monitoring;triple modular redundant system;triple modular redundant system compositional proof theory fault tolerant real time distributed systems failure hypothesis predicate;aircraft;real time systems;program verification distributed processing real time systems software fault tolerance fault tolerant computing reliability theorem proving formal specification	A compositional network proof theory for specifying and verifying fault tolerant real-time distributed systems is presented. Important in such systems is the failure hypothesis that stipulates the class of failures that must be tolerated. In the formalism presented, the failure hypothesis of a system is represented by a predicate which expresses how faults might transform the behavior of the system. The approach is illustrated by investigating a triple modular redundant system. >	distributed computing;real-time transcription	Henk Schepers;Rob Gerth	1993		10.1109/RELDIS.1993.393475	reliability engineering;fault tolerance;real-time computing;predicate;computer science;control system;remote patient monitoring;proof theory;formal specification;reliability;distributed computing;automated theorem proving;software fault tolerance	Theory	-25.8239194919107	35.0013124588163	56949
645f46933f49aa0ee730d7cac4af77c537a45950	the implementation of an integrated concurrency control and recovery scheme	distributed database;management system;programming language;database management;garbage collection;query languages;space use;concurrency control;data base systems;path expressions	This paper describes the implementation level design of an integrated concurrency control and recovery scheme based on the maintenance of multiple versions of data objects in a database. The concurrency control mechanism enhances parallelism by eliminating interference between retrieval and update transactions. The recovery mechanism permits efficient transaction and system recovery by keeping before-images of data objects at the page (block) level. This paper addresses the key technical problems in the implementation of such an integrated scheme. We present an efficient garbage collection algorithm for reclaiming storage space used by old versions of data objects that will no longer be accessed. We also propose an on-line backup algorithm that will permit the backup procedure to run in parallel with regular transactions. This integrated concurrency control and recovery scheme is being implemented in the LDM: the local database manager component of a distributed database management system, now being developed by Computer Corporation of America, that will support the ADAPLEX database application programming language [Chan81a, Smith81].	algorithm;angela mclean (biologist);backup;concurrency control;distributed database;garbage collection (computer science);high-level programming language;interference (communication);level design;naruto shippuden: clash of ninja revolution 3;online and offline;parallel computing;phil bernstein;programming language	Arvola Chan;Stephen Fox;Wen-Te K. Lin;Anil Nori;Daniel R. Ries	1982		10.1145/582353.582386	timestamp-based concurrency control;database theory;optimistic concurrency control;real-time computing;isolation;database transaction;rollback;database tuning;computer science;concurrency control;management system;database;distributed computing;multiversion concurrency control;non-lock concurrency control;garbage collection;programming language;serializability;distributed database;acid;database design;query language;concurrent object-oriented programming;distributed concurrency control	DB	-27.062777987723624	45.92231998486461	57183
44fd2a723f5b9529fbe72dc9e14e4a7f0b3d3d76	dynamic data driven applications systems: new capabilities for application simulations and measurements	modelizacion;distributed system;remote access;sensor system;systeme reparti;acceso remoto;storage system;analisis estadistico;real time;acces a distance;distributed computing;measurement system;bucle control;stockage donnee;probabilistic approach;dynamical system;grid;modelisation;systeme dynamique;captador medida;data storage;software architecture;dynamic data;measurement sensor;dynamic data driven application system;sistema repartido;capteur mesure;statistical analysis;rejilla;enfoque probabilista;approche probabiliste;systeme memoire;temps reel;analyse statistique;data access;grille;advanced technology;calculo repartido;tiempo real;almacenamiento datos;control loop;sistema dinamico;technologie avancee;sistema memoria;modeling;grid computing;calcul reparti;boucle commande;architecture logiciel;tecnologia avanzada	The Data Driven Applications Systems (DDDAS) concept entails “the ability to dynamically incorporate data into an executing application simulation, and in reverse, the ability of applications to dynamically steer measurement processes”, creating “application simulations that can dynamically accept and respond to ‘online’ field data and measurements and/or control such measurements”. Through the DDDAS concept, the application modeling capability, its accuracy and its efficiency, are enhanced over the traditional computational modeling methods, by complementing and augmenting the computational modeling with dynamic data inputs, which can be dynamically incorporated into the computation at runtime. In reverse, the ability of the executing application to steer the measurement processes, and conduct targeted measurements guided by the executing application, can result into more efficient and more effective measurement processes. By integrating the computational and measurement aspects of an application in a dynamic feed-back loop, DDDAS changes the paradigm of the traditionally distinct computational and measurement processes, and leads to a unification of the computing and instrumentation platforms of an application. Together with presenting examples of new capabilities in many important application areas, the presentation will also discuss the DDDAS computational model representing the unification of measurement and computational platforms, the new measurement capabilities enabled through DDDAS, and in particular in architecting and dynamically managing sensor networks, and the systems software needs for supporting the unified measurement and computational platforms in DDDAS environments.	computation;computational model;computer simulation;dynamic data driven applications systems;feedback;programming paradigm;run time (program lifecycle phase);software prototyping;unification (computer science)	Frederica Darema	2005		10.1007/11428848_79	data access;embedded system;software architecture;simulation;dynamic data;computer science;control system;artificial intelligence;dynamical system;computer data storage;distributed computing;grid;grid computing	HPC	-28.06156182989346	42.49048484200339	57638
af7766bb7c151a83f97d1c2c9c270631462d1137	haskell 98: basic input/output	input output	7.1 Standard I/O Functions 977.2 Sequencing I/O Operations 997.3 Exception Handling in the I/O Monad 100	haskell;input/output	Simon L. Peyton Jones	2003	J. Funct. Program.	10.1017/S0956796803000911	input/output;real-time computing;computer science	PL	-26.820050089501137	36.78674907192002	57707
3168d67fd1935507d67e626a91943d6aadaa81be	private memory allocation analysis for safety-critical java	real time java;safety critical systems;real time systems	Safety-critical Java (SCJ) avoids garbage collection and uses a scope based memory model. This memory model is based on a restricted version of RTSJ [2] style scopes. The scopes form a clear hierarchy with different lifetimes. Therefore, references between objects in different scopes are only allowed from objects allocated in scopes with a shorter lifetime to objects allocated in scopes with a longer lifetime.  To ensure memory safety, programmers are required to either manually annotate the application with complex annotations, rely on a runtime test of each reference assignment, or statically analyze all reference assignments and avoid runtime checks when all assignments are proven to be correct. A violation of the assignment rule at runtime leads to an unchecked exception. For safety-critical code that needs to be certified, runtime exceptions must be avoided and the absence of illegal reference assignments needs to be proven. In this paper we present a static program analysis tool that automates the proof that no illegal assignments occur.	exception handling;garbage collection (computer science);memory management;memory model (programming);memory safety;object lifetime;programmer;prototype;real life;real time java;requirement;run time (program lifecycle phase);scalability;static program analysis	Andreas Engelbredt Dalsgaard;René Rydhof Hansen;Martin Schoeberl	2012		10.1145/2388936.2388939	embedded system;real-time computing;computer science;operating system;real time java;life-critical system;programming language	PL	-21.710967460350822	35.59370779160841	58098
f6f04b04e77615a2e331e8b9e7bafe5c944805bd	mobile agents with java: the aglet api	electronic commerce;application program interface;conceptual design;mobile agent system;mobile agent;java language	Java, the language that changed the Web overnight, offers some unique capabilities that are fueling the development of mobile agent systems. In this article we will show what exactly it is that makes Java such a powerful tool for mobile agent development. We will also draw attention to some shortcomings in Java language systems that have implications for the conceptual design and use of Java-based mobile agent systems. Last, but not least, we will introduce the aglet – a Java-based agile agent. We will give an overview of the aglet and, its application programming interface, and present a real-world example of its use in electronic commerce.	agile software development;aglets;application programming interface;e-commerce;event-driven programming;interoperability;java applet;mobile agent;operating system;programming model;tsutomu kanai award;world wide web	Danny B. Lange;Mitsuru Oshima	1998	World Wide Web	10.1023/A:1019267832048	e-commerce;java api for xml-based rpc;real-time computing;jsr 94;application programming interface;computer science;strictfp;conceptual design;mobile agent;database;real time java;programming language;java;world wide web	HCI	-33.34286642472835	42.46842115599634	58139
1ab0f399720d584abdc0154570bb9bca6d0d51cc	throughput performance of the activemq jms server	large scale system;java message service;publish subscribe;software component;high performance	Communication among distributed software components according to the publish/subscribe principle is facilitated by the Java messaging service (JMS). JMS can be used as a message routing platform if the subscribers install filter rules on the JMS server However, it is not clear whether its message throughput is sufficient to support large-scale systems. In this paper, we investigate the capacity of the high performance JMS server implementation ActiveMQ. In contrast to other studies, we focus on the message throughput in the presence of filters and show that filtering reduces the performance significantly. We present a model for the message processing time at the server and validate it by measurements. This model takes the number of installed filters and the replication grade of the messages into account and predicts the overall message throughput for specific application scenarios.	apache activemq;component-based software engineering;distributed computing;java message service;publish–subscribe pattern;routing;server (computing);throughput	Robert Henjes;Daniel Schlosser;Michael Menth;Valentin Himmler	2007		10.1007/978-3-540-69962-0_10	real-time computing;computer science;component-based software engineering;database;publish–subscribe pattern;programming language;world wide web	Metrics	-32.22355102433589	44.49527843148071	58192
5979019c1e797ac12a6a2a60913b880b44ca3a19	avoiding message-dependent deadlock in network-based systems on chip	intellectual property;network on chip;dependence graph;deadlock avoidance;peer to peer streaming;system on chip;cache coherence;flow control	ion, and flexible network configuration,” IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, vol. 24, no. 1, pp. 4–17, 2005. [4] M. Sgroi, M. Sheets, A. Mihal, et al., “Addressing the systemon-a-chip interconnect woes through communication-based design,” in Proceedings of the 38th Design Automation Conference (DAC ’01), pp. 667–672, Las Vegas, Nev, USA, June 2001. [5] M. Coppola, S. Curaba, M. D. Grammatikakis, G. Maruccia, and F. Papariello, “OCCN: a network-on-chip modeling and simulation framework,” in Proceedings of Design, Automation and Test in Europe Conference and Exhibition (DATE ’04), vol. 3, pp. 174–179, Paris, France, February 2004. Andreas Hansson et al. 9 [6] T. Bjerregaard, S. Mahadevan, R. G. Olsen, and J. Sparsø, “An OCP compliant network adapter for GALS-based SoC design using the MANGO network-on-chip,” in Proceedings of International Symposium on System-on-Chip (SOC ’05), pp. 171– 174, Tampere, Finland, November 2005. [7] D. Wingard, “Socket-based design using decoupled interconnects,” in Interconnect-Centric Design for SoC and NoC, J. Nurmi, H. Tenhunen, J. Isoaho, and A. Jantsch, Eds., Kluwer, Dordrecht, The Netherlands, 2004. [8] U. Y. Ogras, J. Hu, and R. Marculescu, “Key research problems in NoC design: a holistic perspective,” in Proceedings of the 3rd IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES, ISSS ’05), pp. 69–74, Jersey City, NJ, USA, September 2005. [9] G.-M. Chiu, “The odd-even turn model for adaptive routing,” IEEE Transactions on Parallel and Distributed Systems, vol. 11, no. 7, pp. 729–738, 2000. [10] J. Hu and R. Marculescu, “Exploiting the routing flexibility for energy/performance aware mapping of regular NoC architectures,” in Proceedings of Design, Automation and Test in Europe Conference and Exhibition (DATE ’03), pp. 688–693, Munich, Germany, March 2003. [11] J. Hu and R. Marculescu, “DyAD—smart routing for networks-on-chip,” in Proceedings of the 41st Design Automation Conference (DAC ’04), pp. 260–263, San Diego, Calif, USA, June 2004. [12] Y. H. Song and T. M. Pinkston, “A progressive approach to handling message-dependent deadlock in parallel computer systems,” IEEE Transactions on Parallel and Distributed Systems, vol. 14, no. 3, pp. 259–275, 2003. [13] T. T. Ye, L. Benini, and G. de Micheli, “Packetized on-chip interconnect communication analysis for MPSoC,” in Proceedings of Design, Automation and Test in Europe Conference and Exhibition (DATE ’03), pp. 344–349, Munich, Germany, March 2003. [14] F. Pétrot, A. Greiner, and P. Gomez, “On cache coherency and memory consistency issues in NoC based shared memory multiprocessor SoC architectures,” in Proceedings of the 9th EUROMICRO Conference on Digital System Design: Architectures, Methods and Tools (DSD ’06), pp. 53–60, Dubrovnik, Croatia, August-September 2006. [15] AMBA AXI Protocol Specification, ARM, June 2003. [16] M. Bekooij, R. Hoes, O. Moreira, et al., “Dataflow analysis for real-time embedded multiprocessor system design,” in Dynamic and Robust Streaming in and between Connected Consumer-Electronics Devices, P. van der Stok, Ed., Kluwer, Dordrecht, The Netherlands, 2005. [17] E. Beigné, F. Clermidy, P. Vivet, A. Clouard, and M. Renaudin, “An asynchronous NOC architecture providing low latency service and its multi-level design framework,” in Proceedings of International Symposium on Asynchronous Circuits and Systems (ASYNC ’05), pp. 54–63, New York, NY, USA, March 2005. [18] M. Millberg, E. Nilsson, R. Thid, and A. Jantsch, “Guaranteed bandwidth using looped containers in temporally disjoint networks within the Nostrum network on chip,” in Proceedings of Design, Automation and Test in Europe Conference and Exhibition (DATE ’04), vol. 2, pp. 890–895, Paris, France, February 2004. [19] S. Stergiou, F. Angiolini, S. Carta, L. Raffo, D. Bertozzi, and G. de Micheli, “×pipes lite: a synthesis oriented design library for networks on chips,” in Proceedings of Design, Automation and Test in Europe (DATE ’05), vol. 2, pp. 1188–1193, Munich, Germany, March 2005. [20] P. Guerrier, “Un réseau d’interconnexion pour systémes intégrés,” Ph.D. dissertation, Universite Paris VI, Paris, France, 2000. [21] Arteris, “A comparison of network-on-chip and busses,” White paper, 2005. [22] S. Murali and G. de Micheli, “An application-specific design methodology for STbus crossbar generation,” in Proceedings of Design, Automation and Test in Europe (DATE ’05), vol. 2, pp. 1176–1181, Munich, Germany, March 2005. [23] SonicsMX Datasheet, Sonics, 2005, http://www.sonicsinc .com/. [24] Y. Durand, C. Bernard, and D. Lattard, “FAUST: on-chip distributed architecture for a 4g baseband modem SoC,” in Proceedings of IP Based SoC Design Conference and Exhibition (IPSOC ’05), Grenoble, France, December 2005. [25] A. Tanenbaum, Computer Networks, Prentice-Hall, Upper Saddle River, NJ, USA, 1996. [26] I. Saastamoinen, M. Alho, and J. Nurmi, “Buffer implementation for Proteo networks-on-chip,” in Proceedings of International Symposium on Circuits and Systems (ISCAS ’03), pp. 113–116, Bangkok, Thailand, May 2003. [27] B. Gebremichael, F. Vaandrager, Z. Miaomiao, K. Goossens, E. Rijpkema, and A. Rădulescu, “Deadlock prevention in the Æthereal protocol,” in Proceedings of the 13th IFIP WG 10.5 Advanced Research Working Conference Correct Hardware Design and Verification Methods (CHARME ’05), pp. 345–348, Saarbrücken, Germany, October 2005. [28] Z. Lu, B. Yin, and A. Jantsch, “Connection-oriented multicasting in wormhole-switched networks on chip,” in Proceedings of IEEE Computer Society Annual Symposium on Emerging VLSI Technologies and Architectures, pp. 205–210, Karlsruhe, Germany, March 2006. [29] S. Murali, P. Meloni, F. Angiolini, et al., “Designing messagedependent deadlock free networks on chips for applicationspecific systems on chips,” in Proceedings of IFIP International Conference on Very Large Scale Integration, pp. 158–163, Nice, France, October 2006. [30] M. Gerla and L. Kleinrock, “Flow control: a comparative survey,” IEEE Transactions on Communications Systems, vol. 28, no. 4, pp. 553–574, 1980. [31] P. Bhojwani and R. Mahapatra, “Interfacing cores with onchip packet-switched networks,” in Proceedings of 16th International Conference on VLSI Design, pp. 382–387, Las Vegas, Nev, USA, June 2003. [32] K. Goossens, J. Dielissen, and A. Rădulescu, “Æthereal network on chip: concepts, architectures, and implementations,” IEEE Design and Test of Computers, vol. 22, no. 5, pp. 414–421, 2005. [33] D. E. Culler, J. P. Singh, and A. Gupta, Parallel Computer Architecture: A Hardware/Software Approach, Morgan Kaufmann Publishers, San Francisco, Calif, USA, 1999. [34] R. Sivaram, R. Kesavan, D. K. Panda, and C. B. Stunkel, “Where to provide support for efficient multicasting in irregular networks: network interface or switch?” in Proceedings of International Conference on Parallel Processing (ICPP ’98), pp. 452–459, Minneapolis, Minn, USA, August 1998. [35] R. V. Boppana, S. Chalasani, and C. S. Raghavendra, “Resource deadlocks and performance of wormhole multicast routing algorithms,” IEEE Transactions on Parallel and Distributed Systems, vol. 9, no. 6, pp. 535–549, 1998. [36] G. Kahn, Information Processing, North-Holland, New York, NY, USA, 1974, ch. The Semantics of a Simple Language for Parallel Processing.	arm architecture;algorithm;automated x-ray inspection;baseband;cache coherence;computer networks (journal);computer architecture;computer-aided design;connection-oriented communication;consistency model;crossbar switch;daniel goossens;data-flow analysis;dataflow;datasheet;deadlock;design automation conference;design automation and test in europe;distributed computing;document structure description;electrical connection;embedded system;end-to-end encryption;faust;holism;holographic principle;integrated circuit;interaction;international federation for information processing;kahn process networks;lu decomposition;level design;lock (computer science);mpsoc;maniac mansion;modem;multicast;multiprocessing;network interface controller;network on a chip;network packet;nice (programming language);open core protocol;packet switching;parallel computing;parallel processing (dsp implementation);peer-to-peer;r language;real-time clock;routing;shared memory;simulation;system on a chip;systems design;very-large-scale integration	Andreas Hansson;Kees G. W. Goossens;Andrei Radulescu	2007	VLSI Design	10.1155/2007/95859	system on a chip;embedded system;cache coherence;parallel computing;real-time computing;computer science;operating system;flow control;distributed computing;network on a chip;deadlock prevention algorithms;intellectual property;computer network	EDA	-25.5428512292663	40.40744366197012	58599
c6eb63fd5c67049cce6d5e4be065011b42ef439a	temporal patterns and properties in multiple-flow interactions	distributed system;systeme reparti;multimedia;analisis estructural;prension;gripping;sistema repartido;internet traffic;internet;elephants;user behaviour;temporal pattern;temporal properties;temporal analysis;prehension;analyse structurale;structural analysis;structure analysis	It is widely recognized that today’s Internet traffic is mostly carried by a relatively small number of elephant flows while mice flows constitute up to 80% of all active flows at any given moment in time. Although there are many research works that perform structural analysis of flows based on their size, rate, and lifespan, such analysis says very little about temporal properties of interactions among multiple flows originating from different applications. This paper focuses on temporal analysis of flows in attempt to grasp properties and patterns of flows that are related to application and user behaviour and can be captured only in the temporal view of traffic.		Marat Zhanikeev;Yoshiaki Tanaka	2006		10.1007/11876601_10	simulation;computer science;structural analysis;law	Metrics	-29.753940065690344	36.66108810623355	58631
c3204f6e114aaa08cc39235ec8550f886911d3f4	persistence in e revisited - implementation experiences	data access;programming language;virtual machine	This paper discusses the design and implementation of the E Persistent Virtual Machine (EPVM), an interpreter that provides support for persistent data access in the current version of the E programming language. Included are descriptions of both the EPVM interface and the major implementation tactics employed within EPVM. A novel pointer swizzling scheme that has been investigated in the context of E and EPVM is also described. Finally, a performance analysis of the key EPVM primitives is presented.	data access;persistence (computer science);pointer (computer programming);pointer swizzling;programming language;virtual machine	Daniel T. Schuh;Michael J. Carey;David J. DeWitt	1990			computer architecture;programming language;programming language implementation;data access;persistence (computer science);virtual machine;computer science	Arch	-22.532962439579112	35.181764002663265	59023
bc37ee4fbf39a95a76986d9e6143c2713876bfbb	notions of fairness for synchronous fork join nets				M. Chadili;Irène Guessarian	1987				EDA	-28.457741628268437	34.60295643576832	59141
b41c7fac4dd4c1d9f52c79e0dc43bfc99d625f24	rule-based management of distributed operating systems	distributed system;networks;name space;rule based;resolution functions;distributed operating system;client server;operating system;name resolution;distributed systems;dynamic adaptation;address space	This paper presents a paradigm for managing distributed operating system using a rule-based architecture. Recent trends have led to the structuring of operating systems, particularly those for distributed systems, as a set of microkernels with much of the system functionality being provided by a set of servers operating in user space. The proliferation of client-server based systems can easily lead to a set of independent, non-cooperating servers, with no common technique for management. The operation of each server is often hard-coded into the server, with no facility for dynamic adaptation and management. A general-purpose, rule-based approach to server control fills the need for management and can even eliminate the need for some services.	client–server model;distributed computing;distributed operating system;general-purpose markup language;hard coding;logic programming;microkernel;programming paradigm;server (computing);user space	Mark D. Wood	1992		10.1145/506378.506429	embedded operating system;middleware;real-time computing;computer science;database;distributed computing;distributed system security architecture	OS	-28.818501864125185	45.47120871088513	59178
28ed50300f22712b4dfecb9adf30c2002b5a6091	robust and speculative byzantine randomized consensus with constant time complexity in normal conditions	speculative execution algorithm randomized byzantine consensus constant time complexity asynchronous distributed system worst case complexity normal system condition crash failure;randomized consensus;randomised algorithms;parallel programming;fault tolerant computing;computational complexity;asynchronous model;normal situations;message passing;randomised algorithms computational complexity fault tolerant computing parallel programming;algorithm design and analysis approximation methods reliability proposals time complexity computer crashes;speculative algorithm;speculative algorithm randomized consensus message passing normal situations asynchronous model	Randomized Byzantine Consensus can be an interesting building block in the implementation of asynchronous distributed systems. Despite its exponential worst-case complexity, which would make it less appealing in practice, a few experimental works have argued quite the opposite. To bridge the gap between theory and practice, we analyze a well-known state-of-the-art algorithm in normal system conditions, in which crash failures may occur but no malicious attacks, proving that it is fast on average. We then leverage our analysis to improve its best-case complexity from three to two phases, by reducing the communication operations through speculative executions. Our findings are confirmed through an experimental validation.	best, worst and average case;byzantine fault tolerance;distributed computing;randomized algorithm;speculative execution;time complexity;worst-case complexity	Bruno Vavala;Nuno Ferreira Neves	2012	2012 IEEE 31st Symposium on Reliable Distributed Systems	10.1109/SRDS.2012.62	message passing;real-time computing;average-case complexity;computer science;quantum byzantine agreement;theoretical computer science;worst-case complexity;distributed computing;programming language;computational complexity theory	Embedded	-22.176539147455518	44.73513126878189	59210
673ef9719cd5b4312ab539fe8504d07ff6c081fd	nasa global change master directory: an implementation of asynchronous management protocol in a heterogeneous distributed environment	databases;earth science repository;protocols;asynchronous management protocol;replicated federated database;aerospace engineering;heterogeneous systems;design and development;component;jdbc;local autonomy;database transparency;nasa global change master directory;object oriented system architecture;local system;heterogeneous distributed environment;environmental science computing;computer architecture;object oriented systems;asynchronous transactions;geoscience;asynchronous transactions nasa global change master directory asynchronous management protocol heterogeneous distributed environment earth science repository global climate change gcmd replicated federated database local autonomy database reliability database transparency object oriented system architecture java rmi remote method invocation jdbc internet distributed object management;distributed objects;internet;geophysics computing;design and implementation;distributed environment;object oriented;global climate change;remote method invocation;rmi;application program interfaces;distributed object management;interface;environmental science computing scientific information systems distributed object management geophysics computing replicated databases software reliability java application program interfaces internet;java rmi;space technology;interoperability;computer science;distributed;gcmd;nasa;environmental management;software reliability;replicated databases;scientific information systems;nasa protocols java databases space technology computer architecture environmental management computer science aerospace engineering geoscience;database reliability;global change;java	The Global Change Master Directory (GCMD) is an earth science repository that specifically tracks research data on global climatic change. The GCMD is migrating from a centralized architecture to a globally distributed replicated heterogeneous federated system. One of the greatest challenges facing database research is the integration of heterogeneous systems without compromising the local autonomy, reliability and transparency of the various databases that are participating in the integration. This paper discusses these challenges in the context of the design and implementation of the next version of the GCMD software (Version 8.0). The proposed system has been designed and developed using an object-oriented system architecture based on Java, RMI (Remote Method Invocation) and JDBC. This system enables other sources to be integrated into the GCMD system, with limited changes to the local system itself. This paper describes the components of the GCMD system and addresses the issues of heterogeneity, distribution and autonomy.	autonomy;blocking (computing);byte;c++;centralized computing;database;global change;input/output;integrated development environment;internationalized domain name;jdbc;java remote method invocation;lazy evaluation;middleware;optimistic replication;programming language;programming tool;relational database;scalability;serializability;serialization;server (computing);software propagation;systems architecture;xml	Kishan Nagendra;Omran A. Bukhres;Srinivasan Sikkupparbathyam;Marcelo Areal;Zina Ben-Miled;Lola Olsen;Chris Gokey;David Kendig;Tom Northcutt;Rosy Cordova;Gene Major	2001		10.1109/DOA.2001.954079	computer science;database;distributed computing;world wide web	DB	-33.04867897414543	44.32383417935752	59394
61edc924feba170d44e12d329d10e8ac49fead19	jr: flexible distributed programming in an extended java	virtual machine;concurrent object oriented programming;programming language;sr;java programming;dynamical processes;distributed programs;object oriented programming;support system;concurrency;asynchronous communication;remote method invocation;java	Java provides a clean object-oriented programming model and allows for inherently system-independent programs. Unfortunately, Java has a limited concurrency model, providing only threads and remote method invocation (RMI).The JR programming language extends Java to provide a rich concurrency model, based on that of SR. JR provides dynamic remote virtual machine creation, dynamic remote object creation, remote method invocation, asynchronous communication, rendezvous, and dynamic process creation. JR's concurrency model stems from the addition of operations (a generalization of procedures) and JR supports the redefinition of operations through inheritance. JR programs are written in an extended Java and then translated into standard Java programs. The JR run-time support system is also written in standard Java.This paper describes the JR programming language and its implementation. Some initial measurements of the performance of the implementation are also included.	concurrency (computer science);distributed computing;java remote method invocation;object lifetime;programming language;programming model;run time (program lifecycle phase);subroutine;virtual machine	Aaron W. Keen;Tingjian Ge;Justin T. Maris;Ronald A. Olsson	2004	ACM Trans. Program. Lang. Syst.	10.1145/982158.982162	active object;java api for xml-based rpc;method;real-time computing;jsr 94;java concurrency;concurrency;computer science;virtual machine;java modeling language;asynchronous communication;strictfp;distributed computing;real time java;programming language;object-oriented programming;java;generics in java;scala;concurrent object-oriented programming;java applet;java annotation;non-blocking i/o	PL	-25.791503885982788	36.08700901626983	59423
49f4cb49466d5806c98890fb46c888639e8de0df	the instrumentation of multics	measurement tool	This paper reports an array of measuring tools devised to aid in the implementation of a prototype computer utility. These tools include special hardware clocks and data channels, general purpose programmed probing and recording tools, and specialized measurement facilities. Some particular measurements of interest in a system which combines demand paging with multi-programming are described in detail. Where appropriate, insight into effectiveness (or lack thereof) of individual tools is provided.	clock signal;computer multitasking;multics;paging;prototype;utility computing	Jerome H. Saltzer;John Gintell	1969		10.1145/961053.961104	embedded system;simulation;computer hardware;computer science	HPC	-24.919510038149923	38.76593370573041	59825
afba3cb29c6de571171465eaaa144b8868273fd2	distributed election in complete networks	reseau ordinateur;computer network;expected message complexity;distributed election algorithms;theory;teoria;red ordenador;article;synchronous complete networks;theorie;asynchronous complete networks	An improved version of Afek and Gafniu0027s synchronous algorithm for distributed election in complete networks is given and anO(n) expected message complexity is shown.	algorithm	Mee Yee Chan;Francis Y. L. Chin	1988	Distributed Computing	10.1007/BF01788564	computer science;theoretical computer science;distributed computing;theory;algorithm;computer network	Theory	-21.689717007437505	43.71702444959764	59831
8dcbf85cf07327ec5b61d0606d1911841dfede2b	y-branches: when you come to a fork in the road, take it	program control structures;load imbalance;clustered processors;fault tolerant computing;inter pe communication;tolerance analysis;instruction replication;sampling methods frequency electric breakdown process control yarn registers delay processor scheduling dynamic scheduling parallel architectures;fault tolerant computing tolerance analysis sampling methods program control structures probabilistic logic;probabilistic logic;sampling methods;instruction distribution;instructions per cycle;statistical frequency breakdown conditional branch statistical sampling y branch short circuit loop iteration	In this paper, we study the effects of manipulating the architected direction of conditional branches. Through the use of statistical sampling, we .nd that about 40% of all dynamic branches and about 50% of mispredicted branches do not affect correct program behavior when forced down the incorrect path. We call such branches Y-branches.To further examine this unexpected phenomenon, we provide a characterization of the coding constructs that give rise to such branches. Examples of such coding constructs include short-circuits and ineffectual loop iterations. We provide a statistical breakdown of the frequency of these branches and their constructs. Finally, we suggest some techniques for exploiting this behavior, particularly when it results from short-circuit constructs.	approximation;instruction pipelining;iteration;pipeline (computing);sampling (signal processing);short-circuit evaluation;well-formed formula	Nicholas J. Wang;Michael Fertig;Sanjay J. Patel	2003		10.1109/PACT.2003.1238002	sampling;parallel computing;real-time computing;computer science;theoretical computer science;operating system;probabilistic logic;instructions per cycle	SE	-20.003173926013034	39.224779550806204	59955
a37db02a6309f2f1a804d05b0e6f4276281ed2db	an economical implementation of the high level real-time language pearl on microcomputers: intel rmx86-pearl	concurrent real time language;real time;intel;rmx86;pearl	Abstract#R##N##R##N#We report on an implementation of the concurrent high level real-time language PEARL on an Intel 8086-based microcomputer. After a short introduction to the PEARL language emphasis is placed on the description of the method of implementation, one of the goals of which was to use standard high level languages and an existing real-time operating system as far as possible. This way an economical, but nevertheless efficient, implementation was achieved.	microcomputer;real-time transcription	P. Heine;F. Kaiser	1984	Softw., Pract. Exper.	10.1002/spe.4380140409	computer architecture;parallel computing;real-time computing;computer science;programming language;pearl	PL	-23.67589285762693	34.582958890174545	60115
0568f9490e74ff872fc42eeb11068626a8e84217	redundant logic elimination in network functions		In current NFV ecosystem, most software NFs delivered by NF vendors tend to be monolithic with multiple features. In runtime, an NF is configured with a subset of its features turned on/off. By our code analysis and primary test, we find that some of the (runtime) unused features are executed silently, which wastes CPU cycles and memory. We propose to use program analysis techniques to eliminate runtime redundant logic in NF code so that the NF performance can be accelerated. We prototype our idea and test it on Snort to show the feasibility.	central processing unit;ecosystem;network function virtualization;new foundations;noise figure;prototype;snort;static program analysis	Bangwen Deng;Wenfei Wu	2018		10.1145/3234200.3234219	parallel computing;program analysis;distributed computing;software;network functions virtualization;computer science;static program analysis;instruction cycle	Security	-20.57961073607701	36.668789712068225	60127
ca9be33b021c22d306a5dd5ed419d9ee754290ac	consistency in distributed systems	distributed system;reaction time	Executions. To specify consistency models, we use abstract executions. The basic idea is very simple: 1. A consistency model is formalized as a set of abstract executions, which are mathematical structures (visualized using graphs) consisting of operation events (vertices) and relations (edges), subject to conditions. Abstract executions capture “the essence” of an execution (that is, what operations occurred, and how those operations are related), without including low-level details (such as exactly what messages were sent when and where). 2. We describe what it means for a concrete execution of a system to correspond to an abstract execution. 3. We say that a system is correct if all of its concrete executions correspond to some abstract execution of the consistency model. The advantage of this approach is that we can separately (1) determine whether programs are correct for a given consistency model, without needing to know details about the system architecture, and (2) determine whether a system correctly implements some consistency model, without knowing anything about the program that is running on it. Consistency models can be thought of as a contract between the programmer and the system implementor. For sequential consistency, we define abstract executions in two steps. First, we define histories: Definition 14. A history is a tuple (Evt, pid, obj, op, rval, po) where – Evt is a set of events. – pid : Evt→ Pid describes the process on which the event happened. – po ⊆ Evt × Evt is a partial order (called process order) that describes the order in which events happened on each process. We require that po is a union of total orders for each process, that is, there exist total orders pop ⊆ (pid−1(p)× pid−1(p)) such that po = ⋃ p∈Pid pop. – obj, op, rval are event attributes (i.e. functions Evt) describing the details of the operation: each event e ∈ Evt represents an operation op(e) ∈ Optype(obj(e)) on an object obj(e) ∈ Obj, which returns the value rval(e) ∈ Valtype(obj(e)). Now we define sequentially consistent abstract executions:	algorithm;asynchronous circuit;asynchronous system;cap theorem;cloud computing;consistency model;correctness (computer science);diagram;distributed computing;eventual consistency;lecture notes in computer science;linearizability;paxos (computer science);programmer;relevance;replication (computing);sequential consistency;springer (tank);strong consistency;switzerland;systems theory;weak consistency	Sebastian Burckhardt	2014		10.1007/978-3-319-28406-4_4	consistency model;release consistency;sequential consistency;strong consistency	SE	-26.796991449770353	33.15462613434135	60242
b924de0becf7884280b56dc83c203d99b4d1f10f	archictecture and performance of java-based distributed object models: corba vs rmi	distributed system;corba;software architecture;distributed objects;remote method invocation;performance model;distributed systems;performance modeling;software architectures;distributed object models	This paper presents a comprehensive comparison of thearchitectural differences and similarities of the two most popularJava-based distributed object models: RMI and CORBA. Performanceand timing issues related to the CORBA and RMI architecturesare also considered. The following aspects are studied for clientserver applications, on Sun UltraSparcs under Solaris 2.5.1 andPentium II under Windows NT 4.0: response time for method invocationwithout parameters as well as with variable number of parameters;response time for applet clients, and response time for variablenumber of clients requesting the same service. The goal is toprovide a reference framework that supports the selection ofeither mechanism for the development of web-based distributedreal-time applications: chat programs, interactive games, sharedboards, etc.	access time;applet;client–server model;collaborative software;common gateway interface;common object request broker architecture;context switch;data structure;distributed computing;distributed object;emoticon;hypertext transfer protocol;internet;java remote method invocation;mega man network transmission;middleware;multitier architecture;name binding;operating system;overhead (computing);programming paradigm;real-time computing;request–response;response time (technology);scalability;scheduling (computing);server (computing);subroutine;vii;web application;windows nt 4.0	César Muñoz;Janusz Zalewski	2001	Real-Time Systems	10.1023/A:1011143320492	interoperable object reference;software architecture;real-time computing;computer science;operating system;dynamic invocation interface;common object request broker architecture;distributed computing;distributed object	OS	-31.898332138388387	43.66574900591297	60443
026cbae9f7d28cedd477fe349ba71d41d645ee7a	controlling fragmentation and space consumption in the metronome, a real-time garbage collector for java	real time;fragmentation;compaction;compact space;garbage collector;garbage collection;software engineering	Now that the use of garbage collection in languages like Java is becoming widely accepted due to the safety and software engineering benefits it provides, there is significant interest in applying garbage collection to hard real-time systems. Past approaches have generally suffered from one of two major flaws: either they were not provably real-time, or they imposed large space overheads to meet the real-time bounds.Our previous work [3] presented the Metronome, a mostly non-copying real-time collector. The Metronome achieves worst-case pause times of 6 milliseconds while maintaining consistent mutator CPU utilization rates of 50% with only 1.5-2.1 times the maximum heap space required by the application, which is comparable with space requirements for stop-the-world collectors.However, that algorithm assumed a constant collection rate, ignored program-dependent characteristics, and lacked a precise specification for when to trigger collection or how much defragmentation to perform. This paper refines the model by taking into account program properties such as pointer density, average object size, and locality of object size. This allows us to bound both the time for collection and consequently the space overhead required much more tightly. We show experimentally that most parameters usually are not subject to large variation, indicating that a small number of parameters will be sufficient to predict the time and space requirements accurately.Our previous work also did not present the details of our approach to avoiding and undoing fragmentation. In this paper we present a more detailed analysis of fragmentation than in previous work, and show how our collector is able to bound fragmentation to acceptable limits.	algorithm;benchmark (computing);best, worst and average case;central processing unit;experiment;fork (software development);fragmentation (computing);garbage collection (computer science);java;locality of reference;memory management;mutator method;overhead (computing);pointer (computer programming);real-time clock;real-time computing;real-time locating system;real-time transcription;requirement;software engineering;tracing garbage collection;user interface	David F. Bacon;Perry Cheng;V. T. Rajan	2003		10.1145/780732.780744	real-time computing;simulation;real-time operating system;computer science;garbage collection;programming language;algorithm	PL	-20.52609998568327	35.811368090274215	60766
9f8b70280dc0155a71d68f9a95a68803585ddd8b	madss: a multi-agent based distributed scripting system	developpement logiciel;distributed system;outil logiciel;metodo adaptativo;software tool;systeme unix;multiagent system;sistema experto;systeme reparti;multi agent system;software integration;agent based;unix system;methode adaptative;scenario;distributed programming integrated software unix multi agent systems;software architecture;multi agent systems;sistema repartido;argumento;desarrollo logicial;software tools software systems application software software performance java computer languages cities and towns multiagent systems control systems user interfaces;distributed programming;forth;adaptive method;algorithme reparti;software development;script;control flow;integrated software;algoritmo repartido;control flows multi agent based distributed scripting system madss software integration unix tool integration nonunix systems unix expert users scripting language unix shell distributed heterogeneous software network environment;sistema unix;systeme expert;sistema multiagente;herramienta software;distributed algorithm;unix;architecture logiciel;scripting language;langage script;systeme multiagent;expert system	One important advantage of software integration constructing a project without platform and machine boundaries. In this study, we propose a scripting mechanism to integrate UNIX tools and other software under non-UNIX systems into a new system. Based on our scripting mechanism, we assumed UNIX experts as the system users. A UNIX expert would be adaptive on this study, because the scripting language extended from a UNIX shell. In order to demonstrate this study, we then propose a multi-agent distributed scripting system (MADSS). MADSS provides a fast and a convenient way for a UNIX expert to combine the heterogeneous software distributed on a network environment. A multi-agent system was employed to be an operational environment of this study. The agents in our system could perform the distributed scripts written by UNIX users through several proposed control flows, for examples parallel, circular trip, and forth_and_back.		Jim-Min Lin;Zeng-Wei Hong;Guo-Ming Fang	2002		10.1109/CMPSAC.2002.1045067	unix architecture;embedded system;software architecture;computer science;artificial intelligence;scenario;software development;operating system;software engineering;unix filesystem;server-side scripting;multi-agent system;database;scripting language;streams;unix;programming language;control flow;forth;system integration	ML	-27.49435597860079	40.12951878051015	60809
278c6e25cef80fb0e15746cc4e424cfaa03ef019	fact: a tool for code generation from communicating automata	code generation		automaton	Cinzia Bernardeschi;Gianluca Dini;Andrea Domenici	2005			computer science;theoretical computer science;redundant code;programming language;algorithm;code generation;unreachable code;source code	Logic	-22.559024143084688	32.926794410087176	60981
bc3905102deec46b82f294b7bf591e626f9fd0c1	deadlock-free channels and locks	program verification;message passing;modular verification	The combination of message passing and locking to protect shared state is a useful concurrency pattern. However, programs that employ this pattern are susceptible to deadlock. That is, the execution may reach a state where each thread in a set waits for another thread in that set to release a lock or send a message. This paper proposes a modular verification technique that prevents deadlocks in programs that use both message passing and locking. The approach prevents deadlocks by enforcing two rules: (0) a blocking receive is allowed only if another thread holds an obligation to send and (1) each thread must perform acquire and receive operations in accordance with a global order. The approach is proven sound and has been implemented in the Chalice program verifier.	blocking (computing);call stack;compile time;compiler;concurrency (computer science);concurrency pattern;deadlock;encode;foreach loop;fork (software development);identifier;join (sql);lock (computer science);message passing;object lifetime;pseudocode;waits	K. Rustan M. Leino;Peter Müller;Jan Smans	2010		10.1007/978-3-642-11957-6_22	parallel computing;message passing;real-time computing;computer science;distributed computing;programming language	SE	-22.11866879102447	32.480931988973076	61136
97929620d53d15bbf772597933fc64bd4922e529	optimal asynchronous agreement and leader election algorithm for complete networks with byzantine faulty links	byzantine failures;distributed algorithms;distributed system;base donnee repartie;systeme reparti;distributed database;reseau asynchrone;distributed processing;reseau ordinateur;byzantine agreement;accord byzantin;base repartida dato;asynchronous network;computer network;upper bound;fault tolerant system;fault tolerant computing;sistema repartido;asynchronous networks;algorithme reparti;red ordenador;sistema tolerando faltas;leader election;private values;algoritmo repartido;systeme tolerant les pannes;faulty channels;agreement problem;borne superieure;panne canal;distributed algorithm;traitement reparti;cota superior;tratamiento repartido	We consider agreement and leader election on asynchronous complete networks when the processors are reliable, but some of the channels are subject to failure. Fischer, Lynch, and Paterson have already shown that no deterministic algorithm can solve the agreement problem on asynchronous networks if any processor fails during the execution of the algorithm. Therefore, we consider only channel failures. The type of channel failure we consider in this paper is Byzantine failure, that is, channels fail by altering messages, sending false information, forging messages, losing messages at will, and so on. There are no restrictions on the behavior of a faulty channel. Therefore, a faulty channel may act as an adversary who forges messages on purpose to prevent the successful completion of the algorithm. Because we assume an asynchronous network, the channel delays are arbitrary. Thus, the faulty channels may not be detectable unless, for example, the faulty channels cause garbage to be sent. We present the first known agreement and leader election algorithm for asynchronous complete networks in which the processors are reliable but some channels may be Byzantine faulty. The algorithm can tolerate up to $$\left[ {\frac{{n - 2}}{2}} \right]$$ faulty channels, where n is the number of processors in the network. We show that the bound on the number of faulty channels is optimal. When the processors terminate their corresponding algorithms, all the processors in the network will have the same correct vector, where the vector contains the private values of all the processors.	adversary (cryptography);byzantine fault tolerance;central processing unit;consensus dynamics;deterministic algorithm;leader election;michael j. fischer;terminate (software)	Hasan Md. Sayeed;Marwan Abu-Amara;Hosame Abu-Amara	1995	Distributed Computing	10.1007/s004460050016	embedded system;distributed algorithm;fault tolerance;real-time computing;computer science;leader election;distributed computing;upper and lower bounds;byzantine fault tolerance;algorithm	Theory	-21.473050430118878	44.12492129759312	61290
b5da724eaefeed6153eda3960b2a6ecb524d44c6	executing distributed prolog programs on a broadcast network			prolog	David Scott Warren;Mustaque Ahamad;Saumya K. Debray;Laxmikant V. Kalé	1984			database;broadcasting (networking);prolog;computer science;distributed computing	DB	-28.630692781422184	35.382204567503315	61698
b45da6e4c4a7b091671b166e9c60cfcb32cbf2f3	parallel processing of relations: a single-assignment approach	scheduling requirement;access scheduling;language extension;relation type procedure parameter;high level language construct;single-assignment approach;data structure relation;parallel processing;concurrent execution;procedure concept;database action;implementation effort;computer languages;concurrent computing;data access;databases;high level language;data structures;high level languages;data structure	Pascal/R, a language extension based on a data structure relation and some high level language constructs for relations [9] is augmented by a procedure concept for concurrent execution of database actions. Relation type procedure parameters serve two purposes: data accessing and access scheduling. Scheduling requirements are analyzed within the framework of the single-assignment approach [10] and proposals for the stepwise reduction of implementation effort are discussed.	assignment (computer science);data structure;high-level programming language;parallel processing (dsp implementation);pascal;requirement;schedule (project management);scheduling (computing);static single assignment form;stepwise regression	Joachim W. Schmidt	1979	Fifth International Conference on Very Large Data Bases, 1979.		fourth-generation programming language;data structure;computer science;theoretical computer science;third-generation programming language;database;fifth-generation programming language;programming language;second-generation programming language;high-level programming language	DB	-24.89653085909507	33.57496096130637	62123
5fd9c8c91a67117e72731c1f33ca1527f2c59156	correctness proofs for device drivers in embedded systems	existing formal semantics;computer system;open-source driver;abstract model;real embedded processor;full functional correctness;o device;abstract device model;verifying device driver software;correctness proof;embedded system	Computer systems do not exist in isolation: they must interact with the world through I/O devices. Our work, which focuses on constrained embedded systems, provides a framework for verifying device driver software at the machine code level. We created an abstract device model that can be plugged into an existing formal semantics for an instruction set architecture. We have instantiated the abstract model with a model for the serial port for a real embedded processor, and we have verified the full functional correctness of the transmit and receive functions from an open-source driver for this device.	arm architecture;central processing unit;computer data storage;correctness (computer science);device driver;embedded system;formal language;hol (proof assistant);hardware description language;input/output;interrupt;machine code;multi-core processor;open-source software;peripheral;scalability;semantics (computer science);separation logic;serial port;transmitter;verification and validation	Jianjun Duan;John Regehr	2010			embedded system;real-time computing;computer science;theoretical computer science;operating system;programming language	Embedded	-29.33820244429721	35.836690251678434	62321
088670c7a410af27635a092680cc40af78ededb5	parallel composition for time-to-fault adaptive stabilization	parallel composition;transient fault	Self-stabilizing algorithms automatically recover from any occurrence of a transient fault. The global state following the transient fault is considered to be the initial state for subsequent execution. An adaptive self-stabilizing algorithm changes its behavior based on characteristics of the initial state. This paper presents an asynchronous, adaptive, self-stabilizing algorithm for any non-interactive task. The algorithm adapts its output stabilization time in relation to the extent of faulty information in the initial state. The paper’s presentation emphasizes composition techniques that leverage several self-stabilizing components from previous research, resulting in a concise description of the algorithm.	algorithm;byzantine fault tolerance;interactivity;self-replication;self-stabilization	Shlomi Dolev;Ted Herman	2007	Distributed Computing	10.1007/s00446-007-0028-y	control engineering;real-time computing;computer science;distributed computing	HPC	-23.277192844859364	43.76072454251086	62589
9e8ef2473bf3c92b47576ed779bf49ada9625d24	cinderella: a retargetable environment for performance analysis of real-time software	developpement logiciel;systeme temps reel;programacion entera;execution time;real time;cache memory;ingenieria logiciel;software engineering;programmation en nombres entiers;worst case execution time;programacion lineal;integer programming;desarrollo logicial;software development;performance analysis;linear programming;genie logiciel;programmation lineaire;timing analysis;temps execution;real time system;sistema tiempo real;tiempo ejecucion;real time systems;time constraint	Real-time systems are characterized by the presence of timing constraints that a task must be completed within a given deadline. In this paper, we present a complete environment for determining best-case and worst-case execution time of a program when running on a given hardware. Our analysis technique is unique in that it allows user to annotate complex program path information and at the same time, models cache memory and pipeline accurately. This results in tight estimations even for complicated programs running on modern hardware. The technique has been implemented on a timing analysis tool - cinderella 3 , which provides retargetable back-ends for analyzing programs written in different languages and executed on different hardware. We present some experimental results of using this tool.	profiling (computer programming);real-time transcription	Yau-Tsun Steven Li;Sharad Malik;Andrew Wolfe	1997		10.1007/BFb0002887	parallel computing;real-time computing;integer programming;cpu cache;computer science;linear programming;software development;operating system;static timing analysis;algorithm;worst-case execution time	SE	-23.000491809138623	36.22113258839403	62729
f993117d7056147916b49c934ad3470f1a3018bb	object-oriented design patterns for debugging heterogeneous languages and virtual machines	classic pattern;vm abstraction;aggregate vm debugger chain;language abstraction;language-neutral virtual machine abstraction;language-specific vm view;target vm;classic design pattern;design pattern;language-specific debugger command interpreter;object-oriented design pattern;heterogeneous language	Debugging multi-language software systems requires examining and executing these systems at multiple levels of abstraction. Embedded systems, for example, often comprise a mix of assembly language device drivers and C language control code. Embedded systems increasingly utilize Java to support dynamic loading and run-time reconfiguration. The RTEEM (Research version of the Tcl Environment for Extensible Modeling) debugger employs three design patterns in solving the problems of multi-language embedded system debugging. The Reflective virtual machine (VM) pattern models a language-neutral virtual machine abstraction, with language-specific interfaces extending this abstraction. Reflection allows a debugger to inspect and control a target VM. The Chain of Responsibility is a classic pattern used to arrange language-specific debugger command interpreters in a delegation chain. All interpreters share a single command syntax, but each interpreter adapts commands to its language abstraction by interacting with its language-specific VM view. Composite is another classic pattern, used to combine objects into tree structures. RTEEM employs it to aggregate VM debugger chains into a hierarchy that supports uniform command syntax for debugging threads, processes, multiprocessor systems, and compositions of these entities. This paper illustrates how combining two classic design patterns with the VM abstraction as a pattern results in an architecture that is powerful and flexible in adapting to the debugging needs of heterogeneous, distributed embedded systems. Copyright c © 2004 John Wiley & Sons, Ltd.	aggregate data;assembly language;debugger;debugging;design pattern;device driver;dynamic loading;embedded system;entity;interaction;java;john d. wiley;multiprocessing;principle of abstraction;software system;tcl;tree structure;virtual machine	Dale E. Parson;David J. Murray;Yu Chen	2005	Softw., Pract. Exper.	10.1002/spe.634	synchronization;parallel computing;real-time computing;reflection;computer science;virtual machine;operating system;object-oriented design;design pattern;programming language	PL	-26.811516988600083	36.679663444816036	62766
c46e274c1e82d6652ea75478d8f4f21e29b919f4	notice of violation of ieee publication principlesa stable election protocol based on an unreliable failure detector in distributed systems	distributed system;detectors;unreliable failure detector;protocols;groupware;failure detectors distributed computing leader election asynchronous distributed systems;computer crashes;distributed processing;distributed computing;failure detectors;satisfiability;safety properties;asynchronous system;failure analysis;arrays;lead;failure detector;safety;nominations and elections;nominations and elections safety detectors computer crashes proposals lead arrays;leader election;asynchronous distributed system;asynchronous distributed systems;proposals;liveness property stable election protocol unreliable failure detector distributed system parallelism support cooperative support cooperative work asynchronous distributed system election algorithm safety property violation safety strengthened leader election protocol failure detector failure analysis;cooperative work;public administration distributed processing failure analysis groupware protocols;public administration	A Leader is a Coordinator that supports a set of processes to cooperate a given task. This concept is used in several domains such as distributed systems, parallelism and cooperative support for cooperative work. In completely asynchronous systems, there is no solution for the election problem satisfying both of safety and liveness properties in asynchronous distributed systems. Therefore, to solve the election problem in those systems, one property should be weaker than the other property. If an election algorithm strengthens the safety property in sacrifice of liveness property, it would not nearly progress. But on the contrary, an election algorithm strengthening the liveness property in sacrifice of the safety property would have the high probability of violating the safety property. In this paper, we presents a safety strengthened Leader Election protocol with an unreliable failure detector and analyses it in terms of safety and liveness properties in asynchronous distributed systems.	algorithm;asynchronous system;distributed computing;failure detector;leader election;liveness;parallel computing	Sung-Hoon Park	2011	2011 Eighth International Conference on Information Technology: New Generations	10.1109/ITNG.2011.168	asynchronous system;communications protocol;failure analysis;detector;lead;real-time computing;computer science;leader election;distributed computing;computer security;failure detector;computer network;liveness;satisfiability	Logic	-22.526486901703976	44.313081042142855	62821
7fa68e79ba7c8723e99798580d02ecd9bf346370	lbnamed: a load balancing name server in perl	load balance	Given a cluster of workstations, users have always wanted a way to login to the leastloaded workstation. This paper discusses an attempt to solve that problem using a load balancing name server. This name server also has the ability to serve other dynamic information as well, such as /etc/passwd information (a la Hesiod [2]). The prototype was written in Perl 4 [1], and recently converted to Perl 5. This paper describes the Perl 4 version first and then describes some of the interesting features in the Perl 5 version. This paper assumes the reader has a basic understanding of Perl, DNS, and BIND [3].	computer cluster;hesiod (name service);linear algebra;load balancing (computing);login;passwd;perl;prototype;server (computing);workstation	Roland Schemers	1995			taint checking;computer science;load balancing;operating system;database;sociology;perl::critic;world wide web	OS	-31.519064200828666	42.8248345883004	63081
784b2fb1ad4538ea1178896db609ba50c55cb95f	control: software for end-user interface programming and interactive performance		The author presents Control, a software application for mobile devices enabling users to define custom graphical user interfaces for transmitting both OSC and MIDI. Unlike other similar mobile applications, interfaces are defined using web standards such as HTML, CSS and JavaScript. The widgets that come predefined with Control can be extended by users via JavaScript; scripting can also be used by users to define new widgets from scratch. The ability to add user defined scripting provides flexibility, dynamism and sophistication to interfaces that is absent in other mobile interface applications. Control is free to download from the Apple App Store and will also be freely available from the Android Market by the time this paper is published. Devices running Control can be automatically discovered on a network; once this occurs servers can ”push” interfaces to them that are ready for immediate use. Bi-directional communication with Control also allows servers to update widget values and dynamically restructure interfaces on the fly. These features make it ideal for audience interaction pieces and installation art as participants can download the software for free, be pushed a custom interface and quickly begin interacting with a work. This paper will describe the advantages and disadvantages of Control over other interface applications for mobile devices.	android;app store;cascading style sheets;download;graphical user interface;html;interaction;javascript;midi;mobile app;mobile device;on the fly;play store;transmitter;web standards	Charles Roberts	2011			computer architecture;component-based software engineering;real-time computing;functional reactive programming;adapter pattern;resource-oriented architecture;system programming;interface control document;software development;computer science;inversion of control	HCI	-32.622286889241394	40.64935924121422	63177
ea26d84e2b113bb8231b438959795c9441e14ab9	on the impact of management instrumentation models on web server performance: a jmx case study	java management extension;java technology-based application;management impact;management instrumentation models;jmx case study;functional service;management activity;jmx instrumented web server;web server performance;accessible resource;java framework;management plane;component model;management system;mobile device	JMX (Java Management eXtension) is a Java framework that allows any Java technology-based application or accessible resource to become easily manageable. This standard begins to be widely used within different managed systems which vary from large mainframes to small mobile devices, limited in both resource and computing capacity. Today, little is known about the costs associated with the manageability of a system. In this paper, we analyse the impact of various instrumentation models on the behavior of both the functional and the management plane. We show on a JMX instrumented web server that the service is highly affected by the management activity in driver and component models while a daemon approach limits the management impact on the functional service.	java management extensions;web server	Abdelkader Lahmadi;Anca Ghitescu;Laurent Andrey;Olivier Festor	2007			embedded system;real-time computing;computer science;operating system;mobile device;management system;component;component object model;database;management;world wide web;computer security;computer network;benchmarking	Web+IR	-32.612403565540625	43.84766214783478	63339
1ac71e1f7a721bc67f6a6ce860c1fc3793d980a5	understanding complex multithreaded software systems by using trace visualization	program comprehension;software systems;visualization;visualization technique;performance optimization;dynamic analysis;multithreading	Understanding multithreaded software systems is typically a tedious task: Due to parallel execution and interactions between multiple threads, such a system's runtime behavior is often much more complex than the behavior of a single-threaded system. For many maintenance activities, system understanding is a prerequisite. Hence, tasks such as bug fixing or performance optimization are highly demanding in the case of multithreaded systems. Unfortunately, state-of-the-art tools for system understanding and debuggers provide only limited support for these systems. We present a dynamic analysis and visualization technique that helps developers in understanding multithreaded software systems in general and in identifying performance bottlenecks in particular. The technique first performs method boundary tracing. Second, developers perform a post-mortem analysis of a system's behavior using visualization optimized for trace data of multithreaded software systems. The technique enables developers to understand how multiple threads collaborate at runtime. The technique is integrated into a professional and scalable tool for visualizing the behavior of complex software systems. In case studies, we have tested the technique with industrially developed, multithreaded software systems to understand system behavior and to identify multithreading-related performance bottlenecks.	boundary tracing;debugger;interaction;mathematical optimization;multithreading (computer architecture);performance tuning;run time (program lifecycle phase);scalability;software system;thread (computing)	Jonas Trümper;Johannes Bohnet;Jürgen Döllner	2010		10.1145/1879211.1879232	software visualization;computer architecture;parallel computing;real-time computing;visualization;multithreading;computer science;software engineering;dynamic program analysis;programming language;software system	SE	-19.46213907767746	39.69163165325279	63508
adf6894986a4ab57dad6fb4fe3b1c2f497af1279	a step towards neutral debugging of distributed applications	distributed application		debugging	Serge Chaumette	1993			debugging;theoretical computer science;parallel computing;computer science;distributed computing	OS	-24.67064755363075	36.56780697539814	63734
e5e0ae77487cea8272caa939608b7b4119b2b94e	toward linux kernel memory safety		e security of billions of devices worldwide depends on the security and robustness of the mainline Linux kernel. However, the increasing number of kernel-specific vulnerabilities, especially memory safety vulnerabilities, shows that the kernel is a popular and practically exploitable target. Two major causes of memory safety vulnerabilities are reference counter overflows (temporal memory errors) and lack of pointer bounds checking (spatial memory errors). To succeed in practice, security mechanisms for critical systems like the Linux kernel must also consider performance and deployability as critical design objectives. We present and systematically analyze two such mechanisms for improving memory safety in the Linux kernel: (a) an overflow-resistant reference counter data structure designed to accommodate typical reference counter usage in kernel source code, and (b) runtime pointer bounds checking using Intel MPX in the kernel.	bounds checking;data structure;emoticon;intel mpx;kernel (operating system);linux;memory safety;pointer (computer programming);program counter;ring counter;the pragmatic programmer	Elena Reshetova;Hans Liljestrand;Andrew Paverd;N. Asokan	2018	Softw., Pract. Exper.	10.1002/spe.2638	bounds checking;robustness (computer science);intel mpx;pointer (computer programming);parallel computing;sysfs;computer science;memory safety;linux kernel;real-time computing;kernel preemption	Security	-21.727369403140553	38.89047231029508	64142
ba1321e39c1a95fb57b4be10f334e9abb2b585ec	debugging aids for microprocessor systems		Abstract   Current teaching and research activities at Newcastle University involving microprocessor systems, have shown the need for debugging aids which can be used for efficiently tracking down both hardware and software faults during the development stage of microprocessor-based digital systems. The paper describes the implementation of two different approaches to this problem, the collective aim being to provide sophistication combined with flexibility.	debugging;microprocessor	Edward P. Farrell;N. G. Kanellopoulos	1978	Microprocessors	10.1016/0308-5953(78)90044-2	embedded system;computer architecture;real-time computing;computer science;operating system	Logic	-27.661551498741186	38.26065677685775	64167
7d874d96f08e393cb68e5efc1a8a81e14f47e0b6	design of a multi-threaded distributed telerobotic framework	distributed application;software tool;multi threading;network protocol;real time;net framework;remoting based distributed components multithreaded distributed telerobotic framework client server stations reliable real time connection distributed application framework software reusability debugging data encapsulation advanced software tools simple object access protocol data transfer data security easy deployment stereo vision force feedback commodity lan puma component;force feedback telerobotics multi threading distributed object management access protocols local area networks data encapsulation security of data;remote procedure call;data encapsulation;computer network;force feedback;distributed component object model;software reusability;distributed object management;stereo vision;access protocols;telerobotics;simple object access protocol;security of data;local area networks;data transfer;telerobotics simple object access protocol master slave computer network reliability network servers real time systems software reusability debugging data encapsulation software tools;data security	A telerobotic system consists of master (client) and slave (server) stations which are usually connected by a computer network. A reliable real-time connection between master and slave systems is proposed using Distributed Components (.NET Remoting). This has a number of benefits such as software reusability, ease of extensibility, debugging, and data encapsulation. It is based on most advanced software tools like .NET Framework that promise definite advantages over DCOM (Distributed Component Object Model) and RPC (Remote Procedure Call), previously used for distributed applications. The components communicate with each other using .NET Remoting and SOAP (Simple Object Access Protocol) that automatically handle the network resources and data transfer while isolating the components from network protocol issues. This enhances the data security as well as facilitates easy deployment. Implementing telerobotics using the proposed approach gives the advantage of a multi-threaded execution needed to effectively realize multistreaming of force, command and stereo data over a LAN.	.net framework;.net remoting;client–server model;communications protocol;data security;debugging;deployment environment;distributed component object model;distributed computing;distributed element model;encapsulation (networking);extensibility;fastest;real-time clock;remote procedure call;soap;server (computing);software deployment;telerobotics;thread (computing)	Mayez A. Al-Mouhamed;Onur Toker;Asif Iqbal	2003		10.1109/ICECS.2003.1301748	embedded system;real-time computing;computer science;distributed computing;.net remoting	Embedded	-33.58578940232094	39.92929972096144	64274
257204fabd92842174dd0bf6da7afb59dc9a8821	domain-based security for distributed object systems			distributed object;domain based security	Nikolaos Yialelis	1996				Crypto	-32.03509061705813	45.75396017265088	64283
8eb1e1759e12dcdf18deca688af4fd067a3bb874	analysis of inter-module error propagation paths in monolithic operating system kernels	kernel;subsystem extraction;performance evaluation;monolithic kernels;monolithic operating system kernels;servers;operating system;operating system kernels device drivers error handling;error propagation;error isolation;device drivers;control flow;error handling;driver circuits;linux;error analysis operating systems kernel hardware computer errors data mining switches application software linux memory management;intermodule error propagation monolithic operating system kernels hardware errors device drivers error isolation;hardware errors;operating system kernels;subsystem extraction monolithic kernels error propagation error isolation;device driver;intermodule error propagation;hardware	Operating Systems interact directly with the hardware, so they are prone to hardware errors. This is particularly true with monolithic kernels, where all subsystems and device drivers share the same execution domain. Even in systems that support kernel modules, components still run under the same privilege level as the main kernel. Module partitioning techniques to address error propagation do exist, but they impose a performance overhead from frequent domain switches when control flows from one module to another. This paper presents a technique to extract the relationship between kernel modules and to identify potential error propagation paths between them. We also suggest a technique to group modules with respect to the function they provide, so that the number of execution domains can be minimized while still maintaining error isolation between subsystems. Additionally, we provide an evaluation of the module grouping technique in respect to performance overhead and dependability for a simple isolation environment.	algorithm;data protection directive;dependability;device driver;hot swapping;kernel (operating system);loadable kernel module;monolithic kernel;network switch;operating system;overhead (computing);privilege level;propagation of uncertainty;software propagation	Roberto Jung Drebes;Takashi Nanya	2010	2010 European Dependable Computing Conference	10.1109/EDCC.2010.29	exception handling;embedded system;kernel;real-time computing;computer science;propagation of uncertainty;operating system;kernel preemption;control flow;linux kernel;server	Embedded	-23.878368029669137	40.68129503067697	64293
73f8def7db691757ad60a6ce1b3af6a40d43b01c	supplying compiler's static compatibility checks by the analysis of third-party libraries	program diagnostics;static verification;byte code;java runtime software loading software libraries ieee computer society;formal verification;analysis type compatibility static verification byte code;analysis;program diagnostics formal verification program compilers;static type checking level compiler static compatibility checks third party library analysis statically typed language compile time check runtime error mutual dependency library usage runtime failure static analysis dependency verification;type compatibility;program compilers	Statically typed languages and their compile time checks prevent a lot of runtime errors thanks to type mismatches detection, namely calls of incompatible methods. Since current applications typically include tens of already compiled third-party libraries, the compile checks are powerless to detect their mutual dependencies. However, the calls among third-party library methods are not less error prone due to bugs or wrong library usage. These all lead to runtime failures. In this paper, we describe a partial solution to this problem based on the static analysis of third-party libraries and verification of their dependencies. This verification is invoked as the application is compiled and assembled, essentially supplying the compiler detecting errors before the application runs. This approach promises improved error detection of complex applications on the static type checking level.	cognitive dimensions of notations;compile time;compiler;error detection and correction;library (computing);mutual exclusion;run time (program lifecycle phase);sensor;software bug;static program analysis;trends in library usage;type system	Kamil Jezek;Lukas Holy;Premek Brada	2013	2013 17th European Conference on Software Maintenance and Reengineering	10.1109/CSMR.2013.53	compile time;parallel computing;real-time computing;formal verification;computer science;operating system;analysis;runtime verification;programming language	SE	-21.82006185706394	36.02325220464799	64408
db2ba43e0133dc2ccdf577fd4f1954fb894786f2	on the false path problem in hard real-time programs	functional dependencies;real time systems np complete problem system analysis and design system testing timing;pruned path enumeration;system analysis and design;exact solution;software performance evaluation;symbolic execution false path problem hard real time programs worst case execution time estimation wcet purely structure oriented methods functional dependencies np complete problem structure oriented methods maximum loop counts user annotations maximum recursion depths pruned path enumeration;functional dependency;purely structure oriented methods;worst case execution time estimation;worst case execution time;symbolic execution;wcet;maximum recursion depths;computational complexity;structure oriented methods;control flow;system testing;hard real time programs;false path problem;user annotations;maximum loop counts;np complete problem;hard real time;real time systems;timing	This paper addresses the important subject of estimating the worst-case execution time ( WCET) of hard real-time programs essentially needed for further evaluation of real time systems. Purely structure oriented methods, analysin g the control flow of the program without taking into account functional dependencies, tend to overestimate the executi on time. An exact solution of this NP-complete problem is impossible for larger applications. In this paper, we propose a new heuristic of finding an estimate on the WCET. It provides a reasonable trade-off between analysis results and analysis efforts: the results will still be better than pure ly structure oriented methods without spending too much time on finding an exact solution. For this purpose our approach does not need any user annotations except for maximum loop counts and maximum recursion depths. The actual algorithm combines pruned path enumeration with the concept of symbolic execution.	algorithm;amiga software;best, worst and average case;cache (computing);compiler;conditional (computer programming);control flow;functional dependency;heuristic;longest path problem;mechatronics;metro (design language);np-completeness;operating system;parallel computing;pipeline (computing);real-time clock;real-time computing;real-time transcription;recursion;run time (program lifecycle phase);symbolic execution;worst-case execution time	Peter Altenbernd	1996		10.1109/EMWRTS.1996.557827	real-time computing;computer science;theoretical computer science;operating system;functional dependency;programming language;algorithm	Embedded	-22.76949851204432	36.40950839068761	64805
29f4746bca58d9858dd64300e44366311fc40591	write-back caches in wcet analysis		Write-back caches are a popular choice in embedded microprocessors as they promise higher performance than write-through caches. So far, however, their use in hard real-time systems has been prohibited by the lack of adequate worst-case execution time (WCET) analysis support. In this paper, we introduce a new approach to statically analyze the behavior of write-back caches. Prior work took an “eviction-focussed perspective”, answering for each potential cache miss: May this miss evict a dirty cache line and thus cause a write back? We complement this approach by exploring a “store-focussed perspective”, answering for each store: May this store dirtify a clean cache line and thus cause a write back later on? Experimental evaluation demonstrates substantial precision improvements when both perspectives are combined. For most benchmarks, write-back caches are then preferable to write-through caches in terms of the computed WCET bounds. 1998 ACM Subject Classification C.3 Real-Time and Embedded Systems	best, worst and average case;cpu cache;cache (computing);embedded system;microprocessor;real-time clock;real-time computing;real-time locating system;run time (program lifecycle phase);worst-case execution time	Tobias Blaß;Sebastian Hahn;Jan Reineke	2017		10.4230/LIPIcs.ECRTS.2017.26	computer science;operating system;distributed computing;cache;cpu cache	Embedded	-20.511676657350467	35.898263535693026	64816
5b1c78f93d8845664f09169edca8c693eaea4725	on the weakest failure detector for hard agreement problems	consensus;terminating reliable broadcast;fault tolerant;atomic commit;distributed computing;synchronous system;failure detector;fault tolerance;agreement problem;reliable broadcast	Chandra and Toueg [J. ACM 43 (1996) 225] and Fromentin et al. [Proc. IEEE Internat. Conf. on Distrib. Comput., 1999, p. 470], respectively, stated that the weakest failure detector for any of non-blocking atomic commitment and terminating reliable broadcast is the perfect failure detector P . Recently, Guerraoui [IPL 79 (2001) 99] presented a counterexample of those results, exhibiting a failure detector called Marabout (M) that is incomparable to P and yet solves those problems. In this paper we present three new perfect failure detector classes as alternatives to P and M . All our classes are weaker than P . Furthermore, two of them are also weaker than M , and yet solve non-blocking atomic commitment and terminating reliable broadcast. Interestingly, our failure detector classes are implementable whenever P is implementable (e.g., in a synchronous system), which is not the case with M . 2003 Elsevier B.V. All rights reserved.	atomic commit;blocking (computing);failure detector;michel raynal;newman's lemma;non-blocking algorithm;p (complexity);synchronous circuit;terminating reliable broadcast	Mikel Larrea	2003	Journal of Systems Architecture	10.1016/S1383-7621(03)00064-X	fault tolerance;real-time computing;computer science;distributed computing;algorithm	OS	-22.207894882942323	43.86259234073894	64917
69f6e8e7c8c8e6726bec1ca9d2b9e0eaab7a3990	adaptive timeliness of consensus in presence of crash and timing faults	metodo adaptativo;timeliness property;crash failure;consensus;crash fault;sistema temporizado;execution time;averia franca;algoritmo adaptativo;timed system;methode adaptative;satisfiability;adaptive algorithm;timing fault;algorithme adaptatif;consenso;uniformite;uniformidad;adaptive method;algorithme reparti;systeme temporise;uniformity;temps execution;algoritmo repartido;panne franche;tiempo ejecucion;distributed algorithm;consensus problem	The ∆-timed uniform consensus is a stronger variant of the traditional consensus and it satisfies the following additional property: Every correct process terminates its execution within a constant time ∆ (∆-timeliness), and no two processes decide differently (Uniformity). In this paper, we consider the ∆-timed uniform consensus problem in presence of fc crash processes and ft timing-faulty processes, and propose a ∆-timed uniform consensus algorithm. The proposed algorithm is adaptive in the following sense: It solves the ∆-timed uniform consensus when at least ft + 1 correct processes exist in the system. If the system has less than ft + 1 correct processes, the algorithm cannot solve the ∆-timed uniform consensus. However, as long as ft + 1 processes are non-crashed, the algorithm solves (non-timed) uniform consensus. We also investigate the maximum number of faulty processes that can be tolerated. We show that any ∆-timed uniform consensus algorithm tolerating up to ft timing-faulty processes requires that the system has at least ft + 1 correct processes. This impossibility result implies that the proposed algorithm attains the maximum resilience about the number of faulty processes. We also show that any ∆-timed uniform consensus algorithm tolerating up to ft timing-faulty processes cannot solve the (non-timed) uniform consensus when the system has less than ft + 1 non-crashed processes. This impossibility result implies that our algorithm attains the maximum adaptiveness.	chandra–toueg consensus algorithm;circuit complexity;consensus (computer science);crash (computing);time complexity;uniform consensus	Taisuke Izumi;Akinori Saitoh;Toshimitsu Masuzawa	2007	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2007.02.004	distributed algorithm;real-time computing;consensus;computer science;distributed computing;chandra–toueg consensus algorithm;algorithm	Logic	-21.382719257768994	44.16671314832785	65128
02284fd73a9c6a1ef5a74d16d81634e2cf85e2b4	informix-online xps: a dynamically scalable rdbms for open parallel platforms	dynamically scalable rdbms;informix-online xps;open parallel platforms		ibm informix;open xml paper specification	Hannes Spintzik	1995			distributed computing	HPC	-30.08428128615281	45.8044267045517	65207
47d7d34b5502eefe2145f0531e24aa62cf17281b	hot-stuff the linear, optimal-resilience, one-message bft devil		We describe a protocol called ‘Hot-Stuff the Linear, Optimal-Resilience, One-Message BFT Devil’ (in short, Hot-Stuff) for n = 3f+1 replicas, of which 2f+1 are honest, to agree on a replicated, ever-changing state. The protocol is always safe against a threshold f of Byzantine failures, even when the system is asynchronous. Progress is guaranteed under periods of synchrony. The per-round communication cost in Hot-Stuff is linear, hence O(n) overall cost to a decision during periods of synchrony, an improvement of O(n) over previous asynchronous BFT protocols. Hot-Stuff uses one type of message exchange, and is succinctly described in under twenty lines of pseudo-code.	byzantine fault tolerance;pseudocode	Ittai Abraham;Guy Golan-Gueta;Dahlia Malkhi	2018	CoRR		psychological resilience;asynchronous communication;distributed computing;byzantine fault tolerance;computer science	DB	-21.833170417908782	44.374395967327445	65527
b42ebe7d6fb0578936e74cbd019e5e6ea9c7fae8	a study of quasi-dynamic load sharing in soft real-time distributed computer systems			hardware description language;real-time transcription	James F. Kurose;Suresh Singh;Renu Chipalkatti	1986			distributed computing;real-time computing;dynamic load testing;computer science;dynamic loading	Embedded	-29.47202442332915	46.138709034687956	65549
c45fc7cd5e83cbee8afc737b10fbfb5623095539	distributed object management	databases;distributed system;management system;standards;heterogeneous systems;distributed computing;object oriented software;distributed objects;information processing;distributed systems;transaction processing;system architecture	Future information processing environments will consist of a vast network of heterogeneous, autonomous, and distributed computing resources, including computers (from mainframe to personal), information-intensive applications, and data (files and databases). A key challenge in this environment is providing capabilities for combining this varied collection of resources into an integrated distributed system, allowing resources to be flexibly combined, and their activities coordinated, to address challenging new information processing requirements. In this paper, we describe the concept of distributed object management, and identify its role in the development of these open, interoperable systems. We identify the key aspects of system architectures supporting distributed object management, and describe specific elements of a distributed object management system being developed at GTE Laboratories.	distributed object	Frank Manola;Sandra Heiler;Dimitrios Georgakopoulos;Mark F. Hornick;Michael L. Brodie	1992	Int. J. Cooperative Inf. Syst.	10.1142/S0218215792000027	distributed algorithm;dce/rpc;real-time computing;global information system;distributed data store;transaction processing;information processing;computer science;object request broker;management system;database;distributed computing;distributed object;distributed system security architecture;distributed design patterns;replication;distributed concurrency control	DB	-28.783754652178683	45.503953922811185	65599
1ed01e9c83b923af9a03985379f0bad7dff446ea	asserting causal properties in high level synthesis		ICs are subject to many causes of malfunction such as aging or aggressive environment, while avoiding unwanted behavior of critical applications is a key issue. Monitoring is a cornerstone of safety policies, as it supports triggering counter measures on demand. High Level Synthesis (HLS) allows to easily implement applications in hardware, and some HLS compliant solutions have been reported. These solutions monitor applications through asserting properties to variables. This paper extends this approach by proposing causal assertions, dedicated to monitoring the evolution of variables over time. Results demonstrate significant gains in term of reactivity and error coverage rate, while keeping the overhead low.	assertion (software development);causal filter;control flow;debugging;embedded system;error detection and correction;experiment;hardware acceleration;high- and low-level;high-level synthesis;induction variable;legacy code;mathematical induction;monitor (synchronization);overhead (computing);semantics (computer science);sensor	Erwan Fabiani;Loïc Lagadec;Mohamed Ben Hammouda;Ciprian Teodorov	2017	2017 IEEE 2nd International Verification and Security Workshop (IVSW)	10.1109/IVSW.2017.8031555	resource management;high-level synthesis;real-time computing;engineering	EDA	-23.042352094349365	37.94715813589449	65626
a1ad0b57255eab419595041fe0a964be79539d9a	weblogic event server: a lightweight, modular application server for event processing	query language;application server;spring;programming model;low latency;complex event processing;osgi;stream processing;modular architecture;java	This paper describes WebLogic Event Server (WL EvS), an application server designed for hosting event-driven applications that require low latency and deterministic behavior. WL EvS is based on a modular architecture in which both server components and applications are represented as modules. The application programming model supports applications that are a mixture of reusable Java components and EPL (Event Processing Language), a query language that extends SQL with stream processing capabilities. WL EvS applications are meta-data driven, in that application behavior can be changed without recompilation or redeploying an application. The paper also presents the results of a benchmark performance study. The results show that the approach used by WL EvS can handle extremely high volumes of events while providing deterministic latency.	application programming interface;application server;benchmark (computing);complex event processing;esoteric programming language;event-driven programming;java;oracle weblogic server;programming model;query language;sql;server (computing);stream processing	Seth White;Alexandre Alves;David Rorke	2008		10.1145/1385989.1386014	embedded system;real-time computing;stream processing;computer science;complex event processing;operating system;database;distributed computing;programming paradigm;programming language;java;query language;application server;low latency	OS	-31.657216088738465	43.22367578294107	65730
9b12bc072f119d1e38e10eefd01380fc18f300e3	low-cost distributed realtime multitasking system	realtime systems;local area networks;68000;multitasking;microsystems;realtime multitasking system	The paper describes the design and implementation of DRM68K, a low-cost distributed realtime multitasking system. Each node in DRM68K consists of a minimally configured 68000 microprocessor and a network interface unit that connects the nodes together to form a token ring local area network. The system is built on top of a distributed multitasking kernel. DRM68K is useful in realtime embedded computing applications such as robotics, process control and flight simulation.	computer multitasking	Kam-Wing Ng	1988	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(88)90118-4	real-time computing;embedded system;microprocessor;flight simulator;process control;token ring;local area network;human multitasking;network interface;computer science;artificial intelligence;robotics	Embedded	-32.3761183837843	38.33552404624874	66134
1ffccf960e41b97b753c00f965fbbb355aa0d774	register indirect jump target forwarding	object oriented programming;processor architecture	Object-oriented languages have recently become common, making register indirect jumps more important than ever. In objectoriented languages, virtual functions are heavily used because they improve programming productivity greatly. Virtual function calls usually consist of register indirect jumps, and consequently, programs written in objectoriented languages contain many register indirect jumps. The prediction of the targets of register indirect jumps is more difficult than the prediction of the direction of conditional branches. Many predictors have been proposed for register indirect jumps, but they cannot predict the jump targets with high accuracy or require very complex hardware. We propose a method that resolves jump targets by forwarding execution results. Our proposal dynamically finds the producers of register indirect jumps in virtual function calls. After the execution of the producers, the execution results are forwarded to the processor’s front-end. The jump targets can be resolved by the forwarded execution results without requiring prediction. Our proposal improves the performance of programs that include unpredictable register indirect jumps, because it does not rely on prediction but instead uses actual execution results. Our evaluation shows that the IPC improvement using our proposal is as high as 5.4% on average and 9.8% at maximum. key words: processor architecture, register indirect jump, object-oriented programming	addressing mode;front and back ends;programming productivity	Ryota Shioya;Naruki Kurata;Takashi Toyoshima;Masahiro Goshima;Shuichi Sakai	2013	IEICE Transactions		real-time computing;simulation;microarchitecture;computer science;operating system;distributed computing;programming language;object-oriented programming	HPC	-19.169197935540893	37.75620007179215	66182
dfd545201acb5b37b55e0c9371e984f4f21f3663	developing intelligent simulation language to support telerobotic workstation activities	intelligent simulation language;telerobotic workstation activity	intelligent simulation language;telerobotic workstation activity	simulation language;telerobotics;workstation	Celestine A. Ntuen;Eui H. Park;G. Ferguson;Ricardo Roberts	1989		10.1145/67312.67385	embedded system;simulation;computer science	Robotics	-32.02352906277644	37.79874265846837	66186
65f9a8135f70a0b00c9026f3f1cf8b9f26b148e8	enabling java mobile computing on the ibm jikes research virtual machine	distributed application;virtual machine;java virtual machine;mobile computer;distributed applications;software architecture;code mobility;thread persistence;source code	Today's complex applications must face the distribution of data and code among different network nodes. Java is a wide-spread language that allows developers to build complex software, even distributed, but it cannot handle the migration of computations (i.e. threads), due to intrinsic limitations of many traditional JVMs. After analyzing the approaches in literature, this paper presents our research work on the IBM Jikes Research Virtual Machine: exploiting some of its innovative VM techniques, we implemented an extension of its scheduler that allows applications to easily capture the state of a running thread and makes it possible to restore it elsewhere (i.e. on a different hardware or software architecture, but still with a version of JikesRVM installed). Our thread serialization mechanism provides support for both proactive and reactive migration of single- and multi-threaded Java applications. With respect to previous approaches, we implemented the mobility framework without recompiling a previous JVM source code, but simply extending its functionalities with a full Java package.	computation;java package;jikes;mobile computing;scheduling (computing);serialization;software architecture;thread (computing);virtual machine	Giacomo Cabri;Letizia Leonardi;Raffaele Quitadamo	2006		10.1145/1168054.1168064	software architecture;parallel computing;real-time computing;java concurrency;computer science;virtual machine;operating system;strictfp;real time java;programming language;java;mobile computing;code mobility;java applet;java annotation;source code	PL	-25.324092975244962	39.51621952277894	66390
bfcf04ce25568843ac01d5c25f800e61d97fabce	a resource accounting and charging system in condor environment	workload;management system;pricing;accounting;distributed computing;supercomputer;comptabilite;fijacion precios;supercomputador;prototipo;tariffication;professional services;tarification;estructura datos;charge travail;calculo repartido;structure donnee;contabilidad;carga trabajo;data structure;prototype;calcul reparti;fixation prix;superordinateur;tarificacion	The authors' aim is to create a resource accounting and charging system for the Grid environment that can be set up as part of the supercomputing Grid prototype, which is developed in an ongoing domestic project. Stiller, Gerke, Reichl and Flury (1,2) has introduced a distributed accounting and charging concept, in which they point out that it could be applied in Grid context as well. This model has been adopted and improved by the authors in the given context; they had created the specification of a proposed solution at algorithm level. The necessary data structures and its query interfaces have been defined. The metering, accounting and pricing processes have been implemented. The system has been adapted to the Condor workload management system. The resulting application has been deployed at the departmental clus- ter. The authors funnel is to continue developing the remaining modules of the system and bring out the completed version as the part of the professional services for the Grid. This paper introduces the applied model, the specification that was built upon it, the results of the implementation and the operating test environment.		Csongor Somogyi;Zoltán László;Imre Szeberényi	2003		10.1007/978-3-540-45209-6_61	pricing;supercomputer;simulation;data structure;computer science;artificial intelligence;operating system;management system;database;distributed computing;prototype;programming language;operations research;computer security	Networks	-27.77475635101581	43.469262884155405	66528
41b558bc07674a7146335edc14ba1478987e9184	reseer: efficient search-based replay for multiprocessor virtual machines		Efficient replay of virtual machines is important for software debugging, fault tolerance, and performance analysis. The current approaches of replaying virtual machines record the details of system execution at runtime. However, these approaches incur much overhead, which affects the system performance. Especially, in a multiprocessor system, recording the shared memory operations of multiple processors leads to a large amount of computing overhead and log files. To address the above issue, this paper proposes ReSeer—a search-based replay approach for multiprocessor virtual machines. ReSeer consists of three phases including record, search, and replay. In the record phase, we record only necessary non-deterministic events at runtime, and incrementally take memory checkpoints at a defined interval. In the search phase, we encode all the possible execution paths as binary strings, and use a genetic algorithm to search expected execution paths achieving the expected checkpoint. In the replay phase, we replay the system execution according to the searched execution paths and the logged non-deterministic events. Compared with current approaches, ReSeer significantly reduces performance overhead at runtime by searching expected execution paths instead of recording all the operations of accessing shared memory. We have implemented ReSeer, and then evaluated it with a series of typical benchmarks deployed on an open source virtual machine—Xen. The experimental results show that ReSeer can reduce the record overhead at runtime efficiently.	multiprocessing;virtual machine	Tao Wang;Jiwei Xu;Wenbo Zhang;Jianhua Zhang;Jun Wei;Hua Zhong	2017	Journal of Systems and Software	10.1016/j.jss.2016.07.032	parallel computing;real-time computing;computer science;operating system;distributed computing	OS	-20.22317925213641	38.31520317067301	66563
1d33451cc347cb37ed1551fbbf3c5ce3b6b5f46e	roscoq: robots powered by constructive reals		WepresentROSCoq, a framework for developing certifiedCoq programs for robots. ROSCoq subsystems communicate using messages, as they do in the Robot Operating System (ROS). We extend the logic of events to enable holistic reasoning about the cyber-physical behavior of robotic systems. The behavior of the physical world (e.g. Newton’s laws) and associated devices (e.g. sensors, actuators) are specified axiomatically. For reasoning about physics we use and extend CoRN’s theory of constructive real analysis. Instead of floating points, our Coq programs use CoRN’s exact, yet fast computations on reals, thus enabling accurate reasoning about such computations. As an application, we specify the behavior of an iRobot Create. Our specification captures many real world imperfections. We write a Coq program which receives requests to navigate to specific positions and computes appropriate commands for the robot. We prove correctness properties about this system. Using the ROSCoq shim, we ran the program on the robot and provide even experimental evidence of correctness.	algorithm;ar (unix);automated theorem proving;autonomous robot;computation;conley–zehnder theorem;coq (software);correctness (computer science);cyber-physical system;database;distributed computing;dynamical system;experiment;faust;formal verification;high- and low-level;holism;hybrid system;icra;irobot create;jean;key;lecture notes in computer science;map;microsoft cluster server;ncr 5380;naruto shippuden: clash of ninja revolution 3;newton;obstacle avoidance;open-source software;programming language design and implementation;rss;raman scattering;robot operating system;runtime verification;sensor;shim (computing);springer (tank);symposium on logic in computer science;type theory;verification and validation	Abhishek Anand;Ross A. Knepper	2015		10.1007/978-3-319-22102-1_3	artificial intelligence;algorithm	Robotics	-29.42971546334862	35.71647170143825	66870
45810e86d7bce889e0246b686cfe160a0d49970a	a formal software synthesis approach for embedded hard real-time systems	timed systems;formal specification;hardware software codesign;processor scheduling petri nets embedded systems hardware software codesign formal specification program compilers operating system kernels program verification;processor scheduling;resource manager;code generation;real time operating system;program verification;embedded system;formal method;embedded systems;time petri net;critical system;hardware software codesign methodologies;hard real time system;operating system;embedded hard real time systems;software synthesis;petri nets;operating system kernels;program compilers;specification model formal software synthesis embedded hard real time systems software program general purpose language operating system kernels automatic software synthesis method code generation petri nets compilers formal methods heated humidifier scheduling resource management synchronization;embedded software real time systems operating systems software systems program processors kernel resource management embedded system petri nets usability;hard real time;real time systems	Software synthesis is defined as the task of translating a specification into a software program in a general purpose language, in such a way that this software can be compiled by conventional compilers. In general, complex real-time systems rely on specialized operating system kernels. However, the operating system usage may introduce significant overheads as in execution time as in memory requirement. In order to eliminate such overheads, automatic software synthesis methods should be implemented. Such methods comprise real-time operating system services (scheduling, resource management, communication, synchronization), and code generation. Formal methods are a very promising alternative to deal with the complexity of embedded systems, and for improving the degree of confidence in critical systems. We present a formal approach for automatic embedded hard real-time software synthesis based on time Petri nets. In order to illustrate the practical usability of the proposed method, it is shown how to synthesize a C code implementation using a heated-humidifier case study.	code generation (compiler);compiler;computer program;daemon (computing);embedded system;formal methods;kernel (operating system);petri net;real-time clock;real-time computing;real-time operating system;real-time transcription;run time (program lifecycle phase);scheduling (computing);usability;usage share of operating systems	Raimundo S. Barreto;Marília Neves;Meuse N. Oliveira;Paulo Romero Martins Maciel;Eduardo Antonio Guimarães Tavares;Ricardo Massa Ferreira Lima	2004	Proceedings. SBCCI 2004. 17th Symposium on Integrated Circuits and Systems Design (IEEE Cat. No.04TH8784)	10.1145/1016568.1016615	embedded system;embedded operating system;computer architecture;verification and validation;parallel computing;real-time computing;real-time operating system;formal methods;software sizing;computer science;package development process;resource management;software framework;component-based software engineering;software development;operating system;software construction;formal specification;programming language;software deployment;petri net;code generation;software metric;software system;avionics software	Embedded	-24.015363311556513	36.20746730775641	67119
00a33b10c2dbd6fd60391da1f7683a2c2d8c1b0e	process-sensitive software engineering environments: an object-oriented view	layered components;programming environments;object oriented model;concurrent computing;object interaction;process objects;programming environments computer aided software engineering message passing object oriented programming;concurrent objects;software development process;transparent message passing;object oriented programming;location;synchronisation process sensitive software engineering environments object oriented model layered components process objects entity objects service objects object interaction patterns object relationships software development process distribution concurrency actors concurrent objects transparent message passing location;software engineering;synchronisation;computer aided software engineering;concurrency;software engineering environment;software development process distribution;entity objects;object oriented;process sensitive software engineering environments;software engineering object oriented modeling scanning probe microscopy programming computer science australia concurrent computing message passing vehicles access protocols;object relationships;message passing;access protocols;service objects;actors;vehicles;computer science;scanning probe microscopy;programming;object oriented modeling;object interaction patterns;australia	An object-oriented model is proposed, designed as a collection of layered components, for process-sensitive software engineering environments (PSEEs). In the model, three types of object (process objects, entity objects and service objects) are identified to abstract and reflect the behaviour in different aspects of a PSEE. An overview of object interaction patterns, which reflects and captures the relationships between these types of object, is presented. To support software development process distribution and concurrency effectively, we introduce the actor (concurrent object) concept into process objects and entity objects, which allows transparent message passing between objects without concern for location and synchronisation. >		Min Kang;Douglas D. Grant	1994		10.1109/APSEC.1994.465251	real-time computing;chain-of-responsibility pattern;concurrent computing;computer science;theoretical computer science;object-oriented design;distributed computing;data transfer object;distributed object;programming language;object-oriented programming;object-orientation	SE	-32.45314872131738	35.08829020899747	67193
7c02b931ff57f69069fd26237f3ea8e44c6c3b77	decomposition of non-deterministic services for the purpose of replication		Replication can improve performance, availability and reliability of services. However, its application raises several design and implementation problems. One of them is non-determinism of processing on replicas. We propose a “design pattern” for structuring the service so that it is possible to overcome the problem.		Marcin Bazydlo;Szymon Francuzik;Cezary Sobaniec;Dariusz Wawrzyniak	2012		10.1007/978-3-642-32741-4_2	computer science;theoretical computer science;distributed computing	OS	-28.317803173440126	46.31359839732524	67332
0b54f38ac79a27267b0e0b543759d68960bff1f6	hybrid compilation and optimization for java-based digital tv platforms	image loading and decoding;ahead of time compilation;java xlets;digital tv;idle time compilation	The Java-based software platform for interactive digital TV (DTV) is composed of the system/middleware class statically installed on the DTV set-top box and the xlet applications dynamically downloaded from the TV stations. The xlet application includes Java classes and image/text files. The xlets are executed only when the TV viewer initiates an interaction, even if the xlets have been completely downloaded. To achieve high performance on this dual-component, user-initiated system, existing just-in-time (JIT) compilation and optimization is not enough; instead, ahead-of-time and idle-time compilation and optimization are also needed, requiring a hybrid compilation and optimization environment. We constructed such a hybrid environment for a commercial DTV software platform and evaluated it using real, on-air xlet applications. Our experimental results show that the proposed hybrid environment can improve the DTV Java performance by more than three times, compared to the JIT-only environment, with little change to other DTV behavior.	ahead-of-time compilation;compiler;digital television adapter;java performance;just-in-time compilation;mathematical optimization;middleware;set-top box	Dong-Heon Jung;Soo-Mook Moon;Hyeong-Seok Oh	2014	ACM Trans. Embedded Comput. Syst.	10.1145/2506257	embedded system;real-time computing;digital television;computer science;operating system;just-in-time compilation;programming language	PL	-20.330728905879624	36.89453742258817	67557
306247ba152c20b4ea6357d9a135322e901f2985	prototyping distributed multimedia systems using communicating real-time state machines	software prototyping real time systems multimedia systems distributed programming java program debugging quality of service;software prototyping;model analysis;distributed multimedia system;real time;modeled remote multimedia presentation system distributed multimedia system prototyping communicating real time state machines real time systems development distributed multimedia systems modeling language jcrsm java2 based toolset graphical environment debugging java code generation prototyped system real time systems hard deadlines soft deadlines user defined level quality of service timing qos parameters end to end delay multimedia session qos constraints recorded timestamped event histories;code generation;state machine;multimedia systems;modeling language;distributed programming;program debugging;quality of service;multimedia presentation;end to end delay;prototypes multimedia systems quality of service real time systems java system testing debugging timing jitter delay remote monitoring;java;real time systems	This paper describes a methodology for the development of real-time systems and shows its application to the modeling, analysis and implementation of distributed multimedia systems. The methodology is centered on Communicating Real-Time State Machines as the modeling language and is supported by a Java toolset (jCRSM). The latter provides a graphical environment for editing, testing, debugging and Java code generation of a prototyped system. Multimedia systems are particular real-time systems which normally do not have hard deadlines to fulfill but only soft deadlines concerning the achievement of a user-defined level of quality of service. For instance, timing QoS parameters refer to jitter, skew and endto-end delay, which are to be kept bounded throughout a multimedia session. QoS constraints are monitored by assertions on the recorded timestamped event histories. The paper reports some experimental results of a modeled remote multimedia presentation system.	code generation (compiler);debugging;graphical user interface;java;modeling language;quality of service;real-time clock;real-time computing;real-time transcription	Giancarlo Fortino;Libero Nigro	2000		10.1109/EMRTS.2000.854016	embedded system;real-time computing;quality of service;computer science;operating system;end-to-end delay;distributed computing;finite-state machine;modeling language;programming language;java;code generation	Embedded	-33.50243474870838	35.142801161148874	67668
f6027ce1f81f1a792525fa836168f78e73750723	the runtime performance of invokedynamic: an evaluation with a java library	dynamic languages;performance evaluation;invokedynamic;runtime performance;java virtual machine;runtime;software engineering;software engineering invokedynamic java virtual machine runtime performance dynamic languages reflection;programming;java runtime programming benchmark testing performance evaluation;reflection;benchmark testing;java	The Java 7 platform includes the invokedynamic opcode in its virtual machine, a feature that lets programmers define-and dynamically change-the linkage of method call sites, thereby maintaining platform optimizations. A comprehensive evaluation of a new library's performance includes a description of how to optimize real Java applications.	java version history;linkage (software);method (computer programming);opcode;programmer;virtual machine	Francisco Ortin;Patricia Conde;Daniel Fernández Lanvin;Raúl Izquierdo	2014	IEEE Software	10.1109/MS.2013.46	benchmark;programming;java api for xml-based rpc;real-time computing;reflection;jsr 94;java concurrency;computer science;operating system;software engineering;java modeling language;strictfp;real time java;reflection;programming language;java;management;generics in java;scala;java applet;java annotation	PL	-25.48315289790784	36.697499158617944	67725
37f76e868186095a9d14e6e0f68fd3266edc5ee3	the rtdevs/corba environment for simulation-based design of distributed real-time systems	layered architecture;modeling and simulation;software complexity;real time;corba;virtual testing environment;simulation based design;distributed real time system;distributed environment;complex system;continuous simulation;middleware;devs;distributed real time systems;real time corba;model continuity	The increasing complexity of large-scale distributed real time systems demands powerful real time object computing technologies. Furthermore, systematic design approaches are needed to support analysis, design, test, and implementation of these systems. In this paper, we discuss RTDEVS/CORBA, an implementation of DEVS modeling and simulation theory based on real time CORBA communication middleware. With RTDEVS/CORBA, the software model of a complex distributed real time system can be designed and then tested in a virtual testing environment and finally executed in a real distributed environment. This model continuity and simulation-based design approach effectively manages software complexity and consistency problems for complex systems and increases the flexibility for test configurations as well as reduces the time and cost for testing. In the paper, the layered architecture and different implementation issues of RTDEVS/CORBA are studied and discussed. An example application is then given to show how RTDEVS/CORBA supports a framework for model continuity in distributed real time modeling and simulation.	ace;assignment zero;automation;bsd;c++;common object request broker architecture;complex systems;control system;devs;distributed computing;distributed object;dynamical systems theory;earl levine;erlang (programming language);memorandum;middleware;opera (web browser);parallel computing;performance evaluation;programming complexity;quality of service;real-time cmix;real-time operating system;real-time transcription;robotics;scheduling (computing);schmidt decomposition;scott continuity;separation of concerns;simulation;software development;tao;world sudoku championship	Young Kwan Cho;Xiaolin Hu;Bernard P. Zeigler	2003	Simulation	10.1177/0037549703038880	real-time computing;simulation;continuous simulation;computer science;multitier architecture;devs;csiv2;common object request broker architecture;middleware;modeling and simulation;distributed computing;distributed design patterns;programming complexity;distributed computing environment	Embedded	-30.292008807322475	46.31115346380727	67962
ae7375b0ee14706178a074c814a4bcdf87c47698	role of the dasd storage control in an enterprise systems connection environment	tratamiento paralelo;systeme commande;sistema control;architecture systeme;interconnection;fibra optica;traitement parallele;input output equipment;cable optico;acceso directo;medio ambiente empresa;equipo almacenamiento datos;fiber optic;environnement entreprise;equipement stockage donnee;control system;optical cable;equipement entree sortie;acces direct;interconnexion;câble optique;direct access;equipo entrada salida;ibm 3990;arquitectura sistema;enterprise system;firm environment;optical fiber;system architecture;data storage equipment;parallel processing;interconeccion;escon;fibre optique	"""This paper compares the Enterprise Systems Connection Architecture"""" (ESCOflf""""), with its use of fiber optic cables, to the parallel channel architecture introduced with System/360TM. It also describes many of the reasons for the introduction of ESCON. The ESCON implementation for the IBM 3990 Storage Control is described in some detail, including a description of nonsynchronous operation. The paper concludes with a discussion of some of the benefits of ESCON for a 3990 installation, performance considerations, and migration considerations."""	escon;optical fiber cable	Carol P. Grossman	1992	IBM Systems Journal	10.1147/sj.311.0123	embedded system;parallel processing;telecommunications;computer science;engineering;control system;electrical engineering;optical fiber;systems architecture	OS	-19.286665874708326	43.65541193724039	68171
0ffda3da9411bd9df6f37fd7ef34e00fefe4340f	teaching concurrent and distributed computing -- initiatives in rio de janeiro	fault tolerance fault tolerant systems programming wireless sensor networks materials education proposals;application level multitasking;cross cutting approaches;teaching distributed computing concurrent computing wireless sensor network environment systems software course application level multitasking;distributed processing;event based programming;coroutines;fault tolerance;concurrency control;wireless sensor networks concurrency control distributed processing teaching;application level multitasking cross cutting approaches fault tolerance event based programming coroutines;wireless sensor networks;teaching	In this paper we describe two ongoing initiatives for teaching concurrency and distribution in PUC-Rio and UFRJ. One of them is a new approach for teaching distributed systems. Conventional distributed system courses follow a syllabus in which a list of topics is discussed independently and at different levels of abstractions. In Edupar'2012, we proposed a course with a novel approach, using a wireless sensor network environment to pin all topics down to concrete applications and to maintain issues such as fault tolerance and coordination continuously present. The second initiative is a smaller one, in which we insert a new topic in a Systems Software course to allow students to have a better understanding of what is application-level multitasking and of how it can be implemented. In this paper, we report on the experience of teaching the proposed syllabus and the adjustments that were necessary. We also discuss some plans for the courses in 2013.	computer multitasking;concurrency (computer science);distributed computing;fault tolerance;personal and ubiquitous computing;winsock	Adriano Branco;Ana Lúcia de Moura;Noemi de La Rocque Rodriguez;Silvana Rossetto	2013	2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum	10.1109/IPDPSW.2013.33	real-time computing;computer science;distributed computing;computer engineering;distributed concurrency control	Embedded	-33.198498241182264	37.758557624782064	68191
264936c1b42ec9eca9b49d553c35403d6e9b5d39	real-time graphic display of time-sharing system operating characteristics	experimental monitoring facility;bell telephone laboratories;general purpose;debugging tool;real-time graphic display;time-sharing system behavior;general electric;general use;time-sharing system operating characteristic;graphic display monitoring;project mac;timesharing system;time sharing;real time	The Graphic Display Monitoring System (GDM) is an experimental monitoring facility for Multics, a general purpose time-sharing system implemented at Project MAC cooperatively with General Electric and the Bell Telephone Laboratories. GDM allows design, systems programming, and operating staff to graphically view the dynamically changing properties of the timesharing system. It was designed and implemented by the author to provide a medium for experimentation with the real-time observation of time-sharing system behavior. GDM has proven to be very useful both as a measuring instrument and a debugging tool and as such finds very general use.	debugger;debugging;mit computer science and artificial intelligence laboratory;multics;real-time transcription;system programming;time-sharing	Jerrold M. Grochow	1969		10.1145/1478559.1478604	embedded system;real-time computing;simulation;engineering	Robotics	-28.909419805707987	38.638638655320804	68282
2a21bc879027963378303e6b45f31627751fb1b8	transparent autonomization in corba	distributed application;self optimization;servidor proxy;optimisation;informatique mobile;optimizacion;adaptive middleware;implementation;generic proxy;logicial personalizado;software systems;mobile computer;langage java;serveur proxy;corba;qualite service;intergiciel;prototipo;monitoring;estudio caso;aplicacion distribuida;object oriented;transparent shaping;etude cas;oriente objet;middleware;lenguaje java;optimization;monitorage;numeration system;application repartie;quality of service;implementacion;mobile computing;monitoreo;dynamic adaptation;orientado objeto;prototype;autonomic computing;proxy server;service quality;java language;calidad servicio	1389-1286/$ see front matter Published by Elsevi doi:10.1016/j.comnet.2008.12.012 * Corresponding author. Tel.: +1 305 348 1835. E-mail addresses: sadjadi@cs.fiu.edu (S.M. Sad msu.edu (P.K. McKinley). URLs: http://www.cs.fiu.edu/~sadjadi (S.M. Sadj msu.edu/~mckinley (P.K. McKinley). Increasingly, software systems are constructed by integrating and composing multiple existing applications. The resulting complexity increases the need for self-management of the system. However, adding autonomic behavior to composite systems is difficult, especially when the constituent components are heterogeneous and they were not originally designed to support such interactions. Moreover, entangling the code for self-management with the code for the business logic of the original applications may actually increase the complexity of the systems, counter to the desired goal. In this paper, we address autonomization of composite systems that use CORBA, one of the first widely used middleware platforms introduced more than 17 years ago that is still commonly used in numerous systems. We propose a model, called Adaptive CORBA Template (ACT), that enables autonomic behavior to be added to CORBA applications automatically and transparently, that is, without requiring any modifications to the code implementing the business logic of the original applications. To do so, ACT uses ‘‘generic” interceptors, which are added to CORBA applications at startup time and enable autonomic behavior to be introduced later at runtime. We have developed ACT/J, a prototype of ACT in Java. We describe a case study in which ACT/J is used to introduce three types of autonomic behavior (self-healing, self-optimization, and self-configuration) to a distributed surveillance application. Published by Elsevier B.V.	autonomic computing;autonomic networking;business logic;common object request broker architecture;interaction;java;like button;mathematical optimization;middleware;prototype;run time (program lifecycle phase);self-management (computer science);software system	Seyed Masoud Sadjadi;Philip K. McKinley	2009	Computer Networks	10.1016/j.comnet.2008.12.012	embedded system;real-time computing;quality of service;telecommunications;computer science;operating system;common object request broker architecture;middleware;prototype;object-oriented programming;implementation;mobile computing;computer security;service quality;computer network;software system	SE	-28.8213356968718	42.104223382246154	68653
a470f17eb9500a49ce05beb1e4be066b367b3fae	synthesis and optimization of coordination controllers for distributed embedded systems	distributed coordination;communication interface;communication system traffic control;protocols;control system synthesis distributed control embedded system protocols distributed computing communication system control communication system traffic control permission partitioning algorithms embedded computing;distributed embedded system;distributed computing;embedded system;permission;ip;control system synthesis;system design;state space;component model;model of computation;communication system control;distributed control;embedded computing;partitioning algorithms	A main advantage of control composition with modal processes [4] is the enhanced retargetability of the composed behavior over a wide variety of target architectures. Unlike previous component models that hardwire the coordination behavior either explicitly in the components or implicitly in the underlying model of computation, modal processes decouple component functionality and coordination protocols. Retargetability is achieved through the synthesis of distributed mode managers, which abstract away low-level synchronization and control communication details that would otherwise be exposed to the component designer. This paper presents an algorithm for the synthesis and optimization of distributed coordination controllers by computing an optimal projection of the global state space onto each processor. It not only minimizes interprocessor communication traffic for coordination but also reduces controller complexity by minimizing replication.	algorithm;control unit;distributed mode loudspeaker;embedded system;high- and low-level;inter-process communication;mathematical optimization;modal logic;model of computation;optimal projection equations;state space	Pai H. Chou;Gaetano Borriello	2000		10.1145/337292.337520	internet protocol;model of computation;embedded system;communications protocol;real-time computing;computer science;state space;operating system;component object model;distributed computing;systems design	EDA	-33.09632545105603	38.756509004812735	69043
40f7ec67b0865d503acfd935e7d555f638ea1dea	analysis of pure methods using garbage collection	dependence analysis;garbage collection;garbage collector;pure functions;datavetenskap datalogi;just in time;computer science;programvaruteknik;software technology;automatic parallelization;dynamic analysis	"""Parallelization and other optimizations often depend on static dependence analysis. This approach requires methods to be independent regardless of the input data, which is not always the case.  Our contribution is a dynamic analysis """"guessing"""" if methods are pure, i. e., if they do not change state. The analysis is piggybacking on a garbage collector, more specifically, a concurrent, replicating garbage collector. It guesses whether objects are immutable by looking at actual mutations observed by the garbage collector. The analysis is essentially for free. In fact, our concurrent garbage collector including analysis outperforms Boehm's stop-the-world collector (without any analysis), as we show in experiments. Moreover, false guesses can be rolled back efficiently.  The results can be used for just-in-time parallelization allowing an automatic parallelization of methods that are pure over certain periods of time. Hence, compared to parallelization based on static dependence analysis, more programs potentially benefit from parallelization."""	automatic parallelization;dependence analysis;experiment;garbage collection (computer science);immutable object;just-in-time compilation;piggybacking (security);tracing garbage collection	Erik Österlund;Welf Löwe	2012		10.1145/2247684.2247694	garbage;parallel computing;real-time computing;computer science;distributed computing;data pre-processing	PL	-20.02743836301394	35.109944265557836	69218
e51c697b42963d358e17d5bab67ac2d145865bc2	office procedures as a distributed database application	distributed database;management system;exception handling;information system	An office proedure specification system is described. The system is to be implemented as a database application in a distributed database management system being developed at Computer Corporation of America. Because of its data-base application characteristic, the system treats form copying and routing differently from other office information systems. This differences makes controlling and tracing forms easier than it is in other systems. We also introduce a generalized trigger, called trigger-lock, for synchronizing independently created procedures and for exception handling.	distributed database;exception handling;information system;routing	Wen-Te K. Lin;Daniel R. Ries;Barbara T. Blaustein;R. Mark Chilenskas	1983	DATA BASE	10.1145/1017712.1017715	exception handling;database tuning;computer science;software engineering;data mining;management system;database;distributed computing;programming language;management;world wide web;database schema;distributed database;information system;database testing	DB	-27.021300536474886	45.90258085315423	69246
38a34f64d231aceb7ca662e2d30e7f079baecb64	applying formal verification with protocol compiler	verilog formal verification protocol compiler industrial design environment testbench assertion checking networking arena rs232 transceiver pipelined fifo like buffer;protocols;transceivers formal verification protocols program compilers hardware description languages;design flow;hardware description languages;formal verification;transceivers;program compilers;formal verification protocols testing hardware design languages computational modeling debugging sections computer science application software computer industry	This paper gives two examples how to verify designs with Protocol Compiler. Our verification flow is to first create a testbench and simulate the design. Then we modify the testbench and perform a formal verification technique called assertion checking. The examples are taken from the networking arena. The first is a simplified RS232 transceiver, the second a pipelined FIFO-like buffer. We find that assertion checking fits well into the design flow and is easy to use within Protocol Compiler.	assertion (software development);compiler;fifo (computing and electronics);fits;formal verification;pipeline (computing);rs-232;simulation;test bench;transceiver	Christian Stangier;Ulrich Holtmann	1999		10.1109/DSD.2001.952270	communications protocol;computer architecture;parallel computing;verification;formal methods;formal verification;compiler correctness;computer science;design flow;formal equivalence checking;high-level verification;hardware description language;programming language;intelligent verification;functional verification;transceiver	EDA	-33.26710197497169	32.724892966247765	69651
789d37153d6e38851c21cb9f6ad8f942fdd083a3	design and comparison of lightweight group management strategies in envirosuite	dynamic programming;red sin hilo;evaluation performance;reseau capteur;optimisation;programacion dinamica;pistage;performance evaluation;optimizacion;reseau sans fil;programming paradigm;surveillance;surveillance system;evaluacion prestacion;wireless network;rastreo;abstraction;semigrupo;blanco movil;election leader;abstraccion;wireless sensor network;management strategy;vigilancia;red sensores;monitoring;algorithme reparti;poursuite cible;semigroupe;programmation dynamique;eleccion jefe;sensor array;leader election;cible mobile;algoritmo repartido;optimization;semigroup;monitorage;target tracking;monitoreo;distributed algorithm;moving target;tracking	Tracking is one of the major applications of wireless sensor networks. EnviroSuite, as a programming paradigm, provides a comprehensive solution for programming tracking applications, wherein moving environmental targets are uniquely and identically mapped to logical objects to raise the level of programming abstraction. Such mapping is done through distributed group management algorithms, which organize nodes in the vicinity of targets into groups, and maintain the uniqueness and identity of target representation such that each target is given a consistent name. Challenged by tracking fast-moving targets, this paper explores, in a systematic way, various group management optimizations including semi-dynamic leader election, piggy-backed heartbeats, and implicit leader election. The resulting tracking protocol, Lightweight EnviroSuite, is integrated into a surveillance system. Empirical performance evaluation on a network of 200 XSM motes shows that, due to these optimizations, Lightweight EnviroSuite is able to track targets more than 3 times faster than the fastest targets trackable by the original EnviroSuite even when 20% of nodes fail.	algorithm;computer network programming;fastest;high- and low-level;leader election;performance evaluation;programming language;programming paradigm;requirement;semiconductor industry	Liqian Luo;Tarek F. Abdelzaher;Tian He;John A. Stankovic	2005		10.1007/11502593_14	distributed algorithm;simulation;wireless sensor network;telecommunications;computer science;wireless network;dynamic programming;leader election;distributed computing;abstraction;tracking;programming paradigm;semigroup;computer security;sensor array	Mobile	-28.799660776064258	41.54319843351285	69705
7d94115a9f2041fb39012ff87e572891889e1557	object-oriented recovery for non-volatile memory		New non-volatile memory (NVM) technologies enable direct, durable storage of data in an applicationu0027s heap. Durable, randomly accessible memory facilitates the construction of applications that do not lose data at system shutdown or power failure. Existing NVM programming frameworks provide mechanisms to consistently capture a running applicationu0027s state. They do not, however, fully support object-oriented languages or ensure that the persistent heap is consistent with the environment when the application is restarted. rnrnIn this paper, we propose a new NVM language extension and runtime system that supports object-oriented NVM programming and avoids the pitfalls of prior approaches. At the heart of our technique is object reconstruction, which transparently restores and reconstructs a persistent objectu0027s state during program restart. It is implemented in NVMReconstruction, a Clang/LLVM extension and runtime library that provides: (i) transient fields in persistent objects, (ii) support for virtual functions and function pointers, (iii) direct representation of persistent pointers as virtual addresses, and (iv) type-specific reconstruction of a persistent object during program restart. In addition, NVMReconstruction supports updating an applicationu0027s code, even if this causes objects to expand, by providing object migration. NVMReconstruction also can compact the persistent heap to reduce fragmentation. In experiments, we demonstrate the versatility and usability of object reconstruction and its low runtime performance cost.	apl;atomicity (database systems);c++;clang;computation;data compaction;experiment;fork (software development);fragmentation (computing);function pointer;llvm;non-volatile memory;overhead (computing);persistent data structure;programming language;randomness;read-only memory;run time (program lifecycle phase);runtime library;runtime system;shutdown (computing);usability;volatile memory	Nachshon Cohen;Yuejun Chen;James R. Larus	2018	PACMPL	10.1145/3276523	runtime system;pointer (computer programming);runtime library;programming language;programming paradigm;computer science;function pointer;object-oriented programming;virtual function;distributed computing;heap (data structure)	PL	-22.57157246635384	39.76833005759285	70022
9d0cf903ce35b88399c43fb9f138681d460be139	new directions for integrated circuit cards operating systems	sistema operativo;smart card;architecture systeme;management system;service provider;integrated circuit;life cycle;secured method execution;evolucion;tiempo vida;circuito integrado;systeme integre;sistema integrado;multi user;application integration;lifetime;integrated circuit card;operating system;object oriented;integrated circuit card applications;object oriented technologies;oriente objet;arquitectura sistema;systeme exploitation;object oriented technology;duree vie;system architecture;integrated system;orientado objeto;database management system;integrated circuit card operating system;circuit integre;evolution	Integrated circuit cards or smart cards are now well-known. Applications such as electronic purses (cash units stored in cards), subscriber identification cards used in cellular telephone or access keys for pay-TV and information highways emerge in many places with millions of users. More services are required by applications providers and card holders. Mainly, new integrated circuit cards evolve towards non-predefined multi-purpose, open and multi-user applications. Today, operating systems implemented into integrated circuit cards cannot respond to these new trends. They have evolved from simple operating systems defining an hardware abstraction level up to file management systems or database management systems where the card behavior was defined once at the manufacturing level or by the card issuer. The needs for open and flexible card life cycle enabling to accommodate executable code loaded by different service providers require a new generation of smart cards. Operating systems based on object-oriented technologies are key components for future integrated circuit cards applications.	abstraction layer;access key;database;executable;hardware abstraction;integrated circuit;issuing bank;mobile phone;multi-purpose viewer;multi-user;operating system	Pierre Paradinas;Jean-Jacques Vandewalle	1995	Operating Systems Review	10.1145/202453.202466	service provider;embedded system;smart card;java card;computer science;operating system;integrated circuit;evolution;management system;card reader;computer security;contactless smart card;systems architecture	OS	-27.84850485104343	44.38835566840548	70055
c7a967dc0b803e38f929d7f3572d6ab9ca0b3777	an eclipse-based tool for symbolic debugging of distributed object systems	distributed application;distributed computing;distributed object system;middleware;life span	After over thirty years of distributed computing, debugging distributed applications is still regarded as a difficult task. While it could be argued that this condition stems from the complexity of distributed executions, the fast pace of evolution witnessed with distributed computing technologies has also played its role by shortening the life-span of many useful debugging tools. In this paper we present an extensible Eclipse-based tool which brings distributed threads and symbolic debuggers together, resulting in a simple and useful debugging aid. This extensible tool is based on a technique that is supported by elements that are common to synchronous-call middleware implementations, making it a suitable candidate for surviving technology evolution.	deadlock;debug symbol;debugger;debugging;design rationale;distributed component object model;distributed computing;distributed object;eclipse;formal specification;gnu debugger;java;middleware;open-source software;oracle call interface;podc;remote procedure call;replay attack;requirement;scalability;screencast;sensor;software portability;thread (computing);universal instantiation	Giuliano Mega;Fabio Kon	2007		10.1007/978-3-540-76848-7_44	distributed algorithm;parallel computing;real-time computing;computer science;distributed computing;distributed object;distributed design patterns	SE	-24.81620555887977	36.46889868046568	70086
13ecbc6283a97b1b0624674fc630410ba62cbaef	a formal model of a virtual filesystem switch		This work presents a formal model that is part of our effort to construct a verified file system for Flash memory. To modularize the verification we factor out generic aspects into a common component that is inspired by the Linux Virtual Filesystem Switch (VFS) and provides POSIX compatible operations. It relies on an abstract specification of its internal interface to concrete file system implementations (AFS). We proved that preconditions of AFS are respected and that the state is kept consistent. The model can be made executable and mounted into the Linux directory tree using FUSE.	directory (computing);executable;flash memory;formal language;linux;mathematical model;posix;precondition	Gidon Ernst;Gerhard Schellhorn;Dominik Haneberg;Jörg Pfähler;Wolfgang Reif	2012		10.4204/EPTCS.102.5	embedded system;real-time computing;filesystem hierarchy standard;computer science;specfs;operating system;programming language;inode;virtual file system	OS	-26.142197525258023	36.85020390319337	70117
c9c64d07cf7df173551cba608547dd917bb5bf22	flexible intrusion detection using variable-length behavior modeling in distributed environment: application to corba objects	formal specification;client server architecture;architecture client serveur;systeme apprentissage;behavior modeling;sistema informatico;securite informatique;computer system;intrusion detection;specification formelle;computer security;learning systems;especificacion formal;distributed environment;intrusion detection systems;arquitectura cliente servidor;systeme informatique;systeme detection intrusion	This paper presents an approach of the intrusion detection problem applied to CORBA-type distributed environments. The approach is based on the measure of deviation from client reference behaviors towards the CORBA servant objects to be protected. We consider a client behavior as a sequence of invoked requests between each couple of client-server, during each connection of the observed client. We construct, during a training period, a client behavior model based on variable-length branches tree representation. This model both takes into account the series of invoked requests and their parameter values. To make our approach more flexible, we construct, at the end of the training period, a tolerance interval for each numerical parameter. These intervals allow deviation between observed and learned values to be measured. This article presents our preliminary results and introduces our future works.	common object request broker architecture;intrusion detection system	Zakia Marrakchi;Ludovic Mé;Bernard Vivinis;Benjamin Morin	2000		10.1007/3-540-39945-3_9	intrusion detection system;embedded system;real-time computing;computer science;artificial intelligence;operating system;database;distributed computing;computer security	SE	-30.771258447480527	36.93825015079317	70578
0efba25fe758469eb79a935d1b97e65377c1d351	simulators: virtual machines of the past (and future)	virtual machine;hardware design	"""Simulators are a form of """"virtual machine"""" intended to address a simple problem: the absence of real hardware. Simulators for past systems address the loss of real hardware and preserve the usability of software after real hardware has vanished. Simulators for future systems address the variability of future hardware designs and facilitate the development of software before real hardware exists."""	interpreter (computing);simulation;spatial variability;usability;virtual machine	Bob Supnik	2004	ACM Queue	10.1145/1016998.1017002	hardware compatibility list;real-time computing;simulation;computer science;virtual machine;operating system;hardware architecture	Arch	-25.10221004479036	37.96477365673077	70624
003d47b00959c6017231289da59733f66491c6a8	objects and actions in reliable distributed systems	distributed system;software reliability data structures multiprocessing programs multivariable control systems;communication system;recovery block;reliability problem failure atomicity object based systems transmission failures node crashes recovery block communication system distributed systems robust distributed programs atomic actions objects abstract data types nondistributed programs atomic action mechanism prototype distributed systems;abstract data types;robust distributed programs;atomic action mechanism;nondistributed programs;transmission failures;failure atomicity;atomic actions;object based systems;reliability problem;objects;node crashes;distributed systems;prototype distributed systems	This paper describes a method for constructing robust distributed programs. The method is based upon the provision of atomic actions that operate upon objects (instances of abstract data types). The paper begins by constructing robustnon-distributed programs using the atomicaction mechanism and then proceeds to showhow robust distributed programs can be constructed in a similar fashion. Finally, the paper briefly examines other prototy pedistributed systems and examines their approachto the reliability problem.	distributed computing	Santosh K. Shrivastava;Graeme N. Dixon;Graham D. Parrington	1987	Software Engineering Journal	10.1049/sej.1987.0021	real-time computing;computer science;object;theoretical computer science;distributed computing;programming language;abstract data type;communications system	SE	-23.829793714139992	44.15092464378945	71034
880d5b5387555429ce0aadb90376532940402a4a	camelot and avalon: a distributed transaction facility	distributed transactions	Part I The Extended Camelot Interface Chapter 1 Introduction to Camelot 1.1 Background 1.2 A Transaction Example 1.3 Overview of the Camelot Distributed Transaction Facility 1.4 Major Camelot Functions 1.5 Camelot from a User's Point of View Chapter 2 An Introduction to Mach for Camelot Users 2.1 Tasks and Threads 2.2 Virtual Memory Management 2.3 Interprocess Communication 2.4 Mach Interface Generator Chapter 3 The Camelot Library 3.1 Introduction 3.2 Using the Camelot Library 3.3 Application Basics 3.4 Server Basics 3.5 Caveats 3.6 Advanced Constructs Chapter 4 Camelot Node Configuration 4.1 Server Maintenance 4.2 Account Maintenance 4.3 Accessing a Remote Node Server 4.4 The Node Server Database 4.5 Commands Listed Chapter 5 A Sample Camelot Application and Server 5.1 Introduction 5.2 Sample Execution 5.3 The Application 5.4 The Server 5.5 Installation Part II The Primitive Camelot Interface Chapter 6 The Structure of Camelot 6.1 The Camelot Architecture 6.2 An Example Message Flow Chapter 7 Mach for Camelot Implementors 7.1 Interprocess Communication 7.2 The External Memory Management Interface 7.3 C Threads Chapter 8 Recoverable Storage Management in Camelot 8.1 Recoverable Segments and Regions 8.2 Initialization 8.3 Mapping 8.4 Forward Processing 8.5 The Shared Memory Queues 8.6 Recovery Processing Chapter 9 Transaction Management in Camelot 9.1 The Nested Transaction Model 9.2 Transaction Services for Applications 9.3 Transaction Services for Servers Chapter 10 Camelot Node Management 10.1 The NA Interface Part III Design Rationale Chapter 11 The Design of Camelot 11.1 Introduction 11.2 Architecture 11.3 Algorithms 11.4 Related Systems Work 11.5 Conclusions Chapter 12 The Design of the Camelot Library 12.1 Introduction 12.2 Architecture 12.3 Related Work 12.4 Conclusions Chapter 13 The Design of the Camelot Local Log Manager 13.1 Introduction 13.2 Architecture 13.3 Algorithms 13.4 Related Work 13.5 Conclusions Chapter 14 The Design of the Camelot Disk Manager 14.1 Introduction 14.2 Architecture 14.3 Algorithms and Data Structures 14.4 Related Work 14.5 Discussion Chapter 15 The Design of the Camelot Recovery Manager 15.1 Introduction 15.2 Architecture 15.3 Algorithms 15.4 Related Work 15.5 Conclusions Chapter 16 The Design of the Camelot Transaction Manager 16.1 Introduction 16.2 Architecture 16.3 Algorithms 16.4 Related Work 16.5 Conclusions Chapter 17 The Design of the Camelot Communication Manager 17.1 Introduction 17.2 Architecture 17.3 Algorithms 17.4 Related Work 17.5 Conclusions Chapter 18 Performance of Select Camelot Functions 18.1 Performance Metrics 18.2 Library Costs 18.3 Recoverable Virtual Memory Costs 18.4 Recovery Costs Part IV The Avalon Language Chapter 19 A Tutorial Introduction to the Avalon Language 19.1 Terminology 19.2 Array of Atomic Integers 19.3 FIFO Queue 19.4 Atomic Counters Chapter 20 Reference Manual 20.1 Lexical Considerations 20.2 Servers 20.3 Base Classes 20.4 Control Structures 20.5 Transmission of Data Chapter 21 Library 21.1 Non-atomic Avalon/C++ Types and Type Generators 21.2 Atomic Types 21.3 Catalog Server Chapter 22 Guidelines for Programmers 22.1 Choosing Identifiers 22.2 Using and Implementing Avalon Types 22.3 Constructing an Avalon Program 22.4 For Experts Only Part V Advanced Features Chapter 23 Common Lisp Interface 23.1 Introduction 23.2 Accessing Camelot Servers from Lisp 23.3 Examples 23.4 The Lisp Recoverable Object Server 23.5 Summary and Future Work Chapter 24 Strongbox 24.1 Introduction 24.2 Design Goals 24.3 Strongbox Architecture 24.4 Converting Camelot Clients and Servers to be Secure 24.5 Secure Loader and White Pages Server 24.6 Interfaces 24.7 Security Algorithms 24.8 Special Issues 24.9 Conclusions Chapter 25 The Design of the Camelot Distributed Log Facility 25.1 Introduction 25.2 Architecture 25.3 Algorithms 25.4 Related Work 25.5 Conclusions Part VI Appendices Appendix A Debugging A.1 Avoiding Bugs A.2 Tools and Techniques Appendix B Abort Codes B.1 System Abort Codes B.2 Library Abort Codes Appendix C Camelot Interface Specification C.1 AT Interface C.2 CA Interface C.3 CS Interface C.4 CT Interface C.5 DL Interface C.6 DN Interface C.7 DR Interface C.8 DS Interface C.9 DT Interface C.10 LD Interface C.11 MD Interface C.12 MR Interface C.13 MT Interface C.14 MX Interface C.15 NA Interface C.16 ND Interface C.17 RD Interface C.18 RT Interface C.19 SR Interface C.20 ST Interface C.21 TA Interface C.22 TC Interface C.23 TD Interface C.24 TR Interface C.25 TS Interface Appendix D Avalon Grammar D.1 Expressions D.2 Declarations D.3 Statements D.4 External Definitions Bibliography Index	avalon;distributed transaction	Jeffrey L. Eppinger;Lily B. Mummert;Alfred Z. Spector	1991			real-time computing;computer science;theoretical computer science;database	DB	-28.080354275189816	36.749261053932905	71038
d9be0c640dd3504131089f63bd661f54635af09c	design and implementation of grid file management system hotfile	file transfer;distributed system;access grid;systeme reparti;management system;protocole transmission;gestion archivos;transferencia fichero;gestion fichier;file management;grid;transport protocols;ftp;protocolo transmision;sistema repartido;transfert fichier;design and implementation;rejilla;protocole transfert fichier;grille;transport protocol;file transfer protocol;protocole transport;transmission protocol	Hotfile is a user level file management system. It wraps GridFTP and GASS or any other file transfer protocol compatible with hotfile structure into a unified vegafile protocol. Based on virtual grid file layer and a set of basic grid file operations, users can access grid file without knowing the physical transport protocol of the file. Test result shows the overhead of vegafile protocol is little in file transfer and operation. Further vegafile transfer experiment shows when file size is smaller than 1M byte, Vega file copy with GASS has higher band- width, where as file is larger than 1M byte, Vega file copy with GridFTP has higher bandwidth.	grid file;management system	Liqiang Cao;Jie Qiu;Li Zha;Haiyan Yu;Wei Li;Yuzhong Sun	2004		10.1007/978-3-540-30208-7_23	fork;self-certifying file system;embedded system;file transfer protocol;torrent file;indexed file;memory-mapped file;device file;computer file;zap file;computer science;class implementation file;stub file;versioning file system;operating system;unix file types;ssh file transfer protocol;journaling file system;database;open;file system fragmentation;transport layer;design rule for camera file system;file area network;file control block;virtual file system	HPC	-19.4571973604062	45.08694198813014	71055
2855fc892538b61a0df81d1677c4d54a9da3f13f	protecting the dynamic dispatch in c++ by dependability aspects		Computer systems, especially devices with highly-miniaturized feature sizes, are unreliable. Data memory is susceptible to a number of physical effects that cause faults, which can be observed as spontaneous bit flips. Although in many application scenarios corrupt data is harmless (“almost” correct result often suffices), control-flow transitions are very sensitive to faults. Indirect jumps, such as the dynamic dispatch of virtual functions in C++, often crash the system in case of a single bit flip. This paper describes a suitable software-based fault-tolerance mechanism, which can be applied to arbitrary C++ software by source-to-source compilation. The overall cost for this mechanism is below 10 % for both runtime and memory overhead. Our evaluation results show that this approach eliminates 67.1 % of all irregular program terminations in a case study using an embedded weather-station software, whose entire data memory is corrupted by single-bit flips.	acceptance testing;algorithm;aspect-oriented programming;baseline (configuration management);c++;computer data storage;control flow;dependability;dynamic data;dynamic dispatch;embedded system;fault tolerance;flash memory;overhead (computing);protection mechanism;redundancy (engineering);reliability engineering;source-to-source compiler;spontaneous order	Christoph Borchert;Horst Schirmeier;Olaf Spinczyk	2012			real-time computing;software;virtual function;dynamic dispatch;flip;computer science;dependability;crash	SE	-22.470492722926128	39.88721097948714	71374
2c3eb4b6887b438936ac6803dafecf2c7e927886	message communication facilities for distributed real-time systems based on concurrent object-oriented paradigm	connection oriented communication	With the development of high-speed communication services in public communication networks, there is a demand for the application of distributed processing based on the concurrent object-oriented paradigm to the communication service control software. This paper discusses message communication facilities with a high processing ability per unit time, a short processing time, and a high reliability that can be applied to communication service control. In the proposed facilities, a buffer with the fixed length used to store the message content is allocated to the shared space in each communication control node, which can be accessed from all user space. By passing the pointer to the buffer, communication processing is made efficient and management overhead is reduced. Reliability is improved by memory that checks unauthorized access to the message buffer in the shared space. In order to realize the efficient communication of large-scale messages, outline message communication is supported, using the page map switching and copy-on-write control. In internode communication, the internode communication control object multiplexes and processes the messages by the connection set between the nodes. Between the internode communication control object and the transmission/reception object, the number of copies is reduced by passing the pointer to the buffer.	programming paradigm;real-time cmix;real-time computing	Satoshi Tanaka;Katsumi Maruyama;Minoru Kubota;Shigeki Yamada	1997	Systems and Computers in Japan	10.1002/(SICI)1520-684X(199704)28:4%3C85::AID-SCJ9%3E3.0.CO;2-L	communication endpoint;embedded system;real-time computing;real-time operating system;competition;telecommunications;computer science;connection-oriented communication;communication source;operating system;computer performance;object-oriented programming;systems architecture	Embedded	-27.397825022432674	45.67713953226423	71561
d02a1c766662ed3c0fce1359c3a363ead04848c9	from functions to object-orientation by abstraction	universiteitsbibliotheek	In previous work we de veloped a frame work of computational models for function and object execution. Themodels on an higher le v l of abstraction in this frame work allow for concurrent e xecution of functions and objects. We show that the computational model for object execution complies with the fundamentals of object-orientation. Ke ywords: programming, computational model, e xecution model, machine model, sequential e xecution, concurrenc y, object-orientation	computational model;concurrency (computer science);ke software;message passing;model of computation;scheduling (computing);shared memory	Bob Diertens	2012	CoRR		real-time computing;computer science;theoretical computer science;programming language	AI	-26.724582939979108	33.036064406956854	71634
bafcca5e6eda210356476a9e2a401f4a340f3d79	a componentized approach to grid enabling seismic wave modeling application	tratamiento datos;modelizacion;geophysics;sismo;algorithm complexity;complejidad algoritmo;seisme;equation onde;logicial personalizado;distributed computing;geofisica;data processing;traitement donnee;grid middleware;seismic response;earthquakes;onde sismique;onda sismica;ecuacion onda;intergiciel;grid;oil and gas;modelisation;wave equation;complexite algorithme;seismic waves;rejilla;comportement utilisateur;seismic wave;grille;calculo repartido;middleware;user behavior;synthetic seismogram;modeling;imperial college e science networked infrastructure;calcul reparti;comportamiento usuario;geophysique	Seismic modeling is an integral part of the seismic data processing for oil and gas exploration, as it provides us the seismic response for a given earth model. Grid enabled seismic wave modeling can facilitate users in the area of geophysics to calculate synthetic seismograms using federated HPC resources and complex solution algorithms without knowing their complexities. The present paper is about componentization of the wave equation based seismic modeling algorithm and its implement using Imperial College e-Science Networked Infrastructure (ICENI) Grid Middleware.	algorithm;e-science;floor and ceiling functions;middleware;synthetic intelligence	Dheeraj Bhardwaj;Jeremy Cohen;Steve McGough;Steven Newhouse	2004		10.1007/978-3-540-30501-9_23	seismic wave;simulation;data processing;seismic to simulation;computer science;operating system	HPC	-28.02550288073394	43.23674659642466	71751
a8a6652e1a857d4a7d8935542e799bfd99b2a47b	a fault-tolerant multiprocessor system with rollback recovery capabilities	fault tolerant		multiprocessing	A. M. Feridun;Kang G. Shin	1981			rollback;distributed computing;computer science;multiprocessing;fault tolerance	OS	-19.727147933383055	43.47914801602542	71759
033988602c274aa31b3f59f3eb50c540e6c77896	a set of multicast primitives for fault tolerant distributed systems	causal ordering;total ordering;fault tolerance;distributed systems;multicast	Reliable multicast among the members of a group is recognized as an important service to support emerging multimedia and distributed applications, These applications have a variety of multicast requirements that may be matched with the semantics of the multicast primitives provided by an underlying layer.This paper deals with the design and the implementation of a high level set of multicast primitives that combine both message ordering and message atomicity semantics. The primitives provide uniform agreement in a synchronous environment in which both omission and crash failures may occur. We introduce a novel algorithmic approach through which the normal processing of the messages can be performed together with the recovery actions that are required to cope with failures. As a consequence, under failure conditions the algorithms perform better in terms of both network load and throughput. Nonetheless, a comparable behaviour under reliable conditions is ensured. Furthermore, by using a stable storage as part of the fault tolerance method, the algorithms autonomously distinguish amongst permanent (crashes) or transient (omission) failures. This makes them independent of the underlying transport service and adaptable to different protocol suites.The paper also contains the analysis of the performances obtained from the initial implementation of the described primitives.	distributed computing;multicast	Elena Pagani;Gian Paolo Rossi	1995	J. High Speed Networks	10.3233/JHS-1995-4306	fault tolerance;real-time computing;multicast;computer science;operating system;pragmatic general multicast;distributed computing;computer security;total order;computer network	Networks	-23.297101473996733	45.34057935669369	71840
8df69b3470bc0000de7b7c2df156c41685d35992	timed migration and interaction with access permissions	mobile agents;professor maciej koutny;specification;operational semantics;professor gabriel ciobanu;eprints newcastle university;open access;distributed systems;static analysis;communication;access permissions	We introduce and study a process algebra able to model the systems composed of processes (agents) which may migrate within a distributed environment comprising a number of distinct locations. Two processes may communicate if they are present in the same location and, in addition, they have appropriate access permissions to communicate over a channel. Access permissions are dynamic, and processes can acquire new access permissions or lose some existing permissions while migrating from one location to another. Timing constraints coordinate and control the communication between processes and migration between locations. Then we completely characterise those situations when a process is always guaranteed to possess safe access permissions. The consequences of such a result are twofold. First, we are able to validate systems where one does not need to check (at least partially) access permissions as they are guaranteed not to be violated, improving efficiency of implementation. Second, one can design systems in which processes are not blocked (deadlocked) because of the lack of dynamically changing access permissions. © 2011 Newcastle University. Printed and published by Newcastle University, Computing Science, Claremont Tower, Claremont Road, Newcastle upon Tyne, NE1 7RU, England. Bibliographical details CIOBANU, G., KOUTNY, M. Timed Migration and Interaction with Access Permissions [By] G. Ciobanu, M. Koutny Newcastle upon Tyne: Newcastle University: Computing Science, 2011. (Newcastle University, Computing Science, Technical Report Series, No. CS-TR-1291)	cs games;computer science;file system permissions;intelligent agent;process (computing);process calculus;silk road;timed automaton;tower of hanoi	Gabriel Ciobanu;Maciej Koutny	2011		10.1007/978-3-642-21437-0_23	real-time computing;computer science;distributed computing;programming language;operational semantics;computer security;specification;static analysis	Security	-30.582523495941377	33.73893332485163	72130
2e12161d9f553541c0072ab52fff4ae2cf2a60f0	k-bounded set objects in eventually synchronous distributed systems with churn and continuous accesses	distributed system;churn;continuous accesses;dynamic distributed system;synchronous system;infinite arrival model;fpga reconfiguration;dependability;eventually synchronous system;k bounded set object	"""This paper introduces a """"k-bounded set object"""", namely a shared object with limited memory that allows processes to add and remove values as well as take a snapshot of its content. The interest of the k-bounded set lies in the fact that it can be used to program useful abstractions for dynamic distributed systems, such as an eventual participant detector."""	computation;distributed algorithm;distributed computing;library (computing);sm4all;snapshot (computer storage)	Roberto Baldoni;Silvia Bonomi;Michel Raynal	2011		10.1145/1978582.1978603	real-time computing;computer science;theoretical computer science;distributed computing;distributed object	Theory	-23.6736826853047	44.12963962206598	72338
fab2f44a515557c1baf138ed3d22d1510f06a653	easy impossibility proofs for distributed consensus problems	distributed computing;distributed consensus;distribution;graphs;fault tolerant;faults;computations;clock synchronization;consensus problem	Easy proofs are given, of the impossibility of solving several consensus problems (Byzantine agreement, weak agreement, Byzantine firing squad, approximate agreement and clock synchronization) in certain communication graphs.	byzantine fault tolerance;computation;consensus (computer science);correctness (computer science);covering graph;graph (discrete mathematics);network topology;software bug	Michael J. Fischer;Nancy A. Lynch;Michael Merritt	1985		10.1145/323596.323602	distribution;clock synchronization;real-time computing;consensus;computer science;quantum byzantine agreement;theoretical computer science;computation;distributed computing;fault;graph	Theory	-22.25504624627377	43.91457129035312	72406
9686ceb6eb7bd19ec042c365dcdf79591a43c0c8	design of a middleware interface for arinc 429 data bus	avionics;protocols;design and development;object oriented programming;middleware aerospace electronics production facilities computer architecture hardware protocols;system buses;computer architecture;embedded systems;c language;object oriented;production facilities;aerospace electronics;middleware;real time communication;avionics hardware board model middleware interface arinc 429 data bus middleware software layer real time communication embedded avionics modules c object oriented based structure;user interfaces;user interfaces avionics c language embedded systems middleware object oriented programming system buses;hardware	This work is focused on the design and development of a middleware software layer which will enable real-time communication among different embedded avionics modules through an ARINC 429 bus. The implemented layer is based on a C++ object-oriented (OO)-based structure and it has been designed in accordance with middleware concepts. It makes each specific avionics application independent from the bus, from the manufacturers' hardware and finally, from the avionics hardware board model.	arinc 429;abstract factory pattern;application programming interface;avionics full-duplex switched ethernet;bus (computing);c++;design pattern;embedded system;factory method pattern;fly-by-wire;interconnection;mathematical optimization;middleware;motherboard;next-generation network;operating system;programming tool;real-time transcription;real-time web;requirement;system bus	L. M. Parrilla;A. L. Rodriguez;A. Simon-Muela;M. M. Prats	2012	IEEE Transactions on Aerospace and Electronic Systems	10.1109/TAES.2012.6178053	avionics;embedded system;real-time computing;integrated modular avionics;arinc 429;computer science;operating system;middleware;arinc 661;object-oriented programming	Embedded	-32.73286689672222	39.03832906073114	72412
04b6c8f56a8de69f8ee655809e74060f726704b5	using a wcet analysis tool in real-time systems education	004;real time;embedded system;off the shelf;lego mindstorms;real time systems	To reach a more widespread use, WCET analysis tools need to be a standard part in the education of embedded systems developers. Many real-time courses in academia use Lego Mindstorms, an off-the-shelf kit of Lego bricks for building and controlling small prototype robots. We describe work on porting the Bound-T WCET analysis tool to the Lego Mindstorms microprocessor; the Renesas H8/3292. We believe that this work will make students, and indirectly the industry of tomorrow, aware of the benefits of WCET analysis tools. We also present the real-time laboratory framework in which this WCET analysis tool will be used. The framework has been developed with schedulability and timing predictability in mind, and is already used in a number of real-time courses given at M̈ alardalen University in Sweden. The developed WCET tool and the real-time laboratory framework will be freely available for academic use.	brickos;computer multitasking;embedded system;h8 family;lego mindstorms;logic analyzer;memory management;microprocessor;operating system;posix;preemption (computing);prototype;real-time clock;real-time computing;real-time transcription;robot;scheduling (computing);semaphore (programming);sensor;sourceforge;worst-case execution time	Samuel Petersson;Andreas Ermedahl;Anders Pettersson;Daniel Sundmark;Niklas Holsti	2005		10.4230/OASIcs.WCET.2005.812	embedded system;real-time computing;simulation;computer science;operating system	Embedded	-28.374125751061896	37.9324464792926	72450
8dd51d75fcfd63420ad0d599f1963de5ace0aaf4	simds: a simulation environment for the design of distributed database systems	distributed system;systems;information systems;real time;distributed transactions;physical design;real time simulation;database management;support system;distributed database system;design and implementation;information system;distributed systems;transaction processing;simulation support systems;distributed simulation;user datagram protocol;simulation environment	Design of a distributed transaction processing system is a complex process. The paper describes the design and implementation of a general purpose scalable simulation environment (SimDS) for designing and evaluating the performance of distributed transaction processing systems. SimDS is a distributed simulation system where each data server is implemented as a separate process that communicates with each other through user datagram protocol. The paper describes the features of SimDS including various design policies that can be modeled by the system. It also discusses different design issues that one needs to consider in the implementation of a distributed simulation environment. The paper concludes with some test examples where SimDS was used to simulate different configurations of a real-time transaction processing system.	datagram;distributed database;distributed transaction;real-time clock;scalability;server (computing);simulation;transaction processing system	Alok R. Chaturvedi;Samir Gupta;Subhajyoti Bandyopadhyay	1998	DATA BASE	10.1145/313310.313342	real-time computing;computer science;database;distributed computing;information system	DB	-28.397134378906603	45.81560356251107	72524
3442ee50dfbc3b63a41fc9b383ac14cefbea7870	engineering safe, real-time distributed control systems	parallel and distributed system;behaviour tracking;control systems;concurrent computing;parallel physical environment;computerised control;application software;reactive computer control systems;distributed control system;real time;nontrivial industrial applications;parallel programming;real time systems distributed control control systems application software software safety concurrent computing physics computing electrical equipment industry system recovery software standards;electrical equipment industry;software engineering;physics computing;concurrent modelling techniques;minimal safety standards;control system;system recovery;software safety;minimal safety standards safe real time distributed control system engineering reactive computer control systems behaviour tracking parallel physical environment nontrivial industrial applications concurrent modelling techniques system complexities hard real time constraints deadlock software engineering;safety critical software;parallel programming real time systems distributed control computerised control safety critical software software engineering control systems;deadlock;industrial application;software standards;computer control;physical environment;hard real time constraints;safe real time distributed control system engineering;distributed control;system complexities;hard real time;real time systems	Reactive computer control systems need to track the behaviour of their inherently parallel physical environment. Hence, most non-trivial industrial applications may depend on concurrent modelling techniques to handle system complexities including hard real-time constraints. Failure of such systems can lead to unacceptable consequences and can therefore be deemed as safety-related with respect to their application. Parallel and distributed systems can exhibit undesirable behaviours, e.g. deadlock, which could render a control system unsafe. This paper proposes that a set of undesirable parallel behaviours can be classified as unsafe for all applications and reviews a technique that can be employed to avoid or mitigate against them. The approach needed by software engineers of parallel and distributed systems to ,facilitate this and meet the minimal safety standards is also given.	computer control company;deadlock;distributed computing;distributed control system;real-time clock;real-time computing;real-time transcription;software engineer	Peter R. Croll;Chris Rudram;Colin Chambers;Naoshi Uchihira	1998		10.1109/EURMIC.1998.711838	control engineering;real-time computing;computer science;distributed computing	SE	-33.607575108415126	36.47952185549879	72552
7167e51b0f3c8483fe7497e78e9e2694d9e5e721	analysis and modeling of correlated failures in multicomputer systems	tolerancia falta;modelizacion;correlacion;evaluation performance;c dependent model;performance evaluation;modelo markov;multiprocessor;computation theory;shared resources;evaluacion prestacion;sistema informatico;computer system;dependence;dependance;p dependent model;modelisation;failure analysis analytical models performance analysis information analysis performance evaluation independent component analysis markov processes stress measurement fault tolerant systems availability;fault tolerant computing;markov model;propagacion;fault tolerance;dependability;multicomputer systems;defaillance;systeme informatique;p dependent model correlated failures multicomputer systems dec vax cluster dependability shared resources c dependent model;dec vax cluster;multiprocessing systems;failures;correlation;modele markov;correlated failures;multiprocesador;multiprocessing systems computation theory fault tolerant computing;modeling;fallo;tolerance faute;propagation;analytical model;dependencia;multiprocesseur	Based on the measurements from two DEC VAXcluster multicomputer systems, this paper addresses the issue of correlated failures. In particular, the characteristics of correlated failures, the impact of correlated failures on dependability, and the modeling of correlated failures are discussed. It is found from the data that most correlated failures are related to errors in shared resources and propagate from one machine to another. Comparisons between measurement-based models and analytical models that assume failure independence show that the impact of correlated failures on dependability is significant. l k o validated models, the c-dependent model and the p-dependent model, are developed to evaluate dependability of systems with correlated failures.	dependability;parallel computing;vmscluster	Dong Tang;Ravishankar K. Iyer	1992	IEEE Trans. Computers	10.1109/12.142683	embedded system;fault tolerance;parallel computing;real-time computing;multiprocessing;systems modeling;theory of computation;computer science;operating system;dependability;distributed computing;markov model;correlation	Metrics	-21.594099778921255	41.53868964772278	72893
c3116e0dadece20b8b84eb25670b04671b7b5c01	estimating the impact of heap liveness information on space consumption in java	java;program analysis;garbage collection;strategies;compilers;garbage collector;memory management	We study the potential impact of different kinds of liveness information on the space consumption of a program in a garbage collected environment, specifically for Java. The idea is to measure the time difference between the actual time an object is collected by the garbage collector (GC) and the potential earliest time an object could be collected assuming liveness information were available. We focus on the following kinds of liveness information: (i) stack-reference liveness (local reference variable liveness in Java), (ii) global-reference liveness (static reference variable liveness in Java), (iii) heap-reference liveness (instance reference variable liveness or array reference liveness in Java), and (vi) any combination of (i)-(iii). We also provide some insights on the kind of interface between a compiler and GC that could achieve these potential savings.The Java Virtual Machine (JVM) was instrumented to measure (dynamic) liveness information. Experimental results are given for 10 benchmarks, including 5 of the SPEC-jvm98 benchmark suite. We show that in general stack-reference liveness may yield small benefits, global-reference liveness combined with stack-reference liveness may yield medium benefits, and heap-reference liveness yields the largest potential benefit. Specifically, for heap-reference liveness we measure an average potential savings of 39% using an interface with complete liveness information, and an average savings of 15% using a more restricted interface.	java;liveness	Ran Shaham;Elliot K. Kolodner;Shmuel Sagiv	2002		10.1145/773039.512437	compiler;real-time computing;computer science;operating system;distributed computing;computer performance;garbage collection;programming language;liveness	PL	-19.991795672972543	35.65601527404031	73352
acdcaad7b1117018967cddc99dd72cc4a39ffa0d	logical time in visualizations produced by parallel programs	data structures;data visualisation;parallel programming;visual programming;mimd;coherent animations;logical time;multiple data stream;multiple instruction stream;parallel program behavior;program behavior;user-defined abstractions;visualization	"""Visualization tools that display data as it is manipulated by a parallel, MIMD computation must contend with the effects of asynchronous execution. We have developed techniques that manipulate logical time in order to produce coherent animations of parallel program behavior despite the presence of asynchrony. Our techniques """"interpret"""" program behavior in light of user-defined abstractions and generate animations based on a logical rather than a physical view of time. If this interpretation succeeds, the resulting animation is easily understood; if it fails, the programmer can be assured that the failure was not an artifact of the visualization. Here we demonstrate that these techniques can be generally applied to enhance visualizations of a variety of types of data as it is produced by parallel, MIMD computations."""	asynchrony (computer programming);coherence (physics);computation;interpreter (computing);mimd;programmer;synchronous programming language	Janice E. Cuny;Alfred Hough;Joydip Kunda	1992			anime;synchronization;parallel computing;vector field;visualization;advection;mimd;computer science;theoretical computer science;operating system;visual programming language;programming language;debugging;computational model;data visualization;climate model;wind;computer graphics (images)	HPC	-19.972596325616518	39.00068091689449	73425
912fa6f2dedd390cd1dfb5c534d526814c954e26	high availability in a real-time system	timed systems;high availability;software tool;fault tolerant;programming paradigm;real time;embedded real time systems;transport layer;distributed scheduling;control system;robot control;hard real time system;failure recovery;real time application;real time systems;time constraint	The area of building  embedded real-time systems  is one inwhich the applications being designed are more advanced than theavailable underlying system support. Examples of such applicationscan be found in several fields, including robot control, avionics,and plant control systems. These systems all have hard real-timerequirements: if a deadline is missed, then the result iscatastrophic. Furthermore, such deadlines must often be met even inthe face of bounded processor or network failures. Yet, theprinciples for building such systems are still being developed andthe availability of systems supporting these principles is verylimited.  One of the most important characteristics required by areal-time system is  predictability , and predictability canbe met in part by ensuring that all timing constraints are met. Inorder to meet timing constraints, the worst case execution must becomputable. Hence, all actions need to be time bounded in order tocompute the cost of a given thread, and a scheduling policy must beused that guarantees resource contention does not cause deadlinesto be missed [LL73, SRL90].  Several recent research projects have addressed the problem ofpredictability both in the context of centralized and distributedsystems, including ARTS [TM89], RT-Mach [TNR90], MARS [DRSK89], andSpring [SR87, SR89]. These projects are based on real-timescheduling algorithms, and usually also include tools for theoff-line development of pre-defined schedules. The issue ofpredictable operation in the face of crashes and network failures,however, has not been as well addressed.  Failures are masked by using redundancy. For example, in adistributed system the failure of a given process can be masked byreplicating the process on several different machines. By doing so,the failure of one replica (caused by the crash of the machine, forexample), does not imply a failure in the service: the otherreplicas can still provide the desired service [Sch90].  Even ignoring predictability, the development of fault-tolerantapplications can be a complex task when the programmer does nothave supporting software tools. At Cornell, we have developed theISIS toolkit that supplies a group programming paradigm forbuilding fault-tolerant programs [BJS87, BC91]. However, thecurrent version of this system is not suitable for buildingreal-time programs. ISIS runs on top of Unix and contains noscheduling support for writing predictable real-timeapplications.  Our goal is to create an environment that supports thedevelopment of hard real-time systems even in the face of resourceloss.  Corto , the system we are building, will support thebasic programming abstractions of ISIS; namely, ordered delivery ofmessages to groups of processes and agreement on membership. Cortowill also support the predictable scheduling of processes andcommunication that systems like ARTS and RT-Mach provide.  We are finding it challenging to integrate these two goals. ISISsupports a model of programming called  virtual synchrony  inwhich events such as failure, recovery and message delivery aretotally ordered. This abstraction is fundamental to ISIS; becauseof virtual synchrony, building applications that maintaindistributed state in the face of changing resources becomes verystraightforward. However, the implementation of virtual synchronyis done by a kind of distributed scheduler which must be madepredictable. Hence, implementing Corto is not just running ISIS ontop of a real-time kernel.  Our initial approach is to build a suite of basic mechanisms,described below, that support a small set of real-timeapplications. We are implementing these mechanisms on top of theISIS transport layer (MUTS [vRBC + 92]) running on astand-alone Unix system with minimal terminal support and our ownscheduling. While such a system will not be completely hardreal-time, this version will help us refine the right set ofmechanisms needed for highly available real-time applications. Wewill then move the system to a kernel that supports hard real-timescheduling.	high availability;real-time clock;real-time computing	Carlos Almeida;Bradford B. Glade;Keith Marzullo;Robbert van Renesse	1992		10.1145/506378.506381	real-time computing;simulation;computer science;distributed computing	Embedded	-25.14811282042002	44.2105861131649	73465
373a03139591eefa9df60db1386c396d569f35a1	synchrony vs. causality in asynchronous petri nets	cluster computing;synchronous system;petri net	Given a synchronous system, we study the question whether th e be aviour of that system can be exhibited by a (non-trivially) distributed and hence async hronous implementation. In this paper we show, by counterexample, that synchronous systems canno t in general be implemented in an asynchronous fashion without either introducing an infinit e implementation or changing the causal structure of the system behaviour. keywords: asynchrony, distributed systems, causal semantics, Petri nets	asynchronous circuit;asynchrony (computer programming);causality;distributed computing;infinit;petri net;synchronous circuit	Jens-Wolfhard Schicke;Kirstin Peters;Ursula Goltz	2011		10.4204/EPTCS.64.9	real-time computing;computer cluster;computer science;theoretical computer science;distributed computing;petri net;synchronizer	Logic	-22.78989999788947	42.6988807877638	73525
11776f6ccb2f865fb75cbe1b2cd6efca08a39724	a java api for global querying and updates for a system of databases	collaborative application;distributed information retrieval;design and implementation;system of databases;multidatabases;global queries updates	In this paper, we present the design of system of databases (SyDb). We also give the design and implementation of a Java API for global querying and updates on the SyDb. The databases may be heterogeneous. The API allows for queries and updates that have global references to schema elements of multiple databases to be executed in a seamless manner. The API can be used to develop collaborative applications that need access to several independent databases on the network. One such collaborative application, called the Calendar application, is illustrated in the paper. In this application each individual keeps their schedule information in their personal database. The users can schedule meetings with others, view others schedules, cancel meetings, etc. We implement the API using direct JDBC connections to databases.	application programming interface;calendaring software;database;jdbc;java class library;list of java apis;seamless3d	Rajshekhar Sunderraman;Erdogan Dogdu;Praveen Madiraju;Laxmikanth Malladi	2005		10.1145/1167350.1167422	computer science;data mining;database;world wide web	DB	-31.080294481732643	44.8801434515123	73772
5533425b9c596d5d151c57053bfbfdd4f2f6e097	supervisory control for real-time systems based on conflict-tolerant controllers	supervisory control;conflict tolerant features supervisory control real time systems conflict tolerant controllers;computer crashes;clocks;data mining;storage tanks;supervisory control real time systems control systems safety automation automatic control timing telecommunication control virtual manufacturing resumes;feature extraction;safety;hybrid system;school of automation;conflict tolerant controllers;automata theory;system development;conflict tolerant features;computer science automation formerly;real time systems;time constraint	This paper addresses the problem of detecting and resolving conflicts due to timing constraints imposed by features in real-time and hybrid systems. We consider systems composed of a base system with multiple features or controllers, each of which independently advise the system on how to react to input events so as to conform to their individual specifications. We propose a methodology for developing such systems in a modular manner based on the notion of conflict-tolerant features that are designed to continue offering advice even when their advice has been overridden in the past. We give a simple priority- based scheme for composing such features. This guarantees the maximal use of each feature. We provide a formal framework for specifying such features, and a compositional technique for verifying systems developed in this framework.	hybrid system;maximal set;real-time clock;real-time computing;sensor;verification and validation	Deepak D'Souza;Madhu Gopinathan;S. Ramesh;Prahladavaradan Sampath	2009	2009 IEEE International Conference on Automation Science and Engineering	10.1109/COASE.2009.5234088	control engineering;real-time computing;simulation;engineering	Embedded	-25.757621750626125	35.054019532447036	73885
7597a4268b677cc309f7d438a1dae4206551075e	using design patterns to develop reusable object-oriented communication software	distributed system;real time;software architecture;medical image;operating system;object oriented;design pattern;network management;personal communication system	Despite dramatic increases in network and host performance, it remains difficult to design, implement, and reuse communication software for complex distributed systems. Examples of these systems include global personal communication systems, network management platforms, enterprise medical imaging systems, and real-time market data monitoring and analysis systems. In addition, it is often hard to directly reuse existing algorithms, detailed designs, interfaces, or implementations in these systems due to the growing heterogeneity of hardware/software architectures and the increasing diversity of operating system platforms.	algorithm;distributed computing;medical imaging;operating system;real-time clock;software architecture	Douglas C. Schmidt	1995	Commun. ACM	10.1145/226239.226255	network management;software architecture;real-time computing;system of systems;computer science;component-based software engineering;software development;operating system;software engineering;middleware;software construction;distributed computing;design pattern;systems development life cycle;distributed design patterns;programming language;object-oriented programming;software system;systems design	PL	-33.376437353988955	44.986682902921885	73913
7054a8bdbe2bb056581b230459cae7c13c02906f	airport simulation using corba and dis	distributed application;performance measure;traffic simulation;airport simulation;traffic control;corba;programming model;dis;performance analysis;distributed interactive simulation;simulation environment;realtime	This paper presents the SEEDS simulation environment for the evaluation of distributed traffic control systems. Starting with an overview of the general simulator architecture, performance measurements of the simulation environment carried out with a prototype for airport ground-traffic simulation are described.#R##N##R##N#The main aspects of the performance analysis are the attained application performance using CORBA and DIS as communication middleware, and the scalability of the overall approach.#R##N##R##N#The evaluation shows that CORBA and DIS are well suited for distributed interactive simulation purposes because of their adequate performance, high scalability, and the high-level programming model which allows to rapidly develop and maintain complex distributed applications.	common object request broker architecture;simulation	Günther Rackl;Filippo de Stefani;Francois Héran;Antonello Pasquarelli;Thomas Ludwig	2000	Future Generation Comp. Syst.	10.1016/S0167-739X(99)00141-7	embedded system;parallel computing;real-time computing;simulation;computer science;operating system;common object request broker architecture;distributed computing;programming paradigm;programming language	Arch	-33.573471925566636	38.98614590731117	74342
a99af939a0ed0b105862d6a569ad6f8864e0a4be	real-time concurrent c: a language for programming dynamic real-time systems	real time;satisfiability;lower bound;real time systems;time constraint	Concurrent C, is a parallel superset of C (and of C++) that provides facilities such as specifying timeouts during process interactions, delaying program execution, accepting messages in a user-specified order, and asynchronous messages that can be used for writing real-time programs. However, Concurrent C does not provide facilities for specifying strict timing constraints, e.g., Concurrent C only ensures that the lower bounds on the specified delay and timeout periods are satisfied. Real-Time Concurrent C extends Concurrent C by providing facilities to specify periodicity or deadline constraints, to seek guarantees that timing constraints will be met, and to perform alternative actions when either the timing constraints cannot be met or the guarantees are not available. In this paper, we will discuss requirements for a real-time programming language, briefly summarize Concurrent C, and motivate and describe the real-time extensions to Concurrent C. We also discuss scheduling and other run-time facilities that have been incorporated to support the real-time extensions. A prototype implementation of Real-Time Concurrent C is nearing completion.	c++;interaction;prototype;quasiperiodicity;real-time programming language;real-time clock;real-time computing;real-time transcription;requirement;scheduling (computing)	Narain H. Gehani;Krithi Ramamritham	1991	Real-Time Systems	10.1007/BF00365999	real-time computing;computer science;distributed computing;upper and lower bounds;programming language;satisfiability	Embedded	-25.11984842630922	34.819423256416655	74574
49b37bcd853171811fc7dec2aa5a02b80c97e77c	the komodo project: thread-based event handling supported by a multithreaded java microcontroller	microcontrollers;multi threading;real time;interrupt service routine strategy komodo project thread based event handling multithreaded java microcontroller multiple real time events processor core automatic guided vehicle;java microcontrollers embedded system costs robotics and automation internet fault tolerance process control world wide web maintenance;embedded systems;automatic guided vehicle;microcontrollers embedded systems java automatic guided vehicles multi threading;automatic guided vehicles;java	The Komodo project concerns the handling of multiple real-time events by Java threads that are supported by a multithreaded Java microcontroller. The architecture of the processor core and resulting implications are considered. The use of thread-based event handling is introduced and explained in combination with an Automatic Guided Vehicle (AGV) application. The advantages of thread-based event handling over a normal Interrupt Service Routine (ISR) strategy are demonstrated by the development of the AGV	central processing unit;distributed computing;embedded system;event (computing);information systems research;interrupt handler;java bytecode;komodo edit;microcontroller;multi-core processor;real-time transcription;thread (computing)	Jochen Kreuzinger;R. Marston;Theo Ungerer;Uwe Brinkschulte;C. Krakowski	1999		10.1109/EURMIC.1999.794770	embedded system;real-time computing;java concurrency;computer science;operating system;embedded java;real time java;java	EDA	-28.448115475086794	38.290195588932946	74632
0a7436eab17476bf47bcbed511aa400f7392b612	component replication in distributed systems: a case study using enterprise java beans	distributed system;persistent objects;computer aided software engineering java middleware containers logic object oriented modeling computer architecture fault tolerance web server programming profession;fault tolerant;application server;atomic transactions component replication distributed systems enterprise java beans object oriented middleware business logic middleware services application servers component middleware architectures corba component model ejb ccm deployment time component persistence;component middleware;object oriented;distributed object management middleware persistent objects transaction processing java;distributed object management;corba component model;middleware;component architecture;transaction processing;enterprise java bean;java	A recent trend has seen the extension of object-oriented middleware to componentoriented middleware. A major advantage components offer over objects is that only the business logic of an application needs to be addressed by a programmer with support services required incorporated into the application at deployment time. This is achieved via components (business logic of an application), containers that host components and are responsible for providing the underlying middleware services required by components (such as persistence) and application servers that host containers. Well-known examples of component middleware architectures are Enterprise Java Beans (EJBs) and the CORBA Component Model (CCM). Services available at deployment time in most component architectures are component persistence (typically using databases) and atomic transactions (for ensuring the consistency of component state). This paper examines, using EJBs, how replication for availability can be supported by containers so that components that are transparently using persistence and transactions can also be made highly available.	application server;business logic;common object request broker architecture;database;distributed computing;enterprise javabeans;java platform, enterprise edition;middleware;persistence (computer science);programmer;software deployment;web container	Achmad I. Kistijantoro;Graham Morgan;Santosh K. Shrivastava;Mark C. Little	2003		10.1109/RELDIS.2003.1238058	fault tolerance;real-time computing;transaction processing;computer science;operating system;middleware;database;distributed computing;programming language;object-oriented programming;java;application server	SE	-33.590999653113435	43.71962257876964	74695
6569a5207cc5552d5cbe47973a80a3d119cb441b	gamine - generalized intelligent middleware for data access in parallel scientific datamining.	general intelligence;data access;middleware			Angela C. Sodan;Gang Hu	2004			data access;middleware;computer science;theoretical computer science;operating system;middleware;g factor;database;distributed computing	HPC	-29.94305830715071	45.927958849322636	74889
8722ed9c6419bdc135b71ab728b3eff79b86b43c	transparent distributed threads for java	libraries;javaparty transparent remote objects;virtual machine;multi threading;software performance evaluation remote procedure calls java multi threading distributed programming synchronisation interrupts;karmi;yarn;interrupt forwarding mechanism;global thread identities;virtual machining;costs and benefits;software performance evaluation;distributed programs;transparent distributed threads;multi threaded distributed programming;synchronisation;yarn java virtual machining libraries distributed control communication system control operating systems workstations scalability network interfaces;network interfaces;synchronization;distributed programming;remote method invocation;workstations;remote monitor acquisition;benchmarks;interrupts;java rmi;scalability;remote monitoring;communication system control;monitor reentry;benchmarks java rmi remote method invocation multi threaded distributed programming karmi global thread identities monitor reentry synchronization remote monitor acquisition interrupt forwarding mechanism javaparty transparent remote objects transparent distributed threads;remote procedure calls;distributed control;operating systems;java	Remote method invocation in Java RMI allows the flow of control to pass across local Java threads and thereby span multiple virtual machines. However, the resulting distributed threads do not strictly follow the paradigm of their local Java counterparts for at least three reasons: Firstly, the absence of a global thread identity causes problems when reentering monitors. Secondly, blocks synchronized on remote objects do not work properly. Thirdly, the thread interruption mechanism for threads executing a remote call is broken. These problems make multi-threaded distributed programming complicated and error prone. We present a two-level solution: On the library level, we extend KaRMI [16], a fast replacement for RMI, with global thread identities for eliminating problems with monitor reentry. Problem with synchronization on remote objects are solved with a facility for remote monitor acquisition. Our interrupt forwarding mechanism enables the application to get full control over its distributed threads. On the language level, we integrate these extensions with JavaParty’s transparent remote objects [17] to get transparent distributed threads. We finally evaluate our approach with benchmarks that show costs and benefits of our overall design.	benchmark (computing);cognitive dimensions of notations;control flow;distributed computing;distributed object;expect;interrupt;java remote method invocation;overhead (computing);parallel computing;programming paradigm;subroutine;thread (computing);tuple space;virtual machine	Bernhard Haumacher;Thomas Moschny;Jürgen Reuter;Walter F. Tichy	2003		10.1109/IPDPS.2003.1213261	synchronization;thread;parallel computing;real-time computing;java concurrency;computer science;operating system;distributed computing;distributed object;green threads;programming language	PL	-24.9960917156059	40.18034326101577	75055
3e50563e373a8a16073d05b0ce9f69c11b25b25d	predicate detection modality and semantics in three partially synchronous models	observability;clocks distributed computing synchronization observability computer science delay history timing information science computerized monitoring;distributed system;programming language semantics;predicate detection modality;history;semantics predicate detection partial synchrony observability modality;information science;clocks;distributed processing;distributed computing;semantics;modality;computerized monitoring;programming language semantics distributed processing;partial synchrony assumption predicate detection modality distributed system predicate detection semantics;synchronization;predicate detection;partial synchrony assumption;computer science;partial synchrony;predicate detection semantics;timing	Predicate detection addresses the challenge of monitoring the state of a distributed system. This research is the first step to explore predicate detection with partial synchrony assumptions. We study the observability of computation and focus on predicate detection semantics in three partially synchronous models. A framework of the behavior of predicate detection is established in terms of partial synchrony, modalities permitted and the best detection semantics. This work forms a conceptualization of the problem space and leads to disciplined approaches to predicate detection in realistic systems by identifying the strongest possible semantics for each modality and partial synchrony assumption.	computation;conceptualization (information science);distributed computing;liveness;logical clock;map;modality (human–computer interaction);problem domain;real-time computing;taxonomy (general)	Chunbo Chu;Monica Brockmeyer	2008	Seventh IEEE/ACIS International Conference on Computer and Information Science (icis 2008)	10.1109/ICIS.2008.95	natural language processing;functional predicate;computer science;theoretical computer science;predicate variable;predicate transformer semantics;predicate;programming language	Logic	-23.525575391410783	42.77636365058227	75108
891c3eaa2fb07d3af7b270ccf20317f3931835c5	flexible real-time linux*: a flexible hard real-time environment	real time;support system;feasibility test;real time operating systems;flexible real time systems;real time synchronization;real time application;hard real time;real time systems	This paper presents a framework appropriate for Flexible Real-Time Systems (FRTS) and a run-time support system based on that framework, called Flexible Real-Time Linux (FRTL). The framework proposes to build each task as a sequence of mandatory and optional components and to separate their execution in two scheduling levels. This approach is shown to provide both hard guarantees and flexible behavior. The FRTL system has been implemented by enhancing the original capabilities of Real-Time Linux (RT-Linux), while maintaining its predictability and efficiency features. This paper also shows a complete schedulability test on which all sources of overhead of the FRTL itself have been introduced. By applying this complete test, the designer is able to safely guarantee a real-time application running on the FRTL system.	linux;overhead (computing);rtlinux;real-time clock;real-time computing;real-time operating system;real-time transcription;scheduling (computing)	Andrés Terrasa;Ana García-Fornes;Vicent J. Botti	2002	Real-Time Systems	10.1023/A:1013437605059	embedded system;feasibility study;real-time computing;real-time operating system;computer science;operating system	Embedded	-27.737470078905652	37.83161374306286	75168
4d4ef12b09b63afdac339dfcd1e2ce86df991012	ubiqstor: a remote storage service for mobile devices	red sin hilo;informatique mobile;mobile device;reseau sans fil;pervasive computing;wireless network;distributed computing;cache memory;antememoria;informatica difusa;antememoire;informatique diffuse;calculo repartido;mobile computing;calcul reparti;ubiquitous computing environment	In Ubiquitous computing environment the mobile devices such as PDAs necessarily connect to remote storage servers. We present an iSCSI caching system that localizes iSCSI target to overcome the shortcomings of iSCSI performance dropping sharply as the latency increases. 1 Motivation Mobile devices such as PDAs are evolving to be incorporated into Ubiquitous computing environment. Due to lightly equipped storage, they lack enough capacity to process application of large data, thus it has been necessitated supplying vast storage capacity from remote machine. For mass storage service, SCSI has been representative protocol in its widespread application. We have built a remote storage system for mobile appliances using iSCSI protocol, which mobile devices can use the storage of a remote server through wireless link but just as their own local storage. It enables mobile appliances to overcome the limitation of storage capacity, as well as the ability to adapt various applications of wired environment in need of mass scale data. 1.1 iSCSI The iSCSI (Internet Small Computer System Interface) is an emerging standard storage protocol that can transfer a SCSI command over IP network. Since the iSCSI protocol can make clients access the SCSI I/O devices of server host over an IP Network, client can use the storage of another host transparently without the need to pass through a server host's file system[1]. Fig. 1 illustrates iSCSI protocol linkage. In iSCSI layer common SCSI commands and data are encapsulated in the form of iSCSI PDU (Protocol Data Unit). The iSCSI PDU is sent to the TCP layer for the IP network transport. The encapsulation and the decapsulation of SCSI I/O commands over TCP/IP enable the storage user to access a remote storage device of the remote server directly[2]. 1.2 iCache iCache is developed to improve iSCSI performance using local cache of a client system. Initiator’s systems have specific cache space for iSCSI data, and iSCSI block M. Ok, D. Kim, and M.-s. Park 686 Fig. 1. Remote Storage Service with iSCSI protocol Fig. 2. iCache Architecture data is cached to minimize network block I/O. Thus iSCSI does not send I/O requests through the network every time the disk I/O happens. Instead it reads cached blocks or sends blocks cached in LogDisk at once to the server for improving iSCSI performance. iCache's buffer space consists of two hierarchical caches comprising Non-Volatile RAM and LogDisk. Data is stored sequentially in NVRAM. When enough data is gathered, iCache process moves data from NVRAM to LogDisk. Blocks which are frequently accessed, are kept in NVRAM where access speed is fast. iCache stores less accessed data in the LogDisk. Caching techniques used in iCache are based on DCD technology, [3] proposed to improve Disk I/O performance. However storage subsystem like iCache is not adequate to mobile devices since it needs additional NVRAM and LogDisk to embody the local cache. Data Data Data SAN Disk Bunch Storage Server UbiqStor Server UbiqStor Server	computer data storage;encapsulation (networking);iscsi;input/output;linc;linkage (software);mass storage;mobile device;non-volatile memory;non-volatile random-access memory;personal digital assistant;remote computer;scsi command;scsi initiator and target;scanline rendering;server (computing);storage area network;thread-local storage;ubiquitous computing;xfig	MinHwan Ok;Daegeun Kim;Myong-Soon Park	2004		10.1007/978-3-540-30501-9_132	hyperscsi;embedded system;real-time computing;cpu cache;computer science;operating system;wireless network;mobile device;database;distributed computing;mobile computing;computer security	OS	-29.40940721380553	43.765476606133454	75223
75ef55ca691d5d9a820b7bf3c807cb066888a4a4	preservation datastores: new storage paradigm for preservation environments	archivo electronico;sistema operativo;union europeenne;gestion archivos;information technology;gestion fichier;age;stockage donnee;technologie information;information access;file management;systeme ouvert;digital archive;data storage;planificacion;operating system;object oriented;acces information;almacenamiento datos;oriente objet;systeme exploitation;planning;acceso informacion;archive electronique;information system;planification;tecnologia informacion;open systems;sistema abierto;european union;union europea;orientado objeto;systeme information;sistema informacion;edad	ion levels to existing OSD commands. In PDS, both OSD and its HL API are executed in a separate process from the upper layers. The XAM layer communicates with the HL-OSD interface via RPC. XAM session execution model A XAM storage system contains one or more XSystems, where each XSystem is a logical container of XSet records. An XSet, the basic artifact in XAM, is a data Table 1 Preservation DataStores (PDS) functionality and benefits for preservation environments. (AIP: archival information package; PDI: preservation description information.) Preservation-aware storage requirements PDS support Benefits for preservation environments Encapsulate and physically colocate the raw data and its metadata objects, such as RepInfo, provenance, and fixity. & Awareness of the AIP structure. & Manage data availability at the level of an AIP. & Group related objects and create copies of objects according to the inherent importance of the data. & Aggregate the AIPs into clusters so that each cluster is self-contained and can be placed on the same media unit. & Ensures that metadata needed for interpretation is not separated from the raw data and thus reduces the risk of losing the metadata. & Supports graceful loss of data, namely the degree of lost information is proportional to the number of bits lost. Execute data-intensive functions such as fixity computation within the storage. & Provide a storlets container (such as applets in applications and servlets in servers), a container that can embed and execute restricted modules with predefined interfaces. & Lessens network bandwidth. & Reduces risks of data loss. & Utilizes the locality property. Execute transformations internally. & Provide a storlets container that can embed and execute transformations. & Simplifies applications since transformations can be carried out by the storage instead of the application. & Improves performance by reducing bandwidth. & Enables transformations to be applied during the migration process. Include in the stored AIP the RepInfo of its PDI. & Awareness of the PDI structure. & Enables the interpretation of PDI in the future. Handle technical provenance records internally. & Awareness of the provenance metadata and appending internally technical provenance events, such as events related to the migration. & Simplifies applications on top of PDS by reducing the number of events to handle. & Includes richer events that are known only to the storage. Support media migration as opposed to system migration (i.e., migration by physically detaching the media from one system and attaching it to the new system). & Supporting a standardized self-contained, self-describing data format. & Reduces the cost of migration. & Reduces the risks of data loss during migrations. Maintain referential integrity including updating all the links during the migration process so they remain valid in the new system. & Awareness of the context and RepInfo metadata and understanding the fields that represent links to either internal or external locations. & Simplifies applications. & Increases the robustness of the system. S. RABINOVICI-COHEN ET AL. IBM J. RES. & DEV. VOL. 52 NO. 4/5 JULY/SEPTEMBER 2008 6 structure that packages multiple pieces of XSet fields (data and metadata), bundled together for access under a common globally unique external name. A XAM client that requires access to a specific XSystem has to establish a XAM session with the PDS XAM library. A XAM session represents a path to the underlying object storage and serves as a context in which XAM requests can be performed. In order to perform a PDS API call (e.g., ingestAIP), multiple XAM requests are invoked on the same XAM session, for example, create an XSet and create the XSet various fields. Since the PDS API call is expected to be long-lived and to handle large amounts of data, multiple PDS API calls are not handled on the same thread. Instead, each such PDS API call is assigned with a dedicated XAM session executed in a dedicated thread. Transactions in XAM In order to support the XSet behavioral model, the concept of an XSet transaction was introduced. XSet transactions support atomicity, consistency, isolation, and durability. An XSet transaction may include one XAM API call (e.g., deleteXSet) or it may include several XAM API calls. For example, an XSet transaction may begin on openXSet, perform several calls, and end on closeXSet. If closeXSet is called without a prior commit call, the state of the XSet will be rolled back to the state before the transaction began. A commit call will make the changes persistent. PDS interfaces PDS exposes a set of interfaces that form the PDS entry points accompanied with their arguments and return values. The PDS entry points cover the functionality PDS exposes to its users including a variety of ways to ingest and access data and metadata, manipulate previously ingested data and metadata, retrieve PDS system information, and configure policies. The entry points may be called directly or via Web services. The PDS interfaces aim to be abstract and technology independent and to survive implementation replacements. The entry points may return different exceptions that are also PDS interfaces. Some of the structures used by the PDS entry points, such as the inner structure of the PDI record (e.g., the inner structure of a provenance record), may have different variants and may depend on the source that generated the record. PDS aims to treat a set of records that may differ in their inner structure in a harmonic way: Although the provenance records may contain records with different inner structures, PDS still handles them similarly. To enable that, the inner structure of each record has by itself RepInfo, such as an XML schema, that is maintained along with the content of the record. When a record is generated by PDS, we use a PDS default XML schema as the RepInfo for the record. These PDS default schemas are also exposed so that users can make	abstraction layer;adaptive internet protocol;aggregate function;applet;application programming interface;archive;atomicity (database systems);behavioral modeling;case preservation;computation;computer data storage;data-intensive computing;durability (database systems);entry point;horseland;java servlet;locality of reference;loss function;object storage;open archival information system;persistence (computer science);portable database image;programming paradigm;prototype;referential integrity;remote procedure call;requirement;self-documenting code;system information (windows);system migration;table (information);web service;xam;xml schema	Simona Rabinovici-Cohen;Michael Factor;Dalit Naor;Leeat Ramati;Petra Reshef;Shahar Ronen;Julian Satran;David L. Giaretta	2008	IBM Journal of Research and Development	10.1147/rd.524.0389	planning;telecommunications;computer science;operating system;computer data storage;open system;object-oriented programming;information technology;world wide web;computer security;information system	DB	-31.225615676337256	41.21068459492404	75284
425bddcf1bcc662741f768e0910aa6446b96429c	integration of multiple platforms for real-time remote model-based condition monitoring	systeme temps reel;modelizacion;control application;control systems;arquitectura red;televigilancia;software platform;operating conditions;surveillance;real time;resource management;model based approach;distributed monitoring;architecture reseau;buffer system;data communication;sistema amortiguador;modelisation;gestion recursos;remote supervision;control system;bus terreno;vigilancia;client server;condition operatoire;condition monitoring;monitoring;telesurveillance;commande hydraulique;mando hidraulico;temps reel;publish subscribe;gestion ressources;tiempo real;control electrohidraulico;commande electrohydraulique;real time system;network architecture;sistema tiempo real;monitorage;hydraulic control;systeme tampon;monitoreo;condicion operatoria;modeling;bus terrain;remote condition monitoring;electrohydraulic control;worldfip fieldbus;field bus;ta engineering general civil engineering general;real time systems;qa76 computer software	Model-based condition monitoring has been demonstrated to have superior performance in process condition monitoring. However, it demands increased computational resources to support its more advanced intelligence. This requirement imposes difficulties in integration into an existing control system that typically has resources dedicated solely to control applications. To overcome this problem, this paper presents an integration of multiple platforms, in which tasks are allocated in different machines with different levels of software platform. Time synchronisation between the local and remote devices is implemented by means of Fieldbus network with published-subscriber architecture. A client–server arrangement is used to deal with the data communication between Matlab and Labwindows. A temporary data buffer provides variable time accuracy while using a small fraction of system resources. This approach has been realised in an electro-hydraulic control system, demonstrating the full use of existing rich software resources and the convenience of configuring the systems. # 2007 Elsevier B.V. All rights reserved.	client–server model;computational resource;control system;data buffer;dynamic data exchange;factory instrumentation protocol;fault detection and isolation;fieldbus;grid computing;labwindows/cvi;matlab;named pipe;open platform communications;real-time clock;remote computer;server (computing);simulation;telecommunications network;while	John Z. Shi;Fengshou Gu;Peter Goulding;Andrew D. Ball	2007	Computers in Industry	10.1016/j.compind.2006.12.002	embedded system;real-time computing;simulation;systems modeling;network architecture;computer science;engineering;control system;bicarbonate buffering system;publish–subscribe pattern;client–server model	AI	-28.458813107914363	41.503374004964975	75444
8ca0a3c29736265fdc26fe5f7aeea3337e60df43	procol - a parallel object language with protocols		PROCOL is a parallel C-based object-oriented language with communication based on one-way synchronous messages. Objects execute in parallel unless engaged in communication. Communication partners are defined by object instance identifiers, or by type. Therefore send-receive mappings may be 1-1, n-1, or 1-n, though only 1 message is transferred. PROCOL controls object access by a novel concept: an explicit per-object protocol. This protocol is a specification of the occurrence and sequencing of the communication between the object and its partners. Thus protocols support structured, safer and potentially verifiable information exchange between objects. Protocols also act as a composition rule over client objects, thereby offering a 'part-of' hierarchy of these cooperating objects.	formal verification;identifier;information exchange;object language;one-way function;unified parallel c (upc)	Jan van den Bos;Chris Laffra	1989		10.1145/74877.74888		PL	-28.023301777712312	32.37103416473414	75639
b39a173266d32db1fac9099830d3127b2062d3db	gigabit satellites in distributed supercomputing for global research	distributed supercomputer;satellite communication;global research;instruments;astronomical telescopes;geophysics;acts;high performance computing;advanced communications technology satellite;high speed networks;distributed processing;remote observation;distributed computing;global climate model;telescopes;distributed supercomputing;acceleration;geophysics computing;satellites telescopes instruments distributed computing nasa supercomputers high performance computing acceleration geophysics high speed networks;satellites;telecommunication;astronomical telescopes distributed processing satellite communication climatology geophysics computing;gigabit satellites;keck telescope;keck telescope distributed supercomputing global research advanced communications technology satellite acts distributed supercomputer global climate model remote observation;nasa;supercomputers;climatology	This paper will examine the application of the NASA advanced communications technology satellite (ACTS) for implementing a distributed supercomputer global climate model, and in remote observation and control of the Keck telescope in Hawaii.	climate model;communications satellite;general circulation model;gigabit;supercomputer	Larry A. Bergman	1995	Digest of Papers. COMPCON'95. Technologies for the Information Superhighway	10.1109/CMPCON.1995.512367	atmospheric sciences;aerospace engineering;physics;remote sensing	HPC	-31.28473271825674	38.779360729478654	75651
731fc0306de56137ee71ec4d5b963be2223892e3	reasonet: inferring network policies using ontologies		Modern Software Defined Networking (SDN) control stacks consist of multiple abstraction and virtualization layers to enable flexibility in the development of new control features. Rich data modeling frameworks are essential when sharing information across control layers. Unfortunately, existing Network Operating System (NOS) data modeling capabilities are limited to simple type-checking and code templating. We present an exploration of a more extreme point on SDN data modeling: ReasoNet. Developers can use semantic web technologies to enrich their data models with reasoning rules and integrity/consistency constraints, and automate state inference across layers. We demonstrate the ability of ReasoNet to automate state verification and cross-layer debugging, through the implementation of two popular control applications, a learning switch and a Quality of Service (QoS) policy engine.		Charalampos Rotsos;Arsham Farshad;Daniel King;David Hutchison;Qianru Zhou;Alasdair J. G. Gray;Cheng-Xiang Wang;Stephen McLaughlin	2018	2018 4th IEEE Conference on Network Softwarization and Workshops (NetSoft)	10.1109/NETSOFT.2018.8460050	virtualization;debugging;ontology (information science);semantic web;software-defined networking;database;network operating system;inference;computer science;data modeling	SE	-24.308514601166983	39.569272124112835	75796
6666f9a8c5a39d6031290d387edef4f5160b5efc	instantgrid: a framework for on-demand grid point construction	developpement logiciel;distributed system;calcul grille;systeme reparti;conference_paper;software management;logicial personalizado;grid middleware;intergiciel;sistema repartido;desarrollo logicial;execution environment;software development;gestion logicial;middleware;article;serveur grille instantanee;grid system;gestion logiciel	This paper proposes the InstantGrid framework for on-demand construction of grid points. In contrast to traditional approaches, InstantGrid is designed to substantially simplify software management in grid systems, and is able to instantly turn any computer into a grid-ready platform with the desired execution environment. Experimental results demonstrate that a 256-node grid point with commodity grid middleware can be constructed in five minutes from scratch.	middleware;software project management	Roy S. C. Ho;K. K. Yin;David C. M. Lee;Daniel H. F. Hung;Cho-Li Wang;Francis C. M. Lau	2004		10.1007/978-3-540-30208-7_136	embedded system;grid file;simulation;semantic grid;computer science;alpha-numeric grid;software development;operating system;middleware;distributed computing;grid computing	HPC	-28.689275921144922	42.74706188664547	75820
53d2c608b3997a417289e45612e6eae17627bade	android/osgi-based vehicular network management system	sensibilidad contexto;informatica movil;offre service;distributed memory;telematics;gestion memoire;context aware;mise a jour;informatique mobile;markets;management system;vehicular network;service provider;informatique dans les nuages;automovil;mercado;intelligent transport system;reseau interconnecte;gestion red;memoria compartida;road traffic;storage management;information technology;securite informatique;telematique;mobile computer;terminal;langage java;android;technologie information;application program interface;systeme ouvert;orientado servicio;intergiciel publication souscription;actualizacion;computer security;proveedores de servicios;gestion memoria;trafic routier;original equipment manufacturer;intergicial editor suscriptor;automobile;object oriented;telematica;seguridad informatica;motor car;marche;service proposal;gestion reseau;oriente objet;lenguaje java;information gateway;trafico carretera;oriente service;network management;osgi;sensibilite contexte;vehicular platform;memoire repartie;mobile computing;intelligent transport systems;tecnologia informacion;market potential;pasarela informacion;open systems;passerelle d information;sistema abierto;red interconectada;security policy;interconnected power system;orientado objeto;publish subscribe middleware;updating;computacion en nube;cloud computing;service oriented;java language	With the enormous market potential of the telematics industry and the rapid development of information technology, automotive telematics has attracted considerable attention for mobile computing and intelligent transport systems (ITSs). This study integrates the Open Gateway Service Initiative Vehicle Expert Group (OSGi/VEG) into an Android platform to generate a vehicular Android/OSGi platform that has the advantages of both original platforms. These features include remote management, rich class sharing, proprietary vehicular applications, security policies, easy management of application programming interface (APIs), and an open environment. This study also integrates a cloud computing mechanism into the Android/OSGi platform, allowing service providers to upload their telematics bundles onto storage clouds using a provisioning server. A management agent in the Android/OSGi platform can simultaneously update its application service modules using remote storage clouds and use visual intelligence to continually change the distinguishing features of applications based on context awareness without user intervention. To assess the feasibility of the proposed Android/OSGi platform, this study presents a vehicular testbed to determine the functionalities of different telematics applications. Android/OSGi platform applications require less memory and system resources than those on the original Android platform when performing complicated operations. Additionally, the Android/OSGi platform launches telematics services more quickly than the original Android platform. The proposed platform overcomes the problem of frequent non-responsive exceptions in the original Android platform.	android;application programming interface;cloud computing;context awareness;management agent;mobile computing;osgi;provisioning;server (computing);telematics;testbed;upload	Ming-Chiao Chen;Jiann-Liang Chen;Teng-Wen Chang	2010	2010 The 12th International Conference on Advanced Communication Technology (ICACT)	10.1016/j.comcom.2010.03.032	service provider;network management;embedded system;distributed memory;cloud computing;telecommunications;computer science;security policy;original equipment manufacturer;operating system;management system;telematics;mobile computing;computer security;android;computer network	Mobile	-29.67948309853786	43.61939385962969	76679
fa121eb9fd808ad216124ac5d6e0142e81977922	unitron: loadable kernel module for adding real-time functionality of uitron to unix kernel	embedded system;loadable kernel module lkm unitron system software resources embedded systems embedded operating system unix kernel uitron real time functionality;operating system real time system embedded system;embedded systems;real time systems kernel computer architecture context embedded systems linux;operating system;real time system;operating system kernels;unix embedded systems operating system kernels;unix	UNIX has been used as an embedded operating system (OS) because there is an increasing demand for highly functional embedded systems, for example, in information appliances. An advantage of using UNIX in an embedded system is that its existing rich software resources such as device drivers, network stacks, and application programs can be used. However, UNIX does not have real-time functionality, which is integral in embedded systems. We propose the Unitron system, a loadable kernel module (LKM) that can add the real-time functionality of uITRON to the UNIX kernel. By using LKM, the Unitron system can allow a developer to dynamically add and remove the real-time functionality from a running UNIX kernel.	device driver;embedded operating system;embedded system;information appliance;loadable kernel module;real-time clock;real-time computing;real-time transcription;system call;unix	Takashi Sato;Yoshikatsu Tada	2013	2013 First International Symposium on Computing and Networking	10.1109/CANDAR.2013.66	unix signal;unix architecture;embedded system;hybrid kernel;embedded operating system;procfs;real-time computing;fork;computer science;kernel panic;operating system;unix file types;unix filesystem;streams;tmpdir;linux kernel;environment variable	Embedded	-32.72715951565753	39.469919457404465	76765
16b7df096fd5488f0bfc32b6a13b1d731e0db7e5	using jini to integrate home automation in a distributed software-system	distributed system;systeme reparti;software systems;langage java;automatizacion domestica;computer network;bus terreno;sistema repartido;software framework;lenguaje java;domotique;jini;bus terrain;field bus;home automation;java language	The last few years, a tendency arose to integrate various programmable devices through ever expanding computer networks. One particular domain in which this evolution stood out clearly is home automation. The EIB standard defines a home automation solution that consists of a network of cooperating components with little computational power. Bridging the EIB network with a computer network allows software to interact with these EIB components. However, past attempts to link EIB components with computer networks fell short in dynamism, automatism or user friendliness. In this paper we present a distributed software framework that overcomes these issues, and is capable of automatically generating a software model based on the configuration of the components on the EIB fieldbus. A framework that can be used in this perspective is Jini. Its excellent capabilities for dynamic reconfiguration and its proven deployment in domestic and office environments make it an appropriate candidate for supporting home automation systems.	adaptive scalable texture compression;advanced spaceborne thermal emission and reflection radiometer;application programming interface;bridging (networking);certificate authority;communications protocol;computer programming;distributed computing;exbibyte;fieldbus;graphical user interface;hierarchical editing language for macromolecules;high- and low-level;home automation;instabus;intensional logic;library (computing);object-oriented software construction;operating system;simulation;software deployment;software framework;ubiquitous computing;usability;web of science;world wide web;jini	Peter Rigole;Tom Holvoet;Yolande Berbers	2002		10.1007/3-540-36261-4_26	embedded system;home automation;real-time computing;computer science;software framework;operating system;database;distributed computing;programming language;computer security;software system	HCI	-32.61363677708668	45.00648176025925	76802
8ac9fab22c6bb67bea2399e9af130bc555071483	more on selecting sequence numbers		This note serves to supplement and extend the ideas and issues raised in [TO74]. Tomlinson examines the problem of establishing a connection (association), and being able to detect delayed packets of an old incarnation of a connection, when it is being opened and closed in quick succesion, or when the connection breaks owing to some crash and is restarted later. No protocol can guarantee reliability of communication given certain types of crashes [SU74], [BE74]. This last issue is out of the scope of this note. First the problem of establishing and closing a connection is further examined and the claim that a three way exchange is sufficient for single message transfer in [TO74] (even under conditions of a correctly functioning system) is refuted. Next the mechanism for implementing the “clock-driven” initial sequence number choice is examined in detail showing how various parameters interact, and the algorithms neccessary in order that it work. Finally alternative schemes to replace “resynchronization” are considered and the tradeoffs shown.		Yogen K. Dalal	1975	Operating Systems Review	10.1145/563905.810895	simulation;computer security;algorithm	Logic	-21.848493482027383	44.666561855229396	76861
5ac394d5dbf7a49242cc0185eaa62d34c9d36431	distributed container: a design pattern for fault tolerance and high speed data exchange	design pattern;serialization;fault tolerant;ada;design patterns;failover;reuse;data exchange;distributed system;data transfer	We describe a design patterns for achieving fast data transfer in a distributed system with a high reliability requirement. Also described are techniques for utilizing the Ada-95 serialization facilities in implementing the design patterns.	distributed computing;fault tolerance;serialization;software design pattern	Tong Dinh;Shan Barkataki	2009		10.1145/1647420.1647445	data exchange;fault tolerance;software design pattern;parallel computing;real-time computing;ada;serialization;computer science;operating system;reuse;design pattern;programming language;failover	DB	-29.121466796003165	45.675614512309046	76912
86910be60af0ef933b4d847ac16157a7dde6bb13	a concurrent partial snapshot algorithm for large-scale and dynamic distributed systems	brief announcement;concurrent partial snapshot algorithm	Checkpoint-rollback recovery, which is a universal method for restoring distributed systems after faults, requires a sophisticated snapshot algorithm especially if the systems are large-scale, since repeatedly taking global snapshots of the whole system requires unacceptable communication cost. As a sophisticated snapshot algorithm, a partial snapshot algorithm has been introduced that takes a snapshot of a subsystem consisting only of the nodes that are communication-related to the initiator instead of a global snapshot of the whole system. In this paper, we modify the previous partial snapshot algorithm to create a new one that can take a partial snapshot more efficiently, especially when multiple nodes concurrently initiate the algorithm. Experiments show that the proposed algorithm greatly reduces the amount of communication needed for taking partial snapshots. key words: fault-tolerance, large-scale distributed system, concurrent snapshot, checkpoint, rollback	application checkpointing;distributed computing;fault tolerance;rollback (data management);scsi initiator and target;snapshot (computer storage);snapshot algorithm;transaction processing system	Yonghwan Kim;Tadashi Araragi;Junya Nakamura;Toshimitsu Masuzawa	2011	IEICE Transactions	10.1007/978-3-642-24550-3_39	simulation;world wide web;computer security	HPC	-22.545089567211278	45.86747992107398	76939
e86ddd8d8e1544769ab05013cd03766d102df26f	runtime detection of temporal memory errors		State-of-the-art memory debuggers have become efficient in detecting spatial memory errors – dereference of pointers to unallocated memory. These tools, however, cannot always detect errors arising from the use of stale pointers to valid memory (temporal memory errors). This paper presents an approach to reliable detection of temporal memory errors during a run of a program. This technique tracks allocated memory tagging allocated objects and pointers with tokens that allow to reason about their temporal properties. The technique further checks pointer dereferences and detects temporal (and spatial) memory errors before they occur. The present approach has been implemented in E-ACSL – a runtime verification tool for C programs. Experimentation with E-ACSL using TempLIST benchmark comprising small C programs seeded with temporal errors shows that the suggested technique detects temporal memory errors missed by state-of-the-art memory debuggers. Further experiments with computationally intensive runs of programs from SPEC CPU indicate that the overheads of the proposed approach are within acceptable range to be used during testing or debugging.	ansi/iso c specification language;addresssanitizer;amortized analysis;benchmark (computing);cpu cache;central processing unit;computer memory;debugger;debugging;dereference operator;experiment;frama-c;instrumentation (computer programming);memory debugger;overhead (computing);pointer (computer programming);run time (program lifecycle phase);runtime verification;sensor;small-c;static program analysis	Kostyantyn Vorobyov;Nikolai Kosmatov;Julien Signoles;Arvid Jakobsson	2017		10.1007/978-3-319-67531-2_18	pointer (computer programming);debugging;real-time computing;shadow memory;computer science;memory errors;memory safety;runtime verification;spec#	SE	-20.4224319880882	37.70349816464174	77529
6ebbd4fecd8804614c04b109a7be8f9d42fda5cd	reversible debugging using program instrumentation	program instrumentation;moderate code growth reversible debugging program instrumentation reversible execution symbolic debuggers performance penalty debugging session repetitive debugging sessions selectable reversible routines recording modes execution penalty;reversible execution;debugging instruments history runtime computer languages checkpointing emulation databases program processors assembly;compilers;debuggers;assembly language program debugging reverse engineering;assembly language;program debugging;reverse engineering	ÐReversible execution has not been fully exploited in symbolic debuggers. Debuggers that can undo instructions usually incur a significant performance penalty during a debugging session. In this paper, we describe an efficient reversible debugging mechanism based on program instrumentation. The approach enables repetitive debugging sessions with selectable reversible routines and recording modes. Experimental results indicate that the execution penalty can be significantly reduced with moderate	assembly language;auxiliary memory;backtrack;backtracking;batch processing;byte;c mathematical functions;computation;debugger;debugging;graphical user interface;input/output;instrumentation (computer programming);machine code;pseudorandom number generator;reversible computing;subroutine;undo;worst-case scenario;wraparound (video games)	Shyh-Kwei Chen;W. Kent Fuchs;Jen-Yao Chung	2001	IEEE Trans. Software Eng.	10.1109/32.940726	computer architecture;compiler;parallel computing;real-time computing;computer science;operating system;algorithmic program debugging;programming language;background debug mode interface;reverse engineering;assembly language;program animation	SE	-20.919713992970976	37.563729790292655	77742
f5759aced939f0c7f2354237dbd15eca817d536b	design and implementation of a 3a accessing paradigm supported grid application and programming environment	distributed system;algoritmo paralelo;access grid;systeme reparti;informatique mobile;productivite;parallel algorithm;access point;programming environment;grid applications;distributed computing;tiempo acceso;systeme ouvert;orientado servicio;productividad;algorithme parallele;service utilisateur;grid;medio ambiente programacion;sistema repartido;design and implementation;rejilla;grid service;grille;calculo repartido;temps acces;oriente service;servicio usuario;productivity;user service;service oriented architecture;mobile computing;open systems;sistema abierto;calcul reparti;environnement programmation;access time;service oriented	The mobile grid users accessing to grid services has become a normally paradigm for getting grid resources. To improve their working productivity in dynamic and open grid environment it should provide the mobile grid users an access-point decoupled and access-time decoupled way to access grid services. In development of the VEGA Grid, corresponding to the user accessing module in the Service-Oriented Architecture, we developed a kind of we called “3A(anytime, anywhere, and on any device) accessing paradigm” supported Grid Application and Programming Environment(GAPE). To the 3A accessing paradigm, we mean a mobile grid user not only could access grid services at anytime anywhere and on any device, but also could continuously manage the executing state of his grid applications even if he changed his access point or access time. This article analyzes the 3A accessing paradigm, and introduces the implementation of the VEGA GAPE.	integrated development environment;programming paradigm;spherical basis	Ge He;Donghua Liu;Yuzhong Sun;Zhiwei Xu	2004		10.1007/978-3-540-30566-8_58	embedded system;productivity;semantic grid;access time;computer science;operating system;service-oriented architecture;data grid;distributed computing;parallel algorithm;open system;grid;mobile computing;drmaa;grid computing	HPC	-28.80509173269882	43.27493507746266	77827
4018406ec257ee5c743f59013bbd1a165037c16b	a method specialisation and virtualised execution environment for java	memory management;garbage collection;barrier method;execution environment;incremental garbage collection;method virtualization;read barrier;language implementation	We present a virtualisation and method specialisation framework for Java that facilitates efficient, dynamic modification of the behaviour of object accesses at run time. The technique works by virtualising all method calls and field accesses associated with selected classes so that all corresponding object accesses are via the invocation of a virtual method. Different access behaviours are then supported by allowing arbitrary specialisations of those methods to be defined. The virtualisation overheads are partially recovered by allowing the JVM's optimisation subsystem to perform guarded inlining of specialised methods. We describe an implementation based on the Jikes RVM and show how the framework can be used to implement an 'implicit' readbarrier that supports incremental garbage collection. The performance overhead of full virtualisation, and the performance of the implicit read barrier compared with an existing conventional, explicit barrier, are evaluated using SPEC JVM98 and DaCapo benchmarks. The net virtualisation costs are shown to be remarkably low and the implicit barrier is shown to outperform the explicit barrier substantially in most cases. Other potential applications, including object proxying, caching, and relocation, and instrumentation are also discussed.	dacapo;garbage collection (computer science);inline expansion;java;jikes;mathematical optimization;overhead (computing);proxy server;relocation (computing);run time (program lifecycle phase)	Andrew M. Cheadle;Tony Field;Johan Nyström-Persson	2008		10.1145/1346256.1346264	parallel computing;real-time computing;computer science;operating system;garbage collection;programming language;memory management	PL	-20.934061897353914	35.25221357159444	77985
a1cf014fd6aad9f42c0d943f941a3d9a70556dde	a simple asynchronous shared memory consensus algorithm based on omega and closing sets	detectors;consensus;multicore systems;computer crashes;concurrent object;computer crashes registers detectors safety lead arrays multicore processing;arrays;computer architecture;shared memory systems;registers;lead;failure detector;multicore processing;fault tolerance;process crash;safety;asynchronous shared memory system;wait freedom termination property asynchronous shared memory consensus algorithm omega sets closing sets multicore architecture base read write system model failure detector;modularity;process crash asynchronous shared memory system concurrent object consensus distributed algorithm eventual leader failure detector fault tolerance modularity multicore systems;shared memory systems computer architecture;distributed algorithm;eventual leader	This paper is on the design of a consensus object in the context of asynchronous shared memory systems where any number of process can suffer a crash failure. These systems are becoming more and more important with the advent of multicore architectures. To circumvent the impossibility of implementing a consensus object in such a context, the paper considers that the base read/write system model is enriched with an eventual leader failure detector (traditionally denoted Ω). This failure detector can easily be used to ensure that all the invocations of the consensus object issued by processes that do not crash eventually terminate(wait-freedom termination property). Hence, when one has to implement a consensus object in such an enriched system model, the main issue consists in designing an object (from base atomic read/write registers) on which the implementation can rely to ensure that no two different values can be decided from the consensus object. This paper presents such an object, called closing set. The main feature of this object is that it takes advantage of the system asynchrony by reducing the number of values that can be deposited: only concurrent deposits of values in an empty set are successful. The paper presents then a simple consensus algorithm based on closing sets. This algorithm is round-based and uses a closing set per round.	asynchronous i/o;chandra–toueg consensus algorithm;closing (morphology);failure detector;multi-core processor;omega;shared memory	Michel Raynal;Julien Stainer	2012	2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems	10.1109/CISIS.2012.198	method;parallel computing;real-time computing;computer science;uniform consensus;distributed computing;chandra–toueg consensus algorithm	Robotics	-22.698799472115766	44.071433092996855	78031
7cd6a736c6fe927576a431a70031981f63cd5b15	decentralized executive control in distributed computer systems	distributed system;control systems;kernel;system software;application software;real time;distributed computing;actuators;executive control;distributed real time system;distributed computing system;pipelines;decentralized control;real time control system;distributed control control systems distributed computing real time systems hardware system software application software kernel actuators pipelines;fault isolation;distributed control;hierarchical model;distributed architecture;hardware;real time systems	This paper discusses the issues involved in building a real-time control system using a message-directed distributed architecture. We begin with a discussion of the nature of real-time soft ware, including the viability of using hierarchical models to organize the software. Next we discuss some realistic design objectives for a distributed real-time system including fault isolation, independent module verification, context independence, decentralized control and partitioned system state. We conclude with some observations concerning the general nature of distributed system software.	distributed computing	William Earl Boebert;William R. Franta;E. Douglas Jensen;Richard Y. Kain	1978		10.1109/CMPSAC.1978.810396	control engineering;application software;kernel;real-time computing;real-time control system;decentralised system;computer science;control system;distributed computing;pipeline transport;distributed system security architecture;distributed design patterns;fault detection and isolation;hierarchical database model;actuator	Theory	-25.52672185587008	43.862457293727616	78116
ef6f38c393934b10d5e0ad4b5163f642dcfe3edd	a transportable code generator system	code generation		automatic programming;code generation (compiler)	M. Howard Williams;A. R. Bulmer	1979	Inf. Process. Lett.	10.1016/0020-0190(79)90052-8	computer science;mathematics;code generation	DB	-22.609420496348278	33.26060381326083	78241
08702ae0d5523f72c635abe8d54f9bdac5d04d2f	structuring reactive systems in b amn	formal specification;ucl;control systems actuators sensor systems guidelines safety partitioning algorithms computer science educational institutions rail transportation computer industry;integrable system;adaptive control;discovery;statecharts structured reactive systems rsds method high integrity systems development railway industry b specifications reactive control systems graphical design b abstract machine notation structuring requirements;theses;conference proceedings;formal specification specification languages finite automata control system synthesis real time systems adaptive systems adaptive control;reactive control;digital web resources;adaptive systems;specification languages;ucl discovery;control system synthesis;open access;finite automata;reactive system;ucl library;book chapters;open access repository;graphic design;real time systems;ucl research	Synchronous Programming • Reactive systems are more naturally modeled as parallel units, but mostly executed on a single processor. Synchronous languages compile explicitly parallel programs into sequential code, and thus keep full control over execution. • Time is discrete, and communication between parallel components is instantaneous, because entirely compiled. • Synchronous languages include Esterel, Lustre, Signal, Safe State Machines, Argos.	compiler;esterel;lustre;signal;synchronous programming language	Kevin Lano;Kelly Androutsopoulos;Pauline Kan	2000		10.1109/ICFEM.2000.873802	graphic design;integrable system;simulation;adaptive control;reactive system;computer science;software engineering;formal specification;programming language	Embedded	-25.889389949755664	34.393219785096264	78354
929a3600e7806b6f7e2d757099baae92f06a307e	mvs dynamic reconfiguration management	concepcion circuito;etude theorique;dynamic reconfiguration;performance;circuit design;operating system;estudio teorico;conception circuit;procesador;rendimiento;theoretical study;processeur;materiel informatique;material informatica;processor;power on reset;hardware	This paper presents an overview of the Dynamic Reconfiguration Management (DRM) function of MVS/ESATM and its support of the IBM Enterprise System/9000TM family of machines. Dynamic Reconfiguration Management Is the ability to select a new I/O configuration definition without needing to perform a power-on reset (POR) of the hardware or an Initial program load (IPL) of the MVS operating system. Dynamic Reconfiguration Management allows the installation to add, delete, or modify definitions for channel paths, control units, and I/O devices, In both the software and hardware I/O configurations.	booting;input/output;operating system;power-on reset	Richard Cwiakala;Jeffrey D. Haggar;Harry M. Yudenfriend	1992	IBM Journal of Research and Development	10.1147/rd.364.0633	embedded system;power-on reset;real-time computing;performance;computer science;engineering;operating system;circuit design	OS	-26.491781009520448	38.45954619803388	78606
ef345d09af483e4a46fa50c11bbbb17f4a3e814c	resource conscious development of middleware for control environments: a case of corba-based middleware for the can bus systems	resource constraint;compact common data representation;embedded control system;customized middleware;distributed and embedded control systems;controller area network;data type;group communication;data representation;compact representation;support group;remote method invocation;publish subscribe;message passing;embedded inter orb protocol;transport protocol;middleware	While it is imperative to exploit middleware technologies in developing software for distributed embedded control systems, it is also necessary to tailor them to meet the stringent resource constraints and performance requirements of embedded control systems. In this paper, we propose a CORBA-based middleware for Controller Area Network (CAN) bus systems. Our design goals are to reduce the memory footprint and remote method invocation overhead of the middleware and make it support group communication that is often needed in embedded control systems. To achieve these, we develop a transport protocol on the CAN and a group communication scheme based on the publisher/subscriber model by realizing subject-based addressing that utilizes the message filtering mechanism of the CAN. We also customize the method invocation and message passing protocol of CORBA so that CORBA method invocations are efficiently serviced on a low-bandwidth network such as the CAN. This customization includes packed data encoding and variable-length integer encoding for compact representation of IDL data types. We have implemented our CORBA-based middleware using GNU ORBit. We report on the memory footprint and method invocation latency of our implementation. q 2004 Published by Elsevier B.V.	can bus;code;common object request broker architecture;control system;embedded system;gnu;imperative programming;java remote method invocation;memory footprint;message passing;middleware;orbit;overhead (computing);requirement;subroutine	Seongsoo Hong;Tae-Hyung Kim	2005	Information & Software Technology	10.1016/j.infsof.2004.09.012	middleware;message passing;real-time computing;can bus;data type;communication in small groups;computer science;message oriented middleware;middleware;database;distributed computing;external data representation;publish–subscribe pattern;programming language;transport layer	Embedded	-33.55582041335657	39.96284903634224	78638
248a01a77aaf5be5cc80f9fad1c8bf2fdd7f39d0	an extended transaction to maintain consistency and recovery in multidatabase systems	transaction management;base donnee;systeme grande taille;protocole transmission;multidatabase system;database;base dato;control table;large scale system;protocolo transmision;concurrency control;analyse transactionnelle;source code;systeme gestion base donnee;sistema gestion base datos;database management system;transactional analysis;sistema gran escala;analisis transaccional;transmission protocol	A complete practical solution to transaction management preserving multidatabase consistency in the presence of multidatabase updates and failures is presented. The approach developed does not require support for the two-phase commit (2PC) protocol in the participating local database management systems (LDBMSs). Furthermore, it does not violate local autonomy; the source code of the LDBMSs is not modified in any way and the multidatabase system (MDBS) does not access or modify any control information of the LDBMS. The principles of the 2PC protocol in the process of global transaction commitment are adopted. The presented method does not rely on any specific concurrency control mechanism for LDBMSs. Consideration is given to global transaction failures due to subtransaction aborts by the LDBMSs and local site crashes. The recovery process is based on undo operations. While a global transaction is in progress, the tables accessed by subtransactions of this transaction at each local site are locked using specially initiated table locks. These locks are stored and maintained in the local database itself as control tables. The approach taken is easy to implement, and its limitations are discussed.		Jayantha Rajapakse;Maria E. Orlowska	1996	Inf. Sci.	10.1016/0020-0255(95)00237-5	real-time computing;two-phase commit protocol;transaction processing;distributed transaction;computer science;concurrency control;x/open xa;database;distributed computing;online transaction processing;transactional analysis;control table;consistency;source code	DB	-26.436706270855073	44.04530622938605	78707
9c18cfb51d5e94f4aee592aaca9415e8a3fd1baa	a survey on some recent advances in shared memory models	topology;crash failure;distributed computability;bg simulation;model equivalence;task;agreement;asynchronous system;wait freedom;core;concurrency;resilience;iterated model;snapshot;survivor set;recursion;fault tolerance;liveness;distributed computing model;adversary;shared memory system;progress condition	Due to the advent of multicore machines, shared memory distributed computing models taking into account asynchrony and process crashes are becoming more and more important. This paper visits models for these systems and analyses their properties from a computability point of view. Among them, the base snapshot model and the iterated model are particularly investigated. The paper visits also several approaches that have been proposed to model failures (mainly the wait-free model and the adversary model) and gives also a look at the BG simulation. The aim of this survey is to help the reader to better understand the power and limits of distributed computing shared memory models.	shared memory	Sergio Rajsbaum;Michel Raynal	2011		10.1007/978-3-642-22212-2_3	real-time computing;computer science;theoretical computer science;distributed computing	Logic	-22.757404830458245	42.94925235684073	78708
692d26c4d2bd5fa6356158c0a032be654fbc283b	structuring conversation in operation/procedure oriented programming languages	backward error recovery;tolerancia falta;lenguaje programacion;detection erreur;deteccion error;metodologia;programming language;concurrent programming;sistema informatico;simultaneidad informatica;software fault tolerance;concurrent program;computer system;ingenieria logiciel;software engineering;methodologie;concurrency;conception logicielle;fault tolerance;programa competidor;structured programming;genie logiciel;langage programmation;systeme informatique;programmation structuree;error detection;methodology;simultaneite informatique;tolerance faute;recouvrement erreur regressif;programme concurrent;programacion estructurada	Abstract   The conversation scheme has been defined to design concurrent software which provides backward error recovery. Since presently no widespread programming language provides constructs for implementing conversations, we propose a methodology for structuring programs, following the conversation scheme. We analyze the use of conversation in languages which adopt the client-server model for processes interaction, pointing out solutions to problems arising from the use of operation and procedure oriented languages [1: Andrews and Schneider,  ACM Comput. Surv.   15 : 3–44; 1983], in which servers are implemented as remote procedures or monitors respectively. The features of a number of programming languages, which are the most suitable for structuring conversations are pointed out. The implementation of nested conversations is also discussed and finally, an industrial application in which our methodology has been profitably applied is presented.		Andrea Clematis;Vittoria Gianuzzi	1993	Comput. Lang.	10.1016/0096-0551(93)90022-S	fault tolerance;real-time computing;error detection and correction;concurrent computing;concurrency;computer science;methodology;programming language;structured programming;second-generation programming language;comparison of multi-paradigm programming languages;algorithm;software fault tolerance	SE	-19.596284889194575	41.41127362879348	78813
1d42592015e64fe0f08ce50588d613037b7d7eda	development and implementation of a real-time open-architecture control system for industrial robot systems	client server architecture;information extraction;path planning;real time;data processing;intelligent task control;task uncertainty;robot manipulator;fuzzy logic;open architecture;control system;flexible manipulator;robot control;robot control system;industrial robots;intelligent system;mechanical impedance;parallel processing	This paper presents a real-time open-architecture control system (ROACS) which has been developed for flexible manipulation of industrial robots. Flexible manipulation refers to robot manipulation that handles tasks with uncertainties; hence, decision-making based on feedback data is essential in realtime operation. A real-time open-architecture control system with the capacity of parallel processing of realtime events, extraction of information from realtime data, and intelligent decision-making, is developed. The entire system consists of a real-time subsystem which manages robot hardware and executes path planning and data processing, and an intelligent subsystem which performs intelligent decision-making and feedback task control. In the context of intelligent task control, information extraction, fuzzy-logic-based interpretation and decision-making, and a novel design of associated real-time robot task language (RTTL) are developed. The conflicts between high bandwidth requirements for real-time services and the undeterministic time length for intelligent decision-making are managed in a cooperative real-time intelligent system model. Client– server architecture is found quite suitable for implementation of the system. The entire system has been successfully developed, implemented, and demonstrated for a robotic salmon slicing task which requires online determination of the backbone position. r 2004 Elsevier Ltd. All rights reserved.	artificial intelligence;control system;flexible display;fuzzy logic;industrial robot;information extraction;internet backbone;motion planning;parallel computing;real-time clock;real-time computing;real-time operating system;real-time transcription;requirement;server (computing)	J. S. Gu;Clarence W. de Silva	2004	Eng. Appl. of AI	10.1016/j.engappai.2004.03.010	fuzzy logic;embedded system;parallel processing;simulation;data processing;open architecture;computer science;control system;artificial intelligence;mechanical impedance;motion planning;robot control;information extraction;client–server model	Robotics	-32.514968320443494	37.53713281267488	78923
992a3f7e03345e59c00d867a4701423e17ec9fd0	comparison of implicit path enumeration and model checking based wcet analysis	worst case execution time;model checking	In this paper, we present our new worst-case execution time (WCET) analysis tool for Java processors, supporting both implicit path enumeration (IPET) and model checking based execution time estimation. Even though model checking is significantly more expensive than IPET, it simplifies accurate modeling of pipelines and caches. Experimental results using the UPPAAL model checker indicate that model checking is fast enough for typical tasks in embedded applications, though large loop bounds may lead to long analysis times. To obtain a tool which is able to cope with larger applications, we recommend to use model checking for more important code fragments, and combine it with the IPET approach.	best, worst and average case;central processing unit;embedded system;gnu;java optimized processor;model checking;multiprocessing;open-source software;pipeline (computing);run time (program lifecycle phase);static program analysis;worst-case execution time	Benedikt Huber;Martin Schoeberl	2009			parallel computing;real-time computing;model checking;computer science;enumeration;worst-case execution time;java	EDA	-22.853024579600657	36.40036956577562	79158
5defab5d4fd91317450f5bcb82be66a9f8613a41	flexible analysis of user actions in heterogeneous distributed learning environments	collaboration analysis;mobile device;programming language;tuple space;discussion support;distributed learning environment;design rationale;mobile devices;tuple spaces	In this paper, we describe an architectural framework for the engineering of distributed learning environments with different devices and multi-language agent support. The framework consists of a central Tuple Space server and clients that differ in hardware (PDAs, PCs with projection) and in programming languages (C#, Prolog, Java). The analysis components use state patterns and action patterns to be defined in and interpreted by Prolog. This framework has been used for supporting the design rationale method QOC in a collaborative visual modelling environment.		Lars Bollen;Adam Giemza;Heinz Ulrich Hoppe	2008		10.1007/978-3-540-87605-2_8	computer science;tuple space;theoretical computer science;operating system;mobile device;database;distributed computing;world wide web	ML	-31.239524279456486	36.35663034442609	79168
86f2857897a41768753792c955eaf881cdfc3b63	modular compilation in high level languages			compiler;high-level programming language	Melvin John Anderson	1988				PL	-22.354492801107835	33.65882784133834	79413
5a4819bc01da26145728c930f08942fa70c6d456	homogeneous agent-based distributed information filtering	distributed system;design process;multi agent system;agent based;representation and clustering;information filtering;distributed computing;multi agent systems;distributed object computing;java rmi	Recent advances in processor, networking and software technologies have made distributed computing a reality in today's world. Distributed systems offer many advantages, ranging from a higher performance to the effective utilization of physically dispersed resources. Many diverse application domains can benefit by exploiting principles of distributed computing. Information filtering is one such application domain. In this article, we present a design of a homogeneous distributed multi-agent information filtering system, called D-SIFTER. D-SIFTER is based on the language-dependent model of Java RMI. The detailed design process and various experiments carried out using D-SIFTER are also described. The results indicate that the distributed inter-agent collaboration improves the overall filtering performance.	application domain;distributed computing;experiment;information filtering system;java remote method invocation;multi-agent system	Rajeev R. Raje;Mingyong Qiao;Snehasis Mukhopadhyay;Mathew J. Palakal;Shengquan Peng;Javed Mostafa	2002	Cluster Computing	10.1023/A:1019760221121	distributed algorithm;real-time computing;design process;computer science;theoretical computer science;multi-agent system;distributed computing;distributed object;distributed design patterns;distributed concurrency control	HPC	-32.50918593216518	44.83166477007956	79575
56d1a8f850938df4af44eb1bbd96b06f782e2546	architecture of the icl goldrush megaserver	high availability;on line transaction processing;satisfiability;parallel computer;parallel machines;system management	This paper discusses the requirements which are to be met by a parallel computer system if it is to satisfy the requirements of commercial database processing, and describes how one such system the ICL GOLDRUSH MegaSERVER has been designed to meet these requirements. GOLDRUSH is a distributed store parallel processor consisting of up to 64 elements, each of which can co-operate in database processing, exploiting both the parallelism found within complex queries (intra-query parallelism) and that found between queries in On-Line Transaction Processing workloads (interquery parallelism). The paper discusses the requirements of business critical database applications including high availability, integrity and manageability. It then details the architecture of GOLDRUSH in order to show how a commercially available system has been designed to meet these requirements; this includes resilience to failure of hardware components such as disks and processors, and the provision of system management applications which allow the parallel machine to be managed as a single system.	alvey;central processing unit;centralisation;computer;database;extended data services;high availability;icl;parallel computing;positive feedback;requirement;scalability;systems management;transaction processing	Paul Watson;George Catlow	1995		10.1007/BFb0000551	parallel computing;real-time computing;systems management;computer science;database;distributed computing;high availability;satisfiability	DB	-28.471938522155543	45.5055917143488	79712
0487f177dd6c6fa3e59d4b08b90ea3df9d7059ec	from remote objects to physically distributed objects	protocols;object oriented programming client server systems distributed object management protocols;object models;distributed objects remote objects physically distributed objects object oriented middleware replication caching;client server systems;object oriented programming;large scale;distributed objects;middleware large scale systems object oriented modeling programming profession protocols computer science ip networks joining processes skeleton;object oriented;clustering;distributed object management;present day;middleware;article in monograph or in proceedings;large scale systems	Present-day object-oriented middleware provides little support for the distribution, replication and caching of the state of a distributed object. This makes these platforms unsuitable for the development of large-scale distributed applications. We argue that the model of distributed objects on which these middleware platforms are based hinders the addition of comprehensive distribution and replication support to these platforms. We present an alternative view of distributed objects, in which objects are not only in control of the functional aspects of their implementation but also in control of their nonfunctional aspects, in particular, the distribution and replication of their state. We claim that a middleware platform based on this view of distributed objects is better suited for developing the large-scale applications	distributed computing;distributed object;entity;middleware	Arno Bakker;Maarten van Steen;Andrew S. Tanenbaum	1999		10.1109/FTDCS.1999.818783	real-time computing;computer science;middleware;database;distributed computing;distributed object	DB	-33.239912947861626	44.350515984214475	79766
1aa6e5ca8e52ae7d19f24da6919c845582444824	efficient rollback-recovery technique in distributed computing systems	distributed system;data transmission;recuperacion;systeme reparti;mise a jour;procesamiento informacion;almacenamiento informacion;checpoint;information transmission;distributed computing systems;distributed processing;distributed computing checkpointing computer crashes very large scale integration fault tolerance electronic switching systems computer society communication networks fault tolerant systems computer networks;transmission message;recovery;message transmission;garbage collection;information storage;fault tolerant system;fault tolerant computing;sistema repartido;system recovery;distributed computing system;community networks;transmission donnee;fault tolerance;information processing;checkpoint;defaillance;sistema tolerando faltas;message passing;rollback recovery;logical ring;stockage information;systeme tolerant les pannes;communication networks rollback recovery technique distributed computing systems logical ring consistent recovery system crash message processing order data messages failure free operation garbage collection task surviving process preceding order information;recuperation;puesta al dia;transmision informacion;failures;message passing distributed processing system recovery fault tolerant computing;transmission information;traitement information;communication;comunicacion;fallo;transmision datos;updating;crash recovery;transmision mensaje;rollback	We propose an approach for implementing rollback recovery in a distributed computing system. A concept of logical ring is introduced for the maintenance of information required for consistent recovery from a system crash. Message processing order of a process is kept by all other processes on its logical ring. Transmission of data messages are accompanied by the circulation of the associated order messages on the ring. The sizes of the order messages are small. In addition, redundant transmission of order information is avoided, thereby reducing the communication overhead incurred during failure free operation. Furthermore, updating of the order information and garbage collection task are simplified in the proposed mechanism. Our approach does not require information about message processing order be written to stable storage; in fact, the time consuming operations of saving information in stable storage are confined to the checkpointing activities. When failures occur, a surviving process need roll back only if some preceding order information is totally lost, which is relatively unlikely considering the ever growing speed of communication networks. It is shown that a system can recover correctly as long as there exists at least one surviving process.		Ge-Ming Chiu;Cheng-Ru Young	1996	IEEE Trans. Parallel Distrib. Syst.	10.1109/71.506695	fault tolerance;parallel computing;real-time computing;information processing;computer science;operating system;database;distributed computing;programming language;computer security;computer network	HPC	-20.68070849471558	44.32347251059911	80146
14fee3c281a2ff9efc5adf54aa2ebfc46a2a9aa2	experience and evolution of concurrentsmalltalk	atomic object;cbox objects yield concurrency;following feature;asynchronous method call;object-oriented concurrent programming language;block context;new feature;concurrent smalltalk;example program;concurrentsmalltalk virtual machine;model of computation;concurrency control;virtual machine;object oriented	ConcurrentSmalltalk is an object-oriented concurrent programming language/system which has been running since late 1985. ConcurrentSmalltalk has the following features:Upper-compatibility with Smalltalk-80. Asynchronous method calls and CBox objects yield concurrency. Atomic objects have the property of running one at a time so that it can serialize the many requests sent to it.  Through experience in writing programs, some disadvantages have become apparent related to concurrency control and the behavior of a block context. In this paper, these issues are re-examined in detail, and then the evolution of the solutions for overcoming these shortcomings is described along with the model of computation in ConcurrentSmalltalk. New features are explained with an example program. The implementation of the ConcurrentSmalltalk virtual machine is also presented along with the evaluation of it.	concurrency (computer science);concurrency control;concurrent computing;model of computation;programming language;serialization;smalltalk;virtual machine	Yasuhiko Yokote;Mario Tokoro	1987		10.1145/38765.38844		PL	-24.532594753901076	37.62587654264991	80251
2b34ac6b0e64ef5780b7b04b7aafd95f8b35e217	stabilizing pipelines for streaming applications	silicon;distributed algorithms;distributed system;streaming applications;protocols;pipeline processing distributed algorithms fault tolerant computing peer to peer computing;fault tolerant;distributed computing;complexity analysis;stabilizing distributed systems;pipelines protocols streaming media sensor phenomena and characterization peer to peer computing sensor systems law legal factors wireless sensor networks application software;sensor network;law;fault tolerant computing;system recovery;scalable stabilizing solutions;sensor networks;pipelines;fault tolerance;peer to peer computing;peer to peer;distributed algorithm;pipeline stabilization;correctness proof;scalable stabilizing solutions pipeline stabilization streaming applications stabilizing distributed systems peer to peer sensor networks;fault tolerance distributed algorithms distributed computing;pipeline processing	In this paper, we study a compositional approach to designing a class of stabilizing distributed systems. We show that the linear pipelined composition of a number of stabilizing modules is inherently stabilizing, and is a useful method of constructing scalable stabilizing solutions for streaming applications that are on the rise in peer-to-peer and sensor networks. We present the correctness proof and complexity analysis of the composition for a linear pipeline. Subsequently, we generalize the pipelined composition to alternative, concurrent, and repetitive versions, investigate the stabilization properties of these versions, and present a set of conditions under which these extended constructions retain their stabilization properties.	acknowledgement (data networks);analysis of algorithms;correctness (computer science);distributed computing;dummy variable (statistics);peer-to-peer;pipeline (computing);scalability;very-large-scale integration	Andrew Berns;Anurag Dasgupta;Sukumar Ghosh	2010	2010 IEEE International Symposium on Parallel & Distributed Processing (IPDPS)	10.1109/IPDPS.2010.5470392	distributed algorithm;fault tolerance;parallel computing;real-time computing;wireless sensor network;computer science;theoretical computer science;distributed computing;computer network	Embedded	-23.61202095170875	45.776218863007394	80355
da5a0a6918fd79a1a8d6a08ee6d0ce94858c8e83	accelerating source-level timing simulation	software prototyping digital simulation graph theory optimisation program verification;probes;synchronization;synchronization software algorithms probes context optimization;software algorithms;optimization;context;virtual environment source level timing simulation timing behavior slts approach instrumentation dependency graphs real life production code	Source-level timing simulation (SLTS) is a promising method to overcome one major challenge in early and rapid prototyping: fast and accurate simulation of timing behavior. However, most of existing SLTS approaches are still coupled with a considerable simulation overhead. We present a method to reduce source-level timing simulation overhead by removing superfluous instrumentation based on instrumentation dependency graphs. We show in experiments, that our optimizations decrease simulation overhead significantly (up to factor 7.7), without losing accuracy. Our detailed experiments are based on benchmarks as well as real life production code, that is simulated in a virtual environment.	algorithm;benchmark (computing);cpu cache;compiler;course (navigation);database;experiment;hardware-in-the-loop simulation;heuristic;hotspot (wi-fi);interrupt;lossless compression;mathematical optimization;overhead (computing);rapid prototyping;real life;real-time transcription;simulation;timing closure;tree accumulation;virtual reality	Simon Schulz;Oliver Bringmann	2016	2016 Design, Automation & Test in Europe Conference & Exhibition (DATE)	10.3850/9783981537079_0234	embedded system;synchronization;real-time computing;simulation;telecommunications;computer science;operating system;distributed computing	EDA	-22.705243514448643	36.841146322728754	80454
b3f3ba9ce8784186c504b9b38de772497917793e	designing masking fault-tolerance via nonmasking fault-tolerance	masking and nonmasking fault tolerance;tolerancia falta;distributed system;detectors;triple modular redundant;systeme reparti;fault tolerance fault tolerant systems design methodology detectors fault detection redundancy costs interconnected systems;formal specification;fault tolerant;detecteur;software fault tolerance;systeme informatique tolerant panne;satisfiability;software engineering;fault tolerant computer systems;mutual exclusion;masquage;sistema repartido;design method;enmascaramiento;stepwise design formal methods;fault tolerance;formal specification software fault tolerance;correcteur;corrector;genie logiciel;masking;correctors;byzantine faults;distributed systems;component based design;tolerance faute;data transfer;process fail stops masking fault tolerance nonmasking fault tolerance program executions specification masking fault tolerant programs fault intolerant program byzantine faults triple modular redundancy	Masking fault-tolerance guarantees that programs continually satisfy their specification in the presence of faults. By way of contrast, nonmasking fault-tolerance does not guarantee as much: it merely guarantees that when faults stop occurring, program executions converge to states from where programs continually (re)satisfy their specification. We present in this paper a component based method for the design of masking fault-tolerant programs. In this method, components are added to a fault-intolerant program in a stepwise manner, first, to transform the fault-intolerant program into a nonmasking fault-tolerant one and, then, to enhance the fault-tolerance from nonmasking to masking. We illustrate the method by designing programs for agreement in the presence of Byzantine faults, data transfer in the presence of message loss, triple modular redundancy in the presence of input corruption, and mutual exclusion in the presence of process fail-stops. These examples also serve to demonstrate that the method accommodates a variety of fault-classes. It provides alternative designs for programs usually designed with extant design methods, and it offers the potential for improved masking fault-tolerant programs.	fault tolerance	Anish Arora;Sandeep S. Kulkarni	1998	IEEE Trans. Software Eng.	10.1109/32.689401	embedded system;fault tolerance;real-time computing;computer science;engineering;distributed computing;programming language	SE	-21.731130100762652	41.57681013771917	80507
2ae65a7b1e62d2ff037878d38ef7ac20995f3273	an end-to-end toolchain: from automated cost modeling to static wcet and wcec analysis		Reliable and fine-grained cost-models are fundamental for real-time systems to statically predict worst-case execution time (WCET) estimates of program code in order to guarantee timeliness. Analogous considerations hold for energy-constrained systems where worst-case energy consumption (WCEC) values are mandatory to ensure meeting predefined energy budgets. These cost models are generally unavailable for commercial off-the-shelf (COTS) hardware platforms, although static worst-case analysis tools require those models in order to predict the WCET as well as the WCEC of program code. To solve this problem, we present NEO, an end-to-end toolchain to automate cost-model generation for both WCET and WCEC analyses. NEO exploits automatically generated benchmarks, which are input for 1) an instruction-level emulation and 2) automatically conducted execution-time and energy-consumption measurements on the target platform. The gathered values (i.e., occurrences per instruction, execution-time and energy-consumption per benchmark) are combined as mathematical optimization problems. The solutions to the formulated problems, which are designed to reveal the worst-case behavior, yield the respective cost models. To statically determine upper bounds of benchmarks, we integrated the cost models into the state-of-the-art WCET analyzer PLATIN. Our evaluations on COTS hardware reveal that our open-source, end-to-end toolchain NEO yields accurate worst-case bounds.	benchmark (computing);best, worst and average case;clang;documentation;embedded system;emulator;end-to-end principle;llvm;library (computing);mathematical optimization;open-source license;open-source software;real-time clock;real-time computing;run time (program lifecycle phase);toolchain;worst-case execution time	Volkmar Sieh;Robert Burlacu;Timo Hönig;Heiko Janker;Phillip Raffeck;Peter Wägemann;Wolfgang Schröder-Preikschat	2017	2017 IEEE 20th International Symposium on Real-Time Distributed Computing (ISORC)	10.1109/ISORC.2017.10	real-time computing;toolchain;computer science;end-to-end principle;benchmark (computing);exploit	Embedded	-23.227625783392632	36.55465311202119	80554
767c76d0d921c4ac969f283ea9d6e1ccde92b3a4	unreliable distributed timing scrutinizer to converge toward decision conditions	consensus;convergence;asynchronous system;unreliable systems;consensus problem	In this paper, we propose to extend the condition-based approach introduced and developed by Mostéfaoui et al. in 2001 by characterizing V n f , the set of all the possible input vectors containing the values proposed by n processes. The condition-based approach consists in identifying sets of input vectors for which the consensus is directly solvable (i.e., in one communication step) in a pure asynchronous model despite up to f crashes. We focus on all the other input vectors. Among them, we identify those that allow to solve the consensus problem in two communication steps still in a pure asynchronous model. For the other ones, we rely on a distributed oracle that enables the input vectors to converge toward a good patterned vector with probability one. We specify a protocol that benefits from this approach to solve the consensus problem very simply and efficiently. RÉSUMÉ. Nous proposons d’étendre l’approche conditionnée, introduite et développée par Mostéfaoui et al. en 2001, par caractérisation de l’ensemble V n f de tous les vecteurs entrants possibles contenant les valeurs générées par n processus. L’approche conditionnée consiste à identifier les ensemble de vecteurs entrants pour lesquels le consensus est directement résoluble (c-a-d en une seule étape) dans un modèle asynchrone pur en dépit de f crashes. Nous nous intéressons aux autres vecteurs entrants parmi lesquels nous identifions ceux qui permettent de résoudre le consensus en deux étapes de communications dans un modèle asynchrone pur. Pour les autres vecteurs, tout dépend d’un oracle distribué qui fait converger les vecteurs vers un vecteur bien conditionné avec probabilité 1 . Nous spécifions un protocole qui tire avantage de cette approche pour résoudre simplement et efficacement le consensus	consensus (computer science);converge;decision problem;identifier	Emmanuelle Anceaume;Eric Mourgaya;Philippe Raipin Parvédy	2004	Stud. Inform. Univ.		real-time computing;consensus;computer science;theoretical computer science;uniform consensus;distributed computing	Logic	-21.73838421702473	43.75671503151935	80720
5c35f9b5aac4a0f400196c96cd267cddb7ac1a91	implementational issues for verifying risc-pipeline conflicts in hol	formal verification;hierarchical model	We outline a general methodology for the formal verification of instruction pipelines in RISC cores. The different kinds of conflicts, i. e. resource, data and control conflicts, that can occur due to the simultaneous execution of the instructions in the pipeline have been formally specified in HOL. Based on a hierarchical model for RISC processors, we have developed a constructive proof methodology, i.e. when conflicts at a specific abstraction level are detected, the conditions under which these occur are generated and explicitly output to the designer, thus easing their removal. All implemented specifications and tactics are kept general, so that the implementation could be used for a wide range of RISC cores. In this paper, the described formalization and proof strategies are illustrated via the DLX RISC processor.	abstraction layer;central processing unit;dlx;floating-point unit;formal verification;hol (proof assistant);hierarchical database model;pipeline (computing);runtime system;tactics ogre: let us cling together	Sofiène Tahar;Ramayya Kumar	1994		10.1007/3-540-58450-1_58	formal verification;computer science;theoretical computer science;programming language;algorithm;hierarchical database model	EDA	-23.379378066720896	34.73097041100652	80730
9133f9d936471226409064231e2146d12dcbd6c9	seamless integration of generic bulk operations in grid applications	application development;distributed system;haute performance;systeme reparti;grid applications;distributed computing;grid;sistema repartido;internet;rejilla;alto rendimiento;grille;calculo repartido;high performance;calcul reparti	Within grid environments, latencies for remote operations of any kind can, as the number of operations increases, become a dominant factor for the overall application performance. Amongst various approaches for latency hiding, bulk operations provide one possible solution to reduce latencies for large numbers of similar operations. The identification of bulks can, however, pose a non-trivial exercise for application developers, often requiring changes to the implemented remote API, and hence direct code modifications to the applications themselves. In this paper we show how bulk operations can be integrated into existing API implementations, and identify the required properties of the API to make this approach feasible. We also show that our approach considers any type of bulk operation, and is independent of the underlying middleware support for bulks. We further describe a prototype implementation (within the SAGA reference implementation effort), and present performance measurements for bulks of remote file copy operations.	application programming interface;middleware;prototype;reference implementation;seamless3d	Stephan Hirmer;Hartmut Kaiser;André Merzky;Andrei Hutanu;Gabrielle Allen	2006		10.1007/11915034_25	embedded system;the internet;simulation;computer science;operating system;distributed computing;grid;rapid application development	OS	-27.038984977793984	43.0412483127941	80777
391f456fc91d85ff3337b709dc6acb02493f9756	from weaving threads to untangling the web: a view of coordination from linda's perspective	distributed system;systeme reparti;ingenieria logiciel;software engineering;conceptual framework;parallel computation;calculo paralelo;sistema repartido;information management;parallel computer;genie logiciel;coordinacion;gestion information;coordination model;calcul parallele;coordination	Exposing the skeleton in the coordination closet p. 18 Design for open systems in Java p. 32 Checking assumptions in component dynamics at the architectural level p. 46 Security benefits from software architecture p. 64 Regulated coordination in open distributed systems p. 81 Debugging distributed applications using a coordination architecture p. 98 Coordinating durative actions p. 115 Communication-passing style for coordination languages p. 131 Software architecture for large control systems: A case study description p. 150 Evaluation of software architectures for a control system: A case study p. 157 Modeling railway control systems using graph grammars: A case study p. 172 On what Linda is: Formal description of Linda as a reactive system p. 187 Three semantics of the output operation for generative communication p. 205 Coordinating mobile agents via blackboards and access rights p. 220 Modeling coordination via asynchronous communication p. 238 Partial order and SOS semantics for linear constraint programs p. 256 Programmable coordination Media p. 274 Safer tuple spaces p. 289 Coordinating actions systems p. 302 Approximating UNITY p. 320 Mobile UNITY coordination constructs applied to packet forwarding for mobile hosts p. 338 From layer to layer: Object-oriented protocol refinement in Kannel p. 355 An asynchronous model of locality, failure, and process mobility p. 374 A component calculus for modeling the Olan configuration language p. 392 A coordination model for distributed object systems p. 410 Coordination patterns for parallel computing p. 414 Concurrent MetateM as a coordination language p. 418 Control-based coordination of human and other activities in cooperation information systems p. 422 Using asynchronous tuple-space access primitives (BONITA primitives) for process coordination p. 426 Berlinda: An object-oriented platform for implementing coordination languages in Java p. 430		Robert D. Bjornson;Nicholas Carriero;David Gelernter	1997		10.1007/3-540-63383-9_69	simulation;computer science;artificial intelligence;operating system;conceptual framework;database;distributed computing;information management;algorithm	PL	-28.750026397608927	33.59205775240944	81204
5437951f0404d3f72f238f84eb0a4da272a12846	instruction tracing via microprogramming	operating system	Assembly level instruction trace routines have been used for years by programmers as a debugging aid. However, most of these have the disadvantages that they are usually 1) very slow and 2) not amenable for use with operating system development. This paper shows how the standard ROM resident instruction set of the H-P 2100 was replaced by a new WCS resident set that contains instruction trace routines with physical I/O. The trace routine was designed so that either all instructions could be traced, or only instructions from a specified area of memory; since the specified area may be modified while the program is running, the user has the flexibility to choose how his program will be monitored. Because all the routines are in firmware rather than software, degradation in speed while the trace executes is not nearly as great as it is for software trace routines. Also, since the trace routine requires no system support, such as I/O or loaders, it can be an effective tool for use in operating system development.	debugging;elegant degradation;firmware;hobbyist operating system development;input/output;microcode;programmer;resident set size;web coverage service	Dan H. Barnes;Larry L. Wear	1974		10.1145/800118.803836	parallel computing;real-time computing;computer hardware;computer science;operating system;programming language;branch trace	Arch	-20.72039810960298	37.38969568376771	81421
f7d0a802ce6d7041e3d3866cc0fc73bcb6544295	evaluating fragment construction policies for sdt systems	experimental design;program instrumentation;measurement;dynamic translation performance;perforation;performance;policies;software dynamic translator;intrusion detection;low overhead;strategy;performance engineering;symposia;software dynamic translation;performance improvement;algorithms;trade off analysis;power consumption;translators;security;security policy;parc;intrusion detection computers;dynamic optimization	Software Dynamic Translation (SDT) systems have been used for program instrumentation, dynamic optimization, security policy enforcement, intrusion detection, and many other uses. To be widely applicable, the overhead (runtime, memory usage, and power consumption) should be as low as possible. For instance, if an SDT system is protecting a web server against possible attacks, but causes 30% slowdown, a company may need 30% more machines to handle the web traffic they expect. Consequently, the causes of SDT overhead should be studied rigorously. This work evaluates many alternative policies for the creation of fragments within the Strata SDT framework. In particular, we examine the effects of ending translation at conditional branches; ending translation at unconditional branches; whether to use partial inlining for call instructions; whether to build the target of calls immediately or lazily; whether to align branch targets; and how to place code to transition back to the dynamic translator. We find that effective translation strategies are vital to program performance, improving performance from as much as 28% overhead, to as little as 3% overhead on average for the SPEC CPU2000 benchmark suite. We further demonstrate that these translation strategies are effective across several platforms, including Sun SPARC UltraSparc IIi, AMD Athlon Opteron, and Intel Pentium IV processors.	align (company);athlon;benchmark (computing);binary translation;central processing unit;dynamic programming;inline expansion;intrusion detection system;just-in-time compilation;mathematical optimization;overhead (computing);pentium 4;place code;run time (program lifecycle phase);sparc;server (computing);service description table;spec#;syntax-directed translation;ultrasparc;web server;web traffic	Jason Hiser;Daniel W. Williams;Adrian Filipi;Jack W. Davidson;Bruce R. Childers	2006		10.1145/1134760.1134778	intrusion detection system;real-time computing;simulation;performance engineering;performance;strategy;computer science;security policy;operating system;programming language;design of experiments;measurement	PL	-23.12711756519826	39.169627483848984	81432
0a28dc7116bd62cf4935b5a51ae308edde5f40af	formal design of a slow-down component for almost synchronous streams	computer languages;history;top down;paper technology;formal method;input output;history mobile communication paper technology computer languages hardware joining processes communication system control visualization machine learning communications technology;visualization;machine learning;mobile communication;joining processes;communications technology;communication system control;state transition;hardware	The paper presents the systematic top-down design of a slown-down component that spreads an incoming stream of almost synchronous messages such that each two proper messages in the output stream are separated by at least one pause. We refine the communication-oriented input/output behaviour to a state-based implementation exploiting three important transformations. In the first design step, we approximate the component’s infinite behaviour by an input/ output synchronous finite behaviour. In the second design step, we differentiate the finite behaviour to localize the effect of single inputs with respect to previous input histories. In the third design step, we extract the component’s state from the input histories by a state abstraction function. Throughout the paper, we explicate a formal method how to implement a specified input/output behaviour by a state transition machine.	approximation algorithm;formal methods;input/output;state transition table;top-down and bottom-up design	Walter Dosch	2006	International Conference on Networking, International Conference on Systems and International Conference on Mobile Communications and Learning Technologies (ICNICONSMCL'06)	10.1109/ICNICONSMCL.2006.100	input/output;information and communications technology;real-time computing;formal methods;visualization;mobile telephony;telecommunications;computer science;theoretical computer science;operating system;top-down and bottom-up design;distributed computing;computer security	EDA	-32.305231297363164	33.85587695038101	81598
fab54e68dbe3a660266090419d5ff2a58f98af26	programming language abstractions for the global network			global network;programming language	Keith R Sibson	2001				Theory	-28.854659955647225	35.0373690350776	81689
17057da6a33a304414f82fe0b16788aacc26c7bd	a policy management system for mobile agent-based services	gestion reseau telecommunication;multiagent system;architecture systeme;agent mobile;collaborative application;cooperation;agente movil;collaborative system;cooperacion;computer network management;arquitectura sistema;mobile agent;system architecture;sistema multiagente;gestion reseau ordinateur;management policy;systeme multiagent;policy management;telecommunication network management	In the Multimedia and Mobile Agent Research Laboratory an underway work is conducted toward combining management policies and Mobile Agents in the area of collaborative applications. The goal is to have a collaborative system thoroughly based on agents and highly flexible and dynamically manageable through multi-level policies. Towards this objective, we have designed a global framework to support policies. This framework is used to define, store and evaluate policies defined through multiple levels of the collaborative system. Moreover, the policies are distributed judiciously over the application. This paper describes the Policy management System we have elaborated and illustrates its integration with the V-Team system through several examples.	management system;mobile agent	Mouhsine Lakhdissi;Hamid Harroud;Ahmed Karmouch;Clifford Grossner	2001		10.1007/3-540-44651-6_12	simulation;computer science;mobile agent;management system;cooperation;systems architecture	Robotics	-29.95384766601817	42.720810352505616	81886
c037059931ce14b3deffa7868cab3822eb6df829	an implementation of loop transformations with a universal intermediate representation interface library	intermediate representation		intermediate representation	Kazuko Kambe;Tsuneo Nakanishi;Kazuki Joe;Yoshitoshi Kunieda;Fujio Kako	1999			distributed computing;computer science;loop fusion;theoretical computer science;intermediate language	HPC	-21.813518633884662	33.53184853870498	81939
fceaafbc4997366047dd76a1a072214fe7465680	the nmfecc cray time-sharing system	systeme temps partage;multiprogrammation;time sharing;multiprogramming;systeme conversationnel;interactive;operating system;interactive system;systeme exploitation;time sharing system;super ordinateur;supercomputers;operating systems	Abstract#R##N#The National Magnetic Fusion Energy Computer Center (NMFECC) at the Lawrence Livermore National Laboratory (LLNL) has implemented a simple, yet powerful interactive operating system, the Cray Time-Sharing System (CTSS), on a Cray-1 supercomputer. CTSS augments the multi-programming batch facilities normally found in supercomputer systems with many of the interactive services typical of interactive minicomputer systems. This paper gives some of the historical background leading to CTSS and gives an overview of the system that emphasizes the strong points or unusual features such as multiple channels, decentralized control of resources, priorities and program scheduling, system recovery, and on-line documentation.		Kirby W. Fong	1985	Softw., Pract. Exper.	10.1002/spe.4380150108	simulation;computer multitasking;computer hardware;computer science;operating system;interactivity;supercomputer operating systems;time-sharing	SE	-26.936951608062795	39.561812659660426	82129
8a4c889c16a043840b48975371cd56a3a0926060	synchronization is coming back,  but is it the same?	content management;detectors;degradation;concurrent computing;shared memory;computer crashes;concurrent object;abortable objects;reduction;failure detection;resource management;atomic register;asynchronous system;concurrent object contection manager obstruction freedom shared memory universal construction failure detection abortable objects atomic register;system recovery;universal construction;monitoring;wait free algorithm;computer crashes monitoring registers degradation programming profession resource management concurrent computing content management object detection detectors;contection manager;registers;programming profession;process crash;test set;atomic snapshot;t resilience;obstruction freedom;adaptive renaming;set agreement;object detection;wait free algorithm adaptive renaming asynchronous system atomic register atomic snapshot process crash reduction set agreement shared memory test set t resilience	This invited talk surveys notions related to synchronization in presence of asynchrony and failures. To the author knowledge, there is currently no textbook in which these notions are pieced together, unified, and presented in a homogeneous way. This talk (that pretends to be neither exhaustive, nor objective) is only a first endeavor in that direction. The notions that are presented and discussed are listed in the keyword list.	asynchrony (computer programming)	Michel Raynal	2008	22nd International Conference on Advanced Information Networking and Applications (aina 2008)	10.1109/AINA.2008.32	asynchronous system;shared memory;detector;parallel computing;real-time computing;test set;degradation;concurrent computing;reduction;telecommunications;content management;computer science;resource management;operating system;database;distributed computing;processor register;computer security	HPC	-23.708202560133497	43.1081579650377	82344
fbb4fb726000c7bd3b57a1c36a166f822452b694	java technology comes to real-time applications	java;real-time systems;java language;memory access safety;portability;productivity;real-time systems	The Java language provides many benefits to application developers, including memory access safety, platform portability, and very high levels of productivity. However, some of the very Java language features that bring these benefits, such as the garbage collector, have also made it difficult or impossible to create applications with bounded response time characteristics. Implementations of the real-time specification for Java (RTSJ) are now available that have proven to be capable of supporting all aspects of real-time systems. This paper discusses the principal concepts underlying the RTSJ, use of the RTSJ's features in real-time applications, the most critical considerations that must be addressed by RTSJ-compliant Java virtual machine implementers, and two example RTSJ-compliant application designs that can fully utilize the RTSJ to portably support their performance requirements.	java;real-time transcription	C. Douglas Locke;Peter C. Dibble	2003	Proceedings of the IEEE		real-time computing;java concurrency;computer science;software development;operating system;strictfp;real time java;garbage collection;programming language;java;rapid application development;specification	Embedded	-23.98860145154617	37.67838381130994	82610
18a8eaad46c6ab17baf9320484140ca58abb09a4	fiona: a fault injector for dependability evaluation of java-based network applications	distributed application;high availability;virtual machines java protocols software fault tolerance;protocols;network protocol;java protocols fault tolerant systems system testing hardware monitoring computer networks fault tolerance control systems application software;fault tolerant;software fault tolerance;virtual machines;fault tolerance fiona dependability evaluation java based network applications unexpected behavior fault injection tool java distributed applications jvmti debugging tool monitoring tool communication faults udp based network protocols;experimental validation;fault injection;java	The use of network applications for high availability systems requires the validation of its fault tolerance mechanisms to avoid unexpected behavior during execution. FIONA is a fault injection tool to experimentally validate these mechanisms of Java distributed applications. The tool uses JVMTI, a new interface for the development of debugging and monitoring tools that enables the instrumentation of Java applications. This approach provides complete transparency between the application under test and the fault injection tool, as well as portability. FIONA injects communication faults, making it possible to conduct the dependability evaluation of UDP based network protocols developed in Java.	communications protocol;debugging;dependability;distributed computing;experiment;fault injection;fault tolerance;high availability;java virtual machine tools interface;system under test	Gabriela Jacques-Silva;Roberto Jung Drebes;Júlio Gerchman;Taisy Silva Weber	2004	Third IEEE International Symposium on Network Computing and Applications, 2004. (NCA 2004). Proceedings.	10.1109/NCA.2004.1347791	embedded system;communications protocol;real-time computing;computer science;operating system;distributed computing;software fault tolerance	Embedded	-33.23601840544282	39.91371064943102	82657
5759ad9e5ef19898b5faf813bb1185bf411fc77f	detection of ada static deadlocks using petri net invariants	petri net invariants;ada;programming environment;red petri;deteccion;concurrent program;ingenieria logiciel;detection;software engineering;message flow;algorithme;medio ambiente programacion;algorithm;system recovery;program testing;monitoring;computational complexity;programming profession;ada tasking programs;programa competidor;concurrency control;control flow;ada static deadlocks;space complexity;genie logiciel;deadlock;interbloqueo;system recovery petri nets algorithm design and analysis information analysis programming profession monitoring dynamic scheduling computer science terminology;terminology;computer science;interblocage;petri nets;system recovery ada computational complexity concurrency control petri nets program testing;ada language;complexities ada static deadlocks petri net invariants ada tasking programs control flow message flow;petri net;information analysis;algorithm design and analysis;complexities;reseau petri;environnement programmation;dynamic analysis;dynamic scheduling;programme concurrent;algoritmo	A method is presented for detecting deadlocks in Ada tasking programs using structural; and dynamic analysis of Petri nets. Algorithmic translation of the Ada programs into Petri nets which preserve control-flow and message-flow properties is described. Properties of these Petri nets are discussed, and algorithms are given to analyze the nets to obtain information about static deadlocks that can occur in the original programs. Petri net invariants are used by the algorithms to reduce the time and space complexities associated with dynamic Petri net analysis (i.e. reachability graph generation). >	ada;deadlock;petri net	Tadao Murata;Boris Shenker;Sol M. Shatz	1989	IEEE Trans. Software Eng.	10.1109/32.21759	real-time computing;stochastic petri net;computer science;distributed computing;process architecture;programming language;petri net	SE	-23.992080775410617	33.03255988821135	82880
b22e606137535861e74fd473a26c5b776c68854f	characterization of timed well-formed petri nets behavior by means of occurrence equations	recursive functions petri nets stochastic processes parallel processing simulation;parallel processing techniques;transition conflicts;stochastic petri net;token creation times;simulation;recursive equations;stochastic petri net models;petri nets power system modeling discrete event simulation analytical models stochastic processes graphics parallel processing differential equations mathematical model state space methods;transition firing instances;stochastic processes;occurrence equations;recursive functions;timed well formed petri nets behavior;high level net models;execution policies;petri nets;execution policies timed well formed petri nets behavior occurrence equations recursive equations stochastic petri net models transition firing instances token destruction times token creation times parallel processing techniques simulation marked graph structures fifo token flow high level net models transition conflicts;petri net;marked graph structures;token destruction times;parallel processing;fifo token flow	So called “recursive equations” have been introduced by Baccell i e t al. as a convenient w a y of characterizing t h e behavior of stochastic P e t r i n e t models in t e r m s of t rans i t ion f iring ins tances and of creation and d e s h c t i o n dimes f o r t o k e n s in places [ I , 2, 31. S u c h equailions have been used t o prove model properties as well 2s t o speed u p s imula t ion by parallel processing techniques in t h e case of Marked Graph structures w i t h FIFO t o k e n f low [4]. W e extend t h e technique t o t h e case of highlevel n e t models in which conflicts among t rans i t ions and f iring disciplines different f r o m FIFO are allowed. W e propose t h e n e w n a m e of “Occurrence Equations” t o characterize t h e technique m o r e precisely. Different execution policies t h a t have been considered in t h e literature are discussed, showing t h e consequences they induce o n t h e n e t occurrence equations.	fifo (computing and electronics);marked graph;parallel computing;recursion (computer science);well-formed petri net	Giovanni Chiola	1995		10.1109/PNPM.1995.524323	real-time computing;stochastic petri net;computer science;theoretical computer science;distributed computing	Vision	-26.657043248599336	33.92867641589348	82941
065d8e4a126c074a391ca69b54316071f0a04762	seamless paxos coordinators	replication;consensus;interdisciplinar;failure detector;fault tolerance;paxos	The Paxos algorithm requires a single correct coordinator process to operate. After a failure, the replacement of the coordinator may lead to a temporary unavailability of the application implemented atop Paxos. So far, this unavailability has been addressed by reducing the coordinator replacement rate through the use of stable coordinator selection algorithms. We have observed that the cost of recovery of the newly elected coordinator’s state is at the core of this unavailability problem. In this paper we present a new technique to manage coordinator replacement that allows the recovery to occur concurrently with new consensus rounds. Experimental results show that our seamless approach effectively solves the temporary unavailability problem, its adoption entails uninterrupted execution of the application. Our solution removes the restriction that the occurrence of coordinator replacements is something to be avoided, allowing the decoupling of the application execution from the accuracy of the mechanism used to choose a coordinator. This result increases the performance of the application even in the presence of failures, it is of special importance to the autonomous operation of replicated applications that have to adapt to varying network conditions and partial failures.	autonomous robot;coupling (computer programming);experiment;leader election;paxos (computer science);seamless3d;selection algorithm;sensor;unavailability	Gustavo M. D. Vieira;Islene C. Garcia;Luiz Eduardo Buzato	2013	Cluster Computing	10.1007/s10586-013-0264-9	paxos;fault tolerance;replication;real-time computing;consensus;computer science;operating system;distributed computing;computer security;failure detector	HPC	-23.19308038439747	45.68278848082836	82951
2e6278d3250f22c385e3f74cc0aa459590dbdf65	a rapidly adaptive collaborative ubiquitous computing environment to allow passive detection of marked objects	contraste;metodo adaptativo;interfase usuario;systeme passif;informatique mobile;user interface;pervasive computing;relacion hombre maquina;man machine relation;methode adaptative;rapidly adapting;informatica difusa;detection objet;detector proximidad;dynamic environment;informatique diffuse;eclairage;adaptive method;interface utilisateur;etalonnage;passive system;relation homme machine;lighting;ingenierie simultanee;ingenieria simultanea;mobile computing;calibration;proximity detector;sistema pasivo;object detection;concurrent engineering;alumbrado;ubiquitous computing environment;detecteur proximite	This paper presents a tool to support the rapid and adaptive deployment of a collaborative, ubiquitous computing environment. A key tool for the configuration and deployment of this environment is a calibration tool to quickly and efficiently calculate the positions of cameras in a dynamic environment. This tool has been incorporated into our current Passive Detection Framework. The paper describes the context where our rapidly adaptive collaborative ubiquitous computing environment would be deployed. The results of a study to test the accuracy of the calibration tool are also presented. This study found that the calibration tool can calculate the position of cameras to within 25 mm for all lighting conditions examined.	software deployment;ubiquitous computing	Hannah Slay;Bruce H. Thomas;Rudi Vernik;Wayne Piekarski	2004		10.1007/978-3-540-27795-8_42	embedded system;real-time computing;calibration;simulation;computer science;operating system;lighting;user interface;mobile computing;concurrent engineering	HCI	-29.847864777170425	43.153339088905135	83115
8a858fb8b10347a51cfc166fdf0d67064fdaa5dd	a modula based language supporting hierarchical development and verification	verification;hierarchical systems;modula	This paper describes a proposal for a modification to the language Modula. The modification was motivated by a desire to bring to the language the ability to build hierarchical systems and to support program verification efforts. In the modified language, called SB-Mod, modules are grouped into levels and calls are permitted from the modules of one level to those of a higher level. Verification is supported through a set of clearly described synchronization constructs and by restricting the flow of information between levels. A result of this is that levels do not interfere with each other and can be treated separately for purposes of verification. In considering modifications, an attempt was made to provide the user with a variety of control mechanisms, while at the same time avoiding situations in which excessive run-time overhead would be incurred.	control system;formal verification;modula;overhead (computing);sandy bridge	Arthur J. Bernstein;J. Robert Ensor	1981	Softw., Pract. Exper.	10.1002/spe.4380110304	real-time computing;verification;computer science;operating system;programming language;algorithm;functional verification	PL	-23.18645617644548	34.75922610759299	83272
2425dd56d770f96f9ae2ef411187b045ef31a6a0	advanced data repository support for java scientific programming	systeme grande taille;programming environment;programacion paralela;sistema informatico;scientific data;object database;parallel programming;computer system;large scale system;base donnee orientee objet;scientific computing;systeme informatique;object oriented databases;information system;systeme information;sistema gran escala;programmation parallele;sistema informacion	Research in the parallel and scientiic computing area has begun to focus on the development of Java-based programming environments. This paper describes the design of an original object-oriented database-style repository interface for high performance storage and retrieval of scientiic data. The design is based on the standard interface to object databases that has been deened by the Object Database Management Group. In the paper, we present the mapping of the repository interface into Java constructs.	database;java;object data management group	Peter Brezany;Marianne Winslett	1999		10.1007/BFb0100673	interface description language;java api for xml-based rpc;parallel computing;jsr 94;java concurrency;application programming interface;computer science;data access object;strictfp;database;real time java;programming language;java;information system;data;java annotation	HPC	-30.091828602136623	41.927150220973246	83297
168abbe6654881e3a18642f2a576ad43f3ba3a35	implicit invocation meets safe, implicit concurrency	language analysis;lenguaje programacion;debugging;puesta a punto programa;empirical study;methode empirique;concurrent object oriented programming;analyse statique;programming language;systeme modulaire;programmation modulaire;analisis dinamica;program design;metodo empirico;performance;empirical method;semantics;simultaneidad informatica;programacion modular;concurrent program;sistema modular;paralelisacion;program verification;semantica;semantique;approche deterministe;analisis estatica;analisis programa;yuheng;debogage;deterministic approach;performance programme;verificacion programa;concurrency;analyse langage;parallelisation;modular system;programa competidor;enfoque determinista;parallelization;analisis lenguaje;langage programmation;concurrent programs;deadlock;modular programming;interbloqueo;design;analyse dynamique;safe implicit concurrency;eficacia programa;modularity;computer science implicit invocation meets safe;program analysis;program performance;interblocage;analyse programme;static analysis;verification programme;parallel languages;simultaneite informatique;implicit concurrency iowa state university hridesh rajan long;languages;language design;dynamic analysis;programme concurrent	Writing correct and efficient concurrent programs still remains a challenge. Explicit concurrency is difficult, error prone, and creates code which is hard to maintain and debug. This type of concurrency also treats modular program design and concurrency as separate goals, where modularity often suffers. To solve these problems, we are designing a new language that we call Panini. In this paper, we focus on Panini's asynchronous, typed events which reconcile the modularity goal promoted by the implicit invocation design style with the concurrency goal of exposing potential concurrency between the execution of subjects and observers.  Since modularity is improved and concurrency is implicit in Panini, programs are easier to reason about and maintain. The language incorporates a static analysis to determine potential conflicts between handlers and a dynamic analysis which uses the conflict information to determine a safe order for handler invocation. This mechanism avoids races and deadlocks entirely, yielding programs with a guaranteed deterministic semantics. To evaluate our language design and implementation we show several examples of its usage as well as an empirical study of program performance. We found that not only is developing and understanding Panini programs significantly easier compared to standard concurrent object-oriented programs, butt also performance of Panini programs is comparable to their equivalent hand-tuned versions written using Java's fork-join framework.	asynchronous i/o;cognitive dimensions of notations;concurrency (computer science);concurrency control;deadlock;implicit invocation;java;static program analysis	Yuheng Long;Sean L. Mooney;Tyler Sondag;Hridesh Rajan	2010		10.1145/1868294.1868304	active object;real-time computing;isolation;computer science;semantics;multiversion concurrency control;non-lock concurrency control;programming language;empirical research;algorithm	PL	-20.631526245034358	33.932303294088655	83301
89f0f7037309ac8ba25269377ae5c1f8ab613974	dynamic checkpointing procedure for the design of stabilizing protocols		In this paper, the problem of designing stabilizing computer communication protocols is addressed. A communication protocol is said to be stabilizing, i f starting from or being at any illegal global state, the protocol will eventually reach a legal (or consistent) global state, and resume its normal execution. To achieve protocol stabilization, the protocol must be able to detect the error when it occurs, and then it must recover from that error and revert to a legal protocol state. Based on the concepts o f event indices and maximally reachable event index tuples, we propose a novel approach for distributed dynamic checkpointing in which the overhead associated with the more traditional periodic checkpointing techniques is avoided. Furthermore, our checkpointing technique can be used as the basis for optimal protocol recovery to achieve stabilization. An example illustrating the new dynamic checkpointing technique is also provided.	application checkpointing;communications protocol;overhead (computing)	K. Saleh;Iftikhar Ahmad;K. Al-Saqabi;A. Agarwal	1993	Information & Software Technology	10.1016/0950-5849(93)90046-6	real-time computing;computer science;distributed computing;computer security	DB	-22.718343323940807	44.88464741787955	83786
4b93080c579747bb37fb3b3f0de42fde3c35002c	cruiser: concurrent heap buffer overflow monitoring using lock-free data structures	program monitor;lock free;program transformation;concurrency;multicore;buffer overflow;multiprocessor architecture;software cruising;non blocking algorithms;high performance;high efficiency;data structure	Security enforcement inlined into user threads often delays the protected programs; inlined resource reclamation may interrupt program execution and defer resource release. We propose software cruising, a novel technique that migrates security enforcement and resource reclamation from user threads to a concurrent monitor thread. The technique leverages the increasingly popular multicore and multiprocessor architectures and uses lock-free data structures to achieve non-blocking and efficient synchronization between the monitor and user threads. As a case study, software cruising is applied to the heap buffer overflow problem. Previous mitigation and detection techniques for this problem suffer from high performance overhead, legacy code compatibility, semantics loyalty, or tedious manual program transformation. We present a concurrent heap buffer overflow detector, Cruiser, in which a concurrent thread is added to the user program to monitor heap integrity, and custom lock-free data structures and algorithms are designed to achieve high efficiency and scalability. The experiments show that our approach is practical: it imposes an average of 5% performance overhead on SPEC CPU2006, and the throughput slowdown on Apache is negligible on average.	blocking (computing);buffer overflow;concurrent computing;data structure;experiment;inline expansion;legacy code;multi-core processor;multiprocessing;non-blocking algorithm;overhead (computing);program transformation;specfp;scalability;throughput	Qiang Zeng;Dinghao Wu;Peng Liu	2011		10.1145/1993498.1993541	multi-core processor;parallel computing;real-time computing;concurrency;data structure;buffer overflow;computer science;operating system;heap overflow;programming language;non-blocking algorithm	PL	-20.91483336577387	39.61180269391013	83907
f89523b88911aba1e59c36d84a1028135f80492c	approaches to design of temporary blackout handling capabilities and an evaluation with a real-time tightly coupled network testbed	highly application dependent design;rams;fully application transparent approach temporary blackout handling capabilities real time tightly coupled network testbed electronic components rams software designer highly application dependent design;application software;real time systems computer networks fault tolerant computing;real time;distributed computing;fully application transparent approach;testing;indexing terms;real time tightly coupled network testbed;computer networks;fault tolerant computing;registers;software design testing application software local area networks electronic components registers read write memory real time systems distributed computing distributed control;electronic components;temporary blackout handling capabilities;software designer;read write memory;software design;distributed control;local area networks;real time systems	The problem of designing real-time tightly coupled networks (TCNs) that can survive through temporary blackout (TB) events that disrupt orderly operation of electronic components and erase the contents of all registers and RAMs is treated. Three approaches are considered. The first, in existence for some time although not practiced extensively, relies on the software designer for highly application-dependent design of all parts of TB handling procedures. The second is a fully application-transparent approach to state saving based on the use of recoverable regions. The third, a compromise between the first two approaches, uses time-driven insertion of saving points and relies on the software designer to determine the membership of the state vector. An experiment that involved designing TB handling capabilities into a real-time TCN testbed using each approach is reported. The testbed-based evaluation results validated the practicality of the two new approaches and indicated the complementary relationship between them and the first approach. >	real-time transcription;testbed	K. H. Kim;W. J. Guan;Andreas Damm;J. A. Rohr	1991		10.1109/FTCS.1991.146703	embedded system;real-time computing;engineering;distributed computing	Embedded	-24.46245038126328	44.46940923554632	83936
5ea18d7217770e599479c441cfbc145467d28d92	bringing agentx subagents to the operating system kernel space	sistema operativo;protocolo acceso;marco;system core;systeme unix;multiagent system;standards;image processing;implementation;unix system;speech processing;tratamiento palabra;kernel function;standard;procesamiento imagen;traitement parole;nucleo sistema;subestructura;noyau systeme;access protocol;traitement image;interface reseau;subsystem;service utilisateur;noyau systeme exploitation;network interfaces;operating system;sous systeme;funcion nucleo;fonction noyau;sous structure;norma;substructure;pattern recognition;systeme exploitation;sistema unix;reconnaissance forme;servicio usuario;operating system kernels;reconocimiento patron;protocole acces;user service;implementacion;network interface;sistema multiagente;etalon;subsistema;norme;systeme multiagent	SNMP agents on conventional operating system platforms are mostly monolithic and implement Managed Objects in a single program. The concept of subagents makes it possible to delegate the implementation of Managed Objects to several subagents located close to the managed subsystems. All subagents are managed by a master agent. While this concept is well accepted for hardware subsystems of modular devices and for host services running in the user space, it is not yet applied for components of conventional operating systems. This paper examines to what extent the IETF standard subagent protocol AgentX is suitable for the management of kernel components. For this purpose, on the Linux platform two subagents have been implemented within the kernel subsystems they manage. They communicate with a master agent in user space. The implemented software contains a generic intermediate layer which carries out AgentX protocol operations and access to Managed Objects. Based on this layer, the network interface subsystem and the Netfilter subsystem have been enhanced with management extensions.	agent extensibility protocol;operating system	Oliver Wellnitz;Frank Strauß	2003		10.1007/978-3-540-39671-0_25	embedded system;simulation;image processing;computer science;network interface;operating system;speech processing;computer network	OS	-27.827760289641624	41.304002451664836	83976
015b50656868a8484df1f27b2efa5869ce2b4015	the distributed application environment - an architecture based on enterprise requirements	distributed application		distributed computing;requirement	I. Domville	1991			enterprise architecture framework;functional software architecture;distributed algorithm;middleware;rm-odp;architecture domain;applications architecture;service-oriented modeling;software engineering;enterprise architecture management;solution architecture;distributed computing;distributed system security architecture;enterprise architecture;distributed design patterns;enterprise integration;view model;computer engineering	SE	-32.7412857098053	45.85784351490699	84005
b82f05c9af09afe0c40bd35483dd2e9146ef8bc8	making distributed applications robust	distributed application;byzantine failures;crash failure;byzantine fault tolerance;byzantine fault tolerant;ordered broadcast	We present a novel translation of systems that are tolerant of crash failures to systems that are tolerant of Byzantine failures in an asynchronous environment, making weaker assumptions than previous approaches. In particular, we assume little about how the application is coded. The translation exploits an extension of the Srikanth-Toueg protocol, supporting ordering in addition to authentication and persistent delivery. We illustrate the approach by synthesizing a version of the Castro and Liskov Practical Byzantine Replication protocol from the Oki and Liskov Viewstamped Replication protocol.	authentication;byzantine fault tolerance;crash (computing);multi-master replication;open knowledge initiative	Chi Ho;Danny Dolev;Robbert van Renesse	2007		10.1007/978-3-540-77096-1_17	real-time computing;computer science;quantum byzantine agreement;distributed computing;byzantine fault tolerance;computer security	OS	-23.164003446470904	45.62752586408873	84411
e690a80ffc562a3d54b2f03d0c8c6ab5aab23b76	gray box based data access time estimation for tertiary storage in grid environment	distributed system;systeme reparti;storage system;storage time;tiempo acceso;stockage donnee;estimation algorithm;sistema reactivo;grid;data storage;temps stockage;simulation methods;sistema repartido;tiempo almacenamiento;rejilla;systeme memoire;data access;reactive system;systeme reactif;grille;almacenamiento datos;temps acces;sistema memoria;access time	In this paper experiments on estimation of data access time for data located on tertiary storage systems are presented. Estimation algorithm based on the gray-box approach using event driven simulation method is described. The implementation of such a system for the Legato DiskXtender HSM system is tested and results are shown. Application of the system for Grid environment is discussed.	access time;computer data storage;data access	Darin Nikolow;Renata Slota;Jacek Kitowski	2003		10.1007/978-3-540-24669-5_24	data access;embedded system;telecommunications;reactive system;access time;computer science;operating system;computer data storage;grid	HPC	-27.69643917719273	42.67974603762358	84543
378ccefb78a975a9edd83b829336dd7a18d6ceaa	brief announcement: deterministic self-stabilizing leader election with o(log log n)-bits	complexity;memory space;self stabilization;leader election	This paper focuses on compact deterministic self-stabilizing solutions for the leader election problem. Self-stabilization is a versatile approach to withstand any kind of transient failures. Leader election is a fundamental building block in distributed computing, enabling to distinguish a unique node, in order to, e.g., execute particular actions. When the protocol is required to be silent (i.e., when communication content remains fixed from some point in time during any execution), there exists a lower bound of Ω(log n) bits of memory per node participating to the leader election (where n denotes the number of nodes in the system). This lower bound holds even in rings.  We present a new deterministic (non-silent) self-stabilizing protocol for n-node rings that uses only O(log log n) memory bits per node, and stabilizes in O(n log2 n) time. Our protocol has several attractive features that make it suitable for practical purposes. First, the communication model matches the one that is expected by existing compilers for real networks. Second, the size of the ring (or any upper bound for this size) needs not to be known by any node. Third, the node identifiers can be of various sizes. Finally, no synchrony assumption besides a weak fair scheduler is assumed. Therefore, our result shows that, perhaps surprisingly, trading silence for exponential improvement in term of memory space does not come at a high cost regarding stabilization time, neither it does regarding minimal assumptions about the framework for our algorithm.	algorithm;binary logarithm;compiler;dspace;distributed computing;identifier;leader election;scheduling (computing);self-stabilization;time complexity	Lélia Blin;Sébastien Tixeuil	2013		10.1145/2484239.2484289	self-stabilization;complexity;real-time computing;computer science;theoretical computer science;leader election;mathematics;distributed computing;algorithm	Theory	-21.693754052614583	44.7257337310549	84584
5a24dde0c76eab62c553ff1dedcf4cbbb643902c	concurrent programming in the ada® language: the polling bias	competition;ada;system programming;rendez vous;synchronisation;programmation systeme;synchronization;concurrent programs;sincronizacion;ada language;processus sequentiel communiquant;competencia	Abstract#R##N##R##N#The rendezvous is an important concept in concurrent programming—two processes need to synchronize, i.e. rendezvous, to exchange information. The Ada programming language is the first programming language to use the rendezvous as the basis of its concurrent programming facilities.#R##N##R##N##R##N##R##N#Our experience with rendezvous facilities in the Ada language shows that these facilities lead to and encourage the design of programs that poll. Polling is generally, but not always, undesirable because it is wasteful of system resources.#R##N##R##N##R##N##R##N#We illustrate and examine the reasons for polling bias in the Ada language. We give suggestions on how to avoid polling programs, and suggest changes to the rendezvous facilities to eliminate the polling bias. The ramifications of these changes to the implementation of the Ada language are also discussed.#R##N##R##N##R##N##R##N#Although we have focused on the rendezvous facilities in the Ada language our analysis is also applicable to other languages. A polling bias can occur in any concurrent programming language based on the rendezvous mechanism if it does not provide appropriate facilities.		Narain H. Gehani;Thomas A. Cargill	1984	Softw., Pract. Exper.	10.1002/spe.4380140503	synchronization;real-time computing;simulation;computer science;operating system;programming language	PL	-20.96185165257687	33.7077939098777	84686
234b2b4ae3cc8d081738d5e9ab0cde5c2c75387a	jompan openmp-like interface for java	shared memory;bulk;i o;parallel programs;asynchronous;java	This paper describes the de nition and implementation of an OpenMP-like set of directives and library routines for shared memory parallel programming in Java. A speci cation of the directives and routines is proposed and discussed. A prototype implementation, JOMP, consisting of a compiler and a runtime library, both written entirely in Java, is presented, which implements a signi cant subset of the proposed speci cation.	c++;compiler;high-level programming language;java;mathematical optimization;openmp;parallel computing;programmer;prototype;runtime library;shared memory	J. Mark Bull;Mark Kambites	2000		10.1145/337449.337466	memory model;computer architecture;parallel computing;java concurrency;strictfp;embedded java;real time java;programming language;java;scala;non-blocking i/o	HPC	-21.72322971818613	34.13045393705324	84715
be86bb328d31d5bd6df12daa32cf7fa06ec8ee46	multicore software engineering, performance, and tools		In a flexible approach to concurrent computation, “processors” ' (computational resources such as threads) are allocated dynamically, just as objects are; but then, just as objects, they can become unused, leading to performance degradation or worse. We generalized the notion of garbage collection (GC), traditionally applied to objects, so that it also handles collecting unused processors. The paper describes the processor collection problem, formalizes it as a set of fixpoint equations, introduces the resulting objects-and-processor GC algorithm implemented as part of concurrency support (the SCOOP model) in the latest version of EiffelStudio, and presents benchmarks results showing that the new technique introduces no overhead as compared to traditional objectsonly GC, and in fact improves its execution time slightly in some cases.	algorithm;central processing unit;computation;computational resource;concurrency (computer science);concurrent computing;eiffelstudio;elegant degradation;fixed point (mathematics);garbage collection (computer science);memory management;multi-core processor;overhead (computing);parallel computing;run time (program lifecycle phase);scoop;software engineering;thread (computing)	Alfred Kobsa;Moni Naor	2012		10.1007/978-3-642-31202-1	computer architecture;search-based software engineering;social software engineering;software development;software construction;computer-aided software engineering;computer engineering	PL	-19.360451520100195	39.53437317380412	84835
f70a31ebec0b5699392ae7dbd93d8d7df8a45883	brief announcement: weakest failure detectors via an egg-laying simulation	shared memory;lower bounds;distributed computing;failure detectors;failure detector;asynchronous distributed system;shared memory system;egg laying;lower bound;wait free	In the <i>k-set agreement task</i>, <i>n</i> processes propose values, and have to decide on at most <i>k</i> of these values. In particular, consensus is 1-set agreement. In PODC 2008 Zieliński showed that the anti-Ω failure detector is necessary and sufficient to solve (<i>n</i> − 1)-set agreement in an asynchronous read/write shared memory system where at most <i>n</i> − 1 processes can fail by crashing.  This paper generalizes Zieliński's result: it shows that anti-Ω<sup><i>t</i></sup> is the weakest failure detector to solve <i>t</i>-set agreement in a <i>t</i>-resilient asynchronous distributed system. Each query to antiΩ<sup><i>t</i></sup> returns a set <i>S</i> of process ids, |<i>S</i>| = <i>n</i> − <i>t</i>, such that some correct process eventually never appears in any such set <i>S</i>; thus, anti-Ω<sup><i>n</i>−1</sup> = anti-Ω, and anti-Ω<sup>1</sup> = Ω. Actually, the paper shows a stronger result: Any failure detector that can be used to solve <i>T</i> is at least as strong as anti-Ω<sup><i>t</i></sup>, for any agreement task <i>T</i> that has no <i>t</i>-resilient solution.	asynchronous i/o;distributed computing;failure detector;podc;sensor;shared memory;simulation	Antonio Fernández;Sergio Rajsbaum;Corentin Travers	2009		10.1145/1582716.1582770	shared memory;real-time computing;computer science;distributed computing;upper and lower bounds;algorithm;failure detector	Logic	-22.00394184003952	44.25018676833162	84995
9d63b237c07c7893da025103c411166e0289dc4b	evaluating the performance of ejb components	containers transaction databases logic java scalability resource management performance analysis access protocols radio access networks;component technology;e codes;scaling law;performance;object oriented programming;software engineering;scaling laws product evaluation benchmarks;mathematical methods and computing;business data processing;software engineering business data processing object oriented programming middleware java;enterprise javabean;middleware;enterprise javabean ejb components business transactions middleware software engineering j2ee mte project;high performance;java	As organizations do more business online, they need scalable, highperformance infrastructures to handle business transactions and provide access to core back-end systems. Middleware components help by providing mechanisms that make it relatively straightforward to build distributed applications. They provide services that support, for example, distributed transaction processing, security features, and directory services. Many middleware products are based on standard infrastructures such as Corba or the Java 2 Enterprise Edition (J2EE) or proprietary technologies such as COM+ or MQSeries. As part of the Middleware Technology Evaluation (MTE) project (www.cmis. csiro.au/adsat/mte.htm),1 we conducted several experiments to explore the performance implications of two common application architectures supported by J2EE’s Enterprise JavaBean (EJB) component technology. One architecture promises simpler engineering and maintenance of the resulting component collection. For applications that require high performance and scalability, however, the alternative architecture might offer a better solution. Such knowledge is crucial to software architects, who must make initial design decisions early in a project, before extensive engineering has begun.	common object request broker architecture;directory service;distributed computing;distributed transaction;enterprise javabeans;experiment;ibm websphere mq;java platform, enterprise edition;java version history;middleware;scalability;software architect;transaction processing	Ian Gorton;Anna Liu	2003	IEEE Internet Computing	10.1109/MIC.2003.1200296	real-time computing;performance;computer science;operating system;middleware;database;distributed computing;programming language;object-oriented programming;java;world wide web	SE	-33.37316856159827	43.14485161644178	85044
38c019557a45f21d5834ee666dea70f811263927	manifest sharing with session types		Session-typed languages building on the Curry-Howard isomorphism between linear logic and session-typed communication guarantee session fidelity and deadlock freedom. Unfortunately, these strong guarantees exclude many naturally occurring programming patterns pertaining to shared resources. In this paper, we introduce sharing into a session-typed language where types are stratified into linear and shared layers with modal operators connecting the layers. The resulting language retains session fidelity but not the absence of deadlocks, which can arise from contention for shared processes. We illustrate our language on various examples, such as the dining philosophers problem, and provide a translation of the untyped asynchronous Ï-calculus into our language.	curry;curry–howard correspondence;deadlock;dining philosophers problem;linear logic;modal logic;type system	Stephanie Balzer;Frank Pfenning	2017	PACMPL	10.1145/3110281	deadlock;curry–howard correspondence;fidelity;modal operator;isomorphism;dining philosophers problem;theoretical computer science;asynchronous communication;distributed computing;linear logic;computer science	PL	-28.74457995028369	32.600761847913255	85209
33da2d99ac96777017b1c1186ea14453584d8b1b	practical experience with os/2 installable file systems	distributed system;sistema operativo;evaluation systeme;andrew file system;architecture systeme;systeme reparti;articulo sintesis;programming environment;article synthese;sistema informatico;evaluacion sistema;gestion fichier;computer system;installable file system;file management;sockets;sna;prototipo;medio ambiente programacion;system evaluation;sistema repartido;operating system;appc;file system;tcp ip;manejo archivos;arquitectura sistema;systeme exploitation;systeme informatique;os 2;system architecture;review;prototype;environnement programmation	Abstract#R##N##R##N#The installable file system (IFS) faculty on OS/2 offers an efficient mechanism for expanding the abilities of the OS/2 kernel. Two prototypes illustrate the usefulness of the IFS facility. An OS/2 port of the Andrew File System (AFS) allows users to access global community files while retaining the private local file system on the OS/2 machine. An IFS implementation of a network protocol mapper, which maps TCP/IP socket calls to SNA Advanced Program-to-Program Communication (APPC) calls, provides the ability to run any socket program on an APPC network after simply re-linking with the mapping library. The only impediment to the development of these prototypes is the lack of kernel-level interfaces to operating system devices, resulting in time-consuming data movement back up to the user level to access the network and the local disks. This impediment will disappear as OS/2 and its associated support software matures.	os/2	David M. Ogle;Neil G. Sullivan;E. Hollins Williams	1992	Softw., Pract. Exper.	10.1002/spe.4380220704	data set;embedded system;installable file system;device file;andrew file system;telecommunications;computer science;engineering;basic sequential access method;operating system;prototype;basic direct access method;internet protocol suite;basic partitioned access method;systems architecture;virtual file system	OS	-26.913980529822776	40.38179675006872	85298
5e2d051f5fad35912091067bc74736004514530d	combining different failure detectors for solving a large-scale consensus problem	distributed system;unreliable failure detector;communication conference;large scale;wan;failure detector;unreliable failure detectors;wide area network;consensus problem	Dependable services in distributed systems rely on some kind of agreement. Such an agreement can be obtained by solving the consensus problem. Most of the proposed consensus' algorithms are based on mutual knowledge of the participants and thus inadequate to wide area networks (WANs). In previous papers, we proposed protocols which deal with WANs constituted of interconnected physical groups of machines (LANs/domains). These protocols rely on Chandra and Toueg' unreliable failure detectors model for asyn-chronous systems extended to handle broadcast addresses and safeness of a whole subnet. Nevertheless, we assumed the same characteristics for local and distant failure detectors. In the present paper, we propose a new algorithm which takes into account a different behavior for the detectors. More precisely, local detectors behave as the S class of Chandra and Toueg and so are more reliable than the distant detectors which behave as the S class. Moreover, the distant failure detector we deene, has the ability to test the failure of a local network via a broadcast address. We prove the correctness of the new algorithm and give some implementations hints in the Internet context.	algorithm;broadcast address;consensus (computer science);correctness (computer science);dependability;distributed computing;failure detector;sensor;subnetwork	Serge Haddad;F. Nguilla Kooh	1999			embedded system;real-time computing;consensus;computer science;artificial intelligence;operating system;database;distributed computing;chandra–toueg consensus algorithm;computer security;failure detector	Theory	-22.815144506928693	44.323244093656	85476
e53d95e4a3ce08c9a1ffa5b9c75cffe93a23dfac	basement: an architecture and methodology for distributed automotive real-time systems	application development;tolerancia falta;developpement logiciel;automotive engineering;systeme temps reel;automotive electronics;fault tolerant;automotive industry;real time;electronique automobile;distributed processing;ingenierie automobile;automotive application;systeme informatique tolerant panne;best effort;holistic approach;indexing terms;real time kernel;distributed computer systems;fault tolerant computer systems;fault tolerant computing;fault tolerant computing real time systems automotive electronics distributed processing safety critical software;distributed real time system;automobile electronic equipment;desarrollo logicial;scheduling;safety critical software;fault tolerance;fault tolerance basement distributed real time architecture automotive real time systems fault tolerance automotive systems holistic approach automotive application software development real time kernel scheduling;resource sharing;software development;systeme informatique reparti;production cost;program development;tolerance faute;ordonnancement;real time systems;computer architecture automotive engineering vehicle safety vehicles application software hardware real time systems kernel fault tolerant systems production systems	BASEMENT TM is a distributed real-time architecture developed for vehicle internal use in the automotive industry. BASEMENT covers application development, as well as the hardware and software that provide execution and communication support. This paper gives an overview of the BASEMENT concept, as well as presenting two system realizations. The first realization is based on the commercial real-time kernel Rubus, while the second is an ultra-dependable architecture (DACAPO) with provisions for fault tolerance at various system levels. BASEMENT is designed for the automotive systems of the future. These systems will be required to simultaneously handle multiple safety critical functions and a large number of less critical functions. All of these features are to be provided at a production cost substantially lower than that of current systems, and, at the same time, with a reliability allowing vehicles to be built without mechanical backup systems, even for safety critical subsystems such as braking and steering. The key constituents of the concept are: 1) resource sharing (multiplexing) of processing and communication resources, 2) a guaranteed real-time service for safety critical applications, 3) a best-effort service for nonsafety critical applications, 4) a communication infrastructure providing efficient communication between distributed devices, 5) a program development methodology allowing resource independent and application oriented development of application software, and 6) a straightforward and well-defined operation principle enabling efficient fault tolerance mechanisms to be employed. Index Terms —Distributed real-time system, holistic approach, automotive application, software development, real-time kernel, scheduling, fault-tolerance. —————————— ✦ ——————————	akaike information criterion;automotive software;backup;best-effort delivery;computer hardware;control system;coprocessor;dacapo;fault tolerance;holism;kernel (operating system);multiplexing;prototype;real-time clock;real-time computing;real-time operating system;real-time transcription;requirement;scheduling (computing);software development;windows rt	Hans A. Hansson;Harold W. Lawson;Olof Bridal;Christer Eriksson;Sven Larsson;Henrik Lönn;Mikael Strömberg	1997	IEEE Trans. Computers	10.1109/12.620482	embedded system;fault tolerance;parallel computing;real-time computing;simulation;computer science;operating system	Embedded	-25.59673047969892	42.899792461432355	85641
02ccd71375aca34314f0f6feda66e5affb436b10	reflective and adaptive middleware for software evolution of information systems		of the Dissertation by Ahmed Ghoneim	information system;middleware;reflection (computer programming);software evolution	Ahmed Mohamed Ali Ghoneim	2007			information system;database;middleware (distributed applications);software evolution;middleware;computer science;distributed computing	SE	-32.1730321665815	45.6656638455373	85852
54f72e0e249f680cf273b6a3ef40db6786d44a79	a hybrid and adaptive model for fault-tolerant distributed computing	distributed system;quality of service distributed processing fault tolerant computing;adaptability;consensus;consensus problem fault tolerant distributed computing distinct runtime condition distributed system quality of service dynamic environment adaptive model synchronous model;fault tolerant;benchmark problem;distributed processing;distributed computing;asynchronous synchronous distributed system;quality of service adaptability asynchronous synchronous distributed system consensus distributed computing model fault tolerance;dynamic environment;fault tolerant computing;fault tolerance;distributed computing model;quality of service;dynamic adaptation;processing speed;fault tolerance distributed computing quality of service computer crashes protocols delay effects fault tolerant systems laboratories runtime context modeling;consensus problem	The capability of dynamically adapting to distinct runtime conditions is an important issue when designing distributed systems where negotiated quality of service (QoS) cannot always be delivered between processes. Providing fault-tolerance for such dynamic environments is a challenging task. Considering such a context, this paper proposes an adaptive model for fault-tolerant distributed computing. This model encompasses both the synchronous model (where there are time bounds on processing speed and message delay) and the asynchronous model (where there is no time bound). To illustrate what can be done in this model and how to use it, the consensus problem is taken as a benchmark problem. An implementation of the model is also described. This implementation relies on a negotiated quality of service (QoS) for channels, that can be timely or untimely. Moreover, the QoS of a channel can be lost during the execution (i.e., dynamically modified from timely to untimely), thereby adding uncertainty into the system.	benchmark (computing);chandra–toueg consensus algorithm;consensus (computer science);distributed computing;fault tolerance;java;linux;quality of service;workstation	Sérgio Gorender;Raimundo José de Araújo Macêdo;Michel Raynal	2005	2005 International Conference on Dependable Systems and Networks (DSN'05)	10.1109/DSN.2005.8	embedded system;fault tolerance;real-time computing;consensus;computer science;distributed computing	HPC	-24.775238774388843	44.534459408581206	86082
518b650706e6b5e723074c918be877c5f53b05ca	performance engineering models of corba-based distributed-object systems	distributed objects	Systems using distributed object technology offer many advantages and their use is becoming widespread. Distributed object systems are typically developed without regard to the locations of objects in the network or the nature of the communication between them. However, this approach often leads to performance problems due to latency in accessing remote objects and excessive overhead for communication. Thus, it is important to provide support for early assessment of the performance characteristics of such systems. This paper presents extensions to the software performance engineering process and its associated models for assessing distributed object systems, and illustrates with a case study.	common object request broker architecture;distributed object;overhead (computing);performance engineering;performance tuning;software performance testing	Connie U. Smith;Lloyd G. Williams	1998			object request broker;performance engineering;csiv2;distributed object;common object request broker architecture;interoperable object reference;distributed computing;computer science;distributed design patterns;software performance testing	SE	-32.804043999981076	44.0789834363784	86425
4e8b5562fd9202d4830be04ecc5352b378aeaf33	rtes demo system2004	level 2;high energy physics	The RTES Demo System 2004 is a prototype for reliable, fault-adaptive infrastructure applicable to commodity-based dedicated application computer farms, such as the Level 2/3 trigger for the proposed BTeV high energy physics project. This paper describes the prototype, and its demonstration at the 11th IEEE Real Time and Embedded Technology Applications Symposium, RTAS 2005.	embedded system;prototype;real time audiosuite	Shikha Ahuja;Ted Bapty;Harry Cheung;Michael Haney;Zbigniew T. Kalbarczyk;Akhilesh Khanna;Jim Kowalkowski;Derek Messie;Daniel Mossé;Sandeep Neema;Steven Nordstrom;Jae C. Oh;Paul Sheldon;Shweta Shetty;Long Wang;Di Yao	2005	SIGBED Review	10.1145/1121802.1121804	simulation;computer science	Embedded	-29.127787944874626	38.223888002601974	86720
d31b589a2c61ee35bcb1e084b92713258e4eb7c3	the asynchronous stack revisited: rounds sets the twilight reeling	twilight reeling;asynchronous stack revisited	Protocols return often to a particular state no matter what happens. We call such a state a ground state. Each action which occurs in the ground state starts a so called round. A round ends when the ground state is reached again. In distributed protocols without global control, rounds are hard to identify. Ground states might be only virtual snapshots and not necessarily observable. When partial order semantics are considered a round can be clearly identified even in a distributed system. We will discuss the use of rounds for structuring and verifying a system's behavior. As an example a Petri net model for the asynchronous stack is introduced.	distributed computing;ground state;observable;petri net;verification and validation	Rolf Walter	1997		10.1007/BFb0052099	theoretical computer science;mathematics;geometry;algorithm	Logic	-22.525938194774447	43.63010414404374	86920
956b9961ddc7d06b03d2283ddad07bf3035edb40	century papers at the first quarter-century milestone	distributed algorithms;distributed system;embryonics;distributed computing;google scholar;chip;distributed systems;distributed algorithm;steady state	My talk intends to look back at the first 25 years of PODC to surface issues regarding its potential impact in light of the extensive spread out of Distributed Computing. Distributed computing expands to a level that no one anticipated even few years ago. In the near future distributed computing will be part of every aspect of our life -- from monitoring personal health to environment tracking, from communication to commuting and will be applied from within a chip through a multi-cpu machine to a virtual globally spanned machine. Society will be completely depended on the ability to continuously provide services at one level or another. The various systems will interact and will never be in a steady state. Are we ready to address such issues? Is the tool-box PODC have developed over the last quarter century will help the community to address the challenges of such systems.When PODC was founded there were skeptics that did not view Distributed Computing as a viable field of Computer Science. Few pioneers envisioned the role it will play and decided that it is an identified discipline with specific focus of interest that will benefit from having a separate conference.An impact is a multi facet notion and there is no single scale to measure it. In the talk I will discuss the impact of PODC from several angles. PODC went through several cycles over the years, from the first very few embryonic years, through a period of stability, some hard years and the emerging focus over the last few years.To get an independent perspective I chose to also look at PODC through the eyes of Google Scholar. I listed regular papers that have at least 100 references to the PODC version and to the subsequent paper in a journal (when I noticed one). The compiled list was different than any list I would have compiled myself1. In the talk I will discuss the list presented in the bibliography and will explore various objective measures that are reflected by it. I will compare it to various other topics and will try to raise issues that the PODC community needs to discuss toward its future role in the continuously expanding Distributed Computing discipline.I will also comment on various emerging fields in which Distributed Computing will play a major role and will point out challenges that the main-stream research in PODC is not capable of addressing.	central processing unit;compiler;computer science;distributed computing;google scholar;podc;steady state	Danny Dolev	2006		10.1145/1146381.1146383	chip;distributed algorithm;simulation;computer science;distributed computing;steady state;operations research;algorithm	HPC	-23.785441898940253	43.07257507742121	86924
ac5178e248c58d7de6c08e2f8f406a70bd43eae3	formal techniques for distributed objects, components, and systems		We strive to use session type technology to prove behavioural properties of fault-tolerant distributed algorithms. Session types are designed to abstractly capture the structure of (even multi-party) communication protocols. The goal of session types is the analysis and verification of the protocols’ behavioural properties. One important such property is progress, i.e., the absence of (unintended) deadlock. Distributed algorithms often resemble (compositions of) multi-party communication protocols. In contrast to protocols that are typically studied with session types, they are often designed to cope with system failures. An essential behavioural property is (successful) termination, despite failures, but it is often elaborate to prove for distributed algorithms. We extend multi-party session types with optional blocks that cover a limited class of link failures. This allows us to automatically derive termination of distributed algorithms that come within these limits.	amiga walker;communications protocol;deadlock;distributed algorithm;distributed computing;distributed object;electronic proceedings in theoretical computer science;fault tolerance;lecture notes in computer science;mobile agent;morgan;r language;springer (tank);terminate (software);termination analysis;type system	Ahmed Bouajjani;Alexandra Silva	2017		10.1007/978-3-319-60225-7	distributed object;distributed computing;computer science	PL	-29.427072824011706	33.28307635411922	86949
ea6e515a07dfa79cf2b32870afb7c370c6a8e2e7	distributed programming with tasks	shared memory;distributed computing;distributed programs;indexation	In round-by-round models of distributed computing processes run in a sequence of (synchronous or asynchronous) rounds. The advantage of the round-by-round approach is that invariants established in the first round are preserved in later rounds. An elegant asynchronous round-by-round shared memory model, is the iterated snapshots model (IS). Instead of the snapshots model where processes share an array m[·] that can be accessed any number of times, indexed by process ID, where Pi writes to m[i] and can take a snapshot of the entire array, we have processes share a two-dimensional array m[·, ·], indexed by iteration number and by process ID, where Pi in iteration r writes once to m[r, i] and takes one snapshot of row r, m[r, ·]. The IS model lends itself more easily to combinatorial analysis. However, to show that whenever a task is impossible in the IS model the task is impossible in the snapshots model, a simulation is needed. Such a simulation was presented by Borowsky and Gafni in PODC97; namely, it was shown how to take a wait-free protocol for the snapshots model, and transform it into a protocol for the IS model, solving the same task. In this paper we present a new simulation from the snapshots model to the IS model, and show that it can be extended to work with models stronger that wait-free. The main contribution is to show that the simulation can work with models that have access to certain communication objects, called 01-tasks. This extends the result of Gafni, Rajsbaum and Herlihy in DISC’2006 stating that renaming is strictly weaker than set agreement from the IS model to the usual non-iterated wait-free read/write shared memory model. We also show that our simulation works with t-resilient models and the more general dependent process failure model of Junqueira and Marzullo. This version of the simulation extends previous results by Herlihy and Rajsbaum in PODC’2010 and DISC’2010 about the topological connectivity of a protocol complex in an iterated dependent process failure model, to the corresponding non-iterated model. Supported by UNAM-PAPIIT. C. Lu, T. Masuzawa, and M. Mosbah (Eds.): OPODIS 2010, LNCS 6490, pp. 205–218, 2010. c © Springer-Verlag Berlin Heidelberg 2010 206 E. Gafni and S. Rajsbaum		Eli Gafni;Sergio Rajsbaum	2010		10.1007/978-3-642-17653-1_17	shared memory;real-time computing;computer science;theoretical computer science;operating system;distributed computing;programming language	Theory	-23.143298791558806	43.25772284217479	87226
05cd403296e8274ada089aafcd1a1913927584d6	reliability and performability modeling using sharpe 2000	sharpe 2000;modelizacion;outil logiciel;evaluation performance;interfaz grafica;software tool;fiabilidad;reliability;performance evaluation;graphical interface;evaluacion prestacion;sistema informatico;computer system;modelisation;herramienta controlada por logicial;fiabilite;performance model;graphic user interface;systeme informatique;modeling;interface graphique	The SHARPE package is now 13 years old. A well known package in the eld of reliability and performability, SHARPE is used in universities as well as in companies. Many important changes have been made during these years to improve the satisfaction of our users. Recently several new algorithms have been added and a Graphical User Interface has been implemented. This paper presents the current status of the tool.	algorithm;graphical user interface;reliability engineering	Christophe Hirel;Robin A. Sahner;Xinyu Zang;Kishor S. Trivedi	2000		10.1007/3-540-46429-8_28	embedded system;simulation;computer science;operating system;graphical user interface;statistics	PL	-19.812276831562453	41.97820983408979	87260
9eb06ad013422ad439d70352f48d72e0c60d3f34	analyzing partially-implemented real-time systems	developpement logiciel;systeme temps reel;algebraic specification;program diagnostics;logica temporal;multiprocessing programs;programming language;ada;ada programming language;processor scheduling;temporal logic;real time;graphical interval logic;algebraic specification real time systems temporal logic program diagnostics processor scheduling multiprocessing programs ada;concurrent program;analyse temporelle;analisis temporal;software engineering;time analysis;real time systems computer languages timing system testing computer society logic programming processor scheduling concurrent computing sequential analysis error correction;concurrency;systems analysis;desarrollo logicial;scheduling;software development;programa competidor;gil;genie logiciel;hybrid systems partially implemented real time systems analysis high level specifications programming language real time concurrent systems ada implemented components partially specified components regular expressions graphical interval logic gil real time temporal logic run time overhead process scheduling static analysis;analyse systeme;static analysis;logique temporelle;ordonnancement;hybrid systems;programme concurrent;real time systems	Most analysis methods for real-time systems assume that all the components of the system are at roughly the same stage of development and can be expressed in a single notation, such as a specification or programming language. There are, however, many situations in which developers would benefit from tools that could analyze partially-implemented systems: those for which some components are given only as high-level specifications while others are fully implemented in a programming language. In this paper, we propose a method for analyzing such partially-implemented real-time systems. We consider real-time concurrent systems for which some components are implemented in Ada and some are partially specified using regular expressions and graphical interval logic (GIL), a real-time temporal logic. We show how to construct models of the partially-implemented systems that account for such properties as run-time overhead and scheduling of processes, yet support tractable analysis of nontrivial programs. The approach can be fully automated, and we illustrate it by analyzing a small example.	real-time operating system;real-time transcription	George S. Avrunin;James C. Corbett;Laura K. Dillon	1998	IEEE Trans. Software Eng.	10.1109/32.707696	parallel computing;real-time computing;ada;computer science;operating system;programming language	SE	-24.617796367892275	34.16848505440073	87285
f6af31cb430719bff2055dbca7794cab5cab5d09	history-dependent petri nets	petri net	Most information systems that are driven by process models (e.g., workflow management systems) record events in event logs, also known as transaction logs or audit trails. We consider processes that not only keep track of their history in a log, but also make decisions based on this log. To model such processes we extend the basic Petri net framework with the notion of history and add guards to transitions evaluated on the process history. We show that some classes of historydependent nets can be automatically converted to classical Petri nets for analysis purposes. These classes are characterized by the form of the guards (e.g., LTL guards) and sometimes the additional requirement that the underlying classical Petri net is either bounded or has finite synchronization distances.	.net framework;acta informatica;automata theory;coloured petri net;component-based software engineering;computation;concurrency (computer science);digital history;enterprise information system;fairness measure;ink serialized format;jan bergstra;jan dietz;knuth–morris–pratt algorithm;lecture notes in computer science;linear temporal logic;r language;rüdiger valk;simulation;springer (tank);synchronicity;tadao kasami;tracing (software);wilfried brauer	Kees M. van Hee;Alexander Serebrenik;Natalia Sidorova;Wil M. P. van der Aalst	2007		10.1007/978-3-540-73094-1_12	real-time computing;stochastic petri net;computer science;database;distributed computing;process architecture;petri net	Logic	-30.217128050913804	34.194218817200664	87348
175579cb2f3e79654ce363f4a3c774e3a48c35bf	from legion to legion-g to ogsi.net: object-based computing for grids	legion g object based computing ogsi net grids object abstraction application codes object based support legion;grid applications;object oriented programming;next generation;message passing;grid computing message passing object oriented programming;grid computing computer science nasa power grids power system dynamics resource management collaboration security fault tolerance software tools;grid computing	1 This work is supported in part by the National Science Foundation grants EIA-9974968, ANI-0222571, and ACI0203960; the NPACI Partnership; the NASA Information Power Grid program; and Microsoft Research. Abstract: The object abstraction has long proven to be an effective foundation upon which to structure application codes; however, its application to Grid Computing contains many challenges related to the heterogeneous, dynamic, and cross-administrativedomain nature of Grids. This paper contains an overview of the succession of three projects at the University of Virginia that provide object-based support for Grid computing: Legion, Legion-G, and OGSI.NET. Throughout the three projects, the overall goal has remained to reduce the barrier for entry to Grid applications developers, thereby enabling next-generation Grid applications beyond those that have been provided by todays heroic programmers. The successes of each project with respect to this overall goal are discussed.	code;grid computing;legion (software);microsoft research;object-based language;operating environment;programmer;software system;succession;system administrator	Marty Humphrey	2003		10.1109/IPDPS.2003.1213379	grid file;method;parallel computing;message passing;semantic grid;computer science;theoretical computer science;operating system;database;distributed computing;programming language;object-oriented programming;grid computing	HPC	-31.096147904628804	42.486587294035246	87566
60690d0b144520fe7683e319de5dbde9f832a005	a resource broker for computing nodes selection in grid computing environments	distributed system;outil logiciel;globus toolkit;calcul grille;software tool;systeme reparti;grid computing environment;resource management;distributed computing;service decouverte et monitorage;securite donnee;resource use;grid;gestion recursos;sistema repartido;rejilla;resource broker;grille;gestion ressources;calculo repartido;herramienta software;grid computing;calcul reparti;security of data	The accelerated development in Grid and peer-to-peer computing systems has positioned them as promising next generation computing platforms. They enable the coordinated or regulated use of geographically distributed resources owned by autonomous organizations (i.e., service providers). The Grid -enabled Problem Solving Environments (PSEs) provide a secure and transparent mechanism for application composition, configuration, expression of user preferences and requirements, and automated resource recovery, scheduling, resource reservation to meet QoS requirement, management of program execution on (remote) resources including staging data and program and gathering results, online access to data sources, along with steering and status management. They leverage services provided by middleware systems for information for resource discovery, trading, advance resource reservation, secure process management, storage access, accounting, and payment management. Nimrod/G is one of the popular Grid-enabled problem solving environments, which is built by leveraging services provided by middleware systems such as Globus, Legion, GRACE, and so on [3][4].	autonomous robot;disk staging;grid computing;legion (software);middleware;next-generation network;peer-to-peer;problem solving;requirement;scheduling (computing);user (computing)	Chao-Tung Yang;Chuan-Lin Lai;Po-Chi Shih;Kuan-Ching Li	2004		10.1007/978-3-540-30208-7_141	broker pattern;computer science;resource management;database;distributed computing;grid;world wide web;computer security;grid computing	HPC	-28.33036987624668	44.03697529610779	87601
bad821f1f58103e63c90dd548af2aa7bed68fb2b	using process algebras for the semantic analysis of data flow networks	unifi;verification;reliability;formal methods;semantics;computer systems;firenze;dependable systems;affidabili;specification and verification;ricerca;resilient computing lab;dependability;software theory;validation;rcl;affidabilita;florence;sistemi;data flow networks;assessment;process algebras	Data flow is a paradigm for concurrent computations in which a collection of parallel processes communicate asynchronously. For nondeterministic data flow networks many semantic models have been defined, however, it is complex to reason about the semantics of a network. In this paper, we introduce a transformation between data flow networks and the LOTOS specification language to make available theories and tools developed for process algebras for the semantic analysis of nondeterministic data flow networks. The transformation does not establish a one-to-one mapping between the traces of a data flow network and the LOTOS specification, but maps each network in a specification which usually contains more traces. The obtained system specification has the same set of traces as the corresponding network if they are finite, otherwise also non fair traces are included. Formal analysis and verification methods can still be applied to prove properties of the original data flow network, allowing in case of networks with finite traces to prove also networks equivalence.	computation;concurrent computing;data flow diagram;dataflow architecture;flow network;language of temporal ordering specification;map;one-to-one (data model);process calculus;programming paradigm;semantic data model;specification language;tracing (software);turing completeness	Cinzia Bernardeschi;Andrea Bondavalli;Luca Simoncini	1995	IEICE Transactions		semantic computing;verification;formal methods;computer science;theoretical computer science;reliability;dependability;database;semantics;educational assessment;statistics	PL	-31.088430421552175	32.34631087182613	88086
9ad43da279999f92321754644d14d6699a6d026e	basic concepts and issues in fault-tolerant distributed systems	basic concepts	The dependability of computing services will become increasingly important in the 90s and beyond. This paper proposes a small number of basic concepts that can be used to explain the architecture of present and future fault-tolerant distributed systems and discusses a list of architectural issues that we find useful to consider when designing or examining such systems. For each issue we present known solutions and design alternatives, we discuss their relative merits and we give examples of systems which adopt one approach or the other. The aim is to introduce some order in the complex discipline of designing and understanding fault-tolerant distributed systems.	dependability;distributed computing;fault tolerance	Flaviu Cristian	1991		10.1007/BFb0024534	architecture;fault tolerance;small number;computer science;dependability;distributed computing	Logic	-26.575167142619033	44.89721498506751	88292
236e6b6e4bfbb18814561e326049666070075721	cadp 2006: a toolbox for the construction and analysis of distributed processes	performance evaluation;distributed processing;asynchronous system;rapid prototyping;message passing;concurrent process	Cadp(Construction and Analysis of Distributed Processes)1 [2,3] is a toolbox for specification, rapid prototyping, verification, testing, and performance evaluation of asynchronous systems (concurrent processes with message-passing communication). The developments of Cadp during the last five years led to a new release named Cadp 2006 “Edinburgh” (as a tribute to the achievements in concurrency theory of the Laboratory for Foundations of Computer Science) that supersedes the previous version Cadp 2001.	asynchronous system;concurrency (computer science);construction and analysis of distributed processes;formal verification;laboratory for foundations of computer science;message passing;performance evaluation;rapid prototyping	Hubert Garavel;Radu Mateescu;Frédéric Lang;Wendelin Serwe	2007		10.1007/978-3-540-73368-3_18	asynchronous system;message passing;real-time computing;computer science;distributed computing;programming language	Logic	-27.97132566363925	35.63123272879945	88496
a6dad7c1cf4a5e2ff07487ec5e19402bd55beca0	from group communication to transactions in distributed systems	distributed system;group communication	The design of structuring concepts that facilitate development of reliable and complex applications and implementation of associated mechanisms is today one of the most important research tasks in computer science. In this context, the 1970s saw the emergence of transactional computing [1], while the 1980s saw the emergence of group communication. This short article describes a group-based system, showing that transaction-based systems and group-based systems are not antithetical. More precisely, we show that adequate group communication can support a specific class of transactions in asynchronous distributed systems. A transaction is a sequence of operations on objects (or on data items) that satisfies the following three properties: From Group Communication to Transactions in Distributed Systems Group Communication	asynchronous i/o;computer science;distributed computing;emergence	André Schiper;Michel Raynal	1996	Commun. ACM	10.1145/227210.227230	communication in small groups;computer science	DB	-24.08928913649658	43.220960199412254	88832
7001abfd4f5f1d4ecbe33cb93b6de74ed3c7983d	a web-based graphical interface for general-purpose high-performance computing clusters	distributed system;interfase usuario;interfaz grafica;systeme reparti;red www;graphical interface;user interface;exigence usager;reseau web;exigencia usuario;distributed computing;besoin utilisateur;necesidad usuario;sistema repartido;internet;user need;network traffic;user requirement;high performance computer;calculo repartido;world wide web;interface utilisateur;just in time;web technology;interface graphique;calcul reparti;service delivery	In this paper we present our work on the development of a Web-based graphical interface for users to remotely log into highperformance computing clusters. We show that the conventional thinclient Web technology has limitations for applications with complex user interface requirements and the rich-client technology such as the Curl is the preferred technology for our graphical interface development. The Curl technology takes the advantage of the processing power of clients to transfer some of the server's jobs to the client. Therefore, it can significantly ease the processing burden on the server and reduce the network traffic. More importantly, adopting the Curl technology we are able to establish a system which can provide just-in-time service delivery to remote users.	general-purpose markup language;graphical user interface	Bing Bing Zhou;B. McKenzie;Andrew Hodgson	2003		10.1007/3-540-37619-4_7	web service;embedded system;the internet;human–computer interaction;computer science;service delivery framework;user requirements document;operating system;graphical user interface;database;distributed computing;user interface;world wide web;graphical user interface testing	HPC	-28.248064512511704	42.95468767062322	89433
3ed47c3e64fda6bd4bc9fc755934ef8399df3d22	implementing the real-time publisher/subscriber model on the controller area network (can)	real time systems communication system control pattern matching routing filtering delay context inspection control systems communication standards;performance evaluation controller area networks field buses real time systems distributed object management;embedded control system;performance evaluation;can bus;performance estimation;real time;controller area networks;real time embedded system;controller area network;field buses;real time communication systems;distributed real time system;design and implementation;addressing scheme real time publisher subscriber model controller area network can distributed real time systems performance evaluation object invocation inter object communication message routing reliability embedded control systems microcontroller powered devices can bus;publish subscribe;distributed object management;tag based addressing;real time communication;publisher subsrciber model;real time application;communication pattern;real time systems	Designing distributed real-time systems as being composed of communicating objects offers many advantages with respect to modularity and extensibility of these systems. However, distributed real-time applications exhibit communication patterns that significantly differ from the traditional object invocation style. The publisher/subscriber model for inter-object communication matches well with these patterns. Any implementation of that model must address the problems of binding subscribers to publishers, of routing and filtering of messages, as well as reliability, efficiency and latency of message delivery. In the context of real-time applications, all these issues must be subject to a rigid inspection with respect to meeting real-time requirements. We argue that for embedded control systems built around smart microcontroller-powered devices these requirements can only be met when exploiting the properties of the underlying network. The CAN-Bus (CAN: Controller Area Network) which is an emerging standard in the field of real-time embedded systems is particularly suited to implement a publisher/subscriber model of communication. In this paper, we present an implementation of the real-time publisher/subscriber model that exploits the underlying facilities of the CANBus. In particular, we introduce a novel addressing scheme for publisher/subscriber communication that makes efficient use of the CAN-Bus addressing method. We provide a detailed design and implementation details along with some preliminary performance estimations.	addressing scheme;can bus;control system;embedded system;extensibility;inter-process communication;microcontroller;name binding;real-time clock;real-time computing;real-time locating system;real-time transcription;requirement;routing	Jörg Kaiser;Michael Mock	1999		10.1109/ISORC.1999.776373	embedded system;real-time computing;can bus;computer science;operating system;distributed computing	Embedded	-33.202142765180575	38.76076909273365	89454
a21ebad59c7f92ca571e1996262ec72a8c68090a	object-oriented real-time distributed programming and support middleware	time triggered;fault tolerant;real time;simulation;object;fault;distributed programs;software fault tolerance;bibliographies;client server systems;object oriented programming;distributed rt objects object oriented real time distributed programming support middleware programming scheme time triggered message triggered object programming scheme tmo programming scheme oo rt programming execution support oo rt distributed programs fault tolerant execution rt distributed parallel simulation;deadline;object oriented programming middleware application software computational modeling software engineering fault tolerance object oriented modeling quantum computing computer applications distributed computing;object oriented;distributed programming;distributed object management;guarantee;middleware;tmo;tolerance;distributed;programming;parallel simulation;digital simulation bibliographies object oriented programming distributed programming client server systems real time systems software fault tolerance distributed object management;digital simulation;real time systems;message triggered	The object-oriented (OO) distributed realtime (RT) programming movement started in 1990's and is growing rapidly at this turn of the century. The motivations are reviewed and then a brief overview is given of the particular programming scheme which this author and his collaborators have been establishing. The scheme is called the time-triggered message triggered object (TMO) programming scheme and it is used to make specific illustrations of the issues and potentials of OO RT programming. The desirable features of middleware providing execution support for OO RT distributed programs are then discussed. The issue of fault-tolerant execution of distributed RT objects and that of RT distributed / parallel simulation are also discussed.	application programming interface;communications satellite;compiler;distributed computing;fault tolerance;ibm notes;middleware;real-time cmix;real-time computing;simulation	K. H. Kim	2000		10.1109/ICPADS.2000.857678	parallel computing;real-time computing;computer science;operating system;distributed computing;programming language;object-oriented programming	HPC	-24.77267647087593	43.18567662116819	89494
c0c41a478e12eb512b79baa4eb5c3bb59b42a61d	self-assessment procedure xx: operating systems	operating system	A self-assessment procedure on operating systems	operating system	John Rosenberg;Akkihebbal L. Ananda;Bhuvanesh Srinivasan	1990	Commun. ACM	10.1145/75577.75584	computer science;operating system	Logic	-28.680277668169566	38.17444716691961	89539
87cf5d5a69b9f01ad60706642ea6a79a35fdc1e1	targeting gnat to the java virtual machine	ada 95;java virtual machine;distributed objects;cryptography;compression;distributed systems;security	The Sun Javan’ technology provides a powerful, portable framework for developing Internet applications. GNAT is a complete Ada 95 compiler that is freely available and runs on a wide range of platforms. There is a natural mapping from Ada 95 to the Java Virtual Machine (JVM), and so it is attractive to consider targeting the GNAT compiler to the JVM to gain the benefits of Ada’s maintainability and reliability for the development of fully portable Internet applications that can operate within the Java environment. We describe a mapping from Ada 95 features as compiled by GNAT into the Java Virtual Machine model, as well as showing how Ada can interface to Java and the class libraries to enable mixed-language applications.	ada;application programming interface;byte;compiler;end-to-end principle;gnat;gnu;global network;gosling emacs;high- and low-level;intermetrics;internet;interoperability;intranet;java class library;java bytecode;java virtual machine;library (computing);maniac mansion;natural mapping (interface design);programmer;programming language specification;raspberry pi 3 model b (latest version);server (computing);server-side;springer (tank);sun one;tucker decomposition	Cyrille Comar;Gary Dismukes;Franco Gasperoni	1997		10.1145/269629.269646	real-time computing;jsr 94;java concurrency;computer science;virtual machine;operating system;strictfp;real time java;programming language;java;scala;java applet;java annotation	PL	-32.079383407508416	41.64742655127681	89556
c0241d37e24f8801642a268464f8143bfc362343	a methodology for compilation of high-integrity real-time programs	systeme temps reel;lenguaje programacion;compilacion;programming language;real time;2614 theoretical computer science;langage programmation;compilation;timing analysis;real time system;sistema tiempo real;program development;1700 computer science	A practical methodology for compilation of trustworthy real-time programs is introduced. It combines new program development and timing analysis techniques with traditional compilation and assembly technologies .	assembly language;compiler;real-time transcription;static timing analysis	Karl Lermer;Colin J. Fidge	1997		10.1007/BFb0002883	dynamic compilation;real-time operating system;computer science;programming language;static timing analysis;algorithm	Embedded	-23.651400849529463	33.681056590678324	89573
bbd38705827e46d830daae8700a8150c1c81331c	a non-conservative software-based approach for detecting illegal cfes caused by transient faults	serviceability;reliability;circuit faults;systematics;availability;transient analysis;software fault tolerance program control structures program diagnostics;assembly;and service ability;fault tolerance;serviceability fault tolerance reliability availability;benchmark testing circuit faults program processors systematics transient analysis operating systems assembly;program processors;extensive fault injection campaign nonconservative software based approach illegal cfes detection transient faults control flow error detection static analysis single bit flips program transformation llvm framework;benchmark testing;operating systems	Software-based methods for the detection of control-flow errors caused by transient fault usually consist in the introduction of protecting instructions both at the beginning and at the end of basic blocks. These methods are conservative in nature, in the sense that they assume that all blocks have the same probability of being the target of control flow errors. Because of that assumption they can lead to a considerable increase both in memory and performance overhead during execution time. In this paper, we propose a static analysis that provide a more refined information about which basic blocks can be the target of control-flow-errors caused by single-bit flips. This information can then be used to guide a program transformation in which only susceptible blocks have to be protected. We implemented the static analysis and program transformation in the context of the LLVM framework and performed an extensive fault injection campaign. Our experiments show that this less conservative approach can potentially lead to gains both in memory usage and in execution time while keeping high fault coverage.	algorithm;basic block;control flow;experiment;fault coverage;fault injection;llvm;overhead (computing);program transformation;run time (program lifecycle phase);sensor;static program analysis;x86	Diego G. Rodrigues;Ghazaleh Nazarian;Álvaro F. Moreira;Luigi Carro;Georgi Gaydadjiev	2015	2015 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFTS)	10.1109/DFT.2015.7315166	serviceability;reliability engineering;embedded system;benchmark;availability;fault tolerance;electronic engineering;parallel computing;real-time computing;computer science;engineering;operating system;reliability;assembly;distributed computing;systematics	Embedded	-21.889908829049926	38.901766902021386	89641
7a998a6e0e4c0a714114c52311c1210c77f23b92	visualized adaptive runtime subsystems	security visualization;trust visualization;open source	Virtual execution platforms contain many runtime subsystems that are invoked on-demand as user code executes. We have instrumented an open-source JVM to dump out information on these runtime subsystems, in order to examine how they are used. The monitored components are known as visualized adaptive runtime subsystems. The visualizations in this poster demonstrate five interesting properties of such runtime subsystems.	open-source software	Jeremy Singer;Chris C. Kirkham	2006		10.1145/1148493.1148541	embedded system;real-time computing;computer science;operating system;runtime verification	HPC	-32.84061345942764	40.60837650109175	89912
a03f6c6c0830141c148b9f0e4c54e08ca79f5168	brief announcement: optimal self-stabilizing mobile byzantine-tolerant regular register with bounded timestamps		This paper proposes the first implementation of a self-stabilizing regular register emulated by n servers that is tolerant to both mobile Byzantine agents, and transient failures in a round-free synchronous model. Differently from existing Mobile Byzantine tolerant register implementations, this paper considers a more powerful adversary where (i) the message delay (i.e., δ) and the period of mobile Byzantine agents movement (i.e., ∆) are completely decoupled and (ii) servers are not aware of their state i.e., they do not know if they have been corrupted or not by a mobile Byzantine agent. The proposed protocol tolerates (i) any number of transient failures, and (ii) up to f Mobile Byzantine agents. In addition, our implementation uses bounded timestamps from the Z13 domain and it is optimal with respect to the number of servers needed to tolerate f mobile Byzantine agents in the given model.	adversary (cryptography);byzantine fault tolerance;emulator;self-stabilization	Silvia Bonomi;Antonella Del Pozzo;Maria Gradinariu Potop-Butucaru;Sébastien Tixeuil	2018		10.1007/978-3-030-03232-6_28	timestamp;adversary;byzantine architecture;bounded function;server;distributed computing;computer science	Metrics	-22.460964311302163	44.85693341964808	89973
adbd6c2b5e0bd86297965244596a5cfef0a75621	an on-line algorithm for checkpoint placement	tolerancia falta;program diagnostics;software fault tolerance;ejecucion programa;systeme informatique tolerant panne;program execution;checkpointing;fault tolerant computer systems;algorithme;performance programme;fault tolerant computing;system recovery;execution programme;checkpointing cost function optimization fault detection time measurement availability programming profession program processors;fault tolerance;algorithms;eficacia programa;program performance;system recovery program diagnostics software fault tolerance;fixed interval;optimal algorithm;on line algorithm;performance optimization;tolerance faute;performance optimization checkpoint placement on line algorithm checkpointing intermediate states fixed intervals fault tolerant computing	Checkpointing enables us to reduce the time to recover from a fault by saving intermediate states of the program in a reliable storage. The length of the intervals between checkpoints affects the execution time of programs. On one hand, long intervals lead to long reprocessing time, while, on the other hand, too frequent checkpointing leads to high checkpointing overhead. In this paper, we present an on-line algorithm for placement of checkpoints. The algorithm uses knowledge of the current cost of a checkpoint when it decides whether or not to place a checkpoint. The total overhead of the execution time when the proposed algorithm is used is smaller than the overhead when fixed intervals are used. Although the proposed algorithm uses only on-line knowledge about the cost of checkpointing, its behavior is close to the off-line optimal algorithm that uses a complete knowledge of checkpointing cost.	algorithm;application checkpointing	Avi Ziv;Jehoshua Bruck	1997	IEEE Trans. Computers	10.1109/12.620479	embedded system;fault tolerance;parallel computing;real-time computing;computer science;operating system;algorithm;software fault tolerance	EDA	-20.372320054176125	44.378116986268154	89992
d02949924b77e2dd622735955c1d25cf9eeaa890	keynote speaker 2: secure software engineering in the cloud		In this talk, I investigate the problem of developing secure development of cloud-based enterprise applications. Consistency, availability, and durability are investigated for web service transactions. I propose an approach that matches the availability of the popular lazy replica update propagation method while increasing durability and consistency. My replica update propagation method is called the Buddy System, which requires that updates are preserved synchronously in two replicas. The first implementation schedules fine-grained WS transactions. In these transactions, each activity is a low-level database operation. Later I consider each transaction as a black box, with only the corresponding Metadata, expressed as UML specifications, as transaction semantics. I refer to these WS transactions as coarse-grained WS transactions. The Buddy System can handle these course grained WS Transactions, using UML stereotypes that allow scheduling semantics to be embedded into the design model. I show that my approach guarantees one-copy serializability, matches the performance of the lazy update propagation methods, and increases durability in the presence of hardware failures. The talk will conclude with current work investigating consistency guarantees for integration of external systems, cloud-based data models and payment security.	cloud computing;software engineering	Aspen Olmsted	2015		10.1109/WorldCIS.2015.7359400	real-time computing;computer science;database;world wide web	SE	-30.86701355839138	35.15460645639658	90638
e318ffd4ea60452af449dc964eaebfa121f56eb3	hgum: messaging framework for hardware accelerators		Software messaging frameworks help avoid errors and reduce engineering efforts in building distributed systems by (1) providing an interface definition language (IDL) to specify precisely the structure of the message (i.e., the message schema), and (2) automatically generating the serialization and deserialization functions that transform user data structures into binary data for sending across the network and vice versa. Similarly, a hardware-accelerated system, which consists of host software and multiple FPGAs, could also benefit from a messaging framework to handle messages both between software and FPGA and also between different FPGAs. The key challenge for a hardware messaging framework is that it must be able to support large messages with complex schema while meeting critical constraints such as clock frequency, area, and throughput. In this paper, we present HGum, a messaging framework for hardware accelerators that meets all the above requirements. HGum is able to generate high-performance and low-cost hardware logic by employing a novel design that algorithmically parses the message schema to perform serialization and deserialization. Our evaluation of HGum shows that it not only significantly reduces engineering efforts but also generates hardware with comparable quality to manual implementation.		Sizhuo Zhang;Hari Angepat;Derek Chiou	2017	2017 International Conference on ReConFigurable Computing and FPGAs (ReConFig)	10.1109/RECONFIG.2017.8279799	computer science;serialization;real-time computing;field-programmable gate array;computer hardware;schema (psychology);software;interface description language;versa;network interface;data structure	Visualization	-29.733147470303393	36.17309572649647	90664
a6861c9539626498cddb343af705e110e13a3e1e	formal approach to agent-based dynamic reconfiguration in networks-on-chip	event b;dynamic reconfiguration;network on chip;formal methods;agent based system;fault tolerance	A Network-On-Chip (NoC) platform is an emerging topology for large-scale applications. It provides a required number of resources for critical and excessive computations. However, the computations may be interrupted by faults occurring at run-time. Hence, reliability of computations as well as efficient resource management at run-time are crucial for such many-core NoC systems. To achieve this, we utilize an agent-based management system where agents are organized in a three-level hierarchy. We propose to incorporate reallocation and reconfiguration procedures into agents hierarchy such that fault-tolerance mechanisms can be executed at run-time. Task reallocation enables local reconfiguration of a core allowing it to be eventually reused in order to restore the original performance of communication and computations. The contributions of this paper are: (i) an algorithm for initial application mapping with spare cores, (ii) a multi-objective algorithm for efficient utilization of spare cores at run-time in order to enhance fault-tolerance while maintaining efficiency of communication and computations at an adequate level, (iii) an algorithm integrating the local reconfiguration procedure and (iv) formal modeling and verification of the dynamic agent-based NoC management architecture incorporating these algorithms within the Event-B framework.	agent-based model	Sergey Ostroumov;Leonidas Tsiopoulos;Juha Plosila;Kaisa Sere	2013	Journal of Systems Architecture - Embedded Systems Design	10.1016/j.sysarc.2013.06.001	embedded system;fault tolerance;parallel computing;real-time computing;formal methods;computer science;operating system;distributed computing;programming language	Embedded	-25.255672171352852	42.71547424535661	90715
ce59facd561c7c47547a0b8bc578052d26a5a092	a dependable system based on adaptive monitoring and replication	graph theory;distributed system;replication;multi agent system;fault tolerant;network flow and congestion;monitoring adaptation models servers fault tolerance fault tolerant systems adaptive systems;agent based;system monitoring distributed processing graph theory multi agent systems software fault tolerance;agent and multi agent based applications;distributed processing;system monitoring;software fault tolerance;large scale system;network flow and congestion fault tolerance replication agent and multi agent based applications reliable parallel and distributed algorithms;fault tolerant distributed systems;simulation experiment;dynamic environment;dependable systems;multi agent systems;servers;fault tolerant system;monitoring;adaptive systems;fault tolerant systems;replication system dependable system adaptive monitoring multiagent system distributed systems large scale system reliability fault tolerance interdependence graph dynamic environment;parallel and distributed algorithms;fault tolerance;adaptive system;reliable parallel and distributed algorithms;network flow;adaptation models	A multi agent system (MAS) has recently gained public attention as a method to solve competition and cooperation in distributed systems. However, MAS's vulnerability due to the propagation of failures prevents it from being applied to a large-scale system. This paper proposes a method to improve the reliability and efficiency of distributed systems. Specifically, the paper deals with the issue of fault tolerance. Distributed systems are characterized by a large number of agents, who interact according to complex patterns. The effects of a localized failure may spread across the whole network, depending on the structure of the interdependences between agents. The method monitors messages between agents to detect undesirable behaviors such as failures. Collecting the information, the method generates global information of interdependence between agents and expresses it in a graph. This interdependence graph enables us to detect or predict undesirable behaviors. This paper also shows that the method can optimize performance of a MAS and improve adaptively its reliability under complicated and dynamic environment by applying the global information acquired from the interdependence graph to a replication system. The advantages of the proposed method are illustrated through simulation experiments based on a virtual auction market.	adaptive grammar;algorithm;distributed computing;experiment;fault tolerance;intelligent agent;interdependence;multi-agent system;replication (computing);simulation;software propagation;throughput	Keinosuke Matsumoto;Akifumi Tanimoto;Naoki Mori	2011	2011 International Conference on High Performance Computing & Simulation	10.1109/HPCSim.2011.5999843	embedded system;fault tolerance;real-time computing;computer science;adaptive system;distributed computing	HPC	-24.588521290764977	45.209555970797965	90802
4cb877afbb66a52dcbd9ecd8ef4f2a1a728ee7d9	a framework of services to provide a persistent data access service for the corba environment			common object request broker architecture;data access	Craig Ball	1999				HPC	-31.691462993019407	45.65234064761414	91221
795577f4976ffc99b28863a89be657a1fa689022	a novel low-overhead recovery approach for distributed systems	distributed system;selected works;bepress	We have addressed the complex problem of recovery for concurrent failures in distributed computing environment. We have proposed a new approach in which we have effectively dealt with both orphan and lost messages. The proposed checkpointing and recovery approaches enable each process to restart from its recent checkpoint and hence guarantee the least amount of recomputation after recovery. It also means that a process needs to save only its recent local checkpoint. In this regard, we have introduced two new ideas. First, the proposed value of the common checkpointing interval is such that it enables an initiator process to log the minimum number of messages sent by each application process. Second, the determination of the lost messages is always done a priori by an initiator process; besides it is done while the normal distributed application is running. This is quite meaningful because it does not delay the recovery approach in any way.	application checkpointing;blocking (computing);clock drift;distributed computing environment;non-blocking algorithm;scsi initiator and target;synchronization (computer science);transaction processing system	Bidyut Gupta;Shahram Rahimi	2009	Journal Comp. Netw. and Communic.	10.1155/2009/409873	real-time computing;computer science;theoretical computer science;distributed computing	HPC	-22.577758774399342	45.83674613533921	91386
114ba41d1ec748549f95adcd000275116cbf364e	the correlation of software testing efforts and software project estimation: an empirical study	software testing;empirical study	A selective, non-manual power controller provides the selective, non-manual power control of various components of a data processing equipment from and reports the power status of such components to a central location. As opposed to pass power controllers which were limited to powering on or off all of the computer equipment controlled by a given controlling element, this invention provides a non-manual capability for remotely powering on or off any one or more components of a system or systems in a selective manner and providing the power status thereof. By being able to selectively activate or deactivate any or all of the components of a data processing system, the ability to conserve electrical energy is optimized. In many cases, a single component or a set of components are not used for extended periods of time, such as an entire production period or at least a large portion of a production period. For example, a peripheral subsystem or a particular peripheral device may be used solely for a certain type of job which is active for only a portion of a production period. Alternatively, a multiprocessor system may run as a unit processor system during evenings and weekends. The net result is a substantial saving in electrical energy that may be implemented from and reported to a central location.	cost estimation in software engineering;software development;software project management;software testing	Junaid Aziz;Faheem Ahmed;Piers R. J. Campbell;Ahmad D. Jaffar	2008		10.3233/978-1-58603-916-5-39	power control;control theory;systems engineering;software;software construction;multiprocessing;computer science;data processing system;software reliability testing;test strategy	SE	-21.191604493568498	41.11022553976522	91397
1e4aa49f4f6c8d8b3527e3d003e538ab06b5d9ff	optimal early stopping uniform consensus in synchronous systems with process omission failures	byzantine failures;distributed system;crash failure;consensus;round based computation;send receive omission;omission failure;send omission;distributed computing;synchronous system;synchronous distributed system;uniform consensus;lower bound	"""Consensus is a central problem of fault-tolerant distributed computing that, in the context of synchronous distributed systems, has received a lot of attention in the crash failure model and in the Byzantine failure model. This paper considers synchronous distributed systems made up of n processes, where up to t can commit failures by crashing or omitting to send or receive messages when they should (""""process omission"""" failure model). It presents a protocol solving uniform consensus in such a context. This protocol has several noteworthy features. First, it is particularly simple. Then, it is optimal both in (1) the number of communication steps needed for processes to decide and stop, namely, min(f+2,t+1) where f is the actual number of faulty processes, and (2) the number of processes that can be faulty, namely t<n/2. Moreover, (3) it ensures that no process (be it correct or faulty) executes more than min(f+2,t+1) rounds, thereby extending the decision lower bound to the full completion time. The design of a uniform consensus protocol with such optimality requirements was an open problem. Interestingly, as min(f+2,t+1) is a lower bound to solve uniform consensus in the synchronous crash failure model, the proposed protocol shows that uniform consensus is not """"harder'' in the omission failure model than in the crash failure model. The protocol is also message size efficient as, in addition to values, a message has to piggyback only n bits of control information."""	byzantine fault tolerance;distributed computing;early stopping;requirement;uniform consensus	Philippe Raipin Parvédy;Michel Raynal	2004		10.1145/1007912.1007963	real-time computing;consensus;computer science;uniform consensus;distributed computing;chandra–toueg consensus algorithm;upper and lower bounds;byzantine fault tolerance;algorithm	Theory	-21.98279539325978	44.323389593925604	91597
2f9ed2605121931dc08715a495ff082c1dec78c3	unpicking the knot: teasing apart vm/application interdependencies	design dependency;virtual machine;transition point;isolation;java virtual machine;resource manager;resource management;keywords dependency;software engineering;execution context;metacircular;dependency;conference paper;virtual machines;dynamic execution;high performance	Flexible and efficient runtime design requires an understanding of the dependencies among the components internal to the runtime and those between the application and the runtime. These dependencies are frequently unclear. This problem exists in all runtime design, and is most vivid in a metacircular runtime --- one that is implemented in terms of itself. Metacircularity blurs boundaries between application and runtime implementation, making it harder to understand and make guarantees about overall system behavior, affecting isolation, security, and resource management, as well as reducing opportunities for optimization. Our goal is to shed new light on VM interdependencies, helping all VM designers understand these dependencies and thereby engineer better runtimes. We explore these issues in the context of a high-performance Java-in-Java virtual machine. Our approach is to identify and instrument transition points into and within the runtime, which allows us to establish a dynamic execution context. Our contributions are: 1) implementing and measuring a system that dynamically maintains execution context with very low overhead, 2) demonstrating that such a framework can be used to improve the software engineering of an existing runtime, and 3) analyzing the behavior and runtime characteristics of our runtime across a wide range of benchmarks. Our solution provides clarity about execution state and allowable transitions, making it easier to develop, debug, and understand managed runtimes.	benchmark (computing);debugging;interdependence;java virtual machine;mathematical optimization;out-of-order execution;overhead (computing);runtime system;software engineering;z/vm	Yi Lin;Stephen M. Blackburn;Daniel Frampton	2012		10.1145/2151024.2151048	real-time computing;computer science;virtual machine;resource management;operating system;distributed computing;runtime verification;programming language	PL	-22.479875945573614	38.686472559275806	91657
2a1c06ba41c0c7186640eb21bc18e90ce09fc619	a multimedia world wide web based conference minute system for group collaboration	world wide web www;conference minute;web documents;multimedia;computer supported cooperative work;video conference;audio video;organizational memory;application sharing;computer supported cooperative work cscw;world wide web	In this paper, we propose a World Wide Web based conference minute system which preserves important information in the conference as web documents and maintains hyperlinks to related minutes to accelerate the progress of the project. This system, based on our Java application sharing framework, provides capabilities to record and replay the audio/video data of the video conference and operations of the shared applications used in the meeting in a synchronous manner. Through the hyperlinks, people can quickly understand the logic flow of every meeting held in the project duration and select any part in a meeting for replay to know what has actually happened. Furthermore, when a new meeting is held, a minute template is generated by the system to inherit the hyperlinks from its predecessors. Other related minutes and the execution status of the resolutions in the project can be easily accessed through the hyperlinks between them. Through the help of the system, execution of the project and management of its organizational memory could be easily achieved to increase the productivity of the collaborative groups with geographically dispersed members.	hyperlink;internet;java;web page;world wide web	Ing-Chau Chang;Bo-Shen Liou;Jau-Hsiung Huang;Shiuh-Sheng Yu;Chee-Wen Shiah	1999	Multimedia Tools and Applications	10.1023/A:1009662809242	simulation;telecommunications;computer science;operating system;computer-supported cooperative work;multimedia;videoconferencing;world wide web;computer security	HPC	-31.687921011831246	40.85116011484678	91867
955f21e36db91a016115e3c12b8ce168dc268197	timing constraint remapping to avoid time discontinuities in distributed real-time systems	controller area networks distributed processing real time systems synchronisation clocks program verification scheduling;clocks;distributed processing;controller area networks;program verification;real world systems timing constraint remapping time discontinuities distributed real time systems dynamic constraint transformation technique timing requirements periodically synchronized distributed local clocks critical time points task release times run time faults constraint transformation for equi continuity discrete clock synchronization algorithms correction intervals continuous clock synchronization formal correctness proving ctec task schedule distributed platform can bus consistency problem;synchronisation;distributed real time system;scheduling;clock synchronization;timing real time systems clocks synchronization runtime read only memory automatic control control systems instruments automation;real time systems;time constraint	In this paper we propose a dynamic constraint transformation technique for ensuring timing requirements in a distributed real-time system possessing periodically synchronized distributed local clocks. Traditional discrete clock synchronization algorithms that adjust local clocks instantaneously yield time discontinuities. Such time discontinuities lead to the loss or the gain of critical time points such as task release times and deadlines, thus raising run-time faults. While continuous clock synchronization is generally suggested to avoid the time discontinuity problem, it incurs too much run-time overhead to be implemented in software. The proposed constraint transformation for equi-continuity (CTEC) technique can solve this problem without modifying discrete clock synchronization algorithms. The CTEC working as an added component of discrete clock synchronization moves timing constraints out of correction intervals. In doing so, it makes use of a mapping derived from continuous clock synchronization in order to exploit the continuity property of continuous clock synchronization. We formally prove the correctness of CTEC by showing that the CTEC with discrete clock synchronization generates the same task schedule as continuous clock synchronization. In order to show the eeectiveness of CTEC, we have implemented it on a distributed platform based on the CAN bus, and performed extensive experiments. The experimental results indicate that time discontinuities present a consistency problem to real-world systems. They also show that CTEC is an eeective solution to the problem, while incurring little run-tine overhead.	algorithm;can bus;clock synchronization;correctness (computer science);experiment;overhead (computing);real-time clock;real-time computing;reflections of signals on conducting lines;requirement;scott continuity;world-system	Minsoo Ryu;Jungkeun Park;Seongsoo Hong	1999		10.1109/RTTAS.1999.777664	clock synchronization;embedded system;synchronization;real-time computing;clock domain crossing;computer science;operating system;self-clocking signal;distributed computing;timing failure;clock drift;matrix clock;scheduling	Embedded	-23.47702958015624	37.744948985741495	92081
2d82f617da10482a019133a092ad8d482f29b66b	search strategies for java bottleneck location by dynamic instrumentation	distributed system;virtual machine;evaluation performance;tecnologia electronica telecomunicaciones;callgraph search algorithm search strategies java bottleneck location dynamic instrumentation prototype tool distributed java applications user selectable program points paradyn performance consultant progressive refinement;systeme reparti;computacion informatica;algoritmo busqueda;performance evaluation;java bottleneck location;gollete estrangulamiento;algorithme recherche;evaluacion prestacion;localization;search algorithm;search strategy;langage java;localizacion;machine virtuelle;software tools java object oriented programming software performance evaluation;goulot etranglement;sistema repartido;localisation;ciencias basicas y experimentales;user selectable program points;strategie recherche;on the fly;progressive refinement;lenguaje java;search strategies;prototype tool;dynamic instrumentation;tecnologias;callgraph search algorithm;maquina virtual;bottleneck;distributed java applications;paradyn performance consultant;java language;estrategia investigacion	The authors have developed a prototype tool that supports instrumentation of distributed Java applications by on-the-fly deployment of interposition code at user-selectable program points. The paper explores the idea, originated in the Paradyn Performance Consultant, of systematically searching for performance bottlenecks by progressive refinement. They present the callgraph search algorithm in detail, and discuss a number of shortcomings with the approach, some of which can be addressed by improving the search strategy. They support their conclusions with two application examples. This is a report of work in progress, aimed at stimulating further investigation of this interesting approach.	java	D. J. Brear;T. Weise;T. Wiffen;Kwok Cheung Yeung;Sarah A. M. Bennett;Paul H. J. Kelly	2003	IEE Proceedings - Software	10.1049/ip-sen:20030807	real-time computing;simulation;internationalization and localization;computer science;virtual machine;operating system;search algorithm	SE	-26.988127509500377	41.197991063875975	92157
459e19e764798e4486bba4f29f38283f36e4d359	an efficient recovery procedure for fault tolerance in distributed systems	algorithme rapide;tolerancia falta;distributed system;algorithme reprise;systeme reparti;fault tolerant;real time;ingenieria logiciel;software engineering;informacion;sistema repartido;propagacion;contexto;fast algorithm;temps reel;fault tolerance;genie logiciel;contexte;tiempo real;algoritmo rapido;context;tolerance faute;information;propagation	In this article, the problem of fault tolerance in real-time distributed systems is addressed by providing an efficient algorithmic procedure for recovery in such systems. Our recovery procedure does not require the application of an intrusive checkpointing procedure, but uses contextual information exchanged between the distributed system components during normal system progress. On detection of a failure, each process, through an efficient propagation mechanism, will have locally computed a recovery point that is mutually consistent with the recovery points computed by other processes. During recovery, each process considers the contextual information recorded after its established recovery point; a minimal amount of computations are redone. Also, a minimal number of processes are required to roll back, and the time needed to revert to normal operation is found to be minimal, thus contributing to the real-time requirements for such systems. Furthermore, the stable storage requirement needed to implement our recovery procedure is bounded and minimal. Proofs of correctness of our procedure are provided, in particular, the absence of orphan messages, message losses, and duplications is shown. An example illustrating our recovery procedure is also provided.		Kassem Saleh;Imtiaz Ahmad;Khaled Al-Saqabi;Anjali Agarwal	1994	Journal of Systems and Software	10.1016/0164-1212(94)90055-8	fault tolerance;real-time computing;simulation;computer science;algorithm	OS	-21.251894696727174	43.675786897472285	92197
71d43e05a201d84079c527ccce0c48559574abed	ordering events based on intentionality in cyber-physical systems		We consider cyber-physical systems (CPSs) comprising a central controller that might be replicated for high-reliability, and one or more process agents. The controller receives measurements from process agents, causing it to compute and issue setpoints that are sent back to process agents. The implementation of these setpoints causes a change in the state of the controlled physical process, and the new state is communicated to the controllers through resulting measurements. To ensure correct operation, the process agents must implement only those setpoints that were caused by their most recent measurements. However, in the presence of replication of the controller, network or computation delays, setpoints and measurements do not necessarily succeed in causing the intended behavior. To capture the dependencies among events associated with measurements and setpoints, we introduce the intentionality relation among such events in a CPS and illustrate its differences with respect to the happened-before relation. We propose a mechanism, intentionality clocks, and the design of controllers and process agents that can be used to guarantee the strong clock-consistency condition under the intentionality relation. Moreover, we prove that our design ensures correct operation despite crash, delay, and network faults. We also demonstrate the practical application of our abstraction through an illustration with a real-world CPS for electrical vehicles.	computation;crash (computing);cyber-physical system;happened-before;intentionality;user error	Wajeb Saab;Maaz Mohiuddin;Simon Bliudze;Jean-Yves Le Boudec	2018	2018 ACM/IEEE 9th International Conference on Cyber-Physical Systems (ICCPS)		intentionality;control theory;smart city;real-time computing;causality;cyber-physical system;computation;abstraction;computer science;crash	Embedded	-24.38017657415877	42.4020953024155	92306
938af67876e0a047ff2061e262e612e6a05262fd	systematic incorporation of efficient fault tolerance in systems of cooperating parallel programs	shared data structures;recovery actions;software reliability data structures parallel programming fault tolerant computing;circuit faults;fault tolerant;application software;cooperating parallel programs;task handling mechanism;task handling mechanism fault tolerance cooperating parallel programs high performance high reliability shared data structures recovery actions;parallel programming;fault tolerant computing;fault tolerant systems;data structures;high reliability;fault tolerance;robustness;computer science;parallel programs;fault tolerant systems data structures fault tolerance circuit faults computer science application software algorithm design and analysis robustness;software reliability;high performance;data structure;algorithm design and analysis	Cooperating parallel programs are being increasingly used in critical applications that require both high performance and high reliability. A promising technique for simultaneously achieving these objectives is to embed the fault tolerance within the program instead of superimposing it via external mechanisms. We develop one such approach for a group of processes that cooperate via shared data structures. The scheme uses data structures having two or more invariant assertions. When the strong invariant is true, the performance is good. When it is false, the performance may be adversely affected, but it is guaranteed that the system will operate correctly provided the weak invariant is true. The algorithms are designed to ensure that processor failures will never cause the weak invariant to be false and to restore the strong invariant within a finite number of recovery actions. We develop a robust task handling mechanism to support the approach and illustrate it for three common data structures. >	fault tolerance	I-Ling Yen;Farokh B. Bastani	1994		10.1109/FTCS.1994.315645	parallel computing;real-time computing;computer science;distributed computing	HPC	-23.142707268908527	41.115988921404195	92368
4c570a8931f91ce4b645c2f45db6c6c0423e9baf	performance evaluation of asynchronous concurrent systems using petri nets	concurrent;performance evaluation;real time;performance;petri nets real time systems performance analysis system performance isolation technology military computing costs microprocessors computational complexity solid state circuits;concurrent systems;real time asynchronous concurrent performance petri net;petri net;asynchronous	Some analysis techniques for real-time asynchronous concurrent systems are presented. In order to model clearly the synchronization involved in these systems, an extended timed Petri net model is used. The system to be studied is first modeled by a Petri net. Based on the Petri net model, a system is classified into either: 1) a consistent system; or 2) an inconsistent system. Most real-world systems fall into the first class which is further subclassified into i) decision-free systems; ii) safe persistent systems; and iii) general systems. Procedures for predicting and verifying the system performance of all three types are presented. It is found that the computational complexity involved increases in the same order as they are listed above.	computational complexity theory;concurrency (computer science);first-class function;performance evaluation;petri net;real-time clock;verification and validation;world-system	C. V. Ramamoorthy;Gary S. Ho	1980	IEEE Transactions on Software Engineering	10.1109/TSE.1980.230492	real-time computing;simulation;stochastic petri net;performance;computer science;asynchronous communication;distributed computing;process architecture;petri net	Embedded	-26.174450181905087	34.66927523997596	92596
90e18ca56592e542d447a02c12651c7592f7aedb	replacing store buffers by load buffers in tso		We consider the weak memory model of Total Store Ordering (TSO). In the classical definition of TSO, an unbounded buffer is inserted between each process and the shared memory. The buffers contains pending store operations of the processes. We introduce a new model where we replace the store buffers by load buffers. In contrast to the classical model, the buffers now contain load operations. We show that the models have equivalent behaviors in the sense that the processes reach identical sets of states when the input program is run under the two models.	control store;protocol buffers	Parosh Aziz Abdulla;Mohamed Faouzi Atig;Ahmed Bouajjani;Ngo Tuan Phong	2018		10.1007/978-3-030-00359-3_2	memory model;real-time computing;computer science;shared memory	Arch	-20.110448611677104	33.32504166309997	92685
2ad8c1c781a69185bab452378f3955bc1a0333e6	fixed-priority sensitivity analysis for linear compute time models	verification;developpement logiciel;preemptive scheduling;real time verification;linear computation time models;fixed priority sensitivity analysis;real time benchmarking;real time;real time architectures;software development process;scheduling discipline;verification temps reel;ingenieria logiciel;fixed priority;indexing terms;schedulability analysis;software engineering;real time architecture;hard real time periodic tasks;software components;formal verification sensitivity analysis scheduling computational complexity real time systems;formal verification;task scheduling feasibility;periodic tasks;computational complexity;sensitivity analysis;desarrollo logicial;task decomposition;scheduling;real time scheduling;temps reel;software development;architecture temps reel;software component;ordonnancement temps reel;genie logiciel;tiempo real;system development;rate monotonic scheduling;ordonamiento;fixed priority scheduling;verificacion;real time architectures fixed priority sensitivity analysis linear computation time models scheduling discipline hard real time periodic tasks task scheduling feasibility fixed priority preemptive scheduling uniprocessor software components task decomposition modules real time scheduling rate monotonic scheduling schedulability analysis real time verification software development process real time benchmarking;modules;ordonnancement;ordonnancement priorite fixe;hard real time;real time systems;uniprocessor;sensitivity analysis processor scheduling scheduling algorithm software algorithms real time systems programming computer architecture runtime law;fixed priority preemptive scheduling	Several formal results exist that allow an analytic determination of whether a particular scheduling discipline can feasibly schedule a given set of hard real-time periodic tasks. In most cases, these results provide little more than a 'yes' or 'no' answer. In practice, it is also useful to know how sensitive scheduling feasibility is to changes in the characteristics of the task set. This paper presents algorithms that allow a system developer to determine, for fixed-priority preemptive scheduling of hard real-time periodic tasks on a uniprocessor, how sensitive schedule feasibility is to changes in the computation times of various software components. The algorithms allow a system developer to determine what changes in task computation times can be made while preserving schedule feasibility (or what changes are needed to achieve feasibility). Both changes to the computation time of a single task and changes to the computation times of a specified subset of the tasks are analyzable. The algorithms also allow a decomposition of tasks into modules, where a module may be a component of multiple tasks. >		Steve Vestal	1994	IEEE Trans. Software Eng.	10.1109/32.277577	parallel computing;real-time computing;computer science;component-based software engineering;operating system;distributed computing;programming language	SE	-24.740307424582646	34.93160553347086	92822
19e2e6b3908b4f05264877714323001e8d0f499f	on embedding a microarchitectural design language within haskell	ucl;discovery;theses;conference proceedings;digital web resources;ucl discovery;open access;ucl library;book chapters;open access repository;ucl research	Based on our experience with modelling and verifying microarchitectural designs within Haskell, this paper examines our use of Haskell as host for an embedded language. In particular, we highlight our use of Haskell's lazy lists, type classes, lazy state monad, and unsafe Perform I0, and point to several areas where Haskell could be improved in the future. We end with an example of a benefit gained by bringing the functional perspective to microarchitectural modelling.	embedded system;haskell;lazy evaluation;microarchitecture;monad (functional programming);type class;verification and validation	John Launchbury;Jeffrey R. Lewis;Byron Cook	1999		10.1145/317636.317784	computer science;programming language;algorithm	PL	-22.460738541523884	33.13835513505039	92878
7a3cc62b960864354df76f87d796364109c31bc3	an architecture for distributing the computation of software clustering algorithms	processing element;cluster algorithm;software engineering tools;process capability;software systems;software structure;automatic programming;computer network;software architecture;distributed version software clustering algorithms computation distribution architecture general purpose networked workstations processing capability supercomputers economic alternative scalable alternative parallel machines individual nodes computer network connected processing elements software engineering tool bunch automatic software system clustering subsystem hierarchy high level abstract views software structure very large systems;distributed programming;computer architecture distributed computing clustering algorithms software algorithms software systems application software computer networks software tools documentation independent component analysis;software tools;workstation clusters;automatic programming software architecture workstation clusters software tools distributed programming	Collections of general purpose networked workstations offer processing capability that often rivals or exceeds supercomputers. Since networked workstations are readily available in most organizations, they provide an economic and scalable alternative to parallel machines. In this paper we discuss how individual nodes in a computer network can be used as a collection of connected processing elements to improve the performance of a software engineering tool that we developed. Our tool, called Bunch, automatically clusters the structure of software systems into a hierarchy of subsystems. Clustering helps developers understand complex systems by providing them with high-level abstract (clustered) views of the software structure. The algorithms used by Bunch are computationally intensive and, hence, we would like to improve our tool’s performance in order to cluster very large systems. This paper describes how we designed and implemented a distributed version of Bunch, which is useful for clustering large systems.	algorithm;bunch;cluster analysis;complex systems;computation;high- and low-level;scalability;software engineering;software system;supercomputer;workstation	Brian S. Mitchell;Martin Traverso;Spiros Mancoridis	2001		10.1109/WICSA.2001.948427	software visualization;software architecture;computer architecture;verification and validation;computing;process capability;software sizing;computer science;engineering;package development process;backporting;software design;software framework;component-based software engineering;software development;software design description;software engineering;software construction;distributed computing;programming language;software analytics;resource-oriented architecture;software deployment;software system;computer engineering	SE	-26.353320293871942	40.59461700884504	92970
1e5e37e547aa7a4f554eade65690ec4e859764e1	a web-based multiuser operating system for reconfiguarble computing	sistema operativo;field programmable gate array;reconfigurable computing;reconfigurable architectures;sistema informatico;computer system;red puerta programable;reseau porte programmable;computer architecture;architecture ordinateur;operating system;systeme exploitation;systeme informatique;arquitectura ordenador;architecture reconfigurable	Traditional recon gurable computing platforms are designed to be used by a single user at a time, and are acknowledged to be di cult to design applications for. These factors limit the usefulness of such machines in education, where one might want to share such a machine and initially hide some of the technical di culties so as to explore issues of greater value. We have developed a multitasking operating system to share our SPACE.2 coprocessing board among up to 8 simultaneous users. A suite of pre{con gured tasks and a web based client allows novices to run recon gurable computing applications. As users develop a knowledge of the FPGA design process they are able to make use of a more advanced PC client to build and upload their own designs. The development aims to increase access to the machine and generate interest in the further study of recon gurable computing. We report on the design, our experience to date, and directions for further development.	computer multitasking;field-programmable gate array;operating system;upload	Oliver Diessel;David A. Kearney;Grant B. Wigley	1999		10.1007/BFb0097942	embedded system;real-time computing;reconfigurable computing;computer science;operating system;distributed computing;field-programmable gate array	HCI	-26.36568552202786	38.89471284729237	93105
f8011459cf516ba31c3ee1ec72299c87a98acfcd	aide - a tool for computer architecture design	computer architecture design;simulation system;critical analysis;interactive simulation;hierarchical modeling environment;computer architecture;top-down architecture design;performance evaluation capability;architecture design environment;process design;top down;operating system;user interfaces;system design;computational modeling;modeling and simulation;packaging;logic simulation;hierarchical model;resource management;hardware	AIDE (Architecture Design Environment) is a modeling and simulation system designed to support the development of computer architectures. By providing a modular, hierarchical modeling environment plus interactive simulation and performance evaluation capabilities, AIDE facilitates the critical analysis necessary in top-down architecture designs. The system currently runs under the UNIX* operating system on a VAX** 11/780. This paper presents the organization of AIDE and discusses its application to computer architecture design.	advanced intrusion detection environment;computer architecture;operating system;performance evaluation;simulation;top-down and bottom-up design;unix;vax	D. J. Ellenberger;Ying W. Ng	1981	18th Design Automation Conference		process design;embedded system;packaging and labeling;computer architecture;electronic engineering;computer science;resource management;operating system;logic simulation;top-down and bottom-up design;modeling and simulation;user interface;computational model;hierarchical database model;computer engineering;systems design	EDA	-30.710025058447755	36.346035379560654	93172
8865093388921b91dde0b5a937c49000d8d13a50	addressing web service performance by replication at the operating system level	per thread replication;replication performance web services architectural translucency;web services operating systems service oriented architecture runtime quality of service delay throughput testing web and internet services application software;replication;request processing techniques;application software;web and internet services;operating system level;performance;testing;web service;runtime;net;software architecture;operating system;per process replication;web services;per thread replication web service performance operating system level replication possibilities evaluation architectural translucency service oriented architecture request processing techniques windows server 2003 iis net per process replication;web service performance;windows server 2003;replication possibilities evaluation;web services operating systems computers software architecture;quality of service;architectural translucency;iis;service oriented architecture;similarity measure;operating systems computers;operating systems;throughput	This paper evaluates replication possibilities for Web services at the operating system level and how they affect Web service performance. This is done in the context of architectural translucency - an approach that defines layers in a service-oriented architecture and states that similar measures have different implications on nonfunctional properties when applied at different layers in different ways. The observed layer here is the operating system. The work presents current request processing techniques and how they are implemented in a typical platform for Web services (Windows Server 2003, IIS and .NET). It then proposes two ways to replicate Web services - per-process replication and per-thread replication and techniques to configure them on the selected platform. The case study demonstrates the feasibility of the concept with performance advantages of up to 50%.	internet information services;microsoft windows;operating system;self-replicating machine;service-oriented architecture;web service	Vladimir Stantchev;Miroslaw Malek	2008	2008 Third International Conference on Internet and Web Applications and Services	10.1109/ICIW.2008.113	web service;web modeling;real-time computing;computer science;operating system;software engineering;ws-policy;ws-addressing;database;law;world wide web;computer security;computer network	SE	-31.989014026641534	43.89378532690047	93222
5f70f7b542117ac6572ed556f66d22614ed30d54	modular code generation from hybrid automata based on data dependency	automatic code generation;data dependency;computer languages;high level languages;continuous dynamics;discrete data;programming language;synchronous semantics modular code generation hybrid automata data dependency hybrid system charon modeling language high level programming language continuous dynamics finite state machine mathematical equation modeling;differential algebraic equations;code generation;high level programming language;formal verification program compilers high level languages;modeling language;charon modeling language;computer vision;automata;interleaved codes;mathematical equation modeling;formal verification;trajectory;hybrid power systems;data dependence;hybrid system;mathematical model;hybrid automata;differential equations;program compilers;hybrid power systems automata mathematical model computer languages computer vision differential equations real time systems differential algebraic equations trajectory interleaved codes;finite state machine;synchronous semantics;modular code generation;real time systems	Model-based automatic code generation is a process of converting abstract models into concrete implementations in the form of a program written in a high-level programming language. The process consists of two steps, first translating the primitives of the model into (approximately) equivalent implementations, and then scheduling the implementations of primitives according to the data dependency inherent in the model. When the model is based on hybrid automata that combine continuous dynamics with a finite state machine, the data dependency must be viewed in two aspects: continuous and discrete. Continuous data dependency is present between mathematical equations modeling timecontinuous behavior of the system. On the other hand, discrete data dependency is present between guarded transitions that instantaneously change the continuous behavior of the system. While discrete data dependency has been studied in the context of code generation from modeling languages with synchronous semantics (e.g., ESTEREL), there has been no prior work that addresses both kinds of dependency in a single framework. In this paper, we propose a code generation framework for hybrid automata which deals with continuous and discrete data dependency. We also propose techniques for generating modular code that retains modularity of the original model. The framework has been implemented based on the hybrid system modeling language CHARON, and experimented with Sony’s robot platform AIBO. Comments Copyright 2003 IEEE. Reprinted from Proceedings of the 9th IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS 2003), pages 160-168. Publisher URL: http://ieeexplore.ieee.org/xpl/tocresult.jsp?isNumber=27075&page=1 This material is posted here with permission of the IEEE. Such permission of the IEEE does not in any way imply IEEE endorsement of any of the University of Pennsylvania's products or services. Internal or personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution must be obtained from the IEEE by writing to pubs-permissions@ieee.org. By choosing to view this document, you agree to all provisions of the copyright laws protecting it. This conference paper is available at ScholarlyCommons: http://repository.upenn.edu/cis_papers/26 Modular Code Generation from Hybrid Automata based on Data Dependency Jesung Kim and Insup Lee Department of Computer and Information Science University of Pennsylvania jesung@saul.cis.upenn.edu, lee@cis.upenn.edu	aibo;automata theory;automatic programming;code generation (compiler);concurrency (computer science);correctness (computer science);data dependency;debugging;dependence analysis;directed acyclic graph;discrepancy function;discrete mathematics;embedded system;esterel;finite-state machine;formal language;high- and low-level;high-level programming language;hybrid automaton;hybrid system;information and computer science;information science;level design;modeling language;numerical partial differential equations;rajeev alur;real time audiosuite;real-time clock;real-time computing;real-time transcription;scheduling (computing);systems modeling;thread (computing)	Jesung Kim;Insup Lee	2003		10.1109/RTTAS.2003.1203048	dependency;real-time computing;computer science;theoretical computer science;operating system;finite-state machine;dependency inversion principle;programming language;high-level programming language;algorithm	Embedded	-33.03118171394705	33.5247024805416	93269
d7aae006ec0c747d299cee4e6732ca42eacdd178	design of transaction commitment protocols	transaccion;tolerancia falta;distributed system;base donnee repartie;systeme reparti;distributed database;protocole transmission;sistema informatico;base repartida dato;transmission message;computer system;message transmission;transaction;protocolo transmision;sistema repartido;fault tolerance;systeme informatique;tolerance faute;transmision mensaje;transmission protocol	Transactions are universally accepted as simple and convenient means of designing fault-tolerant systems; by definition, they preserve consistency. In distributed database systems, implementation of distributed transactions involves guaranteeing that either all sites participating in the transaction incorporate its effects into the local databases or none does. This is known as transaction commitment. The focus of this paper is on protocols achieving transaction commitment in the presence of site and link faults not leading to network partitions. We first introduce a methodology based on the separation of the essence and means of a protocol, to explore the commit protocols. Using this, we derive simple characterizations of commit protocols resilient to a prescribed number of failures. Subsequently we investigate the effects of the architecture of the underlying distributed system on the commit protocols. Finally we present the stepwise derivation of two protocols.	atomic broadcast;central processing unit;commitment ordering;communications protocol;complexity;distributed computing;distributed database;distributed transaction;eng-tips forums;fault tolerance;mathematical model;podc;registered jack;source-to-source compiler;stepwise regression;symposium on principles of database systems;tree (data structure)	K. V. S. Ramarao	1991	Inf. Sci.	10.1016/0020-0255(91)90010-R	three-phase commit protocol;commit;fault tolerance;real-time computing;two-phase commit protocol;telecommunications;distributed transaction;computer science;database;compensating transaction;distributed database;computer security	DB	-21.586715251842154	44.086189964508776	93442
6791efbfc14a72240cc397a716a64da57f1926f9	lua-based virtual machine platform for spacecraft on-board control software	computers;software;virtualization;aerospace field lua based virtual machine platform spacecraft on board control software mission critical embedded software autonomous operation software reuse jvm code portability time slicing scheduler flight computer flight software virtualization environment debug support api lua interpreter message passing scheduler locking coroutine scheduler time slicing coroutines preemptive multitasking collaborative coroutines multithreading control task programming lua script language highly autonomous task spacecraft control spacecraft flight software lua based virtualization environment development cost reduction;virtual machining;runtime;engines;virtualisation aerospace control application program interfaces authoring languages control engineering computing message passing multi threading program debugging scheduling software portability software reusability space vehicles spacecraft computers virtual machines;reusability obcp lua spacecraft virtual machine mission critical embedded software;space vehicles;software space vehicles computers engines virtual machining virtualization runtime	Mission critical embedded software for autonomous operation requires high development cost due to its long development cycle. One of the potential solutions for reducing the cost is to reuse the software developed at previous missions. Virtual machine platform such as JVM is a good example to provide code portability across various missions. Flight software in aerospace field is adopting this concept to improve reusability and eventually to reduce development cost. In this paper, we propose a Lua-based virtualization environment for spacecraft flight software. Flight software for spacecraft control consists of a few tasks that are highly autonomous. Lua is chosen as the script language for programming the control tasks. Though Lua was designed with simplicity and portability, it only supports multithreading with collaborative coroutines. To support preemptive multitasking, we implement time slicing coroutines as spacecraft control processes. New coroutine scheduler is devised and time slicing functionality is added into the scheduler. Scheduler locking and message passing with external flight software are also implemented. Instead of modifying the Lua interpreter, we have exploited the debug support APIs for our implementation. For evaluation, we have implemented the flight software virtualization environment on the flight computer. Accuracy of the time slicing scheduler is also analyzed.	autonomous robot;computer multitasking;content-control software;coroutine;embedded software;embedded system;expressive power (computer science);flight computer;hardware virtualization;lock (computer science);lua;message passing;mission critical;multithreading (computer architecture);preemption (computing);scheduling (computing);scripting language;software portability;virtual machine	Sihyeong Park;Hyungshin Kim;Soo-Yeong Kang;Cheol Hea Koo;Hyunwoo Joe	2015	2015 IEEE 13th International Conference on Embedded and Ubiquitous Computing	10.1109/EUC.2015.21	embedded system;real-time computing;virtualization;computer science;software development;operating system;software construction;distributed computing	Embedded	-32.42670384751991	36.68746216316679	93559
4f5d1770794a1b051f6a8a7dfde38695afad6ca6	os6 - an experimental operating system for a small computer. part 1: general principles and structure	operating system		operating system;self-modifying code	Joseph E. Stoy;C. Strachey	1972	Comput. J.	10.1093/comjnl/15.2.117	computer science	Theory	-22.665331047263706	33.77586204377541	93827
f2a4a7de093ed41139406a7efb1b7fb2a67bc3ef	reuse/ada: a tool to promote code reuse	ada 95;design reuse;code reuse;distributed objects;cryptography;error processing;compression;distributed systems;reusable component;security	The benefits of code and design reuse are widely documented, along with methodologies to effect such reuse. Many solutions, however, require wide organizational support to be effective. We see the need for a too1 that promotes reuse by individuals or by teams, and which can be used at once, so immediate gains may be realized. Our application, ReUSE, attempts to fill this need by acting as an interface to reusable code. After attaching to reusable components through its Package Browser, ReUSE can automatically create function and procedure calls, and it helps the developer instantiate generic packages. It also provides a compiler interface, interactive error processing, centralized storage of project tiles, multiple editors, and other features to help the developer write and reuse Ada code efficiently.	ada;centralized computing;code reuse;compiler	David Battaglia;Austin Burke;John Beidler	1997		10.1145/269629.269641	real-time computing;computer science;operating system;programming language	SE	-31.674444826019407	40.34796550879524	93869
06966e05fe70803c745eed14bef0683d479611f3	a case for richer cross-layer abstractions: bridging the semantic gap with expressive memory		This paper makes a case for a new cross-layer interface, Expressive Memory (XMem), to communicate higher-level program semantics from the application to the system software and hardware architecture. XMem provides (i) a flexible and extensible abstraction, called an Atom, enabling the application to express key program semantics in terms of how the program accesses data and the attributes of the data itself, and (ii) new cross-layer interfaces to make the expressed higher-level information available to the underlying OS and architecture. By providing key information that is otherwise unavailable, XMem exposes a new, rich view of the program data to the OS and the different architectural components that optimize memory system performance (e.g., caches, memory controllers). By bridging the semantic gap between the application and the underlying memory resources, XMem provides two key benefits. First, it enables architectural/system-level techniques to leverage key program semantics that are challenging to predict or infer. Second, it improves the efficacy and portability of software optimizations by alleviating the need to tune code for specific hardware resources (e.g., cache space). While XMem is designed to enhance and enable a wide range of memory optimizations, we demonstrate the benefits of XMem using two use cases: (i) improving the performance portability of software-based cache optimization by expressing the semantics of data locality in the optimization and (ii) improving the performance of OS-based page placement in DRAM by leveraging the semantics of data structures and their access properties.	algorithm;atom;bridging (networking);cpu cache;data structure;dynamic random-access memory;locality of reference;mathematical optimization;operating system;semantics (computer science);software portability	Nandita Vijaykumar;Abhilasha Jain;Diptesh Majumdar;Kevin Hsieh;Gennady Pekhimenko;Eiman Ebrahimi;Nastaran Hajinazar;Phillip B. Gibbons;Onur Mutlu	2018	2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA)	10.1109/ISCA.2018.00027	memory management;parallel computing;semantic gap;cache;hardware architecture;computer architecture;system software;computer science;data structure;software portability;virtual memory	Arch	-24.169166294628717	39.546482168987886	94114
69875a42272f88906697096103739f87d7a729ec	a service-oriented architecture and language for abstracted distributed algorithms		This thesis describes a new programming model designed to provide an intuitive and efficient way of abstracting the partitioning of distributed input data when programming large, dynamic, distributed, parallel, computing environments. It then describes an implementation of this model as a workflow language (Martlet) and a supporting prototype middleware, as well as providing a range of case studies demonstrating the power of this model. Having introduced this model and implementing language, it concludes by describing how this can be of use in the wider scope of such dynamic environments by using just in time compilers to apply Martlet to mainstream middleware and to improve the utilisation of Condor Pools and Clusters. Inspired by the inductive constructs of Functional Programming this programming model was designed to address the issue of how to allow users to write well abstracted programs in a so far poorly explored part of a new scenario presented by Grid Computing, where the location and partitioning of data is truly dynamic, and not under the control of the user. In this environment, unlike previous computing environments, datasets and computing resources are routinely split across a number of locations and organisations, and the nature of this split can often only be determined at runtime. While many projects have been quick to embrace the idea of the Grid Computing platform, they have done so using the same basic programming models that they used in more traditional environments. As such they are restricted by assumptions made in these models that are no longer valid. These assumptions prevent programmers using the full potential of this new computing platform. The specific assumption removed through the programming model presented here is that the data is in a known and constant number of pieces when the program is constructed. This solves a common but often unrecognised problem in many eResearch projects, however, this problem must be solved before eResearch can reach its full potential. This realisation can already be seen in the growing number of workshops, conferences, and drives appearing in an attempt to describe programming models for this new computing platform.	basic programming;compiler;distributed algorithm;functional programming;grid computing;just-in-time compilation;middleware;parallel computing;programmer;programming model;prototype;run time (program lifecycle phase);service-oriented architecture;service-oriented device architecture	Daniel Goodman	2007			computer architecture;computer science;database;programming language	HPC	-24.828382129302828	40.07068528047351	94139
24d0c0d821fde7ec4e872de45bf59f02f3a9fd80	architectural aspects of a thread-safe graphical component system based on aos	lenguaje programacion;complexite;interfase usuario;interfaz grafica;system core;fijacion;verrouillage;programming language;securite;graphical interface;user interface;locking;complejidad;kernel function;nucleo sistema;composant logiciel;complexity;noyau systeme;funcion nucleo;safety;fonction noyau;software component;langage programmation;graphic user interface;interface utilisateur;seguridad;interface graphique	A message sequencer and an optimized locking mechanism for a multi-threaded graphical component system are proposed as a strat- egy to minimize locking overhead and code complexity. The strategy al- lows for fast inter-component communication via delegates in common and simple cases, while still maintaining thread-safety for more complex scenarios. The proposed strategy is applied to a novel graphical user in- terface framework on the basis of the Aos (1) kernel, developed at the ETH Zurich.	graphical user interface;thread safety	Thomas M. Frey	2003		10.1007/978-3-540-45213-3_24	embedded system;simulation;computer science;operating system;graphical user interface;programming language;algorithm	NLP	-27.46463870168678	38.52040269504365	94146
45c9f7c9a6b77b3620d4a83a665f6add55a1ca2c	magic cap, a platform for communications	electronic mail;windows magic cap object oriented runtime system software personal intelligent communicators communications macintosh;object oriented programming;intelligence community;object oriented;electronic mail computer communications software object oriented programming;runtime kernel postal services user interfaces mobile communication object oriented modeling programming profession operating systems packaging power system modeling;computer communications software;software design	The key to maximal functionality for Magic Cap is its object-oriented runtime system. All the other parts of Magic Cap are built atop this, even the operating system and device drivers. The runtime supports many of the most useful features of today’s object-oriented languages, such as multiple inheritance, first class objects, multiple object contexts, and dynamic class loading. But all of this is built into the system, rather than included as features locked within an object-oriented language (Magic Cap’s system calls are merely method calls). And since the runtime is external to the programming language, developers have the choice of using whatever language they wish, as long as it supports some form of procedure call.	device driver;first-class function;java classloader;magic cap;maximal set;multiple inheritance;operating system;programming language;runtime system;subroutine;system call	Phil Goldman	1994		10.1109/CMPCON.1994.282883	embedded system;real-time computing;computer science;computer engineering	PL	-31.56812338018793	37.314893053974934	94172
3d6085916b402bdb84a6bdd547a146486bd0bc2e	the perfectly synchronized round-based model of distributed computing	byzantine failures;distributed system;automatic;protocols;failure;fault tolerant;time complexity;performance;simulation;programmation repartie;distributed computing;synchronous;distributed programs;abstraction;automatico;complexity;calculo automatico;synchrone;synchronous system;computing;model complexity;calcul automatique;complexite temps;fracaso;sincronico;protocole;informatique theorique;distributed programming;fault tolerance;defaillance;automatique;calculo repartido;failures;rendimiento;distributed systems;complejidad tiempo;68q85;fallo;calcul reparti;computer theory;echec;synchronous system models;informatica teorica	The perfectly-synchronized round-based model provides the powerful abstraction of crash-stop failures with atomic and synchronous message delivery. This abstraction makes distributed programming very easy. We describe a technique to automatically transform protocols devised in the perfectly-synchronized round-based model into protocols for the crash, send omission, general omission or Byzantine models. Our transformation is achieved using a round shifting technique with a constant time complexity overhead. The overhead depends on the target model: crashes, send omissions, general omissions or Byzantine failures. Rather surprisingly, we show that no other automatic non-uniform transformation from a weaker model, say from the traditional crash-stop model (with no atomic message delivery), onto an even stronger model than the general-omission one, say the send-omission model, can provide a better time complexity performance in a failure-free execution.	byzantine fault tolerance;consensus (computer science);distributed computing;overhead (computing);time complexity	Carole Delporte-Gallet;Hugues Fauconnier;Rachid Guerraoui;Bastian Pochon	2007	Inf. Comput.	10.1016/j.ic.2006.11.003	fault tolerance;real-time computing;computer science;distributed computing;algorithm	DB	-21.204417480230937	43.36050510576944	94389
695f2bf14e6f8e10ba45054b8028b98cedb60554	an implementation of disk objects in the logical machine monitor	disk object;logical machine monitor	User or program mobility in distributed computing systems is becoming increasingly significant, since users may sometimes change their working locations. This paper proposes a Logical Machine (LM) system that can effectively support software environment migration and resource mapping. The LM partitions the conventional operating systems into two parts: the Logical Machine Operating System (LMOS) and the Logical Machine Monitor (LMM). They are responsible for user service and system resource management, respectively. The LMM provides a machine independent appearance, called the Logical Machine Interface (LMI), for the upper operating system layers to provide the resources they need. In our experimental system, the LMM contains some disk objects that can be bound dynamically. By varying the binds, the users get different disk characteristics. A mobile disk object with the mechanism of block migration on demand is implemented. It can be incorporated with a logical machine migration facility to achieve job migration, i.e., the user can migrate the operating system and disk blocks to the place he or she desires. The mobile disk also simplifies the mechanism of parallel processing when each server reads and processes its data portion locally. With this approach, the system resources can be mapped more flexibly, while transparency to the operating system is retained. © 1997 John Wiley u0026 Sons, Ltd.		Lian-Jou Tsai;Shang-Rong Tsai;Cheng-Liang Hou	1997	Softw., Pract. Exper.	10.1002/(SICI)1097-024X(199711)27:11%3C1335::AID-SPE135%3E3.0.CO;2-8	embedded system;real-time computing;computer science;engineering;operating system;distributed computing;logical disk;programming language;object-oriented programming	DB	-31.119717898415765	43.631931631782855	94589
49d955eaa32f7f80cae87cddc610010378dd9191	a system for computer music performance	sistema operativo;timed systems;interfase usuario;input device;human performance;art;synthese musique;music synthesis;user interface;real time;musica;sistema informatico;relacion hombre maquina;man machine relation;computer system;arte;musique;control structure;operating system;computer music;temps reel;message passing;tiempo real;systeme exploitation;interface utilisateur;systeme informatique;relation homme machine;sintesis musica;music;real time systems	A computer music performance system (CMPS) is a computer system connected to input devices (including musical keyboards or other instruments) and to graphic and audio output devices. A human performer generates input events using the input devices. The CMPS responds to these events by computing and performing sequences of output actions whose intended timing is determined algorithmically. Because of the need for accurate timing of output actions, the scheduling requirements of a CMPS differ from those of general-purpose or conventional real-time systems. This paper describes the scheduling facilities of FORMULA, a CMPS used by many musicians. In addition to providing accurate timing of output action sequences, FORMULA provides other basic functions useful in musical applications: (1) per-process virtual time systems with independent relationships to real time; (2) process grouping mechanisms and language-level control structures with time-related semantics, and (3) integrated scheduling of tasks (such as compiling and editing) whose real-time constraints are less stringent than those of output action computations.	algorithm;compiler;computation;computer;control flow;general-purpose markup language;input device;musical keyboard;output device;real-time clock;real-time computing;requirement;scheduling (computing)	David P. Anderson;Ron Kuivila	1990	ACM Trans. Comput. Syst.	10.1145/77648.77652	embedded system;message passing;real-time computing;simulation;computer science;operating system;music;distributed computing;computer music;programming language;user interface;input device	Graphics	-26.64368363002789	37.88675825385351	94800
198f5f083f9447d3c43837d3e6031d45151e03d3	an extensible scientific computing resources integration framework based on grid service	xml schema;legacy application encapsulation;memory leaks;class pool;grid service;scientific computing;turning point;integration framework;grid computing;scientific research;reflection	"""Scientific computing resources (e.g., components, dynamic linkable libraries, etc) are very valuable assets for the scientific research. However, due to historical reasons, most computing resources can't be shared by other people. The emergence of Grid computing provides a turning point to solve this problem. The legacy applications can be abstracted and encapsulated into Grid service, and they may be found and invoked on the Web using SOAP messages. The Grid service is loosely coupled with the external JAR or DLL, which builds a bridge from users to computing resources. We defined an XML schema to describe the functions and interfaces of the applications. This information can be acquired by users by invoking the """"getCapabilities"""" operation of the Grid service. We also proposed the concept of class pool to eliminate the memory leaks when invoking the external jars using reflection. The experiment shows that the class pool not only avoids the PermGen space waste and Tomcat server exception, but also significantly improves the application speed. The integration framework has been implemented successfully in a real project."""		Binge Cui;Xin Chen;Pingjian Song;Rongjie Liu	2009		10.1007/978-3-642-04265-2_32	grid file;scientific method;reflection;semantic grid;computer science;artificial intelligence;operating system;software engineering;xml schema;database;distributed computing;utility computing;programming language;world wide web;memory leak;grid computing	HPC	-33.14533405159642	43.460624370216024	95340
8ec2e49404f341392913110256714370fea95f34	porting a network cryptographic service to the rmc2000: a case study in embedded software development	important program;networked software;key development issue;proposed porting strategy;limited resource device;case study;transport-layer cryptography service;rabbit rmc2000;network cryptographic service;embedded microcontroller;software development;run-time characteristic;embedded systems;computer science;computer aided software engineering;intelligent networks;multiprogramming;cryptography;transport layer;embedded software;embedded system;microcontrollers;software engineering	This paper describes our experience porting a transport-layer cryptography service to an embedded microcontroller. We describe some key development issues and techniques involved in porting networked software to a connected, limited resource device such as the Rabbit RMC2000 we chose for this case study. We examine the effectiveness of a few proposed porting strategies by examining important program and run-time characteristics.	cryptography;embedded software;embedded system;microcontroller;software development	Stephen Jan;Paolo de Dios;Stephen A. Edwards	2003			porting;embedded system;electronic engineering;embedded software;computer science;cryptography;backporting;operating system;programming language;transport layer;computer engineering	Mobile	-32.81462423872448	39.73675853116304	95368
8331e1c9cf48d006d668fc8a976b3ab4a12daf81	modern software architecture for embedded real-time devices: high value, little overhead	portability real time low end devices embedded modularity reusability;memory size 128 kbyte arm cpu low end embedded devices portability reusability modularity maintenance quality attributes component based software architecture fasalight memory size cpu power embedded real time devices frequency 120 mhz;reusability;software architecture computer architecture real time systems embedded systems hardware embedded software;real time;portability;low end devices;computer architecture;embedded systems;software architecture;modularity;embedded;software quality embedded systems software architecture software maintenance;embedded software;hardware;real time systems	Embedded devices are often tightly constrained by CPU power and memory size. As a consequence, developers of embedded software avoid any kind of design abstractions, thinking that they imply large overhead. This results in complex designs with high coupling between the individual entities. The code of such designs is then difficult to maintain or reuse. This article presents FASAlight, a component-based software architecture for embedded devices with a focus on three main quality attributes that support maintenance and reuse: modularity, reusability, and portability. This architecture can be effectively implemented even for low-end embedded devices and only implies at worst a 14% on CPU and small overhead on memory on a device with a 120MHz ARM CPU and 128 kB of RAM.	arm architecture;algorithm;application programming interface;cpu power dissipation;central processing unit;complexity;component-based software engineering;embedded software;embedded system;entity;fasa studio;hoc (programming language);list of system quality attributes;manycore processor;multi-core processor;operating system;overhead (computing);random-access memory;real-time clock;real-time computing;real-time transcription;reference implementation;response time (technology);scheduling (computing);single-core;software architecture;software portability;software quality;source lines of code;thermal management (electronics);verification and validation	Aurelien Monot;Manuel Oriol;Camille Schneider;Michael Wahler	2016	2016 13th Working IEEE/IFIP Conference on Software Architecture (WICSA)	10.1109/WICSA.2016.11	embedded system;software architecture;reusability;computer architecture;real-time computing;embedded software;computer science;software engineering;embedded java;modularity	Embedded	-21.603198030785975	37.18281563650707	95377
16589e6568da037b6bc98f1eefda22876f4eaa9d	mechanical verification of clock synchronization algorithms	systeme temps reel;distributed system;architecture systeme;systeme reparti;synchronisation;fault tolerant system;formal verification;sistema repartido;synchronization;sistema tolerando faltas;clock synchronization;verification formelle;arquitectura sistema;systeme tolerant les pannes;real time system;sistema tiempo real;sincronizacion;system architecture;distributed architecture	Clock synchronization algorithms play a crucial role in a variety of fault-tolerant distributed architectures. Although those algorithms are similar in their basic structure , the particular designs diier considerably, for instance in the way clock adjustments are computed. This paper develops a formal generic theory of clock synchronization algorithms which extracts the commonalities of speciic algorithms and their correctness arguments; this generalizes previous work by Shankar and Miner by covering non-averaging adjustment functions, in addition to averaging algorithms. The generic theory is presented as a set of parameterized PVS theories, stating the general assumptions on parameters and demonstrating the veriication of generic clock synchronization. The generic theory is then specialized to the class of algorithms using averaging functions, yielding a theory that corresponds to those of Shankar and Miner. As examples of the veriication of concrete, published algorithms, the formal veriication of an instance of an averaging algorithms (by Welch and Lynch 1]) and of a non-averaging algorithm (by Srikant and Toueg 9]) is exhibited.	algorithm;clock synchronization;correctness (computer science);fault tolerance;theory;universal instantiation;welch's method	Detlef Schwier;Friedrich W. von Henke	1998		10.1007/BFb0055353	synchronization;real-time computing;real-time operating system;computer science;operating system;distributed computing;algorithm;systems architecture	Theory	-25.52569049367229	32.86355286783368	95410
c4fa1c6baab6590eaa7128bdc23be46308fe7d53	advanced technologies in manufacturing		The Workshop on European Scientific and Industrial Collaboration (WESIC’98), Promoting Advanced Technologies in Manufacturing was held on June 10–12, 1998 at the University of Girona, Spain. The aim of the workshop was to provide a forum where companies, universities, institutes and research centres could interchange experiences in meeting the needs of advanced technologies in manufacturing systems. The workshop was of interest to those companies and institutions interested in collaborating in scientific projects in their sector, especially in the context of the European Community research projects. The workshop, which was attended by members of important research centres all over Europe, included topics such as Advanced Technologies for Manufacturing, Robotics, Data Communications, Intelligent Systems, Quality Control, Computer Vision and Mechatronics. From this wide range of topics, a reduced number of articles have been selected for the special section contained herein. Concerning Robotics, two topics have been chosen: underwater vehicles and medical robotics. Underwater robotics are used successfully to perform scientific exploration of the ocean and are thus involved in providing solutions to a number of problems such as teleoperation, manoeuvring, sensoring, pressure control, aerodynamics, underwater manipulation, etc. The paper by J. Amat, from the Politechnical University of Catalonia (UPC), discusses a low-cost teleoperated prototype which is able to work at a depth of up to 200 m. The second paper by Alicia Casals, also from the Politechnical University of Catalonia (UPC), considers microrobotics and medical imaging used in the field of assistant robots and laparoscopic surgery. Distributed manufacturing systems are, for certain, a main topic in industrial environments. In this area, five works are presented. The first, a visual tool for developing real time control software by X.C. Pardo, from the University of A Coruña, deals with a visual programming environment applied to computers with real-time operating systems interconnected by means of industrial real time networks. In a related field T. Jost, from the University of Sttutgart, presents the use of master control systems (MCS) for the co-ordination and monitoring of the processes in flexible production systems (FPS). In fact, the paper presents a method for assessing the quality of MCS software and the simulation-based tests of this SW. The third work in this section is by J.M. Fuertes, from UPC and LEA-SICA (European Associated Lab.), deals with distributed intelligent control and presents the current status of the Fieldbus Foundation communication model. One important aspect which really matters in distributed manufacturing, is to bring operating system independent communication capabilities to devices and industrial machine-tools. In this sense, the implementation of the Manufacturing Message Specification (MMS) concepts in the CORBA environment is particularly discussed by E. Gressier, from the GRPI.IUT-University of Paris-Nord. Finally, the work on Fault Tolerant Architectures by J.J. Serrano, from the Politechnical University of Valencia, is presented. Mainly, this research team develops software and hardware tools for the design, test and validation of distributed industrial control systems, including the development of both physical and logical fault injectors, as well as the implementation of local performance monitors. In summary, it is clear that the WESIC’98 workshop was a great success in facilitating a meeting between a wide range of active researchers, which has resulted in the formulation and development of collaborative projects. The work is ongoing and will be reported at WESIC’99 which will be held in Newport UK 1–3 September 1999. (see http://mrc.newport.ac.uk).	common object request broker architecture;computer vision;control system;distributed manufacturing;experience;fieldbus;floating point systems;integrated development environment;intelligent control;master control;mechatronics;medical imaging;microbotics;prototype;real-time clock;real-time operating system;robot;sensor;simulation;underwater robotics;universal product code;visual programming language	Joan Batlle	1999	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/S0141-9331(99)00012-5	advanced manufacturing;computer-aided technologies	Robotics	-32.84750574748861	37.18166340285004	95522
15bed63e031d43498b27cc87a6be930dc24e0ce1	simple concurrency for robotics with the roboscoop framework	roboscoop usability roboscoop framework robotics application simple concurrent object oriented programming concurrent programming error scoop concurrency synchronization mechanisms roboscoop simplicity middlewares;synchronisation concurrency control control engineering computing middleware object oriented programming robots;robot kinematics concurrent computing libraries robot sensing systems synchronization middleware	Concurrency is inherent to robots, and using concurrency in robotics can greatly enhance performance of the robotics applications. So far, however, the use of concurrency in robotics has been limited and cumbersome. This paper presents Roboscoop, a new robotics framework based on Simple Concurrent Object Oriented Programming (SCOOP). SCOOP excludes data races by construction, thereby eliminating a major class of concurrent programming errors. Roboscoop utilizes SCOOP's concurrency and synchronization mechanisms for coordination in robotics applications. We demonstrate Roboscoop's simplicity by comparing Roboscoop to existing middlewares and evaluate Roboscoop's usability by employing it in education.	concurrency (computer science);concurrent computing;middleware;programmer;programming model;robot;robotics;scoop;usability	Andrey Rusakov;Jiwon Shin;Bertrand Meyer	2014	2014 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2014.6942763	real-time computing;concurrent computing;computer science;distributed computing;multiversion concurrency control;non-lock concurrency control;programming language;concurrent object-oriented programming;distributed concurrency control	Robotics	-30.54643082702364	39.89196785425901	95686
50e56e16399faa8de3e96618db3f012f5ae36d2a	modeling real-time database concurrency control protocol two-phase-locking in uppaal	phase locking;databases;protocols;concurrency control protocols database systems real time systems formal verification power system modeling computer science logic transaction databases system recovery;database management systems;real time;program verification;modeling language;automata;system recovery;model checking;synchronization;database systems;protocols concurrency control database management systems program verification;concurrency control;timed automata;timed automata real time database concurrency control protocol two phase locking real time database management systems model checking algorithms verification tool uppaal;database management system;real time systems	Real-time database management systems (RTDBMS) are recently subject of an intensive research. Model checking algorithms and verification tools are of great concern as well. In this paper we show some possibilities of using a verification tool Uppaal on some variants of pessimistic concurrency control protocols used in real-time database management systems. We present some possible models of such protocols expressed as nets of timed automata, which are a modeling language of Uppaal.	algorithm;automata theory;concurrency (computer science);concurrency control;database;lock (computer science);model checking;modeling language;real-time clock;real-time locating system;real-time transcription;timed automaton;two-phase locking;uppaal	Martin Kot	2008	2008 International Multiconference on Computer Science and Information Technology	10.1109/IMCSIT.2008.4747315	model checking;communications protocol;synchronization;real-time computing;computer science;concurrency control;database;distributed computing;automaton;multiversion concurrency control;modeling language	Logic	-26.1580266831514	34.66298432547107	95945
a3d4f654be62bc2f9db39a066b44981531724ad5	sound static deadlock analysis for c/pthreads	time 4 hour sound static deadlock analysis c pthreads real world code analysis c standard pthreads specification deadlock freedom context sensitive abstract interpretation framework thread sensitive abstract interpretation framework lightweight dependency analysis debian gnu linux distribution;concurrent computing;standards;program diagnostics c language formal specification linux;system recovery instruction sets pipelines computer bugs standards concurrent computing scalability;qa0076 computer software;system recovery;pipelines;deadlock analysis;scalability;static analysis;abstract interpretation;qa0075 electronic computers computer science;computer bugs;abstract interpretation deadlock analysis static analysis;instruction sets	We present a static deadlock analysis approach for C/pthreads. The design of our method has been guided by the requirement to analyse real-world code. Our approach is sound (i.e., misses no deadlocks) for programs that have defined behaviour according to the C standard and the pthreads specification, and is precise enough to prove deadlock-freedom for a large number of such programs. The method consists of a pipeline of several analyses that build on a new context- and thread-sensitive abstract interpretation framework. We further present a lightweight dependency analysis to identify statements relevant to deadlock analysis and thus speed up the overall analysis. In our experimental evaluation, we succeeded to prove deadlock-freedom for 292 programs from the Debian GNU/Linux distribution with in total 2.3 MLOC in 4 hours.	ansi c;abstract interpretation;deadlock;debian;dependence analysis;gnu;linux;posix threads;pipeline (computing)	Daniel Kroening;Daniel Poetzl;Peter Schrammel;Björn Wachter	2016	2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)	10.1145/2970276.2970309	parallel computing;real-time computing;scalability;software bug;concurrent computing;computer science;operating system;software engineering;instruction set;distributed computing;pipeline transport;programming language;static analysis	SE	-21.911392323985925	35.946305518867895	95955
01581b0eb81eb73b1c954b2fe9fccd2e73f4c583	clear, correct, and efficient dynamic software updates	jeffrey s foster hayden christopher michael;computer science clear correct and efficient dynamic software updates university of maryland college park michael hicks;dissertation	Dynamic software updating (DSU) allows programs to be updated as they execute, enabling important changes (e.g., security fixes) to take effect immediately without losing active program state. Most DSU systems aim to add runtime updating support transparently to programs—that is, all updating behavior is orchestrated by the DSU system, while avoiding program code modifications. This philosophy of transparency also extends to existing notions of DSU correctness, which emphasize generic correctness properties that apply to all runtime updates, such as type safety. #R##N#We claim that runtime updating support should be treated as a program feature, both for implementation and for establishing correctness. For implementing DSU, this means that the core updating behavior is made manifest in the program's code, exposing the programmer to the application-specific details they need to understand, while relying on the DSU system for everything else. We argue that this approach can provide several benefits: simplified developer reasoning about update behavior, modest effort to implement, support for arbitrary program changes, lightweight tool support, and negligible runtime overhead. For establishing correctness, treating updating support as a program feature means that developers should specify and check the specific behaviors that an updated program will exhibit as they do for other program features, rather than relying on overly general notions of correctness. We argue that developers can write DSU specifications with little work—usually by adapting single-version specifications—and check them using standard methods: testing and verification. #R##N#To support this thesis, we present three pieces of work. First, we describe an empirical study of the techniques used by existing DSU systems to determine when an update can take place. We find that automatic techniques are unable to prevent erroneous behavior and conclude that placing update points in developer-chosen main loops is most effective. Next, we present an approach to specifying and checking the correctness of program features under DSU. We propose a specification strategy that can adapt single-version specifications to describe DSU behavior and a new tool that allows reasoning about DSU specifications using standard checking tools. We have implemented our approach for C, and applied it to updates to the Redis key-value store and several synthetic programs. Finally, we present Kitsune, a new DSU system for C programs, that supports the developer in implementing runtime updating as a program feature. We have used Kitsune to update five popular, open-source, single- and multi-threaded programs, and find that few program changes are required to use Kitsune, and that it incurs essentially no performance overhead.	patch (computing)	Christopher M. Hayden	2012			computer science;data mining;database;algorithm	PL	-21.489098769843373	35.27902182879939	95995
4ab641a0a0ab3db73778a6d443e935a80fb20ec2	panda - supporting distributed programming in c++	distributed application;distributed programs;garbage collection;operating system;global address space	PANDA is a run-time package based on a very small operating system kernel which supports distributed applications written in C++. It provides powerful abstractions such as very ef ficient user -level threads, a uniform global address space, object and thread mobility, garbage collection, and persistent objects. The paper discusses the design rationales underlying the P ANDA system. The fundamental features of P ANDA are surveyed, and their implementation in the current prototype environment is outlined.	c++;design rationale;distributed computing;garbage collection (computer science);kernel (operating system);operating system;partitioned global address space;prototype;rpg maker	Holger Assenmacher;Thomas Breitbach;Peter Buhler;Volker Hübsch;Reinhard Schwarz	1993		10.1007/3-540-47910-4_19	parallel computing;real-time computing;computer science;distributed computing;garbage collection;programming language	OS	-25.42634915036792	39.398291273562975	96012
29103a322910ae67b837e5a0784bec3b017689bc	a taxonomy of distributed debuggers based on execution replay		This paper presents a taxonomy of parallel and distributed debug-gers based on execution replay. Programming of distributed and parallel systems is a complex task. Amongst the many factors contributing to this complexity, the nondeterminacy of these systems is an important one. Execution replay is a technique developed to facilitate the debugging of nondeterministic programs. Execution replay has very broad applications and not every algorithm is applicable in every situation. This taxonomy provides a precise classiication of replay debuggers using nine criteria. From this classiication, it is easier to determine a debugger's scope of application, outline its strengths and weaknesses and compare it with others. This taxonomy is illustrated and validated using a collection of existing replay debuggers.	algorithm;debugger;debugging;taxonomy (general)	Carl Dionne;Marc Feeley;Jocelyn Desbien	1996			taxonomy (biology);computer science;distributed computing	SE	-24.25925743169329	35.75688897213146	96028
252533dc96e865d4aa264d2721e941657fe44dce	fault-safe code motion for type-safe languages	object oriented language;safety properties;partial redundancy elimination;intermediate representations;scheduling;safety dependences;safe code motion;profitability;code motion;speculative code motion;memory latency;intermediate representation	Compilers for Java and other type-safe languages have historically worked to overcome overheads and constraints imposed by runtime safety checks and precise exception semantics. We instead exploit these safety properties to perform code motion optimizations that are even more aggressive than those possible in unsafe languages such as C++.  We present a novel framework for speculative motion of dangerous (potentially faulting) instructions in safe, object-oriented languages such as Java and C#. Unlike earlier work, our approach requires no hardware or operating system support. We leverage the properties already provided by a safe language to define fault safety, a more precise notion of safety that guarantees that a dangerous operation (e.g., a memory load) will not fault at a given program point.  We illustrate how typical code motion optimizations are easily adapted to exploit our safety framework. First, we modify the standard SSAPRE partial redundancy elimination (PRE) algorithm to use fault safety, rather than the traditional down safety property. Our modified algorithm better exploits profile information by inserting of dangerous instructions on new paths when it is profitable and provably safe. Second, we extend an instruction trace scheduler to use fault safety to safely schedule load instructions across branches to better tolerate memory latency and to more compactly target instruction slots.  We implemented these optimizations in StarJIT, a dynamic compiler, and show performance benefits of up to 10% on a set of standard Java benchmarks.	algorithm;benchmark (computing);c++;cas latency;compiler;dynamic compilation;instruction scheduling;itanium;java;loop-invariant code motion;operating system;partial redundancy elimination;scheduling (computing);speculative execution;type safety	Brian R. Murphy;Vijay Menon;Florian T. Schneider;Tatiana Shpeisman;Ali-Reza Adl-Tabatabai	2008		10.1145/1356058.1356078	parallel computing;real-time computing;cas latency;computer science;theoretical computer science;operating system;programming language;intermediate language;object-oriented programming;scheduling;profitability index;partial redundancy elimination	PL	-20.547773999693206	34.56201951776123	96143
dc10301f7560982e6d62ee6f3b72d1bbdd00a459	a promising approach for debugging remote promises	remote promises;debuggers;remote debugging	Promises are synchronization constructs that hide the complexity of process synchronisation from the developer by providing a placeholder for the result of a potentially incomplete computation performed in a concurrent process.  Promises evaluated by remote processes pose challenges for debugging when the remote computation raises an exception. Current debuggers are either unaware that there is a problem in the remote computation or give developers access only to the context of the remote process. This does not allow developers to interact at the same time with the process that launched the promise and the remote process that executed the promise's computation.  To improve debugging of remote promises, in this paper we propose a debugger interface that presents a unified view of both the original and the remote process, by merging the call chains of the two processes at the point where the promise was created. We exemplify our approach, discuss challenges for making it practical, and illustrate through an initial prototype that it can improve debugging of exceptions in remote promises.	computation;debugger;debugging;exception handling;exemplification;parallel computing;prototype	Max Leske;Andrei Chis;Oscar Nierstrasz	2016		10.1145/2991041.2991059	real-time computing;computer science;theoretical computer science;distributed computing;remote procedure call	PL	-27.084940669148672	36.00330407777733	96222
b34ff6dca24e4c766b07204ca1c74547eb9e1745	oasis: an architecture for simplified data management and disconnected operation	control autoajustable;evaluation performance;selftuning control;disconnected operation;reseau pair;informatique mobile;performance evaluation;peer to peer network;asymmetry;availability;disponibilidad;reconfigurable architectures;pervasive computing;evaluacion prestacion;data management;interface programme application;sistema n niveles;asymetrie;informatica difusa;consistency model;igual a igual p2p;informatique diffuse;systeme n niveaux;application program interfaces;multilevel system;replique;asimetria;oasis;systeme gestion base donnee;mobile computing;peer to peer;sistema gestion base datos;database management system;disponibilite;data management system;architecture reconfigurable;replica;commande autoajustable	Oasis is an asymmetric peer-to-peer data management system tailored to the requirements of pervasive computing. Drawing upon applications from the literature, we motivate three high-level requirements: availability, manageability and programmability. Oasis addresses these requirements by employing a peer-to-peer network of weighted replicas and performing background self-tuning. In this paper we describe our architecture and an initial implementation. Our performance evaluation and implementation of three applications suggest that Oasis offers good availability and performance while providing a simple API and a familiar consistency model.		Anthony LaMarca;Maya Rodrig	2004		10.1007/978-3-540-24714-2_9	embedded system;availability;real-time computing;simulation;data management;computer science;consistency model;operating system;database;mobile computing;asymmetry;oasis soa reference model	DB	-28.37286477933241	43.153813633099034	96384
4fd482ff0baa7d1aaede65caf675f65951de392f	the control of traffic signals with an electronic computer - a new application of real-time data processing	real time data		real-time data	L. Casciato	1962			real-time data;real-time computing;computer science	Graphics	-30.357671502099375	38.815598142247445	96407
6fcabdc01b2328c94597819de659a6e73e84271a	concurrent programming made easy	declarative specification concurrent systems constraint based methodology concurrent applications concurrent programming temporal constraint logic program system concurrency;concurrent computing;concurrency control parallel programming;application software;high performance computing;concurrent computing writing safety logic distributed computing high performance computing computational efficiency application software programming profession scattering;concurrent programming;logic;distributed computing;parallel programming;scattering;system concurrency;constraint based methodology;concurrent systems;programming profession;safety;concurrency control;writing;concurrent programs;temporal constraint logic program;logic programs;computational efficiency;concurrent applications;declarative specification;point of interest	The task of programming concurrent systems is substantially more difficult than the task of programming sequential systems with respect to both correctness and efficiency. In this paper we describe a constraint-based methodology for writing concurrent applications. A system is modeled as: (a) a set of processes containing a sequence of “markers” denoting the processes points of interest; and (b) a constraint store. Process synchronization is specified by incrementally adding constraints on the markers’ execution order into the constraint store. The constraint store contains a declarative specification based on a temporal constraint logic program. The store, thus, acts as a coordination entity which on the one hand encapsulates the system synchronization requirements, and on the other hand, provides a declarative specification of the system concurrency issues. This provide great advantages in writing concurrent programs and manipulating them while preserving correctness.	concurrency (computer science);concurrent computing;constraint logic programming;correctness (computer science);emoticon;point of interest;requirement;synchronization (computer science)	Rafael Antonio Márquez Ramírez;Andrew E. Santosa;Roland H. C. Yap	2000		10.1109/ICECCS.2000.873939	constraint logic programming;concurrent constraint logic programming;constraint programming;application software;real-time computing;point of interest;concurrent computing;constraint satisfaction;computer science;concurrency control;distributed computing;scattering;programming language;writing;logic;concurrent object-oriented programming	SE	-25.79821499209595	33.5611600178934	96526
b3e0e7d7e62a3110b742bac53841f548e025ee7b	a distributed algorithm for mutual exclusion in an arbitrary network	mutual exclusion;distributed algorithm	A distributed algorithm for mutual exclusion is presented. No particular assumptions on the network topology are required, except connectivity; the communication graph may be arbitrary. The processes communicate by using messages only and there is no global controller. Furthermore, no process needs to know or learn the global network topology. In that sense, the algorithm is more general than the mutual exclusion algorithms which make use of an a priori knowledge of the network topology (for example either ring or complete network). A proof of the correctness of the algorithm is provided. The algorithm's complexity is examined by evaluating the number of messages required for the mutual exclusion protocol.	acm transactions on database systems;central processing unit;computer networks (journal);computer programming;concurrency (computer science);concurrency control;correctness (computer science);deadlock;distributed algorithm;distributed computing;distributed control system;fail-stop;fault tolerance;fault-tolerant computer system;global network;international federation for information processing;lamport timestamps;mutual exclusion;network topology;springer (tank);the computer journal	Jean-Michel Hélary;Noël Plouzeau;Michel Raynal	1988	Comput. J.	10.1093/comjnl/31.4.289	ricart–agrawala algorithm;maekawa's algorithm;mutual exclusion;computer science;distributed computing;suzuki-kasami algorithm;programming language	Theory	-23.599878680974797	44.514767330743446	96564
54cc83d81993994dcd90f2edc06c3c57336eb166	a scalable approach to multi-agent resource acquisition and control	control reification;multiagent system;resource control;hierarchical control;expressive power;efficient implementation;cyberorgs;on the fly;actors;coordination	Scalable coordination is a key challenge in deployment of multiagent systems. Resource usage is one part of agent behavior which naturally lends itself to abstraction. CyberOrgs is a model for hierarchical coordination of resource usage by multi-agent applications in a network of peer-owned resources. Programming constructs based on the CyberOrgs model allow resource trade and reification of control while maintaining a separation between functional and resource concerns of applications. A prototype implementation of CyberOrgs is described and expressive power of the programming constructs is illustrated with examples.Hierarchical control presents challenges in scalability. However, CyberOrgs make some types of resource coordination more amenable to efficient implementation. Hierarchical scheduling for processor time, for instance, can be implemented scalably by efficiently converting the hierarchical schedule into a flat schedule on the fly. This mechanism can be generalized to achieve scalable coordination of some other resource types. Experimental results are presented which demonstrate scalability of this approach.	agent-based model;multi-agent system;on the fly;prototype;reification (knowledge representation);scalability;scheduling (computing);software deployment	Nadeem Jamali;Xinghui Zhao	2005		10.1145/1082473.1082605	real-time computing;simulation;computer science;distributed computing;expressive power	AI	-30.979464438058752	45.555139616253605	96614
b83944cb333de867c9e634b3ebbeb5045c09bc6f	implementing ada 9x features using posix threads: design issues	process definition;application program interface;software process modeling;operating system;process representation	The draft standard POSIX Threads Extension provides an application program interface to operating system services supporting the creation and execution of multiple threads of control within a single process. Where Ada is implemented over an operating system that supports POSIX-like thread services, there are good reasons to implement the Ada tasks as POSIX threads. This paper explores some of the design issues involved in implementing Ada 9X tasking constructs on a system supporting POSIX threads.	ada;application programming interface;daemon (computing);operating system;posix threads;thread (computing)	E. W. Giering;Frank Mueller;Theodore P. Baker	1993		10.1145/170657.170736	computer architecture;real-time computing;computer science;programming language	OS	-25.76497291258162	36.79440253039639	96658
553d29737ef78d0c6eca25be3eadfbdca4a65446	the cyclic executive model and ada	programming language;real time;embedded computing	Periodic processes are major parts of many real-time embedded computer applications. The programming language Ada permits programming simple periodic processes, but it has some serious limitations; producing Ada programs with real-time performance comparable to those produced to date using traditional cyclic executives requires resorting to techniques that are specific to one machine or compiler. We present and evaluate the cyclic executive model for controlling periodic processes. The features and limitations of Ada for programming cyclic executive software are discussed and demonstrated, and some practical techniques for circumventing Ada limitations are described.	ada;compiler;computer;concurrent computing;cyclic executive;embedded system;high- and low-level;machine-dependent software;programming language;programming paradigm;real-time clock;real-time locating system;real-time transcription	Theodore P. Baker;Alan C. Shaw	1988	Real-Time Systems	10.1007/BF02341919	first-generation programming language;computer architecture;real-time computing;programming domain;computer science;programming language	Embedded	-23.81510299321162	34.508069154231194	96796
faf8a02f4f18f07241f306481c488a21dce4540c	compact deterministic self-stabilizing leader election on a ring: the exponential advantage of being talkative		This paper focuses on compact deterministic self-stabilizing solutions for the leader election problem. When the solution is required to be silent (i.e., when the state of each process remains fixed from some point in time during any execution), there exists a lower bound of $$\varOmega (\log n)$$ Ω ( log n ) bits of memory per participating node , where n denotes the number of nodes in the system. This lower bound holds even in rings. We present a new deterministic (non-silent) self-stabilizing protocol for n-node rings that uses only $$O(\log \log n)$$ O ( log log n ) memory bits per node, and stabilizes in $$O(n\log ^2 n)$$ O ( n log 2 n ) rounds. Our protocol has several attractive features that make it suitable for practical purposes. First, it assumes an execution model that is used by existing compilers for real networks. Second, the size of the ring (or any upper bound on this size) does not need to be known by any node. Third, the node identifiers can be of various sizes. Finally, no synchrony assumption, besides weak fairness, is assumed. Our result shows that, perhaps surprisingly, silence can be traded for an exponential decrease in memory space without significantly increasing stabilization time or introducing restrictive assumptions.	compiler;dspace;fairness measure;identifier;leader election;self-stabilization;time complexity	Lélia Blin;Sébastien Tixeuil	2017	Distributed Computing	10.1007/s00446-017-0294-2	embedded system;real-time computing;operating system;distributed computing;algorithm	Theory	-21.63175639715144	44.808221352650136	96827
cf519ee34a92be9095ea164ea855ad547919042d	phantom: an interpreted language for distributed programming	distributed application;object oriented language;distributed programs	The emerging trend in writing distributed applications is to use an object-based RPC system with a statically compiled, object-oriented language. While such a programming environment is adequate for many tasks, object-based RPC systems and statically compiled languages also have certain intrinsic limitations. These limitations become significant when writing applications which are both distributed and interactive (e.g. network information browsers, distributed conferencing systems and collaborative work tools). This paper discusses these limitations, and presents the design of Phantom, a new intepreted language for distributed programming. Phantom provides many features found in object-based RPC systems and statically compiled languages, including automatic marshalling, transparent remote procedure call, secure authentication and concurrency support. In addition to these traditional features, Phantom's interpreted nature permits the use of certain programming techniques, such as true object migration, remote evaluation, and dynamic extensibility, which are of increasing importance for distributed programming, but which are not available in statically compiled languages and RPC systems. The integration of these features in a single, coherent programming language makes whole new classes of distributed, interactive applications possible.	distributed computing;interpreted language;phantom reference	Antony Courtney	1995			dce/rpc;real-time computing;computer science;theoretical computer science;compiled language;distributed object;fifth-generation programming language;programming language	PL	-30.641930984917423	39.439462699747324	96870
d8e8cd28d5e1b33b791426ae587ae9e4ad21590e	a generic architecture for sensor data integration with the grid	modelizacion;data integrity;aplicacion medical;integration information;serveur informatique;distributed computing;cache memory;antememoria;grid;modelisation;captador medida;antememoire;information integration;measurement sensor;capteur mesure;design and implementation;rejilla;integracion informacion;grille;calculo repartido;servidor informatico;medical application;recherche scientifique;modeling;scientific research;calcul reparti;investigacion cientifica;application medicale;computer server	This paper describes the design and implementation of a model of how to integrate sensors and devices into a GRID infrastructure. We describe its proxy-based approach, the port-type requirements and the set of tools implemented to facilitate configuration of experimental scenarios. Two real world devices, a wearable medical jacket and an Antarctic lake probe, deployed out in the field using this architecture are described, along with their relevance in scientific research.	relevance;requirement;sensor;wearable computer	Jan Humble;Chris Greenhalgh;Alastair Hampshire;Henk L. Muller;Stefan Rennick Egglestone	2004		10.1007/11423287_9	embedded system;simulation;scientific method;systems modeling;cpu cache;telecommunications;computer science;information integration;data integrity;database;grid;server	Robotics	-28.43631719889016	43.43982397240516	96916
3e7e042c0b4435f09e9e80233ac550e94c69f427	a correction and some comments on the article “polynomially complex synthesis of distributed supervisors for large-scale amss using petri nets”	petri net structural analysis resource allocation systems deadlock avoidance;resource management system recovery petri nets analytical models dynamic scheduling indexes	The main purpose of this correspondence is to point out the fallacy of Theorem 1 in the paper that is mentioned in the title, a result that attempts to provide a structural characterization for the liveness of the Petri net class considered in the manuscript. The closing part of the correspondence also takes this opportunity to make some further remarks on the results that are claimed in the paper.		Spyros A. Reveliotis	2019	IEEE Transactions on Control Systems Technology	10.1109/TCST.2017.2675840	resource management;petri net;dynamic priority scheduling;stochastic petri net;fallacy;process architecture;liveness;distributed computing;computer science	Robotics	-26.504630783896577	34.71667121495275	96934
0eef024514fb8db067a6a26995c9e21d53a76452	a dynamic approach for characterizing collusion in desktop grids	collusion;electronic mail;costs redundancy computer science cities and towns uncertainty voting internet viruses medical robustness fault diagnosis;desktop grids;group behavior;on line algorithms;accuracy;redundancy;estimation;heuristic algorithms;threat model;sabotage desktop grid collusion modeling;sabotage;task execution;dynamic approach;collusion detection;modeling;grid computing;on line algorithm;program processors;security of data;collusion detection dynamic approach desktop grids task execution threat model on line algorithms;desktop grid;security of data grid computing	By exploiting idle time on volunteer machines, desktop grids provide a way to execute large sets of tasks with negligible maintenance and low cost. Although desktop grids are attractive for cost-conscious projects, relying on external resources may compromise the correctness of application execution due to the well-known unreliability of nodes. In this paper, we consider the most challenging threat model: organized groups of cheaters that may collude to produce incorrect results. We propose two on-line algorithms for detecting collusion and characterizing the participant behaviors. Using several real-life traces, we show that our approach is accurate and efficient in identifying collusion and in estimating group behavior.	correctness (computer science);desktop computer;directed graph;docking@home;job stream;online algorithm;online and offline;real life;scheduling (computing);sensor;server (computing);stationary process;threat model;tracing (software);vii;whole earth 'lectronic link	Louis-Claude Canon;Emmanuel Jeannot;Jon B. Weissman	2010	2010 IEEE International Symposium on Parallel & Distributed Processing (IPDPS)	10.1109/IPDPS.2010.5470422	estimation;parallel computing;simulation;systems modeling;computer science;operating system;distributed computing;accuracy and precision;redundancy;threat model;computer security;group dynamics;grid computing;statistics;computer network	Arch	-24.049634910163697	45.30581560443355	96940
1111239eecbe8663b85228fa2f21736071df16c9	a leader election protocol for eventually synchronous shared memory systems	synchronous shared memory systems;leader ineluctable;paxos protocol leader election protocol synchronous shared memory systems message passing systems;tolerance aux fautes;protocols;consensus;paxos protocol;shared memory;leader election protocol;efficiency;message passing system;shared memory systems message passing protocols;storage area network systemes asynchrones;communication model;eventual synchrony;asynchronous system;shared memory systems;message passing systems;fault tolerance;message passing;leader election;commodity disk;paxos;crash de processus;nominations and elections protocols read write memory safety conferences collaborative software process design buildings embedded software collaborative work;shared memory system;memoire partagee;leader service	While protocols that elect an eventual common leader in asynchonous message-passing systems have been proposed, to our knowledge, no such protocol has been proposed for the shared memory communication model. This paper presents a leader election protocol suited to the shared memory model. In addition to its design simplicity, the proposed protocol has two noteworthy properties, namely, it does not use timers, and is optimal with respect to the number of processes that have to write forever the shared memory: a single process has to do it (namely, the leader that is eventually elected). Among the many possible uses of such a leader protocol, one is Lamport's Paxos protocol. Paxos is an asynchronous consensus algorithm that relies on an underlying eventual leader abstraction. As recently, several versions of Paxos have been designed for asynchronous shared memory systems (the shared memory being an abstraction of a physically shared memory or a set of commodity disks that can be read and written by the processes), the proposed leader protocol makes Paxos effective in these systems	chandra–toueg consensus algorithm;consensus (computer science);leader election;message passing;paxos (computer science);shared memory;timer	Rachid Guerraoui;Michel Raynal	2006	The Fourth IEEE Workshop on Software Technologies for Future Embedded and Ubiquitous Systems, and the Second International Workshop on Collaborative Computing, Integration, and Assurance (SEUS-WCCIA'06)	10.1109/SEUS-WCCIA.2006.6	distributed shared memory;paxos;parallel computing;real-time computing;computer science;leader election;distributed computing	Embedded	-22.488002761457253	43.843306459529344	97040
4e008a482ba46999246fe4b538a2062705fda773	parallel software development in the disc programming environment	parallel calculus;developpement logiciel;distributed system;systeme reparti;langage c;programming environment;disc;concurrent program;ingenieria logiciel;software engineering;medio ambiente programacion;c language;calculo paralelo;sistema repartido;desarrollo logicial;software development;programa competidor;genie logiciel;calcul parallele;environnement programmation;lenguaje c;programme concurrent	This paper describes the architecture of DISC, a system for parallel software development. The system is designed for programming computer systems having several autonomous units, not memory-sharing, and linked by means of a communication network.#R##N##R##N#The system consists of three parts. The concurrent programming language DISC (DIStributed C), which is an extension of the C language based on the concurrent mechanisms envisaged by the CSP computational model. The programming environment, designed to promote software engineering techniques in the development of distributed-programs. The language run-time support, which provides for the distributed execution of programs.	integrated development environment;software development	Giulio Iannello;Antonino Mazzeo;Carlo Savy;Giorgio Ventre	1990	Future Generation Comp. Syst.	10.1016/0167-739X(90)90036-D	fourth-generation programming language;simulation;n-version programming;programming domain;reactive programming;computer science;programming language implementation;software framework;component-based software engineering;software development;extensible programming;computer programming;programming paradigm;procedural programming;programming language;system programming;disc;high-level programming language;algorithm;concurrent object-oriented programming;software system;parallel programming model	Arch	-24.919186484954352	35.420729982932464	97127
6d36e2d20dc0068ea97329a3c8d32fa432aaac46	simple and efficient transactions for a distributed object store	low level transaction;distributed system;electrical capacitance tomography;main memory access;information systems;parallel main memory object store;persistence;database management systems;very large scale integration;cad;simulation;object database;object oriented systems distributed object store transaction processing information systems persistence database management systems cad vlsi design simulation low level transaction parallel main memory object store ppost main memory access parallel systems distributed systems object databases;vlsi design;law;ppost;memory access;object oriented systems;legal factors;distributed objects;postal services;transaction databases;parallel systems;object databases;distributed object store;electrical capacitance tomography world wide web very large scale integration postal services electronic switching systems read only memory transaction databases proposals law legal factors;distributed databases;electronic switching systems;world wide web;object oriented databases;information system;distributed systems;transaction processing;proposals;database management system;file organisation distributed databases object oriented databases transaction processing;read only memory;file organisation	Even the more or less “canonical”, lower-level architecture of information systems needs to be revisited from time to time. Notions like persistence and transactions belong traditionally to the area of database management systems. There are, however, many applications, such as CAD, VLSI design or simulation, which need persistence and could take advantage of transactions, but require especially fast implementations not provided by DBMS. In this paper we are describing a low-level transaction concept used to implement our parallel main memory object store (PPOST), to provide main memory access times combined with the safety and convenience of transactions.	algorithm;computer data storage;computer-aided design;database;distributed object;enterprise architecture;high- and low-level;information system;parallel computing;persistence (computer science);simulation;very-large-scale integration	László Böszörményi;Carsten Weich	1998		10.1109/DEXA.1998.707480	database transaction;computer science;theoretical computer science;database;distributed computing;online transaction processing;distributed object;very-large-scale integration;compensating transaction;distributed database;information system	DB	-26.27919354112663	45.529597286803764	97148
2b095a92096b12236b387dfceaa944fee36c6604	building flexible multilevel transactions in a distributed persistent environment		As attempts [AB85] are made to integrate general purpose programming languages with the long term facilities of data definition and storage provided by database systems, the old problems of managing concurrent access and update become even more difficult. This paper will discuss these problems in the context of an integrated persistent environment and develop a flexible programming model to deal with them.		G. Lawrence Krablin	1985			programming paradigm;data definition language;concurrency control;distributed computing;computer science	HPC	-27.336443362586213	45.85908098464988	97219
3118df0fe59dd54b68bce2c56a88f437d7c27a5f	a fault-tolerant secure corba store using fragmentation-redundancy-scattering	fault tolerant	This paper presents the design of a secure and fault-tolerant CORBA datastore based on the Fragmentation-Redundancy-Scattering (FRS) technique. This technique consists in fragmenting the con dential data and scattering the resulting fragments across several archives. The FRS-Datastore service interacts with the other CORBA services, in particular with the Persistence, Security and Trading services. One of our goals is to gain a better understanding how the FRS technique can be applied to an open environment prone to crashes and network partitions and using exclusively standard invocations.	archive;common object request broker architecture;crash (computing);data store;fault tolerance;fragmentation (computing);ip fragmentation;naruto shippuden: clash of ninja revolution 3;persistence (computer science)	Cristina Silva;Luís E. T. Rodrigues	1998		10.1007/3-540-49255-0_68	fault tolerance;computer science	Security	-31.97854736115799	45.532849573998604	97235
ea45c6c0e9c36d0dea81a82b98ed32cfa279533f	conversion from data-driven to synchronous execution in loop programs	computers;interprocess communication;flow;language translation;communication and radio systems;loops;processing equipment;computer programs;computer programming;arrays;programmers;algorithms;synchronous machine;data reduction;finite element analysis;data flow;parallel programs;parallel languages;parallel processing;conversion	Conversion algorithms are presented that would enable programmers to write programs in a high-level, data flow language and then run those programs on a synchronous machine. A model of interprocess communication systems is developed in which both data-driven and synchronous execution modes are represented. Balancing equations are used to characterize a subclass of parallel programs, called loop programs, for which conversions are possible. We show that all loop programs having the finite buffer property can be converted into synchronous mode. Finally two algorithms for the conversion of loop programs are presented and discussed.	acm transactions on programming languages and systems;algorithm;compiler;computation;dataflow;handshaking;high- and low-level;input/output;integrated development environment;inter-process communication;mathematical optimization;parallel computing;pascal;programmer	Janice E. Cuny;Lawrence Snyder	1987	ACM Trans. Program. Lang. Syst.	10.1145/29873.31334	parallel processing;data reduction;real-time computing;flow;computer science;computer programming;distributed computing;programming language;inner loop	PL	-24.738133311677736	33.97289786477093	97390
510e071390c7fbd166bee9359e79d8a68a273f66	asynchronous byzantine agreement protocols	byzantine agreement	A consensus protocol enables a system of n asynchronous processes, some of them faulty, to reach agreement. Both the processes and the message system are capable of cooperating to prevent the correct processes from reaching decision. A protocol is t-resilient if in the presence of up to t faulty processes it reaches agreement with probability 1. Byzantine processes are faulty processes that can deviate arbitrarily from the protocol; Fail-Stop processes can just stop participating in it. In a recent paper, f-resilient randomized consensus protocols were presented for t < n/S. We improve this to f <n/3, thus matching the known lower bound on the number of correct processes necessary for consensus. The protocol uses a general technique in which the behavior of the Byzantine processes is restricted by the use of a broadcast protocol that filters some of the messages. The apparent behavior of the Byzantine processes, filtered by the broadcast protocol, is similar to that of Fail-Stop processes. Plugging the broadcast protocol as a communicating primitive into an agreement protocol for Fail-Stop processes gives the result. This technique, of using broadcast protocols to reduce the power of the faulty processes and then using them as communication primitives in algorithms designed for weaker failure models, was used succesfully in other contexts. ‘!:I 1987	broadcast domain;byzantine fault tolerance;communications protocol;fail-stop;randomized algorithm	Gabriel Bracha	1987	Inf. Comput.	10.1016/0890-5401(87)90054-X	universal composability;computer science;quantum byzantine agreement;theoretical computer science;distributed computing;algorithm	Theory	-22.317566882081735	44.50775068206889	97509
6fadf0213b4684ee6b9d4b80ae5f75addec242ed	the weakest failure detector for solving wait-free, eventually bounded-fair dining philosophers	eventually bounded fair dining philosophers texas a m university scott m pike song;dining philosophers the eventually perfect failure detector wait freedom bounded fairness;thesis;yantao;computer science the weakest failure detector for solving wait free;book	The Weakest Failure Detector for Solving Wait-Free, Eventually Bounded-Fair Dining Philosophers. (December 2008) Yantao Song, B.S., Beijing Institute of Technology; M.S., Chinese Academy of Sciences Chair of Advisory Committee: Dr. Scott M. Pike This dissertation explores the necessary and sufficient conditions to solve a variant of the dining philosophers problem. This dining variant is defined by three properties: wait-freedom, eventual weak exclusion, and eventual bounded fairness. Waitfreedom guarantees that every correct hungry process eventually enters its critical section, regardless of process crashes. Eventual weak exclusion guarantees that every execution has an infinite suffix during which no two live neighbors execute overlapping critical sections. Eventual bounded fairness guarantees that there exists a fairness bound k such that every execution has an infinite suffix during which no correct hungry process is overtaken more than k times by any neighbor. This dining variant (WF-EBF dining for short) is important for synchronization tasks where eventual safety (i.e., eventual weak exclusion) is sufficient for correctness (e.g., duty-cycle scheduling, self-stabilizing daemons, and contention managers). Unfortunately, it is known that wait-free dining is unsolvable in asynchronous message-passing systems subject to crash faults. To circumvent this impossibility result, it is necessary to assume the existence of bounds on timing properties, such as relative process speeds and message delivery time. As such, it is of interest to characterize the necessary and sufficient timing assumptions to solve WF-EBF dining. We focus on implicit timing assumptions, which can be encapsulated by failure	2010 flash crash;academy;asynchronous system;black box;correctness (computer science);crash (computing);critical section;cycle (graph theory);daemon (computing);deterministic algorithm;dining philosophers problem;distributed computing;duty cycle;failure detector;fairness measure;fault detection and isolation;fork (software development);gossip protocol;graph coloring;liu hui's π algorithm;message passing;mutual exclusion;network switch;non-blocking algorithm;perpetual beta;pike;refinement (computing);requirement;router (computing);scheduling (computing);self-stabilization;sensor;subroutine;variable (computer science);vii	Yantao Song	2010			computer science;artificial intelligence;operations research;algorithm	Embedded	-22.111374261197422	43.84858324904454	97583
bc7e4b68d0601778a8b23bce40c34ac98972533f	stateful distributed interposition	server consolidation;distributed system;sistema operativo;component services;architecture systeme;systeme reparti;computacion informatica;context information;reseau ordinateur;serveur informatique;distributed computing;grupo de excelencia;contextual information;service operation;computer network;support system;sistema repartido;multitiered services;operating system;ciencias basicas y experimentales;interaction pattern;red informatica;calculo repartido;servidor informatico;arquitectura sistema;systeme exploitation;distributed context;system architecture;communication channels;calcul reparti;operating systems;computer server	Interposition-based system enhancements for multitiered servers are difficult to build because important system context is typically lost at application and machine boundaries. For example, resource quotas and user identities do not propagate easily between cooperating services that execute on different hosts or that communicate with each other via intermediary services. Application-transparent system enhancement is difficult to achieve when such context information is obscured by complex service interaction patterns. We propose a basic mechanism for sharing contextual information across the tiers of multitier computations to support system enhancement for multitier servers and applications.This article introduces generic, cluster-wide context as a new, configurable abstraction for the OS. System administrator- or application-specified context tracking rules determine how context is associated with system processes, sockets, messages, how it is relayed along the interapplication communication channels, and how it is to be interpreted by system interpositions, thus realizing Stateful Distributed Interposition.	computation;inter-process communication;multitier architecture;operating system;state (computer science);stateful firewall;system administrator	John Reumann;Kang G. Shin	2004	ACM Trans. Comput. Syst.	10.1145/966785.966786	embedded system;real-time computing;computer science;operating system;distributed computing;server;systems architecture;channel	OS	-26.25631277056521	45.89267698467994	97698
525779e57f28961b3b925dd4b7a58342aabc253a	building mediators from components	computer languages;sanctuary data mediation run time system mediators distributed database environment sanctuary project internal components corba facility common object interconnection language coil fine grained specification;formal specification;distributed database;programming language;distributed database environment;power system interconnection;object oriented languages distributed databases distributed object management configuration management formal specification specification languages;distributed databases lan interconnection power system interconnection computer languages mediation;sanctuary project;common object interconnection language;coil;lan interconnection;run time system;corba facility;sanctuary data mediation run time system;mediation;specification languages;internal components;distributed object management;distributed databases;fine grained specification;mediators;configuration management;object oriented languages	Mediators as an integral part of a distributed database environment are not a new idea. However, mediators are often looked at from the outside. The goal of the Sanctuary project is to provide an environment that allows one to con gure the internal components of a mediator in a quick and modular fashion that allows the power and breadth of a CORBA facility. The Common Object Interconnection Language (COIL) is a programming language in development by the Database Research Group at the University of Colorado that allows ne grained speci cation of components within a mediator. COIL is the language that is used to specify mediators within the Sanctuary data mediation run-time system.	apl;baseline (configuration management);common object request broker architecture;distributed database;floor and ceiling functions;interconnection;matchware mediator;naruto shippuden: clash of ninja revolution 3;programmer;programming language;runtime system	John Todd;Christian Och;Roger King;Richard Osborne;William J. McIver;Nathan Getrich;Brian Temple	1999		10.1109/DOA.1999.794061	real-time computing;computer science;database;distributed computing	DB	-33.609413966628054	42.531115367242215	97708
5894beb2582de08faf9de96dda93a3d9c1ce892d	internet access to heterogeneous home area network devices with an osgi-based residential gateway	distributed system;remote access;controle acces;residential gateways;remote control;internet access;systeme reparti;acceso remoto;interoperabilite;interoperabilidad;musica;acces a distance;securite informatique;home area network;residential gateway;langage java;telecommande;indexing terms;remote operation;intergiciel publication souscription;computer security;home network;musique;home area networks;sistema repartido;internet;senal video;signal video;intergicial editor suscriptor;design and implementation;teleaccion;seguridad informatica;video signal;lenguaje java;information gateway;open service gateway initiative;access control;control remoto;osgi;interoperability;pasarela informacion;passerelle d information;security;jini;music;publish subscribe middleware;teleoperation;java language;java;upnp	Home area networks are proliferating rapidly in many residential homes. These networks are being designed to enable remote access and control to services and contents such as music, video, and data. It remains a significant challenge to design a home network that exploits different protocol architectures and standards while allowing interoperability among them. We describe the design and implementation of an architecture (known as a residential gateway) that: • enables full interoperability among different technologies by exploiting the Open Service Gateway Initiative (OSGi) technology • provides secure internet access to heterogeneous devices connected to a home area network.	ansari x prize;chao (sonic);entity–relationship model;han unification;itil;internet access;interoperability;osgi;palo;performance evaluation;residential gateway;seamless3d;universal plug and play;user (computing);video;jini	Sherali Zeadally;Priya Kubher	2008	IJAHUC	10.1504/IJAHUC.2008.016194	embedded system;interoperability;teleoperation;internet access;computer science;information security;access control;operating system;music;residential gateway;java;world wide web;computer security;h.248;computer network;remote control	Networks	-29.85315893434592	43.6503456371819	97815
94301a46dc41b0c5dc2d1ca3b3ca1390495c18b2	java model checking	multi threading;computer languages;java data structures laboratories yarn explosions computer science system recovery computer languages writing internet;yarn;multithreaded java programs;assertion failure;thread call stacks;sal language;object oriented programming;program verification;concurrency control java object oriented programming multi threading program verification;system recovery;internet;data structures;java model checking;optimizations;concurrency control;program description;state explosion problem;state explosion problem java model checking multithreaded java programs sal language symbolic analysis laboratory language object instantiations thread call stacks program description deadlocks assertion failure optimizations;writing;explosions;symbolic analysis laboratory language;object instantiations;computer science;deadlocks;java	This paper presents initial results in model checking multi-threaded Java programs. Java programs are translated into the SAL (Symbolic Analysis Laboratory) intermediate language, which supports dynamic constructs such as object instantiations and thread call stacks. The SAL model checker then exhaustively checks the program description for deadlocks and assertion failures. Basic model checking optimizations that help curb the state explosion problem have been implemented. To deal with large Java programs in practice, however, supplementary program analysis tools must work in conjunction with the model checker to make verification manageable. The SAL language framework provides a good starting point to interface new and existing analysis methods with the model checker.	assertion (software development);critical systems thinking;data compaction;data structure;deadlock;dynamic data;dynamization;intermediate representation;java;model checking;partial order reduction;program analysis;state space;static program analysis;thread (computing)	David Y. W. Park;Ulrich Stern;Jens Ulrik Skakkebæk;David L. Dill	2000		10.1109/ASE.2000.873671	model checking;parallel computing;real-time computing;the internet;assertion;multithreading;jsr 94;java concurrency;data structure;computer science;deadlock;java modeling language;concurrency control;strictfp;real time java;programming language;object-oriented programming;java;writing;generics in java;scala;java annotation	SE	-23.340280917074594	32.79828885044025	98086
9ea463b7009e9d9322e1660e0006b11f7e4703c0	failure detection in large-scale internet services by principal subspace mapping	software;distributed system;detectors;metodo correlacion;systeme reparti;analisis estadistico;failure;red www;detection panne;componente logicial;availability;web and internet services;autonomous system;disponibilidad;correlation method;failure detection;reseau web;vector space;service web;composant logiciel;langage java;statistical method;principal canonical correlation analysis;probabilistic approach;web service;correlation methods;indexing terms;j2ee;sistema autonomo;analyse canonique;large scale internet service;failure analysis;novel detection approach;large scale;sistema repartido;fracaso;internet;statistical analysis;monitoring;java 2 platform enterprise edition;canonical correlation analysis;enfoque probabilista;approche probabiliste;principal component analysis;internet services failure detection subspace mapping correlation analysis autonomic computing;analyse statistique;systeme autonome;analyse correlation;software component;statistical analysis correlation methods failure analysis fault diagnosis internet java;reparation;internet services;world wide web;analisis canonico;lenguaje java;cca based detector;espace vectoriel;correlation;enterprise edition based web application;java 2 enterprise edition;large scale systems web and internet services detectors performance analysis application software statistical analysis hardware condition monitoring data mining availability;reparacion;deteccion falla;failure detection enterprise edition based web application java 2 platform enterprise edition cca based detector principal canonical correlation analysis novel detection approach principal subspace mapping large scale internet service;correlation canonique;disponibilite;espacio vectorial;canonical analysis;autonomic computing;correlacion canonica;subspace mapping;analisis correlacion;principal subspace mapping;methode correlation;servicio web;repair;fault diagnosis;data models;java language;canonical correlation;java;echec;correlation analysis	Fast and accurate failure detection is becoming essential in managing large-scale Internet services. This paper proposes a novel detection approach based on the subspace mapping between the system inputs and internal measurements. By exploring these contextual dependencies, our detector can initiate repair actions accurately, increasing the availability of the system. Although a classical statistical method, the canonical correlation analysis (CCA), is presented in the paper to achieve subspace mapping, we also propose a more advanced technique, the principal canonical correlation analysis (PCCA), to improve the performance of the CCA-based detector. PCCA extracts a principal subspace from internal measurements that is not only highly correlated with the inputs but also a significant representative of the original measurements. Experimental results on a Java 2 platform, enterprise edition (J2EE)- based Web application demonstrate that such property of PCCA is especially beneficial to failure detection tasks.	distributed computing;internet;java platform, enterprise edition;web application;web service	Haifeng Chen;Guofei Jiang;Kenji Yoshihira	2007	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2007.190633	canonical correlation;computer science;data mining;database;world wide web;statistics;autonomic computing	DB	-26.966964806953317	42.85561606081801	98700
c405f388bf8ed3e8099cfbeb003a646553c02936	operating system support for portable filesystem extensions	operating system		operating system	Neil Webber	1993			embedded system;operating system;standard operating environment;embedded operating system;computer science	OS	-31.055775885754596	42.00119784309191	98827
6b5eeb5a017de5758e9773b52b0292cfc987ce3d	object race detection	dynamic programming;variabilidad;programacion dinamica;compilateur;java programming;proceso ligero;generation code;estudio comparativo;generacion codigo;code generation;aplicacion espacial;information access;specification programme;object oriented programming;compiler;analisis programa;program optimization;etude comparative;processus leger;data races;comparative study;programmation dynamique;acces information;on the fly;acceso informacion;optimisation programme;program analysis;thread;analyse programme;variability;programmation orientee objet;variabilite;program specification;static program analysis;application spatiale;especificacion programa;compilador;space application;race detection;optimizacion programa	"""We present an on-the-fly mechanism that detects access conflicts in executions of multi-threaded Java programs. Access conflicts are a conservative approximation of data races. The checker tracks access information at the level of objects (object races) rather than at the level of individual variables. This viewpoint allows the checker to exploit specific properties of object-oriented programs for optimization by restricting dynamic checks to those objects that are identified by escape analysis as potentially shared. The checker has been implemented in collaboration with an """"ahead-of-time""""Java compiler. The combination fo static program analysis (escape-analysis) and inline instrumentation during code generation allows us to reduce the runtime overhead of detecting access conflicts. This overhead amounts to about 16-129% in time and less than 25% in space for typical benchmark applications and compares favorably to previously published on-the-fly mechanism that incurred an overhead of about a factor of 2-80 in time and up to a factor of 2 in space."""	approximation;benchmark (computing);code generation (compiler);escape analysis;java compiler;mathematical optimization;overhead (computing);sensor;static program analysis;thread (computing)	Christoph von Praun;Thomas R. Gross	2001		10.1145/504282.504288	program analysis;thread;compiler;real-time computing;simulation;computer science;dynamic programming;comparative research;program optimization;programming language;object-oriented programming;algorithm;code generation;static program analysis	PL	-19.57851681123757	35.81057568008594	98871
8e2009de9bcd2c92d97371708556c088aa8e3eac	estimating the soft error vulnerability of register files via interprocedural data flow analysis	reliability;interprocedural analysis;estimation method;program reliability;software reliability data flow analysis error handling;rvf factor soft error vulnerability estimation register file interprocedural data flow analysis power consumption computing dependability program reliability static estimating method register vulnerability context sensitivity target register;static estimating method;registers reliability equations context mathematical model accuracy runtime;runtime;computing dependability;soft error vulnerability estimation;accuracy;rvf factor;registers;target register;liveness analysis;error handling;mathematical model;data flow analysis;register file;power consumption;register vulnerability;software reliability;liveness analysis soft error register file program reliability interprocedural analysis;soft error;context;context sensitivity;interprocedural data flow analysis	Subsequently to the wall of performance and power consumption, the dependability of computing, caused by soft errors, has become a growing design concern. Since Register Files (RFs) are accessed very frequently and cannot be well protected, soft errors occurred in them is one of the top reasons for affecting the reliability of programs. To access the soft errors vulnerability of RFs, this paper presents a static estimating method via interprocedural data flow analysis. Adopting a previous method, the vulnerability of a register is firstly decomposed into intrinsic and conditional basic block vulnerabilities. Under the prerequisite of context sensitivity, we focus on the computation the post conditions of basic blocks, which can be viewed as the living probability of the target register in the future usage. Finally, the program reliability can be calculated quantitatively under the occurrence of soft errors in RFs. Experimental results from the MiBench benchmarks indicate that our method is more accurate, and compatible with the AVF methods. We also reveal that the reliability of a program has a connection with its structure, such as the RVF factors, which suggests adopting the application specified protected mechanisms for tolerating soft errors occurred in RFs.	basic block;computation;data-flow analysis;dataflow architecture;dependability;dynamic logic (digital electronics);embedded system;experiment;method (computer programming);register file;soft error;static program analysis;structured programming	Jianjun Xu;QingPing Tan;Wanwei Liu	2010	2010 4th IEEE International Symposium on Theoretical Aspects of Software Engineering	10.1109/TASE.2010.20	exception handling;parallel computing;real-time computing;soft error;computer science;data-flow analysis;mathematical model;reliability;database;accuracy and precision;processor register;programming language;register file;software quality	Arch	-22.05205663126482	39.061838971893046	99154
9b3144dfac06864da0c94dab06e724fcbdd92d00	analysis of self-stabilizing clock synchronization by means of stochastic petri nets	tolerancia falta;modelizacion;distributed system;statistical self diagnosis;metodo estadistico;systeme reparti;fault tolerant;red petri;spn software package;stochastic petri net;sistema informatico;distributed processing;statistical test;statistical method;computer system;clocks synchronization stochastic processes petri nets stochastic systems fault tolerant systems fault tolerance algorithm design and analysis control systems software packages;self stabilising clock synchronisation;synchronisation;modelisation;synchronisation distributed processing fault tolerant computing markov processes petri nets;fault tolerant system;fault tolerant computing;markov model;sistema repartido;spn software package self stabilising clock synchronisation fault tolerant clock synchronisation stochastic petri nets statistical self diagnosis self stability markov model;stochastic petri nets;methode statistique;synchronization;indexation;fault tolerance;software package;sistema tolerando faltas;clock synchronization;self stability;systeme tolerant les pannes;systeme informatique;sincronizacion;markov processes;stochastic model;petri nets;petri net;modeling;modelo estocastico;modele stochastique;tolerance faute;reseau petri;fault tolerant clock synchronisation	A model for analyzing a FCS (fault-tolerant clock synchronization) system of the type supported by a statistical self-diagnosis is described. Once a self-diagnosis scheme is integrated into an FCS design, the problem of controlling and measuring the system's self-stability arises. A stochastic Petri net (SPN) model is constructed to derive the self-stability measures of such FCS systems. An example is given to demonstrate the entire modeling and analyzing procedure. The mapping from SPN model to Markov model shown in an example can be automated by using an SPN software package. The results show that the SPN model is an excellent tool for obtaining self-stability measures and that several important system features, such as synchronization and parallelism, can be modeled using the SPN method in a much clearer manner than they can be modeled using other available tools. >	clock synchronization;stochastic petri net	Meiliu Lu;Du Zhang;Tadao Murata	1990	IEEE Trans. Computers	10.1109/12.53573	embedded system;fault tolerance;real-time computing;computer science;distributed computing	Embedded	-22.01450476139745	41.55271506887996	99227
ae8d7b6433c162f8dc0c1a3d70f5e2942ea349ee	on designing direct dependency: based fast recovery algorithms for distributed systems	tolerancia falta;distributed system;recouvrement arriere;systeme reparti;central scheme;checkpointing;communication induced checkpoint;sistema repartido;fault tolerance;rollback recovery;coherence;point reprise;maximum consistent state;coherencia;consistency;tolerance faute	In this paper, we have proposed two recovery algorithms for distributed systems. Both algorithms follow a revolving centralized scheme. The direct dependency tracking of an integer representing the number of messages sent by each process has been shown to be sufficient to determine the maximum consistent state. The main feature of the recovery algorithms is that they are executed simultaneously by all the participating processes while determining the maximum consistent state. It thus ensures fast execution. The time overheads of the recovery algorithms are reduced further because both algorithms avoid some unnecessary comparisons while determining a consistent global checkpoint. The second algorithm has been shown to be faster than the first one, because it avoids, in general, much larger number of unnecessary comparisons compared to the first one; however the trade off is the increased amount of control information to be stored at each checkpoint in the second algorithm.	algorithm;application checkpointing;centralized computing;computation;distributed computing;induced subgraph;overhead (computing);scsi initiator and target;synchronization (computer science);transaction processing system	Bhaskar Gupta;Zilong Liu;Zhi-jie Liang	2004	Operating Systems Review	10.1145/974104.974110	fault tolerance;real-time computing;coherence;computer science;theoretical computer science;operating system;distributed computing;consistency;computer security	DB	-22.40999128065003	45.80775456062773	99411
14f551e165e600804a296f05b790e9df55d67952	maintaining consistency and bounding capacity of software code caches	cache storage;dynamorio runtime code manipulation system software code caches dynamic optimizers consistency maintainance;multi threading;cache consistency;computer architecture program compilers cache storage program interpreters multi threading;production system;program interpreters;dynamic compilation;cache memory;scaling up;computer architecture;software maintenance application software software tools optimizing compilers runtime dynamic compiler emulation production systems hardware yarn;program compilers;dynamic loading;dynamic optimization;dynamic behavior	Software code caches are becoming ubiquitous, in dynamic optimizers, runtime tool platforms, dynamic translators, fast simulators and emulators, and dynamic compilers. Caching frequently executed fragments of code provides significant performance boosts, reducing the overhead of translation and emulation and meeting or exceeding native performance in dynamic optimizers. One disadvantage of caching, memory expansion, can sometimes be ignoredwhen executing a single application. However, as optimizers and translators are applied more and more in production systems, the memory expansion from running multiple applications simultaneously becomes problematic. A second drawback to caching is the addedrequirement of maintaining consistency between the code cache and the original code. On architectures like IA-32 that do not require explicit application actions when modifying code, detecting code changes is challenging. Again, consistency can be ignored for certain sets of applications, but as caching systems scale up to executing large, modern, complex programs, consistency becomes critical. This paper presents efficient schemes for keeping a software code cache consistent and for dynamically bounding code cache size to match the current working set of the application. These schemes are evaluated in the DynamoRIO runtime code manipulation system, and operate on stock hardware in the presence of multiple threads and dynamic behavior, including dynamically-loaded, generated, and even modified code.	cpu cache;cache (computing);compiler;computer program;dynamorio;emulator;ia-32;overhead (computing);sensor;working set	Derek Bruening;Saman P. Amarasinghe	2005	International Symposium on Code Generation and Optimization	10.1109/CGO.2005.19	dead code;computer architecture;code bloat;parallel computing;real-time computing;dynamic compilation;multithreading;cpu cache;computer science;operating system;dead code elimination;redundant code;production system;programming language;code generation;unreachable code	Arch	-19.201522515291842	37.79536735948274	99514
58683a098aee33ed6755d1fc4b950127ddee969d	protothreads: simplifying event-driven programming of memory-constrained embedded systems	state machine;datorsystem;computer systems;sensor network;embedded system;wireless sensor network;embedded systems;lines of code;threads;wireless sensor networks	Event-driven programming is a popular model for writing programs for tiny embedded systems and sensor network nodes. While event-driven programming can keep the memory overhead down, it enforces a state machine programming style which makes many programs difficult to write, maintain, and debug. We present a novel programming abstraction called protothreads that makes it possible to write event-driven programs in a thread-like style, with a memory overhead of only two bytes per protothread. We show that protothreads significantly reduce the complexity of a number of widely used programs previously written with event-driven state machines. For the examined programs the majority of the state machines could be entirely removed. In the other cases the number of states and transitions was drastically decreased. With protothreads the number of lines of code was reduced by one third. The execution time overhead of protothreads is on the order of a few processor cycles.	byte;embedded system;event-driven programming;overhead (computing);programming style;run time (program lifecycle phase);source lines of code	Adam Dunkels;Oliver Schmidt;Thiemo Voigt;Muneeb Ali	2006		10.1145/1182807.1182811	embedded system;real-time computing;wireless sensor network;computer science;distributed computing;finite-state machine	Arch	-21.89603149304526	36.35472578631078	99522
43aa875f2e898d05dc75d7b82fb9886c44d87200	a necessary condition for byzantine $k$-set agreement	atomic read write register;message passing system;k set agreement;byzantine process;algorithms	This short paper presents a necessary condition for Byzanti nek-set agreement in (synchronous or asynchronous) message-passing systems and asynchronou s shared memory systems where the processes communicate through atomic single-writer multi -reader registers. It gives a proof, which is particularly simple, that k-set agreement cannot be solved t-resiliently in ann-process system whenn ≤ 2t + t k . This bound is tight for the case k = 1 (Byzantine consensus) in synchronous message-passing systems.	byzantine fault tolerance;message passing;process architecture;shared memory	Zohir Bouzid;Damien Imbs;Michel Raynal	2016	Inf. Process. Lett.	10.1016/j.ipl.2016.06.009	computer science;quantum byzantine agreement;theoretical computer science;distributed computing;algorithm	Theory	-22.343046764706028	44.05277807733834	99545
921e30018c727b806364a3fd7acd0a5f859556f9	space-efficient on-the-fly race detection using loop splitting	serializable loop.;space efficiency;on-the-fly race detection;two-pass loop splitting;inter-thread coordination;parallel program	  Detecting races is important for debugging shared-memory parallel programs, because the races result in unintended nondeterministic  execution of the programs. Previous on-the-fly techniques to detect races in parallel programs with general inter-thread coordination  shows serious space overhead which is dependant on the maximum parallelism of the program. This paper proposes a two-pass  algorithm which splits a parallel loop with just one event variable into a series of two serializable loops, preserving the semantics of the original program. The first serializable  loop contains all the original dynamic blocks which are executed before the first wait operation in every thread. And, the  next serializable loop contains all the original dynamic blocks which are executed after the first wait operation in every  thread.    		Yong-Cheol Kim;Sang-Soo Jun;Yong-Kee Jun	2011		10.1007/978-3-642-20998-7_21	on the fly;serialization;human–computer interaction;parallel computing;debugging;nondeterministic algorithm;computer science;semantics;loop splitting;thread (computing)	Arch	-20.731730911932555	34.334564629910076	99671
1c59c7bf8b9ede675238ba420ee159f0fa0a3dd2	on the power of shared object types to implement one-resilient consensus	shared objects;distributed algorithms;consensus;fault tolerant;fault tolerance;shared memory system;distributed algorithm	 Abstract. In this paper we study the ability of shared object types to implement Consensus in asynchronous shared-memory systems where at most one process may crash. More specifically, we consider the following question: Let $n\ge3$ and $\mathcal{S}$ be a set of object types that can be used to solve one-resilient Consensus among n processes. Can $\mathcal{S}$ always be used to solve one-resilient Consensus among n - 1 processes? We prove that for n = 3 the answer is negative, even if $\mathcal{S}$ consists only ofdeterministic types. (This strengthens an earlier result by the first author proving the same fact for nondeterministic types.) We also prove that, in contrast, for $n>3$ the answer to the above question is affirmative.	algorithm;computer simulation;consensus (computer science);decision problem;library (computing);nondeterministic finite automaton;object type (object-oriented programming);shared memory;thermal-assisted switching;universal quantification	Wai-Kau Lo;Vassos Hadzilacos	2000	Distributed Computing	10.1007/PL00008920	distributed algorithm;fault tolerance;real-time computing;computer science;theoretical computer science;uniform consensus;distributed computing	Logic	-22.643581637901253	43.99134828643861	99842
5a77b64b170657bec9cc1b4d7b9f7a36a0b705db	poster: likwid: lightweight performance tools	affinity;shared memory;tool;profiling;performance;performance tool;hardware performance counters;performance bounds	Exploiting the performance of today's microprocessors requires intimate knowledge of the microarchitecture as well as an awareness of the ever-growing complexity in thread and cache topology. LIKWID is a set of command line utilities that addresses four key problems: Probing the thread and cache topology of a shared-memory node, enforcing thread-core affinity on a program, measuring performance counter metrics, and microbenchmarking for reliable upper performance bounds. Moreover, it includes an mpirun wrapper allowing for portable thread-core affinity in MPI and hybrid MPI/threaded applications. LIKWID stands out because it is easy to install and use and works with any Linux 2.6 kernel. LIKWID has low overhead and is designed to be easily extended by the user.  Our poster briefly introduces all LIKWID tools. The different usage modes of likwid-perfctr are demonstrated on several examples: Detection of NUMA problems, use of the likwid marker API and noninvasive measurements with the so called stehoscope and timeline mode. A ccNUMA bandwidth map for a four socket AMD Magny Cours node shows one possible application of likwid-bench.	application programming interface;command-line interface;linux;message passing interface;microarchitecture;microprocessor;non-uniform memory access;overhead (computing);processor affinity;shared memory;timeline;weak measurement	Jan Treibig;Georg Hager;Gerhard Wellein;Michael Meier	2011		10.1145/2148600.2148616	shared memory;parallel computing;real-time computing;performance;computer science;operating system;distributed computing;profiling;programming language;computer network	Arch	-24.735290368069798	38.76512313366781	100016
cb379cbd65228dea3996ff0eacc23db5f91d4f6d	asynchrony and real-time in distributed systems	distributed system;real time;distributed computing;process calculus	In this paper we attempt to reveal the most essential properties of distributed computations. We classify distributed computation into four forms according to asynchrony and real-time properties. We try to develop formalisms for the four categories based on a process calculus. The formalisms allow us to describe and analyze both globally and locally temporal properties as well as behavioral properties of distributed objects and interactions among them. We also outline a programming language for asynchronous real-time computing. We here discuss issues remaining to be solved and show some prospects.	apl;apple ii system clocks;asynchronous i/o;asynchrony (computer programming);computation;distributed computing;distributed object;essence;interaction;open road tolling;process calculus;programming language;real-time clock;real-time computing;real-time transcription	Mario Tokoro;Ichiro Satoh	1992		10.1007/BFb0018660	distributed algorithm;real-time computing;failure semantics;theoretical computer science;distributed computing;distributed design patterns;distributed concurrency control	PL	-29.354623101756502	33.356899947567065	100198
a7c4ceb276d41c837d3cbcba83f925766d147445	result checking in global computing systems	network security;global computing;grid;internet computing;sequential test;program checking;grid computing	Global Computing is a particular modality of Grid Computing targeting massive parallelism, Internet computing and cycle-stealing. This new computing infrastructure has been shown to be exposed to a new type of attacks, where authentication is not relevant, network security techniques are not sufficient, and result-checking algorithms may be unavailable. The behavior of a Global Computing System, which is likely to be bimodal, nevertheless offers an opportunity for a probabilistic verification process that is efficient in the most frequent cases, and degrades gracefully as the problem becomes more difficult. For the two cases of a system based on anonymous volunteers, and a better controlled system, we propose probabilistic tests which self-adapt to the behavior of the computing entities.	algorithm;authentication;computation;cycle stealing;entity;fault tolerance;grid computing;modality (human–computer interaction);monte carlo method;network security;parallel computing;property testing	Cécile Germain;Nathalie Playez	2003		10.1145/782814.782846	parallel computing;cloud computing;computer science;theoretical computer science;network security;operating system;end-user computing;distributed computing;soft computing;utility computing;grid;computer security;grid computing;autonomic computing	HPC	-24.4888861493623	45.42166835731198	100266
73330e7b53f0c30a61232570bacf052614e4bbf8	building flexible and extensible web applications with lua		"""The World Wide Web is in constant renovation, with new technologies emerging every day. Most of these technologies are still incipient, and there are few de facto standards for this \new Web"""". There is a need for tools that can run with current standard support, but which are exible and extensible enough to be eventually ported to new APIs and to incorporate new technologies. On the other hand, many Web developers cannot keep pace with the fast track of Web technologies. Therefore, it is important for new tools to be simple enough to be mastered quickly by the average programmer. This paper presents CGILua, a Web development tool that matches these requirements. The paper also discusses why this tool is being adopted in many commercial and academic projects, focusing on issues such as exibility, extensibility, simplicity, and portability."""	extensibility;lua;programmer;requirement;software portability;web application;web developer;web development tools;world wide web	Anna Hester;Renato Borges;Roberto Ierusalimschy	1998	J. UCS	10.3217/jucs-004-09-0748	web application;database;extensibility;computer science	Web+IR	-33.07854416504705	41.97087782601458	100326
46a704195b8f0da3b9382f23d30fbd22ca6439b5	effects of soft error to system reliability	computers;software reliability model;software;system reliability;software reliability fault tolerant computing;computer model;measurement system;soft error factor;measurement uncertainty;software reliability model soft errors fault tolerance system reliability;fault tolerant system;fault tolerant computing;computational modeling;software reliability computer system reliability soft error factor hardware components reliability;hardware components reliability;fault tolerance;probability theory;soft errors;software reliability;soft error;computer system reliability;hardware software software reliability computers computational modeling measurement uncertainty;hardware	Soft errors on hardware could affect the reliability of computer system. To estimate system reliability, it is important to know the effects of soft errors to system reliability. This paper explores the effects of soft errors to computer system reliability. We propose a new approach to measure system reliability for soft error factor. In our approach, hardware components reliability is concerned first. Then, system reliability which shows the ability to perform required function is concerned. We equal system reliability to software reliability based on the mechanism that soft errors affect system reliability. We build a software reliability model under soft errors condition. In our software model, we analyze the state of software combining with the state of hardware. For program errors which are resulted from soft errors, we give an analysis of error mask. These real errors which could lead to software failure are distinguished. Finally, our experiments illustrate our analyses and validate our approach.	computer;experiment;noise margin;soft error;software bug;software quality;software reliability testing;transistor	Lei Xiong;QingPing Tan;Jianjun Xu	2011	2011 IEEE Workshops of International Conference on Advanced Information Networking and Applications	10.1109/WAINA.2011.108	computer simulation;reliability engineering;embedded system;fault tolerance;real-time computing;computer science;software reliability testing;statistics	SE	-22.727067081842648	41.16893450744725	100419
46b9d88a665a94f7bd0fd88d4d99ca71891ad182	devirtualizable virtual machines enabling general, single-node, online maintenance	virtual machine;tiempo parada;high availability;maintenance en ligne;red www;software maintenance;availability;disponibilidad;planned downtime;software management;reseau web;temps arret;machine virtuelle;software engineering;maintenance logiciel;internet;virtual machines;genie logiciel;gestion logicial;world wide web;stopping time;fiabilite logiciel;fiabilidad logicial;online maintenance;maquina virtual;software reliability;disponibilite;ingenieria informatica;gestion logiciel	Maintenance is the dominant source of downtime at high availability sites. Unfortunately, the dominant mechanism for reducing this downtime, cluster rolling upgrade, has two shortcomings that have prevented its broad acceptance. First, cluster-style maintenance over many nodes is typically performed a few nodes at a time, mak-ing maintenance slow and often impractical. Second, cluster-style maintenance does not work on single-node systems, despite the fact that their unavailability during maintenance can be painful for organizations. In this paper, we propose a novel technique for online maintenance that uses virtual machines to provide maintenance on single nodes, allowing parallel maintenance over multiple nodes, and online maintenance for standalone servers. We present the Microvisor, our prototype virtual machine system that is custom tailored to the needs of online maintenance. Unlike general purpose virtual machine environments that induce continual 10-20% over-head, the Microvisor virtualizes the hardware only during periods of active maintenance, letting the guest OS run at full speed most of the time. Unlike past attempts at virtual machine optimization, we do not compromise OS transparency. We instead give up generality and tailor our virtual machine system to the minimum needs of online maintenance, eschewing features, such as I/O and memory virtualization, that it does not strictly require. The result is a very thin virtual machine system that induces only 5.6% CPU overhead when virtualizing the hardware, and zero CPU overhead when devirtualized. Using the Microvisor, we demonstrate an online OS upgrade on a live, single-node web server, reducing downtime from one hour to less than one minute.	central processing unit;downtime;high availability;input/output;mathematical optimization;memory virtualization;online os;operating system;overhead (computing);prototype;server (computing);unavailability;virtual machine;web server	David E. Lowell;Yasushi Saito;Eileen J. Samberg	2004		10.1145/1024393.1024419	embedded system;parallel computing;real-time computing;computer science;virtual machine;operating system	OS	-26.907568822211633	42.92997203570464	101056
5c7077833785c35b9e68080b60245b2e090d3a1c	a new approach to the design of distributed operating systems		"""Application Model Computational Reality Mapping implementation must be tailorable. For example, a reference which crosses a machine boundary may use a name server but when its target is on the local machine, it should be possible to use a simple pointer. A Framework for Mapping π π defines a uniform object model for both application and system software. Its architecture is based on three main notions: Resources elements of the computational reality. Events the causalities of computation. Interfaces structured presentation of resources and events. π specifies how these three ideas are combined into a flexible object-based framework. The elements of the computational reality, such as the computational, storage and communication resources, are encapsulated into resource objects. Similarly, abstract resources like locks and messages are also presented as resource objects. A programmer can use these objects in various ways. They can be used as is, or several can be combined or additional services can be defined. Events are typed entities which encapsulate important state changes in the system. They have three aspects: generation, notification and handling. Each object clearly specifies the events that it might generate and the events that it can handle. Notification mechanism allows decoupling of event generation and event handling. Applications see resource objects and events through interfaces. The interfaces contain the type specification for the services provided by the object and also for the events generated by the object. These three components are glued together by the πenvironment. The environment provides services traditionally found in operating systems, language tools and run-time support systems. It is not a rigid structure and applications can alter it by incorporating value-added services. The generalized object model gives the environment flexibility in the resolution of activation targets. Reification of otherwise implicit features supports metacomputation which allows modifications to the environment. Finally, version set interfaces streamline the management of changes caused by metacomputation. The changes are propagated by metaobjects to their acquaintances, thereby providing a lazy propagation mechanism suitable for distributed systems. The flexible features can be illustrated with a sequence of distributed shared data abstractions. At the basic level, the distributed shared data appears to a programmer like a normal region of memory. Any support for distribution, such as replication and coherency control, is invisible. Similarly, any associated metadata, such as type information for translation between architectures, would be hidden. The abstraction is refined if the metadata is reified and made available for modification. A further refinement is to make the application aware that the data is virtually shared through coherent replicas. Finally, the coherency manager itself could be reified to allow the programmer to change the coherency policy to improve performance. Goals The long term goal of the π project is to develop a framework within which operating systems can be assembled using basic components and their refinements. It focuses on change as the most important aspect and handles it through metacomputation and interfaces. π: A New Approach to the Design of Distributed Operating Systems Dinesh C. Kulkarni, Arindam Banerji and David L. Cohn Distributed Computing Research Laboratory Computer Science & Engineering University of Notre Dame Notre Dame, IN 46556 USA Contact: dlc@cse.nd.edu Abstract Operating systems need to be flexible to meet diverse application needs and to exploit continuously evolving hardware technology. They must present an application-oriented view for ease of use and handle resources effectively for efficiency. Applications can be modeled as dynamic directed graphs that the system software maps onto resources. Events, which generalize method invocations, interrupts and exceptions, contribute to the dynamic nature of the graph. A new operating system architecture, called π is proposed to achieve a flexible mapping. Using the architecture, operating system components can be tailored for specific applications and various hardware platforms. The π architecture specifies consistent service interfaces while metacomputing allows changes to service set implementations and the service set itself.Operating systems need to be flexible to meet diverse application needs and to exploit continuously evolving hardware technology. They must present an application-oriented view for ease of use and handle resources effectively for efficiency. Applications can be modeled as dynamic directed graphs that the system software maps onto resources. Events, which generalize method invocations, interrupts and exceptions, contribute to the dynamic nature of the graph. A new operating system architecture, called π is proposed to achieve a flexible mapping. Using the architecture, operating system components can be tailored for specific applications and various hardware platforms. The π architecture specifies consistent service interfaces while metacomputing allows changes to service set implementations and the service set itself. 1. A VISION OF THE FUTURE OF COMPUTING As the number of computing systems continues to explode, the number of computing architectures does not. The number of computers now is an order of magnitude than a decade ago, but there are probably fewer architectures. Therefore, successful architectures, both for hardware and software, must be flexible enough to span a broad range of uses. The same processor that is the heart of a super computer may also run a toaster. Hardware designers have long recognized the need to specify an architecture and then build a family of realizations. System software developers are just beginning to grapple with the same challenge. 1.1 Flexibility in Operating Systems The implications of flexibility in hardware design are clear: it must be possible to do the """"same thing"""" across a broad cost spectrum. Flexibility was at the heart of IBM’s System/360 and many other systems. The implications of flexibility for operating systems is more complex. There is no one-dimensional measure, such as manufacturing cost, that defines a spectrum. Instead, operating systems must cope with a variety of application requirements and hardware configurations. The ability of an operating system architecture to optimize in these situations is a measure of its flexibility. Different classes of applications have different needs. No single set of primitives will satisfy them all and no single implementation will be best in all cases. For example, when data is shared between remote elements of an application, one of several coherency control mechanisms could be used. The best choice depends on how the application uses the data. However, an application may use the same data differently at different times and hence want to dynamically alter coherency control. A flexible operating system architecture must accommodate a wide range of hardware structures. Classically, this means various processor speeds, differing memory and disk sizes and sundry peripheral devices. Today it would also include multiprocessor systems, diverse network topologies and a new types of input/output media. In the future, as radiobased networking becomes common, these changes will be dynamic, requiring the operating system to adapt as elements of the system move into and out of range. 1.2 Constraints and Conditions A major goal of all system software is to relieve the programmer from the burden of solving non-application domain problems. The sequence of tools from programming languages through run-time support to operating systems must make it easy for the programmer to express what is to be done and then to do it. For simplicity, this discussion will combine run-time support, which is normally associated with a particular language, with operating systems, which are more generic. There is no clear distinction between them and a good operating system architecture should be able to offer whatever run-time tools a language needs. Indeed, one measure of an operating system’s flexibility is whether it can provide those tools. A flexible operating system should scale. That is, the same software architecture should be effective in embedded processors and in large main-frames. This does not mean that one"""	adobe streamline;application domain;central processing unit;coherence (physics);computation;computer science;control system;coupling (computer programming);directed graph;distributed computing;distributed operating system;embedded system;entity;event (computing);event generator;exception handling;exploit (computer security);grapple;ibm system/360;input/output;interface (java);interrupt;lazy evaluation;lock (computer science);map;metacomputing;multiprocessing;network topology;object-based language;peripheral;pointer (computer programming);programmer;programming language;refinement (computing);reification (computer science);requirement;run time (program lifecycle phase);server (computing);software architecture;software developer;software propagation;supercomputer;systems architecture;usability	Dinesh C. Kulkarni;Arindam Banerji;David L. Cohn	1993	OOPS Messenger	10.1145/157710.157736		OS	-32.76378207005435	42.8161985511355	101322
f482b165950bbdc72debbd1fbce16aa19a4642ec	a distributed real-time image processing system	front end;image processing;personal computer;real time;internet use;research and development;image processing and analysis;design and implementation;ip networks;real time image processing;high performance	This paper presents the design and implementation of a distributed, real-time image processing system. In this system, an IBM-PC personal computer is used as the front end to a remote host computer via the Internet. Using standard TCP/IP networking protocols, the software can be configured to accommodate high performance remote devices such as transputer networks, sun SPARC servers and super-computers. The access to the powerful remote computer enables the system to complete complex image processing tasks in real-time. During processing, the image is transferred to the remote machine for processing and then transferred back to the PC for display. The system can serve as a prototype for a full-feature image processing and analysis package, as well as a programming platform for the research and development of new image processing algorithms.	image processing;real-time transcription	D. M. Wu;Ling Guan	1995	Real-Time Imaging	10.1006/rtim.1995.1044	embedded system;computer vision;real-time computing;analog image processing;computer hardware;image processing;computer science;front and back ends;digital image processing;human visual system model	Embedded	-31.760027202650814	39.626421582134974	101545
8f911dd3fd0c965f663cf68002a4f7004574e72c	the future of program analysis	program analysis	Current challenges to the compile time analysis research community include unifying the nomen clature in program analysis embedding analyses in practical software tools in uencing program ming language design to allow analysis and adapting analyses to the blend of architectures languages and operating systems common in modern software These challenges must be met to ensure that compile time analyses will continue to be of practical bene t	compile time;compiler;operating system;program analysis	Barbara G. Ryder	1996	ACM Comput. Surv.	10.1145/242224.242450	program analysis;computer science;programming language	PL	-24.1163129081778	37.69502159841801	101561
7cb3bf8772c84fafa31b4fda190a5fe42ae5b812	implementation and performance evaluation of an intelligent fuzzy-based testbed for wsans: a case study for object tracking			performance evaluation;testbed	Donald Elmazi;Makoto Ikeda;Leonard Barolli	2018	IJCNDS	10.1504/IJCNDS.2018.10013893	fuzzy logic;distributed computing;computer science;video tracking;testbed	Robotics	-30.527674796494903	38.255432648728195	101796
3f4fe56d0bee1049b97a0335198401be21c99c03	noise injection techniques to expose subtle and unintended message races	debugging;non determinism;mpi	Debugging intermittently occurring bugs within MPI applications is challenging, and message races, a condition in which two or more sends race to match with a receive, are one of the common root causes. Many debugging tools have been proposed to help programmers resolve them, but their runtime interference perturbs the timing such that subtle races often cannot be reproduced with debugging tools. We present novel noise injection techniques to expose message races even under a tool's control. We first formalize this race problem in the context of non-deterministic parallel applications and use this analysis to determine an effective noise-injection strategy to uncover them. We codified these techniques in NINJA (Noise INJection Agent) that exposes these races without modification to the application. Our evaluations on synthetic cases as well as a real-world bug in Hypre-2.10.1 show that NINJA significantly helps expose races.	debugging;dhrystone;interference (communication);message passing interface;programmer;software bug	Kento Sato;Dong H. Ahn;Ignacio Laguna;Gregory L. Lee;Martin Schulz;Christopher M. Chambreau	2017		10.1145/3018743.3018767	parallel computing;real-time computing;computer science;message passing interface;operating system;distributed computing;programming language;debugging;computer security	SE	-20.826855442821312	38.832937402042106	101863
172015bc482d7d712a8df679cc056068a9b8243f	automated functional verification of application specific instruction-set processors		Nowadays highly competitive market of consumer electronics is very sensitive to the time it takes to introduce a new product. However, the evergrowing complexity of application specific instruction-set processors (ASIPs) which are inseparable parts of nowadays complex embedded systems makes this task even more challenging. In ASIPs, it is necessary to test and verify significantly bigger portion of logic, tricky timing behaviour or specific corner cases in a defined time schedule. As a consequence, the gap between the proposed verification plan and the quality of verification tasks is widening due to this time restriction. One way how to solve this issue is using faster, efficient and costeffective methods of verification. The aim of this paper is to introduce an automated generation of SystemVerilog verification environments (testbenches) for verification of ASIPs. Results show that our approach reduces the time and effort needed for implementation of testbenches significantly and is robust enough to detect also well-hidden bugs.	central processing unit;code coverage;cognitive dimensions of notations;corner case;embedded system;experiment;open verification methodology;separable polynomial;software bug;systemverilog	Marcela Simková;Zdenek Prikryl;Zdenek Kotásek;Tomás Hruska	2013		10.1007/978-3-642-38853-8_12	real-time computing;simulation;computer science;operations management;high-level verification;functional verification	AI	-22.334909167909803	37.431412957892924	102098
24ec3c2c92186b235ecff3fe0085ce6dee11d4ac	bounds on the time to reach agreement in the presence of timing uncertainty	timing uncertainty;tolerancia falta;distributed system;consensus;fiabilidad;reliability;systeme reparti;fault tolerant;time complexity;incertidumbre;uncertainty;distributed networks;distributed consensus;real time;performance;time;agreement;distributed agreement;algorithme;algorithm;sistema repartido;temps;fiabilite;fault tolerance;upper and lower bounds;incertitude;rendimiento;timeout;tolerance faute;tiempo;algoritmo	Upper and lower bounds are proved for the time complexity of the problem of reaching agreement in a distributed network in the presence of process failures and inexact information about time. It is assumed that the amount of (real) time between any two consecutive steps of any nonfaulty process is at least c1 and at most c2; thus, C = c2=c1 is a measure of the timing uncertainty. It is also assumed that the time for message delivery is at most d. Processes are assumed to fail by stopping, so that process failures can be detected by timeouts. A straightforward adaptation of an (f + 1)-round round-based agreement algorithm takes time (f + 1)Cd if there are f potential faults, while a straightforward modi cation of the proof that f + 1 rounds are required yields a lower bound of time (f + 1)d. The rst result of this paper is an agreement algorithm in which the uncertainty factor C is only incurred for one round, yielding a running time of approximately 2fd + Cd in the worst case. (It is assumed that c2 d.) The second result shows that any agreement algorithm must take time at least (f 1)d + Cd in the worst case. The new agreement algorithm can also be applied in a model where processors are synchronous (C = 1), and where message delay during a particular execution of the algorithm is bounded above by a quantity which could be smaller than the worst-case upper bound d. The running time in this case is approximately (2f 1) + d.	algorithm;best, worst and average case;central processing unit;time complexity;timeout (computing)	Hagit Attiya;Cynthia Dwork;Nancy A. Lynch;Larry J. Stockmeyer	1994	J. ACM	10.1145/174644.174649	fault tolerance;real-time computing;consensus;computer science;mathematics;distributed computing;algorithm	Theory	-21.3795291975809	44.208615711862926	102158
4a41f6f9b9d2c56f02bf0e96a872321120320044	extending www for synchronous collaboration	union bidireccional;groupware;modele client serveur;liaison bidirectionnelle;securite;asynchronous collaboration;real time;mosaic;systeme recherche information;client server;synchronous collaboration;temps reel;safety;information retrieval systems;session control;tiempo real;world wide web;bidirectional link;peer to peer;seguridad;shared workspace;client server model;www	The World-Wide Web (WWW), in conjunction with such tools as Mosaic, is an extremely effective mechanism for individuals to share distributed information. However, access to this information is unidirectional, asynchronous, and limited by a client/server model in which only predefined data are provided. We describe augmenting WWW to support bidirectional, synchronous collaboration between data producers and their consumers. This is accomplished by exploiting WWW's ease of access and use, and by incorporating a peer-to-peer model that provides real-time collaboration services.	www	Thane J. Frivold;Ruth E. Lang;Martin W. Fong	1995	Computer Networks and ISDN Systems	10.1016/0169-7552(95)00092-4	telecommunications;computer science;database;distributed computing;law;world wide web;client–server model;computer network	Theory	-29.944374789667794	43.72919074606913	102275
a34f9391725cd657b7ae5965550436af192a0b6a	developing synchronous collaborative applications with teamcomponents	allgemeine werke;000 informatik;informationswissenschaft	Synchronous groupware applications are playing a major role in, e.g., distance education, video conferencing, joint program development, co-operative publishing, etc. There exists a variety of platforms which relieve the groupware developer from struggling with standard problems like network details, synchronisation algorithms, etc., and allow him or her to concentrate on applicationspecific details. Although these platforms su pport simple applications, groupware with a reasonable number of different kinds of artefacts (e.g. word processors with embedded documents) is still difficult to realise. Component based approaches simplify the development of such applications, but, although these approaches are quite common in single user environments, they have not yet been widely incorporated into groupware development platforms. In contrast to single-user component approaches, additional problems have to be solved: collaborative components have to communicate with other sites and multiple users, have to manage shared data, have to react on group events and have to offer group awareness services. The TeamComponents approach addresses these problems. It is based upon our groupware platform DreamTeam and covers a wide range of collaborative scenarios. A selection of sample applications with TeamComponents validates our design concept.	algorithm;central processing unit;code;collaborative software;component-based software engineering;concurrency (computer science);concurrency control;database transaction;document;embedded system;lambda lifting;lock (computer science);multi-user;runtime system;software project management;software quality;user interface;visual artifact;web page	Jörg Roth;Claus Unger	2000			computer science	DB	-31.167275561139444	40.1148688552965	102292
3f031be3475a4ff45d49234a7bc93872415576b8	orientais: formal verified osek/vdx real-time operating system	verification;automotive engineering;automotive electronics;formal specification;standards;program verification assembly language automotive engineering binary codes c language embedded systems formal specification interrupts operating systems computers;binary codes;safety binary codes abstracts standards operating systems natural languages system recovery;natural languages;program verification;binary intermediate language formal verification osek vdx real time operating system machine verified operating system automotive application c language assembler embedded system orientais application programming interface osek vdx specification high level interaction behavior modeling csp deadlock free verification memory access safety bounded response time interrupt program binary code level verification;embedded systems;c language;system recovery;operating system;assembly language;abstracts;osek vdx;safety;verification osek vdx automotive electronics operating system;interrupts;operating systems computers;operating systems	In this paper, we report on the formal, machine-verified operating system - ORIENTAIS. ORIENTAIS is an OSEK/VDX standard based real-time operating system for automotive applications. About 8000 lines of C and 60 lines of assembler are comprised in the ORIENTAIS. The operating system is of vital importance to embedded systems, especially for some time sensitive and accurate controlling applications just like automotive applications. We prove that the implementation of ORIENTAIS application programming interfaces strictly follow the OSEK/VDX specification which we formalized from natural language expressed OSEK/VDX specification. Meanwhile, we model the high level interaction behaviors with CSP and verify the properties just like deadlock-free. To guarantee the safety of memory access and bounded response time with interrupt program involved, binary code level verification is developed based on xBIL which is a binary intermediate language we proposed. We introduce a series of techniques and approaches for verifying the ORIENTAIS. Our approach is an efficient work for the verification of ORIENTAIS, with whose help several bugs are detected. Now, ORIENTAIS has been certificated by OSEK certification group and installed on more than 1.38 million cars in China.	application programming interface;assembly language;binary code;deadlock;embedded system;high-level programming language;natural language;osek;real-time clock;real-time operating system;response time (technology);software bug;vdx (library software);verification and validation	Jianqi Shi;Jifeng He;Huibiao Zhu;Huixing Fang;Yanhong Huang;Xiaoxian Zhang	2012	2012 IEEE 17th International Conference on Engineering of Complex Computer Systems	10.1109/ICECCS.2012.27	embedded system;binary code;real-time computing;verification;computer science;operating system;formal specification;interrupt;natural language;programming language;assembly language	Embedded	-23.553088230684317	35.77862363237151	102311
152d41e4c51835a323718fae8826fb77fb6a5ae4	bus scheduling for tdl components	timing definition language;systeme temps reel;modelizacion;seguridad funcionamiento;topology;surete fonctionnement;architecture systeme;sistema temporizado;execution time;componente logicial;real time;topologie;timed system;composant logiciel;topologia;modelisation;hard real time system;logical execution time;scheduling;temps reel;dependability;software component;systeme temporise;tiempo real;component model;temps execution;arquitectura sistema;real time system;sistema tiempo real;tiempo ejecucion;system architecture;modeling;ordonnancement;reglamento;hard real time	This paper describes a solution for bus scheduling of distributed multi-mode TDL (Timing Definition Language) components. The TDL component model is based on the concept of Logical Execution Time (LET), which abstracts from physical execution time and thereby from both the execution platform and the communication topology. The TDL component model allows the decomposition of hard real-time applications into modules (= components) that are executed in parallel. A TDL module runs in one particular mode at a time and may switch to another mode independently from other modules. This is in contrast with global modes as introduced by other available hard real-time systems and introduces new challenges for bus scheduling.	algorithm;component-based software engineering;embedded software;embedded system;heuristic (computer science);integration testing;network switch;real-time clock;real-time computing;real-time transcription;run time (program lifecycle phase);scalability;scheduling (computing)	Emilia Farcas;Wolfgang Pree;Josef Templ	2004		10.1007/11786160_4	embedded system;real-time computing;real-time operating system;systems modeling;computer science;component-based software engineering;operating system;dependability;component object model;programming language;scheduling;systems architecture	Embedded	-28.66882640596234	36.24362048138276	102349
6826aa6fa14e9f3017e1dd8d8b50d23a1a923807	programmer's interface and communication protocol for remote procedure calls	remote procedure call;communication protocol	Remote procedure-calls are a useful paradigm for the structuring of distributed computations. Client-processes perform procedure- calls which are executed by server-processes on a possibly different host. Synchronization and data-transfer over a network can be expressed in terms of remote procedure-calls, which provide an inter-process communication facility.	communications protocol;programmer	Michael Spenke	1985		10.1007/978-3-642-70836-7_8	communications protocol;real-time computing;xml-rpc;internet protocol control protocol;computer science;operating system;distributed computing;internet protocol suite;remote procedure call;computer network	EDA	-26.788615590410675	45.60300538171838	102544
06cc69aa5449eb93cf92d587ab11330e20b47170	virgil: objects on the head of a pin	verification;ecriture programme;developpement logiciel;language processor;lenguaje programacion;virtual machine;microcontrollers;machine language;compilacion;resource limitation;cabeza;reseau capteur;systems;lenguaje maquina;microwave;random access memory;calculateur embarque;object oriented language;compilateur;memoria acceso directo;analyse statique;metadata;programming language;program writing;memoire morte;escritura programa;performance;resource management;hyperfrequence;inicializacion;program verification;machine virtuelle;compiler;systems software;analisis estatica;sensor network;embedded system;program optimization;heap compression;multi stage computation;embedded systems;gestion recursos;whole program compilation;verificacion programa;read only memory rom;red sensores;complex data;programa aplicacion;design and implementation;sensor networks;application program;object oriented;desarrollo logicial;microregisseur;memoire acces direct;programme application;estructura datos;software development;data sensitive optimization;boarded computer;hiperfrecuencia;metadonnee;sensor array;memoria muerta;langage programmation;compilation;gestion ressources;code size;radio wave;oriente objet;algorithms;design;structure donnee;optimisation programme;head;metadatos;microcontrolador;tete;programa tratamiento lenguaje;static analysis;experimentation;verification programme;dead code elimination;programme traitement langage;maquina virtual;management;orientado objeto;data structure;embedded processor;langage machine;calculador embarque;initialization;initialisation;onda radio;compilador;microcontroller;standalone programs;onde radioelectrique;optimizacion programa	Embedded microcontrollers are becoming increasingly prolific, serving as the primary or auxiliary processor in products and research systems from microwaves to sensor networks. Microcontrollers represent perhaps the most severely resource-constrained embedded processors, often with as little as a few bytes of memory and a few kilobytes of code space. Language and compiler technology has so far been unable to bring the benefits of modern object-oriented languages to such processors. In this paper, I will present the design and implementation of Virgil, a lightweight object-oriented language designed with careful consideration for resource-limited domains. Virgil explicitly separates initialization time from runtime, allowing an application to build complex data structures during compilation and then run directly on the bare hardware without a virtual machine or any language runtime. This separation allows the entire program heap to be available at compile time and enables three new data-sensitive optimizations: reachable members analysis, reference compression, and ROM-ization. Experi-mental results demonstrate that Virgil is well suited for writing microcontroller programs, with five demonstrative applications fitting in less than 256 bytes of RAM with fewer than 50 bytes of metadata. Further results show that the optimizations presented in this paper reduced code size between 20% and 80% and RAM size by as much as 75%.	bare machine;byte;central processing unit;compile time;compiler;data structure;embedded system;kilobyte;microcontroller;microwave;random-access memory;virtual machine	Ben L. Titzer	2006		10.1145/1167473.1167489	microcontroller;embedded system;parallel computing;real-time computing;wireless sensor network;data structure;computer science;resource management;programming language;object-oriented programming	PL	-19.56189609971295	36.587428788387136	102587
0afff641d311412b78f1c1bcc84c899dc4c3a031	tools and techniques for measuring and improving grid performance	computer information security;computers;distributed memory;data transmission;computational grid;information power grid;computer systems design;distributed processing;distributed computing;grille puissance information;intelligence economique;computer networks;computer programs;decentralized system;position location;nasa programs;monitoring;scheduling;information resources management;sistema descentralizado;calculo repartido;competitive intelligence;tools and techniques;ordonamiento;access control;systeme decentralise;monitorage;architecture computers;inteligencia economica;monitoreo;calcul reparti;ordonnancement;geographic distribution	To better utilize its vast collection of heterogeneous resources that are geographically distributed across the United States, NASA is constructing a computational grid called the Information Power Grid (IPG). This paper describes various tools and techniques that we are developing to measure and improve the performance of a broad class of NASA applications when run on the IPG. In particular, we are investigating the areas of grid benchmarking, grid monitoring, user-level application scheduling, and decentralized system-level scheduling.		Rupak Biswas;Michael A. Frumkin;Warren Smith;Rob F. Van der Wijngaart	2002		10.1007/3-540-36385-8_5	simulation;distributed memory;competitive intelligence;semantic grid;decentralised system;computer science;artificial intelligence;access control;theoretical computer science;operating system;machine learning;database;distributed computing;scheduling;computer security;algorithm;grid computing;data transmission	HPC	-27.83580496988013	43.576224124562046	102695
77181bb4b4acfc75fc785437a2dd3caef36716ac	a simplex architecture for intelligent and safe unmanned aerial vehicles	software;unmanned aerial vehicles safety software hardware computer architecture reliability circuit faults;reliability;circuit faults;hardware faults simplex architecture safe unmanned aerial vehicles uav physical damage safety threats software complexity higher computing performance software platforms transient fault tolerant processor software bugs;computer architecture;safety;telerobotics aerospace computing aerospace control autonomous aerial vehicles control engineering computing mobile robots program debugging;unmanned aerial vehicles;hardware	Unmanned Aerial Vehicles (UAVs) are increasingly demanded in civil, military and research purposes. However, they also possess serious threats to the society because faults in UAVs can lead to physical damage or even loss of life. While increasing their intelligence, for example, adding vision-based sense-and-avoid capability, has a potential to reduce the safety threats, increased software complexity and the need for higher computing performance create additional challenges -- software bugs and transient hardware faults -- that must be addressed to realize intelligent and safe UAV systems. In this paper, we present a fault tolerant system design for UAVs. Our proposal is to use two heterogeneous hardware and software platforms with distinct reliability and performance characteristics: High-Assurance (HA) and High-Performance (HP) platforms. The HA platform focuses on simplicity and verifiability in software and uses a simple and transient fault tolerant processor, while the HP platform focuses on intelligence and functionality in software and uses a complex and highperformance processor. During the normal operation, the HP platform is responsible for controlling the UAV. However, if it fails due to transient hardware faults or software bugs, the HA platform will take over until the HP platform recovers. We have implemented the proposed design on an actual UAV using a low-cost Arduino and a high-performance Tegra TK1 multicore platform. Our case-studies show that our design can improve safety without compromising performance and intelligence of the UAV.	aerial photography;arduino;fault tolerance;formal verification;higher computing;multi-core processor;on intelligence;programming complexity;software bug;systems design;tegra;unmanned aerial vehicle	Paventhan Vivekanandan;Gonzalo Garcia;Heechul Yun;Shawn Keshmiri	2016	2016 IEEE 22nd International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)	10.1109/RTCSA.2016.17	embedded system;real-time computing;simulation;computer science;operating system;reliability;software fault tolerance	Embedded	-33.67615516033975	37.25085876376122	102804
447b119ecdd431218d0f7beccb11498d90bc2419	run-time verification of networked software	distributed application;input output;execution environment	Most applications that are in use today inter-operate with other applications, so-called peers, over a network. The analysis of such distributed applications requires that the effect of the communication with peers is included. This can be achieved by writing or generating stubs of peers, or by including all processes in the execution environment. The latter approach also requires special treatment of network communication primitives. We also present an alternative approach, which analyzes a networked application by recording and caching its communication with peers. Caching becomes useful when several traces of the application are analyzed. It dispenses with the need of generating a new peer application execution for each different execution of the main application. Such a caching framework for input/output has been implemented on the Java PathFinder platform, which can be used to verify executions of non-deterministic applications at run-time.	cache (computing);distributed computing;input/output;java pathfinder;tracing (software)	Cyrille Artho	2010		10.1007/978-3-642-16612-9_7	input/output;real-time computing;computer science;operating system;distributed computing;programming language	OS	-25.03726494693203	39.058153817418095	102831
bd25accfd12c58b6213cb180e7142531c7a9409f	panel session: do the dbms sw vendors offer the products required by the industrial user in the communication industry?	outil logiciel;software tool;computadora personal;base donnee;ordinateur personnel;protocole transmission;personal computer;sql;database;base dato;protocolo transmision;internet;telecomunicacion;herramienta controlada por logicial;analyse performance;telecommunication;performance analysis;computer hardware;systeme gestion base donnee;sistema gestion base datos;database management system;materiel informatique;material informatica;analisis eficacia;transmission protocol	  I am very pleased that we have a panel today with a lot of very excellent people and Jim Gray to moderate the discussion.  We have split the panel in two: Three from industrial users: Ericsson, Nortel, and Telcordia and three vendors: TimesTen,  ClustRa and Oracle.    		Jim Gray;Svein-Olaf Hvasshovd	1999		10.1007/10721056_14	embedded system;sql;the internet;computer science;operating system;database;computer security	DB	-19.3756748741963	43.86084971209776	103030
234266908a586d2d4cc0fa5cb22346d3e9cc8458	benefits and pitfalls of using html5 apis for online experiments and simulations	application programming interfaces;simulation;real time systems;animation;application programming interface;best practices;html;internet;world wide web;cascading style sheets	The most recent advances in the architecture of the Web allow using it as an excellent platform to deliver experiments and simulations over the Internet. However, there are still some challenges related to the animations' accuracy, to user input collection or to real-time communications that have to be accomplished to properly port native application- based experiments and simulations to the Web. The limitations of the standards preceding HTML5 have forced web developers to embed non-HTML objects using a wide range of non-standard plugins and causing an extremely fragmented execution environment where features must be implemented several times in different programming languages to guarantee full compliance with every user-agent. As HTML5 provides a standard -yet full-featured- environment to develop and execute applications, web user-agents are now more similar to application players than to simple Internet browsers. In this paper we analyze the benefits and pitfalls of these new Application Programming Interfaces (APIs), providing examples of both good and bad instances of research-related use.	application programming interface;experiment;html;html5;internet;plug-in (computing);programming language;real-time transcription;simulation;user agent;web developer;world wide web	Pablo Garaizar;Miguel Ángel Vadillo;Diego López-de-Ipiña	2012	2012 9th International Conference on Remote Engineering and Virtual Instrumentation (REV)		the internet;human–computer interaction;application programming interface;html5;computer science;operating system;database;law;world wide web;best practice	Networks	-32.66829336889677	41.31962124925038	103080
21f4fc923ee282535b15c37dba9b7f1cce5667ff	application of an optimistic concurrency control method	transaction management;database management systems;arbre b;b trees;relational database;methodologie;data base management system;concurrency control;optimistic concurrency control;base donnee relationnelle;controle concurrence;systeme gestion base donnee;methodology	This paper illustrates the implementation feasibility of an optimistic approach to concurrency control. After reviewing the approach and clarifying the underlying algorithms and assumptions, it is applied to the design of a multi-user version of an existing relational database management system. Two different system architectures for a UNIXI-based environment are presented and prototype implementations have been constructed. We also provide some performance statistics on the optimistic approach to concurrency control and compare it with a traditional locking protocol.	algorithm;lock (computer science);multi-user;optimistic concurrency control;prototype;relational database management system	Martin L. Kersten;Hans Tebra	1984	Softw., Pract. Exper.	10.1002/spe.4380140205	b-tree;optimistic concurrency control;real-time computing;isolation;relational database;computer science;concurrency control;methodology;database;distributed computing;multiversion concurrency control;non-lock concurrency control;serializability;distributed concurrency control	DB	-20.349797757783328	46.346363620494316	103143
eab0b8a172847000a89128daea00ab704bf2c136	static and dynamic data management in networks	distributed system;algoritmo paralelo;systeme reparti;parallel algorithm;distributed multimedia;algorithme parallele;dynamic data;sistema repartido;informatique theorique;distributed file system;parallel programs;computer theory;informatica teorica	"""Acknowledgments First of all, I would like to thank my advisor Professor Friedhelm Meyer auf der Heide for his great support and many helpful discussions. He showed me in which direction my research could go but always left me the freedom to do the routing and to choose my way. Besides, I would like to thank my """" co-advisor """" Professor Bruce Maggs who lead me to several spectacular attractions including an embedding of the AKS-into the Multibutterfly-network, a life-sized Diplodocus and many fancy restaurants in Pittsburgh. I would like to thank Matthias Westermann and Klaus Schröder for a very productive collaboration and many valuable discussions, not only about distributed data management but also about maybe even more important aspects of life. Many thanks also to Christian Scheideler and Rolf Wanka with whom I shared an office during most of the last three and a half years. I enjoyed listening to many private lessons Christian and Rolf gave me, e.g., in probability theory, sorting algorithms, and history. In particular, I have to thank the students who did most of the implementations for the experimental results presented in my thesis. Harald Räcke implemented the newly invented data management strategies in the DIVA (Distributed Variables) library; Christof Krick implemented a benchmark of applications for evaluating these strategies; and Mark Meierjohann did most of the simulations for the multimedia data server. All of them were very engaged and did a very good job."""	benchmark (computing);bruce maggs;christof ebert;dynamic data;harald ganzinger;routing;server (computing);simulation;sorting algorithm	Berthold Vöcking	1997		10.1007/BFb0002716	parallel computing;real-time computing;dynamic data;computer science;artificial intelligence;theoretical computer science;operating system;database;distributed computing;parallel algorithm;distributed file system;programming language;computer security;algorithm	DB	-20.497009618992607	42.65038939106446	103255
0a70f06b3f15f71b4d6f9870a78838fe34c1eb6e	opf: a distributed context-sensing framework for ubiquitous computing environments	estensibilidad;distributed system;reseau capteur;systeme reparti;pervasive computing;satisfiability;user assistance;informatica difusa;captador medida;software architecture;measurement sensor;red sensores;sistema repartido;capteur mesure;assistance utilisateur;informatique diffuse;heterogeneidad;distributed software architecture;robustesse;algorithme reparti;asistencia usuario;inferencia;sensor array;procesador oleoducto;robustness;algoritmo repartido;extensibilite;scalability;processeur pipeline;distributed algorithm;inference;architecture logiciel;pipeline processor;heterogeneity;heterogeneite;robustez;ubiquitous computing environment	This paper describes the Obje Perception Framework (OPF ), a distributed software architecture for context sensing and inference in ubiquitous computing environments. OPF provides flexibility, scalability, and robustness even as the sensor configuration changes. For flexibility, OPF supports many context inference tasks, ways of achieving those tasks, and heterogeneity in sensor types. With respect to scalability, OPF accommodates the needs of a large number of applications simultaneously while conserving power and reducing the amount of data transmitted over the network. And to support robustness to dynamism, OPF constructs context inference pipelines to satisfy each applications’ needs in a goal-directed fashion. The value of OPF is demonstrated by a case study of an end-user application that helps users establish and manage connections among the various digital resources in their environment.	distributed computing;pipeline (computing);scalability;software architecture;ubiquitous computing	Max Van Kleek;Kai Kunze;Kurt Partridge;James Begole	2006		10.1007/11890348_7	embedded system;software architecture;distributed algorithm;real-time computing;scalability;computer science;heterogeneity;operating system;distributed computing;ubiquitous computing;sensor array;robustness;satisfiability	HCI	-29.01770717495143	42.236702043327995	103677
7bf1921ab3cf747734ff52f33c9d91c7b97e58d4	towards a scalable high performance application platform for immersive virtual environments	high performance;immersive virtual environment	Software for the development and generation of virtual environments used to run on specialized and expensive hardware. This situation has dramatically changed in the last two years. This paper describes a scalable high performance application platform for immersive environments using commodity hardware. Scalability will be obtained with a coarse cluster of specialized nodes, with emphasis on distributed real-time rendering. As data synchronization method a distributed shared memory approach is used. Dedicated to this hardware setup, a modular component oriented design is presented.		Matthias Bues;Roland Blach;Simon Stegmaier;Ulrich Häfner;Hilko Hoffmann;Frank Haselberger	2001		10.2312/EGVE/EGVE01/165-174	real-time computing;simulation;computer science;computer graphics (images)	HPC	-29.908516596483196	40.08662278621615	103734
48ac2eb36287cba7ce3eab7c3a67cfe1736a9a18	software idioms for component-based and topology-aware simulation assembly and data exchange in high performance computing and visualisation environments			component-based software engineering;simulation;supercomputer	Atanas Atanasov	2014				HPC	-31.20677943304874	45.55561100838708	103813
38182256ed543f276e7e7b9f8be1cf2911625177	a lattice-based framework for the classification and design of asynchronous pipelines	graph theory;protocols;lattices;logic design;correct by construction transformation rules;logic;lattice based framework;pipelines protocols logic permission lattices law legal factors computer science circuits tires;design space;law;legal factors;asynchronous pipeline classification;permission;integrated circuit modelling;pipelines;digital design;asynchronous circuits;circuits;tires;design space exploration;computer science;asynchronous pipeline design;asynchronous pipeline circuit modeling;pipeline protocol;graph based model;correct by construction transformation rules lattice based framework asynchronous pipeline classification asynchronous pipeline design asynchronous pipeline circuit modeling pipeline protocol graph based model;pipeline;asynchronous;framework;graph theory asynchronous circuits logic design integrated circuit modelling;partial order	This paper presents a unifying framework for the modeling of asynchronous pipeline circuits. A pipeline protocol is captured in a graph-based model which defines the partial ordering of both its control and data events. The relationship between an entire space of different protocols is then captured in a semi-lattice, which has well-defined top and bottom elements, corresponding to the most concurrent and least concurrent protocol variants, respectively. This framework also provides a set of correct-by-construction transformation rules which allows for the systematic exploration of the entire design space by their successive application. To the best of our knowledge, this is the first formal framework for asynchronous pipelines which can capture protocols from a variety of logic style families, including both dynamic and static. It is also the first to provide a formal foundation for the design-space exploration of asynchronous pipelines.	pipeline (computing);semiconductor industry	Peggy B. McGee;Steven M. Nowick	2005	Proceedings. 42nd Design Automation Conference, 2005.	10.1145/1065579.1065707	electronic engineering;logic synthesis;real-time computing;computer science;graph theory;theoretical computer science;distributed computing;pipeline;logic	EDA	-33.277936474694634	32.71630474352835	103831
1b8d765116f6ed23ed3ed665d20cb42a3704fef4	an operational semantics for the parallel language eden	parallel computing;operational semantics;functional programming;parallel languages;skeletons	The functional parallel language Eden — suitable for the description of parallel and concurrent algorithms in a distributed setting — is an extension of Haskell with a set of coordination features. In this paper we present a formal operational semantics for the kernel of Eden, or more precisely, for a λ-calculus widened with explicit parallelism and potentially infinite communication channels. Eden overrides the lazy nature of Haskell on behalf of parallelism. This interplay between laziness and eagerness is accurately described by the semantics proposed here, which is based on Launchbury's natural semantics for lazy evaluation, and is expressed through a two-level transition system: a lower level for the local and independent evaluation of each process, and an upper one for the coordination between all the parallel processes in the system. As processes are created either under demand or in a speculative way, different scheduling strategies are possible — ranging from a minimal one that only allows the main thread to evolve, to a maximal one that evolves in parallel every active binding.	operational semantics;parallel language	Mercedes Hidalgo-Herrero;Yolanda Ortega-Mallén	2002	Parallel Processing Letters	10.1142/S0129626402000938	parallel computing;computer science;theoretical computer science;operating system;distributed computing;programming language;functional programming;operational semantics;algorithm	HPC	-27.963347173225134	32.87729448226835	103958
ec87f4941e7868455d1db4065980e6fec9dd6b11	commanding and reactive control of peripherals in the tmo programming scheme	i o activities;protocols;time triggered;timing behavior;kernel;computer languages;peripheral interfaces;application software;peripherals;real time;input output programs;distributed computing;application program interfaces distributed programming object oriented programming real time systems distributed object management operating system kernels input output programs peripheral interfaces;programming profession object oriented programming middleware kernel object oriented modeling distributed computing application software operating systems computer languages protocols;object oriented programming;reactive control;timing behavior high level real time distributed computing objects commanding reactive control peripherals tmo programming scheme i o activities real time object programming styles time triggered message triggered object programming scheme;commanding;object oriented;programming profession;distributed programming;time triggered message triggered object programming scheme;application program interfaces;distributed object management;middleware;operating system kernels;parallel programs;tmo programming scheme;object oriented modeling;real time object programming styles;high level real time distributed computing objects;operating systems;real time systems	Although high-level real-time distributed computing objects are generally written in forms independent of execution platforms, input and output (I/O) activities involving peripherals are inherently platform-dependent. Yet, writing parts of real-time objects for controlling peripherals should be done in forms compatible with the adopted real-time object programming styles. Basic issues are discussed in the context of an object-oriented real-time programming scheme called the time-triggered message-triggered object (TMO) programming scheme. A desirable goal here is to facilitate both commanding and reactive control of peripherals in TMOs in general forms while enabling relatively easy analysis of the timing behavior of such TMOs. This paper presents several techniques to meet these requirements.	distributed computing;experiment;high- and low-level;input/output;peripheral;rc4;real-time cmix;real-time clock;real-time locating system;real-time transcription;requirement;software release life cycle	K. H. Kim	2002		10.1109/ISORC.2002.1003813	embedded system;real-time computing;computer science;operating system;distributed computing;programming language;object-oriented programming	PL	-31.815463338032885	38.13627267601964	104167
f45f664eb1f688517a8cb26543b6fdf5324a825e	a real-time multi-sensor fusion platform for automated driving application development	multi sensor fusion;mobility;real time;ts technical sciences;advanced driver assistance systems;ivs integrated vehicle safety;fluid solid mechanics;decision support systems;traffic;adas mixed criticality real time multi sensor fusion latency jitter;adas;latency;mixed criticality;jitter;multiple integrated safety critical adas real time multisensor fusion platform automated driving application development advanced driver assistance systems autonomous emergency braking layer based multisensor fusion real time system mixed criticality system real time layer based platform;sensor fusion driver information systems real time systems	Advanced Driver Assistance Systems (ADAS) become standard and sometimes mandatory for vehicles, e.g. autonomous emergency braking. Future vehicles will include multiple ADAS that assist with safety-critical operations. For efficiency and effectiveness, these ADAS should share resources, information and functionalities. Additionally, ADAS performing safety-critical functionality require predictability for the execution of their processes. This paper presents the integration of a layer-based multi-sensor fusion and processing platform into a real-time system that also supports non-critical processes, i.e. a mixed-criticality system. A suitable system is selected, the behavior of the platform and its interfaces is described and tests are performed to validate the predictable behavior, by examining the difference in jitter and execution latency. The real-time layer-based platform is suitable for the development and testing of multiple integrated safety-critical ADAS.	amd accelerated processing unit;architecture design and assessment system;autonomous car;autonomous robot;mixed criticality;real-time clock;real-time computing;self-organized criticality	Tjerk Bijlsma;Maurice Kwakkernaat;Mari Mnatsakanyan	2015	2015 IEEE 13th International Conference on Industrial Informatics (INDIN)	10.1109/INDIN.2015.7281935	embedded system;real-time computing;simulation;engineering	Robotics	-33.31823120870035	36.70779216940968	104176
ef31d63253492c5df346cf47bde266c85bbb2264	applying a 3-d-gui to a distributed network management system	computer network management java distributed programming distributed object management graphical user interfaces;system configuration;distributed network management;three dimensional;graphical user interfaces;java applet;network configuration;distributed programming;computer network management;distributed object management;fault notifications 3d gui distributed network management system complicated network configurations corba based network management systems java applets management information vrml scene corba server prototype system configuration;graphical user interfaces associate members layout prototypes displays technology management information management virtual reality network servers computer architecture;network management system;java	Three-dimensional (3-D) GUIs help network operators to understand complicated network configurations. With the goal of applying 3-D-GUI technology to CORBA-based network management systems, this paper proposes a method of integrating VRML/Java/CORBA, in which Java applets mediate management information between a VRML scene and a CORBA server. A prototype system configuration that incorporates this method and its operation sequence, which displays the fault notifications on VRML scenes, is described. An evaluation of the prototype system demonstrates the effectiveness of this method.	common object request broker architecture;graphical user interface;java applet;management information system;prototype;server (computing);system configuration;vrml	Naoki Watanabe;Yuminobu Igarashi;Miyoshi Hanaki	2000	IEEE Journal on Selected Areas in Communications	10.1109/49.842987	network management;out-of-band management;three-dimensional space;fcaps;element management system;intelligent computer network;network management station;computer science;operating system;graphical user interface;database;network simulation;real time java;network management application;structure of management information;java;world wide web;network monitoring;java applet	Networks	-31.275505340847655	44.52300167584398	104187
1b48331053ac8fd2cd0b8fc47c14812561f271a2	fault-tolerant hierarchical real-time scheduling with backup partitions on single processor	automotive;autosar;design tools;e e architectures	The resource partitioning has been suggested to provide efficient composition of multi-threaded real-time applications. Partitioning can provide reliable and flexible software upgrade as partitions are strongly isolated in terms of resources. However, there are always possibility of experiencing software faults while operating on a real plant. To avoid entering a hazardous state due to a partition that is yet to be fully verified, we can deploy a backup partition that may implement inefficient algorithms or limited features but is verified with respect to reliability. The backup partition performs failover to carry out missions of the corresponding primary partition when a software fault is detected. There have been significant researches for fault-tolerant real-time scheduling but considerations for partitioned systems have not been studied. In this paper, we extend the resource model for hierarchical real-time scheduling to support primary and backup partitions. Our model can support context-dependent and context-independent tasks in the backup partition efficiently. In addition, we provide the schedulability analysis for suggested model.	algorithm;backup;context-sensitive language;disk partitioning;failover;fault tolerance;real-time clock;real-time computing;real-time operating system;real-time transcription;scheduling (computing);scheduling analysis real-time systems;thread (computing)	Hyun-Wook Jin	2013	SIGBED Review	10.1145/2583687.2583693	embedded system;real-time computing;computer science;automotive industry;operating system;distributed computing	Embedded	-25.341219296001142	43.21195272062249	104474
4f6b63716d5253a6989bbe39799068a75e414266	verification of communicating data-driven web services	bag set semantics;conjunctive queries;inequalities;web service;modular verification;bag semantics;undecidability;first order logic;query containment	We study the verification of compositions of Web Service peers which interact asynchronously by exchanging messages. Each peer has access to a local database and reacts to user input and incoming messages by performing various actions and sending messages. The reaction is described by queries over the database, internal state, user input and received messages. We consider two formalisms for specification of correctness properties of compositions, namely Linear Temporal First-Order Logic and Conversation Protocols. For both formalisms, we map the boundaries of verification decidability, showing that they include expressive classes of compositions and properties. We also address modular verification, in which the correctness of a composition is predicated on the properties of its environment.	correctness (computer science);first-order logic;first-order predicate;verification and validation;web service	Alin Deutsch;Liying Sui;Victor Vianu;Dayou Zhou	2006		10.1145/1142351.1142364	web service;computer science;theoretical computer science;first-order logic;inequality;database;conjunctive query;programming language	DB	-29.508550656434963	32.941326973343045	104481
129d40739c7cd823ea490cfe56d1448b006b3523	designing a testbed for large-scale distributed systems	internet application;different evaluation method;unchanged application code;real-network prototype;maximum portability;flexible system interface;multiple simulator;different tradeoffs;distributed system;network simulator	Different evaluation methods for distributed systems like prototyping, simulation and emulation have different tradeoffs. We present a testbed for Internet applications that supports real-network prototypes and multiple simulators with unchanged application code. To ensure maximum portability between runtimes, a compact but flexible system interface is defined.	distributed computing;emulator;runtime system;simulation;software portability;testbed;usability	Christof Leng;Max Lehn;Robert Rehner;Alejandro P. Buchmann	2011		10.1145/2018436.2018488	real-time computing;simulation;computer science;network simulation;distributed computing;computer network	HPC	-32.53624859000209	39.55026023639649	104669
00afa8afa659eb4a86d20bd9774b8c1cbd9c9e77	dynamic ram-based programs and tasks in the freescale mqx operating system	algorithms random access memory data structures software eprom microcontrollers system on chip;software;microcontrollers;random access memory;system on chip;data structures;eprom;algorithms;mqx kernel dynamic ram based programs freescale mqx real time operating system flash eeprom storage arm based microcontroller chips coldfire based microcontroller chips dynamic ram based code telnet shell finite duration programs continuously executing programs;real time systems flash memories microcontrollers operating system kernels random access storage	This paper describes a solution for supporting dynamic RAM-base code with the Freescale MQX real-time operating system that would normally have all of its code in Flash EEPROM storage found in ColdFire- and ARM-based microcontroller chips. Dynamic RAM-based code can expedite development and refinement of embedded application code by reducing the need to repeatedly build a full code image and reprogram Flash EEPROM. The solution consists of two primary components: a compact addition to MQX on the target platform, and a standalone tool on a host computer to prepare application code in a form suitable for RAM-based use. The addition to MQX exploits the convenience of an existing telnet shell, but also involves custom code for managing data structures for a collection of dynamic programs in RAM. In addition to supporting the execution of finite-duration programs, continuously-executing programs can be dynamically initiated as background tasks in MQX. For a ColdFire microcontroller, the addition to MQX represents a modest increase of approximately 9 kbytes, which is less than 9% of total image size for the MQX kernel with shell and networking code.	arm architecture;adobe flash;codewarrior;data structure;dynamic random-access memory;eeprom;embedded software;embedded system;function pointer;host (network);image resolution;integrated development environment;microcontroller;programming tool;real-time operating system;real-time transcription;refinement (computing)	Naraig Manjikian	2015	2015 IEEE 28th Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2015.7129361	system on a chip;microcontroller;embedded system;real-time computing;data structure;computer hardware;computer science;operating system;eprom	Embedded	-20.92705835937211	37.41361900900475	104835
bd32eb345638e9a852a1ff0cc7cd88814654f1cf	reducing null messages in the conservative parallel simulation of timed petri nets	time petri net;parallel simulation		petri net;simulation	Qung Ming Cui;Stephen John Turner	1998			real-time computing;stochastic petri net;computer science;theoretical computer science;distributed computing;petri net	EDA	-27.127335457661275	33.81104500389289	104949
d5e4bbb3ed478fef5ce672fa76165def3f558659	distributed supervisory control of discrete-event systems with communication delay	delay robustness;distributed supervisory control;discrete event systems;communication delay	This paper identifies a property of delay-robustness in dist ributed supervisory control of discrete-event systems (DES) with communication delays. In previous work a distributed supervisory control problem has been investigated on the assumption that inter-agent co mmunications take place with negligible delay. From an applications viewpoint it is desirable to rel ax this constraint and identify communicating distributed controllers which are delay-robust, namely lo gically equivalent to their delay-free counterparts. For this we introduce inter-agent channels modeled as 2-sta te automata, compute the overall system behavior, and present an effective computational test for d elay-robustness. From the test it typically results that the given delay-free distributed control is de lay-robust with respect to certain communicated events, but not for all, thus distinguishing events which ar e not delay-critical from those that are. The approach is illustrated by a workcell model with three commu nicating agents.	automata theory;computation;distributed control system	Renyuan Zhang;Kai Cai;Yongmei Gan;Zhaoan Wang;Walter Murray Wonham	2016	Discrete Event Dynamic Systems	10.1007/s10626-014-0208-4	control engineering;real-time computing;computer science;control theory;supervisory control	SE	-24.229099845276632	42.4487321522658	105166
c8d34fe2116fb324e4928293291fbfca28937634	deadlock-free incremental replay of message-passing programs	distributed debugging;distributed system;debugging;puesta a punto programa;user needs;systeme reparti;algoritmo adaptativo;transmission message;message transmission;checkpointing;debogage;point controle;adaptive algorithm;sistema repartido;algorithme adaptatif;envoi message;checkpoint;incremental replay;message passing;deadlock;interbloqueo;adaptive logging;interblocage;transmision mensaje	To support incremental replay of message-passing applications, processes must periodically checkpoint and the content of some messages must be logged, to break dependencies of the current state of the execution on past events. This paper shows that known adaptive logging algorithms are likely to introduce deadlocks in replay, and we introduce a new algorithm that: (i) prevents deadlocks in replay and (ii) enables the tuning of its behavior to meet specific user needs. 2001 Academic Press	algorithm;deadlock;experiment;incremental compiler;message passing;online and offline;parallel computing;replay attack;simulation;transaction processing system	Franco Zambonelli;Robert H. B. Netzer	2001	J. Parallel Distrib. Comput.	10.1006/jpdc.2001.1703	parallel computing;message passing;real-time computing;computer science;deadlock;operating system;distributed computing;programming language;debugging	PL	-21.007305767206695	43.007172215772066	105188
0470327194972eb8df545e17151dcaf6e1adb488	testing and demonstrating context-aware services with quake iii arena	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;context aware service;ciencias basicas y experimentales;tecnologias	Developers of context-aware services, i.e. services that make use of sensory information from the environment of their users, often find testing and demonstrating services to be difficult. One reason is that context information may be unavailable or otherwise inaccessible until the time of deployment. To alleviate this problem we present QuakeSim, a simulator of context information based on a modification of the popular game Quake III Arena. Testing and demonstrating context aware services can be difficult. Context aware services inherently need information such as the position of their users, but it is complicated to gather and supply services with such kinds of information. Obviously, one needs to do this when the service is up and running, but while developing, or for demonstration purposes, it may help to simulate the context information. Even though the simulated context information is not real, the service and the routines that gather and receive the context information can be. This enables systems to be developed with less regard for constraints that stem from using real sensor technology while still keeping the core functionality of services separate and ready for real-world deployment. One can image two types of simulation tools: those that simulate a set of values as a part of a test suite, and those that allow you to interactively test services in semi-realistic circumstances. We have chosen that latter approach as it has the added advantage of allowing us to demonstrate services. QuakeSim QuakeSim is a tool that interactively simulates context information in real time. It simulates the real three dimensional (3D) world and different kinds of context information. With QuakeSim, it is possible to test and demonstrate context aware services without requiring users or objects to actually be in and move around the real world. Requirements. In order to serve as a development and demonstration tool, we found that the following requirements should be placed on a context simulator. 1. It should provide a realistic looking simulation of real world environments, complete with people and other complex objects (e.g. buildings, animals, and water). 2. Multiple users, represented by avatars, should be able to share an environment and interact with each other. 3. It should be possible to create and equip the simulator with new environments, avatars, and objects. 4. Tools for building environments, avatars, and objects should be available. 5. Sensors that register information about for example the position and altitude of individual users should be simulated. Surveying available tools for implementing a simulator, we found that the 3D game Quake III Arena1 directly provides functionality that meets requirement 1-4. The game engine of Quake is capable of rendering 3D environments with satisfying realism. It allows multiple users to interact in a shared environment via a network, and 1 See http://www.idsoftware.com tools for authoring environments and designing objects and avatars are available for free. Requirement 5, that sensors for registering position and altitude should be simulated, can be achieved by modifying Quake. An alternative to using Quake III Arena, besides implementing the simulator from scratch, would be to build on for example Web3D2 browsers for VRML (Virtual Reality Modeling Language) and the like. However, our survey showed that such tools generally display less realistic simulations while not providing any more support for simulating sensors than Quake does. Modifications to Quake. For the purpose of implementing a context simulator, Quake III Arena can be seen as being composed of two main parts: one game engine that renders environments and avatars, and one part that controls how objects should behave within the environment. The game engine is proprietary and not open for modification. The second part however, has been made freely available for modification on a source code level. This allows us to extract information about for example the position and altitude of each user. Information about the speed and bearing of users as well as indications on whether users are swimming or flying can also be extracted. This information can in turn be used to simulate different kinds of sensors. Context Toolkit. Let us consider a bit further the relationship of sensors, context information, and services. Sensor information and context information is not the same thing. Sensor information is raw data and as such it is not particularly useful to any service (or human for that matter). It is when the data is interpreted and made available as context information that it suddenly becomes useful. Clearly, data may be interpreted in numerous ways; for example, a temperature reading may be interpreted simply as the temperature of some location. However, if you add to the interpretation an extra layer, for example the significance of an 2 See http://www.web3d.org extremely high value, it may be used to indicate the presence of fire. Furthermore, context information, to be useful, must be accessible to services. It is quite possible that several services will be interested in the same context information. And one service may very well make use of several different pieces of context information. It thus seems like a good idea to streamline the method for services to access context information. For the purpose of gathering, aggregating, interpreting, and publishing sensor and context information we therefore use the Context Toolkit [1]. The Context Toolkit models each piece of sensor information as a “widget” that encapsulates sensor specific details of gathering the information, and provides a common interface towards services that make use of the information. A widget also provides functions for communication with clients, updating of sensor data, polling of data, subscription to state changes, etc. In effect, the Context Toolkit serves as an abstraction and interpretation layer between sensors and services and can thus provide context information. In QuakeSim we have encapsulated the modified version of Quake as a sensor in a Context Toolkit widget (see b in Figure 1). A client can therefore connect to the widget and through the widget’s API make use of the data that Quake provides. It is also possible to interpret the data provided by Quake in a number of different ways. Similarly to the temperature example above, a location value may be interpreted simply as a location but also as signifying presence in a certain room (mimicking an IR-beacon) by correlating the location to a floor plan with coordinates for all the rooms. The Context Toolkit also makes it possible to combine real and simulated sensors. One of our first applications of the simulator was to demonstrate and test a service in a family context. The home of the family was easily modeled in a room equipped with actual sensors and actuators (e.g. a door lock). The outdoor context of the family, such as the children’s playground, was more difficult to model. We therefore simulated it as a world in QuakeSim. The actual application that was demonstrated used input and generated output to the real sensors and actuators, as well as to the simulated ones. GeoNotes—an Example One of the most interesting pieces of context information, and also one of the most readily available using current technologies, is the user’s location. A person’s location may be deduced by any number of means: a personal Global Positioning System (GPS) device, network based Global System for Mobile Communications (GSM) positioning, infrared beacons, radio receivers, etc. In the GeoNotes [2] system users annotate their present location with virtual Post-ItTM-like notes. For example, to post a note in GeoNotes, a user enters the note text and his or her name or alias. The service then associates the note with the user’s present location in physical space. As another user passes this physical location (perhaps at a later time), the system retrieves and presents the note to the other user. To test GeoNotes, we configured it to receive its positioning data from QuakeSim via a Context Toolkit widget (see b in Figure 1). To receive data from a real position data source the QuakeSim widget can be transparently replaced by a widget representing the real sensor (see d in Figure 1). The Context Toolkit Server (see e in Figure 1) enables us to aggregate several sources of sensory information. The GeoNotes system (see c in Figure 1) implements a generic interface for acquiring position information which makes it easy to switch from one data source to another. Figure 2 and Figure 3 illustrate the use of QuakeSim and GeoNotes in conjunction. The location of the user is simulated by QuakeSim (Figure 3) and fed to the GeoNotes service. In this example, the user is presented with a selection of three notes (Figure 2) that have been placed in the introduction room of the first Quake III Arena game level. Conclusions The GeoNotes example illustrates the usefulness of QuakeSim; with QuakeSim we were able to test and demonstrate the GeoNotes system from a desktop PC in our office. For usability testing, and for full-scale system tests, it is obviously necessary to use the real system deployed in its real setting. However, for demonstration purposes, and for small scale testing during the development process, QuakeSim serves its purpose well.	3d floor plan;as-interface;adobe streamline;aggregate data;application programming interface;avatar (computing);context-aware network;desktop computer;full scale;game engine;global positioning system;interactivity;location-based service;modeling language;multi-user;quake engine;rendering (computer graphics);requirement;semiconductor industry;sensor;simulation;software deployment;test suite;usability testing;vrml;virtual reality	Markus Bylund;Fredrik Espinoza	2002	Commun. ACM	10.1145/502269.502294	real-time computing;simulation;computer science;operating system;world wide web	HCI	-32.744061886639514	40.57039283977894	105374
6eb337716f542579999aa46706d7456e13fe1bd8	an approach to developing multi-tenancy saas using metaprogramming	arquitetura;multi tenant;multi tenancy;software como servi o;software as a service;saas	"""In last years have seen an increase in SaaS (Software as a Service) use. The development of multi-tenancy web application (one of the main ways to provide SaaS) increased considerably after the start of call """"Web 2.0 Age"""". This work presents an approach for implementation of a multi-tenancy SaaS application, and an architecture based on plugins and metaprogramming to achieve a high level software reuse. This approach is presented through an experience report described throughout the paper."""	code reuse;high-level programming language;metaprogramming;multitenancy;plug-in (computing);software as a service;web 2.0;web application	Josino Rodrigues;Andreza Leite;Julio Cesar Damasceno;Vinicius Cardoso Garcia;Paulo Silveira;Silvio Romero de Lemos Meira	2012		10.1145/2382636.2382681	computer science;operating system;multitenancy;software as a service;database	SE	-33.30522773352054	42.679667753959315	105382
8bce00bbb3c61406622598dbc326bfe996df430d	corba platform as support for distributed virtual environments	electrical capacitance tomography;programming environments;concurrent computing;virtual reality application software computer networks computer network management environmental management electrical capacitance tomography concurrent computing data processing context scattering;middleware layer;application software;distributed processing;software architecture virtual reality programming environments distributed processing;virtual reality;data processing;scattering;distributed virtual environments;computer networks;software architecture;computer network management;distributed virtual environment;corba platform;middleware;worldtoolkit software;common object request broker architecture;environmental management;context;interlanguage unification;interlanguage unification distributed virtual environments corba platform common object request broker architecture middleware layer worldtoolkit software	This paper focuses on the use of the CORBA (Common Object Request Broker Architecture) platform as a middleware layer to support distributed virtual environments, particularly those based on the WorldToolKit (WTK) software. Some results of an application implemented by using the ILU (InterLanguage Unification), a software that is compatible with the CORBA platform, are also discussed.	common object request broker architecture;han unification;inter-language unification;middleware;sun java wireless toolkit;virtual reality	Felicio Vanderlei Deriggi;Mario Massakuni Kubo;Antonio Carlos Sementille;José Remo Ferreira Brega;Simone Garcon dos Santos;Claudio Kirner	1999		10.1109/VR.1999.756917	interoperable object reference;software architecture;application software;real-time computing;concurrent computing;data processing;computer science;object request broker;operating system;common object request broker architecture;middleware;database;distributed computing;virtual reality;scattering	Visualization	-33.508629005590876	44.22857327753339	105571
134c72e3712e821fe6cb6462229a036619cc2fc5	a pleasant stroll through the land of distributed machines, computation, and universality		Not only the world is distributed, but more and more applications are distributed. Hence, a fundamental question is the following one: What can be computed in a distributed system? The answer to this question depends on the environment in which evolves the considered distributed system, i.e., on the assumptions the system relies on. This environment is very often left implicit and nearly always not formulated in terms of precise underlying requirements. In the extreme case where the environment is such that there is no synchrony assumption and the computing entities may commit failures, some problems become impossible to solve. Given a distributed computing problem, it is consequently important to know the weakest assumptions (lower bounds) that give the limits beyond which the considered distributed problem cannot be solved. This paper is a short introduction to this kind of issues. It is made up of short sections, each addressing an important point of the theory of distributed computing. Its style is voluntarily informal.	computation;universality probability	Michel Raynal;Jiannong Cao	2018		10.1007/978-3-319-92402-1_2	discrete mathematics;computer science;atomicity;asynchronous system;fault tolerance;universality (philosophy);computation;concurrency;commit;distributed computing	Crypto	-23.15257872098667	43.30339032829146	105650
c8314de2c1405f1aee53b4eea8ff3630913060b5	transforming java programs for concurrency using double-checked locking pattern	synchronized block rewriting java programs double checked locking pattern multicore programming synchronized construct performance scalability problems lock contention concurrency code patterns concurrent collection cc read write lock rwl dcl;parallel programming concurrency control java;synchronization java scalability concurrent computing transforms libraries programming	Java provides a synchronized construct for multi-core programming with many workloads. However, naïve use of the synchronized construct causes performance scalability problems due to lock contention. One of the sources of lock contentions is a synchronized collection class. There are known concurrency code patterns to alleviate lock contentions such as a Concurrent Collection (CC), Read-Write Lock (RWL), and Double-Checked Locking (DCL). To date, there is no algorithm to transform a program using DCL. This paper describes steps on how to rewrite synchronized blocks using DCL.	algorithm;concurrency (computer science);double-checked locking;java;lock (computer science);multi-core processor;read-write memory;readers–writer lock;rewrite (programming);scalability	Kazuaki Ishizaki;Shahrokh Daijavad;Toshio Nakatani	2014	2014 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)	10.1109/ISPASS.2014.6844469	double-checked locking;giant lock;lock;computer architecture;parallel computing;real-time computing;java concurrency;computer science;operating system;distributed computing;programming language;concurrent object-oriented programming	Arch	-21.754190206153215	34.45945874319538	105812
7a337735f7d2aa79d995d2b5bd6eff1e5fc7dfe9	a middleware architecture for supporting adaptable replication of enterprise application data	gestion integrada;tratamiento datos;tolerancia falta;gestion integree;seguridad funcionamiento;gestion entreprise;replication;entreprise;gestion memoire;tratamiento transaccion;base donnee;surete fonctionnement;mise a jour;fault tolerant;availability;disponibilidad;storage management;empresa;logicial personalizado;database;base dato;firm management;data processing;integrated management;traitement donnee;data replication;replicacion;transfert connaissance;intergiciel;actualizacion;transferencia conocimiento;gestion memoria;consistency management;replicated data;fault tolerance;dependability;firm;knowledge sharing;data warehousing;knowledge transfer;middleware;administracion empresa;systeme gestion base donnee;information system;transaction processing;sistema gestion base datos;database management system;disponibilite;tolerance faute;systeme information;updating;traitement transaction;sistema informacion	Enterprise-wide data replication improves availability, performance, fault-tolerance and dependability of database services within and between different subunits in medium and large enterprises. The overhead of consistency management of replicated data can be tamed by built-in DBMS functionality. Different kinds of applications, e.g., update-intensive online transaction processing, cyclical updates for data warehousing, knowledge sharing of repository data, and so on, have different requirements for the availability, up-to-dateness and consistency of replicated data. Thus, replication strategies should be adaptable to the specific requirements of diverse enterprise applications. We describe a middleware for enterprise-wide data replication. It maintains meta data for several protocols, so that the replication strategy can be adapted on the fly to the actual needs of an application.	communications protocol;constraint (mathematics);control theory;database trigger;dependability;enterprise software;fault tolerance;middleware;on the fly;online transaction processing;overhead (computing);prototype;replication (computing);requirement;stored procedure	José Enrique Armendáriz-Iñigo;Hendrik Decker;Francesc D. Muñoz-Escoí;Luis Irún-Briz;Rubén de Juan-Marín	2005		10.1007/11681885_4	fault tolerance;data processing;computer science;operating system;data warehouse;database;computer security	DB	-26.71329255522945	43.869995826187	105861
a41516234456ce70306dccca77a64b8eac38494c	performance tuning with instruction-level cost derived from call-stack sampling	intervalo tiempo;developpement logiciel;lenguaje programacion;entire function;evaluation performance;optimisation;appel procedure;call stack sampling;instrumentation;performance evaluation;optimizacion;programming language;software libraries;profiling;program counter;call graph;gollete estrangulamiento;information source;source information;random sampling;evaluacion prestacion;program library;time interval;profiles techniques;multigraph;goulot etranglement;llamada procedimiento;multigrafo;desarrollo logicial;muestreo aleatorio;software development;performance analysis;bibliotheque programme;langage programmation;optimization;value of information;multigraphe;bibliotheque logiciel;echantillonnage aleatoire;bottleneck;procedure call;performance tuning;biblioteca programa;fuente informacion;intervalle temps	Except for program-counter histogramming, most modern profiling tools summarize at the level of entire functions or basic blocks, with or without additional information such as calling context or call graphs. This paper explicates the value of information about the cost of specific instructions, relative to summaries that do not include it. A good source of this information is time-random sampling of the call stack. To get the diagnostic benefit of instruction costs it is not necessary to measure them with high precision or efficiency. In fact, manual sampling suffices quite well, when it can be used. Other benefits of call stack sampling are that it can be used with unmodified software and libraries, and it is easily confined to the time intervals of interest. As with other profiling techniques, it can be employed repeatedly to remove all significant performance problems in single-thread programs.	basic block;call stack;computer performance;library (computing);performance tuning;profiling (computer programming);program counter;sampling (signal processing);thread (computing)	Michael Dunlavey	2007	SIGPLAN Notices	10.1145/1294297.1294298	program counter;call graph;sampling;real-time computing;simulation;computer science;software development;multigraph;value of information;entire function;profiling;programming language;instrumentation;algorithm	PL	-19.579982930120533	36.0346806361694	106051
8af43ca7e7d2748f1eaffa854a4bb8a5ed75c178	safe manual memory management in cyclone	reference counting;memory management;memory safety;cyclone;garbage collection;regions;device driver;reaps;unique pointers;constrained system	The goal of the Cyclone project is to investigate how to make a low-level C-like language safe. Our most difficult challenge has been providing programmers control over memory management while retaining safety. This paper describes our experience trying to integrate and use effectively two previously-proposed, safe memory-management mechanisms: statically-scoped regions and tracked pointers. We found that these typing mechanisms can be combined to build alternative memory-management abstractions, such as Preprint submitted to Elsevier Science reference counted objects and arenas with dynamic lifetimes, and thus provide a flexible basis. Our experience—porting C programs and device drivers, and building new applications for resource-constrained systems—confirms that experts can use these features to improve memory footprint and sometimes to improve throughput when used instead of, or in combination with, conservative garbage collection.	cyclone;device driver;garbage collection (computer science);high- and low-level;manual memory management;memory footprint;object lifetime;programmer;reference counting;scope (computer science);throughput;tracing garbage collection	Nikhil Swamy;Michael W. Hicks;J. Gregory Morrisett;Dan Grossman;Trevor Jim	2006	Sci. Comput. Program.	10.1016/j.scico.2006.02.003	manual memory management;embedded system;memory safety;reference counting;garbage;real-time computing;simulation;computer science;garbage collection;programming language;cyclone;memory leak;memory management	PL	-20.452063286793702	34.88807466359359	106099
103310e9c35321e1f3a6d4ee5e34479f63d25a2e	non-intrusive object introspection in c++: architecture and application	class declaration parsing;runtime software libraries application software object oriented modeling object oriented programming java delay councils contracts computer languages;computer languages;software libraries;application software;automatic input output support;contracts;system implementation;object oriented programming;runtime;c language;nonintrusive object introspection;design and implementation;system design;object oriented programming nonintrusive object introspection c system design system implementation system architecture class declaration parsing software libraries object compatibility automatic input output support dynamically loaded class libraries software reuse;object compatibility;software reusability;software reusability object oriented languages object oriented programming c language software libraries program compilers;object oriented software development;councils;system architecture;program compilers;c;software reuse;object oriented languages;object oriented modeling;java;dynamically loaded class libraries	We describe the design and implementation of system architecture to support object introspection in C++. In this system, information is collected by parsing class declarations, and used to build a supporting environment for object introspection. Our approach is nonintrusive because it requires no change to the original class declarations and libraries, and it guarantees compatibility between objects before and after the addition of introspective capability. This is critical if one wants to integrate third-party class libraries, which are often supplied as black boxes and allow no modification, into highly dynamic applications. We show two applications: The first on automatic I/O support for C++ objects, and the other on interactive exercise of dynamically loaded C++ class libraries.	black box;c++;input/output;introspection;library (computing);parsing;systems architecture	Tyng-Ruey Chuang;Y. S. Kuo;Chien-Min Wang	1998		10.1109/ICSE.1998.671360	type introspection;real-time computing;run-time type information;computer science;class implementation file;operating system;software engineering;new;programming language;object-oriented programming;systems architecture	PL	-31.692143235752145	37.63827213830343	106112
426ae085b8baac8e42e24ec97f50885c9bf44ac8	information flow in secure contexts	trace equivalance;security properties;observational equivalence;bisimulation;information flow;process algebra;trace equivalence;noninterference;contexts	Information flow security in a multilevel system aims at guar anteeing that no high level information is revealed to low level users, even in the presence of any possible malicious process. This requirement could be stronger than necessary when some knowledge about the environment (context) in which the proc ess is going to run is available. To relax this requirement we introduce the notio n of secure contexts for a class of processes . This notion is parametric with respect to both the observat ion equivalence and the operation used to characterize the low l evel view of a process. As observation equivalence we consider the cases of weak bis imulation and trace equivalence. We describe how to build secure contexts in the se cases and we show that two well-known security properties, named BNDCandNDC, are just special instances of our general notion. This work has been partially supported by the EU Contract IST -2001-32617 “Models and Types for Security in Mobile Distributed Systems” (MyThS) and the FIR B project RBAU018RCZ “Interpretazione astratta e model checking per la verifica di sistemi embedded ”. To appear in Journal of Computer Security. c IOS Press.	bisimulation;computer security;embedded system;exception handling;finite impulse response;high-level programming language;information flow;linear algebra;malware;model checking;non-deterministic turing machine;system equivalence;turing completeness	Annalisa Bossi;Damiano Macedonio;Carla Piazza;Sabina Rossi	2005	Journal of Computer Security	10.3233/JCS-2005-13303	process calculus;information flow;computer science;bisimulation;theoretical computer science;programming language;computer security;algorithm	Security	-30.34451575814645	34.54453445729335	106152
d7931ed43d9a1f1d0975ecb5e79bdd62be0e2d5e	on the message complexity of indulgent consensus	crash failure;liverpool;long period;repository;university	Many recommend planning for the worst and hoping for the best. In this paper we devise efficient indulgent consensus algorithms that can tolerate crash failures and arbitrarily long periods of asynchrony, and yet perform (asymptotically) optimally in well-behaved, synchronous executions with few failures. We present two such algorithms: In synchronous executions, the first has optimal message complexity, using only O(n) messages, but runs in superlinear time of O(n). The second has a message complexity of O(n polylog(n)), but has an optimal running time, completing in O(f) rounds in synchronous executions with at most f failures. Both of these results improve significantly over the most message-efficient of previous indulgent consensus algorithms which have a message complexity of at least Ω(n) in well-behaved executions.	algorithm;asynchrony (computer programming);time complexity	Seth Gilbert;Rachid Guerraoui;Dariusz R. Kowalski	2007		10.1007/978-3-540-75142-7_23	real-time computing;simulation;computer science;distributed computing	Theory	-21.736889785230854	44.38090013508941	106199
87d2bd692efa32de1e40befd55bdc4bab7808f95	camelot: a flexible, distributed transaction processing system	x window manager distributed transaction processing camelot unix compatible mach operating system programming interfaces et 1 graphical room reservation system;application software;distributed transactions;bank data processing;window manager;computer networks;protection;postal services;transaction databases;operating system;reservation computer systems bank data processing credit transactions distributed databases;programming profession;credit transactions;distributed databases;computer science;reservation computer systems;transaction processing;programming profession hardware operating systems transaction databases postal services protection computer networks computer science distributed databases application software;operating systems;hardware	The Camelot Project has constructed a distributed transaction facility intended to support widespread use of transaction processing techniques. Camelot executes on a variety of uni- and multiprocessors on top of the Unix-compatible, Mach operating system. The authors describe the design decisions that make Camelot a flexible, easy-to-use system and briefly describe Camelot's programming interfaces and algorithms. They discuss two applications of Camelot: an implementation of distributed ET-1 and a graphical room reservation system that uses the X Window Manager.<<ETX>>	algorithm;distributed transaction;graphical user interface;mach;operating system;transaction processing system;unix;unix-like;x window system;x window manager	Alfred Z. Spector;Randy F. Pausch;G. Bruell	1988	Digest of Papers. COMPCON Spring 88 Thirty-Third IEEE Computer Society International Conference	10.1109/CMPCON.1988.4907	real-time computing;computer science;operating system;database	DB	-27.408749366395703	45.453596717303064	106223
27d94e631367b8beec9437b4a37944ea604ee96a	a correct and scalable deadlock avoidance policy for flexible manufacturing systems	automatic control;manufacturing systems;control systems;configuration specific linear constraints;total order;flexible manufacturing systems;fms;buffer space allocation;high level system specifications;buffer capacity function;scalable deadlock avoidance policy;resource management;configurable controller;software systems;system recovery flexible manufacturing systems automatic control control systems automatic generation control manufacturing systems resource management discrete event systems software systems industrial engineering;polynomial complexity scalable deadlock avoidance policy flexible manufacturing systems fms configuration flexibility deadlock free operation high level system specifications resource order policy configurable controller buffer space allocation configuration specific linear constraints buffer capacity function constraint generation constraint execution;deadlock avoidance;polynomial complexity;production control flexible manufacturing systems;indexing terms;linear constraint;automatic generation;control system;discrete event system;system recovery;production control;constraint execution;flexible manufacturing system;resource order policy;automatic generation control;configuration flexibility;discrete event systems;constraint generation;deadlock free operation;manufacturing system;buffer capacity;industrial engineering	Configuration flexibility and deadlock-free operation are two essential properties of control systems for highly automated flexible manufacturing systems. Configuration flexibility, the ability to quickly modify manufacturing system components and their logical relationships, requires automatic generation of control executables from high level system specifications. These control executables must guarantee deadlock-free operation. The resource order policy is a configurable controller that provides the deadlock-free guarantee for buffer space allocation. It uses a total ordering of system machines and routing information to generate a set of configuration specific linear constraints. These constraints encode the system state along with a buffer capacity function and define a deadlock-free region of operation. Constraint generation and execution are of polynomial complexity.	control system;deadlock;encode;essence;executable;high-level programming language;routing;scalability;time complexity	Mark A. Lawley;Spyros A. Reveliotis;Placid M. Ferreira	1998	IEEE Trans. Robotics and Automation	10.1109/70.720355	control engineering;real-time computing;index term;computer science;control system;control theory;total order;software system	Robotics	-33.40245740244381	33.53276992134401	106258
e0240466ac0c2c1603ebffddb659f5a170d0e0cf	mruby -- rapid software development for embedded systems	embedded software development mruby rapid software development embedded systems development efficiency object oriented programming language ruby embedded system development compiler vm memory footprint;virtual machine;embedded systems hardware memory management registers arrays;virtual machine ruby embedded software;memory management;ruby;arrays;embedded systems;registers;embedded software;virtual machines embedded systems object oriented programming program compilers software engineering;hardware	In order to improve the development efficiency of embedded software, we have developed a programming language called mruby. We apply the object-oriented programming language Ruby to embedded system development. As compared to the interpreter of Ruby, mruby programs are executed by the compiler and VM. The memory footprint of mruby VM is sufficiently small, Ruby program is able to be executed on a limited resource device. In this paper, we show the benefits of using mruby in embedded software development. We also showcase the features and the development environment of mruby, and implementation results of simple application.	apl;compiler;embedded software;embedded system;integrated development environment;memory footprint;open-source software;programming language;ruby;software development;mruby;z/vm	Kazuaki Tanaka;Avinash Dev Nagumanthri;Yukihiro Matsumoto	2015	2015 15th International Conference on Computational Science and Its Applications	10.1109/ICCSA.2015.22	computer architecture;parallel computing;real-time computing;embedded software;computer science;virtual machine;operating system;processor register;programming language;memory management	Embedded	-21.43657721317634	37.15903469231046	106342
4deb143d6fca887c027959c18015ae0e28b2c720	which broadcast abstraction captures k-set agreement?		It is well-known that consensus (one-set agreement) and total order broadcast are equivalent in asynchronous systems prone to process crash failures. Considering wait-free systems, this article addresses and answers the following question: which is the communication abstraction that “captures” k-set agreement? To this end, it introduces a new broadcast communication abstraction, called k-BO-Broadcast, which restricts the disagreement on the local deliveries of the messages that have been broadcast (1-BO-Broadcast boils down to total order broadcast). Hence, in this context, k = 1 is not a special number, but only the first integer in an increasing integer sequence. This establishes a new “correspondence” between distributed agreement problems and communication abstractions, which enriches our understanding of the relations linking fundamental issues of fault-tolerant distributed computing. 1998 ACM Subject Classification C.2.4 Distributed Systems – distributed applications, network operating systems, D.4.5 Reliability – fault-tolerance, F.1.1 Models of Computation – computability theory	asynchronous system;computability theory;computation;consensus (computer science);distributed computing;failure detector;fault tolerance;message passing;network operating system;non-blocking algorithm;point of view (computer hardware company);snapshot (computer storage)	Damien Imbs;Achour Mostéfaoui;Matthieu Perrin;Michel Raynal	2017		10.4230/LIPIcs.DISC.2017.27	atomic broadcast;partially ordered set;real-time computing;asynchronous system;broadcast communication network;distributed computing;theoretical computer science;asynchronous communication;computer science;abstraction;broadcasting;integer sequence	Theory	-22.6290986048274	43.8826066534443	106790
46990629bc3c7ef9510a96e428655fc012008677	an effective information service architecture in grid environment	distributed system;algoritmo paralelo;systeme reparti;parallel algorithm;service information;software platform;autonomous system;resource management;logicial personalizado;distributed computing;service web;web service;orientado servicio;sistema autonomo;algorithme parallele;intergiciel;grid;gestion recursos;sistema repartido;rejilla;indexation;systeme autonome;grille;servicio informacion;gestion ressources;calculo repartido;middleware;oriente service;information service;calcul reparti;grid system;servicio web;service oriented	The information service is a vital part of any Grid software platform, providing the fundamental mechanism for discovering and monitoring services and resources in a Grid. This paper presents an effective information service architecture developed for ChinaGrid Support Platform (CGSP). The architecture is based on domains in CGSP, which are autonomous grid systems. The key issues are to collect information of diverse resources within a domain dynamically, and to share these collected data across domains effectively and securely by providing a unique interface based on a delegation method and an index aggregation mechanism.		Huashan Yu;Yin Luo;Xingguo Zhu;Xiaoming Li	2005		10.1007/11573937_30	web service;embedded system;computer science;autonomous system;resource management;middleware;database;distributed computing;parallel algorithm;grid;world wide web	HPC	-28.93517479127895	43.61507758802258	106846
a18f0f54e870059297ed6b5732ccfc7cd467cc2b	join decompositions for efficient synchronization of crdts after a network partition: work in progress report	replication;state synchronization;crdts	State-based CRDTs allow updates on local replicas without remote synchronization. Once these updates are propagated, possible conflicts are resolved deterministically across all replicas. Δ-CRDTs bring significant advantages in terms of the size of messages exchanged between replicas during normal operation. However, when a replica joins the system after a network partition, it needs to receive the updates it missed and propagate the ones performed locally. Current systems solve this by exchanging the full state bidirectionally or by storing additional metadata along the CRDT. We introduce the concept of join-decomposition for state-based CRDTs, a technique orthogonal and complementary to delta-mutation, and propose two synchronization methods that reduce the amount of information exchanged, with no need to modify current CRDT definitions.	conflict-free replicated data type;deterministic algorithm;duplex (telecommunications);network partition	Vitor Enes;Carlos Baquero;Paulo Sérgio Almeida;Ali Shoker	2016		10.1145/2957319.2957374	real-time computing;computer science;theoretical computer science;distributed computing	PL	-23.152320032207722	46.271202769338956	106906
cb173d8aa6c26613e77af1ac224fc8d062a8ec1f	implementing a reflective fault-tolerant corba system	protocols;fault tolerant;separation of concern;distributed fault tolerance reflective fault tolerant corba system non functional mechanisms separation of concerns application programmer metaobject protocols mops fault tolerance mechanisms specialised mop dependability issues compile time reflection;program compilers distributed object management fault tolerant computing protocols;fault tolerant computing;distributed object management;metaobject protocol;fault tolerant systems fault tolerance reflection access protocols runtime java programming profession control systems mechanical factors machinery production industries;point of view;program compilers	The use of reflection becomes today popular for the implementation of non-functional mechanisms such as for fault-tolerance. The main benefits of reflection are separation of concerns between the application and the mechanisms and transparency from the application programmer point of view. Unfortunately, metaobject protocols available today are not satisfactory with respect to necessary features needed for implementing fault tolerance mechanisms. In previous papers, we proposed a specialised MOP, based on Corba, well adapted for such mechanisms. We deliberately focus in this paper on the implementation of this metaobject protocol using compile-time reflection and its use for implementing distributed fault tolerance. We present the design and the implementation of a fault-tolerant Corba system using this metaobject together with some preliminary experimental results. From the lessons learnt from this work, we briefly address the benefits of reflection in other layers of a system for dependability issues.	byzantine fault tolerance;common object request broker architecture;compile time;compiler;dependability;metaobject;programmer;reflection (computer programming);separation of concerns	Marc-Olivier Killijian;Jean-Charles Fabre	2000		10.1109/RELDI.2000.885403	embedded system;communications protocol;fault tolerance;real-time computing;separation of concerns;computer science;operating system;distributed computing;programming language;software fault tolerance	PL	-30.860824224379893	39.31860513759295	107853
255e0381d5032911d736207dcfd669e654d5a71f	automated deployment of enterprise systems in large-scale environments	distributed system;unfolding;entreprise;systeme reparti;systeme grande taille;componente logicial;deploiement;architecture description language;localization;empresa;despliegue;composant logiciel;langage java;large scale system;localizacion;systeme ouvert;dynamical system;systeme dynamique;large scale;sistema repartido;lenguaje descripcion;localisation;internet;firm;software component;lenguaje java;enterprise system;sistema dinamico;open systems;sistema abierto;langage description;sistema gran escala;java language;description language	The deployment of multi-tiered applications in large-scal e environments remains a difficult task: the architecture of these app lications is complex and the target environment is heterogeneous, open and dynam ic. In this paper, we show how the component-based approach simplifies the design , the deployment and the reconfiguration of a J2EE system. We propose an archit ecture description language that allows specifying constraints on the resourc es needed by the components and on their location, and a deployment solution tha t handles failures. Introduction J2EE application servers are complex service-oriented arc hitectures. They are generally deployed on clusters to improve their quality of service. A J2EE cluster is composed of replicated Web and EJB tiers for load balancin g and fault tolerance. A front-end load balancer dispatches the HTTP requests to the containers. In large-scale environments, machines are highly distributed and heterog eneous in terms of software and hardware configurations. Furthermore, these resources can be dynamic. Therefore the resource allocation should be automated and the deploym ent process should automatically take into account the dynamicity of the environme t. We make the assumption that the large-scale environment is structured in zone s and that for each zone are defined some known machines called zone managers whose role is to maintain a list of the machines in the zone and to orchestrate the deployment pr ocess. Deployment system We adopt an architecture-based approach to manage the J2EE system. We wrap system parts into explicitly bound componen ts. The obtained system, calledJonasALaCarte, is based on the Fractal component model. In large-scale environments, we cannot know in advance the t arg t machine for each component of the system. So, in order to specify the deployme nt of a J2EE system, we have added to the Fractal architecture descriptor (that defi nes the architecture of the system in terms of component definitions and component bindi ngs) adeployment descriptor, that contains, for each component, the description of the r esources that the target platform must satisfy, and references to component i nstances. The deployment descriptor lists all the constraints that a hosting machine as to verify.Resource constraints allow hardware and software needs to be represented, and location constraints make it possible to control the placement of a component when more than one host apply for its hosting. These constraints are solved thanks to o ur deployment process that allows, additionally, the recovery from failures. Deployment process For each zone in the environment, a zone manager maintains the list of the machines in the zone that may host the J2EE syst em components. This zone manager is given the architecture and deployment descr iptors by an administrator. It then multicasts them to the zone nodes. Each node checks th e compatibility of its local resources with the resources required for each compon ent. If it satisfies all the resource constraints associated with a component, it sends to the manager its candidature for the instantiation of this component. The manager re ceiv s several candidatures and tries to compute a placement solution in function of the l ocation constraints and the candidatures. The manager updates the deployment descr iptor with the new placement information and broadcasts it to all the zone nodes. Eac h node that receives the new deployment descriptor updates its own one and is thus inf ormed of which components it is authorized to instantiate and of the new location of the other components. The final step consists in downloading necessary packages fr om well defined package repositories whose location is defined in the deployment des criptor. The steps described above define a propagative deployment, that is, necessary components for running J2EE applications can be instantiated a nd started without waiting for the deployment of all the components. As soon as a resourc e be ome available or a machine offering new resources enters the network, candida tures for the installation of the “not yet installed” components will make the deployment progress. Some preliminary experiments we have conducted on a prototy pe implementation show that the performance of the resource observation and th e constraint solving remain acceptable even for a large number of non trivial resource co nstraints. Automatic recovery from failures In the environment we target, resources can also become unavailable, some parts of the J2EE system can be faul ty and some machine may fail. In this work, we consider silent failures. When a co mponent does not respond to a method call or a request within a timeout, the node detect ing the failure sends to the zone manager a message holding the identity of the compon ent to redeploy. Then, the zone manager updates the deployment descriptor by remov ing the location of the component and broadcasts the new descriptor to all the machi nes connected in the zone. This automates the redeployment of the faulty component sin ce all the machines find themselves back in the propagative deployment described ab ove. Specific actions are carried out in the case of the failure of r eplicated components (eg EJB container and Web container services) or zone manage rs, exploiting group communication and temporary storage of incoming requests. Conclusion The work described in this paper proposes a solution for the d eployment of enterprise systems in large-scale environments. Our mai n contribution consists in the following points. First, the deployment system is resou rce-aware and the constraint resolution is performed in a reasonable time. Second, the de ployment task is simplified since the administrator role is reduced to writing a deploym ent descriptor. All the deployment process and the recovery from failures are automat ed. Finally, we maintain the performability of the system since we maintain the struc ture described in the architecture descriptor by replacing each time a faulty componen t by another. This allows assuring the continuity of Internet services and maintaini ng their quality of service.	application server;authorization;component-based software engineering;computer cluster;constraint satisfaction problem;download;dynamic dispatch;enterprise javabeans;enterprise system;experiment;fault tolerance;fractal component model;java platform, enterprise edition;load balancing (computing);method (computer programming);quality of service;scott continuity;service-oriented device architecture;software deployment;system deployment;timeout (computing);universal instantiation;web container	Takoua Abdellatif;Didier Hoareau;Yves Mahéo	2006		10.1007/11915034_14	embedded system;architecture description language;enterprise system;the internet;simulation;internationalization and localization;deployment diagram;computer science;component-based software engineering;operating system;dynamical system;database;open system;programming language;software deployment	OS	-29.391323708066682	42.28455910162891	108225
9cdd897408094f150886cefe415948fd64df9a75	region-based memory management for a dynamically-typed language	lenguaje programacion;ml language;dynamic typing;gestion memoire;theorie type;compilateur;memory management;programming language;langage type;langage ml;storage management;ramasse miettes;region based memory management;compiler;garbage collection;recogemigas;gestion memoria;type theory;typed language;garbage collector;inferencia;langage programmation;memory allocation;type inference;inference;compilador;lenguaje tipado;type system	Region-based memory management scheme has been proposed for programming language ML. In this scheme, a compiler statically estimates the live range of each object by performing an extension of type inference (called region inference) and inserts code for memory allocation and deallocation. Advantages of this scheme are that memory objects can be deallocated safely (unlike with manual memory management using malloc/free) and often earlier than with run-time garbage collection. Since the region inference is an extension of the ML type inference, however, it was not clear whether the region-based memory management was applicable to dynamically-typed programming languages like Scheme. In this paper, we show that the region-based memory management can be applied to dynamically-typed languages by combining region inference and Cartwright et al.’s soft type system.	c dynamic memory allocation;compiler;garbage collection (computer science);manual memory management;programming language;region-based memory management;register allocation;scheme;type inference;type system	Akihito Nagata;Naoki Kobayashi;Akinori Yonezawa	2004		10.1007/978-3-540-30477-7_16	manual memory management;shared memory;parallel computing;type system;region-based memory management;obstack;computer science;artificial intelligence;operating system;static memory allocation;database;overlay;extended memory;flat memory model;garbage collection;programming language;algorithm;memory leak;memory map;memory management	PL	-20.483129597010418	33.343647492831266	108241
1739f0fa8974708a6029f51a797879e68505906e	static timing analysis of real-time operating system code	systeme temps reel;anotacion;metodo caso peor;sistema operativo;occupation time;evaluation performance;critical region;performance evaluation;analyse statique;sistema temporizado;execution time;product code;evaluacion prestacion;metodo formal;timed system;methode formelle;real time operating system;annotation;analyse temporelle;region critica;optimizacion compiladora;program verification;analisis temporal;analisis estatica;time analysis;formal method;upper bound;verificacion programa;engineering and technology;worst case execution time;teknik och teknologier;temps occupation;operating system;compiler optimization;tiempo ocupacion;methode cas pire;systeme temporise;static timing analysis;temps execution;systeme exploitation;real time system;sistema tiempo real;static analysis;tiempo ejecucion;borne superieure;verification programme;worst case method;optimisation compilateur;region critique;cota superior	Methods for Worst-Case Execution Time (WCET) analysis have been known for some time, and recently commercial tools have emerged. However, the technique has so far not been much used to analyse real production codes. Here, we present a case study where static WCET analysis was used to find upper time bounds for time-critical regions in a commercial real-time operating system. The purpose was not primarily to test the accuracy of the estimates, but rather to investigate the practical difficulties that arise when applying the current WCET analysis methods to this particular kind of code. In particular, we were interested in how labor-intense the analysis becomes, measured by the number of annotations to explicitly constrain the program flow which is necessary to perform the analysis. We also make some qualitative observations regarding what a WCET analysis method would need in order to perform a both convenient and tight analysis of typical operating systems code. In a second set of experiments, we analyzed some standard WCET benchmark codes compiled with different levels of optimization. The purpose of this study was to see how the different compiler optimizations affected the precision of the analysis, and again whether it affected the level of user intervention necessary to obtain an accurate	benchmark (computing);code;control flow;experiment;mathematical optimization;optimizing compiler;real-time clock;real-time operating system;real-time transcription;static timing analysis;window of opportunity;worst-case execution time	Daniel Sandell;Andreas Ermedahl;Jan Gustafsson;Björn Lisper	2004		10.1007/11925040_10	statistical hypothesis testing;real-time computing;simulation;real-time operating system;computer science;optimizing compiler;universal product code;upper and lower bounds;programming language;static timing analysis;static analysis;algorithm;worst-case execution time	Embedded	-22.802437202054946	36.150067251531986	108251
1eb4e754d9b79f0806667302801fc9a0b50f88af	providing persistent objects in distributed systems	distributed system;systeme reparti;procesamiento informacion;client server architecture;architecture client serveur;object oriented programming;performance programme;sistema repartido;distributed environment;information processing;persistent object store;arquitectura cliente servidor;eficacia programa;program performance;information system;traitement information;programmation orientee objet;systeme information;sistema informacion	THOR is a persistent object store that provides a powerful programming model. THOR ensures that persistent objects are accessed only by calling their methods and it supports atomic transactions. The result is a system that allows applications to share objects safely across both space and time. The paper describes how the THOR implementation is able to support this powerful model and yet achieve good performance, even in a wide-area, large-scale distributed environment. It describes the techniques used in THOR to meet the challenge of providing good performance in spite of the need to manage very large numbers of very small objects. In addition, the paper puts the performance of THOR in perspective by showing that it substantially outperforms a system based on memory mapped files, even though that system provides much less functionality than THOR.	computer data storage;concurrency (computer science);concurrency control;distributed computing;experiment;high-availability cluster;logical disk manager;memory-mapped i/o;object storage;overhead (computing);persistence (computer science);persistent object store;phillip rogaway;programming model;tom gruber	Barbara Liskov;Miguel Castro;Liuba Shrira;Atul Adya	1999		10.1007/3-540-48743-3_11	embedded system;real-time computing;simulation;information processing;computer science;operating system;database;distributed computing;programming language;object-oriented programming;computer security;information system;client–server model;distributed computing environment	PL	-27.304695672999742	43.79720748010246	108504
6665d99545c8dd2f53cb8f4982b8ead14fc66d15	a portable run-time system for the hermes distributed programming language			distributed computing;programming language	David F. Bacon;Andy Lowry	1990			programming language;programming language implementation;computer science	PL	-22.852676529137348	33.89621612169714	108522
0f4dc8cda5dec43507af46f34c8b82cdc6f665e6	fail-awareness: an approach to construct fail-safe systems	distributed system;crash failure;synchronous systems;real time;fail awareness;safety properties;synchronous system;upper bound;commercial off the shelf;timed asynchronous systems;asynchronous distributed system;fail safe systems;communication service;hard real time	We present a framework for building fail-safe hard real-time applications in timed asynchronous distributed systems subject to communication partitions and performance, omission, and crash failures. Most distributed systems built from commercial-off-the-shelf (COTS) processor and communication services are subject to such partitions because their COTS components do not provide hard real-time guarantees. Also custom designed systems can be subject to partitions due to unmaskable link or router failures. The basic assumption behind our approach is that each processor has a local hardware clock that proceeds within a linear envelope of real-time. This allows one to compute an upper bound on the actual delays incurred by a particular processing sequence or message transmission. Services and applications can use these computed bounds to detect when they cannot guarantee all their standard properties because of excessive delays. This allows an application to be fail-aware, that is, to detect when it cannot guarantee all its safety properties and in particular, to detect when to switch to a fail-safe mode.	distributed computing;fail-safe;real-time clock;real-time computing;router (computing)	Christof Fetzer;Flaviu Cristian	2003	Real-Time Systems	10.1023/A:1021730519625	embedded system;real-time computing;computer science;operating system;distributed computing;upper and lower bounds	Embedded	-24.38650420123139	44.47567744592904	108595
4d0f5b61f87144041e45b217ced896b01d073ff8	the power of logical clock abstractions	distributed system;clocks;time;knowledge;concurrency;asynchronous distributed system;logical time;causality	Vector and matrix clocks are extensively used in asynchronous distributed systems. This paper asks, “how does the clock abstraction generalize?” To address this problem, the paper motivates and proposes logical clocks of arbitrary dimensions. It then identifies and explores the conceptual link between such clocks and knowledge. It establishes the necessary and sufficient conditions on the size and dimension of clocks required to attain any specified level of knowledge about the timestamp of the most recent system state for which this is possible without using any messages in the clock protocol. The paper then gives algorithms to determine the timestamp of the latest system state about which a specified level of knowledge is attainable in a given system state, and to compute the timestamp of the earliest system state in which a specified level of knowledge about a given system state is attainable. The results are applicable to applications that deal with a certain class of properties, identified as monotonic properties.	algorithm;distributed computing;logical clock;matrix clock	Ajay D. Kshemkalyani	2003	Distributed Computing	10.1007/s00446-003-0105-9	clock synchronization;embedded system;real-time computing;causality;concurrency;vector clock;computer science;theoretical computer science;distributed computing;knowledge;matrix clock;algorithm	Embedded	-23.443858871111818	42.42596431799175	108728
c45d47c619b60ed76f6c6376fa51120e9c85f733	security properties consistent with the testing semantics for communicating processes	acceptance trees;testing security humans system recovery carbon capture and storage computational modeling distributed computing printers tv process control;denicola hennessy theory;printers;testing equivalence;labeled transition systems;formal testing semantics;distributed computing;testing;information flows;computational modeling;system recovery;security theory;specification languages;carbon capture and storage;process control;denotational model;humans;tv;testing information theory security of data specification languages;security;communicating processes;security of data;information theory;information flows security theory denotational model acceptance trees labeled transition systems testing equivalence specification languages communicating processes formal testing semantics denicola hennessy theory	A theory of security that is based on specification languages for communicating processes and the formal testing semantics for such languages is developed. The DeNicola-Hennessy theory of testing semantics for processes as presented by M. Hennessy (Algebraic Theory of Processes, MIT Press, Cambridge, MA, 1988) is reviewed in some detail. The theory is then applied to the analysis of certain information flows. >		Dale M. Johnson;F. Javier Thayer	1989		10.1109/CSFW.1989.40582	action semantics;computer science;theoretical computer science;communicating sequential processes;formal semantics;programming language;operational semantics;denotational semantics	Logic	-31.527436744516717	32.50493676536499	108753
3cd1d12ecb820f6420e07e7bdeff5444b5fcd708	increasing the performance and predictability of the code execution on an embedded java platform (ansätze zur steigerung der leistungsfähigkeit und vorhersagbarkeit der codeausführung auf einer eingebetteten java-plattform)		This thesis explores the execution of object-oriented code on an embedded Java platform. It presents established and derives new approaches for the implementation of high-level objectoriented functionality and commonly expected system services. The goal of the developed techniques is the provision of the architectural base for an efficient and predictable code execution. The research vehicle of this thesis is the Java-programmed SHAP platform. It consists of its platform tool chain and the highly-customizable SHAP bytecode processor. SHAP offers a fully operational embedded CLDC environment, in which the proposed techniques have been implemented, verified, and evaluated. Two strands are followed to achieve the goal of this thesis. First of all, the sequential execution of bytecode is optimized through a joint effort of an optimizing offline linker and an on-chip application loader. Additionally, SHAP pioneers a reference coloring mechanism, which enables a constant-time interface method dispatch that need not be backed a large sparse dispatch table. Secondly, this thesis explores the implementation of essential system services within designated concurrent hardware modules. This effort is necessary to decouple the computational progress of the user application from the interference induced by time-sharing software implementations of these services. The concrete contributions comprise a spill-free, on-chip stack; a predictable method cache; and a concurrent garbage collection. Each approached means is described and evaluated after the relevant state of the art has been reviewed. This review is not limited to preceding small embedded approaches but also includes techniques that have proven successful on larger-scale platforms. The other way around, the chances that these platforms may benefit from the techniques developed for SHAP are discussed.	dispatch table;dynamic dispatch;embedded java;embedded system;garbage collection (computer science);graph coloring;high- and low-level;interference (communication);online and offline;sparse matrix;time-sharing;toolchain	Thomas B. Preußer	2011				PL	-22.921854391831168	34.90404222605856	108948
0a37687b359ea990386662ef89d85ddc82d2fb49	towards an understanding of the behavior of the single parent rule in the rtsj scoped memory model	formal specification;efficient algorithm;storage management;real time specification for java;scoped regions;garbage collection;formal verification;write barriers;storage management real time systems formal specification java formal verification;real time java;write barriers real time java scoped regions garbage collection;java safety;memory model single parent rule real time specification java rtsj;java;real time systems;memory model	The memory model used in the real-time specification for Java (RTSJ) imposes strict assignment rules to or from memory areas preventing the creation of dangling pointers, and thus maintaining the pointer safety of Java. An implementation solution to ensure the checking of these rules before each assignment statement consists of performing it dynamically by using write barriers. This solution adversely affects both the performance and predictability of the RTSJ application. In this paper we present an efficient algorithm for managing scoped regions which requires some modifications in the current RTSJ specification.	algorithm;assignment (computer science);augmented assignment;dangling pointer;imperative programming;memory model (programming);pointer (computer programming);race condition;real-time transcription;text simplification;víctor neumann-lara	M. Teresa Higuera-Toledano	2005	11th IEEE Real Time and Embedded Technology and Applications Symposium	10.1109/RTAS.2005.56	memory model;real-time computing;formal verification;computer science;operating system;formal specification;real time java;garbage collection;programming language;java	Embedded	-20.75429484220639	34.70684532641412	108959
18388aa898b177cfb38f9828d3f0184e32555b19	design and implementation of a distributed agent delivery system	distributed application;distributed system;systeme intelligent;systeme reparti;delivery system;red www;distributed agents;sistema informatico;sistema inteligente;information technology;distributed computing;computer system;technologie information;computer network;sistema repartido;design and implementation;distributed environment;reseau informatique;intelligent system;world wide web;systeme informatique;reseau www;mobile agent;tecnologia informacion;wide area network	Among the most significant changes that have affected the domain of computer networking is the proliferation of distributed applications and services, particularly within wide-area networks such as corporate intranets and most notably within the Internet. As the demand for such applications and services continues to expand, the need for a generic, open solution facilitating the distribution of data and services becomes increasingly apparent. Researchers have recently begun to investigate the feasibility of using the Mobile Agents Paradigm as an integral part of distributed computing infrastructures. In addition to facilitating the exchange of data and the access to services, agents serve as abstractions that separate the communication of data from the location and format of data that is transferred among the nodes of the distributed environment. This paper discusses the goals, design and implementation of a particular multilingual mobile agent development kit, the Distributed Agent Delivery System (DADS). DADS supports multiple agent languages types, and is deemed sufficiently lightweight to be deployed in performance-sensitive environments. DADS thus provides the fundamental mechanisms for the development of distributed applications that would scale well with the ever-increasing size and complexity of modern distributed infrastructures.		Stephen A. Hopper;Armin R. Mikler;John T. Mayes	2000		10.1007/3-540-45111-0_22	embedded system;simulation;computer science;operating system;mobile agent;database;distributed computing;information technology;computer security;distributed computing environment	Robotics	-28.8141163511525	44.16753325746277	108969
146f9321d3c2237079fcbd2e2f80bb81c776315f	a java based framework for off-line collaboration	collaborative work;java programming;design and implementation;scientific computing;geographic distribution	This paper describes a framework that supports a collaborative work environment for scientific computing. Implemented using the Java programming language, the framework allows teams of researchers to collectively visualize and analyze the results of graphs, diagrams, pictures, etc. in an off-line collaborative setting. The framework allows participants to load a diagram, or other graphic object, into workspace and make annotations to this document. These activities will not be carried out simultaneously, but rather each participant will work in tandem, with participants being able to view prior annotations. This off-line method of collaboration involves pulling together these ideas and separate efforts. Using this type of collaborative working method, geographically distributed users are able to visualize results on their own workstation as well as tracking and steering the results of their research counterparts. This project covers the design and implementation of this framework for off-line collaboration.	computational science;diagram;java;online and offline;programming language;workspace;workstation	Azzari Caillier Jarrett;R. Raymond Lang	2000		10.1145/1127716.1127746	human–computer interaction;computer science;database;distributed computing	HCI	-31.206700679261377	40.1573252472788	109445
0f56251df7506dd3233987af1b882a727d9142f7	more ambiguities and insecurities in modula-2	programming language;real time processing;industrial robots;language development	This paper contains this author's additions to the llst of concerns relating to the Modula-2 language and its definition. My experience with Modula-2 is based on three years of almost exclusive use of the Modula-2 language as a systems programming language to implement Modula-2 compilers and language development systems and as a real-time process control language to control industrial robots. I must say that my experience has been nothing but positive! However, in the course of using Modula-2 in various contexts, certain areas of the language have been identified whloh could benefit from minor refinements and/or clarification.	compiler;industrial robot;modula-2;real-time cmix;system programming language	Michael A. Torbett	1987	SIGPLAN Notices	10.1145/25267.25269	natural language processing;very high-level programming language;computer science;programming language	PL	-24.08412658837217	32.9629889203869	109488
8cdbedc491cf77b0a57008108ea7f4c05cc5660e	indexing in an actor-oriented database		Many of today’s interactive server applications are implemented using actor-oriented programming frameworks. Such applications treat actors as a distributed in-memory object-oriented database. However, actor programming frameworks offer few if any database system features, leaving application developers to fend for themselves. It is challenging to add such features because the design space is different than traditional database systems. The system must be scalable to a large number of servers, it must work well with a variety of cloud storage services, and it must integrate smoothly with the actor programming model. We present the vision of an actor-oriented database. We then describe one component of such a system, to support indexed actors, focusing especially on details of the fault tolerance design. We implemented the indexing component in the Orleans actororiented programming framework and present the result of initial performance measurements.	actor model;cloud storage;fault tolerance;in-memory database;programming model;scalability;server (computing);smoothing	Philip A. Bernstein;Mohammad Dashti;Tim Kiefer;David Maier	2017			database catalog;database;computer science;search engine indexing;database search engine;database design	DB	-29.634584552173788	45.07406209716334	109540
68f0529051c83fb26e6989230bc53770e72c6eac	component file systems and the apl standard	component file system;apl standard	The lS0 APL Standards working group, ISO/TC97/SC5/WG6, has begun work on creation of a new standard for Extended APL, including specification of a component file system. It is the opinion of the authors that, although such standardization is desirable, existing file systems which might serve as the basis for such a standard (such as the SHARP APL file system) are a reflection of the design principles of twenty years ago. and fail to address problems such as parallelism and concurrency, database atomicity, increased reliability needs, and combining of independently-written application programs.	apl;atomicity (database systems);concurrency (computer science);parallel computing	Robert Bernecky;Maxine Hersch	1987		10.1145/28315.28339	indexed file;device file;computer file;zap file;computer science;class implementation file;versioning file system;operating system;fstab;unix file types;database;open;file format;design rule for camera file system;file control block;virtual file system	PL	-27.50579833708007	39.1599366405822	109554
5ec95034384e43ba35a0a12ea2e2a1dabb1625a5	platform independent user interface builders: where are we headed?	user interface;cscw;user interface management systems;synchronous groupware;constraint maintenance	Platform independence means that a user interface can be specified and created using a particular combination of hardware, operating system, and windowing environmen~ that single specification can then be recompiled without intervention (ideally) to run on an entirely heterogeneous combination/platform. This is a remarkable feat even considering alone the differences among windowing environments (Motif, Windows, Macintosh), operating systems (various Unix, DOS, Macintosh), or hardware (Sun, HP, DEC, IBM PC/compatible, Macintosh).	dos;ibm pc compatible;ibm personal computer;microsoft windows;motif;operating system;unix;user interface	Richard Chimera;Jeff Barr;Martin Brunecky;Randy F. Pausch;Alain T. Rappaport	1993		10.1145/168642.168666	user interface design;user;real-time computing;interface metaphor;shell;human–computer interaction;natural language user interface;computer science;operating system;computer-supported cooperative work;distributed computing;natural user interface;user interface;multiple document interface	OS	-29.293432736361193	40.0912774258714	109638
70fdcc68a209ef5c3615954011d704364cb2a466	making weak consistency great again	weak consistency;crdt;geo replication	This paper focuses on the problem of implementing web applications on top of weakly consistent geo-replicated systems. Several techniques, such as CRDTs, have been proposed to achieve state convergence on a per-object and per-data type basis. However, that does not guarantee application correctness, as convergence rules applied individually at each object may lead to an invalid state.  We advocate that it is possible to address these problems and implement correct applications under weak consistency. To that end, it is necessary to combine CRDTs with novel semantics, judiciously select the CRDTs that are used by applications, and transform application operations to guarantee that convergence rules, applied on a per-object basis, always lead to valid application states. Achieving this is complex and requires tools to help programmers tame the complexity of programming on top of weak consistency and make the technology more accessible.  In the presentation of this work we make a demonstration of a prototype tool that is capable of detecting concurrency conflicts on applications and propose transformations to make them conflict-free.	concurrency (computer science);correctness (computer science);programmer;prototype;sensor;state (computer science);tame;weak consistency;web application	Valter Balegas;Sergio N. Duarte;Carla Ferreira;Nuno M. Preguiça;Rodrigo Rodrigues	2016		10.1145/2911151.2911167	weak consistency;computer science;data mining;distributed computing;algorithm	PL	-26.99659547503463	34.70804374853282	109887
eb3ebb0edc79ae072a1b23858aa32c3e855a9044	an integrated data structure with multiple access paths for database systems and its performance	hachage;modelizacion;eficacia sistema;acceso multiple;sistema multiple;database system;gestion memoire;base donnee;acces multiple;storage management;simulation;performance systeme;database;base dato;access path;simultaneidad informatica;multiple system;estructura archivo;simulacion;system performance;extendible hashing;modelisation;gestion memoria;concurrency;hashing;indexation;estructura datos;structure fichier;file structure;concurrent transaction;analyse transactionnelle;structure donnee;multikey;b tree;transaction processing;multiple access;grid file;modeling;simultaneite informatique;database management system;data structure;simulation model;transactional analysis;analisis transaccional;systeme multiple	Abstract   In the past a number of file organizations have been proposed for processing different types of queries efficiently. To our knowledge none of the existing file organizations is capable of supporting all types of accesses equally efficiently. In this paper we have taken a different approach for designing an integated data structure which offers multiple access paths for processing different types of queries efficiently. The data structure reported here can be implemented on disk based as well as main memory database systems, however, in this paper we report its behavior mainly in main memory database environment. Our approach is to fuse those data structures which offer an efficient access paths for a particular type. To show the feasibility of our scheme we fused the B + -tree, the grid file and extendible hashing structures, using a proper interface. We implemented and measured its performance through simulation modeling. Our results show that the data structure does improve concurrency and offers a higher throughput for a variety of transaction processing workloads. We argue that our scheme is different than creating secondary indexes for improving concurrency. In the absence of a data strucure which can provide all types of access equally efficiently, an integrated data structure is an acceptable solution which offers an efficient way for increasing the performance of database management systems.	data structure	Vijay Kumar;Judy Mullins	1995	Data Knowl. Eng.	10.1016/0169-023X(95)00009-H	b-tree;grid file;real-time computing;hash function;systems modeling;extendible hashing;concurrency;data structure;transaction processing;computer science;operating system;simulation modeling;data mining;database;transactional analysis;file format;programming language	DB	-19.759414260346254	46.11783286467207	110201
0900d18f28dfce5fc51667a25fd31e8a5402f862	abs: a core language for abstract behavioral specification	publikationer;konferensbidrag;artiklar;rapporter	This paper presents ABS, an abstract behavioral specification language for executable designs of distributed object-oriented systems. The language combines advanced concurrency and synchronization mechanisms for concurrent object groups with a functional language for modeling data. ABS uses asynchronous method calls, interfaces to enforce encapsulation, and cooperative scheduling of method activations inside concurrent objects. This feature combination results in a concurrent object-oriented model which is inherently compositional. This paper discusses central design issues for ABS and formalizes the type system and semantics of Core ABS, a calculus with the main features of ABS. For Core ABS, we prove a subject reduction property which shows that well-typedness is preserved by execution; in particular that method not understood errors do not occur at runtime for well typed ABS models. Finally, we briefly discuss the tool support developed for ABS.	actor model;asynchronous i/o;audio feedback;computer multitasking;concurrency (computer science);data structure;distributed computing;distributed object;domain-specific language;ecoop;effect system;encapsulation (networking);executable;forward error correction;functional programming;futures and promises;imperative programming;java;journal of logical and algebraic methods in programming;kramer graph;lecture notes in computer science;object constraint language;operational semantics;plotkin bound;programming tool;rewriting;run time (program lifecycle phase);scheduling (computing);situated;specification language;springer (tank);subject reduction;symposium on principles of programming languages;type safety;type system;types and programming languages;uppaal;unified model;unified modeling language;π-calculus	Einar Broch Johnsen;Reiner Hähnle;Jan Schäfer;Rudolf Schlatte;Martin Steffen	2010		10.1007/978-3-642-25271-6_8	real-time computing;computer science;distributed computing;programming language	PL	-29.35061530971554	32.66210015127245	110978
9b699fd07848490f17c794db00197b28efed18d1	comparison of failure detectors and group membership: performance study of two atomic broadcast algorithms	detectors;protocols;performance evaluation;fault tolerant;computer crashes;building block;benchmark;simulation;fault tolerant distributed systems;performance study;fault tolerant systems;failure detector;fault tolerance;performance analysis;atomic broadcast;group membership;agreement problem;computer science;broadcasting;methodology;algorithm design and analysis;detectors broadcasting computer crashes protocols performance analysis delay fault tolerant systems fault tolerance computer science algorithm design and analysis;steady state	Protocols that solve agreement problems are essential building blocks for fault tolerant distributed systems. While many protocols have been published, little has been done to analyze their performance, especially the performance of their fault tolerance mechanisms. In this paper, we present a performance evaluation methodology that can be generalized to analyze many kinds of fault-tolerant algorithms. We use the methodology to compare two atomic broadcast algorithms with different fault tolerance mechanisms: unreliable failure detectors and group membership. We evaluated the steady state latency in (1) runs with neither crashes nor suspicions, (2) runs with crashes and (3) runs with no crashes in which correct processes are wrongly suspected to have crashed, as well as (4) the transient latency after a crash. We found that the two algorithms have the same performance in Scenario 1, and that the group membership based algorithm has an advantage in terms of performance and resiliency in Scenario 2, whereas the failure detector based algorithm offers better performance in the other scenarios. We discuss the implications of our results to the design of fault tolerant distributed systems.	algorithm;atomic broadcast;distributed computing;failure detector;fault tolerance;performance evaluation;sensor;steady state	Péter Urbán;Ilya Shnayderman;André Schiper	2003		10.1109/DSN.2003.1209974	fault tolerance;real-time computing;computer science;distributed computing;computer security;computer network	Arch	-21.645229780416713	45.983833728548305	110992
392bc9539df1814fd442e94d67d2509e25173bd6	testing attribute-based transactions in soc	service orientation;distributed transactions;qa 76 software;computer programming	We set the basis for a theory of testing for distributed transactions in service oriented systems where each service definition is decorated with a transactional attribute (inspired by the Java Transaction API). Transaction attributes discipline how services are executed with respect to the transactional scope of the invoking party. We define a language of observers and show that, in general, the choice of different transactional attributes causes different system’s behaviours wrt the testing equivalences induced by the observers.	application programming interface;distributed transaction;java transaction api;theory;transaction processing	Laura Bocchi;Emilio Tuosto	2010		10.1007/978-3-642-13464-7_8	transactional memory;real-time computing;distributed transaction;computer science;computer programming;database;distributed computing;programming language;serializability	DB	-31.341012366515212	34.05474684284863	111461
693f257f937746e8db4a28a82f0511a6d16b8053	a rigorous approach to fault-tolerant programming	stochastic modeling;reliability;fault tolerant;availability;storage management;correctness;fault tolerant system;fault tolerance;stochastic model;fault tolerance hardware logic programming stochastic processes computer crashes availability stochastic systems design methodology fault tolerant systems software systems;stochastic modeling availability correctness fault tolerance programming logic reliability;programming logic;random times	The design of programs that are tolerant of hardware fault occurrences and processor crashes is investigated. Using a stable storage management system as a running example, a new approach is suggested for specifying, understanding, and verifying the correctness of fault-tolerant software. The approach extends previously developed axiomatic reasoning methods to the design of fault-tolerant systems by modeling faults as being operations that are performed at random time intervals on any computing system by the system's adverse environment.	axiomatic system;correctness (computer science);fault tolerance;fault-tolerant computer system;fault-tolerant software;hierarchical storage management;processor register;stable storage;verification and validation	Flaviu Cristian	1985	IEEE Transactions on Software Engineering	10.1109/TSE.1985.231534	reliability engineering;fault tolerance;real-time computing;n-version programming;computer science;stuck-at fault;fault model;distributed computing;programming language;software fault tolerance	SE	-23.24551317362335	41.09532001655274	111497
a6e17716b2a50585c972610c6b3f43e65465435b	comparative design validation based on event pattern mappings	hardware design languages;discrete event simulation high level synthesis specification languages hardware design languages large scale integration laboratories pattern recognition design methodology registers computer architecture;total order;top down;specification language;computer architecture;high level synthesis;parallel computer architecture;large scale integration;registers;specification languages;levels of abstraction;pattern recognition;hardware design;register transfer level;design methodology;discrete event simulation;partial order	This paper proposes a new methodology for performing comparative validation between two specifications of a system at different levels of abstraction. The methodology consists of two steps : extracting a high-level simulation from a low-level simulation by recursively recognizing and naming patterns of events, and compare the extracted simulation to a high-level simulation. This paper introduces a new semantics for high-level simulation (partial order with duration events), describes a new algorithm to compare an extracted simulation (total order with duration events) and a high-level simulation, and lists performance results of the comparison algorithm.	algorithm;asynchronous system;error message;high- and low-level;principle of abstraction;recursion;simulation	Benoit A. Gennart	1993	30th ACM/IEEE Design Automation Conference	10.1145/157485.164936	partially ordered set;embedded system;computer architecture;design methods;specification language;computer science;theoretical computer science;discrete event simulation;operating system;top-down and bottom-up design;processor register;high-level synthesis;programming language;register-transfer level;total order;algorithm	EDA	-33.04624249011381	33.081018677805204	111512
716976a70a6be2f3015d2665f918cfceba9df9e4	design and implementation of middleware for context-aware service discovery in ubiquitous computing environments	sensibilidad contexto;agent platform;utilisation information;uso informacion;multiagent system;context aware;informatique mobile;hospital;context information;service information;information use;pervasive computing;authentication;service web;intelligence artificielle;user preferences;web service;authentification;intergiciel publication souscription;service utilisateur;informatica difusa;hopital;autenticacion;context aware service;intergicial editor suscriptor;design and implementation;informatique diffuse;comportement utilisateur;servicio informacion;artificial intelligence;middleware;inteligencia artificial;user behavior;information service;servicio usuario;service discovery;sensibilite contexte;user service;sistema multiagente;mobile computing;publish subscribe middleware;comportamiento usuario;servicio web;systeme multiagent;ubiquitous computing environment	The purpose of service discovery techniques is to minimize the cost of detecting services and provide users with convenience, even though various devices and services exist. For more dynamic and useful service discovery, middleware for context-aware service discovery is required. In this paper, a middleware system is designed and implemented, based on the agent platform for context-aware service discovery. When a service is detected, context information relating to the user and environment is used. As a policy-based system, our middleware does not only use context information, but also use predefined policy. In other words, user preference can be considered. Also, it has authentication module, so users having authority can only access the middleware. Near the conclusion of this paper, a hospital scenario is composed and implemented, by applying the proposed middleware solution.		Kyu Lee;Hyung-Jun Kim;Ho-Jin Shin;Dong Ryeol Shin	2006		10.1007/11751632_53	middleware;computer science;message oriented middleware;operating system;middleware;authentication;database;service discovery;mobile computing;world wide web;computer security	Mobile	-29.908695198137966	43.30999711503753	111633
c5c9c1e48074944815b38ca8762fefb4ec95b042	a p2p approach to classloading in java	estensibilidad;internet protocol;distributed system;virtual machine;multiagent system;reseau pair;systeme reparti;protocole transmission;protocolo internet;publisher subscriber middleware;java virtual machine;protocole internet;distributed computing;p2p;langage java;machine virtuelle;protocole tcp;transmission control protocol;protocolo transmision;igual a igual p2p;sistema repartido;protocolo tcp;intergiciel editeur souscripteur;calculo repartido;lenguaje java;arquitectura publicacion suscripcion;extensibilite;scalability;sistema multiagente;peer to peer;maquina virtual;calcul reparti;systeme multiagent;java language;transmission protocol	The Classloader has long been one of the key extensibility points of the Java Virtual Machine architecture. It lies at the heart of many of the distributed mechanisms that have made the Java platform so successful. In this paper we give a brief overview of various distributed system technologies and analyze their applicability within a Peer-to-Peer domain. We propose a new architecture for remote loading of classes based on the Peer-to-Peer paradigm. This solution incorporates some novel approaches, addressing many of the problems inherent in current solutions. We also discuss our reference implementation of this approach over both traditional TCP/IP and JXTA based networks.	diagram;distributed computing;extensibility;internet protocol suite;jxta;java classloader;java virtual machine;peer-to-peer;programming paradigm;reference implementation;requirement;scalability;technical standard;unified modeling language	Daryl Parker;David Cleary	2003		10.1007/978-3-540-25840-7_15	internet protocol;embedded system;real-time computing;scalability;computer science;virtual machine;operating system;transmission control protocol;peer-to-peer;distributed computing	DB	-28.650187072619175	42.31420435955573	111796
41c69a079e2479715101cf5730f4dc96f45f674d	a flexible two-phase commit protocol	distributed system;systeme reparti;protocole transmission;sistema informatico;conception;estrategia;transmission message;computer system;probleme terminaison;message transmission;strategy;protocolo transmision;sistema repartido;diseno;termination problem;design;systeme informatique;two phase commit;strategie;problema terminacion;transmision mensaje;transmission protocol	Abstract Even though the two-phase commit protocol is a well-known protocol terminating transactions (atomic actions) in a general distributed environment, nearly all descriptions of the protocol refer to special instances of communication, mostly to distributed databases, and therefore cover only a small range of the possible forms of the protocol. In this paper a flexible two-phase commit protocol for distributed transaction processing trees is presented that permits a free choice of the commit-coordinator and independently a free choice of one or more commit-initiators. The protocol is designed to allow each node of the tree to initiate termination of the transaction based on its own termination conditions and without regard for a hierarchy, but to maintain the essentials of a central site two-phase commit. Since the protocol permits a wide variety of different termination strategies, exceptional techniques such as “nested two-phase commit”, “last agent optimisation” and “inverted tree” can be regarded as specialisations of this protocol. Such techniques are under discussion within the international standardisation organisation ISO as extensions to the rather restrictive commit protocol currently used in the OSI transaction processing standardisation project.		Uwe Bürger	1989	Computer Networks	10.1016/0169-7552(89)90081-0	three-phase commit protocol;design;two-phase commit protocol;telecommunications;strategy;computer science;computer security	Theory	-22.144979394560284	46.37318201184487	112359
1ea311efcec6e08e211be74e6a824f876238f19d	reliability and performance analysis for fault-tolerant programs consisting of versions with different characteristics	reliability;fault tolerant;fault tolerant programming;performance;software systems;functional equivalence;expected execution time;performance analysis;n version programming	This paper presents a simple straightforward algorithm for evaluating reliability and expected execution time for software systems consisting of fault-tolerant components. The components are built from functionally equivalent but independently developed versions characterized by different reliability and performance. Both N-version programming (with parallel and sequential execution of the versions) and the recovery block scheme are considered within a universal model. q 2004 Elsevier Ltd. All rights reserved.	algorithm;fault tolerance;n-version programming;profiling (computer programming);run time (program lifecycle phase);software system	Gregory Levitin	2004	Rel. Eng. & Sys. Safety	10.1016/j.ress.2004.01.002	reliability engineering;fault tolerance;real-time computing;n-version programming;performance;computer science;engineering;reliability;distributed computing;software system	HPC	-23.08961650486945	41.03701428290102	112379
2b498876c9c9ce9f71e1130391d382b088a13ad7	formal deadlock verification for click circuits	integrated circuit design asynchronous circuits formal verification;integrated circuit design;formal verification;synchronous communication fabrics click circuits formal verification scalability deadlock freedom asynchronous circuits design automatic extraction abstract sat smt instances click primitives deadlock verification techniques;asynchronous circuits;article in monograph or in proceedings	Scalable formal verification constitutes an important challenge for the design of complicated asynchronous circuits. Deadlock freedom is a property that is desired but hard to verify. It is an emergent property that has to be verified monolithically. We propose to use Click, an existing library of asynchronous primitives, for verification. We present the automatic extraction of abstract SAT/SMT instances from circuits consisting of Click primitives. A theory is proven that opens the possibility of applying existing deadlock verification techniques for synchronous communication fabrics to asynchronous circuits.	deadlock;emergence;formal verification	Freek Verbeek;Sebastiaan J. C. Joosten;Julien Schmaltz	2013	2013 IEEE 19th International Symposium on Asynchronous Circuits and Systems	10.1109/ASYNC.2013.21	real-time computing;computer science;theoretical computer science;distributed computing;functional verification	EDA	-33.572547421629274	32.704248606581935	112528
d5229a1f0e3111bc9feaccb018eedc647e03cf5f	a framework for transactional consistency models with atomic visibility	004;replication consistency models transactions	Modern distributed systems often rely on databases that achieve scalability by providing only weak guarantees about the consistency of distributed transaction processing. The semantics of programs interacting with such a database depends on its consistency model, defining these guarantees. Unfortunately, consistency models are usually stated informally or using disparate formalisms, often tied to the database internals. To deal with this problem, we propose a framework for specifying a variety of consistency models for transactions uniformly and declaratively. Our specifications are given in the style of weak memory models, using structures of events and relations on them. The specifications are particularly concise because they exploit the property of atomic visibility guaranteed by many consistency models: either all or none of the updates by a transaction can be visible to another one. This allows the specifications to abstract from individual events inside transactions. We illustrate the use of our framework by specifying several existing consistency models. To validate our specifications, we prove that they are equivalent to alternative operational ones, given as algorithms closer to actual implementations. Our work provides a rigorous foundation for developing the metatheory of the novel form of concurrency arising in weakly consistent large-scale databases. 1998 ACM Subject Classification C.2.4 Distributed Systems	algorithm;concurrency (computer science);consistency model;database;distributed computing;distributed transaction;interaction;scalability;transaction processing	Andrea Cerone;Giovanni Tito Bernardi;Alexey Gotsman	2015		10.4230/LIPIcs.CONCUR.2015.58	weak consistency;computer science;theoretical computer science;consistency model;data mining;database;causal consistency;eventual consistency;sequential consistency	DB	-27.13468349559603	34.997390622168886	112761
4d1281c592099af6791baac7800592d58ea453b7	aocms: an adaptive and scalable monitoring system for large-scale clusters	applet servlet communicating controller;adaptive scalable monitoring system;large scale clusters;monitoring large scale systems logic scalability communication system control web server programmable control adaptive control yarn databases;workstation clusters client server systems distributed programming object oriented programming;heterogeneous cluster;client server systems;aocms;object oriented programming;large scale;monitoring system;design and implementation;distributed programming;aop based alarm decoupling aocms adaptive scalable monitoring system large scale clusters adaptive architecture applet servlet communicating controller web server;web server;workstation clusters;adaptive architecture;aop based alarm decoupling	In this paper, we present the design and implementation of AOCMS, an adaptive, scalable and efficient monitoring system for a large-scale cluster. We describe an adaptive architecture of AOCMS in detail, and focus on the discussion about some techniques as to enhancing the adaptation, scalability and efficiency of AOCMS. These techniques include: a solution to monitor a heterogeneous cluster; a universal applet-servlet communicating controller responsible for communication between the clients and the Web server; adaptive pools providing threads or connections to the database for the monitoring tasks on demand; and an AOP-based alarm decoupling the alarming logic from the monitoring logic. Moreover, we measured the performance of AOCMS. The results show that AOCMS runs with low overheads and responds to clients quickly	adaptive architecture;applet;coupling (computer programming);data mining;front-end processor;java persistence api;presentation logic;run time (program lifecycle phase);scalability;self-management (computer science);server (computing);web application;web server	Zhenghua Xue;Xiaoshe Dong;Weiguo Wu	2006	2006 IEEE Asia-Pacific Conference on Services Computing (APSCC'06)	10.1109/APSCC.2006.34	real-time computing;computer science;operating system;database;distributed computing;object-oriented programming;web server	DB	-32.656282932991196	46.08761121223149	112774
edf53f9bd8bbe525c956aebb81e576bd2eccf166	ampats - a multi processor ada tool set	remote procedure call;system design;system integration;source code;functional unit	In this paper an approach is presented which supports the distribution of an Ada Program. The idea is to handle functional units, defined during system design, as distributable units during system integration. These partitions are marked by a specific pragma. A preprocessor is analyzing the source code and producing so called Virtual Nodes. As these virtual nodes are communicating via remote procedure calls instead of rendezvous, the preprocessor automatically changes the rendezvous between tasks located in different virtual nodes into the appropriate remote procedure calls. A configuration tool handles a configuration description and integrates all virtual nodes mapped onto one processor into one Ada program. This approach allows the re-arrangement of virtual nodes not only without changes in the source code, but also without any recompilation.	ada	Karlotto Mangold	1992		10.1007/3-540-55585-4_24	computer architecture;computer science;operating system;programming language;remote procedure call;system integration;source code;systems design	Logic	-26.793157153271775	38.25809281761852	112778
314e335cd2d3f88b2899d6aa64203c1d91925db3	making applications persistent at run-time	orthogonal persistence applications persistence compile time deployment time;runtime java containers relational databases application software testing computer science nonvolatile memory programming environments engines;data flow analysis;program compilers;program compilers data flow analysis	Persistence is a common requirement in many applications. In existing systems, persistence is added to an application at either compile or deployment time by using a variety of mechanisms. In this paper we extend the notion of orthogonal persistence to make it dynamic: persistence becomes not only an orthogonal concern but one that can be added to an application at run-time without interrupting its operations.	compiler;interrupt;java;open-source software;overhead (computing);performance evaluation;persistence (computer science);software deployment	Angela Nicoara;Gustavo Alonso	2007	2007 IEEE 23rd International Conference on Data Engineering	10.1109/ICDE.2007.369013	parallel computing;real-time computing;computer science;data-flow analysis;database;programming language	DB	-22.252324758216663	35.333752899467335	113132
16e5d6f6c9334a2e15aceb7ca7032a22a24ea840	implementing fault-tolerant replicated ojects using psync	protocols;total order;communication networks;concurrent computing;history;fault tolerant;protocols concurrency control fault tolerant computing network operating systems;network operating systems;additional concurrency;ipc protocol;additional concurrency fault tolerant replicated objects psync ipc protocol host failures partial order;fault tolerant replicated objects;host failures;fault tolerant computing;fault tolerance;concurrency control;computer science;broadcasting;fault tolerance protocols communication system operations and management computer science concurrent computing communication networks broadcasting history concrete;communication system operations and management;concrete;psync;partial order	Psync is an IPC protocol that explicitly preserves the partial order of messages exchanged among a set of processes. A description is given of how Psync can be used to implement replicated objects in the presence of network and host failures. Unlike conventional algorithms that depend on an underlying mechanism that totally orders messages for implementing replicated objects, the authors' approach exploits the partial order provided by Psync to achieve additional concurrency. >	fault-tolerant computer system	Shivakant Mishra;Larry L. Peterson;Richard D. Schlichting	1989		10.1109/RELDIS.1989.72747	fault tolerance;parallel computing;real-time computing;concurrent computing;computer science;operating system;database;distributed computing;programming language	HPC	-24.464954684174877	45.80604044789166	113293
6418edc3cacd03dcc4bb732c40f8f328e950f36a	application-specific group communications in distributed servers	group messages application specific group communications lan local area network distributed servers name binding information relaxed consistency weak ordering constraints;network operating systems;group communication;weak order;network servers;client server;network servers local area networks network operating systems;relaxed consistency;network servers file servers local area networks computer science distributed computing computer architecture access protocols availability runtime;local area networks	In a distributed server architecture, a service to clients is provided by a newer group consisting of one or more servers (group members) which run on different machines in a local area network with the service functions distributed among them. The shared state of the server group (e.g., information on name bindings, leadership in the group) is implemented in a decentralized fashion across the group members. The members communicate with one another by messages to coordinate among themselves and provide a consistent view of the state to clients. The paper advocates relazation of strict consistency requirements, relying instead on the inherent ability of the applications implemented by clients and servers to tolerate inconsistency in the state or deal with the inconsistency in an application dependent manner. For example, inconsistency in name binding information may be detected by a client on attempting to access the named object and corrected by a customized protocol. With such a relaxed consistency, operations on the server state often do not require strict coordination among the group members, and may be realized with weak ordering constraints on group messages. Thus a high degree of concurrency and efficiency is possible without compromising correctness. The paper describes sample applications to illustrate the use of relaxed consistency in designing dis tributed servers. K~~ Words: Client-server model, Distributed servers, Remote procedure call, Group communication, State ConsistencY, Message ordering, Application-specific Protocols.	client–server model;concurrency (computer science);correctness (computer science);limbo;linearizability;name binding;remote procedure call;requirement;server (computing);subroutine	K. Ravindran;Samuel T. Chanson	1991		10.1109/INFCOM.1991.147627	local area network;real-time computing;communication in small groups;computer science;operating system;database;distributed computing;client–server model;server;computer network;inter-process communication	Networks	-25.41954840499714	46.13696436159578	113340
405aaa1a81031b301cbc54e7742404edaf1da707	beneath the bytecode: observing the jvm at work using bytecode instrumentation	java virtual machine;dynamic program analysis;program observability;bytecode instrumentation	Many dynamic program analysis (DPA) tools for profiling, debugging, and monitoring programs executing on managed platforms such as the Java Virtual Machine (JVM) rely on bytecode instrumentation (sometimes combined with agents utilizing the JVM Tool Interface and native code libraries) to observe the base program behavior. While this is both the recommended and preferred technique for implementing DPA tools, it has certain noticeable drawbacks [1].  One, the analysis runs in the same process as the base program, and often shares the Java Class Library (JCL) and other resources with the base program. This creates potential for interference that may result in deadlocks, or state corruption in code that does not expect reentrancy.  Two, certain parts of the JCL are typically off-limits for instrumentation, because they either play a vital role during the JVM bootstrap, or the JVM implementation makes certain assumptions about properties of specific classes, or both. These two issues are typically solved by reducing the scope of the instrumentation, leading to under-approximation of the program's behavior.  And three, bytecode instrumentation only allows observing base program events at the bytecode level. The instrumentation code remains oblivious to optimizations performed by the dynamic compiler, and conversely, the compiler is completely unaware of the presence of the instrumentation code. Because the instrumentation code may significantly inflate the base program code and create additional data dependencies as a result of observing the program's behavior, various optimizations performed by the dynamic compiler (e.g., inlining, partial escape analysis, code motion) will be perturbed by the presence of the instrumentation code. As a result, the dynamic analysis may observe events that would not have happened in the base program had it been left alone, thus over-approximating the actual behavior.  In this talk, we will discuss some of the challenges in making the JVM more observable for instrumentation-based DPA tools, with specific focus on getting accurate profiling information in presence of an optimizing dynamic compiler.  The core of this talk is based on the work that was originally presented at OOPSLA'15 [4]. In the meantime, the work has been integrated into the Graal project. Additional parts are based on joint work with other authors, originally presented at AOSD'12 [3] and GPCE'13 [2].	approximation;compiler;data dependency;deadlock;debugging;dynamic compilation;dynamic program analysis;escape analysis;graal;inline expansion;interference (communication);java class library;java virtual machine;job control language;library (computing);loop-invariant code motion;machine code;observable;reentrancy (computing)	Lubomír Bulej;Yudi Zheng;Walter Binder	2016		10.1145/3012408.3012409	instrumentation;real-time computing;computer science;operating system;programming language	PL	-21.27773742337047	36.52070609035572	113399
73283ea7f39269f31afa432e2e2bc657ee8c9683	a dynamic-reconfigurable architecture for protocol stacks of networked systems	protocols;dynamic reconfiguration;reconfigurable architectures;peer component;protocol stacks;computer architecture routing protocols computer networks context pervasive computing application software communication standards wireless application protocol switches computer bugs;state transfer;software framework;peer component dynamic reconfigurable architecture protocol stacks networked systems software framework state transfer;dynamic reconfigurable architecture;networked systems;reconfigurable architectures protocols	This paper proposes a software framework for dynamic- reconfigurable protocol stack The framework presents mechanisms and an algorithm for all required phases for reconfiguration of a running protocol component that include freezing the component in a safe state, changing the component, and state transfer to a new component. Considering that every running protocol component communicates with at least one peer component in another system, we perform the reconfiguration with respect to the peer component.	algorithm;component-based software engineering;executable;extensibility;overhead (computing);plug-in (computing);protocol stack;requirement;software framework	Mahdi Niamanesh;Rasool Jalili	2007	31st Annual International Computer Software and Applications Conference (COMPSAC 2007)	10.1109/COMPSAC.2007.19	embedded system;communications protocol;real-time computing;common component architecture;computer science;software framework;distributed computing;internet protocol suite;programming language	Embedded	-33.688494021914096	39.895116013172334	113596
c23a386f247d06dfe6b3dc3c30714370463a4212	scr algorithm: saving/restoring states of file systems	sistema operativo;cluster computing;preuve programme;program proof;atomic operation;fault tolerant;gestion fichier;ejecucion programa;file management;program execution;checkpointing;algorithme;algorithm;fault tolerant system;operating system;file system;execution programme;fault tolerance;manejo archivos;prueba programa;sistema tolerando faltas;systeme exploitation;systeme tolerant les pannes;recoverability of file systems;check pointing;algoritmo	Fault-tolerance is very important in cluster computing. Many famous cluster-computing systems have implemented fault-tolerance by using checkpoint/restart mechanism. But existent checkpointing algorithms can not restore the states of a file system when roll-backing the running of a program, so there are many restrictions on file accesses in existent fault-tolerance systems. SCR algorithm, an algorithm based on atomic operation and consistent schedule, which can restore the states of file systems, is present in this paper. In SCR algorithm, system calls on file sytems are classified into idempotent operations and non-idempotent operations. A non-idempotent operation modifies a file system's states, and an idempotent operation does not. SCR algorithm dynamically follows the tracks of a program's running, logs each non-idempotent operation used by the program and the information that can restore the operation in disks. When checkpointing roll-backing the program, SCR algorithm will revert the file system states to the last checkpoint time. By using SCR algorithm, users are allowed to use any file operation in their programs.	algorithm;application checkpointing;computer cluster;computer file;fault tolerance;idempotence;linearizability;system call;transaction processing system	Xiaohui Wei;Jiubin Ju	1999	Operating Systems Review	10.1145/309829.309839	self-certifying file system;fault tolerance;parallel computing;real-time computing;device file;computer science;stub file;versioning file system;operating system;journaling file system;open;file system fragmentation;computer security;file control block	OS	-20.312657054065674	42.67001822523351	114152
4728e99bd8a193949cb3149ce8fe2cf315ab45fe	padmaster: an improvisation environment for real time performance		This paper will describe the design and implementation of PadMaster, a real-time improvisation environment running under the NextStep operating system. The system currently uses the Mathews/Boie Radio Drum as a three dimensional controller for interaction with the performer. program, set the MIDI channel used by it, dump and loa the internal calibration tables, etc. • Trigger / Release messages: sent by the drum when a baton hits / leaves the su rface using continuous controllers 26 through 31. The message includes the xy position and velocity of the hit or release. • Switches: sent by the drum when one of the switches changes state using controllers 5E to 5F. • Poll request: sent by the computer to request the position in sp ace of the batons (channel pressure). • Poll answer: sent by the drum in response to a poll request mes sage using a series of channel pressure messages. It includes the position of both batons i n space and optionally the position of the pots. 1 2 3 4 5 Reiving anennas Transmitting antenna uP A/D MIDI i/o rom/ram The existing general purpose controller program (written by David Jaffe / Andrew Schloss) was completely redesigned. A more efficient and faster pro tocol was created to enable the computer to use the Radio Drum as a three dimensional controller with six degrees of freedom. This program is one of many that are stored in the Drum’s firmware, and can be activated remotely with a system exclusive message. This is a short description of part of the protocol : • System exclusive configuration messages: can be used to turn ON or OFF the communication 1.0 The Radio Drum and the MIDI communication protocol The current implementation of the Stanford Radio Dr um was developed by Max Mathews as a simpler alternative to Boie’s design. The two batons act as r adio transmitting antennas. There are five receivin g a tennas underneath the surface of the drum and the multiple xed A/D converter translates signal strength coming from the five receivers to numbers, which the microproce ssor uses to calculate the absolute position of eac h b ton in space. In addition to the batons, the Radio Drum hardware includes two switches and four potentiome ters. It has a MIDI interface that it can use to communic ate with computers or synthesizers. 2.0 The PadMaster program PadMaster is written in Objective C and runs on the NeXT workstation, which is connected through MIDI to the Radio Drum.It uses the Radio Drum as a controller and splits the surface of the drum into up to 30 virtual pads, each one independently programmable to react in a specific way to a hit and to the position information stream of one or more axes of control. Pads can be grouped into Scenes, so that the behavior of the surface of the drum can be subtly or radically altered during the course of a performance by dynamically jumping to a different Scene. The screen of the computer displays the virtual synth #1	analog-to-digital converter;automatic computing engine;baton;communications protocol;computer monitor;drum memory;firmware;input/output;midi;max mathews;nextstep;network switch;objective-c;operating system;random-access memory;real-time transcription;six degrees of separation;transmitter;unified model;velocity (software development);workstation	Fernando Lopez-Lezcano	1995			six degrees of freedom;control theory;firmware;microprocessor;computer hardware;midi;drum;workstation;computer science;communication channel	Networks	-28.66732606294418	39.23014206930187	114226
0268588b692e53a880355d19b42a2899391d52d0	www cache management and its international deployment: challenges in the ai3 project	red www;information retrieval;information technology;technologie information;recherche information;world wide web;reseau www;recuperacion informacion;tecnologia informacion	The World Wide Web (WWW) has become a vital service on the Internet. People are using the service day by day to get specific information or services they want. However, the traffic for the WWW service is increasing rapidly, and now all of the Internet backbone networks are congested by the WWW traffic. In order to improve this situation, several techniques to reduce the traffic have been developed: WWW client cache method, caching proxy servers and WWW hierarchical cache system. Furthermore, since the WWW cache system can be used for reducing the WWW latency, several active caching or prefetching method has been implemented. Our group designed and implemented the prefetching cache system called Wcol (WWW Collector) based on the idea of interactive prefetch scheme. In this paper, we show several performance results from its trial use at NAIST, Nara, Japan. Furthermore, on the AI3 network which is a research testbed network using satellite links covering several Asian countries, we have adopted a caching system with prefetching to improve both cache hit rate and usage of the bandwidth on the AI3 links. On top of caching and prefetching system, we add an agent to plan prefetching strategies based on observations of the traffic and the users' behavior. In this paper, we also show the design of this adaptive WWW cache system.	autoit;software deployment;www	Suguru Yamaguchi;Ken-ichi Chinen;Hiroyuki Inoue	1997		10.1007/3-540-63343-X_53	real-time computing;cache;computer science;operating system;database;distributed computing;information technology;world wide web;computer security	DB	-30.105252339120092	44.122459533051085	114343
c172bf537217b4e328de7b54be4d1794a73a0523	towards real-time enabled microsoft windows	real time;embedded system;embedded systems;microsoft windows;operating system;operating systems;real time systems	Many computer scientists recognize the adverse relationship between Microsoft Windows, a general purpose operating system, which by design does not support Real Time, a specific purpose feature. However, the boundary between a general-purpose system and a special-purpose feature has begun to blur and Microsoft and its partners have kept working on adding real-time services to Windows. In this paper, we will describe existing real-time solutions for Windows, the on-going projects for the next release of Windows and future trends lead by hardware evolution.	computer scientist;general-purpose modeling;microsoft windows;operating system;real-time transcription;real-time web	Alex Xiang Feng	2005		10.1145/1086228.1086256	directx video acceleration;embedded system;microsoft windows;desktop window manager;windows ce;real-time computing;winnuke;computer science;group policy;software versioning;windows vista;operating system;pc system design guide;dynamic data exchange;windows rally;commit charge;vbscript;dll hell;next-generation secure computing base	OS	-32.177438334325736	41.65345746827218	114596
d867cc8a66474c821cbeeb717a9c6ba7f960b439	approaches to code generation for synchronous transfer architecture (sta)			code generation (compiler)	Jie Guo	2008				Arch	-29.345080363377168	34.56964181737592	114681
df423abe938043e304505dbce6cad0fddd89ef6e	large database ada program for real time laboratory instrument control and data acquisition	real time;data acquisition		ada;data acquisition;instrument control	Richard G. Sartore	1994		10.1145/197694.197741	real-time computing;operating system;database	DB	-31.13630614104073	38.98319546028427	114746
fff64b48f5e24acf3f95ff50fb1eac52cb216e30	shared memory synchronization in presence of failures: an exercise-based  introduction for the sophomore	software;detectors;computer crashes detectors registers vehicle crash testing yarn system recovery concurrent computing competitive intelligence software systems read write memory;yarn;concurrent computing;shared memory;computer crashes;compare swap;probability density function;wait free synchronization;exercise based introduction;software systems;asynchronous shared memory systems;atomic register;data mining;shared memory systems;system recovery;ieee;registers;synchronization;wait free synchronization asynchronous shared memory system compare swap load linked store conditional process crash atomic register synchronization swap;process crash;load linked store conditional;vehicle crash testing;asynchronous shared memory system;competitive intelligence;artificial intelligence;swap;read write memory;sophomore introduction exercise based introduction asynchronous shared memory systems theory oriented journals conferences;shared memory system;theory oriented journals;conferences;sophomore introduction	In the recent past, lots of papers have addressed synchronization  in asynchronous shared memory systems prone to process crashes.  Unfortunately, to date, nearly all  these results have  appeared  only in theory-oriented journals and conferences, very few  being presented and studied in  textbooks.  This aim of this paper is to give a flavor of a few  of these fundamental results.  To that end, it considers three problems and presents  solutions proposed to solve them, emphasizing the basic concepts and techniques these  solutions rely on.  These problems have been selected because they address distinct facets  of synchronization in presence of failures. So, the spirit of this  introductory  paper  is mainly pedagogical (with an algorithmic taste)	shared memory	Michel Raynal	2009	2009 International Conference on Complex, Intelligent and Software Intensive Systems	10.1109/CISIS.2009.14	parallel computing;real-time computing;computer science;distributed computing	EDA	-24.06486153482451	43.183835040312935	114794
278ecc5b2f66299a9411d9a8d225a5d1cf78f143	requirements for parallel programming in object-oriented distributed systems	parallelisme;distributed system;eficacia sistema;systeme reparti;transparence;persistence;persistencia;programacion paralela;implementation;performance systeme;parallel programming;system programming;system performance;transparencia;persistance;ejecucion;parallelism;sistema repartido;paralelismo;programmation systeme;programacion sistema;object oriented;oriente objet;transparency;systeme parallele;amadeus system;parallel system;parallel programs;orientado objeto;parallel applications;sistema paralelo;programmation parallele	In this paper we present some ideas on the functionality that should be incorporated into an object-oriented distributed system to support distributed and parallel programming. The work is based on practical experience in developing several substantial distributed and parallel applications on the Amadeus platform. Related work in the area is sketched. Published in The Computer Journal, vol 37, no 6, August 1994. Also technical report TCD-CS-94-41, Dept. of Computer Science, Trinity College Dublin.	computer science;distributed computing;parallel computing;teller assist unit;the computer journal;trinity	Brendan Tangney;Andrew Condon;Vinny Cahill;Neville Harris	1994	Comput. J.	10.1093/comjnl/37.6.499	persistence;embedded system;distributed algorithm;real-time computing;computer science;computer performance;distributed design patterns;transparency;programming language;object-oriented programming;implementation;system programming;algorithm	PL	-19.19371186949228	42.278126898975735	115045
d71a734a411e0a2b2a20e3d0b24b5b119a2544ae	research directions for concurrency	research direction			Joseph Sifakis	1996	ACM Comput. Surv.	10.1145/242224.242294	non-lock concurrency control	Theory	-25.798662296532196	45.334785373511195	115054
cc5de1fc634152ec7d1d7a095ae5986d9eb2b3f9	bugmd: automatic mismatch diagnosis for bug triaging	iteration scheme;micromechanical devices;registers;synchronization;aggregates;feature extraction;temporal encoding;rate encoding;computer bugs;context modeling	System-level validation is the most challenging phase of design verification. A common methodology in this context entails simulating the design under validation in lockstep with a high-level golden model, while comparing the architectural state of the two models at regular intervals. However, if a bug is detected, the diagnosis of the problem with this framework is extremely time and resource consuming. To address this challenge, we propose a novel bug triaging solution that collects multiple architectural-level mismatches and employs a classifier to pinpoint buggy design units. We also design and implement an automated synthetic bug injection framework that enables us to generate large datasets for training our classifier models. Experimental results show that our solution is able to correctly identify the source of a bug over 70% of the time in an out-of-order processor model. Furthermore, our solution can identify the top 3 most likely units with over 90% accuracy.	architectural state;high- and low-level;lockstep (computing);simulation;software bug;statistical classification;synthetic intelligence	Biruk Mammo;Milind Furia;Valeria Bertacco;Scott A. Mahlke;Daya Shanker Khudia	2016	2016 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	10.1145/2966986.2967010	embedded system;synchronization;real-time computing;software bug;feature extraction;computer science;theoretical computer science;operating system;context model;processor register;algorithm	EDA	-21.136337224916026	39.73816165429796	115207
f04f4c8bdcd1780a9ca14ebdfb6ee9d2656eff63	interactive remote recording and playback of multicast videoconferences	distributed system;base donnee;systeme reparti;multimedia;red www;video a peticion;videoconference;video a la demande;aplicacion cliente servidor;video conference;database;audio video;base dato;telecommunication network;transmision asincronica;systeme conversationnel;client server;sistema repartido;internet;interactive system;red telecomunicacion;application client serveur;multimedia data;video on demand;reseau telecommunication;sistema conversacional;world wide web;asynchronous transmission;videoconferencia;transmission asynchrone;reseau www;common object request broker architecture;open standard;client server application	One at the most exciting technologies in today's Internet is the MBone. MBone stands for Multicast Backbone: it provides the infrastructure for efficient multipoint packet delivery in the Internet. The most popular scenario is worldwide audio-video conferencing. However. so far there are no satisfactory solutions available on how to archive multimedia data streams of multicast videoconferences. and how to make them accessible for remote sites (i.e. how to remotely record and remotely play hack MBone conferences). In this paper we present architectural considerations, design issues and describe a prototypical implementation of a Video Conference Recording on Demand (VCRoD) service for the MBone. Our system is called MBone VCRoD Service (MVoD) and is a client-server based architecture for interactive remote recording and playback of MBone sessions. MVoD is implemented based on open standards (e.g. CORBA), making it possible for other applications to interface it. Since the MVoD client application is implemented using JAVA, it will he possible in access the service from almost any platform.	multicast	Wieland Holfelder	1997		10.1007/BFb0000375	mbone;computer science;operating system;database;distributed computing;multimedia;videoconferencing;law;world wide web;computer security;client–server model;computer network	HCI	-29.8804367498214	43.68809993065393	115264
f8488c0e94456382b997889656a63e03d270d64f	construction of a multiple entities communication protocol by compositional approach	compositional approach;parallel composition;correctness properties;protocols;protocols specification languages bisimulation equivalence formal specification;formal specification;correctness properties multiple entities communication protocol compositional approach communicating entities parallel composition sequential composition service specifications protocol specifications basic lotos formal description techniques weak bisimulation equivalence;sequential composition;protocol specifications;formal description technique;multiple entities communication protocol;service specifications;system recovery;formal description techniques;algebra;specification languages;access protocols broadcasting system recovery algebra specification languages;communicating entities;access protocols;weak bisimulation equivalence;protocol specification;communication protocol;broadcasting;bisimulation equivalence;basic lotos	We consider a compositional approach for designing service and protocol specifications for communicating entities. The proposed techniques consider alternative, sequential, and parallel composition of service specifications and protocol specifications. The specifications are specified in Basic LOTOS which is a formal description technique. We use the weak bisimulation equivalence, to represent the correctness properties between the service specification and the protocol specification.	communications protocol;entity	Bhed Bahadur Bista;Norio Shiratori	2001		10.1109/DEXA.2001.953057	communications protocol;computer science;theoretical computer science;distributed computing;programming language	Vision	-31.618974953937403	32.38919502245758	115443
de30f62b7ff816426fd7196d5eb275ee3efe7c11	mobile agents for distributed transactions of a distributed heterogeneous database system	distributed system;modele client serveur;movilidad;tratamiento transaccion;multiagent system;base donnee repartie;base donnee;reseau communication;systeme reparti;mobile radiocommunication;distributed database;agent mobile;mobility;path planning;agente movil;modelo cliente servidor;distributed transactions;heterogeneous databases;distributed computing;database;base repartida dato;base dato;mobile agent technology;simultaneidad informatica;mobilite;radiocommunication service mobile;planification trajectoire;concurrency;client server;sistema repartido;internet;mobile agent;transaction processing;radiocomunicacion servicio movil;sistema multiagente;red de comunicacion;simultaneite informatique;communication network;traitement transaction;systeme multiagent;client server model	A Distributed Heterogeneous Database System (DHDBS) is constituted of different kinds of autonomous databases connected to the network. A distributed transaction in such a system involves many sub-transactions and data movements among database sites. For the time being, most of the commercial database products implement their distributed transactions using the traditional client/server model that is suffering from enormous data movements. This paper proposes a new distributed transaction model which uses mobile agent technology to reduce data traffics in distributed transactions. The idea is backed by the well-known characteristics, such as mobility, autonomy, and concurrency, of mobile agents in supporting distributed computations. The aim is to boost the performance of distributed transactions of a heterogeneous database system in a loosely coupled environment (such as the Internet). An procedure is designed for distributed query decomposition. Some principles are observed for the path planning of a mobile agent roaming the network to carry out various sub-transactions.	distributed transaction;heterogeneous database system;mobile agent	Ding Yen Ye;Ming-Che Lee;Tzone-I Wang	2002		10.1007/3-540-46146-9_40	distributed algorithm;real-time computing;distributed data store;database transaction;distributed transaction;mobile database;computer science;concurrency control;database;distributed computing;distributed object;serializability;mobile computing;distributed database;acid;database testing;client–server model;replication;distributed concurrency control	DB	-29.186156808278188	44.10626670501222	115527
2c9679ef3e7217b7b349cae6c1b1f01193c8b646	frogi: fractal components deployment over osgi	modelizacion;hierarchical system;unfolding;fractal component;mise a jour;componente logicial;deploiement;conditionnement;systeme hierarchise;despliegue;composant logiciel;conditioning;actualizacion;modelisation;sistema jerarquizado;software component;component model;acondicionamiento;composant fractal;modeling;componente fractal;updating	This paper presents FROGi, a proposal to support continuous deployment activities inside Fractal, a hierarchical component model. FROGi is implemented on top of the OSGi platform. Motivation for this work is twofold. On one hand FROGi provides an extensible component model to OSGi developers and eases bundle providing. FROGi-based bundles are still compatible with legacy OSGi bundles that offer third party services. On the other hand, FROGi benefits from the deployment infrastructure provided by OSGi which simplifies conditioning and packaging of Fractal components. With FROGi, it is possible to automate the assembly of a Fractal component application. Partial or complete deployment is also supported as well as performing continuous deployment and	application server;component-based software engineering;continuous delivery;enterprise javabeans;fractal;fractal component model;interoperability;introspection;osgi;server (computing);service-oriented architecture;software deployment	Mikael Desertot;Humberto Cervantes;Didier Donsez	2006		10.1007/11821946_18	embedded system;simulation;systems modeling;computer science;artificial intelligence;component-based software engineering;conditioning;component object model;hierarchical control system;programming language;algorithm;statistics	SE	-29.0394504171735	42.168392624189735	115542
9579bed46e55fd7ab87fc838d99bc3d99153654c	application of petri net models for the evaluation of fault-tolerant techniques in distributed systems	analytical models;distributed system;conversations;algorithm analytical models petri net models fault tolerant techniques distributed systems fault tolerant schemes quantitative evaluation selection specific system configurations rollback recovery checkpointing recovery blocks n version programming conversations fault tolerant system subnet primitives;fault tolerant;system configuration;application software;fault tolerant techniques;distributed processing;selection;distributed computing;checkpointing;algorithm;fault tolerant system;recovery blocks;fault tolerant computing;petri net models;subnet primitives;fault tolerant systems;fault tolerance;rollback recovery;specific system configurations;computer science;petri nets;distributed systems;petri net;n version programming;quantitative evaluation;fault tolerant schemes;analytical model;petri nets distributed processing fault tolerant computing;fault tolerance fault tolerant systems computer science petri nets educational institutions checkpointing hardware application software distributed computing analytical models;hardware	Analytical models are presented that use Petri nets for fault-tolerant schemes used in distributed systems. These models are used in the quantitative evaluation and selection of good fault-tolerant schemes for specific system configurations. Several different fault-tolerant schemes that can be modeled using Petri nets are discussed in detail. These schemes include rollback recovery with checkpointing, recovery blocks, N-version programming, and conversations. After a brief review of Petri net models, extension of the Petri net models to incorporate fault-tolerant schemes is considered. A methodology for evaluating a fault-tolerant scheme for a specific system configuration and the steps involved in building a Petri net model of a fault-tolerant system are described. The subnet primitives involved in building these models are identified and an algorithm for building the models automatically is described. Examples illustrating this extended Petri net model are discussed and numerical results are presented to show the applicability of the models. >	distributed computing;fault tolerance;petri net	Yuan-Bao Shieh;Dipak Ghosal;Prasad R. Chintamaneni;Satish K. Tripathi	1989		10.1109/ICDCS.1989.37943	fault tolerance;real-time computing;computer science;theoretical computer science;distributed computing;process architecture;petri net	EDA	-31.789917255498672	32.660915503853744	115579
daf7402bc99e020f657893d01a6a61953bd40516	brief announcement: robust self-stabilizing construction of bounded size weight-based clusters	satisfiability;system performance;safety properties;network topology;robust stability;transient fault;convergence time	The clustering problem consists of partitioning network nodes into groups called clusters. Each cluster has a single clusterhead that acts as local coordinator of cluster.#R##N##R##N#A technique for designing solutions that tolerate transient faults is selfstabilization. Self-stabilizing protocols are attractive because they need not be initialized: they converge from any configuration to a legitimate one. Also, they are adaptive to topological changes. If the current configuration is inconsistent with the network topology, the self-stabilizing protocol eventually converges to a legitimate configuration. Nevertheless, self-stabilizing protocols do not guarantee any property during the convergence period. In addition, the convergence time may be proportional to the size of the network; particularly, in weight-based clustering protocols. In order to overcome these drawbacks, we are interested to the robust stabilization. Robust stabilization guarantees that from an illegitimate configuration, the system reaches quickly a safe configuration, in which the safety property is satisfied. The safety property has to be defined such that the system performs correctly its task in a safe configuration. During the convergence to a legitimate configuration, the safety property stays always verified.	self-stabilization	Colette Johnen;Fouzi Mekhaldi	2009		10.1007/978-3-642-05118-0_61	real-time computing;mathematics;distributed computing;computer security	Theory	-22.748712210715865	44.78820201947525	115827
4f5e65ca9563cfc0c75362efbed41fcd45f5c16c	space efficient data race detection for parallel programs with series-parallel task graphs	pointer variables;instruments;electronic mail;concurrent computing;on the fly methods;program debugger;parallel programming;parallelism space efficient data race detection parallel programs series parallel task graphs access anomaly shared resource program debugger on the fly methods storage requirements pointer variables series parallel task graph fork join spawning types;runtime;synchronisation;parallelism;technology and engineering;automatic detection;runtime concurrent computing instruments electronic mail parallel processing timing parallel programming;storage requirements;fork join;data races;space efficient data race detection;on the fly;series parallel task graph;program debugging synchronisation parallel programming;spawning types;program debugging;task graphs;shared resource;parallel programs;series parallel;series parallel task graphs;parallel processing;access anomaly;race detection;timing	A data race or access anomaly is a bug in parallel programs, occurring when two parallel processes access the same shared resource in an unsynchronised fashion, and at least one access modifies the resource. The effects of a data race can be non-deterministic and can give the program debugger a very hard time. Race detection represents a class of methods which automatically detect the presence of data races in a parallel program. This paper deals with on-the-fly methods, in which race detection is performed at run-time, during the execution of the program. We present a novel method for on-the-fly race detection, which reduces the storage requirements by several orders of magnitude over previous methods. Moreover, the method is language independent and can handle the problems associated with pointer variables (aliasing). The programs it deals with are restricted to those that have a series-parallel task graph. This includes fork-join and spawning types of parallelism. >	race condition;series-parallel graph	Koenraad Audenaert;Luk Levrouw	1995		10.1109/EMPDP.1995.389169	parallel computing;real-time computing;computer science;distributed computing	HPC	-20.68014818818195	38.95708711915046	115877
d006d2cc409f36430138b0b225e9fbf49b9a78d0	support of java api for the jhisc system	java api;object-oriented programming language;object-oriented system;object model;elemental object;jhisc runtime environment;jhisc api;jhisc system;jhisc core;hardware support delegate function;java program;application program interface;object oriented programming languages	This paper presents the evolution and improvement of the Java API (Application Programming Interface) for Java which used in jHISC Runtime Environment. The jHISC Running Environment is an object-based, single addressing execution environment, specially designed for running object-oriented programming languages such as Java. The jHISC core is a HISC-architecture processor created for executing Java programs. The jHISC API is designed for object-oriented systems to support object model inside jHISC. The jHISC API includes elemental objects such as jhisc.Object, jhisc.Integer and few redesigned objects such as jhisc.util.Vector, jhisc.util.Hashtable. The jHISC API is developed in order to take advantage of using jHISC core and provides a hardware support delegate function in the system.	application programming interface;elemental;hash table;java class library;list of java apis;object-based language;programming language;runtime system	Gary K. W. Hau;Anthony Shi-Sheung Fong;Mok Pak Lun	2003	SIGARCH Computer Architecture News	10.1145/959122.959124	real-time computing;computer science;operating system;programming language	PL	-25.80659002197719	36.690276272359114	115913
e14684d819d0e3f2691e60c6a41e9eec7bb60297	the g-sdm (grid for space data management) project	project management;collaborative work;earth;prototypes;project management distributed computing grid computing earth parallel processing testing space technology collaborative work database systems prototypes;data management;distributed computing;testing;project work;distributed database system;database systems;parallel computer;earth observation;space technology;ministry of education;grid computing;high performance;parallel processing	The G-SDM (Grid for Space Data Management) project, in collaboration with ASI (Space Italian Agency), is a research activity on Earth Observation distributed database system using GRID tecnologies in order to enable high performance and parallel computing. The G-SDM project work has been supported by the Italian MIUR (Italian Ministry of Education, University and Research)-FIRB, GRID.IT Project n° RBNEO1KNFP.	distributed database;parallel computing;software development process	Enrico Grasso;Vita Antonia Lore;Giovanni Milillo;Sergio Stigliano	2005	Proceedings. 2005 IEEE International Geoscience and Remote Sensing Symposium, 2005. IGARSS '05.	10.1109/IGARSS.2005.1525847	earth observation;project management;parallel processing;data management;computer science;database;distributed computing;prototype;earth;software testing;space technology;drmaa;grid computing	HPC	-30.790328122549806	42.40433965833609	116010
46829a9f8d9e0817463e9c6f12fa5b66a4905290	generating fast indulgent algorithms	asynchrony;distributed algorithms;indulgent algorithms	Synchronous distributed algorithms are easier to design and prove correct than algorithms that tolerate asynchrony. Yet, in the real world, networks experience asynchrony and other timing anomalies. In this paper, we address the question of how to efficiently transform an algorithm that relies on synchronous timing into an algorithm that tolerates asynchronous executions. We introduce a transformation technique from synchronous algorithms to indulgent algorithms (Guerraoui, in PODC, pp. 289–297, 2000), which induces only a constant overhead in terms of time complexity in well-behaved executions. Our technique is based on a new abstraction we call an asynchrony detector, which the participating processes implement collectively. The resulting transformation works for the class of colorless distributed tasks, including consensus and set agreement. Interestingly, we also show that our technique is relevant for colored tasks, by applying it to the renaming problem, to obtain the first indulgent renaming algorithm.	asynchrony (computer programming);byzantine fault tolerance;communication complexity;consensus (computer science);distributed algorithm;hagit attiya;overhead (computing);podc;time complexity	Dan Alistarh;Seth Gilbert;Rachid Guerraoui;Corentin Travers	2012	Theory of Computing Systems	10.1007/s00224-012-9407-2	asynchrony;distributed algorithm;real-time computing;computer science;theoretical computer science;distributed computing;algorithm	Embedded	-22.425112446696268	44.074021468466924	116078
fa093c8f9a75e5684a6e5a556c3f9a5f49b40752	report on the fourth acm sigops european workshop: fault tolerance support in distributed systems	distributed system;fault tolerant	"""As the theme of the workshop, """"fault-tolerance support in distributed systems"""" was selected. The motivation for this choice was the observation that distribution and fault tolerance can be argued to be two faces of the same medallion--any system that can tolerate failures must be distributed, and any system that is distributed must be capable of surviving partial failures. To provoke further investigation of this duality, the Call for Participation included the following questions:"""	distributed computing;fault tolerance	Özalp Babaoglu	1991	Operating Systems Review	10.1145/122140.122142	fault tolerance;real-time computing;computer science;distributed computing	Networks	-23.680057566103756	43.951097388217036	116286
79f7a4cc3e358e7a7012d50ce48656d605bcfec7	live heap space analysis for languages with garbage collection	informatica;live heap space analysis;java bytecode;memory management;garbage collection;upper bound;col;object oriented;peak memory consumption;low level languages	The peak heap consumption of a program is the maximum size of the live data on the heap during the execution of the program, i.e., the minimum amount of heap space needed to run the program without exhausting the memory. It is well-known that garbage collection (GC) makes the problem of predicting the memory required to run a program difficult. This paper presents, the best of our knowledge, the first live heap space analysis for garbage-collected languages which infers accurate upper bounds on the peak heap usage of a program's execution that are not restricted to any complexity class, i.e., we can infer exponential, logarithmic, polynomial, etc., bounds. Our analysis is developed for an (sequential) object-oriented bytecode language with a scoped-memory manager that reclaims unreachable memory when methods return. We also show how our analysis can accommodate other GC schemes which are closer to the ideal GC which collects objects as soon as they become unreachable. The practicality of our approach is experimentally evaluated on a prototype implementation. We demonstrate that it is fully automatic, reasonably accurate and efficient by inferring live heap space bounds for a standardized set of benchmarks, the JOlden suite.	benchmark (computing);complexity class;experiment;garbage collection (computer science);memory management;polynomial;prototype;time complexity;unreachable memory	Elvira Albert;Samir Genaim;Miguel Gómez-Zamalloa	2009		10.1145/1542431.1542450	heapsort;binomial heap;garbage;parallel computing;collection;heap;min-max heap;skew heap;double-ended priority queue;computer science;binary heap;operating system;d-ary heap;heap overflow;low-level programming language;upper and lower bounds;garbage collection;programming language;object-oriented programming;algorithm;memory management	PL	-20.559470292723933	35.9809023175117	116448
5c439a0349d766d1dcacbddecc9ddb015f12a271	system support for cross-layering in sensor network stack	distributed system;longevidad;red sin hilo;intercambio informacion;reseau capteur;adaptability;adaptabilite;systeme unix;systeme reparti;informatique mobile;service information;reseau sans fil;longevite;unix system;longevity;wireless network;interrogation base donnee;environmental conditions;interrogacion base datos;useful information;crossed module;informacion util;ad hoc network;modularite;red ad hoc;sensor network;adaptabilidad;wireless sensor network;information sharing;feasibility;systeme linux;red sensores;sistema repartido;reseau ad hoc;sistema linux;echange information;information exchange;sensor array;servicio informacion;modularity;sistema unix;information service;cross layer;mobile computing;modularidad;linux system;database query;practicabilidad;faisabilite;information utile;robust design	Wireless Sensor Networks are deployed in demanding environments, where application requirements as well as network conditions may change dynamically. Thus the protocol stack in each node of the sensor network has to be able to adapt to these changing conditions. Historically, protocol stacks have been designed with strict layering and strong interface between the layers leading to a robust design. However, cross-layer information sharing could help the protocol modules to make informed decisions and adapt to changing environmental conditions. There have been ad hoc approaches to facilitating cross-layer cooperation for adaptability. However, there has been no concerted effort at providing a uniform framework for cross-layer adaptability that preserves the modularity of a conventional protocol stack. This paper presents a novel service, information exchange service (IES), as a framework for cross-module information exchange. IES is a centrally controlled bulletin-board where different modules can post available data, or request for useful information, and get notified when the information becomes available. IES is integrated into the proposed SensorStack architecture that preserves the benefits of layering while facilitating adaptability. IES has been implemented in TinyOS and Linux, to show both the feasibility of the design as well as demonstrate the utility of cross-layering to increase application longevity.	communications protocol;coupling (computer programming);event (computing);handy board;hoc (programming language);information exchange;integrated encryption scheme;linux;linux;memory management;microsoft outlook for mac;notification service;overhead (computing);protocol stack;requirement;sensor;taxonomy (general);tinyos	Rajnish Kumar;Santashil PalChaudhuri;Charles Reiss;Umakishore Ramachandran	2006		10.1007/11943952_67	embedded system;wireless sensor network;computer science;operating system;mobile computing;computer security;computer network	Mobile	-29.165410534805872	42.07561957903904	116761
7090a794bccb078c38c90a531ea4cb47800ee13d	computer interconnection structures: taxonomy, characteristics, and examples	distributed processing;distributed computing;computer network;computer architecture	This paper presents a taxonomy, or naming scheme, for systems of interconnected computers. I t is an attempt to provide an implementation-independent method by which to identify demgns, and a common context in which to discuss them. The taxonomy is based on interprocessor message handling and hardware interconnection topology, and distinguishes ten basic multiple-computer architectures. Various relevant attributes are identified and discussed, and examples of actual designs are given for each architecture.	computer architecture;evolutionary taxonomy;interconnection;taxonomy (general)	George A. Anderson;E. Douglas Jensen	1975	ACM Comput. Surv.	10.1145/356654.356658	distributed algorithm;computer architecture;computing;computer science;theoretical computer science;distributed computing;distributed system security architecture;distributed design patterns;computer network programming;computer network operations	Arch	-26.448478482995878	45.13784185556686	116928
0614aa66db4e6f15e1ce39b130db76f075a8029c	transactional correctness for secure nested transactions - (extended abstract)	critical feature;secure nested transaction;transactional property;multi-level database security;language-based security;enterprise application;transactional semantics;transactional correctness;tauzero calculus;secure nested transactions;traditional nested transaction	Secure Nested Transactions are an adaptation of traditional nested transactions to support the synergy of language-based security and multi-level database security. They have application in security for enterprise applications, where transactional semantics are a critical feature in middleware systems. This article considers correctness in terms of transactional properties for secure nested transactions. Correctness is expressed in terms of a labeled transition system, the TauZero calculus.	correctness (computer science)	Dominic Duggan;Ye Wu	2011		10.1007/978-3-642-30065-3_11	real-time computing;computer science;database;distributed computing	Theory	-30.707524484491966	34.935323426658485	116933
832ead113d302c494d191587e44bd37e65980306	programming with managed time	live programming;programming models	Most languages expose the computer's ability to globally read and write memory at any time. Programmers must then choreograph control flow so all reads and writes occur in correct relative orders, which can be difficult particularly when dealing with initialization, reactivity, and concurrency. Just as many languages now manage memory to unburden us from properly freeing memory, they should also manage time to automatically order memory accesses for us in the interests of comprehensibility, correctness, and simplicity. Time management is a general language feature with a large design space that is largely unexplored; we offer this perspective to relate prior work and guide future research.  We introduce Glitch as a form of managed time that replays code for an appearance of simultaneous memory updates, avoiding the need for manual order. The key to such replay reaching consistent program states is an ability to reorder and rollback updates as needed, restricting the imperative model while retaining the basic concepts of memory access and control flow. This approach can also handle code to enable live programming that incrementally revises program executions in an IDE under arbitrary code changes.	arbitrary code execution;concurrency (computer science);control flow;correctness (computer science);glitch;imperative programming;interactive programming;memory management;programmer	Sean McDirmid;Jonathan Edwards	2014		10.1145/2661136.2661145	real-time computing;computer science;theoretical computer science;operating system;overlay;programming paradigm;programming language;algorithm	PL	-21.228969042201335	35.387832662400086	117107
033c17fdf8bfc0512d975db21114a3eabd11136e	chasing the weakest system model for implementing ω and consensus	fault tolerant distributed consensus;distributed algorithms;distributed system;partial synchrony distributed systems failure detectors fault tolerant distributed consensus system modeling;detectors;computer society;complexity theory;fault tolerant;system modeling;distributed consensus;communication complexity weakest system model leader election oracle broadcast steps unicast steps;communication complexity;failure detectors;leader election oracle;distributed algorithms communication complexity;fault tolerant systems;failure detector;fault detection;fault tolerance;nominations and elections;leader election;broadcasting;distributed systems;unicast delay broadcasting nominations and elections detectors computer society complexity theory fault detection fault tolerant systems modeling;weakest system model;modeling;broadcast steps;unicast steps;lower bound;unicast;partial synchrony	Aguilera et al. and Malkhi et al. presented two system models, which are weaker than all previously proposed models where the eventual leader election oracle Omega can be implemented, and thus, consensus can also be solved. The former model assumes unicast steps and at least one correct process with f outgoing eventually timely links, whereas the latter assumes broadcast steps and at least one correct process with f bidirectional but moving eventually timely links. Consequently, those models are incomparable. In this paper, we show that Omega can also be implemented in a system with at least one process with f outgoing moving eventually timely links, assuming either unicast or broadcast steps. It seems to be the weakest system model that allows to solve consensus via Omega-based algorithms known so far. We also provide matching lower bounds for the communication complexity of Omega in this model, which are based on an interesting ldquostabilization propertyrdquo of infinite runs. Those results reveal a fairly high price to be paid for this further relaxation of synchrony properties.	algorithm;communication complexity;consensus (computer science);leader election;linear programming relaxation;omega;sergio verdú;unicast	Martin Hutle;Dahlia Malkhi;Ulrich Schmid;Lidong Zhou	2009	IEEE Transactions on Dependable and Secure Computing	10.1109/TDSC.2008.24	distributed algorithm;fault tolerance;real-time computing;systems modeling;computer science;distributed computing;computer security;computer network	Theory	-22.16728755347248	44.074939316698675	117256
fc2f566c2621700992d523d1e303de7ba0520537	the design of an inter-task communication scheme	operating system;message passing;inter task communication;software design	Abstract#R##N##R##N#The paper describes an implemented inter-task communication scheme, and its design motivation. The scheme provides a well-defined environment for all situations, including abnormal ones, such as misuse of its facilities. The main design goal is that users of the scheme should be able to verify their communication logic by inspection. Methods are described for reducing the complexity of communication logic to a minimum. The analogy with inter-CPU communication is discussed.	inter-process communication	J. K. R. Barnett	1980	Softw., Pract. Exper.	10.1002/spe.4380101005	message passing;real-time computing;computer science;software design;theoretical computer science;operating system;distributed computing;programming language	HPC	-24.246878057361293	41.66858017307933	117442
0df648ebf5377e8dd2bfc98b01472253bedd9018	exploiting the internet inter-orb protocol interface to provide corba with fault tolerance	total order;fault tolerant;internal structure;group communication;internet inter orb protocol;object request broker	The Eternal system is a CORBA 2.0-compliant system that provides, in addition to the location transparency and the interoperability inherent in the CORBA standard, support for replicated objects and thus fault tolerance. Eternal exploits the Internet Inter-ORB Protocol (IIOP) interface to ‘‘attach’’ itself transparently to objects operating over a commercial CORBA Object Request Broker (ORB). The Eternal Interceptor captures the IIOP system calls of the objects, and the Eternal Replication Manager maps these system calls onto a reliable totally ordered multicast group communication system. No modification to the internal structure of the ORB is necessary, and fault tolerance is provided in a manner that is transparent to both the application and the ORB.	common object request broker architecture;fault tolerance;general inter-orb protocol;group communication system;han unification;interceptor pattern;internet;interoperability;interrupt;map;multicast;palo;replication (computing);system call	Priya Narasimhan;Louise E. Moser;P. M. Melliar-Smith	1997			embedded system;interoperable object reference;real-time computing;computer science;object request broker;csiv2;common object request broker architecture;distributed computing	Networks	-26.56848659929035	46.152090613483686	117679
223f29010e0b471d58509e9c8d54825c4b287377	estimation of energy consumption for tinyos 2.x-based applications	wireless sensor network	The development of energy-efficient applications for wireless sensor networks requires mechanisms and tools for run-time monitoring of energy consumption. We propose a software framework that supports energy profiling of applications for the TinyOS 2.x platform. Measurements are obtained through the insertion of software probes within the code of the operating system. As a consequence, since the APIs are not changed, the programmer is not forced to modify the code of existing applications. The technique has been validated by comparing its results with the values registered by dedicated hardware. c © 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of [name organizer]	electronic organizer;operating system;programmer;software framework;tinyos	Stefano Abbate;Marco Avvenuti;Daniel Cesarini;Alessio Vecchio	2012		10.1016/j.procs.2012.06.167	embedded system;real-time computing;computer science;operating system;nesc	Embedded	-23.39338927111398	39.25286551239976	117738
239e96a72a8348e9d4ebb6934b8e3fc6f8b80a9e	dynamic light-weight groups	protocols;group communication;horus system virtual synchrony model group communication distributed applications performance gains virtual synchrony light weight group service protocols dynamic environments heuristics;dynamic environment;application software intersymbol interference computer science protocols detectors bandwidth power system reliability file systems file servers network servers;performance improvement;resource sharing;technical report;computer science;communication protocols;virtual synchrony;computer network reliability;computer network reliability protocols	The virtual synchrony model for group communication has proven to be a powerful paradigm for building distributed applications. In applications that use a large number of groups, signi cant performance gains can be attained if these groups share the resources required to provide virtual synchrony. A service that maps user groups onto instances of a virtually synchronous implementation is called a LightWeight Group Service. This paper discusses the Light-Weight Group protocols in dynamic environments, where mappings cannot be de ned a priori and may change over time. We show that it is possible to establish mappings that promote sharing and, at the same time, minimize interference. These mappings can be established in an automated manner, using heuristics applied locally at each node. Experiments using an implementation in the Horus system show that signi cant performance improvements can be achieved with this approach. Selected section of this report were published in the Proceedings of the 17th IEEE International Conference on Distributed Computing Systems, Baltimore, Maryland, USA, May, 1997. This work was partially supported by the CEC, through ESPRIT/ BRA Working Group 26 (GODC) and the ARPA/ONR grant N00014-92-J-1866.	distributed computing;experiment;heuristic (computer science);icdcs;interference (communication);map;ping (networking utility);programming paradigm;virtual synchrony	Katherine Guo;Luís E. T. Rodrigues	1997		10.1109/ICDCS.1997.597806	communications protocol;real-time computing;computer science;theoretical computer science;operating system;database;distributed computing;computer security;computer network;gbcast	HPC	-25.620646490595906	46.34402214271409	117987
41d7bb1bd8dfac19d0844b02a96baa6b1f1d9c5e	towards a compositional method for coordinating gamma programs	parallel and distributed computing;network programming	With the growing complexity of software, incurred by the widespread acceptance of parallel and distributed computer systems and networks, program design would bene t from clearly separating the correctness issues (the computation) from e ciency issues (the coordination). Gamma has shown to be a powerful and expressive programming model that allows the basic computations of a program to be expressed with a minimum of control. This enables the programmer to defer e ciency related decisions until a second stage in the design process. In support of this second activity we introduce in this paper a coordination language that exploits the highly nondeterministic behaviour of Gamma to impose additional control. Furthermore, we propose a compositional notion of re nement that can be used to reason about coordination of Gamma programs. This notion induces a number of re nement laws that can be used in an algebraic style of reasoning. Some examples are presented to illustrate application of these laws. A short version of this report appears as [10].	bisimulation;computation;computer;correctness (computer science);linear algebra;nondeterministic algorithm;programmer;programming model;unique name assumption	Michel R. V. Chaudron;Edwin D. de Jong	1996		10.1007/3-540-61052-9_42	real-time computing;computer science;distributed computing;programming language;computer network programming	PL	-27.334655681057896	33.11464139279002	118292
6213d91976b1943182e21dd28e3f6d8d34c1a909	adore-ar: software architecture reconstruction with partitioning and clustering			cluster analysis;software architecture	Jean-Francois Girard	2005				SE	-31.540551496871416	45.640985456889304	118419
88ff0f40309ac265da6ce7828a05e01e6faeb667	salient features of an executable specification language and its environment	parallel processing monitoring specification languages functional programming computational modeling;distributed system;simplicity executable specification language paisley computer languages parallelism mutual exclusion timing constraints automated checking;systeme reparti;programming environments;lenguaje de computadora;executable specification;interpreters;functional programming;executable specifications;langage ordinateur;user interfaces distributed systems executable specifications functional programming interpreters language design operational approach to software development parallelism performance simulation programming environments real time systems;parallelism;computational modeling;sistema repartido;monitoring;specification languages;operational approach to software development;computer language;distributed systems;user interfaces;language design;parallel processing;performance simulation;real time systems	The executable specification language PAISLey and its environment are presented as a case study in the design of computer languages. It is shown that PAISLey is unusual (and for some features unique) in having the following desirable features: (1) there is both synchronous and asynchronous parallelism free of mutual-exclusion problems, (2) all computations are encapsulated, (3) specifications in the language can be executed no matter how incomplete they are, (4) timing constraints are executable, (5) specifications are organized so that bounded resource consumption can be guaranteed, (6) almost all forms of inconsistency can be detected by automated checking, and (7) a notable degree of simplicity is maintained. Conclusions are drawn concerning the differences between executable specification languages and programming languages, and potential uses for PAISLey are given.	computation;computer language;executable;mutual exclusion;parallel computing;programming language;specification language	Pamela Zave;William Schell	1986	IEEE Transactions on Software Engineering	10.1109/TSE.1986.6312946	parallel processing;real-time computing;interpreter;computer science;theoretical computer science;operating system;programming language;functional programming;user interface;computational model	SE	-25.575623560657835	34.09649297334401	118469
ddedcc47d8326c4dc4dad226fa432b1b91389796	mpi: multiple perspective attack investigation with semantic aware execution partitioning		Traditional auditing techniques generate large and inaccurate causal graphs. To overcome such limitations, researchers proposed to leverage execution partitioning to improve analysis granularity and hence precision. However, these techniques rely on a low level programming paradigm (i.e., event handling loops) to partition execution, which often results in low level graphs with a lot of redundancy. This not only leads to space inefficiency and noises in causal graphs, but also makes it difficult to understand attack provenance. Moreover, these techniques require training to detect low level memory dependencies across partitions. Achieving correctness and completeness in the training is highly challenging. In this paper, we propose a semantics aware program annotation and instrumentation technique to partition execution based on the application specific high level task structures. It avoids training, generates execution partitions with rich semantic information and provides multiple perspectives of an attack. We develop a prototype and integrate it with three different provenance systems: the Linux Audit system, ProTracer and the LPM-HiFi system. The evaluation results show that our technique generates cleaner attack graphs with rich high-level semantics and has much lower space and time overheads, when compared with the event loop based partitioning techniques BEEP and ProTracer.	beep;causal graph;correctness (computer science);event (computing);event loop;high- and low-level;high-level programming language;linux;longest prefix match;low-level programming language;programming paradigm;prototype	Shiqing Ma;Juan Zhai;Fei Wang;Kyu Hyung Lee;Xiangyu Zhang;Dongyan Xu	2017			computer science;theoretical computer science;distributed computing	Security	-21.538258621403344	39.611602958082116	118472
6652d5f826d74268b79d70c1e142e8f2d756fece	"""performability evaluation of multipurpose multiprocessor systems: the """"separation of concerns"""" approach"""	performance measure;distributed memory systems;electronic commerce;service level;performance evaluation;multiprocessor systems;e commerce;separation of concern;stochastic reward net;dependability and performability evaluation;environmental concern;reference systems;stochastic reward nets;shared memory systems;internet;stochastic processes;cluster system;software component;clustered systems;multipurpose multiprocessors systems;distributed shared memory;modular modeling	The aim of our work is to provide a modeling framework for evaluating performability measures of Multipurpose, Multiprocessor Systems (MMSs). The originality of our approach is in the explicit separation between the architectural and environmental concerns of a system. The overall dependability model, based on stochastic reward nets, is composed of 1) an architectural model describing the behavior of system hardware and software components, 2) a service-level model, and 3) a maintenance policy model. The two latter models are related to the system utilization environment. The results can be used for supporting the manufacturer design choices as well as the potential end-user configuration selection. We illustrate the approach on a particular family of MMSs under investigation by a system manufacturer for Internet and e-commerce applications. As the systems are scalable, we consider two architectures: a reference one composed of 16 processors and an extended one with 20 processors. Then, we use the obtained results to evaluate the performability of a clustered system composed of four reference systems. We evaluate comprehensive measures defined with respect to the end-user service requirements and specific measures in relation to the distributed shared memory paradigm.		Mourad Rabah;Karama Kanoun	2003	IEEE Trans. Computers	10.1109/TC.2003.1176988	e-commerce;distributed shared memory;embedded system;parallel computing;real-time computing;the internet;service level;separation of concerns;computer science;component-based software engineering;operating system;distributed computing;programming language	Embedded	-31.763376281477484	43.8136593572255	118491
0c68d5afbef2eed7754bad500c246fe4ca57cf61	an ensemble-level programming model with real-time support for multi-robot systems	simulator ensemble level programming model real time support multirobot system programming rmr real time programming for multiple robots mrs timing constraints logic programming model robot ensemble;robot sensing systems;robot kinematics programming robot sensing systems real time systems timing;robot programming digital simulation logic programming multi robot systems real time systems;programming;robot kinematics;real time systems;timing	In this paper, we propose a novel programming model RMR (Real-time programming for Multiple Robots) targeting at programming multi-robot system (MRS) with timing constraints. RMR is a logic programming model with real-time support. In the light of the logic programming paradigm, RMR allows developers to write simple code to accomplish complex tasks and deploy the program in MRS in an efficient way. Moreover, RMR supports timing constraints on the behaviors of an ensemble of robots, which is not implemented by existing works. We deploy RMR in a simulator and a test-bed to test its performance in both cyber and physical world, and then demonstrate RMR based on several applications. This paper presents our current prototype.	logic programming;minimal recursion semantics;programming model;prototype;real-time clock;real-time computing;real-time transcription;robot;testbed	Shan Jiang;Junbin Liang;Jiannong Cao;Rui Liu	2016	2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops)	10.1109/PERCOMW.2016.7457070	programming;constraint programming;real-time computing;simulation;reactive programming;functional reactive programming;computer science;artificial intelligence;event-driven programming;inductive programming;robot kinematics	Robotics	-31.968606348283892	36.32589887942682	118596
0311aef2b503dc265a514c152f3951495b98d4f8	xml-enabled workflow management for e-services across heterogeneous platforms	systeme gestion electronique document;commerce electronique;evaluation performance;extensible markup language;groupware;workflow management;fonction potentiel;comercio electronico;performance evaluation;red www;interoperabilite;xml xsl;evaluacion prestacion;flot donnee;internet e services;flujo datos;flujo informacion;flux information;internet technology;information flow;internet;electronic document management system;information system interoperability;funcion potencial;xml;workflow;world wide web;reseau www;interoperability;information system;data flow;potential function;flow control;collecticiel;sistema gestion electronica documento;systeme information;electronic trade;business process;oracle;business processes;sistema informacion	Advanced e-services require efficient, flexible, and easy-to-use workflow technology that integrates well with mainstream Internet technologies such as XML and Web servers. This paper discusses an XML-enabled architecture for distributed workflow management that is implemented in the latest version of our Mentor-lite prototype system. The key asset of this architecture is an XML mediator that handles the exchange of business and flow control data between workflow and business-object servers on the one hand and client activities on the other via XML messages over http. Our implementation of the mediator has made use of Oracle's XSQL servlet. The major benefit of the advocated architecture is that it provides seamless integration of client applications into e-service workflows with scalable efficiency and very little explicit coding, in contrast to an earlier, Java-based, version of our Mentor-lite prototype that required much more code and exhibited potential performance problems.	business object;e-services;hypertext transfer protocol;java;matchware mediator;prototype;scalability;seamless3d;xml	German Shegalov;Michael Gillmann;Gerhard Weikum	2000	The VLDB Journal	10.1007/s007780100038	workflow;xml;computer science;operating system;database;business process;windows workflow foundation;world wide web;workflow management system;workflow engine;workflow technology	DB	-29.989713445203993	43.56417291716083	118631
062573c3ff4fc5c56332105f26689701e10fa467	powerpc 603 microprocessor power management	software;aplicacion;visualizacion;analisis datos;logiciel;interaction;simulation;simulacion;interfase;data analysis;visualization;visualisation;interface;power management;logicial;analyse donnee;interaccion;application	Addressing the need for long battery life in portable applications and environmental concerns about energy consumption requires microprocessors with low power consump tion as well as high performance. A primary design goal of the PowerPC 603 microprocessor was to provide sophisticated power management without compromising nextgenera-tion performance. As a result, the 603 is ideal for portable applications such as laptop computers in addition to Energy Star compliant desktop computers. The PowerPC 603 allows the system designer to control energy consumption through both hardware and software means as well as providing automatic internal power management.	desktop computer;laptop;microprocessor;power management;powerpc 600;systems design	Brad W. Suessmith;George Paap	1994	Commun. ACM	10.1145/175208.175213	embedded system;simulation;visualization;computer science;operating system;programming language;statistics;computer graphics (images)	Arch	-27.229834651641205	39.02671501718731	118675
eac958198fdeba4ffab98a0807714f7e7b4cdab4	stack bounds analysis for microcontroller assembly code	verification;assembly code;model checking;static analysis;embedded software	An important criterion for correctness of embedded software is stack safety, which requires that the stack must never overflow. This paper presents a static analysis for assembly code that determines upper and lower bounds of the stack. These bounds serve two purposes. First, they can be used to verify stack safety. Second, they can be used to increase the precision of several other static analyses, which are used in the context of model checking. Interrupts play an important role in embedded software, but they are a major challenge for the static analysis of stack bounds. In different micro--controller architectures, the handling of interrupts varies. In some architectures, interrupt handlers are executed atomically, while in others, they are interruptible. Therefore, we applied this analysis to two different microcontrollers, namely the ATMEL ATmega16 and the Intel MCS-51. In a case study, we show the applicability and efficiency of this analysis.	assembly language;correctness (computer science);embedded software;intel mcs-51;interrupt handler;microcontroller;model checking;static program analysis	Jörg Brauer;Bastian Schlich;Thomas Reinbacher;Stefan Kowalewski	2009		10.1145/1631716.1631721	embedded system;stack trace;real-time computing;call stack;computer science;operating system	Embedded	-23.41860055420865	35.94816220704949	118741
94705959fc252545597952beba6fb9e67fa54885	a configurable cryptography subsystem in a middleware framework for embedded systems	distributed system;systeme reparti;systeme grande taille;systeme embarque;network security;securite informatique;reseau ordinateur;logicial personalizado;corba;large scale system;embedded system;computer network;subsystem;intergiciel;computer security;embedded systems;it security;sistema repartido;sous systeme;object oriented;criptografia;cryptography;security requirements;seguridad informatica;interconnected system;sistema interconectado;red informatica;oriente objet;cryptographie;system development;middleware;systeme interconnecte;security;orientado objeto;subsistema;sistema gran escala	Computer and network security is becoming increasingly important as both large systems and, increasingly small, embedded systems are networked. Middleware frameworks aid the system developer who must interconnect individual systems into larger interconnected, distributed systems. However, there exist very few middleware frameworks that have been designed for use with embedded systems, which constitute the vast majority of CPUs produced each year, and none offer the range of security mechanisms required by the wide range of embedded system applications. This paper describes MicroQoSCORBA, a highly configurable middleware framework for embedded systems, and its security sub-system. It first presents an analysis of security requirements for embedded applications and what can and should be done in middleware. It then presents the design of MicroQoSCORBA's security subsystem and the wide range of mechanisms it supports. Experimental results for these mechanisms are presented for two different embedded systems and one desktop computer that collectively represent a wide range of computational capabilities.	cryptography;embedded system;middleware	A. David McKinnon;David E. Bakken;John C. Shovic	2004	Computer Networks	10.1016/j.comnet.2004.06.020	embedded system;embedded operating system;middleware;real-time computing;computer science;cryptography;network security;operating system;middleware;computer security	Theory	-28.00511097726146	41.76929625136741	118792
e4ed47a874eb0342517f2964df1619e65c4df504	definition and analysis of hardware- and software-fault-tolerant architectures	software fault tolerance;computer architecture;fault tolerant computing;fault tolerant computing computer architecture;normal operator;cost issues hardware fault tolerant architectures software fault tolerant architectures;computer architecture fault detection hardware system testing software safety computer errors automatic testing software testing sequential analysis parallel programming	A structured definition of hardware- and software-fault-tolerant architectures is presented. Software-fault-tolerance methods are discussed, resulting in definitions for soft and solid faults. A soft software fault has a negligible likelihood or recurrence and is recoverable, whereas a solid software fault is recurrent under normal operations or cannot be recovered. A set of hardware- and software-fault-tolerant architectures is presented, and three of them are analyzed and evaluated. Architectures tolerating a single fault and architectures tolerating two consecutive faults are discussed separately. A sidebar addresses the cost issues related to software fault tolerance. The approach taken throughout is as general as possible, dealing with specific classes of faults or techniques only when necessary.<<ETX>>	schedule (computer science);software fault tolerance	Jean-Claude Laprie;Jean Arlat;Christian Béounes;Karama Kanoun	1990	Computer	10.1109/2.56851	computer architecture;parallel computing;real-time computing;fault coverage;computer science;stuck-at fault;fault model;general protection fault;normal operator;software fault tolerance	Arch	-23.233212680642115	41.43243387055713	118869
203f8eb4c996a587278409085b8e5e73f639cc16	net-dbx: a java powered tool for interactive debugging of mpi programs across the internet	eficacia sistema;client server architecture;architecture client serveur;java programming;graphical interface;programacion paralela;sistema informatico;performance systeme;parallel programming;computer system;object oriented programming;satisfiability;system performance;internet;programa puesta a punto;arquitectura cliente servidor;systeme informatique;programmation orientee objet;programme debogage;debugging program;programmation parallele	This paper describes Net-dbx, a tool that utilizes Java and other WWW tools for the debugging of MPI programs from anywhere in the Internet. Net-dbx is a source level interactive debugger with the full power of gdb augmented with the debug functionality of LAM-MPI. The main eeort was on a low overhead but yet powerful graphical interface that would be supported by low bandwidth connections. The portability of the tool is of great importance as well because it enables us to use it on heterogeneous nodes that participate in an MPI multicomputer. Both needs are satissed a great deal by the use of Internet Browsing tools and the Java programming language. The user of our system simply points his browser to the URL of the Net-dbx page, logs in to the destination system, and starts debugging by interacting with the tool just like any GUI environment. The user has the ability to dynamically select which MPI-processes to view/debug. A working prototype has already been developed and tested successfully.	browsing;dbx (debugger);debugging;gnu debugger;graphical user interface;interaction;internet;java;message passing interface;overhead (computing);parallel computing;programming language;prototype;www	Neophytos Neophytou;Paraskevas Evripidou	1998		10.1007/BFb0057851	embedded system;real-time computing;the internet;computer science;operating system;graphical user interface;database;distributed computing;computer performance;debug menu;programming language;background debug mode interface;object-oriented programming;client–server model;satisfiability	HPC	-27.00520160204531	41.04961723842898	118873
34dd6722aa9fc11974e34bae4fa93b7b04824e8f	an asynchronous, decentralised commitment protocol for semantic optimistic replication	replication;optimistic replication;data replication;internet architecture;asynchronous system;commitment;semantic;voting protocols	We study large-scale distributed cooperative systems that use optimistic replication. We represent a system as a graph of actions (operations) connec ted by edges that reify semantic constraints between actions. Constraint types include conflic t, execution order, dependence, and atomicity. The local state is some schedule that conforms to the c onstraints; because of conflicts, client state is only tentative. For consistency, site schedules sh ould converge; we designed a decentralised, asynchronous commitment protocol. Each client makes a prop osal, reflecting its tentative and/or preferred schedules. Our protocol distributes the proposa ls, which it decomposes into semanticallymeaningful units called candidates, and runs an election be tween comparable candidates. A candidate wins when it receives a majority or a plurality. The prot oc l is fully asynchronous: each site executes its tentative schedule independently, and determ in s locally when a candidate has won an election. The committed schedule is as close as possible to t he preferences expressed by clients. Key-words: data replication, optimistic replication, semantic repli cat on, commitment, voting protocols. ∗ LIP6, 104, ave. du Président Kennedy, 75016 Paris, France; mailto:pierre.sutra@lip6.fr Un protocole de validation pour la réplication optimiste dans les syst̀emes ŕepartis śemantiquement riches Résuḿe : Nous examinons à travers ce document la cohérence dans les syst` mes répartis répliquant des données de manière optimiste. Le paradigme de la répl ication optimiste est que les sites composant le système réparti peuvent ré-éxecuter les requ êt s des clients (actions) si la sémantique liant les actions le nécessite. Dans de tels systèmes le critèr e de cohérence est que les sites convergent à terme vers des exécutions équivalentes. Afin d’assurer ce tte onvergence, un protocole de validation est nécessaire. C’est l’objet de cette étude. Notre proto cole procède par éléctions successives sur des ensembles d’actions exécutées de manière optimiste par l système. La sémantique prise en compte dans ce protocole est suffisament riche pour exprimer des not ions telles que la non-commutativité, le conflit ou encore la causalité entre les actions. Nous pro uvons que notre protocole est sûr, et ce en dépit des éventuelles pannes franches pouvant survenir s ur les sites. Mots-clés : réplication optimiste, validation, protocoles de vote An Asynchronous, Decentralised Commitment for Optimistic Semantic Replication 3	atomicity (database systems);commitment ordering;consensus dynamics;converge;graph (discrete mathematics);les houches accords;linear algebra;local variable;operating system abstraction layer;optimistic replication;reactions to the november 2015 paris attacks;replication (computing);schedule (computer science)	Pierre Sutra;Marc Shapiro;João Pedro Barreto	2006	CoRR		asynchronous system;replication;real-time computing;computer science;database;distributed computing;computer security;replication	Security	-24.80687597184318	40.73710531679477	118944
2972a84193bd1be82c2eacf13c4eabfe95749580	performance properties of vertically partitioned object-oriented systems	tolerancia falta;vertically partitioned structure;distributed system;sistema operativo;software engineering object oriented programming performance evaluation;state management functions;evaluation performance;object semantics;design concepts;object oriented system design;systeme reparti;recovery points;layered structures;performance evaluation;fault tolerant;object type;application independent overheads;evaluacion prestacion;program design;sistema informatico;application software costs access control concurrency control error correction fault detection control systems operating systems software performance software systems;vertical partitioning;conception programme;computer system;ingenieria logiciel;object oriented programming;indexing terms;object oriented system implementation;software engineering;orientado objecto;software performance;type manager boundaries;object oriented systems;layered structure;performance improvement;sistema repartido;distributed real time system;atomicity;operating system;design and implementation;conventionally organized systems;object oriented;fault tolerance;genie logiciel;distributed real time system application;oriente objet;distributed real time system application object oriented system design object oriented system implementation vertical partitioning vertically partitioned structure object oriented systems application independent overheads conventionally organized systems layered structures extended type managers design concepts performance improvement object semantics state management functions object type atomicity type manager boundaries recovery points performance evaluation;systeme exploitation;systeme informatique;fiabilite logiciel;fiabilidad logicial;software design;extended type managers;software reliability;tolerance faute;concepcion programa	A vertically partitioned structure for the design and implementation of object-oriented systems is proposed, and their performance is demonstrated. It is shown that the application-independent portion of the execution overheads in object-oriented systems can be less than the application-independent overheads in conventionally organized systems built on layered structures. Vertical partitioning implements objects through extended type managers. Two key design concepts result in performance improvement: object semantics can be used in the state management functions of an object type and atomicity is maintained at the type manager boundaries providing efficient recovery points. The performance evaluation is based on a case study of a simple but nontrivial distributed real-time system application. >		Stephen P. Hufnagel;James C. Browne	1989	IEEE Trans. Software Eng.	10.1109/32.31351	fault tolerance;real-time computing;computer science;operating system;database;distributed computing;programming language;object-oriented programming	SE	-25.21885633561076	41.21247798890762	119024
0e992153fe1cc475b0689a7ee92a518e3ae4b0ed	comparing software architectures for coordination languages	developpement logiciel;distributed system;multiagent system;systeme reparti;formal specification;real time;reseau ordinateur;coordination language;ingenieria logiciel;software engineering;specification language;computer network;specification formelle;synchronisation;especificacion formal;software architecture;sistema repartido;synchronization;desarrollo logicial;temps reel;software development;red ordenador;genie logiciel;tiempo real;lenguaje especificacion;sincronizacion;sistema multiagente;langage specification;systeme multiagent	We discuss three software architectures for coordination. All architectures are based on agents. Each agent has a local dataspace that contains shared distributed replicated data. The three architectures diier in the way agents communicate: either through an unordered broadcast, through an atomic broadcast, or through a synchronization among all agents. We rst show how to represent both data-driven and control-oriented coordination languages in our model. Then we compare the behavior of the three architectures, under the assumption that the local dataspaces are either sets or multisets.	atomic broadcast;dataspaces;software architecture	Marcello M. Bonsangue;Joost N. Kok;Gianluigi Zavattaro	1999		10.1007/3-540-48919-3_12	embedded system;synchronization;real-time computing;computer science;operating system;software engineering;programming language	SE	-28.793445230759474	33.78170532432331	119214
b252c692bb382632117af39d04017c2d3bbcf96c	a modular control system for flexible robotized manufacturing cells	modular control system;handling devices;hardware information;error handling;basic function;control system;additional programming effort;necessary task;flexible robotized manufacturing cell;entire control software;vienna university;object-oriented control system	In co-operation with an Austrian small sized company, the Institute for Handling Devices and Robotics at the Vienna University of Technology started a project with the goal to reduce the time necessary for planning, programming and set-up of robot equipped manufacturing cells. In this contribution a modular, object-oriented control system for robotized cells is presented. This system ‘C_CTRL' is responsible for all necessary tasks, like sequencing, supervising, controlling of basic functions, error handling, and recording of statistic data. The control system is ‘self-generating' during program start-up – using hardware information from a simple ASCII configuration file. Regardless which and how many components used in a particular cell, there is no additional programming effort for generation of the entire control software.	control system	Peter Kopacek;Gernot Kronreif;Robert Probst	1999	Robotica		robot;control engineering;embedded system;simulation;computer science;engineering;control system;artificial intelligence;object-oriented programming;systems design	Robotics	-32.32349903802724	36.95599472717653	119239
2780e0909be4c8045b9d1e448ac63db3f9b4db5f	multi user monitoring and real-time control with st-rtl.	real time control;multi user			Raul Murillo Garcia;David K. Harrison;Brian G. Stewart	2003			real-time computing;multi-user;computer science;real-time control system	Embedded	-30.273898455818923	38.4658727029766	119607
cd3f687a0626c59ef18cf7c5702a7a01455c9cec	an algorithm for solving the distributed termination detection problem	distributed system;termination detection;distributed computing;distributed termination;asynchronous communication;message passing;mpi	Abstract In this paper we present an algorithm for solving the distributed termination detection problem. In particular, a strategy based on message counting is used to detect the termination of a distributed computation consisting of a set of processes asynchronously communicating over communication links. The proposed algorithm does not require the FIFO property for the communication links. The assumptions regarding the connectivity of the processes are very simple. For the proposed algorithm we demonstrate the correctness, we evaluate the message and the bit complexity and we give a detailed description of a MPI implementation.	algorithm	Giovanni Aloisio;Patrizia Beraldi;Massimo Cafaro;Francesca Guerriero;Roberto Musmanno	1999	Parallel Algorithms Appl.	10.1080/10637199808947383	distributed algorithm;message passing;real-time computing;computer science;message passing interface;theoretical computer science;asynchronous communication;distributed computing	Logic	-22.30969959100572	43.00204313004271	119829
b75d8af327dc984c72f406190003e8b96d2c0377	timed weak simulation verification and its application to stepwise refinement of real-time software	systeme temps reel;calculateur embarque;pervasive computing;real time;real time operating system;fixed priority;program verification;informatica difusa;refinement method;verificacion programa;design method;informatique diffuse;real time scheduling;temps reel;boarded computer;tiempo real;real time system;sistema tiempo real;methode raffinement;verification programme;metodo afinamiento;calculador embarque	Real-time software runs over real-time operating systems, and guaranteeing qualities are difficult. In this paper, we propose timed weak simulation relation verification and apply it to a refinement design method of real-time software. Moreover, we apply our proposed method to general real-time software scheduled by fixed-priority preemptive policy.	automata theory;embedded system;formal verification;hybrid automaton;information and computation;journal of computer and system sciences;lecture notes in computer science;model checking;real-time cmix;real-time clock;real-time computing;real-time locating system;real-time operating system;real-time transcription;refinement (computing);scheduling (computing);simulation;software engineering;stepwise regression;timed automaton;top-down and bottom-up design	Satoshi Yamane	2005		10.1007/11596356_40	embedded system;real-time computing;real-time operating system;software sizing;design methods;human–computer interaction;software verification;computer science;operating system	Embedded	-24.159234447705035	32.872743121987625	120103
fe5204151cd907ce8a95b3889e77f43b1f8887e9	safety in multi-robot teleoperation system through internet	multi operator multi robot teleoperation system;multi layer safety architecture;real time control;multi operator multi robot momr;safety systems;real time control layer;internet software safety robots hardware fault trees us department of transportation logic computer architecture monitoring collaboration;telerobotics fault trees internet multi robot systems safety systems;internet;collaborative control layer;multi layer safety architecture internet multi operator multi robot teleoperation system multi layer safety structure fault tree analysis interactive monitor layer collaborative control layer real time control layer;safety;multi robot systems;telerobotics;multi layer safety structure;high performance;teleoperation multi operator multi robot momr safety;interactive monitor layer;fault tree analysis;teleoperation;fault trees	Internet based multi-operator multi-robot (MOMR) teleoperation system allow the accomplishment of tasks that a single robot could not approach due to restrictions associated to the product and /or the robot. The safety issue in the system is an important problem according to its complexity. This paper describes the development of multi-layer safety structure of the safety subsystem which consists of software modules as well as hardware components after the threat analysis of the system using fault tree analysis (FTA) technology. The subsystem is divided into three layers with its logic architecture: interactive monitor layer, collaborative control layer and real-time control layer. The safety problems and the related strategy are clarified by detailed analysis of each layer and relationship among the layers. So we can get a high performance MOMR teleoperation system with multi-layer safety architecture	internet;robot	Yongsheng Gao;Jie Zhao;Hegao Cai	2004		10.1109/ROBIO.2004.1521797	embedded system;real-time computing;simulation;fault tree analysis;computer science;engineering;artificial intelligence	Robotics	-32.92638932197464	37.701813778912076	120208
30844418803852ecc22f4ede7f241035ec7dfe48	asserting and checking determinism for multithreaded programs	assertions;determinism;parallel programs	The trend towards processors with more and more parallel cores is increasing the need for software that can take advantage of parallelism. The most widespread method for writing parallel software is to use explicit threads. Writing correct multithreaded programs, however, has proven to be quite challenging in practice. The key difficulty is non-determinism. The threads of a parallel application may be interleaved non-deterministically during execution. In a buggy program, non-deterministic scheduling will lead to non-deterministic results - some interleavings will produce the correct result while others will not.  We propose an assertion framework for specifying that regions of a parallel program behave deterministically despite non-deterministic thread interleaving. Our framework allows programmers to write assertions involving pairs of program states arising from different parallel schedules. We describe an implementation of our deterministic assertions as a library for Java, and evaluate the utility of our specifications on a number of parallel Java benchmarks. We found specifying deterministic behavior to be quite simple using our assertions. Further, in experiments with our assertions, we were able to identify two races as true parallelism errors that lead to incorrect non-deterministic behavior. These races were distinguished from a number of benign races in the benchmarks.	assertion (software development);benchmark (computing);central processing unit;deterministic algorithm;experiment;forward error correction;java;multithreading (computer architecture);nondeterministic algorithm;parallel computing;programmer;scheduling (computing);software bug;thread (computing)	Jacob Burnim;Koushik Sen	2009		10.1145/1595696.1595700	parallel computing;real-time computing;computer science;programming language;determinism	SE	-20.277607707058536	39.0885008709043	120232
31adcfb13cb5c036d54054bda5c68ad75ec52a0f	what service replication middleware can learn from object replication middleware	distributed system;replication;service orientation;distributed objects;service oriented systems;distributed object system;object replication;middleware;distributed object systems;architecture	Replication is a well-known technique to enhance dependability and performance in distributed systems. A plethora of replication middleware for distributed object systems has been proposed in the past decade. However, replication in service-oriented systems is still in its infancy. In this paper, we analyze some of the proposed service replication middleware solutions and compare them on an architectural level with object replication middleware. In particular, we focus on replication middleware that allows for (but is not limited to) strict consistency of replicas since this is required by many real-life applications. We identify six major infrastructure components and present a generalized architecture for both distributed object and service-oriented replication middleware. The result of our comparison is unambiguous: Replication middleware for service-oriented systems and distributed object systems (such as FT-CORBA) share many commonalities and only subtle differences caused by the different granularity of the replicated entity, or different transaction models.	common object request broker architecture;dependability;distributed computing;distributed object;linearizability;middleware;real life;service-oriented architecture;service-oriented device architecture	Johannes Osrael;Lorenz Froihofer;Karl M. Göschka	2006		10.1145/1169091.1169094	middleware;real-time computing;computer science;object request broker;message oriented middleware;middleware;database;distributed computing;distributed object;replication	HPC	-33.150846883555644	44.97007043563748	120372
46fc9e6f0b7de23e8379bf99e2c5931793b599b7	spread: a distributed simulation toolkit	distributed simulation	this article describes “SPREAD”, a simulation tool kit and its use in building “Virtual Robots”, a simulation of multiple mobile robot vehicles used in the teaching of Computer Science at university level. A novel aspect of the simulator is the use of PVM [1] to achieve high performance at low cost by using spare CPU cycles on large numbers of networked workstations.	0 a.d.;central processing unit;computer cluster;computer science;display resolution;khepera mobile robot;list of toolkits;mobile robot;neurocomputing;parallel virtual machine;photocopier;simulation;workstation;xmouse	Paul Chernett;Victor Callaghan;C. Ching;D. Diemmi	1998	Computer Science Education	10.1076/csed.8.3.228.7090	simulation;computer science;engineering;software engineering;programming language;computer graphics (images)	Robotics	-31.75531197762011	37.81884941137084	120442
4b11a2de19a9e0d33d34ebd545877f736099fc9f	inspecting gnu radio applications with controlport and performance counters	profiling;gnu radio;software radio;signal processing	Due to differences in the operating system and the effects of sample rate on the computational load of a software radio, we have historically had a difficult time understanding the performance boundaries of software radio applications. This problem further leads to difficulties in debugging, optimization, and profiling analysis of both software radio frameworks and applications.  This paper introduces a new tool developed for GNU Radio that starts to solve these problems. Called Performance Counters, GNU Radio now has an inbuilt ability to measure its performance for offline optimization as well as real-time behavioral analysis and adaptation. The Performance Counters are designed such that a GNU Radio application can directly sample them or access them through the use of ControlPort, another new tool that enables remote interaction with GNU Radio. We show in this paper some of the tools we have developed around ControlPort and the Performance Counters that will help us better understand GNU Radio's performance and capabilities as well as lead to better on-line adaptation of radios.	canonical account;debugging;gnu radio;hardware performance counter;interaction;mathematical optimization;online and offline;operating system;real-time clock;sampling (signal processing);simulation	Thomas W. Rondeau;Timothy O'Shea;Nathan Goergen	2013		10.1145/2491246.2491259	embedded system;real-time computing;computer science;operating system	HCI	-20.328272842735206	38.082355519238774	120473
0f04a0b658f00f329687d8ba94d9fca25269b4b7	extensibility, safety and performance in the spin operating system	co location;sistema operativo;logical protection;system core;securite;performance;nucleo sistema;reseau;supercomputer;dynamic linking;noyau systeme;spin;red;supercomputador;enforced modularity;operating system;dynamic call binding;safety;arquitectura;systeme exploitation;rendimiento;seguridad;architecture;superordinateur;network	This paper describes the motivation, architecture and performance of SPIN, an extensible operating system. SPIN provides an extension infrastructure, together with a core set of extensible services, that allow applications to safely change the operating system’s interface and implementation. Extensions allow an application to specialize the underlying operating system in order to achieve a particular level of performance and functionality. SPIN uses language and link-time mechanisms to inexpensively export fine-grained interfaces to operating system services. Extensions are written in a type safe language, and are dynamically linked into the operating system kernel. This approach offers extensions rapid access to system services, while protecting the operating system code executing within the kernel address space. SPIN and its extensions are written in Modula-3 and run on DEC Alpha workstations.	address space;dec alpha;daemon (computing);extensibility;kernel (operating system);linker (computing);modula-3;operating system;spin;type safety;workstation	Brian N. Bershad;Stefan Savage;Przemyslaw Pardyak;Emin Gün Sirer;Marc E. Fiuczynski;David Becker;Craig Chambers;Susan J. Eggers	1995		10.1145/224056.224077	embedded system;embedded operating system;supercomputer;real-time computing;performance;computer science;architecture;operating system;spin;process control block;computer security	OS	-26.31524099797207	42.56170857127067	120580
eda8176b38add90c3bbe6be7096e5d3dca339359	a component-based application development, test, and evaluation environment for network applications	application development			M. M. McMahon	2004			computer science	SE	-32.81871634080266	45.346428635319604	120582
08f0db4bb00a9edfce6acc26a94af30fb312c2f2	recovery techniques for database systems	database system;distributed processing;operating system;file system;parallel processing	A survey of techniques and tools used in filing systems, database systems, and operating systems for recovery, backing out, restart, the mamtenance of consistency, and for the provismn of crash resistance is given. A particular view on the use of recovery techmques in a database system and a categorization of different kinds of recovery and recovery techmques and basic principles are presented. The purposes for which these recovery techniques can be used are described Each recovery techmque is illustrated by examples of its application in exmtlng systems described in the literature. A main conclusion from this survey is that the recovery techmques described are all useful; they are applied for different purposes and m different envLronments. However, a certain trend in the increasing use of specific techniques during the past few years can be noted. Another main conclusion is tha t there are still enormous integrity and recovery problems to be solved for parallel processes and distributed processing.	categorization;database;distributed computing;operating system	Joost Verhofstad	1978	ACM Comput. Surv.	10.1145/356725.356730	parallel processing;real-time computing;computer science;operating system;data mining;database	DB	-25.63868998281352	45.42434341356099	120616
f6d8485b3df01f6c9bda8d2c6e4b5ce0ab0e5ede	self-stabilizing dynamic mutual exclusion for mobile ad hoc networks	tolerancia falta;teoria demonstracion;distributed system;red sin hilo;controle acces;autostabilisation;systeme reparti;theorie preuve;informatique mobile;reseau sans fil;proof theory;token circulation;wireless network;ad hoc network;program verification;red ad hoc;exclusion mutual;mutual exclusion;verificacion programa;self stabilization;sistema repartido;token ring;reseau ad hoc;anneau jeton;fault tolerance;annilo ficha;mobile ad hoc network;access control;proof of correctness;exclusion mutuelle;mobile computing;verification programme;critical section;tolerance faute	We propose a self-stabilizing mutual exclusion algorithm for mobile ad hoc networks, in which the composition of processors that want to enter the critical section can change dynamically. Our algorithm is based on dynamic virtual rings formed by circulating tokens. The algorithm always guarantees mutual exclusion and it guarantees different levels of progress under different levels of performance of the token circulation in the presence of mobility and message loss. Rigorous proofs of correctness and performance are given.		Yu Chen;Jennifer L. Welch	2005	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2005.03.009	wireless ad hoc network;self-stabilization;fault tolerance;mobile ad hoc network;token ring;mutual exclusion;telecommunications;computer science;access control;operating system;wireless network;proof theory;distributed computing;critical section;suzuki-kasami algorithm;programming language;mobile computing;computer security;computer network	Mobile	-21.114202432135762	43.05358250001969	120701
55bf60f99355b0d927bfa6de7a64dc82ff520454	aggregated accounting of memory usage in java		Profiling of application memory consumption typically includes a trade-off between overhead and accuracy. We present a new approach for memory usage accounting which has a comparatively low overhead and still provides meaningful results. Our approach considers the structure of modern applications by introducing the notion of memory accounts where application modules get “charged” for memory allocations. We have applied this approach to Java application servers and discuss important implementation aspects as well as experimental results of our prototype.	application server;call stack;high memory;java;memory leak;norm (social);overhead (computing);profiling (computer programming);prototype;sourceforge;stack trace;user experience;web container	Paul Bouché;Martin von Löwis;Peter Tröger	2009			real-time computing;programming language;world wide web	HPC	-23.302996997051956	39.05940498061731	120907
3a60cbe0cb4d4b8e4d0525a344124234d9049000	distributed data base management: some thoughts and analyses	distributed data;data base management systems;new technology;management system;distributed processing;computer architecture;data base software;concurrency control;data base computer;adaptive architecture	The new decade will witness the widespread usage of distributed processing systems. Distributed data base management will turn out to be one of the important applications of this relatively new technology. This paper initially presents a brief outline of the nature of research that has been performed so far in this area. Next, it discusses some of the important issues (like integrity and security constraints, deadlocks, concurrency control, etc.) and analyses some proposed mechanisms. Performance and correctness issues are also addressed. Then, a brief sketch of an adaptive architecture for distributed data base management systems is presented. The last section lists some future directions for research in this area.	adaptive architecture;concurrency (computer science);concurrency control;correctness (computer science);deadlock;distributed computing;distributed database	C. Mohan	1980		10.1145/800176.809995	real-time computing;computer science;concurrency control;database;distributed computing;distributed system security architecture;data architecture;distributed concurrency control	DB	-25.821864687624625	45.265951832694704	121352
ff1de0c6a932797782fe7636d2d716bc8cd64816	pcte - solving case data integration.		PCfE is a programming interface which provides basic operating system primitives for the developer of an integrated software engineering environment. PCfE is designed to be npward compatible with the UNIX 1 operating system. It was defined in an ESPRIT project during 1983-1986. PCfE replaces the file system of traditional operating systems by an object management system, which serves as a base for data integration. The data model of the object management system is a derivation of the Entity-Relationship model. PCfE is aimed to be the kernel for bnilding software engineering environments for 1990's.	application programming interface;bos/360;data model;entity–relationship model;integrated software;operating system;software engineering;unix	Kari Rossi;Kim Portman	1989			systems engineering;computer science;data integration	SE	-30.500256560347037	41.8189103134667	121420
06c62664e9efe55d88bcce20a1ee3b9f2e069d3f	control and coordination of heterogeneous transaction processing systems	software tool;real time control;large scale;computational logic;distributed environment;distributed computing system;object oriented;distributed computing environment;transaction processing;operations and management	Transaction processing systems (TPS) applications are a large component of most business organizations’ investment in computer technology. Heterogeneous and distributed computing environments have become essential and beneficial to most corporations. Thus, there is a need for tools to support the development of new distributed TPSs and the migration of existing TPSs to distributed environments. This paper presents the design and construction of a software tool that provides the functionalities necessary for the construction, operation and management of heterogenous distributed TPS applications. The tool design is based on objectorientation and real-time control and is implemented using Prolog and C. We anticipate that the tool will provide practical and significant benefits to the operators and maintainers of large-scale TPSs. Kevsords: Heterogeneous distributed computing systems; Transaction processing systems; Real-time control and coordination; Object-oriented computing; Logic programming	computer;computer multitasking;distributed computing;distributed shared memory;information processing;integrated software;logic programming;online and offline;programming tool;prolog;real-time cmix;real-time clock;systems management;transaction processing system;on-line system	Ranjit Bose;Stephen D. Burd	1997	Information & Software Technology	10.1016/S0950-5849(96)01134-2	distributed algorithm;real-time computing;transaction processing;computer science;software engineering;database;distributed computing;distributed design patterns;transaction processing system;distributed computing environment	HPC	-28.55487426432896	45.60296450126014	121693
68285c56120dd6f277cd8a550e85bd38ba3ea0b8	demonstration: debugging constraint problems with portable tools			debugging	Pierre Deransart;Ludovic Langevine;Mireille Ducassé	2003			debugging;computer architecture;algorithmic program debugging;computer science	Robotics	-22.709275615832635	33.85854576435041	121744
50f7f2066b516c72d5c1612b0b97861f51cf6b20	dproc - extensible run-time resource monitoring for cluster applications	distributed system;systeme reparti;performance monitoring;building block;surveillance;resource management;ejecucion programa;round trip time;program execution;gestion recursos;vigilancia;sistema repartido;monitoring;execution programme;gestion ressources;monitorage;monitoreo	In this paper we describe the dproc (distributed /proc) kernellevel mechanisms and abstractions, which provide the building blocks for implementation of efficient, cluster-wide, and application-specific performance monitoring. Such monitoring functionality may be constructed at any time, both before and during application invocation, and can include dynamic run-time extensions. This paper (i) presents dproc's implementation in a Linux-based cluster of SMP-machines, and (ii) evaluates its utility by construction of sample monitoring functionality. Full version of this paper can be found at: http://www.cc.gatech.edu/systems/projects/dproc/		Jasmina Jancic;Christian Poellabauer;Karsten Schwan;Matthew Wolf;Neil Bright	2002		10.1007/3-540-46080-2_94	embedded system;real-time computing;computer science;resource management;operating system;distributed computing;round-trip delay time	HPC	-28.883634858625495	42.1144042940132	121771
f069cd23e946a71e75a98628de267fd28b85265c	establish a globally consistent order of discrete events in distributed robotic systems	concurrent tasks;clocks;discrete events;discrete time systems;distributed computing;chronological order;distributed mutual exclusion globally consistent order discrete events distributed robotic systems chronological order concurrent tasks;globally consistent order;synchronization;programming profession;robots;distributed robotic systems;message passing;robots educational institutions context distributed control synchronization clocks distributed computing message passing programming profession delay;distributed mutual exclusion;distributed algorithm;robots discrete time systems distributed control;distributed control;context;discrete event;distributed robotics	A fully distributed algorithm that established a globally consistent order of discrete events in a distributed robotic system (DRS) is presented. It is assumed that discrete events can be consistently identified, but robots may have inconsistent opinions on the chronological order of them. The execution of the algorithm on a robot consists of three conceptually concurrent tasks, of which two are based on distributed mutual exclusion (DME). >	robotics	Jing Wang	1993		10.1109/ROBOT.1993.292251	robot;synchronization;distributed algorithm;message passing;real-time computing;computer science;theoretical computer science;distributed computing	Robotics	-24.479761936402717	44.02500440428449	121794
81c639bdbc280e6856c21ec4fdb2b7253c6c0722	tools for the development of application-specific virtual memory management	virtual memory;operating system	The operating system's virtual memory management policy is increasingly important to application performance because gains in processing speed are far outstripping improvements in disk latency. Indeed, large applications can gain large performance bene ts from using a virtual memory policy tuned to their speci c memory access patterns rather than a general policy provided by the operating system. As a result, a number of schemes have been proposed to allow for application-speci c extensions to virtual memory management. These schemes have the potential to improve performance; however, to realize this performance gain, application developers must implement their own virtual memory module, a non-trivial programming task. Current operating systems and programming tools are inadequate for developing application-speci c policies. Our work combines (i) an extensible user-level virtual memory system based on a metaobject protocol with (ii) an innovative graphical performance monitor to make the task of implementing a new application-speci c page replacement policy considerably simpler. The techniques presented for opening up operating system virtual memory policy to user control are general; they could be used to build applicationspeci c implementations of other operating system policies. This work was supported in part by the National Science Foundation (CDA-8722788), the Digital Equipment Corporation (the Systems Research Center and the External Research Program), and the AT&T Foundation. Anderson was also supported by a National Science Foundation Young Investigator Award. The authors' e-mail addresses are keithk/dloft/vahdat/tea@cs.berkeley.edu.	email;graphical user interface;memory management;memory module;metaobject;openvms;operating system;page replacement algorithm;programming tool;user space	Keith Krueger;David Loftesness;Amin Vahdat;Thomas E. Anderson	1993		10.1145/165854.165867	memory footprint;shared memory;memory management;computer hardware;computer science;virtual memory;operating system;memory protection;overlay;data diffusion machine;memory map;memory management	PL	-30.161579885569548	41.05342940552426	121928
d571261c588e5298245f05f8862a7970da4c76fb	software architecture of the da vinci research kit	software;manipulators;field programmable gate arrays;ieee 1394 standard;hardware;real time systems	The da Vinci Research Kit (dVRK) has been installed at over 25 research institutions across the world, forming a research community sharing a common open-source research platform. This paper presents the dVRK software architecture, which consists of a distributed hardware interface layer, a real-time component-based software framework, and integration with the Robot Operating System (ROS). The architecture is scalable to support multiple active manipulators, reconfigurable to enable researchers to partition a full system into multiple independent subsystems, and extensible at all levels of control.	component-based software engineering;hardware interface design;open-source software;real-time transcription;reconfigurable computing;robot operating system;scalability;software architecture;software framework	Zihan Chen;Anton Deguet;Russell H. Taylor;Peter Kazanzides	2017	2017 First IEEE International Conference on Robotic Computing (IRC)	10.1109/IRC.2017.69	reference architecture;embedded system;software architecture;real-time computing;engineering;hardware architecture;resource-oriented architecture;systems architecture;software system;computer engineering	Robotics	-33.582310870099434	38.30567506472489	121991
b8ce407bf730225d27f3b5574b434c4349bef9c6	windows mobile advanced forensics	logical physical acquisition;nand flash;tool support;market share;tfat file system;heap;mobile phone;windows mobile;cedb edb database;file system;live forensics	Windows CE (at this moment sold as Windows Mobile) is on the market for more than 10 years now. In the third quarter of 2009, Microsoft reached a market share of 8.8% of the more than 41 million mobile phones shipped worldwide in that quarter. This makes it a relevant subject for the forensic community. Most commercially available forensic tools supporting Windows CE deliver logical acquisition, yielding active data only. The possibilities for physical acquisition are increasing as some tool vendors are starting to implement forms of physical acquisition. This paper introduces the forensic application of freely available tools and describes how known methods of Physical Acquisition can be applied to Windows CE devices. Furthermore it introduces a method to investigate isolated Windows CE database volume files for both active and deleted data. a 2010 Elsevier Ltd. All rights reserved.	microsoft windows;mobile phone;windows mobile	C. Klaver	2010	Digital Investigation	10.1016/j.diin.2010.02.001	market share;embedded system;microsoft windows;windows ce;wallpaper;heap;computer science;group policy;software versioning;windows vista;server message block;operating system;windows rally;commit charge;world wide web;vbscript;computer security;dll hell;system.ini;network access protection;next-generation secure computing base	HCI	-32.68719988596896	41.92718236749128	122008
66a5c3a1969c8adc94402a1e14944e3a1abb21db	bottleneck analysis in java applications using hardware performance monitors	phase behavior;profiling;hardware performance monitors;performance analysis;source code;java	This poster presents <sc>MonitorMethod</sc> which helps Java programmers gain insight in the behavior of their applications. <sc>MonitorMethod</sc> instruments the Java application and relates hardware performance monitors (HPMs) to the methods in the Java application's source code. We present a detailed case study showing that linking microprocessor-level performance characteristics to the source code is helpful for identifying performance bottlenecks and their causes. In addition, we relate our work to a previously proposed time-based HPM profiling framework.	java;microprocessor;programmer	Dries Buytaert;Andy Georges;Lieven Eeckhout;Koen De Bosschere	2004		10.1145/1028664.1028735	embedded system;real-time computing;computer science;operating system;strictfp;real time java;profiling;programming language;java;source code	Arch	-20.20184409404497	38.35499833409122	122127
1e86909765bd5603a152bbd55e511e0586f1b77f	the join calculus: a language for distributed mobile programming	programming language;cryptographic protocol;pattern matching	In these notes, we give an overview of the join calculus, its semantics, and its equational theory. The join calculus is a language that models distributed and mobile programming. It is characterized by an explicit notion of locality, a strict adherence to local synchronization, and a direct embedding of the ML programming language. The join calculus is used as the basis for several distributed languages and implementations, such as JoCaml and functional nets. Local synchronization means that messages always travel to a set destination, and can interact only after they reach that destination; this is required for an efficient implementation. Specifically, the join calculus uses ML’s function bindings and pattern-matching on messages to program these synchronizations in a declarative manner. Formally, the language owes much to concurrency theory, which provides a strong basis for stating and proving the properties of asynchronous programs. Because of several remarkable identities, the theory of process equivalences admits simplifications when applied to the join calculus. We prove several of these identities, and argue that equivalences for the join calculus can be rationally organized into a five-tiered hierarchy, with some trade-off between expressiveness and proof techniques. We describe the mobility extensions of the core calculus, which allow the programming of agent creation and migration. We briefly present how the calculus has been extended to model distributed failures on the one hand, and cryptographic protocols on the other. ? This work is partly supported by the RNRT project MARVEL 98S0347 Applied Semantics Summer School (Caminha, 9–15 September 2000) Draft 7/01, pp. 1–66,	concurrency (computer science);cryptographic protocol;cryptography;jocaml;join-calculus;locality of reference;pattern matching;programming language	Cédric Fournet;Georges Gonthier	2000		10.1007/3-540-45699-6_6	recursive join;fluent calculus;process calculus;typed lambda calculus;computer science;theoretical computer science;pattern matching;cryptographic protocol;situation calculus;calculus of communicating systems;algorithm;tuple relational calculus;epsilon calculus	PL	-29.017692889253258	32.67884165007674	122215
f61aa8530610613abfd771b2cc8b06739bb72a7a	common file organization techniques compared	general definition;file organization technique;accepted definition;common file organization technique	In order to make a comparison of file organization techniques, concurrence is needed on terminology. To that end, this introduction offers some definition of terms. Unfortunately, many of these terms do not have universally accepted definitions. A general definition of terms can be found elsewhere.	computer;concurrence (quantum computing);external storage;inverted index;overhead (computing);rewrite (programming);user (computing)	Ned Chapin	1969		10.1145/1478559.1478608	computer science;data mining;database;algorithm	Web+IR	-27.593610945891218	39.20039261871513	122294
605ca5a1afdc6a944fc239480c5b8a1a1df34800	computability in distributed computing: a tutorial	topology;crash failure;distributed computability;model equivalence;task;agreement;asynchronous system;concurrency;waitfreedom;resilience;iterated model;snapshot;recursion;fault tolerance;liveness;distributed computing model;shared memory system	What can and cannot be computed in a distributed system is a complex function of the system's communication model, timing model, and failure model. This tutorial surveys some important results about computability in the canonical distributed system model, where processes execute asynchronously, they communicate by reading and writing shared memory, and they fail by crashing. It explains the fundamental role that topology plays in the distributed computability theory.	computability theory;distributed computing;shared memory	Maurice Herlihy;Sergio Rajsbaum;Michel Raynal	2012	SIGACT News	10.1145/2421096.2421118	asynchronous system;snapshot;recursion;fault tolerance;combinatorics;real-time computing;concurrency;computer science;theoretical computer science;distributed computing;computability;programming language;algorithm;psychological resilience;liveness	HPC	-22.530001478747668	42.96467587306538	122340
59f281559b4322611bc5dc2349ab3fe55ad33198	structural properties and observability in membrane systems	observability biomembranes calculus evolution biology computer science biological system modeling scientific computing context modeling parallel processing biological systems;biocomputing;parallel processing biocomputing mobile computing;distributed parallel computing structural properties membrane system observability ambient calculus contextual bisimulation mobile membrane systems structural congruence translation function;ambient calculus;mobile computing;parallel processing;structural properties	We assimilate some notions of the ambient calculus into the formalism of membrane systems. Thus we consider the exhibit of an ambient, its level, the structural congruence, and the contextual bisimulation to define and study in mobile membrane systems the corresponding observation barbs, the depths of a membrane system, and the structural congruence. The relation between these notions is given by a translation function.	ambient calculus;bisimulation;congruence of squares;semantics (computer science)	Bogdan Aman;Gabriel Ciobanu	2007	Ninth International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC 2007)	10.1109/SYNASC.2007.65	ambient calculus;parallel processing;discrete mathematics;computer science;theoretical computer science;operating system;database;mathematics;distributed computing;programming language;mobile computing;algorithm	Arch	-30.055195259071983	33.348596597378176	122400
6968cc352766d1792f05d3538053771714414d0d	jcod: a lightweight modular compilation technology for embedded java	juste a temps;compilacion;calculateur embarque;compilateur;java programming;langage java;compiler;hot spot;program optimization;mobile phone;code natif;boarded computer;compilation;code size;lenguaje java;just in time;optimisation programme;justo en tiempo;native code;calculador embarque;compilador;java language;optimizacion programa	"""JCOD is a new compiler technology for appliances such as mobile phones or printers running embedded Java programs. Interpreted Java is sometimes too slow and one would like to compile bytecode into native code as this is achieved in JIT compilers on desktops. Our approach takes into account the memory and CPU constraints of the appliances. We have designed a distributed technology to efficiently detect """"hot spots"""" of the application and compile them out of the appliance, on a network compile server that uses a lot of code size optimizations. This paper describes the different components and exhibits their flexibility. They can easily be upgraded independently or tailored for a specific kind of applications running on a given appliance."""	embedded java	Bertrand Delsart;Vania Joloboff;Eric Paire	2002		10.1007/3-540-45828-X_15	compile time;compiler;parallel computing;real-time computing;machine code;computer science;operating system;program optimization;embedded java;database;distributed computing;programming language;java;hot spot;algorithm	Embedded	-20.225265175566804	36.55896173884483	122438
f045a9cd8dabf59b451bda484cbb9ad04e836960	verification method for the fbd-style design specification using sdt and smv			fully buffered dimm;syntax-directed translation	Myung Jun Song;Seo Ryong Koo;Poong-Hyun Seong	2004			computer architecture;design specification;computer science	EDA	-29.449461482193396	34.60526213611746	122458
edab75fcab5bf6808647bd82f01887e75fab3679	using triggers to find significant events during monitoring of real-time systems	real time systems		real-time operating system;real-time transcription	Idriz Smaili	2004			real-time computing;computer science	Embedded	-30.076456906598857	38.09957313902524	122489
59d45d685e35f5a84768c029ea09b9c48765251e	container-based operating system virtualization: a scalable, high-performance alternative to hypervisors	sistema operativo;systeme unix;haute performance;virtualization;alternative;operating time;unix system;time sharing;hypervisor;operating;duree fonctionnement;grid;systeme linux;duracion funcionamiento;xen;tiempo dividido;operating system;design and implementation;sistema linux;rejilla;system;conteneur;alto rendimiento;grille;systeme exploitation;temps partage;sistema unix;linux vserver;contenedor;linux system;high performance;container	Hypervisors, popularized by Xen and VMware, are quickly becoming commodity. They are appropriate for many usage scenarios, but there are scenarios that require system virtualization with high degrees of both isolation and efficiency. Examples include HPC clusters, the Grid, hosting centers, and PlanetLab. We present an alternative to hypervisors that is better suited to such scenarios. The approach is a synthesis of prior work on resource containers and security containers applied to general-purpose, time-shared operating systems. Examples of such container-based systems include Solaris 10, Virtuozzo for Linux, and Linux-VServer. As a representative instance of container-based systems, this paper describes the design and implementation of Linux-VServer. In addition, it contrasts the architecture of Linux-VServer with current generations of Xen, and shows how Linux-VServer provides comparable support for isolation and superior system efficiency.	computer cluster;general-purpose modeling;grid computing;hardware virtualization;hypervisor;linux;linux-vserver;operating system;planetlab;scalability	Stephen Soltesz;Herbert Pötzl;Marc E. Fiuczynski;Andy C. Bavier;Larry L. Peterson	2007		10.1145/1272996.1273025	embedded system;real-time computing;virtualization;computer science;operating system;system;hypervisor;grid;container;time-sharing	OS	-27.30728746847096	43.11690667655574	122515
e9d3635adbcfb7680cce2bb051ed320f64225b55	locality in page reference strings		A probabilistic model is presented of program material in a paging machine. The sequences of page references in the model are associated with certain sequences of LRU stack distances and have reference patterns formalizing a notion of “locality” of reference. Values for parameters of the model can be chosen to make the page-exception characteristics of the generated sequences of page references consistent with those of actual program traces.The statistical properties of the execution intervals (times between page-exception) for sequences of references in the model are derived, and an application of these results is made to a queuing analysis of a simple multiprogrammed paging system. Some numerical results pertaining to the program model and the queuing analysis are given.	locality of reference	Gerald S. Shedler;C. Tung	1972	SIAM J. Comput.	10.1137/0201016	combinatorics;real-time computing;computer science;theoretical computer science;database;programming language;algorithm	Theory	-19.88437448666755	32.58219251860955	122857
6b76942b24258b5cf34a30f4add5549dc01acff8	an adaptive mobile system using mobile grid computing in wireless network	distributed system;red sin hilo;haute performance;systeme reparti;informatique mobile;mobile device;personal digital assistant;reseau sans fil;wireless network;distributed computing;systeme adaptatif;assistant numerique personnel;emergency;sistema repartido;urgencia;adaptive system;alto rendimiento;calculo repartido;urgence;sistema adaptativo;mobile systems;mobile computing;auxiliar personal digital;grid computing;high performance;calcul reparti	In order to overcome the constrained performance inherent in mobile devices, and to support services depending using wireless networks, an adaptive mobile system using mobile grid computing, is proposed. According to the mobile device environment, classes are composed of an application that executes on a specific mobile device, and allocated to surrounding devices containing idle resources. The effectiveness of this system is confirmed, by applying the system to an emergency environment, using mobile devices, which include a PDA and laptop.	grid computing	Jehwan Oh;Seunghwa Lee;Eunseok Lee	2006		10.1007/11751649_6	radio access network;embedded system;mobile identification number;mobile search;mobile device forensics;simulation;mobile web;public land mobile network;telecommunications;gsm services;emergency;mobile processor;mobile database;computer science;adaptive system;operating system;wireless network;mobile technology;mobile device;distributed computing;mobile station;small cell;mobile computing;grid computing	Mobile	-29.752498223808292	43.49241151599844	123012
39abdb03445d487b9647b7ea34fc84fea835184a	stabilizers: a modular checkpointing abstraction for concurrent functional programs	lenguaje programacion;distributed system;outil logiciel;propriete dynamique;error recovery;software tool;reliability;linguistique;phenomene transitoire;systeme reparti;mise a jour;systeme grande taille;measurement;programming language;surveillance;concurrent programming;reponse transitoire;performance;serveur informatique;software systems;concurrent ml;semantics;abstraction;simultaneidad informatica;concurrent program;large scale system;abstraccion;semantica;semantique;functional programming;checkpointing;metalangage;actualizacion;conference paper;large scale;transient response;linguistica;concurrency;respuesta transitoria;vigilancia;sistema repartido;monitoring;metalanguage;propiedad dinamica;envoi message;programa competidor;fenomeno transitorio;punto reanudacion;transient fault;message passing;langage programmation;reparation;concurrent programs;multithread;servidor informatico;coherence;design;exception handling;programmation fonctionnelle;point reprise;multitâche;monitorage;transients;coherencia;reparacion;monitoreo;experimentation;herramienta software;programacion funcional;simultaneite informatique;transactions;languages;multitarea;updating;sistema gran escala;repair;programme concurrent;dynamic properties;computer server;metalenguaje;linguistics	Transient faults that arise in large-scale software systems can often be repaired by re-executing the code in which they occur. Ascribing a meaningful semantics for safe re-execution in multi-threaded code is not obvious, however. For a thread to correctly rexecute a region of code, it must ensure that all other threads which have witnessed its unwanted effects within that region are also reverted to a meaningful earlier state. If not done properly, data inconsistencies and other undesirable behavior may result. however, automatically determining what constitutes a consistent global checkpoint is not straightforward since thread interactions are a dynamic property of the program.In this paper, we present a safe and efficient checkpointing mechanism for Concurrent ML (CML) that can be used to recover from transient faults. We introduce a new linguistic abstraction called stabilizers that permits the specification of per-thread monitors and the restoration of globally consistent checkpoints. Safe global states are computed through lightweight monitoring of communication events among threads (e.g. message-passing operations or updates to shared variables).Our experimental results on several realistic, multithreaded, server-style CML applications, including a web server and a windowing toolkit, show that the overheads to use stabilizers are small, and lead us to conclude that they are a viable mechanism for defining safe checkpoints in concurrent functional programs.	advanced configuration and power interface;application checkpointing;circuit restoration;concurrent ml;functional programming;interaction;message passing;multithreading (computer architecture);server (computing);software bug;software system;thread (computing);threaded code;transaction processing system;web server;widget toolkit	Lukasz Ziarek;Philip Schatz;Suresh Jagannathan	2006		10.1145/1159803.1159822	exception handling;embedded system;design;message passing;real-time computing;coherence;concurrency;performance;metalanguage;computer science;reliability;semantics;abstraction;programming language;functional programming;transient response;algorithm;measurement	PL	-21.4942012250075	41.484815078042246	123260
b947089280e86c12721bbb4a4c73658307118f99	monitoring distributed reactive systems	clocks;distributed processing;program verification;synchronisation clocks computerised monitoring distributed processing embedded systems program verification;monitoring runtime clocks embedded systems delay asynchronous communication semantics;synchronisation;embedded systems;function sequentiality distributed reactive system module monitoring synchronous system desynchronization local clocks asynchronous components runtime verification synchronous composition endo isochronous system theory asynchronous monitors heuristics endochrony;computerised monitoring	Recent results on the desynchronization of synchronous systems introduced the subclass of so-called endo/isochronous systems. Since the modules of these systems can derive their own local clocks from their inputs, they can be implemented as asynchronous components without inefficient synchronizations. Runtime verification has a similar problem since one has to add a monitor to an existing system where typically a synchronous composition is assumed. In this paper, we therefore propose to use the endo/isochronous system theory to implement asynchronous monitors that are still able to check the original synchronous behavior. We only demand that the entire system obtained by adding the monitor is an endo/isochronous system so that we can implement a suitable wrapper around the monitor (and the other components). For the implementation, we use heuristics to check endochrony like the sequentiality of the implemented functions.	algorithm;coupling (computer programming);embedded system;heuristic (computer science);monitor (synchronization);runtime verification;systems theory;temporal logic	Yu Bai;Jens Brandt;Klaus Schneider	2012	2012 IEEE International High Level Design Validation and Test Workshop (HLDVT)	10.1109/HLDVT.2012.6418247	embedded system;synchronization;real-time computing;computer science;operating system;distributed computing	Embedded	-25.574964200477243	34.374365161845176	123615
394f7713a5a943b4f323e47c22c60c6c88d18e6a	operating system concepts for reconfigurable computing: review and survey		One of the key future challenges for reconfigurable computing is to enable higher design productivity and a more easy way to use reconfigurable computing systems for users that are unfamiliar with the underlying concepts. One way of doing this is to provide standardization and abstraction, usually supported and enforced by an operating system. This article gives historical review and a summary on ideas and key concepts to include reconfigurable computing aspects in operating systems. The article also presents an overview on published and available operating systems targeting the area of reconfigurable computing. The purpose of this article is to identify and summarize common patterns among those systems that can be seen as de facto standard. Furthermore, open problems, not covered by these already available systems, are identified.	graph coloring;operating system;reconfigurable computing	Marcel Eckert;Dominik Meyer;Jan Haase;Bernd Klauer	2016	Int. J. Reconfig. Comp.	10.1155/2016/2478907	embedded system;parallel computing;real-time computing;computer science;distributed computing	HPC	-24.246150197338476	38.6263958775198	123734
ebe69ba29ae7a012b72efc5bc56cabc2d3995255	thinking inside the box: compartmentalized garbage collection	computacion informatica;memory management;isolation;garbage collection;ciencias basicas y experimentales;web browser architecture;grupo a	The web browser is the “new desktop.” Not only do many users spend most of their time using the browser, the browser has also become host to rich and dynamic applications that were previously tailored to each individual operating system. The lingua franca of web scripting, JavaScript, was pivotal in this development.  Imagine that all desktop applications allocated memory from a single heap managed by the operating system. To reclaim memory upon application shutdown, all processes would then be garbage collected—not just the one being quit. While operating systems improved upon this approach long ago, this was how browsers managed memory until recently.  This article explores compartmentalized memory management, an approach tailored specifically to web browsers. The idea is to partition the JavaScript heap into compartments and allocate objects to compartments based on their origin. All objects in the same compartment reference each other direct, whereas cross-origin references go through wrapper objects.  We carefully evaluate our techniques using Mozilla’s Firefox browser—which now ships with our enhancements—and demonstrate the benefits of collecting each compartment independently. This simultaneously improves runtime performance (up to 36%) and reduces garbage collection pause times (up to 75%) as well as the memory footprint of the browser. In addition, enforcing the same-origin security policy becomes simple and efficient with compartments.	acm transactions on programming languages and systems;addendum;application programming interface;baseline (configuration management);benchmark (computing);browser speed test;byte;compartmentalization (information security);data structure;desktop computer;dhrystone;digital library;experiment;firefox;garbage collection (computer science);graphics;heap (data structure);item unique identification;javascript;locality of reference;machine code;mathematical optimization;memory footprint;mobile device;multi-compartment model;operating system;performance evaluation;ray tracing (graphics);real-time clock;real-time transcription;region-based memory management;relevance;run time (program lifecycle phase);sha-1;same-origin policy;scripting language;shutdown (computing);spatial variability;testament;thinking outside the box;user experience;vii;web application;web content;webgl;world wide web	Gregor Wagner;Per Larsen;Stefan Brunthaler;Michael Franz	2016	ACM Trans. Program. Lang. Syst.	10.1145/2866576	manual memory management;garbage;isolation;computer science;operating system;database;client-side scripting;garbage collection;programming language;world wide web;memory leak;memory management	Security	-21.865977228115216	37.384000408294206	123778
1be71547a827f2a63a4f251615ba7126400822a2	computational quality of service for scientific components	developpement logiciel;quality assurance;algoritmo paralelo;parallel algorithm;component based software engineering;componente logicial;performance;distributed computing;composant logiciel;software engineering;qualite service;algorithme parallele;paralelismo masivo;software architecture;massively parallel computer;machine parts;desarrollo logicial;software development;software component;scientific computing;genie logiciel;calculo repartido;quality of service;component architecture;other instrumentation;ingenieria informatica;parallelisme massif;quality of service issue;calcul reparti;measuring instruments;massive parallelism;service quality;architecture logiciel;service life;calidad servicio	Scientific computing on massively parallel computers presents unique challenges to component-based software engineering (CBSE). While CBSE is at least as enabling for scientific computing as it is for other arenas, the requirements are different. We briefly discuss how these requirements shape the Common Component Architecture, and we describe some recent research on qualityof-service issues to address the computational performance and accuracy of scientific simulations.	common component architecture;component-based software engineering;computation;computational science;computer;parallel computing;quality of service;requirement;simulation	Boyana Norris;Jaideep Ray;Robert C. Armstrong;Lois C. McInnes;David E. Bernholdt;Wael R. Elwasif;Allen D. Malony;Sameer Shende	2004		10.1007/978-3-540-24774-6_23	quality assurance;computer science;component-based software engineering;operating system;software engineering;database;programming language	HPC	-27.77354135465605	43.08789963580649	124060
dc1ed2711dc79948771c4735f9b0c0e9c06d0570	formal pervasive verification of a paging mechanism	programming language;hoare logic;formal verification;operating system;machine model	Memory virtualization by means of demand paging is a crucial component of every modern operating system. The formal verification is challenging since reasoning about the page fault handler has to cover two concurrent computational sources: the processor and the hard disk. We accurately model the interleaved executions of devices and the page fault handler, which is written in a high-level programming language with inline assembler portions. We describe how to combine results from sequential Hoare logic style reasoning about the page fault handler on the low-level concurrent machine model. To the best of our knowledge this is the first example of pervasive formal verification of software communicating with devices.	assembly language;bit array;correctness (computer science);formal verification;hol (proof assistant);hard disk drive;high- and low-level;high-level programming language;hoare logic;inline assembler;invariant (computer science);isabelle;kernel (operating system);lambda lifting;memory management unit;memory virtualization;operating system;operational semantics;page fault;paging;pervasive informatics	Eyad Alkassar;Norbert Schirmer;Artem Starostin	2008		10.1007/978-3-540-78800-3_9	parallel computing;real-time computing;formal verification;computer science;hoare logic;programming language;algorithm	Arch	-21.70517104951635	32.67377438351981	124287
1cecf6eafa43a2f30c51d20abca3796d3e43fddb	distributed computing issues in hardware design	distributed computing;hardware design	The selection of papers in the first few issues of this journal will probably determine to a large extent what areas of study are included under the heading of Distributed Computing. It is important for our readers to realize that many interesting problems properly fall under this heading, but deal neither with communications networks nor distributed databases. Likewise, if our subject is to remain a fertile area for research, it is important to encourage prospective authors who may wonder if our journal is the appropriate place to publish a paper on a somewhat offbeat but relevant topic. With these goals in mind I suggested to Mohamed Gouda that we should organize a special issue on hardware design. The six papers that we have inclu~ied in this issue represent some of the most active areas in that discipline; four of the papers deal with asynchronous circuits, one with data flow computing, and one with systolic arrays. The papers span quite a spectrum as far level of theory and potential applications are concerned. Some deal with new and practical hardware structures, some address fundamental semantical issues, and some propose new methods for implementing algorithms in hardware. However, in my opinion, all expose exciting problems of common interest to researchers both areas. The first four papers deal with asynchronous circuits. Here the relationship with distributed computing is clear and immediate. In order to ensure that an asynchronous circuit works properly, it is necessary to consider very carefully all assumptions regarding the delays of signals exchanged between various circuit components; ideally the circuit should function correctly regardless of the delays associated with wires or individual circuit components. The advantages of using asynchro-	algorithm;asynchronous circuit;course (navigation);dataflow;distributed computing;distributed database;list of code lyoko episodes;prospective search;telecommunications network	Edmund M. Clarke	1986	Distributed Computing	10.1007/BF01660030	hardware compatibility list;distributed algorithm;dce/rpc;computer architecture;hardware acceleration;computer science;csiv2;hardware architecture;distributed computing;utility computing;distributed design patterns;fpgac;grid computing;replication;unconventional computing;computer engineering;autonomic computing;distributed concurrency control	Theory	-26.068767822614927	44.792385762182064	124393
c1c0b0fc7a887690cac890745ec6853a64a2dc40	the spring system: integrated support for complex real-time systems	multiprocessor kernel;programming language;function and time composition;real time;multi level scheduling;specification language;real time kernel;ipc;flexible manufacturing;operating system;predictability;lessons learned;system integration;real time scheduling;qd chemistry;distributed shared memory;real time application;integrated scheduling;reflection;guarantees;real time systems;time constraint	The Spring system is a highly integrated collection of software and hardware that synergistically operates to provide end-to-end support in building complex real-time applications. In this paper, we show how Spring's specification language, programming language, software generation system, and operating system kernel are applied to build a flexible manufacturing testbed. The same ingredients have also been used to realize a predictable version of a robot pick and place application used in industry. These applications are good examples of complex real-time systems that require flexibility. The goal of this paper is to demonstrate the integrated nature of the system and the benefits of integration; in particular, the use of reflective information and the value of function and time composition. The lessons learned from these applications and the project as a whole are also presented.	algorithm;application programming interface;best, worst and average case;blocking (computing);common object request broker architecture;compiler;concurrency (computer science);debugging;end-to-end principle;executable;kernel (operating system);online and offline;parallel computing;programming language;programming tool;real-time clock;real-time computing;real-time locating system;real-time operating system;real-time transcription;reflection (computer programming);requirement;run time (program lifecycle phase);smt placement equipment;scheduling (computing);scheduling analysis real-time systems;simple directmedia layer;specification language;spring engine;strong generating set;synchronization (computer science);synergy;testbed;worst-case execution time	John A. Stankovic;Krithi Ramamritham;Douglas Niehaus;Marty Humphrey;Gary Wallace	1999	Real-Time Systems	10.1023/A:1008051107382	distributed shared memory;embedded system;real-time computing;simulation;reflection;predictability;specification language;computer science;operating system;programming language;system integration;inter-process communication	Embedded	-28.663751813441653	38.02086739779912	124537
d1e57a0d724f8429780150c42c438556ea306e33	end-to-end memory behavior profiling with dinamite	llvm;instrumentation;spark streaming;memory optimization	Performance bottlenecks related to a program's memory behavior are common, yet very hard to debug. Tools that attempt to aid software engineers in diagnosing these bugs are typically designed to handle specific use cases; they do not provide information to comprehensively explore memory problems and to find solutions. Detailed traces of memory accesses would enable developers to ask various questions about the program's memory behaviour, but these traces quickly become very large even for short executions. We present DINAMITE: a toolkit for Dynamic INstrumentation and Analysis for MassIve Trace Exploration. DINAMITE instruments every memory access with highly debug information and provides a suite of extensible analysis tools to aid programmers in pinpointing memory bottlenecks.	programmer;software bug;software engineer;tracing (software)	Svetozar Miucin;Conor Brady;Alexandra Fedorova	2016		10.1145/2950290.2983941	parallel computing;real-time computing;computer hardware;computer science;programming language;instrumentation;memory leak	SE	-19.911346208426018	38.70948911056785	124867
b09e53f64d56ad1f4e5db325e4496776de7cbef3	quiescence detection in a distributed klic implementation	reference counting;concurrent logic programming;termination detection;parallel and distributed processing;meta programming	Abst rac t . Quiescence detection is a fundamental facility for parallel and distributed processing. This paper describes schemes for quiescence detection in a distributed KLIC implementation. KLIC is a portable implementation of concurrent logic programming language KL1. Termination is detected using the weighted throw counting (WTC) scheme. Based on the scheme a scheme for global suspension was invented. The postmortem system built-in predicate which provides meta programming facilities was designed, and its distributed implementation is also presented.	concurrent logic programming;distributed computing;kl1;metaprogramming;programming language;quiescence search	Kazuaki Rokusawa;Akihiko Nakase;Takashi Chikayama	1994		10.1007/BFb0020491	metaprogramming;reference counting;parallel computing;real-time computing;computer science;distributed computing;programming language	HPC	-22.236764869193895	34.475381742868315	124916
8c74493a38552872f2adab874974e95784ac97cd	realisation of the parallel communicating sequential code methodology and its automatic code generators				S. Shahrin	1995				HPC	-22.32017241839038	33.70274184879648	124964
5b187ef21cc9b09f42aa695ff9980582c60f9845	cold object identification in the java virtual machine	stack sampling;access barrier;java virtual machine;garbage collection;cold objects	Many Java applications instantiate objects within the Java heap that are persistent but seldom if ever referenced by the application. Examples include strings, such as error messages, and collections of value objects that are preloaded for fast access but they may include objects that are seldom referenced. This paper describes a stack-based framework for detecting these “cold” objects at runtime, with a view to marshaling and sequestering them in designated regions of the heap where they may be preferentially paged out to a backing store, thereby freeing physical memory pages for occupation by more active objects. Furthermore, we evaluate the correctness and efficiency of stack-based approach with an Access Barrier. The experimental results from a series of SPECjvm2008 benchmarks are presented. For submission to ‘Software: Practice and Experience’	benchmark (computing);cache (computing);computer data storage;correctness (computer science);data transfer object;error message;java virtual machine;paging;run time (program lifecycle phase);sensor;stack-oriented programming language	Kim T. Briggs;Baoguo Zhou;Gerhard W. Dueck	2017	Softw., Pract. Exper.	10.1002/spe.2396	stack trace;java concurrency;computer science;operating system;database;distributed computing;garbage collection;programming language;java;generics in java	PL	-20.545130736861932	35.035506656340054	125327
20561e4a123dab22694fa273f0cf4b14525c1c7d	persistent execution state of a java virtual machine	persistence;java virtual machine;recovery;execution state;checkpointing;jvm;java	Current work on persistency in Java does not consider. the execution environment of the threads and this is one of the reasons why persistence has not been addressed by the Java high-performance community. Equipping high-performance computing systems with checkpointing and recovery mechanisms allows to minimise work loss in presence of failure. This paper discusses concepts for checkpointing and recovery of running Java virtual machines (JVM). Checkpointing a JVM is to capture the execution state of the JVM and to make this s tate persistent. In order to recover the checkpointed execution state, it is necessary to reproduce the execution state and to resume the JVM. In other words checkpointing and recovery allows the reconstruction of a JVM at any arbitrary execution state. The checkpointing and recovery concepts have been prototypically implemented. The prototype provides generic mechanisms for extracting an execution state from a running JVM and for initialising a JVM with a persi tent execution state. These mechanisms can be used for a wide range of applications. Our prototype also uses these mechanisms for JVM migra t ion (relocation of a running JVM from one computer to another computer). General Terms Persistence, Java, JVM, execution state, checkpointing, recovery	application checkpointing;data recovery;java virtual machine;persistence (computer science);persistent data structure;prototype;relocation (computing);state (computer science);supercomputer	Takashi Suezawa	2000		10.1145/337449.337536	real-time computing;jsr 94;java concurrency;operating system;cross-platform;strictfp;embedded java;real time java;programming language;java;java applet	OS	-24.967439160703087	39.46542949356879	125507
12e2c52edb870001503be06a4d9a8e7e896a36e4	on the utilization of java technology in embedded systems	web based applications;life cycle;java virtual machine;embedded system;embedded systems design;embedded system design;design issues;java technology	Java technology has seen an impressive growth in popularity since its introduction in 1995. Although it has foremost proved its usefulness in the Internet domain, powerful market actors are currently moving Java into the embedded systems domain. In this article we identify major design issues in embedded systems, and analyze the suitability of Java technology in such systems. We find that Java technology can contribute to the embedded system design process on a system level by facilitating higher run-time reliability and the technology can simplify maintenance of the product throughout its life cycle. In addition, programmer efficiency and productivity may be improved, especially for web based applications and distributed embedded systems.	embedded system;foremost;java platform, enterprise edition;programmer;systems design	Øyvind Strøm;Kjetil Svarstad;Einar J. Aas	2003	Design Autom. for Emb. Sys.	10.1023/A:1022344203816	embedded system;biological life cycle;web application;real-time computing;computer science;operating system;strictfp;embedded java;real time java;programming language;java	EDA	-29.29858814370619	37.271442811812086	125694
0cf13bf52b37a425eb3d68ce817ab30ff00c5cd5	fault tolerance in the r-gma information and monitoring system	tolerancia falta;distributed system;replication;haute performance;systeme reparti;fault tolerant;information source;availability;surveillance;disponibilidad;source information;localization;interrogation base donnee;distributed computing;interrogacion base datos;localizacion;donnee globale;replicacion;grid;monitoring system;dato global;vigilancia;sistema repartido;localisation;global data;monitoring;rejilla;fault tolerance;alto rendimiento;grille;calculo repartido;monitorage;information system;monitoreo;high performance;disponibilite;calcul reparti;database query;tolerance faute;systeme information;fuente informacion;sistema informacion	R-GMA (Relational Grid Monitoring Architecture) [1] is a grid monitoring and information system that provides a global view of data distributed across a grid system. R-GMA creates the impression of a single centralised repository of information, but in reality the information can be stored at many different locations on the grid. The Registry and Schema are key components of R-GMA. The Registry matches queries for information to data sources that provide the appropriate information. The Schema defines the tables that can be queried. Without the combined availability of these components, RGMA ceases to operate as a useful service. This paper presents an overview of R-GMA and describes the Registry replication design and implementation. A replication algorithm for the Schema is also described.	algorithm;centralisation;fault tolerance;gridpp;intel gma;management information system;reliability engineering;single point of failure	Rob Byrom;Brian A. Coghlan;Andrew W. Cooke;Roney Cordenonsi;Linda Cornwall;Martin Craig;Abdeslem Djaoui;Alastair D Duncan;Steve Fisher;Alasdair J. G. Gray;Steve Hicks;Stuart Kenny;Jason Leake;Oliver Lyttleton;James Magowan;Robin Middleton;Werner Nutt;David O'Callaghan;Norbert Podhorszki;Paul Taylor	2005		10.1007/11508380_76	embedded system;fault tolerance;information schema;computer science;database;distributed computing;computer security	HPC	-27.83673843193704	43.6766116695798	125931
d0cc857bc4e63346853874dc1083baa5e1d31143	a characterization of state spill in modern operating systems		Understanding and managing the propagation of states in operating systems has become an intractable problem due to their sheer size and complexity. Despite modularization efforts, it remains a significant barrier to many contemporary computing goals: process migration, fault isolation and tolerance, live update, software virtualization, and more. Though many previous OS research endeavors have achieved these goals through ad-hoc, tedious methods, we argue that they have missed the underlying reason why these goals are so challenging: state spill.  State spill occurs when a software entity's state undergoes lasting changes as a result of a transaction from another entity. In order to increase awareness of state spill and its harmful effects, we conduct a thorough study of modern OSes and contribute a classification of design patterns that cause state spill. We present StateSpy, an automated tool that leverages cooperative static and runtime analysis to detect state spill in real software entities. Guided by StateSpy, we demonstrate the presence of state spill in 94% of Android system services. Finally, we analyze the harmful impacts of state spill and suggest alternative designs and strategies to mitigate them.	analysis of algorithms;android;application virtualization;computational complexity theory;design pattern;entity;fault detection and isolation;hoc (programming language);modern operating systems;operating system;process migration;software propagation;xojo	Kevin Boos;Emilio Del Vecchio;Lin Zhong	2017		10.1145/3064176.3064205	data parallelism;virtualization;computer science;process migration;operating system;software design pattern;software;fault detection and isolation;database transaction	OS	-21.41810834023272	39.872182062234735	125932
635d8a125130124527ccfce6ec614a56fd4150e2	development of java based rfid application programmable interface for heterogeneous rfid system	difference operator;api;learning curve;application programmer interface;monitoring;rfid;object tracking;interoperability;sequence diagram;tracking;multithreading	Developing RFID based applications is a painstakingly difficult endeavor. The difficulties include nonstandard software and hardware peripherals from vendors, interoperability problems between different operating systems as well as lack of expertise in terms of low-level programming for RFID (i.e. steep learning curve). In order to address these difficulties, a reusable RFIDTM API (RFID Tracking & Monitoring Application Programmable Interface) for heterogeneous RFID system has been designed and implemented. The API has been successfully employed in a number of application prototypes including tracking of eywords:	application programming interface;high- and low-level;interoperability;java;low-level programming language;operating system;peripheral;radio-frequency identification	Mohammed F. M. Ali;Mohammed I. Younis;Kamal Zuhairi Zamli;Widad Ismail	2010	Journal of Systems and Software	10.1016/j.jss.2010.07.030	radio-frequency identification;sequence diagram;embedded system;interoperability;real-time computing;multithreading;application programming interface;computer science;operating system;video tracking;tracking;learning curve	Mobile	-32.38258888347739	39.859397370992305	126065
ef8acd509db21b7c64fbe6aa3ed74ff5511639e8	communication between agents in alvis language	computer languages;embedded systems alvis language blocking communication nonblocking communication concurrent systems;specification languages multi agent systems programming languages;ports computers ieee 802 11 standard context computational modeling embedded systems computer languages;embedded systems;computational modeling;embedded system alvis modelling language concurrent system programming language asynchronous communication;ports computers;ieee 802 11 standard;context	Concurrent systems are composed of a set of subsystems (processes, threads etc.) that must communicate between themselves to meet the system requirements. Modelling and programming languages provide different communication modes to handle synchronous and/or asynchronous communication between subsystems. The paper provides a survey of communication modes introduced to the Alvis modelling language and discusses how the communication modes may be used while modelling embedded systems.	concurrency (computer science);embedded system;modeling language;process (computing);programming language;requirement;system requirements	Piotr Matyasik;Marcin Szpyrka;Michal Wypych;Jerzy Biernacki	2016	2016 MIXDES - 23rd International Conference Mixed Design of Integrated Circuits and Systems	10.1109/MIXDES.2016.7529784	real-time computing;computer science;distributed computing;fifth-generation programming language;programming language;second-generation programming language	EDA	-33.63585971708676	32.619443502722525	126068
197fd31dcf116c85087fa82902ffb35fc57a81bd	high-level design of a request driven sender component	communication oriented input output behaviour;communication history;computer languages;state space methods;history;abstract state;application software;top down;paper technology;software architecture program compilers;systematic top down design;input output;software architecture;general methods;state space;communication history high level design request driven sender component systematic top down design asynchronous sender component software architecture communication oriented input output behaviour stream processing state transition machine history abstraction abstract state;joining processes;request driven sender component;stream processing;history abstraction;communication system control;program compilers;high level design;history computer languages state space methods paper technology software architecture application software hardware joining processes communication system control java;state transition;asynchronous sender component;hardware;java;state transition machine	The paper studies the systematic top-down design of an asynchronous sender component as part of a software architecture. The receiver pulls messages from the sender by transmitting the number of messages requested. The design refines the communication-oriented input/output behaviour specified by a stream processing function into an implementation by a state transition machine. The development consists of three major transformation steps, viz. the differentiation of the stream processing function, the state introduction using a history abstraction, and the implementation of the abstract state space. The application explicates general methods for the formal design of interactive components in a functional setting	input/output;level design;software architecture;state space;state transition table;stream processing;top-down and bottom-up design;transmitter;viz: the computer game	Walter Dosch;Annette Stümpel	2007	Fourth International Conference on Information Technology (ITNG'07)	10.1109/ITNG.2007.100	input/output;software architecture;application software;real-time computing;stream processing;computer science;state space;theoretical computer science;operating system;software engineering;top-down and bottom-up design;distributed computing;programming language;java;computer security;high-level design;computer network	EDA	-32.334426089043326	33.8707807444442	126328
1d079ee55c5e4c7fb69d057145762f2b453c2f29	real-time system development in ada using lego® mindstorms® nxt	ada;real time systems	In this paper, we describe a set of tools to fully develop a real-time application under Linux using as target the LEGO® Mindstorms® NXT robotics kit. These tools provide Real-Time & Embedded systems teachers with an alternative to conventional software models designed in classrooms and labs.	ada;embedded system;idea nxt;lego mindstorms;linux;real-time clock;real-time computing;real-time operating system;real-time transcription;robotics	Peter J. Bradley;Juan Antonio de la Puente;Juan Zamorano	2010		10.1145/1879063.1879077	embedded system;real-time computing;ada;computer science;operating system;programming language	Embedded	-28.640705695016297	38.052824044123696	126521
94c3890b138df8d7352563b6e17a49a141976a6c	a portable javascript thread library for ajax applications	ajax;concurrent programming;web programming;concurrent programs;multithread;javascript	We propose a portable JavaScript thread library to facilitate the development of Ajax applications. It enables programmers to write asynchronous programs using threads. Since the proposed library is implemented without modifying any existing systems, it is portable among popular Web browsers and has high affinity with the existing event system.	ajax (programming);javascript;processor affinity;programmer;software portability;thread (computing)	Daisuke Maki;Hideya Iwasaki	2007		10.1145/1297846.1297903	ajax;web application;rich internet application;concurrent computing;computer science;unobtrusive javascript;operating system;javascript;programming language;world wide web	SE	-24.813004953781522	36.948414268194	126732
5637987c5f601ab530c96f6963b5c113249f04c2	rewriting logic을 이용한 멀티 태스크 - 멀티 프로세서 시스템 성능 분석	performance estimation;maude;멀티 태스크;thesis;성능 예측;rewriting logic;performance analysis;멀티 프로세서;multi processor;성능 분석;multi task			조용우	2009		10.1007/978-0-387-09766-4_2297	parallel computing;computer science;programming language;algorithm	EDA	-24.435604296823037	33.472393425965684	127370
51a3783c24c04856c0ea20e6564be66f50414478	design and implementation of a transaction-based filesystem on freebsd	data integrity;design and implementation;transaction processing;database management system	Transactional database management systems (DBMS’s) have special data integrity requirements that standard filesystems such as the Berkeley Fast Filesystem do not address. This paper briefly describes the requirements a transactional DBMS makes of a transaction-based filesystem, then goes on to describe the design and implementation of such a filesystem, referred to as a block repository1, which is part of the SQRL DBMS project. The implementation of SQRL’s block repository is different than most traditional filesystems in that it is purposely implemented in user-land using raw devices and threads. Its performance is more tunable to the needs of transaction processing than would be the case if it were integrated into the kernel.	data integrity;database;freebsd;requirement;sqrl;transaction processing	Jason Evans	1999			parallel computing;filesystem hierarchy standard;transaction processing;distributed transaction;computer science;specfs;operating system;data integrity;database	DB	-27.274681977682658	45.44562077175205	127421
f8bf074553957f25d1d8e9a31509919690de17d6	dynamic livelock analysis of multi-threaded programs		A system for analyzing a multi-threaded program includes a processor and a data storage device coupled to the processor to store a multi-threaded program execution and code for detecting one or more lock cycle conditions from the executed trace to identify one or more livelock or deadlock potentials, and code to confirm the livelock or deadlock potentials in a controlled re-execution.	deadlock;thread (computing)	Malay K. Ganai	2012		10.1007/978-3-642-35632-2_3	parallel computing;real-time computing;computer science;distributed computing	Logic	-20.61181922168551	38.89498778053276	127453
aa9256de35ee28ac2bc499cab3851d96d5b70e49	writing parsers like it is 2017		Despite being known since a long time, memory violations are still a very important cause of security problems in low-level programming languages containing data parsers. We address this problem by proposing a pragmatic solution to fix not only bugs, but classes of bugs. First, using a fast and safe language such as Rust, and then using a parser combinator. We discuss the advantages and difficulties of this solution, and we present two cases of how to implement safe parsers and insert them in large C projects. The implementation is provided as a set of parsers and projects in the Rust language.	high- and low-level;low-level programming language;memory management;parser combinator;parsing;rust;software bug	Pierre Chifflier;Geoffroy Couprie	2017	2017 IEEE Security and Privacy Workshops (SPW)	10.1109/SPW.2017.39	computer science;programming language;parser combinator;computer security;parsing;memory management;software bug;software	PL	-21.636029137773267	32.578107390652484	127520
2df06465c0d3aba775e78d5641969c349095801e	concurrency-degrees for p/t - nets.				Cristian Vidrascu;Toader Jucan	2003	Sci. Ann. Cuza Univ.		distributed computing;concurrency;computer science	Logic	-28.59435116062162	34.675554499293824	127626
e7f0623b528592a661192763d0e892c0bb7c9249	on the use of registers in achieving wait-free consensus	termination detection;global flush;communication architecture;group communication;asynchronous distributed systems;distributed algorithm	Rida A. Bazzi”t Gary L. Peterson~ Gil Neiger* Spelman College Georgia Institute of Technology The computational power of concurrent data types has been the focus of much recent research. Herlihy showed that such power may be measured by examining the type’s ability to implement wait-free consensus. Jayanti argued that this “ability” could be measured in different ways, depending, for example, on whether or not read/write registers could be used in an implementation. He demonstrated the significance of this distinction by exhibiting a nondeterministic type whose ability to implement consensus was increased with the availability of registers. We show that registers cannot increase the computational power (to implement consensus) of any deterministic type or of any type that can implement 2-process consensus. These results significantly impact upon the study of the wait-free hierarchies of concurrent data types. In particular, the combination of these results with other recent works shows that Jayanti’s hm hierarchy is robust for deterministic types. *This author was supported in part by the National Science Foundation under grants CCR-9106627 and CCR-9301454. Author’s address: College of Computing, Georgia Institute of Technology, Atlanta, Georgia 30332-0280. f T& author was supported in part by a scholarship from the Hariri Foundation. t ‘ThIs author was supported in part by the W. F. Kellogg Foundation under a grant to the Center for Scientific Applications of Mathematics at Spelman College. Author’s address: Computer and Information Science Program, Spelman College, 35o Spelman Lane SW, Post Office Box 333, Atlanta Georgia 30314-0339. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association of Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. PODC 948/94 Los Angeles CA USA @ 1994 ACM 0-89791 -654-9/94/0008.$3.50	consensus (computer science);information and computer science;information science;maurice herlihy;non-blocking algorithm;podc;shattered world	Rida A. Bazzi;Gary L. Peterson	1994		10.1145/197917.198124	distributed algorithm;real-time computing;communication in small groups;computer science;theoretical computer science;distributed computing;algorithm	Theory	-21.852668542118142	42.69292166557543	127666
cc49f1e25908cd320adf931ad3069892e2af788c	bridging islands of specialized code using macros and reified types	specialization;java virtual machine;data representation;macros;scala;reified types;bytecode	"""Parametric polymorphism in Scala suffers from the usual drawback of erasure on the Java Virtual Machine: primitive values are boxed, leading to indirect access, wasteful use of heap memory and lack of cache locality. For performance-critical parts of the code, the Scala compiler introduces specialization, a transformation that duplicates and adapts the bodies of classes and methods for primitive types. Specializing code can speed up execution by an order of magnitude, but only if the code is called from monomorphic sites or from other specialized code. Still, if these """"islands"""" of specialized code are called from generic code, their performance becomes similar to that of generic code, losing optimality. To address this, our project builds high performance """"bridges"""" between """"islands"""" of specialized code, removing the requirement that full traces need to be specialized: We use macros to delimit performance-critical """"gaps"""" between specialized code, which we also specialize. We then use reified types to dispatch the correct specialized variant, thus recovering performance across the """"islands"""". Our transformation obtains speedups up to 30x and around 12x in average compared to generic only code, by enabling specialization to completely remove boxing and reach its full potential."""	boxing;bridging (networking);compiler;dynamic dispatch;java virtual machine;locality of reference;memory management;parametric polymorphism;partial template specialization;reification (computer science);scala;tracing (software)	Nicolas Stucki;Vlad Ureche	2013		10.1145/2489837.2489847	dead code;code bloat;parallel computing;real-time computing;computer science;redundant code;programming language;code mobility;code generation;unreachable code;source code	PL	-19.17397979346819	35.35922474211384	127696
26c5f3028485058a3a98995c0d856e12c3e60d5d	adding fault-tolerance to a hierarchical dre system	tolerancia falta;systeme temps reel;distributed system;hierarchical system;systeme reparti;calculateur embarque;fault tolerant;sistema critica;componente logicial;distributed real time embedded;interoperabilite;interoperabilidad;resource allocation;systeme critique;resource manager;systeme hierarchise;resource management;logicial personalizado;composant logiciel;comportamiento bizantino;no existencia;comportement arbitraire;component middleware;intergiciel;byzantine behavior;gestion recursos;sistema jerarquizado;fault tolerant system;sistema repartido;critical system;fault tolerance;boarded computer;software component;sistema tolerando faltas;gestion ressources;middleware;systeme tolerant les pannes;real time system;sistema tiempo real;asignacion recurso;interoperability;allocation ressource;non existence;dynamic resource management;calculador embarque;tolerance faute	Dynamic resource management is a crucial part of the infrastructure for emerging mission-critical distributed real-time embedded system. Because of this, the resource manager must be fault-tolerant, with nearly continuous operation. This paper describes an ongoing effort to develop a fault-tolerant multi-layer dynamic resource management capability and the challenges we have encountered, including multi-tiered structure, rapid recovery, the characteristics of component middleware, and the co-existence of replicated and non-replicated elements. While some of these have been investigated before, this work exhibits all of these characteristics simultaneously, presenting a significant fault-tolerance research challenge.	continuous operation;embedded system;fault tolerance;layer (electronics);middleware;mission critical;real-time transcription	Paul Rubel;Joseph P. Loyall;Richard E. Schantz;Matthew Gillen	2006		10.1007/11773887_23	embedded system;fault tolerance;real-time computing;simulation;computer science;resource management;operating system;distributed computing	Embedded	-28.15646478732324	43.05157136206677	127817
eb7e054a9dce9be161782c991c9e2ad15e2c9ce7	flema: a flexible measurement architecture for chinagrid	distributed system;algoritmo paralelo;haute performance;systeme reparti;parallel algorithm;paysage;plugicial;grid applications;distributed computing;mesure niveau;paisaje;metric;algorithme parallele;sistema repartido;level measurement;alto rendimiento;calculo repartido;metrico;plugiciel;landscape;plug in software;high performance;calcul reparti;metrique;medicion nivel	Grid technologies are becoming more and more mature in recent years. In contrast to this trend, the resource measurement landscape in Grids looks rather dismal. As part of ChinaGrid SuperVision project, a Flexible Measurement Architecture (FleMA) for ChinaGrid is presented. In FleMA, business logic at application level is separated from the primary measurement issues at resource level to well adapt to various grid applications of ChinaGrid. A multi-level structure is exploited to generate compound metrics from raw measurements. FleMA also features open WSRF-compliant services and “plugin” measurement pattern, making it possible to achieve and deploy advanced functions synchronously on top of the unique measurement substrate.	business logic;entity;level structure;plug-in (computing);requirement;systems management;universal controls	Weimin Zheng;Meizhi Hu;Lin Liu;Yongwei Wu;Jing Tie	2005		10.1007/11576259_33	simulation;metric;computer science;distributed computing;parallel algorithm;landscape	Metrics	-27.988258578877304	43.088191873544105	127818
a5292372788d5c299ea4e1ee37531b69c785a971	describing distributed environments (abstract only)	error recovery;syntax;lr 1;semantics;portability;compilers;grammars;distributed environment;error correction;execution environment;parsar generators	The Distributed Execution Analysis Suite Project (DEA-Suite) [1] is concerned with developing a set of integrated tools for studying the execution of programs in a distributed environment. DEA-Suite consists of an environment to: (1) allow the specification of a candidate distributed execution environment. (2) assign the distributable portions of a program to the sites of execution in the distributed execution environment. (3) schedule the distributable portions of a program as they become enabled, and finally (4) simulate the execution of the program on the candidate distributed execution environment. One aim is to provide an environments. The presentation's focus will be on the description of distributed environments within the DEA-Suite project.		Paul A. Ponville	1985		10.1145/320599.322535	compiler;real-time computing;error detection and correction;syntax;computer science;database;distributed computing;semantics;linguistics;programming language;distributed computing environment	HPC	-26.352045691563855	36.63081893925878	127839
3cd981ea4c4e4fc4b2a404ac300305314b11fe3f	deductive schedulability verification methodology of real-time software using both refinement verification and hybrid automata	preemptive scheduling;resource allocation;real time;fixed priority preemptive scheduling deductive schedulability verification real time software hybrid automata real time operating system deductive refinement theory scheduling theory periodic process;real time operating system;fixed priority;formal verification;scheduling;hybrid automata;automata processor scheduling real time systems software quality timing resource management safety embedded system software systems cities and towns;real time systems formal verification scheduling;real time systems;time constraint	Real-time software runs over real-time operating systems, and guaranteeing qualities is difficult. As timing constraints and resource allocations are strict, it is necessary to verify schedulability, safety and liveness properties. In this paper, we formally specify real-time software using hybrid automata and verify its schedulability using both deductive refinement theory and scheduling theory. In this case, the above real-time software consists of periodic processes and a fixed-priority preemptive scheduling policy on one CPU. Using our proposed methods, we can uniformally and easily specify realtime software and verify its schedulability based on hybrid automata. Moreover, we can verify its schedulability at design stage.	automata theory;central processing unit;deductive database;hybrid automaton;liveness;preemption (computing);real-time clock;real-time computing;real-time operating system;real-time transcription;refinement (computing);scheduling (computing);verification and validation	Satoshi Yamane	2003		10.1109/CMPSAC.2003.1245390	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;real-time operating system;dynamic priority scheduling;formal verification;resource allocation;computer science;rate-monotonic scheduling;operating system;distributed computing;preemption;scheduling	Embedded	-25.39472727470752	34.88656569457296	127917
f6e75ec320f454741baaeb110ca45b83c0e70c1c	towards job accounting in existing resource schedulers: weaknesses and improvements	resource scheduling;billing;pistage;haute performance;availability;disponibilidad;resource manager;accounting;logicial personalizado;distributed computing;rastreo;grid middleware;comptabilite;intergiciel;grid;tariffication;rejilla;tarification;scheduling;palabra;alto rendimiento;grille;power grid;calculo repartido;middleware;scientific communication;word;contabilidad;facturation;grid computing;high performance;disponibilite;calcul reparti;ordonnancement;tracking;reglamento;mot;tarificacion;facturacion	The vision of having access to tremendous amounts of computation and storage resources on demand, together with access to special devices, similar to the availability of today’s power grids has been formulated by Ian Foster and Carl Kesselman in [1] in 1997 and since then has been known by the term Grid computing. As this vision slowly became reality and we’re now at the verge to having Grids production ready not only for scientific communities but also for industrial partners security, accounting and billing are now major concerns that need to be reflected and further improved. This paper analyzes two of the major local resource managers, Condor [2] and Torque[3], that are being used as local resource managers in the major grid middlewares Globus [4,5,6,7,8] as well as in the gLite and LCG [9,10] software stack with respect of being able to track malicious jobs and enforce a site policy. As weaknesses have been found we also present an approach that is capable of truly tracking any kind of job.	computation;electronic billing;grid computing;job stream;linux;loadable kernel module;malware;process management (computing);system call;the verge;user space;visual intercept;worldwide lhc computing grid;glite	Herbert Rosmanith;Peter Praxmarer;Dieter Kranzlmüller;Jens Volkert	2006		10.1007/11847366_74	availability;real-time computing;simulation;computer science;artificial intelligence;resource management;operating system;middleware;word;database;distributed computing;tracking;grid;scheduling;computer security;grid computing	HPC	-27.752861986622307	43.96210792631402	127993
1f8549b87e2b0a16e5785a9c4013f28bc4e9ef35	evaluating the dynamic behaviour of python applications	dynamic languages;programming language;python and compilers;dynamic behaviour;error detection;static analysis;open source	The Python programming language is typical among dynamic languages in that programs written in it are not susceptible to static analysis. This makes efficient static program compilation difficult, as well as limiting the amount of early error detection that can be performed. Prior research in this area tends to make assumptions about the nature of programs written in Python, restricting the expressiveness of the language. One may question why programmers are drawn to these languages at all, if only to use them in a static-friendly style. In this paper we present our results after measuring the dynamic behaviour of 24 production-stage open source Python programs. The programs tested included arcade games, GUI applications and non-interactive batch programs. We found that while most dynamic activity occurs during program startup, dynamic activity after startup cannot be discounted entirely.	arcade game;batch processing;compiler;error detection and correction;graphical user interface;interactivity;open-source software;programmer;programming language;python;static program analysis	Alex Holkner;James Harland	2009			real-time computing;python;computer science;theoretical computer science;scripting language;programming language	PL	-20.642904006715025	32.66421855786588	128077
f2cc4bb4809835ff77776dc1b1ccedf8d5809a92	an assessment of the modsim/twos parallel simulation environment	discrete event simulation;object-oriented programming;parallel processing;c/twos application;modsim/twos parallel simulation environment;modsim language;time warp operating system;compiler support;object oriented simulation environment;parallel discrete event simulation;process-based execution model	The major flaw with the ModSim/IIVOS system as it currently exists is that there is no compiler support for mapping a ModSim application into an efficient CITWOS application. Moreover, the ModSim language as currently defined does not provide explicit hooks into the Time Warp Operating System and hence the developer is unable to tailor a ModSim application in the same fashion that a C application can be tailored. Without sufficient compiler suppofi there is a mismatch between ModSim’s object-oriented, process-based execution model and the Time Warp execution model. In this paper we present our assessment of ModSim/TWOS and also discuss both components in isolation.	compiler;flaw hypothesis methodology;operating system;simulation	David O. Rich;Randy E. Michelsen	1991			parallel processing;parallel computing;real-time computing;simulation;computer science;programming language;object-oriented programming	HPC	-25.09481341424353	36.06903161003382	128712
27135a4354cb9df80a8615f62cfd518f6a523ec6	a middleware approach to asynchronous and backward compatible detection and prevention of arp cache poisoning	lan host;cache storage;operating system source code;microwave integrated circuits;protocols;alarms;memory protocols;information security;ethernet;performance middleware arp cache poisoning address resolution protocol malicious act lan host spurious ip address mac address mapping ethernet design constraints operating system source code backward compatibility asynchronous solution streams based networking subsystem bump in the stack streams module driver user level application alarms;performance;streams based networking subsystem;bump in the stack streams module;client server systems;computer crime;backward compatibility;middleware local area networks ethernet networks electronic switching systems operating systems protocols internet arm microwave integrated circuits information security;transport protocols;design constraints;internet;operating system;address resolution protocol;asynchronous solution;electronic switching systems;driver;arm;middleware;transport protocols client server systems cache storage memory protocols computer crime local area networks;source code;spurious ip address;malicious act;arp cache poisoning;user level application;ethernet networks;mac address mapping;local area networks;operating systems	"""This paper discusses the Address Resolution Protocol (ARP) and the problem of ARP cache poisoning. ARP cache poisoning is the malicious act, by a host in a LAN, of introducing a spurious IP address to MAC (Ethernet) address mapping in another host’s ARP cache. We discuss design constraints for a solution: the solution needs to be implemented in middleware, without access or change to any operating system source code, be backward-compatible to the existing protocol, and be asynchronous. We present our solution and implementation aspects of it in a Streams based networking subsystem. Our solution can be implemented in non-Streams based networking subsystems also. Our solution comprises two parts: a """"bump in the stack"""" Streams module, and a separate Stream with a driver and user-level application. We also present the algorithm that is executed in the module and application to prevent ARP cache poisoning where possible and detect and raise alarms otherwise. We then discuss some limitations with our approach and present some preliminary performance numbers for our implementation."""	arp spoofing;algorithm;asynchronous i/o;backward compatibility;cpu cache;dns spoofing;mac address;middleware;network performance;operating system;protocol stack;streams;thermal copper pillar bump;user space	Mahesh V. Tripunitara;Partha Dutta	1999		10.1109/CSAC.1999.816040	local area network;address resolution protocol;embedded system;communications protocol;the internet;backward compatibility;performance;computer science;information security;operating system;middleware;arm architecture;cache algorithms;computer security;ethernet;transport layer;proxy arp;computer network;arp spoofing;source code	HPC	-25.975435131356058	41.82844448838167	128849
0b30a40dd64629281984f51232bf17e40b54c244	just-in-time compiler assisted object reclamation and space reuse	parallel garbage collector;compiler assisted garbage collection;garbage collection;just in time compiler;garbage collector;live variable information;pointer and escape analysis	Garbage collection consumes significant overhead to reclaim memory used by dead (i.e., unreachable) objects in applications. This paper explores techniques for compiler assisted object reclamation and allocation on an actual JVM. Thereinto, the just-in-time compiler identifies dead objects using pointer and escape analysis combining liveness information and inserts calls to free them. The garbage collector provides runtime support for explicit reclamation and space reuse. Our approach differs from other compiler assisted GC in two crucial ways. First, it identifies not only the objects that are no longer referenced directly by the program, but also the objects that are referenced only by those identified to-be-freed objects. Second, it modifies a parallel garbage collector, and not only frees the identified dead objects, but also tries to reuse their space immediately. The experimental results show that the JIT-assisted GC improves the memory utility and the performance efficiently. Keyword: compiler assisted garbage collection, pointer and escape analysis, live variable information, parallel garbage collector	compiler;escape analysis;garbage collection (computer science);just-in-time compilation;live variable analysis;liveness;overhead (computing);pointer (computer programming);unreachable memory	Yu Zhang;Lina Yuan;Tingpeng Wu;Wen Peng;Quanlong Li	2010		10.1007/978-3-642-15672-4_4	manual memory management;dead store;garbage;parallel computing;real-time computing;ephemeron;computer science;operating system;garbage in, garbage out;garbage collection;programming language;mark-compact algorithm	PL	-20.11360905452527	35.15561050391701	129194
11ce2eda248b602cb01f1adf99d60f0b6c39e152	revisiting fast practical byzantine fault tolerance		In this note, we observe a safety violation in Zyzzyva [7, 9, 8] and a liveness violation in FaB [14, 15]. To demonstrate these issues, we require relatively simple scenarios, involving only four replicas, and one or two view changes. In all of them, the problem is manifested already in the first log slot.	byzantine fault tolerance;liveness	Ittai Abraham;Guy Golan-Gueta;Dahlia Malkhi;Lorenzo Alvisi;Ramakrishna Kotla;Jean-Philippe Martin	2017	CoRR		zyzzyva;distributed computing;real-time computing;computer science;liveness;byzantine fault tolerance	OS	-22.19154248836143	45.136934770512624	129263
6351c3b295a40835dcb27477db93b9dbce536317	group membership failure detection: a simple protocol and its probabilistic analysis	distributed system;failure detection;safety properties;probabilistic analysis;asynchronous distributed system;group membership	A group membership failure (in short, agroup failure) occurs when one of the group members crashes. A group failure detection protocol has to inform all the non-crashed members of the group that this group entity has crashed. Ideally, such a protocol should be live (if a process crashes, then the group failure has to be detected) and safe(if a group failure is claimed, then at least one process has crashed). Unreliable asynchronous distributed systems are characterized by the impossibility for a process to get an accurate view of the system state. Consequently, the design of a group failure detection protocol that is both safe and live is a problem that cannot be solved in all runs of an asynchronous distributed system. This paper analyses a group failure detection protocol whose design naturally ensures its liveness. We show that by appropriately tuning some of its duration-related parameters, the safety property can be guaranteed with a probability as close to one as desired. This analysis shows that, in real distributed systems, it is possible to achieve failure detection with a negligible probability of wrong suspicions.	crash (computing);distributed computing;liveness;norm (social);performance tuning;probabilistic analysis of algorithms	Michel Raynal;Frédéric Tronel	1999	Distributed Systems Engineering	10.1088/0967-1846/6/3/301	probabilistic analysis of algorithms;real-time computing;computer science;distributed computing;computer security	Security	-22.473244199834976	44.597180136623585	129655
83eaaadcf2cd580410727dcac9cef5abb8ade82b	resource-based scripting to stitch distributed components	distributed application;application development;distributed system;systeme reparti;programming paradigm;resource manager;simultaneidad informatica;systeme ouvert;transmision asincronica;concurrency;sistema repartido;algorithme reparti;asynchronous transmission;middleware;algoritmo repartido;transmission asynchrone;access control;point of view;open systems;sistema abierto;distributed algorithm;simultaneite informatique;scripting language	This paper proposes the Resource-Based Programming paradigm as support for the design, implementation, debugging and tuning of distributed applications. This paradigm considers components as resource managers and expresses the application logic through scriptable transactional resource manipulations. In this paper, we describe the benefits deriving from such a paradigm both from a theoritical and from a practical point of view. We first introduce the resource-based paradigm in itself and the CLF middleware [3] that implements it. We then illustrate through an example application the various advantages of using it in the context of distributed applications.	anurag kumar;aspect-oriented programming;aspectj;business logic;certificate authority;common look and feel;common object request broker architecture;database transaction;debugging;distributed computing;distributed element model;ecoop;feedback;high-level programming language;ibm websphere mq;image stitching;interaction;jean;middleware;performance tuning;programming paradigm;sms language;sql;scripting language;springer (tank);tooltalk;tuple space	Jean-Marc Andreoli;Damián Arregui;François Pacull;Jutta Willamowski	2002		10.1007/3-540-45785-2_34	distributed algorithm;real-time computing;concurrency;computer science;artificial intelligence;access control;operating system;asynchronous communication;middleware;database;distributed computing;scripting language;programming paradigm;open system;programming language;rapid application development;algorithm	HPC	-28.939148902256342	42.21437830938382	129851
353bfc5460691bd5d7b9e07d1b41c4f30851a35a	implementing atomic objects with the relax transaction facility	distributed processing;distributed system;transaction processing;project management;object oriented programming;atomic layer deposition;interference;computer science;open systems;kernel;resource management	This paper presents an object-oriented model for distributed transaction processing and discusses the issues which had to be explored in the implementation of this model. The functionality of this transaction model meets the requirements of a range of concurrent, distributed applications. We show that transaction functionality can be implemented in a language independent manner allowing the model to be provided through multiple languages. In particular, this paper presents the design and implementation of the Amadeus/RelaX system. We describe the architecture of the RelaX extensible transaction facility and its integration with the Amadeus distributed, persistent object system. The resulting transaction system can support different languages and allows the use of resource types such as files, and database relations as well as objects, and is portable to various UNIX-like platforms.	distributed computing;distributed transaction;linear programming relaxation;relax ng;requirement;transaction processing;unix;unix-like	Michael Mock;Reinhold Kröger;Vinny Cahill	1992	Computing Systems		real-time computing;transaction processing;distributed transaction;computer science;x/open xa;database;distributed computing;online transaction processing;transaction processing system	DB	-27.41534465807763	45.68284281771087	129954
738fe79d09a61a2bc03b4bc2d355e779487f9018	distributed virtual worlds - foundations and implementation techniques using vrml, java, and corba		Recently, with the success of Java and the existence of different interfaces be tween VRML and Java, it became possible to implement three-dimensional internet applications on standard VRML browsers (Plugins) using Java....	common object request broker architecture;java;plug-in (computing);vrml;virtual world	Stephan Diehl	2001				PL	-33.61811964828175	42.85266526605481	130241
456fb4f26425fb45e023ca99872df67d046a9cd9	racetm: detecting data races using transactional memory	data race detection;conflict detection;data races;multicore processors;transactional memory;parallel applications	Widespread emergence of multicore processors will spur development of parallel applications, exposing programmers to more hardware concurrency. Dependable multithreaded software will have to rely on the ability to dynamically detect data races, which are non-deterministic and notoriously hard to reproduce symptoms of synchronization bugs. In this paper, we propose RaceTM, a novel approach that exploits transactional memory support to detect data races. We introduce the concept of lightweight debug transactions that exploit the conflict detection mechanisms of transactional memory systems to perform data race detection. Debug transactions differ from regular transactions in that they do not need to be rolled back, and therefore require no versioning or checkpointing support. Debug transactions do not overlap with a regular transaction, thus providing a transparent mechanism to leverage existing transactional memory support for data race detection.	application checkpointing;central processing unit;concurrency (computer science);debug;emergence;file synchronization;multi-core processor;programmer;race condition;sensor;software bug;synchronization (computer science);thread (computing);transactional memory	Shantanu Gupta;Florin Sultan;Srihari Cadambi;Franjo Ivancic;Martin Roetteler	2008		10.1145/1378533.1378551	multi-core processor;transactional memory;parallel computing;real-time computing;computer science;operating system;software transactional memory;distributed computing	Arch	-20.87906896178792	39.7209051049833	130244
b53e3748ff7a963d736c2ad1f919bb2f0543b59b	chat: the copy-hybrid approach to tabling	architecture memoire;ingenieria logiciel;logical programming;software engineering;abstract machine;analisis programa;hybrid approach;performance programme;programmation logique;memory architecture;estructura datos;genie logiciel;eficacia programa;structure donnee;program analysis;program performance;analyse programme;programacion logica;data structure	The copying approach to tabling (CAT) is an alternative to SLG-WAM and based on incrementally copying the areas that the SLG-WAM freezes to preserve execution states of suspended computations. The main advantage of CAT over the SLG-WAM is that support for tabling does not affect the speed of the underlying abstract machine for strictly non-tabled execution. The disadvantage of CAT as pointed out in a previous paper is that in the worst case, CAT must copy so much that its tabled execution becomes arbitrarily worse than that of the SLG-WAM. Remedies to this problem have been studied, but a completely satisfactory solution has not emerged. Here, a hybrid approach is presented: abbreviated as CHAT. Its design was guided by the requirement that for non-tabled (i.e. Prolog) execution no changes to the underlying WAM engine need to be made. CHAT not only combines certain features of the SLG-WAM with features of CAT, but also introduces a technique for freezing WAM stacks without the use of the SLG-WAM’s freeze registers that is of independent interest. This article describes only the basic CHAT mechanism which allows for programs that perform arbitrarily worse than under the SLG-WAM. However, empirical results indicate that even basic CHAT is a better choice for implementing the control of tabling than SLG-WAM or CAT. © 2000 Elsevier Science B.V. All rights reserved.	abstract machine;best, worst and average case;computation;memoization;prolog	Bart Demoen;Konstantinos Sagonas	1999		10.1007/3-540-49201-1_8	program analysis;simulation;data structure;computer science;artificial intelligence;operating system;database;abstract machine;programming language;algorithm	PL	-19.601837661841962	33.750577395508884	130356
7fe786a45995b8243ba0f5a378b020c6639599d7	run-control and service element code simulation for the s/390 microprocessor	verification;simulation ordinateur;microprocessor;metodologia;methode essai;concepcion sistema;serveur informatique;methodologie;system design;system integration;servidor informatico;microprocesseur;time to market;simulacion computadora;test method;verificacion;methodology;computer simulation;microprocesador;conception systeme;computer server;metodo ensayo	In recent years the importance of time to market for new computer systems has grown. Very little time can be spent in hardware bring-up and the system integration phase when new hardware and new code (several megabytes) come together for the first time on the test floor. This paper describes some of the measures that were taken to achieve this goal on the S/390® Parallel Enterprise Server Generation 4.	microprocessor;simulation	Stefan Koerner;Steven M. Licker	1997	IBM Journal of Research and Development	10.1147/rd.414.0577	computer simulation;embedded system;real-time computing;verification;simulation;computer science;engineering;methodology;test method;server;system integration;systems design	Arch	-19.831147056021187	41.927474028585394	130900
5a89e3ce5c64c512927e907ac4351e6779daeef6	implementing a graphical multi-user interface toolkit	floor control;interfase usuario;filter event;filtre evenement;graphical interface;user interface;ingenieria logiciel;software engineering;synchronisation;graphical multi user interfaces;event filters;synchronization;multi user interfaces;genie logiciel;interface utilisateur;sincronizacion;interface graphique;user interface toolkits	Multi-user applications allows users in different locations to simultaneously interact with a common interface. Creating multi-user applications is complicated by issues such as process synchronization, replicated window management, and floor control. As a result, several papers describing toolkits that simplify programming of multi-user applications have appeared in the literature. This paper discusses several low-level issues that must be addressed when implementing such a toolkit. Issues relating to replicated window management, supporting heterogeneous hardware environments, and multi-user event handling are discussed.	event (computing);graphical user interface;high- and low-level;list of toolkits;multi-user;synchronization (computer science);user interface toolkit;window manager	Douglas C. Kohlert;Kenneth J. Rodham;Dan R. Olsen	1993	Softw., Pract. Exper.	10.1002/spe.4380230905	synchronization;real-time computing;human–computer interaction;computer science;operating system	HCI	-27.415842649540593	40.44029199146698	130952
9d92e5abd925e4195d58d1b566cfb548c6111b2b	learning unix for mac os x tiger - unlock the power of unix			mac os x 10.4 tiger;sim lock;unix	Dave Taylor	2005			single unix specification;unix architecture;embedded system;os x;mac os;computer hardware;computer science;operating system;unix;berkeley software distribution;environment variable	Crypto	-28.90494493148877	39.53821883408795	131259
e375b75a9c4652610de7485fe1126771161479e8	an object-oriented view of fragmented data processing for fault and intrusion tolerance in distributed systems	distributed system;data processing;professor brian randell;eprints newcastle university;object oriented systems;distributed computing system;object oriented;open access;intrusion tolerance;not significant	This paper describes a technique, called Object-Oriented Fragmented Data Processing, for jointly improving the reliability and security with which distributed computing systems process sensitive information. The technique protects the information contained in, and the processing performed by, a given object by first fragmenting the object into the subsidiary objects of which it is composed. It then relies on the (i) the correct execution of a majority of a set of copies of these subsidiary objects, and (ii) the reliable storage of a majority of a set of copies of each of these subsidiary objects, having distributed the subsidiary objects widely across a number of computers in a distributed computing system. The intent is to impede intruders and to tolerate faults, and involves ensuring that an isolated subsidiary object is not significant, due to the lack of information it would provide to a potential intruder. This technique can be applied to application objects and/or to the objects used in the implementation of the basic object-oriented system. The paper illustrates the technique using a detailed example, of an “electronic diary”, that has been designed using Eiffel, and experimented with using the DELTA-4 Support Environment.	computer;distributed computing;eiffel;ip fragmentation;information sensitivity;intrusion tolerance	Jean-Charles Fabre;Brian Randell	1992		10.1007/BFb0013899	intrusion tolerance;real-time computing;data processing;computer science;database;distributed computing;distributed object;programming language;object-oriented programming;computer security	DB	-26.295130382191523	40.56050767783017	131537
fc6e81d819097f6f423e62ad61b14c9a024c3380	message-efficient omission-tolerant consensus with limited synchrony	detectors;smart card;fault free processes;computer crashes;message complexity message efficient omission tolerant consensus limited synchrony general omission failure model smart card based security framework fault free processes;limited synchrony;communication complexity;detectors security timing smart cards computer crashes fault tolerance personal digital assistants laboratories fault detection control systems;data mining;message efficient omission tolerant consensus;smart cards;smart card based security framework;failure detector;general omission failure model;smart cards communication complexity mobile computing security of data;mobile computing;proposals;security of data;algorithm design and analysis;message complexity;timing	We study the problem of consensus in the general omission failure model, i.e., in systems where processes can crash and omit messages while sending or receiving. This failure model is motivated from a smart card-based security framework in which certain security problems can be reduced to consensus in that model. We propose an algorithm that solves consensus based on very weak timing assumptions. More precisely, we show that consensus is solvable using an eventual bisource and a majority of fault-free processes. An eventual bisource is a fault-free process that can eventually communicate with all other processes in a timely manner. In contrast to previous work, we use timing assumptions directly in the algorithm and do not employ the notion of a failure detector. We argue that this is helpful in reducing the message complexity, a critical aspect of algorithms which run on smart cards.	algorithm;decision problem;eventual consistency;failure detector;smart card	Carole Delporte-Gallet;Hugues Fauconnier;Andreas Tielmann;Felix C. Freiling;Mahir Kilic	2009	2009 IEEE International Symposium on Parallel & Distributed Processing	10.1109/IPDPS.2009.5160899	smart card;parallel computing;real-time computing;computer science;operating system;distributed computing;chandra–toueg consensus algorithm;mobile computing;computer security;algorithm;computer network	Logic	-22.674609172778123	44.19605952435065	131664
c1e365d9aec1eec82e0ccc5af671950449203266	flexible open caching for the web	red www;web community;caching;web;object oriented framework;cache memory;weak consistency;antememoria;antememoire;internet;object oriented;reseau telecommunication;oriente objet;world wide web;reseau www;large scale distributed systems;orientado objeto;web caching;telecommunication networks	Caching plays a vital role in the performance of any large-scale distributed system and, as the variety and number of Web applications grows, is becoming an increasingly important research topic within the Web community. Existing caching mechanisms are largely transparent to their users and cater for resources which are primarily read-only, offering little support for customisable or complex caching strategies. In this paper we examine the deficiencies in these mechanisms with regard to applications with requirements for shared access to data where clients may require a variety of consistency guarantees. We present 'open' caching within an object-oriented framework, an approach to solving these problems which, instead of offering caching transparency makes the caching mechanism highly visible allowing great flexibility in caching choices. Our implementation is built upon the W3Objects infrastructure and allows clients to make caching decisions for individual resources with minimal impact upon other resources which do not support our mechanisms.	cache (computing);distributed computing;file system permissions;programmer;read-only memory;requirement;web application;world wide web	Steve J. Caughey;David B. Ingham;Mark C. Little	1997	Computer Networks	10.1016/S0169-7552(97)00015-9	weak consistency;the internet;false sharing;cpu cache;computer science;database;distributed computing;object-oriented programming;world wide web;computer network	Web+IR	-29.327002669012167	44.17522728187395	131793
51273d67a2d8364d6d03938112c628dbb2f96af1	refinement rules for real-time multi-tasking programs	systeme temps reel;real time;concurrent program;ingenieria logiciel;specification programme;program verification;software engineering;verificacion programa;programa competidor;genie logiciel;2614 theoretical computer science;real time system;sistema tiempo real;verification programme;program specification;lenguaje formal;especificacion programa;formal language;hard real time;programme concurrent;1700 computer science;langage formel	We present several formal program refinement rules for designing multi-tasking programs with hard real-time constraints.	computer multitasking;real-time computing;real-time locating system;real-time transcription;refinement (computing)	Colin J. Fidge	1997		10.1007/BFb0000472	refinement calculus;formal language;simulation;real-time operating system;computer science;software engineering;refinement;programming language;algorithm	Logic	-24.06866331774754	32.49347823615085	132052
4da8fd16677939c4b8e36cdf2113a911c0ac461a	in-kernel servers on mach 3.0: implementation and performance	existing performance problem;in-kernel servers;full rpc mechanism;single server;performance critical application;performance degradation;rpc performance;in-kernel server;rpc stub generator;rpc path;performance gain;mach microkernel	The advantages in modularity and power of microkernel-based operating systems such as Mach 3.0 are well known. The existing performance problems of these systems, however, are signi cant. Much of the performance degradation is due to the cost of maintaining separate protection domains, traversing software layers, and using a semantically rich inter-process communication mechanism. An approach that optimizes the common case is to permit merging of protection domains in performance critical applications, while maintaining protection boundaries for debugging or in situations that demand robustness. In our system, client calls to the server are e ectively bound either to a simple system call interface, or to a full RPC mechanism, depending on the server's location. The optimization reduces argument copies, as well as work done in the control path to handle complex and infrequently encountered message types. In this paper we present a general method of doing this for Mach 3.0 and the results of applying it to the Mach microkernel and the OSF/1 single server. We describe the necessary modi cations to the kernel, the single server, and the RPC stub generator. Semantic equivalence, backwards compatibility, and common source and binary code are preserved. Performance on micro and macro benchmarks is reported, with RPC performance improving by a factor of three, Unix system calls to the server improving between 20% and a factor of two, and 4{13% performance gain on large benchmarks. A breakdown of the times on the RPC path is also presented. 1	backward compatibility;benchmark (computing);binary code;data protection directive;debugging;elegant degradation;inter-process communication;kernel (operating system);mach;mathematical optimization;microkernel;operating system;performance;remote procedure call;server (computing);system call;the times;tru64 unix;turing completeness	Jay Lepreau;Mike Hibler;Bryan Ford;Jeffrey Law;Douglas B. Orr	1993			real-time computing;computer science;operating system;distributed computing	OS	-24.40851811488149	40.82878663824662	132152
32a7962247f15b0309f9b3ee800262c39d077486	an optimized memory management algorithm for realtime simulation on linux operation system		As an important branch of simulation technology, realtime hardware-in-the-loop simulation has been widely used in industrial design and equipment testing. The current real-time simulation software is mostly based on proprietary systems or realtime transformation of the Windows system and cannot run in the general Linux system with a large number of users. At the same time, the existing memory management algorithm has low utilization rate and cannot adapt to the needs for a long time simulation. In view of this problem, this paper combines the design method of the existing real-time software to design the real-time simulation framework in Linux environment, and improves the memory management method to meet the needs of largescale and long-term simulation. The experimental results	algorithm;hardware-in-the-loop simulation;linux;linux;matlab;memory management;microsoft windows;operating system;real-time clock;real-time locating system;real-time transcription;requirement;simulation software;software framework;time complexity	Miao Zhang;Zhiwen Jiang;Yiping Yao;Tianlin Li	2017		10.1145/3173519.3173542	simulation software;computer science;real-time computing;utilization rate;memory management;real-time simulation;software;algorithm;inter-process communication	Embedded	-20.415796002349943	37.28431892342752	132265
dd381d782f9e9be5f18ed86a23b272ee4a5c2409	the implementation of a user-extensible system on a dynamically microprogrammable computer	microprogrammed routine;base machine;virtual control memory;user-extensible assembler;basic machine instruction;virtual memory;integral part;user-extensible system;writable control storage;dynamically microprogrammable computer;dynamically user-microprogrammable computer;software engineering;virtual machines;microprogramming;emulation	On a dynamically user-microprogrammable computer the user can tailor the machine to his needs by constructing microprogrammed routines and adding them to the system. If these routines are recognized by the assembler, then using them is no different from using any other basic machine instruction of the computer. The base machine is thus extended. The design and implementation of such a user-extensible system is described. It consists of 2 main parts: a pager which manages a virtual memory for the writable control storage and a user-extensible assembler which accepts microprogrammed routine into the virtual control memory and makes this an integral part of the system.	assembly language;floor and ceiling functions;machine code;microcode	Fergus K. Fung;Willis K. King	1977			emulation;computer architecture;parallel computing;computer hardware;computer science;virtual machine;virtual memory;operating system;microcode;programming language;data diffusion machine;virtual finite-state machine	Arch	-26.239904958379373	38.347159963307384	132769
0dde5a19d899cbae45eb559ff8e4af7f99ceec96	scheduling considerations for building dynamic verification tools for mpi	model checking;distributed programming;partial order reduction;message passing;mpi;dynamic verification;partial order	Dynamic verification methods are the natural choice for formally verifying real world programs when model extraction and maintenance are expensive. Message passing programs written using the MPI library often fall under this category, especially when these programs have to be verified after being ported to new platforms and iteratively optimized. However, implementing dynamic verification tools for MPI requires solving many problems pertaining to the scheduling realities of the MPI runtime. In this paper, we describe the progression of our ideas during the development of our dynamic verification tool for MPI programs, called in-situ partial order (ISP). Each idea developed in this progression relates to our dual goals of ensuring full coverage of all representative interleavings (in the sense of partial order reduction) among MPI processes, and forcing the MPI runtime to affect these interleavings. We briefly examine similar issued faced by other builders of dynamic verification tools. We conclude with observations backing the growing importance of addressing scheduling issues in future dynamic verification tools for various concurrency APIs.	color gradient;concurrency (computer science);formal verification;message passing interface;partial order reduction;scheduling (computing);software verification;verification and validation	Sarvani S. Vakkalanka;Michael Delisi;Ganesh Gopalakrishnan;Robert Michael Kirby	2008		10.1145/1390841.1390844	partially ordered set;model checking;partial order reduction;message passing;real-time computing;computer science;message passing interface;theoretical computer science;distributed computing;programming language	HPC	-24.779865867256706	35.777368203311376	133091
548f8b6b4afec02acc035a9f40186921a48072a2	larva --- safer monitoring of real-time java programs (tool paper)	runtime verification larva realtime java programs timed automata industrial system financial transactions;industrial system;financial transactions;yarn;runtime verification;java programming;clocks;real time;monitoring of real time properties;realtime java programs;java formal verification;resource bounded monitoring runtime verification monitoring of real time properties;runtime;upper bound;formal verification;duration calculus;monitoring;larva;calculus;performance analysis;real time java;timed automata;java runtime logic computer science calculus performance analysis feedback software engineering computerized monitoring real time systems;resource bounded monitoring;programming tool;java;real time systems	The use of runtime verification, as a lightweight approach to guarantee properties of systems, has been increasingly employed on real-life software. In this paper, we present the tool LARVA, for the runtime verification of properties of Java programs, including real-time properties. Properties can be expressed in a number of notations, including timed-automata enriched with stopwatches, Lustre, and a subset of the duration calculus. The tool has been successfully used on a number of case-studies, including an industrial system handling financial transactions. LARVA also performs analysis of real-time properties, to calculate, if possible, an upper-bound on the memory and temporal overheads induced by monitoring. Moreover, through property analysis, LARVA assesses the impact of slowing down the system through monitoring, on the satisfaction of the properties.	automata theory;duration calculus;lustre;real life;real time java;real-time clock;runtime verification;timed automaton	Christian Colombo;Gordon J. Pace;Gerardo Schneider	2009	2009 Seventh IEEE International Conference on Software Engineering and Formal Methods	10.1109/SEFM.2009.13	embedded system;duration calculus;real-time computing;larva;formal verification;computer science;real time java;runtime verification;upper and lower bounds;programming language;java;financial transaction	SE	-23.933043168761486	35.552317839214965	133356
551f644d29983c9e8f464ff9d97c0d348a74b1e8	design and implementation of an end-to-end operation system for digital television	digital video broadcasting;application development;end to end operation system;software systems;application execution system;telecommunication computing;digital television;indexing terms;digital tv application software us department of transportation satellite broadcasting tv broadcasting middleware software systems control systems hardware testing;se top box;interactive application;operating system;design and implementation;data broadcast system;interactive dtv applications;application development environment;middleware;interactive dtv applications end to end operation system digital television applications application execution system data broadcast system application development environment middleware system se top box;data broadcast;interactive television;middleware system;telecommunication computing digital video broadcasting interactive television middleware;digital television applications	This paper addresses an end-to-end operation system for digital television (DTV) applications. It is designed to develop, broadcast, download and execute interactive DTV applications. The system is composed of three subsystems. They are application execution system (AES), data broadcast system (DBS) and application development environment (ADE). AES, generally called DTV middleware system, is the software system running in DTV se-top box (STB) to execute and control interactive DTV applications. It isolates DTV applications from STB hardware. DBS is used to multiplex, transmit and broadcast DTV data, as well as manage DTV applications. ADE is a special integrative toolkit designed for developing interactive DTV applications. Application developers can edit, compile, debug and test a DTV application in ADE. Then DBS broadcasts the application through DTV channel. After being downloaded into STB, the application is executed by AES in the STB. Design and implementation of these three subsystems are presented in this paper. The proposed system has been used in real environment of interactive DTV operation	broadcasting (networking);compiler;debugging;direct-broadcast satellite;download;end-to-end encryption;end-to-end principle;internet;middleware;multiplexing;operating system;set-top box;software development kit;software system	Rui Zhang;Dequan Yu;Songyu Yu	2006	IEEE Transactions on Consumer Electronics	10.1109/TCE.2006.1706476	embedded system;real-time computing;index term;digital television;telecommunications;computer science;operating system;middleware;interactive television;rapid application development;digital video broadcasting;software system	Mobile	-31.946064412009708	39.326175373936536	133382
4453f5622cc369f8c416fc3cd6860a448e1bec3e	effect of hyper-threading technology on java virtual machines: a performance study			hyper-threading;java	Mei-Leng Yau;Hai-Shuan Lam;G. S. V. R. Krishna Rao;Chikkannan Eswaran	2005			java applet;programming language;computer science;plug-in;operating system;embedded java;real time java;java;cross-platform;strictfp;java concurrency	Arch	-31.894591795680576	42.79194701662291	133430
1b872cb94301d3f9a6f8a2a0797293d3b0ea027d	macro-programming wireless sensor networks using kairos	modelizacion;distributed system;traitement signal;red sin hilo;remote access;reseau capteur;gestion memoire;systeme reparti;acceso remoto;macro programming;reseau sans fil;localizacion objeto;generation code;storage management;acces a distance;object location;wireless network;generacion codigo;distributed computing;code generation;distributed programs;abstraction;abstraccion;sensor network;wireless sensor network;programming model;modelisation;gestion memoria;red sensores;sistema repartido;levels of abstraction;signal processing;object tracking;algorithme reparti;poursuite cible;data access;sensor array;calculo repartido;coordinacion;algoritmo repartido;macro programmation;information system;macroprogrammacion;target tracking;distributed algorithm;procesamiento senal;modeling;localisation objet;calcul reparti;systeme information;coordination;sistema informacion	The literature on programming sensor networks has focused so far on providing higher-level abstractions for expressing local node behavior. Kairos is a natural next step in sensor network programming in that it allows the prog rammer to express, in a centralized fashion, the desired global behavior of a distributed computation on the entire sensor network. Kairos’ compile-time and runtime subsystems expose a small set of programming primitives, while hiding from the programmer the details of distributed-code generation and instantiation, remote data access and management, and inter-node program flow coordination. I n this paper, we describe Kairos’ programming model, and demonstrate its suitability, thr oug actual implementation, for a variety of distributed programs—both infrastr uctu e services and signal processing tasks—typically encountered in sensor network literature: routing tree construction, localization, and object tracking. Our experimental results suggest that Kairos does not adversely affect the per formance or accuracy of distributed programs, while our implementation experiences suggest that it greatly raises the level of abstraction presented to the programmer .	apache continuum;application programming interface;centralized computing;code generation (compiler);compile time;compiler;computation;computer network programming;computer programming;control flow;data access;distributed computing;internationalization and localization;kairos;middleware;programmer;programming model;reflow soldering;routing;signal processing;universal instantiation	Ramakrishna Gummadi;Omprakash Gnawali;Ramesh Govindan	2005		10.1007/11502593_12	embedded system;distributed algorithm;wireless sensor network;telecommunications;computer science;artificial intelligence;signal processing;distributed computing;programming language	Mobile	-28.7828191525658	41.62935104807822	133431
9d04bd7f408ee4f0d17bf3eaec85e22f7c5c061a	an architecture for a video rate fuzzy golay processor.				Randy H. Steinvorth;G. F. Taylor;Jack F. McDonald;Tony Hunter	1985			embedded system;real-time computing	Arch	-29.974342290383042	38.20963366312836	133471
0cfcf8569cc622bacc64a0c4c6131d7117ec3472	some deadlock properties of computer systems	resource allocation;operating system	First, a “meta theory” of computer systems is developed so that the terms “process” and “deadlock” can be defined. Next, “reusable resources” are introduced to model objects which are shared among processes, and “consumable resources” are introduced to model signals or messages passed among processes. Then a simple graph model of computer systems is developed, and its deadlock properties are investigated. This graph model is useful for teaching purposes, unifies a number of previous results, and leads to efficient deadlock detection and prevention algorithms.		Richard C. Holt	1972	ACM Comput. Surv.	10.1145/356603.356607	parallel computing;real-time computing;real-time operating system;resource allocation;computer science;deadlock;concurrency control;distributed computing;deadlock prevention algorithms	Theory	-25.548761805204656	45.18944992981507	133808
90607f529b80b41d2816347bc11b5fcab6e49443	tool support for the synchronization and presentation of distributed multimedia	tool support;distributed multimedia	Synchronization of multiple media is a major issue in multimedia applications; in distributed systems, this problem is aggravated further. We present tools for the creation, editing, and presentation of synchronized multimedia objects. In particular, we describe a graphical Synchronization Editor for the specification of synchronization schemes and a Synchronizer for the execution of multimedia presentations. We emphasize the requirements imposed by an underlying distributed heterogeneous environment, as well as support for interactive user control. The tools described are not restricted to a fixed set of media, but support the inclusion of arbitrary user-defined media. The Synchronization Editor and Synchronizer are part of the Mode project, which in turn covers the ‘distributed multimedia object support’ part of NESTOR, an authoring/learning environment developed jointly by the Universities of Karlsruhe and Kaiserslautern and the Digital Equipment CEC, Karlsruhe.		Gerold Blakowski;Jens Hübel;Ulrike Langrehr;Max Mühlhäuser	1992	Computer Communications	10.1016/0140-3664(92)90113-S	real-time computing;telecommunications;computer science;operating system;distributed computing;multimedia;computer security;computer network	HPC	-33.03590664096263	35.764040450846394	134031
92407d0679f0e4875ccb47f58843feaa1c9b9f31	a persistent distributed architecure supported by the mach operating system	operating system		mach;operating system	Francis Vaughan	1990			mach number;embedded system;real-time computing;operating system;computer science	Theory	-30.88116957292301	41.94769782143106	134458
002ccfde5919bc282b95b0861862279646680c62	@pt: unobtrusive parallel programming with java annotations				Mostafa Mehrabi;Nasser Giacaman;Oliver Sinnen	2019	Concurrency and Computation: Practice and Experience	10.1002/cpe.4831	parallel computing;computer science;annotation;java annotation;object-oriented programming	PL	-24.80899324175788	36.788510740894196	134470
81ef4316dd44211fe11d74aba32f879451b23f93	dart-fas: federated access service on database grid	distributed system;base donnee repartie;base donnee;systeme reparti;distributed database;service orientation;distributed transactions;distributed computing;database;base repartida dato;base dato;orientado servicio;grid;software architecture;sistema repartido;federated database;rejilla;base donnee federee;virtual organization;grille;calculo repartido;coordinacion;phase ii;base dato federada;oriente service;calcul reparti;architecture logiciel;coordination;service oriented	The emergence of a service-oriented view of computation and data resources on the grid raises the question as to how database resources can best be deployed or adapted for use and management in Grid. Several proposals have been made for the development of Grid-enabled database services. However, there are few service orchestration frameworks for constructing sophisticated higher-level services that allow database dynamic federation and distributed transaction to take place within a Database Virtual Organization. As the phase II of DartGrid we propose DART-FAS, a service orchestration focusing on the construction of dynamic federation and federated access service in Database Grid. This paper will discuss the architecture, core components and primary processes of DART-FAS.	computation;dart (programming language);distributed transaction;emergence;federated database system;orchestration (computing);service-orientation;service-oriented device architecture;virtual organization (grid computing)	Guozhou Zheng;Zhaohui Wu;Chang Huang	2004		10.1007/978-3-540-30207-0_2	software architecture;database transaction;distributed transaction;computer science;operating system;database;distributed computing;grid;world wide web;database schema;distributed database	DB	-28.489188579315382	44.024071513999345	134512
35ec49f928883ea6d489b84434af5c0f7f3ec012	building modular communication systems in ada: the simple_com approach	distributed application;lenguaje programacion;distributed system;communication system;architecture systeme;systeme reparti;programming language;ada;ingenieria logiciel;software engineering;sistema repartido;genie logiciel;langage programmation;arquitectura sistema;fiabilite logiciel;quality of service;fiabilidad logicial;ada language;system architecture;software reliability	This paper is devoted to study the use, in the Simple-Com system, of several mechanisms provided by the Ada programming language (type extension, dynamic dispatching, encapsulation, generics, etc.). The Simple-Com system is a toolbox for building protocols of different qualities of service (both unicast and multicast). It is flexible, extensible, portable, and provides clean and simple interfaces. Many of its features are possible thanks to the extensive use of those Ada mechanisms. The Simple-Com system is useful for building distributed applications (using the protocols already provided), or to design and test new protocols (either combining some of the pieces provided, or building new ones).		Jesús M. González-Barahona;Pedro de las Heras Quirós;José Centeno-González;Francisco J. Ballesteros	1998		10.1007/BFb0055008	embedded system;ada;quality of service;computer science;operating system;programming language;software quality;communications system;systems architecture	SE	-27.999795917672174	41.12502279637387	134552
11ce20e7268fec0168f4c429baa7a28c3054725e	a kind of communication simulation system for worldfip field intelligent control network	multi threading;communication system;principle programming language worldfip field intelligent control network communication simulation system data communication network scheduler intelligent nodes multithread method oop multilayered hmi visual hmi vc net;programming language;intelligent control intelligent networks control system synthesis communication system control communication industry electrical equipment industry industrial control production systems data communication job shop scheduling;telecommunication computing;object oriented programming;control network;intelligent control;data communication;good practice;design technique;design and implementation;community networks;industrial production;intelligent networks;system simulation;user interfaces;user interfaces intelligent control intelligent networks multi threading object oriented programming telecommunication computing	Simulation of communication system in control network plays important role in modern industrial production and can be used in various application. Based on development of WorldFIP field intelligent control network, a kind of communication simulation system was designed and implemented. Simulation principle and implementation methods for data communication in the network were presented. Design and implementation for simulation of network scheduler, intelligent nodes and WorldFIP network communication based on OOP and multi-thread methods were presented in detail. Visual and multi-layered HMI for the simulation system was designed. Techniques in OOP were fully used in design with VC.NET as principle programming language. Complete simulation of WorldFIP communication network and field intelligent nodes was implemented. Operational practice showed the simulation system was stable in operation, good in flexibility and portability, which showed good practicability.	algorithm;computer data storage;factory instrumentation protocol;human–computer interaction;information exchange;intelligent control;mathematical optimization;network scheduler;operating system;programming language;scheduling (computing);simulation;system simulation;telecommunications network;usability;user interface	Geng Liang;Guotian Yang	2009	2009 International Asia Conference on Informatics in Control, Automation and Robotics	10.1109/CAR.2009.87	industrial production;control network;intelligent network;real-time computing;simulation;intelligent computer network;multithreading;computer science;artificial intelligence;operating system;network simulation;distributed computing;object-oriented programming;user interface;communications system;intelligent control	Robotics	-32.53241726182833	39.26496374523386	134633
75830494aa1a4bb2b7619135166f71c010c02a5d	concurrent processes with synchronization: net and algebraic approach	algebraic approach;deadlock detection;concurrent process	The paper consists of two parts. The first one deals with the net formalism (OS-nets) to specify concurrent processes with synchronization. Some results of deadlock detection for OS-nets based on analysing the net structure are established.		Ludmila Cherkasova;Alexander S. Filurin	1989		10.1007/3-540-51237-3_6	discrete mathematics;real-time computing;computer science;deadlock;distributed computing;deadlock prevention algorithms	Logic	-27.543802399452083	33.28119403915204	134643
4bb2f470ec9d7fff726357e7f8c599168ff2eb8a	automated synchronization and boundary condition application for the cactus framework		"""The Einstein Toolkit (ETK) is an open-source software platform for computational simulations in relativistic astrophysics and gravitational physics. The Cactus Framework (Cactus) comprises the core component of the ETK and handles creation of distributed data structures, parallelism, I/O, checkpointing, etc. The current Cactus scheduling system relies on the manual synchronization of ghost zones for grid functions (i.e. distributed matrices). Unfortunately, deciding which subroutines should synchronize which grid functions is a non-trivial problem. Incorrect synchronization can result in over synchronization (a performance problem) or under synchronization (an error). This issue also creates a barrier for new users and collaborators. We are developing a new scheduling and synchronization method for Cactus to improve the accessibility and efficiency of the ETK. Synchronization and application of boundary conditions are now handled automatically by Cactus. The new approach requires each subroutine to have """"read"""" and """"write"""" declarations for individual grid functions. Before scheduled functions run, Cactus checks these declarations and performs any synchronization or boundary conditions as needed. This method removes the difficulty of deciding where synchronization should take place and removes unneeded synchronizations. The only knowledge required to provide these declarations is what grid functions a given subroutine uses and on which parts of the grid they are read or written. This new system is a first step in improving Cactus' scheduling methods to use more advanced and scalable techniques."""	accessibility;application checkpointing;cactus framework;computer simulation;data structure;input/output;open-source software;parallel computing;scalability;scheduling (computing);subroutine	Samuel Cupp;Steven R. Brandt	2018		10.1145/3219104.3229256	boundary value problem;distributed computing;grid;subroutine;scalability;scheduling (computing);software;synchronization;data structure	HPC	-19.505956276706957	40.12979532157141	134739
a72695a8612414d4cbfb59ed5a0678d357d9d7dd	service discovery supporting open scalability using fipa-compliant agent platfrom for ubiquitous networks	estensibilidad;red sin hilo;service discovery protocol;data sharing;multiagent system;shared memory;reseau sans fil;interoperabilite;interoperabilidad;memoria compartida;pervasive computing;wireless network;distributed computing;service web;intelligence artificielle;ad hoc network;compatibilidad;web service;red ad hoc;intergiciel publication souscription;informatica difusa;reseau ad hoc;intergicial editor suscriptor;informatique diffuse;compatibility;calculo repartido;artificial intelligence;middleware;compatibilite;extensibilite;scalability;inteligencia artificial;interoperability;service discovery;sistema multiagente;publish subscribe middleware;calcul reparti;memoire partagee;servicio web;systeme multiagent	Service discovery protocol is the main element that determines the efficiency in middleware platform of ubiquitous networks. Recently, a large number of middlewares supporting scalability which focus on the distributed computing and data sharing among tremendous peers has been proposed. However, due to the distributed nature of ad-hoc networks, peers may not be able to find other peers and corresponding resources persistently. Furthermore, current service discovery engines do not provide open scalability that can make them to interoperate with each other. In this paper, we propose a simple mechanism, which provides cross-platform interoperability through directory federation combined with DHT mechanism to support open scalability and lightweight service discovery in ad-hoc network based on FIPA compatibility agent framework.	scalability;service discovery	Kee-Hyun Choi;Ho-Jin Shin;Dong Ryeol Shin	2005		10.1007/11424857_11	computer science;operating system;database;distributed computing;service discovery;world wide web;computer security;ubiquitous computing	AI	-29.015667063476595	43.85157631761908	134880
9eac38431e09e4efe64ab9d337fff6aa37c4c244	timix: a distributed real-time kernel for multi-sensor robots	robot sensing systems;control systems;manipulators;kernel;interprocess communication;information science;computerised control;real time;distributed processing;distributed computing;real time processing;multisensor robot;distributed real time kernel;robots computerised control distributed processing operating systems computers real time systems;programming profession;robots;interprocess communication primitives distributed processing timix distributed real time kernel multisensor robot;interprocess communication primitives;kernel timing robot sensing systems real time systems manipulators programming profession control systems laboratories distributed computing information science;timix;operating systems computers;real time systems;timing	Timix is a distributed real-time kernel that is being developed to support multisensor robot systems. The overall structure of the kernel is described, including a hierarchy of interprocess communication primitives and a generic way to interact with external devices. A simple multisensor robot that is being implemented using Timix is also presented. Three salient aspects of Timix are as follows. First, it is possible to estimate the amount of time that a real-time process takes to execute since the execution times of system calls are bounded. Second, an hierarchy of communication methods, which differ in synchronization, time and space overheads, and bandwidth requirements, are provided to allow the programmer to choose the one most applicable to a particular application, depending on the real-time requirements. Finally, new devices, which ar directly controlled by application processes, can be integrated into the system without changing the kernel. >	kernel (operating system);real-time clock;robot	I. Lee;R. King	1988		10.1109/ROBOT.1988.12292	robot;embedded system;kernel;real-time computing;information science;computer science;control system;distributed computing;inter-process communication	Robotics	-31.960877407053207	38.16689553520772	135110
540b54f6acc667e28cb2ecb8e30f884101866c0b	sablevm: a research framework for the efficient execution of java bytecode	virtual machine;java bytecode;c programming language;data layout;research framework;open source	SableVM is an open-source virtual machine for Java intended as a research framework for efficient execution of Java bytecode. The framework is essentially composed of an extensible bytecode interpreter using state-of-the-art and innovative techniques. Written in the C programming language, and assuming minimal system dependencies, the interpreter emphasizes high-level techniques to support efficient execution.#R##N##R##N#In particular, we introduce a biderectional layout for object instances that groups reference fields sequentially to allow efficient garbage collection. We also introduce a sparse interface virtual table layout that reduces the cost of interface method calls to that of normal virtual calls. Finally, we present a technique to improve thin locks[13] by eliminating busy-wait in presence of contention.	java bytecode	Etienne M. Gagnon;Laurie J. Hendren	2001			parallel computing;java concurrency;computer science;operating system;strictfp;common intermediate language;real time java;programming language;java;interpreted language;java applet	EDA	-25.160134756512573	36.97504401717916	135208
c1f2abd912ca6733e0fff5f12f0ee273aa865806	an accelerated remote graphics architecture for pdas	personal digital assistant;user interface;handheld computer;hardware accelerator;web 3d;general solution;chromium;vrml;inherently 3d;usability;3d graphics;workstation cluster	A new category of devices, known as Personal Digital Assistant (PDA), has become increasingly widespread since the end of the nineties. A large number of software applications have been developed for PDAs, but high-quality 3D graphics still remain beyond the computational capability of these devices.This paper tackles this issue by proposing a generic solution for hardware-accelerated remote rendering on cluster. The rendering task is submitted to a PC/workstation cluster (each cluster machine is equipped by a graphics accelerator) by means of the Chromium architecture. Each machine renders a part of the image that is then reassembled and sent to the PDA via a software bridge. On the PDA side, the user can explore the scene using an ad-hoc navigation interface.The proposed solution allows to display extremely realistic and complex models in an interactive way. Moreover, our architecture does not depend on commercial solutions/products and can be easily modified in order to better fulfill requirements of specific applications.Computer GraphicsDistributed/network graphics Distributed SystemsDistributed applications	3d computer graphics;distributed shared memory;graphics processing unit;hardware acceleration;hoc (programming language);personal digital assistant;rendering (computer graphics);requirement;workstation	Fabrizio Lamberti;Claudio Zunino;Andrea Sanna;Antonino Fiume;Marco Maniezzo	2003		10.1145/636593.636602	embedded system;computer hardware;computer science;real-time computer graphics;graphics software;software rendering;3d computer graphics;computer graphics (images)	Graphics	-30.02330194203824	40.16136354894814	135363
1b82b1ec13a1a6d563e2ce8e574c6f96a6c572e9	class hierarchy specialization	weak pointers;resource management;garbage collection;finzlization	Class libraries are generally designed with an emphasis on versatility and extensibility. Applications that use a library typically exercise only part of the library's functionality. As a result, objects created by the application may contain unused members. We present an algorithm that specializes a class hierarchy with respect to its usage in a program P. That is, the algorithm analyzes the member access patterns for P's variables, and creates distinct classes for variables that access different members. Class hierarchy specialization reduces object size, and is hence primarily a space optimization. However, execution time may also be reduced through reduced object creation/destruction time, and caching/paging effects.	algorithm;cache (computing);class hierarchy;extensibility;library (computing);mathematical optimization;object lifetime;paging;partial template specialization;run time (program lifecycle phase)	Frank Tip;Peter F. Sweeney	1997		10.1145/263698.263748	real-time computing;computer science;resource management;database;distributed computing;garbage collection;programming language	PL	-19.81646702122408	35.96561240838678	135436
02d6deee534a9678b5f7ac8471d1af63f34ad3be	using parallel programming language for the performance analysis of concurrent systems	protocols;parallel programming performance analysis stochastic systems protocols specification languages clocks calculus telecommunications logic programming stochastic processes;clocks;parallel programming;parallel programming language;concurrent systems;logic programming;stochastic processes;specification languages;calculus;performance analysis;stochastic systems;telecommunications		concurrency (computer science);parallel programming model;profiling (computer programming);programming language	Vincenza Carchiolo;Maurizio Papale	1993		10.1109/SIMSYM.1993.639158	concurrent constraint logic programming;first-generation programming language;declarative programming;programming domain;reactive programming;computer science;theoretical computer science;extensible programming;functional logic programming;programming paradigm;procedural programming;symbolic programming;inductive programming;fifth-generation programming language;programming language theory;programming language;logic programming;second-generation programming language;comparison of multi-paradigm programming languages;algorithm;control flow analysis;concurrent object-oriented programming;parallel programming model	HPC	-26.345459872347135	33.416128030367815	135585
6f46c5b0208374cb69157376897c82b7520976f2	extending the operating system to support an object-oriented environment	distributed system;information technology;object oriented;distributed environment;operating system;application development;virtual memory	Comandos is a project within the European Strategic Programme for Research on Information Technology - ESPRIT and it stems from the identified need of providing simpler and more integrated environments for application development in large distributed systems. The fundamental goal of the project is the definition of an integrated platform providing support for distributed and concurrent processing in a LAN environment, extensible and distributed data management and tools for monitoring and administrating the distributed environment. An object oriented approach was used as the ground level for the integration of the multidisciplinary concepts addressed in the project. This paper starts by describing the basic model and architecture of Comandos, which results from a common effort by all the partners in the project. We focus then on the description of a first prototype of the system, which implements a subset of the architecture and is currently running on a set of personal computers and workstations at INESC. The prototype is a testbed for the architecture, providing dynamic linking, access to persistent objects and transparent distribution. Special attention is given to the performance aspects of object invocation in virtual memory.	computer multitasking;distributed computing;dynamic linker;height above ground level;operating system;personal computer;prototype;testbed;workstation	José Alves Marques;Paulo Guedes	1989		10.1145/74877.74890	real-time computing;simulation;computer science;virtual memory;distributed computing;distributed object;object-oriented programming;rapid application development;information technology;distributed computing environment	DB	-30.67584375363594	42.5153285409195	135660
38ab3489f432513c7d534a8b976d3b659a156c86	priority inheritance revisited. towards the conformance of real-time protocols	systeme temps reel;herencia;sistema operativo;validation of protocol implementations;operating time;validacion;defecto;protocol verification;processor scheduling;heritage;inversion;real time;priority inheritance protocol;problema inverso;duree fonctionnement;duracion funcionamiento;inverse problem;operating system;real time scheduling;temps reel;defect;defaut;tiempo real;real time protocol;systeme exploitation;validation;real time system;sistema tiempo real;ordonnancement processeur;inheritance;probleme inverse;protocol errors	The priority inversion problem was discovered in the eighties. The decisive ideas to cope with this problem have been published in the nineties. In the meantime the suppliers of real-time operating systems and run-time systems have occupied this topic by providing certain protocols in order to give the application programmer comfortable system calls to avoid priority inversion. At a closer look there are considerable errors and defects in the protocol implementations but also in the approach to derive these protocols. So, on the one hand this article unfolds an undetected error of the priority inheritance protocol. On the other hand it shows by a sequence of test suites that certain operating systems and runtime systems have different kinds of defects in implementing the protocol.	conformance testing;priority inheritance;real-time transcription	Dieter Zöbel;David Polock	2005	Technique et Science Informatiques	10.3166/tsi.24.939-961	inversion;priority inheritance;real-time computing;real-time operating system;computer science;inverse problem;operating system;distributed computing;priority ceiling protocol;algorithm	AI	-24.20857276652451	33.21956632079794	135760
59eb1c7729ee7dd12bb6654f26d974f3a713dd50	μitron for small-scale embedded systems	microcontrollers;design principle;formal specification;embedded control system;standards;real time;low cost real time lan standard small scale embedded systems spl mu itron standard real time kernel specification microcontrollers design principles spl mu itron bus;mcus;embedded system;real time kernel;lan interconnection;embedded systems;formal specification microcontrollers real time systems lan interconnection standards;lans;tron project;embedded system control systems microcontrollers application software joining processes real time systems operating systems;real time systems	The μITRON standard real-time kernel specification for small-scale embedded control systems has been implemented in a large number of microcontrollers and applications. We describe the design principles of the specification and the current state of its implementations and applications. We also introduce the μITRON bus, a low-cost real-time LAN standard for connecting small-scale embedded systems.	control system;embedded system;microcontroller;real-time clock	Hiroaki Takada;Ken Sakamura	1995	IEEE Micro	10.1109/40.476258	microcontroller;embedded system;real-time computing;computer science;operating system;formal specification	Embedded	-33.020551729692095	38.95849083762182	135988
a84a3a99a70170f6cdbb490a5649996241c42077	jamuth: an ip processor core for embedded java real-time systems	virtual machine;real time;multithreaded processor;embedded real time systems;real time embedded system;java execution environment;embedded system;garbage collection;chip;operating system;execution environment;real time scheduling;software development;embedded operating system;java processor;non real time;embedded system on a chip implementation;real time systems	This paper proposes a Java multithreaded processor core for embedded real-time systems, jamuth. The processor core is an enhancement of the earlier developed multithreaded Java processor named Komodo. It features a real-time capable incremental garbage collection, integrated real-time scheduling schemes and full compatibility to the Java CDC standard. Hence, it is suitable for embedded hard, soft, and non real-time systems. Due to its design as an IP core for Altera's System-on-Programmable-Chip (SoPC) environment, it can easily be combined with other (peripheral) components to a whole system on a single chip. Additionally, the usage of Java decreases the effort of software development and maintenance in a significant way. In this paper, we evaluate the performance and the utilization as well as the real-time capabilities of the jamuth IP core.		Sascha Uhrig;Jörg Wiese	2007		10.1145/1288940.1288974	chip;embedded system;embedded operating system;real-time computing;java concurrency;computer science;virtual machine;software development;operating system;strictfp;embedded java;real time java;garbage collection;java	Embedded	-22.67971221176346	37.57849598439939	136335
823bf87acedd8f4f4bbe568f78bac1d5e4e35c9d	cloud computing for small research groups in computational science and engineering: current status and outlook	calcul scientifique;software;analisis numerico;ordered group;programmation;logiciel;complexite calcul;68m 14;hombre;analyse numerique;programacion;algorithme;groupe ordonne;algorithm;business model;68 02;complejidad computacion;computacion cientifica;computational science and engineering;numerical analysis;infrastructure as a service;computational complexity;platform as a service;human resource;human;68u01;logicial;software as a service;programming support;scientific computation;58a25;programming;68m14;cloud computing;homme;algoritmo	Cloud computing could offer good business models for small computational science and engineering (CSE) research groups because these groups often do not have enough human resources and knowledge to manage the complexity of computational and data infrastructure for their research, while cloud computing aims to eliminate that complexity from the user. In this paper, we have analyzed current status of supporting tools for small CSE groups to utilize cloud computing. Although cloud computing is perceived as an interesting model, we have identified several issues that prevent a wide adoption of cloud computing from small CSE research groups. We also present recommendations for addressing these issues in order to attract small CSE groups to utilize cloud computing.	cloud computing;computation;computational engineering;computational science;data infrastructure;data-intensive computing;ecosystem;experiment;job stream;microsoft outlook for mac;platform as a service;software as a service;web application	Hong Linh Truong;Schahram Dustdar	2010	Computing	10.1007/s00607-010-0120-1	simulation;cloud computing;human resources;computer science;theoretical computer science;operating system;mathematics;utility computing;algorithm	HPC	-26.651973577868436	42.30696144939339	136854
7b57f579c4997c480f7dfe08de099ad8ce96c262	functional multiprocessing in an experimental digital switching office	control systems;telephony;computer architecture;telecommunication switching;process control;computer architecture communication system control control systems telephony hardware process control switches communication switching telecommunication switching switching systems;switching systems;communication switching;communication system control;switches;hardware	Controlling a telephone switching system is a difficult software problem involving many concurrent processes and complex patterns of inter-process communication. This paper describes the functional multiprocessing architecture used in the control of an Experimental Digital Switching office. The software system is partitioned into two subsystems: Peripheral Control and Call Processing. The Peripheral Control Subsystem maintains the status of the switching resources, passes customer inputs to the Call Processing Subsystem, and carries out all the hardware control functions. The Call Processing Subsystem performs all the decision making functions to provide telephone features. By choosing a proper interface between them, the Peripheral Control Subsystem hides the hardware details of the peripherals to provide a high-level abstract switching machine. By isolating feature processing from hardware control, new services and peripherals can be introduced to the system easily. The authors' experience with this system is presented.		R. C. Cheung;W. A. Montgcmery	1979		10.1109/CMPSAC.1979.762469	control engineering;embedded system;real-time computing;lan switching;network switch;computer science;cut-through switching;operating system;process control;5ess switch;telephony;computer security;circuit switching	EDA	-32.26351459760323	38.5918444221843	136856
0af2033353d9aa3260de7dfcbc30ed6397a3b57d	postgres revisited: a business application perspective	tuple space;transputer;speculative processing;parallel lisp	This paper describes changes to the POSTGRES Rule Manager that are required in order to guarantee sequential evaluation of POSTGRES rules based on assigned priority values. The proposed rule management algorithm relies on the identification of elementary rules and elementary user commands, and requires that all elementary rules be managed by tuple-level processing rather than by query-rewrite processing.	algorithm;postgresql;rewrite (programming)	Ronald C. Linton	1992		10.1145/131214.131284	computer architecture;parallel computing;computer science;tuple space;lisp;programming language	DB	-24.814570855846647	33.64146565903718	136938
42ac68aeb41a8d4a08bf6cc5187583e08d61121a	a pipeline virtual service pre-scheduling pattern and its application in astronomy data processing	tratamiento datos;modelizacion;optimal solution;groupware;optimisation;solution optimale;haute performance;formal specification;optimizacion;execution time;astronomia;astronomie;metaservice;distributed computing;data processing;traitement donnee;specification formelle;grid;modelisation;especificacion formal;software architecture;pre scheduling;rejilla;scheduling;solucion optima;alto rendimiento;grille;calculo repartido;workflow;temps execution;procesador oleoducto;optimization;astronomy;processeur pipeline;tiempo ejecucion;collecticiel;modeling;grid computing;high performance;calcul reparti;ordonnancement;pipeline;architecture logiciel;pipeline processor;reglamento	Based on Open Grid Services Architecture (OGSA), the concept and the formal model of Pipeline Virtual Service (PVS) are proposed and presented in this paper. PVS is used to model a special type of grid workflow composed of a group of services that can be executed as a pipeline. A PVS Pre-Scheduling Pattern is described in detail, which can overlap the execution time of a PVS with the time of generating and optimizing the scheduling solution pool. The Pattern includes two independent components, the solution generating component (GenFunc) and the solution execution component (ExeFunc). GenFunc can take advantage of the powerful computing potential of grid environment to find the optimal or a near optimal scheduling solution, while ExeFunc can select a suitable scheduling solution and put a PVS into running as soon as possible. Two corresponding algorithms, SODGen and SODExe, are also developed. The analytic and simulation results show that the PVS Pre-Scheduling Pattern can not only balance the scheduling cost and scheduling precision, save the scheduling time greatly, but also reduce the execution time through selecting the optimized solution. A prototype is designed and implemented for a large scale astronomy data processing center. The early engineering evaluation experiments show that the PVS Pre-Scheduling Pattern is feasible, efficient, and flexible in real astronomy data processing.	scheduling (computing)	Man Wang;Zhihui Du;Zhili Cheng;Suihui Zhu	2007	Simulation	10.1177/0037549707079234	workflow;software architecture;parallel computing;real-time computing;simulation;systems modeling;data processing;computer science;operating system;formal specification;programming language;grid;scheduling;pipeline;grid computing	HPC	-27.625653038626073	42.787757896801	137246
d68cb1d6fcdb6180270d43634adf585d91d04dae	on barriers and the gap between active and passive replication (full version)		Active replication is commonly built on top of the atomic broadcast primitive. Passive replication, which has been recently used in the popular ZooKeeper coordination system, can be naturally built on top of the primaryorder atomic broadcast primitive. Passive replication differs from active replication in that it requires processes to cross a barrier before they become primaries and start broadcasting messages. In this paper, we propose a barrier function τ that explains and encapsulates the differences between existing primary-order atomic broadcast algorithms, namely semi-passive replication and Zookeeper atomic broadcast (Zab), as well as the differences between Paxos and Zab. We also show that implementing primary-order atomic broadcast on top of a generic consensus primitive and τ inherently results in higher time complexity than atomic broadcast, as witnessed by existing algorithms. We overcome this problem by presenting an alternative, primary-order atomic broadcast implementation that builds on top of a generic consensus primitive and uses consensus itself to form a barrier. This algorithm is modular and matches the time complexity of existing τ -based algorithms.	algorithm;atomic broadcast;barrier function;consensus (computer science);semiconductor industry;time complexity	Flavio Paiva Junqueira;Marco Serafini	2013		10.1007/978-3-642-41527-2_21	real-time computing;atomic broadcast;computer science;theoretical computer science;distributed computing	OS	-23.198964967599238	45.48750250095467	137257
2dae436baa209333a72887f0095f6d3fd1d4be8e	dynamic transparent general purpose process migration for linux		Process migration refers to the act of transferring a process in the middle of its execution from one machine to another in a network. In this paper, we proposed a process migration framework for Linux OS. It is a multilayer architecture to confine every functionality independent section of the system in separate layer. This architecture is capable of supporting diverse applications due to generic user space interface and dynamic structure that can be modified according to demands.	linux;operating system;process migration;user space	Amirreza Zarrabi	2012	CoRR	10.5121/ijgca.2012.3402	embedded system;parallel computing;real-time computing;computer science;operating system;distributed computing	OS	-31.286238410607126	43.738829293718645	137405
466772ec7336826029c21a2663f920c90c614ee4	a high performance configurable storage manager	storage management;client server systems;database systems memory management hardware object oriented databases relational databases multimedia systems file servers distributed computing costs protection;relational databases storage management client server systems transaction processing object oriented databases distributed databases;object oriented;distributed databases;relational databases;object oriented databases;transaction processing;high performance;shared memory high performance configurable database storage manager bess bell laboratories storage system object oriented database management systems relational database management systems home grown database management systems multi client multi server architecture distributed transaction management facilities extensible support persistence fast object reference technique database reorganization operation modes copy on access	This paper presents the architecture of BeSS ~ a high performance configurable database storage manager providing key facilities for the fast development of object-oriented, relational, or home-grown database management systems. BeSS is based on a multi-client multi-server architecture offering distributed transaction management facilities and extensible support for persistence. W e present some novel aspects of the BeSS architecture, including a fast object reference technique that allows re-organization of databases without affecting existing references and two operation modes an application running on a client or server machine can use to interact with the storage system copy on access and shared memory.	computer data storage;database storage structures;distributed transaction;persistence (computer science);server (computing);shared memory	Alexandros Biliris;Euthimios Panagos	1995		10.1109/ICDE.1995.380412	database theory;relational database management system;database transaction;transaction processing;relational database;computer science;database model;transaction log;database;distributed computing;object-oriented programming;world wide web;distributed database;database testing;database design	DB	-27.14929271179721	45.74074542190609	137610
00105669dd757e877c4f4bddb5c63417902762d8	a design approach to automatically generate on-chip monitors during high-level synthesis of hardware accelerator	hardware monitoring;high level synthesis;security	Embedded systems often implement safety critical applications making security a more and more important aspect in their design. Control-Flow Integrity (CFI) attacks are used to modify program behavior and can lead to learn valuable information directly or indirectly by perturbing a system and creating failures. Although CFI attacks are well-known in computer systems, they have been recently shown to be practical and feasible on embedded systems as well. In this context, CFI checks are mainly used to detect unintended software behaviors while very few works address non programmable hardware component monitoring. In this paper, we present a hardware-assisted paradigm to enhance embedded system security by detecting and preventing unintended hardware behavior. We propose a design approach that designs on-chip monitors (OCM) during High-Level Synthesis (HLS) of hardware accelerators (HWacc). Synthesis of OCM is introduced as a set of steps realized concurrently to the HLS flow of HWacc. Automatically generated OCM checks at runtime both the input/output timing behavior and the control flow of the monitored HWacc. Experimental results show the interest of the proposed approach: the error coverage on the control flow ranges from 99.75% to 100% while in average the OCM area overhead is less than 10%, the clock period overhead is at worst less than 5% and impact on the synthesis time is negligible.	clock rate;control flow;control-flow integrity;embedded system;hardware acceleration;high- and low-level;high-level synthesis;input/output;overhead (computing);programming paradigm;run time (program lifecycle phase);sensor	Mohamed Ben Hammouda;Philippe Coussy;Loïc Lagadec	2014		10.1145/2591513.2591521	embedded system;electronic engineering;real-time computing;computer science;engineering;information security;operating system;high-level synthesis;computer security	EDA	-23.13211106896154	37.964164016223584	137624
5bb101c5fb3174c6ac83d30c558669c718e5af75	a hardware approach to detect, expose and tolerate high level data races	software;debugging;hardware software concurrent computing debugging programming proposals heuristic algorithms;concurrent computing;testing;bloom filters;concurrency;high level data races software deployment software debugging software testing independent atomic blocks concurrency errors concurrency bugs hldr error prone concurrent programs;heuristic algorithms;data races;proposals;programming;bloom filters concurrency testing debugging data races;hardware;program testing concurrency computers program debugging	"""Concurrent programs are more complex and error prone than their sequential peers, and are much harder to debug as well. High level data races (HLDR) are one of the concurrency bugs most difficult to debug. They are a class of concurrency errors that are not commonly addressed by the testing and debugging techniques and tools. HLDR result from the misdefinition of the scope of an atomic block, which should be unique but was wrongly split into two or more independent atomic blocks. Interleavings involving these misdefined atomic blocks may violate the program correctness invariants and cause the concurrent program to fail. In this work we propose a hardware module to detect, expose and tolerate HLDR in concurrent programs, with applications in both the software testing and debugging and the software deployment phases. In the detecting mode, our proposal detects HLDR with few false positives and without the overhead and intrusion of other dynamic software approaches. In the exposing mode, it """"stimulates"""" the program to expose existing latent HLDR and trigger hidden HLDRs. Finally, in the tolerating mode, it may act as a software healing technique by inhibiting certain buggy interleavings. The results shows a reasonable performance overhead and few false positives in all modes."""	best-effort delivery;code;cognitive dimensions of notations;concurrency (computer science);concurrent computing;correctness (computer science);debugging;overhead (computing);programmer;race condition;sensor;software bug;software deployment;software testing;transactional memory	Lois Orosa;João Lourenço	2016	2016 24th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP)	10.1109/PDP.2016.57	programming;parallel computing;real-time computing;concurrent computing;concurrency;computer science;bloom filter;operating system;software construction;distributed computing;software testing;algorithmic program debugging;programming language;debugging;concurrent object-oriented programming	SE	-22.34536454646932	39.78956191766146	137652
049f22c8bfacc0dde51c2ca82e64b5e555a79e0d	balancing the load	software verification;formal verification;lessons learned;pervasive formal verification;systems verification	We have developed a stack of semantics for a high-level C-like language and low-level assembly code, which has been carefully crafted to support the pervasive verification of system software. It can handle mixed-language implementations and concurrently operating devices, and permits the transferral of properties to the target architecture while obeying its resource restrictions. We demonstrate the applicability of our framework by proving the correct virtualization of user memory in our microkernel, which implements demand paging. This verification target is of particular interest because it has a relatively simple top-level specification and it exercises all parts of our semantics stack. At the bottom level a disk driver written in assembly implements page transfers via a swap disk. A page-fault handler written in C uses the driver to implement the paging algorithm. It guarantees that a step of the currently executing user can be simulated at the architecture level. Besides the mere theoretical and technical difficulties the project also bore the social challenge to manage the large verification effort, spread over many sites and people, concurrently contributing to and maintaining a common theory corpus. We share our experiences and elaborate on lessons learned.	algorithm;assembly language;high- and low-level;microkernel;obedience (human behavior);page fault;paging;pervasive informatics	Eyad Alkassar;Mark A. Hillebrand;Dirk Leinenbach;Norbert Schirmer;Artem Starostin;Alexandra Tsyban	2009	Journal of Automated Reasoning	10.1007/s10817-009-9123-z	real-time computing;formal verification;software verification;computer science;artificial intelligence;database;distributed computing;high-level verification;runtime verification;programming language;intelligent verification;functional verification	Arch	-21.768900715726794	32.79994072018547	137816
ab0cc6bfc0a28b794755cbc172784e137b0913e2	an environment for prototyping distributed applications	distributed application;distributed system;systeme reparti;interconnection;programming environment;program design;sistema informatico;distributed processing;conception programme;computer system;prototipo;medio ambiente programacion;sistema repartido;interconnexion;systeme informatique;traitement reparti;prototype;concepcion programa;interconeccion;environnement programmation;tratamiento repartido	Designing a distributed application is an extremely complex task. Proper facilities for prototyping distributed applications can be useful in evaluating a design, and also in understanding the effect of different parameters on the performance of an application. We describe a language for prototyping distributed applications, that supports different communication primitives with specified delay, and provides primitives to aid debugging and evaluation. Our environment for executing distributed programs supports heterogeneous computation in which processes can execute on different hardware. Different source languages can be used for coding different modules of the processes. The system has a centralized control and monitoring facility which is based on the Suntools window system.		James M. Purtilo;Pankaj Jalote	1991	Comput. Lang.	10.1016/0096-0551(91)90007-V	embedded system;real-time computing;simulation;computer science;interconnection;program design language;prototype	HPC	-27.0386301829109	40.748547089630854	138038
70e75e1c492bda4280892f1b7494184e871bbe21	static analysis of real-time component-based systems configurations	systeme temps reel;distributed system;sistema experto;systeme reparti;formal specification;normal distribution;component based systems;real time;reseau ordinateur;semantics;intelligence artificielle;semantica;semantique;specification language;computer network;specification formelle;especificacion formal;sistema repartido;complex system;analyse performance;performance analysis;red ordenador;artificial intelligence;real time system;lenguaje especificacion;sistema tiempo real;inteligencia artificial;systeme expert;static analysis;langage specification;analisis eficacia;expert system	"""Nowadays, more and more often, complex systems are built by assembling together diierent system components. This technology also aaects the construction of heterogeneous and/or hybrid systems where components can represent hardware sensors, software controllers, etc. Moreover the resulting system is normally distributed. These systems have often real-time constraints/requirements and each component is characterized by its own speed determined by its local clock. Conng-uring a system out of such components means to be able to determine a given global clock of the system deened in terms of the various local clocks. In this paper we present a framework in which it is possible to specify and statically analyze the architecture of a system as a network of (parallel) components, each one with its own local clock. Then con-guring the system means to formally deene how to get the global clock out of the local clocks. This clock connguration step is \optimal"""" that is, it is the best way to relate the local clocks so that the maximum number of synchronizations in the system can happen. The ability of modeling the clock connguration step allows us, besides the usual behavioral and timing analysis, to statically analyze the system with respect to diierent conngurations. For example, we can verify if, and how changing the local speed of a component can aaect the global performance of the system."""	complex systems;hybrid system;naruto shippuden: clash of ninja revolution 3;real-time clock;real-time transcription;requirement;sensor;static program analysis;static timing analysis	Candida Attanasio;Flavio Corradini;Paola Inverardi	1999		10.1007/3-540-48919-3_23	normal distribution;embedded system;simulation;specification language;computer science;artificial intelligence;formal specification;semantics;programming language;expert system;static analysis	Embedded	-28.68049829391254	36.17524657583961	138042
23018628c5e844bd2cf92a5af6ef985103804f52	grand challenge: the techniball system	real time event processing;event processing	In this work we present the solution to the DEBS'2013 Grand Challenge, as crafted by the joint effort of teams from the Technion and TU Dortmund. The paper describes the architecture, details the queries, shows throughput and latency evaluation, and offers our observations regarding the appropriate way to trade-off high-level processing with time constraints.	high- and low-level;throughput	Avigdor Gal;Sarah Keren;Mor Sondak;Matthias Weidlich;Hendrik Blom;Christian Bockermann	2013		10.1145/2488222.2488282	real-time computing;simulation;computer science;data science;complex event processing;database	AI	-28.28525534174187	37.61910148300724	138061
ab33f2e9e8cf0202ca68b004a31c378b8ddb144a	permit based locking		"""The Permit based Locking design pattern provides fast acquisition and release of locks without network communication even in distributed systems build around a central lock server. Instead of plain locks, the server manages """"permits to lock"""", and passes them to those clients which probably need the lock next. If a client hosts a permit, the associated lock can be acquired immediately without server interaction. If a permit asked for is not present at the server but at some other client, it can be revoked."""	client (computing);distributed computing;lock (computer science);server (computing);software design pattern	Dietmar Schütz	2001			systems engineering;lock (computer science);real-time computing;computer science	DB	-31.758444381086246	40.97422218180184	138069
d52e823b698ad6110545b3f0c10dcfa6fc6fb1e6	hydra: efficient detection of multiple concurrency bugs on fused cpu-gpu architecture	debugging;concurrent computing;history;gpu debugging concurrency bug;gpu;program debugging graphics processing units;concurrency bug;graphics processing units computer bugs concurrent computing instruction sets synchronization history image color analysis;image color analysis;synchronization;graphics processing units;computer bugs;helgrind hydra multiple concurrency bugs fused cpu gpu architecture data race atomicity violation order violation software based approach massive parallelism bug detection on chip interconnect bloom filter critical path processor component cache heavyweight software bug detector;instruction sets	Detecting concurrency bugs, such as data race, atomicity violation and order violation, is a cumbersome task for programmers. This situation is further being exacerbated due to the increasing number of cores in a single machine and the prevalence of threaded programming models. Unfortunately, many existing software-based approaches usually incur high runtime overhead or accuracy loss, while most hardware-based proposals usually focus on a specific type of bugs and thus are inflexible to detect a variety of concurrency bugs. In this paper, we propose Hydra, an approach that leverages massive parallelism and programmability of fused GPU architecture to simultaneously detect multiple types of concurrency bugs, including data race, atomicity violation and order violation. Hydra instruments and collects program behavior on CPU and transfers the traces to GPU for bug detection through on-chip interconnect. Furthermore, to achieve high speed, Hydra exploits bloom filter to filter out unnecessary detection traces. Hydra incurs small hardware complexity and requires no changes to internal critical-path processor components such as cache and its coherence protocol, and is with about 1.1% hardware overhead under a 32-core configuration. Experimental results show that Hydra only introduces about 0.35% overhead on average for detecting one type of bugs and 0.92% overhead for simultaneously detecting multiple bugs, yet with the similar detectability of a heavyweight software bug detector (e.g., Helgrind).	algorithm;atomicity (database systems);bloom filter;cpu cache;cache coherence;central processing unit;computation;concurrency (computer science);graphics processing unit;hydra (chess);hydra (operating system);overhead (computing);parallel computing;programmer;race condition;sensor;software bug;tracing (software);vii	Zhuofang Dai;Haojun Wang;Weihua Zhang;Haibo Chen;Binyu Zang	2014	2014 43rd International Conference on Parallel Processing	10.1109/ICPP.2014.42	synchronization;parallel computing;real-time computing;software bug;concurrent computing;computer hardware;computer science;operating system;instruction set;programming language;debugging	Arch	-21.090216222933286	39.6271346176237	138104
501d4ee9b55279463ba28a23f0948f6f5aea6f43	hgum: messaging framework for hardware accelerators (abstact only)	hardware accelerator;hgum;messaging framework	Software messaging frameworks help avoid errors and reduce engineering effort in building distributed systems by (i) providing an interface definition language (IDL) to precisely specify the structure of the message (the message schema) and (ii) automatically generating the serialization and deserialization functions that transform user data structures into binary data for sending across the network and vice versa. Similarly, a hardware-accelerated system that consists of host software and multiple FPGAs, could also benefit from a messaging framework to handle messages both between software and FPGA and also between different FPGAs. The key challenge for a hardware messaging framework is that it must be able to support large messages with complex schema while meeting critical constraints such as clock frequency, area, and throughput. We present HGum, a messaging framework for hardware accelerators that meets all the above requirements. HGum is able to generate high-performance and low-cost hardware logic by employing a novel design that algorithmically parses the message schema to perform serialization and deserialization. Our evaluation of HGum shows that it not only significantly reduces engineering effort but also generates hardware with comparable quality to manual implementation.	algorithm;binary data;clock rate;data structure;distributed computing;electronic hardware;field-programmable gate array;hardware acceleration;interface description language;requirement;serialization;throughput	Sizhuo Zhang;Hari Angepat;Derek Chiou	2016		10.1145/2847263.2847289	embedded system;messaging pattern;parallel computing;real-time computing;hardware acceleration;computer science;operating system;database	Arch	-29.735621477464804	36.18447078114362	138345
22b6b51731b073ead00be7e752f4dd2aa1b13975	slisp: a flexible software toolkit for hybrid, embedded and distributed applications	exploratory programming;hybrid programming;lisp;c;xlisp;world wide web;scripting languages	We describe Slisp (pronounced ‘Ess-Lisp’), a hybrid Lisp–C programming toolkit for the development of scriptable and distributed applications. Computationally expensive operations implemented as separate C-coded modules are selectively compiled into a small Xlisp interpreter, then called as Lisp functions in a Lisp-coded program. The resulting hybrid program may run in several modes: as a stand-alone executable, embedded in a different C program, as a networked server accessed from another Slisp client, or as a networked server accessed from a C-coded client. Five years of experience with Slisp, as well experience with other scripting languages such as Tcl and Perl, are summarized. These experiences suggest that Slisp will be most useful for mid-sized applications in which the kinds of scripting and embeddability features provided by Tcl and Perl can be extended in an efficient manner to larger applications, while maintaining a well-defined standard (Common Lisp) for these extensions. In addition, the generality of Lisp makes Lisp a good candidate for an application-level communication language in distributed environments.	common lisp;compiler;distributed computing;embedded system;executable;perl;scripting language;server (computing);tcl	James F. Brinkley;Jeffrey S. Prothero	1997	Softw., Pract. Exper.	10.1002/(SICI)1097-024X(199701)27:1%3C33::AID-SPE72%3E3.0.CO;2-P	read–eval–print loop;interpreter;computer science;operating system;server-side scripting;lisp;database;scripting language;*lisp;programming language;preprocessor	PL	-31.58692355465229	40.58840099830984	138491
5ea988d4982362c0694271fda6dba763c1d6ae3b	practical software reuse for ibm system z i/o subsystems	molecular computation;diseno circuito;difference operator;circuit design;calculo molecular;operating system;design and implementation;conception circuit;software reuse;device driver;calcul moleculaire	The design and implementation of the z/VMt SCSI (Small Computer System Interface) I/O subsystem is described. z/VM is an operating system that provides multiple virtual IBM System ze machines on a single IBM System z computer. The approach adopted herein allows the reuse of entire device drivers from AIX 5Le, a completely different operating system, essentially unchanged. AIX 5L is the IBM UNIXt operating system for the IBM System pe platform. The design, and much of the implemented code that allows the incorporation of such ‘‘foreign’’ device drivers, is independent of both z/VM and AIX 5L and could potentially be used in other operating system environments.	aix;c preprocessor;central processing unit;code reuse;cryptographic service provider;device driver;executable;ibm system z;input/output;linc;linux;operating system;overhead (computing);scsi;software release life cycle;software reliability testing;source lines of code;system testing;unit testing;z/vm	Alan M. Webb;Raymond Mansell;Joshua W. Knight;Steven J. Greenspan;David Emmes	2007	IBM Journal of Research and Development	10.1147/rd.511.0229	embedded system;real-time computing;memory management;computer science;operating system;cics;pr/sm;circuit design;word;ibm floating point architecture;ibm power microprocessors;access method	OS	-26.473422376486976	38.45803099073593	138835
81142dcc135122f4fe541b6a1595edcaad643b56	denotational data flow analysis for parallel implementation of imperative programs	formal specification;programming language;program counter;program transformation;functional equivalence;denotational semantic;data flow graph;computer architecture;side effect;partial evaluation;control flow;central control unit;parallel computer;data flow analysis;parallel implementation;model of computation;point of view;data flow	Syntax P ::= K K ::= begin D; S end D ::= D,; D, 1 var I 1 const I= N 1 proc I (II,.., I,) = S S::=S,;S,IreadIIwriteE]I:=E 1 call I (El,.., E,) I if B then S, else S, I while B do S I K E::=E,+E,(E,-E,(E,*E,~E,/E,~I~N B ::= E, =E,lE,fE,lE,<E,IE,>E,tE,IE,IE,2E, I Semantic Doma*& T : T = {true, false, w} Y : N = (0, 1: 2,.., w} Q : L = {l* 2, 3,.., w} q5:@=N a:C=L+N c *==~xxxx .n:n=L*44 S:A=L+N+II ?J:T=I-A Semantic Equations P: Program + File + File Program Block Declaration Statement Expression Boolean-expression Identifier Truth value Natural number Location File Store Configuration Procedure Denotable-value Environment P CKl = X4.(K EKl (X1.w) <Xa.w, 9, nil>)13 K: Block -+ Environment + Configuration -t Configuration K E begin D; S end] = Xu.X(.let <u’, CT’>= D KD-j’j v ((11) in S E Sl ZI’ <o’, (12, <13> D: Declaration -+ Environment + Store --+ Environment X Store D ED,; D2n = Xu.Xa.let <u’, a’>= D E D,7) u 0 in D E Den u’ O’ D E const I= Nj = Xu.Xa.<[ItinA Nju, cr> D a var 11 = Xu.Xa.let cr=new-loco in < [IcinA o]v, [a+-l]a> D E proc I (I, ,.., IJ= Sn = XU.XCVC [ItinA X(o, ,.., cr,).(S 1II Sn(]Irca, ,.., I,+o&))]u, 0 S: Statement + Environment + Configuration -+ Configuration s 6 s,; s,n = hp E s,n u) o (S E s,n v) S E I:= El = Xu.X&< [(U E 11 1 L)+E ml v (W)](W), ~12, {13> S E read 11~ Xu.XW [(u E I] I L)+hd(U)](Cll), tl(f12), (131 S E write En = Xu.X~.<<Jl, t32, append(<l3, EE En V (tll))> S E if B then S, else Sex 3 Xu.X<.(B KBl v (CJl) -s ll3,nve,s u3,llvr) S [c while B do Sn = fix(Xf.Xv.X&B [rB7] V ((11) f(S [c S7] V (5)) c) S E call I (El,.., E,)] m Xu.Xc.let CY,= new-loc(),.., q,= new-loco in ((v E 11 I II)(o+.., an)) <[y-E EElI v (Cl%, antE m,n v (W(W), ~1% ~13> S E Kn = Xu.XF.KE Kn V c E: Expression + Environment -t Store ---, Natural number E EE,opE,+Xv.Xa.E ~E&vopE [I:E&o E E 17) = h.h.U (V E 111 L) E KI] = hh.(V KInIN) E EN] = h.Xu.N B: Boolean-expression -+ Environment Store Truth B EE, rel-op Eel = XV.XU.(E EE,n v u rel-op E [IIE,] v u + true, false) Figure 3.1 Denotational Semantics of a Simple Algol-like Language	binary prefix;boolean expression;const (computer programming);data-flow analysis;dataflow;denotational semantics;emoticon;identifier;imperative programming;loco linux	Shan-Jon Chao;Barrett R. Bryant	1988		10.1145/322609.322612	parallel computing;computer science;theoretical computer science;data-flow analysis;programming language	Web+IR	-27.54041983979102	36.37831526424432	138898
f010f24aa7a66d7e6c15de0dd71e91a882979d4c	object-oriented database support for software environments	data type;multi user;object oriented;object oriented approach;object oriented database;requirement specification	Cactis is an object-oriented, multi-user DBMS developed at the University of Colorado. The implementation is self-adaptive and concurrent, and runs in the Unix/C Sun workstation environment. A central, unique focus of Cactis is the support of functionally-defined data in a manner which provides good performance. Cactis is intended for use in applications which are conducive to an object-oriented approach and involve derived data. Such applications include software environments. Cactis supports the construction of objects and type/subtype hierarchies, which are useful for managing the complex and highly-interrelated data found in software environments. Such data types include programs, requirement specifications, milestone reports, configurations, documentation, and many others. Cactis uses techniques based on attributed graphs to ensure that functionally-defined attributes of objects, such as compilation dependencies, cost calculations, and milestone dependencies can be maintained efficiently. Since it is necessary to dynamically add new tools (such as debuggers and compilers) to a software environment, the DBMS allows the user to extend the type structure. The system also supports an efficient rollback and recovery mechanism, which provides the framework for a software version facility.	compiler;concurrent computing;debugger;documentation;multi-user;sun workstation;software versioning;unix	Scott E. Hudson;Roger King	1987		10.1145/38713.38763	real-time computing;data type;computer science;operating system;database;programming language;object-oriented programming	DB	-30.483315606563778	41.33995001533769	138981
fbb7c0b8b64d53af44cda0d1d1950220dc688c14	a distributed fault tolerant architecture for nuclear reactor and other critical process control applications	real time systems computer architecture distributed processing fault tolerant computing nuclear engineering computing process computer control;nuclear engineering computing;nuclear reactor;fault tolerant;distributed processing;distributed recovery block;computer architecture;process computer control;fault tolerant system;fault tolerant computing;fault tolerance process control control systems chemical processes fault tolerant systems hardware real time systems programmable control testing network interfaces;process control;chemical processing system distributed fault tolerant architecture nuclear reactor critical process control distributed recovery block software faults replication loose coupling periodic status messages restart capability diverse interconnection paths automated restart capability logging function system supervisor node extended distributed recovery block;real time systems	A distributed fault tolerant system for process control that is based on an enhancement of the distributed recovery block (DRB) is described. Fault tolerance provisions in the system cover software faults by use of the DRB; hardware faults by means of replication and the DRB; system software faults by means of replication, loose coupling, periodic status messages, and a restart capability; and network faults by means of replication and diverse interconnection paths. Maintainability is enhanced through an automated restart capability and logging function resident on a system supervisor node. The system, called the extended distributed recovery block, or EDRB, has been implemented and integrated into a chemical processing system. >	reactor (software)	Myron Hecht;J. Agron;Herbert Hecht;K. H. Kim	1991		10.1109/FTCS.1991.146702	embedded system;real-time computing;engineering;distributed computing;software fault tolerance;replication	Arch	-25.812695346398666	44.269879215413205	139193
2d14b7575687d0b0eb92146b49f7e21bccb21dd0	specifying weak sets	distribution;language use;mathematics;access;formal specification;information systems;specification assertion language;area coverage;unix systems formal specifications abstraction weak sets latencies world wide web concurrency distribution semantic requirements mathematical sets strong consistency specification assertion language;formal specifications;semantics;abstraction;set theory;semantic requirements;design space;requirements;latencies;computer programming;unix systems;concurrency;strong consistency;formal specifications delay information retrieval information systems web sites concurrent computing instruments;interrogation;low strength;world wide web;computer files;mathematical sets;information system;trade off analysis;weak sets;consistency;global;guarantees	"""We present formal speci cations of a new abstraction, weak sets, which can be used to alleviate high latencies when retrieving data from a wide-area information system like the World Wide Web. In the presence of failures, concurrency, and distribution, clients performing queries may observe behavior that is inconsistent with the stringent semantic requirements of mathematical sets. For example, an element retrieved and returned to the client may be subsequently deleted before the query terminates. We chose to specify formally the behavior of weak sets because we wanted to understand the varying degrees of inconsistency clients might be willing to tolerate and to understand the tradeo between providing strong consistency guarantees and implementing weak sets e ciently. Our speci cation assertion language uses a novel construct that lets us model reachability explicitly; with it, we can distinguish between the existence of an object and its accessibility. These speci cations were instrumental in understanding the design space, and we are currently implementing the most permissive of the speci cations in several types of Unix systems. 1 Motivation for Weak Sets Suppose you are browsing the World Wide Web (WWW) and want to display the .face les of all people listed on Carnegie Mellon's home page. Or, suppose through the on-line library information system (LIS) you want to get a list of papers by a particular author. Or, suppose you are a tourist in Pittsburgh and want to look at the on-line menus of all Chinese restaurants before choosing where to eat for dinner. Each of these kinds of queries returns a set of objects (.face les, card catalog entries, menus). What properties should we expect these sets to have? We claim that some standard properties of mathematical sets are desired, but others are not. In particular, we expect that: { Membership of an element is determined at some time between starting the query and nishing the query. Membership may not necessarily hold before the query, continuously throughout the run of the query, or even after the query completes. For example, if the LIS database is not up-to-date, we would not be surprised if an author's most recent paper is not listed; we would not go hungry if our restaurant search missed some (but not all) Chinese restaurants in Pittsburgh. { Order among elements does not matter. Hence retrieval of elements can be optimized. { There are no duplicates. (Though we probably would not be overly annoyed if there were.) { Elements in the set change infrequently. A restaurant's menu may change weekly or seasonally; a .face le, annually; an LIS entry, never. Because of the nature of the information repositories over which we run these queries, we would not expect concurrent reads and writes on the repository to be serializable. In particular, user A may be updating the information repository concurrently with user B who is reading from it. User B may see partial writes of A. This non-serializable behavior implies that: { Two people running the same query at the same time may obtain di erent sets of elements. { Running the same query twice in a row may return di erent sets of elements. Thus these sets provide weaker guarantees to the user than traditional set semantics or traditional distributed databases. However, for the kinds of wide area systems we consider, clients do not expect strong consistency properties, and implementations that provide stronger guarantees may prove ine cient. The key di erence, of course, is that unlike for transaction-oriented databases (e.g., a bank's set of accounts), there is no global consistency requirement that must be upheld across a set of information repositories in the WWW. This paper explores a design space for variations on the semantics of weak sets. Sets are characterized by membership of its elements. In our design and implementation of weak sets, we determine membership through an iterator operation, elements, on sets. This iterator yields elements in the set one at a time. Points in our design space di er by looking at the di erences in the behavior of the elements iterator. 1.1 Context for This Work Our original motivation for investigating the semantics of weak sets arose in the context of distributed le systems. Our target environment is a wide-area le system on a network of (possibly mobile) workstations. Failures are assumed to be common, e.g., disconnecting a mobile client from the network while traveling is an induced failure, yet consistency of data may be sacri ced to gain high performance and high availability. In a distributed le system, les and subdirectories in the same directory may reside on nodes di erent from each other and/or from the directory itself. To reduce the high latency of accessing a group of objects in a distributed le system, one of us (DCS) as part of a Ph.D. thesis is adding a set abstraction called dynamic sets to the Unix Application Programmer's Interface. In a typical le system, the expected behavior of the UNIX-like command ls, for example, is to list the les in the directory in some order (e.g., alphabetically), thus requiring that all les be accessed before ls returns. In a distributed le system, satisfying this requirement is prohibitively expensive; in the worst case, because of failures some les may no longer be accessible and so non-termination is possible. By removing this requirement, we gain two advantages: (1) We can return information to the user more quickly by yielding partial information about the contents of a directory; and (2) we can implement such le system commands more e ciently by fetching les in parallel, fetching \closer"""" les rst, and fetching all accessible les despite network failures. The resulting behavior observed by the user is akin to a set's, where ordering of the items does not matter. Also, by supporting a set-like abstraction, we can support database-like queries, e.g., nding all les that satisfy a given predicate. 1.2 Contributions of Paper To better understand the semantics of dynamic sets, in particular what properties the implementor must guarantee to its clients, we decided to more formally specify their properties. In so doing, we realized that there is a wide range of reasonable semantics, resulting in our variations of weak sets. This paper presents some of the points in this range. The weakest of the behaviors corresponds exactly to the semantics of dynamic sets that we are implementing. In our rst attempt at writing formal speci cations of weak sets we ran up against two limitations of current formal methods. First, we need to deal more explicitly with the failure case due to the distributed nature of our context. In particular, we need to distinguish between the existence of an object, say an element of a set, and its accessibility; an element may satisfy a query but we may not be able to reach it because of a failure. Second, membership for weak sets is determined by invoking an iterator, which incrementally retrieves elements that satisfy a given query. Little work has addressed the formal speci cation of iterators (we discuss related work in Section 4); none that we are aware of is suitable for a concurrent or distributed environment. In summary the two main contributions of this paper are: { A design space for the semantics of weak sets in a distributed environment. We present in Section 3 a set of dimensions for our design space and describe four of the interesting points in this space. { A novel speci cation construct needed to capture the inherent distributed nature of the application. In a distributed system where node and network failures are possible, knowing about the existence of an object does not imply being able to access it. We introduce a reachable function to our assertion language to help make this distinction. Secondary new contributions of this paper are (1) a way of specifying iterators in the presence of concurrency and distribution and (2) a more precise semantics for dynamic sets, a new distributed le system abstraction [15]. Both the notion of weak sets and our speci cation technique can be applied to other contexts. A le system is a special kind of persistent object repository where les are objects and directories are collections. A distributed le system is a special kind of a wide-area information system, for which clients expect continuous operation despite faults and transmission delays. So, though originally motivated to support distributed le systems, weak sets are more generally abstractions useful for both persistent object repositories, e.g., Cricket [14], EOS [5], Gemstone [10], and Thor [8] (see [1] for others), and wide-area information systems and their applications, e.g., the WorldWide Web (WWW) [2], WAIS [7], and Gopher[11]. Using an iterator-like operation to perform search and retrieval is common in these systems."""	accessibility;assertion (software development);best, worst and average case;chinese room;chinese wall;concurrency (computer science);continuous operation;directory (computing);distributed computing;distributed database;divergence (computer science);eos;formal methods;high availability;home page;information repository;information system;iterator;linux;observable;online and offline;programmer;reachability;requirement;serializability;strong consistency;tru64 unix;unix;unix-like;usability;www;weak consistency;web search query;workstation;world wide web	Jeannette M. Wing;David C. Steere	1995		10.1109/ICDCS.1995.500046	computer science;theoretical computer science;operating system;formal specification;database;distributed computing;semantics;programming language;computer security;information system	DB	-24.728494830663845	46.07243705116884	139281
111894f19a4c42836981e2787b437946ee5a8ae7	distributed universal constructions: a guided tour		The notion of a universal construction is central in computing science: the wheel has not to be reinvented for each new problem. In the context of n-process asynchronous distributed systems, a universal construction is an algorithm that is able to build any object defined by a sequential specification despite the occurrence of up to (n − 1) process crash failures. The aim of this paper is to present a guided tour of such universal constructions. Its spirit is not to be a catalog of the numerous constructions proposed so far, but a (as simple as possible) presentation of the basic concepts and mechanisms that constitute the basis these constructions rest on.	algorithm;computer science;distributed computing	Michel Raynal	2017	Bulletin of the EATCS		computer science;theoretical computer science;mathematics;algorithm	Theory	-24.12549374155999	43.314307526491824	139536
fa22199843052602149048b293169a4706e3121a	myp2pworld: highly reproducible application-level emulation of p2p systems	discrete event simulator;emulation reproducibility of results concurrent computing control systems job shop scheduling operating systems system testing electrical equipment industry wrapping production;p2p system;computer engineering;concurrent computing;scheduling operating systems computers peer to peer computing program testing;overlay networks;peer to peer application level emulator overlay networks bandwidth modelling discrete event simulator;emulation;testing;application level emulator;other electrical engineering electronic engineering information engineering;program testing;operating system;scheduling;annan elektroteknik och elektronik;standard widely used networking highly reproducible application level emulation p2p systems operating system;overlay network;production;bandwidth;bandwidth modelling;datorteknik;peer to peer computing;highly reproducible application level emulation;standard widely used networking;peer to peer;operating systems computers;context;p2p systems;java;discrete event simulation	In this paper, we describe an application-level emulator for P2P systems with a special focus on high reproducibility. We achieve reproducibility by taking control over the scheduling of concurrent events from the operating system. We accomplish that for inter- and intra- peer concurrency. The development of the system was driven by the need to enhance the testing process of an already-developed industrial product. Therefore, we were constrained by the architecture of the overlying application. However, we managed to provide highly transparent emulation by wrapping standard/widely-used networking and concurrency APIs. The resulting environment has proven to be useful in a production environment. At this stage, it started to be general enough to be used in the testing process of applications other than the one it was created to test.	concurrency (computer science);deployment environment;emulator;floor and ceiling functions;open-source software;operating system;peer-to-peer;requirement;scheduling (computing);software deployment;streaming media;system time;wrapping (graphics)	Roberto Roverso;Mohammad Alaggan;Amgad Naiem;Andreas Dahlstrom;Sameh El-Ansary;Mohammed El-Beltagy;Seif Haridi	2008	2008 Second IEEE International Conference on Self-Adaptive and Self-Organizing Systems Workshops	10.1109/SASOW.2008.48	embedded system;real-time computing;overlay network;concurrent computing;computer science;operating system;distributed computing;programming language	HPC	-33.09329533705364	46.23940892603392	139537
5e9e307f6eb3abcfa4a3757ecfcad0e50f126778	optimal design of multiple hash tables for concurrency control	hash algorithms multiple hash tables concurrency control data sharing database systems false contentions;file organisation concurrency control;modelizacion;lock contentions;distributed system;eficacia sistema;base donnee;architecture systeme;systeme reparti;concurrency control aggregates database systems control systems transaction databases availability delay parallel processing scalability fault tolerant systems;modele mathematique;performance systeme;teleinformatica;database;base dato;modelo matematico;system performance;algorithme;multiple hash tables;modelisation;algorithm;teleinformatique;sistema repartido;hash table;analyse performance;concurrency control;performance analysis;data access;mathematical model;optimal design;arquitectura sistema;information system;hash algorithms;system architecture;modeling;remote data processing;systeme information;algoritmo;sistema informacion;analisis eficacia;file organisation	In this paper, we propose the approach of using multiple hash tables for lock requests with diierent data access patterns to minimize the number of false contentions in a data sharing environment. We rst derive some theoretical results on using multiple hash tables. Then, in light of these derivations, a two step procedure to design multiple hash tables is developed. In the rst step, data items are partitioned into a given number of groups. Each group of data items is associated with the use of a hash table in such a way that lock requests to data items in the same group will be hashed into the same hash table. In the second step, given an aggregate hash table size, the hash table size for each individual data group is optimally determined so as to minimize the number of false contentions. Some design examples and remarks on the proposed method are given. It is observed from real database systems that diierent data sets usually have their distinct data access patterns, thus resulting in an environment where this approach can ooer signiicant performance improvement.	aggregate data;concurrency control;data access;database;distributed hash table;optimal design	Ming-Syan Chen;Philip S. Yu	1997	IEEE Trans. Knowl. Data Eng.	10.1109/69.599928	data access;hash table;double hashing;hash function;systems modeling;linear hashing;perfect hash function;dynamic perfect hashing;merkle tree;primary clustering;quadratic probing;computer science;optimal design;consistent hashing;theoretical computer science;concurrency control;hash chain;mathematical model;data mining;hash buster;database;distributed computing;hash list;rolling hash;computer performance;suha;world wide web;information system;algorithm;cryptographic hash function;systems architecture;hash tree;hash filter;hat-trie	DB	-19.763613094849017	46.38069737030836	139577
1e6eb0eb651726e34b5969896b58343a0d3a6e48	polychronous automata	clocks;semantics;automata;computational modeling;syntactics;unified modeling language;mathematical model	This paper investigates the way state diagrams can be best represented in the polychronous model of computation. In this relational model, the basic objects are signals, which are related through data-flow equations. Signals are associated with logical clocks, which provide the capability to describe systems in which componentsobey to multiple clock rates. We propose a model of finite-state automata, called polychronous automata, which is based on clock relations. A specificity of this model is that an automaton is submitted to clock constraints. This allows one to specify a wide range of control-related configurations, either reactive, or restrictivewith respect to their control environment. A semantic model is defined for these polychronous automata, that relies on a Boolean algebra of clocks.	automaton;boolean algebra;clock rate;dataflow;diagram;finite-state machine;logical clock;mathematical model;model of computation;open-source software;regular expression;relational model;signal (programming language);selective area epitaxy;sensitivity and specificity;smoothing	Paul Le Guernic;Thierry Gautier;Jean-Pierre Talpin;Loïc Besnard	2015	2015 International Symposium on Theoretical Aspects of Software Engineering	10.1109/TASE.2015.21	unified modeling language;real-time computing;computer science;theoretical computer science;mathematical model;semantics;automaton;computational model;mobile automaton;timed automaton;algorithm	Embedded	-33.08772538692705	32.654228973405274	139643
59519dbfdc16d6ca6261988921e015aa98be4b1b	a multi-agent architecture for intelligent mobile agents	performance measure;evaluation performance;multiagent system;architecture systeme;agent mobile;performance evaluation;evaluacion prestacion;agente movil;reseau ordinateur;technology management;computer network;mobile agent system;client server;agent intelligent;intelligent agent;red ordenador;multi agent architecture;arquitectura sistema;agente inteligente;mobile agent;system architecture;sistema multiagente;systeme multiagent	The client/server technology manages to carry and treat an ever increasing amount of data. However, it is poorly scalable and personalized, and it does not consider the topology of networks. In spite of many weaknesses and the lack of killer applications, multi-agent and mobile agent systems offer more flexibility and reduce network load. They carry their code, where as other applications only send data on the network. This paper proposes a multi-agent architecture which solves this problem by splitting the mobile agent into several cooperating small agents and integrating a notion of neighborhood. Performance measures validated the design of the architecture. Those measures show that the proposed architecture and algorithms improve the intelligence and the use of network resources. As a result, this architecture is suitable for applications where optimising bandwidth is more important than speed, this is the case for many applications in wireless environments.	agent architecture;mobile agent	Sylvain Goutet;Samuel Pierre;Roch H. Glitho	2001		10.1007/3-540-44651-6_13	reference architecture;embedded system;space-based architecture;real-time computing;simulation;computer science;artificial intelligence;technology management;operating system;mobile agent;intelligent agent;client–server model;data architecture	Robotics	-28.910397400514192	44.57675548822211	139695
8963df4f1144067314b0d9729f4fd1685d7cccee	modelling real-time database systems in duration calculus	priority ceiling protocol;database system;duration calculus;real time;concurrency control	The Concurrency Control in Real Time Database Systems has to ensure not only the consistency of the data in the multi-user environments like in traditional databases, but also the temporal consistency of the data, and that all transactions meet their deadline. Therefore, the Concurrency Control in Real Time Database Systems (RTDBS) is much more complicated than the Concurrency Control in traditional database systems (DBS). A comprehensive model for the concurrency control and formal technique for reasoning about its behaviour will support the design, analysis and verification of concurrency control protocols. In this paper, we propose such a model based on Duration Calculus. With our formal model, we give a formal verification of some conditions for maintaining the temporal consistency of the data, and a formal verification of the correctness of the Read/Write Priority Ceiling Protocol (R/WPCP) for the concurrency control in real-time database systems. Ho Van Huong is a Fellow of UNU/IIST from January 2002 to September 2002. He is a Ph.D.student at the Faculty of Mathematics, Mechanics and Informatics, School of Natural Sciences, Viet Nam National University. His research interests include Formal Methods, Real-Time Databases, Programming Languages. His current email address is: hvh@iist.unu.edu. Dang Van Hung is a Research Fellow of UNU/IIST, on leave of absence from the Institute of Information Technology, Hanoi, Vietnam. His research interests include Formal Techniques of Programming, Concurrent and Distributed Systems, Real-Time Systems. His email address is: dvh@iist.unu.edu. Copyright c © 2002 by UNU/IIST, Ho Van Huong and Dang Van Hung	concurrency control;correctness (computer science);database;direct-broadcast satellite;duration calculus;email;formal language;formal methods;formal verification;informatics;multi-user;nam;priority ceiling protocol;real-time clock;real-time locating system;real-time operating system;real-time transcription	Dang Van Hung;Ho Van Huong	2004			duration calculus;formal specification;programming language;concurrency control;formal methods;proof calculus;process calculus;formal verification;refinement;computer science	DB	-30.02816825432911	34.300079823784294	139702
fb4cd138fc8424073198cec89f5e988483c2deb7	how to be a more efficient snoop: refined probe complexity of quorum sets	fault tolerant distributed system probe complexity quorum sets;complexity theory;fault tolerant;computer crashes;distributed processing;data mining;probes;fault tolerant distributed systems;fault tolerant computing;adaptation model;fault tolerant computing distributed processing;wool;fault tolerance;quorums;probe complexity;probe complexity fault tolerance quorums;probes computer crashes fault tolerant systems wool distributed computing application software storms computer science vehicle crash testing sequential analysis	Quorums are flexible and well-studied means for implementing fault-tolerant distributed systems. The probe complexity gives the number of probes required to find a quorum of noncrashed processes or to reveal that no such quorum currently exists. In this paper, we refine the original notion of probe complexity by explicitly considering the underlying failure model. A refined probe complexity gives a tight bound on the number of required probes, which is lower than the original probe complexity for most failure models. Additionally, we present a universal probe strategy that is defined for all quorum sets and exhibits the refined probe complexity in the worst case. In contrast, previous probe strategies were limited to special quorum sets, namely to coteries, and meet the original probe complexity only for special (i. e., nondominated) coteries.	best, worst and average case;computation;distributed computing;fault tolerance;precomputation;quorum sensing;run time (program lifecycle phase);structural integrity and failure;tight binding;snoop	Timo Warns;Christian Storm;Oliver E. Theel	2009	2009 International Conference on Parallel and Distributed Computing, Applications and Technologies	10.1109/PDCAT.2009.31	fault tolerance;parallel computing;real-time computing;computer science;theoretical computer science;distributed computing	Theory	-22.760398591257136	45.56695752309045	139935
942d7b97303603d14d78ca41fe5ba2472f75c161	a fast and general implementation of mach ipc in a network	operating system	This paper describes an implementation of the Mach IPC abstraction on a network. Our implementation, called Mach NetIPC, is done in the context of the x-kernel, which provides a networking subsystem for Mach. The paper motivates the design choices we made, describes the x-kernel protocol graph that implements the design, and reports on the performance of the resulting system.	authorization;central processing unit;communications protocol;device driver;digital signature;information security;internet protocol suite;kernel (operating system);lock (computer science);mach;overhead (computing);richard schroeppel;type signature	Hilarie K. Orman;Sean W. O'Malley;Edwin Menze;Larry L. Peterson;Richard Schroeppel	1993			embedded system;parallel computing;computer science;operating system	Networks	-25.96409926477736	41.78230786268341	140154
3316e68a8309c8d173393df870dce8ee2c1bb135	byzantine clock synchronization	tolerancia falta;fault tolerant;multiprocessing;consistencia;algorithme;synchronisation;algorithm;algorritmo;general solution;probleme generaux byzantins;synchronization;fault tolerance;consistance;multitraitement;horloge;clock synchronization;sincronizacion;clock;consistency;tolerance faute;reloj;multitratamiento	"""An informal description is given of three fault-tolerant clock-synchronization algorithms. These algorithms work in the presence of arbitrary kinds of failure, including """"two-faced"""" clocks. Two of the algorithms are derived from Byzantine Generals solutions."""	algorithm;byzantine fault tolerance;clock synchronization	Leslie Lamport;P. M. Melliar-Smith	1986	Operating Systems Review	10.1145/12476.12477	synchronization;fault tolerance;parallel computing;real-time computing;computer science;quantum byzantine agreement;distributed computing;byzantine fault tolerance	Metrics	-21.60819669758424	43.644973043536375	140171
8a5205a889e7745d4f0bc361226ab30f15ae295a	trace recording for embedded systems: lessons learned from five industrial projects	trace recording;case studies;real time operating system;tracing;overhead;embedded system;technology transfer;embedded systems;general solution;engineering and technology;teknik och teknologier;monitoring;lessons learned;scheduling;experiences	This paper presents experiences from five industry collaboration projects performed between 2004 – 2009 where solutions for embedded systems trace recording have been developed and evaluated; in four cases for specific industrial systems and in the last case as a generic solution for a commercial real-time operating system, in collaboration with the RTOS company. The experiences includes technical solutions regarding efficient instrumentation and logging, technology transfer issues and evaluation results regarding CPU and RAM overhead. A brief overview of the Tracealyzer tool is also presented, a result of the first project (2004) which still is used by ABB Robotics and now in commer-	32-bit;algorithm;andy wellings;central processing unit;computer multitasking;debugging;digital video recorder;embedded system;experience;extrapolation;fixed-priority pre-emptive scheduling;instrumentation (computer programming);linux;overhead (computing);random-access memory;real-time operating system;real-time transcription;robotics;scheduling (computing);video game developer	Johan Kraft;Anders Wall;Holger M. Kienle	2010		10.1007/978-3-642-16612-9_24	embedded system;real-time computing;simulation;real-time operating system;tracing;computer science;overhead;scheduling	Embedded	-28.649857615370273	38.06374181578568	140594
475a7ed1787f05087759f7a758759d869805822f	personal information annotation on wearable computer users with hybrid peer-to-peer communication	anotacion;distributed system;reseau information;database system;interfase usuario;computadora hibrida;systeme reparti;mise a jour;distributed database;realite virtuelle;realidad virtual;modelo autorregresivo;user interface;low frequency;par a par;serveur informatique;database;virtual reality;base repartida dato;base dato;p2p;annotation;information network;delai transmission;autoregressive model;transmission time;dynamical system;actualizacion;systeme dynamique;hybrid computer;realite augmentee;realidad aumentada;client server;sistema repartido;analisis regresion;poste a poste;base de donnees repartie;basse frequence;base de donnees;analyse regression;servidor informatico;interface utilisateur;wearable computer;regression analysis;baja frecuencia;sistema dinamico;augmented reality;modele autoregressif;plazo transmision;peer to peer;updating;red informacion;calculateur hybride;computer server	This paper proposes a wearable annotation overlay system which can correctly annotate dynamic users of wearable computers. To provide users with the newest annotation information, a network shared database system for wearable AR systems has been proposed. With the database, a wearable annotation overlay system which can dynamically annotate users of wearable systems has been investigated. In conventional systems, since dynamic users’ position is transmitted to wearable AR systems via a shared database server, it is difficult to overlay annotations at a correct position because of low frequency of updating and delay of client-server communication. In this paper, we propose a new effective method for wearable AR systems to obtain dynamic users’ positions by using hybrid peer-to-peer(P2P). In experiments, annotations on dynamic users have been proven to be overlaid correctly enough to show where users are.	ar (unix);client–server model;database server;effective method;experiment;server (computing);wearable computer	Koji Makita;Masayuki Kanbara;Naokazu Yokoya	2006		10.1007/11941354_23	embedded system;transmission time;augmented reality;simulation;wearable computer;computer science;dynamical system;peer-to-peer;database;virtual reality;low frequency;autoregressive model;hybrid computer;user interface;world wide web;distributed database;regression analysis;client–server model;server	OS	-29.99551465778723	43.78692431806119	140739
401f5206f548755592a8e0034c59deca638f159d	injecting distributed capabilities into legacy applications through cloning and virtualization	process migration;api interception;mid- dleware;distributed operating systems;windows nt.;operating system;resource manager;boundary layer	Applications and operating systems can be augmented with extra functionality by injecting additional middleware into the boundary layer between them, without tampering with their binaries. Using this scheme, we separate the physical resource bindings of the application and replace it with virtual bindings. This is called virtualization. We are developing a virtualizing Operating System (vOS) residing on top of Windows NT, that injects all applications with the virtualizing software. The vOS makes it possible to build communities of systems that cooperate to run applications and share resources completely non-intrusively while retaining complete application binary compatibility. In this paper, we describe a prototype system that virtualizes the application’s window, making it possible to relocate the window to remote machines without the application’s awareness. The prototype copies, or clones a window of an application onto a display on a remote machine and then, using API interception, applies the application semantics to the clone window in terms of data and message flow. The virtualization of the application‘s window is one of the steps towards making all system resources virtualizable and any application movable between systems. This research is part of a larger project called Computing Communities (CC) which is building large unions of distributed machines supporting shared resource management using legacy applications.	application programming interface;binary file;hardware virtualization;middleware;operating system;prototype;remote computer;windows nt	Tom Boyd;Partha Dasgupta	2000			process migration;computer science;virtualization;software;distributed operating system;distributed computing;operating system;binary code compatibility;legacy system;shared resource;middleware	OS	-32.516001636107994	42.80585302284369	140858
324076861951368c018894391feca98fc1259c59	processus compositionnels interactifs : une architecture pour la programmation et l'exécution des structures musicales. (interactive compositional processes : a framework for programming and rendering musical structures)		Computer-aided composition (cac) tools allow composers to generate musical data using programming. The computer-aided composition programs are generally called deferred-time to underline the difference between the time included in their result, and the absolute time that flows during their executions. cac tools offer a temporal representation of musical data, allowing to compose at the scale of a musical work. However, they do not allow any interaction with this structure during its rendering. This restricts the user to a sequential workflow : compose, then play. On the other hand, real-time environments interleave program execution time and output rendering time. This link introduces interactivity in programs, but limits computing power and complexifies the specification of temporal structures. This thesis aims at designing a computer system enabling the computation of musical structures, their presentation/handling on a compositional side, and their interactive rendering. It is a study at the crossroads between several computer science research fields : discrete systems modeling, scheduling, software design and human-computer interfaces. We propose an architecture where program editing can affect their outputs, including during the rendering phase, while preserving the compositional benefits of the deferred-time approach. Compositions are therefore considered as continually running programs, where computation and rendering mechanisms are interleaved. We introduce new tools and interfaces to arrange their execution through time thanks to dynamic temporal scenario scripting, which we call meta-composing. The different results described in this manuscript are implemented in the computer-aided composition environment OpenMusic.	computation;computer science;interactivity;linear algebra;openmusic;real-time transcription;rendering (computer graphics);run time (program lifecycle phase);scheduling (computing);software design;systems modeling	Dimitri Bouche	2016				Graphics	-26.601917425630926	37.629671361084235	140901
1e9e3d2f3c24bd71d74aea85c18ab0b8afb23ec2	an analysis of the dynamic behavior of javascript programs	program behavior;site web;dynamic programming;lenguaje programacion;empirical study;programacion dinamica;driving force;methode empirique;measurement;programming language;analisis dinamica;metodo empirico;empirical method;metric;comportamiento programa;tracing;program verification;dynamic metrics;analisis programa;verificacion programa;web programming;object oriented;execution tracing;tracage;programmation dynamique;langage programmation;comportement programme;oriente objet;analyse dynamique;metrico;program analysis;sitio web;analyse programme;static analysis;experimentation;verification programme;javascript;orientado objeto;languages;metrique;web site;trazado;dynamic analysis;type system;dynamic behavior	The JavaScript programming language is widely used for web programming and, increasingly, for general purpose computing. As such, improving the correctness, security and performance of JavaScript applications has been the driving force for research in type systems, static analysis and compiler techniques for this language. Many of these techniques aim to reign in some of the most dynamic features of the language, yet little seems to be known about how programmers actually utilize the language or these features. In this paper we perform an empirical study of the dynamic behavior of a corpus of widely-used JavaScript programs, and analyze how and why the dynamic features are used. We report on the degree of dynamism that is exhibited by these JavaScript programs and compare that with assumptions commonly made in the literature and accepted industry benchmark suites.	benchmark (computing);compiler;correctness (computer science);javascript;programmer;programming language;static program analysis;text corpus;type system;web development	Gregor Richards;Sylvain Lebresne;Brian Burg;Jan Vitek	2010		10.1145/1806596.1806598	simulation;computer science;unobtrusive javascript;programming language;empirical research;world wide web	PL	-20.340393700555957	34.86274477999455	140923
7265fe0db87e301b80196222f3541c6b20831158	behavioural equivalences over migrating processes with timers	timer;mobility;professor maciej koutny;bisimulation;equivalence;professor gabriel ciobanu;eprints newcastle university;open access;behaviour;process algebra	The temporal evolution of mobile processes is governed by independently operating local clocks and their migration timeouts. We define a formalism modelling such distributed systems allowing (maximal) parallel execution at each location. Taking into account explicit timing constraints based on migration and interprocess communication, we introduce and study a number of timed behavioural equivalences, aiming to provide theoretical underpinnings of verification methods. We provide several relationships between such behavioural equivalences.	bisimulation;concurrency (computer science);distributed computing;inter-process communication;maximal set;mobile agent;parallel computing;process calculus;semantics (computer science);session-based testing;timed automaton;timer;turing completeness;verification and validation	Bogdan Aman;Gabriel Ciobanu;Maciej Koutny	2012		10.1007/978-3-642-30793-5_4	equivalence;process calculus;computer science;bisimulation;artificial intelligence;programming language;mobile computing;algorithm	Logic	-29.197476403952315	32.99659915932224	141045
0e749e78b4b938e1ce6716bb4ccf984b70865170	partial ordering of synchronization events for distributed debugging in tightly-coupled multiprocessor systems	distributed debugging;distributed system;multiprocessor systems;distributed programs;message passing;parallel programs;partial order	In this paper, a partial ordering of synchronization events for the debugging of distributed programs in tightly-coupled multiprocessor systems is defined. Techniques for the debugging of parallel programs require timestamping of events. The physical clocks of different processors are in general not suitable for time stamping events, because these clocks are not synchronized. Synchronization of the physical clocks of all processors in a multiprocessor system requires additional hardware mechanisms. In an alternative approach, a partial ordering of events can be derived using logical clocks for timestamping events with virtual time. The concept of virtual time has been used successfully to derive clock conditions in distributed systems, in which message-passing is the only form of interaction. In this paper, clock conditions are derived for tightly-coupled synchronization primitives in multiprocessor systems. Finally the concept is successfully used in the implementation of a distributed debugger in the EMPS multiprocessor system.	debugging;multiprocessing	Gerardus Johannes Wichardus van Dijk;A. J. van der Wal	1991		10.1007/BFb0032927	distributed algorithm;parallel computing;real-time computing;computer science;distributed computing	Arch	-23.45608159697474	42.512020955017135	141115
fb6fcde6afd9c1cb1d8f820ede8c762c7941bee1	a construction of distributed reference counting	machine abstraite;proof assistant;distributed system;comptage;reference counting;systeme reparti;tree;arbol;maquina abstracta;distributed programs;difusion;contaje;safety properties;abstract machine;garbage collection;algorithme;algorithm;sistema repartido;reference;estructura datos;counting;arbre;referencia;structure donnee;proof of correctness;reference counter;diffusion;data structure;compteur reference;algoritmo	Distributed reference counting is a general purpose technique, which may be used, e.g., to detect termination of distributed programs or to implement distributed garbage collection. We present a distributed reference counting algorithm and a mechanical proof of correctness carried out using the proof assistant Coq. The algorithm is formalised by an abstract machine, and its correctness has two different facets. The safety property ensures that if there exists a reference to a resource, then its reference counter will be strictly positive. Liveness guarantees that if all references to a resource are deleted, its reference counter will eventually become null.	abstract machine;algorithm;coq (software);correctness (computer science);distributed garbage collection;garbage collection (computer science);liveness;program counter;proof assistant;reference counting	Luc Moreau;Jean Duprat	2001	Acta Informatica	10.1007/PL00013315	data structure;computer science;theoretical computer science;distributed computing;abstract machine;diffusion;programming language;algorithm	PL	-20.705863304675653	42.782369615317705	141250
061d30c3abf7374711bd82071b8441ffe7b6cd93	simplified programming of faulty sensor networks via code transformation and run-time interval computation	application development;automatic code generation;run time interval computation;computer languages;sensor network programming language;fault tolerant;programming language;temperature sensors;runtime libraries;telecommunication computing;interval computations;compiler;automatic generation;sensor network;temperature sensor;data analysis expressions;wireless sensor network;domain knowledge;data analysis expressions faulty sensor networks simplified programming code transformation run time interval computation wireless sensor network fault detection error correction algorithms facts system sensor network programming language compiler runtime libraries automatic code generation;error analysis;data analysis;large scale;complex data;error correction;fault detection;error correction algorithms;code size;code transformation;faulty sensor networks;facts system;data quality;correlation;error estimate;program compilers;wireless sensor networks data analysis error correction fault diagnosis program compilers telecommunication computing;programming;error analysis temperature sensors fault detection computer languages temperature distribution programming correlation;temperature distribution;wireless sensor networks;simplified programming;fault diagnosis	Detecting and reacting to faults is an indispensable capability for many wireless sensor network applications. Unfortunately, implementing fault detection and error correction algorithms is challenging. Programming languages and fault tolerance mechanisms for sensor networks have historically been designed in isolation. This is the first work to combine them. Our goal is to simplify the design of fault-tolerant sensor networks. We describe a system that makes it unnecessary for sensor network application developers and users to understand the intricate implementation details of fault detection and tolerance techniques, while still using their domain knowledge to support fault detection, error correction, and error estimation mechanisms. Our FACTS system translates low-level faults into their consequences for application-level data quality, i.e., consequences domain experts can appreciate and understand. FACTS is an extension of an existing sensor network programming language; its compiler and runtime libraries have been modified to support automatic generation of code for on-line fault detection and tolerance. This code determines the impacts of faults on the accuracies of the results of potentially complex data aggregation and analysis expressions. We evaluate the overhead of the proposed system on code size, memory use, and the accuracy improvements for data analysis expressions using a small experimental testbed and simulations of large-scale networks.	algorithm;compiler;computation;computer network programming;data aggregation;data quality;edge detection;error detection and correction;fault detection and isolation;fault tolerance;high- and low-level;library (computing);online and offline;overhead (computing);programmer;programming language;run time (program lifecycle phase);runtime library;runtime system;sensor;simulation;testbed	Lan S. Bai;Robert P. Dick;Peter A. Dinda;Pai H. Chou	2011	2011 Design, Automation & Test in Europe	10.1109/DATE.2011.5763023	embedded system;electronic engineering;real-time computing;wireless sensor network;computer science;theoretical computer science;operating system;distributed computing;programming language;algorithm	Embedded	-23.75273391131207	40.27951634351746	141453
be0d0dbb7e00814126dcba53b8177fe14d049b65	a callgraph-based search strategy for automated performance diagnosis (distinguished paper)	performance;diagnostico;automaton;distributed parallel program;systeme non deterministe;automata;non deterministic system;automate;programme parallele reparti;sistema no determinista;programme callgraph;rendimiento;diagnosis;diagnostic	We introduce a new technique for automated performance diagnosis, using the program’s callgraph. We discuss our implementation of this diagnosis technique in the Paradyn Performance Consultant. Our implementation includes the new search strategy and new dynamic instrumentation to resolve pointerbased dynamic call sites at run-time. We compare the effectiveness of our new technique to the previous version of the Performance Consultant for several sequential and parallel applications. Our results show that the new search method performs its search while inserting dramatically less instrumentation into the application, resulting in reduced application perturbation and consequently a higher degree of diagnosis accuracy. Copyright  2002 John Wiley & Sons, Ltd.	aix;authorization;bottleneck (software);call graph;call site;code;concurrency control;entry point;experiment;foremost;ibm notes;irix;john d. wiley;perturbation theory;refinement (computing);turing completeness;window blind	Harold W. Cain;Barton P. Miller;Brian J. N. Wylie	2000		10.1007/3-540-44520-X_15	real-time computing;simulation;computer science;artificial intelligence;automaton;algorithm	AI	-20.705711758600724	41.28945163057776	141493
838efbd8b71c7777a8ce051d470800753b43eba8	two real formal verification experiences: atm switch chip and parallel cache protocol	architecture systeme;design process;sistema informatico;computer system;transmision asincronica;formal method;chip;theorem prover;formal verification;cache coherence protocol;parallel architectures;model checking;architecture parallele;asynchronous transmission;hardware design;verification formelle;arquitectura sistema;transmission asynchrone;systeme informatique;system architecture	"""In this paper, we report two of our recent efforts in applying formal verification methods to our real hardware designs. The first one is to try to verify ATM switch LSI chips through the combined use of a theorem prover and model checking programs, and the second one is to try to formally verify the correctness of a cache coherency protocol used in one of our parallel PC servers by model checking programs. In both Ccises, the verifications themselves were successful (we could really verify the """"abstracted/simplified"""" designs). We could not, however, get much benefits from formal methods, since the verification process was not automatic but interactive. We had to spend significant amount of human time and human efforts in applying formal verification techniques, which made it very difficult to verify designs """"in time"""", that is, before the design process finishes. We review our experiences and describe problems that we typically encounter in application of formal verification techniques to real life designs."""	atm turbo;formal verification	Masahiro Fujita;Sreeranga P. Rajan;Alan J. Hu	1998		10.1007/3-540-48257-1_18	chip;model checking;parallel computing;real-time computing;formal methods;design process;formal verification;computer science;theoretical computer science;operating system;asynchronous communication;database;distributed computing;high-level verification;automated theorem proving;programming language;algorithm;systems architecture	HPC	-23.794197329728135	33.834333580197885	141538
012f8e43e7973c8fad3c9a48b4dd7be773c770d1	drfx: a simple and efficient memory model for concurrent programming languages	modelizacion;lenguaje programacion;diseno circuito;conflict detection;data race;sequential consistency;compilateur;shared memory;programming language;securite;memoria compartida;acces concurrent;coherencia secuencial;memory models;circuit design;semantics;simultaneidad informatica;java memory model;langage java;soft fences;metodo secuencial;optimizacion compiladora;sequential method;compiler;semantica;semantique;memory model exception;modelisation;acceso simultaneo;concurrency;data races;compiler optimization;safety;langage programmation;methode sequentielle;concurrent programs;multithread;hardware design;design;lenguaje java;conception circuit;modele donnee;coherence sequentielle;multitâche;seguridad;modeling;simultaneite informatique;languages;multitarea;optimisation compilateur;compilador;memoire partagee;data models;java language;memory model	The most intuitive memory model for shared-memory multithreaded programming is sequential consistency(SC), but it disallows the use of many compiler and hardware optimizations thereby impacting performance. Data-race-free (DRF) models, such as the proposed C++0x memory model, guarantee SC execution for datarace-free programs. But these models provide no guarantee at all for racy programs, compromising the safety and debuggability of such programs. To address the safety issue, the Java memory model, which is also based on the DRF model, provides a weak semantics for racy executions. However, this semantics is subtle and complex, making it difficult for programmers to reason about their programs and for compiler writers to ensure the correctness of compiler optimizations.  We present the DRFx memory model, which is simple for programmers to understand and use while still supporting many common optimizations. We introduce a memory model (MM) exception which can be signaled to halt execution. If a program executes without throwing this exception, then DRFx guarantees that the execution is SC. If a program throws an MM exception during an execution, then DRFx guarantees that the program has a data race. We observe that SC violations can be detected in hardware through a lightweight form of conflict detection. Furthermore, our model safely allows aggressive compiler and hardware optimizations within compiler-designated program regions. We formalize our memory model, prove several properties about this model, describe a compiler and hardware design suitable for DRFx, and evaluate the performance overhead due to our compiler and hardware requirements.	c++11;concurrent computing;correctness (computer science);file synchronization;halting problem;java memory model;memory model (programming);optimizing compiler;overhead (computing);programmer;programming language;race condition;requirement;sequential consistency;shared memory;thread (computing)	Daniel Marino;Abhayendra Singh;Todd D. Millstein;Madan Musuvathi;Satish Narayanasamy	2010		10.1145/1806596.1806636	shared memory;memory model;design;compiler;parallel computing;real-time computing;concurrency;computer science;circuit design;semantics;programming language;java memory model;sequential consistency	PL	-20.630824989440175	33.48060791403726	141584
bde3a40a451d86987487f9366cd5823643c8dd35	epistemic model checking of atomic commitment protocols with byzantine failures		The notion of knowledge-based program introduced by Halpern and Fagin provides a useful formalism for designing, analysing, and optimising distributed systems. This paper formulates the two phase commit protocol as a knowledge-based program and then an iterative process of model checking and counter-example guided refinement is followed to find concrete implementations of the program for the case of perfect recall semantics in the Byzantine faults context with synchronous reliable communication. We model several different kinds of Byzantine faults and verify different strategies to detect them. We address a number of questions that have not been considered in the prior literature, viz., under what circumstances a sender can know that its transmission has been successful, and under what circumstances an agent can know that the coordinator is cheating, and find concrete answers to these questions. The paper also describes a methodology based on temporal-epistemic model checking technology that can be followed to verify the shortest and longest execution time of a distributed protocol and the scenarios that lead to them.	byzantine fault tolerance;consensus (computer science);correctness (computer science);cryptography;distributed algorithm;distributed computing;distributed transaction;formal methods;iteration;knowledge-based systems;model checking;refinement (computing);run time (program lifecycle phase);semantics (computer science);sensor;two-phase commit protocol;viz: the computer game	Omar I. Al-Bataineh	2017	CoRR		parallel computing;computer science;quantum byzantine agreement;theoretical computer science;distributed computing;algorithm	Logic	-22.25156151660798	43.644710433200004	141668
cb03c027392b92895397c6079c301d17e51f6865	distributed algorithms: modeling and analysis with petri nets	distributed algorithms;concurrency theory distributed algorithms petri nets;atomic action;distributed algorithms algorithm design and analysis petri nets logic data structures distributed computing computer architecture application software nominations and elections transformers;phase based behaviour distributed algorithms representation technique operational primitives local atomic actions synchronization local states message buffers verification technique transparent proofs elementary predicate transforms concurrent runs local progress;temporal logic;predicate transformer;distributed computing;petri nets;petri net;distributed algorithm;localized state;modeling and analysis;concurrency theory	likewise established basis for distributed algorithms is missing, that correspondingly would fix fundamental controland data structures, as well as a matching verification technique. An algorithm is said to be distributed if it operators on a physically or logically distributed computing architecture. Typically, such architectures lack global control. This requires particular means to model and to verify distributed algorithms. Decisive reasons for this unpleasant situation will be discussed in the forthcoming Chapter 2. A well known distributed algorithm, solving the leader election problem will be employed in Chapter 3, to exemplify a technique to represent formally, yet intuitively, distributed network algorithms, as well as adjusted verification techniques for this kind of algorithms. This algorithm will be verified in Chapter 4. Distributed algorithms are frequently designed in an abstract setting, assuming any network of agents. One of the agents is frequently assumed to initiate a computation, with all other agents reacting by means of identical algorithms. Each agent is aware of its neighbour agents only. Hence, such an algorithm is a schema-of behaviour, to run on any in a whole class of networks, such as the connected networks, the ringor tree-shaped networks, etc. We suggest a representation technique that is particularly tailored to distributed algorithms, based on the observation that the adequate operational primitives of distributed algorithms include local atomic actions, synchronization, local states, message buffers and similar constructs, whereas assignment statements and global states are no longer essential. Furthermore, a verification technique will be presented, allowing surprizingly simple and transparent proofs. This technique includes well established Petri Net based concepts as well as new, temporal logic based arguments. The logic exploits the particularly simple structure of Petri nets: Petri Net places are taken as predicates, Petri Net transitions are elementary predicate transformers, and the notion of concurrent runs yields means to adequately argue on local progress and phase based behaviour.	advanced configuration and power interface;computation;computer architecture;data structure;distributed algorithm;distributed computing;exemplification;leader election;linearizability;petri net;predicate transformer semantics;temporal logic;transformers	Wolfgang Reisig	1998		10.1109/ICSMC.1998.725380	distributed algorithm;concurrency;computer science;artificial intelligence;theoretical computer science;machine learning;distributed computing;process architecture;petri net;algorithm;distributed concurrency control	Logic	-27.1163366165817	33.23377179232634	141889
da9fdf27b50eeb53618fd679fdcfddc698ae5e56	searchable virtual file system: toward an intelligent ubiquitous storage	sistema operativo;legacy software;systeme intelligent;informatique mobile;gestion archivos;pervasive computing;sistema inteligente;interrogation base donnee;distributed computing;index structure;interrogacion base datos;gestion fichier;estructura archivo;intelligence artificielle;compatibilidad;file management;grid;informatica difusa;logiciel patrimonial;operating system;indexing;informatique diffuse;rejilla;file system;logicial herencia;indexation;structure fichier;file structure;indizacion;intelligent system;compatibility;grille;calculo repartido;artificial intelligence;ubiquitous computing;systeme exploitation;compatibilite;inteligencia artificial;mobile computing;calcul reparti;database query	As moving toward ubiquitous environment, demand for a easy data-lookup is growing rapidly. In an ocean of the exploding data, users should use some tools to find an right data. Intelligent ubiquitous applications also make the data-lookup service essential to the ubiquitous computing framework. This paper proposes a new, searchable, backward-compatible, virtual file system (S-VFS) for a easy file-lookup. We add the lookup functionality to VFS, the de facto standard layer in the file system. Users don't need to remember a full path to find a file any longer. Instead, each file has the attributes to use at lookup. S-VFS maintains the attributes in a normal file per partition. The indexing structures for the attributes are placed on a separated partition. Using the attribute files and the indexing structures, S-VFS processes queries provided by users and returns the result as a form of directory. In spite of this modification in VFS, S-VFS uses the legacy file systems without any modification. Since S-VFS supports the full backward compatibility, users can even browse hierarchically with the legacy path name.		YongJoo Song;Yongjin Choi;HyunBin Lee;Donggook Kim;Daeyeon Park	2006		10.1007/11745693_39	fork;self-certifying file system;search engine indexing;torrent file;indexed file;device file;computer file;computer science;stub file;versioning file system;operating system;unix file types;ssh file transfer protocol;journaling file system;database;distributed computing;open;everything is a file;data file;file format;file system fragmentation;compatibility;grid;world wide web;ubiquitous computing;legacy system;design rule for camera file system;working directory;computer network;file control block;virtual file system	HPC	-29.248539765256492	43.66588489433274	141934
6def8cd3b57c67a17b20b8348cdec39b97a36695	on breakable cyclic definitions	real time processing;system design;combinational circuits;high level synthesis;combinational circuit;information flow;combined cycle	In the course of hardware system design or real-time process control, high-level specifications may contain simultaneous definitions of concurrent modules whose information flow forms cyclic dependencies without the separation of state-holding elements. The temporal behavior of these cyclic definitions may be meant to be combinational rather than sequential. Most prior approaches to analyzing cyclic combinational circuits were built upon the formulation of ternary-valued simulation at the circuit level. This work shows the limitation of this formulation and investigates, at the functional level, the most general condition where cyclic definitions are semantically combinational. It turns out that the prior formulation is a special case of our treatment. Our result admits strictly more flexible high-level specifications. Furthermore, it allows a higher-level analysis of combinationality, and, thus, no costly synthesis of a high-level description into a circuit netlist before combinationality analysis can be performed. With our formulation, when the target is software implementations, combinational cycles need not be broken as long as the execution of the underlying system obeys a sequencing execution rule. For hardware implementations, combinational cycles are broken and replaced with acyclic equivalents at the functional level to avoid malfunctioning in the final physical realization.	combinational logic;directed acyclic graph;emoticon;high- and low-level;netlist;real-time transcription;simulation;systems design	Jie-Hong Roland Jiang;Alan Mishchenko;Robert K. Brayton	2004	IEEE/ACM International Conference on Computer Aided Design, 2004. ICCAD-2004.	10.1145/1112239.1112306	electronic engineering;real-time computing;computer science;theoretical computer science;combinational logic;algorithm	EDA	-23.4351148844634	34.78427325040957	141989
1dab16c6c49769a3be4351fecee418893f75d099	performance analysis of recovery techniques	database system;reliability;base donnee;technology;recouvrance;database;recovery;systeme base donnee;algorithme;modelisation;algorithm;model evaluation;algorritmo;fiabilite;analyse performance;technologie;performance analysis;modeling;analytical model;tecnologia	Various logging and recovery techniques for centralized transaction-oriented database systems under performance aspects are described and discussed. The classification of functional principles that has been developed in a companion paper is used as a terminological basis. In the main sections, a set of analytic models is introduced and evaluated in order to compare the performance characteristics of nine different recovery techniques with respect to four key parameters and a set of other parameters with less influence. Finally, the results of model evaluation as well as the limitations of the models themselves are discussed.	acm transactions on database systems;algorithm;application checkpointing;backup;centralized computing;concurrency (computer science);consistency model;data manipulation language;disaster recovery;downtime;end-of-file;granule (oracle dbms);hard time;input/output;lock (computer science);mean time between failures;online and offline;overhead (computing);profiling (computer programming);redundancy (engineering);response time (technology);software propagation;throughput;transaction processing system	Andreas Reuter	1984	ACM Trans. Database Syst.	10.1145/1994.1996	recovery;computer science;artificial intelligence;reliability;database;operations research;technology	DB	-20.370717748282686	46.18904804158023	142080
6e7259d057ae0140d31a10d0bf8f7c292fc79012	static worst-case execution time analysis tool for embedded operating systems	real time;schedulability analysis;embedded system;worst case execution time;operating system	Real-time support of embedded Operating Systems is essential for contemporary embedded systems. In order to achieve supporting real-time property, it is crucial that schedulability analysis for real-time task is finished before implementing the embedded systems. Acquiring Worst-Case Execution Time (WCET) of task is a core part of this schedulability analysis. In this paper, we design and implement WATERk, WCET analysis tool which deliberates on scheduling primitives of system using embedded Linux. WATERk can estimate WCET of both normal application tasks and corresponding primitives which influence the schedulability of embedded systems. Evaluation Results show that WATERk provides more reliable estimation results compared with traditional WCET tools.	embedded operating system;embedded system;worst-case execution time	Hansub Park;Jiman Hong;S. M. Yang	2008		10.1007/978-3-540-69839-5_58	embedded system;embedded operating system;real-time computing;computer science;operating system;worst-case execution time	Embedded	-23.81222087460285	37.067880649183984	142135
4c4a7959a5135fd525f8572505e1aeaaf0195159	non-stop haskell	continuation based evaluation;garbage collection;upper bound;binding time improvements;cps transformation of control flow information;continuation based partial evaluation;cps transformation of binding time information;glasgow haskell compiler	"""We describe an efficient technique for incorporating Baker's incremental garbage collection algorithm into the Spineless Tagless G-machine on stock hardware. This algorithm eliminates the stop/go execution associated with bulk copying collection algorithms, allowing the system to place an upper bound on the pauses due to garbage collection. The technique exploits the fact that objects are always accessed by jumping to code rather than being explicitly dereferenced. It works by modifying the entry code-pointer when an object is in the transient state of being evacuated but not scavenged. An attempt to enter it from the mutator causes the object to """"self-scavenge"""" transparently before resetting its entry code pointer. We describe an implementation of the scheme in v4.01 of the Glasgow Haskell Compiler and report performance results obtained by executing a range of applications. These experiments show that the read barrier can be implemented in dynamic dispatching systems such as the STG-machine with very short mutator pause times and with negligible overhead on execution time."""	algorithm;compiler;experiment;garbage collection (computer science);mutator method;overhead (computing);pointer (computer programming);run time (program lifecycle phase);star trek generations;the glorious glasgow haskell compilation system;transient state	Andrew M. Cheadle;Tony Field;Simon Marlow;Simon L. Peyton Jones;R. Lyndon While	2000		10.1145/351240.351265	parallel computing;real-time computing;computer science;upper and lower bounds;garbage collection;programming language;mark-compact algorithm	PL	-20.525146400066255	34.51066553273292	142424
38bfca1470e5c73696f6a0f24071478c48502a64	ice: circumventing meltdown with an advanced binary analysis framework	intermediate languages;extensibility;frameworks;instruction set architecture;intermediate language;intermediate representation	In this paper we propose ICE, an Integrated Comprehension Environment, designed to facilitate advanced binary analysis through an extensible framework. ICE makes extensive use of modules and a flexible intermediate representation to enable seamless integration of instruction set architectures, platforms, and analysis techniques.	intermediate representation;list comprehension;seamless3d	Dean Pucsek;Jonah Wall;Celina Berg;Jennifer Baldwin;Martin Salois;Yvonne Coady	2011		10.1145/1984708.1984731	computer architecture;parallel computing;real-time computing;computer science	EDA	-21.845012880520578	33.506146624776235	142450
f8576e7e176baa3a6899d4bd7d85533971bce09f	a sophisticate's introduction to distributed concurrency control (invited paper)	concurrency control		distributed concurrency control	Philip A. Bernstein;Nathan Goodman	1982			computer science;concurrency control;database;distributed computing;multiversion concurrency control;non-lock concurrency control;distributed concurrency control	AI	-25.78229021742853	45.382273897139825	142832
fe75f784445650f271a2ad8df31d3adf49294990	a new approach to collaborative frameworks using shared objects	shared objects;groupware;collaborative work;multi user graphical applications;object oriented toolkit;collaboration;maintenance engineering;object oriented programming;multi user;collaborative tools;single object instance;graphical user interfaces;object oriented toolkit collaborative frameworks shared objects multi user graphical applications interface objects display maintenance single object instance collaborative overheads shared object collaborative framework;object oriented;displays;multi access systems;interface objects;object oriented programming groupware multi access systems graphical user interfaces;informatics;collaborative frameworks;shared object collaborative framework;collaboration collaborative work collaborative tools object oriented modeling informatics maintenance engineering australia displays collaborative software java;object oriented modeling;australia;collaborative software;display maintenance;collaborative overheads;java	Multi-user graphical applications currently require the creation of a set of interface objects t o main ta in each participating display. T h e concept of shared objects allows a single object instance to be used in multiple contexts concurrently. This provides a novel way of reducing collaborative overheads by requiring the maintenance of only a single set of interface objects. This paper presents the concept of a shared-object collaborative framework and illustrates how the concept can be incorporated into a n existing object-oriented toolkit.	graphical user interface;library (computing);multi-user	Aaron Ceglar;Paul R. Calder	2001		10.1109/ACSC.2001.906617	human–computer interaction;computer science;database;distributed computing	HCI	-31.507114391449953	40.08517765280518	142845
5e28af9b37a67f306c456f3dc36a74b07e2457be	highly space-efficient self-stabilizing depth-first token circulation for trees		Self-stabilization was rst introduced by Dijkstra Dij74]: it is the property for a system to eventually recover itself a legitimate state after any perturbation modifying the memory state. Since Dijkstra original paper, the goal of many works has been to obtain self-stabilizing algorithms requiring the fewest possible number of states. A great deal of proposed algorithms are token circulations, very useful to solve distributed mutual exclusion. In every algorithm, the token is held by the processor enabled to make a move. Tchuente Tch81] showed that in such conditions, the expected state number lower bound to solve mutual exclusion over tree networks is 2 n Q n i=1 i , n is the number of processors, i is the neighbors number of each processor p i. In this paper, we use a weaker token formulation introduced by Villain Vil97]: a processor holds a token if it holds a particular state. This new light allows us to propose a self-stabilizing depth-rst token circulation for tree networks requiring fewer states than Tchuente's lower bound, i.e. (1 + 1) Q n i=2 ((i + 2) states only.	central processing unit;dijkstra's algorithm;mutual exclusion;self-stabilization	Franck Petit	1997			computer science;security token;depth-first search;distributed computing	Theory	-21.674002493156056	44.518916314780455	143074
eec80944d1c40d983c509a0c382c2bf0ae6007a9	a lightweight and portable approach to making concurrent failures reproducible	race condition;unit testing;data races;concurrent programs	Concurrent programs often exhibit bugs due to unintended interferences among the concurrent threads. Such bugs are often hard to reproduce because they typically happen under very specific interleaving of the executing threads. Basically, it is very hard to fix a bug (or software failure) in concurrent programs without being able to reproduce it. In this paper, we present an approach, called ConCrash, that automatically and deterministically reproduces concurrent failures by recording logical thread schedule and generating unit tests. For a given bug (failure), ConCrash records the logical thread scheduling order and preserves object states in memory at runtime. Then, ConCrash reproduces the failure offline by simply using the saved information without the need for JVM-level or OS-level support. To reduce the runtime performance overhead, ConCrash employs a static data race detection technique to report potential possible race conditions, and only instruments such places. We implement the ConCrash approach in a prototype tool for Java and experimented on a number of multi-threaded Java benchmarks. As a result, we successfully reproduced a number of real concurrent bugs (e.g., deadlocks, data races and atomicity violation) within an acceptable overhead.	atomicity (database systems);crash (computing);deadlock;experiment;forward error correction;java;lu decomposition;online and offline;operating system;overhead (computing);program slicing;prototype;race condition;run time (program lifecycle phase);scheduling (computing);software bug;space-time adaptive processing;thread (computing);unit testing	Qingzhou Luo;Sai Zhang;Jianjun Zhao;Min Hu	2010		10.1007/978-3-642-12029-9_23	parallel computing;real-time computing;computer science;distributed computing;race condition;unit testing;programming language	SE	-21.018109040852174	38.44581831016828	143252
084b30b319233a9a0cb5fd49323d26f107f765c8	refactoring kieker′s monitoring component to further reduce the runtime overhead		Kieker’s monitoring component is tuned for a low runtime overhead. Nevertheless, we recently identified potential for improvement. Unfortunately, we could utilize this potential only by refactoring major parts of its architecture. In this paper, we describe these changes and discuss their advantages. Moreover, we present an evaluation which shows that our changes reduce the runtime overhead to 17% in our setup while simultaneously having a complexity of only 73%.	blocking (computing);code refactoring;method (computer programming);non-blocking algorithm;overhead (computing);run time (program lifecycle phase)	Hannes Strubel;Christian Wulf	2016	Softwaretechnik-Trends			SE	-21.988523411570394	38.18866101483932	143384
76cbacfeab664480c436b919afc6355c4ea5fd87	is it time for real-time functional programming?	real time;functional programming;design and implementation;functional language;real time systems	This paper explores the suitability of functional languages for programming real-time systems. We study the requirements of real-time systems in general, outline typical language approaches for this domain, consider issues relating to memory and time usage and explore how all existing functional languages, including our own language Hume, match these requirements. We conclude by posing some research challenges that functional language designs and implementations must meet if they are to be regarded as suitable vehicles for realtime systems implementation.	code refactoring;correctness (computer science);formal verification;functional programming;garbage collection (computer science);higher-order function;hume (programming language);indeterminacy in concurrent computation;memory management;programmer;programming language implementation;real-time clock;real-time computing;real-time transcription;requirement;space–time tradeoff	Kevin Hammond	2003			declarative programming;programming domain;reactive programming;functional reactive programming;computer science;programming language implementation;extensible programming;functional logic programming;programming paradigm;procedural programming;symbolic programming;inductive programming;fifth-generation programming language;programming language;functional programming;purely functional	Embedded	-23.483081379749564	33.88605382945769	143517
5a1d73c1b7c5853bd091051cb0c95053a60f49fa	stabilization-preserving atomicity refinement	tolerancia falta;seguridad funcionamiento;ajustamiento modelo;surete fonctionnement;syntax;fault tolerant;functional properties;stabilization;modele lineaire;semantics;simultaneidad informatica;concurrent program;modelo lineal;syntaxe;semantica;semantique;atomicity refinement;exclusion mutual;mutual exclusion;ajustement modele;synchronisation;refinement method;concurrency;atomicity;estabilizacion;atomicite;synchronization;envoi message;model matching;fault tolerance;dependability;linear model;programa competidor;message passing;preservation;sincronizacion;stabilisation;exclusion mutuelle;methode raffinement;sintaxis;simultaneite informatique;metodo afinamiento;preservacion;tolerance faute;programme concurrent	Program re nements from an abstract to a concrete model empower designers to reason e ectively in the abstract and architects to implement e ectively in the concrete. For re nements to be useful, they must not only preserve functionality properties but also dependability properties. In this paper, we focus our attention on re nements that preserve the dependability property of stabilization. Speci cally, we present a stabilizationpreserving re nement of atomicity from an abstract model where a process can atomically access the state of all its neighbors and update its own state, to a concrete model where a process can only atomically access the state of any one of its neighbors or atomically update its own state. Our re nement is sound and complete with respect to the computations admitted by the abstract model, and induces linear step complexity and constant synchronization delay in the computations admitted by the concrete model. It is based on a bounded-space, stabilizing dining philosophers program in the concrete model, and is readily extended to: (a) solve stabilizationpreserving semantics re nement, (b) solve the stabilizing drinking philosophers problem, (c) solve fairness re nement problem, and (d) allow further re nement into a message-passing model.	atomicity (database systems);computation;dependability;dining philosophers problem;emoticon;fairness measure;message passing	Mikhail Nesterenko;Anish Arora	2002	J. Parallel Distrib. Comput.	10.1006/jpdc.2001.1828	synchronization;fault tolerance;combinatorics;parallel computing;real-time computing;computer science;operating system;mathematics;distributed computing;semantics;programming language;algorithm	Logic	-24.93145819114936	32.45781369977436	143571
cded580a4ba01888bc0f18b4526f40e6cb3327ed	uniform self-stabilizing orientation of unicyclic networks under read/write atomicity	distributed system	A distributed system is self-stabilizing if its behavior is correct reAbstract-1 gardless of its initial state. A ring is a distributed system in which all processors are connected in a cycle and each processor communicates directly with only its two neighbors. A ring is oriented when all processors have a consistent notion of their left and right neighbors. A ring is uniform when all processors run the same program and have no distinguishing attributes, such as processor IDs. A well-known selfstabilizing uniform protocol for ring orientation is that of [IJ93b]. For a ring of size n, this protocol will stabilize in expected O(n2) processor activations. This assumes that processors are scheduled by a distributed demon—one in which the communication registers between processors can be atomically updated (a read followed by a write), and the processors have the ability to make random choices. This paper generalizes the notion of orienting a ring to that of Abstract-2 orienting a unicyclic network, that is, a ring with trees attached. We present a very simple protocol for the self-stabilizing orientation of such unicyclic networks. It has the same expected O(n2) processor activation performance as the Israeli and Jalfon protocol for rings. But ours works under the more general scheduling assumption of a read/write demon—one in which a read or write of a communication register is atomic, but an update (a read followed by a write) is not. We similarly assume the ability to make random choices. A subresult of our protocol is a uniform self-stabilizing algorithm for the two processor token-passing problem under the read/write demon. 1 Chicago Journal of Theoretical Computer Science 1996-5 Hoover, Rudnicki Uniform Self-Stabilizing Orientation §1 Our protocol is uniform in the sense that all processors of the Abstract-3 same degree are identical. In addition, observations of the behavior of the protocol on an edge yield no information about the degree of the processors at the ends of the edge. 1 Self-Stabilization and Ring Orientation The prototypical distributed system is a collection of discrete-state machines 1-1 connected by a network. Such a system is self-stabilizing if it has the property that regardless of its current state, it will eventually enter and remain within a well-defined set of stable states, called the target set (or the safe or legitimate set). Although a longstanding notion in control theory, its first application to computing systems is generally credited to Dijkstra [Dij74, Dij86]. Dijkstra’s original paper was virtually ignored for a decade, with the ex1-2 ception of [Kru79]. It took almost another decade before there was sufficient material1 to warrant the survey by [Sch93]. Although our paper is selfcontained, we assume that the reader is familiar with the general perspective of self-stabilization as would be provided by Schneider’s survey. Two fundamental problems of self-stabilization are mutual exclusion 1-3 [AEY91, BGW89, BP89, CGR87, Dij74, Dij86, DIM93, Gho91, Her90, Her92, IJ90, Kes87, Kru79, Lam86a, Lam86b, LH91] and ring orientation [ASW88, HR91, IJ93b, SP87]. Mutual exclusion can be cast in terms of a token-passing problem, in which the privilege of entering the critical section is conferred by the possession of a token that is passed among the processors. Ring orientation is the problem of obtaining consensus among the processors for a consistent notion of left and right. That is, if processor A thinks its right neighbor is processor B, then processor B must think that its left neighbor is processor A. On a ring network topology, mutual exclusion and orientation are closely 1-4 related. For example, orienting a ring first, and then passing a token from left to right is one way to ensure fair exclusive access to a resource. On the other hand, if a token is being passed among processors in a ring, as it moves between processors it induces an orientation (call left the direction it arrives from, and right the direction it leaves). If the token ever arrives at a 1Self-stabilization is now an active research area, with a number of World Wide Web sites easily located by a search engine.	atomicity (database systems);central processing unit;consensus (computer science);control theory;critical section;cycle (graph theory);dijkstra's algorithm;distributed computing;mutual exclusion;network topology;pseudoforest;ring network;scheduling (computing);self-stabilization;theoretical computer science;web search engine;world wide web	H. James Hoover;Piotr Rudnicki	1996	Chicago J. Theor. Comput. Sci.		parallel computing;computer science;theoretical computer science;mathematics;distributed computing;algorithm	Theory	-21.121743773834723	45.46015564585583	143687
e6b3d127b129c0ad7c62ffaca2e709a925b6c5c7	adaptive time-based dispatching of distributed real-time tasks	real time		real-time transcription	Sameh M. Elsharkawy;Ashok K. Agrawala;Tamer Nadeem	2003				Embedded	-30.11699396579409	38.2852589881613	143817
3ff6d5acdfab238ccdd2d8f8086e07f34fd6f6db	automated protocol implementations based on activity threads	transition reordering automated protocol implementations activity threads automated mapping formal description semantic conflicts sdl compiler cocos performance gain;protocols;formal specification;protocols yarn signal processing gain measurement software measurement performance gain software performance testing specification languages software design;telecommunication computing;telecommunication computing protocols formal specification;formal description techniques;code generation tools;protocol implementation;automated protocol implementation;activity threads;sdl	In this paper we present a new approach for the automated mapping of formal descriptions into activity thread implementations. Our approach resolves semantic conflicts by reordering of statements at compile time. This simplifies the mapping process and considerably improves the efficiency of the generated code. The approach is implemented in the SDL compilerCOCOS. We describe the approach as well as its implementation and prove how semantic conflicts are resolved. Finally we present measurements which show the achieved performance gain.	cartography;compile time;compiler	Peter Langendörfer;Hartmut König	1999		10.1109/ICNP.1999.801910	communications protocol;parallel computing;real-time computing;computer science;operating system;formal specification;programming language;computer network	SE	-32.444426894381316	32.690966817812395	143927
27aef8913db5c2a471ba4e4f16c24a2bfe27b914	using model checking to debug device firmware	effective model checking;debugging support;model checker;model checking;abstract model;device firmware;debugging device firmware;debug vmmc firmware;esp compiler;spin model checker;race condition;operating system;network interface;software complexity	Device firmware is a piece of concurrent software that achieves high performance at the cost of software complexity. They contain subtle race conditions that make them difficult to debug using traditional debugging techniques. The problem is further compounded by the lack of debugging support on the devices. This is a serious problem because the device firmware is trusted by the operating system.Model checkers are designed to systematically verify properties of concurrent systems. Therefore, model checking is a promising approach to debugging device firmware. However, model checking involves an exponential search. Consequently, the models have to be small to allow effective model checking.This paper describes the abstraction techniques used by the ESP compiler to extract abstract models from device firmware written in ESP. The abstract models are small because they discard some of the details in the firmware that is irrelevant to the particular property being verified. The programmer is required to specify the abstractions to be performed. The ESP compiler uses the abstraction specification to extract models conservatively. Therefore, every bug in the original program will be present in the extracted model.This paper also presents our experience with using Spin model checker to develop and debug VMMC firmware for the Myrinet network interfaces. An earlier version of the ESP compiler yielded models that were too large to check for system-wide properties like absence of deadlocks. The new version of the compiler generated abstract models that were used to identify several subtle bugs in the firmware. So far, we have not encountered any bugs that were not caught by Spin.	compiler;concurrency (computer science);correctness (computer science);deadlock;debug;debugger;esp game;exponential search;firmware;java;model checking;operating system;programmer;programming complexity;race condition;relevance;spin model checker;software bug;state space	Sanjeev Kumar;Kai Li	2002		10.1145/1060289.1060296	model checking;parallel computing;real-time computing;computer science;network interface;operating system;race condition;programming language;computer security;programming complexity	OS	-21.74317918301883	32.393877183686854	143933
3b14728efcdbe5b8c3026809f85dbbb4e013d31a	using message-based threading for multimedia applications	yarn;application software;streaming video;multimedia application;sockets;multimedia systems;signal processing;yarn timing application software multithreading sockets computer science multimedia systems signal processing communication system control operating systems;computer science;communication system control;operating systems;multithreading;timing;time constraint	Components of a complex multimedia application typically work reactively processing events such as notifications from other threads, signals, and network packets. To better support these applications we have built a message-based threading platform providing more flexibilty than event handling with one thread and easier synchronisation than conventional multithreading approaches. Reuse and reconfiguration are facilitated by using a uniform message interface for all types of events. Moreover, scheduling can be based on timing constraints attached to messages rather than to threads. The reimplementation of a multi-stream video player shows the benefits of this approach.	event (computing);message passing;multithreading (computer architecture);scheduling (computing);thread (computing)	Rainer Koster;Thorsten Kramp	2001	IEEE International Conference on Multimedia and Expo, 2001. ICME 2001.	10.1109/ICME.2001.1237791	embedded system;application software;parallel computing;real-time computing;multithreading;computer science;operating system;signal processing;super-threading	Visualization	-31.84598318070454	38.35606455619077	143980
20d05ed3cbe6d1e602dc3aa4ddf50fc0b57d760c	generating the trace qualification configuration for mcds from a high level language	high level languages;program compilers;program debugging;program diagnostics;system-on-chip;infineon multicore debug solution;mcds enabled soc;high level compiler;high level language;trace qualification configuration	This paper introduces a high level trace qualification language and compiler which enables the user defining analysis tasks efficiently and fully utilize the powerful features of Infineon's Multi-Core Debug Solution (MCDS) without the need of getting into the internals. The language and the compiler are already in industrial use where software development is based on MCDS enabled SoCs to support the developers to achieve better product quality and shorter product development cicles.	compiler;debug;high-level programming language;multi-core processor;new product development;software development;system on a chip	Jens Braunes;Rainer G. Spallek	2009	2009 Design, Automation & Test in Europe Conference & Exhibition		system on a chip;embedded system;computer architecture;parallel computing;real-time computing;computer science;operating system;programming language;high-level programming language;statistics	EDA	-21.739062469208438	37.25474994700513	144118
837ad09b5a91d48cff479cd5d9bf1a325c2ed95f	faults in grids: why are they so bad and what can be done about it?	fault diagnosis;grid computing;software fault tolerance;computational grids;failure diagnosis;fault tolerance scheme;fault treatment;software replicas;distributed application;fault tolerant;middleware;team work	Computational Grids have the potential to become the main execution platform for high performance an d distributed applications. However, such systems are extremely complex and prone to failures. In this pa per, we present a survey with the grid community on whic h several people shared their actual experience regar ding fault treatment. The survey reveals that, nowadays, users have to be highly involved in diagnosing failures, that most failures are due to configuration problems (a hint of the area’s immaturity), and that solutions for deal ing with failures are mainly application-dependent. Goi ng further, we identify two main reasons for this stat e of affairs. First, grid components that provide high-l evel abstractions when working, do expose all gory detai ls when broken. Since there are no appropriate mechani sms to deal with the complexity exposed (configuration, middleware, hardware and software issues), users ne ed to be deeply involved in the diagnosis and correction of failures, when, in fact, all they want is to run th eir applications. One needs a way to coordinate differe nt support teams working at the grids different levels of abstraction. Second, fault tolerance schemes today implemented on grids tolerate only crash failures. Since grids are prone to more complex failures, such as heisenbugs, one needs to tolerate tougher failures. Our hope is that the very heterogeneity, that makes a g rid a complex environment, can help in the creation of di verse software replicas, a strategy that can tolerate mor e complex failures.	byzantine fault tolerance;component-based software engineering;computation;crash (computing);distributed computing;expect;heisenbug;middleware;principle of abstraction;test automation;verse protocol	Raissa Medeiros;Walfredo Cirne;Francisco Vilar Brasileiro;Jacques Philippe Sauvé	2003			fault tolerance;parallel computing;real-time computing;teamwork;computer science;operating system;middleware;distributed computing;software fault tolerance;grid computing	HPC	-24.707660815195375	45.3531819227295	144123
89898747020396630c5dce33fbdd5bbee30e2bdf	interception in the aroma system	benchmarking;distributed system;high availability;fault tolerant;java performance	Interceptors are software mechanisms that provide hooks that introduce additional services to an existing application, at runtime. We have developed interceptors for distr ibuted Java applications that are based on the Java RMI architecture. Our interceptors are novel in that they are external to the Java application, add minimal overhead to system operation, and are easy to deploy, requiring little or no modification to the application. In the Aroma System, we exploit these interceptors to introduce replication mechanisms to the Java runtime; these mechanisms can then be exploited to provide fault tolerance and high availability to the distributed system.	belief revision;common object request broker architecture;communications of the acm;design pattern;distributed computing;distributed object;fault tolerance;general inter-orb protocol;global file system;group communication system;hierarchical editing language for macromolecules;high availability;interceptor pattern;java remote method protocol;java remote method invocation;moser spindle;multicast;operating system;overhead (computing);rmi-iiop;run time (program lifecycle phase);sms language;user space;webserver directory index	Nitya Narasimhan;Louise E. Moser;P. M. Melliar-Smith	2000		10.1145/337449.337494	hydrology;geotechnical engineering	HPC	-32.44010607896259	44.37311000099655	144336
b88a099f5c9c2cfc75fee8b0aa8d0a28ad7f049b	self-stabilizing paxos		We present the first self-stabilizing consensus and replicated state machine for asynchronous message passing systems. The scheme does not require that all participants make a certain number of steps prior to reaching a practically infinite execution where the replicated state machine exhibits the desired behavior. In other words, the system reaches a configuration from which it operates according to the specified requirements of the replicated state-machine, for a long enough execution regarding all practical considerations. ∗Regular Paper, Eligible for Best Student Paper Award. The paper should also be considered for the Brief Announcement. †PhD student, LRI, University of Paris-Sud XI, Orsay, France. Email: blanchard@lri.fr ‡Dept. of Computer Science, Ben-Gurion Univ. of the Negev, Beer-Sheva, 84105, Israel. Email: dolev@cs.bgu.ac.il. Partially supported by Deutsche Telekom, Rita Altura Trust Chair in Computer Sciences, Intel, MFAT, MAGNET and Lynne and William Frankel Center for Computer Sciences. §LRI, University of Paris-Sud XI, Orsay, France. Email: jb@lri.fr ¶LRI, University of Paris-Sud XI, Orsay, France. Email: delaet@lri.fr ar X iv :1 30 5. 42 63 v1 [ cs .D C ] 1 8 M ay 2 01 3	computer science;email;finite-state machine;message passing;requirement;self-stabilization;stan frankel	Peva Blanchard;Shlomi Dolev;Joffroy Beauquier;Sylvie Delaët	2013	CoRR		parallel computing;real-time computing;computer science;distributed computing	Theory	-22.00010812344542	43.80251029567133	144351
e53673ce43a6b5fb3bd6055019cabbcae826bcd6	dataflow resource managers and their synthesis from open path expressions	computers;concurrent computing;memory management;distributed networks;probability density function;resource manager;resource management;automatic programming;data mining;functional programming;specification language;resource use;dataflow computers;distributed operating system;resource management operating systems functional programming concurrent computing automatic programming parallel processing control system synthesis centralized control memory management specification languages;operating system;data dependence;specification languages;control system synthesis;synchronization;data structures;execution environment;open path expressions;centralized control;switches;resource managers applicative programming concurrent access dataflow computers open path expressions operating systems parallel processing;programming;concurrent access;path expressions;parallel processing;resource managers;operating systems;applicative programming	The control of concurrent access to shared resources is an important feature of both centralized and distributed operating systems. In conventional systems, exclusive access is the rule while concurrent access is the exception. Dataflow computer systems, along with an applicative style of programming, provide an execution environment in which this philosophy is reversed. In these latter systems, it is necessary to reexamine the manner in which synchronization of access to shared resources is specified and implemented. A basic design for a dataflow resource manager is reviewed, illustrating the clear separation between access mechanism and scheduling policy. The semantics of the access mechanism is based solely on the principle of data dependency. Specifications are presented for a general scheduler to further constrain or order accesses to the resource. Using ``open path expressions'' as a very high-level specification language for synchronization, it is shown how to automatically synthesize a scheduler as a distributed network of communicating modules.	applicative programming language;centralized computing;concurrency control;data dependency;dataflow;distributed operating system;exception handling;high- and low-level;path expression;scheduling (computing);specification language	Arthur E. Oldehoeft;Steven F. Jennings	1984	IEEE Transactions on Software Engineering	10.1109/TSE.1984.5010233	synchronization;programming;probability density function;real-time computing;specification language;network switch;computer science;resource management;operating system;distributed computing;programming language;memory management	OS	-26.419440225987085	32.674035600749114	144554
4285124ce453ce838151c4dba96048a78cbcc72d	on the fly estimation of the processes that are alive/crashed in an asynchronous message-passing system	message passing system;distributed computing;asynchronous system;fault tolerant computing;message passing;on the fly;asynchronous message passing system;fault tolerant distributed computing;local clock based algorithm	It is well-known that, in an asynchronous system where processes are prone to crash, it is impossible to design a protocol that provides each process with the set of processes that are currently alive. Basically, this comes from the fact that it is impossible to distinguish a crashed process from a process that is very slow or with which communications are very slow. Nevertheless, designing protocols that provide the processes with good approximations of the set of processes that are currently alive remains a real challenge in fault-tolerant distributed computing. This paper proposes such a protocol. To that end, it considers a realistic computation model where the processes are provided with non-synchronized local clocks and a function alpha(). That function takes a local duration as a parameter, and returns an integer that is an estimate of the number of processes that can crash during that duration. A simulation-based experimental evaluation of the protocol is also presented. The experiments show that the protocol is practically relevant	approximation;asynchronous system;crash (computing);distributed computing;experiment;fault tolerance;message passing;model of computation;on the fly;simulation	Achour Mostéfaoui;Michel Raynal;Gilles Trédan	2006	2006 12th Pacific Rim International Symposium on Dependable Computing (PRDC'06)	10.1109/PRDC.2006.48	asynchronous system;message passing;real-time computing;telecommunications;computer science;theoretical computer science;operating system;distributed computing;programming language	Logic	-22.507672612891632	43.79569748670535	144739
addf8c9c9bd1023b2a5768b08d2368867cec202e	modeling component based embedded real-time systems			embedded system;real-time clock;real-time computing	Uwe Rastofer	2004				EDA	-30.04965860421463	38.13110469130501	144783
3e1fed977b125e0ffb42b618b90813a2ebce0d7a	the election problem in asynchronous distributed systems with bounded faulty processes	distributed system;consensus;systeme reparti;failure;detection panne;failure detection;transmision asincronica;sistema repartido;fracaso;consenso;failure detector;asynchronous transmission;asynchronous distributed system;transmission asynchrone;agreement problem;deteccion falla;echec	Determining the “weakest” failure detectors is a central topic in solving many agreement problems such as Consensus, Non-Blocking Atomic Commit and Election in asynchronous distributed systems. So far, this has been studied extensively for several of such fundamental problems. It is stated that Perfect Failure Detector P is the weakest failure detector to solve the Election problem with any number of faulty processes. In this paper, we introduce Modal failure detector M and show that to solve Election, M is the weakest failure detector to solve election when the number of faulty processes is less than ⌈n/2⌉. We also show that it is strictly weaker than P.		SeongHoon Park	2006		10.1007/11751649_8	real-time computing;consensus;computer science;asynchronous communication;distributed computing;chandra–toueg consensus algorithm;computer security;algorithm;failure detector	Theory	-21.96465456421415	43.84661436441083	144901
d0a7b4af3173ced5ba4145bad2c969049880fceb	univers: an attribute-based name server	base relacional dato;remote access;organization;white pages service;acceso remoto;server;sistema informatico;acces a distance;reseau ordinateur;annuaire;computer system;relational database;service;computer network;interfase;anuario;serveur;yearbook;interface;red ordenador;base donnee relationnelle;systeme informatique;organisation;organizacion;yellow pages service;servicio	Abstract#R##N##R##N#Univers is a generic attribute-based name server upon which a variety of high-level naming services can be built. This paper defines Univers' underlying attribute-based naming model. It also describes several aspects of its implementation and demonstrates how various naming services—including a global white-pages service, a local yellow-pages service and a conventional name-to-address mapper—can be built on top of Univers.		Mic Bowman;Larry L. Peterson;Andrey Yeatts	1990	Softw., Pract. Exper.	10.1002/spe.4380200406	telecommunications;computer science;organization;operating system;database;programming language;world wide web	ML	-27.855189666670192	44.39073056538225	145067
3832b6d8de2093accef89fcc1dd1c60c70e0f700	bounds on the time to reach agreement in the presence of timing uncertainty	distribution;network analysis management;message processing;networks;time complexity;uncertainty;distributed networks;agreements;real time;time;quantity;delivery;algorithms;upper and lower bounds;lower bound;problem solving	Upper and lower bounds are proved for the real time complexity of the problem of reaching agreement in a distributed network, in the presence of process failures and inexact information about time. It is assumed that the amount of (real) time between any two consecutive steps of any nonfaulty process is at least c1 and at most CZ; thus, C = c2/cl is a measure of the timing uncertainty. It is also assumed that the time for message delivery is at most d. Processes are assumed to fail by stopping, so that process failures can be detected by timeouts. Let T denote the worst-case time to detect a failure, i.e., the elapsed time between tlhe failure of some process p and the time when all correct processes determine that p has failed; a straightforward approach yields T roughly eqr.lid to Cd. Letting ~ denote the number of faults to be tolerated, a simple adaptation of an (~+ 1)-rownd syn●This work was supported by ONR contract NOOO14-85K-0168, by NSF grants CCR-8611442 and CCR-8915206, and by DARPA contracts NOO014-89-J-1988 and NooO1487-K-0825. ‘Department of Computer Science, Technion. Work performed while the author was at the Laboratory for Computer Science, MIT. ‘IBM Almaden Research Center. Work performed while on sabbatical at the Laboratory for Computer Science, MIT. ‘Laboratory for Computer Science, MIT. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the thle of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise , or to republish, requires a fee and/or specific permission. @ 1991 ACM 089791-397-3/91/0004/0359 $1.50 Nancy Lynch$ Larry Stockmeyer~ chronous agreement algorithm takes time (~+ l)T, or roughly (~+ l) Cd. The first principal result of this paper is an agreement algorithm in which the worst-case time T for a timeout is incurred at most once, yielding a running time of approximately 2ffi + T in the worst case, where 6 is an upper bound on the message delay that actually occurs in a given execution. This represents a significant reduction in -complexity in case C >> 1 or 6 << d. The second principal result is a lower bound of (~ – l)d + Cd on the running time of any agreement algorithm, for the case where 6 = d; this is close to the upper bound of 2fd + Cd for this case.	algorithm;best, worst and average case;haplogroup cz (mtdna);ibm notes;ibm research - almaden;larry stockmeyer;mit computer science and artificial intelligence laboratory;time complexity;timeout (computing)	Hagit Attiya;Cynthia Dwork;Nancy A. Lynch;Larry J. Stockmeyer	1991		10.1145/103418.103457	mathematical optimization;real-time computing;computer science;mathematics;distributed computing;upper and lower bounds;algorithm	Theory	-21.292639285434927	44.282720245711936	145556
909c07f1efcc17be04d5b88b71a018bfc62d70e3	lexically scoped distribution: what you see is what you get	distributed programs;dynamic linking;local community;process migration;type system	We define a lexically scoped, asynchronous and distributed π-calculus, with local communication and process migration. This calculus adopts the network-awareness principle for distributed programming and follows a simple model of distribution for mobile calculi: a lexical scope discipline combines static scoping with dynamic linking, associating channels to a fixed site throughout computation. This discipline provides for both remote invocation and process migration. A simple type system is a straightforward extension of that of the π-calculus, adapted to take into account the lexical scope of channels. An equivalence law captures the essence of this model: a process behavior depends on the channels it uses, not on where it runs.	asynchronous i/o;computation;distributed computing;distributed object communication;dynamic linker;process migration;remote procedure call;scope (computer science);turing completeness;type system;wysiwyg;π-calculus	António Ravara;Ana Gualdina Almeida Matos;Vasco Thudichum Vasconcelos;Luís M. B. Lopes	2003	Electr. Notes Theor. Comput. Sci.	10.1016/S1571-0661(05)80088-X	process migration;type system;computer science;theoretical computer science;distributed computing;programming language;algorithm	PL	-29.303631056094964	32.93000943148406	145635
f2fc5cd3d347ab4de750ccc395eb165f58dcdc3f	use of a functional programming model in fault tolerant parallel processing	error recovery;degradation;concurrent computing;fault tolerant parallel processing;fault tolerant;user interface;user interface remote procedure based programming fault masking functional programming fault tolerant parallel processing distributed checkpointing error recovery load balancing graceful degradation draper fault tolerant parallel processor fault detection;distributed checkpointing;distributed computing;functional programming;fault masking;system performance;checkpointing;fault tolerant computing;system recovery;draper fault tolerant parallel processor;fault detection;fault tolerance;graceful degradation;load management;load balancing;parallel computer;functional programming fault tolerance degradation load management user interfaces concurrent computing distributed computing checkpointing computer errors system performance;load balance;remote procedure based programming;user interfaces fault tolerant computing functional programming parallel processing system recovery;user interfaces;computer errors;parallel processing	In a fault-tolerant parallel computer, a functional programming model can facilitate distributed checkpointing, error recovery, load balancing, and graceful degradation. Such a model has been implemented on the Draper fault-tolerant parallel processor (FTPP). When used in conjunction with the FTPP's fault-detection and masking capabilities, this implementation results in a graceful degradation of system performance after faults. Three graceful degradation algorithms are presented. A user interface has been implemented which requires minimal cognitive overhead by the application programmer, masking such complexities as the system's redundancy, distributed nature, variable complement of processing resources, load balancing, fault occurrence, and recovery. This user interface is described and its use demonstrated. >	fault tolerance;functional programming;parallel computing;programming model	Richard E. Harper;Gail Nagle;Martin A. Serrano	1989		10.1109/FTCS.1989.105537	parallel computing;real-time computing;computer science;distributed computing	HPC	-24.15081558815814	41.67383804241621	145687
42abcaa592c77b96b4fa1f97839475cbe2941372	distributed agreement and its relation with error-correcting codes	tolerancia falta;distributed system;crash failure;consensus;error correcting code;systeme reparti;fault tolerant;averia franca;codigo corrector error;code theory;teoria conjunto;distributed computing;theorie ensemble;erroneous value;set theory;condition;sistema repartido;hamming distance;error correction code;coding theory;fault tolerance;distance hamming;calculo repartido;asynchronous distributed system;interactive consistency;agreement problem;panne franche;code correcteur erreur;calcul reparti;distancia hamming;tolerance faute	The condition based approach identifies sets of input vectors, called conditions, for which it is possible to design a protocol solving a distributed problem despite process crashes. This paper investigates three related agreement problems, namely consensus, interactive consistency, and k-set agreement, in the context of the condition-based approach. In consensus, processes have to agree on one of the proposed values; in interactive consistency, they have to agree on the vector of proposed values; in k-set agreement, each process decides on one of the proposed values, and at most k different values can be decided on. For both consensus and interactive consistency, a direct correlation between these problems and error correcting codes is established. In particular, crash failures in distributed agreement problems correspond to erasure failures in error correcting codes, and Byzantine and value domain faults correspond to corruption errors. It is also shown that less restrictive codes can be used to solve k-set agreement, but without a necessity proof, which is still an open problem.	code;consensus (computer science);error detection and correction;forward error correction	Roy Friedman;Achour Mostéfaoui;Sergio Rajsbaum;Michel Raynal	2002		10.1007/3-540-36108-1_5	fault tolerance;error detection and correction;computer science;artificial intelligence;theoretical computer science;machine learning;database;mathematics;distributed computing;computer security;algorithm;statistics;coding theory	Theory	-21.71906415065456	43.93252337859589	146318
83b7d659fc837a3b3b8b93ed0a975c3cd99314ec	a experimental investigation of software diversity in a fault-tolerant avionics application	hardware failures;fault tolerant;failure detection;real time;hardware fault tolerant sensor array software diversity fault tolerant avionics application failure detection and isolation hardware failures software design diversity algorithm diversity redundancy management software;fault tolerant avionics application;redundancy management software;software performance;software diversity;failure detection and isolation;fault tolerant computing;redundancy;software design diversity;fault detection;aerospace electronics;sensor array;performance gain;software algorithms;fault tolerant computing aerospace computer control aircraft instrumentation;software design;aircraft instrumentation;fault detection sensor arrays hardware software algorithms performance gain aerospace electronics real time systems software design software performance redundancy;algorithm diversity;sensor arrays;hardware fault tolerant sensor array;hardware;real time systems;aerospace computer control	Highly reliable and effective failure detection and isolation (FDI) software is crucial in modern avionics systems that tolerate hardware failures in real time. The FDI function is an excellent opportunity for applying the principal of software design diversity to the fullest, i.e., algorithm diversity, in order to provide gains in functional performance as well as potentially enhancing the reliability of the software. The authors examine algorithm diversity applied to the redundancy management software for a hardware fault-tolerant sensor array. Results of an experiment are presented that show the performance gains that can be provided by utilizing the consensus of three diverse algorithms for sensor FDI. >	avionics	Alper K. Caglayan;Paul R. Lorczak;Dave E. Eckhardt	1988		10.1109/RELDIS.1988.25781	reliability engineering;embedded system;fault tolerance;real-time computing;software sizing;software performance testing;computer science;software design;software reliability testing;redundancy;sensor array;fault detection and isolation;avionics software	HCI	-33.52452251037209	37.101916685821124	146375
503364f78e3555dfb90ca83948a018bc0b93849b	java bytecode transformations for efficient, portable cpu accounting	performance measure;java bytecode;resource control;resource manager;resource management;program transformation;denial of service attack;bytecode engineering;software component;j raf2;program transformations;runtime system;jraf2;java	Resource management is essential to build reliable middleware and to host potentially untrusted software components. Resource accounting allows to study and optimize program performance and to charge users for the resource consumption of their deployed components, while resource control can limit the resource consumption of components in order to prevent denial-of-service attacks. In the approach presented here, program transformations enable resource management in Java-based environments, even though the underlying runtime system may not expose information concerning the resource consumption of applications. We present a fully portable program transformation scheme to enhance standard Java runtime systems with mechanisms for CPU management. We implemented several optimizations in order to reduce the overhead of our CPU accounting scheme. Detailed performance measurements quantify this overhead and show the impact of various optimizations.	algorithm;central processing unit;component-based software engineering;denial-of-service attack;embedded system;high- and low-level;high-level programming language;java bytecode;middleware;operating system;overhead (computing);program transformation;programming model;runtime system;server (computing)	Walter Binder;Jarle Hulaas	2005	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2005.02.037	parallel computing;real-time computing;computer science;resource management;component-based software engineering;operating system;programming language;java;denial-of-service attack	OS	-23.34001906059145	39.16668694143984	146403
de9e5c401094bbe35e9420287b0db5aaabafe4b3	asynchronous monitoring of events for distributed cooperative environments	active databases;distributed databases;flexible manufacturing systems;groupware;knowledge based systems;object-oriented databases;specification languages;eca rules;gem;global event manager;sentinel;snoop;active dbmss;active oodbms;active databases;address space;asynchronous event detector;asynchronous event monitoring;cooperative problem solving environments;distributed cooperative environments;distributed event specification;distributed plan monitoring application;distributed setting;event specification;event specification language;event-condition-action rules;flexible manufacturing application;implementation considerations	Most of the work in active databases (event specification and detection) has concentrated on centralized environments. In other words, ECA rules are accepted and managed by active DBMSs within the same address space. However, cooperative problem solving environments are inherently distributed and heterogeneous; hence there is a need for supporting ECA (Event-Condition-Action) rules in a distributed setting. The paper analyzes the design and implementation considerations of an asynchronous event detector termed GEM (Global Event Manager) that can detect and communicate events along with their parameters in a distributed environment. The paper presents extension to the Snoop event specification language to accommodate distributed event specification and develops an architecture and its implementation in the context of the Sentinel active OODBMS. A distributed plan monitoring application and a flexible manufacturing application have been developed using the functionality and the system described in the paper		Sharma Chakravarthy;Hui Liao	2001			detector;real-time computing;specification language;computer science;knowledge-based systems;data mining;database;distributed computing;address space;programming language;distributed database;distributed computing environment	HPC	-27.30944370405461	46.07845951564702	146592
89ea34bf4da0f91d2f94aa9ac94a54ee78cb31e9	the sombrero single address space operating system prototype a testbed for evaluating distributed persistent system concepts and implementation	operating system	The Sombrero distributed single address space operating system prototype is currently being implemented. The prototype includes an emulation of CPU-resident protection hardware necessary to fully utilize the properties of a single address space. The primary objective of the Sombrero project is to demonstrate that software development costs are sharply reduced in a single address space environment with no reduction in performance. This paper presents Sombrero design decisions and implementation mechanisms developed in order to support protection, communication, resource access and control transfer across a very large persistent distributed address space. Included are changes to operating system architecture, evolution of programming types and a new approach to distributed consistency management in a single address space based-DSM system that is being integrated into the prototype.	application checkpointing;central processing unit;compiler;emulator;fault tolerance;linker (computing);programming complexity;programming language;prototype;single address space operating system;software development;systems architecture;testbed	Alan Skousen;Donald Miller	2000			embedded system;computer science;distributed computing;testbed;single address space operating system	HPC	-26.239034500595626	43.05107656594492	146684
5cda94704c1906b0529f69d3bf041ef8ec08a8c8	design issues of network enabled server systems for the grid	eficacia sistema;systeme client serveur;protocole transmission;client server architecture;architecture client serveur;sistema informatico;performance systeme;client server systems;computer system;grid middleware;network enabled servers;system performance;computer network;programming model;protocolo transmision;design guideline;reseau informatique;arquitectura cliente servidor;systeme informatique;systeme gestion base donnee;sistema gestion base datos;database management system;transmission protocol	Network Enabled Server is considered to be a good candidate as a viable Grid middleware, offering an easy-to-use programming model. This paper clarifies design issues of Network Enabled Server systems and discusses possible choices, and their implications, namely those concerning connection methodology, protocol command representation, security methods, etc. Based on the issues, we have designed and implemented new Ninf system v.2.0. For each design decision we describe the rationale and the details of the implementation as dictated by the choices. We hope that the paper serves as a design guideline for future NES systems for the Grid.	grid computing	Satoshi Matsuoka;Mitsuhisa Sato;Hidemoto Nakada;Satoshi Sekiguchi	2000		10.1007/3-540-44444-0_2	embedded system;computer science;operating system;computer performance;programming paradigm;world wide web;client–server model;computer network	HPC	-27.766123416796326	44.36197182304967	146785
d3e1b65356793e2290acffd198d58423e48c7ded	extension of the unified modeling language for mobile agents	mobile agents;analysis and design;software agents;intelligent agents;unified modeling language;agent technology;mobile agent;quality of service;distributed systems	Mobile agents gained immense attraction as a new programming concept for implementing distributed applications. However, up to now mobile agent programming has been mainly technology driven, with a focus on the implementation of mobile agent platforms and only small programming applications. In this chapter, we present an extension of the standard UML that provides language concepts for modeling mobility both in analysis and design phases. This extended version of UML is applied to the modeling of an advanced telecommunication system.	distributed computing;mobile agent;prototype;seamless3d;software development;unified modeling language	Cornel Klein;Andreas Rausch;Marc Sihling;Zhaojun Wen	2001		10.4018/978-1-930708-05-1.ch008	agent architecture;real-time computing;simulation;computer science;multi-agent system;mobile agent;distributed computing;intelligent agent	Robotics	-33.00770044415187	45.664211957748314	147208
063131cab7d3d4db868dcbd3b8318f871ae1189f	using ada in a service-ooriented architecture		One of the latest trends in software architecture is known as a Service-Oriented Architecture (SOA). This paper describes SOA briefly and one of the enabling technologies of SOA, namely the Enterprise Service Bus (ESB). The paper goes on to describe two ways in which Ada applications can be built as services in a SOA. The first method is to build the Ada code as a Dynamically Linked Library (DLL) and wrap it in Java code. The second method is to use the Ada Web Server (AWS) and build a direct interface to the Ada code that is needed to plug into the ESB.	ada;amazon web services;dynamic-link library;enterprise service bus;java;service-oriented architecture;service-oriented device architecture;software architecture;web server	Ricky E. Sward	2007		10.1145/1315580.1315596	embedded system;real-time computing;computer science;applications architecture;operating system;software engineering;service-oriented architecture;oasis soa reference model	SE	-33.31722781385407	42.7070888072434	147216
48b84141b312575ca2a1b603cfd1bf9f0ccbb149	an operational system for computer resource sharing	distributed data;protocols;distributed data base management;computer network;distributed operating system;operating system;resource sharing;computer resource sharing	Users and administrators of a small computer often desire more service than it can provide. In a network environment additional services can be provided to the small computer, and in turn to the users of the small computer, by one or more other computers. An operational system for providing such “resource sharing” is described; some “fundamental principles” are abstracted from the experience gained in constructing the system; and some generalizations are suggested.	computer;operating system;operational system	Bernard P. Cosell;Paul R. Johnson;J. H. Malman;Richard E. Schantz;J. Sussman;Robert H. Thomas;David C. Walden	1975		10.1145/800213.806524	shared resource;communications protocol;computer science;knowledge management;operating system;database;distributed computing;computer network programming	Networks	-25.857951421061447	46.07841992896506	147256
0d4e0622311229f41fb1ac73c3169fffc90deba6	implementing mixed criticality systems in ada	certification requirement;mixed criticality application;lower level;static schedulability analysis;necessary run-time mode change;mixed criticality system;run-time monitoring;non safety-critical;new feature;safety-critical embedded system	Many safety-critical embedded systems are subject to certification requirements. However, only a subset of the functionality of the system may be safety-critical and hence subject to certification; the rest of the functionality is non safety-critical and does not need to be certified, or is certified to a lower level. The resulting mixed criticality system offers challenges both for static schedulability analysis and run-time monitoring. This paper considers both of these issues and indicates how mixed criticality applications can be implemented in Ada. In particular, code is produced to illustrate how the necessary run-time mode changes can be supported. This support makes use of a number of the new features introduced into Ada 2005.	ada;criticality matrix;embedded system;mixed criticality;requirement;run time (program lifecycle phase);scheduling analysis real-time systems;self-organized criticality	Sanjoy K. Baruah;Alan Burns	2011		10.1007/978-3-642-21338-0_13	embedded system;real-time computing;engineering;operating system	Embedded	-23.906010003387212	37.200736445835936	147338
b44314020d228501c8e4b8ff91cc18e1e70666fd	system-level reliability analysis considering imperfect fault coverage		Safety-critical systems rely on redundancy schemes such as k-out-of-n structures which enable tolerance against multiple faults. These techniques are subject to Imperfect Fault Coverage (IFC) as error detection and recovery might be prone to errors or even impossible for certain fault models. As a result, these techniques may act as single points of failure in the system where uncovered faults might be overlooked and lead to wrong system outputs. Neglecting IFC in reliability analysis may lead to fatal overestimations in case of safety-critical applications. Yet, existing techniques that do consider IFC are overly pessimistic in assuming that the occurrence of an uncovered fault always results in a system failure. But often, in particular in complex systems with nested redundant structures, a fault that is not noticed by an inner redundancy scheme might be caught by an outer redundancy scheme. This paper proposes to automatically incorporate IFC into reliability models, i. e. Binary Decision Diagrams (BDDs), to enable an accurate reliability analysis for complex system structures including nested redundancies and repeated components. It also shows that IFC does not equally affect different redundancy schemes. Experimental results presented for applications in multimedia and automotive confirm that the proposed approach can analyze system reliability more accurately at an acceptable execution time and memory overhead compared to the underlying IFC-unaware technique.	binary decision diagram;complex system;complex systems;data recovery;error detection and correction;fault coverage;fault detection and isolation;fault model;fault tolerance;overhead (computing);reliability engineering;run time (program lifecycle phase);single point of failure	Faramarz Khosravi;Hananeh Aliee;Jürgen Teich	2017		10.1145/3139315.3141787	single point of failure;real-time computing;fault coverage;redundancy (engineering);complex system;computer science;error detection and correction;imperfect;binary decision diagram	SE	-22.381575700089513	40.46287480569251	147455
4641d20e0e7b10922efac2b217e04ad2697b0277	specification and analysis of soft real-time systems: quantity and quality	verification;soft real time system;real time systems algebra stochastic processes automata probability distribution delay clocks algorithm design and analysis discrete event simulation reachability analysis;fault tolerant;clocks;processor scheduling;discrete event simulation model;specification;simulation;formal methods;semantics;soft constraints;arbitrary probability distributions;soft real time;quantitative properties;automata;fault tolerant multiprocessor system specification soft real time systems process algebra soft constraints arbitrary probability distributions semantics stochastic automata quantitative properties on the fly generation discrete event simulation model symbolic technique classical reachability analysis;fault tolerant multiprocessor system;fault tolerant computing;stochastic processes;algebra;stochastic automata;soft real time systems;analytical method;probability distribution;performance analysis;reachabili ty;on the fly;symbolic technique;timed automata;multiprocessing systems;point of view;process algebra;on the fly generation;classical reachability analysis;algorithm design and analysis;reachability analysis;discrete event;delays;real time systems process algebra stochastic automata reachability analysis fault tolerant computing multiprocessing systems processor scheduling delays discrete event simulation;real time systems;discrete event simulation	This paper presents a process algebra for specifying soft real-time constraints in a compositional way. For these sof t constraints we take a stochastic point of view and allow arbitrary probability distributions to express delays of act ivities. The semantics of this process algebra is given in terms of stochastic automata, a variant of timed automata where clocks are initialised randomly and run backwards. To analyse quantitative properties, an algorithm is presente d for the on-the-fly generation of a discrete-event simulatio n model from a process algebra specification. On the qualitative side, a symbolic technique for classical reachabili ty analysis of stochastic automata is presented. As a result a unifying framework for the specification and analysis of quantitative and qualitative properties is obtained. We di scuss an implementation of both analytic methods and specify and analyse a fault-tolerant multi-processor system.	algorithm;automata theory;fault tolerance;multiprocessing;process calculus;randomness;real-time clock;real-time computing;real-time transcription;timed automaton	Pedro R. D'Argenio;Joost-Pieter Katoen;Ed Brinksma	1999		10.1109/REAL.1999.818832	probability distribution;algorithm design;fault tolerance;process calculus;real-time computing;verification;formal methods;computer science;theoretical computer science;discrete event simulation;distributed computing;semantics;automaton;specification	Embedded	-26.687079453504182	34.24275935624574	147516
39439c8fc74323a23e6423916bddd47fa4ba7afe	a linux-based implementation of a middleware model supporting time-triggered message-triggered objects	time triggered;kernel;programming environments;formal specification;programming environment;middleware kernel prototypes linux distributed computing object oriented modeling timing real time systems programming environments operating systems;system specification;prototypes;distributed computing;programming environments middleware linux real time systems formal specification object oriented programming;tmo programming;object oriented programming;operating system;linux operating system middleware model time triggered message triggered objects distributed real time systems tmo programming system specification windows programming environments;middleware;linux;middleware model;linux operating system;distributed real time systems;windows programming environments;object oriented modeling;time triggered message triggered objects;operating systems;real time systems;timing	Programming and composing deterministic distributed real-time systems is becoming increasingly important, yet remains difficult and error-prone. An innovative approach to such systems is the general-form timeliness-guaranteed design paradigm, which is the basis for the time-triggered message-triggered object (TMO) programming and system specification scheme. This approach was originally developed for Windows programming environments and operating systems. This paper describes the techniques needed to make TMO support the Linux operating system and reports the resulting performance characteristics.	cognitive dimensions of notations;commodity computing;high- and low-level;iteration;linux;linux;microsoft windows;middleware;operating system;programming paradigm;real-time computing;real-time locating system;scheduling (computing);software portability;thread (computing);user space	Stephen F. Jenks;K. H. Kim;Emmanuel Henrich;Yuqing Li;Liangchen Zheng;Moon-hae Kim;Hee Yong Youn;Kyung-Hee Lee;Dong-Myung Seol	2005	Eighth IEEE International Symposium on Object-Oriented Real-Time Distributed Computing (ISORC'05)	10.1109/ISORC.2005.2	embedded system;kernel;real-time computing;computer science;operating system;system requirements specification;middleware;formal specification;prototype;object-oriented programming;linux kernel	Embedded	-31.978898737047405	38.39201284806908	148216
19ce85cfbe3f0cb8873847ae360532fe0a9c5083	support of java api for the jhisc system	java api;object-oriented programming language;object-oriented system;object model;elemental object;jhisc runtime environment;jhisc api;jhisc system;jhisc core;hardware support delegate function;java program;application program interface;object oriented programming languages	This paper presents the evolution and improvement of the Java API (Application Programming Interface) for Java which used in jHISC Runtime Environment. The jHISC Running Environment is an object-based, single addressing execution environment, specially designed for running object-oriented programming languages such as Java. The jHISC core is a HISC-architecture processor created for executing Java programs. The jHISC API is designed for object-oriented systems to support object model inside jHISC. The jHISC API includes elemental objects such as jhisc.Object, jhisc.Integer and few redesigned objects such as jhisc.util.Vector, jhisc.util.Hashtable. The jHISC API is developed in order to take advantage of using jHISC core and provides a hardware support delegate function in the system.	application programming interface;java class library;list of java apis	Gary K. W. Hau;Anthony Shi-Sheung Fong;Mok Pak Lun	2003		10.1145/963600.963724	computer architecture;parallel computing;real-time computing;object model;application programming interface;computer science;operating system;programming language;object-oriented programming	HCI	-25.77653622712628	36.6942378201919	148295
dc7653e78ae51a61dc059e8a5088eb6ef7b0d4b7	a survey of desynchronization in a polychronous model of computation	synchronous programming;desynchronization;computer model;distributed computing;endochrony and isochrony;conceptual framework;embedded system;model of computation;gals design	The synchronous hypothesis arose in the late Eighties as a conceptual framework for the computeraided design of embedded systems. Along with this framework, the issue of desynchronization was simultaneously raised as the major topic of mapping the ideal communication and computation model of synchrony on realistic and distributed computer architectures. The aim of the present article is to survey the development of this topics in the particular yet promising model of one of the prominent environments that were build along these principles: Signal and its polychronous (synchronous multi-clocked) model of computation, before to give some hints and ideas about ongoing research addressing this issue.	clock rate;computer architecture;degree of isochronous distortion;embedded system;model of computation;performance	Julien Ouy	2006	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2005.05.040	computer simulation;model of computation;real-time computing;computer science;theoretical computer science;conceptual framework;distributed computing	EDA	-23.361241952746692	42.36193969477118	148658
10aac4932648f7e0d7b7bdb0156f65e238be1997	architecture-driven platform independent deterministic replay for distributed hard real-time systems	real time;embedded real time systems;testing;testability;hard real time system;cost effectiveness;design;evaluation;software product line;architecture	Distributed hard real-time systems have become a major component of many advanced technical products. Means to ensure their proper quality are thus of paramount importance. To ensure high quality software, besides preventive means also cost-effective techniques for defect removal are important. The later activity in practice includes testing in order to detect failures, subsequent diagnosis in order to pin down the observed failure to a defect, and finally the proper removal of the defect. In this chain of activities, finding the cause of a failure is often a rather difficult and long-winded undertaking. In the domain of embedded real-time systems the problem is even harder than in a standard environment because of the real-time behavior and hardware heterogeneity (development vs. target platform). Both renders the deterministic replay of faulty behavior a hard problem which today can only be addressed when a substantial amount of additional monitoring hardware is added to the system. The paper proposes to minimize the required additional hardware using an architecture-driven approach which exploits the high-level information available at the architectural level in order to achieve platform independent deterministic replay for distributed hard real-time systems at relative low cost.	display resolution;embedded system;high- and low-level;real-time clock;real-time computing;real-time locating system;rendering (computer graphics);software bug	Holger Giese;Stefan Henkler	2006		10.1145/1147249.1147253	testability;embedded system;design;real-time computing;simulation;engineering;architecture;evaluation	Embedded	-25.607025050481802	39.85000338602751	148723
0692b1655b4364d1252b75f63cd89415385665ed	transforming ada serving tasks into protected objects	ada;protected object;serving tasks;protected objects;transforming ada;transformation	Protected objects are new features of Ada 95 that overcome the limitations of tasks in Ada 83, support more efficient communication, and provide mutually exclusive access to shared data. Transforming large concurrent software systems, that were written in Ada 83, to software systems using protected objects would make maintenance easier and improve system performance dramatically. In this paper the semantics of rendezvous and protected objects is examined, a group of hypotheses is developed, an algorithm that transforms sewing tasks written in Ada 83 into protected objects in Ada 95 is presented, and finally an example is given to demonstrate applications of this algorithm.	ada;algorithm;software system	Bangqing Li;Baowen Xu;Huiming Yu	1998		10.1145/289524.289633	transformation;parallel computing;real-time computing;ada;computer science;programming language	SE	-26.135923730762922	40.03173129935483	148792
cd2d2ad347272d7af04d81f5daca74a44c5f4677	distributed system software design paradigm with application to computer networks	distributed system;system software software design application software large scale systems computer networks local area networks wide area networks software maintenance software performance system performance;design principle;systeme reparti;metodologia;software quality distributed systems large scale computer network local area networks wide area network distributed systems maintainability understandability system performance;software reliability computer networks distributed processing;protocole transmission;large scale computer network;system software;concepcion sistema;application software;software maintenance;understandability;distributed processing;reseau ordinateur;transmission message;system performance;methodologie;message transmission;software performance;computer networks;computer network;large scale;protocolo transmision;sistema repartido;system design;red ordenador;methodology;distributed systems;software design;software reliability;conception systeme;software quality;local area networks;local area network;wide area network;wide area networks;maintainability;large scale systems;transmision mensaje;transmission protocol	A paradigm for the system and software design of distributed systems is presented with application to an actual large scale computer network involving both local area networks and a wide area network. A number of design principles are offered with particular reference to how they can be applied to the design of distributed systems. The major contribution of this paper to the field of distributed systems is an explanation of how to make design decisions about distributed systems in a way which will enhance maintainability and understandability of the software and, at the same time, result in good system performance. Our aim is to recognize the implications for Software quality of various decisions which must be made in the process of specifying a distributed system.	distributed computing;programming paradigm;software design;software quality	Norman F. Schneidewind	1989	IEEE Trans. Software Eng.	10.1109/32.16601	local area network;reliability engineering;dce/rpc;real-time computing;computer science;systems engineering;software design;component-based software engineering;software development;software design description;operating system;software engineering;middleware;software construction;distributed computing;computer performance;distributed design patterns;resource-oriented architecture;software quality;software system	SE	-26.050369634491833	41.36579244571958	149051
6a6776c2ac8a2381a79c8e4f9a51f7e0fb871c73	extracting instruction semantics via symbolic execution of code generators	symbolic execution;instruction set semantics extraction;code generators	Binary analysis and instrumentation form the basis of many tools and frameworks for software debugging, security hardening, and monitoring. Accurate modeling of instruction semantics is paramount in this regard, as errors can lead to program crashes, or worse, bypassing of security checks. Semantic modeling is a daunting task for modern processors such as x86 and ARM that support over a thousand instructions, many of them with complex semantics. This paper describes a new approach to automate this semantic modeling task. Our approach leverages instruction semantics knowledge that is already encoded into today’s production compilers such as GCC and LLVM. Such an approach can greatly reduce manual effort, and more importantly, avoid errors introduced by manual modeling. Furthermore, it is applicable to any of the numerous architectures already supported by the compiler. In this paper, we develop a new symbolic execution technique to extract instruction semantics from a compiler’s source code. Unlike previous applications of symbolic execution that were focused on identifying a single program path that violates a property, our approach addresses the all paths problem, extracting the entire input/output behavior of the code generator. We have applied it successfully to the 120K lines of C-code used in GCC’s code generator to extract x86 instruction semantics. To demonstrate architecture-neutrality, we have also applied it to AVR, a processor used in the popular Arduino platform.	arm architecture;arduino;atmel avr;central processing unit;code generation (compiler);crash (computing);debugging;gnu compiler collection;input/output;llvm;symbolic execution;x86	Niranjan Hasabnis;R. Sekar	2016		10.1145/2950290.2950335	real-time computing;computer science;theoretical computer science;software engineering;programming language;operational semantics	SE	-21.927724629131568	37.51886458928206	149484
26f443cff6263459f0cfdae994cf5883c749593f	concurrent timed port automata.	asynchronous communication	We present a new and powerful class of automata which are explicitly concurrent and allow a very simple de nition of composition. The novelty of these automata is their time-synchronous message-asynchronous communication mechanism. Time synchrony is obtained by using a global clock. Message asynchrony is obtained by requiring the automata to react to every input. Explicit concurrency is obtained by marking each transition with a set of input and output messages. We compare these automata with a history based approach which uses the same communication mechanism and show that they are equivalent. Chapter	asynchronous i/o;automata theory;automaton;concurrency (computer science);input/output;item unique identification;message passing;multiversion concurrency control	Radu Grosu;Bernhard Rumpe	2014	CoRR		novelty;ω-automaton;asynchrony;asynchronous communication;timed automaton;input/output;mobile automaton;concurrency;real-time computing;computer science;distributed computing	Logic	-28.223842369767066	33.529207591313465	149521
9f9520bdbd5d91bbd35f46a88f8c1acfc0a693a7	a distributed infrastructure for metadata about metadata: the hdmm architectural style and portal-doors system	hierarchical authority;hdmm;distributed registrydirectory system;pds;iris dns system;mobile metadata;portal doors system;architectural style	Both the IRIS-DNS System and the PORTAL-DOORS System share a common architectural style for pervasive metadata networks that operate as distributed metadata management systems with hierarchical authorities for entity registering and attribute publishing. Hierarchical control of metadata redistribution throughout the registry-directory networks constitutes an essential characteristic of this architectural style called Hierarchically Distributed Mobile Metadata (HDMM) with its focus on moving the metadata for who what where as fast as possible from servers in response to requests from clients. The novel concept of multilevel metadata about metadata has also been defined for the PORTAL-DOORS System with the use of entity, record, infoset, representation and message metadata. Other new features implemented include the use of aliases, priorities and metaresources.	faceted classification;future internet;indirection;integrated development environment;iteration;open-source software;rational doors;recursion;semantic web;software project management	Carl Taswell	2010	Future Internet	10.3390/fi2020156	geospatial metadata;computer science;operating system;marker interface pattern;database;database catalog;internet privacy;metadata;world wide web;data element;meta data services;metadata repository	HPC	-31.447106475178476	45.90123369058915	149612
2a9dcd7704545acd22de014344dddfead20de362	the design and implementation of enterprise javabean (ejb) wrapper for legacy system	wrapping;new technology;investments;e business;object oriented component framework;cobol;software maintenance;prototypes;java wrapping sun prototypes costs computer architecture software maintenance software engineering investments object oriented modeling;software engineering;ejb wrapper;computer architecture;ibm cics cobol system enterprise javabean wrapper ejb wrapper legacy system world wide web e business object oriented component framework functionality slicing;design and implementation;object oriented;component framework;distributed object management;sun;program slicing distributed object management java cobol;enterprise javabean;world wide web;functionality slicing;program slicing;legacy system;object oriented modeling;ibm cics cobol system;java;enterprise javabean wrapper	Legacy Systems were customized by a large investment for many years, their program structure has become obsolete and deteriorated gradually. In addition, the pressure of applying the legacy systems to new technology and environment like Web is on the increase. As an example of an emerging trend in e-business, Sun provides an Enterprise JavaBean (EJB) which is a kind of an object-oriented component framework written in Java. EJB is a suitable framework in heterogeneous and distributed Web environment. In this paper, we propose a Legacy Wrapper Model for Enterprise JavaBean(EJB) component wrapping of the legacy systems which are written in COBOL by the functionality slicing. And then we design and implement a component wrapping prototype tool that connects a legacy system framework of IBM CICS COBOL System to EJB framework.	cobol;customer information control system (cics);electronic business;enterprise javabeans;heterogeneous computing;java;legacy system;prototype;structured programming;wrapping (graphics)	Moon Soo Lee;Seok-Gyoo Shin;Young-Jong Yang	2001		10.1109/ICSMC.2001.973686	program slicing;computer science;electronic business;database;prototype;cobol;programming language;object-oriented programming;software maintenance;java;legacy system	SE	-33.575388958228636	42.402444897128596	149679
cc5df0f5f5875018fde621603dbfac5180090276	a formal model of anonymous systems	cluster computing;failure detector;consensus problem	We put forward a formal model of anonymous systems. And we concentrate on the anonymous failure detectors in our model. In particular, we give three examples of anonymous failure detectors and show that • they can be used to solve the consensus problem; • they are equivalent to their classic counterparts. Moreover, we show some relationship among them and provide a simple classification of anonymous failure detectors. Some proofs are in the appendix. Email: danielliy@gmail.com. Department of Computer Science and Engineering, The Chinese University of Hong Kong.)	consensus (computer science);email;formal language;sensor	Yang D. Li	2011	CoRR		consensus;computer cluster;computer science;distributed computing;world wide web;computer security;failure detector	Security	-22.05633982253384	43.48373326056918	149723
84fe9ce455b0b39d0629881c80bc778537fb8e57	the sybase open server	sybase open server	The talk will consist of a technical overview of the Sybase Open Server. There will also be a discussion of how the Open Server fits into the overall Sybase client/server mchitecture. Examples of Open Server usage will be included as well as a description of the Sybase CICS gateway which is built on top of Open Server. The Open Server is a programming library which is the server-side component of the Sybase clientkrver distributed architecture that allows users to write custom servers. The Open Server consists of a server component which makes the application look like a Sybase server in terms of communication and protocol. It also provides multi-threading services such as thread creation, scheduling, inter-thread communication and shared resource management. The Open Server is used by Sybase customers to provide gateways to dbms &@ proprietary filebascd da@ and shared memory data. It is rdso used to provide a gateway to external services such as encryption, extended mathematical computation, and applications, e.g., e-mail. These services can be included in a Sybase SQL Server trigger or stored procedure. Included will be a technical description of how Sybase remote procedure calls are used to implement these applications. The Sybase CICS gateway is a product built on top of the Open Server library. It allows any Sybase client or SQL Server to execute static CICS transactions and dynamic DB2 SQL on the IBM mainframe. The talk will include an overview of the network components, including LU6.2, as well as the client and server components that make up the gateway.	adaptive server enterprise;client–server model;computation;customer information control system (cics);distributed computing;email;encryption;fits;ibm lu6.2;inter-process communication;library (computing);mainframe computer;microsoft sql server;remote procedure call;scheduling (computing);server (computing);server-side;shared memory;stored procedure;thread (computing)	Paul Melmom	1992		10.1145/130283.130344	computer science;database	OS	-31.673369589356614	42.412298446910185	150087
323382736ae5e9838dec311f7d16c3a07444cb7c	development of a class of distributed termination detection algorithms	distributed system;incremental development;message counting;systeme reparti;self organizing data structure;termination detection;message communication;efficient algorithm;first in first out;distributed processing;reseau ordinateur;deadlock detection;distributed computing;detection terminaison;indexing terms;computer network;detection algorithms distributed algorithms algorithm design and analysis distributed computing computer networks design methodology network topology change detection algorithms data structures system recovery;system recovery data structures distributed processing;message communications;sistema repartido;system recovery;detection interblocage;distributed environment;data structures;algorithme reparti;connectivity distributed termination detection algorithms self organizing data structure distributed environment message counting message communications;red ordenador;communication message;self organization;algoritmo repartido;connectivity;distributed algorithm;data structure;distributed termination detection algorithms;design methodology	Accessing and updating information in a self organizing data structure in a distributed environment requires execution of various distributed algorithms. Design of such algorithms is often facilitated by the use of a distributed termination detection algorithm superimposed on top of another distributed algorithm. The problem of distributed termination detection is considered, and message counting is introduced as an effective technique in designing such algorithms. A class of efficient algorithms, based on the idea of message counting, for this problem is presented. After termination has occurred, it is detected within a small number of message communications. These algorithms do not require the FIFO (first in, first out) property for the communication lines. Assumptions regarding the connectivity of the processes are simple. The algorithms are incrementally developed, i.e. a succession of algorithms leading to the final algorithms is presented. >	algorithm	Devendra Kumar	1992	IEEE Trans. Knowl. Data Eng.	10.1109/69.134251	randomized algorithms as zero-sum games;distributed algorithm;probabilistic analysis of algorithms;real-time computing;self-organization;index term;data structure;design methods;fifo and lifo accounting;computer science;connectivity;theoretical computer science;iterative and incremental development;database;distributed computing;deadlock prevention algorithms;distributed computing environment	DB	-21.476167626135005	42.83879451804428	150137
c4f08d5cb201478d60ee39732a5f8706fc7950e1	a programming model for the automatic construction of usn applications based on nano-qplus	modelizacion;distributed system;reseau capteur;routeur;systeme reparti;calculateur embarque;echelle nanometrique;monitoring control system;programacion automatica;detail level;pervasive computing;systeme controle commande;automatic programming;sistema control mando;automatic generation;sensor network;niveau detail;programming model;informatica difusa;modelisation;red sensores;sistema repartido;informatique diffuse;boarded computer;sensor array;nanometer scale;router;modeling;calculador embarque;programmation automatique;nivel detalle	A programming model for the automatic construction of USN applications based on Nano-Qplus is proposed in this paper. Nano-Qplus is a sensor network platform developed by ETRI. Programs of nodes such as sensors, routers, sinks and actuators in a sensor network are automatically generated through the technique of this paper. Developers can implement USN applications from models of sensor networks. The configuration information of each node is automatically generated from a model. Then, the execution code is automatically generated using the configuration information. Through the technique of this paper, developers can easily implement USN applications even if they do not know the details of low-level information. The development effort of USN applications also will be decreased because execution codes are automatically generated. Furthermore, developers can consistently construct USN applications from USN models using the proposed tool.	algorithm;automatic programming;code;code generation (compiler);gnu nano;high- and low-level;programming model;router (computing);sensor	Kwangyong Lee;Woojin Lee;Juil Kim;Kiwon Chong	2006		10.1007/11802167_16	embedded system;real-time computing;systems modeling;wireless sensor network;human–computer interaction;computer science;operating system;machine learning;distributed computing;programming paradigm;programming language;ubiquitous computing;sensor array	Mobile	-29.14719072999865	41.08412054471819	150400
1383895f11d9bbe7dcc11a3af0e83755ab778481	symbolic execution and timed automata model checking for timing analysis of java real-time systems	signal image and speech processing;circuits and systems;control structures and microprogramming;electronic circuits and devices	This paper presents SYMRT, a tool based on a combination of symbolic execution and real-time model checking for timing analysis of Java systems. Symbolic execution is used for the generation of a safe and tight timing model of the analyzed system capturing the feasible execution paths. The model is combined with suitable execution environment models capturing the timing behavior of the target host platform including the Java virtual machine and complex hardware features such as caching. The complete timing model is a network of timed automata which directly facilitates safe estimates of worst and best case execution time to be determined using the UPPAAL model checker. Furthermore, the integration of the proposed techniques into the TETASARTS tool facilitates reasoning about additional timing properties such as the schedulability of periodically and sporadically released Java real-time tasks (under specific scheduling policies), worst case response time, and more.	automata theory;best, worst and average case;cache (computing);java virtual machine;model checking;real time java;real-time clock;real-time computing;real-time locating system;response time (technology);run time (program lifecycle phase);scheduling (computing);static timing analysis;symbolic execution;timed automaton;uppaal	Kasper Søe Luckow;Corina S. Pasareanu;Bent Thomsen	2015	EURASIP J. Emb. Sys.	10.1186/s13639-015-0020-8	embedded system;parallel computing;real-time computing;computer science;operating system;programming language	Embedded	-23.372601010193144	36.511826909847116	150981
92506731d1e8bf1e8d20820778d083f05968b0ec	safer: system-level architecture for failure evasion in real-time applications	carnegie mellon university safer system level architecture failure evasion real time applications distributed embedded real time systems hard real time systems hardware replication techniques configurable task level fault tolerance features fail stop processor task failures time based failure detection event based failure detection ubuntu 10 04 lts boss award winning autonomous vehicle;libraries;cold standby fault tolerance real time task level replication distributed embedded hot standby;task level replication;real time;distributed processing;real time systems timing fault tolerance fault tolerant systems libraries heart beat computer architecture;software fault tolerance;mobile robots;computer architecture;embedded systems;fault tolerant systems;fault tolerance;vehicles distributed processing embedded systems mobile robots software fault tolerance;hot standby;cold standby;vehicles;embedded;distributed;heart beat;real time systems;timing	Recent trends towards increasing complexity in distributed embedded real-time systems pose challenges in designing and implementing a reliable system such as a self-driving car. The conventional way of improving reliability is to use redundant hardware to replicate the whole (sub)system. Although hardware replication has been widely deployed in hard real-time systems such as avionics, space shuttles and nuclear power plants, it is significantly less attractive to many applications because the amount of necessary hardware multiplies as the size of the system increases. The growing needs of flexible system design are also not consistent with hardware replication techniques. To address the needs of dependability through redundancy operating in real-time, we propose a layer called SAFER(System-level Architecture for Failure Evasion in Real-time applications) to incorporate configurable task-level fault-tolerance features to tolerate fail-stop processor and task failures for distributed embedded real-time systems. To detect such failures, SAFER monitors the health status and state information of each task and broadcasts the information. When a failure is detected using either time-based failure detection or event-based failure detection, SAFER reconfigures the system to retain the functionality of the whole system. We provide a formal analysis of the worst-case timing behaviors of SAFER features. We also describe the modeling of a system equipped with SAFER to analyze timing characteristics through a model-based design tool called SysWeaver. SAFER has been implemented on Ubuntu 10.04 LTS and deployed on Boss, an award-winning autonomous vehicle developed at Carnegie Mellon University. We show various measurements using simulation scenarios used during the 2007 DARPA Urban Challenge. Finally, we present a case study of failure recovery by SAFER when node failures are injected.	autonomous car;autonomous robot;avionics;best, worst and average case;darpa grand challenge (2007);dependability;design tool;driving simulator;elegant degradation;embedded system;evasion (network security);fail-stop;fault tolerance;hot spare;real-time clock;real-time computing;real-time transcription;self-replicating machine;simulation;systems design;ubuntu version history	Junsung Kim;Gaurav Bhatia;Ragunathan Rajkumar;Markus Jochim	2012	2012 IEEE 33rd Real-Time Systems Symposium	10.1109/RTSS.2012.74	mobile robot;embedded system;hot spare;fault tolerance;real-time computing;simulation;computer science;operating system;software fault tolerance	Embedded	-33.40944705783168	37.391065578779376	151052
737750ba03650e98bb64a7cc0156b100687348c1	software reliability via run-time result-checking	debugging;built in testing;fault tolerant;fourier transform;concurrent error detection;real time;reliability function;fault tolerance;built in test;linear transformation;self correcting;profitability;result checking;software reliability	We review the field of result-checking, discussing simple checkers and self-correctors. We argue that such checkers could profitably be incorporated in software as an aid to efficient debugging and enhanced reliability. We consider how to modify traditional checking methodologies to make them more appropriate for use in real-time, real-number computer systems. In particular, we suggest that checkers should be allowed to use stored randomness: that is, that they should be allowed to generate, preprocess, and store random bits prior to run-time, and then to use this information repeatedly in a series of run-time checks. In a case study of checking a general real-number linear transformation (e.g., a Fourier Transform), we present a simple checker which uses stored randomness, and a self-corrector which is particularly efficient if stored randomness is employed.	debugging;preprocessor;randomness;real-time computing;real-time transcription;software quality;software reliability testing	Hal Wasserman;Manuel Blum	1997	J. ACM	10.1145/268999.269003	fault tolerance;real-time computing;computer science;theoretical computer science;mathematics;programming language;algorithm	Theory	-22.98897739446899	40.93320953878519	151201
54f9e0b77af887ae8340ad34d19d238a588d67ce	toward automatic and objective evaluation of synchronization in synchronized diving video				Yixin Du;Xin Li	2018		10.2352/ISSN.2470-1173.2018.2.VIPC-205	real-time computing;synchronization;computer science	Vision	-30.07942959941221	38.094859043943586	151464
e227a848f605342960beedf9e2e731c9449923ae	plumbing and other utilities	user interface;data exchange;drag and drop;inter process communication	Plumbing is a new mechanism for interprocess communication in Plan 9, specifically the passing of messages between interactive programs as part of the user interface. Although plumbing shares some properties with familiar notions such as cut and paste, it offers a more general data exchange mechanism without imposing a particular user interface. The core of the plumbing system is a program called the plumber, which handles all messages and dispatches and reformats them according to configuration rules written in a special-purpose language. This approach allows the contents and context of a piece of data to define how it is handled. Unlike with drag and drop or cut and paste, the user doesn’t need to deliver the data; the contents of a plumbing message, as interpreted by the plumbing rules, determine its destination. The plumber has an unusual architecture: it is a language-driven file server. This design has distinct advantages. It makes plumbing easy to add to an existing, Unix-like command environment; it guarantees uniform handling of inter-application messages; it offloads from those applications most of the work of extracting and dispatching messages; and it works transparently across a network.	cut, copy, and paste;drag and drop;dynamic dispatch;file server;inter-process communication;left 4 dead 2;plan 9 from bell labs;server (computing);unix;unix-like;user interface	Rob Pike	2000			data exchange;embedded system;real-time computing;computer science;operating system;user interface;computer security;inter-process communication	PL	-29.170623509703617	36.78760423118663	151611
6da0afddec4a359a7517fee6f3f5f78f482faecc	an evaluation of the java-based approaches to web database access	remote access;support construction;evaluation performance;base donnee;acceso remoto;performance evaluation;red www;web databases;evaluacion prestacion;acces a distance;database;cooperative information system;base dato;mobile agent technology;corba;appui;internet;conexion;remote method invocation;raccordement;applet jdbc;world wide web;reseau www;java rmi;information system;apoyo;connection;systeme information;sistema informacion	Given the undeniable popularity of the Web, providing efficient and secure access to remote databases using a Web browser is crucial for the emerging cooperative information systems and applications. In this paper, we evaluate all currently available Java-based approaches that support persistent connections between Web clients and database servers. These approaches include Java applets, Java Sockets, Servlets, Remote Method Invocation, CORBA, and mobile agents technology. Our comparison is along the important parameters of performance and programmabil ity.	common object request broker architecture;database server;http persistent connection;information system;interaction;java applet;java remote method invocation;java servlet;kilobyte;mobile agent;mobile computing;requirement;scalability;web application;world wide web	Stavros Papastavrou;Panos K. Chrysanthis;George Samaras;Evaggelia Pitoura	2000		10.1007/10722620_9	java api for xml-based rpc;web modeling;the internet;web-based simulation;connection;computer science;operating system;common object request broker architecture;web navigation;web page;database;distributed computing;real time java;java;world wide web;computer security;information system;java annotation	Web+IR	-29.467118458797408	43.50733869590589	151700
61918043093ac64918fb71deeeb5fb3c3deb74c2	operating system development with ats: work in progress	programming language;practical reasoning;linear types;operating system;dependent types;work in progress;type system;operating systems	Typical operating system design is marked by trade-offs between speed and reliability, features and security. Most systems are written in a low-level untyped programming language to achieve optimal hardware usage and for other practical reasons. But, this often results in CPU, memory, and I/O protection flaws due to mistakes in unverified code. On the other hand, fully verified systems are exceedingly hard to construct on any industrial scale. A high-level programming language, with an expressive type system suitable for systems programming, can help alleviate many of these problems without requiring the enormous effort of full verification.	ats;central processing unit;high- and low-level;high-level programming language;input/output;operating system;system programming;systems design;type system	Matthew Danish;Hongwei Xi	2010		10.1145/1707790.1707793	practical reason;embedded operating system;real-time computing;dependent type;type system;computer science;theoretical computer science;work in process;programming paradigm;programming language;system programming;algorithm	OS	-21.655241224179843	32.716066110702236	151731
e182b3c11d7595db3f578172c1bccb3303e84c88	a microprogrammed interpreter for the personal sequential inference machine			microcode	Minoru Yokota;Akira Yamamoto;Kazuo Taki;Hiroshi Nishikawa;Shunichi Uchida;Katsuto Nakajima;Masaki Mitsui	1984			computer architecture;computer science;inference;interpreter	NLP	-22.186900226305973	33.58487222202819	151799
2e239b8624f0e412a5917cb52623502a3cca0fdb	a common multi-platform hardware object model	object oriented design;code reuse;operating system;object model	About 5 years ago one group in IBM's high-end server system started a redesign of its hardware access layer. Flexibility for any kind of configuration and hardware was the main goal for the design, to allow for rapid bring up changes and changing hardware packaging. Object-oriented design was the obvious choice.About 2 years ago another group in IBM's middle and low end server systems started a redesign of their hardware access layer. The same basic objectives as the high-end systems applied. Additionally the middle and low-end systems group was continuing the consolidation of its servers to one eServer with a common service processor.Both hardware platforms are multi-processor systems supporting terabytes of I/O and a multitude of operating systems from z/OS and OS/400 to AIX and Linux.Everything cried for reuse.This paper is not so much about the final design as it is the challenges of a major object-oriented design affecting many components and attempting code reuse between different projects on different hardware in different organizations and different development sites including different countries. We will list the goals we had, what we ended up with, what proved to be good concepts and what the roadblocks were. The paper ends with an outlook on what we will approach next.	aix;code reuse;ibm eserver;ibm i;input/output;linux;microsoft outlook for mac;multiprocessing;operating system;semiconductor consolidation;server (computing);terabyte;z/os	Joe Armstrong;Astrid Kreissig	2002		10.1145/604251.604256	hardware compatibility list;real-time computing;simulation;object model;computer science;object-oriented design;programming language	OS	-32.70144211853438	42.59263468216876	151884
91d1c429088b6e1ef9e03421d04fd71470d755fe	ircs – infra red code system: access to infra red codes for ambient and assisted living	aide handicape;handicapped aid;consumidor;environmental control systems;ayuda minusvalido;interfase usuario;red www;user interface;consommateur;reseau web;consumer electronics;infra red;calculo ambiente;user assistance;calcul ambiant;assisted living;assistance utilisateur;internet;consumer;asistencia usuario;web based system;world wide web;ambient calculus;interface utilisateur	This paper presents a prototype of a web based system which allows to upload and to share infra red codes for consumer electronic devices support or automate the integration of the interface of these devices in an accessible user interface i.e. in Environmental Control Systems	code	Klaus Miesenberger;Gerhard Nussbaum;Martin Bartsch;Thomas Mayrhofer;Christoph Strobl-Mairhofer	2006		10.1007/11788713_73	ambient calculus;embedded system;the internet;infrared;consumer;telecommunications;computer science;operating system;environmental control system;programming language;user interface;world wide web	Networks	-30.2458848425822	43.64287130675939	151900
1fff9a8499bd8e4467a6bd1751dd8b38d05a415d	a high-level semantics for program execution under total store order memory		Processor cores within modern multicore systems often communicate via shared memory and use (local) store buffers to improve performance. A penalty for this improvement is the loss of Sequential Consistency to weaker memory guarantees that increase the number of possible program behaviours, and hence, require a greater amount of programming effort. This paper formalises the effect of Total Store Order (TSO) memory — a weak memory model that allows a write followed by a read in the program order to be reordered during execution. Although the precise effects of TSO are well-known, a high-level formalisation of programs that execute under TSO has not been developed. We present an interval-based semantics for programs that execute under TSO memory and include methods for fine-grained expression evaluation, capturing the non-determinism of both concurrency and TSO-related reorderings.		Brijesh Dongol;Oleg Travkin;John Derrick;Heike Wehrheim	2013		10.1007/978-3-642-39718-9_11	parallel computing;computer science;database;programming language;load/store architecture	Logic	-20.110165451061665	33.55307841984022	152025
313f8076ccb11ee76b3fbe95ba3fca014460a844	predicting concurrent computer system performance using petri-net models	loop invariants;automatic programming;program synthesis;program correctness	A method for efficiently employing Petri-Net models to predict performance of concurrent computer architectures is presented. The feasibility of such methods for use as architectural design tools is demonstrated, and the model's properties are discussed.	computer architecture;concurrency (computer science);petri net;software architecture	L. A. Cox	1978		10.1145/800178.810160	program analysis;computer architecture;real-time computing;computer science;programming language	EDA	-24.884330188015152	34.44001189793927	152094
e732b7f15ad26859a213231ce54cd13aaed441d8	office work coordination using a distributed database system	distributed database system	The office system ProMlnanD supports cooperative office work by electronic circulation folders. Based on both, an abstract description of office tasks in terms of work steps, and knowledge of the organizational structure, a folder navigates through an organization from one office worker in charge to the next. Deviations from predefined cooperation procedures are supported by extensive exception handling. The system uses widely information kept in databases and being distributed over the network. Data structures and the mechanisms controlling the migration are discussed. The resolving of addresses and references is supported by an extended slot mechanism. Due to the distributed transaction concept the folder migration is secure and the distributed databases are consistent. -------------------------------------------This paper is an outcome of the Project ProMInanD Extended Office Process Migration with Interactive Panel Displays. ProMinanD is supported in part by ESPRIT European Strategic Programme for Research and Development in Infromation	distributed database;distributed transaction;exception handling;process migration	Bernhard Karbe;Norbert Ramsperger;Pavel Vogel	1991			real-time computing;database server;computer science;database;distributed computing;distributed database	DB	-27.18761444440676	46.18951596672563	152098
34af84180c0fb3596381fb5439a05f85f2f4593e	operational characterization of weak memory consistency models		To improve their overall performance, all current multicore and multiprocessor systems are based on memory architectures that allow behaviors that do not exist in interleaved (sequential) memory systems. The possible behaviors of such systems can be described by so-called weak memory consistency models. Several of these models have been introduced so far, and different ways to specify these models have been considered like axiomatic or view-based formalizations which have their particular advantages and disadvantages. In this paper, we propose the use of operational/architectural models to describe the semantics of weak memory consistency models in an operational, i.e., executable way. The operational semantics allow a more intuitive understanding of the possible behaviors and clearly point out the differences of these models. Furthermore, they can be used for simulation, formal verification, and even to automatically synthesize such memory systems.	consistency model;correctness (computer science);operational semantics;quartz (graphics layer);synchronous programming language	Maximilian Senftleben;Klaus Schneider	2018		10.1007/978-3-319-77610-1_15	computer science;memory architecture;real-time computing;theoretical computer science;operational semantics;consistency model;executable;multiprocessing;multi-core processor;formal verification;microarchitecture	PL	-20.353905318620225	33.313627825568105	152421
daf6b4d729d98f28120853a3d76021c173d42b9f	reducing and eliding read barriers for concurrent garbage collectors	elision;garbage collection;garbage collector;compiler optimization;read barrier	In order for a garbage collector to concurrently move an object while an application mutator thread accesses it, either read or write barriers are necessary. A read barrier places certain invariants on loaded values that allow the garbage collector and mutator to progress in parallel. However, the read barrier is performed on loads and can be viewed as an impediment to the performance of the application threads. This paper builds on the work of a highly efficiency concurrent garbage collector known as the Continuously Concurrent Compacting Collector (C4) which progresses the design of read barriers to create what is known as the Loaded Value Barrier (LVB). This paper's key insight is the dynamic number of LVBs may be dramatically reduced by a compiler using the invariants the LVB provides. The paper describes three examples of this class of transformation, and reasons about their correctness and performance. We are unaware of work describing compiler optimizations to elide read barriers or restructure code to cut their dynamic execution. We detail related work on improving read barrier efficiency.	barrier (computer science);correctness (computer science);garbage collection (computer science);mutator method;optimizing compiler;out-of-order execution	Ian Rogers	2011		10.1145/2069172.2069177	parallel computing;real-time computing;computer science;operating system;garbage in, garbage out;garbage collection	PL	-20.179287050746595	34.85477182440943	152475
e7297b8fd8f17ef5bf5dc571291109baf83b9507	specification of real-time systems using a timed automata model with shared variables and verification of partial-deadlock freeness	partial deadlock free;partial deadlock freeness;formal specification;shared boolean variables;formal specifications;real time systems automata time of arrival estimation timing formal specifications sufficient conditions system recovery explosions;timed automata model;sufficient conditions;partial deadlock free real time systems timed automata model shared variables partial deadlock freeness tasv extended timed automata shared boolean variables;automata;system recovery;shared variables;concurrency control;time of arrival estimation;extended timed automata;automata theory;explosions;timed automata;tasv;formal specification automata theory real time systems concurrency control;real time systems;timing	We propose a timed automata model with shared variables (TASV). A TASV is a set of extended timed automata (ETAs) with shared boolean variables. For this model, we propose (1) an algorithm which decides whether a given TASV is partial-deadlock free, and (2) a sufficient condition that we can efficiently prove a given TASV is partial-deadlock free. Each ETA in a TASV can access to /modify shared boolean variables independently. By constructing a tuple automaton for all ETAs in a given TASV, we can decide the existence of deadlocks. However, such an approach causes the state explosion problem. Our algorithm and our proposed sufficient condition reduce the possibility of the state explosion by dividing the ETAs into some sets and proving their partial-deadlock freeness independently.	algorism;algorithm;automata theory;deadlock;directed acyclic graph;liveness;real-time clock;real-time computing;real-time transcription;shared variables;timed automaton;turing completeness	Kozo Okano;Satoshi Hattori;Akira Yamamoto;Teruo Higashino;Kenichi Taniguchi	1999		10.1109/ICPPW.1999.800118	real-time computing;computer science;distributed computing;algorithm	Logic	-25.807456547458703	34.30803551518867	152602
b718009949b92ce97803c7fbe586b7170723fe5e	an soa based design of juno daq online software		 Abstract—The Online Software, manager of the JUNO data acquisition (DAQ) system, is composed of many distributed components working coordinately. It takes the responsibility of configuring, processes management, controlling and information sharing etc. The design of service-oriented architecture (SOA) which represents the modern tendency in the distributed system makes the online software lightweight, loosely coupled, reusable, modular, self-contained and easy to be extended. All the services in the SOA distributed online software system will send messages each to another directly without a traditional broker in the middle, which means that services could operate harmoniously and independently. ZeroMQ is chosen but not the only technical choice as the low-level communication middle-ware because of its high performance and convenient communication model while using Google Protocol Buffers as a marshaling library to unify the pattern of message contents. Considering the general requirement of JUNO, the concept of partition and segment are defined to ensure multiple small-scaled DAQs could run simultaneous and easy to join or leave. All running data except the raw physics events will be transmitted, processed and recorded to the database. High availability (HA) is also taken into account to solve the inevitable single point of failure (SPOF) in the distribution system. This paper will introduce all the core services’ functionality and techniques in detail.	cloud computing;data acquisition;distributed computing;high availability;high- and low-level;loose coupling;mathematical optimization;protocol buffers;reliability engineering;service-oriented architecture;service-oriented device architecture;single point of failure;software deployment;software system;sound quality;warez;zeromq	Jin Li;Minhao Gu;Fei Li;Kejun Zhu	2018	CoRR		single point of failure;marshalling;software system;operating system;physics;models of communication;software;information sharing;high availability;electronic engineering;modular design	PL	-32.49193703527412	42.71343313485249	152644
711d89567b4da81f9916dd57f9ea1f58035bb639	object-oriented technology ecoop 2002 workshop reader		Safe programming languages offer safety and security features making them attractive for developing extensible environments on a wide variety of platforms, ranging from large servers all the way down to hand-held devices. Extensible environments facilitate dynamic hosting of a variety of potentially untrusted codes. This requires mechanisms to guarantee isolation among hosted applications and to control their usage of resources. While most safe languages provide certain isolation properties, typically resource management is difficult with the current standard APIs and existing virtual machines. This one-day workshop brought together practitioners and researchers working on various approaches to these problems to share ideas and	code;ecoop;isolation (database systems);mobile device;programming language;virtual machine	Isabel Michiels;Jürgen Börstler;Kim B. Bruce;Alejandro Fernández	2002		10.1007/3-540-36208-8		PL	-32.48276110866563	41.413569606786126	152778
68e657a4f9b723442afe7fb997bce343f1a597e7	a formal model of concurrency for distributed object-oriented systems	distributed system;formal specification;distributed processing;object oriented programming;program verification;object oriented modeling concurrent computing nominations and elections computer science context modeling distributed computing distributed processing algebra communication channels calculus;higher order;distributed objects;specification and verification;object oriented;distributed object system;point of view;program verification formal concurrency model distributed object oriented systems object oriented constructions concurrently executing objects interoperation process oriented perspective interacting processes behaviour pattern formal model concurrent objects process theory spl pi calculus specification;process algebra;process algebra distributed processing object oriented programming formal specification program verification	It is widely accepted that object-oriented constructions can be used as a pertinent basis for the support of distributed systems consisting of concurrently executing objects that communicate and interoperate among them. In this context, distributed object systems are representedfrom a process-oriented perspective which uses the process as the basic modelling structure. This point of view allows us to model concurrent objects as a collection of interacting processes, each of them describing a pattern of behaviour This paper aims to provide a formal foundation for objectoriented constructions. To do so, we present a formal model of concurrent objects based on a well-de$ned process theory, the x-calculus, which oglers a very effective mechanism of specification and verification. The election of the n-calculus is justified by some of itsfeatures ---e.g., mobility and higher-order constructionsfor they will be essential to the description of some object behaviour and constructions.	calculus of constructions;distributed computing;distributed object;formal language;interaction;interoperability;mathematical model;relevance	Manuel Barrio-Solórzano;Pablo de la Fuente	1997		10.1109/APSEC.1997.640203	computer science;theoretical computer science;distributed computing;distributed object;programming language;object-oriented programming	PL	-29.926508380694905	32.45286341833994	152813
4762c73fcbc9044ceb3a933ada16105939df35bf	a formal semantics of clock refinement in imperative synchronous languages	clocks synchronization semantics computational modeling instruction sets analytical models;over synchronization formal semantic clock refinement imperative synchronous language infinite sequence structural operational semantic;analytical models;programming language semantics;quartz;clocks;synchronous languages;clock refinement;semantics;structural operational semantic;synchronous language;formal semantics;imperative synchronous language;computational modeling;synchronization;infinite sequence;subclocks synchronous languages quartz semantics;subclocks;over synchronization;formal semantic;instruction sets	The synchronous model of computation divides the execution of a program into an infinite sequence of so-called macro steps, which are further divided into finitely many micro steps. Since all threads of a program are forced to run in lockstep, programmers have no means to express the independence of parallel threads, which leads to a phenomenon called over-synchronization. In this paper, we therefore propose a generalization of the synchronous model of computation by means of refined clocks, which divide a macro step into finer grained steps that themselves consist of micro steps. In particular, we present a structural operational semantics of sub clocks and prove that the internal asynchrony given by sub clocks still preserves input/output determinism.	asynchronous i/o;clock rate;imperative programming;input/output;lockstep (computing);model of computation;operational semantics;programmer;quartz (graphics layer);refinement (computing);static program analysis	Mike Gemünde;Jens Brandt;Klaus Schneider	2010	2010 10th International Conference on Application of Concurrency to System Design	10.1109/ACSD.2010.25	synchronization;computer science;theoretical computer science;instruction set;formal semantics;sequence;semantics;programming language;computational model;algorithm	Embedded	-25.735028456179275	33.5450981139086	152973
c85cd1472a5c97be408d8c034ae297f39d88f68d	software component replication for improved fault-tolerance: can multicore processors make it work?		Programs increasingly rely on the use of complex component libraries, such as in-memory databases. As any other software, these libraries have bugs that may lead to the application failure. In this work we revisit the idea of software component replication for masking software bugs in the context of multi-core systems. We propose a new abstraction: a Macro-Component. A Macro-Component is a software component that includes several internal replicas with diverse implementations to detect and mask bugs. By relying on modern multicores processing capacity it is possible to execute the same operation in multiple replicas concurrently, thus incurring in minimal overhead. Also, by exploring the multiple existent implementations of well-known interfaces, it is possible to use the idea without incurring in additional development cost.	component-based software engineering;fault tolerance;in-memory database;library (computing);multi-core processor;multiprocessing;overhead (computing);software bug	João Soares;João Lourenço;Nuno M. Preguiça	2013		10.1007/978-3-642-38789-0_15	parallel computing;real-time computing;computer science;distributed computing	OS	-20.510508038636793	40.05327888792941	153258
45a86ca361a83c588fab693b11d25624b5dc013a	chromium renderserver: scalable and open remote rendering infrastructure	chromium renderserver;parallel rendering;protocols;chromium rendering computer graphics application software computer networks concurrent computing graphics hardware computer industry protocols streaming media;concurrent computing;client viewers;software architecture parallel processing public domain software rendering computer graphics;scalable remote rendering infrastructure;industry standard layer 7 network protocols;application software;software infrastructure;distance visualization remote visualization remote rendering parallel rendering virtual network computer collaborative visualization;hardware accelerator;computer industry;open source software chromium renderserver open remote rendering infrastructure scalable remote rendering infrastructure software infrastructure interactive opengl remote parallel computational platform graphics hardware accelerators industry standard layer 7 network protocols client viewers rendering architectures;indexing terms;rendering architectures;computer networks;graphics hardware accelerators;public domain software;software architecture;collaborative visualization;col;graphics hardware;streaming media;chromium;open remote rendering infrastructure;virtual network computing;parallel computer;remote rendering;remote visualization;virtual network computer;distance visualization;remote parallel computational platform;interactive opengl;rendering computer graphics;parallel processing;graphics;open source software;algorithms computer graphics image enhancement image interpretation computer assisted imaging three dimensional information storage and retrieval internet signal processing computer assisted software;hardware	Chromium Renderserver (CRRS) is a software infrastructure that provides the ability for one or more users to run and view image output from unmodified, interactive OpenGL and X11 applications on a remote parallel computational platform equipped with graphics hardware accelerators via industry-standard Layer-7 network protocols and client viewers. The new contributions of this work include a solution to the problem of synchronizing X11 and OpenGL command streams, remote delivery of parallel hardware-accelerated rendering, and a performance analysis of several different optimizations that are generally applicable to a variety of rendering architectures. CRRS is fully operational, open source software.	apba1 wt allele;advance directive - proxy;analysis of algorithms;architecture as topic;authentication;authorization documentation;chromium (web browser);clients;cobalt-chromium alloys;collaborative software;communications protocol;distributed memory;dynamic range;end-to-end principle;fisheye;glossary of computer graphics;graphics hardware;hardware acceleration;image resolution;image scaling;imagery;interactive visualization;job queue;mobile device;moving picture experts group;occupations;open-source hardware;open-source software;opengl;parallel rendering;performance evaluation;protocols documentation;proxy server;rendering (computer graphics);scalability;single user mode;small;test scaling;throughput;user space;video card;x window system;benefit;chromic chloride	Brian E. Paul;Sean Ahern;E. Wes Bethel;Eric Brugger;Rich Cook;Jamison Daniel;Ken Lewis;Jens Owen;Dale Southard	2008	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2007.70631	parallel processing;software architecture;chromium;application software;concurrent computing;computer hardware;computer science;graphics;operating system;parallel rendering;graphics hardware;public domain software;software rendering;computer graphics (images)	Visualization	-30.30704258105054	40.31866276618935	153358
d5624f0f1b89dd064c3f7283186755bbd46f7f94	dependence analysis for java	dependence analysis;parallelizing compilers;dependence graph;linear time algorithm;program transformation;optimizacion compiladora;object oriented programming;transformation programme;memory consistency;analisis programa;compilateur parallelisation;organizacion memoria;transformacion programa;data dependence;compiler optimization;organisation memoire;code motion;program analysis;memory organization;analyse programme;programmation orientee objet;optimisation compilateur	"""We describe a novel approach to performing data dependence analysis for Java in the presence of Java's \non-traditional"""" language features such as exceptions, synchronization, and memory consistency. We introduce new classes of edges in a dependence graph to model code motion constraints arising from these language features. We present a linear-time algorithm for constructing this augmented dependence graph for an extended basic block."""	algorithm;alias analysis;consistency model;data dependency;dependence analysis;distributed computing;diwan-khane;edward wegman;exception handling;extended basic block;fink;gosling emacs;instruction scheduling;instruction selection;j. eliot b. moss;java;java memory model;java virtual machine;ken arnold;loop-invariant code motion;mark n. wegman;optimizing compiler;program analysis;programming language;quasicircle;ron sun;scheduling (computing);static single assignment form;stepping level;supercomputer;symposium on principles of programming languages;time complexity;vortex;william l. burke	Craig Chambers;Igor Pechtchanski;Vivek Sarkar;Mauricio J. Serrano;Harini Srinivasan	1999		10.1007/3-540-44905-1_3	program analysis;parallel computing;computer science;theoretical computer science;operating system;optimizing compiler;distributed computing;memory organisation;programming language;object-oriented programming;algorithm;generics in java;scala;dependence analysis	PL	-22.43588856161434	32.62358215207042	153604
e9a885225508cd298df108d5122b99b4956313e8	jra: offline analysis of runtime behaviour	java virtual machine;runtime behaviour;low overhead;visualization;java	The JRockit Java virtual machine has a built-in capability to produce recordings of the runtime behaviour of an application environment. It is a light-weight system with a very low performance cost, which can give valuable insights as to how the JVM and application interact in production. The JRockit Runtime Analyzer (JRA) is a tool for analyzing these recordings by graphic visualization.	jrockit;java virtual machine;online algorithm;online and offline	Helena Åberg Östlund	2004		10.1145/1028664.1028674	real-time computing;visualization;computer science;operating system;programming language;java	SE	-20.75131343528978	37.79274961598178	153751
526bea3050768596c5b3d23fc82c7bdac13efc9f	implementation of the blit debugger	debugging;outil logiciel;infographe;software tool;bitmap terminal;mise au point programme;terminal graphique;symbol tables;terminal blit;graphics debugging;asynchronous debugging;graphical terminal;remote debugging	Abstract#R##N##R##N#joff is an asynchronous, source-level, break-and-examine debugger for C programs running on the Blit, a programmable bitmap terminal, joff is implemented as two processes: a small process running in the terminal and a larger process running in a time-sharing host. The constraints on its design and a menu-driven user interface combine to present an unusual set of implementation difficulties. The way the problems were tackled and the degree to which they were solved may be interesting to those designing other debuggers. Operating system designers should assess the merits of a debugger that runs asynchronously with its subject and consider providing the necessary support.	bit blit;debugger	Thomas A. Cargill	1985	Softw., Pract. Exper.	10.1002/spe.4380150204	parallel computing;real-time computing;computer science;operating system;programming language;debugging	SE	-25.979168891537512	37.962725773127985	153879
a2b00fa1de8f032f32849c797ca06058ed51d034	an environment for dataflow program development of parallel processing system-harray	tratamiento paralelo;developpement logiciel;detection erreur;deteccion error;traitement parallele;flot donnee;system programming;flujo datos;japon;asie;programmation systeme;programacion sistema;desarrollo logicial;software development;error detection;data flow;program development;japan;parallel processing;asia	Abstract#R##N##R##N#This paper considers the dataflow program development environment for the system programmer who develops the compiler and proposes a method to improve the debugging efficiency. The conventional debugging methods are either: (1) to monitor the packet in the dataflow ring, or (2) to specify the function containing a bug. The former contains unsolved problems such as the determination of start timing for the data monitoring and the presentation of a large amount of information to the user. The latter contains a problem in that the debugging is impossible at the dataflow level.#R##N##R##N##R##N##R##N#This paper aims at the solution of those problems, and the detailed debugging is executed on the software, not on the real machine. The information presentation on a dataflow graph is considered for systematic presentation of the debugging information. As the development environment, the parallel processing system Harray proposed by the authors is considered. In the proposed system, a two-stage process is employed in which the first step is to specify the macro-block (which is a task unit in Harray) containing the bug, and the second step is the detailed debugging of the specified macro-block. The debugging within the macroblock is executed on the software, and the debugging efficiency is improved by: (1) diagram representation for easier visual recognition, and (2) backward tracing function.		Hayato Yatnana;Jun Kohdate;Toshiaki Yasue;Yoichi Muraoka	1991	Systems and Computers in Japan	10.1002/scj.4690220803	data flow diagram;parallel processing;shotgun debugging;parallel computing;real-time computing;error detection and correction;computer science;software development;operating system;algorithmic program debugging;programming language;background debug mode interface;system programming;algorithm	SE	-23.45172957532502	36.01032121632492	154129
39619efda1e82c236d002b8fe300bb2225dbbdc3	pardis: corba-based architecture for application-level parallel distributed computation	software system;multiple supercomputing resource;objects interact;corba-based architecture;spmd object;metaapplication component;building block;different software system;interface definition language;application-level parallel;common object request broker;data-parallel computation;computer science;application software;parallel;distributed environment;common object request broker architecture;distributed computing;computer applications;computer architecture;processor architecture;software systems;concurrent computing;corba;distributed application;interoperability;distributed system;system design	Modern technology provides the infrastructure necessary to develop distributed applications capable of using the power of multiple supercomputing resources and exploiting their diversity. The performance potential offered by distributed supercomputing is enormous, but it is hard to realize due to the complexity of programming in such environments. In this paper we introduce PARDIS, a system designed to overcome this challenge, based on ideas underlying the Common Object Request Broker Architecture (CORBA), a successful industry standard. PARDIS is a distributed environment in which objects representing data-parallel computations, called SPMD objects, as well as non-parallel objects present in parallel programs, can interact with each other across platforms and software systems. Each of these objects represents a small encapsulated application and can be used as a building block in the construction of powerful distributed metaapplications. The objects interact through interfaces specified in the Interface Definition Language (IDL), which allows the programmer to integrate within one metaapplication components implemented using different software systems. Further, support for non-blocking interactions between objects allows PARDIS to build concurrent distributed scenarios.	common object request broker architecture;computation;distributed computing	Katarzyna Keahey;Dennis Gannon	1997		10.1109/SC.1997.10021	parallel computing;real-time computing;concurrent computing;computer science;theoretical computer science;operating system;common object request broker architecture;distributed computing;distributed object;programming language	HPC	-32.48948644822076	44.5642745736087	154387
691cb46009bdd1c7c7dca7b3a9f72737a858533d	the design and implementation of the front-end software for the telemetry and telecontrol system of satellite	test on the ground;software;satellite communication;remote control;telemetry satellites data processing databases testing software systems;telecommunication computing;remote telemetry;telecontrol control engineering computing satellite communication space telemetry telecommunication computing;space telemetry;telecontrol;data communications front end software telemetry system telecontrol system satellite ground test system;control engineering computing;test on the ground software remote telemetry remote control data process;data process	This document mainly describes how to design and implement a telemetry and telecontrol systems which is apply for satellite on ground test. Telemetry and telecontrol systems front-end software is part of a satellite's ground test system, running on a host computer, which is mainly used to complete the unified control and management of the telemetry and remote ground equipment. The software system has been tested on the ground for data communications from and to the satellite, which is one of the essential components during the ground test. The result shows that the software system operated stably and has achieved satisfactory test results.	front and back ends;host (network);software system	Zhao Qi;Ma Li	2013	2013 IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber, Physical and Social Computing	10.1109/GreenCom-iThings-CPSCom.2013.350	embedded system;data processing;telecommunications;computer science;communications satellite;portable telemetry;remote control	Embedded	-31.70262985610757	39.165050351109365	154681
13d21723ead8fc019df379a5dd4017bf042782b7	embedded java	object oriented programming;embedded systems;java	The increasing complexity of embedded systems also results in a rapid growth of the software part, which tends to be developed in object oriented programming languages like C++ or Java. Originally planned for embedded systems, Java recently plays again a more important role in the context of embedded system from different points of views. Especially platform independence, multithreading parallelism, and internet embedding are important advantages and contribute to the increasing importance of Java in the following different aspects.At first, software reuse oriented concepts like Java Beans for the specification and prototyping of embedded systems have to be mentioned.Second, several standards have been developed to improve memory footprints as well as performance of Java for its use in embedded systems. Examples include PersonalJava, EmbeddedJava, JavaCard, Romizers, J2ME, and KVM.As a third more research oriented development we find Java more and more in the role of a modeling, specification, simulation, and synthesis language not only for the software but also for the hardware parts of embedded systems. This aspect is especially interesting for hardware/software co-design and co-simulation.In this talk, all these different aspects of Java, as well as their roles, contributions and impacts especially for embedded system design will be discussed.	c++;co-simulation;code reuse;embedded java;embedded system;java card;java platform, enterprise edition;multithreading (computer architecture);parallel computing;personaljava;programming language;simulation;systems design;thread (computing)	Wolfgang Rosenstiel	2000		10.1145/501790.501826	parallel computing;real-time computing;java concurrency;computer science;java modeling language;interface;strictfp;embedded java;real time java;programming language;java;generics in java;scala;java annotation	Embedded	-29.25862657782433	37.18712572227455	154817
b3e36ba261d379d6db9e5186e650c2834f8a60f5	synthesising choreographies from local session types (extended version)		Designing and analysing multiparty distributed interactions can be achieved either by means of a global view (e.g. in choreography-based approaches) or by composing available computational entities (e.g. in service orchestration). This paper proposes a typing systems which allows, under some conditions, to synthesise a choreography (i.e. a multiparty global type) from a set of local session types which describe end-point behaviours (i.e. local types).		Julien Lange;Emilio Tuosto	2012	CoRR		real-time computing;computer science;distributed computing;world wide web	Theory	-31.518471535197847	33.83703500344353	155311
4123c4545104ae8d22c9004bc052508e1f709c7a	instruction folding compression for java card runtime environment	smart card;random access memory;java card;software architecture data compression embedded systems java read only storage smart cards;virtual machining;java dictionaries virtual machining smart cards read only memory random access memory indexes;indexes;smart cards;dictionary compression system instruction folding compression java card runtime environment secure java running environment smart cards low end embedded systems rom size rom execution time java card software architecture acceleration mechanisms software complexity;dictionaries;instructions folding;compression;instructions folding smart card java card compression;read only memory;java	Java Card is a secure Java running environment targeted for smart cards. In such low-end embedded systems, ROM size and execution time play very important, usually opposing roles. Dictionary compression can be applied to the Java Card software architecture, but pays for the reduced ROM size of the applications with a higher execution time. On the other hand, acceleration mechanisms to speed up the execution need additional information or additional software complexity, with the effect of increasing ROM size. In this paper, we propose a dictionary compression system based on an instruction folding mechanism that permits a reduction in the ROM size of Java Card applications, and at the same time, a speed-up of their execution.	dictionary coder;embedded system;java card;java bytecode;method framework for engineering system architectures;programming complexity;read-only memory;run time (program lifecycle phase);runtime system;smart card;software architecture;virtual machine	Massimiliano Zilli;Wolfgang Raschke;Reinhold Weiss;Johannes Loinig;Christian Steger	2014	2014 17th Euromicro Conference on Digital System Design	10.1109/DSD.2014.32	embedded system;smart card;java card;parallel computing;jsr 94;java concurrency;computer hardware;jar;computer science;operating system;smart card application protocol data unit;strictfp;embedded java;real time java;card reader;open smart card development platform;java;openpgp card;basiccard;java applet;java annotation	EDA	-21.268554156655064	37.045392740312565	155322
96d76261d921e377cb3f2c32124f0649aa76d58a	designing multi-processor real-time systems with a multi-view approach	real time systems		multiprocessing;real-time operating system;real-time transcription	Liqing Zhang;Jan van Katwijk	1994			system of systems engineering;system of systems;real-time computing;systems design;computer science	Embedded	-29.988883645782717	38.074453889575274	155573
5224d7ad20fbd9a6fd41a3153276b27896e2552f	events can make sense	control flow;event based system	Tame is a new event-based system for managing concurrency in network applications. Code written with Tame abstractions does not suffer from the “stackripping” problem associated with other event libraries. Like threaded code, tamed code uses standard control flow, automatically-managed local variables, and modular interfaces between callers and callees. Tame’s implementation consists of C++ libraries and a source-to-source translator; no platform-specific support or compiler modifications are required, and Tame induces little runtime overhead. Experience with Tame in real-world systems, including a popular commercial Web site, suggests it is easy to adopt and deploy.	c++;concurrency (computer science);control flow;library (computing);local variable;overhead (computing);platform-specific model;source-to-source compiler;tame;threaded code;world-system	Maxwell N. Krohn;Eddie Kohler;M. Frans Kaashoek	2007			real-time computing;computer science;operating system;distributed computing;programming language;control flow	OS	-22.627530772393428	32.611885219399326	155599
25540ceb3a81cc384986c7f4e40750f2d320f8e3	file hoarding under nfs and linux	disconnected operation;file system;source code;modes of operation;cache management;file systems;file caching	This paper describes an implementation of a file hoarding system for the Linux/NFS platform. Designed as a cache manager on the mobile Linux platform, the system supports fully connected, partially connected and disconnected mode of operations. The unique feature of the system is the mechanism used for its implementation, i.e. the local proxy of the remote NFS server. This choice assures high flexibility and portability of the system since no modifications are required in the native system's kernel source code. The experiments presented in the paper show that this mechanism provides a viable solution for implementing fiie system extension~ such as file hoarding and disconnected operation.	cpu cache;experiment;linux;server (computing);software portability	Dorota M. Huizinga;Heather Sherman	1998		10.1145/330560.330849	fork;self-certifying file system;parallel computing;torrent file;memory-mapped file;device file;computer file;computer science;stub file;versioning file system;operating system;fstab;unix file types;ssh file transfer protocol;journaling file system;database;open;everything is a file;programming language;file system fragmentation;file area network;file control block;source code;virtual file system	OS	-26.306230876328083	42.7949358847346	155610
667d8cda406d0ad4bceacd08a4ac0a606fabd900	automatic run-time versioning for bpel processes		We describe a middleware solution for automatic run-time process versioning in Business Process Execution Language (BPEL) and then analyse its impact in terms of scalability and performance. Business processes change in response to business needs, but the deployment of new versions to a BPEL engine must ensure that running instances are not disrupted and can conclude following their original workflows. Our solution is implemented as a standalone component that manages versioning transparently to the process editor, the orchestration engine, the web services used by the process, and the end-user. We have tested it for almost 1 year in the production environment of a telecommunications company, without significant overhead in terms of process invocation time.	business process execution language;business requirements;deployment environment;experiment;high- and low-level;legacy code;load balancing (computing);middleware;overhead (computing);run time (program lifecycle phase);runtime system;scalability;service-oriented architecture;software deployment;software versioning;web service	Paulo Melo;Paulo Rupino da Cunha;Catarina Ferreira Da Silva;André Macedo	2017	Service Oriented Computing and Applications	10.1007/s11761-017-0211-3	distributed computing;business process;orchestration (computing);real-time computing;computer science;business process execution language;scalability;business process model and notation;database;middleware;workflow;service-oriented architecture	OS	-33.36223275891156	43.139141476662495	155754
8b1eabc28a6ddf8b838d5e556da81c453a3510e6	developing smart card-based applications using java card	application development;smart card;java card;design and development;distributed objects;development methodology	"""In this paper we describe a methodology for developing smart card-based applications which accounts for both internal and external software production: on-card and client programs. This development methodology is based on the application of distributed object-oriented principles to Java Card. We design a model in which a card application is viewed as a remote object accessed through method invocations handled by a proxy object executing on the terminal. With a simple example, we show how this model enhances the development of smart card-based applications by allowing Java programmers to rapidly design and develop on-card and oo-card programs without worrying about the speciic smart card features. This scheme has been implemented as the core technology in the Gemplus Java Card application development environment GemX-presso RAD. 1 Background and Objectives In this section we review the emergent and promising open smart card development platform based on the Java Card speciication. We give an overview of the processes involved in the creation of a Java Card-based application. We outline the limits of the Java Card speciication as a model for the interaction between Java Card applets and the outside world. We then show how this limit has brought us to deene a development methodology based on distributed object-oriented principles applied to Java Cards. During the past twenty years smart cards have evolved from simple dedicated devices (phone cards, french \Carte Bleue"""") to open computing platforms 14, ? Java and Java Card are trademarks of Sun Microsystems Inc. GemXpresso RAD is a trademark of Gemplus. All other product names mentionned herein are the trademarks of their respective owners."""	applet;client (computing);client-side;client–server model;dce/rpc;distributed object;encode;emergence;java card;java remote method invocation;operating system;programmer;proxy pattern;proxy server;rapid application development;remote procedure call;server (computing);server-side;smart card;software development kit	Jean-Jacques Vandewalle;Eric Vétillard	1998		10.1007/10721064_9	multos;embedded system;smart card;java card;real-time computing;computer hardware;java card openplatform;computer science;operating system;smart card application protocol data unit;real time java;distributed object;open smart card development platform;java;rapid application development;computer security;basiccard;contactless smart card	SE	-33.26946089635658	42.258578062306896	155805
b3970081c89765cadcad1cf1667b24456a352899	cooperative nets	cooperative nets	The behavior of some kinds of systems features a high rate of dynamic evolution. The system running causes the introduction of new components whereas some others disappear, and links between components are dynamically set: a component sometimes interacts with given components and sometimes with others. It is uneasy to capture such evolution inside Petri nets whose structure is fixed; but it is necessary to respect the Petri net semantics and keep the possibility to apply the structural analysis technics. The paper introduces two extensions of Petri nets dealing with this problem, Communicative Nets and Cooperative Nets. They enable to model a system as a collection of nets which encapsulate their behavior, while interacting by means of message sending or a client/ server protocol; a net may instantiate another net, and the links between nets are dynamic. An algorithm is given which captures this dynamicity by building a single fixed net whose behavior is equivalent to a whole system.	algorithm;dataflow;information system;interaction;petri net;programming language;semantics (computer science);server (computing);structural analysis	Christophe Sibertin-Blanc	1994		10.1007/3-540-58152-9_26		SE	-31.79901600429463	34.22794662961522	155921
24b2f92dc7b26a045ac89d4d86447c1705fc83b9	hardware implementation of the ravenscar ada tasking profile	language use;programming language;fpga;property a;timing analysis;hardware implementation;hardware compilation;real time systems;timing	Real-Time Systems place large demands on the languages used to implement them. Processor based implementation methods do not allow accurate timing analysis of systems due to the complexity of modern processors. FPGAs provide a means to implement a real-time system in a way that allows accurate timing analysis to be performed.Existing hardware implementations of high-level programming languages do not support the needs of real-time systems. This paper presents a hardware implementation of the SPARK Ravenscar subsets of Ada which can be accurately analysed for its timing properties. A method of compiling sequential Ada programs has been described elsewhere [21], and this is expanded to include the compilation of protected objects and tasks. The effect this has on the ability to analyse the timing of the program is then examined.	ada;central processing unit;compiler;concurrency (computer science);control system;field-programmable gate array;hardware description language;high- and low-level;high-level programming language;ravenscar profile;real-time clock;real-time computing;real-time operating system;real-time transcription;spark;statement (computer science);static timing analysis;window of opportunity	Michael Ward;Neil C. Audsley	2002		10.1145/581630.581641	embedded system;computer architecture;parallel computing;real-time computing;computer science;operating system;programming language;static timing analysis;field-programmable gate array	Embedded	-23.669853851711174	34.48387227780196	156534
619e996c79b33f772120fb362fa2f1cefe025bcb	high-level accelerated array programming in the web browser	dsl;web;gpgpu;ocaml;javascript	Client-side web programming currently means using technologies embedded in web browsers to run computations on the client computer. Most solutions imply using JavaScript which allows to describe computations, and modifications of the DOM displayed by the browser. However, JavaScript limits static checking as everything (types, names, etc.) is checked at runtime. Moreover its concurrent model does not take advantage of multi-core or GPU architectures. In this paper we present WebSPOC, an adapted version of the SPOC library for web applications. SPOC is an OCaml GPGPU library focusing on abstracting memory transfers and handling GPGPU computations in a strongly static typed context. SPOC proposes a specific language, called Sarek, to express kernels and different parallel skeletons to compose them. To run SPOC programs on the Web client side, its OCaml part is compiled to JavaScript code and its Sarek part to kernels running on GPUs or multi-core CPUs.	array programming;central processing unit;client (computing);client-side;compiler;computation;document object model;embedded system;general-purpose computing on graphics processing units;graphics processing unit;javascript;multi-core processor;ocaml;run time (program lifecycle phase);small private online course;web application;web development	Mathias Bourgoin;Emmanuel Chailloux	2015		10.1145/2774959.2774964	computer science;operating system;programming language;world wide web	PL	-24.962016532506972	36.95573900657774	156565
899d3b9f2e326ac8f248a331b9cfbb4aa234413d	online optimizations driven by hardware performance monitoring	modele comportement;juste a temps;dynamic programming;utilisation information;lenguaje programacion;behavior model;compilacion;java bytecode;evaluation performance;uso informacion;programacion dinamica;compilateur;performance evaluation;localite;measurement;execution time;just in time compilation;programming language;information use;information source;surveillance;source information;resource allocation;hardware performance monitors;evaluacion prestacion;modelo comportamiento;performance;ramasse miettes;online optimization;locality;cache memory;langage java;ejecucion programa;optimizacion compiladora;compiler;program execution;antememoria;recogemigas;antememoire;monitoring system;just in time compiler;vigilancia;monitoring;execution programme;garbage collector;compiler optimization;programmation dynamique;langage programmation;compilation;temps execution;lenguaje java;just in time;justo en tiempo;asignacion recurso;monitorage;spatial locality;allocation ressource;tiempo ejecucion;monitoreo;optimisation compilateur;compilador;fuente informacion;java language;generic programming;dynamic optimization;java	Hardware performance monitors provide detailed direct feedback about application behavior and are an additional source of infor-mation that a compiler may use for optimization. A JIT compiler is in a good position to make use of such information because it is running on the same platform as the user applications. As hardware platforms become more and more complex, it becomes more and more difficult to model their behavior. Profile information that captures general program properties (like execution frequency of methods or basic blocks) may be useful, but does not capture sufficient information about the execution platform. Machine-level performance data obtained from a hardware performance monitor can not only direct the compiler to those parts of the program that deserve its attention but also determine if an optimization step actually improved the performance of the application.  This paper presents an infrastructure based on a dynamic compiler+runtime environment for Java that incorporates machine-level information as an additional kind of feedback for the compiler and runtime environment. The low-overhead monitoring system provides fine-grained performance data that can be tracked back to individual Java bytecode instructions. As an example, the paper presents results for object co-allocation in a generational garbage collector that optimizes spatial locality of objects on-line using measurements about cache misses. In the best case, the execution time is reduced by 14% and L1 cache misses by 28%.	basic block;best, worst and average case;cpu cache;compiler;computer performance;garbage collection (computer science);java bytecode;just-in-time compilation;locality of reference;mathematical optimization;online and offline;overhead (computing);principle of locality;run time (program lifecycle phase);runtime system	Florian T. Schneider;Mathias Payer;Thomas R. Gross	2007		10.1145/1250734.1250777	parallel computing;real-time computing;profile-guided optimization;compiler correctness;computer science;loop optimization;operating system;just-in-time compilation;programming language;functional compiler	PL	-19.487418808625037	36.02438515253421	156593
0c4dff595aba936fbf6006b46b24f73f64d7854e	automatic production of controller specifications from control and timing behavioral descriptions	automatic control;protocols;transducers;automatic control production timing control system synthesis permission hardware signal synthesis automatic generation control protocols transducers;permission;data dependence;control system synthesis;automatic generation control;production;signal synthesis;graph model;finite state machine;hardware;timing;time constraint	This paper presents a method for the generation of controller specifications from high-level behavioral descriptions in control and timing graph form. Input descriptions may contain multiple timing constraints, asynchronous and synchronous inputs, data dependent internal loops, and parallel and conditional branches. The timing graph model is transformed automatically to a state table specification of a synchronous finite state machine. The specification method is effective not only for independent data processors, but also for processors constrained by interface requirements and performing I/O protocol translation. The method has been programmed and tested on selected examples. Results from one example are given along with a comparison with results on the same example from another system.	central processing unit;finite-state machine;high- and low-level;input/output;parallel computing;requirement	S. Hayati;A. Parker	1989	26th ACM/IEEE Design Automation Conference	10.1145/74382.74396	control engineering;communications protocol;real-time computing;transducer;computer science;theoretical computer science;automatic control;programming language	EDA	-33.24575549675081	33.427206456499	156798
544148fd8f014e3f4df78e53017cb83c9cdae15f	a quantitative approach to the design of an optimized hardware interpreter for java byte-code			byte;java bytecode	Guido Masera;Gianluca Piccinini;Massimo Ruo Roch;Maurizio Zamboni	1999				Arch	-22.52249641560747	33.80805705085937	156969
346b05d67a652e7837c2f2cb85a215a576ec6d4d	an integrated fault tolerance framework for service oriented computing			fault tolerance;service-oriented architecture	Stephen Hall	2010				HPC	-32.276471470367184	46.113044761956736	157365
69eec15e52e685fe34cd89fc27ef5cfe20d3e857	"""""""carbon credits"""" for resource-bounded computations using amortised analysis"""	control application;real time embedded system;upper bound;carbon credit;worst case execution time;safety critical system;floating point	Bounding resource usage is important for a number of areas, notably real-time embedded systems and safety-critical systems. In this paper, we present a fully automatic static type-based analysis for inferring upper bounds on resource usage for programs involving general algebraic datatypes and full recursion. Our method can easily be used to bound any countable resource, without needing to revisit proofs. We apply the analysis to the important metrics of worst-case execution time, stackand heap-space usage. Our results from several realistic embedded control applications demonstrate good matches between our inferred bounds and measured worst-case costs for heap and stack usage. For time usage we infer good bounds for one application. Where we obtain less tight bounds, this is due to the use of software floating-point libraries.	algebraic data type;amortized analysis;best, worst and average case;embedded system;library (computing);real-time clock;real-time computing;recursion;run time (program lifecycle phase);space–time tradeoff;worst-case execution time	Steffen Jost;Hans-Wolfgang Loidl;Kevin Hammond;Norman Scaife;Martin Hofmann	2009		10.1007/978-3-642-05089-3_23	real-time computing;computer science;floating point;theoretical computer science;carbon credit;upper and lower bounds;programming language;algorithm;worst-case execution time	Embedded	-23.094078155856486	36.191196675715595	157413
44807d40746c27e188c816f91339fa7e1fb430cb	static latency tracking with placement types		Large-scale distributed applications, e.g., in geodistributed data centers, pose a performance challenge to developers which need to take high cross-data-center latency communication cost into account. We present a preliminary investigation of a type system that tracks latency and makes the cost of remote calls explicit, raising developers' awareness of communication overhead.		Pascal Weisenburger	2018		10.1145/3236454.3236486	latency (engineering);object-oriented programming;static analysis;distributed computing;computer science	HPC	-22.595508230961208	38.96501195182111	157661
e619bfd15cae568092b2caea75cc478d3e35a67c	dependability modeling and analysis of distributed programs	hardware faults;distributed algorithms;reseau petri stochastique;distributed system;program diagnostics;program availability;fiabilidad;reliability;systeme reparti;multiprocessing programs;programme reparti;availability;red petri;program reliability;multiprocessing programs distributed algorithms petri nets program diagnostics software reliability system recovery stochastic processes programming theory;disponibilidad;stochastic petri net;availability model;reliability modeling;system status restoration;distributed control petri nets availability hardware stochastic systems distributed computing stochastic processes reliability theory graph theory tree graphs;distributed programs;ingenieria logiciel;repartition fichier;software engineering;program execution;failure state;sistema repartido;system recovery;programming theory;stochastic processes;hardware support;distributed computing system;stochastic petri nets;distributed computing system environment;fiabilite;normal operator;genie logiciel;centralized repair team;global repair mode;local repair model;petri nets;distributed program;file distribution dependability modeling dependability analysis distributed programs stochastic petri nets program reliability program availability distributed computing system environment program execution repair actions global repair mode centralized repair team system status restoration failure state local repair model hardware support hardware faults program interruption;petri net;software reliability;repair actions;disponibilite;dependability modeling;program interruption;dependability analysis;modele disponibilite;reseau petri;file distribution;modeling and analysis	Presents a modeling approach based on stochastic Petri nets to estimate the reliability and availability of programs in a distributed computing system environment. In this environment, successful execution of programs is conditioned on the successful access of related files distributed throughout the system. The use of stochastic Petri nets is demonstrated by extending a basic reliability model to account for repair actions when faults occur. To this end, two possible models are discussed: the global repair model, which assumes a centralized repair team that restores the system to its original status when a failure state is reached, and the local repair model, which assumes that repairs are localized to the node where they occur. The former model is useful in evaluating the availability of programs (or the availability of the hardware support) subject to hardware faults that are repaired globally; therefore, the programs of interest can be interrupted. On the other hand, the latter model can be used to evaluate program reliability in the presence of hardware faults subject to repair, without interrupting the normal operation of the system. >	dependability	Noé Lopez-Benitez	1994	IEEE Trans. Software Eng.	10.1109/32.286421	reliability engineering;stochastic process;distributed algorithm;real-time computing;stochastic petri net;computer science;operating system;software engineering;distributed computing;petri net;statistics	SE	-22.40296022105651	41.565166950864906	157985
4dad500d01ea01857c778a3664fbed208f6e31e1	coverage modeling for dependability analysis of fault-tolerant systems	tolerancia falta;modelizacion;computing coverage;detection erreur;system reliability;deteccion error;fiabilite systeme;dependence analysis;stochastic petri net;sistema informatico;transient recovery;coverage rate;computer system;recovery;grado recubrimiento;fiabilidad sistema;modelisation;error analysis;sensitivity;fault tolerant system;fault tolerant computing;system recovery;petri net models;stochastic processes;systems analysis;fault tolerance;fault tolerant systems computer errors predictive models transient analysis error correction error analysis fault detection stochastic processes reliability fault tolerance;error handling;sistema tolerando faltas;transient recovery dependability analysis fault tolerant system petri net models computing coverage recovery sensitivity system reliability;cost effectiveness;systeme tolerant les pannes;systeme informatique;markov processes;error detection;petri nets;modeling;degre recouvrement;tolerance faute;real time operation;dependability analysis;system recovery fault tolerant computing markov processes petri nets	Several different models for predicting coverage in a fault-tolerant system are discussed, including models for permanent, intermittent, and transient errors. Markov, semi-Markov, nonhomogeneous Markov, and extended stochastic Petri net models for computing coverage are developed. Two types of events which interfere with recovery are examined; methods for modeling such events (applicable if the events are deterministic or random) are given. The sensitivity of system reliability/availabiIity to the coverage parameter and the sensitivity of the coverage parameter to various error handling strategies are investigated. Particularly, we discovered that a policy of attempting transient recovery upon detection of an error (as opposed to automatically reconfiguring the affected component out of the system) may actually increase the unreliability of the system. This result is true if the error detectability is not nearly perfect, so that the risk of producing an undetectable error (if the transient error is still present) is greater than the benefit gained by not discarding the component.	dependability;exception handling;fault tolerance;markov chain;semiconductor industry;stochastic petri net	Joanne Bechta Dugan;Kishor S. Trivedi	1989	IEEE Trans. Computers	10.1109/12.24286	stochastic process;embedded system;fault tolerance;real-time computing;computer science;statistics	Embedded	-22.406669406280955	40.78705743161015	157997
b7ce02e38d8ba08ace3ee3cd64d1ccac749f0f01	operators of the temporal object system and their implementation	temporal database;object manager;object oriented databases;object oriented database;temporal objects	We proposed a Temporal Object System (TOS) which maintains changes to both the structure and the state of an object in a temporal fashion (Shah, 1992; Fotouhi et al, 1992a; Fotouhi, et al, 1992b; Fotouhi, et al, 1994). Objects in TOS are referred to as temporal objects and are allowed to evolve over time. A collection of temporal objects which share the same set of common properties is grouped into a family. A temporal object that can be defined by using the local knowledge of a family is referred to as an offstage object (Shah et al, 1993a). We also discussed the renovations of both temporal complex objects and offstage objects in (Fotouhi et al, 1992; Shah et al, 1993a; Fotouhi et al, 1994). This paper is a continuation of the work reported in (Fotouhi et al, 1994), and now we report on the operators of the temporal object system (TOS) and their implementation. These operators are grouped into three different modules of the TOS based on their relevant functions. These modules are: Object Manager (or Object Module), Family Module, and Root of TOS (RTOS) Module. The important module is the Object Manager (OM) that consists of basic operators. The modules provide a facility for defining a simple temporal object and later to add a stage in the temporal object. The other operators are grouped into the two other modules and are	continuation;object manager;word lists by frequency	Abad A. Shah;Farshad Fotouhi;William I. Grosky;Jalal Al-Muhtadi	2004	Inf. Sci.	10.1016/j.ins.2003.08.004	method;real-time computing;object model;computer science;theoretical computer science;object-oriented design;database;data transfer object;temporal database	AI	-30.848128452182277	41.1097700514106	158230
1a65e787b08fe8812797a0557760ae84072ad292	treegraph-based instruction scheduling for stack-based virtual machines	llvm;bytecode instruction scheduling;stack code;dags;treegraphs	Given the growing interest in the JVM and Microsoft’s CLI as programming language implementation targets, code generation techniques for efficient stack-code are required. Compiler infrastructures such as LLVM are attractive for their highly optimizing middleend. However, LLVM’s intermediate representation is register-based, and an LLVM code generator for a stack-based virtual machine needs to bridge the fundamental differences of the register and stack-based computation models. In this paper we investigate how the semantics of a register-based IR can be mapped to stack-code. We introduce a novel program representation called treegraphs. Treegraph nodes encapsulate computations that can be represented by DFS trees. Treegraph edges manifest computations with multiple uses, which is inherently incompatible with the consuming semantics of stack-based operators. Instead of saving a multiply-used value in a temporary, our method keeps all values on the stack, which avoids costly store and load instructions. Code-generation then reduces to scheduling of treegraph nodes in the most cost-effective way. We implemented a treegraph-based instruction scheduler for the LLVM compiler infrastructure. We provide experimental results from our implementation of an LLVM backend for TinyVM, which is an embedded systems virtual machine for C.	code generation (compiler);compiler;computation;depth-first search;embedded system;instruction scheduling;intermediate representation;llvm;programming language implementation;scheduling (computing);stack-oriented programming language;virtual machine	Jiin Park;Jinhyung Park;Wonjoon Song;Songwook Yoon;Bernd Burgstaller;Bernhard Scholz	2011	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2011.11.004	parallel computing;real-time computing;call stack;computer science;programming language	PL	-20.32048964838893	36.50679791194976	158293
fd6c0f61c649820f7237224476cd5c8d4b9090d4	mastering the windows eiffel library	windows component;windows api library;object technology;windows eiffel library;engineering quality windows software;complete windows application;windows api;quality windows software;windows software;wel library	windows component;windows api library;object technology;windows eiffel library;engineering quality windows software;complete windows application;windows api;quality windows software;windows software;wel library	bus mastering;eiffel;microsoft windows	Glenn Maughan;Raphael Simon	1999		10.1109/TOOLS.1999.10076	windows ce;real-time computing;computer science;microsoft transaction server;eiffel;software versioning;programming language;data protection api;world wide web;vbscript;dll hell;next-generation secure computing base	Logic	-32.16799623603498	41.89928858684814	158351
13e662b5388452d7f275e0adc214f580f1a02c37	petri nets with non-blocking arcs are difficult to analyze	java programming;petri net	In this paper, we study the decidability of five problems on a class of extended Petri nets. The study of this class of extended Petri nets is motivated by the problem of parametric verification of multiple copies of processes that can communicate with a partially non-blocking rendez-vous. This kind of communications occurs in abstractions of multi-threaded JAVA programs.	arcs (computing);blocking (computing);déjà vu;java;non-blocking algorithm;petri net;thread (computing)	Jean-François Raskin;Laurent Van Begin	2004	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2003.10.005	real-time computing;stochastic petri net;computer science;distributed computing;process architecture;programming language;petri net	Logic	-27.497271960258725	33.30785090098807	158459
cdd8e7ff0aa708cba5a5ecc57787e48881b9db39	ppardb/pvm: a portable pvm based parallel database management system	management system;parallel databases	Without Abstract	management system;parallel virtual machine;parallel database	N. Papakostas;George K. Papakonstantinou;Panayiotis Tsanakas	1996		10.1007/3-540-61695-0_20	computer architecture;parallel computing;database	DB	-27.72060001308402	45.87662736823643	158507
126d1da7f47ff5b57ba8d76cf149b04c40b4ab2e	identifying and validating irregular mutual exclusion synchronization in explicitly parallel programs	programa paralelo;compilateur;compiler;analisis programa;exclusion mutual;mutual exclusion;synchronisation;synchronization;lock picking;sincronizacion;program analysis;exclusion mutuelle;analyse programme;parallel program;compilador;programme parallele	Existing work on mutual exclusion synchronization is based on a structural definition of mutex bodies. Although correct, th is structural notion fails to identify many important locking patterns present in some programs. In this paper we present a novel analysis technique for identifying mu tual exclusion synchronization patterns in explicitly parallel programs. We use this analysis in a new technique, called lock-picking, which detects and eliminates redundant mutex operations. We also show that this new mutex analysis tec hnique can be used as a validation tool in a compiler. Using this analysis, a com piler can detect irregularities like lock tripping, deadlock patterns, incomple te mutex bodies, dangling lock andunlock operations and partially protected code.	compiler;deadlock;lock (computer science);mutual exclusion	Diego Novillo;Ronald C. Unrau;Jonathan Schaeffer	2000		10.1007/3-540-44520-X_50	lock;synchronization;parallel computing;real-time computing;reentrant mutex;computer science;operating system;distributed computing;programming language	SE	-21.404323729358087	33.86221049592659	158687
5ab809375a7b6a9b58ca070e5490fac35d875ac8	fault-tolerant resource reasoning	08 information and computing sciences;conference paper;artificial intelligence image processing;chapter	Separation logic has been successful at verifying that programs do not crash due to illegal use of resources. The underlying assumption, however, is that machines do not fail. In practice, machines can fail unpredictably for various reasons, e.g. power loss, corrupting resources. Critical software, e.g. file systems, employ recovery methods to mitigate these effects. We introduce an extension of the Views framework to reason about such methods. We use concurrent separation logic as an instance of the framework to illustrate our reasoning, and explore programs using write-ahead logging, e.g. an ARIES recovery algorithm.	algorithm;atomicity (database systems);concurrency (computer science);concurrent computing;database transaction;expectation propagation;fault tolerance;fault-tolerant computer system;fault-tolerant software;idempotence;message queue;point of view (computer hardware company);programming language;separation logic;verification and validation;write-ahead logging	Gian Ntzik;Pedro da Rocha Pinto;Philippa Gardner	2015		10.1007/978-3-319-26529-2_10	artificial architecture;music and artificial intelligence;computer science;artificial intelligence;data science;procedural reasoning system;artificial psychology;artificial intelligence, situated approach	PL	-21.587424737223433	40.223451118409486	158723
0c326bac51ffce5c6b81dd9b98688933a10f28b4	functioning without closure: type-safe customized function representations for standard ml	modelo dinamico;lenguaje programacion;compilateur;programming language;estudio comparativo;representation fonction;dynamic model;program transformation;standard ml;transformation programme;compiler;data representation;metalangage;typed intermediate language;etude comparative;transformacion programa;metalanguage;function representation;modele dynamique;comparative study;representacion funcion;langage programmation;cost model;compilador;metalenguaje	The CIL compiler for core Standard ML compiles whole ML programs using a novel typed intermediate language that supports the generation of type-safe customized data representations. In this paper, we present empirical data comparing the relative efficacy of several different flow-based customization strategies for function representations. We develop a cost model to interpret dynamic counts of operations required for each strategy. In this cost model, customizing the representation of closed functions gives a 12-17% improvement on average over uniform closure representations, depending on the layout of the closure. We also present data on the relative effectiveness of various strategies for reducing representation pollution, i.e., situations where flow constraints require the representation of a value to be less efficient than it would be in ideal circumstances. For the benchmarks tested and the types of representation pollution detected by our compiler, the pollution removal strategies we consider often cost more in overhead than they gain via enabled customizations. Notable exceptions are selective defunctionalization, a function representation strategy that often achieves significant customization benefits via aggressive pollution removal, and a simple form of flow-directed inlining, in which pollution removal allows multiple functions to be inlined at the same call site.	analysis of algorithms;call site;common intermediate language;compiler;defunctionalization;function representation;inline expansion;overhead (computing);standard ml;type safety	Allyn Dimock;Ian Westmacott;Robert Muller;Franklyn A. Turbak;Joe B. Wells	2001		10.1145/507635.507640	compiler;simulation;metalanguage;computer science;comparative research;external data representation;function representation;programming language;algorithm	PL	-19.325309957862448	35.40832473956492	158791
ac7ed5035ebbdd3ada5e83b85424afac70493fe7	the design and prototype of ruda, a distributed grid accounting system	estensibilidad;distributed system;network resources;gestion memoire;systeme reparti;decentralised design;securite;ruda;resource allocation;storage management;distributed accounting;resource management;accounting;integrite;computational resources;integridad;storage resources;comptabilite;resource usage data management and accounting;grid;gestion recursos;gestion memoria;sistema repartido;grid resources;integrity;rejilla;grid accounting;safety;grille;gestion ressources;contabilidad;extensibilite;scalability;asignacion recurso;grid infrastructures;allocation ressource;grid resource usage;seguridad;grid security	The grid environment contains a large and growing number of widely distributed sites with heterogeneous resources. It is a great challenge to dynamically manage and account for usage data of grid resources, such as computational, network, and storage resources. A distributed Resource Usage Data management and Accounting (RUDA) system is designed to perform accounting in the grid environment. RUDA utilises fully decentralised design to enhance scalability and supports heterogeneous resources with no significant impact on local systems. It can easily be integrated into grid infrastructures and maintains the integrity of the grid security features.	prototype	Meili Chen;Al Geist;David E. Bernholdt;Kasidit Chanchio;Daniel L. Million	2008	IJCIS	10.1504/IJCIS.2008.017442	scalability;semantic grid;resource allocation;computer science;engineering;environmental resource management;resource management;resource;database;grid;world wide web;drmaa;grid computing	HPC	-28.28584461366849	43.64719297405182	158826
537e6e616c1cd0c5f93f0f498187cf17dfd0e149	bounded dataflow networks and latency-insensitive circuits	article	We present a theory for modular refinement of Synchronous Sequential Circuits (SSMs) using Bounded Dataflow Networks (BDNs). We provide a procedure for implementing any SSM into an LI-BDN, a special class of BDNs with some good compositional properties. We show that the Latency-Insensitive property of LI-BDNs is preserved under parallel and iterative composition of LI-BDNs. Our theory permits one to make arbitrary cuts in an SSM and turn each of the parts into LI-BDNs without affecting the overall functionality. We can further refine each constituent LI-BDN into another LI-BDN which may take different number of cycles to compute. If the constituent LI-BDN is refined correctly we guarantee that the overall behavior would be cycle-accurate with respect to the original SSM. Thus one can replace, say a 3-ported register file in an SSM by a one-ported register file without affecting the correctness of the SSM. We give several examples to show how our theory supports a generalization of previous techniques for Latency-Insensitive refinements of SSMs.	correctness (computer science);dataflow;interrupt latency;iterative method;li-chen wang;refinement (computing);register file;rule 184	Muralidaran Vijayaraghavan;Arvind	2009	2009 7th IEEE/ACM International Conference on Formal Methods and Models for Co-Design		dataflow architecture;parallel computing;computer science;theoretical computer science;dataflow;distributed computing	EDA	-27.989218749918432	34.507852683143646	158848
2334b88000f4a40b3b2e409190ed315a665cb945	bounds checking with taint-based analysis	buffer overflow;compiler optimization	We analyze the performance of different bounds checking implementations. Specifically, we examine using the x86 bound instruction to reduce the run-time overhead. We also propose a compiler optimization that prunes the bounds checks that are not necessary to guarantee security. The optimization is based on the observation that buffer overflow attacks are launched through external inputs. Therefore, it is sufficient to bounds check only the accesses to those data structures that can possibly hold the external inputs. Also, it is sufficient to bounds check only the memory writes. The proposed optimizations reduce the number of required bounds checks as well as the amount of meta-data that need to be maintained to perform those checks.	bounds checking;buffer overflow;data structure;mathematical optimization;optimizing compiler;overhead (computing);taint checking;x86	Weihaw Chuang;Satish Narayanasamy;Brad Calder;Ranjit Jhala	2007		10.1007/978-3-540-69338-3_6	parallel computing;real-time computing;buffer overflow;computer science;bounds checking;optimizing compiler;distributed computing;programming language	Security	-20.25726347442896	34.20187848322727	159347
4d34af34b08d0afcd18e3bad0bacc6c8cac9766a	towards verifying determinism of systemc designs	c language;electronic engineering computing;formal verification;esl;common concurrency problems;concurrency verification problem;concurrent software;deadlock detection;determinism verification;electronic system level;formal verification;functional specification;high-level systemc designs;proven determinism;race analysis;simulative verification	Ensuring the correctness of high-level SystemC designs is an important and challenging problem in today's Electronic System Level (ESL) methodology. Prevalently, a design is checked against a functional specification given by e.g. a testcase with reference output or a user-defined property. Another research direction takes the view of a SystemC design as a piece of concurrent software. The design is then checked for common concurrency problems and thus, a functional specification is not required. Along this line, several methods for deadlock detection and race analysis have been developed. In this work, we propose to consider a new concurrency verification problem, namely input-output determinism, for Sys-temC designs. That means for each possible input, the design must produce the same output under any valid process schedule. We argue that determinism verification is stronger than both deadlock detection and race analysis. Beside being an attractive correctness criterion itself, proven determinism helps to accelerate both simulative and formal verification. We also present a preliminary study to show the feasibility of determinism verification for SystemC designs.	concurrency (computer science);correctness (computer science);deadlock;electronic system-level design and verification;experiment;formal verification;functional specification;high- and low-level;linux;schedule (computer science);simulation;systemc;test case;thread (computing);verification and validation	Hoang Minh Le;Rolf Drechsler	2014	2014 Design, Automation & Test in Europe Conference & Exhibition (DATE)		real-time computing;formal verification;software verification;computer science;distributed computing;high-level verification;runtime verification;electronic system-level design and verification;programming language;intelligent verification;functional verification	EDA	-23.65608426597107	34.231347091910706	159369
710486fa72b0800a152bb3fccec05e4464fd9c0a	data-flow based detection of loop bounds	004;upper bound;wcet analysis loop bound detection flow analysis;static analysis;data flow	To calculate the WCET of a program, safe upper bounds on the number of loop iterations for all loops in the program are needed. As the manual annotation of all loops with such bounds is difficult and time consuming, the WCET analyzer aiT originally developed by Saarland University and AbsInt GmbH uses static analysis to determine the needed bounds as far as possible. This paper describes a novel data-flow based analysis for aiT to calculate the needed loop bounds on the assembler level. The new method is compared with a pattern based loop analysis already in use by this tool.	alloy analyzer;assembly language;dataflow;for loop;iteration;mesh analysis;microsoft outlook for mac;powerpc;static program analysis;vamp;worst-case execution time	Christoph Cullmann;Florian Martin	2007		10.4230/OASIcs.WCET.2007.1193	data flow diagram;real-time computing;computer science;theoretical computer science;upper and lower bounds;static analysis;algorithm	SE	-23.127612567741593	36.12256711764233	159440
8fa672f601b294609baee2f0e8f2485d1784fd91	on asynchronous avoidance of deadlocks in parallel programs	multimodule programs;synchronous and asynchronous data exchanges;transition system;realizing map;csp;parallel programs	A number of approaches to asynchronous communication in parallel programs based on both data dependence analysis and buffering techniques are briefly described. A criterion for automatically resolving some classes of deadlocks by means of asynchronous data exchanges is established and examples showing the comparative power of the approaches for deadlock avoidance are presented.		Anatoly E. Doroshenko	1992	Parallel Processing Letters	10.1142/S012962649200043X	real-time computing;computer science;theoretical computer science;communicating sequential processes;distributed computing;programming language	HPC	-27.64187275351502	33.3706618975817	159455
eba5a8ed163678d9743b649bf569c3b698e7a793	superscalar communication: a runtime optimization for distributed applications	distributed application;instruction level parallel;superscalar;concurrency;research and development;runtime system;event;thread;network programming;programming;network;dynamic scheduling;dynamic optimization	Building distributed applications is difficult mostly because of concurrency management. Existing approaches primarily include events and threads. Researchers and developers have been debating for decades to prove which is superior. Although the conclusion is far from obvious, this long debate clearly shows that neither of them is perfect. One of the problems is that they are both complex and error-prone. Both events and threads need the programmers to explicitly manage concurrencies, and we believe it is just the source of difficulties. In this paper, we propose a novel approach—superscalar communication, in which concurrencies are automatically managed by the runtime system. It dynamically analyzes the programs to discover potential concurrency opportunities; and it dynamically schedules the communication and the computation tasks, resulting in automatic concurrent execution. This approach is inspired by the idea of superscalar technology in modern microprocessors, which dynamically exploits instruction-level parallelism. However, hardware superscalar algorithms do not fit software in many aspects, thus we have to design a new scheme completely from scratch. Superscalar communication is a runtime extension with no modification to the language, compiler or byte code, so it is good at backward compatibility. Superscalar communication is likely to begin a brand new research area in systems software, which is characterized by dynamic optimization for networking programs.	algorithm;backward compatibility;byte;cognitive dimensions of notations;compiler;computation;concurrency (computer science);distributed computing;dynamic programming;execution unit;instruction-level parallelism;lua;mathematical optimization;microprocessor;parallel computing;programmer;programming model;runtime system;superscalar processor;thread (computing)	Huiba Li;Shengyun Liu;Yuxing Peng;Dongsheng Li;Hangjun Zhou;Xicheng Lu	2010	Science China Information Sciences	10.1007/s11432-010-4051-4	programming;thread;computer architecture;parallel computing;real-time computing;concurrency;event;dynamic priority scheduling;computer science;superscalar;computer network programming	PL	-19.1258852351632	39.51706757229181	159781
5cfc936d12bbd8a0f100687b12b20e406215f30a	unikernels: library operating systems for the cloud	hypervisor;functional programming;operating system;microkernel	We present unikernels, a new approach to deploying cloud services via applications written in high-level source code. Unikernels are single-purpose appliances that are compile-time specialised into standalone kernels, and sealed against modification when deployed to a cloud platform. In return they offer significant reduction in image sizes, improved efficiency and security, and should reduce operational costs. Our Mirage prototype compiles OCaml code into unikernels that run on commodity clouds and offer an order of magnitude reduction in code size without significant performance penalty. The architecture combines static type-safety with a single address-space layout that can be made immutable via a hypervisor extension. Mirage contributes a suite of type-safe protocol libraries, and our results demonstrate that the hypervisor is a platform that overcomes the hardware compatibility issues that have made past library operating systems impractical to deploy in the real-world.	address space;cloud computing;compile time;compiler;high- and low-level;hypervisor;immutable object;library (computing);ocaml;operating system;prototype;type safety;unikernel	Anil Madhavapeddy;Richard Mortier;Charalampos Rotsos;David J. Scott;Balraj Singh;Thomas Gazagnaire;Steven A F Smith;Steven Hand;Jon A Crowcroft	2013		10.1145/2451116.2451167	embedded system;real-time computing;storage hypervisor;computer science;operating system;hypervisor;functional programming	Arch	-21.00799024966393	36.36455051773847	160028
2e151b36863baaca9e9c274973842f9ce428badf	hypertool: a programming aid for message-passing systems	synchronization errors;programming profession processor scheduling computer science parallel processing automation scheduling algorithm partitioning algorithms multiprocessing systems system recovery data mining;program quality measures;software tools electronic messaging scheduling;message passing system;automation concepts;indexing terms;programming aid;critical path method;message passing systems;scheduling;index termshypertool;electronic messaging;software tools;program quality measures hypertool programming aid message passing systems automation concepts scheduling communication primitive insertion synchronization errors critical path method performance estimates;performance estimates;program development;communication primitive insertion	|As both the number of processors and the complexity of problems to be solved increase, programming multiprocessing systems becomes more di cult and errorprone. This paper discusses programming assistance and automation concepts and their application to a program development tool for message-passing systems called Hypertool. It performs scheduling and handles the communication primitive insertion automatically. Two algorithms, based on the critical-path method, are presented for scheduling processes statically. Hypertool also generates the performance estimates and other program quality measures to help programmers in improving their algorithms and programs.	algorithm;central processing unit;critical path method;message passing;multiprocessing;programmer;scheduling (computing)	Min-You Wu;Daniel Gajski	1990	IEEE Trans. Parallel Distrib. Syst.	10.1109/71.80160	parallel computing;real-time computing;index term;computer science;theoretical computer science;operating system;critical path method;database;distributed computing;programming language;scheduling;algorithm	EDA	-24.041608973829526	41.451545458728006	160036
4a37f2137e516b74691bc5c853a430703f0e0d87	implementation of an embedded system on a ts7800 board for robot control	xml actuators control engineering computing embedded systems humanoid robots learning artificial intelligence linux microcomputers program compilers sensors;sensors;actuators;embedded systems;equilibrium subsystem embedded system robot control growing functional modules learning based controllers gfm generic embedded interface ts 7800 single board computer sbc debian linux operating system external boards actuators xml configuration file virtual sensors embedded system interface launcher video capture compilers eabi emulation extra libraries final embedded system humanoid robot gfm controller;ports computers servomotors embedded systems actuators robot sensing systems;humanoid robots;xml;linux;control engineering computing;learning artificial intelligence;program compilers;gfm linux embedded system robot interface learning based control ts7800;microcomputers	Growing Functional Modules (GFM) learning based controllers need to be experimented on real robots. In 2009, looking to develop a flexible and generic embedded interface for such robots, we decided to use a TS-7800 single board computer (SBC) with a Debian Linux operating system. Despite the many advantages of this board, implementing the embedded system has been a complex task. This paper describes the implementation of protocols through the TS-7800 different ports (RS232, TCP/IP, USB, analog and digital pins) as well as the connection of external boards (TS-ADC24, TS-DIO64, SSC-32 and LCD display). This implementation was required to connect a large range of actuators, sensors and other peripherals. Furthermore, the architecture of the embedded system is exposed in detail, including topics such as the XML configuration file that specifies the peripherals connected to the SBC, the concept of virtual sensors, the implementation of parallelism and the embedded system interface launcher. Technical aspects such as the optimization of video capture and processing are detailed because their execution required specific compilers versions, EABI emulation and extra libraries (openCV libjpg and libpngand libv4l). The final embedded system was implemented in a humanoid robot and connected to the GFM controller in charge of developing its equilibrium subsystem.	application binary interface;compiler;debian;embedded system;emulator;humanoid robot;internet protocol suite;library (computing);linux;mathematical optimization;opencv;operating system;parallel computing;peripheral;rs-232;remote desktop services;robot control;sensor;single-board computer;usb;xml	Jérôme Leboeuf Pasquier;Arturo Gonzalez Villa;Kevin Herrera Burgos;Donald Carr-Finch	2014	2014 International Conference on Electronics, Communications and Computers (CONIELECOMP)	10.1109/CONIELECOMP.2014.6808580	embedded system;embedded operating system;real-time computing;xml;computer hardware;computer science;sensor;humanoid robot;artificial intelligence;operating system;microcomputer;linux kernel;actuator	Embedded	-32.58127801922032	38.78094309889126	160061
e9852418b28b3d1990ce787193ed1deb2cbc406a	the xtreemfs architecture - a case for object-based file systems in grids		In today’s Grids, files are usually managed by Grid data management systems that are superimposed on existing file and storage systems. In this paper, we analyze this predominant approach and argue that object-based file systems can be an alternative when adapted to the characteristics of a Grid environment. We describe how we are solving the challenge of extending the object-based storage architecture for the Grid in XtreemFS, an object-based file system for federated infrastructures. Copyright © 2008 John Wiley & Sons, Ltd.	database;object storage;object-based language;systems architecture;xtreemfs	Felix Hupfeld;Toni Cortes;Björn Kolbeck;Jan Stender;Erich Focht;Matthias Hess;Jesús Malo;Jonathan Martí;Eugenio Cesario	2008	Concurrency and Computation: Practice and Experience	10.1002/cpe.1304	self-certifying file system;grid file;computer science;storage resource broker;database;distributed computing;open;global namespace;world wide web	HPC	-28.64066185300603	44.98946803283237	160281
189cc86044cd4fe61c97a2b2de3cc60d5c7d1b8d	evaluation of android dalvik virtual machine	virtual machine;just in time compilation;dalvik;interpreter;android platform;java	More than half of the smart phones world-wide are currently employing the Android platform, which employs Java for programming its applications. The Android Java is to be executed by the Dalvik virtual machine (VM), which is quite different from the traditional Java VM such as Oracle's HotSpot VM. That is, Dalvik employs register-based bytecode while HotSpot employs stack-based bytecode, requiring a different way of interpretation. Also, Dalvik uses trace-based just-in-time compilation (JITC), while HotSpot uses method-based JITC. Therefore, it is questioned how the Dalvik VM performs compared the HotSpot VM. Unfortunately, there has been little comparative evaluation of both VMs, so the performance of the Dalvik VM is not well understood. More importantly, it is also not well understood how the performance of the Dalvik VM affects the overall performance of the Android applications (apps). In this paper, we make an attempt to evaluate the Dalvik VM. We install both VMs on the same board and compare the performance using EEMBC benchmark. Our results show that Dalvik slightly outperforms HotSpot in the interpreter mode due to its register-based bytecode. In the JITC mode, however, Dakvik is slower than HotSpot by more than 2.9 times and its generated code size is not smaller than HotSpot's due to its worse code quality and trace-chaining code. We also investigated how real Android apps are different from Java benchmarks, to understand why the slow Dalvik VM does not affect the performance of the Android apps seriously.	android;benchmark (computing);eembc;java hotspot virtual machine;java virtual machine;just-in-time compilation;processor register;smartphone;software quality;stack-oriented programming language;z/vm	Hyeong-Seok Oh;Beom-Jun Kim;Hyung-Kyu Choi;Soo-Mook Moon	2012		10.1145/2388936.2388956	embedded system;real-time computing;interpreter;computer science;virtual machine;operating system;just-in-time compilation;programming language;java	Security	-20.306569418762372	37.65115275046446	160327
da93bdcf0975f7ddefb08f9ad76bca613c51d5c8	expressing high-level visual concurrency structures in the pfg kernel language	virtual machine;virtual machine high level visual concurrency structures pfg kernel language parallel programming language graphical syntax formal operational semantics hg model concurrent real time software systems place timed petri net parallel threads software construction higher level languages graphical assembly language;parallel programming concurrency control high level languages;high level languages;concurrent computing kernel mercury metals yarn parallel programming virtual machining computational modeling computer science educational institutions real time systems;real time;operational semantics;software systems;parallel programming;time petri net;parallel programming language;concurrency control	The PFG language is a parallel programming language with graphical syntax. Its formal operational semantics are expressed by the HG model of concurrent real-time software systems. Informally, each procedure in a PFG program is a hierarchical graph expressing the data state and a place-timed Petri net expressing the possible parallel threads of control operating the data state. The author demonstrates how the PFG language, which is sufficient in itself for software construction, can be used as a kernel language for the implementation of higher-level languages. PFG can then be thought of as a graphical assembly language, with the HG model being the virtual machine. >		P. David Stotts	1988		10.1109/WVL.1988.18025	fourth-generation programming language;first-generation programming language;parallel computing;very high-level programming language;language primitive;computer science;programming language implementation;theoretical computer science;third-generation programming language;programming paradigm;low-level programming language;fifth-generation programming language;programming language theory;programming language;second-generation programming language;high-level programming language;concurrent object-oriented programming;parallel programming model	ML	-25.569196619157694	33.77010878319959	160333
43f770e28aa54b5f0c180e282ebc0c4f1d9e4989	a monitoring architecture for control grids	estensibilidad;tolerancia falta;distributed system;debugging;puesta a punto programa;constrenimiento flexible;metodo adaptativo;evaluation performance;layered architecture;haute performance;systeme reparti;performance evaluation;fault tolerant;maintenance;recoleccion dato;data gathering;surveillance;monitoring architecture;pervasive computing;evaluacion prestacion;echantillonnage;accounting;distributed computing;methode adaptative;comptabilite;constraint satisfaction;grid monitoring architecture;ease of use;debogage;sampling;grid;informatica difusa;satisfaction contrainte;monitoring system;soft constraint;vigilancia;sistema repartido;monitoring;informatique diffuse;rejilla;control grids;fault tolerance;adaptive method;data visualization;alto rendimiento;mantenimiento;grille;calculo repartido;contrainte souple;visualisation donnee;contabilidad;extensibilite;scalability;monitorage;satisfaccion restriccion;muestreo;monitoreo;collecte donnee;high performance;high speed;calcul reparti;tolerance faute;large data;time constraint	Interdisciplinary projects Monitoring systems are nowadays ubiquitous in complex environments, such as Grids. Their use is fundamental for performance evaluation, problem spotting, advanced debugging and per-use accounting. Building such systems raises challenging issues, like data gathering from Grid components, low intrusiveness, ease of use, adaptive data visualization, faulttolerance and self-maintenance. How well does this system work?	data visualization;debugging;grid computing;performance evaluation;usability	Alexandru Iosup;Nicolae Tapus;Stéphane Vialle	2005		10.1007/11508380_94	embedded system;fault tolerance;real-time computing;simulation;computer science;operating system;distributed computing;data visualization;statistics	HPC	-28.019328390585095	42.42648734825453	160419
fb1629be9eabe20264c5e189d7e1bd2a7ea57c66	specifying concurrent objects	distributed application;004 datenverarbeitung;high level petri net;object interaction;computer model;abstract data type;distributed data structure;formal semantics;mutual exclusion;cartesian product;concurrent systems;distributed environment;community networks;object oriented;informatik;multiple inheritance;message passing;petri net;data structure;state transition;object oriented paradigm;dynamic behavior	The object-oriented style of programming (OOP) is gaining increasing importance as a practical technique for organizing large designs and programs. Another striking aspect of OOP is its potential for concurrent and distributed applications which is based on the fact that objects may coexist in time and concurrently may exchange information by message passing. Up to now, however, there is only little progress in the development of formal computation models that exploit the full power of concurrency inherent in the OOP paradigm. (One of the few exceptions is the actor model [1].) As a consequence, there are not many OOP languages such as POOL [2] or Trellis/Owl [7] that provide mechanisms allowing the designer to keep control of how objects are dynamically created, how they interact in a distributed environment, and how objects can be allocated on a network of processors. Our Model. We propose a model of concurrent objects that integrates ideas from three different research areas to cope with what we think is the substance of the object-oriented paradigm: 1) Cardelli's work on a formal semantics of multiple inheritance [3] influenced our way of thinking about object decomposition and inheritance relationships between them; in particular, we adopt his idea to base the decomposition of objects on labeled Cartesian products and disjoint sums. 2) The algebraic foundation of abstract data types provides a representation independent notion of data structures and encapsulation concepts. 3) To support a notion of distributed state and concurrent state changes, we use high level Petri nets. They describe dynamic behavior of concurrent systems in a way that is at the same time formal and visual. It is easy to see that record and variant type constructors can be handled in an algebraic framework, if taking some care of variants. Moreover, in [5] and [6] we have shown that algebraic and Petri net based specification techniques can be unified in a conceptually and semantically coherent framework. In the sequel we give two examples to explain this combination of concepts. Similar to [4], we distinguish between functions to denote object attributes and methods to denote state changing operations: we use Cardelli's notation of variants and records, and an intuitive notation for signatures and conditional axioms. We allow methods to operate concurrently on an object's attributes, provided that they do not share any attribute of that object. Variant objects. Variants are taken to model sequential objects. The disjoint cases of a variant are used to describe the set of distinct states in which a variant object can be observed. All methods defined on a variant object mutually exclude each other and affect a specific state transition. For example, the simple object module SENDER specified below might form a component in the specification of an alternating bit protocol: The axioms both specify constraints to the applicability of methods and the effect a method invocation has on the state of an instance. For example, method get-ack is only applicable if an instance, say S, is in the state labeled snt: the effect of get-ack either is that S is in state ack (in which a new message can be accepted) or in state rdy (in which the old message is to be resent). Like Cardelli, we assume basic operations as-L to extract the contents of a variant object with a particular label L. In place of the axioms, we better could have used high level Petri nets1 to visualize the dynamic behavior of sender objects: Remark: The dependency between the control bits B, B' and the label L involved in method get-ack must be specified by an axiom. The new method is omitted. Record objects. More interesting behavioral aspects are associated with record objects as we view their attributes as potential candidates for concurrent manipulation. To achieve this, we conceptually treat record objects as distributed data structures by splitting them along their decomposition in attributes. For each method we have to indicate which attributes it needs to access. Then, concurrency arises when methods access different attributes of a particular object. In the specification below we discuss some aspects of a host in a communications network. It is composed of different, partly independent subsystems such as a server providing diverse client services, input and output buffers to store incoming and outgoing messages, a sender, and a receiver which are responsible message transmission to other hosts. For simplification we give meaning only to a few of the conceivable methods. Discussion. The above Petri net reflects the behavioral concepts we are interested in as follows: 1) Independently accessible local data appear as distinct data tokens: 2) mutual exclusion between methods is manifested in terms of conflicting accesses to such tokens: 3) sequential dependencies are expressed by a producer-consumer relationship w.r.t. particular tokens (cf. the previous example); 4) concurrency arises when methods access different tokens; and (what has not been shown) 5) object interaction is expressed as participation in common method invocations. Conclusions. The underlying theory of Petri nets offers concepts for reasoning about lifeness and safeness of a behavior specification and provides an appropriate notion of nonsequential observations of method executions while many-sorted partial algebras provide a precise meaning of the local data operated on. Inheritance mechanism have not been discussed here as we are not yet sure whether our initial ideas to extend Cardelli's structural approach to behavior specifications really will hold.	abstract data type;actor model;alternating bit protocol;care-of address;cartesian closed category;central processing unit;coexist (image);coherence (physics);computation;concurrency (computer science);concurrent computing;customer relationship management;data buffer;data structure;distributed computing;high-level programming language;input/output;linear algebra;message passing;multiple inheritance;mutual exclusion;object file;organizing (structure);petri net;producer–consumer problem;programming paradigm;semantics (computer science);server (computing);state transition table;subroutine;telecommunications network;text simplification;trellis quantization;type constructor;type signature;variant object	Bernd J. Krämer	1988	SIGPLAN Notices	10.1145/67387.67432	multiple inheritance;message passing;data structure;mutual exclusion;computer science;theoretical computer science;formal semantics;cartesian product;distributed computing;programming language;object-oriented programming;abstract data type;petri net;algorithm;distributed computing environment	DB	-26.97388212282822	32.41817949212101	160488
0850aed182893ec8fe728b21bad8e4f8e3581700	interactive microprogram validation: a prime 400 testbed facility	microcode assembler;event driven microprogram simulator;microcode developement system;microprogramming;microcode test facility	This paper presents a solution to the problem of an inadequate microprogram testbed facility for the Prime 400 system, but more importantly, defines typical problems resulting from lack of good microprogram developement software in the university environment, and provides a model for their solution.	microcode;testbed	Phillip Crews;Laura M. Leventhal	1979		10.1145/1014188.803013	computer architecture;parallel computing;computer hardware;computer science;operating system;microcode	OS	-25.434105264983867	37.84306746467392	160779
8f67eeb7d452b7f95c4f0989c8ba323d9be0d6e3	towards a calculus for wireless systems	interferences;operational semantics;broadcast;reduction semantics;labelled transition semantics;wireless systems	In wireless systems, the communication mechanism combines features of broadcast, synchrony, and asynchrony. We develop an operational semantics for a calculus of wireless systems. We present a Reduction Semantics and a Labelled Transition Semantics and prove a correspondence result between them. We first consider a core calculus, essentially with only the primitives for communication, and then a few extensions. A major goal of the semantics is to describe the forms of interferences among the activities of processes that are peculiar of wireless systems. Such interferences occur when a location is simultaneously reached by two transmissions.		Nicola Mezzetti;Davide Sangiorgi	2006	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2006.04.017	failure semantics;computer science;theoretical computer science;mathematics;distributed computing;programming language;operational semantics;denotational semantics;algorithm	ECom	-28.570754283995363	32.76628281803555	160781
5629aa155ee66488bb5ec150c65b17e3e8bd125f	design and performance of an object-oriented framework for high-speed electronic medical imaging	object oriented framework;medical image;high performance	This paper describes the design and performance of an object-oriented communication framework being developed by the Health Imaging division of Eastman Kodak and the Electronic Radiology Laboratory at Washington University School of Medicine. The framework is designed to meet the demands of next-generation electronic medical imaging systems, which must transfer extremely large quantities of data efficiently and flexibly in a distributed environment. A novel aspect of this framework is its seamless integration of flexible high-level CORBA distributed object computing middleware with efficient low-level socket network programming mechanisms. In the paper, we outline the design goals and software architecture of our framework, describe how we resolved design challenges, and illustrate the performance of the framework over high-speed ATM networks.	atm turbo;common object request broker architecture;computer network programming;distributed object;high- and low-level;medical imaging;middleware;radiology;seamless3d;software architecture	Irfan Pyarali;Timothy H. Harrison;Douglas C. Schmidt	1996	Computing Systems		real-time computing;simulation;engineering;computer engineering	HPC	-33.441007196979086	44.93142801936881	160822
c14c25a4d695fb1e7542abcd1f72a1811fa59e33	experience with rapid prototypes	encapsulation;fl;protocols;programming environments;distributed protocol;reusability;software prototyping;high performance c code;clocks;collective communication;programming environment;parallel machines rapid environment rapid prototypes distributed protocols programming encapsulation reusability transitional programming environment c rapid fl subset functional language fl storage management communication management clock synchronization high performance c code communication protocol;storage management;prototypes;prototypes object oriented programming protocols functional programming programming profession encapsulation programming environments safety clocks synchronization;transitional programming environment;object oriented programming;functional programming;rapid prototyping;distributed protocols;synchronization;programming profession;rapid environment;software reusability;safety;rapid fl subset;communication protocol;clock synchronization;parallel machines;learning to program;c;software prototyping protocols programming environments functional programming software reusability;rapid prototypes;communication management;functional language;high performance;programming	The goals of the RAPID environment are (1 ) to mate the programming of distributed protocols simp l e without restricting the protocol relevant choices of the programmer, (2) to provide encapsulation and reusability that are at least as powerful as those offered b y object oriented programming, and (3) to provide for different styles of programming that mate RAPID an easy transitional programming environment between older and lower level languages and C. The environment provides and is programmed in the RAPID-FL subset of the functional language FL. Although the full power of FL is available to the programmer, a very small number of concepts need to be learned to program in RAPID-FL. Moreover, restriction to RAPID-FL means that one can have the safety of a functional language combined with reasonable uses of assignment. RAPID makes storage management trivial and reduces the complezity of communication management to handling a f e w simple commands. The programmer can arrange for true broadcast or point-to-point communication via either UDP or TCP, without having to master the details of these communication protocols. A protocol written in RAPID-FL is compiled to C. It can run anywhere C can run and interoperate with other programs written either in C or in RAPID-FL. So the programmer can build a RAPID prototype and replace pieces of it with C to provide a test bed for the development of a Cprogram or for better performance. In this paper we describe our ezperience using RAPID to perform clock synchronization experiments 'This research was supported in part by Yeshaya Horowitz Association. 62 1074-6005194 $3.00	clock synchronization;compiler;encapsulation (networking);experiment;functional programming;integrated development environment;interoperability;point-to-point protocol;point-to-point (telecommunications);programmer;prototype;rapid prototyping;testbed	Danny Dolev;Ray Strong;Ed Wimmers	1994		10.1109/IWRSP.1994.315908	embedded system;communications protocol;real-time computing;computer science;operating system;software engineering;distributed computing;programming paradigm;programming language;functional programming	PL	-30.549258471611086	37.38552600523097	161027
13d3096276731a6771943f3408edf19136c9afeb	fuzzy-timing petri net model for distributed multimedia synchronization	streaming media multimedia databases quality of service timing multimedia systems nonhomogeneous media jitter software systems laboratories fuzzy systems;distributed processing;distributed multimedia;object oriented programming;satisfiability;fuzzy logic multimedia communication quality of service synchronisation petri nets distributed processing object oriented programming;fuzzy logic;synchronisation;time petri net;multimedia communication;inter stream synchronizations fuzzy timing petri net model distributed multimedia synchronization fine grained temporal petri net model fuzzy temporal requirements quality of service requirements relative temporal relations multimedia objects intra stream synchronizations;petri nets;quality of service;petri net	This paper presents a new fine-grained temporal Petri net model for distributed multimedia synchronization that can handle fuzzy temporal requirements and facilitate to verify the possibility of satisfying QoS requirements. We present a procedure for constructing the fine-grained model, starting from a set of relative temporal relations among multimedia objects. And we give an approach to infer unknown durations. Finally, we discuss how to model intra-stream and inter-stream synchronizations so as to guarantee the QoS.	petri net	Yi Zhou;Tadao Murata	1998		10.1109/ICSMC.1998.725416	real-time computing;computer science;artificial intelligence;theoretical computer science;distributed computing;petri net	Robotics	-33.07585670971989	35.36431272219593	161205
fda11794212730739a6a353f45aec8ebd91ec763	an infrastructure for monitoring and management in computational grids	performance measure;event service;distributed memory systems;computational grid;client server architecture;architecture client serveur;interface programme application;systeme memoire repartie;fault tolerant system;parallel architectures;design and implementation;architecture parallele;application program interfaces;grid service;sistema tolerando faltas;metaprogrammation;arquitectura cliente servidor;systeme tolerant les pannes;coarse grained;metaprogramming;metaprogramacion;directory service	We presentthe designand implementationof an infrastructurethat enablesmonitoring of resources,services,and applicationsin a computational grid andprovidesa toolkit to help managetheseentitieswhenfaultsoccur. This infrastructurebuilds on threebasicmonitoring components:sensorsto perform measurements, actuatorsto performactions,andaneventserviceto communicate eventsbetweenremoteprocesses. We describehow we applyour infrastructureto support a grid service and an application: (1) the Globus Metacomputing Directory Service;and (2) a long-runningand coarse-grainedparameterstudy application.We usetheseapplicationto show thatour monitoringinfrastructureis highly modular , conveniently retar gettable, and e xtensible.	computation;directory service;grid computing;metacomputing	Abdul Waheed;Warren Smith;Jude George;Jerry C. Yan	2000		10.1007/3-540-40889-4_18	metaprogramming;embedded system;fault tolerance;real-time computing;directory service;computer science;operating system;database;distributed computing;converged infrastructure;computer security;client–server model	HPC	-29.135086423001482	45.66301464171811	161255
2ef0a1be6a2f2ce22d27286dfa6d8808cd2db9fd	analysis of overhead in dynamic java performance monitoring	dynamic instrumentation;performance measurement overhead;java	In production environments, runtime performance monitoring is often limited to logging of high level events. More detailed measurements, such as method level tracing, tend to be avoided because their overhead can disrupt execution. This limits the information available to developers when solving performance issues at code level. One approach that reduces the measurement disruptions is dynamic performance monitoring, where the measurement instrumentation is inserted and removed as needed. Such selective monitoring naturally reduces the aggregate overhead, but also introduces transient overhead artefacts related to insertion and removal of instrumentation. We experimentally analyze this overhead in Java, focusing in particular on the measurement accuracy, the character of the transient overhead, and the longevity of the overhead artefacts.  Among other results, we show that dynamic monitoring requires time from seconds to minutes to deliver stable measurements, that the instrumentation can both slow down and speed up the execution, and that the overhead artefacts can persist beyond the monitoring period.	aggregate data;experiment;high-level programming language;java performance;overhead (computing);run time (program lifecycle phase)	Vojtech Horký;Jaroslav Kotrc;Peter Libic;Petr Tuma	2016		10.1145/2851553.2851569	embedded system;real-time computing;computer science;engineering;operating system;overhead;java	Metrics	-21.919733165363077	38.26302927452378	161486
a6a2a074e0b824e9e15245f7284fbd82c43cfee2	thread management in mashup execution platforms	event driven mashups;web api;management strategy;low latency;thread management strategy;high throughput;orchestration	We propose a Thread Management Strategy for Server Side Platforms that support the execution of Event Driven Mashups (i.e., composite services in which the service components interact through events rather than through the classical Call-Response paradigm). A Thread Management Strategy is necessary considering that such platforms are supposed to support the concurrent execution of large number of Mashups and as a consequence must exhibit high throughput and low latency. The Thread Management Strategy stems from an analysis of the interaction paradigms inside Mashups (e.g., call-response, polling, etc.). The paper describes the Thread Management Strategy and discusses its performance in the light of a set of experiments.	cloud computing;docs (software);event-driven architecture;experiment;internet;jackbe;java virtual machine;mashup (web application hybrid);open road tolling;polling (computer science);presto;programming paradigm;response time (technology);server-side;symantec endpoint protection;thread (computing);throughput;utility;web application;web development;world wide web	Michele Stecca;Massimo Maresca	2010		10.1145/1967486.1967628	real-time computing;computer science;operating system;world wide web	DB	-31.8229376171172	43.62768681701663	161858
16c84bbabf5977dcb742791baea24a6f513505dd	fully concurrent garbage collection of actors on many-core machines	garbage collection;concurrency;message passing;actors;many core	Disposal of dead actors in actor-model languages is as important as disposal of unreachable objects in object-oriented languages. In current practice, programmers are required to either manually terminate actors, or they have to rely on garbage collection systems that monitor actor mutation through write barriers, thread coordination through locks etc. These techniques, however, prevent the collector from being fully concurrent.  We developed a protocol that allows garbage collection to run fully concurrently with all actors. The main challenges in concurrent garbage collection is the detection of cycles of sleeping actors in the actors graph, in the presence of concurrent mutation of this graph. Our protocol is solely built on message passing: it uses deferred direct reference counting, a dedicated actor for the detection of (cyclic) garbage, and a confirmation protocol (to deal with the mutation of the actor graph).  We present our ideas informally through an example, and then present a formal model, prove soundness and argue completeness. We have implemented the protocol as part of a runtime library. As a preliminary performance evaluation, we discuss the performance of our approach as currently used at a financial institution, and use four benchmarks from the literature to compare our approach with other actor-model systems. These preliminary results indicate that the overhead of our approach is small.	actor model;formal language;garbage collection (computer science);lock (computer science);manycore processor;message passing;overhead (computing);performance evaluation;programmer;reference counting;runtime library;terminate (software);unreachable memory	Sylvan Clebsch;Sophia Drossopoulou	2013		10.1145/2509136.2509557	manual memory management;garbage;parallel computing;message passing;real-time computing;concurrency;computer science;garbage in, garbage out;distributed computing;garbage collection;programming language	PL	-21.346858678752984	34.05936155520207	161928
ab2d1fd9a27039cb4dcdf91422ca54e6ca38dbaf	prettier concurrency: purely functional concurrent revisions	prettier concurrency;deterministically resolve conflict;rev monad;o operation;different thread;st monad;imperative mutable variable;functional concurrent revision;deterministic conflict resolution;conflicting concurrent task;concurrent revision;concurrent game;data structure;side effect;isolation;software transactional memory;conflict resolution;transaction	This article presents an extension to the work of Launchbury and Peyton-Jones on the ST monad. Using a novel model for concurrency, called concurrent revisions [3,5], we show how we can use concurrency together with imperative mutable variables, while still being able to safely convert such computations (in the Rev monad) into pure values again.  In contrast to many other transaction models, like software transactional memory (STM), concurrent revisions never use rollback and always deterministically resolve conflicts. As a consequence, concurrent revisions integrate well with side-effecting I/O operations. Using deterministic conflict resolution, concurrent revisions can deal well with situations where there are many conflicts between different threads that modify a shared data structure. We demonstrate this by describing a concurrent game with conflicting concurrent tasks.	client–server model;computation;concurrency (computer science);concurrent data structure;haskell;immutable object;imperative programming;input/output;jones calculus;monad (functional programming);producer–consumer problem;rev;seamless3d;server (computing);software transactional memory;type system	Daan Leijen;Manuel Fähndrich;Sebastian Burckhardt	2011		10.1145/2034675.2034686	transactional memory;parallel computing;real-time computing;isolation;data structure;computer science;conflict resolution;software transactional memory;database;programming language;side effect;concurrent object-oriented programming	PL	-26.08227037453021	33.53823123208163	162195
4b5f547bda4b2d17b458ea75b8d40ca63412b7c3	error detection in data base systems	complex data;design and implementation;error detection	"""Incorrect data poses a serious impediment to the effective use of computerized data bases. Conventional approaches to the design and implementation of automated data error detection systems are inadequate for large and complex data bases. Partly, this derives from the inherent intricacy of the problem, with decisions being required as to what checks to perform, how and when to do the checking, and how to respond should an error be found; writing procedures to accomplish these functions is a difficult programming task. Also at fault is the unrealistic and overly simplistic view of data correctness embodied in most contemporary systems.  """"Intelligent"""" data checking systems are required, which possess more extensive knowledge of the data base environment. They will need to understand the structure of the world which the data base models; the way the data base is used, and the relative importance of its various components; the sources of the errors that might occur and the costs of detecting them; and the patterns and rates of errors that actually do occur. Such a system would then be in a position to detect a wide range of errors, allocating its resources in a systematic fashion and responding appropriately to different error situations."""	correctness (computer science);criticality matrix;data validation;database;error detection and correction;front-end processor;heuristic (computer science);norm (social);sensor	Michael Hammer	1976		10.1145/1499799.1499908	computer science;theoretical computer science;data mining;distributed computing	DB	-23.793214870803546	40.5579245450234	162393
3aa8da56859c8b56f0105d4791ee984965a28630	local area networks and the practical aspects of interworking	local network;reseau local;local area network	The potential for cost-effective distribution and coordinated sharing of information processing systems is substantially enhanced by the recent emergence of comparatively cheap, very reliable, high speed local area networks (LANs). The lack of common interface specifications is however a major impediment to progress. The benefits to be gained by ensuring that the user accessible interface to a local area network provides identical functionality to that offered over a long haul network argue for a subset of features common to both types. This need for commonali ty argues against exploitation of some of the more novel features intrinsic to certain styles of technologically advanced systems. By this means, the enormous investment in existing (wide area) networked applications can be applied within a local context and, perhaps even more importantly, applications mounted in a LAN environment will also be accessible from, and be able to communicate with, other more remote systems.	emergence;information processing	Kenneth S. Heard	1983	Computer Networks	10.1016/0376-5075(83)90045-4	local area network;simulation;telecommunications;computer science;operations research;computer security;computer network	Metrics	-28.916232964070883	44.458332636260444	162437
d9a54f4ecb83a0ed4cefa192e1f24a4c6254089d	a taxonomy of distributed termination detection algorithms	distributed system;fault tolerant;termination detection;first in first out;distributed computing;network topology;asynchronous communication;communication protocol	An important problem in the ®eld of distributed systems is that of detecting the termination of a distributed computation. Distributed termination detection (DTD) is a dicult problem due to the fact that there is no simple way of gaining knowledge of the global state of the system. Of the algorithms proposed in the last 15 years, there are many similarities. We have categorized these algorithms based on the following factors: algorithm type (e.g., wave, credit-recovery), required network topology, algorithm symmetry, required process knowledge, communication protocol (synchronous or asynchronous), communication channel behavior (®rst-in ®rst-out (FIFO) or non-FIFO), message optimality, and fault tolerance. This methodology is intended to guide future research in DTD algorithms (since research continues on these algorithms) as well as to provide a classi®cation survey for this area. Ó 1998 Elsevier Science Inc. All rights reserved.	byzantine fault tolerance;categorization;channel (communications);channel (programming);communications protocol;computation tree;dijkstra's algorithm;distributed algorithm;distributed computing;fifo (computing and electronics);file spanning;message passing;network topology;sensor;spanning tree;symmetric-key algorithm;taxonomy (general)	Jeff Matocha;Tracy Camp	1998	Journal of Systems and Software	10.1016/S0164-1212(98)10034-1	communications protocol;distributed algorithm;fault tolerance;real-time computing;fifo and lifo accounting;computer science;theoretical computer science;asynchronous communication;distributed computing;network topology	Theory	-21.971786600199945	43.49928018795403	162520
195ca63c1053ed616f69ea34d79ca7f78a9161ca	dynamic testing for deadlocks via constraints	verification;system recovery instruction sets schedules testing synchronization detectors probabilistic logic;detectors;reliability;deadlock triggering;should happen before relation;verification deadlock triggering scheduling should happen before relation constraint reliability;testing;constraint;system recovery;synchronization;scheduling;schedules;probabilistic logic;scheduling concurrency control program diagnostics program testing;dynamic testing static analysis memory access real world programs steering failure scheduling constraints conlock deadlock detectors;instruction sets	Existing deadlock detectors are either not scalable or may report false positives when suggesting cycles as potential deadlocks. Additionally, they may not effectively trigger deadlocks and handle false positives. We propose a technique called ConLock+, which firstly analyzes each cycle and its corresponding execution to identify a set of scheduling constraints that are necessary conditions to trigger the corresponding deadlock. The ConLock+ technique then performs a second run to enforce the set of constraints, which will trigger a deadlock if the cycle is a real one. Or if not, ConLock+ reports a steering failure for that cycle and also identifies other similar cycles which would also produce steering failures. For each confirmed deadlock, ConLock+ performs a static analysis to identify conflicting memory access that would also contribute to the occurrence of the deadlock. This analysis is helpful to enable developers to understand and fix deadlocks. ConLock+ has been validated on a suite of real-world programs with 16 real deadlocks. The results show that across all 811 cycles, ConLock+ confirmed all of the 16 deadlocks with a probability of ≥80 percent. For the remaining cycles, ConLock+ reported steering failures and also identified that five deadlocks also involved conflicting memory accesses.	deadlock;dynamic testing;scalability;scheduling (computing);sensor;static program analysis	Yan Cai;Qiong Lu	2016	IEEE Transactions on Software Engineering	10.1109/TSE.2016.2537335	synchronization;detector;parallel computing;real-time computing;verification;schedule;computer science;operating system;instruction set;reliability;distributed computing;software testing;probabilistic logic;constraint;scheduling	SE	-21.607084618996133	39.231347200150495	162789
70b1a9a8440b156c7cced6da28d73fdbf7328a72	semi-automatic region-based memory management for real-time java embedded systems	program diagnostics;dynamic memory management;storage management embedded systems inference mechanisms java program diagnostics;memory consumption;storage management;memory leaks;region based memory management;inference mechanisms;real time java embedded systems;embedded system;garbage collection;region inference;embedded systems;memory management real time systems java embedded system programming profession algorithm design and analysis feedback dynamic programming inference algorithms safety;static analysis algorithm;garbage collector;memory consumption real time java embedded systems dynamic memory management garbage collection static analysis algorithm region based memory management region inference memory leaks;real time java;static analysis;java	In this paper we address the problem of dynamic memory management in real-time Java embedded systems. Our work aims at suppressing the need for garbage collection in order to avoid unpredictable pause times. For that we use a simple static analysis algorithm coupled with region-based memory management as presented in [15]. To overcome the well-known limitations of region inference, we propose in this paper to involve the developer in the analysis process by providing feedback on programming constructs likely to produce memory leaks. Experiments show that for most programming patterns, our system behaves as efficiently as a garbage collector in terms of memory consumption. Our analysis tool is furthermore able to provide useful feedback to the programmer to pinpoint problematic constructs.	algorithm;compile time;compiler;data structure;embedded system;escape analysis;feedback;garbage collection (computer science);interaction;memory leak;peripheral;programmer;programming style;real time java;real-time clock;region-based memory management;semiconductor industry;static program analysis;virtual machine;whole earth 'lectronic link	Guillaume Salagnac;Christophe Rippert;Sergio Yovine	2007	13th IEEE International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA 2007)	10.1109/RTCSA.2007.67	embedded system;garbage;parallel computing;real-time computing;region-based memory management;computer science;operating system;overlay;flat memory model;garbage collection;programming language;memory leak;memory management	Embedded	-20.790539663126058	34.4436994769731	162927
6f70e0ef327d33099fadc0283997240d796d9d7b	a study of application and device effects between a wap phone and a palm pda	g400 computer science;protocolo wap;distributed system;red sin hilo;interfase usuario;systeme reparti;informatique mobile;mobile device;reseau sans fil;user interface;wireless application protocol;relacion hombre maquina;wireless network;net framework;man machine relation;langage java;sistema repartido;java 2 micro edition;utilisabilite;lenguaje java;interface utilisateur;source code;relation homme machine;protocole wap;usabilidad;mobile computing;usability;java language	Technologies like Java 2 Micro Edition and Microsoft’s .NET framework allow applications to be developed and deployed across a range of mobile devices without having to significantly change the source code. However, mobile devices have very different interfaces and capabilities and it is not clear whether these generic deployment technologies adversely affect the usability of applications by ignoring individual device characteristics. This paper describes an experiment that aimed to see whether users of two applications written with J2ME and deployed on two devices experienced any differences in the usage of the applications on the different devices. Our findings indicate that usability can be maintained through multi-platform deployment. but that there are may also be usability advantages if the specific interaction paradigms of different mobile platforms are taken into account. This would require means of separating not just the interface from the functionality, but also the interface functionality from the interface data.	.net framework;java platform, micro edition;java version history;mobile device;personal digital assistant;software deployment;usability	Jiraporn Buranatrived;Paul Vickers	2004		10.1007/978-3-540-28637-0_17	embedded system;usability;wireless application protocol;computer science;operating system;wireless network;mobile device;database;distributed computing;user interface;mobile computing;world wide web;computer security;source code	HCI	-27.535891900262996	41.87826325458628	163229
d723e0052bd8e62cfc76574fd2f2b4d6f96d6476	visual exploration of memory traces and call stacks		Analysis of software performance typically takes into account clock cycles and memory consumption at each sampling point in time. Although this is a valid strategy, we argue that it is also worth investigating data and control flow structures, as observed using memory traces and call stacks, because of their importance for performance engineering. In this work, we present a visual approach to memory profiling that supports analysis of memory layout, access patterns, and aliasing in correlation to program execution. Our method leverages language-agnostic dynamic code instrumentation to minimize the impact of tracing on performance, i.e., the application remains usable on commodity hardware. The profiled data is then clustered and visualized using a density-based scatter plot. If debug symbols are available, the scatter plot is augmented by a flame graph to ease linking to the high-level source code. Our visualization helps software engineers to identify runtime behavior by relating memory addresses to instruction execution. We demonstrate our approach using a set of examples revealing different memory access patterns and discuss their influence on software performance.	algorithm;aliasing;call stack;clock signal;commodity computing;control flow;debug symbol;digital footprint;high- and low-level;inter-process communication;language-independent specification;machine code;mathematical optimization;performance engineering;profiling (computer programming);program optimization;sampling (signal processing);software engineer;software performance testing;thread pool;tracing (software)	Patrick Gralka;Christoph Schulz;Guido Reina;Daniel Weiskopf;Thomas Ertl	2017	2017 IEEE Working Conference on Software Visualization (VISSOFT)	10.1109/VISSOFT.2017.15	memory address;theoretical computer science;memory management;flat memory model;overlay;real-time computing;distributed memory;memory map;computer science;computing with memory;uniform memory access	SE	-19.66488536048231	38.5661895365553	163377
7aa32f2190a47fa24a1d9f082f4e8e597a46fa2b	timed-event abstraction and timing constraints in distributed real-time programming	distributed algorithms;timing constraints;object oriented programming languages timed event abstraction timing constraints distributed real time programming timing properties specification hard real time programs correctness proof execution platform;programming language;real time;execution platform;object oriented programming;distributed real time programming;object oriented programming languages;timed event abstraction;object oriented languages timing distributed algorithms real time systems object oriented programming;hard real time programs;timing properties specification;timing computer languages electronic mail instruments formal verification real time systems proposals handicapped aids object oriented programming multitasking;object oriented languages;correctness proof;non real time;hard real time;real time systems;timing;time constraint	Considers a method for extending programming languages that enables the specification of timing properties. The way time is treated is not language-specific and the extension can therefore be included in many existing programming languages. An essential feature is that it enables the construction of (hard) real-time programs that may be proven correct independently of the properties of the machines that are used for their execution. It therefore provides a similar abstraction from the execution platform as is normal for non-real-time languages. The aim of this paper is to illustrate the method and to show how event abstraction is instrumental in obtaining the mentioned properties. We compare our approach to some other methods of including timing constraints in (object-oriented) programming languages.	real-time clock;real-time computing	Jozef Hooman;Onno S. van Roosmalen	1997		10.1109/WORDS.1997.609947	fourth-generation programming language;real-time computing;declarative programming;abstraction inversion;reactive programming;computer science;third-generation programming language;distributed computing;programming paradigm;inductive programming;fifth-generation programming language;programming language;high-level programming language;control flow analysis	Embedded	-25.590167326079598	34.07144192550651	163437
5fa599e074bf12efbbcf21b3297a156021f9af91	tornado: a novel input replay tool	nondeterminism;input replay;technology and engineering;operating system	This paper presents TORNADO, a fully operational tool that enables us to replay the nondeterministic input of real world applications. We present a new technique to trace write operations done by the OS kernel to user space. Using this technique we were able to construct a replay tool capable of replaying a large class of applications with an acceptable overhead of less than a factor 2.	graphical user interface;kernel (operating system);microsoft windows;operating system;overhead (computing);system call;tornado;user space;x window system;xedit	Frank Cornelis;Michiel Ronsse;Koen De Bosschere	2003			embedded system;parallel computing;real-time computing;simulation;computer science;operating system	OS	-21.02780351201435	37.930075734854086	163456
ed44a1cddcb5286571f87c8e8ef67b7e5d082968	non-deterministic queue operations	non-deterministic queue operation;transaction processing	Queues play a central role in transaction processing systems. We present a transaction model that allows significant concurrency improvements for extended queue operations such as non-blocking dequeue, priority dequeue, non-blocking enqueue, and others.	non-deterministic turing machine	Hector Garcia-Molina;Kenneth Salem	1995	J. Comput. Syst. Sci.	10.1006/jcss.1995.1062	parallel computing;real-time computing;systems modeling;concurrency;transaction processing;computer science;operating system;queue management system;programming language;scheduling;queue;blocking	Theory	-26.999031619592646	33.915454374207016	163534
952e1c7e7b3e313c5ee1454822c27ad86e5774e6	network-assisted raft consensus algorithm		Consensus is a fundamental problem in distributed computing. In this poster, we ask the following question: can we partially offload the execution of a consensus algorithm to the network to improve its performance? We argue for an affirmative answer by proposing a network-assisted implementation of the Raft consensus algorithm. Our approach reduces consensus latency, is failure-aware, and does not sacrifice correctness or scalability. In order to enable Raft-aware forwarding and quick response, we use P4-based programmable switches and offload partial Raft functionality to the switch. We demonstrate the efficacy of our approach and performance improvements it offers via a prototype implementation.	chandra–toueg consensus algorithm;consensus (computer science);correctness (computer science);distributed computing;network switch;prototype;raft (computer science);scalability	Yang Zhang;Bo Han;Zhi-Li Zhang;Vijay Gopalakrishnan	2017		10.1145/3123878.3131998	computer network;distributed computing;computer science;latency (engineering);scalability;correctness;raft;real-time computing;algorithm	Networks	-22.3383606141739	45.86731163803983	163989
6d6ed77c9e932d559270a7caf319d75bea83db4b	handling fpga faults and configuration sequencing using a hardware extension	reconfiguration;tolerancia falta;programmable circuit;field programmable gate array;serveur documentaire;reconfiguracion;fault tolerant;circuit programmable;unidad control;periodic structure;unite controle;estructura periodica;red puerta programable;reseau porte programmable;ordinateur hote;circuito programable;run time reconfigurable;host computer;documentary server;fault tolerance;field programmable logic;control unit;structure periodique;computador huesped;proveedor documental;programmable logic;tolerance faute;unite controle reconfiguration	"""Tool name: Autonomy Project(s): V3-09 Summary: This tool suite and API provides a different use-model for FPGAs that could be used to create new capabilities to members' products, and provide a potentially new method for fault recovery. This tool is intended to ultimately make a system that is to a degree """"self-aware"""" and can configure itself autonomously at a fine granularity in response to external stimuli. A system with these capabilities could do system-level link maintenance (cognitive and software-defined radios), change the topology of a computation (HPC), universal modularity for in-system adaptation, or rework a system in response to a highly localized failure."""	application programming interface;autonomy;clock rate;computation;coprocessor;embedded system;fmrib software library (fsl);field-programmable gate array;rework (electronics);self-awareness;self-reconfiguring modular robot;sentience;software deployment	Peter Zipf;Manfred Glesner;Christine Bauer;Hans Wojtkowiak	2002		10.1007/3-540-46117-5_61	embedded system;fault tolerance;real-time computing;computer science;control reconfiguration;operating system;distributed computing	SE	-29.00752231297483	40.65104543928912	164461
59016c9b58269928be65500f1138eb57eee1f918	towards unanticipated runtime adaptation of java applications	wrapping;object recognition;virtual machining;unanticipated runtime adaptation;runtime;arrays;java applications;runtime java application software virtual machining wrapping sun software engineering programming software maintenance security;java hotswap;programming;object wrapping;object wrapping java applications unanticipated runtime adaptation java hotswap;java	Modifying an application usually means to stop the application, apply the changes, and start the application again. That means, the application is not available for at least a short time period. This is not acceptable for highly available applications. One reasonable approach which faces the problem of unavailability is to change highly available applications at runtime. To allow extensive runtime adaptation the application must be enabled for unanticipated changes even of already executed program parts. This is due to the fact that it is not predictable what changes become necessary and when they have to be applied. Since Java is commonly used for developing highly available applications, we discuss its shortcomings and opportunities regarding unanticipated runtime adaptation. We present an approach based on Java HotSwap and object wrapping which overcomes the identified shortcomings and evaluate it in a case study.	cognitive dimensions of notations;compiler;darwin;fits;high availability;hot swapping;java;programming language;real life;requirement;run time (program lifecycle phase);runtime system;unavailability;virtual machine;wrapping (graphics)	Mario Pukall;Christian Kästner;Gunter Saake	2008	2008 15th Asia-Pacific Software Engineering Conference	10.1109/APSEC.2008.66	programming;real-time computing;jsr 94;java concurrency;computer science;operating system;cognitive neuroscience of visual object recognition;strictfp;real time java;programming language;java;management;java annotation	SE	-22.329330843244943	37.776762586451774	164462
2f25429bfd0560ccc65f75315d32385c5ec1b333	revisiting the paxos algorithm	verification;tolerancia falta;distributed system;algorithme paxos;systeme reparti;fault tolerant;i o automata;distributed consensus;automaton;generation time;paxos algorithm;synchronous system;algorithme;synchronisation;algorithm;automata;electrical engineering and computer science;formal verification;sistema repartido;thesis;synchronization;automate;fault tolerance;sincronizacion;i o automata models;verificacion;correctness proof;partially synchronous systems;tolerance faute;algoritmo;timing	The paxos algorithm is an e cient and highly fault tolerant algorithm devised by Lamport for reaching consensus in a distributed system Although it appears to be practical it seems to be not widely known or understood This thesis contains a new presentation of the paxos algorithm based on a formal decomposition into several interacting components It also contains a correctness proof and a time performance and fault tolerance analysis The presentation is built upon a general timed automaton GTA model The correctness proof uses automaton composition and invariant assertion methods The time performance and fault tolerance analysis is conditional on the stabilization of the underlying physical system behavior starting from some point in an execution In order to formalize this stabilization a special type of GTA called a Clock GTA is de ned Thesis Supervisor Prof Nancy Lynch Title NEC Professor of Software Science and Engineering	algorithm;assertion (software development);correctness (computer science);distributed computing;fault tolerance;interaction;paxos (computer science);timed automaton	Roberto De Prisco;Butler W. Lampson;Nancy A. Lynch	2000	Theor. Comput. Sci.	10.1016/S0304-3975(00)00042-6	paxos;synchronization;fault tolerance;raft;computer science;theoretical computer science;distributed computing;automaton;algorithm	Theory	-22.29464695468569	42.93671682542873	164492
2a1822ba72ee6b08702e714f5c8624dad70f6472	compositional gossip: a conceptual architecture for designing gossip-based applications	distributed application;distributed system;sistema operativo;gossip based computing;systeme reparti;gossiping all to all;building block;conceptual analysis;analisis conceptual;distributed applications;conceptual design;sistema repartido;operating system;design framework;todos a todos;utilisabilite;systeme exploitation;usabilidad;analyse conceptuelle;usability;echange total	Most proposed gossip-based systems use an ad-hoc design. We observe a low degree of reutilization among this proposals. We present how this limits both the systematic development of gossip-based applications and the number of applications that can benefit from gossip-based construction. We posit that these reinvent-the-wheel approaches poses a significant barrier to the spread and usability of gossip protocols.  This paper advocates a conceptual design framework based upon aggregating basic and predefined building blocks (B2). We show how to compose building blocks within our framework to construct more complex blocks to be used in gossip-based applications. The concept is further depicted with two gossip-based applications described using our building blocks.	gossip protocol;hoc (programming language);usability	Etienne Rivière;Roberto Baldoni;Harry C. Li;José Orlando Pereira	2007	Operating Systems Review	10.1145/1317379.1317387	gossip protocol;simulation;usability;computer science;artificial intelligence;conceptual design;distributed computing	OS	-29.084196795663924	41.59568051217066	164508
fc61b971fd5282f374c55ddb403ef768f7bff0e5	dynamic state machines with multiway synchronization, channels and shared variables	state machine		shared variables	Günter Karjoth	1993			real-time computing;theoretical computer science;control theory	Theory	-28.834382194596493	34.16760239333516	164597
236c0b6da2384ce134805791ca73f97c923a70c6	fault tolerance for internet agent systems: in cases of stop failure and byzantine failure	byzantine failures;distributed system;commitments;fault tolerant;fault tolerant system;agents;agent systems;exception handling;multiagent systems	In this demo, we present our two fault-tolerant systems to overcome stop failure and Byzantine failure, respectively, for agent execution platforms such as JADE and Aglets. For both failures, we have extended traditional fault tolerance methods for intranet to make them applicable to Internet agent systems, which are huge, open, dynamic, autonomous, and unorganized distributed systems.	aglets;autonomous robot;byzantine fault tolerance;distributed computing;internet;intranet;jade	Tadashi Araragi	2005		10.1145/1082473.1082815	fault tolerance;real-time computing;computer science;artificial intelligence;quantum byzantine agreement;multi-agent system;distributed computing;byzantine fault tolerance;computer security	OS	-28.028354342585803	45.719166425135384	164603
48960c0acedc3dc22709516fc1b11899485ca0dd	efficient threshold detection in a distributed environment: extended abstract	threshold detection;transmission complexity;distributed networks;wireless network;distributed computing;distributed environment;communication protocol;message complexity	Consider a distributed network in which events occur at arbitrary nodes and at unpredicted times. An event occurring at node u is sensed only by u which in turn may invoke a communication protocol that allows nodes to exchange messages with their neighbors. We are interested in the following threshold detection (TD) problem inherent to distributed computing: Given some threshold k, the goal of a TD protocol is to broadcast a termination signal when at least k events have occurred (throughout the network).  In this paper we develop a randomized TD protocol that may fail with negligible probability but which significantly improves previous results in terms of the message complexity, namely, the total number of messages sent by all participating nodes. With the right choice of parameters our randomized protocol turns into a deterministic one that guarantees low communication burden for any node. This is a principal complexity measure in many applications of wireless networks and which, to the best of our knowledge, has not been bounded before in the context of such problems.	blum axioms;communications protocol;computational complexity theory;distributed computing;randomized algorithm	Yuval Emek;Amos Korman	2010		10.1145/1835698.1835742	communications protocol;real-time computing;computer science;theoretical computer science;wireless network;distributed computing;distributed computing environment	Theory	-21.909495553388485	44.33618551316524	165021
d41d344b29405d1969603f4131879a1baeb3f409	an object-oriented component model for heterogeneous nets	distributed application;distributed system;wireless network;operational semantics;modeling language;object oriented;rewriting logic;component model;formal analysis	Many distributed applications can be understood in terms of components interacting in an open environment. This interaction is not always uniform as the network may consist of subnets with different quality: Some components are tightly connected with order preservation of communicated messages, whereas others are more loosely connected such that overtaking of messages and even message loss may occur. Furthermore, certain components may communicate over wireless networks, where sending and receiving must be synchronized, since the wireless medium cannot buffer messages. This paper proposes a formal framework for such systems, which allows high-level modeling and formal analysis of distributed systems where interaction is managed by a variety of nets, including wireless ones. We introduce a simple modeling language for object-oriented components, extending the Creol language. An operational semantics for the language is defined in rewriting logic, which directly provides an executable implementation in Maude.	component-based software engineering;distributed computing;executable;high- and low-level;interaction;maude system;modeling language;operational semantics;rewriting;subnetwork	Einar Broch Johnsen;Olaf Owe;Joakim Bjørk;Marcel Kyas	2007		10.1007/978-3-540-92188-2_11	real-time computing;rewriting;computer science;theoretical computer science;wireless network;component object model;distributed computing;modeling language;programming language;object-oriented programming;operational semantics	PL	-31.78900090984185	34.06044452740403	165057
286ebfa4a50a4e870c3bfb49c51ce0274b70ee43	library interface versioning in solaris and linux	versioning mechanism;similar mechanism;global symbol name;versioning technique;library interface;particular release level;shared library;finer granularity;application use;application interface;system-supplied shared library	Shared libraries in Solaris and Linux use a versioning technique which allows the link editor to record an application’s dependency on a particular release level of the library. The versioning mechanism operates at the level of the library’s GLOBAL symbol names—a finer granularity than simply associating a version number with the library itself. In Solaris, this mechanism has also been used to provide a means for the system-supplied shared libraries to define their application interface: to declare specifically which of their symbols are intended for application use (and are stable from one release to the next), and which are internal to the system’s implementation (and hence subject to incompatible change). This paper describes the library symbol-versioning technology in Linux and Solaris, the ways in which it is used to support upward compatibility for existing compiled applications from one release of Solaris to the next, and the potential for similar mechanisms to be applied in Linux versioned shared libraries.	compiler;forward compatibility;library (computing);linker (computing);linux;software versioning	David J. Brown;Karl Runge	2000			computer science;operating system;database;openzfs;world wide web;solaris cluster	OS	-28.841889630001067	36.78524750722382	165199
452798b4e886719caedb9269bac6caa55de815fb	applying hardware transactional memory for concurrency-bug failure recovery in production runs		Concurrency bugs widely exist and severely threaten system availability. Techniques that help recover from concurrency-bug failures during production runs are highly desired. This paper proposes BugTM, an approach that leverages Hardware Transactional Memory (HTM) on commodity machines for productionrun concurrency-bug recovery. Requiring no knowledge about where are concurrency bugs, BugTM uses static analysis and code transformation to insert HTM instructions into multi-threaded programs. These BugTMtransformed programs will then be able to recover from a concurrency-bug failure by rolling back and re-executing the recent history of a failure thread. BugTM greatly improves the recovery capability of state-of-the-art techniques with low run-time overhead and no changes to OS or hardware, while guarantees not to introduce new bugs.	concurrency (computer science);html;multiversion concurrency control;operating system;overhead (computing);software bug;static program analysis;thread (computing);transactional memory	Yuxi Chen;Shu Wang;Shan Lu;Karthikeyan Sankaralingam	2018			parallel computing;concurrency;computer science;transactional memory	OS	-20.93072376421161	39.7377499254587	165222
e2a961980df988d53dc6cca0f3e73f1b28b3b675	storage organization in programming systems	storage allocation;file handling;codewords;time sharing;program representation;segmentation;data representation;paging;storage organization;data structures;addressing mechanisms;storage protection;data structure;storage control	The system of program and data representation that has been in use on the Rice University computer for five years is described. Each logical entity in storage occupies a block of consecutive memory locations. Each block is labeled by a codeword and may contain a program, a data vector, or codewords which in turn label blocks to form arrays. This storage arrangement is discussed with its realized advantages in programming systems: simplicity of programmed addressing, flexibility of data structures, efficiency of memory utilization, variability of system composition during execution, means of linkage between programs and from programs to data, and basis for storage protection. The application of labeled blocks may be extended to areas of time-sharing and multi-media storage control. On the basis of experience at Rice, some ideas on such extensions are presented.	code word;data (computing);data point;data structure;heart rate variability;linkage (software);memory protection;time-sharing	Jane G. Jodeit	1968	Commun. ACM	10.1145/364139.364152	persistence;real-time computing;data striping;data structure;computer science;theoretical computer science;operating system;database;external data representation;data efficiency;programming language;information repository;sequential access memory;segmentation;time-sharing;algorithm;paging	PL	-26.622784295455457	37.34129156585553	165248
351bb8d9269adbd25fdc120f31be2ca11adcd42d	design of a scalable reasoning engine for distributed, real-time and embedded systems	mission critical systems;fault tolerance;scalability;knowledge reasoning and dissemination	Effective and efficient knowledge dissemination and reasoning in distributed, real-time, and embedded (DRE) systems remains a hard problem due to the need for tight time constraints on evaluation of rules and scalability in dissemination of knowledge events. Limitations in satisfying the tight timing properties stem from the fact that most knowledge reasoning engines continue to be developed in managed languages like Java and Lisp, which incur performance overhead in their interpreters due to wasted precious clock cycles on managed features like garbage collection and indirection. Limitations in scalable dissemination stem from the presence of ontologies and blocking network communications involving connected reasoning agents. This paper addresses the existing problems with timeliness and scalability in knowledge reasoning and dissemination by presenting a C++-based knowledge reasoning solution that operates over a distributed and anonymous publish/subscribe transport mechanism provided by the OMG’s Data Distribution Service (DDS). Experimental results evaluating the performance of the C++based reasoning solution illustrate microsecond-level evaluation latencies, while the use of the DDS publish/subscribe transport illustrates significant scalability in dissemination of knowledge events while also tolerating joining and leaving of system entities. keywords: knowledge reasoning and dissemination; mission-critical systems; fault tolerance; scalability	blocking (computing);c++;clock signal;data distribution service;distributed multi-agent reasoning system;embedded system;entity;fault tolerance;garbage collection (computer science);indirection;java;lisp;mission critical;modal logic;ontology (information science);open-source software;overhead (computing);publish–subscribe pattern;real-time clock;real-time computing;real-time transcription;requirement;scalability;semantic reasoner;smartphone;software deployment;test automation	James R. Edmondson;Aniruddha S. Gokhale	2011		10.1007/978-3-642-25975-3_20	fault tolerance;real-time computing;scalability;computer science;artificial intelligence;database;distributed computing;reasoning system	AI	-27.92626856047156	45.53634524441868	165289
497fb686263429b7206cd39b2e1996561dd6723e	bigraphical model of context-aware in ubiquitous computing environments	asia conferences;graph theory;context awareness;context aware;smart phone bigraphical model ubiquitous computing environments context aware mobile systems bigraphical reactive system place graph link graph mobile applications algebra language;smart phone;smart phones;mobile computer;ubiquitous computing graph theory process algebra smart phones;bigraphical reactive system;mobile computing bigraphical reactive system context awareness ubiquitous computing;reactive system;ubiquitous computing;mobile systems;mobile computing;process algebra;mobile application;conferences;asia;ubiquitous computing environment	In this paper, we give a bigraphical model for context-aware mobile systems. We describe how to represent context-aware behaviors by means of Bigraphical Reactive System (BRS), which is proposed to provide a uniform way to model ubiquitous applications. A bigraph consists of two graphs, namely place graph and link graph respectively. We can depict mobility and context-awareness using bigraphs in mobile applications. Besides, bigraphs provide an algebra language by which we can model for applications formally. Finally, the formalisms are explicitly illustrated through a simple but non-trivial smart phone example.	brs/search;bigraph;context awareness;mobile app;ubiquitous computing	De-Zhen Xu;Dong Xu;Zhou Lei	2011	2011 IEEE Asia-Pacific Services Computing Conference	10.1109/APSCC.2011.58	embedded system;process calculus;reactive system;computer science;theoretical computer science;operating system;distributed computing;mobile computing	SE	-30.558494634082102	33.30618476138062	165413
0d7a2762428e847ae925cfcdf3ee3f277937627a	an extensible test framework for the microsoft streaminsight query processor	verification;sql server;testing;streaminsight;data streaming	Microsoft StreamInsight (StreamInsight, for brevity) is a platform for developing and deploying streaming applications. StreamInsight adopts a deterministic stream model that leverages a temporal algebra as the underlying basis for processing long-running continuous queries. In most streaming applications, continuous query processing demands the ability to cope with high input rates that are characterized by imperfections in event delivery (i.e., incomplete or out-of-order data). StreamInsight is architected to handle imperfections in event delivery, to generate real-time low-latency output, and to provide correctness guarantees on the resultant output.  On one hand, streaming operators are similar to their well-understood relational counterparts - with a precise algebra as the basis of their behavior. On the other hand, streaming operators are unique in their non-blocking nature, which guarantees low-latency and incremental result delivery. While our deterministic temporal algebra paves the way towards easier testing of the streaming system, one unique challenge is that as the field evolves with more customers adopting streaming solutions, the semantics, behavior, and variety of operators is constantly under churn. This paper overviews the test framework for the StreamInsight query processor and highlights the challenges in verifying the functional correctness of its operators. The paper discusses the extensibility and the reusability of the proposed streaming test infrastructure, as the research and industrial communities address new and constantly evolving challenges in stream query processing.	blocking (computing);correctness (computer science);database;extensibility;non-blocking algorithm;real-time clock;requirement;resultant;streaming media;test automation;verification and validation	Alex Raizman;Asvin Ananthanarayan;Anton Kirilov;Badrish Chandramouli;Mohamed H. Ali	2010		10.1145/1838126.1838128	real-time computing;computer science;theoretical computer science;database	DB	-30.2551767982282	36.74239750482538	165588
535f9e9feae31c0883a56d2f2a1c73d1fdb70d94	quasi-synchronous checkpointing: models, characterization, and classification	degradation;theoretical framework;zigzag paths;application software;distributed checkpointing;distributed computing;message overhead;computer industry;classification;quasi synchronous checkpointing;checkpointing;consistent global checkpoint;process execution;fault tolerant computing;system recovery;condition monitoring;guidelines;checkpointing distributed computing degradation algorithm design and analysis application software guidelines fault tolerance software debugging condition monitoring computer industry;fault tolerance;maximum autonomy;maximum autonomy quasi synchronous checkpointing classification message overhead process execution performance degradation;software debugging;performance degradation;failure recovery;fault tolerant computing system recovery;algorithm design and analysis;causality	Checkpointing algorithms are classiied as synchronous and asynchronous in the literature. In synchronous checkpointing, processes synchronize their checkpointing activities so that a globally consistent set of checkpoints is always maintained in the system. Synchronizing checkpointing activity involves message overhead and process execution may have to be suspended during the checkpointing coordination, resulting in performance degradation. In asynchronous checkpointing, processes take checkpoints without any coordination with others. Asynchronous checkpointing provides maximum autonomy for processes to take checkpoints; however, some of the checkpoints taken may not lie on any consistent global checkpoint, thus making the checkpointing efforts useless. Asynchronous checkpointing algorithms in the literature can reduce the number of useless checkpoints by making processes take communication induced checkpoints , besides asynchronous checkpoints. We call such algorithms, quasi-synchronous. Quasi-synchronous checkpointing algorithms are attractive because they improve the performance without introducing undesirable eeects. In this paper, we present a theoretical framework for characterizing and classifying such algorithms. The theory not only helps to classify and characterize the quasi-synchronous checkpointing algorithms, but also helps analyzing the properties and limitations of the algorithms belonging to each class; it also provides guidelines for designing and evaluating such algorithms. This classiication also sheds light on some open problems that remain to be solved.	algorithm;application checkpointing;asynchronous i/o;asynchronous circuit;elegant degradation;overhead (computing);synchronization (computer science);synchronizing word;transaction processing system	D. Manivannan;Mukesh Singhal	1999	IEEE Trans. Parallel Distrib. Syst.	10.1109/71.780865	algorithm design;fault tolerance;application software;parallel computing;real-time computing;degradation;causality;biological classification;computer science;distributed computing	HPC	-22.46498449632064	45.36557857036952	165739
942d688159fc7db84efc0621b570d37bdbecf185	seminar: safe concurrent programming in java with csp	concurrent programming;concurrent programs;csp;threads;java	We present methods for safe and correct programming for concurrent threads in Java. The methods are based on the principles of Concurrent Sequential Processes (CSP). We demonstrate the use of tools which provide the structure of CSP within Java to avoid some of the pitfalls of multithreaded programming using monitors, the primitive synchronization tool in Java. Several examples illustrate the use of these tools.	concurrent computing;java;thread (computing)	Christopher H. Nevison	1999		10.1145/299649.299817	concurrent constraint logic programming;thread;parallel computing;real-time computing;java concurrency;concurrent computing;computer science;java modeling language;communicating sequential processes;strictfp;real time java;programming language;java;scala;concurrent object-oriented programming;java annotation	PL	-23.402486552880926	32.79403724324346	165980
9bd9c0834cdfbd13ef4519015395014354cda48f	dpac: an infrastructure for dynamic program analysis of concurrency java programs	concurrency;dynamic program analysis;platform support	Concurrency programs are hard to test or debug due to their non-deterministic nature. Existing dynamic program analysis approaches tried to address this by carefully examine a recorded execution trace. However, developing such analysis tools is complicated, requiring to take care of many tedious implementation details, and comparing and evaluating different analysis approaches are also subject to various biases, due to lack of a common base platform. This motivates us to design DPAC, an infrastructure that support in building dynamic program analysis tools for concurrency Java programs. DPAC takes events and their various processing mechanisms as its underlying model to facilitate monitoring and manipulation of program executions as required by dynamic program analysis. Various analysis tools can be implemented by customizing their required event types and processing mechanisms. We show two concrete case studies how our DPAC helps building existing dynamic program analysis approaches, as well as tuning subtle implementation details for supporting customized function implementation and code transformation.	care-of address;concurrency (computer science);dynamic program analysis;java	Yanyan Jiang;Chang Xu;Xiaoxing Ma	2013		10.1145/2541534.2541591	computer architecture;real-time computing;computer science;dynamic program analysis;programming language	SE	-21.80965406390163	35.52515510803446	166117
95228e122129ea03745478ce96edcdb60df876f2	a linda-based runtime system for a distributed logic language	network server;tuple space;coordination language;run time system;runtime system;logic programs	We describe an application of the Linda coordination language in the design and distributed implementation of a parallel logic language called ESP. This is a logic language that includes a concept of Multiple Tuple Spaces, so it effectively extends Linda and moreover it integrates it with the logic programming paradigm. The implementation that we describe uses a Linda-based network server as the kernel of the ESP distributed run-time system.	linda (coordination language);runtime system	Paolo Ciancarini	1992		10.1007/3-540-57502-2_58	real-time computing;computer science;tuple space;distributed computing;runtime verification;programming language;server	PL	-26.146018660893382	36.51830660421579	166223
066100d1b50a76a8f13b947d4e977085eed15451	implementation of distributed semaphores in iec 61499 with consensus protocols		An approach is proposed for the implementation of distributed semaphores in the IEC 61499 architecture on the basis of protocols for solving consensus in a network of unreliable processes that allows developing function blockbased control applications with complex types of interactions using the resources sharing. The models of distributed semaphores (in the form of coloured Petri nets) based on Paxos and Raft protocols for solving consensus are developed, simulation experiments are performed in the CPN Tools, comparative analysis and recommendations are given.	coloured petri net;correctness (computer science);distributed control system;experiment;interaction;operating system;performance evaluation;qualitative comparative analysis;semaphore (programming);simulation	Victor Dubinin;Artem Voinov;Ilya Senokosov;Valeriy Vyatkin	2018	2018 IEEE 16th International Conference on Industrial Informatics (INDIN)	10.1109/INDIN.2018.8472078	real-time computing;paxos;semaphore;synchronization;engineering;petri net;shared resource;distributed database;raft;cpn tools;distributed computing	Robotics	-28.772853695561082	45.999594563895236	166316
94257ede6617b6432d2fff017edfd0bfe0c9aa15	customization of distributed systems using com	distributed system;object oriented methods;fault tolerant;high speed networks;distributed computing;software systems;parallel programming;object oriented programming;research and development;distributed objects;polymorphism;component object model;software reusability;load balance;software reusability object oriented programming object oriented methods parallel programming;com dcom distributed systems customization com high speed networking object oriented programming reusable software distributed objects software systems distributed object applications remote invocation versioning load balancing fault tolerance component object model distributed com2 binary standard component based applications encapsulation polymorphism software reuse cross process setting distributed extension;application software object oriented programming computer architecture buildings distributed computing high speed networks ip networks explosives software reusability software systems;software reuse	Distributed computing is moving into the mainstream because of advances in high speed networking and the Internet's explosive growth. Object oriented programming has become the dominating paradigm for developing reusable software. Distributed objects combine these two trends and are becoming increasingly popular. More and more software systems are built as distributed object applications, and they often share the needs of some basic features such as remote invocation, versioning, load balancing, and fault tolerance. The Component Object Model and Distributed COM2 either provide some of these features directly or provide an architecture that facilitates building such features. COM specifies an architecture, a binary standard, and a supporting infrastructure for building, using, and evolving component based applications. It extends the benefits of object oriented programming, such as encapsulation, polymorphism, and software reuse, to a dynamic and cross process setting. DCOM is the distributed extension of COM. It specifies the additional infrastructure needed to further extend the benefits to networked environments. By using COM/DCOM as a platform to build distributed object applications, researchers and developers can concentrate on important issues specific to their applications, without devoting significant effort to building the supporting infrastructure.	distributed computing	Yi-Min Wang;Pi-Yu Chung	1998	IEEE Concurrency	10.1109/4434.708249	polymorphism;fault tolerance;parallel computing;real-time computing;computer science;load balancing;operating system;component object model;distributed computing;distributed object;programming language;object-oriented programming;software system	Embedded	-33.54953644539121	44.093636423408505	166339
5cba74fbbb7944d8ea30d4580dac904d9bc98cb5	corbaviews: distributing objects with views	corba views object oriented applications access rights generic class like algebraic structures viewpoints view programming object slice duplication;object slice duplication corba views object oriented applications access rights generic class like algebraic structures viewpoints view programming;access rights;distributed object management object oriented programming;functional programming permission context aware services quality of service;corba views;generic class like algebraic structures;object oriented programming;functional programming;view programming;distributed objects;object oriented programming distributed object management;permission;object oriented;distributed object management;object slice duplication;difference set;quality of service;object oriented applications;viewpoints;context aware services	We propose a model for building objectoriented applications based on the composition of application slices or fragments that provide their own overlapping definitions or expectations of the same domain objects. Different slices may implement different functional or implementation concerns, or embody different access rights and privileges to the same domain objects. We call such slices views and we recognize that the behavior embodied in views may be abstracted into generic clas-like algebraic structures called viewpoints, from which views for specific domain classes may be generated. In this paper, we are interested in the problem of distributing viewbased applications when different sites access different slices of the same domain objects. Specifically, we are interested in the problem of offering different views of the same domain objects to different client programs in a CORBAlike environment, We first discuss the principles behind view programming, and then explore ways in which objects with views may be distributed in a way that supporfs different sets of functionalities to different client programs. An interesting application of view programming in a distributed context is the selective duplication of object slices.	access control;business object;cesg listed adviser scheme;definition;domain-driven design;privilege (computing)	Hafedh Mili;Hamid Mcheick;Joumana Dargham;Salah Sadou	2001		10.1109/AICCSA.2001.934017	computer science;theoretical computer science;database;distributed computing;programming language;object-oriented programming;functional programming	PL	-31.888329921236906	34.91713465184935	166463
bfa8872bd115fc44d68d72174b1035c5f52f73f3	on the equity of mutual exclusion algorithms in distributed systems	critere selection;distributed system;selection criterion;reseau ordinateur;site selection;criterio seleccion;computer networks;distributed computer systems;equite;exclusion mutual;algorithme;mutual exclusion;temps reponse;equidad;equity;secteur critique;algorithms;systeme informatique reparti;exclusion mutuelle;distributed systems;response time computer systems;mutual exclusion algorithms;choix site	The basic problem in mutual exclusion in distributed systems is to insure that one and only one site has access to a critical section at any given time. Two of the more common performance metrics for mutual exclusion algorithms are (a) number of messages necessary per critical section invocation, and (b) response time which is the time interval from token request until the process can enter the critical section. Fast response times require an equitable means of selecting the next site to receive the token. We present two scenarios which show that neither selection technique always achieves equity. Additionally, we propose a new priority based selection method which can lead to improved system throughput.	algorithm;distributed computing;mutual exclusion	Garrison W. Greenwood	1995	Inf. Process. Lett.	10.1016/0020-0190(95)00107-N	mutual exclusion;computer science;artificial intelligence;distributed computing;critical section;suzuki-kasami algorithm;operations research;equity	DB	-20.80624842059955	46.218349757804475	166526
1517d6107c17e5a2914632961ba678704e1833e8	failure detectors in homonymous distributed systems (with an application to consensus)	asynchrony;informatica;distributed system;detectors;crash failure;cluster computing;consensus;problem;homonymous system;distributed computability;t technology general;computer crashes;process failure failure detectors homonymous distributed system consensus crash failure system membership membership knowledge synchrony requirement homonymous asynchronous system unique identifiers anonymous systems partial synchrony crash prone message passing distributed system;process crash agreement problem asynchrony consensus distributed computability failure detector homonymous system message passing;distributed computing;q science general;agreement;synchronous system;asynchronous system;qa75 electronic computers computer science;fault tolerant computing;system recovery;system recovery fault tolerant computing message passing;failure detector;process crash;safety;nominations and elections;message passing;face;agreement problem;data structure;article;context;detectors computer crashes safety context nominations and elections distributed computing face;tk electrical engineering electronics nuclear engineering;ta engineering general civil engineering general;partial synchrony;consensus problem	This paper is on homonymous distributed systems where processes are prone to crash failures and have no initial knowledge of the system membership (“homonymous” means that several processes may have the same identifier). New classes of failure detectors suited to these systems are first defined. Among them, the classes HΩ and HΣ are introduced that are the homonymous counterparts of the classes Ω and Σ, respectively. (Recall that the pair 〈Ω, Σ〉 defines the weakest failure detector to solve consensus.) Then, the paper shows how HΩ and HΣ can be implemented in homonymous systems without membership knowledge (under different synchrony requirements). Finally, two algorithms are presented that use these failure detectors to solve consensus in homonymous asynchronous systems where there is no initial knowledge of the membership. One algorithm solves consensus with 〈HΩ, HΣ〉, while the other uses only HΩ, but needs a majority of correct processes. Observe that the systems with unique identifiers and anonymous systems are extreme cases of homonymous systems from which follows that all these results also apply to these systems. Interestingly, the new failure detector class HΩ can be implemented with partial synchrony, while the analogous class AΩ defined for anonymous systems can not be implemented (even in synchronous systems). Hence, the paper provides us with the first proof showing that consensus can be solved in anonymous systems with only partial synchrony (and a majority of correct processes).	algorithm;asynchronous system;crash (computing);distributed computing;failure detector;requirement;sensor;unique identifier	Sergio Arévalo;Antonio Fernández;Damien Imbs;Ernesto Jiménez;Michel Raynal	2012	2012 IEEE 32nd International Conference on Distributed Computing Systems	10.1109/ICDCS.2012.13	parallel computing;real-time computing;consensus;data structure;computer science;operating system;distributed computing;computer security;algorithm	Embedded	-22.52942938947545	44.161916098787174	166609
118c9418ed9c78b253cfcccb252ae8a2c47ce871	mainwave: multi agents and issues negotiation for web using alliance virtual engine	network repositories;e commerce;concurrent programming;data mining;multi agent;service negotiation;web services;artificial intelligence	This paper showcases an improved architecture for a complete negotiation system that permits multi party multi issue negotiation. The concepts of multithreading and concurrency has been utilized to perform parallel execution. The negotiation history has been implemented that stores all the records of the messages exchanged for every successful and rejected negotiation process and implements the concepts of artificial intelligence in determination of proper weights for a valid negotiation mechanism. The issues are arranged in a hierarchical pattern so as to simplify the representation and priorities are assigned to each issue, which amounts to its relative importance. There is refinement of utilities by consideration of the non-functional attributes. So as to avoid overloading of the system, a maximum number of parties are allowed to participate in the entire mechanism and if more parties arrive, they’re put into a waiting queue in accordance to certain criteria such as the first come first serve or the relative priorities. This helps in fault tolerance. It also supports the formation of alliances among the various parties while carrying out a negotiation.	artificial intelligence;concurrency (computer science);fault tolerance;function overloading;multithreading (computer architecture);refinement (computing);thread (computing);whole earth 'lectronic link	Debajyoti Mukhopadhyay;Saurabh Deochake;Shashank Kanth;Subhadip Chakraborty;Suresh Sarode	2012	Smart CR	10.6029/smartcr.2012.05.001	e-commerce;web service;concurrent computing;computer science;knowledge management;artificial intelligence;data mining	AI	-31.655099165936388	37.05426118761136	166630
c1f887c9152a387394475be4a9033bacda5b3b95	a rule-based publish-subscribe message routing system for ubiquitous computing	consumidor;distributed system;regle inference;sistema experto;systeme reparti;informatique mobile;base de connaissances;routing;consommateur;pervasive computing;rule based system;computability;rule based;routage;satisfiability;intergiciel publication souscription;inference rule;informatica difusa;large scale;sistema repartido;intergicial editor suscriptor;informatique diffuse;consumer;calculabilite;envoi message;publish subscribe;message passing;base conocimiento;ubiquitous computing;middleware;systeme expert;mobile computing;publish subscribe middleware;calculabilidad;regla inferencia;knowledge base;expert system;enrutamiento	The ubiquitous computing produces big volume of messages as the pervasive computability is deployed in large scale. As a middleware between the message producer and message consumer, message routing system enables backend systems to efficiently acquire the interested message. A widely adopted message routing mechanism is the content-based publish-subscribe framework. Based on this paradigm, we propose a rule-based system for supporting message routing in ubiquitous computing. The novel system features in the flexibility of the message computing, which is accomplished through a set of message operators. The message consumer could select the appropriate operator and specify the operating rule to get satisfying messages.		Yixin Jing;Dongwon Jeong;Jinhyung Kim;Doo-Kwon Baik	2006		10.1007/11890348_1	routing;event loop;message passing;real-time computing;consumer;computer science;artificial intelligence;operating system;middleware;database;distributed computing;message queue;publish–subscribe pattern;computability;message broker;mqtt;computer security;ubiquitous computing;algorithm;rule of inference;satisfiability	Visualization	-30.04169993485095	42.9897030524253	166711
5023fa51c94a4d8e7c8d16ffeb46312a71e5e884	tight self-stabilizing mobile byzantine-tolerant atomic register	byzantine mobile agents;self stabilizing atomic storage;distributed storage;mobile byzantine faults;round based synchronous computation	This paper proposes the first implementation of a self-stabilizing atomic register that is tolerant to both Mobile Byzantine Agents and transient failures. The register is maintained by n servers and our algorithm tolerates (i) any number of transient failures and (ii) up to f Mobile Byzantine Failures. In the Mobile Byzantine Failure model, faulty agents move from one server to another and when they are affecting a server, it behaves arbitrarily. Our implementation is designed for the round-based synchronous model where agents are moved from round to round. The paper considers four Mobile Byzantine Failure models differing for the diagnosis capabilities at server side i.e., when servers can diagnose their failure state (that is, be aware that the mobile Byzantine agent has left the server), and when servers cannot self-diagnose. We first prove lower bounds on the number of servers n necessary to construct a register tolerant to the presence of f Mobile Byzantine Failures for each of the Mobile Byzantine Failure models considered and then we propose a parametric algorithm working in all the models and matching the lower bounds.	algorithm;byzantine fault tolerance;mobile agent;self-stabilization;server (computing);server-side	Silvia Bonomi;Antonella Del Pozzo;Maria Gradinariu Potop-Butucaru	2016		10.1145/2833312.2833320	real-time computing;distributed data store;computer science;quantum byzantine agreement;distributed computing;byzantine fault tolerance;computer security	Metrics	-22.5143332975023	44.94485973291278	166717
a9164cb8181721f655866424b656473fba46cd49	achieving a better middleware design through formal modeling and analysis	middleware		middleware	Weixiang Sun;Tianjun Shi;Gonzalo Argote-Garcia;Yi Deng;Xudong He	2006			systems engineering;computer science;database;middleware (distributed applications);middleware	EDA	-32.206870724141034	45.854624528048795	166734
4c119efe148c6c9140dcc7b9dd30a66cbc778b41	customizable data distribution for shared data spaces	distributed data;component based software engineering;component based systems;separation of concern;data type;data distribution;article in monograph or in proceedings	To support component-based software engineering, simple and efficient mechanisms for dynamic composition and decomposition of components are needed. Shared data spaces are a simple composition mechanism, yet their efficient distributed implementation faces several complicating factors. One of these factors is that the communication needs of components may differ per data type, per application, and may even change over time. While existing data-space implementations treat all data equally, we propose a distributed data-space architecture that provides the means for differentiating distribution policies according to the type of data. Using this approach we are able to cater for the specific needs of the data. We maintain the transparency of the shared data space paradigm to the application programmer, but extend its capabilities for optimizing its efficiency.	component-based software engineering;dataspaces;programmer;programming paradigm;spaces	Giovanni Russello;Michel R. V. Chaudron;Maarten van Steen	2003			data modeling;data type;separation of concerns;computer science;data science;component-based software engineering;data mining;database;programming language	SE	-32.004695482477736	36.26291811962758	166974
e7b6f7d4c69ca855a7028bf03d7da662ba9e6fc2	a proactive middleware platform for mobile computing	distributed system;virtual machine;adaptacion;durabilite;systeme reparti;mobile radiocommunication;informatique mobile;mobile device;durabilidad;logicial personalizado;mobile computer;ejecucion programa;machine virtuelle;radiocommunication service mobile;program execution;intergiciel;sistema repartido;sevicio proactivo;durability;base station;execution programme;adaptation;proactive;on the fly;middleware;functionality;fonctionnalite;radiocomunicacion servicio movil;mobile computing;dynamic adaptation;maquina virtual;funcionalidad;service proactif	An obvious prerequisite for mobile computing devices is the ability to adapt to different computing environments. Otherwise the devices are forced to carry with them everything they may eventually need during their operational life time. This is neither desirable nor feasible, thereby hinting at the need for dynamic adaptation. The idea would be to let the environment be proactive and adapt the application rather than forcing the application to adapt itself to every possible environment. In this paper we present a platform for doing exactly this. Applications running on our modified JVM can be extended at run time with new functionality. Through this platform, mobile devices can acquire on-the-fly any functionality extension they may need to work properly in a given environment. The functionality extensions are local in time and space: they are active only on a specific site and just for the time they are needed. The platform can be used in both centralized settings (with a base station providing the extensions) or in self configuring mode (extensions are provided by peers). In this paper we describe the platform, how to use it and report on one of the several prototypes that have been constructed.	middleware;mobile computing	Andrei Popovici;Andreas Frei;Gustavo Alonso	2003		10.1007/3-540-44892-6_23	embedded system;real-time computing;simulation;computer science;virtual machine;base station;operating system;durability;middleware;mobile device;database;distributed computing;mobile computing;computer security;adaptation	Robotics	-28.962418466047232	42.717398006916504	166983
7f35c2acb58a0d39329fe801aae79bde32763f43	multitolerance in distributed reset	distributed system	A reset of a distributed system is safe if it does not complete “preAbstract-1 maturely,” i.e., without having reset some process in the system. Safe resets are possible in the presence of certain faults, such as process failstops and repairs, but are not always possible in the presence of more general faults, such as arbitrary transients. In this paper, we design a bounded-memory distributed-reset program that possesses two tolerances: (1) in the presence of fail-stops and repairs, it always executes resets safely, and (2) in the presence of a finite number of transient faults, it eventually executes resets safely. Designing this multitolerance in the reset program introduces the novel concern of designing a safety detector that is itself multitolerant. A broad application of our multitolerant safety detector is to make any total program likewise multitolerant.	distributed computing;transient (computer programming)	Sandeep S. Kulkarni;Anish Arora	1998	Chicago J. Theor. Comput. Sci.		real-time computing;computer science;control theory;mathematics	PL	-22.718975419491894	43.96995671665274	167029
172e53475249525093594009251e7c4f60795b88	conseq: detecting concurrency bugs through sequential errors	debugging;no determinismo;puesta a punto programa;software testing;reliability;ciclo desarrollo;data race;tranchage;shared memory;storage access;life cycle;langage c;memoria compartida;acces concurrent;simultaneidad informatica;interlacing;probabilistic approach;program verification;debogage;verificacion programa;slicing;c language;acceso simultaneo;concurrency;non determinism;false positive rate;concurrency bugs;state space method;non determinisme;methode espace etat;data dependence;enfoque probabilista;approche probabiliste;data races;state space;entrelacement;acces memoire;cycle developpement;chapeado;acceso memoria;concurrent programs;entrelazado;fiabilite logiciel;fiabilidad logicial;verification programme;control dependence;software reliability;simultaneite informatique;languages;memoire partagee;lenguaje c;metodo espacio estado	Concurrency bugs are caused by non-deterministic interleavings between shared memory accesses. Their effects propagate through data and control dependences until they cause software to crash, hang, produce incorrect output, etc. The lifecycle of a bug thus consists of three phases: (1) triggering, (2) propagation, and (3) failure.  Traditional techniques for detecting concurrency bugs mostly focus on phase (1)--i.e., on finding certain structural patterns of interleavings that are common triggers of concurrency bugs, such as data races. This paper explores a consequence-oriented approach to improving the accuracy and coverage of state-space search and bug detection. The proposed approach first statically identifies potential failure sites in a program binary (i.e., it first considers a phase (3) issue). It then uses static slicing to identify critical read instructions that are highly likely to affect potential failure sites through control and data dependences (phase (2)). Finally, it monitors a single (correct) execution of a concurrent program and identifies suspicious interleavings that could cause an incorrect state to arise at a critical read and then lead to a software failure (phase (1)).  ConSeq's backwards approach, (3)!(2)!(1), provides advantages in bug-detection coverage and accuracy but is challenging to carry out. ConSeq makes it feasible by exploiting the empirical observationthat phases (2) and (3) usually are short and occur within one thread. Our evaluation on large, real-world C/C++ applications shows that ConSeq detects more bugs than traditional approaches and has a much lower false-positive rate.	c++;concurrency (computer science);concurrent computing;hang (computing);multiversion concurrency control;program slicing;sensor;shared memory;software bug;software propagation;state space search;structural pattern	Wei Zhang;Junghee Lim;Ramya Olichandran;Joel Scherpelz;Guoliang Jin;Shan Lu;Thomas W. Reps	2011		10.1145/1950365.1950395	shared memory;biological life cycle;parallel computing;real-time computing;interlacing;concurrency;false positive rate;computer science;state space;reliability;race condition;software testing;programming language;debugging;algorithm;software quality	Arch	-21.25994551332576	39.54369226866079	167117
5129f6afa615e8c29e29c9b514e760e7827eb4b5	correctness of a distributed deadlock resolution algorithm for the single request model	single request model;distributed algorithms;distributed system;system recovery automata phase detection information systems probes costs cleaning mathematics algorithm design and analysis distributed algorithms;formal specification;complete distributed system;input output automata model distributed deadlock resolution algorithm single request model high level specification resolution algorithm initial specification complete distributed system refinements;automata theory distributed algorithms concurrency control operating systems computers formal specification;input output;distributed deadlock resolution algorithm;initial specification;high level specification;concurrency control;automata theory;resolution algorithm;operating systems computers;refinements;input output automata model	In this paper* we consider the problem of the distributed deadlock resolution. Starting from a high level specification of the problem and the resolution algorithm for a system with single request model, we provide successive levels of decreasing abstraction of the initial specification in order to achieve a solution in a complete distributed system. The successive refinements and the final distributed deadlock resolution algorithm are formally described and proved by using the Input/Output Automata Model.	algorithm;automaton;correctness (computer science);deadlock;distributed computing;high-level programming language;input/output;resolution (logic)	José Ramón González de Mendívil;Akim Demaille;José M. Bernabéu-Aubán;José Ramón Garitagoitia	1995		10.1109/EMPDP.1995.389136	real-time computing;computer science;theoretical computer science;deadlock;distributed computing;edge chasing;deadlock prevention algorithms	DB	-32.67356005368315	33.854969828263854	167242
73c903027cfcc88735deb2c44bc067c08001c789	early performance testing of distributed software applications	distributed application;distributed system;architectural design;software testing;quality attributes;settore inf 01 informatica;performance test;ucl;discovery;theses;conference proceedings;development process;software performance;digital web resources;settore ing inf 05 sistemi di elaborazione delle informazioni;ucl discovery;distributed software architecture;performance analysis models;specification tests;open access;performance analysis;middleware;ucl library;book chapters;open access repository;early development;java 2 enterprise edition;common object request broker architecture;ucl research	Performance characteristics, such as response time, through put and scalability, are key quality attributes of distributed applications. Current practice, however, rarely applies systematic techniques to evaluate performance characteristics. We argue that evaluation of performance is particularly crucial in early development stages, when important architectural choices are made. At first glance, this contradicts the use of testing techniques, which are usually applied towards the end of a project. In this paper, we assume that many distributed systems are built with middleware technologies, such as the Java 2 Enterprise Edition (J2EE) or the Common Object Request Broker Architecture (CORBA). These provide services and facilities whose implementations are available when architectures are defined. We also note that it is the middleware functionality, such as transaction and persistence services, remote communication primitives and threading policy primitives, that dominate distributed system performance Drawing on these observations, this paper presents a novel approach to performance testing of distributed applications. We propose to derive application-specific test cases from architecture designs so that performance of a distributed application can be tested using the middleware software at early stages of a development process. We report empirical results that support the viability of the approach.	common object request broker architecture;database transaction;distributed computing;java platform, enterprise edition;java version history;list of system quality attributes;middleware;persistence (computer science);response time (technology);scalability;software performance testing;test case;thread (computing)	Giovanni Denaro;Andrea Polini;Wolfgang Emmerich	2004		10.1145/974044.974059	middleware;software performance testing;computer science;engineering;object request broker;software engineering;common object request broker architecture;middleware;database;distributed computing;software testing;programming language;management;world wide web;software development process	SE	-32.78610756244393	43.98849849383235	167302
107a7c19de330ddb789c660ccb68100290f15653	[engineering paper] a tool for optimizing java 8 stream software via automated refactoring		Streaming APIs are pervasive in mainstream Object-Oriented languages and platforms. For example, the Java 8 Stream API allows for functional-like, MapReduce-style operations in processing both finite, e.g., collections, and infinite data structures. However, using this API efficiently involves subtle considerations like determining when it is best for stream operations to run in parallel, when running operations in parallel can be less efficient, and when it is safe to run in parallel due to possible lambda expression side-effects. In this paper, we describe the engineering aspects of an open source automated refactoring tool called Optimize Streams that assists developers in writing optimal stream software in a semantics-preserving fashion. Based on a novel ordering and typestate analysis, the tool is implemented as a plug-in to the popular Eclipse IDE, using both the WALA and SAFE frameworks. The tool was evaluated on 11 Java projects consisting of ~642 thousand lines of code, where we found that 36.31% of candidate streams were refactorable, and an average speedup of 1.55 on a performance suite was observed. We also describe experiences gained from integrating three very different static analysis frameworks to provide developers with an easy-to-use interface for optimizing their stream code to its full potential.	application programming interface;code refactoring;data structure;eclipse;java version history;mapreduce;open-source software;optimizing compiler;plug-in (computing);streams;source lines of code;speedup;static program analysis;typestate analysis	Raffi Khatchadourian;Yiming Tang;Mehdi Bagherzadeh;Syed Ahmed	2018	2018 IEEE 18th International Working Conference on Source Code Analysis and Manipulation (SCAM)	10.1109/SCAM.2018.00011	typestate analysis;programming language;streams;code refactoring;speedup;computer architecture;data structure;computer science;software;source lines of code;java	SE	-20.40114782747942	37.131049053825635	167524
650100b0f5a2bb7221f2036d1e54a0dab61b2299	java 2 platform enterprise edition (j2ee) for building web-based enterprise applications	java 2 platform enterprise edition	J2EE offers “Write Once, Run Anywhere” platform, and takes advantage of JDBC API for database access, CORBA technology for interaction with existing enterprise resources, a security model that protects data in Internet applications. Building on this foundation, J2EE offers Enterprise JavaBeans(EJB), JavaBeans, Java Servlets API, and JavaServer Pages (JSP) technology. Enterprise JavaBeans and JavaBeans are Java-based component technologies that provide a universal integration and enabling technology for component-based development of Web-based enterprise applications.	application programming interface;common object request broker architecture;component-based software engineering;enterprise javabeans;enterprise software;jdbc;java platform, enterprise edition;java servlet;javaserver pages;write once, run anywhere	Gilda Pour	2001		10.1109/TOOLS.2001.10008	enterprise application integration;jsr 94;nist enterprise architecture model;computer science;data science;operating system;software engineering;enterprise integration;java;purdue enterprise reference architecture	OS	-33.38596344452779	42.855320104873584	167697
1e6f86e758797aa62882a1c06e35da9241b9fb0b	a method for continuous real-time supervision	real time		real-time transcription	R. Iorgulescu;Rudolph E. Seviora	1997	Softw. Test., Verif. Reliab.	10.1002/(SICI)1099-1689(199706)7:2%3C69::AID-STVR131%3E3.0.CO;2-4	computer science	SE	-30.11443370745863	38.08582340967887	167867
46145c34dde555b8a634ee13080e30f9c40cc368	brief announcement: weak synchrony models and failure detectors for message passing (k-)set agreement	shared memory;message passing system;distributed computing;asynchronous system;failure detector;message passing;shared memory system;consensus problem	Motivation. In recent years, the quest for weak system assumptions, which add just enough synchrony resp. failure information to purely asynchronous systems to circumvent impossibility results, has been an active research topic in distributed computing. Most work in this area has been devoted to (1) identifying weak(est) failure detectors (FDs), and (2) identifying synchrony assumptions just strong enough to implement these weak FDs.	message passing;sensor;weak ai	Martin Biely;Peter Robinson;Ulrich Schmid	2009		10.1007/978-3-642-04355-0_38	asynchronous system;distributed shared memory;shared memory;parallel computing;message passing;real-time computing;consensus;computer science;distributed computing;message broker;failure detector	Vision	-22.50585108801367	44.07431931199966	168076
f9092a9b3b4577969c0125a79da5d25470f13e33	termination detection by using distributed snapshots	distributed system;sistema operativo;systeme reparti;protocole transmission;termination detection;sistema informatico;transmission message;computer system;detection terminaison;message transmission;algorithme;algorithm;protocolo transmision;sistema repartido;operating system;snapshots;deteccion terminacion;systeme exploitation;systeme informatique;transmision mensaje;algoritmo;transmission protocol	Abstract   This paper discusses termination detection by using distributed snapshots. An algorithm is presented which is a modification of a recently proposed algorithm (Huang, 1988) The presented algorithm avoids the weak point of the original algorithm, which requires a process to wait for an acknowledgement from the receiver for every basic message sent.		Shing-Tsaan Huang	1989	Inf. Process. Lett.	10.1016/0020-0190(89)90010-0	snapshot;embedded system;telecommunications;computer science;algorithm	DB	-21.061257125166037	43.565062300281156	168102
0b0c96b4ae533644ef9eb46887aa4a677204597a	osi remote procedure call: standardization issues, design and implementation	distributed application;interconnection;implementation;distributed processing;osi remote procedure call;conception;systeme ouvert;remote operation;communication model;remote procedure call;interfase;interconexion;ejecucion;design and implementation;teleaccion;interface;interconnexion;diseno;design;open systems;sistema abierto;traitement reparti;rose interfaces;control blocks;teleoperation;tratamiento repartido;open distributed processing	OSI Remote Procedure Call (RPC) has been identified as an essential communications and distribution mechanism for open distributed processing environments. This paper presents a design and implementation of an RPC protocol based on the ISO's second Committee Draft standard, and illustrates the results of the implementation with a non-trivial distributed application. The paper identifies, through implementation, problems with the OSI RPC Committee Draft standard, and provides extensive discussion on various lessons learnt. The paper also raises the need for the design of configurable interfaces of OSI modules, and for an improved RPC communication model.	osi model;remote procedure call;subroutine	Y. Liu;Doan B. Hoang	1997	Computer Communications	10.1016/S0140-3664(97)00042-X	embedded system;design;dce/rpc;teleoperation;real-time computing;telecommunications;computer science;operating system;interconnection;interface;database;implementation;remote procedure call;computer security;computer network	Networks	-27.92773562836389	41.169803800601294	168213
05837c92cdb78aa0ef1c1d3f6d8034e6b94be0d3	intelligent home network service management platform design based on osgi framework	distributed system;systeme intelligent;systeme reparti;multimedia;gestion red;sistema inteligente;serveur informatique;service management;intelligence artificielle;home network;sistema repartido;civil engineering;gestion reseau;intelligent system;reseau intelligent;servidor informatico;artificial intelligence;genie civil;network management;intelligent networks;inteligencia artificial;ingenieria civil;open standard;service provision;computer server	In this paper, we propose an open standard-based, intelligent service management platform that aims to provide a flexible and extensible platform for building intelligent home network services. To have greater flexibility and efficiency in managing home network services, we further propose an AAA proxy, a service provisioning, security agent, a sip proxy service, and others. We call this platform the IHSM (Intelligent Home Network Service Management) Platform, which consists of the ISMS (Intelligent Service Management System) and the ISMF (Intelligent Service Management Framework).	aaa (video game industry);home automation;ibm service management framework;management system;osgi;provisioning	Choon-Gul Park;Jae-Hyoung Yoo;Seung-Hak Seok;Ju-Hee Park;Hoen-In Lim	2006		10.1007/11876601_63	network management;service level requirement;embedded system;element management system;intelligent network;intelligent computer network;open standard;service management;computer science;service delivery framework;operating system;service design;world wide web;computer security;server	Mobile	-29.66144079786924	43.59045587815927	168217
1c9fa0e3e1ce6529563024bf6a009058701a4161	using java applets and corba for multi-user distributed applications	distributed application;common gateway interface;client server systems;object oriented programming;multi user;application program interfaces internet object oriented languages object oriented programming client server systems remote procedure calls;internet;java applet;application program interfaces;www common gateway interface java language environment java applets corba world wide web multiuser distributed applications common object request broker architecture software technologies client software www downloadable java applets remote server software shared resources;world wide web;interaction effect;common object request broker architecture;remote procedure calls;object oriented languages;java application software world wide web graphical user interfaces file servers web server internet network servers html displays;java language	43 1089-7801/ 97/$10.00 ©1997 IEEE h t tp ://compu te r.o rg/ in te rne t/ MAY • JUNE 1997 The Java language environment, World Wide Web, and Common Object Request Broker Architecture are complementary software technologies, which, when used together provide a powerful set of tools for developing and deploying multi-user distributed applications. In this article we describe an approach to building reasonably sophisticated and easy-to-use client software as WWW-downloadable Java applets, which use CORBA to interact effectively with remote server software and thus coordinate and control access to a set of shared resources.	client (computing);common object request broker architecture;distributed computing;java applet;multi-user;server (computing);www;world wide web	Eric Evans;Daniel Rogers	1997	IEEE Internet Computing	10.1109/4236.589194	computer science;operating system;common object request broker architecture;database;distributed computing;programming language;object-oriented programming;world wide web;java applet	SE	-33.65649088786056	43.48386621066911	168222
bd5e5f46ddcfa1e51a433c8015d737fccfa9845a	verifiable abstractions for contract-oriented systems	verification;session types;rewriting logic;contract oriented computing	Article history: Received 19 September 2014 Received in revised form 13 October 2015 Accepted 14 October 2015 Available online xxxx		Massimo Bartoletti;Maurizio Murgia;Alceste Scalas;Roberto Zunino	2017	J. Log. Algebr. Meth. Program.	10.1016/j.jlamp.2015.10.005	real-time computing;verification;rewriting;computer science;distributed computing;programming language;algorithm	Logic	-30.181511382379966	34.206448986401604	168318
cac0fcc79cf82140d00d99f988d819189b67280c	an open event-driven architecture for reactive programming and lifecycle management in space-based middleware		Highly dynamic distributed applications often require flexible coordination among several autonomous components. Space-based middleware provides a suitable, data-driven coordination paradigm for such scenarios, where distributed peers exchange data and commands in a scalable and decoupled way using shared tuple spaces. In its basic form, such a middleware supports access to a data storage and (blocking) queries on the stored tuples. However, in many cases the injection of additional server-side logic would ease the development of complex applications, as the semantics of the tuple space can be adapted to domain-specific requirements.This paper introduces reactive programming features for XVSM, a space-based middleware that enhances the tuple space concept with powerful coordination mechanisms. We present a comprehensive extension mechanism that supports the execution of application logic in reaction to composite and time-based events. As an example for the feasibility of the approach, we provide a bootstrapped solution for a leasing mechanism that manages the lifetime of data in the space.	autonomous robot;blocking (computing);bootstrapping (compilers);business logic;computer data storage;distributed computing;event-driven architecture;event-driven programming;high- and low-level;middleware;open-source software;programming paradigm;reactive programming;requirement;scalability;server (computing);server-side;tuple space	Stefan Craß;eva Kühn;Vesna Sesum-Cavic;Harald Watzke	2017	2017 43rd Euromicro Conference on Software Engineering and Advanced Applications (SEAA)	10.1109/SEAA.2017.69	real-time computing;tuple space;computer science;scalability;tuple;event-driven architecture;distributed database;middleware (distributed applications);middleware;reactive programming;distributed computing	SE	-31.005943412333345	45.69851258468258	168533
991dd3666c58f48ec39e8c6a11debac3b9a1f145	code management automation for erlang remote actors	mobile code	Distributed Erlang provides mechanisms for spawning actors remotely through its remote spawn BIF. For remote spawn to function properly, the node hosting the spawned actor must share the same codebase as that of the node launching the actor. This assumption turns out to be too strong for various distributed settings. We propose a higher-level framework for the remote spawn of side-effect free actors, abstracting from codebase migration and management.	erlang (programming language);spawn (computing)	Adrian Francalanza;Tyron Zerafa	2013		10.1145/2541329.2541344	real-time computing;computer science;operating system;computer security	EDA	-31.720109538325445	40.861899276878574	168654
f25acfa4bbc7360094719c313fda90eb38b5c9fa	a distributed computing pattern language part ii: concurrency patterns.				Frank Buschmann;Kevlin Henney	2002			computer architecture;concurrent computing;computer science;concurrency control;distributed computing;distributed design patterns;non-lock concurrency control;programming language;distributed concurrency control	Theory	-25.79059135214263	45.28055834322931	168689
5eff5a4a719f233f2cd9d7302decb311ceb84cc0	reengineering legacy client-server systems for new scalable secure web platforms	client server		code refactoring	Julius Dichter;Ausif Mahmood;Andrew Barrett	2002			distributed computing;client–server model;computer science;database;scalability;business process reengineering	Crypto	-33.203911807495686	43.27479384920923	168757
21f81a7fd855e4805258b38ba446ba728ba76d03	distributed matching for communicating sequential processes			communicating sequential processes	Jau-Yueh Wang;Shing-Tsaan Huang	1989	J. Inf. Sci. Eng.		distributed computing;computer science;communicating sequential processes	DB	-29.182227698455858	35.3171560439308	169278
58079139bc62874656058a2640b61543e9963162	analysis of vme-bus communication protocol - rtcp-net approach	computacion informatica;coloured petri net;ciencias basicas y experimentales;communication protocol;grupo a;petri net;rtcp nets;vme bus;real time systems	The paper discusses an RTCP-net approach to design and analysis of an example of VMEbus communication protocol. RTCP-nets are a novel Petri net class, based on time coloured Petri nets but were defined to give users powerful tools for easy and rapid design of real-time systems. Page templates are one of the main advantages of the new nets' design stage. Just modifying values of parameters in the page hierarchy graph is enough to change some features of a modelled system. Therefore, it is easy to experiment on different versions of the same model with very little additional effort. It is also very easy to reorganize page templates in order to model a different structure of a system. Relevant definitions and main properties of RTCP-nets are presented in the paper. A VMEbus communication protocol case study is used to demonstrate some applications of this approach.	cp/m;coloured petri net;communications protocol;high-level programming language;page view;real-time clock;real-time computing;real-time transcription;vmebus	Marcin Szpyrka	2006	Real-Time Systems	10.1007/s11241-006-9003-0	embedded system;communications protocol;real-time computing;computer science;operating system;distributed computing;process architecture;vmebus;petri net	Embedded	-32.05288324383583	35.068320156362205	169430
0534d8ebfb638084b0283810f24737a5e7db2ffd	acp model of java multithreading	distributed system;multi threading;formal specification;communicating process algebra acp model java multithreading concurrent programming distributed systems model checking;model checking;concurrent systems;concurrent programs;java multithreading algebra concurrent computing automata computer languages system recovery petri nets power system modeling laboratories;process algebra;formal specification multi threading java;java	Feasibiliv and efjiciency of analyzing concurrent programs mostly rely on the programs ’ representations. So modeling concurrent programs in a proper and suitable way is very important. In Java, multithreading is provided to support concurrent programming, which is now widely used in distributed systems. This paper proposes a model of Java multithreading by using ACP in a neat and tidy way, so that Java concurrent system can be transformed to process algebra expressions which facilitate model checking or some further analysis. In addition, many problems similar to the mechanism of protected object can be modeled in the same way. With these models, many analyses can be performed, such as model checking.	concurrency (computer science);concurrent computing;distributed computing;html tidy;java;model checking;multithreading (computer architecture);process calculus;thread (computing)	Yuan Liu;Baowen Xu	2003		10.1109/IRI.2003.1251459	model checking;process calculus;parallel computing;real-time computing;multithreading;jsr 94;java concurrency;computer science;operating system;java modeling language;strictfp;formal specification;real time java;programming language;java;generics in java;scala;concurrent object-oriented programming;java annotation	SE	-25.70308680024202	33.38837405311564	169764
9fddb9a738b5d32a640da963b26bc4f2b819a899	high level programming for distributed computing	loosely coupled system;programming language;distributed computing;assertions;messages;modules	Programming for distributed and other loosely coupled systems is a problem of growing interest. This paper describes an approach to distributed computing at the level of general purpose programming languages. Based on primitive notions of module, message, and transaction key, the methodology is shown to be independent of particular languages and machines. It appears to be useful for programming a wide range of tasks. This is part of an ambitious program of development in advanced programming languages, and relations with other aspects of the project are also discussed.	distributed computing;loose coupling;programming language	Jerome A. Feldman	1979	Commun. ACM	10.1145/359114.359127	fourth-generation programming language;first-generation programming language;message;protocol;declarative programming;programming domain;reactive programming;computer science;theoretical computer science;extensible programming;operating system;third-generation programming language;functional logic programming;modular programming;computer programming;distributed computing;programming paradigm;event-driven programming;procedural programming;symbolic programming;inductive programming;fifth-generation programming language;programming language theory;programming language;second-generation programming language;comparison of multi-paradigm programming languages;algorithm;concurrent object-oriented programming	HPC	-26.633153943933483	32.39101063184937	169844
2bdffe4282b0cd3b1600ec782355df0693d074b2	a lock-free, concurrent, and incremental stack scanning mechanism for garbage collectors	duracion;gestion memoire;fiabilidad;reliability;langage c;storage management;performance;ramasse miettes;ejecucion programa;duration;lock free data structures;program execution;recogemigas;synchronisation;gestion memoria;c language;marcador;pointer;synchronization;execution programme;fiabilite;estructura datos;garbage collector;pointeur;algorithms;design;incremental and concurrent garbage collection;structure donnee;sincronizacion;stack scanning;concurrent garbage collection;data structure;lenguaje c;duree	Two major efficiency parameters for garbage collectors are the throughput overheads and the pause times that they introduce. Highly responsive systems need to use collectors with as short as possible pause times. Pause times have decreased significantly over the years, especially through the use of concurrent garbage collectors. For modern concurrent collectors, the longest pause is typically created by the need to atomically scan the runtime stack. All practical concurrent collectors that we are aware of must obtain a snapshot of the pointers on each thread's runtime stack, in order to reclaim objects correctly. To further reduce the duration of the collector pauses, incremental stack scans were proposed. However, previous such methods employ locks to stop the mutator from accessing a stack frame while it is being scanned. Thus, these methods introduce potentially long and unpredictable pauses for a mutator thread. In this work we propose the first concurrent, incremental, and lock-free stack scanning mechanism for garbage collectors, that allows high responsiveness and support for programs that employ fine-grain synchronization to avoid locks. Our solution can be employed by all concurrent collectors that we are aware of, it is lock-free, it imposes a negligible overhead on the program execution, and it supports intra-stack references as found in languages like C#.	call stack;compiler;concurrent computing;garbage collection (computer science);lock (computer science);multithreading (computer architecture);mutator method;non-blocking algorithm;overhead (computing);responsiveness;runtime system;snapshot (computer storage);thread (computing);thread pool;throughput	Gabriel Kliot;Erez Petrank;Bjarne Steensgaard	2009	Operating Systems Review	10.1145/1618525.1618527	stack trace;synchronization;parallel computing;real-time computing;data structure;computer science;operating system;programming language	PL	-19.48770593014435	40.48915812082008	169845
128ac8e3e59870efa04d45d03f75c8bad4bbca25	dynamic aspects for runtime fault determination and recovery	program logic;virtual machine;impedance;computer languages;runtime fault recovery;fault tolerant;runtime fault determination;programming language;runtime computer languages computer science application software fault tolerance computer errors logic programming programming profession impedance virtual machining;application software;parallel fault handling;virtual machining;software fault tolerance;object oriented programming;runtime;system recovery;logic programming;dynamic aspect;aspect oriented programming;programming profession;fault tolerance;error handling;system recovery error handling object oriented programming software fault tolerance;distributed fault handling runtime fault determination runtime fault recovery aspect oriented programming fault tolerance programming language error handling code program logic dynamic aspect rescue virtual machine run time constraint parallel fault handling;distributed fault handling;error handling code;computer science;computer errors;fault recovery;rescue;run time constraint	"""One of the most promising applications of aspect oriented programming (AOP) is the area of fault tolerance and recovery. In traditional programming languages, error handling code must be closely interwoven with program logic. AOP allows the programmer to take a more modular approach - error handling code can be woven into the code by expressing it as an aspect. One major impediment to handling error code in this way is that while errors are a dynamic, runtime property, most research on AOP has focused on static properties. In this paper, we propose a method for handling a variety of run-time faults as dynamic aspects. First, we separate fault handling into two different notions: fault determination, or the discovery of faults within a program, and fault recovery, or the logic used to recover from a fault. Our position is that fault determination should be expressed as dynamic aspects. We propose a system, called Rescue, that exposes underlying features of the virtual machine in order to express faults as variety of run-time constraints. We show how our methodology can be used to address several of the flaws in state of the art fault handling techniques. This includes their limitations in handling parallel and distributed faults, their obfuscated nature and their overly simplistic notion of what a """"fault"""" actually may comprise"""	aspect-oriented programming;asynchronous i/o;exception handling;fault tolerance;parallel computing;programmer;programming language;run time (program lifecycle phase);virtual machine	Jeremy Manson;Jan Vitek;Suresh Jagannathan	2006	Proceedings 20th IEEE International Parallel & Distributed Processing Symposium	10.1109/IPDPS.2006.1639576	fault tolerance;parallel computing;real-time computing;computer science;stuck-at fault;segmentation fault;fault model;distributed computing;programming language;software fault tolerance	Embedded	-22.810223587655322	40.2245581312978	169888
93229f3ec5bdf7e2a7e15f9b2182911b4ec85f9a	analysis of comparison-based diagnosable systems using temporal criteria	fiabilidad;reliability;multiprocessor;microprogrammation;microprogramacion;sistema informatico;computer system;algorithme;algorithm;fault tolerant system;diagnostic panne;fiabilite;fault diagnostic;diagnostico pana;sistema tolerando faltas;systeme tolerant les pannes;systeme informatique;microprogramming;multiprocesador;algoritmo;multiprocesseur	Lu0027approche proposee est basee sur un critere temporel pour lu0027identification des unites defectueuses dans un systeme multiprocesseur tolerant les pannes		Fabrizio Lombardi	1988	Comput. J.	10.1093/comjnl/31.3.201	embedded system;fault tolerance;multiprocessing;computer science;operating system;reliability;microcode;algorithm	Logic	-20.216034329229046	41.52636623948855	169904
16c4bf12eb4dba6d5deaef6a66a2eb67d29440c8	device state recovery in non-volatile main memory systems	message passing system;system performance;cpu device state recovery nonvolatile main systems memory systems peripheral devices software based approach recoverable system complex hardware equipments consistency requirements distributed systems message passing systems device driver uart network devices system execution recovery;system recovery;operating system kernels device drivers random access storage system recovery message passing;device drivers;message passing;memory systems;random access storage;operating system kernels;device driver;nonvolatile memory application software resumes hardware central processing unit energy management power system management operating systems system performance usability	This paper proposes a scheme to recover the state of peripheral devices in non-volatile main memory systems so that the system resumes its execution after an unpredictable power failure. Our scheme is software-based approach and accomplishes the recoverable system without complex hardware equipments. First, the requirements for maintaining consistency are discussed based on the concepts of distributed message-passing systems. Next, the application to a device driver is illustrated using an example. Experiments with UART and network devices showed that the system restarted properly after a power failure, and that system performance was barely decreased.	computer data storage;non-volatile memory	Ren Ohmura;Nobuyuki Yamasaki;Yuichiro Anzai	2003		10.1109/CMPSAC.2003.1245316	embedded system;message passing;real-time computing;computer hardware;computer science;operating system;database;computer performance;programming language;computer security	DB	-25.024111321807514	42.99990902594705	170083
1388e187fc6455820ce9073aed22d9b64b97f66f	hpcbugbase: an experience base for hpc defects	data collection;high productivity computing systems;software engineering;design and implementation;levels of abstraction;high performance computer;scientific applications;overlapping communication and computation;experience base;performance modeling	We present the design and implementation of HPCBugBase, an experience base for high performance computing (HPC) software defects. Our goal is to accumulate empirical knowledge about commonly occurring defects in HPC codes using an incremental approach. This knowledge is structured so that HPC practitioners such as programmers and tool builders can use it to reduce debugging costs, as well as provide feedback which becomes incorporated into the system. By building the experience base, we expect to help the process of making explicit the knowledge about recurring defects that otherwise cannot be shared. The current system is built on a Wiki system, which allows incremental accumulation of data at various levels of abstraction. We implement additional analysis functions that do not exist in a generic Wiki system as custom plug-ins. We have populated the system with data collected from software engineering studies from the DARPA High Productivity Computer Systems Project.		Taiga Nakamura	2006		10.1145/1188455.1188589	parallel computing;simulation;computer science;operating system;programming language;statistics;data collection	HPC	-19.521133306420175	39.69184927251723	170197
be8bdcd1b667b992ba995cc4d70e72e4e6137374	a unified proof of minimum time complexity for reaching consensus and uniform consensus - an oracle-based approach	consensus;fault tolerant;time complexity;lower bounds;computer model;concurrency control computational complexity message passing fault tolerant computing;distributed computing;distributed computing message passing educational institutions computational modeling fault tolerance context delay systems algorithm design and analysis computer crashes mobile computing;fault tolerant computing;computational complexity;fault tolerance;concurrency control;message passing;uniform consensus;lower bound;induction proofs distributed computing uniform consensus synchronous message passing oracle argument lower bounds fault tolerance time complexity consensus	In this paper, we offer new proofs to two lower bound results in distributed computing: a minimum of and rounds for reaching consensus and uniform consensus respectively when at most fail-stop faults can happen. Here the computation model is synchronous message passing. Both proofs are based on a novel oracle argument. These two induction proofs are unified in the following sense: the induction steps are the same and only the initial step ( =0) needs to be proved separately. The techniques used in the proof offer new insights into the lower bound results in distributed computing.	algorithm;distributed computing;emoticon;fail-stop;mathematical induction;message passing;model of computation;time complexity;uniform consensus	Jun Xu	2002		10.1109/RELDIS.2002.1180178	computer simulation;fault tolerance;real-time computing;computer science;theoretical computer science;distributed computing	Theory	-22.414920104291745	44.270861002253554	170724
00f2d3ed453c64d2026e1be95cad4ce173d4be86	brief announcement: time efficient self-stabilizing stable marriage		“Stable marriage” refers to a particular matching with constraints having a wide variety of applications in different domains (two-sided markets, Cloud computing, college admissions, etc.). Most of the studies on this problem performed up to now were for centralized and synchronous settings assuming initialization. We consider a distributed and asynchronous context, without initialization (i.e., in a self-stabilizing manner, tolerating any transient fault) and with some confidentiality requirements. The single already known self-stabilizing solution in Laveau et al. (SSS’ 2017), based on Ackerman et al.’s algorithm (SICOMP’ 2011), stabilizes in (O(n^4)) moves (activation of a single node). We improve on this previous result considerably by presenting a solution with (O(n^2)) steps, relying on the idea of Gale and Shapley’s algorithm (AMM 1962), which takes also (O(n^2)) moves, but in a centralized synchronous context. Moreover it is not self-sabilizing solution and a corruption cannot be repaired locally, as noticed by Knuth (1976).	self-stabilization;stable marriage problem	Joffroy Beauquier;Thibault Bernard;Janna Burman;Shay Kutten;Marie Laveau	2018		10.1007/978-3-030-03232-6_26	initialization;asynchronous communication;cloud computing;sss*;mathematics;distributed computing;stable marriage problem	Theory	-22.801366827696484	45.13076744689646	170857
e2213443945e71f5de088626f200e7dfc6f1ef3d	system support for pervasive applications	distributed system;sistema operativo;eficacia sistema;fiabilidad;reliability;architecture systeme;systeme reparti;migration;gestion red;pervasive computing;performance systeme;discovery;reseau omnipresent;system performance;checkpointing;ubiquitous network;programming model;informatica difusa;structured i o;sistema repartido;thesis;operating system;informatique diffuse;tuples;red ubicua;fiabilite;gestion reseau;ubiquitous computing;arquitectura sistema;systeme exploitation;one world;network management;logic operation pattern;system architecture;asynchronous events	Pervasive computing provides an attractive vision for the future of computing. Computational power will be available everywhere. Mobile and stationary devices will dynamically connect and coordinate to seamlessly help people in accomplishing their tasks. For this vision to become a reality, developers must build applications that constantly adapt to a highly dynamic computing environment. To make the developers' task feasible, we present a system architecture for pervasive computing, called <i>one.world</i>. Our architecture provides an integrated and comprehensive framework for building pervasive applications. It includes services, such as discovery and migration, that help to build applications and directly simplify the task of coping with constant change. We describe our architecture and its programming model and reflect on our own and others' experiences with using it.	experience;mobile computing;pervasive informatics;programming model;stationary process;system migration;systems architecture;ubiquitous computing	Robert Grimm;Janet Davis;Eric Lemar;Adam MacBeth;Steven Swanson;Thomas E. Anderson;Brian N. Bershad;Gaetano Borriello;Steven D. Gribble;David Wetherall	2004	ACM Trans. Comput. Syst.	10.1145/1035582.1035584	network management;embedded system;real-time computing;context-aware pervasive systems;simulation;tuple;computer science;human migration;operating system;end-user computing;reliability;programming paradigm;programming language;ubiquitous computing	HCI	-28.22735456074018	42.26049270692652	171230
ffabb8d83df361b73fc7d933988b9f87d39e930c	a software architecture for hpc grid applications (research note)	composante;distributed system;architecture logicielle;flujo termico;systeme reparti;component;distributed computing;reseau;calculo automatico;hpc application;computing;red;calcul automatique;heat flow;software architecture;sistema repartido;scheduling;componente;calculo repartido;ordonamiento;calcul reparti;ordonnancement;flux thermique;network	We introduce a component software architecture designed for demanding grid computing environments that allows the optimal performance of the assembled component applications to be achieved. Performance over the assembled component application is maintained through inter-component static and dynamic optimisation techniques. Having defined an application through both its component task and data flow graphs we are able to use the associated performance models to support application level scheduling. By building grid aware applications through reusable interchangeable software components with integrated performance models we enable the automatic and optimal partitioning of an application across distributed computational resources.	software architecture	Steven Newhouse;Anthony Edward Mayer;John Darlington	2000		10.1007/3-540-44520-X_95	embedded system;software architecture;computing;real-time computing;common component architecture;computer science;operating system;component;distributed computing;scheduling	HPC	-27.72577918383567	42.806656535287075	171291
a9bd02bbc1aba716a66d6e82d7cf5830e2558702	shared memory multimicroprocessor operating system with an extended petri net model	software;sistema operativo;microprocessor;programming environments;shared memory;shared memorymultimicroprocessor operating system;logiciel;multiprocessor;system software;multiprocessor systems;red petri;single bus multiprocessors;job levelprogramming;index termsoperating systems computers;conceptual model;parallel programming;conception;indexing terms;software engineering;softwareengineering;shared memory systems;modified petri nets;operating system;programming environments operating systems computers shared memory systems petri nets software engineering parallel programming;software development;operating systems application software parallel programming power system modeling robotics and automation hardware software systems control systems multiprocessing systems;event driven systems;diseno;logicial;design;systeme exploitation;extended petri net model;microprocesseur;programming support;task level programming;petri nets;job level programming shared memory multimicroprocessor operating system extended petri net model event driven systems task level programming parallel programs operating system programming support software development system software extended petri net conceptual model;multiprocesador;software design;parallel programs;petri net;microprocesador;operating systems computers;reseau petri;run time executives;extended petri net;multiprocesseur	In this paper we propose a methodology for programming multiprocessor event-driven systems. This methodology is based on two programming levels: the task level, which involves programming the basic actions that may be executed in the system as units with a single control thread; and the job level, on which parallel programs to be executed by the complete multiprocessor system are developed. We also present the structure and implementation of an operating system designed as the programming support for software development under the proposed methodology. The model that has been chosen for the representation of the system software is based on an extended Petri net, which provides a well-established conceptual model for the development of the tasks, thus allowing a totally independent and generic development. This model also facilitates job-level programming, since the Petri net is a very powerful description tool for the parallel program.	computer programming;event-driven programming;multiprocessing;operating system;petri net;shared memory;software development	Fernando Vallejo;José-Ángel Gregorio;Michael González Harbour;José M. Drake	1994	IEEE Trans. Parallel Distrib. Syst.	10.1109/71.296320	parallel computing;real-time computing;programming domain;reactive programming;computer science;software development;operating system;database;distributed computing;programming paradigm;inductive programming;programming language;system programming;petri net	HPC	-25.117702686088943	35.40333635431009	171667
7af0f9fb2c3bc95081e42a296ea59607ce8ecad9	testing a multiprogramming system	multiprogramming;program testing;processor multiplexing;rc 4000;process communication;monitor	A central problem in program design is to structure a large program such that it can be tested systematically by the simplest possible techniques. This paper describes the method used to test the RC 4000 multiprogramming system. During testing, the system records all transitions of processes and messages between various queues. The test mechanism consists of fifty machine instructions centralized in two procedures. By using this mechanism in a series of carefully selected test cases, the system was made virtually error free within a few weeks. The test procedure is illustrated by examples. © 1973 Wiley Periodicals, Inc.	computer multitasking	Per Brinch Hansen	1973	Softw., Pract. Exper.	10.1002/spe.4380030206	monitor;parallel computing;real-time computing;computer multitasking;computer hardware;computer science;operating system;programming language	SE	-21.123223397275	41.17338980231707	171670
22f728136b78cad7a695aacb3a65497664c0bb44	identifying domain-specific defect classes using inspections and change history	empirical study;code reading;bottom up;change history;inspection;message passing interface;lessons learned;levels of abstraction;high performance computer;source code;parallel programs;domain specific defects;domain specificity	We present an iterative, reading-based methodology for analyzing defects in source code when change history is available. Our bottom-up approach can be applied to build knowledge of recurring defects in a specific domain, even if other sources of defect data such as defect reports and change requests are unavailable, incomplete or at the wrong level of abstraction for the purposes of the defect analysis. After defining the methodology, we present the results of an empirical study where our method was applied to analyze defects in parallel programs which use the MPI (Message Passing Interface) library to express parallelism. This library is often used in the domain of high performance computing, where there is much discussion but little empirical data about the frequency and severity of defect types. Preliminary results indicate the methodology is feasible and can provide insights into the nature of real defects. We present the results, derived hypothesis, and lessons learned.	iterative method;message passing interface;parallel computing;software bug;software inspection;supercomputer;top-down and bottom-up design	Taiga Nakamura;Lorin Hochstein;Victor R. Basili	2006		10.1145/1159733.1159785	simulation;computer science;theoretical computer science	HPC	-19.182918545170065	39.651942531464826	171676
d3e4b30a6499c530bec0d4a1511ed4b85ef8462e	personalized cache management for mobile computing environments	databases;mobile;medio ambiente;base donnee;informatique mobile;gestion;propriete spatiale donnee;database;base dato;mobile computer;cache memory;calcul mobile;taille;calculo automatico;computing;antememoria;calcul automatique;antememoire;cache requirement rate;movil;environment;talla;gestion base donnee;environnement;data spatial property;crr;mobile computing;size;management;cache management;data base management;gestion cache		mobile computing	Ho-Sook Kim;Hwan-Seung Yong	2003	Inf. Process. Lett.	10.1016/S0020-0190(03)00352-1	embedded system;computing;computer science;operating system;database;size;mobile computing	DB	-29.305375071791367	43.684206051713524	171695
2239c59c7f4ffb53b662da9202e7143edbdc9a58	towards abstractions for distributed systems	distributed system;distributed computing	For historical, sociological and technical reasons, λ-calculi have been the dominant theoretical paradigm in the study of functional computation. Similarly, but to a lesser degree, π-calculi dominate advanced mathematical accounts of concurrency. Alas, and despite its ever increasing ubiquity, an equally convincing formal foundation for distributed computing has not been forthcoming. This thesis seeks to contribute towards ameliorating that omission. To this end, guided by the assumption that distributed computing is concurrent computing with partial failures of various kinds, we extend the asynchronous π-calculus with • a notion of sites, • the possibility of site failure, • a persistence mechanism to deal with site failures, • the distinction between inter-site and intra-site communication, • the possibility of message loss in inter-site communication and • a timer construct, as is often used in distributed algorithms to deal with various failure scenarios. The basic theory of two of the resulting augmented π-calculi is explored in considerable detail: the asynchronous π-calculus with timers and the asynchronous π-calculus with timers, sites and message failure. The emphasis of this development is on soundly approximating reduction congruence, the canonical equivalence for asynchronous π-calculi. In the case of the asynchronous π-calculus with timers we manage to obtain a characterisation of reduction congruence as a labelled bisimilarity. Our results appear to be robust under variations of the underlying calculi. In addition, as a test to evaluate the usefulness and the integration of the aforementioned extensions, we cleanly and incrementally represent the Two Phase Commit Protocol – an important distributed algorithm, used to ensure consistency of distributed databases in the face of various kinds of (non-byzantine) failures – in the asynchronous π-calculus, the asynchronous π-calculus with timers, sites and message failure and in the asynchronous π-calculus with timers, sites, site failure and	distributed computing	Martin Friedrich Berger	2003			distributed algorithm;csiv2;distributed computing;distributed object;distributed design patterns;replication;autonomic computing;distributed concurrency control	PL	-23.254012463574142	45.19411268437409	171766
7db38afdf8a4650d0f97bb09685dc34f05cd5472	blueswitch: enabling provably consistent configuration of network switches		Previous research on consistent updates for distributed network configurations has focused on solutions for centralized network-configuration controllers. However, such work does not address the complexity of modern switch datapaths. Modern commodity switches expose opaque configuration mechanisms, with minimal guarantees for datapath consistency and with unclear configuration semantics. Furthermore, would-be solutions for distributed consistent updates must take into account the configuration guarantees provided by each individual switch - plus the compositional problems of distributed control and multi-switch configurations that considerably transcend the single-switch problems. In this paper, we focus on the behavior of individual switches, and demonstrate that even simple rule updates result in inconsistent packet switching in multi-table datapaths. We demonstrate that consistent configuration updates require guarantees of strong switch level atomicity from both hardware and software layers of switches - even in a single switch. In short, the multiple-switch problems cannot be reasonably approached until single-switch consistency can be resolved.  We present a hardware design that supports a transactional configuration mechanism, and provides packet-consistent configuration: all packets traversing the datapath will encounter either the old configuration or the new one, and never an inconsistent mix of the two. Unlike previous work, our design does not require modifications to network packets. We precisely specify the hardware-software protocol for switch configuration; this enables us to prove the correctness of the design, and to provide well-specified invariants that the software driver must maintain for correctness. We implement our prototype switch design using the NetFPGA-10G hardware platform, and evaluate our prototype against commercial off-the-shelf switches.	atomicity (database systems);centralized computing;correctness (computer science);datapath;device driver;distributed control system;expectation propagation;invariant (computer science);multiple buffering;netfpga;network packet;network switch;openflow;packet switching;prototype;research data archiving	Jong Hun Han;Prashanth Mundkur;Charalampos Rotsos;Gianni Antichi;Nirav H. Dave;Andrew W. Moore;Peter G. Neumann	2015	2015 ACM/IEEE Symposium on Architectures for Networking and Communications Systems (ANCS)		openflow;parallel computing;real-time computing;computer science;control system;operating system;distributed computing;pipeline transport;computer security;atomicity;computer network	Networks	-24.546823152944512	44.478099763936676	172090
7b4ee87e5fa2b9a1cbb13455f94e32d4162d1776	modular specification and verification of a cache-coherent interface	monoidal categories;protocols;history;semantics;feedback circuits;probes;circuit topology;category theory;micromechanical devices;cognition;coherence;digital circuits;multivalued logic	We consider the problem of constructing a modular specification for a cache coherence protocol implementing a weakly consistent shared memory model. That is, we wish to specify the interface between components in a way that, if all components locally satisfy their interface specifications, the components collectively implement the desired memory semantics. The problem we face is that the semantics involves an existential quantifier over memory orderings that cannot be witnessed locally. We solve this problem using a specification idiom based on reference objects and circular assume-guarantee reasoning. The specification is written using a language and a tool called Ivy. We use Ivy to specify the TileLink coherent memory interface protocol and to prove compositionally that interconnections of TileLink components implement the memory semantics correctly. The specification is also used for modular specification-based testing of RTL components.	apache ivy;cache coherence;coherence (physics);computation;correctness (computer science);existential quantification;formal methods;formal specification;integration testing;liveness;memory semantics (computing);programming paradigm;quantifier (logic);replication (computing);scalability;serialization;shared memory;system on a chip;the witness	Kenneth L. McMillan	2016	2016 Formal Methods in Computer-Aided Design (FMCAD)	10.1109/FMCAD.2016.7886668	topology;communications protocol;cognition;coherence;computer science;theoretical computer science;semantics;programming language;digital electronics;algorithm;language of temporal ordering specification;category theory	Logic	-27.343439511675616	32.46165089873699	172129
2108491c3410ed744329e51b1f151bab67efaa6e	analyzing and verifying locally clocked circuits with the concurrency workbench	asynchronous circuits;circuit analysis computing;formal verification;logic cad;logic design;process algebra;timing;ccs process algebra;asynchronous circuits;asynchronous communication;concurrency workbench;concurrent system modelling;locally clocked circuits;synchronous computational elements	Locally Clocked Modules (LCMs) allow asynchronous communication between synchronous computational elements. The concurrency workbench models concurrent systems in the CCS process algebra. We describe the use of the concurrency workbench to specify, simulate, and verify implementations of LCMs and discuss its application to the specification of asynchronous circuits	clock rate;concurrency (computer science);verification and validation;workbench	Garth Baulch;David Hemmendinger;Cherrice Traver	1995			process calculus;logic synthesis;real-time computing;asynchronous circuit;formal verification;computer science;theoretical computer science;asynchronous communication;distributed computing;non-lock concurrency control;programming language	Logic	-33.042846624038866	32.49802712172337	172132
2157f59c409ebee864dc12a896e6a998f9913a91	a graphical user interface toolkit approach to thin-client computing	binary image;client server systems;user interface toolkit;client server;x window system;remote method invocation;graphic user interface;network computing	"""Network and server-centric computing paradigms are quickly returning to being the dominant methods by which we use computers. Web applications are so prevalent that the role of a PC today has been largely reduced to a terminal for running a client or viewer such as a Web browser. Implementers of network-centric applications typically rely on the limited capabilities of HTML, employing proprietary """"plug ins"""" or transmitting the binary image of an entire application that will be executed on the client. Alternatively, implementers can develop without regard for remote use, requiring users who wish to run such applications on a remote server to rely on a system that creates a virtual frame buffer on the server, and transmits a copy of its raster image to the local client.We review some of the problems that these current approaches pose, and show how they can be solved by developing a distributed user interface toolkit. A distributed user interface toolkit applies techniques to the high level components of a toolkit that are similar to those used at a low level in the X Window System. As an example of this approach, we present RemoteJFC, a working distributed user interface toolkit that makes it possible to develop thin-client applications using a distributed version of the Java Foundation Classes."""	binary image;computer;framebuffer;graphical user interface;html;high-level programming language;java;plug-in (computing);raster graphics;server (computing);thin client;transmitter;user interface toolkit;web application;widget toolkit;x window system	Simon Lok;Steven K. Feiner;William M. Chiong;Yoav J. Hirsch	2002		10.1145/511446.511540	binary image;computer science;operating system;graphical user interface;database;fat client;law;world wide web;client–server model	Web+IR	-31.774127422750773	40.64259678269345	172134
5237c1600460eab9da573204919e2cab2ea8463f	graph relabelling systems: a tool for encoding, proving, studying and visualizing - distributed algorithms	distributed algorithm		distributed algorithm	Michel Bauderon;Yves Métivier;Mohamed Mosbah;Afif Sellami	2001	Electr. Notes Theor. Comput. Sci.	10.1016/S1571-0661(04)80194-4	computer science;theoretical computer science;machine learning;distributed computing	Logic	-21.67926301196499	41.93013365776381	172502
3f9923d3358960d48f32ad1d1ff94e64447bc5e0	test-driven repair of data races in structured parallel programs	data race;structured parallelism;async;program repair;finish	"""A common workflow for developing parallel software is as follows: 1) start with a sequential program, 2) identify subcomputations that should be converted to parallel tasks, 3) insert synchronization to achieve the same semantics as the sequential program, and repeat steps 2) and 3) as needed to improve performance. Though this is not the only approach to developing parallel software, it is sufficiently common to warrant special attention as parallel programming becomes ubiquitous. This paper focuses on automating step 3), which is usually the hardest step for developers who lack expertise in parallel programming.  Past solutions to the problem of repairing parallel programs have used static-only or dynamic-only approaches, both of which incur significant limitations in practice. Static approaches can guarantee soundness in many cases but are limited in precision when analyzing medium or large-scale software with accesses to pointer-based data structures in multiple procedures. Dynamic approaches are more precise, but their proposed repairs are limited to a single input and are not reflected back in the original source program. In this paper, we introduce a hybrid static+dynamic test-driven approach to repairing data races in structured parallel programs. Our approach includes a novel coupling between static and dynamic analyses. First, we execute the program on a concrete test input and determine the set of data races for this input dynamically. Next, we compute a set of """"finish"""" placements that prevent these races and also respects the static scoping rules of the program while maximizing parallelism. Empirical results on standard benchmarks and student homework submissions from a parallel computing course establish the effectiveness of our approach with respect to compile-time overhead, precision, and performance of the repaired code."""	benchmark (computing);compile time;compiler;data structure;overhead (computing);parallel computing;pointer (computer programming);race condition;scope (computer science)	Rishi Surendran;Raghavan Raman;Swarat Chaudhuri;John M. Mellor-Crummey;Vivek Sarkar	2014		10.1145/2594291.2594335	parallel computing;real-time computing;computer science;asynchronous communication;distributed computing;race condition;programming language	PL	-19.570110239777424	37.369484500189124	172509
410da047427248b3781fe0a91a2c76cd4bc44e62	systemic support for transaction-based spatial-temporal programming of mobile robot swarms	transaction based spatial temporal programming time based two phase commit protocol spatial temporal action executability context aware actions distributed actions concurrent actions mobile robot swarms;protocols;sensors;swarm intelligence mobile robots robot programming;schedules robots programming trajectory protocols operating systems sensors;trajectory;robots;schedules;programming;operating systems	In this paper, we present an approach to support transaction-based spatial-temporal programming of mobile robot swarms on a systemic level. We introduce a programming model for swarms of mobile robots. Swarm applications consist of concurrent, distributed and context-aware actions. We provide distributed transactions in order to guarantee atomic execution of a set of dependent actions. We distinguish between schedulability and executability of a set of actions. In order to guarantee executability of a distributed transaction of spatial-temporal actions, we present the concept of path alternatives and a time-based two-phase commit protocol in order to assure consistency. We show the feasibility of our approach by a proof-of-concept.	best, worst and average case;computation;distributed transaction;mobile robot;programming model;scheduling (computing);swarm;two-phase commit protocol	Daniel Graff;Daniel Röhrig;Reinhardt Karnapke	2015	2015 IEEE 40th Local Computer Networks Conference Workshops (LCN Workshops)	10.1109/LCNW.2015.7365921	robot;communications protocol;programming;real-time computing;simulation;schedule;computer science;sensor;trajectory;operating system;distributed computing	Robotics	-31.439766616354305	36.148918758261324	172773
1a276ac59b1df66ea31c732fa3140497e6fe8b97	distributed composite objects: a new object model for cooperative applications	distributed system;unfolding;replication;systeme reparti;deploiement;transparence;programming environment;implementation;despliegue;replicacion;transparencia;medio ambiente programacion;sistema repartido;internet;object oriented;algorithme reparti;concurrency control;oriente objet;transparency;algoritmo repartido;controle concurrence;control concurrencia;implementacion;distributed algorithm;orientado objeto;environnement programmation	This paper introduces a new programming model for distributed systems, distributed composite objects (DCO), to meet efficient implementation, transparency, and performance demands of distributed applications with cooperating users connected through the internet. DCO model incorporates two basic concepts: composition and replication. It allows the representation of an object as a collection of sub-objects and enhances the object distribution concept by implementing replication at the sub-object level and only when demanded. DCOBE, a DCO-based programming environment, conceals implementation details of the DCO model behind its interface and provides basic mechanisms for object composition, distribution and replication of object state, consistency management, concurrency control and dynamic deployment of restructured objects.	access control;authorization;concurrency (computer science);concurrency control;device configuration overlay;distributed computing;integrated development environment;middleware;object composition;programming model;software deployment	Guray Yilmaz;Nadia Erdogan	2003		10.1007/978-3-540-24639-8_10	distributed algorithm;replication;real-time computing;the internet;simulation;computer science;operating system;concurrency control;database;distributed computing;distributed object;transparency;programming language;object-oriented programming;implementation	Networks	-29.02644110787634	42.64078384970986	172909
c6a994363c51cba1a6edd9f70d31a45c41c2028f	automatic checking of aggregation abstractions through state enumeration	verification;protocols;invariant property;memory protocols;telecommunication network reliability;flash multiprocessor system aggregation abstractions state enumeration transaction oriented protocol finite state enumerator verification invariant property finite state protocols general purpose theorem prover cache coherence protocol;logic;flash multiprocessor system;state enumeration;theorem proving;automata;aggregation abstractions;finite state protocols;formal verification;cache coherence protocol;finite state enumerator;general purpose theorem prover;protocols coherence nasa multiprocessing systems logic automata read write memory telecommunication network reliability laboratories computer science;transaction processing formal verification memory protocols multiprocessing systems theorem proving;transaction oriented protocol;coherence;multiprocessing systems;computer science;read write memory;transaction processing;nasa	Aggregation abstraction is a way of defining a desired correspondence between an implementation of a transaction-oriented protocol and a much simpler idealized version of the same protocol. This relationship can be formally verified to prove the correctness of the implementation. We present a technique for checking aggregation abstractions automatically using a finite-state enumerator. The abstraction relation between implementation and specification is checked on-the-fly and the verification requires examining no more states than checking a simple invariant property. This technique can be used alone for verification of finite-state protocols, or as preparation for a more general aggregation proof using a general-purpose theorem-prover. We illustrate the technique on the cache coherence protocol used in the F LASH multiprocessor system.	automated theorem proving;cache coherence;correctness (computer science);enumerator (computer science);formal verification;general-purpose modeling;multiprocessing	Seungjoon Park;Satyaki Das;David L. Dill	1997	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.875327	parallel computing;verification;coherence;transaction processing;formal verification;computer science;theoretical computer science;operating system;distributed computing;programming language;logic;abstraction model checking;algorithm	Logic	-31.458483601122012	32.61114242613445	172949
59b429a992ba10442aceba07065c43b2ebdcea38	programming language support for writing fault-tolerant distributed software	tolerancia falta;software;lenguaje programacion;replication;computer languages writing fault tolerance programming profession strontium sun workstations runtime fault tolerant systems distributed computing;programming environments;distributed programming language;fault tolerant;programming language;logiciel;logiciel reparti;implementation;distributed software;data management;distributed programs;abstraction;software fault tolerance;langage programmation reparti;abstraccion;replicacion;programming model;sun workstations programming language support fault tolerant distributed software high level distributed programming language fault tolerance sequential languages specialized languages ft sr data manager stable storage;ejecucion;levels of abstraction;fault tolerance;langage programmation;logicial;programming environments software fault tolerance;tolerance faute	Good programming language support can simplify the task of writing fault-tolerant distributed software. Here, an approach to providing such support is described in which a general high-level distributed programming language is augmented with mechanisms for fault tolerance. Unlike approaches based on sequential languages or specialized languages oriented towards a given fault-tolerance technique, this approach gives the programmer a high level of abstraction, while still maintaining flexibility and execution efficiency. The paper first describes a programming model that captures the important characteristics that should be supported by a programming language of this type. It then presents a realization of this approach in the form of FT-SR, a programming language that augments the SR distributed programming language with features for replication, recovery, and failure notification. In addition to outlining these extensions, an example program consisting of a data manager and its associated stable storage is given. Finally, an implementation of the language that uses the x-kernel and runs standalone on a network of Sun workstations is discussed. The overall structure and several of the algorithms used in the runtime are interesting in their own right.	apl;ada;algorithm;argus (programming language);avalon;c++;coherence (physics);common lisp;communications protocol;distributed computing;experiment;fault tolerance;high- and low-level;high-level programming language;library (computing);programmer;programming model;runtime system;sr (programming language);seamless3d;stable storage;usability;workstation	Richard D. Schlichting;Vicraj T. Thomas	1995	IEEE Trans. Computers	10.1109/12.364532	fourth-generation programming language;embedded system;first-generation programming language;fault tolerance;parallel computing;real-time computing;very high-level programming language;language primitive;programming domain;reactive programming;data management;computer science;programming language implementation;extensible programming;operating system;third-generation programming language;functional logic programming;programming paradigm;symbolic programming;low-level programming language;inductive programming;fifth-generation programming language;programming language theory;programming language;programming language specification;second-generation programming language;high-level programming language;algorithm	PL	-25.199743998824655	41.345233382259956	173148
902740031793f5dbd7c2ff9f63b415cd1870d30a	global snapshots for distributed debugging	distributed algorithms;global state;property preserving algorithm;distributed debugging;monitoring;support tools;program debugging;global snapshots;abstract framework;distributed computing;parallel programming;computer networks;history;debugging;parallel processing	The widespread adoption of distributed computing has accentuated the need for an eeective set of support tools. In providing such support, one fundamental problem is that of constructing a global snapshot or global state of a distributed computation. This paper examines global snapshot algorithms from a distributed debugging perspective, and proposes an abstract framework based on global snapshots, which is deened to form a consistent state of the entire system. It is shown that by using a property preserving algorithm this framework can be superimposed on the underlying computation, but not interfere with it.	algorithm;breakpoint;communicating sequential processes;computation;debugging;distributed computing;expressive power (computer science);high-level programming language;inter-process communication;snapshot (computer storage)	Zhonghua Yang;T. Anthony Marsland	1992			real-time computing;computer science;theoretical computer science;distributed computing	HPC	-27.318752127781142	35.31861807090082	173164
0c7c549085feea45ad4e5eac869beb7598b92302	the type discipline of behavioral separation	interference;separation;concurrency;behavioral types;higher order programming	We introduce the concept of behavioral separation as a general principle for disciplining interference in higher-order imperative concurrent programs, and present a type-based approach that systematically develops the concept in the context of an ML-like language extended with concurrency and synchronization primitives. Behavioral separation builds on notions originally introduced for behavioral type systems and separation logics, but shifts the focus from the separation of static program state properties towards the separation of dynamic usage behaviors of runtime values. Behavioral separation types specify how values may be safely used by client code, and can enforce fine-grained interference control disciplines while preserving compositionality, information hiding, and flexibility. We illustrate how our type system, even if based on a small set of general primitives, is already able to tackle fairly challenging program idioms, involving aliasing at various types, concurrency with first-class threads, manipulation of linked data structures, behavioral borrowing, and invariant-based separation.	aliasing;concurrency (computer science);imperative programming;interference (communication);linked data structure;separation kernel;state (computer science);type system	Luís Caires;João Costa Seco	2013		10.1145/2429069.2429103	higher-order programming;concurrency;computer science;theoretical computer science;interference;programming language;algorithm	PL	-26.34121727245702	32.449619741934555	173385
5a41f47387b761f2ff2f243b143b4ba5885c05af	a new objective-c runtime: from research to production	trumps new feature;new objective-c runtime	Backward compatibility always trumps new features	backward compatibility;c standard library;objective-c	David Chisnall	2012	Commun. ACM	10.1145/2330667.2330682	world wide web;computer engineering;objective-c;computer science	Logic	-32.19635138751374	41.804422694820495	173484
1b6d8162c7a969ee42e8689b9e447c414b97cbdb	poems: a parallel object-oriented environment for multi-computer systems	computing;thesis;drntu engineering computer science and engineering computer systems organization special purpose and application based systems;object oriented	POEMS is a Parallel Object-oriented Environment for Multi-computer Systems. In order to support dynamic load balancing, its runtime execution model is based on object replication. Method invocation in POEMS is asynchronous and threads are created to execute methods. Inter-object, intra-object as well as intra-method parallelism are all supported. Programs in POEMS are written using two classes of objects, i.e. parallel object replication (POR) and parallel object collection (POC) classes. They are used to support programming in MPMD and SPMD styles, respectively. This paper will focus on the object models and programming facilities of POEMS and presents some preliminary performance studies. The major features and execution models of POR and POC classes are described in detail. In addition, some typical applications are also presented to illustrate the usage of these two classes. The implementation issues of a POEMS prototype runtime system are also discussed.	asynchronous i/o;flynn's taxonomy;hardware description language;load balancing (computing);parallel computing;prototype;runtime system;spmd;thread (computing)	Wei Jie;Wentong Cai;Stephen John Turner	2002	Comput. J.	10.1093/comjnl/45.5.540	computing;computer science;theoretical computer science;operating system;database;distributed computing;programming language;algorithm	HPC	-25.871563636960392	36.63698775248436	173531
69208417f01d8edd86fd5e4de20c38be3f194ac2	internet nuggets		Having taken the RISC ISA that we did, using the coprocessor interface is one way to extend the processor without disturbing existing execution (so existing code from existing compilers still works, and existing OSes will work). This also enables easy conditional compilation: flip the build flag and the CHERI because a capability-free BERI, which is important because we use BERI for other things and don't want to have to maintain two codebases.	compiler;conditional compilation;coprocessor	Mark Thorson	2015	SIGARCH Computer Architecture News	10.1145/2927964.2927982		Arch	-20.421257394956626	36.34957408858873	173838
0782a40f26ed7d4f0605c91b46fddb6e9f5b8e8c	fault-tolerant mutual exclusion algorithms	tolerancia falta;distributed system;evaluation performance;fiabilidad;reliability;systeme reparti;performance evaluation;fault tolerant;evaluacion prestacion;sistema informatico;reseau ordinateur;transmission message;computer system;message transmission;computer network;exclusion mutual;algorithme;mutual exclusion;algorithm;sistema repartido;fiabilite;fault tolerance;red ordenador;systeme informatique;exclusion mutuelle;tolerance faute;transmision mensaje;algoritmo	A distributed computing system or a computer network consists of an interconnection af a set of N independently running computer systems called the nodes of the network. These nodes communicate among themselves only by exchanging messages. in this paper, we propose two different fault-tolerant distributed mutual exclusion algorithms that can establish mutual exclusion in such a distributed environment even when the member nodes fail, and we evaluate their relative performance.	algorithm;byzantine fault tolerance;distributed computing;interconnection;mutual exclusion	Shivakant Mishra;Pradip K. Srimani	1990	Journal of Systems and Software	10.1016/0164-1212(90)90056-R	distributed algorithm;fault tolerance;telecommunications;computer science;distributed computing;suzuki-kasami algorithm;computer security	HPC	-21.1076052305884	44.09011775809702	173851
eb99b9ca8ca55bb46a46c4316e10c0a32d35ff78	design and implementation requirements for corba lightweight components	guidelines network servers resource management memory management runtime packaging optical reflection fault tolerance protocols fault diagnosis;protocols;groupware;fault tolerant;grid computing implementation requirements corba lightweight components corba spl lscr c repository cpu cycles packaging logical network cohesion distributed resource queries fault tolerant protocols cscw;distributed component models;corba;fault tolerant computing;client server;design and implementation;network model;distributed object management;fault tolerant computing distributed object management groupware protocols;component model;cscw;grid computing	This paper describes the guidelines we followed and the requirements we stated while designing and implementing the CORBALightweight Components(CORBA–LC) Component Model. CORBA– LC is a lightweight distributed reflective component model based on CORBA. Instead of using a traditional client/server model, it imposes a peer net work model in which the whole network act as a repository for managing and assigning the whole set of resources: components, CPU cycles, memory, etc. Thus, application deployment is automatically and adaptively performed at run-time. Requirements for component description, packag ing, deployment, reflection, logical network cohesion, dis tributed resource queries and fault-tolerant protocols ar e identified. Finally, we show the validity of the identified requirements in dealing with CSCW and Grid Computing applications and show how current component models fail on addressing some of these requirements.	central processing unit;client–server model;common object request broker architecture;component-based software engineering;computer-supported cooperative work;distributed computing;fault tolerance;grid computing;lc circuit;limbo;load balancing (computing);programmer;requirement;sms language;server (computing);software deployment	Diego Sevilla Ruiz;José M. García;Antonio F. Gómez-Skarmeta	2001		10.1109/ICPPW.2001.951952	communications protocol;fault tolerance;parallel computing;real-time computing;computer science;operating system;network model;computer-supported cooperative work;common object request broker architecture;component object model;database;distributed computing;client–server model;grid computing;computer network	SE	-33.03911186594692	45.93515015199834	173905
f12a4d9d9cede498a00686d52475d0bfa044ed3e	a formal model of atomicity in asynchronous systems	professor brian randell;asynchronous system;eprints newcastle university;model error;open access;professor eike best;model of computation	We propose a generalisation of occurrence graphs as a formal model of computational structure. The model is used to define the “atomic occurrence” of a program, to characterise “interference freeness” between programs, and to model error recovery in a decentralised system.	asynchronous system;atomicity (database systems);computation;decentralised system;formal language;interference (communication)	Eike Best;Brian Randell	1981	Acta Informatica	10.1007/BF00289593	model of computation;asynchronous system;computer science;artificial intelligence;errors-in-variables models;mathematics;algorithm	SE	-25.09014844860674	32.97593757176126	173982
673a3ec4027f604b52afe1b8c106529e89eb2e11	fault detection in multi-threaded c++ server applications	static dynamic co analysis;debugging;runtime analysis;race condition;multi threaded programming;race conditions;object oriented programming;synchronization;data races;fault detection;parallel programs	This paper describes experiments with the freely available tool Helgrind, results obtained by using it for debugging a server application comprising 500 kLOC. We present improvements to the run time analysis of C++ programs that result in a dramatic reduction of false warnings.	c++;debugging;experiment;run time (program lifecycle phase);server (computing);thread (computing)	Arndt Mühlenfeld;Franz Wotawa	2007		10.1145/1229428.1229457	parallel computing;real-time computing;computer science;operating system;distributed computing;race condition;programming language	SE	-21.09450972290794	37.99916407149713	174030
596cc6e9eeca98bce6efe600548ce57432a0525a	functional units for natural numbers	thread algebra;service provider;programming language;universiteitsbibliotheek;execution environment;state space;logic in computer science;functional unit	Interaction with services provided by an execution environment forms part of the behaviours exhibited by instruction sequences under execution. Mechanisms related to the kind of interaction in question have been proposed in the setting of thread algebra. Like thread, service is an abstract behavioural concept. The concept of a functional unit is similar to the concept of a service, but more concrete. A state space is inherent in the concept of a functional unit, whereas it is not inherent in the concept of a service. In this paper, we establish the existence of a universal computable functional unit for natural numbers and related results.	computable function;execution unit;state space	Jan A. Bergstra;Kees Middelburg	2009	CoRR		service provider;computer science;state space;theoretical computer science;distributed computing;programming language	SE	-28.868349262071973	32.94846713715333	174076
ab8939bb3d2395c1cb45162e7fb13773a4ff7761	towards meta-level engineering and tooling for complex concurrent systems		With the widespread use of multicore processors, software becomes more and more diverse in its use of parallel computing resources. To address all application requirements, each with the appropriate abstraction, developers mix and match various concurrency abstractions made available to them via libraries and frameworks. Unfortunately, today’s tools such as debuggers and profilers do not support the diversity of these abstractions. Instead of enabling developers to reason about the high-level programming concepts, they used to express their programs, the tools work only on the library’s implementation level. While this is a common problem also for other libraries and frameworks, the complexity of concurrency exacerbates the issue further, and reasoning on the higher levels of the concurrency abstractions is essential to manage the associated complexity. In this position paper, we identify open research issues and propose to build tools based on a common meta-level interface to enable developers to reasons about their programs based on the high-level concepts they used to implement them.	central processing unit;concurrency (computer science);debugger;high- and low-level;high-level programming language;library (computing);multi-core processor;open research;parallel computing;profiling (computer programming);requirement	Stefan Marr;Elisa Gonzalez Boix;Hanspeter Mössenböck	2016			real-time computing;computer science;systems engineering;computer engineering	SE	-23.293152276905477	38.46604727303626	174113
2a6e0f70fd810c69bbcd826290f46692e7dea00b	enforcing memory safety for sensor node programs	wireless sensor networks c language operating systems computers storage management telecommunication computing;memory safety;storage management;telecommunication computing;control flow verification;c language;sensor networks;control flow verification sensor networks memory safety stack protection;stack protection;operating system memory memory safety sensor node programs mmu user program errors robust programs memory safety schemes c programming language;safety kernel assembly random access memory dynamic scheduling registers;operating systems computers;wireless sensor networks	Sensor nodes are generally resource-constrained and MMUs are not present on sensor nodes. Without MMU, operating system is volatile to user program errors. so it is notoriously difficult to write robust programs. In this paper, we present memory safety schemes for sensor programs written in C programming language to isolate user program memory from operating system memory. Our memory safety schemes have shown a number of superiorities over other existing safety schemes for sensor nodes. Evaluations show the overhead of our memory safety schemes and the performance of memory safety is compared with other safety schemes.	memory management unit;memory safety;operating system;overhead (computing);programming language;read-only memory;sensor node	Nan Lin;Yabo Dong;Dongming Lu;Jie He	2012	2012 IEEE 12th International Conference on Computer and Information Technology	10.1109/CIT.2012.78	memory address;uniform memory access;distributed shared memory;shared memory;embedded system;semiconductor memory;parallel computing;real-time computing;memory management;wireless sensor network;memory refresh;computer science;physical address;virtual memory;operating system;memory protection;database;overlay;key distribution in wireless sensor networks;conventional memory;extended memory;flat memory model;registered memory;computer security;computer network;memory management	Embedded	-22.87907636699662	40.15562326336346	174136
51573be8f0ffb24de7d44ef8515dd2f4c02ac9cf	towards a smart compilation manager for java	compilacion;systeme intelligent;image processing;speech processing;sistema inteligente;tratamiento palabra;procesamiento imagen;traitement parole;langage java;traitement image;programa puesta a punto;defaillance;intelligent system;pattern recognition;compilation;lenguaje java;reconnaissance forme;failures;reconocimiento patron;fallo;programme debogage;debugging program;java language	It is often infeasible to recompile all the sources an application consists of each time a change is made. Yet, a recompilation strategy which does not guarantee the same outcome of an entire recompilation is not useful: why wasting time in debugging a program (a set of .class files in the Java case) which might behave differently from the program obtained recompiling all the sources from scratch? We say that a compilation strategy is sound if it recompiles, besides the changed sources, all the unchanged sources whose new binary, produced by the overall recompilation, would differ from the existing one (if any) and all the sources for which the recompilation would be undefined: indeed, when the entire compilation fails, so should do the partial	compiler;debugging;java;undefined behavior	Giovanni Lagorio	2003		10.1007/978-3-540-45208-9_24	real-time computing;image processing;computer science;operating system;speech processing;database;programming language;algorithm	PL	-20.63741796427166	35.39279058037272	174191
18a2ae4c239a8b959610ded8d5ed34631a787540	building on quicksand	cluster computing;fault tolerant;error correction code	Reliable systems have always been built out of unreliable components. Early on, the reliable components were small such as mirrored disks or ECC (Error Correcting Codes) in core memory. These systems were designed such that failures of these small components were transparent to the application. Later, the size of the unreliable components grew larger and semantic challenges crept into the application when failures occurred. As the granularity of the unreliable component grows, the latency to communicate with a backup becomes unpalatable. This leads to a more relaxed model for fault tolerance. The primary system will acknowledge the work request and its actions without waiting to ensure that the backup is notified of the work. This improves the responsiveness of the system. There are two implications of asynchronous state capture: 1) Everything promised by the primary is probabilistic. There is always a chance that an untimely failure shortly after the promise results in a backup proceeding without knowledge of the commitment. Hence, We gratefully acknowledge support from the Simons Foundation and member institutions	backup;ecc memory;fault tolerance;keneth alden simons;magnetic-core memory;responsiveness	Pat Helland;David Campbell	2009	CoRR		fault tolerance;parallel computing;real-time computing;error detection and correction;computer cluster;computer science;operating system;distributed computing;computer security;algorithm	OS	-22.00964851495375	45.12288844281364	174443
aeb641bc27792ee5dfd0fa22f7ccebad5f3a1ed5	a compilation technique to increase x3d performance and safety	performance;virtual reality;object oriented;safety;x3d;compilation;virtual worlds	As virtual worlds grow more and more complex, virtual reality browsers and engines face growing challenges. These challenges are centered on performance on one hand (an interactive framerate is always required) and complexity on the other hand (the larger and more articulated a virtual world, the more immersive the experience).  The usual implementation of an engine or browser for running virtual worlds features an object-oriented architecture of classes. This architecture is a source of often underestimated overhead in terms of dynamic dispatching, and dynamic lookups by scripts when they try to access portions of the scene are both costly and possible sources of mistakes.  In this paper we discuss how we have tackled the problem of increasing performance in X3D browsers while also making scripts safe. We have used a compilation technique that removes some overhead and which allows us to introduce safety for scripts that access the state	benchmark (computing);code generation (compiler);compile time;compiler;dynamic dispatch;java;javascript;microsoft windows;microsoft xna;mobile device;overhead (computing);type safety;virtual reality;virtual world;windows phone;x3d;xbox 360	Giuseppe Maggiore;Fabio Pittarello;Michele Bugliesi;Mohamed Abbadi	2012		10.1145/2245276.2245465	simulation;performance;computer science;operating system;database;virtual reality;multimedia;x3d;programming language;object-oriented programming;world wide web	PL	-21.385211832216598	37.004132537405155	174522
d43552963ebf7f43acf42e23fedfc889de40c0f2	an analysis of replication strategies for x.500-like distributed directories	distributed databases;protocols;redundancy;x.500;distributed directories;replication strategies	The X.500 standard for distributed directories is now in its second cycle of definition and is close to completion. There is, however, much work remaining regarding issues of replication. The success of the standard is predicated on a workable replication strategy. The authors look at replication algorithms in the context of X.500-like distributed directories, report on the performance of some, and include an assessment and recommendations for the future. u003e		J. Michael Bennett;Michael Anthony Bauer	1990			computer science;database;distributed computing;world wide web	Robotics	-27.567915727897873	39.31528133350471	174555
2ce05d6065c0cf18f7c8f8db18990efdaa1863a8	a useful system prototype for intrusion detection - architecture and experiments	intruder detector;multiagent system;architecture systeme;distributed agents;securite informatique;structure sandwich;intrusion detection;system performance;computer security;systeme linux;sandwich structure;sistema linux;seguridad informatica;intrusion detection systems;arquitectura sistema;analyse information;estructura sandwich;detecteur intrus;detection intrus reparti base agent independant iadidf system;system architecture;sistema multiagente;linux system;detector intruso;information analysis;systeme detection intrusion;intrusion detection system;systeme multiagent	With the ever increasing sophistication of attacking techniques, intrusion detection has been a very active field of research. We are designing and implementing a prototype intrusion detection system (IADIDF) that is composed of distributed agents. This paper describes the function of entities, defines the communication and alert mechanism. There are three main agents include Detectors, Managers and Communicators. Each agent operates cooperatively yet independently of the others, providing for efficiency alerts and distribution of resources. Communication mechanism is composed of three layers, which are Transport, Hosts and MessageContent layers. All entities of the prototype are developed in C program under Linux platform. Then, we analyze system performance, advantages of the prototype, and come to a conclusion that the operating of agents will not impact system heavily.	intrusion detection system;prototype	Ye Du;Huiqiang Wang;Yonggang Pang	2004		10.1007/978-3-540-30214-8_35	intrusion detection system;embedded system;host-based intrusion detection system;simulation;computer science;computer performance;computer security;systems architecture	Security	-27.302415227662145	40.91609831835067	174600
2cb1ee5ed66933a9875c2fcc73500ecfbfac32f5	state space reconfigurability: an implementation architecture for self modifying finite automata	design flow;reconfigurability;state machine;adaptive behavior;embedded system;reconfigurable architecture;logic synthesis;fsm;smfa;state space;finite automata;model development;classical logic;design theory;modeling methodology;architecture	Many embedded systems exhibit temporally and behaviorally disjoint behavior slices. When such behaviors are captured by state machines, the current design flow will capture it as a union of all the behavior slices, and map it using traditional state assignment followed by logic synthesis. Such implementations costs are proportional to the union of all the behavior slices (in area, energy and delay). We propose to use self-modifying finite automata (SMFA), that have been studied from complexity-theoretic perspective, for expressing and implementing such adaptive behaviors in embedded systems. Towards this end, we present an implementation architecture for SMFAs. We compare the area, time and energy costs of SMFA implementations with the classical logic space (FSM) implementations for four adaptive behaviors.	application-specific integrated circuit;automata theory;automaton;embedded system;field-programmable gate array;finite-state machine;logic synthesis;lookup table;reconfigurability;specification language;state space;temporal logic	Ka-Ming Keung;Akhilesh Tyagi	2006		10.1145/1176760.1176772	embedded system;classical logic;parallel computing;logic synthesis;real-time computing;computer science;state space;design flow;theoretical computer science;architecture;adaptive behavior;finite-state machine	EDA	-32.6099781916961	33.0757543667222	175048
d1157a902730c68d0ceefb6ba03a7a5069ab0d9c	an inproved method for constructing multiphase communications protocols	machine abstraite;protocols;chaotic communication;metodologia;reseau transmission donnee;protocole transmission;metodo descomposicion;working environment noise;maquina abstracta;chainage donnee;methode decomposition;reliable transport;protocol design;conception;multiphase communications protocols;indexing terms;buildings transport protocols chaotic communication joining processes communication system control safety process design design methodology working environment noise;methodologie;safety properties;abstract machine;process design;transport protocols;decomposition method;protocolo transmision;data transmission network;message corruption multiphase communications protocols noiseless environment reliable transport;safety;data link;red transmision datos;diseno;joining processes;communication protocol;design;validation;message corruption;methodology;communication system control;communicating finite state machine;noiseless environment;buildings;design methodology;transmission protocol;ligazon datos	Research has shown that many communications protocols exhibit multiple phases of behavior, performing a distinct function in each phase. A systematic method has been proposed by Chow, Gouda, and Lam for building multiphase protocols. By connecting several simpler protocols modeling the specific phases in a disciplined way, the newly constructed multiphase protocol enjoys the same correctness properties as the individual phases. The inherent modularity of the resultant protocol makes it easier to understand and analyze. However, the applicability of the existing method is subject to two rather stringent restrictions: the inability to handle message corruption or loss during phase transitions, and a rigid requirement on the selection of the points that connect different phases. This paper describes an improved method that either relaxes or eliminates the above restrictions. The construction of the Normal Response Mode of HDLC (Highlevel Data-Link Control) is presented to illustrate the use of this new method.	communications protocol;correctness (computer science);lam/mpi;resultant;synchronous data link control	Huai-An Lin;Chao-Li Tarng	1993	IEEE Trans. Computers	10.1109/12.192210	embedded system;communications protocol;parallel computing;simulation;telecommunications;computer science;electrical engineering;operating system;distributed computing;abstract machine;algorithm;computer network	Networks	-27.943775036496046	40.82765947648206	175104
89274cfa6f4a93a5fcfb96e76a489cef76855d56	run-time dynamic linking for reprogramming wireless sensor networks	virtual machine;resource constraint;java virtual machine;dynamic linking;sensor network;embedded system;wireless sensor network;embedded systems;engineering and technology;teknik och teknologier;operating system;virtual machines;energy consumption;sensor nodes;energy cost;wireless sensor networks;heterogeneous network;operating systems	From experience with wireless sensor networks it has become apparent that dynamic reprogramming of the sensor nodes is a useful feature. The resource constraints in terms of energy, memory, and processing power make sensor network reprogramming a challenging task. Many different mechanisms for reprogramming sensor nodes have been developed ranging from full image replacement to virtual machines.We have implemented an in-situ run-time dynamic linker and loader that use the standard ELF object file format. We show that run-time dynamic linking is an effective method for reprogramming even resource constrained wireless sensor nodes. To evaluate our dynamic linking mechanism we have implemented an application-specific virtual machine and a Java virtual machine and compare the energy cost of the different linking and execution models. We measure the energy consumption and execution time overhead on real hardware to quantify the energy costs for dynamic linkin.Our results suggest that while in general the overhead of a virtual machine is high, a combination of native code and virtual machine code provide good energy efficiency. Dynamic run-time linking can be used to update the native code, even in heterogeneous networks.	dynamic linker;effective method;java virtual machine;loader (computing);machine code;object file;overhead (computing);run time (program lifecycle phase);semantic network;sensor	Adam Dunkels;Niclas Finne;Joakim Eriksson;Thiemo Voigt	2006		10.1145/1182807.1182810	embedded system;real-time computing;wireless sensor network;computer science;distributed computing;key distribution in wireless sensor networks	Embedded	-23.19518543561568	39.5882389612427	175338
440829166a5eecaa2964b626c5ff5553a8d1c59b	design constraints in the construction of a truly distributed operating system (abstract only)	error recovery;interprocess communication;syntax;loosely coupled system;user interface;high speed networks;lr 1;resource manager;distributed computing;semantics;portability;compilers;distributed operating system;grammars;operating system;error correction;parsar generators	Distributed computing will be viewed from three levels. First, from possible hardware configurations, where emphasis will be placed on loosely coupled systems interconnected with High Speed Networks (HSN). Second, from the Operating System (OS) level where five fundamental additions to existing uniprocessor OSs are required. They include the creation of a message-based interprocess communication facility, a communication manager, an extended file manager, a resource manager, and an extended user interface. The third and final view of truly distributed OSs will be from the applications level. How the user views the logical system, and automatic versus manual control of computational granularity will be discussed.	computation;distributed computing;distributed operating system;formal system;inter-process communication;loose coupling;message passing;uniprocessor system;user interface	P. Tobin Maginnis	1985		10.1145/320599.322557	compiler;parallel computing;real-time computing;error detection and correction;syntax;computer science;operating system;software engineering;database;distributed computing;semantics;programming language;user interface;inter-process communication	OS	-26.16594747097245	36.94178934065538	175478
9d03c6fd8447989af0cfc438c799d9ad2b7ed99f	memory debugging in parallel and distributed applications		Memory bugs, essentially a mistake in the management of heap memory, can occur in any program that is being written, enhanced, or maintained. A memory bug can be caused by a number of factors, including failure to check for error conditions; relying on nonstandard behavior; memory leaks including failure to free memory; dangling references such as failure to clear pointers; array bounds violations; and memory corruption such as writing to memory not owned/over running array bounds. These can sometimes cause programs to crash or generate incorrect “random” results, or more frustratingly, they may lurk in the code base for long periods of time — only to manifest themselves at the worst possible time. Memory problems are difficult to track down with conventional tools on even a simple desktop architecture, and are much more vexing then encountered on a distributed parallel architecture. This paper will review the challenges of memory debugging, with special attention paid to the challenges of parallel development and debugging, introduce a tool that helps developers identify and resolve memory bugs in parallel and distributed applications, highlight its major features and provide usage tips. Published: June 2008 Highlights: Challenges with memory debugging Identifying and resolving memory bugs in parallel and distributed applications Using the Heap Interposition Agent (HIA) to analyze memory problems The Challenges of Memory Debugging in Parallel Development The fact that memory bugs can be introduced at any time makes memory debugging a challenging task especially in codes that are written collaboratively or that are being maintained over a long period of time, where assumptions about memory management can either change or not be communicated clearly. They can also lurk in a code base for long periods of time since they are often not immediately fatal and can suddenly become an issue when a program is ported to a new architecture or scaled up to a larger problem size, or when code is adapted and reused from one program to another. Memory bugs often manifest themselves in several ways: either as a crash that always happens, a crash that sometimes happens (instability), or just as incorrect results. Furthermore, they are difficult to track down with commonly used development tools and techniques (such as printf and traditional source code debuggers), which are not specifically designed to solve memory problems. Adding parallelism to the mix makes things even harder because parallel programs are often squeezed between two effects, meaning that these programs have to be very careful with memory. Parallel programs are also written in situations where the problem set is “large,” so the program naturally ends up loading a very significant amount of data and using a lot of memory. However, special purpose highperformance computing (HPC) systems often have less memory per node than one might ideally desire, as memory is expensive. Classifying Memory Errors Programs typically make use of several different categories of memory that are managed in different ways. These include stack memory, heap memory, shared memory, thread private memory and static or global memory. However, programmers are required to pay special attention to memory that is allocated out of the heap memory. This is because the management of heap memory is done explicitly in the program rather than implicitly at compile or run time. There are a number of ways that a program can fail to make proper use of dynamically allocated heap memory. It is useful to develop a simple categorization of these mistakes for discussion; in this paper, they will be described in terms of the C malloc() API. However, it is important to note that analogous errors can also be made with memory that is allocated using the C++ new statement and the FORTRAN 90 allocate statement. Malloc Errors Malloc errors occur when a program passes an invalid value to one of the operations in the C Heap Manager API. This could potentially happen if the value of a pointer (the address of a block) is copied into another pointer, and then at a later time, both pointers are passed to free(). In this case, the second free() is incorrect because the specified pointer does not correspond to an allocated block. The behavior of the program after such an operation is undefined. Dangling Pointers A pointer can be said to be dangling when it references memory that has already been deallocated. Any memory access (either a read or a write) through a dangling pointer can lead to undefined behavior. Programs with dangling pointer bugs may sometimes appear to function without any obvious errors — even for significant amounts of time — if the memory that the dangling pointer points to happens not to be recycled into a new allocation during the time that it is accessed. Memory Bounds Violations Individual memory allocations that are returned by malloc() represent discrete blocks of memory with defined sizes. Any access to memory immediately before the lowest address in the block or immediately after the highest address in the block results in undefined behavior. Read-Before-Write Errors Reading memory before it has been initialized is a common error. Some languages assign default values to uninitialized global memory, and many compilers can identify when local variables are read before being initialized. What is more difficult and generally can only be done at random is detecting when memory accessed through a pointer is read before being initialized. Dynamic memory is particularly affected, since this is always accessed through a pointer, and in most cases, the content of memory obtained from the memory manager is undefined. Detecting Memory Leaks Leaks occur when a program finishes using a block of memory and discards all references to the block, but fails to call free() to release it back to the heap manager for reuse. The result is that the program is neither able to make use of the memory nor reallocate it for a new purpose. The impact of leaks depends on the nature of the application. In some cases the effects are very minor; in others, where the rate of leakage is high enough or the runtime of the program is long enough, leaks can significantly change the memory behavior and the performance characteristics of the program. For longrunning applications or those where memory is limited, even a small leakage rate can have a very serious cumulative and adverse effect. This somewhat paradoxically takes leaks all that much more annoying, since they often linger in otherwise well-understood codes. It can be quite challenging to manage dynamic memory in complex applications to ensure that allocations are released exactly once so that malloc and leak errors do not occur. Leak detection can be done at any point in program execution. As discussed, leaks occur when the program ceases using a block of memory without calling free. It is hard to define “ceasing to use” but an advanced memory debugger is able to execute leak detection by looking to see if the program retains a reference to specific memory locations. The MemoryScape Debugger The MemoryScape memory debugger is an easy-to-use tool for developers. It has a lightweight architecture that requires no recompilation and has modest impact on the runtime performance of the program. The interface is designed around the concept of an inductive user interface, which guides the user through the task of memory debugging and provides easy-to-understand graphical displays, powerful analysis tools, and features to support collaboration (making it easy to report a lurking memory bug to the library vendor, scientific collaborator, or colleague who wrote the code in question). MemoryScape is designed to be used with parallel and multi-process target applications, providing both detailed information about individual processes, as well as high level memory usage statistics across all of the processes that make up a large parallel application. MemoryScape’s specialized features, including support for launching and automatically attaching to all of the processes of a parallel job, the ability to memory debug many processes from within one GUI, and the ability to do script-based debugging to use batch queue environments, make it wellsuited for debugging these parallel and distributed applications. MemoryScape Architecture MemoryScape accomplishes memory debugging on parallel and distributed applications through the modified use of a technique called interposition. MemoryScape provides a library, called the Heap Interposition Agent (HIA), that is inserted between the user’s application code and the malloc() subsystem. This library defines functions for each of the memory allocation API functions. It is these functions that are initially called by the program whenever it allocates, reallocates, or frees a block of memory. Figure.1 MemoryScape Heap Interposition Agent (HIA) Architecture. The HIA sits between the application and the memory allocation layer in glibc. The interposition technique used by MemoryScape was chosen in part because it provides for lightweight memory debugging. Low overheads are an important factor if the performance of a program is not to suffer because of the presence of the HIA. In most cases, the runtime performance of a program being debugged with the HIA engaged will be similar to that where the HIA is absent. This is absolutely critical for high-performance computing applications, where a heavyweight approach that significantly slowed the target program might very well make the runtime of programs exceed the patience of developers, administrators and job schedulers. Interposition differs from simply replacing the malloc() library with a debug malloc in that the interposition library does not actually fulfill any of the operations itself — it arranges for the program’s malloc() API function calls to be forwarded to the underlying heap manager that would hav	analysis of algorithms;application programming interface;c dynamic memory allocation;c++;categorization;code;compiler;crash (computing);dangling pointer;debugging;desktop computer;distributed computing;fortran;gnu c library;graphical user interface;high-level programming language;infographic;instability;job queue;local variable;lurker;memory corruption;memory debugger;memory leak;memory management;parallel computing;printf format string;programmer;programming tool;run time (program lifecycle phase);sensor;shared memory;software bug;spectral leakage;subject matter expert turing test;supercomputer;undefined behavior	Chris Gottbrath	2008		10.1007/978-3-540-68564-7_6	uniform memory access;computer architecture;parallel computing;distributed memory;flash memory emulator;programming language;background debug mode interface;debugging	PL	-19.4126823089922	37.84580408080772	175546
e73f0a1b6e19ac2c0f0ee4a3fddfd528ec744721	performance evaluation of a self-maintained memory module	control application;nondeterministic behavior;virtual execution platform;control system analysis computing;real time;aires toolkit virtual execution platform accurate analysis distributed real time control system development abstract run time model nondeterministic behavior;real time systems distributed control control systems application software runtime automatic control control system synthesis automatic generation control hardware operating systems;data exchange;real time operating system;automatic generation;accurate analysis;distributed real time control system development;aires toolkit;abstract run time model;software component;real time control system;real time systems control system analysis computing distributed control operating systems computers;distributed control;operating systems computers;real time systems	Hardware approach emerges as one of the candidate in improving the performance of dynamic memory management. This paper presents measurements of a self-maintained memory module subjected to several different workloads. This memory module supporting explicit dynamic memory management takes advantage of the high speed of a pure hardware implementation. Object allocation and deletion are strictly bounded in time. The whole heap space is divided into two semi-spaces, and a concurrent bidirectional memory compaction algorithm is exploited, so that memory compaction can be done while mutator process is running on the processor concurrently. Reported measurements demonstrate that hardware-assisted memory management is a viable alternative to traditional explicit memory management techniques. Experimental results show that more than 60% of memory traffic is saved by the proposed memory compaction scheme compared to software-only approach. Both processor delay and program execution time are greatly reduced.	algorithm;data compaction;garbage collection (computer science);memory management;memory module;mutator method;performance evaluation;run time (program lifecycle phase);semiconductor industry	Weixing Ji;Feng Shi;Baojun Qiao;Qi Zuo;Caixia Liu	2007	28th IEEE International Real-Time Systems Symposium (RTSS 2007)	10.1109/RTSS.2007.30	data exchange;embedded system;real-time computing;real-time operating system;real-time control system;computer science;component-based software engineering;operating system;open platform	Embedded	-23.024067715351038	37.5856977336091	175743
433074120bf30891efbeeb91e384b42d3f8656de	running large vr applications on a pc cluster: the flowvr experience	collective communication;real time;distributed interactive applications;imperceptible projection blanking;segmentation;software engineering;gestural interfaces;networked collaboration;pc cluster;middleware;mixed and augmented reality;data flow;high performance	In this paper, we present how FlowVR enables the development of modular and high performance VR applications running on a PC cluster. FlowVR is a middleware we specifically developed targeting distributed interactive applications. The goal of the FlowVR design is to favor the application modularity in an attempt to alleviate software engineering issues while taking advantage of this modularity to enable efficient executions on PC clusters. FlowVR relies on an extended data flow model that enables to implement complex message handling functions like collective communications, or bounding box based routing. After a short presentation of FlowVR, we describe a representative application that takes benefit of FlowVR to reach a real time performance running on a PC Cluster.	application programming interface;code;computation;computer cluster;data flow diagram;dataflow;eurographics;input/output;library (computing);middleware;minimum bounding box;movie projector;parallel rendering;public library;quicktime vr;routing;simulation;software engineering	Jérémie Allard;Clément Ménier;Edmond Boyer;Bruno Raffin	2005		10.2312/EGVE/IPT_EGVE2005/059-068	embedded system;real-time computing;simulation;computer science	OS	-29.91444304198581	40.03541424732538	175775
58211bc262d9f9e00a9dcf840a4ebca8c753cfd3	design and implementation of a speech server for unix based multimedia applications		In this paper we describe a general purpose speech recognition server (SRS) that provides a standard interface between applications and speech recognition modules. The recognition modules cover diierent techniques such as speaker dependent or independent, isolated or connected word recognition. The SRS is designed mainly for multi-media applications running on a network of UNIX workstations. Our concept uses multiple processes for the different tasks and UNIX interprocess communication techniques .	emoticon;extensibility;inter-process communication;microsoft speech server;server (computing);speech recognition;unix;workstation	Stefan Euler;K. Riedel	1993			computer architecture;operating system;unix;unix architecture;computer science	OS	-28.958476138360563	40.010771319865746	176003
046928da32b34a086f971755dd33efb2f2017eda	mlblm: a multi-level load balancing mechanism in agent-based grid	distributed application;distributed system;multiagent system;haute performance;systeme reparti;computational grid;agent based;equilibrio de carga;logicial personalizado;equilibrage charge;distributed computing;grid middleware;intelligence artificielle;satisfiability;intergiciel;grid;sistema repartido;rejilla;algorithme reparti;load balancing;alto rendimiento;grille;calculo repartido;artificial intelligence;middleware;algoritmo repartido;load balance;inteligencia artificial;sistema multiagente;distributed algorithm;high performance;calcul reparti;systeme multiagent	A computational grid is a widespread computing environment that provides huge computational power for large-scale distributed applications. Load balancing, has a considerable effect on the grid middleware performance. Current load balancing methods cannot satisfy all necessities for the grid. In this paper, a Multi-level Load Balancing Method (MLBM) is proposed. Cooperation among different levels in this method, removes disadvantages of each level, while satisfy most of load balancing requirements needed. Simulation results indicate that this new mechanism surpasses its predecessors in increasing efficiency and decreasing communication overhead.	distributed computing;electronic billing;grid computing;layer (electronics);load balancing (computing);middleware;overhead (computing);requirement;scheduling (computing);simulation	Mohsen Amini Salehi;Hossein Deldari;Bahare Mokarram Dorri	2006		10.1007/11947950_18	embedded system;distributed algorithm;network load balancing services;real-time computing;load balancing;computer science;load balancing;distributed computing	HPC	-28.69529677588703	44.25214368783894	176492
0636eb1f6dc6a2e18f56bfc4ff5e06631a3af722	deriving a protocol converter: a top-down method	example conversion problem;top-down method;finite-state specification;different protocol;layered network architecture;useful interaction;protocol converter;network architecture;top down	A protocol converter mediates the communication between implementations of different protocols, enabling them to achieve some form of useful interaction. The problem of deriving a protocol converter from specifications of the protocols and a desired service can be viewed as the problem of finding the “quotient” of two specifications. We define a class of finite-state specifications and present an algorithm for solving “quotient” problems for the class. The algorithm is applied to an example conversion problem. We also discuss its application in the context of layered network architectures.	acm transactions on programming languages and systems;algorithm;calculus of communicating systems;communicating sequential processes;communications of the acm;communications protocol;connection-oriented communication;correctness (computer science);duplex (telecommunications);equation solving;gateway (telecommunications);hoare logic;ieee transactions on software engineering;lam/mpi;language of temporal ordering specification;lecture notes in computer science;protocol converter;simon s. lam;throughput	Kenneth L. Calvert;Simon S. Lam	1989		10.1145/75246.75271	real-time computing;network architecture;computer science;theoretical computer science;top-down and bottom-up design;distributed computing;computer network	Networks	-30.978493949064134	32.71422061346589	176656
bd34f5e62cb313f33dff3bad6bb0e96394198361	a knowledge theoretic analysis of atomic commitment protocols	atomic commit protocols;theoretical analysis	"""1 INTRODUCTION Recently a new theory of dlsmbuted computing has been proposed , accordmg to which a dlsmbuted computation 1s vIewed as an activity of knowledge acqulsmon and chssemmatlon by commumcatmg processes (Halpem and Moses [ 19861, Halpem and Fagm [1985]) In addmon to supplymg a formal log& foundation for &smbuted computmg which directly supports the informal way m which dlsmbuted algonthms are often described and thought about, this """" knowledge theory """" has afforded relatively simple proofs of interesting results for specific problems (e g Chandy and msra [1986], Dwork and Moses [1986], Moses and Tuttle [1986]) In this paper, we use the knowledge formahsm to analyse atormc comrmtment protocols employed by transactions m chs-mbuted database systems, such as two-phase comnut We charactense the two-phase comnut and three-phase conumt famlhes of protocols in terms of the level of knowledge that must be acquved by a site to commit a tramactlon We show that m the two-phase comnut protocol the declslon to comnnt is reached with the nunlmum knowledge necessary under any atomic comnntment protocol, and that m the three-phase commit protocol the decision to comnut is reached with the mmlmum knowledge necessary under any non-blocking atomic comnutment protocol Our analysis also provides a proof of the fact that there 1s no non-blockmg atonuc comnutment protocol that can tolerate commumcatlon filures (a result anticipated m the work of Gray-cf hn """" Generals' Parddox """" [1978]-and formally proved by Skeen [ 19821 for a model of computation less general than the one used here) Fmally, usmg knowledge theory, we denve a lower bound for the number of messages needed to comrmt a transachon (a previously known result, due to Dwork and Skeen [1983]) This lower bound 1s"""	blocking (computing);classical limit;cynthia dwork;database;model of computation;moses;non-blocking algorithm;theory;three-phase commit protocol;two-phase locking	Vassos Hadzilacos	1987		10.1145/28659.28672	computer science	DB	-22.266636353641278	44.338489520100204	176794
12e2db1e82a84cff97e8dbf11619d135b340b49c	paricheck: an efficient pointer arithmetic checker for c programs	production system;buffer overflows;performance bounds;bounds checking	Buffer overflows are still a significant problem in programs written in C and C++. In this paper we present a bounds checker, called PAriCheck, that inserts dynamic runtime checks to ensure that attackers are not able to abuse buffer overflow vulnerabilities. The main approach is based on checking pointer arithmetic rather than pointer dereferences when performing bounds checks. The checks are performed by assigning a unique label to each object and ensuring that the label is associated with each memory location that the object inhabits. Whenever pointer arithmetic occurs, the label of the base location is compared to the label of the resulting arithmetic. If the labels differ, an out-of-bounds calculation has occurred. Benchmarks show that PAriCheck has a very low performance overhead compared to similar bounds checkers. This paper demonstrates that using bounds checkers for programs or parts of programs running on high-security production systems is a realistic possibility.	bounds checking;buffer overflow;c++;memory address;overhead (computing);pointer (computer programming)	Yves Younan;Pieter Philippaerts;Lorenzo Cavallaro;R. Sekar;Frank Piessens;Wouter Joosen	2010		10.1145/1755688.1755707	real-time computing;buffer overflow;computer science;bounds checking;distributed computing;production system;computer security;algorithm;smart pointer	SE	-21.143568703007094	38.5951868117875	176893
198cf6cbd00370d19a893baf653499cd229cdc35	replica determinism in distributed real-time systems: a brief survey	distributed system;fault tolerant;real time;distributed real time system	Replication of entities is a convenient technique to achieve fault-tolerance. The problem of replica determinism thereby is to assure, that replicated entities show consistent behavior in the absence of failures. Possible sources for replica non-determinism as well as basic requirements and strategies to enforce replica determinism are presented. The problem of replica determinism enforcement under real-time constraints is surveyed in the context of the communication problem for distributed systems. Furthermore the close interdependence between replica determinism on the one side and synchronization strategies, handling of failures and redundancy preservation on the other side is reviewed. The impact of synchronous or asynchronous approaches on replication strategies is also discussed.	distributed computing;entity;fault tolerance;interdependence;nondeterministic algorithm;real-time computing;real-time transcription;requirement	Stefan Poledna	1994	Real-Time Systems	10.1007/BF01088629	fault tolerance;real-time computing;computer science;theoretical computer science;distributed computing	Embedded	-23.571620761826164	45.309144056834235	177153
646f110a7f553791506cee5a3a0f65efe12bec6d	specification, implementation and testing of hfsms in dynamically reconfigurable fpgas	field programmable gate array;software tool;control algorithm;architecture systeme;formal specification;dynamic reconfiguration;top down;reconfigurable architectures;maquina estado finito;sistema informatico;computer system;red puerta programable;reseau porte programmable;specification formelle;input output;especificacion formal;arquitectura sistema;systeme informatique;system architecture;machine etat fini;architecture reconfigurable;finite state machine	This paper discusses methods and software tools that we have developed for the specification, verification, implementation and debugging of control circuits. The specification method that we have adopted is based on the use of Hierarchical Graph-Schemes. The circuit implementation model is a Hierarchical Finite State Machine, which supports the top-down decomposition of the control algorithms. The application input/output interface provides links with other external tools that perform synthesis and implementation tasks. Some of the utilities we have developed, such as the random control algorithm generator, allow many useful supplementary tasks to be handled and provide powerful assistance for experiments. In particular, the tools have been used to implement Hierarchical Finite State Machines in the Xilinx XC6200 dynamically reconfigurable FPGAs.	algorithm;comparison of command shells;debugging;dynamic-link library;experiment;field-programmable gate array;finite-state machine;input/output;reconfigurability;reconfigurable computing;top-down and bottom-up design	Arnaldo S. R. Oliveira;Andreia Melo;Valery Sklyarov	1999		10.1007/978-3-540-48302-1_32	input/output;embedded system;computer architecture;real-time computing;computer science;operating system;top-down and bottom-up design;formal specification;finite-state machine;programming language;field-programmable gate array;systems architecture	EDA	-30.253253911376486	35.89165472805104	177285
2ba68d98df08f8f1f2ba026b876e8c3bb9fa6915	compiler optimizations for java aglets in distributed data intensive applications	distributed data;distributed database;mobile agents;digital signatures;data distribution;cryptography;high performance fortran;compiler optimization;mobile code;evaluation;optimization;technical report;security;java aglets	Code migration in light of distributed data intensive computing poses interesting compilation issues. In this work, we first define a small extension to the aglet model to allow data distribution. In our aglet program, data is distributed over the network using annotations (this is similar to High Performance Fortran (HPF) where the programmer specifies data distributions through annotations). We analyze the program using the annotations and use the 'owner computes' rule to determine where a given computation should take place. The compiler then schedules the aglet through the network and also determines the data it should carry during its migration. Determining efficient schedule of the aglet and which data to carry during migration poses interesting issues.We propose two strategies to optimize the aglet schedule. The first strategy called Take All Live Data: (TALD) attempts to carry all the live definitions of variables from a given node when visited. The second strategy Take Only Needed Data (TOND) attempts to carry only those definitions whose uses are in the destination node. The goal of the first strategy is to minimize the number of migrations which are expensive due to high serialization overheads The second strategy aims to minimize bandwidth consumption during a migration. This could significantly reduce the communication overhead due to minimal amount of data carried during each migration. We have implemented both the strategies in the Jikes compiler from IBM. We have evaluated it on a distributed database application and show benefits of both the strategies on large and small databases. The results show that strategies generated by our compiler analysis reduce the overheads and improve execution time.	aglets;computation;data-intensive computing;distributed database;high performance fortran;java;jikes;optimizing compiler;overhead (computing);programmer;run time (program lifecycle phase);serialization	Abhishek Singh;Santosh Pande	2002		10.1145/508791.508809	parallel computing;real-time computing;computer science;cryptography;information security;technical report;evaluation;operating system;software engineering;database;programming language;world wide web;distributed database;computer security	HPC	-21.05646513537974	35.8787473994374	177300
c2978b7e15503ebf81f28f97602ffc2955a80f5f	a virtualization approach for reusing middleware adapters	middleware	Middleware systems use adapters to integrate remote systems and to provide uniform access to them. Different middleware platforms use different adapter technologies, e.g. the J2EE platform uses J2EE connectors and federated database systems based on the SQL standard use SQL wrappers. However, a middleware platform cannot use adapters of a different middleware platform, e.g. a J2EE application server cannot use an SQL wrapper. Even if an SQL wrapper exists for a remote system that is to be integrated by a J2EE application server, a separate J2EE connector for that remote system has to be written. Tasks like that occur over and over again and require to invest additional resources where existing IT infrastructure should be reused. Therefore, we propose an approach that allows to reuse existing adapters. Reusing adapters is achieved by means of a virtualization tier that can handle adapters of different types and that provides uniform access to them. This enables middleware platforms to use each others adapters and thereby avoids the costly task of writing new adapters.	application server;experiment;federated database system;hardware virtualization;java ee connector architecture;java platform, enterprise edition;middleware;multitier architecture;prototype;sql;server (computing);smoothing;software deployment	Ralf Wagner;Bernhard Mitschang	2007			middleware;computer science;operating system;middleware	OS	-33.15716712320599	43.18514469408056	177338
9b49c3bcafc50b677070a4a3aa83bba9bf35b616	partitioning technique for concurrent software design	developpement logiciel;circuit commutation;systeme temps reel;modelizacion;systeme commande;logiciel concurrent;sistema control;tarea concurrente;analisis datos;reseau interconnecte;multiprocessing;flot donnee;simulation;simultaneidad informatica;simulacion;flujo datos;ingenieria logiciel;concurrent software;software engineering;modelisation;data analysis;control system;concurrency;concurrent system;desarrollo logicial;software development;flot commande;systeme concurrent;control flow;multitraitement;genie logiciel;switching circuit;circuito conmutacion;analyse donnee;real time system;sistema tiempo real;tâche concurrente;flujo control;functional requirement;software design;data flow;red interconectada;modeling;interconnected power system;simultaneite informatique;concurrent task;structure analysis;multitratamiento	Software partitioning is the process of mapping software functional requirements into a set of program modules for implementation. This paper analyzes concurrent software design techniques that are based on structured analysis and design (SA/SD) in order to highlight their potential and their shortcomings. A partitioning technique based on the analysis of the data and control flow of a system's functional requirements is proposed next. This technique, called the Concurrent Software Design Technique (CSDT), extends the current SA/SD techniques by identifying concurrent independent tasks for implementation in multitasking or multiprocessing environments. Finally, the application of this technique is illustrated through an example.		Jahangir Karimi;Craig Lee Carpenter	1996	Journal of Systems and Software	10.1016/0164-1212(95)00120-4	data flow diagram;software requirements specification;parallel computing;real-time computing;multiprocessing;systems modeling;concurrency;computer science;control system;software design;software development;software engineering;software construction;structural analysis;data analysis;control flow;functional requirement;algorithm	SE	-24.937652585940537	32.94481883547385	177490
9a85cf1a9ce376ada7112388a792460fed8640e9	introduction to reliable and secure distributed programming (2. ed.)	distributed programs	"""In modern computing a program is usually distributed among several processes. The fundamental challenge when developing reliable and secure distributed programs is to support the cooperation of processes required to execute a common task, even when some of these processes fail. Failures may range from crashes to adversarial attacks by malicious processes.Cachin, Guerraoui, and Rodrigues present an introductory description of fundamental distributed programming abstractions together with algorithms to implement them in distributed systems, where processes are subject to crashes and malicious attacks. The authors follow an incremental approach by first introducing basic abstractions in simple distributed environments, before moving to more sophisticated abstractions and more challenging environments. Each core chapter is devoted to one topic, covering reliable broadcast, shared memory, consensus, and extensions of consensus. For every topic, many exercises and their solutions enhance the understanding This book represents the second edition of """"Introduction to Reliable Distributed Programming"""". Its scope has been extended to include security against malicious actions by non-cooperating processes. This important domain has become widely known under the name """"Byzantine fault-tolerance""""."""	distributed computing	Christian Cachin;Rachid Guerraoui;Luís E. T. Rodrigues	2011		10.1007/978-3-642-15260-3	distributed algorithm;real-time computing;computer science;theoretical computer science;distributed computing	Crypto	-23.90443498476106	43.65374875116053	177656
168bf8fecfad7417e480ada8d7869384e58b77f8	a comparative analysis of the reliability of simple and two-level checkpointing techniques in distributed industrial control systems	comparative analysis		application checkpointing;control system	Alicia Rubio;Rafael Ors Carot;Juan José Serrano	2000			distributed computing;computer science;industrial control system	Logic	-28.97158773775126	46.23901594798934	177708
4896fef2634bce2c7e08d3ae52910ad0b4ad8e15	the design of the saguaro distributed operating system	distributed operating system	"""This paper describes the design of the Saguaro operating system for computers connected by a local-area network. Systems constructed on such an architecture have the potential advantages of concurrency and robustness. In Saguaro, these advantages are made available to the user through several mechanisms. One is channels, an interprocess communication and synchronization facility that allows the input and output of different commands to be connected to form general graphs of communicating processes. Two additional mechanisms are provided to support semitransparent file replication and access: reproduction sets and metafiles. A reproduction set is a collection of files that the system attempts to keep identical on a """"best effort"""" basis. A metafile is a special file that contains symbolic pathnames of other files; when a metafile is opened, the system selects an available constituent file and opens it instead. The advantages of concurrency and robustness are also realized at the system level by the use of pools of server processes and decentralized allocation protocols. Saguaro also makes extensive use of a type system to describe user data such as files and to specify the types of arguments to commands and procedures. This enables the system to assist in type checking and leads to a user interface in which command-specific templates are available to facilitate command invocation."""	best-effort delivery;computer;concurrency (computer science);distributed operating system;input/output;inter-process communication;metafile;robustness (computer science);server (computing);type system;user interface	Gregory R. Andrews;Richard D. Schlichting	1986	IEEE Transactions on Software Engineering	10.1145/503956.503958	local area network;synchronization;real-time computing;computer science;operating system;distributed computing;user interface	OS	-26.610453982918493	45.653242967474206	177862
cf32414b0d8540ec95c125c9bca2cac2385ab176	superstabilizing protocols for dynamic distributed systems	superstabilizing protocols;self-stabilizing topology update protocol;legitimacy predicate;transient fault;topology change;passage predicate;superstabilizing protocol;dynamic environment;dynamic change;self-stabilizing protocol;arbitrary transient fault	 Two aspects of reliability of distributed protocols are a protocol's ability to recoverfrom transient faults and a protocol's ability to function in a dynamic environment.Approaches for both of these aspects have been separately developed, but have drawbackswhen applied to an environment that has both transient faults and dynamicchanges. This paper introduces definitions and methods for addressing both concernsin the design of systems.A protocol is superstabilizing if it is (i)... 	distributed computing	Shlomi Dolev;Ted Herman	1997	Chicago J. Theor. Comput. Sci.		real-time computing;computer science;theoretical computer science;distributed computing;algorithm	Theory	-23.095014516677228	44.98251900593245	177871
be3d3df21cb3390e3431ebe139ec8b0f364e2b69	an algorithm for the real-time evaluation of temporal trace specifications			algorithm;real-time clock	Markus Lepper	2004			computer science;theoretical computer science;algorithm	Embedded	-30.00571194621739	37.88181651026041	178196
4bb903977b16301435366eeb2a609e53ac72ecbd	implementation and performance evaluation of an adaptable failure detector	heuristic;detectors;performance evaluation;computer crashes;distributed processing;heartbeat failure detector;delay effects;stability;asynchronous system;quality of service fault tolerant computing distributed processing system recovery;fault tolerant computing;heuristic adaptable failure detector performance evaluation asynchronous system heartbeat failure detector scalable applications expected arrival date estimation short detection time quality of service adaptation layer;system recovery;fault tolerant systems;expected arrival date estimation;short detection time;failure detector;fault detection;fault tolerance;detectors computer crashes quality of service fault detection heart beat fault tolerant systems broadcasting fault tolerance delay effects stability;broadcasting;quality of service;adaptation layer;scalable applications;heart beat;adaptable failure detector;consensus problem	Chandra and Toueg introduced the concept of unreliable failure detectors. They showed how, by adding these detectors to an asynchronous system, it is possible to solve the Consensus problem. In this paper, we propose a new implementation of a failure detector. This implementation is a variant of the heartbeat failure detector which is adaptable and can support scalable applications. In this implementation we dissociate two aspects: a basic estimation of the expected arrival date to provide a short detection time, and an adaptation of the quality of service according to application needs. The latter is based on two principles: an adaptation layer and a heuristic to adapt the sending period of “I am alive” messages.	asynchronous system;consensus (computer science);failure detector;heuristic;performance evaluation;quality of service;scalability;sensor	Marin Bertier;Olivier Marin;Pierre Sens	2002		10.1109/DSN.2002.1028920	asynchronous system;embedded system;detector;fault tolerance;real-time computing;heuristic;consensus;quality of service;stability;computer science;operating system;distributed computing;chandra–toueg consensus algorithm;computer security;broadcasting;fault detection and isolation;failure detector;computer network	HPC	-24.704986370852293	44.59300993627727	178392
e9c6d22bd817b1c05f82ff7383554119b16f8433	post-deployment performance debugging in wireless sensor networks	software;debugging;performance monitoring;debugging sensor network;blind logging;routing;software modules;data mining;sensor network;post deployment performance debugging;wireless sensor network;inference rule;tinyos post deployment performance debugging wireless sensor networks blind logging data flows software modules;debugging wireless sensor networks application software programming profession performance loss delay software performance monitoring testing computer bugs;engines;monitoring;data dependence;energy consumption;data flows;tinyos;data flow;wireless sensor networks	When an application on a wireless sensor network (WSN) exhibits poor post-deployment performance, users (programmers and administrators) usually do not know which nodes in the network, nor which pieces of debugging information are relevant to the determination of causes of the performance problem. Blind logging and collection of information on all nodes and/or links for the purpose of debugging, however, are energy expensive and sometimes ineffective. To address this problem, we need algorithms and tools that help users pinpoint the causes of application performance problems, and then provide useful hints for fixing them or further examination. To meet this need, we propose a data-centric approach called post-deployment performance debugging (PD2). PD2 focuses on the data flows that an application generates, and relates poor application performance to significant data losses or latencies of some data flows (problematic data flows) as they go through the software modules on individual nodes and through the network. PD2 derives a few inference rules based on the data dependencies between different software modules, as well as between different nodes, and use them to trace back in each problematic flow. Then, PD2 turns on the performance monitoring of, and collects debugging information from, only those modules and nodes that the problematic flows go through. Finally, PD2 provides the debugging information to help users isolate the causes of poor performance. We have implemented PD2 on TinyOS and evaluated it on a real WSN testbed. Our experimental results show that PD2 helps users quickly locate the possible sources of problems, such as code bugs, weak links, and radio interference. Depending on the hop-count between the source of the problem and the data sink, PD2’s energy consumption (communication overhead) is shown to be only 5–10% of that of collecting debugging information from all nodes.	catastrophic interference;data dependency;debugging;interference (communication);overhead (computing);programmer;software bug;software deployment;testbed;tinyos	Zhigang Chen;Kang G. Shin	2009	2009 30th IEEE Real-Time Systems Symposium	10.1109/RTSS.2009.47	embedded system;real-time computing;wireless sensor network;computer science;operating system;distributed computing	Embedded	-23.766272373812967	40.28963986285341	178795
3c62e856752aaafeb7693578d24f2eaab9f9cecf	high-level specification of concurrency control in distributed database systems		Concurrency control is one of the major issues in database systems; therefore, many concurrency control algorithms based on different strategies have been proposed. Unfortunately there is still lack of a general model for describing these algorithms. Hence, algorithms cannot be uniformly presented, which makes it hard to understand them and to prove their correctness. This paper proposes a high level specification, based on an object-oriented model, of concurrency control algorithms. Concurrency control algorithms are specified in a high level fashion without losing their formality. Basing on the object-oriented model, objects are individually specified. Therefore, the specification of a concurrency control algorithm consists of the specifications of objects and their interactions.	algorithm;concurrency control;correctness (computer science);distributed database;high-level programming language;interaction	Lin Chiu;Ming T. Liu	1988				DB	-26.842622543441742	34.41924002526552	178830
03a1287c60d749898dc3e9e0262f4eae8e4ad4ce	distributed agreement in tile self-assembly	self assembly;distributed system;crash failure;cluster computing;fault tolerant;distributed computing;three dimensional;evolutionary computing;consensus problem	Laboratory investigations have shown that a formal theory of fault-tolerance will be essential to harness nanoscale self-assembly as a medium of computation. Several researchers have voiced an intuition that self-assembly phenomena are related to the field of distributed computing. This paper formalizes some of that intuition. We construct tile assembly systems that are able to simulate the solution of the wait-free consensus problem in some distributed systems. (For potential future work, this may allow binding errors in tile assembly to be analyzed, and managed, with positive results in distributed computing, as a “blockage” in our tile assembly model is analogous to a crash failure in a distributed computing model.) We also define a strengthening of the “traditional” consensus problem, to make explicit an expectation about consensus algorithms that is often implicit in distributed computing literature. We show that solution of this strengthened consensus problem can be simulated by a two-dimensional tile assembly model only for two processes, whereas a three-dimensional tile assembly model can simulate its solution in a distributed system with any number of processes.	automata theory;cellular automaton;computation;consensus (computer science);distributed computing;failure cause;fault tolerance;jack lutz;jim hall (programmer);non-blocking algorithm;rendering (computer graphics);self-assembly;simulation	Aaron Sterling	2009		10.1007/978-3-642-10604-0_16	three-dimensional space;distributed algorithm;fault tolerance;parallel computing;real-time computing;consensus;failure semantics;computer cluster;computer science;theoretical computer science;operating system;uniform consensus;distributed computing;self-assembly;algorithm;evolutionary computation	Theory	-22.64020935194816	42.86423754827159	178889
e2d3df5fe15ab30f0f5e52cb9861207d6803c8c8	design of fault-tolerant clocks with realistic failure assumptions	phase locking;synchronisation clocks fault tolerant computing;fault tolerance clocks hardware frequency synchronization real time systems digital systems aerospace engineering marine technology delay systems distributed processing;fault tolerant;clocks;synchronisation;fault tolerant computing;nonmalicious fault tolerant clocks realistic failure assumptions phase locked clocks clock failures hardware complexity reliability failed clock modules malicious	The authors address the problem of designing fault-tolerant, phase-locked clocks in the presence of different types of clock failures and show that significant improvements in hardware complexity and reliability can be achieved when failed clock modules are partitioned into two classes: malicious and nonmalicious. They show that the condition N>2t+max(t1, 1) is necessary and sufficient to tolerate up to t failed clock modules out of which a maximum of t1 can behave maliciously. The practical value of this design concept is demonstrated by examples. >	failure cause;fault tolerance	Nagesh Vasanthavada;Philip Thambidurai;Peter N. Marinos	1989		10.1109/FTCS.1989.105555	clock synchronization;embedded system;real-time computing;engineering;distributed computing	Logic	-23.16627138985782	43.98775014225687	179249
aa3c2ce120181db8a386ca2b498a01674eef05f1	application-level causally ordered broadcast for large-scale group communication	estensibilidad;fiabilidad;reliability;tecnologia electronica telecomunicaciones;reseau communication;systeme grande taille;protocole transmission;simulation;gossip;simulacion;large scale system;causal ordering;group communication;causal order delivery;algorithme;algorithm;large scale;protocolo transmision;fiabilite;diffusion donnee;difusion dato;extensibilite;scalability;data broadcast;tecnologias;grupo a;red de comunicacion;communication network;sistema gran escala;algoritmo;transmission protocol	Gossip-based reliable broadcast protocols with reasonably weak reliability properties scale well to large groups and degrade system performance gracefully even if node failure or message loss rates increase compared with traditional protocols. However, although many distributed applications require highly steady performance only by allowing causality to be used asynchronously, there is no existing gossip-based protocol offering causally ordered delivery property more lightweight than totally ordered delivery one. This paper presents an application-level broadcast algorithm to guarantee causally-ordered delivery semantics based on peer to peer interaction models for scalability, reasonable reliability and stable throughput. Processes propagate each message with a vector time stamp much like the spread of rumor in society for a fixed number of rounds. Upon receipt of these messages, correct processes immediately deliver the corresponding messages to the application layers in a causal order. Simulation results show that the proposed algorithm outperforms the existing ones in terms of delivery throughput.		ChaYoung Kim;JinHo Ahn;Chong-Sun Hwang	2005	IEICE Transactions	10.1093/ietisy/e88-d.12.2883	gossip;real-time computing;scalability;simulation;telecommunications;computer science;reliability;algorithm;statistics	Visualization	-21.158224577098075	43.99452174732068	179564
0632c9f9c21169015ddd31a9c992e1244ddb3818	supporting concurrency, communication, and synchronization in human-computer interaction - the sassafras uims	human computer interaction;user interface management system;user interface;multiple input devices;human factors;message passing	Sassafras is a prototype User Interface Management System (UIMS) specifically designed to support a wide range of user interface styles. In particular, it supports the implementation of user interfaces where the user is free to manipulate multiple input devices and perform several (possibly related) tasks concurrently. These interfaces can be compactly represented and efficiently implemented without violating any of the rules of well-structured programming. Sassafras also supports elaborate run-time communication and synchronization among the modules that make up the user interface. This is needed to implement user interfaces that have context-sensitive defaults, and it simplifies recovery from semantic errors. Sassafras is based on a new language for specifying the syntax of human-computer dialogues known as Event-Response Language (ERL) and a new run-time structure and communication mechanism for UIMSs known as the Local Event Broadcast Method (LEBM). Both ERL and LEBM are described in detail, and implementation techniques are presented. The effectiveness of Sassafras is demonstrated by describing two interfaces that have been implemented with Sassafras.	context-sensitive grammar;erlang (programming language);human–computer interaction;input device;management system;prototype;structured programming;user interface management systems	Ralph D. Hill	1986	ACM Trans. Graph.	10.1145/24054.24055	user interface design;message passing;real-time computing;human–computer interaction;computer science;human factors and ergonomics;distributed computing;programming language;user interface	Graphics	-31.160597135848644	34.92177664088915	179600
47db5084a32c458e84a1279d03d3e1f2c5023976	lightweight framework for runtime updating of c-based software in embedded systems		Software updates in embedded systems are typically performed by bringing the system to stop, replacing the software and restarting the system. This process can in certain cases be very time consuming and costly, which leads to less frequent software updates. In order to establish both long uptime and up-to-date software, the software must be updated during runtime. This paper presents a runtime updating framework for embedded systems capable of replacing parts of software without stopping the system. The framework is based on FreeRTOS and mechanisms have been added to dynamically link and re-link FreeRTOS tasks to the system during runtime. Our framework enables the programmer to easily create updatable software with simple annotations to the program. Experiments demonstrate the benefits of updating software during runtime with an acceptable overhead when transferring the application state.	dynamic linker;embedded system;freertos;overhead (computing);patch (computing);programmer;state (computer science);uptime	Simon Holmbacka;Wictor Lund;Sébastien Lafond;Johan Lilius	2013			lightweight methodology;real-time computing;operating system;distributed computing	Embedded	-22.047122603925043	36.65372505824939	179663
7a881a80ea0605916546a980bacab47960dfc58d	distribution and mobility with lexical scoping in process calculi	process calculi	We propose a simple model of distribution for mobile processes, independent of the underlying calculus. Conventional processes compute within sites; inter-site computation is achieved by message sending and object migration, both obeying a lexical scope. We focus on the semantics of networks, on programming practice, and on physical realization with current technology.	computation;curry–howard correspondence;mobile agent;obedience (human behavior);process calculus;scope (computer science);software design pattern	Vasco Thudichum Vasconcelos;Luís M. B. Lopes;Fernando M. A. Silva	1998	Electr. Notes Theor. Comput. Sci.	10.1016/S1571-0661(04)00142-2	process calculus;computer science;theoretical computer science;programming language;algorithm	PL	-29.40083289433956	32.775185665877096	179735
9e8deae37d108417119af6f744dfe2a800de5b2a	transaction routing for distributed oltp systems: survey and recent results	distributed system;remote access;eficacia sistema;cargamento;base donnee repartie;architecture systeme;systeme reparti;distributed database;routing;distributed transactions;reseau ordinateur;performance systeme;base repartida dato;loading;chargement;system performance;computer network;algorithme;algorithm;sistema repartido;scheduling;red ordenador;arquitectura sistema;ordonamiento;encaminamiento;system architecture;scheduling and routing;communication;comunicacion;ordonnancement;acheminement;algoritmo	Workloads in distributed database applications consist of queries and transactions. In order to address performance requirements, distributed transaction processing systems have to deal with two related issues: transaction routing and scheduling. Due to the distribution of data objects among nodes and the access cost incurred by remote accesses, efficient transaction routing is an important consideration for overall system performance. Another important consideration is workflow scheduling and routing. Workflows are complex units of work consisting of multiple, possibly interdependent, transactions. In this survey, we discuss a number of different transaction routing mechanisms and their performance.	distributed database;distributed transaction;interdependence;online transaction processing;requirement;routing;scheduling (computing);transaction processing system	Christos Nikolaou;Manolis Marazakis;G. Georgiannakis	1997	Inf. Sci.	10.1016/S0020-0255(96)00173-9	policy-based routing;embedded system;routing;static routing;real-time computing;database transaction;transaction processing;distributed transaction;computer science;multipath routing;transaction data;distributed computing;online transaction processing;compensating transaction;routing protocol;link-state routing protocol;serializability;scheduling;distributed database;acid;transaction processing system	DB	-19.781586861389243	46.127745234860264	179747
892223019f681caed2c32b1c90d45bbbf826ab35	dynamic virtual worker nodes in a production grid	virtual machine;haute performance;realite virtuelle;realidad virtual;localization;logicial personalizado;customization;distributed computing;virtual reality;personnalisation;grid middleware;localizacion;machine virtuelle;language resources;intergiciel;grid;lenguaje descripcion;localisation;rejilla;execution environment;personalizacion;alto rendimiento;grille;calculo repartido;middleware;management tool;virtual environment;user involvement;maquina virtual;grid computing;high performance;calcul reparti;langage description;description language	There is a growing body of opinion that virtual machines (VMs) provide a good environment for executing user jobs on Grid compute nodes. Sites which execute jobs in specially-created virtual machines can provide levels of isolation and customisation that are unobtainable when jobs run directly on the hardware. Various solutions have been proposed for initiating and controlling such dynamic virtual environments, but issues of integration with a production Grid middleware stack have not received much attention. In addition, solutions proposed to date often require significant user involvement in the process of locating and initiating VMs. We outline a scheme for transparently providing dynamically-instantiated VM-based worker nodes in the EGEE production grid. By extending server-side software, the use of virtual machines is made invisible to the user. Users simply specify the details of their required execution environment in the standard job description language. Resource brokers then locate sites that advertise support for that particular environment. Sites that support dynamic virtual worker nodes advertise support for the various environments that they know how to create; the site's compute element is responsible for instantiating a VM that conforms to the environment description requested and for executing the job in that VM's context. We also evaluate the VM management tools available to implement such a scheme and describe their possible integration with LCG and gLite middleware.		Stephen Childs;Brian A. Coghlan;Jason McCandless	2006		10.1007/11942634_44	embedded system;real-time computing;computer science;virtual machine;operating system;database;distributed computing;virtual reality;computer security	HPC	-28.85869361057506	42.60505483008719	180548
cbe951340a055aa1b675cad6d9389885357f85b0	message queuing patterns for middleware-mediated transactions	message oriented middleware;distributed objects;object oriented;middleware	Many enterprise applications require the use of object-oriented middleware and message-oriented middleware in combination. Middleware-mediated transacdons have been proposed as a transaction model to address reliability of such applications; they extend distributed object transactions to include message-oriented transactions. In this paper, we present three message queuing patterns that we have found useful for implementing middleware-mediated transactions. We discuss and show how the patterns can be applied to support guaranteed compensation in the engineering of transactional enterprise applications.	message queue;middleware	Stefan Tai;Alexander Totok;Thomas A. Mikalsen;Isabelle Rouvellou	2002		10.1007/3-540-38093-0_12	middleware;real-time computing;computer science;message oriented middleware;middleware;database;distributed computing;distributed object;message broker;object-oriented programming	DB	-32.36345034451979	44.2127741688099	180557
104a9057b97b50d053a01e7a36c0de46480a1948	analysis and optimization of engines for dynamically typed languages	mechanical engineering computing;info eu repo semantics conferenceobject;high performance computing;prototypes;dynamic compiler;engines optimization benchmark testing dynamic compiler vehicle dynamics prototypes;engines;conference report;computer architecture dynamic typed languages dynamic compilation;optimization;calcul intensiu informatica;arees tematiques de la upc informatica arquitectura de computadors;program compilers;hw sw optimizations engine optimization engine analysis dynamically typed programming languages javascript dynamic compilation activities housekeeping activities garbage collector compilation;programming languages engines java mechanical engineering computing program compilers;vehicle dynamics;benchmark testing;programming languages;java;info eu repo semantics publishedversion	Dynamically typed programming languages have become very popular in the recent years. These languages ease the task of the programmer but introduce significant overheads since assumptions about the types of variables have to be constantly validated at run time. Java Script is a widely used dynamically typed language that has gained significant popularity in recent years. In this paper, we provide a detailed analysis of the two main sources of overhead in the Java Script execution. The first one is the runtime overhead needed for dynamic compilation and housekeeping activities (i.e. Garbage collector, compilation, etc.). The second one is the additional checks and guards introduced by the dynamic nature of Java Script. Then, we propose three new HW/SW optimizations that reduce this latter type of overhead. We show that these two types of overhead represent 35% and 25% respectively of the total execution time on average for a representative workload, and the proposed optimizations provide a 6% average speedup.	benchmark (computing);compiler;dynamic compilation;garbage collection (computer science);java;javascript engine;open-source software;overhead (computing);programmer;programming language;run time (program lifecycle phase);shattered world;speedup;steady state;type system	Gem Dot;Alejandro Martínez;Antonio González	2015	2015 27th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)	10.1109/SBAC-PAD.2015.20	benchmark;supercomputer;parallel computing;real-time computing;vehicle dynamics;computer science;operating system;prototype;programming language;java	Arch	-20.226084635065348	35.86484469059557	180853
b11592e729e3a779146054d729284eed2f19e65c	analysis and evaluation of distributed checkpoint algorithms to avoid rollback propagation	distributed algorithms;theoretical framework;local checkpoint;rollback propagation;distributed applications;consistent global checkpoint;fault tolerance;distributed checkpoint algorithms;theoretical framework distributed checkpoint algorithms rollback propagation fault tolerance distributed applications local checkpoint consistent global checkpoint	Checkpointing is a very well known mechanism to achieve fault tolerance. In distributed applications where processes can checkpoint independently of each other, a local checkpoint is useful for fault tolerance purposes only if it belongs to at least one consistent global checkpoint. In this case, execution can be restarted from it without needing to rollback the execution in the past. The paper exploits a theoretical framework that facilitates the definition and analysis of distributed checkpoint algorithms to avoid rollback propagation. Several distributed algorithms are presented which avoid rollback propagation by forcing additional checkpoints in processes. The effectiveness of the algorithms is evaluated in several testbed applications, showing their limited capability of bounding the number of additional checkpoints.	algorithm;software propagation;transaction processing system	Franco Zambonelli	1998	IEE Proceedings - Software	10.1049/ip-sen:19982442	distributed algorithm;fault tolerance;parallel computing;real-time computing;computer science;distributed computing	HPC	-22.844776933683296	45.66168577505777	180917
809ccbec02f0de997c8f1b2d125ce47c0ba4ba65	an algorithm for interpreting closure property of javascript through runtime stack (a lightweight interpreter for embedded device)			algorithm;call stack;embedded system;javascript	Binod Kumar Pattanayak;Sambit Kumar Patra;Bhagabat Puthal	2014	I. J. Comput. Appl.		programming language;closure (mathematics);javascript;computer science;interpreter	Embedded	-21.998423085203086	32.54516421718979	181021
91b995d4f38fad789d6e2b7fbb06de3624a5805b	code generation for embedded java with ptolemy	code generation;synchronous data flow;worst case execution time;real time java;model based design;finite state machine;real time systems	Code generation from models is the ultimate goal of model-based design. For real-time systems the generated code must be analyzable for the worstcase execution time (WCET). In this paper we evaluate Java code generation from Ptolemy II for embedded real-time Java. The target system is the time-predictable Java processor JOP. The quality of the generated code is verified by WCET analysis for the target platform. Our results indicate that code generated from synchronous data-flow and finite state machine models is WCET analyzable and the generated code leads to tight WCET bounds.	code generation (compiler);dataflow;embedded java;embedded system;finite-state machine;handbook;java optimized processor;java processor;ptolemy ii;real time java;real-time clock;real-time computing;real-time locating system;run time (program lifecycle phase);synchronous data flow;worst-case execution time	Martin Schoeberl;Christopher X. Brooks;Edward A. Lee	2010		10.1007/978-3-642-16256-5_16	dead code;parallel computing;real-time computing;computer science;redundant code;real time java;finite-state machine;programming language;model-based design;code generation;worst-case execution time;unreachable code;source code	Embedded	-23.34600485956408	36.33381861448164	181250
f36ca3b31c6d7f35db2b72cb63a8b4cffa1d9d84	fault-tolerant vliw processor design and error coverage analysis	tolerancia falta;vliw processor;distributed system;langage description materiel informatique;systeme reparti;calculateur embarque;fault tolerant;coverage analysis;data path;mot instruction tres long;pervasive computing;real time;hardware description languages;camino datos;informatica difusa;fault tolerant system;sistema repartido;estimation erreur;informatique diffuse;error estimation;verilog hardware description language;vhdl;temps reel;fault tolerance;estimacion error;boarded computer;sistema tolerando faltas;very long instruction word;tiempo real;chemin donnees;systeme tolerant les pannes;modele donnee;palabra instruccion muy larga;fault model;calculador embarque;langage vhdl;tolerance faute;data models	In this paper, a general fault-tolerant framework adopting a more rigid fault model for VLIW data paths is proposed. The basic idea used to protect the data paths is that the execution result of each instruction is checked immediately and if errors are discovered, the instruction retry is performed at once to overcome the faults. An experimental architecture is developed and implemented in VHDL to analyze the impacts of our technique on hardware overhead and performance degradation. We also develop a comprehensive fault tolerance verification platform to facilitate the assessment of error coverage for the proposed mechanism. A paramount finding observed from the experiments is that our system is still extremely robust even in a very serious fault scenario. As a result, the proposed fault-tolerant VLIW core is quite suitable for the highly dependable real-time embedded applications.	central processing unit;dependability;elegant degradation;embedded system;error detection and correction;experiment;fail-safe;fault injection;fault model;fault tolerance;general protection fault;overhead (computing);processor design;real-time clock;real-time computing;retry;simulation;vhdl;verification and validation	Yung-Yuan Chen;Kuen-Long Leu;Chao-Sung Yeh	2006		10.1007/11802167_76	embedded system;fault tolerance;parallel computing;real-time computing;computer science;operating system;distributed computing;ubiquitous computing;algorithm	Embedded	-20.861244575207603	40.575236168189264	181652
60d5e01d8560779bc61b5da162fea02eadaf3bfd	axioms for memory access in asynchronous hardware systems	chip;memory access;asynchronous algorithm;concurrent programs;timing analysis;design verification;flip flop	The problem of concurrent accesses to registers by asynchronous components is considered. A set of axioms about the values in a register during concurrent accesses is proposed. It is shown that if these axioms are met by a register, then concurrent accesses to it may be viewed as nonconcurrent, thus making it possible to analyze asynchronous algorithms without elaborate timing analysis of opera-tions. These axioms are shown, in a certain sense, to be the weakest. Motivation for this work came from analyzing low-level hardware components in a VLSI chip which concurrently accesses a flip-flop. Categories and Subject Descriptors: D. l. 3 [Programming Techniques]: Concurrent Programming General Terms: Design, Verification Additional Key Words and Phrases: Concurrent access 		Jayadev Misra	1984		10.1007/3-540-15670-4_5	chip;uniform memory access;computer architecture;parallel computing;real-time computing;computer science;static timing analysis	EDA	-22.753401192363235	34.8671585735473	181814
010a36e50e6da2cef578b331762962f0b476f2ba	determin: inferring likely deterministic specifications of multithreaded programs	multi threading;determin;multithreaded programs;graphic processing units;lattices;deterministic specification;deterministic specifications;semantics;bridges;parallel programming;parallel programming multiprocessing systems multi threading;bridges schedules vegetation lattices semantics instruction sets java;vegetation;schedules;graphic processing unit;specification inference;multicore processors;multiprocessing systems;specification inference determinism parallel programs;deterministic specification determin multicore processors multithreaded programs graphic processing units parallel programs java deterministic specifications;determinism;parallel programs;parallel applications;instruction sets;java	The trend towards multicore processors and graphic processing units is increasing the need for software that can take advantage of parallelism. Writing correct parallel programs using threads, however, has proven to be quite challenging due to nondeterminism. The threads of a parallel application may be interleaved nondeterministically during execution, which can lead to nondeterministic results---some interleavings may produce the correct result while others may not. We have previously proposed an assertion framework for specifying that regions of a parallel program behave deterministically despite nondeterministic thread interleaving. The framework allows programmers to write assertions involving pairs of program states arising from different parallel schedules.  We propose an algorithm to dynamically infer likely deterministic specifications for parallel programs given a set of inputs and schedules. We have implemented our specification inference algorithm for Java and have applied it to a number of previously examined Java benchmarks. We were able to automatically infer specifications largely equivalent to or stronger than our manual assertions from our previous work.  We believe that the inference of deterministic specifications can aid in understanding and documenting the deterministic behavior of parallel programs. Moreover, an unexpected deterministic specification can indicate to a programmer the presence of erroneous or unintended behavior.	assertion (software development);central processing unit;deterministic algorithm;forward error correction;graphics processing unit;java;multi-core processor;nondeterministic algorithm;parallel computing;parallel programming model;programmer;schedule (computer science);software documentation;thread (computing)	Jacob Burnim;Koushik Sen	2010	2010 ACM/IEEE 32nd International Conference on Software Engineering	10.1145/1806799.1806860	multi-core processor;parallel computing;real-time computing;multithreading;schedule;computer science;operating system;instruction set;lattice;semantics;programming language;java;vegetation;determinism	SE	-20.13982112820591	39.12721207310322	182169
98fce654aaf45e64c3577935b5cf194c940de048	mobile agent system for jini networks employing remote method invocation technology	resource limitation;multiagent system;navegacion informacion;informatique mobile;mobile device;agent mobile;red www;navigation information;real time;agente movil;reseau web;information browsing;langage java;intelligence artificielle;intergiciel publication souscription;mobile agent system;appel procedure a distance;internet;intergicial editor suscriptor;remote method invocation;rmi;temps reel;agent systems;tiempo real;artificial intelligence;world wide web;lenguaje java;inteligencia artificial;mobile agent;sistema multiagente;mobile computing;remote procedure calls;publish subscribe middleware;systeme multiagent;java language	A mobile agent system employing a Remote Method Invocation(RMI) technology has been demonstrated for a resource-limited mobile device. The agent system facilitates the mobile device to support Jini services without any additional client program installation in it. It also provides a dynamic service list, which facilitates the users to search and to utilize the various services supported on a Jini network in a real time through a web browser of the mobile device.		Sang Tae Kim;Byoung-Ju Yun;Hyun Deok Kim	2005		10.1007/11552413_145	embedded system;real-time computing;mobile search;the internet;mobile web;mobile database;computer science;operating system;mobile technology;mobile agent;mobile device;database;distributed computing;mobile computing;remote procedure call;world wide web;computer security	EDA	-29.812268588665166	43.40876964438466	182941
fdce619eee38e7065270c8b2eba402b5803068c9	a light weight kernel server		We propose a light weight kernel server for dynamic and transparent configuration of services and interaction mechanisms, allowing a run-time negotiation of a desired service functionality, of service interfaces, and of the degree of the fault-tolerance provided. The kernel server provides abstractions concerning: (1) the interprocess communication, (2) the coordination of process interaction and the service management and (3) the fault-tolerance. Furthermore, we offer not only useful abstractions, but also tools for the user to define new abstractions. To allow this we introduce a simple basic communication framework, the Active Virtual Port, and means for the developer to implement and attach new abstractions (port threads), as well as for the user to use them by means of port capabilities.	kernel (operating system);server (computing)	Rumen Stainov;Winfried Kalfa	1992	Microprocessing and Microprogramming	10.1016/0165-6074(92)90291-E	embedded system;parallel computing;real-time computing;computer science;operating system;distributed computing	Vision	-31.5146767318639	43.71973827937604	182949
c2839e464008a35a14c9ddebb40d7fdc18baed5b	adaptive strategies for speeding up sequences of consensus	adaptability agreement problem consensus paxos fast paxos;protocols;optimisation;adaptability;consensus;optimisation distributed processing;consensus sequence;fast paxos;distributed processing;so protocol;unreliable asynchronous system;ro protocol;runtime;asynchronous system;optimization protocols context delay lead runtime scalability;paxos mic protocol;lead;http requests;optimizations;optimization;http requests paxos mic protocol consensus sequence unreliable asynchronous system optimizations so protocol ro protocol;scalability;agreement problem;paxos;agreement problems;context	The Paxos-MIC protocol allows to solve a sequence of consensus instances in an unreliable asynchronous system. It follows the basic principles of Paxos and uses two optimizations of this protocol: a safe one, So that is always activated and a risky one, Ro. The paper focuses on the interest of Ro that has been introduced by Lamport in the Fast Paxos protocol. We study the optimization Ro in favorable and unfavorable scenarios where it may lead to an additional cost. Paxos-MIC is adaptive as it tries to obtain the best performance gain depending on the current context. Indeed, between two consecutive consensus instances, the leader determines if Ro has to be triggered or not. In the particular context of a secure Web architecture whose design relies on a consensus service, we use a trace that contains all the HTTP requests addressed to a real Web site during a period of 16 days. We propose different triggering criteria and we analyze their accuracy to predict collisions when proposed values are produced at the rate observed in this trace.	asynchronous system;hypertext transfer protocol;mathematical optimization;paxos (computer science);persistence (computer science);server (computing);web server	Michel Hurfin;Izabela Moise;Jean-Pierre Le Narzul;Frédéric Majorczyk	2012	2012 26th International Conference on Advanced Information Networking and Applications Workshops	10.1109/WAINA.2012.178	consensus sequence;asynchronous system;paxos;communications protocol;lead;real-time computing;adaptability;scalability;consensus;computer science;operating system;database;distributed computing;computer network	Mobile	-21.836579707236826	45.316757304262445	183311
5ab95623670f341bbc1ee4a7277aa5967221a55a	hdb-a high level debugging	debugging;data mining;source code;parallel processing	This paper presents a new high level debugging tool, HDB, for debugging large scientific programs running on a moderate number of processors. The unique feature of HDB is that checksums are used to compress arrays and groups of variables without losing meaningful information for debugging. Using checksums makes it possible to use invariance assertions to detect misbehavior of a program at a place near the source of the error. Tracing the checksums allows the tracing of a large amount of data with a small amount of output. Comparing the traced checksums of a program and the traced checksums of its reference copy can rapidly reduce the potential error sources to a small number of subroutines. These subroutines can then be directly probed for further investigation. If desired, a debugger providing break points and single stepping source code can be used in conjunction with HDB. Examples show that using the HDB method can rapidly uncover bugs hidden in both parallel and sequential programs.	central processing unit;checksum;debugger;debugging;high-level programming language;software bug;stepping level;subroutine	Doreen Cheng	1989	Proceedings of the 1989 ACM/IEEE Conference on Supercomputing (Supercomputing '89)	10.1145/76263.76327	parallel processing;parallel computing;real-time computing;computer science;operating system;programming language;debugging;source code	HPC	-19.43179395213078	38.06546435069464	183427
e4124efe14c73d3bddc14e2068010d6992aad24f	the research of ajax technique application based on the j2ee	ajax technique application;web application programs;oceans;response data;data locality;loading;weather forecasting;web2 0 core technology;xml internet java;browsers;j2ee;servers;servers browsers engines xml loading oceans weather forecasting;internet;engines;xml;xml ajax technique application j2ee response data web application programs data transfer web2 0 core technology asynchronous javascript;asynchronous javascript;data transfer;java	"""This paper focuses on the researches of Ajax technique and its application based on J2EE.The advantage and the disadvantage of using Ajax technique are analyzed through the experiments.Ajax technique is a comprehensive utilization of a set of Web2.0 core technology.The difference from the traditional Web working module is that Ajax technique adopts asynchronous to send request to server.The advantage is to update the response data locally on the current page, so that user does not experience updating interaction. However,when the amount of response data increases,the burden on server also increases. Thus, the waiting period for response data is extended at users.Ajax technique only adapts to the Web application programs with small amount of data transfer and frequent interaction. Another feature of Ajax technique is that the Browser's""""backwards"""" function is impacted."""	ajax (programming);experiment;java platform, enterprise edition;server (computing);web 2.0;web application;world wide web	Jing Wang;Feng Xu	2010	2010 2nd International Workshop on Database Technology and Applications	10.1109/DBTA.2010.5659073	ajax;the internet;xml;weather forecasting;computer science;operating system;data mining;database;programming language;java;world wide web;server	SE	-31.74140116418654	41.76086184649132	183774
7e40209617935569a12a104c354eabf029a3b537	a type and effect system for deterministic parallel java	verification;modelizacion;parallelisme;distributed memory;distributed system;no determinismo;algoritmo paralelo;programa paralelo;compilacion;theorie type;systeme reparti;parallel algorithm;object oriented language;shared memory;validacion;complex programming;memoria compartida;programacion compleja;semantics;simultaneidad informatica;langage java;indice aptitud;interlacing;probabilistic approach;program verification;semantica;semantique;systeme deterministe;approche deterministe;algorithme parallele;deterministic approach;modelisation;indice aptitude;verificacion programa;parallelism;concurrency;sistema repartido;non determinism;paralelismo;type checking;sistema determinista;non determinisme;object oriented;capability index;enfoque probabilista;approche probabiliste;effects;type theory;entrelacement;enfoque determinista;deterministic parallelism;compilation;multithread;oriente objet;experimental validation;programmation complexe;lenguaje java;validation;entrelazado;multitâche;performance determinism;parallel programming model;commutativity;memoire repartie;determinism;parallel programs;verification programme;effect systems;modeling;simultaneite informatique;orientado objeto;parallel program;languages;multitarea;memoire partagee;type system;deterministic system;java language;programme parallele	Today's shared-memory parallel programming models are complex and error-prone.While many parallel programs are intended to be deterministic, unanticipated thread interleavings can lead to subtle bugs and nondeterministic semantics. In this paper, we demonstrate that a practical type and effect system can simplify parallel programming by guaranteeing deterministic semantics with modular, compile-time type checking even in a rich, concurrent object-oriented language such as Java. We describe an object-oriented type and effect system that provides several new capabilities over previous systems for expressing deterministic parallel algorithms.We also describe a language called Deterministic Parallel Java (DPJ) that incorporates the new type system features, and we show that a core subset of DPJ is sound. We describe an experimental validation showing thatDPJ can express a wide range of realistic parallel programs; that the new type system features are useful for such programs; and that the parallel programs exhibit good performance gains (coming close to or beating equivalent, nondeterministic multithreaded programs where those are available).	cognitive dimensions of notations;compiler;deterministic parallel java;effect system;parallel algorithm;parallel computing;shared memory;software bug;thread (computing);type system	Robert L. Bocchino;Vikram S. Adve;Danny Dig;Sarita V. Adve;Stephen Heumann;Rakesh Komuravelli;Jeffrey Overbey;Patrick Simmons;Hyojin Sung;Mohsen Vakilian	2009		10.1145/1640089.1640097	computer science;theoretical computer science;semantics;programming language;object-oriented programming;algorithm	PL	-20.63137831103994	33.793958212188876	183782
2215b56c2812f700708c2ec9c158932e010f431b	unix on a loosely coupled architecture: the chorus/mix approach	parallelism;distributed systems;operating systems;unix;mix approach	In the CHORUS/MiX R distributed operating system architecture the microkernel provides system servers with generic services which are independent of a particular operating system; these services include processor scheduling, memory management and inter-process communications. In turn, co-operating system servers provide at the application programmer's interface a particular operating system personality. The CHORUS/MiX implementation of UNIX R is based on AT&T source code, but is signi cantly re-structured into a set of system servers. This re-structuring has resulted in a modular and adaptable system which is well suited to distribution across a loosely coupled parallel architecture. The CHORUS/MiX system is further being developed to provide what has been termed single site semantics (SSS). This will make it possible to create the illusion of UNIX running on a single processor whilst taking advantage of the availability of a number of loosely coupled processors. The IMS T9000 R Transputer will be one of the rst processors on which CHORUS/MiX SSS will be implemented.	central processing unit;chorusos;distributed operating system;inter-process communication;loose coupling;memory management;microkernel;parallel computing;programmer;scheduling (computing);systems architecture;transputer;unix;while;windows nt processor scheduling	Lawrence Albinson;Dominique Grabas;Pascal Piovesan;Michel Tombroff;Christian Tricot;Hossein Yassaie	1992	Future Generation Comp. Syst.	10.1016/0167-739X(92)90030-F	embedded system;real-time computing;operating system	OS	-28.97558742144691	40.119110369786135	183966
fef07f6eeb9b0f93a61ac284d6daaa0d07707267	dynamically instrumenting message-passing programs using virtual clocks	program debugging message passing program diagnostics real time systems concurrency control software performance evaluation;debugging;program instrumentation;program diagnostics;instruments;message passing programs;non deterministic choices;clocks;real time;run time behaviour;software performance evaluation;non deterministic communication;debugging message passing programs virtual clocks run time behaviour distributed program program instrumentation trace recording instructions real time execution speed non deterministic choices logical clock approach inter process communication real time execution non deterministic communication deadlock carrier null message algorithm event timing information performance tuning;distributed programs;event timing information;logical clock approach;system recovery;monitoring;instruments clocks monitoring system recovery timing debugging performance analysis data visualization process control communication system control;virtual clocks;carrier null message algorithm;data visualization;concurrency control;performance analysis;process control;message passing;deadlock;real time execution speed;program debugging;real time execution;distributed program;communication system control;trace recording instructions;performance tuning;inter process communication;real time systems;timing	Analysing and visualising the run time behaviour of a distributed program requires collecting performance data during its execution. This is usually done through program instrumentation that inserts trace recording instructions into the program. The intrusiveness of inserted extra code to the original program may make the existing errors vanish, or can cause new errors to appear. It will not only change the real time execution speed, but also change the probability of making particular non deterministic choices. W. Cai and S.J. Turner (1994) proposed a logical clock approach (LCA) to control the inter process communication. It uses a logical clock in each process to reflect the real time execution of the process when running without monitoring. Not relying on any special hardware, this approach achieves minimum intrusiveness and makes the monitoring effect on the original program completely independent from the amount of time spent on monitoring activities. A main problem with LCA is that in an event of non deterministic communication and when several processes wait on each other's logical clock to advance, a deadlock may occur. LCA uses a carrier null message algorithm to break the deadlock situation. But sending an extra null message will distort the event timing information. Therefore, LCA is only suitable for debugging rather than for performance tuning. We present a major improvement to LCA, which preserves the timing information without introducing any deadlock. Our improved approach can support both debugging and performance tuning. We call our clocks virtual clocks to avoid confusion.	instrumentation (computer programming);message passing	Kang Zhang;Chengzheng Sun;Kei-Chun Li	1998		10.1109/HPDC.1998.710020	parallel computing;message passing;real-time computing;computer science;deadlock;operating system;concurrency control;process control;distributed computing;programming language;debugging;data visualization;inter-process communication	HPC	-20.68618269464281	38.84590548189141	184203
b2a930b3f60cfe9a10deaed923b3a2fb91fef692	"""design of a remote controlled caching proxy system - """"architecture, algorithm and implementation"""""""		A caching proxy server acts as an invisible intermediary between browsing clients and the internet servers. In the case of a Web cache, cacheable objects are always separate and are always read in their entity with no pre-fetching. In the present study we present a novel design for a system to remote control an array of proxy system. The administrator can monitor and configure the caching array system from any normal client computational facility. The current system emphasizes on the fact that the administrator can change the configuration of the system with no need either to start the system or alter the clients’ statuses. This is achieved by implementing the concurrency control system under the system hierarchy. The primarily local testing of the system shows promising results to get implemented on large scale of enterprise systems.. Key-Words: : proxy, cache, web caching, least recently used (LRU), proxy array selector	algorithm;applet;cache (computing);client (computing);concurrency (computer science);concurrency control;control system;enterprise system;graphical user interface;internet;java;loopback;multithreading (computer architecture);proxy server;remote control;server (computing);simulation;system administrator;thread (computing);usability;virtual reality;web cache;web server	Khaled E. A. Negm;Mariam A. Al-Aly	2005			enterprise system;world wide web;computer science;systems architecture;concurrency control;proxy server;cache algorithms;database;proxy pattern;remote control	OS	-31.26598195923385	44.19178249957344	184341
80a531e38c1d28f7c796c34a8efc61614190bf3f	time and exceptional behavior in multiparty structured interactions	meaningful model;conversation calculus;multiparty structured interaction;conversation abortion;exceptional behavior;explicit signal;multiparty interaction;structured communication;healthcare scenario;compelling example	The Conversation Calculus (CC) is a model of multiparty interactions which extends the π-calculus with the notion of conversation—a possibly distributed medium in which participants may communicate. Here we study the interplay of time and exceptional behavior for models of structured communications based on conversations. We propose C3, a timed variant of the CC in which conversations feature both standard and exceptional behavior. The exceptional behavior may be triggered either by the passing of time (a timeout) or by an explicit signal for conversation abortion. By presenting a compelling example from a healthcare scenario, we argue that the combination of time and exceptional behavior leads to more meaningful models of structured communications.	interaction;left 4 dead 2;timeout (computing)	Hugo A. López;Jorge A. Pérez	2011		10.1007/978-3-642-29834-9_5	simulation;computer science;artificial intelligence	ECom	-29.57131945546488	32.85848523030444	184480
89934a56c2b408d7ccd48300865ccc4613782ca6	static analysis of run-time errors in embedded critical parallel c programs	sequential consistency;mutual exclusion;run time errors;dynamic memory allocation;static analysis;abstract interpretation;parallel programs	We present a static analysis by Abstract Interpretation to check for run-time errors in parallel C programs. Following our work on Astrée, we focus on embedded critical programs without recursion nor dynamic memory allocation, but extend the analysis to a static set of threads. Our method iterates a slightly modified non-parallel analysis over each thread in turn, until thread interferences stabilize. We prove the soundness of the method with respect to a sequential consistent semantics and a reasonable weakly consistent memory semantics. We then show how to take into account mutual exclusion and thread priorities through partitioning over the scheduler state. We present preliminary experimental results analyzing a real program with our prototype, Thésée, and demonstrate the scalability of our approach.	acm sigact;abstract interpretation;acta informatica;astrée (static analysis);computer programming;concurrency (computer science);consistency model;correctness (computer science);david gries;deadlock;denotational semantics;distributed computing;embedded c;embedded system;forward error correction;higher-order and symbolic computation;interference (communication);java memory model;lecture notes in computer science;list of code lyoko characters;lock (computer science);memory management;memory semantics (computing);model checking;monitor (synchronization);multiprocessing;mutual exclusion;operational semantics;parallel computing;priority inversion;program analysis;prototype;real-time clock;recursion;scalability;scheduling (computing);shared variables;shared memory;software engineering;springer (tank);unified parallel c (upc);weak consistency	Antoine Miné	2011		10.1007/978-3-642-19718-5_21	parallel computing;real-time computing;mutual exclusion;computer science;static memory allocation;distributed computing;c dynamic memory allocation;programming language;static analysis;sequential consistency	PL	-22.271042419832987	32.38180403453888	184716
d0c7d71fbb4c1398833bb0e6e83ad4d57ad94e00	open source meets venture capital	vendor portfolio venture capital open source code server based configuration spikesource company open source development house java application server;venture capital linux web server law legal factors maintenance investments java portfolios marketing and sales;venture capital open source;open source development;application server;venture capital;java venture capital open systems public domain software;public domain software;open systems;san francisco;venture capitalist;java;open source	Long-established vendors such as IBM and Novell have announced or strengthened their open source offerings from the data server to the desktop, sometimes offering and supporting certified versions of open source applications, sometimes using open source code in new server-based configurations that let customers choose specific functionalities per user. New companies such as SpikeSource, a San Francisco-based startup offering integrated, validated, and certified open source stacks with ongoing maintenance and support services, are convincing venture capitalists the open source stack is a viable investment. Open source development houses themselves are being recognized for delivering standalone best-of-breed technology - such as the Java application server JBoss - or as valuable acquisitions in a larger vendor's portfolio.	desktop computer;distributed computing;java;open-source software;server (computing);websphere application server community edition;wildfly	Greg Goth	2005	IEEE Distributed Systems Online	10.1109/MDSO.2005.33	venture capital;computer science;operating system;programming language;world wide web	SE	-32.9500482666585	42.2781971106948	184996
cb69c120ef9e4a07a183f9cb933ef59a16f56f36	brief announcement: early decision despite general process omission failures	distributed consensus;sectional faults	In the consensus problem, each process proposes a value and the non-faulty processes have to decide (termination) on the same value (agreement) that has to be one of the proposed values (validity). Two versions of the consensus problem are usually distinguished. They differ in the statement of the agreement property. In the non-uniform version (consensus), agreement is only required on the non-faulty processes (this means that faulty processes are allowed to decide values different from the value decided by the nonfaulty processes). In the uniform version (uniform consensus), agreement concerns all the processes that decide, no two processes (be them faulty or not) can decide differently. Synchronous systems provide upper bounds on processing time and communication delays. Those bounds allow consensus problems to be solved. Basically, a distributed synchronous consensus protocol proceeds by successive rounds. During each round the processes exchange values until they attain a round during which they can conclude that they have converged to the same value. Consensus protocols in synchronous systems are characterized by the failure model they address~ the maximal number of processes they allow to be faulty, and the maximal number of rounds they need to attain a decision. Three failure models have been investigated: the crash model where processes can fail by prematurely halting, the omission model where processes can fail by halting or omitting to send or receive messages they should, and the Byzantine model where processes can fail by exhibiting arbitrary behavior. These failure models are of increasing severity. Let n and t denote the total number of processes and the maximum number of processes that can be faulty, respectively. We have: • Crash failure model: both consensus and uniform consensus can be solved for any value of t (i.e., for t < n), • Omission failure model: consensus can be solved for any t, while uniform consensus requires t < n/2, • Byzantine failure model: consensus can be solved provided that t < n/3. (Uniform consensus is meaningless in that model.) It has been shown that t + 1 is a lower bound on the	byzantine fault tolerance;consensus (computer science);maximal set;uniform consensus	Fabrice Le Fessant;Philippe Raipin Parvédy;Michel Raynal	2003		10.1145/872035.872068	real-time computing;consensus;computer science;distributed computing;computer security	Theory	-21.897161353649647	44.353322437690785	185209
922be46e7e18b4358ed9b6bc1df2f9c99e758904	modelling the performance of large-scale systems	alphaserver system;modelizacion;static analysis large scale systems performance modelling software maintenance hardware maintenance performance verification system installation asci q supercomputers earth simulator alphaserver system;distributed system;parallel machines performance evaluation geophysics computing digital simulation program diagnostics;evaluation performance;tecnologia electronica telecomunicaciones;systeme reparti;computacion informatica;systeme grande taille;performance evaluation;asci q;calculateur;software maintenance;earth;evaluacion prestacion;hardware maintenance;calculadora;calculator;large scale system;terre;simulator;modelisation;performance verification;sistema repartido;simulador;ciencias basicas y experimentales;simulateur;system installation;tecnologias;static analysis;earth simulator;tierra;modeling;large scale systems performance modelling;supercomputers;sistema gran escala	Performance modelling can be used throughout the development, deployment and maintenance of system hardware and application software. In this work the authors illustrate three uses of performance modelling on large-scale systems: the verification of performance during system installation, the comparison of two large-scale systems, and the prediction of performance on possible future architectures. They detail how a performance model gave an expectation of the performance of ASCI Q, a 20Tflop system recently installed at Los Alamos. A comparison between ASCI Q and the Earth Simulator is also detailed, resulting in the sizing of an AlphaServer system that has the same performance as the Earth Simulator. The modelling approach is application centric. A detailed model is developed for each application of interest based on a static analysis of the code but parametrised in terms of its dynamic behaviour.		Darren J. Kerbyson;Adolfy Hoisie;Harvey J. Wasserman	2003	IEE Proceedings - Software	10.1049/ip-sen:20030808	tierra;embedded system;simulation;systems modeling;computer science;engineering;operating system;software engineering;earth;software maintenance;static analysis	HPC	-19.764626787535917	41.92664785736496	185229
3a2df802b68c1d1464d442cb1ec973ef93ce69a0	"""concurrent control with """"readers"""" and """"writers"""""""	mutual exclusion;shared access to resources;critical section	The problem of the mutual exclusion of several independent processes from simultaneous access to a “critical section” is discussed for the case where there are two distinct classes of processes known as “readers” and “writers.” The “readers” may share the section with each other, but the “writers” must have exclusive access. Two solutions are presented: one for the case where we wish minimum delay for the readers; the other for the case where we wish writing to take place as early as possible.	critical section;mutual exclusion	Pierre-Jacques Courtois;F. Heymans;David Lorge Parnas	1971	Commun. ACM	10.1145/362759.362813	mutual exclusion;computer science;distributed computing;critical section;programming language;world wide web	Theory	-20.960985433215463	45.72346827414889	185358
0ff03d7e2bd54df6adf66669ea0b8628fd6b7178	real-time support in com	standards;real time;electrical capacitance tomography chemical technology distributed control control systems costs process control electronic switching systems operating systems prototypes proposals;real time operating system;distributed object management;component object model real time support distributed heterogeneous environment corba com policy specification interface real time com real time operating systems heterogeneous object oriented distributed systems inter operability;real time application;operating systems computers;operating systems computers distributed object management standards real time systems;real time corba;real time systems	While there has been substantial work on real-tim CORBA — to offer real-time support in a distributed hete geneous environment with standard real-time middle-wa comparatively less work has been done to investigate s port for real-time applications in COM, the direct compe tor of CORBA. In this paper, we examine the COM techn ogy and explore the possibility of providing real-time su port in COM. We argue that real-time COM should pr vide a policy specification interface between the appli tion and the underlying (real-time) operating systems t is as declarative as possible, and we conclude that C can be extended to provide various real-time support s vices through this interface. We shall discuss an experim tal prototype targeted for real applications along the line our proposal.	central processing unit;common object request broker architecture;experiment;microsoft windows;operating system;prototype;real-time clock;real-time computing;real-time transcription;resources, events, agents (accounting model);tor messenger;windows nt;wintel	Deji Chen;Aloysius K. Mok;Mark Nixon	1999		10.1109/HICSS.1999.772819	embedded system;real-time computing;real-time operating system;service interface for real time information;computer science;operating system;distributed computing	Embedded	-33.60102599781253	38.967506886568664	185488
b96305475f086514e80ef84100fce9203686dd1b	principles of design in the octopus computer network	design principle;computer performance evaluation;computer network;software event monitor;network connectivity;operating systems	The concepts and methods are reviewed which have proven to be of the most value in designing and implementing the Octopus computer network, which is one of the largest concentrations of computing capability in the world. The discussion summarizes design principles relating to the scope of system software, privacy and security, processor organization, file structure, network connections, hardware selection, programming techniques, standards, and use of resources. Differences with what appear to be widespread belief and practice are cited, including such matters as the size of the programmer staff, the significance of the privacy issue, the importance of the choice of languages and language constructions, the primary causes of system failure, and efficiency.	computer security;programmer	John G. Fletcher	1975		10.1145/800181.810357	computing;simulation;intelligent computer network;computer science;theoretical computer science;network security;network simulation;computer network programming	Arch	-26.129013010375488	44.94789126609344	185511
11d01cbdd90177c882bfa029879c48d0cbd3a4a9	principles of verifiable rtl design - a functional coding style supporting verification processes in verilog			32-bit;8-bit;and gate;apriori algorithm;assertion (software development);asynchronous circuit;black box;boolean algebra;boolean satisfiability problem;cmos;care-of address;clock rate;cobham's thesis;combinational logic;communications protocol;compiler;deadlock;declaration (computer programming);design flow (eda);device driver;emoticon;encapsulation (networking);event-driven programming;experiment;fifo (computing and electronics);failure analysis;failure cause;failure rate;fastest;feedback;finite-state machine;formal equivalence checking;formal language;formal methods;formal verification;gate count;gate equivalent;generic eclipse modeling system;hardware random number generator;hypervisor;inline expansion;inversion (discrete mathematics);level design;library (computing);limbo;lint (software);logic simulation;mean time between failures;model checking;modular programming;multiplexer;norm (social);one-hot;pp (complexity);period-doubling bifurcation;petri net;problem domain;procedural programming;programming language;programming style;reachability;register file;register-transfer level;regular language;requirement;resultant;run time (program lifecycle phase);semantics (computer science);sensor;software bug;software testability;software testing;state logic;static timing analysis;surround sound;switch statement;synchronizing word;synchronous circuit;systems design;test vector;thinking outside the box;three-state bus;three-state logic;time complexity;timing closure;transistor;triangular function;turing completeness;type rule;verilog	Lionel Bening;Harry Foster	2001				Logic	-29.747619950796093	34.92895730316175	185541
81442c96aac721879026ea45f1d1e3fd2d29a549	predicate detection in asynchronous pervasive environments	distributed system;distributed system sensor networks predicate detection pervasive computing middleware strobe clocks;protocols;logical time modality predicate detection asynchronous pervasive environment sensor network software logical clock middleware scalar strobe clock vector strobe clock resource constrained environment time complexity conjunctive predicate physical time modality;clocks;pervasive computing;accuracy;clocks vectors synchronization accuracy protocols approximation methods equations;vectors;sensor networks;computational complexity;wireless sensor networks computational complexity middleware ubiquitous computing;synchronization;strobe clocks;predicate detection;ubiquitous computing;middleware;approximation methods;wireless sensor networks	An important task in sensor networks is to sense locally to detect global properties that hold at some instant in physical time, namely, Instantaneously. We propose software logical clocks, called strobe clocks, that can be implemented by the middleware when synchronized physical clocks are not available or are too expensive in resource-constrained environments. Strobe clocks come in two flavors--scalar and vector. Let (n) be the number of sensors and (p) be the upper bound on the number of relevant events sensed at a sensor. We propose an algorithm using vector strobes that can detect all occurrences of a conjunctive predicate in time (O(n3p)). The algorithm has some false negatives but this is the best achievable accuracy in the face of race conditions. We also present a variant algorithm using scalar strobes; it needs time (O(n2p)) but may also suffer from some false positives. We provide a characterization of the errors. Both algorithms can also detect relational predicates but with a greater chance of error. The message complexity of strobe clocks (scalar and vector) and both algorithms is (O(np)), which is the same as that of reporting each sensed event for detection of the predicate even with synchronized physical clocks. We formalize the physical time modality, Instantaneously, and show its relationship to the logical time modalities Definitely and Possibly.	algorithm;logical clock;middleware;modality (human–computer interaction);race condition;sensor	Ajay D. Kshemkalyani;Jiannong Cao	2013	IEEE Transactions on Computers	10.1109/TC.2012.162	embedded system;parallel computing;real-time computing;wireless sensor network;computer science;theoretical computer science;operating system;distributed computing;ubiquitous computing;algorithm	Embedded	-23.451472705530357	43.041264846154235	185571
e153684b428232c65f7700bba8024de992768b66	ajax applied in environment monitoring system based on wsn	ajax;ajax environment monitoring system wireless sensor network page refresh speed;page refresh speed;refresh;wsn;environment monitoring system;b s;wireless sensor network;data analysis;monitoring system;servers;monitoring wireless sensor networks web server data analysis search engines xml user interfaces wireless application protocol internet java;internet;engines;monitoring;wireless sensor networks computerised monitoring data analysis;xml;computerised monitoring;security;refresh ajax wsn b s;wireless sensor networks	This article puts forward a method to access the data and analyzed results from the monitoring system of environment based on WSN with the B/S mode. It resolves the problem of low speed of page refresh with Ajax. The experiment shows that the partial refresh feature of Ajax can make it possible for the users to get access to the data and analyzed results easily through the browser, and experience a smarter response just like window programs.	ajax (programming);information system;performance	Wei Han;Kang-ling Fang;Xiaohui Li;Liang Zhang	2008	2008 International Symposium on Computer Science and Computational Technology	10.1109/ISCSCT.2008.327	ajax;embedded system;real-time computing;computer science;world wide web	Arch	-31.776860416734124	41.75448595183439	185749
b79a84c4df84d504ffb053b00e119b03c698c4ac	detecting termination of distributed computations using markers	termination detection;distributed computing;process network;role;script;enrollment	A problem of considerable importance in designing computations by process networks, is detection of termination. We propose a very simple algorithm for termination detection in an arbitrary network using a single marker We show an application of this scheme in solving the problem of token loss detection and token regeneration in a token ring.	algorithm;computation;distributed computing;kahn process networks;token ring	Jayadev Misra	1983		10.1145/800221.806729	real-time computing;computer science;theoretical computer science;role;distributed computing;suzuki-kasami algorithm	Security	-21.32114674331891	43.29233451010264	185778
c9f8b7b0251fb04785fe72987738fac5eb5a10b3	tactics for minimal interference from class loading in real-time java™	class load;refactoring;reduction;real time;precompilation;optimization;java	Class loading within a Java#8482; virtual machine can result in undesirable long interruptions, preventing real-time deterministic behaviour. Development of real-time software tasks and applications may call for constraints and fine-tuned control of the class loading activity within the virtual machine when running time-sensitive applications. This paper presents various alternative approaches aimed towards reducing the burden of class loading in a real-time Java VM, all of which avoid revisiting the application design.  Amongst these alternatives is a novel class flow analysis algorithm allowing for the elimination of unused items in an application, a novel bytecode alteration technique for reducing class loads induced by the Java verifier, a novel class file splitting technique for more distributed class loading behaviour, and various other technologies that are available to achieve better performance and more precise control of class loading in real-time Java applications.	algorithm;data-flow analysis;interference (communication);java platform, enterprise edition;real time java;real-time locating system;real-time transcription;time complexity;virtual machine	Sean Foley	2007		10.1145/1288940.1288944	embedded system;real-time computing;reduction;computer science;operating system;distributed computing;programming language;java;code refactoring	Embedded	-22.504663210202544	32.60927518868967	185985
edbf1549dc0e8800d109666813d664575b69b319	build an operating system from scratch: a project for an introductory operating systems course	operating system;file system;data structure;operating systems	This paper describes a semester project where students design an operating system from the ground-up, capable of booting from a floppy disk on an actual machine. Unlike previous projects of this kind, this project was designed for students with only one semester of programming experience and no prior exposure to data structures, assembly language, or computer organization. Students nevertheless wrote a full system consisting of system calls, program execution, a file system, a command-line shell, and support for multiprocessing. The project was assigned to a class and successfully completed by nearly every student.	assembly language;booting;command-line interface;data structure;floppy disk;microarchitecture;multiprocessing;operating system;system call	Michael D. Black	2009		10.1145/1508865.1509022	real-time computing;data structure;computer hardware;computer science;operating system;software engineering	OS	-25.89984712961137	38.65457949458361	186010
62c541f70e958a2559367b2e0d8679acf42318c7	self-stabilizing and private distributed shared atomic memory in seldomly fair message passing networks		We study the problem of privately emulating shared memory in message-passing networks. The system includes clients that store and retrieve replicated information on N servers, out of which e are malicious. When a client access a malicious server, the data field of that server response might be different than the value it originally stored. However, all other control variables in the server reply and protocol actions are according to the server algorithm. For the coded atomic storage (CAS) algorithms by Cadambe et al., we present an enhancement that ensures no information leakage and malicious fault-tolerance. We also consider recovery after the occurrence of transient faults that violate the assumptions according to which the system is to behave. After their last occurrence, transient faults leave the system in an arbitrary state (while the program code stays intact). We present a self-stabilizing algorithm, which recovers after the occurrence of transient faults. This addition to Cadambe et al. considers asynchronous settings as long as no transient faults occur. The recovery from transient faults that bring the system counters (close) to their maximal values may include the use of a global reset procedure, which requires the system run to be controlled by a fair scheduler. After the recovery period, the safety properties are provided for asynchronous system runs that are not necessarily controlled by fair schedulers. Since the recovery period is bounded and the occurrence of transient faults is extremely rare, we call this design criteria self-stabilization in the presence of seldom fairness. Our selfstabilizing algorithm uses a bounded amount of storage during asynchronous executions (that are not necessarily controlled by fair schedulers). To the best of our knowledge, we are the first to address privacy, malicious behavior and self-stabilization in the context of emulating atomic shared memory in message-passing systems.	algorithm;asynchronous system;emulator;fair queuing;fairness measure;fault tolerance;information leakage;malware;maximal set;message passing;scheduling (computing);self-stabilization;server (computing);shared memory;spectral leakage	Shlomi Dolev;Thomas Petig;Elad Michael Schiller	2018	CoRR		message passing;distributed computing;real-time computing;data field;asynchronous system;bounded function;information leakage;asynchronous communication;computer science;server;shared memory	Metrics	-21.89022270308569	45.0655310123596	186165
00d97c7fcfd8e16ffc74535dbd4d9a51385ab9f9	generalised interfacing with microprocessor system hardware monitors	sysctl hardware sensors;openbsd;performance evaluation;hardware monitors microprocessor system openbsd sysctl hardware sensors;microprocessor system;performance evaluation microcomputers;microcomputers;hardware monitors;microprocessors hardware instruction sets monitoring fans open source software control systems energy consumption semiconductor device noise computer displays	In this paper, we will discuss the possibilities, functionalities and limitations of Microprocessor System Hardware Monitors. We will provide a comparison survey of their main functions, depict some weaknesses and give an overview of what possibilities they provide for the end-user. We will also discuss OpenBSD's sysctl Hardware Sensors framework, and describe our recent contributions to the addressing scheme and underpinnings of the framework.	atx;addressing scheme;application programming interface;bsd;common gateway interface;computer science;concurrent versions system;datasheet;device driver;environment (systems);microprocessor;netbsd;norm (social);openbsd journal;patch (computing);programmer;sensor;slashdot;speedfan;sysctl;system monitor;system monitoring;workstation	Constantine A. Murenin	2007	2007 IEEE International Conference on Networking, Sensing and Control	10.1109/ICNSC.2007.372901	hardware compatibility list;embedded system;real-time computing;computer hardware;computer science;operating system;microcomputer	Robotics	-31.078919914800306	41.741389525482106	186227
b1d00c45f19803557fd2ddd1726eeef05ad8e831	automatic effective verification method for distributed and concurrent systems using timed language inclusion	alternating bit;concurrent system;automatic effective verification method;verification system;clock variable;language inclusion;proposed specification method;finite set;certain hard real-time constraint;verification method;fair schedulers;actual value;timing constraint;fairness abstract;distributed systems;formal verification;automata;computer science;distributed processing;timed automaton;protocols;algebra;formal specification;distributed system;automata theory	In distributed and concurrent systems, the notions of fairness and time are important as follows: (1)Fairness is a mathematical abstraction in distributed and concurrent systems. Fairness abstracts the details of fair schedulers and the speeds of independent processors. (2)The distributed and concurrent systems have to meet certain hard real-time constraints, and the correctness of them depends on the actual values of the delays.In this paper, we propose the specification and verification method of fairness and time in distributed and concurrent systems as follows: (1)In order to specify fairness, an enable condition and a performed condition are attached to a finite set of states in our proposed specification method. (2)In order to effectively verify distributed and concurrent systems, we restrict timing constraints of timed automaton such that in cycles we must specify timing constraints about the clock variables after they are reset to zero.	concurrency (computer science)	Satoshi Yamane	1998	Scalable Computing: Practice and Experience		real-time computing;computer science;theoretical computer science;distributed computing	SE	-25.721298798739493	34.122912713486386	186449
b48582aadeaee5b51968813575cf65fc73d10058	is the web ready for in-car infotainment? a framework for browser performance tests suited for embedded vehicle hardware	databases;in car infotainment systems;performance evaluation;local storage functionality in car infotainment browser performance test web application pc smartphone tablet in vehicle infotainment system ivi system javascript embedded vehicle hardware;benchmark testing browsers databases engines vehicles hardware performance evaluation;javascript benchmark;in car infotainment systems web applications performance evaluation javascript benchmark embedded systems;telecommunication computing;telecommunication computing embedded systems entertainment internet java on board communications online front ends;browsers;web applications;online front ends;embedded systems;internet;engines;vehicles;entertainment;benchmark testing;on board communications;hardware;java	After Web applications have successfully found their way to PCs, smartphones and tablets, they are on the verge to be used on in-vehicle infotainment (IVI) systems. One of the often claimed drawbacks of Web applications is their low performance in conjunction with limited resources. We have created a benchmark framework to evaluate the performance of JavaScript in comparison to native code. The framework is designed to take the resource constraints of IVI systems into account. We conclude that general calculation tasks in JavaScript are on the average two to four times slower than native compiled counterparts on embedded vehicle hardware. The factor is independent from the allowed resource limits for each calculation. Using new features for Web applications (e.g. local storage functionality) or making frequent use of recursions there is a significant performance drop in JavaScript. In these cases native code runs up to 10 times faster than their counterparts in JavaScript.	benchmark (computing);compiler;embedded system;javascript;machine code;recursion;smartphone;the verge;thread-local storage;web application;world wide web	Simon Isenberg;Matthias Goebl;Uwe Baumgarten	2012	2012 14th IEEE International Symposium on Web Systems Evolution (WSE)	10.1109/WSE.2012.6320530	embedded system;benchmark;entertainment;web application;real-time computing;the internet;computer science;unobtrusive javascript;operating system;database;programming language;java;world wide web	Arch	-20.961072463267506	36.96574803999578	186522
ed12b502bc74c2c37d429430b0cefa3feb8ffbf3	automatic transaction compensation for reliable grid applications	grid applications;service orientation;automatic generation;grid service;scientific computing;grid computing	As grid technology is expanding from scientific computing to business applications, service oriented grid computing is aimed at providing reliable services for users and hiding complexity of service processes from them. The grid services for coordinating long-lived transactions that occur in business applications play an important role in reliable grid applications. In this paper, the grid transaction service (GridTS) is proposed for dealing with long-lived business transactions. We present a compensation-based long-lived transaction coordination algorithm that enables users to select results from committed sub-transactions. Unlike other long-lived transaction models that require application programmers to develop corresponding compensating transactions, GridTS can automatically generate compensating transactions on execution of a long-lived grid transaction. The simulation result has demonstrated the feasibility of GridTS and effectiveness of the corresponding algorithm.	algorithm;computational science;grid computing;long-lived transaction;programmer;simulation	Feilong Tang;Minglu Li;Joshua Zhexue Huang	2006	Journal of Computer Science and Technology	10.1007/s11390-006-0529-3	grid file;real-time computing;transaction processing;semantic grid;distributed transaction;computer science;database;distributed computing;online transaction processing;compensating transaction;transaction processing system;drmaa;grid computing	HPC	-31.72344685635224	44.888632257368066	186745
7fa50abf991b4b55b0ce7ee3bbd5e794e801cb44	a fully abstract model of fair asynchrony	abstract model;fair asynchrony	Without Abstract	asynchrony (computer programming);denotational semantics	Philippe Darondeau	1984		10.1007/3-540-15670-4_21	real-time computing	Crypto	-27.65035153772581	33.26668189020761	187050
