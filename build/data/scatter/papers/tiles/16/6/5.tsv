id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
36d939432f0a5e3d53afb96f25191bf3dc1f4a40	visualization and interaction techniques for node-link diagram editing and exploration			diagram;interaction technique;molecule editor	Mathias Frisch	2012				HCI	-33.66448045606971	-32.34142809580391	58048
e5b7ec891e63dab4effa549af5cf9c195abe2af7	connected motorized riders — a smart mobility system to connect two and three-wheelers		The Smart Cities Mission has been launched in India in 2015 to develop 100 cities, with smart mobility being one of the main topics in the mission. As urban areas are flooded with two (motorcycles) and three wheelers (auto-rickshaws), introducing smart control of such vehicles may reduce the congestions on the roads and the number of accidents. Indeed, over-speeding and drunken driving are common traffic violations. In this project we propose an IoT-based smart mobility system which tracks data, such as the vehicle location, vehicle speed, alcohol level of the driver, etc. efficiently over the internet. Our system has been conceived with CPAL, a high-level language meant to simulate and execute Cyber Physical Systems including IoT applications. A prototype running on ARM mbed IoT hardware, shows the feasibility of our concept. We believe that more efficient and interactive traffic management, more disciplined driving behaviors, reduction in accident rate, more controlled pollution, increased passenger safety can be achieved if systems like the one prototyped in this work deployed contributing to smarter cities.	behavior;contribution;drug vehicle;drunk driving;ethanol;floods;high- and low-level;high-level programming language;internet;motorcycles;prototype;simulation;smart city;speed (motion);track (course);mbed	Sakthivel Manikandan Sundharam;Loic Fejoz;Nicolas Navet	2016	2016 Sixth International Symposium on Embedded Computing and System Design (ISED)	10.1109/ISED.2016.7977110	launched;cyber-physical system;the internet;computer security;alcohol level;engineering;internet of things	Mobile	-20.49299166053837	-27.7566258828467	58365
a0a1802a473220b7c3e8415f564c2b2055afadfc	optical graph edge recognition		Optical graph recognition is a process that from an input raster image extracts a graph topology. Graph recognition is interesting for not only because it allows reusing information from other diagrams, but also it is a tool that can measure the readability of a graph diagram visualisation or help with a testing of automatic graph visualisation engines. In this paper, we propose an optical graph edge recognition algorithm that can recognise edges with arbitrary edge routing style, handle drawings with many edge crossings and process edges that are rendered as polylines using a solid or dashed stroke. To evaluate the proposed algorithm we have developed comprehensive test suite with 2400 graphs of various sizes, edge densities, edge routing styles and edge rendering strokes.	algorithm;biological network;diagram;dijkstra's algorithm;force-directed graph drawing;raster graphics;router (computing);routing;solid edge;test case;test suite;thickness (graph theory);time complexity;topological graph theory	Rudolfs Opmanis	2018		10.5220/0006550401840191	graph edge;computer vision;computer science;artificial intelligence	Graphics	-29.446548261265477	-35.82171390570252	58734
6db3a43155465de4b62e3befedc9ec688259a92b	visualizing flow data using assorted glyphs	multidimensional data;visualization technique;flow field	This project visualizes a scientific dataset containing two-dimensional flow data from a simulated supernova collapse provided by astrophysics researchers. We started our project by designing visualizations using multiple hand drawings representing the flow data without taking into consideration the implementation constraints of our designs. We implemented a few of our hand drawn designs. We used an assortment of simple geometric graphical objects, called glyphs, such as, dots, lines, arrows, and triangles to represent the flow at each sample point. We also incorporated transparency in our visualizations. We identified two important goals for our project: (1) design different types of graphical glyphs to support flexibility in their placement and in their ability to represent multidimensional data elements, and (2) build an effective visualization technique that uses glyphs to represent the two-dimensional flow field.	glyph;graphical user interface;wave function collapse	Amit P. Sawant;Christopher G. Healey	2007	ACM Crossroads	10.1145/1373596.1373599	simulation;computer science;artificial intelligence;theoretical computer science;world wide web	Visualization	-28.642050497125265	-32.45073002968846	58935
a55b14229b323c46ba7cab2a7eafda6fd5dc323a	evolving levels for super mario bros using grammatical evolution	grammar;generators;evolutionary computation;linearity;feature extraction;games;generators grammar games linearity electron tubes humans feature extraction;humans;assistive tool super mario bros grammatical evolution design grammars playable 2d platform levels ge based level generator;computer games;electron tubes;evolutionary computation computer games	This paper presents the use of design grammars to evolve playable 2D platform levels through grammatical evolution (GE). Representing levels using design grammars allows simple encoding of important level design constraints, and allows remarkably compact descriptions of large spaces of levels. The expressive range of the GE-based level generator is analyzed and quantitatively compared to other feature-based and the original level generators by means of aesthetic and similarity based measures. The analysis reveals strengths and shortcomings of each generator and provides a general framework for comparing content generated by different generators. The approach presented can be used as an assistive tool by game designers to compare and analyze generators' capabilities within the same game genre.	grammatical evolution;level design;procedural generation;samegame;software design	Noor Shaker;Miguel Nicolau;Georgios N. Yannakakis;Julian Togelius;Michael O'Neill	2012	2012 IEEE Conference on Computational Intelligence and Games (CIG)	10.1109/CIG.2012.6374170	games;simulation;feature extraction;computer science;artificial intelligence;machine learning;grammar;linearity;algorithm;evolutionary computation	AI	-27.49866174145544	-25.775565322366855	58996
f7e91d22f69914cd1a7211065678ad4d72210a7f	comparing relations with a multi-holed region	relational model;topological relation	Relation models have treated multi-holed regions relations either the same as hole-free regions relations, loosing this way the peculiarities of the holed topology, or with methods dependent on the number of holes. This paper discusses a model of relations between a hole-free and a multi-holed region that departs from past approaches by using the frequencies of the relations in which the holes participate to summarize the relation. The model is independent of the number of holes and builds on the 23 topological relations between a hole-free and a singleholed region. With the help of a balanced algorithm the relation model is used in a method that compares relations for their topological similarity, by computing the cost of transforming one relation into the other. The placement of the holes in relation to the hole-free region is found to be of same importance as the placement of the host of the holes, for similarity comparisons.	algorithm;cartographic generalization;design rationale;finite difference method;norm (social);real life;semantic similarity	Maria Vasardani;Max J. Egenhofer	2009		10.1007/978-3-642-03832-7_10	discrete mathematics;relational model;topology;computer science;mathematics;geometry	NLP	-24.97042726982265	-29.08014804923451	59504
04ff3489f268bcb50913be788bf619dc64e63e7c	cross-table linking and brushing: interactive visual analysis of multiple tabular data sets		Studying complex problems often requires identifying and exploring connections and dependencies among several, seemingly unrelated, data sets. Those data sets are often represented as data tables. We propose a novel approach to studying such data sets using linking and brushing across multiple data tables in a coordinated multiple views system. We first identify possible mappings from a subset of one data set to a subset of another data set. That collection of mappings is then used to specify linking among data sets and to support brushing across data sets. Brushing in one data set is then mapped to a brush in the destination data set. If the brush is refined in the destination data set, the inverse mapping, or a back-link, is used to determine the refined brush in the original data set. Brushing and back-links make it possible to efficiently create and analyze complex queries interactively in an iterative process. That process is further supported by a user interface that keeps track of the mappings, links and brushes. The proposed approach is evaluated using three data sets.	backlink;brushing and linking;color-coding;data compression;interactive visual analysis;interactivity;iteration;relational algebra;semantics (computer science);systemic functional grammar;table (information);usability testing;user interface	Rainer Splechtna;Michael Beham;Denis Gracanin;Maria Luján Ganuza;Katja Bühler;Igor S. Pandzic;Kresimir Matkovic	2018	The Visual Computer	10.1007/s00371-018-1516-8	interactive visual analysis;computer vision;computer science;table (information);machine learning;visual analytics;iterative and incremental development;data set;artificial intelligence;user interface	ML	-29.478932825829403	-33.892315768294566	59779
37d6eaadcfeb6a65cfcb1e55171405f11504e772	visualizing categorical data: an introduction to correspondence analysis for technical communication researchers	quantitative research;xlstat visualizing categorical data correspondence analysis technical communication researcher descriptive statistics contingency table advanced statistical technique categorical data set;technical communication research correspondence analysis data visualization quantitative research;data visualization writing visualization tutorials market research spreadsheet programs;correspondence analysis;data visualization;statistical analysis data visualisation;technical communication research	Technical communication researchers often collect categorical, or non-numerical, data. However, when analyzing this type of data, researchers are typically limited to reporting descriptive statistics or simple contingency tables. One advanced statistical technique that allows researchers to more powerfully explore complex categorical data sets is correspondence analysis. This article will first define correspondence analysis and then walk through a tutorial for conducting correspondence analysis in XLSTAT.	categorical variable;certificate authority;contingency table;correspondence analysis;lam/mpi;numerical analysis;variable (computer science)	Chris Lam	2014	2014 IEEE International Professional Communication Conference (IPCC)	10.1109/IPCC.2014.7020345	quantitative research;computer science;data science;data mining;correspondence analysis;data visualization;statistics	Visualization	-26.64920109653259	-32.15907590722931	60421
34d037569452d3a0520fc27720190fb1bc8420a7	uncovering the spatio-temporal structure of social networks using cell phone records	social network services;gravity model;mobility management mobile radio;poles and towers;cdr;probability;social network services cellular phones probability distribution poles and towers humans gravity cities and towns;gravity;social aspects of automation;human mobility;spatial distribution spatio temporal structure uncovering cell phone records human mobility data accessing complexity social interactions spatiotemporal feature extraction large scale dataset social network structure;computational complexity;social networks;feature extraction;probability distribution;social networking online;spatiotemporal phenomena;cities and towns;humans;spatiotemporal phenomena computational complexity feature extraction mobile computing mobility management mobile radio probability social aspects of automation social networking online;mobile computing;gravity model human mobility social networks cdr;cellular phones	Although research in the areas of human mobility and social networks is extensive, our knowledge of the relationship between the mobility and the social network of an individual is very limited, mainly due to the complexity of accessing adequate data to be able to capture both mobility and social interactions. In this paper we present and characterize some of the spatio-temporal features of social networks extracted from a large-scale dataset of cell phone records. Our goal is to measure to which extent individual mobility shapes the characteristics of a social network. Our results show a nontrivial dependence between social network structure and the spatial distribution of its elements. Additionally, we quantify with detail the probability of a contact to be at a certain distance, and find that it may be described in the framework of gravity models, with different decaying rates for urban and interurban scales.	individual mobility;interaction;mobile phone;social network	Luis Gregorio Moyano;Oscar R. Moll Thomae;Enrique Frías-Martínez	2012	2012 IEEE 12th International Conference on Data Mining Workshops	10.1109/ICDMW.2012.132	probability distribution;simulation;gravity;gravity model of trade;feature extraction;computer science;dynamic network analysis;probability;data mining;computational complexity theory;mobile computing;statistics;social network	DB	-19.120035584598845	-35.60826342952325	61094
294a8d5108d9c486c4e266882c3798fa7911ca21	visualizing a sequence of a thousand graphs (or even more)		The visualization of dynamic graphs demands visually encoding at least three major data dimensions: vertices, edges, and time steps. Many of the state-of-the-art techniques can show an overview of vertices and edges but lack a data-scalable visual representation of the time aspect. In this paper, we address the problem of displaying dynamic graphs with a thousand or more time steps. Our proposed interleaved parallel edge splatting technique uses a time-to-space mapping and shows the complete dynamic graph in a static visualization. It provides an overview of all data dimensions, allowing for visually detecting timevarying data patterns; hence, it serves as a starting point for further data exploration. By applying clustering and ordering techniques on the vertices, edge splatting on the links, and a dense time-to-space mapping, our approach becomes visually scalable in all three dynamic graph data dimensions. We illustrate the usefulness of our technique by applying it to call graphs and US domestic flight data with several hundred vertices, several thousand edges, and more than a thousand time steps.	cluster analysis;data structure;diagram;directed graph;eye tracking;forward error correction;graph drawing;interaction technique;preprocessor;scalability;sensor;space mapping;vertex (geometry)	Michael Burch;Marcel Hlawatsch;Daniel Weiskopf	2017	Comput. Graph. Forum	10.1111/cgf.13185	computer science;theoretical computer science;graph	Visualization	-28.74182585969112	-34.94029713420649	61286
349b18d74b4d9b6d235a831daba54ebe958376fa	visualization of industrial engineering data in augmented reality	interaction techniques;scientific visualization;tablet pc;visualization technique;augmented reality;industrial engineering;interaction technique;numerical simulation;open source	This paper presents an innovative application of Augmented Reality (AR) techniques in the field of industrial engineering in which the user explores data from numerical simulations or the results of measurements and experiments, superimposed to the real object that they refer to. The user observes the object through a tablet PC, used as a video see-through handheld display. Data are visualized superimposed to the real object that represents a spatial reference relative to which the user can refer to, so the exploration is more natural compared to a traditional visualization software. Moreover, we have developed a new framework, called VTK4AR, that provides a set of useful software classes for the rapid development of AR applications for scientific visualization. VTK4AR is built on top of VTK (an open source API for scientific visualization), so it will be possible to employ a wide range of visualization techniques in many application fields, and moreover, it is possible to interactively manipulate data-sets in order to achieve a more effective way of visualization.	augmented reality;industrial engineering	Fabio Bruno;Francesco Caruso;Luigi De Napoli;Maurizio Muzzupappa	2006	J. Visualization	10.1007/BF03181679	computer simulation;software visualization;augmented reality;visual analytics;scientific visualization;information visualization;visualization;interactive visualization;human–computer interaction;computer science;multimedia;interaction technique;computer graphics (images)	Visualization	-29.356008607021167	-31.97087013163959	61529
178171ecace5ee8d85033162af2899204cc51200	spatial chromatic model in high-dimensional spaces and the uniqueness of chromatic code: a new perspective of geographic entity-space relationship	dimension;spatial chromatic model;spatial analysis;entity space relationship	The abstraction, representation, and computation of entity–space relationship are keystones of geographic information science (GIS). The newly proposed spatial chromatic tessellation (SCT) provides a novel model to explore this relationship. SCT has demonstrated a variety of potential applications in GIS, such as reasoning spatial topology, point pattern analysis, and Voronoi diagrams. This study aims to theoretically investigate SCT by focusing on two aspects: (1) extending SCT to higher dimensional spaces. Results show that cells missing in lower dimensional spaces are hidden in higher dimensional spaces; (2) exploring the uniqueness of chromatic codes, particularly the chromatic codes of 2-cell and 3-cell clusters: their codes are proved to be unique. In a mathematical perspective, the observed phenomena from the above two aspects bring some new thoughts into the first law of geography and spatial heterogeneity. Based on these new understandings of entity–space relationship, SCT is replaced by spatial chromatic model (SCM) in which spaces are created by entities themselves rather than by partitioning the space preexisted. This makes a change from an absolute geographic space to a relative geographic space.	code;computation;entity;entity–relationship model;geographic information science;pattern recognition;voronoi diagram	Weining Zhu	2015	International Journal of Geographical Information Science	10.1080/13658816.2014.931586	pure mathematics;mathematics;geometry;spatial analysis;dimension;statistics	DB	-25.590501961536738	-29.577993305607606	61534
649d729837772fcad2bfb0113b7a887618d20a71	what has been revealed by urban grid data of shanghai		With the fast-growing economy in the past ten years, cities in China have experience great changes, meanwhile, huge volume of urban grid management data has been recorded. Studies on urban grid management are not common so far. This kind of study is important, however, because the urban grid data describes the individual behaviors and detailed problems in community, and reveals the dynamics of changing policies and social relations. In this article, we did a preliminary study on the urban grid management data of Shanghai, and investigated the key characteristics of the interactions between local government and citizen in such a fast-growing metropolitan. Our investigation illustrates the dynamics of coevolution between economy and living environments. We also developed mathematical model to quantitatively discover the spatial and temporal intra-relations among events found in data, providing insights to local government to fine tune the policy of resource allocation and give proper incentives to drive the coevolution to the optimal state, thereby achieving the good governance.	interaction;mathematical model	Yongkun Wang;Yaohui Jin;Bo Fan	2018	CoRR		knowledge management;local government;grid;china;environmental resource management;social relation;computer science;incentive;resource allocation;corporate governance;metropolitan area	HCI	-20.614862295290024	-36.54715014724508	61676
391a0e465d5b045505c130dae35163f6813f502a	working with patterns in large multivariate datasets - karnaugh-veitch-maps revisited	analytical models;human computer interaction;data categories;computer graphics;interactive visualization;data categories large multivariate datasets karnaugh veitch maps interactive visualization method karnaugh veitch diagrams;layout;data visualisation;data analysis;navigation;feedback;multivariate data analysis;displays;data visualization;large multivariate datasets;visual feedback;pattern analysis;humans;interactive visualization method;karnaugh veitch diagrams;analytical model;karnaugh veitch maps;data visualization pattern analysis displays data analysis humans navigation computer graphics layout feedback analytical models	We present an interactive visualization method for the multivariate analysis of large and complex datasets, based on the layout of Karnaugh-Veitch-diagrams. Working on data categories, we additionally provide an interactive partitioning of value ranges of ordinal types. Multivariate dependencies manifest on the map in characteristic color patterns. These patterns are representations of subsets of the data or attributes which embody significant information. While the task of the user is to identify visual patterns of particular interest to him by clicking on the map, the software identifies a minimal representation of the corresponding subset and gives a visual feedback. Hence, user and machine cooperate on the basis of a strong visual coupling in short iterative cycles. During this process the trade-off between the accuracy and simplicity of a representation, which is crucial for any type of the building of analytical models, can be found in an effective way.	am broadcasting;aggregate data;categorization;coherence (physics);diagram;elemental;embedded system;graph (discrete mathematics);graph drawing;interactive visualization;iteration;iterative method;karnaugh map;mathematical optimization;ordinal data;tree (data structure)	Thorsten May	2007	2007 11th International Conference Information Visualization (IV '07)	10.1109/IV.2007.145	computer science;data science;machine learning;data mining	Visualization	-28.22370484922087	-33.531941831369764	61724
52eea2f3691ea6b12db9c625227829e466b8d5c0	controllable and progressive edge clustering for large networks	relative position;delaunay triangulation;p 180 cluster;information visualization;g 350 clusters;level of detail;clustering method	Node-link diagrams are widely used in information visualization to show relationships among data. However, when the size of data becomes very large, node-link diagrams will become cluttered and visually confusing for users. In this paper, we propose a novel controllable edge clustering method based on Delaunay triangulation to reduce visual clutter for node-link diagrams. Our method uses curves instead of straight lines to represent links and these curves can be grouped together according to their relative positions and directions. We further introduce progressive edge clustering to achieve continuous level-of-details for large networks.	algorithm;cache (computing);cluster analysis;clutter;delaunay triangulation;diagram;information visualization;zelda ii: the adventure of link	Huamin Qu;Hong Zhou;Yingcai Wu	2006		10.1007/978-3-540-70904-6_38	correlation clustering;computer vision;combinatorics;information visualization;delaunay triangulation;theoretical computer science;level of detail;mathematics;geometry;cluster analysis	Vision	-29.03269805183581	-34.748195489941935	61821
3d625ccf7512f280c661af26edd77f575c91847b	visualization, optimization, and business strategy: a case study	three-dimensional visualization;business strategy;information visualization presentation;optimal solution;business strategy;visualization application;visualization capability;benefit tradeoffs;customer service arena;case study;large optimization run;strategic business decision	We describe a visualization application intended for operational use in formulating business strategy in the customer service arena. The visualization capability provided in this application implicitly allows the user to better formulate the objective function for large optimization runs which act to minimize costs based on certain input parameters. Visualization is necessary because many of the inputs to the optimization runs are themselves strategic business decisions which are not pre-ordained. Both information visualization presentations and three-dimensional visualizations are included to help users better understand the cost/benefit tradeoffs of these strategic business decisions. Here, visualization explicitly provides value not possible algorithmically, as the perceived benefit of different combinations of service level does not have an a priori mathematical formulation. Thus we take advantage of the fundamental power of visualization, bringing the user’s intuition and pattern recognition skills into the solution, while simultaneously taking advantage of the strength of algorithmic approaches to quickly and accurately find an optimal solution to a well-defined problem. CR Categories: I.3.6 [Computer Graphics]: Methodology and Techniques—Interaction techniques	algorithm;computer graphics;information visualization;interaction technique;loss function;mathematical optimization;optimization problem;pattern recognition;strategic management	Donna L. Gresh;Eugene I. Kelton	2003				Visualization	-29.106284230842064	-27.901528534643464	62088
48671da83bef7c329377a17ae4b1a275555ff1f5	visual reasoning for informational retrieval from very large databases	visual reasoning;computer languages;informational retrieval;database management systems;information retrieval;visualnet informational retrieval very large databases data visualization visual reasoning data objects information retrieval request visual query visual examples visual clues visual language compiler;visualnet;information retrieval visual databases data visualization graphics computer languages taxonomy animation large screen displays;visual clues;query languages;very large database;visual language compiler;animation;information retrieval request;data visualization;taxonomy;visual query;visual language;visual examples;user interfaces database management systems information retrieval query languages;very large databases;large screen displays;user interfaces;data objects;graphics;visual databases	When the database grows larger and larger, the user no longer knows what is in the database. Nor does the user know clearly what should be retrieved. How to get at the data becomes a central problem for very large databases. We suggest an approach based upon data visualization and visual reasoning. The idea is to transform the data objects and present sample data objects in a visual space. The user can then incrementally formulate the information retrieval request in the visual space. By combining data visualization, visual query, visual examples and visual clues, we hope to come up with better ways for formulating and modifying a user's query. A prototype system using the Visual Language Compiler and the VisualNet is then described.	compiler;data visualization;database;information retrieval;prototype;visual language	Shi-Kuo Chang	1989		10.1109/WVL.1989.77033	interactive visual analysis;computer science;database;human visual system model;world wide web;information retrieval	Visualization	-31.753434908015006	-32.75762782478228	62120
03a74e799f5f46a813dd2f240fea16bfe357fa61	diverse information integration and visualization	anotacion;0705k;partition method;user needs;general and miscellaneous mathematics computing and information science;computer graphics information visualization categorical data parallel coordinates;classification non supervisee;etude experimentale;information retrieval;integration information;scientific data;outlier;annotation;information visualization;prior knowledge;sistema complejo;data type;computer graphic;observacion aberrante;data analysis;visualization;information integration;methode partition;systeme complexe;visualisation;complex system;clasificacion no supervisada;integracion informacion;unsupervised classification;complex systems;observation aberrante;information society;analyse donnee;metodo particion;sensor fusion;classification automatique;automatic classification;clasificacion automatica;categorical data;parallel coordinates	This paper presents and explores a technique for visually integrating and exploring diverse information. Researchers and analysts seeking knowledge and understanding of complex systems have increasing access to related, but diverse, data. These data provide an opportunity to consider entities of interest from multiple informational perspectives not available from any single, data or information type. These multiple perspectives are derived from diverse, but related data and integrated for simultaneous analysis. Our approach visualizes multiple entities across multiple perspectives where each perspective, or dimension, is an alternate partitioning of the entities. The partitioning may be based on inherent or assigned attributes such as meta-data or prior knowledge captured in annotations. The partitioning may also be directly derived from entity data; for example, clustering, or unsupervised classification, can be applied to multi-dimensional vector entity data to partition the entities into groups, or clusters. The same entities may be clustered on data from different experiment types or processing approaches. This reduction of diverse data/information on an entity to a series of partitions, or discrete (and unit-less) categories, allows the user to view the entities across diverse data without concern for data types and units. Parallel coordinate plots typically visualize continuous data across multiple dimensions. We adapt parallel coordinate plots for discrete values such as partition names to allow the comparison of entity patterns across multiple dimension for identifying trends and outlier entities. We illustrate this approach through a prototype, Juxter (short for Juxtaposer).	algorithm;categorical variable;category theory;cluster analysis;complex systems;computer cluster;entity;gestalt psychology;parallel coordinates;prototype;unsupervised learning	Susan L. Havre;Anuj R. Shah;Christian Posse;Bobbie-Jo M. Webb-Robertson	2006		10.1117/12.643492	complex systems;visualization;computer science;data science;machine learning;data mining	ML	-27.04294738267782	-31.274611756887605	62286
a37449fc9975191244b01baedc9ce4769a0c1ba1	consensus clustering for urban land use analysis using cell phone network data	cdr;urban planning;human dynamics;cell phone data;madrid;cell phones;urban land use;call detail records;digital footprint;spectral clustering;automatic identification;mobile phones;phone networks;mobile phone records;consensus clustering;spain	Pervasive large-scale infrastructures, such as cell phone networks, have the ability to capture individual digital footprints, and as a result, generate datasets that provide a new vision on human dynamics. In this context, cell phones and cell phone networks, due to its ubiquity, can be considered one of the main sensors of human behavior. The information collected by these networks can be used to understand the dynamics of urban environments with a detail not available up to now. One of the areas that can benefit from this information is urban planning. In this paper, we present a technique for the automatic identification of land uses from the information gathered by a cell-phone network. Our approach first computes the aggregated calling patterns of the antennas and, after that, finds clusters that identify how individuals use each geographic region. Given the inherent diversity of human activities in urban landscapes, we use consensus clustering to identify land uses, characterizing only those geographical areas with well defined behaviors. We present and validate our results using cell phone records and official land use data collected for Madrid.	automatic identification and data capture;baseline (configuration management);broadcast television systems inc.;cluster analysis;consensus clustering;data mining;digital footprint;human dynamics;mobile phone;sensor;sputter cleaning;type signature;urban computing	Vanessa Frías-Martínez;Víctor Soto;Ángel Sánchez;Enrique Frías-Martínez	2014	IJAHUC	10.1504/IJAHUC.2014.065157	computer science;operating system;machine learning;consensus clustering;data mining;urban planning;human dynamics;spectral clustering	ML	-19.582285941247207	-34.34521636798837	62495
7675b267b359ef9c9471cae0a49e716fc6309d68	high performance rowing - a research outlook using a coaches perspective	sonification;rowing;production systems;research outlook;olympic sports;coaches perspective	The purpose of this paper is to explore research opportunities in the Olympic sport of rowing. While innovation in equipment is promoted in rowing the FISA rules don’t allow for it to be a deciding factor in the performance outcome for an individual crew. Thus, the challenge is to look at innovative ways to develop these abilities within a boat and harness their energy to create the most efficient and effective machine. This paper describes an outlook identifying four areas containing research opportunities with an emphasis on being able to ‘fine tune’ the moving parts of the engine that is a rowing crew: Sonification in the learning of motoric movement, rowing dynamics that will impact the hydrodynamics around the hull by inducing pitch and heave instead of forward propulsion, surface structures and finally objectivity in on water performance. A research outlook is made into different research opportunities in Rowing, using a coaches perspective. Another novelty is the comparison of the work carried out by the athletes in the rowing to the situation in production systems with assembly operators working at assembly workstations, opening up an new area of well-established theories to by utilised in sports.	microsoft outlook for mac;objectivity/db;sonification;theory;workstation	Christian Finnsgård;David McKenzie McGowan	2015		10.5220/0005713802990309	simulation;engineering;mechanical engineering	HCI	-30.323612604098262	-24.73909950831725	63060
09a126cf56cad13c1061f407a50b23023df4ea43	agro-gator: digesting experts, logs, and n-grams	user study;user studies;data analysis;n gram analysis;data aggregation	As research includes more and larger user studies, a significant problem lies in combining the many types of data files into a single table suitable for analysis by common statistical tools.  We have developed a data-aggregation tool that combines user logs, expert scoring, and task/session attributes. The tool also integrates the n-grams derived from a given sequence of actions in the user tasks. The tool provides a GUI for quick and easy configuration.	grams;graphical user interface;n-gram;usability testing	Michael Huggett	2010		10.1145/1835449.1835573	data aggregator;computer science;data mining;database;data analysis;world wide web;statistics	Graphics	-31.4953322070497	-30.73097417202983	63529
a5e73c426bd951301e4ec06c8e67c16acabd26df	using multiple coordinated views for multiple datasets analysis	web based information visualization application;desktop application multiple coordinated view multiple dataset analysis web based information visualization application silverlight technology client application;application software;search engines;multiple dataset analysis;information visualization;layout;data mining;computer applications;html;data visualisation;computer architecture;data analysis;servers;client application;internet;visualization technique;image color analysis;web services;data visualization;desktop application;bandwidth;middleware;web services data handling data visualisation middleware;data analysis data visualization application software search engines web server internet computer applications information analysis html bandwidth;web server;data handling;rendering computer graphics;information analysis;multiple coordinated view;silverlight technology	The goal of this paper is to present a web based information visualization application with the use of Silverlight technology. We have chosen this technology to better use the processing power of the client application in order to support the use of advanced interactions and the same interface components of a desktop application.Also, the information visualization application uses multiple coordinated views and multiple simultaneous datasets. We highlight the application layout configuration by the user, including the flexibility to specify the number of data views and to associate different datasets for each visualization techniques.	client (computing);desktop computer;information visualization;interaction;microsoft silverlight	Rafael Veras Guimarães;Nikolas Jorge S. Carneiro;Bianchi Serique Meiguins;Leandro Hernandez Almeida;Aruanda Simões Goncalves Meiguins	2009	2009 13th International Conference Information Visualisation	10.1109/IV.2009.72	computer science;data mining;database;world wide web	Visualization	-29.7024532676927	-32.66534195462064	63785
94d4f74fff08de6b4856f7ea896b7992172a1fb0	estimation of drivers ‘ awareness of pedestrians		On urban roads, 25% of all car accidents involve pedestrians who enter the roadway. Driversu0027 uncertainty about safety and their inattentiveness account for 70% of these accidents. The purpose of this study is to analyze driversu0027 attention to pedestrians so as to give an alert when the driveru0027s attention is insufficient. This method consists of estimating driversu0027 attention to pedestrians using gaze information, which is 90% of the cognitive information source when driving; operation information on the driver; and momentary change. A driveru0027s gaze information was estimated based on information sensed by a gaze-measuring instrument. Braking and accelerating were used as driver operation information. The relationship between gazing target, operation information, momentary change amount, and contact with and avoidance of a pedestrian who jumped out was analyzed using a support vector machine (SVM). Evaluation was carried out by preparing a course simulating a city road on a driving simulator, asking a subject to drive the course, and using that data. Using this method, for a pedestrian who jumped into the roadway, we were able to predict whether the driver would collide or avoid with a probability of 70% when Time to Collision (TTC) was 4 seconds. We were able to confirm the possibility of alerting the driver to avoid accidents with pedestrians on urban roads.	driving simulator;information source;simulation;support vector machine	Nobuhiro Mizuno;Akira Yoshizawa;Akihiro Hayashi;Takeshi Kawashima	2018	2018 IEEE 17th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC)	10.1109/ICCI-CC.2018.8482052	data collection;simulation;pedestrian;computer science;driving simulator	Robotics	-19.24548513588694	-27.39284693799363	64140
622a2f945816fafae5f2fb728849344d8bd9a2b4	improved location acquisition algorithms for the location-based alert service	moving object;alert service;information acquisition;location based service;mobile device;lbs;acquisition algorithm;data acquisition	The location-based alert services can be regarded as the one of the most practical location-based services. For the services, the system alerts mobile device users when they enter into or leave from specific regions, and provides certain services previously asked by the users. The services work by acquiring the location information of the users periodically. However, the system that handles the locations of the users may face serious problems as the number of users increases fast. Hence it is a critical issue to properly adjust the time interval of location data acquisition while maintaining the accuracy of the services. In this paper we propose two effective location acquisition algorithms; the speed-based acquisition algorithm and the angle-based acquisition algorithm. The proposed algorithms could reduce the irrelevant location information acquisition based on the movement of moving objects. The speed-based acquisition algorithm and the angle-based acquisition algorithm reduced the average numbers of location acquisitions by 20% and 37% over the distancebased acquisition algorithm, respectively, while they both maintained the same level of accuracy.	algorithm;data acquisition;location-based service;mobile device;performance;relevance	So-Young Kang;Jin-Woo Song;Kwang-Jo Lee;Ju-Hee Lee;Ji-Hoon Kim;Sung-Bong Yang	2009		10.1007/978-3-642-02617-1_47	computer science;operating system;location-based service;data mining;mobile device;pound;database;data acquisition;world wide web	HCI	-20.057240174676068	-30.634159501088686	64333
b1e2e42615408d37f789f98672b29d1cdd4f6df3	combining gpu-generated linear trajectory segments to create collision-free paths for real-time ambient crowds		Abstract Ambient crowds are used widely in today’s computer games and movies. In this study, a real-time steering-free ambient crowd navigation technique is presented, which combines linear and constant-speed trajectory segments end-to-end to provide collision-free paths to simulated agents. This method seeks spatio-temporal space to find such trajectory segments by utilizing specialized features of the GPU. Each segment is required to come one after another, and at the transition points, the segments are restricted to have direction and/or speed changes within certain limits. Experiments revealed that the proposed multi-segment path technique can create denser crowds by simulating more agents (up to 53% on average and up to 44% as a maximum) than the single-segment path method existing in the literature. It is also shown in the experiments that the presented technique requires less time per navigated agent per time step (up to 98%) than a popular velocity-based microscopic method.	ambient occlusion;graphics processing unit;real-time locating system	Oner Barut;Murat Haciomeroglu;Ebru Akcapinar Sezer	2018	Graphical Models	10.1016/j.gmod.2018.07.002	collision;microscopic method;crowds;trajectory;computer vision;mathematics;artificial intelligence	HCI	-24.211520422911356	-36.71392822956689	64930
5b358836efc59eee668444249780d7c6823ffc35	travel and us: the impact of mode share on sentiment using geo-social media and gis		AbstractCommute stress is a serious health problem that impacts nearly everyone. Considering that microblogged geo-locational information offers new insight into human attitudes, the present research examined the utility of geo-social media data for understanding how different active and inactive travel modes affect feelings of pleasure, or displeasure, in two major US cities: Chicago, Illinois and Washington DC. A popular approach was used to derive a sentiment index (pleasure or valence) for each travel Tweet. Methodologically, exploratory spatial data analysis (ESDA) and global and spatial regression models were used to examine the geography of all travel modes and factors affecting their valence. After adjusting for spatial error associated with socioeconomic, environmental, weather and temporal factors, spatial autoregression models proved superior to the base global model. The results showed that water and pedestrian travel were universally associated with positive valences. Bicycling also favourabl...	geographic information system;social media	Greg Rybarczyk;Syagnik Banerjee;Melissa D. Starking-Szymanski;Richard R. Shaker	2018	J. Location Based Services	10.1080/17489725.2018.1468039	data mining;regression analysis;computer science;sentiment analysis;spatial analysis;socioeconomic status;pleasure;feeling;social media	AI	-19.95000568754101	-33.66523831615793	65216
4bb2cf59ae721e528a421302cdfb8dc4e405701b	event sequence mining to develop profiles for computer forensic investigation purposes	computer forensics;methodology and techniques;data mining;sequence mining;event sequences	Developing profiles to describe user or system behaviour is a useful technique employed in Computer Forensic investigations. Information found in data obtained by investigators can often be used to establish a view of regular usage patterns which can then be examined for unusual occurrences. This paper describes one such method based on details provided by events found within computer forensic evidence. Events compiled from potentially numerous sources are grouped according to some criteria and frequently occurring event sequences are established. The methodology and techniques to extract and contrast these sequences are then described and discussed along with similar prior work in the same domain.	algorithm;compiler;computer forensics;event chain methodology;external storage;iteration;profiling (computer programming);requirement;sequential pattern mining	Tamas Abraham	2006		10.1145/1151828.1151846	sequential pattern mining;computer science;bioinformatics;data science;data mining;computer forensics	Security	-25.513253713849707	-31.63257109786027	65356
cd690e2b83fad0adb581ea9c0ed8bd129e71018d	efficient services management in libraries using ai and wireless techniques	libraries;orientation;zigbee;rfid;planning	Radio Frequency IDentification (RFID) has been used in a wide variety of applications such as highway toll collection, building access control, animal tracking, remote keyless entry for automobiles and tracking assets. For example, RFID in libraries, with a modest investment, can improve the capabilities of both librarians and users. This paper presents a new use of RFID in libraries to help determining the physical location of a book within the library and to provide assistance to users to arrive to the desired locations. Our initial prototype has been extended and experimentally implemented in Meco’s Public Library (Madrid, Spain). The application comprises three main systems: an electronic one which detects users through a RFID sensors system; an AI-based system to plan and to monitor the users’ requests according to their interests; and finally a screen-based information system that communicates visually the directions the users have to follow. We have developed a wireless communications system based on Zigbee technology to allow both, the information flow across the building and to connect the antennas to detect RFID users. This eliminates the need for using wires. The application not only helps users to easily locate the books or the reading rooms inside the building, but also automates tasks manually performed by the library staff (i.e. generate statistics about books usage time, age-related usage, etc).	access control;artificial intelligence;book;experiment;information system;librarian;library (computing);olga (technology);point of view (computer hardware company);point of sale;prototype;public library;radio frequency;radio-frequency identification;sensor;technical support	María Dolores Rodríguez-Moreno;Bonifacio Castaño;David F. Barrero;Agustín Martinez-Hellín	2014	Expert Syst. Appl.	10.1016/j.eswa.2014.06.047	radio-frequency identification;planning;simulation;orientation;world wide web;computer security	HCI	-22.481346871505533	-28.98208272719139	65623
a23d2e408b0384429eabc797c1c4ebe70d62d5ef	visualizing geospatial distribution of pesticide residue pollution using cartogram and heat map		Pesticide Residue is one of main sources resulted in food safety problems. It is necessary to analyze the distribution pattern of pesticide residue in order to supervision and management the overuse of pesticide. Thematic map is an effective approach for visualizing data combined with a specific geographic area. The most popular of the thematic maps are Choropleth, in which the values of the attribute are encoded as points or colored regions on the map. However, when the density of attribute-points on an area is different with that region's area, the data overlap will be produced. In this paper, we present a method for visualizing multidimensional data based on Cartogram. With this method, we first create Cartogram and Choropleth for presenting the geospatial distribution of data at the same time in order to avoid data overlapping, in which the Cartogram is generated by using diffusion algorithm; Second, we create thematic geographic heat map for presenting the pesticide residue pollution index by means of Inverse Distance Weighted interpolation to reckon missing data, in which the pesticide residue pollution index is calculated by using multiple linear regression algorithm; Thirdly, a multi-view spatial-temporal data visualization system, which combines maps, time axis, bar chart, bubble chart, pie chart etc. is presented to help user analyzing the data. A variety of interactive means such as region selection, data filtering, time cursor dragging, are also introduced to the system. The system uses two different ways to combine spatial with time. The results of user evaluation demonstrated that our method and system can effectively help user to analyze geospatial distribution of pesticide residue pollution.	heat map	Yi Chen;Yunfang Zhao;Xingru Chen;Xun Zhang	2017	T. Edutainment	10.1007/978-3-662-54395-5_20	environmental science;environmental engineering;hydrology;waste management	Robotics	-26.02223622828896	-32.375313827803076	65987
8a5665eb456f947ce364d4f0dcc38225dae4bff7	poster: on the quest for representative mobile datasets	human mobility;dataset	Mobile datasets are often incomplete or have heterogeneous spatiotemporal resolutions, e.g., a dataset is often aggregated or in lack of fields. We create a reliable dataset describing mobile data traffic in individual's spatiotemporal view. We focus on individuals having enough geographical information and merge their call records from one dataset with the data traffic records extracted from another dataset. The resulting dataset contains data session records associated with time and location fields.		Guangshuo Chen;Aline Carneiro Viana	2015		10.1145/2801694.2802147	geography;data science;data mining;database	ML	-19.670595977378735	-34.62455174497943	66516
458262c06568eccdb1bd9789721cc31b5606a5d6	exploring the spatio-temporal dynamics of geographical processes with geographically weighted regression and geovisual analytics		Received: 17 April 2008 Revised: 30 May 2008 Accepted: 9 June 2008 Online publication date: 31 July 2008 Abstract The paper examines the potential for combining a spatial statistical methodology – Geographically Weighted Regression (GWR) – with geovisual analytical exploration to help understand complex spatio-temporal processes. This is done by applying the combined statistical – exploratory methodology to a simulated data set in which the behaviour of regression parameters was controlled across space and time. A variety of complex spatio-temporal processes was captured through space-time (i.e. as spatio-temporal) varying parameters whose values were known. The task was to see if the proposed methodology could uncover these complex processes from the data alone. The results of the experiment confirm that the combined methodology can successfully identify spatio-temporal patterns in the local GWR parameter estimates that correspond to the controlled behaviour of the original parameters. Information Visualization (2008) 7, 181--197. doi:10.1057/palgrave.ivs.9500187	guinness world records;information visualization;spatial analysis;statistical model	Urška Demšar;A. Stewart Fotheringham;Martin Charlton	2008	Information Visualization	10.1057/palgrave.ivs.9500187	data science;data mining;statistics	Visualization	-22.493248643852922	-35.16191063989047	66621
59ca0c3b86539a16d57fb3b63b097fc6964a65a9	geographical statistics and characteristics of p2p query strings		P2P file-sharing applications are quickly being adopted by a wider and more mainstream audience. There is much to be learned from keyword searches users perform in order to retrieve content from these networks. This paper presents a large-scale measurement study of search terms in the modern Gnutella network. We developed a highly parallelized architecture capable of capturing an unprecedented amount of geographical-identified queries. We applied this architecture to generate daily logs of search queries. We collected over25 such daily Gnutella logs, with more than 15 millions unique queries in each, over a three month period. We analyzed both static snapshots of the Gnutella networks, as well as the dynamics of the network over time. In particular, we look at the geographic location and the trends of searches to better understand the dynamics.	file sharing;geographic coordinate system;gnutella;parallel computing;peer-to-peer;web search query	Adam Shaked Gish;Yuval Shavitt;Tomer Tankel	2007			statistics;snapshot (computer storage);architecture;computer science;query string	Web+IR	-21.115899709799923	-36.08918982345356	67088
1cd74d922dcc57ab6f0e44389cdfad9183314894	a data reduction algorithm for planar curves	representation graphique;segmentation;reduction donnee;algorithme;algorithm;algorritmo;data reduction;courbe planaire;infographie;graphics	Une courbe plane peut etre representee par une sequence de segments de lignes connectes. On examine des algorithmes existants pour reduire le nombre de segments de lignes utilises pour representer une courbe. Developpement d'un algorithme simple de point de vue calcul et efficace (en temps lineaire). Cet algorithme realise un haut degre de reduction de donnees tout en produisant une representation qui est precise meme pour les courbes les plus complexes	algorithm	James Robergé	1985	Computer Vision, Graphics, and Image Processing	10.1016/0734-189X(85)90117-3	data reduction;computer science;graphics;segmentation;algorithm	Vision	-22.17161824552902	-37.74669958421253	67221
128f3073f6511afe5e9e3d295358a91d2dabb0fd	summarization via pattern utility and ranking: a novel framework for social media data analytics		The firehose of data generated by users on social networking and microblogging sites such as Facebook and Twitter is enormous. The data can be classified into two categories: the textual content written by the users and the topological structure of the connections among users. Real-time analytics on such data is challenging with most current efforts largely focusing on the efficient querying and retrieval of data produced recently. In this article, we present a dynamic pattern driven approach to summarize social network content and topology. The resulting family of algorithms relies on the common principles of summarization via pattern utilities and ranking (SPUR). SPUR and its dynamic variant (D-SPUR) relies on an in-memory summary while retaining sufficient information to facilitate a range of user-specific and topic-specific temporal analytics. We then follow up by describing variants that take the implicit graph of connections into account to realize the Graph-based SPUR variant (G-SPUR). Finally we describe scalable algorithms for implementing these ideas on a commercial GPU-based systems. We examine the effectiveness of the summarization approaches along the axes of storage cost, query accuracy, and efficiency using real data from Twitter.	algorithm;automatic summarization;display resolution;graphics processing unit;implicit graph;in-memory database;network topology;real-time transcription;scalability;social media;social network;structure mining;time complexity	Xintian Yang;Yiye Ruan;Srinivasan Parthasarathy;Amol Ghoting	2013	IEEE Data Eng. Bull.		microblogging;data mining;implicit graph;automatic summarization;computer science;multi-document summarization;analytics;social media;data analysis;social network	DB	-24.49576910989125	-35.75539171725501	67742
1eb5fc8a9fcb22a94dbe2ef79eeaba001f70c6ae	assembling and using a cellular dataset for mobile network analysis and planning		In a world of open data and large-scale measurements, it is often feasible to obtain a real-world trace to fit to one's research problem. Feasible, however, does not imply simple. Taking next-generation cellular network planning as a case study, in this paper we describe a large-scale dataset, combining topology, traffic demand from call detail records, and demographic information throughout a whole country. We investigate how these aspects interact, revealing effects that are normally not captured by smaller-scale or synthetic datasets. In addition to making the resulting dataset available for download, we discuss how our experience can be generalized to other scenarios and case studies, i.e., how everyone can construct a similar dataset from publicly available information.		Paolo Di Francesco;Francesco Malandrino;Luiz A. DaSilva	2018	IEEE Transactions on Big Data	10.1109/TBDATA.2017.2734100	data mining;machine learning;open data;artificial intelligence;computer science;big data;network planning and design;cellular network;download;base station	ML	-20.977228695322655	-35.88421922493995	67875
adff15913daedf7907a1dccc31ff6dcad4aac848	an intelligent assistant for high-level task understanding	language understanding;multi domain;spoken dialog system sds;user intention	People are able to interact with domain-specific intelligent assistants (IAs) and get help with tasks. But sometimes user goals are complex and may require interactions with multiple applications. However current IAs are limited to specific applications and users have to directly manage execution spanning multiple applications in order to engage in more complex activities. An ideal personal agent would be able to learn, over time, about tasks that span different resources. This paper addresses the problem of cross-domain task assistance in the context of spoken dialogue systems. We propose approaches to discover users' high-level intentions and using this information to assist users in their task. We collected real-life smartphone usage data from 14 participants and investigated how to extract high-level intents from users' descriptions of their activities. Our experiments show that understanding high-level tasks allows the agent to actively suggest apps relevant to pursuing particular user goals and reduce the cost of users' self-management.	dialog system;domain-specific language;experiment;file spanning;high- and low-level;intelligent agent;interaction;natural language;real life;self-management (computer science);smart device;smartphone;usage data	Ming Sun;Yun-Nung Chen;Alexander I. Rudnicky	2016		10.1145/2856767.2856818	simulation;human–computer interaction;computer science;artificial intelligence;operating system;multimedia;world wide web	HCI	-32.46854998798213	-26.779524814133737	68087
b2754c758248c7357bd0d9ba77ccd8fe9048a97b	immersive visual data mining: the 3dvdm approach	visual data mining;3dvdm;real time 3d soundscapes	A software system has been developed for the study of static and dynamic data visualization in the context of Visual Data Mining in Virtual Reality. We use a specific data set to illustrate how the visualization tools of the 3D Visual Data Mining (3DVDM) system can assist in detecting potentially interesting non-linear data relationships that are hard to discover using traditional statistical methods of analysis. These detected data structures can form a basis for specification of further explanatory statistical analysis. The visualization tools are shown to reveal many interesting patterns and in particular the dynamic data visualization appears to have a very promising potential.#R##N##R##N#To further explore the human faculties, sound has also been used to represent statistical data. Current technology enables us to create advanced real-time 3D soundscapes which may prove useful since the human ears' field of hearing is larger than the eyes' field of view, and thus is able to inform us on events happening in areas that we cannot see. The audio-visual tools in the 3DVDM system are tested and the effectiveness of them is discussed for situations where sound acts as support for visual exploration, as well as use of sound as a sole cue for analyzing data in VR.	data mining	Henrik R. Nagel;Erik Granum;Søren Bovbjerg;Michael Vittrup	2008		10.1007/978-3-540-71080-6_18	speech recognition;data science;data mining	ML	-25.765374985177182	-33.165503196604774	68498
6d1ec61bfcf5ab99bad58204987752047aaa4203	evolution of mutating software		We propose using random walks in software space as abstract formal models of biological evolution. The goal is to shed light on biological creativity using toy models of evolution that are simple enough to prove theorems about them. We consider two models: a single mutating piece of software, and a population of mutating software. The fitness function is taken from a well-known problem in computability theory that requires an unlimited amount of creativity, the Busy Beaver problem.	busy beaver;computability theory;evolution;fitness function	Gregory J. Chaitin	2009	Bulletin of the EATCS		mathematics;applied mathematics;theoretical computer science;software	SE	-26.14110626823006	-27.206939997517637	68534
94fbfa18726108ac69b57384bec9e236d3bc5053	integrating gis, simulation and animation	computer animation;digital simulation;geographic information systems;road traffic;traffic computer control;animation;computer animation;geographical information systems;information transfer;microscopic simulation;simulation;software;traffic engineer	This paper describes techniques for combining the strengths of geographical information systems (GIS), microscopic simulation and computer animation. We deseribe a simulation system integrated with an existing GIS to provide the user with the capability of accessing and managing the information transfer between the GIS and the simulation models. This integrated system nmd not be limited to simulation alonq other calculations which are essential for the traffic engineer can be integrated as well. For example, the calculation of highway capacity is a basic need of all traffic engineers. The software to perform these calculations can, itself, be integrated with both the GIS system, traffic simulation and animation. Such a system offers the engineer a capability that goes beyond analysis: the engineer can now perform designs of his system exploring alternative treatments to identify the most effective technique for improving traffic operations.	computer animation;simulation	Edward Lieberman	1991			integrable system;enterprise gis;simulation;information transfer;computer science;technical report;stochastic modelling;theoretical computer science;simulation modeling;geographic information system;computer animation;world wide web;system integration;computer engineering	Arch	-21.730270232897166	-23.976506557788287	68646
8d6fa13567c70e8025eb24823292581614c322e7	real-time monitoring of traffic congestions		Alleviating the difficulty of congestion roads is quite a tough task; however such an alleviation can prevent many unwanted problems like employees late to work; deliveries do not arrive on time and many more. One of the main tactics to deal with the congested road difficulty is alerting the drivers about congested roads in real time, so the drivers will be able to evade these congested roads. This paper suggests examining road's images in real time so as to figure out which roads are congested and which roads are vacant. Moreover, the paper suggests combining the entire data into a full map showing each road's congestion intensity.	computer;digital camera;discrete cosine transform;jpeg;mobile phone;network congestion;real-time computing;real-time transcription;traffic exchange;waze	Yair Wiseman	2017	2017 IEEE International Conference on Electro Information Technology (EIT)	10.1109/EIT.2017.8053413	computer network;computer science;image segmentation;traffic congestion	Robotics	-19.78531080672455	-29.077855780308305	68726
070b86f7cccff51c6cefa2f441cf0b2a9510c39e	user engagement engine for smart city strategies		The new challenges in the smart city context are mainly related to the stimulation of the city users towards taking more sustainable behaviors, in mobility and energy. The state of the art in this case is mainly focused on classical smart city solution for informing the city users and or for engaging them with specific wired rules toward virtuous models. And not using flexible languages and predictive models, pushing them towards a larger range of virtuous habits. On this regards, the main problems are the computation of user behavior via data analytic (semantic computing, machine learning), as well as the formalization of strategies via simple and well formalized language for producing engagements to the city users, which can be understood by city operators. In this paper, a solution for city users engagement is studied and implemented for Sii-Mobility Smart city national project in Italy has been presented. The solution has been implemented thanks to the exploitation of Km4City model and semantic computing. The paper also presents the validation of results about the effective usage of the solution by providing some statistical evidence about the efficient assessment of user behavior and of engagement rules acceptance rate.	algorithm;computation;formal language;hoc (programming language);machine learning;predictive modelling;semantic computing;smart city	Claudio Badii;Pierfrancesco Bellini;Daniele Cenni;Angelo Difino;Michela Paolucci;Paolo Nesi	2017	2017 IEEE International Conference on Smart Computing (SMARTCOMP)	10.1109/SMARTCOMP.2017.7947059	operator (computer programming);smart city;semantic computing;simulation;computation;computer science	Robotics	-20.311012721469883	-31.98288361900218	68848
da8cf07f193a8640d8c15652c4c05cdecd71a8c1	the behavioural implications of ubiquitous monitoring	automatic control;ubiquitous;pervasive;theory of planned behaviour;endnotes;monitoring intelligent agent space technology humans intelligent sensors predictive models automatic control conferences informatics context modeling;monitoring;behaviour;intelligent agent;predictive models;informatics;pubications;humans;space technology;ubiquitous behaviour modelling monitoring pervasive;context modeling;intelligent sensors;conferences	Ubiquitous environments such as intelligent pervasive spaces are designed to make life better for users. In order to provide much of their intended functionality, significant amounts of data need to be collected about users through sensors deployed ubiquitously. Existing monitoring technologies have been known to often cause undesirable effects, and it is anticipated that ubiquitous monitoring, with its increased coverage, will result in an increase in the occurrence of these effects. So far, a limited amount of research has investigated the impact of this technology on users. As such, we present a preliminary model, consisting of a series of factors related to ubiquitous monitoring believed to influence behaviour, and augmented by the Theory of Planned Behaviour for understanding, predicting and therefore preventing any undesirable effects.	intelligent agent;participatory monitoring;pervasive informatics;sensor	Stuart Moran;Keiichi Nakata	2009	2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2009.294	simulation;human–computer interaction;computer science;artificial intelligence;data mining;predictive modelling;space technology;context model;informatics;ubiquitous computing;theory of planned behavior;intelligent sensor	HCI	-30.377800410105095	-25.3464656521327	69075
2fd62e8b172e4dc5e6c72b85e36c5bb1e73c1981	an online information system for apartment services with fuzzy spatial queries	fuzzy logic;: spatial database;spatial query;php;web application;mysql;spatial database;spatial data;information system	Spatial data lies at the heart of GIS research. The great strength of the spatial data is to query about the location and direction of spatial objects. This paper is to explore the possibilities and advantages of geo-spatial data to improve online apartment services. In order to support spatial querying in nature, a simple fuzzy query model is presented in the paper. An online spatial information system is developed by utilizing PHP technology with MySQL database. The system will provide visitors and residents with more accurate information about the apartment. Querying examples are also provided.	digital visitor and resident;geographic information system;mysql;php;spatial analysis;spatial query	Huiqing Yang;Geoffrey Tranard	2006			fuzzy logic;information retrieval;data mining;spatial database;spatial analysis;information system;apartment;computer science;spatial query	DB	-31.28351267714166	-35.61405869853371	69152
b9f80615f15ced168c45a4cdbaa7ea0c37734029	many-to-many geographically-embedded flow visualisation: an evaluation	clutter;standards;cartographic information visualisation;visualization;cartographic information visualisation flow maps matrix visualisation;data visualization;joining processes;flow maps;cartographic information visualisation many to many geographically embedded flow visualisation geographic locations visual representations od maps maptrix clutter geographic embedding od matrix representations bundled node link flow map representations;algorithm design and analysis;visualization data visualization clutter labeling standards algorithm design and analysis joining processes;labeling;matrix algebra cartography data visualisation;matrix visualisation	Showing flows of people and resources between multiple geographic locations is a challenging visualisation problem. We conducted two quantitative user studies to evaluate different visual representations for such dense many-to-many flows. In our first study we compared a bundled node-link flow map representation and OD Maps [37] with a new visualisation we call MapTrix. Like OD Maps, MapTrix overcomes the clutter associated with a traditional flow map while providing geographic embedding that is missing in standard OD matrix representations. We found that OD Maps and MapTrix had similar performance while bundled node-link flow map representations did not scale at all well. Our second study compared participant performance with OD Maps and MapTrix on larger data sets. Again performance was remarkably similar.	anatomic node;clutter;embedding;evaluation;flow map;gold;large;many-to-many;node - plant part;usability testing;algorithm	Yalong Yang;Tim Dwyer;Sarah Goodwin;Kim Marriott	2017	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2016.2598885	algorithm design;computer vision;labeling theory;information visualization;visualization;computer science;data mining;clutter;multimedia;data visualization	Visualization	-29.038148148236797	-35.18582950127873	69401
5aa5072a6225ed4815371401045f1208f9c6fec2	visual exploration of global trade networks with time-dependent and weighted hierarchical edge bundles on gpu		The UN Comtrade database is the world’s largest repository of bilateral trade data. Their complexity poses a challenge to visualization systems, leading to issues such as scalability and visual clutter. Thus, we propose a radial layout-based visual exploration system to enable the user to smoothly explore the change over time and to explore different commodity classes at once by using a novel edge bundling concept. We evaluated our system with the aid of a group of domain experts.	bilateral filter;clutter;graphics processing unit;radial (radio);scalability;smoothing;subject-matter expert	J. Hofmann;M. Größler;M. Rubio-Sánchez;Peter-Paul Pichler;D. J. Lehmann	2017	Comput. Graph. Forum	10.1111/cgf.13186	theoretical computer science;computer science;artificial intelligence;time series;computer vision;visualization;bilateral trade;scalability	Visualization	-28.204203712262533	-35.623546489664676	69467
47ed26fc42f926445ccd7017cc1bfcf185aa35a5	implementing deletion in b+-trees	miscellaneous;sgml;text database;object oriented databases;c programming language	This paper describes algorithms for key deletion in B+-trees. There are published algorithms and pseudocode for searching and inserting keys, but deletion, due to its greater complexity and perceived lesser importance, is glossed over completely or left as an exercise to the reader. To remedy this situation, we provide a well documented flowchart, algorithm, and pseudo-code for deletion, their relation to search and insertion algorithms, and a reference to a freely available, complete B+-tree library written in the C programming language.	algorithm;b+ tree;flowchart;gloss (annotation);mike lesser;pseudocode;the c programming language	Jan Jannink	1995	SIGMOD Record	10.1145/202660.202666	computer science;theoretical computer science;database;programming language;algorithm;sgml	Theory	-32.13037477796671	-25.709870119189112	69684
84fc31995c6a5c9713282d108e86b01bfae65a97	modeling and extracting deep-web query interfaces	visual representation;interface model;deep web;spatial clustering	Interface modeling & extraction is a fundamental step in bui lding a uniform query interface to a multitude of databases on the Web. E xisting solutions are limited in that they assume interfaces are flat and thus ignor e the inherent structure of interfaces, which then seriously hampers the effect iv ness of interface integration. To address this limitation, in this chapter, we m odel an interface with a hierarchical schema (e.g., an ordered-tree of attributes) . We describeExQ, a novel schema extraction system with two distinct features. First , ExQ discovers the structure of an interface based on its visual representation via s patial clustering. Second, ExQ annotates the discovered schema with labels from the interf ac by imitating the human-annotation process. ExQ has been extensively evaluated with real-world query interfaces in five different domains and the results sh ow thatExQ achieves above 90% accuracy rate in both structure discovery & schema annotation tasks.	algorithm;attachments;browser user interface;cluster analysis;database;deep web;earthbound;experiment;information extraction;interactivity;tree (data structure);world wide web	Wensheng Wu;AnHai Doan;Clement T. Yu;Weiyi Meng	2009		10.1007/978-3-642-04141-9_4	computer science;data mining;database;world wide web	DB	-30.38051056373833	-31.324722571309497	69786
3b246d2f643b3ebd397ed87e501b35eaf0d3ee5d	adapting the human plausible reasoning theory to a graphical user interface	graphical user theory;user modelling;cognitive systems;intelligent user interface;gui human plausible reasoning theory graphical user theory cognitive theory intelligent file manipulator simple additive weighting theory user modeling graphical user interface;inference mechanisms graphical user interfaces user modelling cognitive systems file organisation;intelligent file manipulator;inference mechanisms;graphical user interface;cognitive theory;indexing terms;user modeling;humans graphical user interfaces intelligent systems rendering computer graphics user interfaces feedback computer errors command languages informatics;feedback;graphical user interfaces;human plausible reasoning theory;intelligent systems;simple additive weighting theory;gui;graphic user interface;command languages;informatics;humans;rendering computer graphics;user interfaces;computer errors;user model;file organisation	This paper describes the adaptation of a cognitive theory, called Human Plausible Reasoning (HPR), for the purposes of an intelligent graphical user interface (GUI). The GUI is called intelligent file manipulator (IFM) and manages files and folders in a similar way as the Windows 98/NT Explorer. However, IFM also incorporates intelligence, which aims at rendering the interaction more human-like than in a standard explorer in terms of assistance to users' errors. IFM constantly reasons about users' actions, goals, plans, and possible errors, and offers automatic assistance in case of a problematic situation. HPR is used in IFM to simulate the reasoning of users in its user modeling component and the reasoning of human expert helpers when they try to provide assistance to users. The adaptation of HPR in IFM has focused on the domain representation, statement transforms, and certainty parameters. The certainty parameters of HPR have been combined in a novel way with user stereotypes and the simple additive weighting theory. IFM has been evaluated and the evaluation results showed that IFM could generate plausible hypotheses about users' errors and helpful advice to a satisfactory extent; hence, HPR seemed to have fulfilled the purpose for which it was incorporated in IFM.	graphical user interface;incremental funding methodology;interaction-free measurement;microsoft windows;proteomics;simulation;user modeling;utility functions on indivisible goods	Maria Virvou;Katerina Kabassi	2004	IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans	10.1109/TSMCA.2004.826300	intelligent decision support system;human–computer interaction;computer science;artificial intelligence;theoretical computer science;machine learning;graphical user interface;database	HCI	-31.322379516338408	-25.608769720076157	69955
33fd93cafc58c59cfbb328123f60d5b358bd40aa	behaviortracker: visual analytics of customer switching behavior in o2o market		Visualization of customer behavior is urgently needed for an increasing number of customer orders on O2O (online to offline) platform. Although many works have been done on visualizing customer opinion or customer click events of one store, visualizing customer switching behavior among stores is still challenging. The challenge is to show customer order records over time and structure the inter-connection among different stores when customer switching behavior happens. In this work, we focus on Takeout O2O service to present a novel visual analysis system for retailers focusing on customer switching behavior patterns. Firstly we define five customer segments based on switching behavior. Then this system enables temporal-spatial driver exploration for different segments through several interactive views. Moreover, in order to visualize inter-connection sequences, augmented streamgraph with the bundled parallel coordinates is proposed as one alternative technique to visualize temporal event sequences. Case studies through collaboration with domain experts also demonstrate the usefulness and effectiveness of this system in helping customer relationship management.		Yaru Du;Changbo Wang;Chenhui Li;Hong Yin	2018		10.1145/3231622.3231627	data mining;e-commerce;consumer behaviour;visualization;visual analytics;customer relationship management;parallel coordinates;computer science	AI	-25.890293531905463	-34.04974513298675	70004
de45e41d6d4bccd0b34852f3afaa881184a38b1a	moir: a prototype for managing moving objects in road networks	databases;location based web page recommendation;moving object;web pages;query processing;road network;software prototyping;trajectory smoothing;trajectory data management;digital road maps;road traffic;prototypes;data management;conference management;network constrained moving object management;road networks;moir;smoothing methods;internet;roads;traffic engineering computing data acquisition internet query processing road traffic;spatiotemporal phenomena;driver circuits;traffic engineering computing;web based prototype;prototypes spatiotemporal phenomena conference management roads large scale systems software prototyping data acquisition smoothing methods query processing web pages;2200 engineering;data acquisition;movement predications;large scale systems;digital road maps moir road networks web based prototype network constrained moving object management data acquisition trajectory smoothing trajectory data management query processing movement predications location based web page recommendation;real time systems	MOIR is a Web-based prototype to support a number of novel applications with network-constrained moving object management. Technical aspects of MOIR range from data acquisition and trajectory smoothing, trajectory data management and query processing, movement predications, and location based Web page recommendation. The demo is in the context of detailed digital road maps with 38,0000 road segments and 55,000 road intersection points, and real spatiotemporal data of over ten thousand taxis in Beijing.	data acquisition;database;map;prototype;smoothing;web page	Zhiming Ding;Limin Guo;Kuien Liu;Hu Wu;Xiaofang Zhou	2008	The Ninth International Conference on Mobile Data Management (mdm 2008)	10.1109/MDM.2008.40	the internet;data management;computer science;web page;data mining;database;prototype;data acquisition;world wide web	DB	-33.13407413841825	-30.717833715915795	70432
c4138f9e989de956774dc635e4553e084bdb5260	capturing the semantics of weg log data by navigation matrices	navigation matrices;weg log data;web design;directed graph;web navigation	The information left behind by users who have visited a web site is recorded in the related web server log files. From analysing the data contained in such files, a web designer is able to understand the interaction between the users and a web site, and then to improve the web topology. We assume that the information of web usage can be generated from log files via a cleaning process, from which we identify a set of navigation sessions that represent the trails formed by users during the navigation process. The trails are modelled as a weighted directed graph, called a transition graph, and then a corresponding navigation matrix is computed with respect to the underlying web topology. The main contribution in this paper is that we formally define a minimal set of binary operators on navigation matrices, which consists of the sum, union, intersection and difference operators. These operations afford us the ability to analyse users navigation from the contents of two given navigation matrices.	data logger;directed graph;server (computing);server log;sputter cleaning;web design;web server	Wilfred Ng	2001			directed graph;web design;computer science;theoretical computer science;web navigation;web log analysis software;database;world wide web	Web+IR	-32.11342589040282	-34.76055762722294	70502
ac8d6525dc734b41e73c2d0785fec460c81c5eff	"""automating the conceptual design process: """"from black box to component selection"""""""	automated design;functional design;conceptual design;graph grammars;concept generation	Conceptual design is a vital part of the design process during which designers first envision new ideas and then synthesize them into physical configurations that meet certain design specifications. In this research, a suite of computational tools is developed that assists the designers perform this non-trivial task of navigating the design space for creating conceptual design solutions. The methodology is based on automating the function-based synthesis paradigm by combining various computational methods. Accordingly, three nested search algorithms are developed and integrated that mimic a designer’s decision-making at various stages of conceptual design. The implemented system provides a method for automatically generating novel alternative solutions to real design problems. The application of the approach to the design of an electromechanical device shows the method’s range of capabilities, and how it serves as a comparison to human conceptual design generation and as a tool suite to complement the skills of a designer.	black box;programming paradigm;search algorithm;software design	Tolga Kurtoglu;Albert Swantner;Matthew I. Campbell	2010	AI EDAM	10.1017/S0890060409990163	iterative design;conceptual model;simulation;probabilistic design;functional design;computer science;systems engineering;engineering;design flow;conceptual design;design language;design education;design technology;engineering drawing;generative design;mechanical engineering	EDA	-30.036423695047546	-26.518028704188115	70527
9f82d7a5788593ad721309adbbbc59f1d211727c	the industrial application of the irregular 3d-objects image processing in the compact reverse engineering system	image tridimensionnelle;concepcion asistida;computer aided design;image processing;methode mesure;digitizing;retroingenierie;procesamiento imagen;metodo medida;numerisation;traitement image;3d model;mathematical model;conception assistee;industrial application;tridimensional image;numerizacion;measurement method;ingeniera inversa;imagen tridimensional;reverse engineering	The problems of irregular 3D-objects manufacturing preparation are considered. The irregular surfaces digitizing process by video system is offered. The mathematical models of video digitizing process and software basic stages for computer 3D-models creation are shown. The forming of the computer 3Dmodels from video image as one from main stages of irregular 3D-objects compact reverse manufacturing is considered. The video system assubsystem of Compact Reverse Engineering System (CRES) is offered.	computer simulation;image processing;mit engineering systems division;mathematical model;reverse engineering	Dmitry Svirsky;Yuri Polozkov	2001		10.1007/3-540-44692-3_56	computer vision;simulation;image processing;computer science;operating system;mathematical model;reverse engineering;statistics;computer graphics (images)	Graphics	-33.483253529009	-26.122321032048923	70655
866bd49f1f90d4afef90a7c7bda908bb8f807ca0	model-based human-centered task automation: a case study in acc system design	cognitive science;design automation;perceptual triggering events;system analysis and design;systems engineering;government;biological system modeling;adaptive cruise control systems;programmable control;indexing terms;technology management;human behavior;perceptual states model based human centered task automation human comfort human factors analysis human behavior generation mental models adaptive cruise control systems perceptual triggering events;model based human centered task automation;mental models;perceptual states;human factors;systems analysis human factors systems engineering automobile industry;systems analysis;factor analysis;system design;engineering management;human centered design;safety;satisficing;human comfort;humans;human centered automation;design automation humans cognitive science biological system modeling system analysis and design technology management engineering management government safety programmable control;human factors analysis;automobile industry;mental model;human behavior generation	Engineers, business managers, and governments are increasingly aware of the importance and difficulty of integrating technology and humans. The presence of technology can enhance human comfort, efficiency, and safety, but the absence of humanfactors analysis can lead to uncomfortable, inefficient, and unsafe systems. Systematic human-centered design requires a basic understanding of how humans generate and manage tasks. A very useful model of human behavior generation can be obtained by recognizing the task-specific role of mental models in not only guiding execution of skills but also managing initiation and termination of these skills. By identifying the human operator’s mental models and using them as templates for automating different tasks, we experimentally support the hypothesis that natural and safe interaction between human operator and automation is facilitated by this model-based human-centered approach. The design of adaptive cruise control (ACC) systems is used as a case study in the design of model-based task automation systems. Such designs include identifying ecologically appropriate perceptual states, identifying perceptual triggering events for managing transitions between skilled behaviors, and coordinating the actions of automation and operator.	automation;autonomous car;complex systems;control theory;decision theory;driving simulator;ecology;experiment;information;mathematical optimization;mental model;network switch;quanta computer;requirements analysis;simulation;state space;systems design;terminate (software);user-centered design	Michael A. Goodrich;Erwin R. Boer	2003	IEEE Trans. Systems, Man, and Cybernetics, Part A	10.1109/TSMCA.2003.817040	systems analysis;satisficing;simulation;computer science;knowledge management;artificial intelligence;technology management;factor analysis;human behavior;government	Robotics	-24.287110626473826	-24.288550417349082	70670
3137502a129c3429a579e4e23542974670dece8b	simulation level of detail for multiagent control	control algorithm;path planning;mobile agents;search algorithm;level of detail;mobile agent;multiagent simulation;path following;physical simulation	Many classes of applications require multiagent navigation control algorithms to specify the movements and actions of heterogeneous groups containing thousands of characters. The scale and complexity of these interacting character groups require navigation control algorithms that are both generalizable and specifically tuned to particular character platforms. We propose a technique called simulation level of detail (LOD) that provides a simulation-based interface between navigation control algorithms and the specific mobile characters on which they operate. A simulation LOD efficiently models a character's ability to move given its dynamic state and provides this simplified version of the character to navigation controllers for use in run-time search algorithms that compute locomotion actions. We develop our simulation LOD algorithms on groups of physically simulated human and alien bicyclists and demonstrate reusable controllers that provide improvements in path following and herding tasks.	agent-based model;interaction;level of detail;search algorithm;simulation	David C. Brogan;Jessica K. Hodgins	2002		10.1145/544741.544789	computer vision;simulation;computer science;artificial intelligence;level of detail;mobile agent;motion planning;search algorithm	Graphics	-26.45434108969352	-24.509216243849686	71264
fe57552e07396ebff4352db16f4758d666dc3e84	interaction between controls and displays during the approach manoeuvre of v/stol aircraft		This thesis assesses the pilot handling problems of a V/STOL aircraft during the approach manoeuvre to a restricted landing area in weather conditions of low cloudbase and poor visibility. The main aspects examined are: how the handling problems during the approach can be reduced by the use of automatic flight control or electronic display systems, in what way each form of augmentation can be most effectively used, and how they interact with each other. The early part of the thesis analyses the reasons for the increased pilot compensation task during the approach, and why current operational control and display systems do not permit a full instrument approach. The constraints imposed on the type of approach profile due to aircraft characteristics and external factors are next assessed, and preliminary conclusions drawn on the type of profile most suited to the handling qualities of V/STOL aircraft. Leading on from the approach profile, the range of controls and displays currently available are described and their applicability to the present problems is discussed. The main part of the document details the flight and simulator trials carried out, describes the display formats and control laws developed during the work, and justifies their use for the control and display interaction assessment. The final chapters analyse the qualitative and quantitative results obtained with the various levels of control and display systems investigated. The results illustrate the way in which the multi-variable control problems of the instrument approach can be broken down into separate tasks of inner loop and outer loop control, and demonstrate that the pilot is best employed controlling the outer loop flight path using the instrument display whilst the inner loop is controlled automatically by the flight control system.		J. N. Barrett	1978			visibility;inner loop;airway;control engineering;control system;instrument approach;computer science	HCI	-24.151033060680106	-25.02660500146386	71718
6e3f8ba01fda0022ee23d3e7e18e6b75deb260c0	adaptive presentation and navigation for geospatial imagery tasks	busqueda informacion;contenu image;image numerique;image content;navegacion informacion;recherche image;ingenierie connaissances;information retrieval;navigation information;knowledge management;information browsing;image multiple;imagen multiple;information overload;navigational aid;multiple image;user assistance;assistance utilisateur;recherche information;asistencia usuario;imagen numerica;aide navigation;digital image;ayuda navegacion;imagerie geospatiale;contenido imagen;image retrieval;knowledge engineering	Advances in technology for digital image capture have given rise to information overload problems in the geosciences and fields that rely on geospatial image retrieval. To help address such imagery information overload, our research is developing methods to extract and apply contextual knowledge relating user task goals to the images being used. As users analyze imagery retrieved to support specific tasks, multiple relevant images and salient image content can be captured together with task annotations to provide a basis for contextual knowledge management support. This paper describes how our environment for image interaction leverages captured task-based knowledge to support adaptive presentation and navigation in the space of available imagery.		Dympna O'Sullivan;Eoin McLoughlin;Michela Bertolotto;David C. Wilson	2004		10.1007/978-3-540-27780-4_23	computer vision;simulation;image retrieval;computer science;artificial intelligence;information overload;knowledge engineering;multimedia;digital image	Vision	-33.291352337168114	-27.87487853860749	71805
84f79cb1d364d3441bb96bd275c49aba17a123d2	braincove: a tool for voxel-wise fmri brain connectivity visualization	filtering;paper;visualization;picture image generation;image generation;brain mapping;package;mri;i 3 3 computer graphics;opengl;computer science;raycasting;opencl;functional brain connectivity;gpu volume rendering;rendering	Functional brain connectivity from fMRI studies has become an important tool in studying functional interactions in the human brain as a complex network. Most recently, research has started focusing on whole brain functional networks at the voxel-level, where fMRI time-signals at each voxel are correlated with every other voxel in the brain to determine their functional connectivity. For a typical 4mm isotropic voxel resolution, this results in connectivity networks with more than twenty thousand nodes and over 400 million links. These cannot be effectively visualized or interactively explored using node-link representations, and due to their size are challenging to show as correlation matrix bitmaps. In this paper, we present a number of methods for the visualization and interactive visual analysis of this new high resolution brain network data, both in its matrix representation as well as in its anatomical context. We have implemented these methods in a GPU raycasting framework that enables real-time interaction, such as network probing and volume deformation, as well as real-time filtering. The techniques are integrated in a visual analysis application in which the different views are coupled, supporting linked interaction. Furthermore, we allow visual comparison of different brain networks with side-by-side and difference visualization. We have evaluated our approach via case studies with domain scientists at two different university medical	4d film;bitmap;complex network;image resolution;interaction;interactive visual analysis;interactivity;map;matrix representation;ray casting;real-time clock;resting state fmri;visual comparison;volume rendering;voxel	Andre F. van Dixhoorn;Julien Milles;Baldur van Lew;Charl P. Botha	2012		10.2312/VCBM/VCBM12/099-106	computer vision;computer science;theoretical computer science;computer graphics (images)	Visualization	-27.90274970627822	-37.39698624362879	71844
421ce8b598043813400e60820e0d89d593eac9d6	a noise map of new york city	urban noises;big data;urban computing;social media	This demonstration presents a noise map of New York City, based on four ubiquitous data sources: 311 complaint data, social media, road networks, and Point of Interests (POIs). The noise situation of any location in the city, consisting of a noise pollution indicator and a noise composition, is derived through a context-aware tensor decomposition approach we proposed in [5]. Our demo highlights two components: a) ranking locations based on inferred noise indicators in various settings, e.g., on weekdays (or weekends), at a time slot (or overall time), and in a noise category (or all categories); b) revealing the distribution of noises over different noise categories in a location.	emoticon;social media	Yilun Wang;Yu Zheng	2014		10.1145/2638728.2638776	big data;social media;telecommunications;computer science	HCI	-19.814869372006537	-34.03192898807098	71853
07d8f5baec71ced46b53695224439c816519b405	high volume geospatial mapping for internet-of-vehicle solutions with in-memory map-reduce processing	geospatial mapping;internet of vehicles;performance;roads vehicles geospatial analysis java computational efficiency hardware real time systems;big data;raf high volume geospatial mapping internet of vehicle solutions in memory map reduce processing iov computational efficiency storage accesses avoidance hadoop based approach jts java awt vehicle positions road segments secondary sort in memory processing lightweight in memory computing framework computational throughput;hadoop;road vehicles driver information systems geographic information systems internet of things java mobile computing;geospatial mapping hadoop big data internet of vehicles performance	With the flourishing of IoV(Internet of Vehicles) technology, location based services need to handle the positional coordinates streaming in continuously from large numbers of vehicles. Across the hundreds of thousands of kilometers of roads, with tens of millions of vehicles on them, it is a significant performance challenge to determine in real time where vehicles are; how quickly and where they are headed; and when, where, and how much congestion can be expected to build as a result. The high volume of data and the rate at which the mappings must be performed require high computational efficiency and avoidance of storage accesses where possible. This paper introduces a Hadoop based approach for handling such large volumes of information. The paper describes a couple of simple adjustments to methods available in JTS and Java AWT that provide efficient mapping between vehicle positions and road segments, shows the importance of secondary sort in achieving the needed computational throughput, and establishes the significant performance benefit to be achieved from in-memory processing. An evaluation using RAF, a lightweight in-memory computing framework, shows the mapping is 20X+ faster than Hadoop approach to achieve results for real-time operation.	abstract window toolkit;agile software development;analysis of algorithms;apache hadoop;cartography;computation;geographic coordinate system;geographic information system;geospatial analysis;in-memory database;in-memory processing;internet;java topology suite (jts);location-based service;mapreduce;memory map;network congestion;object type (object-oriented programming);provisioning;real-time clock;real-time computing;run time (program lifecycle phase);scalability;streaming media;throughput;tree traversal	Tao Zhong;Kshitij A. Doshi;Gang Deng;Xiaoming Yang;Hegao Zhang	2014	2014 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2014.7004309	real-time computing;simulation;computer science;world wide web	HPC	-21.544496287780447	-30.46365829151482	71919
4f4138548394b83146ff3c225c38f57d70a6cdfc	visualizing and discovering non-trivial patterns in large time series databases	motif discovery;anomaly detection;euclidean distance;time series;data mining;suffix tree;pattern discovery;data analysis;visualization;local structure;tree structure;data visualization;query by content;time series data;visual system;symbolic representation	Data visualization techniques are very important for data analysis, since the human eye has been frequently advocated as the ultimate data-mining tool. However, there has been surprisingly little work on visualizing massive time series datasets. To this end, we developed VizTree, a time series pattern discovery and visualization system based on augmenting suffix trees. VizTree visually summarizes both the global and local structures of time series data at the same time. In addition, it provides novel interactive solutions to many pattern discovery problems, including the discovery of frequently occurring patterns (motif discovery), surprising patterns (anomaly detection), and query by content. VizTree works by transforming the time series into a symbolic representation, and encoding the data in a modified suffix tree in which the frequency and other properties of patterns are mapped onto colors and other visual properties. We demonstrate the utility of our system by comparing it with state-of-the-art batch algorithms on several real and synthetic datasets. Based on the tree structure, we further device a coefficient which measures the dissimilarity between any two time series. This coefficient is shown to be competitive with the well-known Euclidean distance.	algorithm;anomaly detection;coefficient;color;data mining;data visualization;database;euclidean distance;motif;suffix tree;synthetic intelligence;time series;tree structure;whole earth 'lectronic link	Jessica Lin;Eamonn J. Keogh;Stefano Lonardi	2005	Information Visualization	10.1057/palgrave.ivs.9500089	anomaly detection;computer science;data science;machine learning;time series;data mining;data visualization;statistics	ML	-27.20072478969348	-33.98354124495941	72086
2c615f6166517e1aef83fa1d4ca5fb33de402d03	an architecture for collaborative driving systems	protocols;t technology general;automobiles;collaboration;automated highways;q science general;intelligent cruise control collaborative driving systems vehicle automation driver assistance antilock braking emergency braking;qa75 electronic computers computer science;computer architecture;merging;road vehicles automated highways driver information systems;driver information systems;protocols collaboration automobiles merging computer architecture hardware;tk electrical engineering electronics nuclear engineering;ta engineering general civil engineering general;hardware;road vehicles	Vehicle automation has progressed from systems that monitor the operation of a vehicle and assist a driver, with functions such as antilock braking and cruise control, to systems that detect the operation of adjacent vehicles, to implement emergency braking and intelligent cruise control. The next generation of systems will share sensor readings and collaborate to control braking operations by looking several cars ahead or by creating safe gaps for merging vehicles. The rules that control the interaction between automobiles are protocols.		Shou-pon Lin;Nicholas F. Maxemchuk	2012	2012 20th IEEE International Conference on Network Protocols (ICNP)	10.1109/ICNP.2012.6459954	communications protocol;simulation;computer science;cadence braking;collaboration	Robotics	-21.386573225979603	-25.87043981577572	72440
8f6482f3cd56ab4a2b96219b23b3ae5f1e396382	big data on a few pixels	white spaces;visualization;big data;data visualization;scalability;rendering computer graphics;bars	Data aggregation techniques help to reduce large data volumes in data visualization systems and are particularly effective when incorporating the spatial properties of the final visualization. One such technique is the Visualization-Driven Data Aggregation (VDDA) that models the pixel-level overplotting as data reduction query inside the database. In this paper, we extend VDDA with a novel approach to prepare high-dimensional data for the visualization in chart matrices. Incorporating properties of human perception, we introduce and formalize visual capacity functions for the most common chart types and use these functions for automatically configuring the best-perceivable visualization to contain the acquired data. We demonstrate how the introduced capacity functions can be used for VDDA-precedent pruning using real-world data in a relational database.	big data;data aggregation;data visualization;global variable;pixel;relational database;scalability	Uwe Jugel;Zbigniew Jerzak;Volker Markl	2016	2016 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2016.7840684	scientific visualization;information visualization;computer science;data science;data mining;database	Visualization	-25.76334776048697	-31.12493182327629	72637
308073753eadf2e5b47141e60bc482ef082b8ac6	clues: a unified framework supporting interactive exploration of density-based clusters in streams	density based cluster;data stream;real time;user study;spectrum;multi dimensional;visualization;experimental evaluation;interaction technique;stream;evolution	Although various mining algorithms have been proposed in the literature to efficiently compute clusters, few strides have been made to date in helping analysts to interactively explore such patterns in the stream context. We present a framework called CLUES to both computationally and visually support the process of real-time mining of density-based clusters. CLUES is composed of three major components. First, as foundation of CLUES, we develop an evolution model of density-based clusters in data streams that captures the complete spectrum of cluster evolution types across streaming windows. Second, to equip CLUES with the capability of efficiently tracking cluster evolution, we design a novel algorithm to piggy-back the evolution tracking process into the underlying cluster detection process. Third, CLUES organizes the detected clusters and their evolution interrelationships into a multidimensional pattern space - presenting clusters at different time horizons and across different abstraction levels. It provides a rich set of visualization and interaction techniques to allow the analyst to explore this multi-dimensional pattern space in real-time. Our experimental evaluation, including performance studies and a user study, using real streams from ground group movement monitoring and from stock transaction domains confirm both the efficiency and effectiveness of our proposed CLUES framework.	algorithm;application domain;cluster analysis;computer cluster;evolution;interaction technique;interactivity;microsoft windows;real-time clock;real-time locating system;sed;unified framework;usability testing	Di Yang;Zhenyu Guo;Elke A. Rundensteiner;Matthew O. Ward	2011		10.1145/2063576.2063694	spectrum;real-time computing;simulation;visualization;computer science;data mining;evolution;database;stream;world wide web;interaction technique	DB	-25.74762345266414	-34.23942402208724	72960
4a61faca2ab0071c598615b339879af40d6b90be	some early computers for aviators	instruments;history;calculators;analog computation;computer applications;military aircraft;airplanes;numerical computation;world war ii;analog computers;aircraft navigation military computing calculators military aircraft analog computers instruments history computer applications airplanes marine navigation;military computing;marine navigation;aircraft navigation	During the years between the World Wars aviation became established as a credible form of transport. Airmail delivery and passenger service gained acceptance with the civilian population, while aircraft for observation, transport, and combat roles were adopted by military and naval forces. A pre-requisite to routine air travel was the development of reliable methods of aerial navigation. In addition to new navigational techniques and instruments, numerous computational aids were developed to simplify the aerial navigator's work. Highly specialized computational aids were also developed to assist military aviators in performing aerial gunnery and bombardment. The following article describes a few of these devices, with special attention given to the mechanical analog computers used in military aircraft during World War II.	aerial photography;airmail;analog computer;television antenna	Paul G. McConnell	1991	Annals of the History of Computing	10.1109/MAHC.1991.10013	analog computer;navigation;simulation;aerospace engineering;engineering;electrical engineering;aeronautics;computer applications;world war ii	Robotics	-22.29248112927385	-24.965898510186566	73068
02fe0f7ab90d24f3bd75061da606864de3066a4c	learning pattern graphs for multivariate temporal pattern retrieval	inproceedings	We propose a two-phased approach to learn pattern graphs, a powerful pattern language for complex, multivariate temporal data, which is capable of reflecting more aspects of temporal patterns than earlier proposals. The first phase aims at increasing the understandability of the graph by finding common substructures, thereby helping the second phase to specialize the graph learned so far to discriminate against undesired situations. The usefulness is shown on data from the automobile industry and the libras data set by taking the accuracy and the knowledge gain of the learned graphs into account.	parallel computing;pattern language	Sebastian Peter;Frank Höppner;Michael R. Berthold	2012		10.1007/978-3-642-34156-4_25	computer science;machine learning;pattern recognition;data mining	ML	-24.78175639632717	-32.846583542047995	73621
4615a5c74bec1534dd3de8aaa2d774e2cdb24f05	self-organizing maps for multi-objective pareto frontiers	resource allocation;data visualisation;self organising feature maps data structures data visualisation decision making interactive systems resource allocation;self organising feature maps;data structures;real world multiobjective case studies multiobjective pareto frontiers decision makers pareto frontier visualization objective functions visual interactive approach pareto frontier data semantically enhanced self organizing map 2d mapping visual representation;inproceedings;interactive systems;data visualization visualization vectors optimization layout neurons decision making	Decision makers often need to take into account multiple conflicting objectives when selecting a solution for their problem. This can result in a potentially large number of candidate solutions to be considered. Visualizing a Pareto Frontier, the optimal set of solutions to a multi-objective problem, is considered a difficult task when the problem at hand spans more than three objective functions. We introduce a novel visual-interactive approach to facilitate coping with multi-objective problems. We propose a characterization of the Pareto Frontier data and the tasks decision makers face as they reach their decisions. Following a comprehensive analysis of the design alternatives, we show how a semantically-enhanced Self-Organizing Map, can be utilized to meet the identified tasks. We argue that our newly proposed design provides both consistent orientation of the 2D mapping as well as an appropriate visual representation of individual solutions. We then demonstrate its applicability with two real-world multi-objective case studies. We conclude with a preliminary empirical evaluation and a qualitative usefulness assessment.	data point;gon;interactivity;objectivity/db;organizing (structure);pareto efficiency;requirement;self-organizing map	Shahar Chen;David Amid;Ofer M. Shir;Lior Limonad;David Boaz;Ateret Anaby-Tavor;Tobias Schreck	2013	2013 IEEE Pacific Visualization Symposium (PacificVis)	10.1109/PacificVis.2013.6596140	computer science;artificial intelligence;machine learning;data mining	AI	-29.0406843391419	-27.762699391118264	74353
5867be7724fb816d65010600640ddf216d4dad8a	qualitative spatial representation for situational awareness and spatial decision support	decision support;representacion espacial;systeme information geographique;realite virtuelle;geographic information system;realidad virtual;systeme aide decision;information retrieval;virtual reality;raisonnement qualitatif;sistema ayuda decision;human subjects;spatial decision support;decision support system;situation awareness;spatial representation;graphic user interface;razonamiento calitativo;representation spatiale;qualitative reasoning;3d display;sistema informacion geografica;support function	This paper summarizes elements of research on the effectiveness of using qualitative spatial representation (QSR) in 2D and 3D display modes to determine its usefulness for situational awareness and decision making. The study involved: 1) creating spatial query functions based on QSR that capture knowledge about objects in space; 2) building these query functions into a graphical user interface environment as simulated user accessible support functions; and 3) testing the utility of these support functions by evaluating the performance of human subjects in solving sets of spatial decision-making and information retrieval tasks.		Christopher D. Ellis;Douglas M. Johnston	1999		10.1007/3-540-48384-5_29	support function;situation awareness;computer vision;stereo display;qualitative reasoning;decision support system;computer science;artificial intelligence;graphical user interface	HCI	-32.78953407586358	-28.192708976207143	74824
2c4a6dd01ff710bf790bd53b3e10de25ad2091da	time-varying data visualization using clustered heatmap and dual scatterplots	clustering process time varying data visualization clustered heatmap dual scatterplots interactive filtering nonimportant data items time steps interactive mechanism dendrogram slider widgets;clustering time varying data visualization heatmap scatterplot;time varying filters data visualisation information filtering interactive systems pattern clustering;data visualization space heating image color analysis clustering algorithms correlation process control	Heatmap is one of the effective representations for time-varying data visualization. It may require large display spaces when an input dataset contains large number of data items or time steps. We may often want mechanisms to interactively filter non-important data items or time steps, so that we can form appropriate sizes of heatmaps and focus on important data items or time steps. This paper presents a heatmap-based time-varying data visualization technique featuring an interactive mechanism to display meaningful data items and time steps. This technique firstly calculates distances between arbitrary pairs of data items, and constructs a dendrogram consisting the data items. It then generates clusters of the data items and displays the data items belonging to the specified sizes of clusters in the heatmap, so that we can focus on groups of similar or correlated data items. It applies a similar mechanism to a set of time steps so that we can remove outlier time steps from the heatmap. Our implementation features two scatterplots, which represent distribution of data items and time steps respectively, and slider widgets to interactively adjust the thresholds of the clustering process. We can intuitively understand how clusters of data items or time steps are constructed, by looking at the scatterplots while operating the sliders.	algorithm;cluster analysis;data visualization;dendrogram;heat map;hierarchical clustering;interactivity;scientific visualization;usability	Satsuki Kumatani;Takayuki Itoh;Yousuke Motohashi;Keisuke Umezu;Masahiro Takatsuka	2016	2016 20th International Conference Information Visualisation (IV)	10.1109/IV.2016.50	computer science;data mining;multimedia;cluster analysis;computer graphics (images)	DB	-28.273777513746047	-34.03881768844305	74904
0f1d14a6a4414584a9067e978cd2d3eb85d8599b	network visualization by semantic substrates	automatic control;user defined semantic substrates;data visualization displays law legal factors tunneling filters scalability graphical user interfaces terminology automatic control;legal precedent data;nvss 1 0;network visualization;filters;information visualization;law;data visualisation;legal factors;graphical user interfaces;legal citations;graphical user interfaces data visualisation;displays;data visualization;graphic user interface;terminology;scalability;semantic substrate;graphical user interfaces network visualization information visualization designers user defined semantic substrates nvss 1 0 legal precedent data legal citations;user interaction;graphical user interfaces network visualization semantic substrate information visualization;information visualization designers;tunneling	Networks have remained a challenge for information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a strategy based on two principles: (1) layouts are based on user-defined semantic substrates, which are non-overlapping regions in which node placement is based on node attributes, (2) users interactively adjust sliders to control link visibility to limit clutter and thus ensure comprehensibility of source and destination. Scalability is further facilitated by user control of which nodes are visible. We illustrate our semantic substrates approach as implemented in NVSS 1.0 with legal precedent data for up to 1122 court cases in three regions with 7645 legal citations	clutter;graph drawing;imagery;information visualization;interactivity;nrao vla sky survey;national vital statistics system (nvss);node - plant part;scalability;user interface;citation	Ben Shneiderman;Aleks Aris	2006	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2006.166	human–computer interaction;computer science;data mining;graphical user interface;database;world wide web;data visualization;statistics	Visualization	-28.860907991680627	-34.839839765352636	74981
6b6c1122117830ec9494fe5d916c4cb419364033	schemadrill: interactive semi-structured schema design		Ad-hoc data models like JSON make it easy to evolve schemas and to multiplex different data-types into a single stream. This flexibility makes JSON great for generating data, but also makes it much harder to query, ingest into a database, and index. In this paper, we explore the first step of JSON data loading: schema design. Specifically, we consider the challenge of designing schemas for existing JSON datasets as an interactive problem. We present SchemaDrill, a roll-up/drill-down style interface for exploring collections of JSON records. SchemaDrill helps users to visualize the collection, identify relevant fragments, and map it down into one or more flat, relational schemas. We describe and evaluate two key components of SchemaDrill: (1) A summary schema representation that significantly reduces the complexity of JSON schemas without a meaningful reduction in information content, and (2) A collection of schema visualizations that help users to qualitatively survey variability amongst different schemas in the collection.	data drilling;data model;hoc (programming language);interactivity;json;keyboard technology;multiplexing;self-information;semiconductor industry;spatial variability	William Spoth;Ting Xie;Oliver Kennedy;Ying Yang;Beda Christoph Hammerschmidt;Zhen Hua Liu;Dieter Gawlick	2018		10.1145/3209900.3209908	decision analysis;information integration;database;computer science;data mining;data modeling;json;schema (psychology);data quality	DB	-30.433370129167773	-33.32197035773609	75034
7a6b9d316445e038cbc7a02fdf89d5f640beb0e0	investigating time series visualisations to improve the user experience	time series;visual encoding;visualization;evaluation;graphical perception;interaction technique;coordinate system	Research on graphical perception of time series visualisations has focused on visual representation, and not on interaction. Even for visual representation, there has been limited study of the impact on users of visual encodings and the strengths and weaknesses of Cartesian and Polar coordinate systems. In order to address this research gap, we performed a comprehensive graphical perception study that measured the effectiveness of time series visualisations with different interactions, visual encodings and coordinate systems for several tasks. Our results show that, while positional and colour visual encodings were better for most tasks, area visual encoding performed better for data comparison. Most importantly, we identified that introducing interactivity within time series visualisations considerably enhances the user experience, without any loss of efficiency or accuracy. We believe that our findings can greatly improve the development of visual analytics tools using time series visualisations in a variety of domains.	graphical user interface;interaction;interactivity;time series;user experience;visual analytics	Muhammad Adnan;Mike Just;Lynne Baillie	2016		10.1145/2858036.2858300	computer vision;visualization;human–computer interaction;computer science;evaluation;coordinate system;time series;multimedia;interaction technique	HCI	-28.894912741794272	-36.51764822050245	75156
5e4d4242757bf56594dc2b4641311cf3ef614ddc	summarizing video information using self-organizing maps	user modelling;multimedia retrieval systems;self organizing maps;multimedia retrieval;video retrieval;classification;visualization components;structuring components;data visualisation;video information summarization;content visualization;self organising feature maps;self organizing feature maps data mining feature extraction streaming media multimedia databases data visualization multimedia systems prototypes spatial databases visual databases;video retrieval classification content based retrieval data visualisation multimedia databases self organising feature maps user modelling;multimedia databases;multimedia information;self organized map;intuitive hierarchical interaction;user interaction;content based retrieval;user modelling video information summarization self organizing maps multimedia information multimedia retrieval systems structuring components visualization components intuitive hierarchical interaction content visualization	Facing a huge amount of multimedia information available today, it becomes inevitably necessary to develop efficient methods for accessing, searching, structuring, and representing it. Multimedia retrieval systems especially in the case of video should support users in all of these tasks. Therefore, specialized systems that focus on each of these aspects have been developed. However, an open research perspective issue is the development of a retrieval tool that integrates all user interactions in a single interface. In this paper, we present a system that focuses on the summarization of one single video. We consider the structuring and visualization components including reasonable user interactions to have the most significant influence on the systems usability. Our prototype is based on growing self-organizing maps. The emphasis is on intuitive hierarchical interaction for content visualization exploiting the features of the maps and integrating additional potentially useful information.	interaction;open research;organizing (structure);prototype;self-organization;self-organizing map;usability	Thomas Bärecke;Ewa Kijak;Andreas Nürnberger;Marcin Detyniecki	2006	2006 IEEE International Conference on Fuzzy Systems	10.1109/FUZZY.2006.1681764	self-organizing map;biological classification;computer science;machine learning;data mining;multimedia;information retrieval;data visualization	Visualization	-30.74288470062455	-32.84083456794998	75496
88921147b81af6c6c390fcd1589b71c42306b204	hybrid motion graph for character motion synthesis	motion template;motion synthesis;motion graph;motion fields;motion transition	Objective: This paper proposes a novel framework of Hybrid Motion Graph (HMG) for creating character animations, which enhances the graph-based structural control by motion field representations for efficient motion synthesis of diverse and interactive character animations. Methods: In HMG framework, the motion template of each class is automatically derived from the training motions for capturing the general spatio-temporal characteristics of an entire motion class. Typical motion field for each class is then constructed. The smooth transitions among motion classes are then generated by interpolating the related motion templates with spacetime constraints. Finally, a hybrid motion graph is built by integrating the separate motion fields for each motion class into the global structural control of motion graph through smooth transition. Results: In motion synthesis stage, a character may freely ‘switch’ among different motion classes in the hybrid motion graph via smooth transitions between motion templates and ‘flow’ within each class through the continuous space of motion field with agile and the continuous control process. Conclusion: Experimental results show that our framework realizes the fast connectivity among different motion classes and high responsiveness and interactivity for creating realistic character animation of rich behaviors with limited motion data and computa-	agile software development;interactivity;interpolation;motion field;responsiveness;speech synthesis	Weiwei Xing;Xiang Wei;Jian Zhang;Cheng Ren;Wei Lu	2014	J. Vis. Lang. Comput.	10.1016/j.jvlc.2013.10.001	computer vision;structure from motion;simulation;motion estimation;motion field;mechanics of planar particle motion	Graphics	-24.38868260814191	-36.82597678181936	75522
4906ee442d870e0c679ec3a197e697b319ab38d0	volume visualization and exploration based on semi-automatic multidimensional transfer function design	hierarchical clustering;hierarchical visualization multidimensional transfer function cluster analysis volume rendering parallel coordinates;transfer functions data visualization clustering algorithms rendering computer graphics image color analysis partitioning algorithms density functional theory;pattern clustering;multidimensional transfer function;high density;three dimensions;volume rendering;hierarchical visualization;hsv color space;interactive method;marching cube method volume visualization semiautomatic multidimensional transfer function design scalar data multivariate volume data physical simulation medical treatment visual analytics volumetric data set color property interaction method cluster distribution multidimensional multivariate space hierarchical tree 2d radial layout semiautomatic coloring scheme hierarchical cluster tree encoding hue saturation hsv color space;data visualisation;cluster analysis;transfer function;clustering method;volume visualization;visual analytics;medical treatment;marching cube;multivariate data;pattern clustering data visualisation;physical simulation;parallel coordinates;volume data	Exploration and analysis of scalar and multivariate volume data play an important role in different domains from physical simulations to medical treatments. In visual analytics of volumetric data sets we need to define a multidimenional transfer functions. This is a challenging task because of the difficulty in understanding multiple attribute spaces and displaying in physical three dimension space. Frequently, the transfer function is designed based on mapping one or two dimensional space to color properties (RGB) and opacity (A). We propose visualization and interaction methods for analyzing individual clusters as well as cluster distribution within and across levels in the cluster hierarchy. We also provide a clustering method that operates on density rather than individual records. We compute density in the given multidimensional multivariate space. Clusters are formed by areas of high density. We present an approach that automatically computes a hierarchical tree of high density clusters. To visually represent the cluster hierarchy, we present a 2D radial layout that supports an intuitive understanding of the distribution structure of the multidimensional multivariate data set. We apply a semi-automatic coloring scheme based on the 2D radial layout of the hierarchical cluster tree encoding hue, saturation, and value of the HSV color space. The system support an easily method to define the multidimensional transfer function over entire multidimensional attributes space. Finally, the surface extract by applying marching cube methods.	algorithm;cluster analysis;color space;embedded system;graph coloring;isosurface;marching cubes;olap cube;parallel coordinates;radial (radio);ray casting;scientific visualization;semiconductor industry;simulation;transfer function;user interface;visual analytics	Tran Van Long	2011	2011 Third International Conference on Knowledge and Systems Engineering	10.1109/KSE.2011.17	three-dimensional space;computer vision;multivariate statistics;visual analytics;hsl and hsv;parallel coordinates;computer science;theoretical computer science;machine learning;hierarchical clustering;transfer function;marching cubes;cluster analysis;volume rendering;statistics;computer graphics (images)	Visualization	-28.50532133326022	-33.53014963392236	75789
6dab04b48bd8db79dfa0c929574c3a23a0856932	a game-independent play trace dissimilarity metric		This paper defines a metric for comparing play traces (sequences of user decisions) in a game-independent way. The properties of this metric are determined by a proposed tool we call the Gamalyzer, an exploratory visualization of arbitrary games which clusters together similar play traces. Our Gamalyzer metric is based on refinements to edit distance and has broad uses outside of visualization and, indeed, outside of games (e.g. player and opponent modeling, goal recognition, player mimicry, user testing, and so on). We validate our metric against one synthetic and one real-world data set, finding that Gamalyzer discerns designer-relevant differences between play traces nearly as well as hand-tuned feature selection while remaining gameand genre-agnostic. The main problem with conventional game visualizations is that judging the similarity of two game states is an underspecified problem requiring knowledge of game rules and of the purpose for which the states are being compared. Gamalyzer, in contrast, directly compares sequences of actions: it considers strategies instead of states. Existing game visualizations require significant development effort for individual genres, games, and even specific queries. Our proposed visualization (based on the Gamalyzer metric) could quickly and inexpensively show designers the strategic landscape of their game without requiring specialized knowledge of statistics or machine learning.	edit distance;feature selection;machine learning;synthetic data;tracing (software);usability testing;video game developer	Joseph C. Osborn;Michael Mateas	2014			simulation;machine learning;computer science;artificial intelligence	HCI	-26.161459668052988	-36.32725767122214	75929
e16b199dc24ad53fd5e44c6022d2df195dfaaf43	patterns of internal migration of mexican highly qualified population through network analysis		Many real, social, technological, biological and information systems can be described as complex networks. Nonetheless, few studies treat migration from this standpoint. Some migration studies focus on people, and some others on places. The former require very detailed data, while the latter are based on aggregate data. This study is based on places and uses aggregate data, taking flows as an observable and their resulting patterns are the object of study. Mexican censual events take place every ten years, the most recent on 2010, and it has been only until recently that there are enough capabilities and tools available to visualize and model internal migration to the municipal level. Few studies have focused on analyzing migratory movements of such detail, opting instead for the state level. Network analysis allows the identification of communities with a certain degree of spatial structure, that is, the importance that geographical proximity plays in migration.		Camilo Caudillo-Cos;Rodrigo Tapia-McClung	2014		10.1007/978-3-319-09147-1_13	demography	ML	-20.511468748376142	-36.99860301901679	76310
971009dc9f8597368174b1bf6238d1dc39789239	mobile augmented reality for environmental monitoring	mobile visualization;environmental sensor networks;mobile augmented reality	In response to dramatic changes in the environment, and supported by advances in wireless networking, pervasive sensor networks have become a common tool for environmental monitoring. However, tools for on-site visualization and interactive exploration of environmental data are still inadequate for domain experts. Current solutions are generally limited to tabular data, basic 2D plots, or standard 2D GIS tools designed for the desktop and not adapted to mobile use. In this paper, we introduce a novel augmented reality platform for 3D mobile visualization of environmental data. Following a user-centered design approach, we analyze processes, tasks, and requirements of on-site visualization tools for environmental experts. We present our multilayer infrastructure and the mobile augmented reality platform that leverages visualization of georeferenced sensor measurement and simulation data in a seamless integrated view of the environment.	augmented reality;desktop computer;geographic information system;requirement;seamless3d;simulation;table (information);user-centered design	Eduardo E. Veas;Raphaël Grasset;Ioan Ferencik;Thomas Grünewald;Dieter Schmalstieg	2012	Personal and Ubiquitous Computing	10.1007/s00779-012-0597-z	simulation;human–computer interaction;multimedia	HCI	-33.28761557485014	-30.158359938025544	76317
6500db911cbbc9531f5af518e1daabab2170a512	poster: optimal path finding for emergency cases on android	gps;gsm mssd;optimal path finding	This paper intends to develop the optimal path finding for emergency cases on mobile devices. According to the weak road network infrastructure of Myanmar, there are some difficulties for Emergency Vehicles. In some townships, there are narrowed roads which are not wide enough to enter the vehicles and closed roads which are not passed through the other streets. In the emergency cases (e.g. Accident or Fire), the drivers mistakenly choose these roads, it can cause problems and delays. The main objective of this system is to find the optimal routes between incident site and emergency services without delay caused by closed and narrowed roads. The system uses Multiple Sources Single-Destination (MSSD) Algorithm using node exclusion to calculate optimal route. Our proposed system significantly solves to find the accident location and locate the closest emergency services by using the real-time technology (GPS/GSM).	algorithm;android;global positioning system;mobile device;pathfinding;real-time clock	K.-zin Phyo;Myint Myint Sein	2016		10.1145/2938559.2948851	simulation;global positioning system;computer security	Mobile	-19.473595121796933	-28.79243269069165	76703
78aecb9ee89abd88564277a08e1353afac608dd3	polyphonic accompaniment using genetic algorithm with music theory	rhythm;evolutionary computation;genetic algorithms biological cells rhythm evolutionary computation humans genetics;genetics;biological cells;music artificial intelligence genetic algorithms;artificial intelligence;genetic algorithms;humans;music;fitness function polyphonic accompaniment genetic algorithm music theory artificial intelligence computational intelligence automatic music composition computational creativity evolutionary computation human feedback	Computational creativity using artificial intelligence and computational intelligence has received increasing attention. Automatic music composition is a blooming field in computational creativity; especially, automatic accompaniment has gained some promising results. However, most of the automatic accompaniment systems based on evolutionary computation require human feedback as evaluation criterion, which is vulnerable to the fatigue and decreased sensitivity after long-time listening. This study adopts music theory as the basis of evaluation criterion for accompaniment to address this issue. Specifically, we develop a genetic algorithm (GA) to generate polyphonic accompaniment, in which the fitness function consists of several evaluation rules based on music theory. Three accompaniments, i.e., main, bass, and chord accompaniments are considered in the study. Experimental results show that, given a dominant melody, the proposed method can effectively generate multiple scores to form polyphonic accompaniment.	artificial intelligence;beneath a steel sky;bloom (shader effect);computational creativity;computational intelligence;evolutionary computation;fitness function;genetic algorithm	Chien-Hung Liu;Chuan-Kang Ting	2012	2012 IEEE Congress on Evolutionary Computation	10.1109/CEC.2012.6252869	evolutionary music;speech recognition;computer science;artificial intelligence;rhythm;machine learning;music;pop music automation;evolutionary computation	AI	-27.624776417067665	-25.952500840456263	77251
cad02fe8871f117b3ba5d5f9ceea89daebf2b505	navigating product catalogs using 2+1d fisheye browser		This paper introduces a novel user interface of online product catalogs. Our research focused on its capability for helping shoppers to navigate and analyze online product information. Specifically, we discuss the application of a new multi-level focus+context visualization technique, called 2+1D Fisheye Browser; in the design of interactive visual interface which can be used to assist buyers in navigating online product catalogs which contain large number of products. The 2+1D Fisheye Browser uses an ordinary 2D Hyperbolic Tree Browser to display the major structure of hierarchies while a ID distortion-based Fisheye Menu is also used to assist the display of those sub-hierarchies containing large number of leaf nodes. We implement this technique as a visual product catalog of an online Grocery Shop. This Grocery Shop system simulates the experience of online shopping. It is applicable to any e-commerce shopping application.	fisheye	Wu Quan;Mao Lin Huang	2004			world wide web;hyperbolic tree;visualization;database;user interface;computer science	NLP	-32.1277816005039	-33.91919795940164	77340
58ca5e07ee007970365d3492aea8544a0717d866	from game events to team tactics: visual analysis of dangerous situations in multi-match data	inproceedings	Sport analytics in general and soccer analytics in particular constitute quickly growing markets when it comes to professional analyses and visualizations. From a data analysis research perspective, soccer is a rich source of geospatial and temporal movement data, with high details and a controlled environment. However, soccer movement is complex as its compounds are actions and reactions of two opposing teams with inverse goals. Common analyses performed today are typically oriented towards statistical analysis and considering aggregate measurements. In this work, we propose a set of effective visual-interactive methods for investigating set plays as a first step towards semi-automated analysis of tactic behavior. In our analytic design, we follow the so-called Information-seeking Mantra by Ben Shneiderman by providing overview visualizations, interactive refinements, and detailed analysis views. We take an applied approach in showing case studies that give evidence for the applicability and merits of our proposed techniques.	aggregate data;feature vector;glyph;high-level programming language;information seeking;interactivity;interdependence;semiconductor industry;time series;web analytics	Manuel Stein;Halldór Janetzko;Andreas Lamprecht;Daniel Seebacher;Tobias Schreck;Daniel A. Keim;Michael Grossniklaus	2016	2016 1st International Conference on Technology and Innovation in Sports, Health and Wellbeing (TISHW)	10.1109/TISHW.2016.7847777	simulation;engineering;social psychology;operations research	Visualization	-25.536447585772077	-34.93769180553237	77469
9a24773c1f66cc0a465e342b8c61cc398b8fe6b0	variable binned scatter plots	journal_article;variable binned scatter plots;correlations;continuous variable;cause effect;data distribution;data center;energy consumption;patterns;credit cards	The scatter plot is a well-known method of visualizing pairs of two continuous variables. Scatter plots are intuitive and easy-to-use, but often have a high degree of overlap which may occlude a significant portion of the data. To analyze a dense non-uniform dataset, a recursive drill-down is required for detailed analysis. In this paper, we propose variable binned scatter plots to allow the visualization of large amounts of data without overlapping. The basic idea is to use a non-uniform (variable) binning of the x and y dimensions and to plot all data points that are located within each bin into the corresponding squares. In the visualization, each data point is then represented by a small cell (pixel). Users are able to interact with individual data points for record level information. To analyze an interesting area of the scatter plot, the variable binned scatter plots with a refined scale for the subarea can be generated recursively as needed. Furthermore, we map a third attribute to color to obtain a visual clustering. We have applied variable binned scatter plots to solve real-world problems in the areas of credit card fraud and data center energy consumption to visualize their data distributions and causeeffect relationships among multiple attributes. A comparison of our methods with two recent scatter plot variants is included.	cluster analysis;color;credit card fraud;data center;data drilling;data point;distortion;pixel;product binning;recursion	Ming C. Hao;Umeshwar Dayal;Ratnesh K. Sharma;Daniel A. Keim;Halldór Janetzko	2010	Information Visualization	10.1057/ivs.2010.4	scatter plot;data center;statistical graphics;computer science;data mining;pattern;bivariate data;partial residual plot;statistics	ML	-26.860752982614507	-33.08849554784643	77536
a769d9831611599ed8c2dbb5f530b3a68aa95a50	an interactive evolutionary design system with feature extraction	hierarchical clustering;database system;evolutionary design;genetics;conceptual design;feature extraction;interactive genetic algorithm;multidimensional scaling;conceptual design product form the interactive evolutionary design system;morphological analysis	In order to extraction the product form features, the Web-based feature database system was carried out and the feature cognition space was constructed. The form feature information was analysed and processed through Multidimensional Scaling (MDS), hierarchical clustering and morphological analysis technology. To enhance the efficiency of the automatic conceptual design, the interactive evolutionary design system (IEDS) based on the Orthogonal Interactive Genetic Algorithm (OIGA) in form design was advanced. With this method, the genetic convergence effects are improved and users' fatigues are alleviated by means of simplifying the solution space orthogonally, communizing the fitness evaluation and visualizing the project interface. Example results indicate the improved IEDS was more feasible and reasonable than the simple IEDS.		Jiang Xu;Shouqian Sun;Zhengyu Tan;Fuqian Shi	2007		10.1007/978-3-540-73111-5_119	multidimensional scaling;interactive evolutionary computation;feature extraction;morphological analysis;computer science;bioinformatics;machine learning;data mining;conceptual design;hierarchical clustering	EDA	-33.14881883877125	-32.641996094652534	77658
782d458026d72d421bcfc056beaee410e6cf5f9f	auction-based autonomous intersection management	vehicles roads delays cities and towns mobile robots pricing throughput;traffic mitigation;intersections;intersection auctions;mobile robots;signalized intersections;city scale maps auction based autonomous intersection management autonomous vehicle auctions traffic congestion traffic control schemes stop signs traffic signals autonomous reservation protocols benevolent system agent microscopic simulator;road traffic control;equity justice;traffic congestion;road traffic control mobile robots;intelligent vehicles;highway traffic control	Autonomous vehicles present new opportunities for addressing traffic congestion through flexible traffic control schemes. This paper explores the possibility that auctions could be run at each intersection to determine the order in which drivers perform conflicting movements. While such a scheme would be infeasible for human drivers, autonomous vehicles are capable of quickly and seamlessly bidding on behalf of human passengers. Specifically, this paper investigates applying autonomous vehicle auctions at traditional intersections using stop signs and traffic signals, as well as to autonomous reservation protocols. This paper also addresses the issue of fairness by having a benevolent system agent bid to maintain a reasonable travel time for drivers with low budgets. An implementation of the mechanism in a microscopic simulator is presented, and experiments on city-scale maps are performed.	algorithm;autonomous robot;autonomous system (internet);experiment;fairness measure;map;marginal model;network congestion;routing;simulation;uncore	Dustin Carlino;Stephen D. Boyles;Peter Stone	2013	16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013)	10.1109/ITSC.2013.6728285	simulation;floating car data;engineering;traffic congestion reconstruction with kerner's three-phase theory;traffic flow;transport engineering;computer security	Robotics	-20.31754969387623	-25.8999239328777	77736
d28bdc4c2203f5c82ea23b7a502588e5367ee3c5	ux graph and erm as tools for measuring kansei experience	ux curve;user experience;ux graph;erm	"""UX graph Kurosu 2015 is a revised version of UX curve Kujala et al. 2011 in which the emphasis is not on the curve itself but on the episodes that constitute the graph, hence the graph will be drawn after plotting each episodic events. Furthermore, UX graph expands its temporal scope by including the expectation before purchase and the anticipation for future.#R##N##R##N#Although the original UX graph was a paper-based method, Hashizume et al. 2016 developed a smartphone/PC application that dynamically shows the graph depending on the input episodic information and allows users to manipulate the event and the curve by finger/mouse. Compared to the original paper-based method, this interactive software facilitates users to change the coordinate of the event point vertically level of satisfaction and horizontally time.#R##N##R##N#Furthermore, another method is proposed under the name of """"ERM"""" or the experience recollection method. In this method, users are asked not to place the events at exact temporal coordinate on the abscissa but to classify them in the rough time zone. This will make it possible to represent past experience stored in memory more easily and more """"correctly""""."""	a/ux	Masaaki Kurosu;Ayako Hashizume;Yuuki Ueno;Tuyoshi Tomida;Hirotoshi Suzuki	2016		10.1007/978-3-319-39510-4_31	user experience design;simulation;human–computer interaction;computer science;artificial intelligence;data mining;enterprise risk management	HCI	-32.49002538244939	-33.88811572855012	77860
75920f7c08bfda6f86a0412bb9f63c141b884cb4	design and implementation of a mobile ambient intelligence based mesoscale weather forecasting system	mobile device;atmospheric modeling mobile handsets weather forecasting predictive models augmented reality forecasting;user location mobile ambient intelligence mesoscale weather forecasting system forecasting system design weather information prediction weather data augmented reality mobile device;mobile ambients;weather forecasting;geophysics computing;design and implementation;weather forecasting augmented reality geophysics computing mobile computing user interfaces;augmented reality;mobile computing;user interfaces	This study aims at designing a forecasting system providing the predicted weather information based on the past weather data. Meanwhile, the augmented reality on the mobile device helps users obtain the weather around users' locations.	ambient intelligence;augmented reality;mobile device	Cheng-Tsung Chen;Jenq-Shiou Leu;Kuan-Wu Su;Zhe-Yi Zhu;Tung-Hung Chiang	2012	2012 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2012.6161975	augmented reality;simulation;weather forecasting;human–computer interaction;computer science;operating system;mobile device;user interface;mobile computing;weather research and forecasting model	Robotics	-33.51690982990374	-29.478156759691448	77995
5f1e55f9d67e12d90cc707f2da60ce8e79b4f432	fleye on the car: big data meets the internet of things	collision alert system;video streaming;internet of things;quadrotors	"""Vehicle-based vision algorithms, such as the collision alert systems [4], are able to interpret a scene in real-time and provide drivers with immediate feedback. However, such technologies are based on cameras on the car, limited to the vicinity of the car, severely limiting their potential. They cannot find empty parking slots, bypass traffic jams, or warn about dangers outside the car's immediate surrounding. An intelligent driving system augmented with additional sensors and network inputs may significantly reduce the number of accidents, improve traffic congestion, and care for the safety and quality of people's lives.  We propose an open-code system, called Fleye, that consists of an autonomous drone (nano quadrotor) that carries a radio camera and flies few meters in front and above the car. The streaming video is transmitted in real time from the quadcopter to Amazon's EC2 cloud together with information about the driver, the drone, and the car's state. The output is then transmitted to the """"smart glasses"""" of the driver. The control of the drone, as well as the sensor data collection from the driver, is done by low cost (<30$) minicomputer. Most computation is done in the cloud, allowing straightforward integration of multiple vehicle behaviour and additional sensors, as well as greater computational capability."""	algorithm;autonomous robot;big data;cloud computing;computation;gnu nano;internet of things;minicomputer;network congestion;open-source software;real-time transcription;sensor;smartglasses;streaming media;unmanned aerial vehicle	Soliman Nasser;Andew Barry;Marek Doniec;Guy Peled;Guy Rosman;Daniela Rus;Mikhail Volkov;Dan Feldman	2015		10.1145/2737095.2742919	embedded system;simulation;computer science;operating system;computer security;internet of things	Mobile	-20.852756115807615	-28.354736470738253	78050
0277cab9a2d234d0bc036945d6827750f35603d7	zoomtree: unrestricted zoom paths in multiscale visual analysis of relational databases	conference_paper	Unrestricted zoom paths are much desired to gain deep understandings during visual analysis of relational databases. We present a multiscale visualization system supporting unrestricted zoom paths. Our system has a flexible visual interface on the client side, called “ZoomTree”, and a powerful and efficient back end with GPU-based parallel online data cubing and CPU-based data clustering. Zoom-trees are seamlessly integrated with a table-based overview using “hyperlinks” embedded in the table, and are designed to represent the entire history of a zooming process that reveals multiscale data characteristics. Arbitrary branching and backtracking in a zoom-tree are made possible by our fast parallel online cubing algorithm for partially materialized data cubes. Partial materialization provides a good tradeoff among preprocessing time, storage and online query time. Experiments and a user study have confirmed the effectiveness of our design.	relational database	Baoyuan Wang;Gang Chen;Jiajun Bu;Yizhou Yu	2010		10.1007/978-3-642-25382-9_21	computer science;artificial intelligence;computer graphics (images)	Vision	-30.68147292449454	-33.88886897272798	78133
cb93b14f27fec6764ea8f11ad78d7adcdbf6ea2f	motion and episode models for (simulated) football games: acquisition, representation, and use	motion analysis;citation analysis;sensor systems;information systems;multi agent system;application software;software systems;intelligent agents;permission;football;performance analysis;intelligent systems;agent systems;tv;resource conflicts;application software tv software systems motion analysis citation analysis permission performance analysis sensor systems intelligent systems information systems	One of the key problems in the study of multi agent systems in which the agents exhibit continuous behavior is the automatic recognition and analysis of intentional activities based on observable behavior. Such an analysis requires software systems to structure motions into episodes that are meaningful in the application domains, to acquire and maintain models of the activities, and to use such models to reason about multi agent system behavior. In the research sketched in this paper we study the acquisition of episode and motion models for football games. We show that these models allow for the realization of impressive application systems including interactive football TV and agent systems that assist coaches in analyzing their teams.	application domain;multi-agent system;observable;software system	Michael Beetz;Thomas Stammeier;Sven Flossmann	2004	Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems, 2004. AAMAS 2004.	10.1109/AAMAS.2004.177	application software;simulation;computer science;artificial intelligence;multi-agent system;multimedia;citation analysis;computer security;information system;software system	AI	-30.020400510758567	-27.625026601097755	78302
735c157b78e25b689150c95a05c949e02409b804	driving interactive graph exploration using 0-dimensional persistent homology features		Graphs are commonly used to encode relationships among entities, yet, their abstractness makes them incredibly difficult to analyze. Node-link diagrams are a popular method for drawing graphs. Classical techniques for the node-link diagrams include various layout methods that rely on derived information to position points, which often lack interactive exploration functionalities; and force-directed layouts, which ignore global structures of the graph. This paper addresses the graph drawing challenge by leveraging topological features of a graph as derived information for interactive graph drawing. We first discuss extracting topological features from a graph using persistent homology. We then introduce an interactive persistence barcodes to study the substructures of a force-directed graph layout; in particular, we add contracting and repulsing forces guided by the 0-dimensional persistent homology features. Finally, we demonstrate the utility of our approach across three datasets.	barcode;diagram;directed graph;encode;entity;force-directed graph drawing;homology (biology);persistence (computer science);persistent homology	Ashley Suh;Mustafa Hajij;Bei Wang;Carlos Eduardo Scheidegger;Paul Rosen	2017	CoRR		theoretical computer science;encode;computer vision;artificial intelligence;computer science;persistent homology;graph layout;graph drawing;graph	HCI	-28.991359801124663	-35.29273856282297	78470
7b357223f5a6eb20b4dbce86e7af40b4ffb4be3a	daisyviz: a model-based user interfaces toolkit for development of interactive information visualization		Although the increasing hordes of information visualization technologies are recognized both in industry and research community, there are seldom toolkits for non-expert users or end-users to rapidly design and develop domain-specific information visualization applications. Such toolkits should provide support for the unified data structures suited to tree, network, temporal and multi-dimensional data, well-known visualization techniques and interaction techniques, and generic visualization tasks. We built DaisyViz, a model-based user interfaces toolkit, which enables end-users to rapidly develop domain-specific information visualization applications without traditional programming. DaisyViz is based on an interface model called UIMI consisting of three declarative models – data model, visualization model, and control model. In the development process, users visually construct UIMI which could be used to generate profiles. Those profiles can be parsed by DaisyViz to automatically generate a prototype system. We firstly give the formal definition of UIMI, and then discuss the architecture of DaisyViz. To evaluate DasyViz we built an application in a manufacturing enterprise and performed a user study. The results show DaisyViz is usable and effective.	information visualization	Lei Ren;Feng Tian;Lin Zhang;Guozhong Dai	2009		10.1007/978-1-4419-0312-9_14	visual analytics;information visualization;interactive visualization;human–computer interaction	HCI	-30.279346532237476	-31.29783147052839	78527
3f9b88406bbac52ea0dbd94003c93facd0bae113	visibility-difference entropy for automatic transfer function generation		Direct volume rendering allows for interactive exploration of volumetric data and has become an important tool in many visualization domains. But the insight and information that can be obtained are dependent on the transfer function defining the transparency of voxels. Constructing good transfer functions is one of the most time consuming and cumbersome tasks in volume visualization. We present a novel general purpose method for automatically generating an initial set of best transfer function candidates. The generated transfer functions reveal the major structural features within the volume and allow for an efficient initial visual analysis, serving as a basis for further interactive exploration in particular of originally unknown data. The basic idea is to introduce a metric as a measure of the goodness of a transfer function which indicates the information that can be gained from rendered images by interactive visualization. In contrast to prior methods, our approach does not require a user feedback-loop, operates exclusively in image space and takes the characteristics of interactive data exploration into account. We show how our new transfer function generation method can uncover the major structures of an unknown dataset within only a few minutes.	interactive visualization;scientific visualization;transfer function;volume rendering;voxel	Philipp Schlegel;Renato Pajarola	2013		10.1117/12.2002971	computer vision;computer science;artificial intelligence;computer graphics (images)	Visualization	-27.094708932172452	-35.54458657483387	78673
615f391b0ec72eafbb61f0ebf75ed9289591c2a0	semantic map generation from satellite images for humanitarian scenarios applications	change detection;data analysis;semantic mapping;spatial distribution;satellite image;image analysis;earth observation;information theory	This paper demonstrates how knowledge driven methods and the associated data analysis algorithms are changing the paradigms of user-data interactions, providing an easier and wider access to the Earth Observation data. Some information theory based algorithms are proposed for anomaly and change detection on SPOT images, relative to a widespread humanitarian crisis scenario: floods. The outcomes of these algorithms define an informational representation of the image, revealing the spatial distribution of a particular theme. Using image analysis and interpretation, the multitude of features from a scene are classified into meaningful classes to create sematic maps.		Corina Vaduva;Daniela Faur;Anca Andreea Popescu;Inge Gavat;Mihai Datcu	2008		10.1007/978-3-540-88458-3_73	earth observation;computer vision;image analysis;information theory;computer science;data mining;data analysis;change detection;statistics	Robotics	-23.976067259097686	-31.475512340332997	78948
aafc1ab031bda77544a2ebea331177e982810545	latviz: a new practical tool for performing interactive exploration over concept lattices		With the increase in Web of Data (WOD) many new challenges regarding exploration, interaction, analysis and discovery have surfaced. One of the basic building blocks of data analysis is classification. Many studies have been conducted concerning Formal Concept Analysis (FCA) and its variants over WOD. But one fundamental question is, after these concept lattices are obtained on top of WOD, how the user can interactively explore and analyze this data through concept lattices. To achieve this goal, we introduce a new tool called as LatViz, which allows the construction of concept lattices and their navigation. LatViz proposes some remarkable improvements over existing tools and introduces various new functionalities such as interaction with expert, visualization of Pattern Structures, AOC posets, concept annotations, filtering concept lattice based on several criteria and finally, an intuitive visualization of implications. This way the user can effectively perform an interactive exploration over a concept lattice which is a basis for a strong user interaction with WOD for data analysis.	age of empires ii: the conquerors;formal concept analysis;interaction;interactivity;statistical classification	Mehwish Alam;Thi Nhu Nguyen Le;Amedeo Napoli	2016			data mining;computer science;lattice miner;lattice (order);theoretical computer science;semantic web;visualization;formal concept analysis	HCI	-30.28750312054695	-32.36993921023359	79110
b027649af904200b1ebe637b854a43a192c705f1	askfuzzy: attractive visual fuzzy query builder	front end;pragmatics;web based applications;fuzzy set;query processing;user interface;visual queries;user centric application;relational database;fuzzy set theory;fuzzy sets;visual programming;visualization;internet;visual programming fuzzy set theory internet query processing user interfaces;visual queries query interface fuzzy system user centric application;fuzzy sets visualization optimization educational institutions pragmatics relational databases;optimization;relational databases;user interfaces;query interface;fuzzy system;back end database askfuzzy attractive visual fuzzy query builder user centric query interface internet based era web based applications structured databases query coding front end visual user interface	The user-centric query interface is very common application that allows expressing both the input and the output using fuzzy terms. This is becoming a need in the evolving internet-based era where web-based applications are very common and the number of users accessing structured databases is increasing rapidly. Restricting the user group to only experts in query coding must be avoided. The Ask Fuzzy system has been developed to address this vital issue which has social and industrial impact. It is an attractive and friendly visual user interface that facilitates expressing queries using both fuzziness and traditional methods. The fuzziness is not expressed explicitly inside the database, it is rather absorbed and effectively handled by an intermediate layer which is cleverly incorporated between the front-end visual user-interface and the back-end database.	database;fuzzy control system;internet;query language;requirement;table (database);user interface;web application	Keivan Kianmehr;Negar Koochakzadeh;Reda Alhajj	2012	2012 IEEE 28th International Conference on Data Engineering	10.1109/ICDE.2012.116	computer science;data mining;database;fuzzy set;world wide web;pragmatics	DB	-31.201706104597385	-32.71090720791882	79613
60e86851d48f2355dcf3fac29819dec28179071e	volume composition using eye tracking data	i 3 7 computer graphics three dimensional graphics and realism;categories and subject descriptors according to acm ccs i 3 6 computer graphics interaction techniques;parameter selection;region of interest;eye tracking;user interaction;visual system	This paper presents a method to automate rendering parameter selection, simplifying tedious user interaction and improving the usability of visualization systems. Our approach acquire s regions-of-interest for a dataset with an eye tracker and simple user interaction. Based on this importance inform ati n, we then automatically compute reasonable rendering parameters using a set of heuristic rules ad apte from visualization experience and psychophysics experiments. While the parameter selections for a specific visualization task are subjective, our approach provides good starting results that can be refined by the user . Our system improves the interactivity of a visualization system by significantly reducing the necessary paramete r selection and providing good initial rendering parameters for newly acquired datasets of similar types.	experiment;eye tracking;heuristic;interactivity;usability	Aidong Lu;Ross Maciejewski;David S. Ebert	2006		10.2312/VisSym/EuroVis06/115-122	computer vision;scientific visualization;simulation;information visualization;computer science;parallel rendering;computer graphics (images)	Visualization	-32.56990141170789	-36.16779691520418	79966
4a197df001eb5af155861795dab2453e2300e2d6	a multiple-aspects visualization tool for exploring social networks	graph theory;social network;human interface;visualization;graph representation;social network analysis	Social network analysis (SNA) has been used to study the relationships between actors in social networks, revealing their features and patterns. In most cases, nodes and edges in graph theory are used to represent actors and relationships, and graph representations are used to visually analyze social networks. However, many visualization tools using network diagrams tend to depict most information about social networks by using the properties of nodes, which result in a visual burden when identifying actors or relationships according to certain properties. There is a lack of tools to support work by investigators to provide insights into multiple-aspect networks. We considered actors, relationships, and communities to be three important elements, and developed a tool called MixVis that integrates a tagcloud, network diagrams, and a list to show the elements. Our tool allows users to explore social networks from elements of interest, and acquire details through links with the three different viewpoints.	brushing and linking;diagram;graph theory;real-time web;social network analysis;tag cloud	Jie Gao;Kazuo Misue;Jiro Tanaka	2009		10.1007/978-3-642-02559-4_31	network science;evolving networks;computer science;dynamic network analysis;theoretical computer science;machine learning;data mining;geometric networks;complex network	Metrics	-28.292592177438358	-35.537990483190185	79972
335fa6f6941862a90f0eec9012be0f8d857c0b97	attrition and fatigue: modeling the effects of crew size and crew fatigue on the control of tactical unmanned aerial vehicles (tuavs)	long range dependence;unmanned aerial vehicle;network traffic models;cost effectiveness;analysis methodology;close range;target detection;stochastic dependence;discrete event simulation	The field element of the U.S. Army Research Lab (ARL) at Fort Huachuca, Arizona is concerned with the manning required to operate the close-range Tactical Unmanned Aerial Vehicle (TUAV). The operational requirements of the TUAV operators may include extended duty days, reduced crew size and varying shift schedules. These conditions are likely to reduce operator effectiveness due to fatigue. The objective of this study was to analyze how fatigue, crew size, and rotation schedule affect operator workload and performance during the control of a TUAV. The conclusions from executing the models indicate that reducing the number of operators currently recommended for the control of TUAVs results in 1) 33% more aerial vehicle (AV) mishaps during emergencies, 2) a 13% increase in the time it takes to search for targets, and 3) an 11% decrease in the number of targets detected. Over 400 mission scenario replications of the model were executed allowing statistically reliable predictions to be made of the effect of operator fatigue on performance. Discrete Event Simulation (DES) models may provide a cost effective means to estimate the impact of human limitations on military systems and highlight performance areas needing attention.	aerial photography;attrition (website);requirement;simulation;unmanned aerial vehicle	Brett Walters;Jon French;Michael J. Barnes	2000			simulation;cost-effectiveness analysis;computer science;engineering;discrete event simulation;operations research	Robotics	-23.874670337989027	-25.450751770336858	80070
225924cac2dc0fbe6798bfc24c6d7ff4362c1a4d	telecom data for efficient malaria interventions.		Telecom data is rich on mobility information and as such can be used to identify mobility patterns of people in near real time, enabling to build epidemiological models for understanding where epidemics might spread over time. Based on previous research, we have built an operational tool fed with telecom data which shows malaria risk flows in Zambia in near real time. It provides insights on which areas should eradicate malaria first in order to have a maximum impact on the overall country malaria flows, and it highlights regions that should coordinate their eradication efforts together. Such information is particularly relevant for countries like Zambia, which are getting close to malaria elimination and need to prevent its re-introduction into areas that are already malaria-free.	real-time computing	Kristýna Tomsu;Alexis Eggermont;Nicolas Snel	2016	CoRR		malaria;telecommunications;computer science;psychological intervention	AI	-20.90477396052119	-31.081540717282945	80106
7c945b612483f6ff17b46949d1c379710bb1795c	interactive optimization for steering machine classification	user study;interactive machine learning;visualization;machine learning;interactive optimization;confusion matrix;decision theory;classification system	"""Interest has been growing within HCI on the use of machine learning and reasoning in applications to classify such hidden states as user intentions, based on observations. HCI researchers with these interests typically have little expertise in machine learning and often employ toolkits as relatively fixed """"black boxes"""" for generating statistical classifiers. However, attempts to tailor the performance of classifiers to specific application requirements may require a more sophisticated understanding and custom-tailoring of methods. We present ManiMatrix, a system that provides controls and visualizations that enable system builders to refine the behavior of classification systems in an intuitive manner. With ManiMatrix, users directly refine parameters of a confusion matrix via an interactive cycle of re-classification and visualization. We present the core methods and evaluate the effectiveness of the approach in a user study. Results show that users are able to quickly and effectively modify decision boundaries of classifiers to tai-lor the behavior of classifiers to problems at hand."""	black box;confusion matrix;human–computer interaction;list of toolkits;machine learning;mathematical optimization;requirement;statistical classification;trapezoidal rule;usability testing	Ashish Kapoor;Bongshin Lee;Desney S. Tan;Eric Horvitz	2010		10.1145/1753326.1753529	visualization;confusion matrix;decision theory;human–computer interaction;computer science;artificial intelligence;operating system;machine learning;data mining;world wide web	HCI	-26.324153169283043	-36.67181253195145	80732
dfe74a6f600d856e55001af247ad0eac019585ee	a planning and control system for self-driving racing vehicles		Autonomous robots will soon enter our everyday life as self-driving cars. These vehicles are designed to behave according to certain sets of cooperative rules, such as traffic ones, and to respond to events that might be unpredictable in their occurrence but predictable in their nature, such as a pedestrian suddenly crossing a street, or another car losing control. As civilian autonomous cars will cross the road, racing autonomous cars are under development, which will require superior Artificial Intelligence Drivers to perform in structured but uncertain conditions. We describe some preliminary results obtained during the development of a planning and control system as key elements of an Artificial Intelligence driver for the competition scenario.	artificial intelligence;autonomous car;autonomous robot;chimeric antigen receptor;control system;drug vehicle;racing - animals;racing - production class code;robot (device);rule (guideline)	Danio Caporale;Adriano Fagiolini;Lucia Pallottino;A. Settimi;Andrea Biondo;Francesco Amerotti;Federico Massa;Stefano De Caro;Andrea Corti;Luca Venturini	2018	2018 IEEE 4th International Forum on Research and Technology for Society and Industry (RTSI)	10.1109/RTSI.2018.8548444		Robotics	-19.911593645166178	-24.33047795961489	81177
31317c7956d5841f728364a96a54578e7118a310	assisted journey recollections from photo streams: (demo paper)	photo;journey;gps;recollection;itinerary;movement	We extract GPS traces from photo streams and analyze them to reveal movement types. Speed and locale patterns hint about the kinds of activity as captured by the photos of the day. When properly categorized and visualized, the photos and their movement patterns help people in navigating the itineraries of their past, and in retreating images of possible highlights. Our method is tolerant of erroneous and missing positional information in the photos' metadata. External geospatial resources can be further combined and visualized with the itineraries and photos to assist people's recollection of the places they were visiting.	categorization;global positioning system;tracing (software)	Tyng-Ruey Chuang;Jheng-Peng Huang;Hsin-Huei Lee;Kae-An Liu;Huang-Sin Syu	2016		10.1145/2996913.2996955	movement;global positioning system;geography;world wide web;cartography;remote sensing;computer graphics (images)	HCI	-23.24240179678303	-33.6765945921756	81194
6efd1bfcda36858f7dd9011e9720475e22cc89bc	where chicagoans tweet the most: semantic analysis of preferential return locations of twitter users	human mobility;big data;urban activity;twitter;social media;semantic trajectories	Recent studies on human mobility show that human movements are not random and tend to be clustered. In this connection, the movements of Twitter users captured by geo-located tweets were found to follow similar patterns, where a few geographic locations dominate the tweeting activity of individual users. However, little is known about the semantics (landuse types) and temporal tweeting behavior at those frequently-visited locations. Furthermore, it is generally assumed that the top two visited locations for most of the users are home and work locales (Hypothesis A) and people tend to tweet at their top locations during a particular time of the day (Hypothesis B). In this paper, we tested these two frequently cited hypotheses by examining the tweeting patterns of more than 164,000 unique Twitter users whom were residents of the city of Chicago during 2014. We extracted landuse attributes for each geo-located tweet from the detailed inventory of the Chicago Metropolitan Agency for Planning. Top-visited locations were identified by clustering semantic enriched tweets using a DBSCAN algorithm. Our results showed that although the top two locations are likely to be residential and occupational/educational, a portion of the users deviated from this case, suggesting that the first hypothesis oversimplify real-world situations. However, our observations indicated that people tweet at specific times and these temporal signatures are dependent on landuse types. We further discuss the implication of confounding variables, such as clustering algorithm parameters and relative accuracy of tweet coordinates, which are critical factors in any experimental design involving Twitter data.	algorithm;antivirus software;cluster analysis;dbscan;design of experiments	Aiman Soliman;Junjun Yin;Kiumars Soltani;Anand Padmanabhan;Shaowen Wang	2015		10.1145/2835022.2835032	big data;social media;computer science;data mining;internet privacy;world wide web	HCI	-19.346274450862733	-34.861390463855265	81534
2fd66d24dd73f284c7546030c675a25f58cf2b1e	discovering customer journey maps using a mixture of markov models		Customer Journey Maps (CJMs) summarize the behavior of customers by displaying the most common sequences of steps they take when engaging with a company or product. In many practical applications, the challenge lies in automatically discovering these prototypical sequences from raw event logs for thousands of customers. We propose a novel, probabilistic approach based on a mixture of Markov models and show it can reliably extract CJMs with just one input parameter (and potentially none).	markov chain;markov model;parameter (computer programming)	Matthieu Harbich;Gaël Bernard;Pietro Berkes;Benoît Garbinato;Periklis Andritsos	2017			machine learning;markov model;computer science;artificial intelligence	ML	-25.338943105461876	-36.85443777005409	82287
0ffbf9c316c90f9a1fa3fa7eca5cdcdd751c8a52	social game epitome versus automatic visual analysis	histograms;image segmentation;digital photography;social network;visualization;epitome;social networks;image color analysis;social game;visual search;games;visual analysis;facebook;game;games visualization facebook histograms image color analysis image segmentation humans;visual analysis photo summarization social game social networks facebook application;facebook application;humans;photo summarization	With the rapid growth of digital photography, sharing of photos with friends and family has become very popular. When people share their photos, they usually organize them in albums according to events or places. To tell the story of some important events in one's life, it is desirable to have an efficient summarization tool which can help people to get a quick overview of an album containing huge number of photos. In this paper, we analyze an approach for photo album summarization through a novel social game “Epitome” as a Facebook application. This social game can collect research data and, at the same time, it provides a collage or a cover photo of the user's photo album, while, at the same time, the user enjoys playing the game. As a benchmark comparison to this game, we performed automatic visual analysis considering several state-of-the-art features.	benchmark (computing);digital photography;facebook platform	Peter Vajda;Ivan Ivanov;Lutz Goldmann;Touradj Ebrahimi	2011	2011 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2011.6011927	game design;games;computer vision;visual analytics;computer science;multimedia;internet privacy;social network	Visualization	-24.333033369939297	-35.31907189620032	82466
b013d88b3031f26a9a5ec95cf931d9167fcb1187	a generic approach to challenge modeling for the procedural creation of video game levels	video games challenge modeling fun player enjoyment procedural content creation;video games;procedural content creation;genetic algorithms constraint handling entertainment games of skill;games humans computational modeling weapons genetic algorithms genetics arrays;create levels procedural creation automatic video game level design player enjoyment generative system evolutionary computing entertainment value genetic algorithms constraint satisfaction methods player skill;computer model;constraint satisfaction;video game;genetics;arrays;computational modeling;challenge modeling;games of skill;games;player enjoyment;constraint handling;genetic algorithm;genetic algorithms;fun;humans;entertainment;weapons;fitness function	This paper presents an approach to automatic video game level design consisting of a computational model of player enjoyment and a generative system based on evolutionary computing. The model estimates the entertainment value of game levels according to the presence of “rhythm groups,” which are defined as alternating periods of high and low challenge. The generative system represents a novel combination of genetic algorithms (GAs) and constraint satisfaction (CS) methods and uses the model as a fitness function for the generation of fun levels for two different games. This top-down approach improves upon typical bottom-up techniques in providing semantically meaningful parameters such as difficulty and player skill, in giving human designers considerable control over the output of the generative system, and in offering the ability to create levels for different types of games.	bottom-up proteomics;computational model;constraint satisfaction;evolutionary computation;fitness function;generative systems;genetic algorithm;high- and low-level;high-level programming language;level design;procedural generation;software design;stellar classification;top-down and bottom-up design	Nathan Sorenson;Philippe Pasquier;Steve DiPaola	2011	IEEE Transactions on Computational Intelligence and AI in Games	10.1109/TCIAIG.2011.2161310	computer simulation;simulation;genetic algorithm;computer science;artificial intelligence;multimedia;generative design	AI	-27.274513131464083	-25.772285846423074	82596
f308ad9712264c6457b314ca9cfa9f9d2b1bc2e0	automatic congestion detection and visualization using networked gps unit data	virtual objects;learning;haptics;network mobility;traffic congestion;multimodal interaction	The goal of this work is to explore systems for the automatic determination of vehicle traffic congestion using GPS-enabled networked mobile phones. A location based data set is collected and analyzed. Additionally, sample filtering and route matching approaches are considered.	global positioning system;mobile phone;network congestion	Benjamin Bishop;Joseph Casabona	2009		10.1145/1566445.1566550	embedded system;real-time computing;simulation;floating car data;computer science;slow-start	HCI	-19.503007311995674	-30.110308045451397	82902
74462d83a94a701d062bbf6550fca749c398edd0	information visualization design for multidimensional data: integrating the rank-by-feature framework with hierarchical clustering	dissertation	Interactive exploration of multidimensional data sets is challenging because: (1) it is difficult to comprehend patterns in more than three dimensions, and (2) current systems are often a patchwork of graphical and statistical methods leaving many researchers uncertain about how to explore their data in an orderly manner. #R##N#This dissertation offers a set of principles and a novel rank-by-feature framework that could enable users to better understand multidimensional and multivariate data by systematically studying distributions in one (1D) or two dimensions (2D), and then discovering relationships, clusters, gaps, outliers, and other features. Users of this rank-by-feature framework can view graphical presentations (histograms, boxplots, and scatterplots), and then choose a feature detection criterion to rank ID or 2D axis-parallel projections. By combining information visualization techniques (overview, coordination, and dynamic query) with summaries and statistical methods, users can systematically examine the most important 1D and 2D axis-parallel projections. This research provides a number of valuable contributions: (a) Graphics, Ranking, and Interaction for Discovery (GRID) principles—a set of principles for exploratory analysis of multidimensional data, which are summarized as: (1) study 1D, study 2D, then find features (2) ranking guides insight, statistics confirm. GRID principles help users organize their discovery process in an orderly manner so as to produce more thorough analyses and extract deeper insights in any multidimensional data application. (b) Rank-by-feature framework—a user interface framework based on the GRID principles. Interactive information visualization techniques are combined with statistical methods and data mining algorithms to enable users to orderly examine multidimensional data sets using ID and 2D projections. (c) The design and implementation of the Hierarchical Clustering Explorer (HCE), an information visualization tool available at www.cs.umd.edu/hcil/hce. HCE implements the rank-by-feature framework and supports interactive exploration of hierarchical clustering results to reveal one of the important features—clusters. (d) Validation through case studies and user surveys: Case studies with motivated experts in three research fields and a user survey via emails to a wide range of HCE users demonstrated the efficacy of HCE and the rank-by-feature framework. These studies also revealed potential improvement opportunities in terms of design and implementation.	computer cluster;hierarchical clustering;information visualization	Jinwook Seo	2005			computer science;data science;data mining;world wide web	DB	-27.149415886476614	-34.560945158288405	83073
12e793b44759b9b54e2f92c8326013fe2e1afaf6	using games to do exploratory experiments in graph comprehension	graph theory;potential game;data visualisation;web sites;information theory graph theory web sites data visualisation computer games;software architecture graph comprehension graph game web site shannon switching game;humans internet;computer games;information theory	The paper describes a project to set up a graph-game Web site as a platform for carrying out exploratory experiments in graph comprehension. A few potential games are considered with the Shannon switching game being the most promising because of the ease with which challenging game graphs can be generated. Finally, the paper describes the architecture of the software needed to support the site.	experiment;shannon (unit);video game developer	John Bovey	2005	Ninth International Conference on Information Visualisation (IV'05)	10.1109/IV.2005.132	game design;simulation;computer science;theoretical computer science;graph;multimedia;game programming;graph database	Robotics	-29.910173698429272	-33.060767944513735	83240
786e44bed547d2a6c38f3c11b1bfe0be83e8c872	a world survey of artificial brain projects, part i: large-scale brain simulations	large scale brain simulations;individual differences;sentence comprehension;digital image sensor;cognitive architecture;large scale;functional connectivity;optic nerve signals;research and development;artificial brains;thalamocortical system;working memory;cerebral cortex;retinal ganglion cells;computational model;article	Driven by rapid ongoing advances in computer hardware, neuroscience and computer science, Artificial Brain research and development are blossoming. This article constitutes the first half of a two-part world survey of artificial brain projects: this part dealing with large-scale brain simulations, and the second part with biologically inspired cognitive architectures (BICAs). The large-scale brain simulations we consider in depth here include those by Markram, Modha, Boahen, Horwitz, Edelman, Izhikevich, and Just. As well as reviewing the particulars of these simulation projects, we position them in a broader perspective, comparing at the different underlying definitions of the concept of ‘‘simulation,’’ noting that in many ways the projects are modeling neurosystems at different levels as well as using different methodologies. & 2010 Elsevier B.V. All rights reserved.	artificial brain;biologically inspired cognitive architectures;cognitive architecture;computer hardware;computer science;simulation	Hugo de Garis;Shuo Chen;Ben Goertzel;Ruiting Lian	2010	Neurocomputing	10.1016/j.neucom.2010.08.004	differential psychology;cognitive architecture;computer science;artificial intelligence;machine learning;working memory;computational model;cognitive science	AI	-23.11625376384027	-36.993184623348846	83287
eb968e6c86a50393a64a6874df09cfdd0ace2edc	intelligent feature extraction and tracking for visualizing large-scale 4d flow simulations	flow visualization;machine learning;computational modeling;visual system;data reduction;user interface;hardware accelerator;data visualization;artificial neural network;transfer functions;computer simulation;data mining;feature extraction	"""Terascale simulations produce data that is vast in spatial, temporal, and variable domains, creating a formidable challenge for subsequent analysis. Feature extraction as a data reduction method offers a viable solution to this large data problem. This paper presents a new approach to the problem of extracting and visualizing 4D features within large volume data. Conventional methods requires either an analytical description of the feature of interest or tedious manual intervention throughout the feature extraction and tracking process. We show that it is possible for a visualization system to """"learn"""" to extract and track features in complex 4D flow field according to their """"visual"""" properties, location, shape, and size. The basic approach is to employ machine learning in the process of visualization. Such an intelligent system approach is powerful because it allows us to extract and track an feature of interest in a high-dimensional space without explicitly specifying the relations between those dimensions, resulting in a greatly simplified and intuitive visualization interface."""	artificial intelligence;computer simulation;feature extraction;information visualization;machine learning;terascale (microarchitecture)	Fan-Yin Tzeng;Kwan-Liu Ma	2005	ACM/IEEE SC 2005 Conference (SC'05)		computer simulation;data reduction;visual system;hardware acceleration;flow visualization;feature extraction;computer science;data science;machine learning;data mining;transfer function;user interface;computational model;feature;data visualization;artificial neural network	HPC	-27.123809773917657	-31.4383812496927	83321
d82bc6666cd342dc01e56900f64b80b03974e6ca	storyteller: visual analytics of perspectives on rich text interpretations		Complexity of event data in texts makes it difficult to assess its content, especially when considering larger collections in which different sources report on the same or similar situations. We present a system that makes it possible to visually analyze complex event and emotion data extracted from texts. We show that we can abstract from different data models for events and emotions to a single data model that can show the complex relations in four dimensions. The visualization has been applied to analyze 1) dynamic developments in how people both conceive and express emotions in theater plays and 2) how stories are told from the perspective of their sources based on rich event data extracted from news or biographies.	complexity;data model;visual analytics	Maarten A. J. van Meersbergen;Piek T. J. M. Vossen;Janneke M. van der Zwaan;Antske Fokkens;Willem Robert van Hage;Inger Leemans;Isa Maks	2017			visualization;computer science;artificial intelligence;data modeling;natural language processing;visual analytics;data model;rich text format;cultural analytics	NLP	-30.600168483933068	-30.24444178498014	83491
550c5dd390dd4e5c2fd21c51e7db12315c0a6d02	vespa 2.0: data-driven behavior models for visual analytics of movement sequences		Ubiquitous availability of human mobility data has opened up new possibilities to address a multitude of application domains. However, so far, the visual analysis of this data has been hindered by the limited ability to explore and query complex movement sequences and to create models that allow meaningful aggregation. To address this problem, this paper presents a novel analytical approach that allows to automatically create and semiautomatically advance models for large-scale movement behavior. Using a bottom-up procedure, the analyst can first explore movement sequences with assistance of automated sorting and grouping methods. Secondly, findings can be semi automatically extracted and represented using a data-driven modeling language. In an incremental process, the analyst can then further advance the model, use it to query more results, and find regular as well as outlying patterns. We demonstrate the applicability of our approach based on a real-world case study and a user study.	bottom-up proteomics;modeling language;semiconductor industry;sorting;top-down and bottom-up design;usability testing;visual analytics	Robert Krüger;Tina Tremel;Dennis Thom	2017	2017 International Symposium on Big Data Visual Analytics (BDVA)	10.1109/BDVA.2017.8114626	data visualization;modeling language;data mining;visualization;visual analytics;computer vision;data-driven;data modeling;computer science;artificial intelligence;sorting	Visualization	-26.107169836841734	-34.10366236983635	83869
6afedb6a6ba4b686340d61292741c946ff51e5d3	improved exploration with dimensional weight manipulation in radviz		RadViz is one of the most commonly used radial visualization techniques, and it can easily grasp the distribution of multidimensional data. RadViz projects multidimensional data onto a plane using a spring-force analogy. In this paper, we discuss the interactive visualization system of a RadViz that helps users analyze multidimensional data from various perspectives by allowing them to change the locations of the dimension anchors and the forces between the data and the dimension anchors.	interactive visualization;radial (radio)	Hyunwoo Han;Taerin Yoon;Hyeonsik Gong;Kyungwon Lee	2018		10.1145/3231622.3232507	computer vision;data visualization;clustering high-dimensional data;data mining;interactive visualization;analogy;artificial intelligence;grasp;computer science	HCI	-28.819596442255474	-33.76999264340184	84180
ca201aeb0b8607bff2c562ab75410e8656951b85	a study on textures and their perceptual visual dimensions as application for flexible and effective scientific visualization	scientific visualization		scientific visualization;texture mapping	Francesca Taponecco	2006		10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2006/123-127	computer vision;visual analytics;scientific visualization;information visualization;visualization;computer science;multimedia;computer graphics (images)	Visualization	-32.9787017617798	-33.08547664247413	84210
46aac5a0620d64d631c8b83c10525b64b6143939	a visual analysis approach for community detection of multi-context mobile social networks	yu xin ma jia yi xu di chao peng 可视化分析 网络社区 变化检测 上下文信息 社交 移动 语境 网络结构 a visual analysis approach for community detection of multi context mobile social networks	The problem of detecting community structures of a social network has been extensively studied over recent years, but most existing methods solely rely on the network structure and neglect the context information of the social relations. The main reason is that a context-rich network offers too much flexibility and complexity for automatic or manual modulation of the multifaceted context in the analysis process. We address the challenging problem of incorporating context information into the community analysis with a novel visual analysis mechanism. Our approach consists of two stages: interactive discovery of salient context, and iterative context-guided community detection. Central to the analysis process is a context relevance model (CRM) that visually characterizes the influence of a given set of contexts on the variation of the detected communities, and discloses the community structure in specific context configurations. The extracted relevance is used to drive an iterative visual reasoning process, in which the community structures are progressively discovered. We introduce a suite of visual representations to encode the community structures, the context as well as the CRM. In particular, we propose an enhanced parallel coordinates representation to depict the context and community structures, which allows for interactive data exploration and community investigation. Case studies on several datasets demonstrate the efficiency and accuracy of our approach.	assistive technology;bluetooth;british informatics olympiad;brookgpu;computer graphics;computer science;encode;entity–relationship model;information visualization;iterative method;mechatronics;medical image computing;mobile social network;modulation;next-generation network;parallel coordinates;relevance;rendering (computer graphics);school of computing (robert gordon university);scientific visualization;sensor;social network analysis;software engineering;virtual reality;visual analytics;xi-cheng zhang	Yu-Xin Ma;Jia-Yi Xu;Dichao Peng;Shaobo Zhang;Cheng-Zhe Jin;Huamin Qu;Wei Chen;Qunsheng Peng	2013	Journal of Computer Science and Technology	10.1007/s11390-013-1378-5	computer science;artificial intelligence;machine learning;data mining;database;context model;computer security;algorithm	AI	-27.75674363961328	-36.29199395758477	84251
85e635ca2cbe20564a0a08bc60b89549d3750bcd	duration-aware alignment of process traces		Objective: To develop an algorithm for aligning process traces that considers activity duration during alignment and helps derive data-driven insights from workflow data. Methods: We developed a duration-aware trace alignment algorithm as part of a Java application that provides visualization of the alignment. The relative weight of the activity type vs. activity duration during the alignment is an adjustable parameter. We evaluated proportional and logarithmic weights for activity duration. Results: We used duration-aware trace alignment on two real-world medical datasets. Compared with existing context-based alignment algorithm, our results show that duration-aware alignment algorithm achieves higher alignment accuracy and provides more intuitive insights for deviation detection and data visualization. Conclusion: Duration-aware trace alignment improves upon an existing trace alignment approach and offers better alignment accuracy and visualization.	algorithm;anomaly detection;data visualization;digital footprint;java;open research;tracing (software)	Sen Yang;Moliang Zhou;Rachel Webman;Jaewon Yang;Aleksandra Sarcevic;Ivan Marsic;Randall S. Burd	2016		10.1007/978-3-319-41561-1_28	data visualization;visualization;dynamic time warping;workflow;artificial intelligence;java;computer science;pattern recognition	Visualization	-25.32707489009259	-34.073975828080634	84261
f09fc8abb26d98b51b24627cc6515a99451d59e6	recon: a remotely controlled drone for roads safety	software;telerobotics autonomous aerial vehicles data acquisition road safety;data acquisition cameras software hardware adders monitoring safety;data acquisition remote control drone uav surveillance labview;monitoring;adders;safety;data acquisition;pervasive computing recon project remotely controlled drone road safety unmanned aerial vehicle uav data acquisition devices labview web enabled software smart phones tablets laptops;cameras;hardware	The RECON project is an unmanned aerial vehicle (UAV), which is automated to monitor, analyze, inspect, and intervene in bridges, roads, residential areas, etc. RECON is controlled using data acquisition devices from National Instruments and programmed under LabVIEW. The system is prepared to make a stable journey, communicate, deliver, and intervene and assist. RECON is ubiquitous; the software is web-enabled so that the user can control it using smart phones, tablets, laptops and other computing devices. The system provides a true pervasive computing experience. This paper presents the system organization, architecture, programming application, evaluation and analysis of the proposed system.	aerial photography;data acquisition;labview;laptop;remote control;smartphone;ubiquitous computing;unmanned aerial vehicle	Jassim Al-Fadhli;Mustafa Ashkanani;Abdulwahab Yousef;Issam W. Damaj;Mohammed El-Shafei	2014	2014 International Conference on Connected Vehicles and Expo (ICCVE)	10.1109/ICCVE.2014.7297688	embedded system;simulation;engineering;computer security	Robotics	-22.092163256429295	-28.91560383249526	84645
b7b3c36f1bb640eb60b2be8fc9e6757d4ea57d7b	design and evaluation of human-machine communication for image information mining	extraction information;information communication;dato observacion;interfaz grafica;cbir;high resolution;human computer interaction;visual interface cbir human machine communication information representation and visualization;multimedia;image processing;image resolution;information extraction;graphical interface;image databank;human machine communication;relacion hombre maquina;procesamiento imagen;fouille information dans image;heterogeneous data;man machine relation;data mining;traitement image;information content;data visualisation;informal communication;communication information;haute resolution;resolucion imagen;visual interface;internet;banco imagen;banque image;image databases data mining relational databases spatial databases visual databases remote sensing feedback earth image analysis computer vision;data visualization;alta resolucion;comunicacion informacion;visualisation donnee;earth observation;relation homme machine;donnee observation;high resolution imager;very large databases;content based image retrieval knowledge driven image information mining human machine communication very large image repository internet cbir information representation information visualization visual interface;visual interfaces;interface graphique;content based retrieval;user interfaces;resolution image;extraccion informacion;observation data;content based retrieval data mining human computer interaction user interfaces data visualisation very large databases visual databases image retrieval;information representation and visualization;visual databases;image retrieval	Very large volumes of heterogenous data, like multimedia, Earth observation images, scientific and engineering measurements, for instance, are continuously generated and stored. A typical case is the field of Earth observation. The widespread availability of high resolution images does not only explore the volumes of data, but also brings order at magnitude in the image detail, thus enormously increasing the information content. However, today's concepts and technologies are still limited in communicating the information content to people for use in real life applications. In this paper, we overview a new concept for knowledge-driven image information mining (KIM) and both analyze and evaluate it from the perspective of human-machine communication. The KIM concept enables the information communication from a very large image repository to users via the Internet. The communication is at a semantic level of representation and is adapted to the user's conjecture.	data mining;image resolution;internet;mental representation;real life;self-information	Herbert Daschiel;Mihai Datcu	2005	IEEE Transactions on Multimedia	10.1109/TMM.2005.858383	computer vision;image resolution;computer science;data mining;world wide web;information retrieval;data visualization;statistics	Visualization	-33.19265402072267	-28.035313476993803	84745
2b2fbf5bc4eb42ccd1a79ba9a30325e046defd39	a left turn assist application using wireless vehicle-to-vehicle communications at unsignalized intersections	wireless vehicle to vehicle communications;wave;safety applications;mobile services	We present a wireless vehicle-to-vehicle communications-based safety application to assist drivers with safe left turns at unsignalized intersections. When a potentially dangerous situation such as an oncoming vehicle from the opposite lane is detected, our system can provide the driver with a warning. Our system gives advisory or imminent warnings according to the predicted accident levels through a HMI. For a performance test of our application, we configured three test scenarios and tested our system with vehicles on a proving ground. The test results showed 93% success rates.	human–computer interaction;vehicle information and communication system;vehicle-to-vehicle	Hyun-Soo Seo;Chang-Jin Lee;Hyo-Un Kim;Dong-Gyu Noh;Sang-Sun Lee	2013		10.1145/2536853.2536922	simulation;wave	Mobile	-19.85474255216127	-28.07406846504893	84774
115531e899d3a75819be4d06e8119be2e7790399	improving spatial awareness for human trajectory visualization in space-time cubes		With the increasing evolution of computer graphics, 3D visualizations have become more common and are nowadays seen as a promising way to represent complex types of information. In particular, space-time cubes (STC) have been proposed as an alternative to 2D maps for the visualization of spatio-temporal data, and they have become increasingly used to explore the dynamics and patterns of human movement. However, previous research has pointed out perceptual limitations that can condition the use of 3D views for decoding locations and spatial properties. We aim to address those issues by presenting a comparative study between three variants of the STC technique, with different methods to improve spatial awareness. Our results support that the use of a movable plane or an additional 2D map view improve users’ accuracy when performing common tasks, and are preferred over simpler, yet less cluttered approaches. Additionally, it also supports the possible advantages of combining 2D and 3D views for human trajectory visualization.	cubes;spatial–temporal reasoning	Tiago Gonçalves;Ana Paula Afonso;Bruno Martins	2015		10.1007/978-3-319-22723-8_26	computer vision;data science;data mining	HCI	-29.083523345196475	-34.93635509404947	85270
8c6d8d7a8681c02c4e57ce01461af1d9fb3a0455	improving emergency response to mass casualty incidents	mass casualty incidents;national security;emergency response;mobile device;terrorism emergency services information retrieval personnel pervasive computing resource management hospitals transportation computer science performance analysis;emergency service;pervasive computing;contextual information;pervasive system;pervasive computing technology;ubiquitous computing emergency services national security;pervasive computing technology emergency response mass casualty incidents emergency services contextual information;ubiquitous computing;emergency services	Mass casualty incidents generate a sequence of response events from the emergency services, requiring the allocation and use of resources in a timely fashion. In this paper we describe a pervasive system that helps emergency services optimize their efficiency and coordination. The system emulates a multiple casualty emergency response environment in which contextual information, retrieved from victims' wearable or mobile devices, guides early assessments on the health condition of the affected population. Additionally, we analyze the behavior of our system under different conditions and derive the necessary parameters for achieving accurate estimations. Our main contribution is the enhancement of the existing emergency response process for mass casualty incidents through the use of pervasive computing technology.	emulator;mobile device;pervasive informatics;ubiquitous computing;wearable computer	Marcus Lucas da Silva;Vassilis Kostakos;Mitsuji Matsumoto	2008	2008 Sixth Annual IEEE International Conference on Pervasive Computing and Communications (PerCom)	10.1109/PERCOM.2008.71	simulation;human–computer interaction;emergency;computer science;national security;mobile device;computer security;ubiquitous computing	Robotics	-23.266508094320304	-27.617307456124404	85450
93b040abe17cc5a0b75f11da580b454e1499bfbd	interactive genjam: integrating real-time performance with a genetic algorithm		This presentation will describe and demonstrate recent enhancements to GenJam, an interactive genetic algorithm jazz improviser. The most significant enhancement incorporates a pitch-to-MIDI capability, which allows GenJam to integrate human improvisations into its own improvisations. Specifically, when GenJam “trades fours” with a human, it listens to the human’s last four measures, maps what it hears to its chromosome representation, mutates the chromosomes, and plays the result as its next four. In other words, GenJam evolves what it “hears” into what it will play in real time. Other recent enhancements are also discussed.	genetic algorithm;real-time transcription	John A. Biles	1998			machine learning;genetic algorithm;population-based incremental learning;artificial intelligence;computer science	AI	-28.474251779565286	-24.787723609766847	85701
4179be6abcaf155f1d8a20d14e451ce6c76ed82f	cartolis. vers un outil géomatique pour identifier et caractériser les segments de lisières forestières		Forest edges are key components of rural landscap es because they influence ecological processes at t he interface between habitats. There is a variability o f forest edges, according to their physiognomy, ori entation, history and topography, but few methods are available to ide nt fy these different types of edges and to map the m at a large scale. We propose to identify edge segments based o n morphological subdivision of forest boundaries. T hese segments are mapped and characterized by request on other spatial data. A procedure based on ArcGis to ols, applied on the output from GUIDOS tools, is used to identif y edge segments. We provide examples of edge segmen ts descriptors obtained from a digital elevation model and from a landcover map. Results showed the feasib ility of the automatic mapping of edge variability over a large scale. It opens new perspectives to build up a new to ol for analyzing landscape dynamics and their effects on b i diversity. MOTS-CLÉS : Lisière forestière, SIG, métrique paysagère, segm ent de polyligne, morphologie, généralisation	arcgis;digital elevation model;habitat;identifier;non-functional requirement;ordinary least squares;spatial variability;subdivision surface;topography	Audrey Alignier;Philippe Espy;Marc Deconchat;Sylvie Ladet	2011	Revue Internationale de Géomatique	10.3166/rig.21.443-467		ML	-24.41818249594439	-28.471583639280347	85770
12be263d0c17ebfd0618e9429c0d5c045a1241f9	self-automated parking lots for autonomous vehicles based on vehicular ad hoc networking	vehicular ad hoc networks automobiles electric propulsion mobile robots road traffic control;space vehicles aerospace electronics mobile robots layout space exploration proposals;parking lot controller self automated parking lots vehicular ad hoc networking car transportation traffic congestion urban landscape park cars mechanical parking systems fully autonomous vehicular technology semi autonomous vehicular technology electric propulsion paradigm	Parking is a major problem of car transportation, with important implications in traffic congestion and urban landscape. Reducing the space needed to park cars has led to the development of fully automated and mechanical parking systems. These systems are, however, limitedly deployed because of their construction and maintenance costs. Leveraging on semi and fully-autonomous vehicular technology, as well as on the electric propulsion paradigm and in vehicular ad hoc networking, we propose a new parking concept where the mobility of parked vehicles is managed by a parking lot controller to create space for cars entering or exiting the parking lot, in a collaborative manner. We show that the space needed to park such vehicles can be reduced to half the space needed with conventional parking lot designs. We also show that the total travelled distance of vehicles in this new parking lot paradigm can be 30% less than in conventional parking lots. Our proposal can have important consequences in parking costs and in urban landscape.	24-hour clock;autonomous car;autonomous robot;emergence;extended validation certificate;hoc (programming language);mathematical optimization;multi-storey car park;network congestion;programming paradigm;semiconductor industry	Michel Ferreira;Luís Damas;Hugo Conceição;Pedro M. d'Orey;Ricardo Fernandes;Peter Steenkiste;Pedro Gomes	2014	2014 IEEE Intelligent Vehicles Symposium Proceedings	10.1109/IVS.2014.6856561	vehicular ad hoc network;engineering;automotive engineering;parking guidance and information;transport engineering;vehicular communication systems;computer security	Mobile	-21.18253466417292	-25.999801947223503	86439
e282a14b2a8d74b0ccdafa3741f7e3b2b1dc1360	inferring fine-grained details on user activities and home location from social media: detecting drinking-while-tweeting patterns in communities		Nearly all previous work on geo-locating latent states and activities from social media confounds general discussions about activities, self-reports of users participating in those activities at times in the past or future, and self-reports made at the immediate time and place the activity occurs. Activities, such as alcohol consumption, may occur at different places and types of places, and it is important not only to detect the local regions where these activities occur, but also to analyze the degree of participation in them by local residents. In this paper, we develop new machine learning based methods for fine-grained localization of activities and home locations from Twitter data. We apply these methods to discover and compare alcohol consumption patterns in a large urban area, New York City, and a more suburban and rural area, Monroe County. We find positive correlations between the rate of alcohol consumption reported among a community’s Twitter users and the density of alcohol outlets, demonstrating that the degree of correlation varies significantly between urban and suburban areas. While our experiments are focused on alcohol use, our methods for locating homes and distinguishing temporally-specific self-reports are applicable to a broad range of behaviors and latent states.	experiment;machine learning;report;sensor;social media	Nabil Hossain;Tianran Hu;Roghayeh Feizi;Ann Marie White;Jiebo Luo;Henry A. Kautz	2016	CoRR		simulation	HCI	-19.34041782196634	-34.747220656044604	86791
7ca709f7860e78e71ce73fd1b2cb7a39fe1e9fdc	towards a visualization framework for service selection in cloud e-marketplaces		Abstract-In spite of the success of many commercial cloud service e-marketplaces the search results from these platforms are usually presented as an unordered list of icons representing the services that best fit users’ keyword-based queries. The drawback of such presentation mechanisms is that users are not able to immediately discriminate among the cloud services for easy decision making. A number of cloud service selection frameworks have been proposed; however, some of these frameworks do not enable users make comparisons among services. In this paper, we introduce a visualization framework for cloud service selection. Our framework takes into cognizance the set of cloud services that matches a user’s request and based on QoS attributes, users can interact with the results via bubble graph visualization to compare and contrast the search results to ascertain the best alternative. The bubble graph enables the exploration of services in a unified view of the QoS space, exhibiting both high object coherence and correlation. Result from our experiments shows that our framework simplifies decision making as users can identify services that best fit their requirements quicker and easier compared to tabular formats.	cloud computing;curve fitting;e-commerce;experiment;graph drawing;html element;holism;information visualization;requirement;table (information);usability;user experience	Azubuike Ezenwoke;Olawande Daramola;Matthew Adigun	2017	2017 IEEE World Congress on Services (SERVICES)	10.1109/SERVICES.2017.31	data mining;bubble;quality of service;visualization;database;computer science;cloud computing;graph drawing;spite;graph	Visualization	-29.727917148937006	-28.97107506689699	87209
2626644cb166d30615782f6e32b5da56ebe1c67b	towards application of automated planning in urban traffic control	tl motor vehicles aeronautics astronautics;tf railroad engineering and operation;neural networks;te highway engineering roads and pavements;road traffic control;he transportation and communications;feedback;urban areas;roads planning artificial neural networks junctions navigation cognition control systems;advanced traffic management systems;artificial intelligence;planning;road traffic control feedback planning;highway traffic control;rerouting;temporal planning problem automated planning technique urban traffic control system feed back algorithm adaptive green phase flexible coordination road traffic network self managing systems;tk electrical engineering electronics nuclear engineering;ta engineering general civil engineering general;qa76 computer software	Advanced urban traffic control systems are often based on feed-back algorithms. For instance, current traffic control systems often operate on the basis of adaptive green phases and flexible co-ordination in road (sub) networks based on measured traffic conditions. However, these approaches are still not very efficient during unforeseen situations such as road incidents when changes in traffic are requested in a short time interval. Therefore, we need self-managing systems that can plan and act effectively in order to restore an unexpected road traffic situations into the normal order. A significant step towards this is exploiting Automated Planning techniques which can reason about unforeseen situations in the road network and come up with plans (sequences of actions) achieving a desired traffic situation. In this paper, we introduce the problem of self-management of a road traffic network as a temporal planning problem in order to effectively navigate cars throughout a road network. We demonstrate the feasibility of such a concept and discuss our preliminary evaluation in order to identify strengths and weaknesses of our approach and point to some promising directions of future research.	algorithm;automated planning and scheduling;control system;feedback;knowledge base;real-time locating system;self-management (computer science);sensor;simulation	Falilat Jimoh;Lukás Chrpa;T. L. McCluskey;Shahin Shah	2013	16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013)	10.1109/ITSC.2013.6728360	simulation;engineering;civil engineering;transport engineering	Robotics	-19.22843626590613	-24.417854264265404	87258
7e46420f93671b589102ae20cc4c3792da107e47	a study of users' acceptance and satisfaction of emergency call service	location based service;ecall platform;v2i and v2v communications;road safety;embedded nomadic devices;emergency services	SummaryrnIn recent years, there has been rapid and significant development of road transport technologies in order to reduce the number of killed and injured people on roads. These include safety technologies, emergency call systems (eCall), and advanced traveler information systems. The eCall system is an automatic in-vehicle emergency call service, which is mainly used for notifying emergency services about dangerous road situations and their exact location. In this paper, an eCall platform prototype is developed to allow quick and efficient rescue of injured people in dangerous road situations. The eCall function is developed and installed in nomadic devices (e.g., smartphones and tablets). Large-scale field operational tests were conducted in real settings to assess the impacts of the eCall function provided by in-vehicle nomadic devices. More precisely, experiments were conducted by more than 250 participants with different sociodemographic profiles in order to study the usersu0027 acceptance of the use of the developed eCall function for large-scale usage. The collected data are analyzed, and results are reported. Performed experiments showed the usefulness, acceptance, and satisfactory performance of the eCall service. Copyright © 2016 John Wiley u0026 Sons, Ltd.		Abderrahim Chariete;Mohamed Bakhouya;Ahmed Nait-Sidi-Moh;Wafaa Ait-Cheik-Bihi;Jaafar Gaber;Raed Kouta;Maxime Wack;Pascal Lorenz	2016	Int. J. Communication Systems	10.1002/dac.3161	computer science;location-based service;computer security;computer network	HCI	-20.619485448836258	-28.423393717437165	87393
87cc66a7eae45f9df7fa10c14c77f4178abd2563	pedestrian behaviour monitoring: methods and experiences		The investigation of pedestrian spatio-temporal behaviour is of particular interest in many different research fields. Disciplines like travel behaviour research and tourism research, social sciences, artificial intelligence, geoinformation and many others have approached this subject from different perspectives. Depending on the particular research questions, various methods of data collection and analysis have been developed and applied in order to gain insight into specific aspects of human motion behaviour and the determinants influencing spatial activities. In this contribution, we provide a general overview about most commonly used methods for monitoring and analysing human spatio-temporal behaviour. After discussing frequently used empirical methods of data collection and emphasising related advantages and limitations, we present seven case studies concerning the collection and analysis of human motion behaviour following different purposes.	artificial intelligence;geographic information system;kinesiology	Alexandra Millonig;Norbert Brändle;Markus Ray;Dietmar Bauer;Stefan van der Spek	2009		10.3233/978-1-60750-048-3-11	empirical research;environmental science;data collection;management science;tourism;geographic information system;pedestrian	AI	-22.515282699384663	-34.83086598673821	87409
5abe09c7d769ac80b8849d3aebbf83e96dcb7c61	exploring forensic data with self-organizing maps	self-organizing map;data visualization;computer forensics;neural network model;unsupervised learning;data analysis	This paper discusses the application of a self-organizing map (SOM), an unsupervised learning neural network model, to support  decision making by computer forensic investigators and assist them in conducting data analysis in a more efficient manner.  A SOM is used to search for patterns in data sets and produce visual displays of the similarities in the data. The paper explores  how a SOM can be used as a basis for further analysis. Also, it demonstrates how SOM visualization can provide investigators  with greater abilities to interpret and explore data generated by computer forensic tools.  	map;organizing (structure)	Bennie Fei;Jan H. P. Eloff;Hein S. Venter;Martin S. Olivier	2005			computer science;data science;machine learning;data mining	AI	-27.410181157349793	-31.980858167424973	87973
29804755f88e7985e40ae31de3ed71ce912fd445	interactive visualization of normal behavioral models and expert rules for maritime anomaly detection	maritime surveillance systems;data analysis interactive visualization normal behavioral models maritime surveillance systems heterogeneous sensor data autonomous anomaly detection systems human expert knowledge system embedded system data mining association rules mining;expert systems;surveillance;surveillance system;behavior modeling;technology;anomaly detection;interactive visualization;computer and information science;association rules;ais data;data mining;surveillance data analysis data mining data visualisation embedded systems expert systems marine engineering security of data;embedded system;teknik;data visualisation;embedded systems;data analysis;data visualization humans data mining surveillance sensor systems monitoring data security national security computer graphics object detection;data visualization;situation awareness;ais data interactive visualization normal behavioral models rules signatures anomaly detection visual analytics data mining maritime situation awareness;heterogeneous sensor data;marine engineering;autonomous anomaly detection systems;rules signatures;human expert knowledge system;humans;expert knowledge;maritime situation awareness;normal behavioral models;cognitive load;visual analytics;data och informationsvetenskap;security of data;data models;association rules mining	Maritime surveillance systems analyze vast amounts of heterogeneous sensor data from a large number of objects. In order to support the operator while monitoring such systems, the identification of anomalous vessels or situations that might need further investigation may reduce the operator's cognitive load. While it is worth acknowledging that many existing mining applications support identification of anomalous behavior, autonomous anomaly detection systems are rarely used in the real world, since the detection of anomalous behavior is normally not a well-defined problem and therefore, human expert knowledge is needed. This calls for the development of interaction components that can support the user in the detection process. In order to support the comprehension of the knowledge embedded in the system, we propose an interactive way of visualizing expert rules and normal behavioral models built from the data. The overall goal is to facilitate the validation and update of these models and signatures, supporting the insertion of human expert knowledge while improving confidence and trust in the system.	anomaly detection;antivirus software;autonomous robot;embedded system;interaction;interactive visualization	Maria Riveiro;Göran Falkman	2009	2009 Sixth International Conference on Computer Graphics, Imaging and Visualization	10.1109/CGIV.2009.54	computer science;data science;data mining;computer security	Robotics	-22.668068726119824	-27.70776836358084	88072
950fe343baaa8b73f807ad2b7a69f113ae69ce2e	smartgis: a svg-based tool for visualizing and monitoring of sars movement	geographic information system;information visualization;decision maker;medical computing;data visualisation;internet;level of detail;geographic information systems;decision making process;data visualization;diseases;web gis;visual data exploration;monitoring data visualization management information systems graphics information management geographic information systems decision making hospitals crisis management risk management;tool integration;interactive manipulation smartgis sars movement location based data visualization geographical information system information visualization scalable vector graphics svg gis based spatial temporal decision making;medical computing data visualisation geographic information systems decision making internet visual databases diseases;visual databases	Location-based data visualization employing geographical information system and information visualization provides an advanced means to assist with visual data exploration, hypothesis formation and decision making. An effective location-based data visualization system can significantly enhance the communication among decision-makers and facilitate the agreement on the most appropriate alternatives. This study presents SmartGIS, a tool integrating SVG, Web GIS, and data visualization techniques to augment the analytical capabilities of GIS-based spatial and temporal decision-making process. It provides an intuitive, interactive manipulation of SVG-based SARS map, dynamically generated from GIS database. SmartGIS provides hierarchical operations to allow a user to view SARS data at multiple levels of details on the Web. This facilitates the continuously visualizing and monitoring of SARS outbreak status. The implementation issues of SmartGIS are described and its applications to other areas are discussed.	abductive reasoning;data visualization;geographic information system;information visualization;scalable vector graphics;world wide web	Long Chyr Chang;Heien-Kun Chiang;Wen-Yi Chiang	2005	ITRE 2005. 3rd International Conference on Information Technology: Research and Education, 2005.	10.1109/ITRE.2005.1503124	computer science;data science;data mining;world wide web	Visualization	-26.64531622266495	-28.82133375036321	88173
d53f15679968998b085ed2d5477e42d74b40e9de	analyzing social media communications for correlation with freeway vehicular traffic		Participatory sensing of traffic, where Internet users share traffic situations either observed by them or automatically sensed by sensors on their smartphones, has become an established means of collecting real-time traffic information (e.g., Google Traffic and Waze). Recent studies have identified strong correlation between social media activity and traffic patterns in the New York area. Interestingly, social media communication leads road traffic. This project computes similar correlations in southern California with an aim to increase the time-resolution of vehicle traffic prediction as near real-time message volume information is available from online social networks. This study collects the number of public messages sent from southern California on the Twitter social media platform. Messages related to several topics are collected. Vehicle flow data at major freeways in the Los Angeles region as measured by Caltrans' extensive network of inductive loop sensors from Caltrans Performance Measurement System (PeMS). The correlation between the two datasets — social media communications and vehicle traffic — is calculated between these datasets. The strengths of these correlations are used to describe the relationship between social media traffic and vehicular traffic in different regions in the southern California. Results show that social media communication is correlated to traffic sensor data with both showing a periodic pattern with approximately the same period. The relationship between social media and vehicular traffic is similar in different roadways in the same region and also holds across regions. Correlation of traffic with volume of social media communications is maximized with a lag of approximately 3 hours (i.e., social media changes appear before traffic volume changes). If further study can also show that there is predictive value in this observation, the time resolution of traffic prediction can be increased by adapting it to real-time changes in social media message volume.	freeway;multimedia framework;participatory sensing;real-time clock;real-time computing;real-time locating system;sensor;smartphone;social media;social network;system of measurement;waze	Niyati Bichu;Anand Panangadan	2017	2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)	10.1109/UIC-ATC.2017.8397565	computer network;distributed computing;computer science;the internet;induction loop;performance measurement;traffic volume;lag;social network;participatory sensing;social media	Metrics	-19.23961717104368	-34.30552382861226	88248
ff5d7a65e8b05b1bd9eec51391babba0b0813329	potensoft: matlab-based software for potential field data processing, modeling and mapping	computadora;tratamiento datos;computers;maps;software;aeromagnetic maps;teledetection;filtering;filtrage;turquia;interfaces;magnetic field;three dimensional models;mapa;modelo 3 dimensiones;spatial domain filtering;logiciel;champ gravimetrique;ordinateur;champ potentiel;modele 3 dimensions;mapa aeromagnetico;frequence;data processing;campo magnetico;traitement donnee;potential field;carte;deteccion a distancia;windows;computer programs;interfase;champ magnetique;frecuencia;asie;frequency domain filtering;gravity field;fenetre;remote sensing;gravity and magnetic data;interface;graphic user interface;ventana;turkey;mapping;source code;campo gravitatorio;middle east;process model;carte aeromagnetique;gui graphical user interface;frequency domain;frequency;programa computador;modeling;programme ordinateur;moyen orient;oriente medio;asia;open source software;turquie	An open-source software including an easy-to-use graphical user interface (GUI) has been developed for processing, modeling and mapping of gravity and magnetic data. The program, called Potensoft, is a set of functions written in MATLAB. The most common application of Potensoft is spatial and frequency domain filtering of gravity and magnetic data. The GUI helps the user easily change all the required parameters. One of the major advantages of the program is to display the input and processed maps in a preview window, thereby allowing the user to track the results during the ongoing process. Source codes can be modified depending on the users’ goals. This paper discusses the main features of the program and its capabilities are demonstrated by means of illustrative examples. The main objective is to introduce and ensure usage of the developed package for academic, teaching and professional purposes. & 2011 Elsevier Ltd. All rights reserved.	graphical user interface;matlab;map;open-source software;qr code;requirement;synthetic intelligence	M. Özgü Arisoy;Ünal Dikmen	2011	Computers & Geosciences	10.1016/j.cageo.2011.02.008	simulation;data processing;computer science;interface;quantum mechanics	HCI	-27.790184415629763	-29.15963894081738	88325
4dfeb3fdba00127159849380186c27737247658c	automatic high-fidelity 3d road network modeling based on 2d gis data	gis;civil engineering;procedural modeling	Many computer applications such as racing games and driving simulations demand high-fidelity 3D road network models. However, few methods exist for the automatic generation of 3D realistic road networks, especially for those in the real world. On the other hand, vast 2D road network data in various geographical information systems (GIS) have been collected in the past and are used by a wide range of applications. A method that can automatically produce 3D high-fidelity road network models from 2D real road GIS data will significantly reduce both the labor and time cost, and greatly benefit applications involving road networks. Based on a set of carefully selected civil engineering rules for road design, this paper proposes a novel approach that transforms existing road GIS data that contain only 2D road centerline information into high-fidelity 3D road network models. The proposed method consists of several major components, including road GIS data preprocessing, 3D centerline modeling, and 3D geometric modeling. With this approach, basic road elements such as road segments, road intersections and traffic interchanges are generated automatically to compose sophisticated road networks in a seamless manner. Results show that this approach provides a rapid and efficient 3D road modeling method for applications that have stringent requirements on high-fidelity road models.	geographic information system	Jie Wang;Gary Lawson;Yuzhong Shen	2014	Advances in Engineering Software	10.1016/j.advengsoft.2014.06.005	simulation;engineering;civil engineering;road weather information system;route planning software;transport engineering	SE	-24.436386583750732	-29.774502167665034	88494
a5a2aa0eb9a194d4eaa00b43707e4e4676c676d0	3d visualization technique for retrieval of documents and images	visualized information space;3dcg;information retrieval;interactive search;visualization;indexing;direction;user interaction;directional display of information;deivational search;image retrieval	This paper describes a new method of multimedia information retrieval which shows multimedia information on a screen in a multi-directional way, using perspective, during the process of recursive interactive retrieval. This method supports a graphical, sensitive and individually tailored interaction between a user and multimedia data. The original work here in is the support of interaction between a user and multimedia data in a way that shows as many as multimedia data in a multi-directional manner on a screen. This work does not involve analytical techniques, although much current research into multimedia information retrieval focuses on processing and handling multimedia data. The prototype system INMUL(Interactive Multidirectional Information Displaying System) is now being implemented.	graphical user interface;information retrieval;programming paradigm;prototype;recursion;visualization (graphics)	Haruo Kimoto	1997		10.1145/275519.275530	document retrieval;computer vision;query expansion;visual word;information visualization;concept search;world wide web;information retrieval;human–computer information retrieval	Web+IR	-31.077832288637044	-33.68936182858909	88610
b963b75fb6c64501aca42c518dde7deb84d96f50	mobile communication signatures of unemployment		The mapping of populations socio-economic well-being is highly constrained by the logistics of censuses and surveys. Consequently, spatially detailed changes across scales of days, weeks, or months, or even year to year, are difficult to assess; thus the speed of which policies can be designed and evaluated is limited. However, recent studies have shown the value of mobile phone data as an enabling methodology for demographic modeling and measurement. In this work, we investigate whether indicators extracted from mobile phone usage can reveal information about the socio-economical status of microregions such as districts (i.e., average spatial resolution < 2.7km). For this we examine anonymized mobile phone metadata combined with beneficiaries records from unemployment benefit program. We find that aggregated activity, social, and mobility patterns strongly correlate with unemployment. Furthermore, we construct a simple model to produce accurate reconstruction of district level unemployment from their mobile communication patterns alone. Our results suggest that reliable and cost-effective economical indicators could be built based on passively collected and anonymized mobile phone data. With similar data being collected every day by telecommunication services across the world, survey-based methods of measuring community socioeconomic status could potentially be augmented or replaced by such passive sensing methods in the future.	aggregate data;causality;interaction;logistics;mobile phone;personalization;population	Abdullah Almaatouq;Francisco Prieto Castrillo;Alex Pentland	2016		10.1007/978-3-319-47880-7_25	simulation;data mining	HCI	-19.42412912495817	-33.241639216405474	88658
60f432331abc0976cf236c738844f9427277b0de	evaluating visual conversational agents via cooperative human-ai games		As AI continues to advance, human-AI teams are inevitable. However, progress in AI is routinely measured in isolation, without a human in the loop. It is crucial to benchmark progress in AI, not just in isolation, but also in terms of how it translates to helping humans perform certain tasks, i.e., the performance of human-AI teams. In this work, we design a cooperative game – GuessWhich – to measure human-AI team performance in the specific context of the AI being a visual conversational agent. GuessWhich involves live interaction between the human and the AI. The AI, which we call ALICE, is provided an image which is unseen by the human. Following a brief description of the image, the human questions ALICE about this secret image to identify it from a fixed pool of images. We measure performance of the human-ALICE team by the number of guesses it takes the human to correctly identify the secret image after a fixed number of dialog rounds with ALICE. We compare performance of the human-ALICE teams for two versions of ALICE. Our human studies suggest a counterintuitive trend – that while AI literature shows that one version outperforms the other when paired with an AI questioner bot, we find that this improvement in AI-AI performance does not translate to improved human-AI performance. This suggests a mismatch between benchmarking of AI in isolation and in the context of human-AI teams.	alice;amazon mechanical turk;amazon web services;artificial intelligence;benchmark (computing);computation;dialog system;downstream (software development);graphics processing unit;ibm notes;intelligent agent;reinforcement learning;sl (complexity);supervised learning;the turk;torch	Prithvijit Chattopadhyay;Deshraj Yadav;Viraj Prabhu;Arjun Chandrasekaran;Abhishek Das;Stefan Lee;Dhruv Batra;Devi Parikh	2017			benchmarking;human–computer interaction;applications of artificial intelligence;human computation;computer science;counterintuitive;dialog box;dialog system;artificial intelligence;human-in-the-loop	AI	-25.10061233167583	-26.15251219630268	88701
7ba1063c11af35db9165429630b383acdbc36857	an intelligent system for supporting personal creativity based on genetic algorithm	information technology;genetic algorithm;idea generation	Creativity has long been recognized as vital to organizational success. IT (Information Technology) may play a supporting role to help organizations and groups in support of creativity. However idea generation inside the personal creative process is still a black box. This motivates us to propose an intelligent system for supporting personal creativity. This study proposes a human-machine interactive mechanism based on IGA (interactive genetic algorithm) for evolution process to help individuals' creativity. Chance discovery has been applied as the strategy in evolution process. It provides more efficient evolution. The intelligent system could bring individuals stimulus to improve personal creativity.	artificial intelligence;genetic algorithm	Heng-Li Yang;Cheng-Hwa Lee	2006		10.1007/11801603_71	functional analysis;black box;simulation;genetic algorithm;creativity technique;ideation;computer science;artificial intelligence;evolutionary algorithm;creativity;information technology	AI	-28.657287141976795	-24.42839827972625	88727
526384db45aefcddf3282e7454351a2573011b3b	mobile analysis of large temporal datasets for exploration and discovery	geospatial analysis mobile communication data visualization data collection satellites image resolution;history;spatiotemporal data geographic information systems mobile computing geovisualization spatio temporal datageographic information systems mobile computing geovisualization;mongolia mobile analysis large temporal datasets mobile field geographic information system gis geospatial datasets location aware mobile computing devices knowledge synthesis virtual data layers mobile tablets direct ground exploration cultural heritage sites discovery;geographic information systems;notebook computers geographic information systems history mobile computing;notebook computers;mobile computing	The increasing power and decreasing size of mobile devices and tablets provide a compelling new platform for mobile field geographic information system (GIS) operations with geospatial datasets. As these data sets become increasingly larger and more dynamic, it introduces the need for real time analysis and data collection in the field. Successful field research in the digital age requires computing power, functionality, and mobility. Location aware mobile computing devices enable new methods of knowledge synthesis by merging physical and virtual data layers. The geospatial dataset in this study is both large in scale and quickly transforms on a daily basis, requiring innovative strategies for effective application. This paper presents the novel combination of mobile tablets, GIS, and geospatial data to direct ground exploration and discovery of cultural heritage sites in Mongolia.	field research;geographic information system;location-based service;mobile computing;mobile device	Andrew Huynh;Albert Yu-Min Lin	2013	2013 Digital Heritage International Congress (DigitalHeritage)	10.1109/DigitalHeritage.2013.6744822	mobile search;geography;data science;geospatial analysis;data mining;mobile computing;world wide web	HCI	-33.168719323760314	-30.305541240369333	88822
8e50940948a9f80ac36e4945ae00b6709c3a284b	correct and faulty driver support from shared haptic control during evasive maneuvers	manuals;driving;vehicles haptic interfaces trajectory manuals roads automation;automobiles;shared control;driving simulator;haptic interfaces automobiles;trajectory;roads;driving simulator shared control haptic guidance evasive maneuvers driving;haptic shared control system faulty driver support shared haptic control evasive maneuvers car maneuver control interface fixed base driving simulator;vehicles;haptic interfaces;evasive maneuvers;haptic guidance;automation	With shared control both driver and support system have control authority and as such exert control actions to maneuver the car. In haptic shared control, the support system acts through guiding forces on the same control interface with which the driver interacts with the vehicle. Previous research showed beneficial results when drivers are supported during lane keeping and curve negotiation. Haptic shared control can be used as an intermediary support system in between the opposites of manual and automatic control. In a fixed-base driving simulator experiment we tested a haptic shared control system during evasive maneuvers. Besides the expected benefits with a perfectly functioning system we also tested the capabilities of drivers to override the system in case of a malfunction. Results of the experiment show that for a time-to-contact (TTC) of 1.4s, haptic shared control reduced the hit rate with obstacles from 21.2% to 15.2%. Even though failure of the haptic support system at TTC=1.4s increased the hit rate to 64.7% (compared to 100% in case of full automation) time spent in the opposite lane was not significantly changed by the failure.	automatic control;control system;device driver;driving simulator;haptic technology;simulation	Mark Mulder;David A. Abbink	2011	2011 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/ICSMC.2011.6083814	embedded system;simulation;artificial intelligence;trajectory;automation	Robotics	-22.12512198675844	-26.331536822964427	88945
590e877af0a1ce455c033ac54313cd2e0fcfcb7f	using direction of arrival to detect cognitive traffic sign in city environments	urban;traffic sign;obu;cr;doa	"""This paper proposes a novel cognitive traffic signs approach. We considered several traffic signs including: right turn ban, """"Be careful pedestrian!"""", """"Car Park"""" etc. The cognitive radio devices on the traffic signs transmit signals to the on-board-unit (OBU) on the car. We assume that radio frequency devices are attached to the traffic signs in the urban area. Traffic signals are transmitted to cars at every t time. We consider the use of direction of arrival model on the OBU unit on the car to receive the signal. The radio devices must be the same direction as the driving direction in two-way street such that cars in the opposite direction will not received the signals. Driving direction and the traffic signs are usually in the same direction. The current study evaluates the performance of the approach by conducting computing simulations."""	direction of arrival	Chi-Kun Lin;Gwo-Jiun Horng;Chi-Hsuan Wang;Jar-Ferr Yang	2015	Wireless Personal Communications	10.1007/s11277-014-2035-1	chromium;telecommunications;traffic wave;computer security	Mobile	-20.004528493436638	-28.57796414985791	89012
411ea5905891c477b4dcc8e33541a5e59f7da895	architectures to make simple visualisations using simple systems	internet desktop integration;mixed initiative;plug and play;separation of concern;hierarchical data;interactive visualisation;artificial intelligent;qa75 electronic computers computer science;software architecture;artificial intelligence;internet application	In previous work, the first author argued for simple lightweight visualisations. These are surprisingly complex to produce due to the need for infrastructure to read files, etc. onCue, a desktop 'agent', aids the rapid production of such visualisations and their integration with desktop and Internet applications. Two examples are used dancing histograms for 2D tables and pieTrees for hierarchical numeric data. A major focus is the importance of architecture, both that of onCue itself and the underlying component infrastructure on which it is built — separation of concerns, mixed initiative computation and plug-and-play components lead to easily produced and easily used systems.	computation;desktop computer;internet;level of measurement;plug and play;separation of concerns	Alan J. Dix;Russell Beale;Andy Wood	2000		10.1145/345513.345250	software architecture;simulation;interactive visualization;human–computer interaction;separation of concerns;computer science;artificial intelligence;theoretical computer science;operating system;data mining;multimedia;world wide web;hierarchical database model	OS	-30.78635726605099	-30.931304383070003	89432
c3c84b82dc84bf4defca995ceec9ce95b0336318	holographic video display of time-series volumetric medical data	computer graphic equipment;holography;medical image processing;rendering (computer graphics);mri dataset;animated electro-holographic visualization;brain lesion;computer graphic rendering;hologram encoding;holographic video display;magnetic resonance imaging;medical imaging;multiple sclerosis;spatial display;time-series volumetric medical data	We describe an animated electro-holographic visualization of brain lesions due to the progression of multiple sclerosis. A research case study is used which documents the expression of visible brain lesions in a series of magnetic resonance imaging (MRI) volumes collected over the interval of one year. Some of the salient information resident within this data is described, and the motivation for using a dynamic spatial display to explore its spatial and temporal characteristics is stated. We provide a brief overview of spatial displays in medical imaging applications, and then describe our experimental visualization pipeline, from the processing of MRI datasets, through model construction, computer graphic rendering, and hologram encoding. The utility, strengths and shortcomings of the electro-holographic visualization are described and future improvements are suggested.	augmented reality;color gradient;display device;holography;medical imaging;resonance;time series	Wendy Plesniak;Michael W. Halle;Steven D. Pieper;William M. Wells;Marianna Jakab;Dominik S. Meier;Stephen A. Benton;Charles R. G. Guttmann;Ron Kikinis	2003	IEEE Visualization, 2003. VIS 2003.		computer vision;radiology;computer science;magnetic resonance imaging;time series;multimedia;holography;computer graphics;computer graphics (images)	Visualization	-27.89673800638403	-37.4602968633336	89526
162e7d803909db5db2c079726032503e051bf2c9	visualization of clustered directed acyclic graphs without node overlapping	directed graphs;directed acyclic graph;electrostatic forces visualization directed acyclic graphs force directed;directed graphs data visualisation;charged particles;data visualisation;visualization;force directed;electrostatic force;directed graph;visual analysis;directed acyclic graphs;electrostatic forces;e spring algorithm clustered directed acyclic graphs graph visualization;e spring algorithm;graph visualization;clustered directed acyclic graphs	Conventional force directed graph drawing methods aim to produce aesthetically pleasing visualization of graphs. The edges of the graph have more or less equal length, and there are as few crossing edges as possible. This paper proposes a new e-spring algorithm for visualizing clustered directed acyclic graphs (DAGs) without node overlapping, extended from the popular spring embedder model. In our framework, nodes are modeled as nonuniform charged particles with weights, and a final drawing is derived by adjusting the positions of the nodes according to a combination of spring forces and repulsive forces derived from electrostatic forces between the nodes. Experimental results and visualization/analysis of this method are reported.	algorithm;class diagram;directed acyclic graph;directed graph;force-directed graph drawing;statistical classification;tree (data structure);tree structure;unified modeling language	Pushpa Kumar;Kang Zhang;Yuke Wang	2008	2008 12th International Conference Information Visualisation	10.1109/IV.2008.85	combinatorics;discrete mathematics;theoretical computer science;force-directed graph drawing;mathematics;graph drawing;directed acyclic graph	Robotics	-29.359000131887576	-36.019054375792045	89565
7ba94acd677f6cccab82cf440d7718b90c340ad6	control representation in an eda assistant	search space;complex data;exploratory data analysis	To develop an initial understanding of complex data, one often begins with exploration. Exploratory data analysis (EDA) provides a set of statistical tools through which patterns in data may be extracted and examined in detail. The search space of EDA operations is enormous, too large to be explored directly in a data-driven manner. More abstract EDA procedures can be captured, however, by representations commonly used in AI planning systems. We describe an implemented planning representation for Aide, an automated EDA assistant, with a focus on control issues. This research was supported by ARPA/Rome Laboratory under contracts F30602-91-C-0076 and F30602-93-C0100. 1 Understanding Complex Data Data analysis plays a central role in our attempts to understand the behavior of complex systems. Exploratory studies are one part of the descriptive process; they provide an informal prelude to experiments, in which questions and procedures can be re ned. Exploration is a kind of detective work: to make a formal presentation of a case, the researcher must follow subtle and potentially con icting clues to a set of possible conclusions. Exploratory results give rise to con rmatory studies in a cycle of successively more re ned exploration and con rmation [Cohen95, Hand86]. Exploratory data analysis (EDA) o ers a wide range of statistical tools for the early stages of analysis [Tukey77]. Simple exploratory procedures generate histograms of discrete and continuous variables, scatter plots and box plots for bivariate relationships, partitions of relationships that distinguish di erent modes of behavior, simpli ed functional relationships, and two-way tables such as contingency tables. From a consideration of these partial descriptions of data, a more complete picture emerges. Viewed as search, exploration is a di cult problem. The exibility of exploratory operators entails a large branching factor and an unbounded search space. If an exploratory analysis were to be driven purely by successive features discovered in data, the task would be impossible: Is a partitioning or a functional transformation appropriate? With what parameters? When should one stop? Though di cult and painstaking, exploration is nevertheless manageable in human hands. Several characteristics of exploration make this possible: relatively few general principles guide exploratory procedures; di cult problems are often decomposed into smaller or simpler parts; exploration is constructive, often relying on partial results and incremental improvement to reach solutions. We can draw a natural analogy between exploration and planning. We have designed an Assistant for Intelligent Data Exploration, Aide, to assist humans in the early stages of data analysis [StAmant94a, StAmant94b]. In Aide, data-directed mechanisms extract simple observations and suggestive indications from the data. Scripted EDA operations then act in goal-directed fashion to generate simpler, deeper, and more extensive descriptions of the data. Control plans guide the EDA operations, relying on intermediate results for their decisions. The system is mixed-initiative, capable of autonomously pursuing high and low level goals while still allowing the user to guide or override its decisions. Aide is currently a prototype under development. Though capable of the analysis we present here, Aide has not yet been extensively tested.	automated planning and scheduling;bivariate data;branching factor;complex systems;contingency table;emergence;experiment;exploratory testing;high- and low-level;naruto shippuden: clash of ninja revolution 3;prototype;μ operator	Robert St. Amant;Paul R. Cohen	1995		10.1007/978-1-4612-2404-4_34	computer science;data science;machine learning;data mining	AI	-24.7272124293067	-32.798889143796096	89773
6ff612ecefafadf5d4ae3356e28be856f7e3e310	interactive particle swarm optimization for the architectural design of truss structures	design engineering;supports architecture design engineering particle swarm optimisation;architecture pso nurbs fem structural engineering user interaction;optimization splines mathematics surface topography surface reconstruction shape topology algorithm design and analysis;interactive particle swarm optimization truss tower design process truss structures algorithmic design aesthetic design particle swarm optimizer optimization scheme free form geometry cad programs computer aided design nurbs truss chords aesthetic criteria truss structure design interactive framework architectural design;supports;architecture;particle swarm optimisation	This paper presents an interactive framework for the design of truss structures with aesthetic criteria. The truss chords are described using NURBS, a tool widely used in computer aided design (CAD) programs to describe free-form geometry. This allows for a convenient interface between the optimization scheme, a particle swarm optimizer, and the user. Driven from the fact that aesthetic design goals are not easily quantifiable, key elements are introduced and implemented herein towards an interactive framework for algorithmic design of truss structures. Within this framework, the user can visually assess interesting solutions, save them for later assessment, actively drive the optimization towards individual aims, re-initialize the optimization with a set of available solutions, or restart the design process. A criterion is introduced as a means of quantifying subjective goals, expressing the similarity of the shape of candidate solutions with respect to reference designs. The framework is tested on a benchmark case and then applied to the design of a truss tower. The effectiveness of the similarity criteria, as well as the ability of the user to drive the process towards specific design goals is demonstrated.	benchmark (computing);computation;computational intelligence;computer-aided design;design tool;dynamic loading;framing (world wide web);interactive design;machine learning;mathematical optimization;microsoft outlook for mac;non-uniform rational b-spline;parallel computing;particle swarm optimization;prototype;reference architecture;sensor;structural analysis	Juliana Felkner;Eleni Chatzi;Toni Kotnik	2013	2013 IEEE Symposium on Computational Intelligence for Engineering Solutions (CIES)	10.1109/CIES.2013.6611723	structural engineering;simulation;engineering;engineering drawing	EDA	-30.042888540977113	-26.56360642715874	89898
04d4fb908c724270f2437ee3f44315b9027e7147	moving on twitter: using episodic hotspot and drift analysis to detect and characterise spatial trajectories	time varying data;inproceedings;geospatial visualisaition;feature detection tracking;visual knowledge discovery	Today, a tremendous source of spatio-temporal data is user generated, so-called volunteered geographic information (VGI). Among the many VGI sources, microblogged services, such as Twitter, are extensively used to disseminate information on a near real-time basis. Interest in analysis of microblogged data has been motivated to date by many applications ranging from trend detection, early disaster warning, to urban management and marketing. One important analysis perspective in understanding microblogged data is based on the notion of drift, considering a gradual change of real world phenomena observed across space, time, content, or a combination thereof.  The scientific contribution provided by this paper is the presentation of a systematic framework that utilises on the one hand a Kernel Density Estimation (KDE) to detect hotspot clusters of Tweeter activities, which are episodically sequential in nature. These clusters help to derive spatial trajectories. On the other hand we introduce the concept of drift that characterises these trajectories by looking into changes of sentiment and topics to derive meaningful information. We apply our approach to a Twitter dataset comprising 26,000 tweets. We demonstrate how phenomena of interest can be detected by our approach. As an example, we use our approach to detect the locations of Lady Gaga's concert tour in 2013. A set of visualisations allows to analyse the identified trajectories in space, enhanced by optional overlays for sentiment or other parameters of interest.	java hotspot virtual machine;kernel density estimation;real-time clock;real-time computing;tweeter;volunteered geographic information	Hansi Senaratne;Arne Bröring;Tobias Schreck;Dominic Lehle	2014		10.1145/2755492.2755497	simulation;geography;data science;data mining	AI	-22.877850477292785	-34.36611634499079	90062
6505cddb57385a8be302187f85fdb02742ded902	colored-sketch of text information	user interface;decision support system;color coding;visualization;information retrieval	This paper presents an information visualization method, which transforms text into abstracted visual representations. The proposed colorcoding algorithm converts text into a sequence of colored icons that inform users about the distributional patterns of given queries, as well as the structural overview of a document simultaneously. By presenting the compact, but instructive visual abstraction of texts concurrently, users can compare multiple documents intuitively while alleviating the need to reference the underlying text. The system provides interactive navigation tools to support users’ decision-making processes – including multi-level viewing, a tree hierarchy recording previous search activities, and suggestive words for refinement of the search scope. An experimental study evaluating this visual approach for delivering search results has been conducted on text corpora in comparison with a traditional information retrieval system. By informing search results to clientele in a perceptive form, the users’ performance in obtaining desired information has been improved, while maintaining the accuracy.	algorithm;experiment;information retrieval;information visualization;refinement (computing);text corpus	Beomjin Kim;Philip Johnson;Adam S. Huarng	2002	InformingSciJ	10.28945/547	knowledge management;automatic summarization;the internet;information retrieval;visualization;computer science;digital library;sketch;abstraction;information visualization;ranking	Web+IR	-30.766121326823665	-34.18683244331871	90261
038ef96a76c515169e77ef9f5ef25498ed4860da	towards a virtual environment for interactive analysis of cluster-based flow pattern abstraction		Recent research efforts show the benefits of using machine learning and interactive visualizations in data analytics. However, there is a void in the implementation of these techniques for the analysis of large and complex 4-dimentional (4D) unsteady flows. Hence, this paper presents an initial development of a virtual environment (VE) to fill this void. The VE has a two-layer architecture with different technologies running in the back and fore grounds. Using machine learning, the background layer implements clustering algorithms for abstracting spatiotemporal patterns of the flows like flow features, spatial regions and temporal phases. The outputs of the clustering algorithms are fed to the foreground layer for interactive selection, sorting and filtering of these patterns. The operations in the foreground make up our designed techniques of flow pattern analysis that aims to provide greater comprehension of 4D flow data. Running in the foreground, the virtual reality (VR) technologies of stereoscopic rendering and haptic feedback further enhance these analysis techniques. Thus, our work introduces a novel environment for the interactive analysis of cluster-based flow pattern abstractions.	algorithm;cluster analysis;haptic technology;machine learning;pattern recognition;sorting;stereoscopy;verification and validation;virtual reality;visual analytics	Suryatapa Roy;Yaoping Hu;Robert J. Martinuzzi;Chris Morton	2017	2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2017.8123181	rendering (computer graphics);machine learning;architecture;data visualization;computer science;cluster analysis;artificial intelligence;data analysis;comprehension;haptic technology;virtual machine	Visualization	-28.669808839294284	-32.50194130841398	90301
6012f5942a8ca03b101871a99de170789dfb95a5	strange beta: an assistance system for indoor rock climbing route setting using chaotic variations and machine learning	pilot study;human computer interaction;chaos;grupo de excelencia;artificial intelligent;machine learning;ciencias basicas y experimentales;natural language;matematicas;smooth transition;domain specificity	This paper applies the mathematics of chaos to the task of designing indoor rock-climbing routes. Chaotic variation has been used to great advantage on music and dance, but the challenges here are quite different, beginning with the representation. We present a formalized system for transcribing rock climbing problems and then describe a variation generator that is designed to support human route-setters in designing new and interesting climbing problems. This variation generator, termed strange beta, uses chaos to introduce novelty. We validated this approach with a large blinded study in a commercial climbing gym, in cooperation with experienced climbers and expert route setters. The results show that strange beta can help a human setter produce routes that are at least as good as, and in some cases better than, those produced in the traditional manner.	chaos theory;climbing;machine learning	Caleb Phillips;Lee Becker;Elizabeth Bradley	2012	Chaos	10.1063/1.3693047	simulation;computer science;artificial intelligence;control theory;mathematics;natural language	HCI	-26.123511916844183	-25.863486337315724	90375
7c96a6026f742184fbe772849b0efac6e7dade6a	multi-feature visualisations of phenotypic behaviour for creative interactive evolution	visualisation;interactive genetic algorithm;creative interactive evolution	A visualisation method is presented for interactive evolution of interactive software objects, in which multiple outputs of the system are used to construct a two-dimensional shape in a feature space. The method allows multiple phenotypes to be overlaid allowing for quick feedback on the different properties of phenotypes. The properties of the resulting visualisations are discussed.	feature vector;interactive evolutionary computation	Oliver Bown;Rob Saunders	2013		10.1145/2464576.2464602	simulation;computer science;theoretical computer science;multimedia	HCI	-33.39648508656657	-32.563069887251416	90392
21a185c7e8b98248db1b092581e7fb90792822f4	interactive visual optimization and analysis for rfid benchmarking	optimisation;time varying;user evaluation;agate;instruments;history;parallel coordinate plots;interactive visualization;orientation plots;data engineering;3d spatial viewer;indexing terms;radiofrequency identification data visualisation optimisation;data visualisation;rfid benchmarking;data analysis;visualization;rfid tags;radio frequency;radiofrequency identification instruments data engineering data visualization performance analysis radio frequency rfid tags multidimensional systems history data analysis;visualization technique;rfid;visual analysis;data visualization;visual history mechanism;rfid visual analytics visualization;performance analysis;radio frequency identification;visual analytics;3d spatial viewer interactive visual optimization rfid benchmarking radiofrequency identification agate data visualization parallel coordinate plots orientation plots visual history mechanism;interactive visual optimization;radiofrequency identification;multidimensional systems;parallel coordinates	Radiofrequency identification (RFID) is a powerful automatic remote identification technique that has wide applications. To facilitate RFID deployment, an RFID benchmarking instrument called aGate has been invented to identify the strengths and weaknesses of different RFID technologies in various environments. However, the data acquired by aGate are usually complex time varying multidimensional 3D volumetric data, which are extremely challenging for engineers to analyze. In this paper, we introduce a set of visualization techniques, namely, parallel coordinate plots, orientation plots, a visual history mechanism, and a 3D spatial viewer, to help RFID engineers analyze benchmark data visually and intuitively. With the techniques, we further introduce two workflow procedures (a visual optimization procedure for finding the optimum reader antenna configuration and a visual analysis procedure for comparing the performance and identifying the flaws of RFID devices) for the RFID benchmarking, with focus on the performance analysis of the aGate system. The usefulness and usability of the system are demonstrated in the user evaluation.	antenna device component;benchmark (computing);cns disorder;deploy;engineering;imagery;mathematical optimization;parallel coordinates;radio frequency identification device;radio-frequency identification;usability;weakness	Yingcai Wu;Ka-Kei Chung;Huamin Qu;Xiaoru Yuan;Shing-Chi Cheung	2009	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2009.156	radio-frequency identification;computer vision;visual analytics;computer science;data mining;world wide web;data visualization;statistics	Visualization	-29.170854721517415	-32.199003655992556	90693
458747974899a810fe99c719a13332a01f094d21	the effect of source nature and status on the subjective value of information	value of information	This is an empirical, experimental investigation of the value of information, as perceived through the willingness to purchase information (WTP) and the willingness to sell it (accept payment, WTA). We examined the effects of source nature: expertise versus content, and source status: copy versus exclusive original of information on the WTA–WTP ratio. In an animated computer simulation of a business game, players could maximize their profits by making choices regarding inventory and prices. Participants were offered the chance to bid for buying or selling information regarding the weather that may affect demand. We find, as hypothesized, that the subjective value of information does indeed follow the predictions of endowment effect theory. The ratio of willingness to accept to willingness to purchase (WTA–WTP) recorded for the 294 subjects resembles the ratio common for private goods, rather than the intuitively expected unity. The WTA–WTP ratios diverged from unity more often and in a more pronounced manner for information traded in the “original” form rather than as a copy of the original, although even for copies the WTA–WTP ratio is still double. The results yield a value of about three for the WTA–WTP ratio for original information whether the source is content or expertise. Copy information received a subjective value that was significantly different (lower) than original information. The implications for both online trading and online sharing of information are discussed. © 2006 Wiley Periodicals, Inc.		Daphne Ruth Raban;Sheizaf Rafaeli	2006	JASIST	10.1002/asi.20280	information;computer science;value of information;endowment effect;information quality;information economy;world wide web	HCI	-24.142240385788597	-26.731268265928698	90841
111948446d0682c920f8e1e144be981f1282e6e5	visual behavior characterization for intrusion detection in large scale systems.	intrusion detection;information visualization;large scale system;computer security;visual representation			Robert F. Erbacher	2001			computer vision;computer science;data mining;computer security	Metrics	-32.417453310884234	-29.67892374308604	91136
52c164c3e8c6e4e6c86ab84bf0e93eff4e4c55fa	a visual digital library approach for time-oriented scientific primary data	content based search;digital library;query formulation;data type;cluster analysis;visual cluster analysis;visual search;visual analysis;data visualization;earth observation;inproceedings;scientific primary data;visual analytics	Digital Library support for textual and certain types of nontextual documents has significantly advanced over the last years. While Digital Library support implies many aspects along the whole library workflow model, interactive and visual retrieval allowing effective query formulation and result presentation are important functions. Recently, new kinds of non-textual documents which merit Digital Library support, but yet cannot be accommodated by existing Digital Library technology, have come into focus. Scientific primary data, as produced for example, by scientific experimentation, earth observation, or simulation, is such a data type. We report on a concept and first implementation of Digital Library functionality, supporting visual retrieval and exploration in a specific important class of scientific primary data, namely, time-oriented data. The approach is developed in an interdisciplinary effort by experts from the library, natural sciences, and visual analytics communities. In addition to presenting the concept and discussing relevant challenges, we present results from a first implementation of our approach as applied on a real-world scientific primary data set.	digital library	Jürgen Bernard;Jan Brase;Dieter W. Fellner;Oliver Köpler;Jörn Kohlhammer;Tobias Ruppert;Tobias Schreck;Irina Sens	2010		10.1007/978-3-642-15464-5_35	earth observation;visual analytics;visual search;data type;computer science;data science;data mining;cluster analysis;cultural analytics;world wide web;information retrieval	HPC	-30.493283378682683	-33.575516868065826	91205
4b54cef1b09eafae29cab58a0f363635af8d5498	pattern recognition of subconscious underpinnings of cognition using ultrametric topological mapping of thinking and memory	hierarchical clustering;ultrametric;text analysis;metric;multivariate data analysis;correspondence analysis;cognition;unsupervised classification;psychoanalysis;social media;computation	The author reviews the theory and practice of determining what parts of a data set are ultrametric. He describes the potential relevance of ultrametric topology as a framework for unconscious thought processes. This view of ultrametric topology as a framework that complements metric-based, conscious, Aristotelian logical reasoning comes from the work of the Chilean psychoanalyst, Ignacio Matte Blanco. Taking text data, the author develops an algorithm for finding local ultrametricity in such data. He applies that in two case studies. The first relates to a large set of dream reports, and therefore can possibly recall traces of unconscious thought processes. The second case study uses Twitter social media, and has the aim of picking up underlying associations. The author’s case studies are selective in regard to names of people and objects, and are focused in order to highlight the principle of his approach, which is one of particular pattern finding in textual data. Pattern Recognition of Subconscious Underpinnings of Cognition using Ultrametric Topological Mapping of Thinking and Memory	algorithm;cognition;matte display;pattern language;pattern recognition;relevance;social media;text corpus;tracing (software)	Fionn Murtagh	2014	IJCINI	10.4018/ijcini.2014100101	text mining;cognition;social media;metric;computer science;artificial intelligence;machine learning;ultrametric space;computation;hierarchical clustering;multivariate analysis;correspondence analysis;statistics	Web+IR	-24.521237331983816	-32.28354986146358	91453
10e5eeb4902abfb66c6013782039380a976379cd	designing human friendly human interaction proofs (hips)	turing test;human interactive proof;automatic generation;computer vision;visual letter recognition;evaluation;profitability;completely automated public turing tests to tell computers and humans apart captchas;human perception;human interaction proofs hips	HIPs, or Human Interactive Proofs, are challenges meant to be easily solved by humans, while remaining too hard to be economically solved by computers. HIPs are increasingly used to protect services against automatic script attacks. To be effective, a HIP must be difficult enough to discourage script attacks by raising the computation and/or development cost of breaking the HIP to an unprofitable level. At the same time, the HIP must be easy enough to solve in order to not discourage humans from using the service. Early HIP designs have successfully met these criteria [1]. However, the growing sophistication of attackers and correspondingly increasing profit incentives have rendered most of the currently deployed HIPs vulnerable to attack [2,7,12]. Yet, most companies have been reluctant to increase the difficulty of their HIPs for fear of making them too complex or unappealing to humans. The purpose of this study is to find the visual distortions that are most effective at foiling computer attacks without hindering humans. The contribution of this research is that we discovered that 1) automatically generating HIPs by varying particular distortion parameters renders HIPs that are too easy for computer hackers to break, yet humans still have difficulty recognizing them, and 2) it is possible to build segmentation-based HIPs that are extremely difficult and expensive for computers to solve, while remaining relatively easy for humans.	attack (computing);computation;computer;distortion;humans;machine learning;rendering (computer graphics);security hacker;user-centered design	Kumar Chellapilla;Kevin Larson;Patrice Y. Simard;Mary Czerwinski	2005		10.1145/1054972.1055070	turing test;simulation;computer science;artificial intelligence;evaluation;perception;world wide web;profitability index	Security	-25.40322926017626	-26.18828155086348	91537
05894f2a7ae4351c8094d56c64a215d193060d04	emu: the emory user behavior data management system for automatic library search evaluation	data collection;data capture;user behavior modeling;data exploration;user behavior;user interaction;library search evaluation;database management system;data management system	We describe EMU, a system for collecting, managing, and mining the behavior data collected in the Emory libraries search system. We describe the data capture system based on the LibX browser plugin, the database management system for successfully storing, searching and exploring millions of resulting user interactions, and preliminary results of interesting queries and statistics that we are using to evaluate the effectiveness of library search tools.	browser extension;database;interaction;libx;library (computing)	Qi Guo;Ryan P. Kelly;Selden Deemer;Arthur Murphy;Joan A. Smith;Eugene Agichtein	2009		10.1145/1555400.1555477	computer science;data mining;database;automatic identification and data capture;world wide web;data collection	Web+IR	-31.595474869735877	-30.514639024237272	92065
976e18abe13e62091dc18223ddb059fb2c1fd0df	dynamic traffic light system for unhindered passing of high priority vehicles: wireless implementation of dynamic traffic light systems using modular hardware		Response time of the emergency services is vital in drastically improving the chances of survival and of meaningful recovery for the affected individuals in emergency situations. Often precious time is often lost for emergency services due to traffic, especially at traffic intersections. What we propose is a dynamic solution to the aforementioned problem using an intelligent network of smart traffic lights which all turn green in anticipation of an approaching emergency vehicle, thus providing unhindered passage to it. Further, so to facilitate the implementation of the aforementioned logic in non-smart traffic networks, a wireless embedded system based hardware solution is proposed to convert existing autonomous traffic light systems into a networked one.	autonomous robot;embedded system;intelligent network;responsiveness	A. Athul Krishna;Bharath A. Kartha;Vishnu S. Nair	2017	2017 IEEE Global Humanitarian Technology Conference (GHTC)	10.1109/GHTC.2017.8239237	computer hardware;response time;wireless;modular design;intelligent network;emergency vehicle;computer science	Mobile	-20.51754483903689	-26.302959842985043	92454
08eaad442e3fe2d5c37b404f585fbccfd53c72ef	validation of the enlisted grade model gradebreaks	digital simulation;military computing;active army military manpower program;military occupational specialty level system;army strength analysts;enlisted grade model gradebreaks;operations research;predictive validation	This paper describes the validation of the Enlisted Grade model gradebreaks and describes a current application of simulation in operations research. The Enlisted Grade model is part of a suite of models used by Army strength analysts to forecast active Army strength to develop the Active Army Military Manpower Program and for use in the President's Budget and the Program Objective Memorandum. The Enlisted Grade model gradebreaks were tested by predictive validation, comparison to the Military Occupational Specialty Level System and face validity before acceptance. The validation of the Enlisted Grade gradebreaks was the final milestone in the acceptance of the Enlisted Grade model.	memorandum;operations research;simulation	Andrew O. Hall	2004	Proceedings of the 2004 Winter Simulation Conference, 2004.		simulation;predictive validity;computer science;engineering;operations research	EDA	-22.624727538612497	-25.541340408397517	92579
274f10bd7c1b13fcddb5c37d3720b9f3e6087eae	eye2i: coordinated multiple views for gaze data	visual interaction;multiple views;data visualization;coordinated multiple views;gaze data visualization	Different visualizations, such as gaze plots and heat maps, are prevalent tools for analyzing gaze data. For complex and multi-variate data, the use of coordinated multiple views is an efficient approach to visualizing information. This paper presents a tool combining gaze data visualizations with coordinated multiple-view methods for exploring gaze data.	heat map	Harri Rantala	2008		10.1145/1344471.1344509	computer vision;computer science;data mining;multimedia	HCI	-28.908711310885227	-33.71760526038538	92742
edeb06a190f76d76a70d81d2658494f480d76c58	visualization support for multi-criteria decision making in geographic information retrieval		The goal of geographic information retrieval (GIR) is to provide information about geo-entities to end-users and assist their spatial decision making. In the current means of GIR interfaces, users could easily visualize the geo-entities of interest on a map interface via sequential querying or browsing of individual categories. However, there are several decision making scenarios when the user needs to explore and investigate the geospatial database with multiple criteria of interests, which is not well supported by the sequential querying or browsing functionality of current GIR interfaces. There is a need for more sophisticated visual interfaces to enable end-users in discovering knowledge hidden in multi-dimensional geospatial databases. In this paper we discuss some of the HCI issues in realizing such multi-criteria decision making scenario based on the user requirement analysis. To tackle the human centered aspects we propose different heatmap based interfaces to support multi-criteria visualizations in GIR, i.e., to facilitate the knowledge based exploration of geospatial databases with less information overload.	information retrieval	Chandan Kumar;Wilko Heuten;Susanne Boll	2013		10.1007/978-3-642-40511-2_26	information visualization;gis and public health;data mining;information retrieval;human–computer information retrieval	Web+IR	-30.634824222382896	-32.80932127775516	92855
acddfa11bc9f94125b3f5a01414c254b0b2f3101	navy enhanced sierra mechanics (nesm): toolbox for predicting navy shock and damage	damage;engineering;object recognition;investments;electric shock;create;design engineering;testing;investment;hpcmp;computer applications;physics;computational modeling;navy;ships;parallel architectures;marine vehicles;us department of defense;mechanics;scientific computing;software software engineering;military;naval engineering computing;weapons;military computing;shock	The US Navy is developing a new suite of computational mechanics tools (Navy Enhanced Sierra Mechanics) for the prediction of ship response, damage, and shock environments transmitted to vital systems during threat weapon encounters. NESM includes fully coupled Euler-Lagrange solvers tailored to ship shock/damage predictions. NESM is optimized to support high-performance computing architectures, providing the physics-based ship response/threat weapon damage predictions needed to support the design and assessment of highly survivable ships. NESM is being employed to support current Navy ship design and acquisition programs while being further developed for future Navy fleet needs.	computational mechanics;euler;supercomputer	Thomas Moyer;Jonathan Stergiou;Garth Reese;James Luton;Najib Abboud	2016	Computing in Science & Engineering	10.1109/MCSE.2016.47	simulation;investment;computer science	HPC	-22.657444699314304	-24.807488963650318	93507
f51720150bf52f3c83d0734285ad59a96e49a67f	predicting nuclear power-plant operator performance using discrete event simulation	human performance;pedestrian safety;poison control;injury prevention;simulation;safety literature;traffic safety;injury control;home safety;simulation software;injury research;safety abstracts;human factors;occupational safety;safety;regulatory;nuclear;safety research;accident prevention;validation;nuclear power plant;violence prevention;bicycle safety;poisoning prevention;modeling;falls;simulation model;computer simulation;ergonomics;suicide prevention;discrete event simulation	A study was conducted to evaluate the use of discrete event simulation (DES) to predict human performance in a nuclear power plant control room environment. Computer simulation models of two disturbance scenarios were built using a simulation software program, Micro Saint. In parallel, data were also collected at a full-scope training simulator at the Halden man-machine laboratory (HAMMLAB) in Halden, Norway, using crews of commercial nuclear power plant operators from the Loviisa nuclear power plant in Loviisa, Finland. Comparisons were made between predicted operator performance data generated by the simulation models and crew performance in the HAMMLAB experiment to determine the degree of agreement between the simulated data and the data from operators. The models were then used to extrapolate advanced control room conditions and alarm systems that were not tested in the HAMMLAB experiment. This report summarizes these findings and provides recommendations for improvements to the DES approach for use by a regulatory agency.	advanced process control;computer program;computer simulation;experiment;extrapolation;flight simulator;human reliability;self-replication;simulation software	Amy Yow;Brett Walters;Beth M. Plott;K. Ronald Laughery;J. Persensky	2004	Cognition, Technology & Work	10.1007/s10111-004-0167-x	human performance technology;regulation;simulation;systems modeling;simulation software;nuclear weapon;computer science;engineering;suicide prevention;human factors and ergonomics;injury prevention;discrete event simulation;simulation modeling;forensic engineering;computer security	SE	-22.566940348522376	-25.5140166405803	93726
5d2181bb40e921464d90165a2eedee028299b54e	treeviz: treemap visualization of hierarchically structured information	hierarchical structure;story grammars;educational software;user interaction	Scientific visualization has received a great deal of attention in recent years. There are many reasons for this but chief among them is the simple observation that humans have difficulty extracting meaningful information from large volumes of data. Our increasing ability to produce, disseminate, and collect information has quite naturally led to a demand for tools which aid in the analysis of this information and support our intuition.	scientific visualization;treemapping	Brian Johnson	1992		10.1145/142750.142833	computer science;theoretical computer science;educational software	Visualization	-30.700833785877787	-30.322162173440294	93763
1962d808967f75146218bffe40282e3c40d50172	structural analysis of hypertexts: identifying hierarchies and useful metrics	graph theory;hierarchical structure;complex network;metrics;hierarchies;structural complexity;structural analysis;authoring tool;hypertext;structure analysis	Hypertext users often suffer from the “lost in hyperspace” problem: disorientation from too many jumps while traversing a complex network. One solution to this problem is improved authoring to create more comprehensible structures. This paper proposes several authoring tools, based on hypertext structure analysis. In many hypertext systems authors are encouraged to create hierarchical structures, but when writing, the hierarchy is lost because of the inclusion of cross-reference links. The first part of this paper looks at ways of recovering lost hierarchies and finding new ones, offering authors different views of the same hypertext. The second part helps authors by identifying properties of the hypertext document. Multiple metrics are developed including compactness and stratum. Compactness indicates the intrinsic connectedness of the hypertext, and stratum reveals to what degree the hypertext is organized so that some nodes must be read before others. Several existing hypertexts are used to illustrate the benefits of each technique. The collection of techniques provides a multifaceted view of the hypertext, which should allow authors to reduce undesired structural complexity and create documents that readers can traverse more easily.	complex network;cross-reference;hypertext;kinetic data structure;lost in hyperspace;mechatronics;structural analysis;traverse	Rodrigo A. Botafogo;Ehud Rivlin;Ben Shneiderman	1992	ACM Trans. Inf. Syst.	10.1145/146802.146826	computer science;artificial intelligence;graph theory;theoretical computer science;machine learning;data mining;database;structural analysis;world wide web	Web+IR	-28.70480881993201	-36.165085553505534	93770
0d2374e7bb40f2ffc3b7e8dc4b4f90a0d9c3a10e	mobile application development exploiting science gateway technologies	dcis;science gateways;scientific visualization;large scale datasets;astrophysics;collaborative environments;mobile application;workflow systems	SummaryrnNowadays, collaborative applications are valuable tools for scientists to share their studies and experiences, for example, by interacting simultaneously with their data and outcomes giving feedback to other colleagues on how the data are processed. This paper presents a mobile application connected to a workflow-enabled framework to perform visualization and data analysis of large-scale, multi-dimensional datasets on distributed computing infrastructures. In particular, the usage of workflow-driven applications, through science gateway technologies, allows the scientist to share heavy data exploration tasks as workflows and the relative results in a transparent and user-friendly way. Copyright © 2015 John Wiley u0026 Sons, Ltd.		Fabio Vitello;Eva Sciacca;Ugo Becciani;Alessandro Costa;Piero Massimino;Éva Takács;Balázs Szakál	2015	Concurrency and Computation: Practice and Experience	10.1002/cpe.3538	scientific visualization;human–computer interaction;computer science;data science;world wide web	Logic	-30.783267333853118	-29.0402325273394	94699
a8e034dc1fdaf235ed415f1cff6cac76f274774a	distributed force-directed graph layout and visualization	directed graph	While there exist many interactive tools for the visualization of small graphs and networks, these tools do not address the fundamental problems associated with the visualization of large graphs. In particular, larger graphs require much larger display areas (e.g., display walls) to reduce visual clutter, allowing users to determine the structure of large graphs. Moreover, the layout algorithms employed by these graph visualization tools do not scale to larger graphs, thereby forcing users into a batchoriented process of generating layouts offline and later viewing of static graph images. In this paper, we present a parallel graph layout algorithm based on the Fruchterman-Reingold force-directed layout algorithm and demonstrate its implementation in a distributed rendering environment. The algorithm uses available distributed resources for both compute and rendering tasks, animating the graph as the layout evolves. We evaluate the algorithm for scalability and interactivity and discuss variations that minimize communication for specific types of graphs and applications.	algorithm;clutter;computer cluster;directed graph;existential quantification;force-directed graph drawing;graph (discrete mathematics);interactivity;online and offline;parallel computing;parallel rendering;real-time clock;real-time data;scalability;video wall;workstation	Christopher Mueller;Douglas P. Gregor;Andrew Lumsdaine	2006		10.2312/EGPGV/EGPGV06/083-090	directed graph;computer science;theoretical computer science;machine learning;distributed computing;graph;graph drawing;graph operations	Visualization	-28.589654718544878	-35.33646345050583	94809
20d2fe25e1c083e99b5d5d764ab42f978c389003	emergent phenomena in constrained 3d layout design		While explored in the context of creativeness in computer aided design, emergence has hardly ever been mentioned as a phenomenon that may enhance optimization process in engineering design. This paper presents the original approach to constrained 3D component layout design problem that takes advantage of visual shape grammar computations, emergent phenomena and computational intelligence methods. Possible design solutions are generated with a use of a simple shape grammar. Design specific knowledge is represented in a form of goals and constraints and the search process is driven by an intelligent derivation controller. The presented framework is very general but in the same time flexible and easily adjustable to a specific problem domain.	emergence	Katarzyna Grzesiak-Kopec;Maciej Ogorzalek	2014		10.1007/978-3-319-07176-3_42	control theory;artificial intelligence;computer science;machine learning;computer aided design;engineering design process;shape grammar;page layout;computational intelligence;problem domain;phenomenon	HCI	-28.86872217927748	-25.57564167199732	94886
b1bc7ebd183b8e1f6c609a7783662dcb66ee7c9e	an adaptive complex data investigation methodology using interactive multi-menus	complex data;directional data;interaction model;missing data;multimedia presentation;user interaction	Multimedia presentation of dynamic rheological experimental and simulated data sets is a complex process, due to the dynamic interrelation of the data. In this work we address the problem of direct data interaction, focusing particularly on the case where the application has to dynamically handle changes at runtime. Interactivity modeling relies on visual metadata representations, which are both used to relate directly to the underlying system-graph and formally describe content-connectivity. Under this context a novel user-interaction structure (Multi-Menu) is introduced, allowing valid-only data comparison across the vast number of possible results combinations, supporting discussion-based data combinations and user-driven scenarios, which can in turn trigger automated simulation execution to generate missing data. The proposed methodology applies to other complex data investigation scenarios and systems with adaptive interactivity and automatic system-adjustment requirements.	effective method;interactivity;logic programming;missing data;requirement;run time (program lifecycle phase);simulation	Deliyiannis Ioannis;Andreas Floros;Michael F. Webster	2007		10.1007/978-0-387-77745-0_38	human–computer interaction;missing data;computer science;data mining;world wide web;complex data type	Visualization	-25.796807259947716	-34.030040763610636	95117
71a4bbaccec013cd1d750c37ae90bf54cf4d912e	using spring algorithms to remove node overlapping	node overlapping;graph drawing;spring algorithm	Cluttered drawings of graphs cannot effectively convey the information of graphs. Two issues might cause node overlapping when one draws a picture of a graph. The first issue occurs when applying a layout algorithm for an abstract graph to a practical application in which nodes are labeled. The second is the changing of a node’s size in a dynamic drawing system. This paper presents two algorithms, DNLS and ODNLS, for removing the two kinds of overlapping. The algorithms are based on the well-known spring embedder model. The outputs of the algorithms provide the features of spring algorithms. Experiments are carried out to compare DNLS and ODNLS to the Force Scan(FS) algorithm and its variants. The results demonstrate the advantages of DNLS and ODNLS in terms of some aesthetic criteria.	algorithm;experiment;field electron emission;force-directed graph drawing;graph (discrete mathematics);mental mapping;video post-processing;whole earth 'lectronic link	Wanchun Li;Peter Eades;Nikola S. Nikolov	2005			computer science;theoretical computer science;force-directed graph drawing;machine learning;distributed computing	ML	-29.60076098827103	-36.37721429711018	95169
59addcc7128689b0104a389fce98a13e23ed1592	comparing information graphics: a critical look at eye tracking	area of interest;visualization;evaluation;eye tracking;line graph	Effective graphics are essential for understanding complex information and completing tasks. To assess graphic effectiveness, eye tracking methods can help provide a deeper understanding of scanning strategies that underlie more traditional, high-level accuracy and task completion time results. Eye tracking methods entail many challenges, such as defining fixations, assigning fixations to areas of interest, choosing appropriate metrics, addressing potential errors in gaze location, and handling scanning interruptions. Special considerations are also required designing, preparing, and conducting eye tracking studies. An illustrative eye tracking study was conducted to assess the differences in scanning within and between bar, line, and spider graphs, to determine which graphs best support relative comparisons along several dimensions. There was excessive scanning to locate the correct bar graph in easier tasks. Scanning across bar and line graph dimensions before comparing across graphs was evident in harder tasks. There was repeated scanning between the same dimension of two spider graphs, implying a greater cognitive demand from scanning in a circle that contains multiple linear dimensions, than from scanning the linear axes of bar and line graphs. With appropriate task design and targeted analysis metrics, eye tracking techniques can illuminate visual scanning patterns hidden by more traditional time and accuracy results.	eye tracking;graphics;high- and low-level;image scanner;infographic;line graph	Joseph H. Goldberg;Jonathan Helfman	2010		10.1145/2110192.2110203	computer vision;simulation;computer science;computer graphics (images)	HCI	-30.494905247691538	-36.76846842594612	95275
a95a8a0a8661e905b057b2cdbaa02854a31e207f	measuring economic activity in china with mobile big data	computational social science;economic activity;mobile data;complex systems	Emerging trends in the use of smartphones, online mapping applications, and social media, in addition to the geo-located data they generate, provide opportunities to trace users’ socio-economic activities in an unprecedentedly granular and direct fashion and have triggered a revolution in empirical research. These vast mobile data offer new perspectives and approaches to measure economic dynamics, and they are broadening the social science and economics fields. In this paper, we explore the potential for using mobile data to measure economic activity in China from a bottom-up view. First, we build indices for gauging employment and consumer trends based on billions of geo-positioning data. Second, we advance the estimation of offline store foot traffic via location search data derived from Baidu Maps, which is then applied to predict Apple’s revenues in China and to accurately detect box-office fraud. Third, we construct consumption indicators to track trends in various service sector industries and verify them with several existing indicators. To the best of our knowledge, this is the first study to measure the world’s second-largest economy by mining such unprecedentedly large-scale and fine-granular spatial-temporal data. In this way, our research provides new approaches and insights into measuring economic activity.	big data;online and offline;smartphone;social media;top-down and bottom-up design;web mapping	Lei Dong;Sicong Chen;Yunsheng Cheng;Zhengwei Wu;Chao Li;Haishan Wu	2017	EPJ Data Science	10.1140/epjds/s13688-017-0125-5	computational sociology;data science;mobile broadband;big data;empirical research;computer science;data mining;complex system;social media;tertiary sector of the economy;revenue	HCI	-20.28834742003987	-34.99063459705756	95649
f3eb5b0634bd30bd81899f7f2fb0f3fba4d034f0	do we have a sense for irrational numbers?	numerical distance effect;natural number bias;magnitude representation;number comparison;number sense	Number sense requires, at least, an ability to assess magnitude information represented by number symbols. Most educated adults are able to assess magnitude information of rational numbers fairly quickly, including whole numbers and fractions. It is to date unclear whether educated adults without training are able to assess magnitudes of irrational numbers, such as the cube root of 41. In a computerized experiment, we asked mathematically skilled adults to repeatedly choose the larger of two irrational numbers as quickly as possible. Participants were highly accurate on problems in which reasoning about the exact or approximate value of the irrational numbers’ whole number components (e.g., 3 and 41 in the cube root of 41) yielded the correct response. However, they performed at random chance level when these strategies were invalid and the problem required reasoning about the irrational number magnitudes as a whole. Response times suggested that participants hardly even tried to assess magnitudes of the irrational numbers as a whole, and if they did, were largely unsuccessful. We conclude that even mathematically skilled adults struggle with quickly assessing magnitudes of irrational numbers in their symbolic notation. Without practice, number sense seems to be restricted to rational numbers.		Andreas Obersteiner;Veronika Hofreiter	2017	JNC	10.5964/jnc.v2i3.43	arithmetic;discrete mathematics;mathematics		-24.89237012113814	-28.24271310647735	95960
f1c55256716a92fa996a4d9c0038f56a7f85637d	distributed visual analytics on large-scale high-resolution displays	rendering computer graphics data visualisation fractals graphics processing units image resolution pattern clustering;performance characteristics distributed visual analytics large scale high resolution displays graphics cluster software development interactive information visualization visual analytics distributed gpu based rendering multitile large scale display information visualization scientific visualization high resolution information visualization software architecture fractal tree visualization technique;rendering computer graphics data visualization visual analytics graphics processing units three dimensional displays geometry	Large-scale high-resolution displays are becoming increasingly available and have thus been the target of recent research. Such systems are usually driven by a graphics cluster, making software development a tedious endeavor; this might be the reason why it is uncommon to use them for interactive information visualization and visual analytics. However, this application area can particularly benefit from a large number of pixels. Therefore, we investigate distributed GPU-based rendering for visual analytics on a multi-tile large-scale display offering high resolution. We discuss conceptual differences and commonalities between information and scientific visualization on high-resolution displays. The requirements of high-resolution information visualization result in design choices for a software architecture for distributed GPU rendering. We illustrate our system for the example of a fractal tree visualization technique and report on performance characteristics and other experiences.	big data;fractal;graphics processing unit;hardware acceleration;image resolution;information visualization;interaction technique;magnetic-core memory;pixel;requirement;scalability;scientific visualization;simulation;software architecture;software development;usability testing;visual analytics	Hansjörg Schmauder;Michael Burch;Christoph Müller;Daniel Weiskopf	2015	2015 Big Data Visual Analytics (BDVA)	10.1109/BDVA.2015.7314291	software visualization;computer vision;visual analytics;scientific visualization;information visualization;visualization;interactive visualization;rendering;interactive visual analysis;computer science;parallel rendering;real-time computer graphics;multimedia;computer graphics;data visualization;software rendering;3d computer graphics;computer graphics (images)	Visualization	-28.48611189953373	-32.4639815625823	96042
fd2c7aa203cfe66532a8de1a6beb762471e50ef5	smart drivers' guidance system based on iot technologies for smart cities application		Finding an available parking place is becoming an exhaustive task due to the increasing amount of cars and vehicles, especially in the metropolitan cities. The search for an available parking place through the roads and parking stations is a major waste of time and efforts, mainly in pic hours when parking places are almost full. This problem can be felt mainly around city centres, hospitals, shopping complexes and many other crowded stations and roads. This can also accentuate the problem of traffic congestion and aggravate the task of the drivers.	guidance system;smart card;smart city	Imen Masmoudi;Wiam Elleuch;Ali Wali;Adel M. Alimi	2017		10.1007/978-3-319-59650-1_45	guidance system;machine learning;smart city;artificial intelligence;transport engineering;computer science;internet of things;metropolitan area;traffic congestion	HCI	-20.144459845713858	-28.77927868743527	96733
21b456621a45b25f1491dcd51aff8f51c0b93505	a comparative study of desktop, fishtank, and cave systems for the exploration of volume rendered confocal data sets	data analysis data visualization microscopy cells biology virtual reality virtual environment collaboration layout three dimensional displays costs;laser confocal microscopy data;biological data exploration;spatial relationships desktop fishtank cave systems volume rendered confocal data sets biological data exploration volume rendering laser confocal microscopy data data visualization biological data analysis;volume rendering;collaboration;virtual reality;microscopy;layout;info eu repo semantics article;scientific visualization;data visualisation;data analysis;participant evaluation;evaluation methodology;three dimensional displays;fishtank;data visualization;virtual reality data visualisation rendering computer graphics;biological data analysis;participant studies;algorithms computer graphics ecosystem image enhancement image interpretation computer assisted imaging three dimensional microscopy confocal numerical analysis computer assisted reproducibility of results sensitivity and specificity signal processing computer assisted;spatial relationships;biological data;applications virtual reality evaluation methodology;virtual environment;rendering computer graphics;confocal microscopy;applications;cave systems;cells biology;volume rendered confocal data sets;desktop;info eu repo semantics publishedversion	We present a participant study that compares biological data exploration tasks using volume renderings of laser confocal microscopy data across three environments that vary in level of immersion: a desktop, fishtank, and cave system. For the tasks, data, and visualization approach used in our study, we found that subjects qualitatively preferred and quantitatively performed better in the cave compared with the fishtank and desktop. Subjects performed real-world biological data analysis tasks that emphasized understanding spatial relationships including characterizing the general features in a volume, identifying colocated features, and reporting geometric relationships such as whether clusters of cells were coplanar. After analyzing data in each environment, subjects were asked to choose which environment they wanted to analyze additional data sets in - subjects uniformly selected the cave environment.	colocation centre;desktop computer;imagery;immersion (virtual reality);microscopy, confocal;volume rendering	Prabhat;Andrew S. Forsberg;Michael Katzourin;Kristi Wharton;Mel Slater	2008	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2007.70433	spatial relation;layout;computer vision;biological data;computer science;virtual machine;confocal laser scanning microscopy;data mining;multimedia;data analysis;volume rendering;data visualization;statistics;computer graphics (images);collaboration	Visualization	-32.514525173283786	-36.72192662406653	96749
b83b89e8dc42519062020c844d082be251682558	solutions to the problem of inconsistent plans in railway traffic operation	control systems;human computer interaction;pedestrian safety;manniska datorinteraktion interaktionsdesign;poison control;injury prevention;cooperation;safety literature;traffic management;traffic safety;injury control;home safety;injury research;safety abstracts;human factors;railroad traffic;energy consumption;operator interface;occupational safety;safety;safety research;rail human factors;railroad safety;accident prevention;violence prevention;bicycle safety;railroad traffic control;poisoning prevention;falls;ergonomics;suicide prevention;infrastructure;train traffic control;driver advisory system;automation	The demands on modern railway traffic systems are high. Higher efficiency is required, meaning better utilisation of infrastructure capacity and reduced energy consumption. Timeliness has a high priority and safety has to be unconditional. The operation of railway traffic includes many actors in different roles and separate organisations. Our studies of train traffic control have shown that improved collaboration between the actors and advanced control systems are needed to meet the high demands. Instead, many actors are following their own plans based on their own goals and insufficient information. This paper explores the concept of a real-time traffic plan (RTTP) to coordinate collaboration between the different actors, and demonstrates how it can be implemented in systems for train traffic control and driver information. We present the traffic control system STEG and the driver advisory system CATO. Both systems are in use, allowing re-planning and sharing of such an RTTP. Based on these systems, we discuss general and specific design solutions, in accordance with human factors and explain a way of introducing automation that supports the traffic controllers without interfering with their planning. With these systems, we are able to show that a more holistic approach to train traffic control, based on an RTTP, is technically feasible and that sharing this plan with the train drivers substantially improves qualities in train traffic	advanced process control;control system;holomovement;human factors and ergonomics;real-time transcription	Simon Tschirner;Bengt L. Sandblad;Arne W. Andersson	2014	JRTPM	10.1016/j.jrtpm.2014.10.002	simulation;engineering;transport engineering;computer security	OS	-19.44637973993584	-25.379801440296266	96968
f68d546e983db5101aeb36943f806df16fab93a0	mental map preserving graph drawing using simulated annealing	graph drawing;information visualization;simulated annealing;mental map	0020-0255/$ see front matter 2011 Elsevier Inc doi:10.1016/j.ins.2011.06.005 q A preliminary version of this work was presente ⇑ Corresponding author. E-mail address: yen@cc.ee.ntu.edu.tw (H.-C. Yen Visualizing graphs has been studied extensively in the community of graph drawing and information visualization over the years. In some applications, the user is required to interact with a graph by making slight changes to the underlying graph structure. To visualize graphs in such an interactive environment, it is desirable that the differences between the displays of the original and the modified graphs be kept minimal, allowing the user to comprehend the changes in the graph structure faster. As the mental map concept refers to the presentation of a person’s mind while exploring visual information, the better the mental map is preserved, the easier the structure change of a graph is understood. It is somewhat surprising that preserving the user’s mental map has largely been ignored in the graph drawing community in the past. We propose an effective mental-map-preserving graph drawing algorithm for straight-line drawings of general undirected graphs based on the simulated-annealing technique. Our experimental results and questionnaire analysis suggest this new approach to be promising. 2011 Elsevier Inc. All rights reserved.		Yi-Yi Lee;Chun-Cheng Lin;Hsu-Chun Yen	2006		10.1145/1151903.1151930	economic graph;computer science;artificial intelligence;theoretical computer science;machine learning;graph drawing	HCI	-29.949131781424306	-36.470577893253704	96993
36a317552b7035345e752123a40ac7f4698968bf	a unified approach to labeling graphical features	graph drawing	The automatic placement of text or symbol labels corresponding to graphical objects is critical in several application areas such as Cartography, Geographical Information Systems, and Graph Drawing. In this paper we present a general framework for solving the problem of assigning text or symbol labels to a set of graphical features in two dimensional drawings or maps. Our approach does not favor the labeling of one type of graphical feature (such as a node, edge, or area) over another. Additionally, the labcls arc allowed to have arbitrary size and orientation. We have applied our framework to drawings of graphs. We have implemented our techniques and have performed extensive experimentation on hierarchical and orthogonal drawings of graphs. The resulting label assignments are very practical and indicate the effectiveness of our approach.	cartography;geographic information system;graph (discrete mathematics);graph drawing;graphical user interface;map;node (computer science)	Konstantinos G. Kakoulis;Ioannis G. Tollis	1998		10.1145/276884.276923	mathematics;graph drawing	HCI	-30.162962872285107	-35.4011484216432	97753
ce67d7020cd838e3032456aa357cf97cfd66b811	gisting continuous speech	prompt notification;continuous output stream;air traffic controller;processing radio communication;continuous speech;voice traffic;timely report;real-time system;real time systems;real time	"""The objective of this work is automatic, real-time """"gisting"""" of voice: traffic for updating of information in databases, for producing timely reports, and for prompt notification of events of interest. Specifically, the goal is to build a prototype, real-time system capable of processing radio communication between air traffic controllers and pilots; identifying dialogs and extracting their """"gist"""" (e.g., identifying flights, determining whether they are landing or taking off), and producing a continuous output stream with that information. The approach is intended to be general and applicable to other domains."""	database;gist;prototype;real-time clock;real-time computing;real-time transcription	Jan Robin Rohlicek	1993			real-time computing;simulation;speech recognition;computer science	DB	-21.813618284405504	-27.99500133558513	97867
4743266c74e181c17f9986852d8c1ffc2970bf13	system specifications for developing an automatic dependent surveillance-broadcast (ads-b) monitoring system	system specifications;performance monitoring;automatic dependent surveillance broadcast ads b system	Automatic Dependent Surveillance-Broadcast (ADS-B) is a surveillance system placed in aircraft that periodically transmits state vector estimates and other information to air traffic control centers and other nearby aircraft (and may also receive traffic and weather information from various entities). The state vector estimates are derived from navigation avionics and are transmitted via a common communications channel, which means that ADS-B is highly dependent on aircraft navigation and communication systems. ADS-B also requires ground stations to receive information from aircraft. As a result of this complex architecture, the ADS-B system is prone to various failure modes.#R##N##R##N#A systematic and comprehensive performance monitoring system is required to ensure the safe use of ADS-B data for air traffic control operations. It is vital that such monitoring systems are in place before a global ADS-B implementation date is mandated by the International Civil Aviation Organization. A number of air navigation service providers and regulators have developed ADS-B performance monitoring methods without a standardized guideline for system specifications. These include Airservices Australia, the U.S. Federal Aviation Administration, EUROCONTROL, the Civil Aviation Authority of Singapore and the Civil Aviation Department of Hong Kong.#R##N##R##N#This paper presents a holistic set of system specifications for ADS-B monitoring systems. In particular, the paper analyzes the ADS-B infrastructure, conducts a systematic review of existing ADS-B monitoring systems, classifies the system characteristics to identify gaps, and derives a set of specifications for developing ADS-B monitoring systems. The paper also assesses the compliance of existing ADS-B monitoring systems against the proposed specifications using a mapping exercise. The system specifications serve as a foundation or minimum requirements for air navigation service providers and original equipment manufacturers to develop systematic and comprehensive ADS-B monitoring systems.	automatic dependent surveillance – broadcast	Busyairah Syd Ali	2016	IJCIP	10.1016/j.ijcip.2016.06.004	simulation;engineering;transport engineering;automatic dependent surveillance-broadcast;computer security	OS	-24.00811697228052	-25.64438340572456	97875
1393142828967c762b0e36b336ccfeb42fe44c6b	cyber-physical system for assisted living and home monitoring		Assisted living and home monitoring systems are gradually becoming a necessity, considering the current trends in population ageing and older adults' desire to continue living independently in their homes and their communities for as long as possible. This paper presents our current achievements regarding the implementation of a cyber-physical system for assisted living and home monitoring, developed as part of a European Union-funded research project. Integrating a wireless network of smart, sensor-equipped hardware nodes for indoor localization and ambient monitoring, as well as both server and client side software components, the system offers basic activity recognition, decision support, supervision and real-time alerting capabilities. While briefly presenting the high-level architecture of our proposed solution, in this paper we focus our attention on the software components of the platform, which are portrayed in more detail. Using data acquired by the smart nodes along with data processing and analysis techniques, the system is able to pinpoint the location of monitored persons within the home, to provide reports about ambient conditions and basic activities of the supervised person and, most importantly, in case of potential danger, send real-time alerts to caregivers, allowing them to act immediately to ensure the safety of monitored persons.	activity recognition;algorithm;autonomous robot;behavioral pattern;client-side;complex system;component-based software engineering;cyber-physical system;decision support system;high-level architecture;machine learning;real-time transcription;sensor;server (computing);smart transducer;smartphone;typical set;user interface	Maria-Iuliana Bocicor;David Cuesta-Frau;Ionut-Catalin Draghici;Nicolae Goga;Arthur-Jozsef Molnar;Raul Valor Perez;Andrei Vasilateanu	2017	2017 13th IEEE International Conference on Intelligent Computer Communication and Processing (ICCP)	10.1109/ICCP.2017.8117052	client-side;computer security;architecture;wireless network;artificial intelligence;computer vision;component-based software engineering;decision support system;computer science;cyber-physical system;activity recognition;software	Robotics	-22.166599099016498	-28.512206990236074	98130
52f1934384283623eb06be9722349b79b2309f15	short range networks of wearables for safer mobility in smart cities		Ensuring safe and efficient mobility is a critical issue for smart city operators. Increasing safety not only reduces the likelihood of road injuries and fatalities, but also reduces traffic congestion and disruptions caused by accidents, increasing efficiency. While new vehicles are increasingly equipped with semi-automation, the added costs will initially limit the penetration rate of these systems. An inexpensive way to replace or augment these systems is to create networks of wearables (smart glasses, watches) that exchange positional and path data at a very fast rate between all users, identify collision risks and feedback collision resolution information to all users in an intuitive way through their smart glasses.	augmented reality;autonomous robot;centralized computing;cloud computing;emergence;hash table;marginal model;network congestion;real-time locating system;semiconductor industry;smart city;smartglasses;smartphone;smartwatch;throughput;wearable computer;wearable technology	Kapil Sharma;Christian G. Claudel	2015	CoRR		simulation;computer security	Mobile	-20.09740744078044	-28.001989981584078	98134
46316ed993317f35535fa25b40b8d6df8f85ffbc	the impact of solar radiation on the quality of buildings: research methods		Daylight analyses presented in this paper are fragments of a wider research project. The daylight simulation study focused on the influence of various facade solutions on lighting environment in office buildings located in the south of Poland. The development of scientific principles lying behind correctly daylit workspaces in offices was the main project's aim. The another, equally crucial purpose was the development of design guidelines for office buildings in the southern Poland. Selected architectural solutions were compared in this study. They included facade solutions (window placements and shapes, glazing-to-wall (GWR) ratios), solar radiation reflectors (light shelves) and deflectors (venetian blinds). Moreover two types of daylight performance met- rics were explored, static and dynamic. The objective of this document is to promote the use of the most advanced and sophisticated computer simulation methods, techniques and tools for sustainable building design regarding quality of daylit indoor environment.		Dariusz Masly;Michal Sitek;Klaudiusz Fross	2015		10.1007/978-3-319-20687-5_31	simulation;architectural engineering;engineering;civil engineering	EDA	-31.527911919747865	-26.509200160875455	98149
c251ab2fd9d672a80da0219ae69b4f58849aab3b	game design through self-play experiments	positive feedback;reinforcement learning;game design;perudo;machine learning;common sense;cumulant;computer games;self play experiments;computer game;artificial neural network	The application of self-play experiments to computer games was pioneered by Thompson in 1982 with his chess machine BELLE. Since then the technique has been widely used in a variety of games to train artificial players employing a range of artificial neural network architectures. Of particular note is the TD-learning Backgammon program of Tesauro developed in 1995. When developing artificial game players that learn by experience, it is generally possible to accelerate the training process through self-play. Compared with training by humans, this confers the advantages of greater speed and a precise control of playing strength through parameter variation. In spite of these potential advantages, the use of self-play experiments is considered by many to be a treacherous road fraught with problems. The value of such experiments is unclear and the threshold of learning that can be achieved through self-play alone is unknown. There is the common-sense perception that only limited playing skill can be achieved through machine self-play, a notion that is challenged here. A new application that is immune from the problems associated with machine learning is the use of self-play experiments to test the integrity and fairness of games and modify the rules accordingly. We will show how the rules of a particular game, Perudo, can be analysed for fairness and how the excessive positive feedback that arises when forces become unbalanced can be curbed. We use the notion of fair in the same sense as in a soccer game - if a team loses a goal, neglecting psychological effects, the chance of losing a second goal is not significantly changed. It is recognised that the cumulative growth in advantage is part of many games and that it is inappropriate to alter the rules in these cases. However the rate at which advantages grow can be moderated by rule alterations. We will also consider the application of the technique to a range of traditional games. In chess, for example, White is considered to have an advantage over Black. The imbalance can be determined for different playing strengths and extrapolated. We will show that the principles can be extended to the more complex situations of computer games and propose that the development of unintelligent agents to explore game play is advantageous.	artificial neural network;automata theory;automaton;belle (chess machine);experiment;extrapolation;fairness measure;fitness function;machine learning;online and offline;pc game;play store;positive feedback;software development;temporal difference learning;the turk;traditional game;unbalanced circuit;video game design	Alasdair Macleod	2005		10.1145/1178477.1178572	non-cooperative game;combinatorial game theory;simulation;simultaneous game;computer science;artificial intelligence;game mechanics;machine learning;metagaming;repeated game;screening game;simulations and games in economics education;sequential game	AI	-25.50553836933123	-25.575715940454078	98420
1f11948b3cd8841959424b871391aa49b7be418a	a practical framework for privacy-preserving data analytics	sampling;data analytics;differential privacy	The availability of an increasing amount of user generated data is transformative to our society. We enjoy the benefits of analyzing big data for public interest, such as disease outbreak detection and traffic control, as well as for commercial interests, such as smart grid and product recommendation. However, the large collection of user generated data contains unique patterns and can be used to re-identify individuals, which has been exemplified by the AOL search log release incident. In this paper, we propose a practical framework for data analytics, while providing differential privacy guarantees to individual data contributors. Our framework generates differentially private aggregates which can be used to perform data mining and recommendation tasks. To alleviate the high perturbation errors introduced by the differential privacy mechanism, we present two methods with different sampling techniques to draw a subset of individual data for analysis. Empirical studies with real-world data sets show that our solutions enable accurate data analytics on a small fraction of the input data, reducing user privacy risk and data storage requirement without compromising the analysis results.	association rule learning;big data;computer data storage;data mining;differential privacy;sampling (signal processing)	Liyue Fan;Hongxia Jin	2015		10.1145/2736277.2741122	sampling;analytics;computer science;data mining;database;data analysis;world wide web;differential privacy	ML	-22.386146770719247	-36.20070079745388	98559
605ffc38a44dfe41365ae9f266db992e6e5070e9	information extraction system using indoor location and activity plan	information extraction;real time;context model;agent based system	In this paper we present an agent based system for extracting live and historic position data on multiple persons in a real environment, using a commercial off the shelves Real Time Location System (RTLS). We present a context model for representing the location data which allows composition of location data with preexisting knowledge on the environment and activities taking place at the locations. We describe our experiences using the RTLS deployed in non-laboratory environment with hundreds of participants.		Bjørn Grønbæk;Pedro Valente;Kasper Hallenborg	2011		10.1007/978-3-642-19875-5_4	real-time computing;simulation;geography;data mining	HCI	-22.54716135564767	-33.073836702532255	98855
cd55933b0d034382f37f6d33d913ffedf93e44ee	efficient large-scale image data set exploration: visual concept network and image summarization	kernel canonical correlation analysis;positive feedback;user study;large scale;visualization technique;greedy algorithm;data exploration	When large-scale online images come into view, it is very important to construct a framework for efficient data exploration. In this paper, we build exploration models based on two considerations: inter-concept visual correlation and intra-concept image summarization. For inter-concept visual correlation, we have developed an automatic algorithm to generate visual concept network which is characterized by the visual correlation between image concept pairs. To incorporate reliable inter-concept correlation contexts, multiple kernels are combined and a kernel canonical correlation analysis algorithm is used to characterize the diverse visual similarity contexts between the image concepts. For intra-concept image summarization, we propose a greedy algorithm to sequentially pick the best representation of the image concept set. The quality score for each candidate summary is computed based on the clustering result, which considers the relevancy, orthogonality and uniformity terms at the same time. Visualization techniques are developed to assist user on assessing the coherence between concept-pairs and investigating the visual properties within the concept. We have conducted experiments and user studies to evaluate both algorithms. We observed very good results and received positive feedback.		Chunlei Yang;Xiaoyi Feng;Jinye Peng;Jianping Fan	2011		10.1007/978-3-642-17829-0_11	computer vision;greedy algorithm;positive feedback;computer science;automatic summarization;machine learning;pattern recognition;data mining	Vision	-27.284355144914414	-34.668058205736	98877
76ad18be0cbd824a6f528643531cad6929cf6243	a uav-based traffic monitoring system - invited paper		Traffic monitoring is important in urban areas. Traffic sensing solutions based on static cameras, however, do not offer a flexible, inexpensive solution for short-term traffic studies. To overcome the limitations of static solutions, we propose an aerial traffic monitoring system. It uses unmanned aerial vehicles (UAV) and onboard cameras to capture traffic video, which is sent and processed in the cloud. To validate the proposed system, we implemented a prototype with a quadcopter, an onboard camera with video and data processing algorithms, and a web application. The video processing module includes a vehicle detection stage based on the Haar cascade model and a frame-by-frame tracking stage. After experimental testing based on videos collected by the UAV, we conclude that the designed system can monitor traffic with high accuracy and flexibility.	aerial photography;algorithm;cloud computing;electrical engineering;haar wavelet;harris affine region detector;laptop;prototype;skipper (former orm designer);television antenna;tier 1 network;ut-vpn;unmanned aerial vehicle;user interface;video processing;web application	Haoran Niu;Nuria González Prelcic;Robert W. Heath	2018	2018 IEEE 87th Vehicular Technology Conference (VTC Spring)	10.1109/VTCSpring.2018.8417546	computer network;web application;computer science;cloud computing;artificial intelligence;computer vision;data processing;onboard camera;video processing;haar-like features;quadcopter	Mobile	-21.693803739505192	-29.581698818059518	99164
3aad53e1ef343045c07eae0b4d9c6e4cec573ecf	pariket: mining business process logs for root cause analysis of anomalous incidents		Process mining consists of extracting knowledge and actionable information from event-logs recorded by Process Aware Information Systems (PAIS). PAIS are vulnerable to system failures, malfunctions, fraudulent and undesirable executions resulting in anomalous trails and traces. The flexibility in PAIS resulting in large number of trace variants and the large volume of event-logs makes it challenging to identify anomalous executions and determining their root causes. We propose a framework and a multi-step process to identify root causes of anomalous traces in business process logs. We first transform the event-log into a sequential dataset and apply Windowbased and Markovian techniques to identify anomalies. We then integrate the basic eventlog data consisting of the Case ID, time-stamp and activity with the contextual data and prepare a dataset consisting of two classes (anomalous and normal). We apply Machine Learning techniques such as decision tree classifiers to extract rules (explaining the root causes) describing anomalous transactions. We use advanced visualization techniques such as parallel plots to present the data in a format making it easy for a process analyst to identify the characteristics of anomalous executions. We conduct a triangulation study to gather multiple evidences to validate the effectiveness and accuracy of our approach. I dedicate my MTech Thesis to my father-in-law Surinder Gupta who is not here to live this day. He encouraged and supported me to pursue MTech after marriage. I miss him.	anomaly detection;basic stamp;business process;data pre-processing;decision tree;experiment;information system;machine learning;parallel coordinates;preprocessor;tracing (software);triangulation (geometry);window function	Nisha Gupta;Kritika Anand;Ashish Sureka	2015		10.1007/978-3-319-16313-0_19	data science;data mining	Security	-25.052505935918322	-33.84264866120639	99413
0d36967e764e59405ff598c84e24ef03faf0d356	photo tours	graph theory;computer graphics;internet;travelling salesman problems;user interfaces;geography	This paper describes an effort to automatically create ``tours'' of thousands of the world's landmarks from geo-tagged user-contributed photos on the Internet. These photo tours take you through each site's most popular viewpoints on a tour that maximizes visual quality and traversal efficiency. This planning problem is framed as a form of the Traveling Salesman Problem on a graph with photos as nodes and transition costs on edges and pairs of edges, permitting efficient solution even for large graphs containing thousands of photos. Our approach is highly scalable and is the basis for the Photo Tours feature in Google Maps, which can be viewed at http://maps.google.com/phototours.	graph (discrete mathematics);internet;scalability;travelling salesman problem;tree traversal	Avanish Kushal;Ben Self;Yasutaka Furukawa;David Gallup;Carlos Hernández;Brian Curless;Steven M. Seitz	2012	2012 Second International Conference on 3D Imaging, Modeling, Processing, Visualization & Transmission	10.1109/3DIMPVT.2012.62	simulation;computer science;multimedia;computer graphics (images)	DB	-33.32452283978021	-34.65770505967373	99567
30873e1343290d7da8a5d44fb46d4ef578547050	an interactive multiscale framework for enhancement and visualization of 2d and 3d image data	categories and subject descriptors according to acm ccs i 3 3 computer graphics interaction techniques			Andrew D. Graham;Martin J. Turner;W. Terry Hewitt	2006		10.2312/LocalChapterEvents/TPCG/TPCG06/171-178	computer science;theoretical computer science;multimedia;computer graphics (images)	Visualization	-33.041612011386185	-33.056921028952566	99976
f79742bb4ca1f274782f99c6831c17c2f0fd4ea9	architectural & decorative construction using coloured concrete sample	aesthetic appearance;architectural construction;decorative appearance;aesthetic finish;construction material;architectural appearance architectural construction decorative construction coloured concrete sample construction material india structural strength house construction structural stability aesthetic appearance aesthetic finish decorative appearance;construction industry;architectural appearance;pigments architecture concrete construction industry mechanical strength;concrete pigments building materials minerals earth slabs chemicals paints coatings manufacturing;surface treatment;structural strength;image color analysis;aggregates;pigments;house construction;decorative construction;mechanical strength;architecture;structural stability;india;concrete;coloured concrete sample	Concrete is the most widely used construction material in India. Unlike European and Western countries, India is using concrete for house construction also. Architectural and decorative appearance requires aesthetic finish. In addition, structural stability needs strength. Coloured concrete offers aesthetic appearance and structural strength. Builder's owners, architects and engineers prefer coloured concrete for architectural and decorative appearance. Any chosen look with broad expanses or minute details can be created in coloured concrete. The effects will be unlimited with special forms and /or techniques.	color;column (database);drum memory;radiant ai	Kiran M. Tajne;Nitin U. Thakare	2009	2009 Second International Conference on Emerging Trends in Engineering & Technology	10.1109/ICETET.2009.42	structural engineering;visual arts;architectural engineering;engineering	SE	-32.576580818587615	-25.119194677640063	99977
848479d329f51f6e42ff276001079531237f7260	a knowledge discovery system with support for model selection and visualization	model selection;rule induction;decision tree;stomach cancer;model performance;conceptual clustering;data mining;user s participation;performance metric;visualization;kdd;multiple model;knowledge discovery in database;knowledge discovery	The process of knowledge discovery in databases consists of several steps that are iterative and interactive. In each application, to go through this process the user has to exploit different algorithms and their settings that usually yield multiple models. Model selection, that is, the selection of appropriate models or algorithms to achieve such models, requires meta-knowledge of algorithm/model and model performance metrics. Therefore, model selection is usually a difficult task for the user. We believe that simplifying the process of model selection for the user is crucial to the success of real-life knowledge discovery activities. As opposed to most related work that aims to automate model selection, in our view model selection is a semiautomatic process, requiring an effective collaboration between the user and the discovery system. For such a collaboration, our solution is to give the user the ability to try various alternatives and to compare competing models quantitatively by performance metrics, and qualitatively by effective visualization. This paper presents our research on model selection and visualization in the development of a knowledge discovery system called D2MS. The paper addresses the motivation of model selection in knowledge discovery and related work, gives an overview of D2MS, and describes its solution to model selection and visualization. It then presents the usefulness of D2MS model selection in two case studies of discovering medical knowledge in hospital data—on meningitis and stomach cancer—using three data mining methods of decision trees, conceptual clustering, and rule induction.	algorithm;cluster analysis;conceptual clustering;data mining;database;decision tree;discovery system;iterative method;model selection;online and offline;preprocessor;real life;rule induction;video post-processing;view model	Tu Bao Ho;Trong Dung Nguyen;Hiroshi Shimodaira;Masayuki Kimura	2003	Applied Intelligence	10.1023/A:1023876925609	visualization;computer science;artificial intelligence;data science;machine learning;decision tree;data mining;model selection;conceptual clustering	ML	-28.05172888586148	-30.923232932864074	100028
3c14c6137c7be689cab8c4bdd3429392d6bde252	visualizing the activity of a web-based collaborative platform	information structure;groupware;workplace awareness;tree data structures data visualisation groupware internet;hierarchical data;tree data structures;workplace awareness web based collaborative platform hierarchical data visualization classic vertical tree ellimap treemap view;data visualisation;internet;web based collaborative platform;classic vertical tree;visual features;hierarchical data visualization;data visualization collaborative work employment monitoring prototypes taxonomy technological innovation international collaboration stress context awareness;ellimap treemap view	This paper describes a prototype that offers visualization features for monitoring a Web-based collaborative platform. The data displayed supports workplace awareness by providing an overview of the activities carried out on the platform. The prototype focuses on the information structured as hierarchical data. Three views are included: a classic vertical tree, a treemap view and an original new layout called ellimap. The system has been implemented on a real case in the domain of the support to innovation.	algorithm;hierarchical database model;prototype;tree (data structure);treemapping;web application	Benoît Otjacques;Monique Noirhomme-Fraiture;Xavier Gobert;Pierre Collin;Fernand Feltz	2007	2007 11th International Conference Information Visualization (IV '07)	10.1109/IV.2007.137	computer science;data science;data mining;world wide web	Visualization	-29.94236395398192	-32.20201896017911	100256
4330b207f200266927521c3f426840a5eee29108	human sensors: case-study of open-ended community sensing in developing regions	smart phones;internet;sensors cities and towns smart phones mobile communication communities media google;electronic messaging;data handling;mobile computing;human sensors crowdsensing based system university students contextual data sensing interface sms mobile application emergency neighbourhood issues civic complaint india event processing city development event collection smartphone hardware sensors citizen life style traffic jam automated collection city infrastructure continuous monitoring developing regions open ended community sensing;smart phones data handling electronic messaging internet mobile computing	With the growing number of cities and population, continuous monitoring of city's infrastructure and automated collection of day-to-day events (such as traffic jam) is essential and can help in improving life style of citizens. It is extremely costly and ineffective to install hardware sensors to sense these events in developing regions. Due to advent of smartphones, citizens can play role of sensors and actively participate in collection of the events which can be shared with others for information or can be used in decisions which affects city development. In this paper, we describe an architecture of crowdsensing testbed for capturing and processing events affecting citizens in cities in India. One of the design principle of our testbed is that it encourages users to do an open-ended sensing under five broad categories: Civic complaints, traffic, neighbourhood issues, emergency and others. As part of testbed, we allow events submissions from different submission modes i.e. mobile application, SMSes and web. Our mobile application exploits different sensing interfaces provided by today's smartphones to add contextual data with event reports such as images, audio, fine-grained location etc. Proposed testbed is used by university students across India to report event happening around them. Finally, we describe the data collected and uncover some of challenges and opportunities which may help future designs of crowdsensing based systems.	crowdsensing;jam;mobile app;nonlinear gameplay;population;sensor;smartphone;testbed	Kuldeep Yadav;Dipanjan Chakraborty;Sonia Soubam;Naveen Prathapaneni;Vikrant Nandakumar;Vinayak S. Naik;Nithya Rajamani;L. Venkata Subramaniam;Sameep Mehta;Pradipta De	2013	2013 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops)	10.1109/PerComW.2013.6529523	embedded system;the internet;simulation;human–computer interaction;computer science;operating system;group method of data handling;internet privacy;mobile computing;computer security;computer network	Mobile	-19.827317759195235	-31.304957929993886	100458
a90e8c35416a8c56074c436d6248188b96664526	towards an information-theoretic framework for quantifying wayfinding information in virtual environments		Signage systems are critical for communicating environmental information. Signage that is visible and properly located can assist individuals in making efficient navigation decisions during wayfinding. Drawing upon concepts from information theory, we propose a framework to quantify the wayfinding information available in a virtual environment. Towards this end, we calculate and visualize the uncertainty in the information available to agents for individual signs. In addition, we expand on the influence of new signs on overall information (e.g., joint entropy, conditional entropy, mutual Information). The proposed framework can serve as the backbone for an evaluation tool to help architects during different stages of the design process by analyzing the efficiency of the signage system.	agent-based model;analysis of algorithms;cognition;color;complex systems;conditional entropy;entropy (information theory);information theory;internet backbone;joint entropy;koch snowflake;mutual information;shannon (unit);signage systems;unity;virtual reality	Rohit K. Dubey;Mubbasir Kapadia;Tyler Thrash;Victor R. Schinazi;Christoph Hölscher	2017			artificial intelligence;machine learning;information theory;computer science	ML	-31.213076391836328	-27.59324579240946	100732
d04d35e5599370080c15aa2babca97f8c2220b84	hidden roles of the train driver: a challenge for metro automation	complex system;task analysis;safety;complex systems;human centered automation;automated metro;quality of service;metro train driver work;core task analysis	In the year 2014, the Helsinki Metro is planned to be fully automated. This automation means that the metro trains will be computer-driven and monitored remotely from a stationary control room. To investigate the challenges related to this scenario, we decided to study the ways in which the current train drivers contribute to the metro system. We conducted three separate but interrelated studies, which were based on the Core-Task Analysis method. Our results suggest that there is much more to driving the metro train than meets the eye. The drivers do not only operate the train on track and its doors at stations, but they also contribute to a variety of other important, albeit more hidden, functions in the metro system. For example, the drivers anticipate, observe, interpret, and react to events in the surrounding environment. Furthermore, they are a significant interaction link between different actors of the metro system. Our conclusion is that if the identified critical roles of the drivers are not accounted for, a migration to a fully automated metro system can affect the quality of service and raise safety issues. In addition to automated metros, the results of this research can be applicable to automation implementations also in other domains.	metro (design language)	Hannu Karvonen;Iina E Aaltonen;Mikael Wahlström;Leena Salo;Paula Savioja;Leena Norros	2011	Interacting with Computers	10.1016/j.intcom.2011.04.008	complex systems;simulation;quality of service;human–computer interaction;computer science;task analysis;computer security	EDA	-19.38227682355222	-25.45981060416127	100817
c668e8c9ba92b3c15fc827853ec5966873ba0fae	sketch-line interactions for 3d image visualization and analysis		This paper explores the effectiveness of an interaction model based on user-sketched line segments and curve segments, together known as sketch-lines. Directly sketching line segments on image slices, or curve segments on the surfaces of objects in volume rendered or surface rendered 3D data, is an effective means by which to quickly and simply transfer accurate information, such as position, object surface orientation, and surface region width, from the user to a visualization algorithm. This information can be used for fast, intuitive and precise object-relative image slice positioning and for precise, editable region of interest (ROI) delineation in a volume image. The results from two user studies are presented that analyze the efficiency, intuitiveness and precision of the sketch-line interaction model as well as quantitatively and qualitatively compare aspects of the model to other interaction techniques.	algorithm;cursor (databases);cutaway drawing;graphics processing unit;interaction technique;interpolation;oblique projection;polygon mesh;region of interest;rendering (computer graphics);scientific visualization;seamless3d;sketch;smoothing;spline (mathematics);subdivision surface;usability testing;vtk;volume rendering	Tim McInerney;Y. S. Shih	2012		10.1007/978-3-642-33179-4_65	biological data visualization	Visualization	-32.298632165206364	-35.8227958385374	100875
b66b52e80ac2f5a6741c1d0896307fec089dd1d1	a hyper-heuristic inspired by pearl hunting	conference_paper;book chapter;shellfish;book book chapter;optimization	Pearl hunting is a traditional way of diving to retrieve pearl from pearl oysters or to hunt some other sea creatures. In some areas, hunters need to dive and search seafloor repeatedly at several meters depth for pearl oysters. In a search perspective, pearl hunting consists of repeated diversification (to surface and change target area) and intensification (to dive and find pearl oysters). A Pearl Hunter (PHunter) hyper-heuristic is inspired by the pearl hunting, as shown in Fig. 1. Given a problem domain and some low-level heuristics (LLHs), PHunter can group, test, select and organize LLHs for the domain by imitating a rational diver.	diversification (finance);heuristic (computer science);high- and low-level;hunter;hyper-heuristic;problem domain	Ching-Yuen Chan;Fan Xue;Andrew W. H. Ip;Chi Fai Cheung	2012		10.1007/978-3-642-34413-8_26	mathematical optimization;mathematics	AI	-27.457302979052397	-24.906349813157743	100934
e2fc72a84bb8f1ff85f46a7b14623bbe6996c573	visualization of association rules over relational dbmss	video similarity model;design and development;user interface;video retrieval;association rule mining;input output;video indexing;association rule;data access;video content analysis;visual system	The focus of this paper is the association rule visualization system that we have designed and developed. The rules produced by the mining algorithm are assumed to be stored in tables. The alternatives for visualization include tabular form, interactive two-dimensional, and three-dimensional graphics. By providing sorting and filtering abilities, the rule visualization system proposed in this paper provides a flexible, efficient, and easier way to manage and understand large number of association rules. As a result, this visualization system becomes an essential part of our association rule mining subsystem. We compare our association rule software with Intelligent Miner from IBM in various aspects, such as data accessibility, user interface, input/output, and rule visualization.	accessibility;algorithm;association rule learning;database;graphics;input/output;sorting;table (information);user interface	Sharma Chakravarthy;Hongen Zhang	2003		10.1145/952532.952714	information visualization;association rule learning;computer science;operating system;data mining;database;world wide web	DB	-31.202278345251766	-33.23069155297669	101385
a9f8c240b5a42c16f0115565fc4e2defdb2ba2a3	using gps-enabled cell phones for traffic-flow data collection.	data collection;traffic flow			Bruce Beyeler;David C. Pheanis	2005			computer science;traffic flow;data collection	HCI	-20.081760727017688	-33.04540856032436	101486
7d10021f008734219886675d82032ef54a03e2ec	a focus + context technique for visualizing a document collection	cluster algorithm;document handling;document collection;layout context clustering algorithms semantics algorithm design and analysis text analysis data visualization;semantics;text analysis;visual analytics semantic zoom focus context document collection;layout;data visualisation;semantic zooming;interactive systems data visualisation document handling;data visualization;document collection visualization focus technique context technique nonnumerical data semantic zoom view szv interactive document collection visualization czsaw visual analytics system interactive semantic zooming single integrated visualization large document collection document contents;semantic zoom;clustering algorithms;visual analytics;interactive systems;algorithm design;context;algorithm design and analysis;focus context	Investigative analysts need overviews of large amounts of data, which is a challenge when working with non-numerical data such as document collections. We present Semantic Zoom View (SZV), an interactive document collection visualization implemented as part of the CZSaw visual analytics system. SZV uses a focus + context technique to provide an overview with details on demand through interactive semantic zooming. SZV lets an analyst easily and quickly see the main topics of a document collection while keeping surrounding documents visible for context. Working within a single integrated visualization, an analyst can also quickly find related documents and break a large document collection into smaller meaningful groups. SZV's focus + context technique was compared to an overview + detail version for finding answers within a document collection and results indicated its strength for maintaining visibility of a full overview when document contents are accessed.	archive;focus-plus-context screen;level of measurement;numerical analysis;visual analytics;zooming user interface	Dustin Dunsmuir;Eric Lee;Chris D. Shaw;Maureen C. Stone;Robert F. Woodbury;John Dill	2012	2012 45th Hawaii International Conference on System Sciences	10.1109/HICSS.2012.57	algorithm design;computer science;database;world wide web;information retrieval;data visualization	Visualization	-28.306928939222637	-34.47146012221381	101524
8fdb735be0757e6d5373ca8655e8c5dcb72e0561	user modeling for interactive evolutionary computation applications using fuzzy logic		Interactive evolutionary computation (IEC) is a branch of evolutionary computation where users are involved in the evolution process. In IEC systems the user generally evaluates subjective information of the population in large quantities. One of the problems in the IEC systems is not having friendly interfaces for the evaluation of mass information and this causes the user lose interest. These systems have quickly migrated to the Web by the large number of users that can be found on a voluntary basis. For these applications we can find users with different characteristics, for example, users with different level of knowledge about the application domain, different participation interest or experience in use of Web-Based IEC applications. In this paper we propose a user modeling for IEC to help tailor the user interface depending on the characteristics, preferences, interests, etc. of the user using fuzzy logic.	fuzzy logic;interactive evolutionary computation;user modeling	José C. Romero;Mario García Valdez	2013		10.1007/978-3-642-33021-6_41	fuzzy electronics;discrete mathematics;interactive evolutionary computation;theoretical computer science;machine learning	Robotics	-30.9428491247938	-25.96573733152548	102064
53b653256c0772968712d801d7b77d9d8cec8aae	painting multiple views of complex objects	complex objects;direct manipulation;scientific database;multiple views;programming model;exploratory data analysis	This paper reviews and illustrates a direct manipulation approach to visualization of complex objects called painting multiple views. We describe a programming model for direct manipulation in general and for painting in particular, based on simple constraints between entities in an the underlying scientific database and the components of displays used to examine the data. With this model, the original notion of “brushing scatterplots” is easily extended.	brushing and linking;database;direct manipulation interface;entity;programming model	John Alan McDonald;Werner Stuetzle;Andreas Buja	1990		10.1145/97945.97975	computer vision;computer science;data mining;multimedia;programming paradigm;programming language;exploratory data analysis	DB	-30.328118785913755	-33.38806766147559	102320
599165750ad0b0ded787130e871ee5dd79623985	metroeye: towards fine-grained passenger tracking underground	context sensing;smartphone;crowdsourcing;trip guide	Subway has become the first choice of traveling for people in metropolis due to its efficiency and convenience. Yet passengers have to rely on subway broadcasts to know their locations because popular localization services (e.g. GPS and wireless localization technologies) are often unavailable underground. To this end, we propose MetroEye, a fine-grained passenger tracking service underground. MetroEye leverages smartphone sensors to record ambient contextual features, and infers the state of passengers (including stop, running, and interchange) during a metro trip using a Conditional Random Field (CRF) model. MetroEye further provides arrival alarm services based on individual passenger state, and aggregates crowdsourced interchange durations to guide passengers for intelligent metro trip planning. Experimental results within 6 months across over 14 subway trains in 3 major cities demonstrate that MetroEye outperforms the state-of-the-art.	conditional random field;crowdsourcing;global positioning system;sensor;smartphone	Weixi Gu;Ming Jin;Zimu Zhou;Costas J. Spanos;Lin Zhang	2016		10.1145/2968219.2971437	embedded system;simulation;computer science;computer security;crowdsourcing	Mobile	-19.31651076190192	-31.540637693072206	102769
c2d337e0eb4f6e0107ba1e5ff639bccdb97c3b29	eyes: a novel overtaking assistance system for vehicular networks	rtsp;vehicular network;its;technology and engineering;comunicacion en congreso;video transmission;real implementation;capitulo de libro;live streaming;android application	Developments in the ITS area are received with great expectation by both consumers and industry. Despite their huge potential benefits, ITS solutions suffer from the slow pace of adoption by manufacturers. In this paper we propose EYES, an ITS system that aims at helping drivers in overtaking. The system autonomously creates a network of the devices running EYES, and provides drivers with a video feed from the vehicle located just ahead, thus presenting a better view of any vehicles coming from the opposite direction and the road ahead. This is specially useful when the front view of the driver is blocked by large vehicles, and thus the decision whether to overtake can be taken based on the visuals provided by the application. We have validated EYES, the proposed overtaking assistance system, in both indoor and realistic scenarios involving vehicular network, and preliminary results allow being optimistic about its effectiveness and applicability.	device driver;global positioning system;smartphone;video	Subhadeep Patra;Javier H. Arnanz;Carlos Miguel Tavares Calafate;Juan-Carlos Cano;Pietro Manzoni	2015		10.1007/978-3-319-19662-6_26	embedded system;real time streaming protocol;simulation;telecommunications;computer science;computer security	Mobile	-20.409347393534926	-29.34747333620837	102926
1c9519d09cfe4d666e98401186e17685ee7e1940	scalable performance of fcbo algorithm on museum data		Formal Concept Analysis – known as a technique for data analysis and visualisation – can also be applied as a means of creating interaction approaches that allow for knowledge discovery within collections of content. These interaction approaches rely on performant algorithms that can generate conceptual neighbourhoods based on a single formal concept, or incrementally compute and update a set of formal concepts given changes to a formal context. Using case studies based on content from museum collections, this paper describes the scalability limitations of existing interaction approaches and presents an implementation and evaluation of the FCbO update algorithm as a means of updating formal concepts from large and dynamically changing museum datasets.	algorithm;complete (complexity);computation;formal concept analysis;scalability	Tim Wray;Jan Outrata;Peter W. Eklund	2016			computer science;data mining;scalability;theoretical computer science;multimedia	AI	-31.559542046508884	-31.032385202055178	103090
565fbbd12cb1b007870054829affd7199e614d5e	analyzing vessel behavior using process mining	esi embedded systems innovation;defence;ts technical sciences;mining techniques;situational awareness;safety and security;suspicious behavior;defence safety and security;communication information;maritime environments;automatic identification systems ais	In the maritime domain, electronic sensors such as AIS receivers and radars collect large amounts of data about the vessels in a certain geographical area. We investigate the use of process mining techniques for analyzing the behavior of the vessels based on these data. In the context of maritime safety and security, the goal is to support operators in identifying suspicious behavior that may indicate accidents or undesired activities such as smuggling and piracy. Our approach consists of two phases. In the first phase, process mining is used offline to extract from historical data a reference model of the normal vessel behavior, which can be adapted by experienced operators and domain experts. In the second phase, process mining is used online to verify whether the current vessel behavior is compliant with the reference model, thus allowing for the identification of suspicious behavior.		Fabrizio Maria Maggi;Arjan J. Mooij;Wil M. P. van der Aalst	2013		10.1007/978-1-4614-6230-9_9	simulation;engineering;data mining;computer security	Robotics	-22.238882841385	-27.6868200582552	103176
e533d8aa1b879b33675a3af445cfee21033fb22c	mining online social networks with python to study urban mobility		On-line social networks have grown quickly over the last few years and nowadays many people use them frequently. Furthermore the emergence of smartphones allows to access these networks any time from any physical location. Among the social networks, Twitter offers a particularly large set of data publicly available. Here we discuss the procedure to mine this data and store it in distributed databases using Python scripts. We also illustrate how geolocated tweets can be used to study the mobility of people in urban areas.	distributed database;emergence;python;smartphone;social network	Antònia Tugores;Pere Colet	2014	CoRR		computer science	HCI	-20.99411943519494	-36.02698946843297	103198
44c8844cf63be1cfb977796cc49912b64d21c32b	estimation of vehicular connectivity in autonomous parking scenarios		In this paper different parking scenarios for autonomous vehicles are considered. For control andmonitoring purposes reliable Wi-Fi-based communication between the vehicles and a back-end is needed. It must be ensured that potential QoS requirements of different applications are met and that vehicles do not hit so-called “white spots” without any network connectivity. The network properties are represented and estimated by a Connectivity Map. For this purpose, network and measurement data are continuously collected so that other vehicles can be provided with the newly gained knowledge, which allows the planning of the proposed scenarios. This paper shows potential QoS requirements and discusses the necessary steps for the realization of such a Connectivity Map. In addition to the automated continuous collection of relevant network parameters as a byproduct of vehicular communications, the mapping of the scenarios in terms of floor plans with additional meta-information as well as the representation of connectivity properties are shown. We outline our vision for using the developed Connectivity Map for advanced parkingmanagement decisions. *Tobias Pögel: E-Mail: poegel@ibr.cs.tu-bs.de Julian Timpner: E-Mail: timpner@ibr.cs.tu-bs.de Stephan Rottmann: E-Mail: rottmann@ibr.cs.tu-bs.de LarsWolf: E-Mail: wolf@ibr.cs.tu-bs.de	autonomous car;autonomous robot;decision support system;heat map;quality of service;requirement	Tobias Pögel;Julian Timpner;Stephan Rottmann;Lars C. Wolf	2013	Praxis der Informationsverarbeitung und Kommunikation	10.1515/pik-2013-0026	parking guidance and information	Robotics	-21.26452335221558	-26.938977094492977	103236
8cffb0d6a5504da37422e48b9c4f569f52138cb8	protect yourself from rfid: fend off frightening tracking tech.	radiofrequency identification antennas object tracking;microchips;object tracking radiofrequency identification microchip antenna social security number fm radio station rfid radio wave tag;taggging;consumer protection;consumer behavior;radiofrequency identification;privacy;tracking;radiofrequency identification privacy tracking rfid tags consumer behavior microchips consumer protection	Acreepy new spying technology called radio-frequency identification (RFID) is starting to show up on products you buy at stores like Walmart, and it could be used to track your every move. RFID uses tiny microchips hooked up to miniature antennas to track items from a distance. This chip and antenna combination is called an RFID tag. Each tag contains an ID number that uniquely identifies the item to which it is attached. It is like a Social Security number for things. RFID tags are tracked by RFID reading devices. These readers gather information from the tags via radio waves, similar to the radio waves that allow you to listen to your favorite FM radio station. RFID radio waves, like FM radio waves, travel invisibly through solid objects such as purses, backpacks, wallets, and shopping bags.	integrated circuit;radio broadcasting;radio frequency;radio wave;radio-frequency identification;social security	Katherine Albrecht;Liz McIntyre	2015	IEEE Consumer Electronics Magazine	10.1109/MCE.2015.2393008	radio-frequency identification;telecommunications;computer science;tracking;privacy;computer security;consumer behaviour	Mobile	-31.217682454470467	-27.070856144275496	103714
a9c142205666420420d6a034dbeaa42b314da0dc	analysis of multibeam sonar data using dissimilarity representations		This paper considers the problem of low-dimensional visualisation of very high dimensional information sources for the purpose of situation awareness in the maritime environment. In response to the requirement for human decision support aids to reduce information overload (and specifically, data amenable to inter-point relative similarity measures) appropriate to the below-water maritime domain, we are investigating a preliminary prototype topographic visualisation model. The focus of the current paper is on the mathematical problem of exploiting a relative dissimilarity representation of signals in a visual informatics mapping model, driven by real-world sonar systems. An independent source model is used to analyse the sonar beams from which a simple probabilistic input model to represent uncertainty is mapped to a latent visualisation space where data uncertainty can be accommodated. The use of euclidean and non-euclidean measures are used and the motivation for future use of non-euclidean measures is made. Concepts are illustrated using a simulated 64 beam weak SNR dataset with realistic sonar targets.	decision support system;informatics;information overload;open-source software;point cloud;prototype;sonar (symantec);signal-to-noise ratio;topography	Iain Rice;Roger Benton;Les Hart;David Lowe	2014	CoRR		computer vision;artificial intelligence;machine learning;data mining;statistics	Robotics	-23.08551203928873	-31.6635560103894	103840
0d26cd0ca1904345804931d11f85afe9c5ff9e69	the design and implementation of real-time systems in urban and suburban transportation	real time systems		real-time transcription	Robert L Faure	1971			simulation;engineering	Embedded	-20.929795583649597	-24.850389370962958	104072
cbd4fef1e0656f54c7e6fbcc441715deea2b90a6	vision based front and rear vehicle collision warning system	dedicated short range communications dsrc;collision warning;time to contact ttc;optical flow;appearance based	In the current driving environment, the top priority is the safety of person. There are two methods proposed to solve safety problems. One is active sensors method and another is passive sensor method. Though with high accuracy, active sensors method has many disadvantages such as high cost, failure to adapt to complex change of environments, and problems relating to laws. Thus there is no way to popularize it. In contrast, passive sensor method is more suitable to current assist systems in virtue of low cost, ability to acquire lots of information. In this paper, the passive sensor method is applied to front and rear vision-based collision warning application. Meanwhile, time-to-contact is used to collision judgment analysis and dedicated short range communications is used to give alert information to near vehicle.	image sensor	SenMa;Shi-Huang Chen;Chun-Sheng Yang;Shu-Chuan Chu;Jeng-Shyang Pan	2015	2015 Third International Conference on Robot, Vision and Signal Processing (RVSP)	10.1109/RVSP.2015.14	simulation;telecommunications;engineering;computer security	Robotics	-20.116568048701197	-28.096150704519594	104100
1e2669037c74d071b98e96dd7f03b423b5b4918d	topological data analysis and applications		Topological data analysis is interested in problems relating to nonlinear systems, large scale data and development of more accurate models, that contribute to a high level research. In the study of time-series data we can identify problems that focus aspects of that nature, with applications to digital disease detection, gene expression, viral evolution, etc. In particular, it describes the qualitative aspects of the data, focusing the topological features with longest lifetimes. To encode the latter, it uses novel mathematical methods that can provide diagrams which are a clear and practical tool that allow us the detection of outliers and to capture the dynamics of the system. In this paper we review this methodology and discuss several applications that can lead to new perspectives to modelling and simulation in system behaviour.	diagram;encode;high-level programming language;mathematical model;nonlinear system;simulation;time series;topological data analysis	João Pita Costa	2017	2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)	10.23919/MIPRO.2017.7973488	time series;topological data analysis;feature extraction;nonlinear system;computer science;machine learning;artificial intelligence	HPC	-22.345845148746886	-35.06176052368257	104146
49bcfc25d66de94418836d0cd16ff43230bba498	tests of smartphone localization accuracy using w3c api and cell-id	smart phones;internet;statistical analysis;global positioning system;application program interfaces	Location based services (LBS) are considered very relevant for the users of mobile networks. All local events and facts related to area nearby seem to be more important that others which happen in remote places. Localization data is used in all types of services: weather, traffic, tourist info, etc. One of its most important (and regulated by law) applications is providing persons location in case of emergency. This paper presents results of field tests related to assessment of accuracy of two most commonly used localization methods: Cell-Id and W3C Geolocalization. The tests were conducted in the form of test drives along some of the most important roads in Poland. Position of the test vehicle obtained using analyzed methods was logged and compared to localization obtained from the Global Positioning System (GPS). Data collected during test drives was processed and statistical information about localization accuracy was calculated. Results obtained for different methods were compared and conclusions about localization quality are provided. The paper also describes test environment and data model which were used during work being reported.	algorithm;android;application programming interface;black box;data model;deployment environment;global positioning system;internationalization and localization;location-based service;smartphone;w3c geolocation api	Grzegorz Sabak	2013	2013 Federated Conference on Computer Science and Information Systems		the internet;simulation;global positioning system;data mining;law;computer security;statistics	HCI	-19.249694987574546	-30.69884603871453	104824
0b53d23584071656e88ca2943ed61857c20a26d0	irregularity in multi-dimensional space-filling curves with applications in multimedia databases	music databases;linear order;music feature extraction;multi dimensional;content based music data retrieval;space filling curve;multimedia database;mp3 databases;mp3 indexing	A space-filling curve is a way of mapping the multi-dimensional space into the one-dimensional space. It acts like a thread that passes through every cell element (or pixel) in the N-dimensional space so that every cell is visited at least once. Thus, a space-filling curve imposes a linear order of the cells in the N-dimensional space. There are numerous kinds of space-filling curves. The difference between such curves is in their way of mapping to the one-dimensional space. Selecting the appropriate curve for any application requires a brief knowledge of the mapping scheme provided by each space-filling curve. Irregularity is proposed as a quantitative measure of the quality of the mapping of the space-filling curve. Closed formulas are developed to compute the irregularity for any general dimension D with N points in each dimension for different space-filling curves.A comparative study of different space-filling curves with respect to irregularity is conducted and results are presented and discussed. The applicability of this research is the area of multimedia databases is illustrated with a discussion of the problems that arise.	database;pixel;space-filling curve	Mohamed F. Mokbel;Walid G. Aref	2001		10.1145/502585.502671	theoretical computer science;machine learning;data mining;database;total order	Graphics	-24.540286022430053	-29.343234022915752	105294
ef31a546a1b766853fcbfb3fd3dc78562aa4bda6	document clustering and visualization with latent dirichlet allocation and self-organizing maps	document clustering;latent dirichlet allocation;self organizing maps som;self organized map;latent dirichlet allocation lda	Clustering and visualization of large text document collections aids in browsing, navigation, and information retrieval. We present a document clustering and visualization method based on Latent Dirichlet Allocation and self-organizing maps (LDA-SOM). LDA-SOM clusters documents based on topical content and renders clusters in an intuitive twodimensional format. Document topics are inferred using a probabilistic topic model. Then, due to the topology preserving properties of self-organizing maps, document clusters with similar topic distributions are placed near one another in the visualization. This provides the user an intuitive means of browsing from one cluster to another based on topics held in common. The effectiveness of LDA-SOM is evaluated on the 20 Newsgroups and NIPS data sets.	archive;cluster analysis;euclidean distance;information retrieval;k-means clustering;kullback–leibler divergence;latent dirichlet allocation;linear discriminant analysis;nips;organizing (structure);rendering (computer graphics);self-organization;self-organizing map;topic model	Jeremy R. Millar;Gilbert L. Peterson;Michael J. Mendenhall	2009			latent dirichlet allocation;dynamic topic model;document clustering;computer science;machine learning;pattern recognition;data mining;information retrieval;hierarchical dirichlet process	Web+IR	-30.40795025873496	-34.245707165360415	105657
49289c90923516aaa8bb84fdf2ad196b4e7b3271	identification of decision rules in a human-controlled system: vehicles at a traffic intersection	human information processing;remote control;intersections;automobiles;road traffic;kinematics;human factors;emergency medical technician;law enforcement;identification;robots;secure system;algorithms;traffic engineering computing;vehicles humans testing decision making kinematics prediction algorithms game theory robot vision systems traffic control automotive engineering;traffic engineering computing identification decision making road traffic automobiles robot kinematics;strategic game;data set decision rules identification human controlled system caltech multivehicle lab traffic intersection decision making human behavior cars robot kinematics;autonomous robot;decision rule;robot kinematics	The rules that govern decision making in systems controlled by humans are often simple to describe. However, deriving these rules from the actions of a group can be very difficult, making human behavior hard to predict. We develop an algorithm to determine the rules implemented by drivers at a traffic intersection by observing the trajectories of their cars. We apply such algorithm to a traffic intersection scenario reproduced in the Caltech multi-vehicle lab, with human subjects remotely driving kinematic robots. The results obtained on these data suggest that this kind of human behavior is to some extent predictable on our data set, and different subjects implement similar rules.	algorithm;curse of dimensionality;device driver;experiment;online and offline;robot	Claire Walton;Domitilla Del Vecchio;Richard M. Murray	2004	IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004	10.1109/ROBOT.2004.1307983	identification;robot;control engineering;kinematics;simulation;computer science;engineering;artificial intelligence;human factors and ergonomics;decision rule;transport engineering;robot kinematics;remote control	Robotics	-20.00741103111024	-25.49923791038398	105917
8713df6ea0570d3ee6c3d6c66f8212bb9d5eee88	fast algorithms for online construction of web tag clouds		Abstract In this paper tag cloud construction for web exposition is studied. Construction of a tag cloud must simultaneously solve at least three interdisciplinary engineering problems: modeling and controlling graphics aesthetics, solving discrete two-dimensional layout optimization problem, and all these must be done on computationally constrained browser platform. We analyze the design choices in the earlier tag cloud studies and provide a taxonomy of algorithmic approaches to tag cloud building. Then, the design requirements for tag clouds on websites are defined. We propose to quantify tag cloud aesthetics by use of a novel objective function based on the rules of typography. Tag cloud construction is formalized as a combinatorial optimization problem with an irregular objective function. A set of algorithms is proposed and evaluated on a collection of tag sets from popular web pages. The methods that meet constraints of the browser platform are chosen.	algorithm;tag cloud	Jakub Marszalkowski;Dariusz Mokwa;Maciej Drozdowski;Lukasz Rusiecki;Hubert Narozny	2017	Eng. Appl. of AI	10.1016/j.engappai.2017.06.023	data visualization;web page;graphics;tag cloud;metaheuristic;computer science;combinatorial optimization;algorithm;optimization problem;web engineering	AI	-30.233604581769075	-35.500725105134556	106155
9c6ca9fcca472d652c399e4486628d972906a64b	building a visual database for example-based graphics generation	performance evaluation;computer graphics;information visualization;data visualisation;learning by example;engines;learning from examples;displays;spatial databases;visual database;data visualization;performance analysis;visual databases computer graphics data visualization spatial databases computer science engines buildings performance evaluation performance analysis displays;example based graphics generation;computer science;feature based scheme;feature based scheme visual database example based graphics generation information visualizations learning from examples;buildings;information visualizations;visual databases;learning by example data visualisation visual databases	Example-based graphics generation systems automatically create new information visualizations by learning from existing graphic examples. As part of the effort on developing a general-purpose example-based generation system, we are building a visual database of graphic examples. In this paper, we address two main issues involved in constructing such a database: example selection and example modeling. As a result, our work offers three unique contributions: First, we build a visual database that contains a diverse collection of well-designed examples. Second, we develop a feature-based scheme to model all examples uniformly and accurately. Third, our visual database brings several important implications to the area of information visualization.	graphics	Michelle X. Zhou;Min Chen;Ying Feng	2002		10.1109/INFVIS.2002.1173143	computer vision;computer science;data science;data mining;computer graphics;information retrieval;data visualization;database design;statistics	Vision	-31.03645539508236	-32.639512558933895	106471
ec5b8f9496470ae21a91d12f29cca8dd69310004	computing in astronomy: applications and examples	software libraries astronomy computing astronomical visualization event classification big data;software;programming environments;data visualization nasa data processing scientific computing astronomy motion pictures computer applications astrophysics;motion pictures;data triage;data processing;gpu;machine;fast transients;software libraries astronomy computing big data data visualisation pattern classification;software engineering;big data computer applications physical sciences and engineering astronomy internet applications libraries information repositories publishing visualization astrophysics gpu astronomy data triage machine learning data movement data archiving visualization radio astronomy v fastr fast transients data processing machine emerging technologies computer systems organization graphical environments programming environments software engineering;computer applications;data movement;visualization;machine learning;big data;physical sciences and engineering;internet applications;data visualization;emerging technologies;libraries information repositories publishing;radio astronomy;propulsion;astrophysics;astronomy;nasa;graphical environments;data archiving;computer systems organization;v fastr	Computing in astronomy has a wide variety of applications,. We grouped a series of sidebars to provide pointers to ongoing work as well to give illustrative examples on astronomical visualization, event classification, Big Data, and software libraries.	big data;library (computing)	F. Alexander Bogert;Nicholas Smith;John Holdener;Eric M. De Jong;Andrew F. Hart;Luca Cinquini;Shakeh E. Khudikyan;David R. Thompson;Chris Mattmann;Kiri Wagstaff;Joseph Lazio;Dayton L. Jones;Alice E A Allen;Lior Shamir;Peter J. Teuben	2014	Computer	10.1109/MC.2014.243	machine;radio astronomy;propulsion;big data;visualization;data processing;computer science;artificial intelligence;data science;operating system;software engineering;computer applications;emerging technologies;data visualization;computer graphics (images)	Visualization	-32.55143007852331	-29.637518349455995	106584
ad702a9d4eb462c368517f091fd0a98cc7e98553	generative art images by complex functions based genetic algorithm		This paper presents a novel computer supported design system which uses computational approach to producing 3D images for stimulating creativity of designers. It put forward generic algorithm based on a binary tree to generate 3D images. This approach is illustrated by an artwork design example, which uses general complex function expressions to form 3D images of artistic flowers. It shows that approach is able to generate some innovative solutions and demonstrates the power of computational approach.	agent architecture;binary tree;computation;fractal;generic programming;genetic algorithm;knowledge-based systems;multi-agent system;solid modeling	Hong Liu;Xiyu Liu	2007		10.1007/978-0-387-75456-7_13	computer vision;computer science;artificial intelligence;machine learning;generative design	AI	-28.31621112158304	-24.661054990533792	106655
61143c27f2683ee1dad5d63d5d4926713e168971	exploring representation in evolutionary level design		Automatic content generation is the production of content for games, web pages, or other purposes by procedural means. Search-based automatic content generation employs search-based algorithms to accomplish automatic content generation. This book presents a number of different techniques for search-based automatic content generation where the search algorithm is an evolutionary algorithm. The chapters treat puzzle design, the creation of small maps or mazes, the use of L-systems and a generalization of L-system to create terrain maps, the use of cellular automata to create maps, and, finally, the decomposition of the design problem for large, complex maps culminating in the creation of a map for a fantasy game module with designersupplied content and tactical features. The evolutionary algorithms used for the different types of content are generic and similar, with the exception of the novel sparse initialization technique are presented in Chapter 2. The points where the content generation systems vary are in the design of their fitness functions and in the way the space of objects being searched is represented. A large variety of different fitness functions are designed and explained, and similarly radically different representations are applied to the design of digital objects all of which are, essentially, maps for use in games.	automata theory;cellular automaton;evolutionary algorithm;fitness function;l-system;level design;map;search algorithm;sparse matrix;web page	Daniel A. Ashlock	2018		10.2200/S00840ED1V01Y201803GCI003	terrain;evolutionary computation;web page;theoretical computer science;cellular automaton;evolutionary algorithm;initialization;search algorithm;level design;computer science	HCI	-27.483727411903953	-24.965096932443736	106680
c2ccd7162edff43bcf2ed4d09153bc95f9bdbd74	gaussian cubes: real-time modeling for visual exploration of large multidimensional datasets	analytical models;manuals;data models data visualization computational modeling analytical models visualization principal component analysis manuals;interactive visualization;data modeling;visualization;computational modeling;dimensionality reduction;principal component analysis;data cubes data modeling dimensionality reduction interactive visualization;data visualization;data cubes;data models	Recently proposed techniques have finally made it possible for analysts to interactively explore very large datasets in real time. However powerful, the class of analyses these systems enable is somewhat limited: specifically, one can only quickly obtain plots such as histograms and heatmaps. In this paper, we contribute Gaussian Cubes, which significantly improves on state-of-the-art systems by providing interactive modeling capabilities, which include but are not limited to linear least squares and principal components analysis (PCA). The fundamental insight in Gaussian Cubes is that instead of precomputing counts of many data subsets (as state-of-the-art systems do), Gaussian Cubes precomputes the best multivariate Gaussian for the respective data subsets. As an example, Gaussian Cubes can fit hundreds of models over millions of data points in well under a second, enabling novel types of visual exploration of such large datasets. We present three case studies that highlight the visualization and analysis capabilities in Gaussian Cubes, using earthquake safety simulations, astronomical catalogs, and transportation statistics. The dataset sizes range around one hundred million elements and 5 to 10 dimensions. We present extensive performance results, a discussion of the limitations in Gaussian Cubes, and future research directions.		Zhe Wang;Nivan Ferreira;Youhao Wei;Aarthy Sankari Bhaskar;Carlos Eduardo Scheidegger	2017	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2016.2598694	data modeling;interactive visualization;computer science;data science;machine learning;data mining;data visualization	Visualization	-25.805717182458878	-34.99616729393379	107205
e06027360a99f52d78b7aade524bcd548238f257	observing social web for smog disaster forecasting	forecasting;social web;weibo;smog disaster	Smog disasters are greatly affected by social activities such as driving. In this poster, we observe social web to enhance smog disaster forecasting. Different kinds of social indicators are measured from social web data with a social web data processing framework, and then evaluated for smog disaster forecasting with two experiments.	driving simulator;experiment;social media	Yalin Zhou;Jiaoyan Chen;Huajun Chen	2015		10.1145/2786451.2786454	meteorology;environmental science;advertising;computer security	ML	-20.303940575547387	-33.75524468512212	107362
22c0c4b25f7648f44671402b3f2ede872734bc44	interactive visualization for information analysis in medical diagnosis	research outputs;research publications;visualization;visual analytics;medical diagnosis	This paper investigates to what extend the findings and solutions of information analysis in intelligence analysis can be applied and transferred into the medical diagnosis domains. Interactive visualization is proposed to address some of the problems faced by both domain. Its design issues related to selected common problems are then discussed in details. Finally, a visual sense making system INVISQUE is used as an example to illustrate how the interactive visualization can be used to support information analysis and medical diagnosis.	interactive visualization;visual analytics	B. L. William Wong;Kai Xu;Andreas Holzinger	2011		10.1007/978-3-642-25364-5_11	visual analytics;information visualization;visualization;human–computer interaction;interactive visual analysis;computer science;data science;multimedia	HCI	-28.08311364672226	-31.290877660630112	107605
3c27f664730e736d4e8fe3cc4b57f56730e6b3fc	managing interaction between users and agents in a multi-agent storytelling environment	embodied agents;interactive narrative;sense of coherence;narrative structure;planning;virtual environment;computer games;computer game;embodied agent;virtual worlds	This paper describes an approach for managing the interaction of human users with computer-controlled agents in an interactive narrative-oriented virtual environment. In these kinds of systems, the freedom of the user to perform whatever action she desires must be balanced with the preservation of the storyline used to control the system's characters. We describe a technique, narrative mediation, that exploits a plan-based model of narrative structure to manage and respond to users' actions inside a virtual world. We define two general classes of response to situations where users execute actions that interfere with story structure: accommodation and intervention. Finally, we specify an architecture that uses these definitions to monitor and automatically characterize user actions, and to compute and implement responses to unanticipated activity. The approach effectively integrates user action and system response into the unfolding narrative, providing for the balance between a user's sense of control within the story world and the user's sense of coherence of the overall narrative.	multi-agent system;unfolding (dsp implementation);virtual reality;virtual world	Mark O. Riedl;C. J. Saretto;Robert Michael Young	2003		10.1145/860575.860694	planning;simulation;embodied agent;computer science;virtual machine;artificial intelligence;multimedia;narrative structure	AI	-31.757192036675704	-24.549468742742413	107880
0fac6da94b713b140221c5f12659fa54c23855c8	human mobility in advanced and developing economies: a comparative analysis		The deployment of ubiquitous computing technologies in the real-world has enabled the capture of large-scale quantitative data related to human behavior, including geographical information. This type of data creates an opportunity to characterize human mobility, with potential applications ranging from modeling the spread of viruses to transportation planning. This paper presents an initial study focused on understanding the similarities and differences in mobility patterns across countries with different economic levels. In particular, we analyze and compare human mobility in a developing and an advanced economy 1 by means of their cell phone traces. We characterize mobility in terms of (1) average distance traveled, (2) area of influence of each individual, and (3) geographic sparsity of the social network. Our results indicate that there are statistically significant differences in human mobility across countries with different economic levels. Specifically, individuals in the developing economy show smaller mobility and smaller geographical sparsity of their social network when compared to individuals in the advanced	mobile phone;social network;software deployment;sparse matrix;tracing (software);ubiquitous computing	Alberto Rubio;Vanessa Frías-Martínez;Enrique Frías-Martínez;Nuria Oliver	2010			simulation;operations research	HCI	-19.420397035360306	-34.5591538338857	107939
04929b630d69e317c829e92fa559fedbe7e2a0d8	tracking human queues using single-point signal monitoring	wifi;human queue monitoring;smartphones;received signal strength	We investigate using smartphone WiFi signals to track human queues, which are common in many business areas such as retail stores, airports, and theme parks. Real-time monitoring of such queues would enable a wealth of new applications, such as bottleneck analysis, shift assignments, and dynamic workflow scheduling. We take a minimum infrastructure approach and thus utilize a single monitor placed close to the service area along with transmitting phones. Our strategy extracts unique features embedded in signal traces to infer the critical time points when a person reaches the head of the queue and finishes service, and from these inferences we derive a person's waiting and service times. We develop two approaches in our system, one is directly feature-driven and the second uses a simple Bayesian network. Extensive experiments conducted both in the laboratory as well as in two public facilities demonstrate that our system is robust to real-world environments. We show that in spite of noisy signal readings, our methods can measure service and waiting times to within a $10$ second resolution.	bayesian network;cns;data recovery;embedded system;experiment;network model;printed circuit board;queueing theory;real-time web;scheduling (computing);smartphone;tracing (software);transmitter	Yan Wang;Jie Yang;Yingying Chen;Hongbo Liu;Marco Gruteser;Richard P. Martin	2014		10.1145/2594368.2594382	embedded system;wi-fi;real-time computing;simulation;computer science;operating system;queue management system	Mobile	-19.748679265855653	-31.24441649648678	107969
589a927d50be4400214af1ed64d6b8c9677095af	pedestrian walking safety system based on smartphone built-in sensors		People watching smartphones while walking causes a significant impact to their safety. Pedestrians staring at smartphone screens while walking along the sidewalk are generally more at risk than other pedestrians not engaged in smartphone usage. In this paper, we propose Safe Walking, an Android smartphone-based system that detects the walking behavior of pedestrians by leveraging the sensors and front camera on smartphones, improving the safety of pedestrians staring at smartphone screens. More specifically, Safe Walking first exploits a pedestrian speed calculation algorithm by sampling acceleration data via the accelerometer and calculating gravity components via the gravity sensor. Then, this system utilizes a grayscale image detection algorithm to detect the face and eye movement modes based on OpenCV4Android to determine if pedestrians are staring at the screens. Finally, Safe Walking generates a vibration by a vibrator on smartphones to alert pedestrians to pay attention to road conditions. We implemented Safe Walking on an Android smartphone and evaluated pedestrian walking speed, accuracy of eye movement, and system performance. The results show that Safe Walking can prevent the potential danger for pedestrians staring at smartphone screens with a true positive rate of 91%.	algorithm;android;grayscale;sampling (signal processing);sensitivity and specificity;sensor;smartphone;vibrator (electronic)	Yantao Li;Fengtao Xue;Xinqi Fan;Zehui Qu;Gang Zhou	2018	IET Communications	10.1049/iet-com.2017.0502	computer vision;real-time computing;mathematics;pedestrian;preferred walking speed;accelerometer;android (operating system);staring;artificial intelligence	Mobile	-19.808715599749444	-28.25548061412807	108311
7d0e783e5bb1c35a871a45e72fddaf7bf3db5d28	constraint programming systems for modeling music theories and composition	music theory;building block;computer model;music constraint programming systems;music representation;algorithmic composition;constraint programming;modeling music theories;computer aided composition;article	Constraint programming is well suited for the computational modeling of music theories and composition: its declarative and modular approach shares similarities with the way music theory is traditionally expressed, namely by a set of rules which describe the intended result. Various music theory disciplines have been modeled, including counterpoint, harmony, rhythm, form, and instrumentation. Because modeling music theories “from scratch” is a complex task, generic music constraint programming systems have been proposed that predefine the required building blocks for modeling a range of music theories. After introducing the field and its problems in general, this survey compares these generic systems according to a number of criteria such as the range of music theories these systems support.	computational model;constraint programming;instrumentation (computer programming);theory	Torsten Anders;Eduardo Reck Miranda	2011	ACM Comput. Surv.	10.1145/1978802.1978809	constraint programming;evolutionary music;computer science;artificial intelligence;theoretical computer science;music theory;pop music automation;programming language;algorithm	AI	-26.917865360012712	-26.466332035176016	108561
149440a086795907b0f2c6dbe9dfad56ebbfe906	next generation search interfaces - interactive data exploration and hypothesis formulation	busqueda informacion;sistema interactivo;search engine;ontologie;buscador;lien hypertexte;keyword;hipertexto;information sources;multimedia;information source;source information;enlace hipertexto;information retrieval;e science;semantics;hyperlink;multiplicite;palabra clave;mot cle;semantica;semantique;web search engine;systeme conversationnel;user assistance;hypermedia;biblioteca electronica;hierarchical classification;assistance utilisateur;semantic searches;keyword search;interactive system;recherche information;semantic inferencing;asistencia usuario;multiplicidad;next generation;classification hierarchique;interactive data exploration;ontologia;ontologies;e research;electronic library;moteur recherche;interactive graphics;clasificacion jerarquizada;ontology;multiplicity;hypertexte;hipermedia;hypertext;bibliotheque electronique;fuente informacion	To date, the majority of Web search engines have provided simple keyword search interfaces that present the results as a ranked list of hyperlinks. More recently researchers have been investigating interactive, graphical and multimedia approaches which use ontologies to model the knowledge space. Such systems use the semantic relationships to structure the assimilated search results into interactive semantic graphs or hypermedia presentations which enable the user to quickly and easily explore the results and detect previously unrecognized associations. More recently, the proliferation of eResearch communities has led to a demand for search interfaces which automate the discovery, analysis and assimilation of multiple information sources in order to prove or disprove a particular scientific theory or hypothesis. We believe that such semiautomated analysis, assimilation and hypothesis-driven approaches represent the next generation of search engines. In this paper we describe and evaluate such a search interface which we have developed for a particular eScience application.	data assimilation;e-science;graphical user interface;hyperlink;hypermedia;knowledge space;next-generation network;ontology (information science);search algorithm;semantic web;web search engine	Jane Hunter;Kateryna Falkovych;Suzanne Little	2004		10.1007/978-3-540-30230-8_9	hypertext;web search engine;semantic search;computer science;ontology;artificial intelligence;operating system;machine learning;ontology;data mining;database;semantics;hyperlink;multiplicity;world wide web;information retrieval;algorithm;search engine	Web+IR	-33.61845029831821	-27.979177581791724	108833
a2b60406ea8c34fbaf3cc1e36caba5e6273119ff	the effect of color on expression of joy and sadness in virtual humans	art;evolutionary model;emotion perception;color;behavioural sciences computing;expressed emotion;virtual reality;virtual human;emotion recognition;image expression;sadness;filter parameter;filtering algorithms;image color analysis;image colour analysis;pixel;visual art;virtual reality behavioural sciences computing emotion recognition filtering theory genetic algorithms image colour analysis;genetic algorithm;genetic algorithms;humans;lighting;sadness color image expression emotion perception virtual human visual arts evolutionary model genetic algorithm filter parameter joy;visual arts;humans filters art genetic algorithms marine technology cultural differences mood layout physics painting;filtering theory;approaches to learning;joy	For centuries artists have been exploring color to express emotions. Following this insight, the paper describes an approach to learn how to use color to influence the perception of emotions in virtual humans. First, a model of lighting and filters inspired on the visual arts is integrated with a virtual human platform to manipulate color. Next, an evolutionary model, based on genetic algorithms, is created to evolve mappings between emotions and lighting and filter parameters. A first study is, then, conducted where subjects evolve mappings for joy and sadness without being aware of the evolutionary model. In a second study, the features which characterize the mappings are analyzed. Results show that virtual human images of joy tend to be brighter, more saturated and have more colors than images of sadness. The paper discusses the relevance of the results for the fields of expression of emotions and virtual humans.	color;genetic algorithm;humans;models of dna evolution;relevance;sadness;virtual actor	Celso de Melo;Jonathan Gratch	2009	2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops	10.1109/ACII.2009.5349585	psychology;computer vision;genetic algorithm;computer science;artificial intelligence;machine learning;virtual reality;multimedia	Robotics	-28.278451918053452	-25.875167660691222	109039
86c0773d8cca2556c539af6509d070180bd9cc31	ontology visualization for domain experts: a new solution	hierarchical connected circle;gestalt principles;gestalt principles ontology visualization hierarchical connected circle aesthetics;node link diagram domain experts ontology visualization knowledge representation ontology understanding ontology exploration multiple view visualization tool hierarchical connected circle indented tree;tree data structures;ontology visualization;ontologies artificial intelligence;tree data structures data visualisation humanities ontologies artificial intelligence;data visualisation;aesthetics;humanities;ontologies data visualization visualization educational institutions color organizations	In the last few years ontologies have emerged in many fields as efficient knowledge representation. Some of the visualization tools that should ease ontology understanding and exploration, are sometimes too complex to be used by domain experts, or are too simple and do not support all necessary user tasks. We present a multiple view visualization tool, which enables users a good hierarchical and relations overview as well as observation from different viewpoints. The tool embeds hierarchical connected circle, indented tree and node-link diagram. Basic and advanced functionalities allow searching, location of interest, exploration and understanding, while well thought design enables intuitive usage.	desktop computer;diagram;gestalt psychology;java;knowledge representation and reasoning;level of detail;mind;ontology (information science);requirement;subject-matter expert;usability;web application	Sasa Kuhar;Vili Podgorelec	2012	2012 16th International Conference on Information Visualisation	10.1109/IV.2012.67	upper ontology;information visualization;computer science;ontology;data science;theoretical computer science;data mining;ontology-based data integration;process ontology	Visualization	-30.053791447198996	-32.09714159703966	109123
dcf382238884c41a03991246c76f70803a464554	dclustere: a framework for evaluating and understanding document clustering using visualization	document clustering;multiple perspectives;document analysis;performance evaluation;user study;information visualization;information organization;visualization;clustering;ground truth;cluster validity;user interaction	Over the last decade, document clustering, as one of the key tasks in information organization and navigation, has been widely studied. Many algorithms have been developed for addressing various challenges in document clustering and for improving clustering performance. However, relatively few research efforts have been reported on evaluating and understanding document clustering results. In this article, we present DClusterE, a comprehensive and effective framework for document clustering evaluation and understanding using information visualization. DClusterE integrates cluster validation with user interactions and offers rich visualization tools for users to examine document clustering results from multiple perspectives. In particular, through informative views including force-directed layout view, matrix view, and cluster view, DClusterE provides not only different aspects of document inter/intra-clustering structures, but also the corresponding relationship between clustering results and the ground truth. Additionally, DClusterE supports general user interactions such as zoom in/out, browsing, and interactive access of the documents at different levels. Two new techniques are proposed to implement DClusterE: (1) A novel multiplicative update algorithm (MUA) for matrix reordering to generate narrow-banded (or clustered) nonzero patterns from documents. Combined with coarse seriation, MUA is able to provide better visualization of the cluster structures. (2) A Mallows-distance-based algorithm for establishing the relationship between the clustering results and the ground truth, which serves as the basis for coloring schemes. Experiments and user studies are conducted to demonstrate the effectiveness and efficiency of DClusterE.	algorithm;cluster analysis;experiment;force-directed graph drawing;graph coloring;ground truth;information visualization;interaction;knowledge organization;usability testing	Yi Zhang;Tao Li	2012	ACM TIST	10.1145/2089094.2089100	information visualization;visualization;document clustering;fuzzy clustering;ground truth;computer science;machine learning;data mining;cluster analysis;brown clustering;world wide web;information retrieval;conceptual clustering	Web+IR	-27.370011913265795	-34.84066578026118	109425
cbe56e3352c80823f295e3ae2b0d1cba427b55dd	visualization, integration and analysis of multi-element geochemical data	earth and related environmental sciences;geovetenskap och miljovetenskap	Geochemical mapping programs carried out by the Geological Survey of Sweden (SGU) have generated large databases containing information on the concentrations of chemical elements in rocks, surface sediments and biogeochemical materials. Regional geochemical data being imprecise, multivariate, spatially auto-correlated and non-normally distributed pose specific problems to the choice of data analysis methods. Commonly several methods are combined, and the choice of techniques depends on the characteristics of data as well as the purpose of study. One critical issue is dealing with extreme data values (or outliers) in the initial stages of analysis. Another common problem is that integrated analysis of several geochemical datasets is not possible without interpolating the point data into surfaces. Finally, separation of anthropogenic influences from natural geochemical background in the surface materials is an issue of great importance for environmental studies. This study describes an approach to address the above-mentioned problems by a flexible combination and use of GIS and multivariate statistical techniques with high-dimensional visualization. Dynamically linked parallel coordinate and scatterplot matrix display techniques allow simultaneous presentation of spatial, multi-element and qualitative information components of geochemical data. The plots not only display data in multi-dimensional space, but also allow detailed inspection of the data with interactive multi-dimensional brushing tools. The results of the study indicate that these simple high-dimensional visualization techniques can successfully complement the traditional statistical and GIS analysis in all steps of data processing, from data description and outlier identification through data integration, analysis, validation, and presentation of results. The outcomes of the study include: a visual procedure towards intelligent data cleaning where potentially significant information in very high element concentrations is preserved, methods for integration and visual analysis of geochemical datasets collected in different grids, estimation of geochemical baseline concentrations of trace metals in till geochemistry of southeastern Sweden, use of multi-element spatial fingerprints to trace natural geochemical patterns in biogeochemistry, and a new graphical approach to present multi-element geochemical data summaries and results from numerical analysis.	approximation;baseline (configuration management);bedrock (framework);biogeochemistry;brushing and linking;cartography;censoring (statistics);cluster analysis;color;data domain;data quality;database;fingerprint;geographic information system;graphical user interface;information systems;interpolation;level of measurement;map;numerical analysis;pc²;parallel coordinates;pet rock;plasma cleaning;pokémon red;principal component analysis;rocks cluster distribution;sampling (signal processing);shading;spatial query;spatial reference system;thin plate spline;type signature;vii	Katrin Grünfeld	2005			mining engineering;geography;hydrology	Visualization	-25.431974051873308	-30.942018752010107	109543
72d80d5f29300c45e43e7f0e91edb32e66b16d4a	interactive maps for visual data exploration	visual data exploration	Descartes (formerly called IRIS) is a software system designed to support visual exploration of spatially referenced data, e.g. demographic, economical, or cultural information about geographical objects or locations such as countries, districts, or cities. Descartes o ers two integrated services: automated presentation of data on maps, and facilities to interactively manipulate these maps. Automated mapping is enabled by incorporating generic knowledge on map design into the system. Descartes selects suitable presentation methods according to characteristics of the variables to be analysed and relationships among those variables Ð if more than one were selected simultaneously. The cartographic knowledge of Descartes allows non-cartographers to receive proper presentations of their data, and the automation of map construction helps the users to save valuable time that can better be used for data analysis and problem-solving. Exploratory data analysis requires highly interactive, dynamic data displays. We strive to develop various interactive techniques for map manipulation that could enhance the expressiveness of maps and thus promote data exploration. We are convinced that a technique can be made especially productive if it is directed towards a particular presentation method: it can utilise peculiarities of this method and support those analytical operations that best ® t to the method.	alan maceachren;cartography;descartes' rule of signs;dynamic data;exploratory testing;integrated services;interactivity;nonlinear system;problem solving;programming paradigm;software system;source data;thematic map	Gennady L. Andrienko;Natalia V. Andrienko	1999	International Journal of Geographical Information Science	10.1080/136588199241247	computer vision;simulation;geography;computer science;machine learning;data mining;database;cartography	HCI	-32.152579027450294	-32.39929119235734	109612
847d95fe7957fd1fee8949baffeb8f011ef9a3e4	acoustic localization of an electronic emergency siren		Having the ability to adequately detect the direction of an approaching emergency siren is critical to the effectiveness of the emergency system. Having this ability allows both pedestrians and drivers of nearby vehicles to more quickly and safely react to an approaching emergency vehicle. This study considers a typical electronic siren system that is currently being used by the Windsor Fire u0026 Rescue Services Department. This siren has two fundamental settings; the standard siren signal and the air horn mode, which is typically used when the emergency vehicle is approaching roadway intersections, as these pose the most danger to occupants of both emergency vehicle and general public. Siren and air horn signals were recorded at specific distances from the driveru0027s position at 45° radial increments. From these, the recorded signals and sound pressure levels measured inside the cabin of the vehicle at the various approach angles was used to prepare a subjective jury evaluation to determine the localization c...	acoustic cryptanalysis	Frank Angione;Colin Novak;Peter D'Angela;Helen Ule	2016	Proc. Meetings on Acoustics	10.1121/2.0000507	simulation;siren (mythology);computer security;emergency vehicle;engineering;sound pressure	HCI	-19.415722124948292	-28.038602106274933	110206
5164cf59501341c118d8fe99847adc178d495d3e	sentio: driver-in-the-loop forward collision warning using multisample reinforcement learning		Thanks to the adoption of more sensors in the automotive industry, context-aware Advanced Driver Assistance Systems (ADAS) become possible. On one side, a common thread in ADAS applications is to focus entirely on the context of the vehicle and its surrounding vehicles leaving the human (driver) context out of consideration. On the other side, and due to the increasing sensing capabilities in mobile phones and wearable technologies, monitoring complex human context becomes feasible which paves the way to develop driver-in-the-loop context-aware ADAS that provide personalized driving experience. In this paper, we propose Sentio1; a Reinforcement Learning based algorithm to enhance the Forward Collision Warning (FCW) system leading to Driver-in-the-Loop FCW system. Since the human driving preference is unknown a priori, varies between different drivers, and moreover, varies across time for the same driver, the proposed Sentio algorithm needs to take into account all these variabilities which are not handled by the standard reinforcement learning algorithms. We verified the proposed algorithm against several human drivers. Our evaluation, across distracted human drivers, shows a significant enhancement in driver experience---compared to standard FCW systems---reflected by an increase in the driver safety by 94.28%, an improvement in the driving experience by 20.97%, a decrease in the false negatives from 55.90% down to 3.26%, while adding less than 130 ms runtime execution overhead.	algorithm;architecture design and assessment system;device driver;machine learning;mobile phone;overhead (computing);personalization;reinforcement learning;sensor;wearable computer	Salma Elmalaki;Ekin Kaya Şimşek;Mani B. Srivastava	2018		10.1145/3274783.3274843	collision;computer science;advanced driver assistance systems;real-time computing;reinforcement learning;wearable technology;automotive industry;autonomous system (internet);thread (computing);human-in-the-loop	Mobile	-20.67412418540362	-29.764904940975388	110263
339c443a90550208e82943ba3bd51ee6e3d84e35	touristic site attractiveness seen through twitter	articulo;complexity;human mobility;geolocated data;tourism;computer appl in social and behavioral sciences;socio and econophysics population and evolutionary models;spatial network	Tourism is becoming a significant contributor to medium and long range travels in an increasingly globalized world. Leisure traveling has an important impact on the local and global economy as well as on the environment. The study of touristic trips is thus raising a considerable interest. In this work, we apply a method to assess the attractiveness of 20 of the most popular touristic sites worldwide using geolocated tweets as a proxy for human mobility. We first rank the touristic sites based on the spatial distribution of the visitors’ place of residence. The Taj Mahal, the Pisa Tower and the Eiffel Tower appear consistently in the top 5 in these rankings. We then pass to a coarser scale and classify the travelers by country of residence. Touristic site’s visiting figures are then studied by country of residence showing that the Eiffel Tower, Times Square and the London Tower welcome the majority of the visitors of each country. Finally, we build a network linking sites whenever a user has been detected in more than one site. This allow us to unveil relations between touristic sites and find which ones are more tightly interconnected.	eiffel	Aleix Bassolas;Maxime Lenormand;Antònia Tugores;Bruno Gonçalves;José J. Ramasco	2016	EPJ Data Science	10.1140/epjds/s13688-016-0073-5	complexity;simulation;spatial network;mathematics;tourism;algorithm	Web+IR	-20.222912304050944	-35.950898606000784	110433
d55c2a37ff0558cb5d4258a7a38fe51a8a0d929e	trees in a treemap: visualizing multiple hierarchies	0705k;networks;hierarchized structure;routing;routage;structure hierarchisee;information visualization;routage reseau;network routing;data analysis;visualization;visualisation;taxonomy;analyse donnee;decision trees;arbre decision;estructura jerarquizada	This paper deals with the visual representation of a particular kind of structured data: trees where each node is associated with an object (leaf node) of a taxonomy. We introduce a new visualization technique that we call Trees In A Treemap. In this visualization edges can either be drawn as straight or orthogonal edges. We compare our technique with several known techniques. To demonstrate the usability of our visualization techniques, we apply them to find interesting patterns in decision trees and network routing data.	anomaly detection;crossing number (graph theory);dos;decision tree;directory (computing);information visualization;routing;taxonomy (general);tree (data structure);treemapping;usability	Michael Burch;Stephan Diehl	2006		10.1117/12.643272	routing;information visualization;visualization;computer science;theoretical computer science;machine learning;data mining;taxonomy	Visualization	-29.127485972544875	-34.41941443244805	110464
5ef9e251614c304874f1d183a5414ce067a3f235	autonomous campus mobility services using driverless taxi		In this paper, we present a driverless taxi system for autonomous campus mobility services. College campuses have unique mobility requirements in terms of layout, population, and demand and patterns. It is typically recommended to minimize the presence of private automobiles on campuses due to teaching and research disturbances, visual degradation from parking provision, environmental pollution, and negative health effects. As an alternative to private automobiles, shared mobility systems have been considered for both campus and urban transportation. Conventional shuttle systems suffer from the first and last mile problem. A bicycle and pedestrian friendly policy is not a generalizable solution for all geographic locations and campus layouts. We suggest a driverless taxi service as an alternative point-to-point shared mobility system for campuses. We have demonstrated the feasibility of this service on a 4.5-km campus road at Seoul National University. The service has covered over 10 000 km autonomously since the first public demonstration was made in November 2015.	application control management system;autonomous car;autonomous robot;elegant degradation;internationalization and localization;last mile;lateral thinking;point-to-point (telecommunications);population;requirement	Seong-Woo Kim;Gi-Poong Gwon;Woo-Sol Hur;Daejin Hyeon;Dae-Young Kim;Sung-Hyun Kim;Dong-Kyoung Kye;Sang-Hyun Lee;Soomok Lee;Myung-Ok Shin;Seung-Woo Seo	2017	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2017.2739127	last mile;simulation;pedestrian;engineering;tracking system;global positioning system;public transport;environmental pollution;population;transport engineering	Mobile	-20.750429091954384	-26.933529742473205	110601
73a1fb89c086317e4c8dd68cdee74301da971fb2	a desert storm crew flying hour model	digital simulation;military computing;personnel;desert storm crew flying hour model;simscript ii.5;average flying hours;crew augmentation;data driven;military airlift;mission cancellations;mission delays;mission requirements;parameter files;reserve callup/release	Desert Storm was propelled by the largest airlift in history--an airlift built upon the resources of the Military Airlift Command (MAC). The crews who flew the airlift missions were one of the key resources which .MAC had to manage throughout Desert Storm. In this paper we will describe a’ model which was widely used to support decisions on employment of aircrews. We will begin by describing the Desert Storm scenario and defining the components of the airlift system and the rules for its operation. Next we will describe the model and its inputs and outputs. We will then discuss the application of the model to specific decisions and the validation of model results.	disk staging;level of detail;requirement;simscript	Joseph R. Litko;William Brand Carter	1991			experiment;decision-making;verification;simulation;aerospace engineering;computer science;engineering;technical report;resource management;network model;level of detail;storm;world wide web;statistics	ECom	-23.010243586551457	-24.160462908623963	110862
61ccb91f381d67faac46398fa8dfcb51ba865cc2	semantic data layers in air quality monitoring for smarter cities		Air pollution is one of the key indicators for quality of life in urban environments, and is also the subject of global health concern, given the number of mortal diseases associated to exposure to pollutants. Assessing and monitoring air quality is an important step in order to better understand the impact of pollution on the health of the population. Nevertheless, in order to scale to the city level, traditional high-quality stationary sensing stations are not enough. Limitations include lack of coverage, the cost of deployment and maintenance, as well as the resolution of the observed phenomena. The OpenSense2 project aims at providing a city-level sensing deployment that combines different levels of air quality sensing: reference stations, mobile sensing on public transportation, and participatory crowdsensing. In this paper we highlight some of the key challenges of managing the data captured by such infrastructure, taking the city of Lausanne as a driving use-case. Furthermore, we present a semantics-based approach for characterizing and exposing the air quality data, so that it can be made available to citizens and application developers in a way that it can be usable and understood effectively.	activity recognition;adobe air;aggregate function;anomaly detection;cab direct (database);code coverage;crowdsensing;ecosystem;hippi;heart rate variability;hyperlink;image resolution;layer (electronics);participatory monitoring;resource description framework;sensor;smart city;smarter planet;software deployment;stationary process;time series	Jean-Paul Calbimonte;Julien Eberle;Karl Aberer	2015			simulation;environmental engineering;engineering;data mining	HCI	-19.41765445882306	-32.74921463160665	111081
4bc1bf7238ce830fdf555bcd10166179c9ea24f5	dendrogramix: a hybrid tree-matrix visualization technique to support interactive exploration of dendrograms	electronic mail;dendrogramix;interaction;data visualization visualization binary trees encoding switches clustering algorithms electronic mail;hybrid visualization;binary trees;interaction agglomerative hierarchical clustering dendrogram dendrogramix hybrid visualization;visualization;agglomerative hierarchical clustering;uncommon patterns dendrogramix hybrid tree matrix interactive visualization technique interactive exploration dendrograms cluster analysis algorithms hierarchical clustering algorithms data set binary tree node link representation subtrees;data visualization;dendrogram;clustering algorithms;trees mathematics data visualisation interactive systems pattern clustering;switches;encoding	Clustering is often a first step when trying to make sense of a large data set. A wide family of cluster analysis algorithms, namely hierarchical clustering algorithms, does not provide a partition of the data set but a hierarchy of clusters organized in a binary tree, known as a dendrogram. The dendrogram has a classical node-link representation used by experts for various tasks like: to decide which subtrees are actual clusters (e.g., by cutting the dendrogram at a given depth); to give those clusters a name by inspecting their content; etc. We present Dendrogramix, a hybrid tree-matrix interactive visualization of dendrograms that superimposes the relationship between individual objects on to the hierarchy of clusters. Dendrogramix enables users to do tasks which involve both clusters and individual objects that are impracticable with the classical representation, like: to explain why a particular objects belongs to a particular cluster; to elicit and understand uncommon patterns (e.g., objects that could have been classified in a totally different cluster); etc. Those sensemaking tasks are supported by a consistent set of interaction techniques that facilitates the exploration of large clustering results.	algorithm;binary tree;cluster analysis;dendrogram;hierarchical clustering;interaction technique;interactive visualization;sensemaking;tree (data structure)	Renaud Blanch;Remy Dautriche;Gilles Bisson	2015	2015 IEEE Pacific Visualization Symposium (PacificVis)	10.1109/PACIFICVIS.2015.7156353	complete-linkage clustering;computer science;theoretical computer science;machine learning;data mining;hierarchical clustering;single-linkage clustering;dendrogram;hierarchical clustering of networks	Visualization	-28.465647949822497	-34.03478561188478	111122
35ae88638d15227de16adc339f10284a782453c3	trellis display for modeling data from designed experiments	fractional factorial design;interaction plot;machine learning;model building;data visualization;statistics	Visualizing data by graphing a response against certain fac tors, and conditioning on other factors, has arisen independently in many different types of applications. One case is the interaction plots used in the analysis of data from des ign d experiments; these plots show conditional dependence base d on the output of methods and models applied to the data. Trel lis display, a framework for the visualization of multivariabl e data, allows conditioning to be readily carried out in a gen eral way. It was developed initially in the context of data sets with a mod erate or large number of observations to support the conditi ing. This article demonstrates through examples that trellis is also a highly useful visualization framework for designed e xperiments with a small number of runs. This includes highly fractionat ed designs: the number of runs is just a fraction of the number that would result if all combinations of the factors were run . Trellis succeeds because it allows the visualization of co nditional dependence, not based only on the output of models and method s, but also based on the raw data directly. This provides inci ive assessments of patterns of dependence in the data that can gu ide the choice of the final methods and models used in the analy sis, contributing substantially to the understanding of the dat a.	experiment;fly-by-wire;non-functional requirement;trellis quantization	Montserrat Fuentes;Bowei Xi;William S. Cleveland	2011	Statistical Analysis and Data Mining	10.1002/sam.10102	fractional factorial design;model building;computer science;artificial intelligence;machine learning;data mining;mathematics;data visualization;statistics	ML	-25.169956832930236	-37.24038518460012	111154
da389c39a387b334a6fe146eaaa0361c9a0622e3	trajectory clustering and coastal surveillance	situation awareness;information overload;decision support;decision maker;anomaly detection	In this paper we explore trajectory clustering as a means for representing the normal behavior of vessels in a coastal surveillance scenario. Trajectory clustering however suffers from some drawbacks in this type of setting and we therefore propose a new approach, spline-based clustering, with a potential for solving the task of representing the normal course of events.	cluster analysis;spline (mathematics)	Anders Dahlbom;Lars Niklasson	2007			traverse;submarine pipeline;seabed;dredging;operations research;trajectory;marine engineering;trench;engineering	AI	-22.44932979830924	-27.766114599067297	111452
c7337249b7f9272fea8ab7658cd4673624958254	from meander designs to a routing application using a shape grammar to cellular automata methodology		The usefulness of a methodology that integrates shape grammar for capturing design information with cellular automata for computational output of a design solution space is demonstrated in this paper. The application domain is the ornamental artwork known as Chinese lattices or meanders, a subject of earlier interest in shape grammar studies. In this study, a specification for a Chinese lattice is used for creating a shape grammar to capture the model’s rules of self-organization, which are then transcribed into cellular automata to physically generate a catalog of designs that meet the requirements of this particular meander style. Then, the study compares the use of a probabilistic (evolutionary computation) technique against complete enumeration for managing the search for unique designs. In consideration of the finding of a very large number of rule solutions for a design specification which produced only a very small number of graphically unique architectures, the question is raised as to whether a more efficient search process other than brute force enumeration can be used. Finally, the meander study is extended to a real engineering system, demonstrating the applicability of the shape grammar to cellular automata (SG Ø CA) methodology for finding the most efficient system architecture solutions for a comparable routing/circuit problem. System architectures addressing an underground heating specification are automatically generated and evaluated, resulting in a group of design alternatives displaying the best piping layouts for the given requirements.	application domain;automata theory;brute-force search;cellular automaton;evolutionary computation;feasible region;formal grammar;mit engineering systems division;requirement;routing;self-organization;systems architecture	Thomas H. Speller	2012	Complex Systems		machine learning;mathematics;artificial intelligence;cellular automaton;meander;shape grammar	EDA	-29.669780638973897	-26.502721391592765	111697
f89a0bbbe271727454eed8806837736a85354fab	interactive document clustering revisited: a visual analytics approach		Document clustering is an efficient way to get insight into large text collections. Due to the personalized nature of document clustering, even the best fully automatic algorithms cannot create clusters that accurately reflect the user»s perspectives. To incorporate the user»s perspective in the clustering process and, at the same time, effectively visualize document collections to enhance user's sense-making of data, we propose a novel visual analytics system for interactive document clustering. We built our system on top of clustering algorithms that can adapt to user's feedback. First, the initial clustering is created based on the user-defined number of clusters and the selected clustering algorithm. Second, the clustering result is visualized to the user. A collection of coordinated visualization modules and document projection is designed to guide the user towards a better insight into the document collection and clusters. The user changes clusters and key-terms iteratively as a feedback to the clustering algorithm until the result is satisfactory. In key-term based interaction, the user assigns a set of key-terms to each target cluster to guide the clustering algorithm. A set of quantitative experiments, a use case, and a user study have been conducted to show the advantages of the approach for document analytics based on clustering.	algorithm;algorithmic trading;archive;cluster analysis;experiment;interaction;k-means clustering;personalization;sensemaking;t-distributed stochastic neighbor embedding;usability testing;visual analytics	Ehsan Sherkat;Seyednaser Nourashrafeddin;Evangelos E. Milios;Rosane Minghim	2018		10.1145/3172944.3172964	visualization;computer science;human–computer interaction;data mining;visual analytics;cluster analysis;analytics;document clustering	Web+IR	-27.72381897725694	-34.87778680974341	111705
5107458b8325e21e0db6acef8ac33ebc1b7da800	matrix visualization in the design of numerical algorithms	software tool;mathematics;numerical software;use of visualization in numerical analysis applications;analysis of algorithms;visualization of data structures for optimal design;object oriented;numerical algorithm;scientific computing;interactive computer graphics for algorithm design;computer science	At the heart of much scienti c computing are the algorithmic kernels often found in numerical software libraries. Numerical analysts and algorithm designers can be aided by various software tools in the design of their algorithms. We present a tool for matrix visualization and its application in the design and development of numerical algorithms for supercomputers. We discuss the development of the tool as an object-oriented distributed system and show examples of its use, including applications in linear algebra and performance monitoring. By using color computer graphics, one can gain insights into algorithm behavior, which can then be used to design more e cient numerical algorithms. Speci c use in the development of hybrid parallel algorithms for the singular value decomposition is highlighted. Subject Categories/Phrases: Computer Science/interactive computer graphics for algorithm design, Mathematics/use of visualization in numerical analysis applications, Analysis of Algorithms/visualization of data structures of optimal design. Introduction With the growing availability of supercomputers and parallel computers, a surge of interest in the development of e cient numerical algorithms for computationally intensive applications (e.g., signal processing, computational uid dynamics, and structural dynamics) has evolved. As numerical analysts develop innovative solution techniques, programmers endeavor to incorporate such techniques into existing large application codes in order to exploit sophisticated hardware. Both tasks can bene t from tools to visualize the behavior and performance of the numerical algorithms. With visualization tools for numerical linear algebra research, one can easily represent the static and dynamic structure of a matrix. The static structure might be the pattern of zero and non-zero elements or the magnitude of the elements. The dynamic structure refers to those regions (e.g., rows, columns, or elements) of the matrix which are a ected by the algorithm at a particular step. Color or grey level can show the static structure of the matrix, while a combination of color, highlighting, and animation can be used to reveal the active portions of the matrix. The graphics technology used in matrix visualization is not new, but this application of computer graphics has not been well exploited. We particularly emphasize the avail1 ability of graphics techniques, and their application in mathematical software development. Some may perceive graphics as di cult to apply. We attempt to show the usefulness and ease of matrix visualization. It is important to distinguish this work as a type of data structure visualization and di erent from current work in algorithm animation. Computer graphics has been used in MAP to display memory access patterns in Fortran programs [5]. This package denotes access of matrix elements by color coding. MAP depends on a preprocessor to instrument a program with data collection calls. At execution time a trace le is written for subsequent rendering by the display program. An nice performance evaluation tool, MAP does not interact with an executing program, nor does it show the contents of a data structure. In [17] an abstraction function is used to map computational states to objects. A rendering function maps the objects into images. Again, the objects are removed from the actual data structures by this abstraction. Algorithm animation has been used to show behavior and performance of algorithms in the diverse contexts of debugging, analysis, design. There is an attempt to model the process of the algorithm rather than show the literal contents of data structures. Here we present a case for a direct representation of the data structure's contents. As a special case, we have selected the two2 dimensional array commonly used to represent a matrix. In Section 2 we discuss a tool used for matrix visualization and some aspects of the tool's design. Section 3 provides an example of the use of this tool for research in key areas of numerical linear algebra, the symmetric eigenvalue problem and the singular value decomposition. Additional examples of matrix visualization are provided in Section 4. The nal sections discuss future directions and summarize our results. 1 Approach to Matrix Visualization Our initial approach to matrix visualization was a short subroutine embedded in an application on a color Sun 3/110 workstation. This helped identify some of the key ideas underlying matrix visualization needs: the level of graphics, the program interface, color choices, and other display issues. The need for a more general purpose solution which would provide matrix visualization as an abstraction for the programmer became apparent. Several display formats were considered. The three-dimensional mesh surface plots and contour maps, both commonly used for displaying surfaces, imply a continuity between matrix elements which does not exist in the purely mathematical abstraction. Also, mesh plots and three-dimensional 3 bar charts both require views from several angles to obtain an unobstructed view of all the elements. There are high-end workstations which can rotate a three-dimensional wire frame or shaded image in real time. However, this capability is beyond the low-end workstations and personal computers which are present on most desks today. Further, there is a problem in publishing an image of an object that needs to be viewed from several angles. Therefore, a useful format is to represent each matrix element as a small colored square on the display with its color representing its value, and a matrix as a two-dimensional array of these elements. The remainder of this section provides an overview of MatVu, a matrix visualization tool. 1.1 Requirements Matrix algorithms involve not only dense matrices (often square), from tens of rows and columns to hundreds of rows and columns, but also very large sparse matrices with thousands of rows and columns. Many of these matrices can not have all of their elements adequately displayed on a workstation with screens of approximately 1000 by 1000 pixel resolution (a pixel is a picture element or dot on the display). To discern algorithm behavior we need to look at the overall structure of the matrix as well as to zoom in on individual regions. In fact, it would be useful to simultaneously monitor several regions 4 of one matrix, or perhaps several matrices at once. There are three immediate uses envisioned for this visualization: algorithm development, program and algorithm debugging, and output of results. None of these necessitates extremely fast graphics performance, but development and debugging may require a dynamic tracking of the matrix data, showing screen updates of the matrix contents continuously or on request. Our applications are supercomputer-based. Some are impossible to run on workstations or mini-computers due to speed or memory limitations. However, most of the graphics hardware available to a scientist today can reside in his or her desktop workstation or personal computer. A viable tool will display a matrix from a supercomputer application on a workstation, and update the display throughout execution. We have no immediate need for graphical input of matrix values or locator information, but have not excluded such interaction from our design. 1.2 Graphics and Display Issues The graphics concepts and algorithms are quite basic (see [11]). All the display algorithms are two-dimensional, and involve window and viewport transformations, polygon ll (usually supported in hardware), and the use 5 of color maps. In contrast to state-of-the-art photo-realistic images, we are not interested in antialiasing the matrix ( ltering speci cally to compensate for sampling at a low frequency). To do so would distort the values and hinder the detection of sharp transitional boundaries. When displaying a very large matrix in its entirety, we do apply a crude lter to reduce the matrix size by a constant integer amount by averaging n adjacent elements in each direction. In this case, n is chosen to be the smallest integer for which both rows=n and columns=n will t in the available display area. Individual elements of the original matrix are displayed by visually roaming through the matrix and displaying submatrices. Matrices can be displayed on any raster graphics device in color or monochrome. Individuals with normal color vision can easily distinguish eight or more well chosen colors. Beyond this, the identi cation of a speci c color with a key becomes challenging. However, a large number of colors will help in showing the rate of change across elements rather than forcing intermediate values into only a few categories. On a black-and-white 1-bit deep frame bu er one can use dither patterns similar to a halftone screen to achieve approximately 8 easily distinguishable grey levels with a sacri ce in the resolution of the displayed matrix. By recognizing that each device has its own rendering methods and private data describing its parameters (e.g., 6 resolution, colors), a device independent interface can be provided in the software. We bind a matrix object to a device when it is created. Each object may be associated with a di erent device or several with the same device. A procedure is provided to copy a matrix object but with a new device binding. Thus, a matrix displayed on a color workstation can be copied to a hard copy printer. Although black-and-white Sun workstations dominate our network, we do have color Suns, Apollos, a Pixar Image Computer, and PostScript printers that can be used as graphics output devices. The workstations run both the SunView1 and X windowing systems. The PostScript output is especially important for embedding grey-level matrix graphics into articles and reports for publication. It may be di cult for a programmer inexperienced in computer graphics or color use to select a good color map. Even if he or she can	1-bit architecture;algorithm design;analysis of algorithms;array data structure;chart;code;color mapping;color vision;column (database);computer animation;computer graphics;computer science;contour line;debugging;desktop computer;device independence;display device;distortion;distributed computing;dither;embedded system;experience;fortran;framebuffer;graphical user interface;graphics hardware;grayscale;human–computer interaction;information privacy;library (computing);list of numerical analysis software;literal (mathematical logic);map;mathematical software;matrix element (physics);minicomputer;monochrome;numerical linear algebra;online locator service;optimal design;output device;parallel algorithm;parallel computing;performance evaluation;personal computer;pixar image computer;pixel;postscript;preprocessor;printer (computing);programmer;raster graphics;run time (program lifecycle phase);sampling (signal processing);scott continuity;shading;signal processing;singular value decomposition;software development;sparse matrix;spatial anti-aliasing;structural dynamics;subroutine;supercomputer;the matrix;viewport;workstation	Allan Tuchman;Michael W. Berry	1990	INFORMS Journal on Computing	10.1287/ijoc.2.1.84	software visualization;computational science;information visualization;computer science;analysis of algorithms;theoretical computer science;mathematics;object-oriented programming;algorithm	Visualization	-28.355966722192285	-32.13444273249555	112235
8fdf7bc32780775271e7bbbcf1baa4fb219941fc	learning maritime traffic rules using potential fields	computer and information science;data och informationsvetenskap	The Automatic Identification System (AIS) is used to identify and locate active maritime vessels. Datasets of AIS messages recorded over time make it possible to model ship movements and analyze traffic events. Here, the maritime traffic is modeled using a potential fields method, enabling the extraction of traffic patterns and anomaly detection. A software tool named STRAND, implementing the modeling method, displays real-world ship behavior patterns, and is shown to generate traffic rules spontaneously. STRAND aids maritime situational awareness by displaying patterns of common behaviors and highlighting suspicious events, i.e., abstracting informative content from the raw AIS data and presenting it to the user. In this it can support decisions regarding, e.g., itinerary planning, routing, rescue operations, or even legislative traffic regulation. This study in particular focuses on identification and analysis of traffic rules discovered based on the computed traffic models. The case study demonstrates and compares results from three different areas, and corresponding traffic rules identified in course of the result analysis. The ability to capture distinctive, repetitive traffic behaviors in a quantitative, automatized manner may enhance detection and provide additional information about sailing practices.		Ewa Osekowska;Bengt Carlsson	2015		10.1007/978-3-319-24264-4_21	simulation;computer science;data mining;computer security;information and computer science	Robotics	-22.09978026246134	-27.78771417492931	112734
ab845ef1d19f74181e933972f9a7487dab3757e5	semantic video analysis for psychological research on violence in computer games	video analysis;psychology;semi supervised learning;machine learning;semantic video analysis;automatic annotation;indexation;video content analysis;graphic user interface;brain activation;computer games;computer game	In this paper, we present an automatic semantic video analysis system to support interdisciplinary research efforts in the field of psychology and media science. The psychological research question studied is whether and how playing violent content in computer games may induce aggression. To investigate this question, the extraction of meaningful content from computer games is required to gain insights into the interrelationship of violent game events and the underlying neurophysiologic basis (brain activity) of a player. Previously, human annotators had to index game content according to the current game state, which is a very time-consuming task. The automatic annotation of a large number of computer game recordings (i.e. videos) speeds up the experimentation process and allows researchers to analyze more experimental data on an objective basis. The proposed computer game video content analysis system for computer games extracts several audiovisual low-level as well as mid-level features and deduces semantic content via a machine learning approach. This system requires manual annotations for a single video only to facilitate the semi-supervised learning process. Finally, human experts are allowed to refine the annotation results via a graphical user interface. Experimental results demonstrate the feasibility of the proposed approach.	digital video;electroencephalography;graphical user interface;high- and low-level;machine learning;pc game;semi-supervised learning;semiconductor industry;supervised learning;video content analysis	Markus Mühling;Ralph Ewerth;Thilo Stadelmann;Bernd Freisleben;René Weber;Klaus Mathiak	2007		10.1145/1282280.1282367	semi-supervised learning;game design;game development tool;computer vision;simulation;computer science;artificial intelligence;machine learning;graphical user interface;multimedia;world wide web;game testing	AI	-25.502228373779094	-35.4761393505496	113028
9c949bf4e653b8f728aa969f9269e64c773cbc87	the flat zone approach: a general low-level region merging segmentation method	filtering;mathematical morphology;filtrage;morfologia matematica;image processing;filtrado;procesamiento imagen;flat zone method;segmentation;imagen nivel gris;traitement image;grafo;feature extraction;graph;graphe;image niveau gris;watershed;connected component;methode zone plate;grey level image;connected operator;segmentacion;region merging;flat zone approach;morphologie mathematique	Cet article presente une methode de segmentation, l'approche par zone plate, qui pallie certaines limitations de la methode watershed-plus-marqueurs. L'approche watershed-plus-marqueurs, qui constitue la technique traditionnelle de segmentation en morphologie mathematique, presente deux problemes inherents: (1) la separation possible d'une region constante par morceaux de l'image d'entree en plusieurs regions dans la partition de sortie, et (2) le probleme de l'obtention des marqueurs (composantes de pixels connectees indiquant les regions significatives) pour les attributs qui sont de largeur un ou deux pixels. Ces problemes sont lies a la puissance limitee de resolution (pour l'extraction d'attributs) des operateurs de gradient. L'approche par zone plate etend le concept de marqueur de region (contenir des regions entieres, et non pas une partie de region) et ne requiert ni le calcul de la fonction gradient ni la modification du support de l'image d'entree dans le but d'augmenter la taille des attributs. Notre approche utilise le graphe forme des zones plates de l'image (ou des regions constantes par morceaux). Ceci permet d'assurer que les regions de l'image d'entree ne sont pas coupees et de prendre en compte toutes les zones plates d'entree sans distinction de taille. Une relation d'inclusion entre les zones plates de l'image d'entree et les regions de la partition de sortie est imposee. Plus precisement, une methode de segmentation de zones plates est une methode de fusion de regions (zones plates) et se comporte comme un operateur connecte. Notre methode est robuste (dans le sens qu'elle est invariante selon certaines transformations des valeurs d'intensite) et utilise un algorithme de file d'attente hierarchique qui la rend extremement efficace.	game & watch;high- and low-level	José Crespo;Ronald W. Schafer;Jean Paul Frédéric Serra;Cristophe Gratin;Fernand Meyer	1997	Signal Processing	10.1016/S0165-1684(97)00114-X	filter;computer vision;mathematical morphology;connected component;watershed;image processing;feature extraction;computer science;mathematics;graph;segmentation	Vision	-22.165570114778863	-37.755616286932884	113179
ff9353413b1812e4644a825e511c7deb53fd8e2d	view coordination architecture for information visualisation	task performance;multiple window coordination;design space;multiple views;software architecture;complex data;design and implementation;visual representation;view coordination;information seeking;information visualisation;mental model	A view is a particular visual representation of a data set. Complex data sets typically require multiple views, each revealing a different aspect of the data. Coordinating the behaviour of these views is known to expedite tasks such as information seeking, and has been used to facilitate the exploration of large and complex data sets. The design and implementation of multiple view coordinations is challenging; poorly designed coordinations may in fact detract from task performance, while the failure to make coordinations apparent could lead to unneccessarily complex mental models of a data set. In order to facilitate the exploration of this design space, we present here an architecture for the implementation of view coordinations. In contrast with many existing tools and prototypes, which focus on specific view coordination techniques, this architecture provides generic support for view coordination. The implementation of several standard coordination techniques within the architecture are discussed by way of illustration, and the architecture compared with the Snap view coordination architecture. Examples of its initial implementation within the InVision component-based framework for information visualisation	component-based software engineering;ips community suite;information seeking;information visualization;mental model;software framework	Tim Pattison;Matthew Phillips	2001			computer vision;simulation;computer science;data mining;data architecture	Visualization	-29.934801739408517	-31.05429429117744	113485
5ce9e40ac8e95b24fab44e455031db8a8b8d7ffb	ilp, the blind, and the elephant: euclidean embedding of co-proven queries	relational data;elephants;euclidean space	Relational data is complex. This complexity makes one of the basic steps of ILP difficult: understanding the data and results. If the user cannot easily understand it, he draws incomplete conclusions. The situation is very much as in the parable of the blind men and the elephant that appears in many cultures. In this tale the blind work independently and with quite different pieces of information, thereby drawing very different conclusions about the nature of the beast. In contrast, visual representations make it easy to shift from one perspective to another while exploring and analyzing data. This paper describes a method for embedding interpretations and queries into a single, common Euclidean space based on their co-proven statistics. We demonstrate our method on real-world datasets showing that ILP results can indeed be captured at a glance.		Hannes Schulz;Kristian Kersting;Andreas Karwath	2009		10.1007/978-3-642-13840-9_20	combinatorics;topology;relational database;computer science;euclidean space;mathematics;geometry	ML	-24.74951554706238	-32.04049977745989	113523
80c991b1842f7d90de4ee4b6d82f040cf2e29306	evaluating 2d and 3d visualizations of spatiotemporal information	3d;computer vision and robotics autonomous systems;spatiotemporal;time varying;3d animation;human computer interaction;manniska datorinteraktion interaktionsdesign;3d visualization;user study;datorseende och robotik autonoma system;computer and information science;user studies;space time;visualization technique;space time cube;animation;relative efficiency;2d;data och informationsvetenskap;human perception;geospatial data	Time-varying geospatial data presents some specific challenges for visualization. Here, we report the results of three experiments aiming at evaluating the relative efficiency of three existing visualization techniques for a class of such data. The class chosen was that of object movement, especially the movements of vehicles in a fictitious landscape. Two different tasks were also chosen. One was to predict where three vehicles will meet in the future given a visualization of their past movement history. The second task was to estimate the order in which four vehicles arrived at a specific place. Our results reveal that previous findings had generalized human perception in these situations and that large differences in user efficiency exist for a given task between different types of visualizations depicting the same data. Furthermore, our results are in line with earlier general findings on the nature of human perception of both object shape and scene changes. Finally, the need for new taxonomies of data and tasks based on results from perception research is discussed.	experiment;taxonomy (general)	Andreas Kjellin;Lars Winkler Pettersson;Stefan Seipel;Mats Lind	2008	TAP	10.1145/1773965.1773970	cognitive psychology;anime;computer vision;2d computer graphics;simulation;visualization;human–computer interaction;computer science;artificial intelligence;geospatial analysis;efficiency;operating system;space time;computer animation;multimedia;perception;3d computer graphics;spatiotemporal database;computer graphics (images)	Visualization	-28.78566364141768	-36.29635944708971	113884
03fdb9f0286bc0d1c43c204394b3d6919ef3e588	tracking scalar features in unstructured data sets	visualization;feature tracking;computer vision;scalar feature;unstructured datasets;scientific visualiztion;cfd;time-varying;algorithm;feature extraction;region of interest;scientific visualization;data structures;data structure;data visualisation;structured data;tracking	3D time-varying unstructured and structured data sets are difficult to visualize and analyze because of the immense amount of data involved. These data sets contain many evolving amorphous regions, and standard visualization techniques provide no facilities to aid the scientist to follow regions of interest. In this paper, we present a basic framework for the visualization of time-varying data sets, and a new algorithm and data structure to track volume features in unstructured scalar data sets. The algorithm and data structure are general and can be used for structured, curvilinear, adaptive and hybrid grids as well. The features tracked can be any type of connected regions. Examples are shown from ongoing research.	algorithm;data structure;hybrid fibre-coaxial;region of interest	Deborah Silver;Xin Wang	1998	Proceedings Visualization '98 (Cat. No.98CB36276)	10.1145/288216.288228	computer vision;visualization;data structure;feature extraction;data model;computational fluid dynamics;computer science;theoretical computer science;data mining;tracking;programming language;structured data analysis;region of interest	Visualization	-27.73647432467179	-33.25370237336536	114115
471858df194339403cc311b84dc2749b3d38847a	epidemiology of helicopter accidents: trends, rates, and covariates		Abstract The objective of this work is to provide a better understanding of helicopter accidents and to identify important areas for different stakeholders to focus their attention and resources for accident prevention. To this end, we undertook Record Linkage of two federal data sources: the FAA civil helicopter registration data and the NTSB accident data. First, the analysis of accident rates and trends shows little progress in accident prevention over the last decade. Second, we find that helicopter accident rates vary significantly by number of main rotor blades, with the four- and six-bladed helicopters having the safest track record. Third, we show that accident rates vary by engine types when controlling for the number of blades. For example, the combination of reciprocating engine and three-bladed (3B) helicopters is associated with one of the highest accident rates. We further examine differences in accident rates between single and twin-engine helicopters, controlling for engine type and number of blades. The worst-in-class in terms of rates are the 5B and 6B single-engine turboshaft helicopters, whereas the worst-offenders in terms of contributing to the total count of accidents are the single-engine 2B reciprocating and turboshaft helicopters. The 4B single-engine turboshaft occupy a safety sweet spot and have the lowest accident rates of all single-engine helicopters. We provide risk ratios for pairwise comparisons and 95% confidence intervals for all accident rates, and discuss possible confounders for these results. The issues here examined lend themselves to a rich set of technical and operational implications, and they deserve careful attention from helicopter operators, regulators, and manufacturers. Any serious effort to improve helicopter safety will entail action on multiple safety levers, including design, operational, and policy-related ones. These actions should be evidence-based and they require better helicopter accident investigations and better data.		Jared S. Churchwell;Katherine S. Zhang;Joseph H. Saleh	2018	Rel. Eng. & Sys. Safety	10.1016/j.ress.2018.08.007	demographic economics;environmental science;covariate;epidemiology	DB	-19.37226930994789	-25.457281245684893	114719
ad7d89cf4af2bd0679659343adb91b4411ae3adb	cooperative emergency braking warning system in vehicular networks	signal image and speech processing;information systems applications incl internet;communications engineering networks	Safety applications in vehicular networks have been popular research topics in recent years, such as forward collision warning, emergency braking warning and intersection collision warning systems. The basic safety message broadcast from each car transmits the position, car speed and car heading information. Neighbouring cars receiving this information can decide if there is any danger within the next second. However, the safety application message has positioning accuracy and time-critical problems. Accurate positioning of the car provides a more effective warning to the driver. Moreover, the reliable and efficient delivery of safety information needs to be improved when the penetration rate increases. Hence, this paper proposes a cooperative emergency braking warning system to solve the above problems. This is a system that integrates a camera sensor to construct the state of neighbourhood cars in order to solve the first problem. It then proposes to reduce the repeat and derivable information between the broadcast messages in order to solve the second problem. The proposed system has been implemented to provide a safer driving environment.	course (navigation);image sensor;information needs;window of opportunity	Ming-Fong Tsai;Yung-Cheng Chao;Lien-Wu Chen;Naveen K. Chilamkurti;Seungmin Rho	2015	EURASIP J. Wireless Comm. and Networking	10.1186/s13638-015-0262-0	simulation;telecommunications;computer security;computer network	Mobile	-19.962759821470357	-28.421454179847558	114963
cd3254be8ba4fefb78fbcf33c650bfc97349587d	geometric reasoning in sketch-based volumetric decomposition framework for hexahedral meshing		This paper presents a sketch-based volumetric decomposition framework using geometric reasoning to assist in hex meshing. The sketch-based user interface makes the framework user-friendly and intuitive, and the geometric reasoning engine makes the framework smarter and improves the usability. The system first generates a database that contains both the B-rep and 3D medial object to capture the exterior and interior of the input model, respectively. Next, the geometric reasoning process determines sweeping direction and two types of sweepable regions and provides visual aids to assist the user in developing decomposition solutions. The user conducts decomposition via the sketch-based user interface, which understands the user’s intent through freehand stroke inputs for smart decomposition. Imprint and merge operations are then performed on the decomposed model before passing it to the sweeping algorithm to create hex meshes. The proposed framework has been tested on industrial models.	adobe freehand;algorithm;database;hexahedron;image-based meshing;industrial robot;medial graph;semantic reasoner;sensor;usability;user interface	Jean Hsiang-Chun Lu;Inho Song;William Roshan Quadros;Kenji Shimada	2012	Engineering with Computers	10.1007/s00366-013-0332-z	simulation;computer science;database;engineering drawing;algorithm;computer graphics (images)	Vision	-32.2997578229629	-35.786001525232095	114964
bbd0f488957657c19cef473625dd87750ff362c2	collecting and analysing personal information management data		Personal Information Management (PIM) research has investigated the information trail generated by an individual while performing some information-seeking task on their desktop, with the aim of improving PIM tool-support. Nevertheless, due to the personal nature of the data, this is rarely released for reuse. Furthermore, there exists no tool that allows a PIM researcher to investigate how PIM related data evolves over time nor one that allows for the results of applying different approaches over such data to be analysed. In this paper, we present the Personal Information Management Analytix framework (PiMx) that leverages upon a graph-analytics approach for the analysis and visualisation of evolving activity-data generated by individuals performing tasks on their desktops. We further describe a data collection methodology that opens up the data for reuse and briefly discuss how PiMx is used to analyse such a collection.	desktop computer;personal information management	Charlie Abela;Chris Staff;Siegfried Handschuh	2015			data collection methodology;data science;reuse;data mining;visualization;personal information management;computer science	HPC	-30.122716562980735	-31.027905255448115	114968
ed4e5ab6948debfe00693444c28c1d69c182dfb4	visage: interactive visual graph querying	visualization;graph querying and mining;interaction design	"""Extracting useful patterns from large network datasets has become a fundamental challenge in many domains. We present Visage, an interactive visual graph querying approach that empowers users to construct expressive queries, without writing complex code (e.g., finding money laundering rings of bankers and business owners). Our contributions are as follows: (1) we introduce graph autocomplete, an interactive approach that guides users to construct and refine queries, preventing over-specification; (2) Visage guides the construction of graph queries using a data-driven approach, enabling users to specify queries with varying levels of specificity, from concrete and detailed (e.g., query by example), to abstract (e.g., with """"wildcard"""" nodes of any types), to purely structural matching; (3) a twelve-participant, within-subject user study demonstrates Visage's ease of use and the ability to construct graph queries significantly faster than using a conventional query language; (4) Visage works on real graphs with over 468K edges, achieving sub-second response times for common queries."""	graph - visual representation;query by example;query language;question (inquiry);ring device;sensitivity and specificity;specification;usability testing;visage	Robert Pienta;Acar Tamersoy;Alex Endert;Shamkant B. Navathe;Hanghang Tong;Duen Horng Chau	2016	AVI : proceedings of the Workshop on Advanced Visual Interfaces. AVI	10.1145/2909132.2909246	visualization;human–computer interaction;computer science;interaction design;data mining;database;world wide web;graph database	HCI	-30.942909594727233	-34.504992432369754	114973
3d52e97f8d246d3f5f5ec2a6d9d0428af232a18d	passenger's transport between platform and train within the metro in paris				Jérôme Amory	2013		10.1007/978-3-319-02812-5_14	transport engineering	Vision	-20.824174630741346	-24.74904518886129	115026
bd004b2f32e8cb577d31e427c254eb860a5b8d92	crowdsending based public transport information service in smart cities	qa75 electronic computers computer science szamitastechnika;szamitogeptudomany;t2 technology general műszaki tudomanyok altalaban;xmpp based communication framework crowdsensing based public transport information service smart cities intelligent services public transportation mobile crowdsensing trafficinfo android application google maps automatic stop event detection public transport vehicles extensible messaging and presence protocol based communication framewor;sensors crowdsourcing real time systems public transportation urban areas smart cities;traffic engineering computing android operating system geography information services smart cities	Thanks to the development of technology and the emergence of intelligent services smart cities promise to their inhabitants enhanced perception of city life. For example, a live timetable service of public transportation can increase the efficiency of travel planning substantially. However, its implementation in a traditional way requires the deployment of some costly sensing and tracking infrastructure. Mobile crowdsensing is an alternative, when the crowd of passengers and their mobile devices are used to gather data for almost free of charge. In this paper, we put the emphasis on the introduction of our crowdsensing based public transport information service, what we have been developing as a prototype smart city application. The front-end interface of this service is called TrafficInfo. It is a simple and easy-to-use Android application which visualizes real-time public transport information of the given city on Google Maps. The lively updates of transport schedule information relies on the automatic stop event detection of public transport vehicles. TrafficInfo is built upon our Extensible Messaging and Presence Protocol (XMPP) based communication framework what we designed to facilitate the development of crowd assisted smart city applications. The paper introduces shortly this framework, than describes TrafficInfo in detail together with the developed stop event detector.		Károly Farkas;Gábor Fehér;András A. Benczúr;Csaba István Sidló	2015	IEEE Communications Magazine	10.1109/MCOM.2015.7180523	simulation;telecommunications;operating system;internet privacy;computer security;computer network	Mobile	-19.898836773535937	-30.5616396456109	115179
cad938120ca10ce7b51dd123a5f24e162e77c1af	just how dense are dense graphs in the real world?: a methodological note	edge density;real world examples;random generation;user study;information visualization;graph models;interface evaluation;graph model;graph visualization	This methodological note focuses on the edge density of real world examples of networks. The edge density is a parameter of interest typically when putting up user studies in an effort to prove the robustness or superiority of a novel graph visualization technique. We survey many real world examples all being of equal interest in Information Visualization, and draw a list of conclusions on how to tune edge density when randomly generating graphs in order to build artificial though realistic examples.	graph drawing;information visualization;randomness	Guy Melançon	2006		10.1145/1168149.1168167	information visualization;computer science;theoretical computer science;data mining;graph drawing	ML	-29.895577726837743	-36.48708279377214	115325
d4f66ae349a71594b05a446016149454f0d810d3	graphiti: interactive specification of attribute-based edges for network modeling and visualization		Network visualizations, often in the form of node-link diagrams, are an effective means to understand relationships between entities, discover entities with interesting characteristics, and to identify clusters. While several existing tools allow users to visualize pre-defined networks, creating these networks from raw data remains a challenging task, often requiring users to program custom scripts or write complex SQL commands. Some existing tools also allow users to both visualize and model networks. Interaction techniques adopted by these tools often assume users know the exact conditions for defining edges in the resulting networks. This assumption may not always hold true, however. In cases where users do not know much about attributes in the dataset or when there are several attributes to choose from, users may not know which attributes they could use to formulate linking conditions. We propose an alternate interaction technique to model networks that allows users to demonstrate to the system a subset of nodes and links they wish to see in the resulting network. The system, in response, recommends conditions that can be used to model networks based on the specified nodes and links. In this paper, we show how such a demonstration-based interaction technique can be used to model networks by employing it in a prototype tool, Graphiti. Through multiple usage scenarios, we show how Graphiti not only allows users to model networks from a tabular dataset but also facilitates updating a pre-defined network with additional edge types.	ccir system a;cdisc adas-cog - commands summary score;diagram;entity name part qualifier - adopted;interaction technique;modeling language;node - plant part;prototype;sql;silo (dataset);specification;subgroup;table (information)	Arjun Srinivasan;Hyunwoo Park;Alex Endert;Rahul C. Basole	2018	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2017.2744843	network model;data visualization;artificial intelligence;raw data;visualization;sql;computer vision;data mining;interaction technique;data modeling;computer science;scripting language	Visualization	-31.389824365106495	-31.582553612088073	115516
15e2d2b917b09d1e65f823851f430f3c1a7cf4b8	social informatics		Understanding the spatio-temporal dynamics of cities is important for many applications including urban planning, zoning, and real-estate construction. So far, much of this understanding came from traditional surveys conducted by persons or by leveraging mobile data in the form of Call Detailed Records. However, the high financial and human cost associated with these methods make the data availability very limited. In this paper, we investigate the use of large scale and publicly available user contributed content, in the form of social media posts to understand the urban dynamics of cities. We build activity time series for different cities, and different neighborhoods within the same city to identify the different dynamic patterns taking place. Next, we conduct a cluster analysis on the time series to understand the spatial distribution of patterns in the city.	cluster analysis;social informatics;social media;time series;user-generated content	Steffen Staab;Olessia Koltsova;Dmitry I. Ignatov	2018		10.1007/978-3-030-01159-8		HCI	-19.596598361713	-34.88004940690566	115782
ebbf088897db51a015130790e23a391385d3f199	mard-a moving average rose diagram application for the geosciences	rose diagram;qe geology;moving average;microsoft excel;matlab;vector mean;circular statistics	MARD 1.0 is a computer program for generating smoothed rose diagrams by using a moving average, which is designed for use across the wide range of disciplines encompassed within the Earth Sciences. Available in MATLAB^(R), Microsoft^(R) Excel and GNU Octave formats, the program is fully compatible with both Microsoft^(R) Windows and Macintosh operating systems. Each version has been implemented in a user-friendly way that requires no prior experience in programming with the software. MARD conducts a moving average smoothing, a form of signal processing low-pass filter, upon the raw circular data according to a set of pre-defined conditions selected by the user. This form of signal processing filter smoothes the angular dataset, emphasising significant circular trends whilst reducing background noise. Customisable parameters include whether the data is uni- or bi-directional, the angular range (or aperture) over which the data is averaged, and whether an unweighted or weighted moving average is to be applied. In addition to the uni- and bi-directional options, the MATLAB^(R) and Octave versions also possess a function for plotting 2-dimensional dips/pitches in a single, lower, hemisphere. The rose diagrams from each version are exportable as one of a selection of common graphical formats. Frequently employed statistical measures that determine the vector mean, mean resultant (or length), circular standard deviation and circular variance are also included. MARD's scope is demonstrated via its application to a variety of datasets within the Earth Sciences.		Mark A. Munro;Thomas G. Blenkinsop	2012	Computers & Geosciences	10.1016/j.cageo.2012.07.012	simulation;computer science;theoretical computer science;machine learning;database;mathematics;moving average;statistics	EDA	-26.311310962759222	-37.69094012729543	115957
0f26bb157655bc3140162b67cf5d33659cba7296	measuring crew resource management: challenges and recommendations		This paper presents a methodology for measuring Crew Resource Management (CRM) parameters as applied to a pilot decision-making task. Six teams of pilots took part in a desk-top decision-making exercise. Flight crew performance was observed by human factors researchers and was measured on a number of parameters pertaining to communication, situational awareness, decision-making, mission analysis, leadership, adaptability and assertiveness. This methodology facilitated the mapping of decisions in the context of the overall process. The communication analysis can be considered more objective than standard CRM expert rating. This methodology could be used to examine CRM for training, recruitment, incident and accident analysis, identifying degraded performance on the flight-deck and has further implications for multi- team co-ordination. It could also be used to provide a sound contribution to the design of automatic means of detection for CRM metrics on the flight deck.	crew resource management;recommender system	Alison M. Kay;Paul M. Liston;Sam Cromie	2014		10.1007/978-3-319-07515-0_48	simulation;engineering;operations management;operations research	OS	-24.568722247645628	-23.95139491413325	116029
355656d6a7fef7f0a6b3eedd190326df239c8f4c	role of temporal diversity in inferring social ties based on spatio-temporal data		The last two decades have seen a tremendous surge in research on social networks and their implications. The studies include inferring social relationships, which in turn have been used for target advertising, recommendations, search customization etc. However, the offline experiences of humans, the conversations with people and face-to-face interactions that govern our lives interactions have received lesser attention. We introduce DAIICT Spatio-Temporal Network (DSSN), a spatiotemporal dataset of 0.7 million data points of continuous location data logged at an interval of every 1 minute by mobile phones of 46 subjects.  Our research is focused at inferring relationship strength between students based on the spatiotemporal data and comparing the results with the self-reported data. In that pursuit we introduce Temporal Diversity, which we show to be superior in its contribution to predicting relationship strength than its counterparts. We also explore the evolving nature of Temporal Diversity with time.  Our rich dataset opens various other avenues of research that require fine-grained location data with bounded movement of participants within a limited geographical area. The advantage of having a bounded geographical area such as a university campus is that it provides us with a microcosm of the real world, where each such geographic zone has an internal context and function and a high percentage of mobility is governed by schedules and time-tables. The bounded geographical region in addition to the age homogeneous population gives us a minute look into the active internal socialization of students in a university.	data point;experience;experiment;geographic coordinate system;interaction;microcosm (hypermedia system);mike lesser;mobile phone;online and offline;schedule (computer science);social network;socialization;sparse matrix	Deshana Desai;Harsh Nisar;Rishabh Bhardawaj	2017		10.1145/3041823.3041836	social science;simulation;machine learning;social psychology;world wide web;statistics	HCI	-19.888798258243984	-35.5965075818015	116095
8e347b75fab63c85e961489c467d8cb18704ff09	visa: visual subspace clustering analysis	distance function;cognitive ability;interactive visualization;individual object;data mining;visualization technique;visual analysis;grouped data;subspace clustering;large data	To gain insight into today's large data resources, data mining extracts interesting patterns. To generate knowledge from patterns and benefit from human cognitive abilities, meaningful visualization of patterns are crucial. Clustering is a data mining technique that aims at grouping data to patterns based on mutual (dis)similarity. For high dimensional data, subspace clustering searches patterns in any subspace of the attributes as patterns are typically obscured by many irrelevant attributes in the full space. For visual analysis of subspace clusters, their comparability has to be ensured. Existing subspace clustering approaches, however, lack interactive visualization and show bias with respect to the dimensionality of subspaces.  In this work, dimensionality unbiased subspace clustering and a novel distance function for subspace clusters are proposed. We suggest two visualization techniques that allow users to browse the entire subspace clustering, to zoom into individual objects, and to analyze subspace cluster characteristics in-depth. Bracketing of different parameter settings enable users to immediately see the effect of parameters on their data and hence to choose the best clustering result for further analysis. Usage of user analysis for feedback to the subspace clustering algorithm directly improves the subspace clustering. We demonstrate our visualization techniques on real world data and confirm results through additional accuracy measurements and comparison with existing subspace clustering algorithms.	algorithm;browsing;cluster analysis;clustering high-dimensional data;cognition;data mining;interactive visualization;relevance;user analysis	Ira Assent;Ralph Krieger;Emmanuel Müller;Thomas Seidl	2007	SIGKDD Explorations	10.1145/1345448.1345451	random subspace method;correlation clustering;constrained clustering;data stream clustering;subclu;cognition;interactive visualization;metric;fuzzy clustering;computer science;canopy clustering algorithm;machine learning;consensus clustering;pattern recognition;cure data clustering algorithm;data mining;grouped data;cluster analysis;clustering high-dimensional data	ML	-27.073055129733923	-34.511570330659126	116252
72175f5be5ab47683a08997e3bbff78152de8c5e	access control in virtual environments	graph theory;dive;cve;access control;virtual environment;security	This paper develops a spatial approach tom access control for virtual environments and presents an implementation in the DIVE system. Access control is governed according to the space within which subjects and objects reside and whether a subject can traverse this space in order to get close to an object. After considering why a spatial approach is appropriate, the concepts of boundaries and access graphs are introduced. Boundaries are objects which partition a space into regions or which link separate spaces. By considering the properties needed to traverse boundaries and the structure of the space as a whole we can construct an access graph, a mathematical description of the access properties of the space. This graph can then be interrogated to provide an understanding of these properties and to enable users to more easily manage access rights.	access control;tom;traverse;virtual reality	Adrian Bullock;Steve Benford	1997		10.1145/261135.261142	common vulnerabilities and exposures;computer science;virtual machine;access control;graph theory;distributed computing;world wide web;computer security	DB	-32.70589314592969	-34.55605851024266	116645
8660aafdf1f529f2d1126e44395ad61d4a6e0468	open source programming for interpreted language: graphic interface and macro bridging interface in the eeglab software	electrophysiological data processing;software;scripting open source eeg ica eeglab macro menu;history;graphical interface;menu;authoring languages;public domain software;macro;graphical user interfaces;graphics electroencephalography history software graphical user interfaces signal processing data structures;data structures;signal processing;graphic interface;eeg;language interpretation;electroencephalography;open source programming;automated macro scripting;ica;medical diagnostic computing;public domain software authoring languages electroencephalography graphical user interfaces medical diagnostic computing medical signal processing;scripting;medical signal processing;graphics;eeglab software;macro bridging interface;automated macro scripting open source programming language interpretation graphic interface macro bridging interface eeglab software electrophysiological data processing;open source;eeglab	Interpreted languages like Matlab or Python are popular in the Open Source community. Not-only do these software environments offer the possibility of developing comprehensive graphic interfaces but they also contain nearly unlimited scripting capabilities for automating procedures. We describe the GIMBI framework (Graphic Interface and Macro Bridging Interface) for easily bridging graphic interface functions with automated macro scripting in an interpreted language. We illustrate this method using the open source EEGLAB software we have developed, which is currently the most widely used public software for processing electrophysiological data.	bridging (networking);david b. fogel;electroencephalography;graphical user interface;independent component analysis;information processing;interpreted language;jung;matlab;open-source software;python;scripting language;software project management	Arnaud Delorme;Scott Makeig	2009	2009 Fifth International Conference on Signal Image Technology and Internet Based Systems	10.1109/SITIS.2009.73	human–computer interaction;computer science;theoretical computer science;operating system;signal processing;graphical user interface;database;programming language	SE	-32.528802138434514	-29.261510054048628	116886
39b69c27945efc59277aae77a72e33298c8f85ca	recommender systems for evaluating computer messages	recommender system	Free-riding leads to too few evaluations. Beyond this, evaluations will be provided by an unrepresentative group—those who most enjoy the evaluation process. Hence, their evaluations may be misleading. Free-riding implies neither sloth nor conscious selfinterested calculation; it can arise innocently. For instance, a newsgroup reader with the flu may not evaluate messages for several days. Upon return, that reader should find a set of the best messages as selected by other readers, and none of the worst. Such an experience would probably diminish the reader’s zeal to evaluate. Figure 1 shows payoffs for Example 1. There are two potential readers for a particular message that is equally likely to be either “good” or “bad.” A single evaluation is assumed to completely identify the value of the message. Table (b) is derived by calculating expected outcomes from section (a). For example, assume B reads. If A also reads immediately, her payoff is 10 if the message is good and -12 if it is bad, implying -1 on average. If A waits, she will read only if the message is good, yielding an expected payoff of 5. In Example 1, it would be optimal for one person to read immediately and the other to wait, giving a total payoff of 4. Unfortunately, reader B gains by waiting no matter what reader A does, and vice versa. Thus, neither player reads immediately, although the social benefits (that is, benefits to the other player) of an evaluation by either person (+5 on average) outweigh its cost (-1 on average). No one will read a message unless it offers a positive expected personal payoff, and many useful messages will never be read. (Moreover, if effort in evaluations can be chosen when a message is read, it will be insufficient.) Analogously, any John Grisham novel sells well, regardless of initial reviews, but excellent novels by Recommender Systems for Evaluating Computer Messages	emoticon;recommender system;waits	Christopher Avery;Richard J Zeckhauser	1997	Commun. ACM	10.1145/245108.245127	computer science;multimedia;internet privacy;world wide web;recommender system	Web+IR	-24.17688698752941	-26.769878328149492	116893
922daf2df18f3a28c1d379bba9118af67baf70d3	an agent and group model for generating a variety of flocking behaviours	group model;flocking behaviours			Quasim H. Mehdi;Hussam Suliman;Norman E. Gough	2002			flocking (texture);machine learning;artificial intelligence;computer science	NLP	-27.58690852065367	-23.957989929827313	117180
5b135d67ce30f0dcd5be81973db5a7fee662b96a	from coding to automatic generation of legends in visual analytics	user interface;interactive visualization;information visualization;automatic generation;financial data;interactive graphics;visual analytics;graph visualization	  The description of the process that transforms non graphic data (astronomical, biological, or financial data for example)  into interactive graphical representations of this data has been at the core of information visualization research over the  past decades. That process often referred to as coding, can be supported and controlled at different levels and by different  types of users. Different levels bring different types of opportunity. In order to make it possible for all users to benefit  from the pros of different levels approaches, we propose a toolkit named STOOG that addresses the needs of different types  of users. STOOG brings a four-fold contribution: (1) a style sheet language for the description of the transformation process  at stake in information visualization, (2) an application building automatically interactive visualization of data based on  the style-sheet description, (3) a user interface devoted to the conception of style sheets and then (4) the generation of  basic legends. This paper presents STOOG basic concepts and mechanisms and provides a case study to illustrate the benefits  of using STOOG for the interactive and visual exploration of information.    		Guillaume Artignan;Mountaz Hascoët	2010		10.1007/978-3-642-19802-1_28	analytics;visual analytics;information visualization;visualization;interactive visualization;human–computer interaction;interactive visual analysis;computer science;data mining;multimedia;graph drawing;user interface;data visualization;computer graphics (images)	Vision	-29.97152848993687	-31.279458240866266	117827
95f3b6ca3d37ea2631f3b792d094e22566763274	analyzing spatial data from twitter during a disaster	spatial data analysis;twitter;disasters and mass emergencies	Social media can be an invaluable help in a mass emergency, but the information handling can be challenging. One major concern is identifying posts related to the area, or pinning them on a map. This exploratory study analyzes the spatial data coming with tweets during two natural disasters, an earthquake and a hurricane. Geo-tagged tweets confirm to be a small fraction of all tweets and disasters within a limited region appear to be a niche topic in the whole stream. The results can help researchers and practitioners in the design of tools to identify these messages.		Luca Venturini;Evelina Di Corso	2017	2017 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2017.8258378	exploratory research;data mining;spatial analysis;computer science;social media;natural disaster	DB	-21.181682772654323	-33.68237644426319	117849
f35d572478e167d482e8ae5f309194f5b74b5326	should we place the license plate tracking system in the cloud?		We developed a software system to extract and track vehicle license plate numbers from real-time surveillance cameras and crowd sourced video streams. The system can also calculate the probable routes of a vehicle over a range of dates based on the geographical coordinates. In this paper, we present both of our linear and parallel processing implementation schemes and analyze the performance based on evaluation results. Our results show that while cloud based parallel processing can address the scalability needs, performance outweighs the cost only when the real-time streaming data becomes increasingly large.	automatic number plate recognition;closed-circuit television;computation;cost efficiency;crowdsourcing;emoticon;fastest;geographic coordinate system;google compute engine;microsoft azure;parallel computing;real-time clock;real-time transcription;scalability;software deployment;software system;storm botnet;stream (computing);streaming media;time complexity;tracking system	Razib Iqbal;Matthew Kenney;Jamil Saquer	2017		10.5220/0006470000770080		HPC	-21.519369192506286	-30.41664035144734	118095
66c33b6ccf06243e4fe881f4b18b9a090b99f77e	visualizing the effects of scale and geography in multivariate comparison	ga mathematical geography cartography;geography data visualisation demography feature selection;qa75 electronic computers computer science;visual interactive approach multivariate data visualization local geography geodemographic classifications variable selection process;i 5 2 pattern recognition design methodology feature evaluation and selection;correlation geography encoding image color analysis data visualization visualization input variables;d 2 2 software engineering design tools and techniques;z665 library science information science;i 5 2 pattern recognition design methodology feature evaluation and selection d 2 2 software engineering design tools and techniques	Our research investigates the sensitivities and complexities of visualizing multivariate data over multiple scales with the consideration of local geography. We investigate this in the context of creating geodemographic classifications, where multivariate comparison for the variable selection process is an important, yet time-consuming and intensive process. We propose a visual interactive approach which allows skewed variables and those with strong correlations to be quickly identified and investigated and the geography of multi-scale correlation to be explored. Our objective is to present comprehensive documentation of the parameter space prior to the development of the visualization tools to help explore it.	documentation;faceted classification;feature selection	Sarah Goodwin;Jason Dykes;Aidan Slingsby	2014	2014 IEEE Conference on Visual Analytics Science and Technology (VAST)	10.1109/VAST.2014.7042515	computer science;data science;machine learning;data mining	Visualization	-26.222914377695748	-33.110146604396554	118174
70ba755adb82f9ab0fd05834a9b5f78145be6383	repulsive attractive network for baseline extraction on document images	extraction information;image processing;langage c;information extraction;simulation;procesamiento imagen;simulacion;dynamic system;segmentation;transformacion hough;traitement image;experimental result;dynamical system;algorithme;systeme dynamique;algorithm;c language;active model;baseline;resultado experimental;pattern recognition;hough transformation;hough transform;repulsive attractive network;transformation hough;energy minimization;reconnaissance forme;sistema dinamico;curve fitting;reconocimiento patron;resultat experimental;segmentacion;lenguaje c;algoritmo;extraction informacion	Cet article decrit un nouveau cadre de travail, appele reseau repulsif attractif pour l'extraction de la ligne de base sur des images de documents. Let reseau repulsif attractif est un systeme dynamique minimisant une energie, qui interagit avec l'image du texte du document par des forces attractives et repulsives definies sur les composantes du reseau et sur l'image du document. Des resultats experimentaux indiquent que le reseau peut extraire avec succes les lignes de base sous un bruit important et en presence de recouvrements entre les parties ascendantes et descendantes des caracteres de deux lignes adjacentes. Le schema propose est applicable a une large gamme d'applications de traitement d'images, telles l'ajustement de courbes, la segmentation et l'affinement.	baseline (configuration management)	Erhan Öztop;Adem Yasar Mülayim;Volkan Atalay;Fatos T. Yarman-Vural	1999	Signal Processing	10.1016/S0165-1684(98)00220-5	hough transform;computer vision;image processing;computer science;artificial intelligence;dynamical system;information extraction;algorithm	ML	-22.191464380124987	-37.76347287030953	118272
6e1879ccde311333ce8567d88973130d4989c6fd	drivers' needs and safety systems	product model;point of view;human error;motor function;accidentology;safety functions	Motivation - Drivers' needs in safety functions must be defined from a human-centered point of view, going beyond technical offers. This paper presents a study conducted in the frame of the European TRACE project, focusing on the diagnosis of such needs from a detailed analysis of the real difficulties met by drivers in accident-generating situations.  Research approach - This study is based on a sample of 432 car drivers involved in a road accident. The sample was extracted from INRETS (France) in-depth accident studies database (EDA). The analysis relied upon a human error production model (Van Elslande, 2003; Van Elslande & Fouquet, 2007) delineating the different perceptive, cognitive and motor functional failures leading drivers to have an accident. Drivers' safety needs were deduced from these failures of the functions that usually make the driver able to compensate for driving system malfunctions.  Findings/Design - Drivers' difficulties in accident production show an important need in: 1) detecting other users, 2) diagnosing driver's condition, and 3) controlling the vehicle.  Research limitations/Implications - Drivers needs in safety functions were defined from attested safety problems as they are expressed in accident. A complement of such an approach is to be found in naturalistic driving studies.  Originality/Value - The definition of needs relies upon an ultra in-depth analysis of accident cases with detailed interviews of people involved and cinematic reconstruction of the events.	device driver;human error;portable collision avoidance system;sensor	Pierre Van Elslande;Katel Fouquet	2008		10.1145/1473018.1473029	simulation;human error;motor skill;engineering;forensic engineering	HCI	-23.556232106354283	-26.19812683549953	118383
6705d7d425a4da7d33afbee00cc82c906f62b36f	small multipiles: piling time to explore temporal patterns in dynamic networks	networks;brain connectivity;h 5 2 information interfaces and presentation;h 5 2 information interfaces and presentation user interfaces graphical user interfaces;visualization;graphical user interfaces;tempral data;user interfaces;dynamic networks;categories and subject descriptors according to acm ccs	We introduce MultiPiles, a visualization to explore time-series of dense, weighted networks. MultiPiles is based on the physical analogy of piling adjacency matrices, each one representing a single temporal snapshot. Common interfaces for visualizing dynamic networks use techniques such as: flipping/animation; small multiples; or summary views in isolation. Our proposed ‘piling’ metaphor presents a hybrid of these techniques, leveraging each one’s advantages, as well as offering the ability to scale to networks with hundreds of temporal snapshots. While the MultiPiles technique is applicable to many domains, our prototype was initially designed to help neuroscientists investigate changes in brain connectivity networks over several hundred snapshots. The piling metaphor and associated interaction and visual encodings allowed neuroscientists to explore their data, prior to a statistical analysis. They detected high-level temporal patterns in individual networks and this helped them to formulate and reject several hypotheses.	adjacency matrix;british informatics olympiad;cluster analysis;computer graphics;desktop metaphor;direct manipulation interface;eurographics;heuristic (computer science);high- and low-level;holomatix rendition;interaction;interactivity;john d. wiley;prototype;small multiple;snapshot (computer storage);social network;time series;timeline;webgl;weighted network	Benjamin Bach;Nathalie Henry Riche;Tim Dwyer;Tara M. Madhyastha;Jean-Daniel Fekete;Thomas J. Grabowski	2015	Comput. Graph. Forum	10.1111/cgf.12615	visualization;human–computer interaction;computer science;theoretical computer science;operating system;graphical user interface;user interface;world wide web;computer graphics (images)	HCI	-28.469499460211203	-34.979887743165115	118682
f5490b128502249abddb9e3c6cc73938db30ac32	preview of recommended routes in large-scale virtual environments	previews;sequence mining;route selection;navigation;virtual environment;landmark	In large-scale virtual environments (VEs), there is often more than one possible route to a destination, and each of the VE users may have their own route preferences. In this paper, we introduce a route preview tool to help users select a desirable route out of several alternative routes, without having to first travel any of the candidate routes. The route preview tool has both a text component to highlight the quantitative features of the routes (ex. time to travel the route, distance of the route, number of turns in the route) and an image component to highlight the qualitative features (ex. scenery and objects along the route). Our experiments showed that the proposed route preview tool is informative, capable of highlighting the most salient features of the routes, and provides the necessary support to help users select an appropriate route.	experiment;information;virtual reality	Pedram Sadeghian;Mehmed M. Kantardzic;Oleksandr Lozitskiy;Yuriy Lozitskiy	2006		10.1145/1128923.1128930	simulation;engineering;route planning software;transport engineering;world wide web	HCI	-31.021297429467275	-35.78642493664815	118777
734fc7f8f2d5ea57858671668d7e59d01abbb95c	generating discourse across several user models maximizing belief while avoiding boredom and overload	user model	In this paper we present a content planning system which takes into consideration a user's boredom and cognitive overload Our system applies a constraint-based optimization mechanism which maximizes a probabilistic function of a user's beliefs, and uses a representation of boredom and overload as constraints that affect the possible values of this function Further, we discuss two orthogonal policies for relaxing the parameters of the communication process when these constraints are violated conveying less information or breaking up the material into smaller chunks	algorithm;central processing unit;interactivity;loss function;mathematical optimization;naruto shippuden: clash of ninja revolution 3;optimization mechanism;optimization problem;viz: the computer game	Ingrid Zukerman;Richard McConachy	1995			user modeling;computer science;artificial intelligence	HCI	-31.260984732933178	-24.318349655646387	118786
218899ac999fd9942fc1f3e198e51eb578e4f8cb	a web-based interactive data visualization system for outlier subspace analysis	data visualization	Detecting outliers from high-dimensional data is a challenge task since outliers mainly reside in various lowdimensional subspaces of the data. To tackle this challenge, subspace analysis based outlier detection approach has been proposed recently. Detecting outlying subspaces in which a given data point is an outlier facilitates a better characterization process for detecting outliers for high-dimensional data stream, and make outlier mining for large high-dimensional data set to be more manageable. In this paper, to facilitate outlier subspaces analysis from human perception perspectives in supporting the development of efficient solutions for high-dimensional data, we propose a web-based interactive data visualization system, which can display various low-dimensional outlier subspaces to allow users to observe and analyze the distributions of outliers. The proposed visualization tool can help the developers of outlier detection applications to directly examine the distributions of outliers in various low-dimensional subspaces to validate their experiment results.	anomaly detection;data point;interactive data visualization;sensor;web application	Dong Liu;Qigang Gao;Hai H. Wang;Ji Zhang	2010			computer science;data science;machine learning;data mining	ML	-26.786924630744988	-34.343293689888654	119006
69d45f7e8b1ccef6a6759063629a999982beba54	notice of violation of ieee publication principlesdetecting high-value individuals in covert networks: 7/7 london bombing case study	covert network;covert networks;high value individuals;social network analysis covert networks detecting hidden hierarchy high value individuals position role centrality;intelligence agency;7 7 london bombing;social sciences computing;terrorist network;mathematical model;social network analysis;detecting hidden hierarchy;terrorism social sciences computing;measure theory;position role centrality;social network analysis high value individuals covert network 7 7 london bombing terrorist network intelligence agency;terrorism;social network services weapons intelligent networks terrorism computer science humans frequency conversion face law enforcement mathematical model	This article focuses on the study and development of recently introduced new measures, theories, mathematical models and algorithms to detect high value individuals in terrorist networks. Specific models and tools are described, and applied to a case study to demonstrate their applicability to the area. We are confident that the models described can help intelligence agencies in understanding and dealing with terrorist networks.	algorithm;mathematical model;theory	Nasrullah Memon;Nicholas Harkiolakis;David L. Hicks	2008	2008 IEEE/ACS International Conference on Computer Systems and Applications	10.1109/AICCSA.2008.4493536	social network analysis;measure;artificial intelligence;mathematical model;terrorism;computer security;statistics	Visualization	-22.746383602488834	-30.493896878160733	119102
10617fae640285e7432cd281dd4b911ddf2d3902	infinite images: creating and exploring a large photorealistic virtual space	automatic control;image taxi;large photorealistic virtual space;motion pictures;space technology navigation image retrieval tagging cities and towns layout displays automatic control motion pictures second life;virtual reality;virtual 3d space;layout;navigation;photo collections;left right;photographs;image edge detection;three dimensional displays;image color analysis;displays;pixel;realistic images;cities and towns;second life;space technology;photographs large photorealistic virtual space virtual 3d space image taxi photo collections;virtual space;virtual reality realistic images;cameras;tagging;image retrieval	We present a system for generating “infinite” images from large collections of photos by means of transformed image retrieval. Given a query image, we first transform it to simulate how it would look if the camera moved sideways and then perform image retrieval based on the transformed image. We then blend the query and retrieved images to create a larger panorama. Repeating this process will produce an “infinite” image. The transformed image retrieval model is not limited to simple 2-D left/right image translation, however, and we show how to approximate other camera motions like rotation and forward motion/zoom-in using simple 2-D image transforms. We represent images in the database as a graph where each node is an image and different types of edges correspond to different types of geometric transformations simulating different camera motions. Generating infinite images is thus reduced to following paths in the image graph. Given this data structure we can also generate a panorama that connects two query images, simply by finding the shortest path between the two in the image graph. We call this option the “image taxi.” Our approach does not assume photographs are of a single real 3-D location, nor that they were taken at the same time. Instead, we organize the photos in themes, such as city streets or skylines and synthesize new virtual scenes by combining images from distinct but visually similar locations. There are a number of potential applications to this technology. It can be used to generate long panoramas as well as content aware transitions between reference images or video shots. Finally, the image graph allows users to interactively explore large photo collections for ideation, games, social interaction, and artistic purposes.	approximation algorithm;data structure;graph (discrete mathematics);image retrieval;interactive media;shortest path problem;simulation	Josef Sivic;Biliana Kaneva;Antonio Torralba;Shai Avidan;William T. Freeman	2008	2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops	10.1109/CVPRW.2008.4562950	layout;computer vision;navigation;image retrieval;computer science;automatic control;virtual reality;multimedia;space technology;pixel;computer graphics (images)	Vision	-33.15270283562957	-34.5767240564349	119344
85a5291d92ec085bf70126893f05c1fafee79f7d	the correspondence analysis platform for uncovering deep structure in data and information	information space;data format;artificial intelligent;correspondence analysis;projective space;article	We study two aspects of information semantics: (i) the collection of all relationships, (ii) tracking and spotting anomaly and change. The first is implemented by endowing all relevant information spaces with a Euclidean metric in a common projected space. The second is modelled by an induced ultrametric. A very general way to achieve a Euclidean embedding of different information spaces based on cross-tabulation counts (and from other input data formats) is provided by Correspondence Analysis. From there, the induced ultrametric that we are particularly interested in takes a sequential – e.g. temporal – ordering of the data into account. We employ such a perspective to look at narrative, “the flow of thought and the flow of language” (Chafe). In application to policy decision making, we show how we can focus analysis in a small number of dimensions. 1 Analysis of Narrative 1.	anomaly detection;contingency table;correspondence analysis;euclidean distance;table (information)	Fionn Murtagh	2010	Comput. J.	10.1093/comjnl/bxn045	projective space;discrete mathematics;computer science;theoretical computer science;database;mathematics;correspondence analysis;multiple correspondence analysis;algorithm;statistics		-24.56522104995583	-32.261560835659665	119936
c37500005eda09049f1da867d39ffeb4ce3703fb	research report: information animation applications in the capital markets	financial data processing computer animation securities trading data visualisation decision support systems risk management;financial data processing;decision support tool;fixed income trading analytics;capital market;securities trading;fixed income risk viewing;3d computer graphics;animation information security data security risk analysis application software computer graphics computer displays layout humans decision making;risk analysis;securities industry;visual design;risk management;information overload;computer graphic;data visualisation;visualization;three dimensional computer graphics information animation applications capital markets 3d computer graphics securities market visual design decision support tool securities industry equity trading analytics fixed income trading analytics fixed income risk viewing;capital markets;decision support systems;animation;securities market;information animation applications;equity trading analytics;income risk;short period;computer animation;three dimensional computer graphics	3D computer graphics can be extremely expressive. It is possible to display an entire securities market, like the S&P 500, on a single screen. With the correct approach to the visual design of the layout, these massive amounts of information can be quickly and easily comprehended by a human observer. By using motion and animated interaction, it is possible to use 3D as a reliable, accurate and precise decision-support tool. Information animation applications are particularly suited to the securities industry because that is where we find huge amounts of data, the value of which declines rapidly with time, and where critical decisions are being made on this data in very short periods of time. Information animation technology is an important new tool for the securities industry, where people need to be in the decision-making loop without suffering from information overload. Several examples are discussed including equity trading analytics, fixed income trading analytics and fixed-income risk viewing.	3d computer graphics;equity crowdfunding;information overload	W. Wright	1995	Proceedings of Visualization 1995 Conference	10.1109/INFVIS.1995.528682	simulation;risk management;computer science;data mining;capital market;data visualization;3d computer graphics	Visualization	-25.25783702109343	-28.63817267455849	120485
c0bfe8ec3da211fc013652576f7ae3b0e1797a02	user-based active learning	uncertainty;active learning;training;interactive visualization;example labeling;information visualization;visualization active learning information visualization user behavior;data visualisation;visualization;visualization labeling uncertainty entropy training data visualization data models;user based visually supported active learning strategy;user selection strategy;data visualization;pattern classification;example selection;information visualization user based active learning data labeling pattern classification user based visually supported active learning strategy example selection example labeling interactive visualization classifier a posteriori output probability user selection strategy;entropy;user behavior;classifier a posteriori output probability;learning artificial intelligence;sampling methods;interactive systems;user based active learning;pattern classification data visualisation interactive systems learning artificial intelligence;data labeling;labeling;data models	Active learning has been proven a reliable strategy to reduce manual efforts in training data labeling. Such strategies incorporate the user as oracle: the classifier selects the most appropriate example and the user provides the label. While this approach is tailored towards the classifier, more intelligent input from the user may be beneficial. For instance, given only one example at a time users are hardly able to determine whether this example is an outlier or not. In this paper we propose user-based visually-supported active learning strategies that allow the user to do both, selecting and labeling examples given a trained classifier. While labeling is straightforward, selection takes place using a interactive visualization of the classifier's a-posteriori output probabilities. By simulating different user selection strategies we show, that user-based active learning outperforms uncertainty based sampling methods and yields a more robust approach on different data sets. The obtained results point towards the potential of combining active learning strategies with results from the field of information visualization.	active learning (machine learning);information visualization;interactive visualization;oracle database;sampling (signal processing);simulation;statistical classification	Christin Seifert;Michael Granitzer	2010	2010 IEEE International Conference on Data Mining Workshops	10.1109/ICDMW.2010.181	data modeling;sampling;entropy;labeling theory;margin;visualization;uncertainty;computer science;machine learning;pattern recognition;data mining;active learning;active learning;data visualization;statistics	ML	-26.19530509891747	-36.801696491033326	120762
0a77527a833faade3c29bf27d1eeaca4dfceca21	temporal visualization of planning polygons for efficient partitioning of geo-spatial data	time dependent attribute temporal visualization geospatial data partitioning resource allocation capacity time slices temporal data resource utilization utilization cost minimization multiattribute visualization comparative visualization multiple partition;long term effect;resource utilization;health care services;time dependent;town and country planning;spatial data;resource allocation;temporal data;temporal visualization;geographic information systems data visualisation town and country planning;data visualisation;complex data;visualization technique;visual representation;time dependent attributes;geographic information systems;time varying data;multi attribute visualization;dynamic adaptation;data visualization resource management displays educational institutions costs animation medical services chromium urban planning data analysis;temporal change;spatial partitioning	Partitioning of geo-spatial data for efficient allocation of resources such as schools and emergency health care services is driven by a need to provide better and more effective services. Partitioning of spatial data is a complex process that depends on numerous factors such as population, costs incurred in deploying or utilizing resources and target capacity of a resource. Moreover, complex data such as population distributions are dynamic i.e. they may change over time. Simple animation may not effectively show temporal changes in spatial data. We propose the use of three temporal visualization techniques -wedges, rings and time slices - to display the nature of change in temporal data in a single view. Along with maximizing resource utilization and minimizing utilization costs, a partition should also ensure the long term effectiveness of the plan. We use multi-attribute visualization techniques to highlight the strengths and identify the weaknesses of a partition. Comparative visualization techniques allow multiple partitions to be viewed simultaneously. Users can make informed decisions about how to partition geo spatial data by using a combination of our techniques for multi-attribute visualization, temporal visualization and comparative visualization.	carr–benkler wager;extrapolation;language weaver;larry laffer;mathematical optimization	Poonam Shanbhag;Penny Rheingans;Marie desJardins	2005	IEEE Symposium on Information Visualization, 2005. INFOVIS 2005.	10.1109/INFOVIS.2005.32	in situ resource utilization;simulation;resource allocation;computer science;space partitioning;data mining;database;spatial analysis;temporal database;programming language;data visualization;statistics;complex data type	Visualization	-26.51646498738691	-28.937986742490065	120793
7e68748b06796d789a4d38345cec38c1fc610089	reducing snapshots to points: a visual analytics approach to dynamic network exploration	biological patents;biomedical journals;topology data analysis data visualisation network theory graphs;text mining;europe pubmed central;dimensionality reduction visual analytics approach dynamic network exploration dynamic network analysis network snapshots network evolution stable state detection recurring state detection outlier topology discretization vectorization normalization;principal component analysis visual analytics animation manganese data visualization indexes;citation search;citation networks;dimensionality reduction dynamic networks exploration;manganese;indexes;dimensionality reduction;research articles;abstracts;principal component analysis;open access;animation;data visualization;life sciences;clinical guidelines;exploration;full text;visual analytics;rest apis;orcids;europe pmc;dynamic networks;biomedical research;bioinformatics;literature search	We propose a visual analytics approach for the exploration and analysis of dynamic networks. We consider snapshots of the network as points in high-dimensional space and project these to two dimensions for visualization and interaction using two juxtaposed views: one for showing a snapshot and one for showing the evolution of the network. With this approach users are enabled to detect stable states, recurring states, outlier topologies, and gain knowledge about the transitions between states and the network evolution in general. The components of our approach are discretization, vectorization and normalization, dimensionality reduction, and visualization and interaction, which are discussed in detail. The effectiveness of the approach is shown by applying it to artificial and real-world dynamic networks.	anomaly detection;automatic vectorization;cluster analysis;database normalization;dimensionality reduction;dimensions;discretization;dual;dynamic web page;graph - visual representation;imagery;inspiration function;leigh disease;nonlinear system;outlier;preparation;prototype;silo (dataset);snapshot (computer storage);t-distributed stochastic neighbor embedding;timeline fluoride releasing resin;visual analytics;statistical cluster	Stef van den Elzen;Danny Holten;Jorik Blaas;Jarke J. van Wijk	2016	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2015.2468078	computer vision;text mining;visual analytics;exploration;computer science;data science;manganese;machine learning;data mining;data visualization;dimensionality reduction;principal component analysis	Visualization	-27.527207824766204	-33.88572458807004	120870
78668a7adbdf5607141928575779da9cde2f1fef	beyond heuristics: learning visualization design		In this paper, we describe a research agenda for deriving design principles directly from data. We argue that it is time to go beyond manually curated and applied visualization design guidelines. We propose learning models of visualization design from data collected using graphical perception studies and build tools powered by the learned models. To achieve this vision, we need to 1) develop scalable methods for collecting training data, 2) collect different forms of training data, 3) advance interpretability of machine learning models, and 4) develop adaptive models that evolve as more data becomes available.	digital curation;graphical user interface;heuristic;holographic principle;machine learning;recommender system;scalability;test set	Bahador Saket;Dominik Moritz;Halden Lin;Victor Dibia;Çagatay Demiralp;Jeffrey Heer	2018	CoRR		human–computer interaction;visualization;computer science;scalability;design elements and principles;heuristics;training set;machine learning;interpretability;artificial intelligence	Visualization	-25.937966737776186	-35.86683589106849	121830
5c6b01c810ea69f5e3740d74efcea0fadd6ab0a2	progressive attribute editing for geological interpretation of remote sensing images	remote sensing materials xml rocks software databases;rocks remote sensing;remote sensing;progressive attribute editing module geological interpretation;rocks;interpretation processes remote sensing images step by step characteristic easy to difficult characteristic interpreted feature attributes reference materials field work feedback aconsequence interpreter geological interpreter attribute adjustments attribute transformations geological categories interpretation process geological interpretation typical characteristic ofa progressive attribute editing module design ofa progressive attribute editing module implementation interaction experience improvement	Step-by-step and from-easy-to-difficult are the outstanding characteristics of geological interpretationof remote sensing images. The interpretation results, especially the attributes of interpreted features, can be changed or adjusted on each step according to the reference materials and the field work feedback. As aconsequence, geological interpreters may make a lot of attribute adjustments and transformations among the geological categories during their interpretation process. Considering this typicalcharacteristicof geological interpretationof remote sensing images, in this article we introduce the design and implementation ofa progressive attribute editing module, which can improve interaction experience and make the interpretationprocesses more efficient.	field research;unsupervised learning	Hu Shao;Lun Wu;Yuan Tian;Yong Gao;Wei Kang	2013	2013 21st International Conference on Geoinformatics	10.1109/Geoinformatics.2013.6626108	computer vision;computer science;data mining;database	Robotics	-25.93594870768173	-32.078478655787976	122309
bb7368fe12f9a55359f20dbc08bd410d56a3d5a2	on the limits of positioning-based pedestrian risk awareness	pedestrian safety;localization;gps;augmented reality;smartphone	This paper studies the use of positioning techniques for sensing when pedestrians are at an increased risk of a traffic accident. Such sensing techniques could support augmented reality applications that increase pedestrian safety. We discuss requirements for pedestrian risk detection from rural to urban environments and consider algorithms relying on inertial and positioning sensors for distinguishing safe and unsafe walking locations. We study the limits of this approach through walking trials in different environments.	algorithm;augmented reality;requirement;sensor	Shubham Jain;Carlo Borgiattino;Yanzhi Ren;Marco Gruteser;Yingying Chen	2014		10.1145/2609829.2609834	simulation;engineering;transport engineering;computer security	HCI	-19.83348279368974	-27.916382886149545	122551
1ae9ae1938ac7bc4c20002b33f95f4d98e4989cf	first study on data readiness level		We introduce the idea of Data Readiness Level (DRL) to measure the relative richness of data to answer specific questions often encountered by data scientists. We first approach the problem in its full generality explaining its desired mathematical properties and applications and then we propose and study two DRL metrics. Specifically, we define DRL as a function of at least four properties of data: Noisiness, Believability, Relevance, and Coherence. The information-theoretic based metrics, Cosine Similarity and Document Disparity, are proposed as indicators of Relevance and Coherence for a piece of data. The proposed metrics are validated through a text-based experiment using Twitter	binocular disparity;computable function;computation;cosine similarity;data science;dd (unix);document-oriented database;driven right leg circuit;image;information theory;intellect;modality (human–computer interaction);relevance;text-based (computing)	Hui Guan;Thanos Gentimis;Hamid Krim;James Keiser	2017	CoRR		computer science;theoretical computer science;machine learning;data mining;database;world wide web;statistics	DB	-24.45380203303654	-32.26473226088089	122590
2628ef74935d0c2d54319bcaf43e734a456753bf	roles of an intelligent tutor agent in a virtual society	groupware;internet intelligent tutoring systems software agents groupware;social context;animated agent;software agent;social filtering;collaborative system;intelligent tutoring;software agents;internet;spatial distribution;intelligent tutoring systems;software animated agent intelligent tutor agent virtual society spatial distributed team agent mediated collaborative system group management role social filter algorithm;intelligent agent virtual groups software agents collaboration disaster management humans computer architecture coherence software algorithms cognitive science;mental model	In this paper we investigate how agents can facilitate and mediate interaction, communication and cooperation among participants of spatially distributed teams. We illustrate the architecture of an agent mediated-collaborative system that can serve the role of a tutor within a virtual group. In the virtual group the software agent should play besides the tutoring role also the group management role. The group manager has the responsibility to control the coherence of the actual group in regard to the actual group structure definition. This research will highlight also the incorporation of social-filter algorithms to mental models of software animated agents. Those algorithms may qualify an agent's expression of its emotional state by the social context, thereby enhancing the agent's believability not only as a tutor but also as a conversational partner or virtual teammate.	algorithm;computer animation;mental model;software agent	Bogdan-Florin Marin;Axel Hunger;Stefan Werner;Sorin Meila;Christian Schuetz	2005	The 2005 Symposium on Applications and the Internet	10.1109/SAINT.2005.55	agent architecture;human–computer interaction;embodied agent;computer science;knowledge management;autonomous agent;software agent;belief–desire–intention software model;multi-agent system;multimedia;intelligent agent;agent-based social simulation	AI	-31.688056681292586	-24.632941008129674	122772
6817470e8ae27f5c25be0f83a3ab71b70318d602	hypergraph modeling and visualisation of complex co-occurence networks		Finding inherent or processed links within a dataset allows to discover potential knowledge. The main contribution of this article is to define a global framework that enables optimal knowledge discovery by visually rendering co-occurences (i.e. groups of linked data instances attached to a metadata reference) either inherently present or processed from a dataset as facets. Hypergraphs are well suited for modeling co-occurences since they support multi-adicity whereas graphs only support pairwise relationships. This article introduces an efficient navigation between different facets of an information space based on hypergraph modelisation and visualisation.	2.5d;connected component (graph theory);graph partition;linked data	Xavier Ouvrard;Jean-Marie Le Goff;Stéphane Marchand-Maillet	2018	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2018.11.011	knowledge extraction;discrete mathematics;rendering (computer graphics);visualization;constraint graph;metadata;linked data;information space;hypergraph;theoretical computer science;mathematics	ML	-28.934585590651285	-34.945985432197126	123008
f69e1ba2b7cb1ddd866688e6d6007bc9e79b17fd	theory-guided data science for climate change	meteorology ocean temperature spatiotemporal phenomena temperature distribution;theory guided data science;climate change;data mining;data analysis;data analysis discovery analytics data mining big data scientific computing theory guided data science climate change;big data;scientific insights theory guided data science climate change data science methods spatiotemporal nature physical nature climate phenomena statistical analysis;scientific computing;discovery analytics;statistical analysis climate mitigation data handling scientific information systems	To adequately address climate change, we need novel data-science methods that account for the spatiotemporal and physical nature of climate phenomena. Only then will we be able to move from statistical analysis to scientific insights.	data science	James H. Faghmous;Arindam Banerjee;Shashi Shekhar;Michael Steinbach;Vipin Kumar;Auroop R. Ganguly;Nagiza F. Samatova	2014	Computer	10.1109/MC.2014.335	big data;computer science;data science;discovery science;data mining;data analysis;climate change	AI	-25.11941793814835	-30.837334243937654	123132
0d687fb6e1a54abf022990ace6c8f901be9f85e8	cooperative tracking of cyclists based on smart devices and infrastructure		In future traffic scenarios, vehicles and other traffic participants will be interconnected and equipped with various types of sensors, allowing for cooperation based on data or information exchange. This article presents an approach to cooperative tracking of cyclists using smart devices and infrastructure-based sensors. A smart device is carried by the cyclists and an intersection is equipped with a wide angle stereo camera system. Two tracking models are presented and compared. The first model is based on the stereo camera system detections only, whereas the second model cooperatively combines the camera based detections with velocity and yaw rate data provided by the smart device. Our aim is to overcome limitations of tracking approaches based on single data sources. We show in numerical evaluations on scenes where cyclists are starting or turning right that the cooperation leads to an improvement in both the ability to keep track of a cyclist and the accuracy of the track particularly when it comes to occlusions in the visual system. We, therefore, contribute to the safety of vulnerable road users in future traffic.		Günther Reitberger;Stefan Zernetsch;Maarten Bieshaar;Bernhard Sick;Konrad Doll;Erich Fuchs	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8569267	computer vision;smart device;simulation;artificial intelligence;yaw;information exchange;stereo camera;computer science	Robotics	-20.101890996302664	-28.112845127455724	123345
01400c47d4fef3efcf796f41b983ed5f5a1298bb	learning from lions: inferring the utility of agents from their trajectories		We build a model using Gaussian processes to infer a spatio-temporal vector field from observed agent trajectories. Significant landmarks or influence points in agent surroundings are jointly derived through vector calculus operations that indicate presence of sources and sinks. We evaluate these influence points by using the Kullback–Leibler divergence between the posterior and prior Laplacian of the inferred spatio-temporal vector field. Through locating significant features that influence trajectories, our model aims to give greater insight into underlying causal utility functions that determine agent decision-making. A key feature of our model is that it infers a joint Gaussian process over the observed trajectories, the timevarying vector field of utility and canonical vector calculus operators. We apply our model to both synthetic data and lion GPS data collected at the Bubye Valley Conservancy in southern Zimbabwe.	causal filter;eclipse;field research;gaussian process;global positioning system;https;kullback–leibler divergence;sparse matrix;synthetic data	Adam D. Cobb;Andrew Markham;Stephen J. Roberts	2017	CoRR		divergence;operator (computer programming);machine learning;computer science;vector field;artificial intelligence;vector calculus;gaussian process;synthetic data;laplace operator	ML	-20.423613690588763	-33.39556083128352	123346
0fd6737370e2fa8484969d1d5784a7e244964e32	statsplorer: guiding novices in statistical analysis	data analysis;inferential statistics;data visualization	Each step of statistical analysis requires researchers to make decisions based on both statistical knowledge and the knowledge of their own data. For novice analysts, this is cognitively demanding and can lead to mistakes and misinterpretations of the results. We present Statsplorer, a software that helps novices learn and perform inferential statistical tests. It lets the user kick-start data analysis from their research questions. Statsplorer automatically tests necessary statistical assumptions and uses visualizations to guide the user in both selecting statistical tests and interpreting the results. We compared Statsplorer with a statistics lecture and investigated how Statsplorer prepares novices for learning statistics in an AB/BA crossover experiment. The results indicates that using Statsplorer prior to the lecture leads to significantly better test scores in understanding statistical assumptions and choosing appropriate statistical tests. Statsplorer is open-source and is available online at: http://hci.rwth-aachen.de/statsplorer.	business architecture;inferential programming;music visualization;open-source software	Chat Wacharamanotham;Krishna Subramanian;Sarah Theres Völkel;Jan O. Borchers	2015		10.1145/2702123.2702347	statistical inference;statistical theory;computer science;data science;machine learning;data mining;data analysis;world wide web;data visualization	HCI	-25.223538950123057	-37.193005731972825	123455
267d858319c259ae9b566b990fea989f9a02449f	an interactive approach for inspecting software system measurements		In recent times, visual analysis has become increasingly important, especially in the area of software measurement, as most of the data from software measurement is multivariate. In this regard, standard software analysis tools are limited by their lack of ability to process huge collections of multidimensional data sets; current tools are designed to either support only well-known metrics or are too complicated to use for generating custom software metrics. Furthermore, the analyst requires extensive knowledge of the underlying data schemas and the relevant querying language. To address these shortcomings, we propose an interactive visual approach that focuses on visual elements, their configurations, and interconnectivity rather than a data ontology and querying language. In order to test and validate our methodology, we developed a prototype tool called VIMETRIK (Visual Specification of Metrics). Our preliminary evaluation study illustrates the intuitiveness and ease-of-use of our approach to understand software measurement and analysis data.	software system	Taimur Ahmed Khan;Henning Barthel;Karsten Amrhein;Achim Ebert;Peter Liggesmeyer	2015		10.1007/978-3-319-22698-9_1	visual approach;computer science;interactive visual analysis;software system;software visualization;software analysis pattern;human–computer interaction;data mining;ontology-based data integration;software measurement;custom software	SE	-30.023203441491667	-31.18331785044694	123621
24825a4514023c9ca5231a463dfc8b7e61ca412b	graph drawing aesthetics in user-sketched graph layouts	graph drawing;graph aesthetics;graph layout;point of view;sketching;graph drawing creation	Empirical work on appropriate layout aesthetics for graph drawing algorithms has concentrated on the interpretation of existing graph drawings. A more recent experiment has considered layout aesthetics from the point of view of users moving nodes in an existing graph drawing so as to create a desirable layout. The project reported here extends this research further, by asking participants to use sketching software to draw graphs based on adjacency lists, and to then lay them out – removing any bias caused by an initial configuration. We find, in common with many other studies, that removing edge crossings is the most significant aesthetic, but also discover that aligning nodes and edges to an underlying grid is important, especially to male participants who have Computer Science experience. We observe that the aesthetics favoured by participants during creation of a graph drawing are often not evident in the final product.	adjacency list;algorithm;computer science;graph drawing;vector graphics editor;yang	Helen C. Purchase;Beryl Plimmer;Rosemary Baker;Christopher Pilcher	2010			computer science;theoretical computer science;force-directed graph drawing;graph;graph drawing	HCI	-29.91499329546339	-36.41612930489038	123639
332415a1cd88fab6c90d4a1670941a6005dfa205	geoplot: an excel vba program for geochemical data plotting	computadora;tratamiento datos;computers;discrimination diagram;tierras raras;spidergram;ordinateur;riolita;roche ultramafique;terre rare;data processing;roche ignee;traitement donnee;roca ignea;igneous rocks;roche plutonique;roche volcanique;computer programs;roca granuda;triangular plot;cipw;volcanic rocks;spilite;rare earths;ultramafics;gabbros;rhyolites;gabbro;plutonic rocks;rhyolite;programa computador;roca volcanica;x y plot;programme ordinateur;gabro	Microsoft Excel is a spreadsheet application widely used by geochemists for data storage and manipulation. It has limited functionality for geochemists as only manual data organization and basic X–Y plots are available for data interpretation. Consequently some software packages such as MinPet (Richard, 1997), Igpet (Carr, 1995), Newpet (Clarke, 1993) and PETROGRAPH (Petrelli, 2003) have been developed for better data visualization and interpretation. However, all these programs only have access to the plot functionalities that are not directly linked to a spreadsheet. The programs require the data set in the Excel format to be imported or converted to an external file with certain formats, and this procedure has to be repeated every time the data set is updated. In addition, these programs have many discrimination diagrams but users cannot customize or add new ones. Although several previous Excel macro programs are capable of plotting X–Y plots and triangular plots (e.g., Sidder, 1994; Christie and Langmuir, 1994; Marshall, 1996), they cannot meet the need of today’s geochemists using an advanced computer system. The program PetroPlot of Su et al. (2003) has the plotting functions of multi-series X–Y plots and spider diagrams. However, it cannot deal with the	carr–benkler wager;code;computer data storage;data visualization;diagram;edmund m. clarke;spreadsheet;visual basic for applications;volcano plot (statistics);yao graph	Jibin Zhou;Xianhua Li	2006	Computers & Geosciences	10.1016/j.cageo.2005.07.005	mining engineering;gabbro;data processing;geology;paleontology;mineralogy	PL	-27.91002945849094	-29.030180746323698	124058
af8028d8869e16312ab54380ac2b29753233fefa	exploring web site log data with a multi-classification interface	graph theory;structured graph viewer;graph theory data visualisation web sites very large databases graphical user interfaces tree data structures online front ends;web site visitor address dimension;information technology;information filtering;multidimensional data;multidimensional data set;tree data structures;interface design;data mining;online front ends;data visualisation;graphical user interfaces;machine learning;multiclassification interface;sgviewer tool;relational databases multidimensional systems data visualization visual databases information technology australia information filtering information filters data mining machine learning;web site referrer address dimension;configurable nested tree visualisation;web sites;data visualization;web site log data exploration;configurable nested tree visualisation web site log data exploration multiclassification interface multidimensional data set structured graph viewer sgviewer tool web site download dimension web site visitor address dimension web site referrer address dimension;relational databases;web site download dimension;very large databases;information filters;multidimensional systems;australia;visual databases	Many interface designs have been developed for the exploration of multidimensional data sets, many based on finding subsets by filtering attribute values independently or successively. However, many of these interfaces do not also support the use of hierarchies for selection and summarisation. We show how an interface that uses coordinated hierarchy views of data supports the exploration of such data. Our interface is demonstrated with our SGViewer tool and a Web site log dataset where visits to a Web site have been organised into time, downloads, visitor address and referrer address dimensions. A configurable nested tree visualisation is used to present each dimension hierarchy. We show how both rapid and flexible exploration of this data is supported by our interface.		Mark Sifer	2003		10.1109/IV.2003.1217963	computer science;data mining;database;world wide web	DB	-29.63245525818148	-33.17187156397462	124145
b468486d8c28e6e5744e2892e35340777d1ad316	assisting human cognition in visual data mining	statistical approach;human cognition;data representation;visual data mining;analytical method;visual analysis;statistical techniques;chapter	As discussed in Part 1 of the book in chapter “Form-SemanticsFunction – A Framework for Designing Visualisation Models for Visual Data Mining” the development of consistent visualisation techniques requires systematic approach related to the tasks of the visual data mining process. Chapter “Visual discovery of network patterns of interaction between attributes” presents a methodology based on viewing visual data mining as a “reflection-inaction” process. This chapter follows the same perspective and focuses on the subjective bias that may appear in visual data mining. The work is motivated by the fact that visual, though very attractive, means also subjective, and non-experts are often left to utilise visualisation methods (as an understandable alternative to the highly complex statistical approaches) without the ability to understand their applicability and limitations. The chapter presents two strategies addressing the subjective bias: “guided cognition” and “validated cognition”, which result in two types of visual data mining techniques: interaction with visual data representations, mediated by statistical techniques, and validation of the hypotheses coming as an output of the visual analysis through another analytics method, respectively.	cognition;data mining	Simeon J. Simoff;Michael H. Böhlen;Arturas Mazeika	2008		10.1007/978-3-540-71080-6_17	computer vision;visual analytics;interactive visual analysis;computer science;data science;data mining	HCI	-25.839870621216225	-35.40293231255653	124346
0a4496956926a81060fe18e20bd154266df25cce	code checking and visualization of an architecture design	future;architectural design;design automation;application software;computer graphics;government;data mining;visualization;internet;data mining buildings data visualization containers design automation valves computer graphics application software government internet;data visualization;techniques;valves;buildings;containers;hardware	Computer graphics has be successfully applied to architecture design. There is more demand to new applications. One of them, to be addressed in this work, is the code checking and visualization of the checking results.	computer graphics	Rong Xu;Wawan Solihin;Zhiyong Huang	2004	IEEE Visualization 2004	10.1109/VISUAL.2004.14	model checking;application software;visualization;computer science;operating system;database;computer graphics;data visualization;government	Visualization	-32.70792122630472	-29.782870601427234	124353
f86f9c2fe7f384d44e5d96eb01a984061332bcc8	spatial-temporal analysis of human dynamics on urban land use patterns using social media data by gender		The relationship between urban human dynamics and land use types has always been an important issue in the study of urban problems in China. This paper used location data from Sina Location Microblog (commonly known as Weibo) users to study the human dynamics of the spatial-temporal characteristics of gender differences in Beijing’s Olympic Village in June 2014. We applied mathematical statistics and Local Moran’s I to analyze the spatial-temporal distribution of Sina Microblog users in 100 m × 100 m grids and land use patterns. The female users outnumbered male users, and the sex ratio (SR varied under different land use types at different times. Female users outnumbered male users regarding residential land and public green land, but male users outnumbered female users regarding workplace, especially on weekends, as the SR on weekends (SR was 120.5) was greater than that on weekdays (SR was 118.8). After a Local Moran’s I analysis, we found that High–High grids are primarily distributed across education and scientific research land and residential land; these grids and their surrounding grids have more female users than male users. Low–Low grids are mainly distributed across sports centers and workplaces on weekdays; these grids and their surrounding grids have fewer female users than male users. The average number of users on Saturday was the highest value and, on weekends, the number of female and male users both increased in commercial land, but male users were more active than female users (SR was 110).		Chengcheng Lei;An Zhang;Qingwen Qi;Huimin Su;Jianghao Wang	2018	ISPRS Int. J. Geo-Information	10.3390/ijgi7090358	land use;demographic economics;microblogging;china;human dynamics;beijing;social media;business	HCI	-19.166739325131058	-33.54970723126779	124813
bf99796ecf198a41da50af3d416599fa5494b2ff	modelling the safety of a semi-autonomous wheelchair	analytical models;hazards wheelchairs unified modeling language mobile robots analytical models;hazards;mobile robots;safety analysis semiautonomous wheelchair robot safety information text based formats model based format safeml modelling language;wheelchairs control engineering computing handicapped aids medical robotics mobile robots;unified modeling language;wheelchairs	Safety is important to a robot that is used in a way that can impact on the wellbeing of people. However, understanding and managing the safety information of a robot is not a trivial task. The quantity of this information is large, and it is usually stored in text-based formats. These factors mean that maintaining safety information when it changes is error prone, and understanding it requires manually searching through lengthy reports. In this paper, we demonstrate that a robot's safety information can be stored in a model-based format. We use the SafeML modelling language to model the results of a safety analysis performed on a semi-autonomous wheelchair. We then illustrate and discuss the benefits of storing and managing safety information using a model, both to maintainability of the information and to understanding the safety of the robot.	autonomous robot;cognitive dimensions of notations;modeling language;natural language;robotics;semiconductor industry;text-based (computing)	Geoffrey Biggs;Takuya Ogure;Kiyoshi Fujiwara;Yoshihiro Nakabo;Tetsuo Kotoku	2015	2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2015.7354041	mobile robot;unified modeling language;computer vision;simulation;hazard;computer science;engineering;artificial intelligence	Robotics	-24.91283018957481	-27.105386953549903	124870
8b58870f48c0b87799411c0063a78abd6465bff0	integrating spatial data display with virtual reconstruction	dato observacion;vision ordenador;representation graphique;solid modeling computer graphics data visualization application software computer displays rendering computer graphics animation geometry winches military computing;aplicacion;visualizacion;spatial data;spatial data display;computer graphics;representacion grafica;virtual reconstruction;virtual reality;archaeology;integration;data distribution;computer graphic;computer vision;data visualisation;reconstruction image;visualization;archaeological visualization;visualisation;imagen virtual;reconstruccion imagen;spatial distribution;three dimensional displays;integracion;image reconstruction;arqueologia;image virtuelle;usage areas spatial data display virtual site reconstruction archaeological excavations 3d data artifact data layering artifact distribution computer graphics techniques environmental context site architecture prehistoric pithouse;vision ordinateur;virtual reality archaeology architecture data visualisation three dimensional displays;donnee observation;application;observed data;grafico computadora;architecture;infographie;virtual image;graphics;archeologie	Archaeological excavations record a vast amount of 3D data. Layering artifact data on a virtual reconstruction of a site helps correlate the distribution of artifacts with their proximity to structural features. In the case presented in this article, we describe how computer graphics techniques make it possible to incorporate the display of artifact data distributions into the structural and environmental context of site architecture (specifically, a prehistoric pithouse). We have found that visualizing excavation data in this manner can help identify the implications of architectural constraints on usage areas as well as spatial distribution of artifacts with respect to significant site features. >		Philip Peterson;F. David Fracchia;Brian Hayden	1995	IEEE Computer Graphics and Applications	10.1109/38.391489	computer vision;visualization;human–computer interaction;computer science;architecture;virtual reality;data visualization;computer graphics (images)	Visualization	-29.217012622731406	-33.46894293490184	125099
d3cd0f91b8a809ea80c62e363e9e977e8d7180ff	traffic modeling software for ivhs applications	civil engineering computing;digital simulation;road traffic;town and country planning;traffic computer control;ivhs applications;traf system;advanced driver information system;advanced traffic management system;advanced vehicle control systems;commercial vehicle operations;corridor networks;freeways;highway system operation;management techniques;real-time traffic management systems;surface streets;traffic engineering modeling software;urban planning	Intelligent Vehicle/Highway Systems (IVHS) is an an ambitious multi-year, multi-billion research/demonstration program which aims at improving the vehicle/highway system operation and management techniques for the post-interstate construction era. The main goal of the IVHS program, which will carry the Federal Highway Administration into the 21st century, is to develop the state of the art vehicle/highway management, information and control systems which will effectively combat congestion and succeed in providing an increased level of safety, mobility, driver convenience and environmental quality in both rural and urban areas. This paper begins with an introduction of the framework of IVHS which has four major components: 1) Advanced Traffic Management System (ATMS); 2) Advanced Driver Information System (ADIS); 3) Commercial Vehicle Operations (CVO); and 4) Advanced Vehicle Control Systems (AVCS) and emphasizes the ATMS related research and development plans to support the realtime traffic management systems and control strategies. This paper then reviews the state of art traffic engineering modeling software currently available from FHWA. The discussion centers around the TRAF system a family of microscopic and macroscopic traffic simulation software models for surface streets, freeways, and corridor networks. The gap between the capabilities provided by the current traffic modelling software and the functional requirement of the IVHS traffic models are also addressed in the paper. The paper concludes by outlining the work that needs to be done in order to fully support the IVHS program.	ccir system a;computer scientist;control system;electrical engineering;functional requirement;information and computation;information system;management system;mathematical optimization;network congestion;simulation software	Alberto J. Santiago;Hobih Chen	1990			environmental quality;active traffic management;application software;simulation;computer science;engineering;control system;technical report;automotive engineering;management system;transport engineering;functional requirement;advanced traffic management system;information system	Robotics	-21.537494508366898	-24.435826436283794	125331
f4f31f452c139d58b728b3e2fb3f792114083ee9	post-processing strategies for the ecmwf model		Climate models are steadily evolving towards higher resolution and the upcoming model inter-comparison projects require an unprecedented number of produced variables. As a consequence, the post-processing of the output of these models start to form a bottleneck for CMIP experiments. We discuss how the ece2cmor3 tool processes the EC-Earth model output in parallel, and present a new coupling of the ECMWF weather model to the XIOS library to allow on-the-fly post-processing of its atmospheric fields.		Gijs Van Den Oord;Xavier Yepes;Mario Acosta	2018	2018 IEEE 14th International Conference on e-Science (e-Science)	10.1109/eScience.2018.00121	computer science;distributed computing;atmospheric model;data modeling;server;bottleneck;climate model	DB	-24.369162060614904	-30.534702659829865	125477
7210420b28daeecaf31f650f62c6d91d05034b00	on the usage patterns of multimodal communication: countries and evolution	chinese users multimodal communication usage patterns phone calls text messages chinese city san francisco area communication modes after lunch siesta;cellular radio;mobile radio;electronic messaging;pattern recognition;correlation internet telecommunications measurement cultural differences pricing electronic mail;usage patterns text messages phone calls multimodal communication;pattern recognition cellular radio electronic messaging;mobile radio electronic messaging	How do people use phone calls and text messages for their communication needs? Most studies so far study each mode of communication in isolation. Here, we study the interplay of multi-modal communications. We analyze more than a billion call and text records from a Chinese city and San Francisco Area between 2007 and 2011. First, we provide some definitions towards a framework for analyzing multi-modal communications. Then,we study the relationship of the two communication modes and quantify several aspects of correlation and inference. For a communicating pair, we find that the existence of texting during the weekend is the strongest indicator that the pair will communicate at other times with texts or calls. We compare the behavior between China and the U.S. and we find several similarities and differences. For example, we find evidence of an after-lunch siesta among Chinese users. Finally, we study the evolution of the two modes over time. We find that texting has taken over in sheer number of ”events” by flipping the number of calls over that of texts from 2: 1 in 2007 to 1:2 in 2011.	british undergraduate degree classification;mobile phone;modal logic;multimodal interaction;network science cta;preemption (computing)	Yi Wang;Michalis Faloutsos;Hui Zang	2013	2013 Proceedings IEEE INFOCOM	10.1109/INFCOMW.2013.6562859	telecommunications;computer science;multimedia;world wide web;computer network	NLP	-19.77331478672406	-35.27014676982335	125488
5d19c706c389f19b3ced9754b57d7a64fc9386e8	social media and mobility landscape: uncovering spatial patterns of urban human mobility with multi source data		In this paper, we present a three-step methodological framework, including location identification, bias modification, and out-of-sample validation, so as to promote human mobility analysis with social media data. More specifically, we propose ways of identifying personal activity-specific places and commuting patterns in Beijing, China, based on Weibo (China's Twitter) check-in records, as well as modifying sample bias of check-in data with population synthesis technique. An independent citywide travel logistic survey is used as the benchmark for validating the results. Obvious differences are discerned from Weibo users' and survey respondents' activity-mobility patterns, while there is a large variation of population representativeness between data from the two sources. After bias modification, the similarity coefficient between commuting distance distributions of Weibo data and survey observations increases substantially from 23% to 63%. Synthetic data proves to be a satisfactory cost-effective alternative source of mobility information. The proposed framework can inform many applications related to human mobility, ranging from transportation, through urban planning to transport emission modelling.	benchmark (computing);coefficient;jaccard index;social media;source data;synthetic data	Yilan Cui;Xing Xie;Yi Liu	2018	CoRR		chemistry;data integration;representativeness heuristic;data science;inorganic chemistry;spatial ecology;beijing;social media;sampling bias;population;urban planning	HCI	-19.556132376075592	-33.555731292088886	125946
36ca7c949ed6455d0cb41dba37034bcefe45f300	vispol: an interactive tabletop graph visualization for the police	graphs;information visualization	Vispol (Visualization for the police) is an interactive graph-based visualization that supports the work of the police of Hessen, Germany. A Vispol graph visualizes involved persons and their relations in crisis incidents like hostage takings or bank hold-ups. It presents a tabletop-based multi-touch and tangible user interface for the structured creation and manipulation of node-link diagrams. For instance, persons can be stamped into a graph with a stamp tangible object and links can be established employing multi-touch gestures. The graph can be visually filtered by applying layout algorithms via layout tangibles or by using a tangible magnet metaphor. We presented Vispol to the police to gather qualitative feedback. The police appreciated the visualization and generally liked the approach to use a multi-touch and tangible user interface. However, when it came to interacting with the tabletop system, police officers acted very cautiously and hesitatingly, as they were afraid of the new technology.	algorithm;basic stamp;context (computing);diagram;graph (discrete mathematics);graph drawing;information visualization;interaction technique;multi-touch;tangible user interface;usability testing	Johannes Luderschmidt;Ralf Dörner;Melanie Seyer;Frederic Frieß;Rudi Heimann	2012			human–computer interaction;visual analytics;multimedia;visualization;graph drawing;tangible user interface;interactive visualization;information visualization;multi-touch;gesture;computer science	HCI	-31.048910615004203	-35.13906356648407	126450
303337fd6d65d8ff4d74b1bf6cb5f76aa286717e	crime mapping through geo-spatial social media activity	crime analysis;big data;business intelligence;social media;spatial statistics	The presence of crime is one of the major challenges for societies all over the World, especially in metropolitan areas. As indicated by prior research, Information Systems can contribute greatly to cope with the complex factors that influence the emergence and location of delinquencies. In this work, we combine commonly used approaches of static environmental characteristics with Social Media. We expect that blending in such dynamic information of public behavior is a valuable addition to explain and predict criminal activity. Consequently, we employ Zero-Inflated Poisson Regressions and Geographically Weighted Regressions to examine how suitable Social Media data actually is for this purpose. Our results unveil geographic variation of explanatory power throughout a metropolitan area. Furthermore, we find that Social Media works exceptionally well for description of certain crime types and thus is also likely to enhance the accuracy of delinquency prediction.	alpha compositing;crime mapping;dummy variable (statistics);emergence;guinness world records;hotspot (wi-fi);information systems;information system;kernel density estimation;kerrison predictor;larceny;latent dirichlet allocation;point of interest;poisson regression;population;sentiment analysis;social media;social presence theory;spatial analysis	Johannes Bendler;Antal Ratku;Dirk Neumann	2014			public relations;social science;big data;social media;computer science;artificial intelligence;marketing;spatial analysis;business intelligence;management;law;world wide web;computer security	HCI	-20.442828554491363	-34.47387662818928	126539
6722b5e19f7c93c09bb80366adab311d107ab759	enhancing computer forensics investigation through visualisation and data exploitation	computers;domain knowledge processing computer forensics data visualisation systems data analysis techniques digital evidence data exploitation techniques normalisation techniques;computer forensics;application software;domain knowledge processing;security of data data analysis data visualisation;data mining;data exploitation;event correlation;digital evidence computer forensics visualisation data exploitation visual data analysis;domain knowledge;data visualisation;computer architecture;data analysis;visualization;visualisation;visual representation;portable computers;data visualization;computer displays;digital evidence;data exploitation techniques;humans;data visualisation systems;data analysis techniques;forensics data visualization data analysis computer architecture application software humans australia computer displays data mining portable computers;security of data;context;normalisation techniques;forensics;australia;visual data analysis	This paper focuses on establishing the need for new architectures on which to build visualisation systems that enhance computer forensic investigation of digital evidence. The issues surrounding processing of large quantities of digital evidence are established. In addition, the current state of visualisation and data analysis techniques for computer forensics are highlighted. This paper suggests need for new visualisation techniques in order to display data in familiar visual forms that facilitate efficient insight gaining into digital evidence. Visualisations techniques also require a source of processed data that contains context relevant information to present to an investigator. To this end this paper introduces the notion of data exploitation as a way to describe techniques that provide opportunistic data analysis across multiple sources of digital evidence. Data exploitation techniques provide normalisation techniques, event correlation, relationship extraction and investigative domain knowledge processing to occur across a set of evidence. This enables a visual representation of digital evidence to highlight relationships and events across many data sources, support an investigator throughout the entire data analysis process and enable an investigator to focus on the context of the current crime.	computer forensics;event correlation;relationship extraction	Grant Osborne;Benjamin Turnbull	2009	2009 International Conference on Availability, Reliability and Security	10.1109/ARES.2009.120	computer science;data science;data mining;world wide web	DB	-29.137285442255628	-30.36646716966411	126558
01fc860da6c813c981f1624938e70d2a390bedfb	can mobile usage predict illiteracy in a developing country?		The present study provides the first evidence that illiteracy can be reliably predicted from standard mobile phone logs. By deriving a broad set of mobile phone indicators reflecting users’ financial, social and mobility patterns we show how supervised machine learning can be used to predict individual illiteracy in an Asian developing country, externally validated against a large-scale survey. On average the model performs 10 times better than random guessing with a 70% accuracy. Further we show how individual illiteracy can be aggregated and mapped geographically at cell tower resolution. Geographical mapping of illiteracy is crucial to know where the illiterate people are, and where to put in resources. In underdeveloped countries such mappings are often based on out-dated household surveys with low spatial and temporal resolution. One in five people worldwide struggle with illiteracy, and it is estimated that illiteracy costs the global economy more than $1 trillion dollars each year [1]. These results potentially enable costeffective, questionnaire-free investigation of illiteracy-related questions on an unprecedented scale.	machine learning;mobile phone;supervised learning;verification and validation	Pål Sundsøy	2016	CoRR			HCI	-19.411370713726356	-34.266381204359824	126823
b8a0b3852627b083ba9922702838cd09782b09d1	interactive service for visualizing data association using a self-organizing structure of schemas		One way to visualize the association of semi-structured data is to show the structure of its schemas. We developed an interactive service system using of a method for self-organizing schema structure, an application of self-organizing mapping. A graph structure is generated by estimating data association as a link between field names in relational tables. This facilitates exploratory visualization in data lakes. Experiment results obtained with a prototype system demonstrated the method's practicability.	correspondence problem;organizing (structure);prototype;self-organization;self-organizing map;semi-structured data;semiconductor industry	Takaaki Yamada;Yuko Kato;Yuki Maekawa;Tomoe Tomiyama	2017	2017 IEEE 10th Conference on Service-Oriented Computing and Applications (SOCA)	10.1109/SOCA.2017.39	database;data visualization;data integration;computer science;visualization;distributed computing;big data;metadata;schema (psychology);service system;graph	Visualization	-26.80087352952979	-30.151861204453628	126932
7751a1c50cbb4714cc3dd4ebd5d6b1f502691297	server-based intelligent public transportation system with nfc		Mass transit systems have existed for over a century. In the traditional payment structure, tickets, cards and tokens are used for public transportation. Discounts for specific type of riders and benefits coming with transfer fee are only available with cards specifically designed for each city. Balances are kept on fare media, and the cost of ride is calculated and deducted by the validators while getting on the vehicle. This paper proposes a novel serverbased fare calculation and user management system for providing personalized exclusive privileges to riders without getting the special card of the province and allows passengers to benefit from all the advantages of the cities' transport pricing. In addition, it removes the obstacles that prevent the use of new technologies such as contactless bank cards and Near Field Communication (NFC) standard like a traditional province card in public transport. The installation of the system with NFC usage was applied on five different cities in Turkey. By collecting and analyzing real-world data, the association rules were found for the proposed system using FP-Growth algorithm as a data mining technique. This paper also presents a comparison of the proposed system with the existing systems to show its advantages.	algorithm;association rule learning;cluster analysis;contactless smart card;data mining;futures studies;interoperability;mobile app;near field communication;personalization;server (computing);validator	Ufuk Demir Alan;Derya Birant	2018	IEEE Intelligent Transportation Systems Magazine	10.1109/MITS.2017.2776102	simulation;smart card;engineering;public transport;management system;near field communication;association rule learning;intelligent transportation system;payment	Robotics	-22.573665780564582	-28.91517937176527	127106
46bf85c600df04ced9117347053f622fca89fdce	leavenow: a social network-based smart evacuation system for disaster management		The importance of timely response to natural disasters and evacuating affected people to safe areas is paramount to save lives. Emergency services are often handicapped by the amount of rescue resources at their disposal. We present a system that leverages the power of a social network forming new connections among people based on real-time location and expands the rescue resources pool by adding private sector cars. We also introduce a car-sharing algorithm to identify safe routes in an emergency with the aim of minimizing evacuation time, maximizing pick-up of people without cars, and avoiding traffic congestion.	algorithm;network congestion;real-time transcription;social network	Ziyuan Wang;Jianbin Tang;Yini Wang;Bo Han;Xi Liang	2016	CoRR		simulation;computer security	HCI	-20.25805524006335	-26.799982452054223	127148
526494866c15e8d1a417e4995f7a8daa26cc4424	experiencing optiquevqs: a multi-paradigm and ontology-based visual query system for end users	visual query systems;journal article;peer reviewed;ontology based data access;visual query formulation;data retrieval	Data access in an enterprise setting is a determining factor for value creation processes, such as sense-making, decision-making, and intelligence analysis. Particularly, in an enterprise setting, intuitive data access tools that directly engage domain experts with data could substantially increase competitiveness and profitability. In this respect, the use of ontologies as a natural communication medium between end users and computers has emerged as a prominent approach. To this end, this article introduces a novel ontology-based visual query system, named OptiqueVQS, for end users. OptiqueVQS is built on a powerful and scalable data access platform and has a user-centric design supported by a widget-based flexible and extensible architecture allowing multiple coordinated representation and interaction paradigms to be employed. The results of a usability experiment performed with non-expert users suggest that OptiqueVQS provides a decent level of expressivity and high usability and hence is quite promising.	computer;data access;ontology (information science);programming paradigm;scalability;sensemaking;usability;usability testing	Ahmet Soylu;Martin Giese;Ernesto Jiménez-Ruiz;Guillermo Vega-Gorgojo;Ian Horrocks	2015	Universal Access in the Information Society	10.1007/s10209-015-0404-5	peer review;human–computer interaction;computer science;operating system;data mining;world wide web;data retrieval;information retrieval	HCI	-30.774161696834394	-32.995777550786144	127780
55e03433d0234e58987c63c4f5db92de2bf86305	individual movements and geographical data mining. clustering algorithms for highlighting hotspots in personal navigation routes	kernel density estimation;gps traces;dbscan;activity dairy data	The rapid developments in the availability and access to spatially referenced information in a variety of areas, has induced the need for better analysis techniques to understand the various phenomena. In particular our analysis represents a first insight into a wealth of geographical data collected by individuals as activity dairy data. The attention is drawn on point datasets corresponding to GPS traces driven along a same route in different days. Our aim here is to explore the presence of clusters along the route, trying to understand the origins and motivations behind that in order to better understand the road network structure in terms of 'dense' spaces along the network. In this paper the attention is therefore focused on methods to highlight such clusters and see their impact on the network structure. Spatial clustering algorithms are examined (DBSCAN) and a comparison with other non-parametric density based algorithm (Kernel Density Estimation) is performed. A test is performed over the urban area of Trieste (Italy).	algorithm;data mining	Gabriella Schoier;Giuseppe Borruso	2011		10.1007/978-3-642-21928-3_32	kernel density estimation;computer science;data science;machine learning;data mining;dbscan;statistics	ML	-19.164165462685435	-34.93825311822096	128002
3acf5c561a2e83933ba77581e97f768d9e186869	two years before the mist: experiences with aquanet	multicard;technology assessment;data model;hypermedia toolkit	Aquanet is a collaborative hypertext tool that combines elements of frame-based knowledge representation and graphical presentation. In this paper, we examine the first major application of the tool in an analysis task, a two year long technology assessment that Rsulted in ahnost 2000 nodes and more than 20 representational types. First, we cover the implications of the representational resourees provided and representational deeisions that were made. Then we discuss how spatial layout was used in lieu of the complex relations Aquanet’s data model supports. Finally, we show how distinct regions emerged to refleet particular activities and how they were subsequently used as the basis for a later collaboration on a Similar task. 1 Overview: The tool and the task Aquanet is a collaborative hypertext tool designed to meet the needs of knowledge structuring tasks like analysis and argumentation. The tool combines elements of frame-based knowledge representation and graphical presentatio~ it has its roots in gIBIS [4], Germ [3], NoteCards [5], and IDE [15]. This paper examines how Aquanet was used in a large application, a multi-year assessment of a specific area of researeh and technology development. This type of analysis is common in business intelligence and other kinds of information-intensive interpretive processes. Permission to copy without fee all or part of this material is granted provided that copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is givem that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to repubtish, requires a fee and/or specific permission. @1992 ACM 0-89791-547-X/92/OOll/O053/ $1.50 1.1 Hypertext to keep your knowledge in place Aquanet enables people to describe a domain of discourse in terms of basic objects and how they are interrelated (relations). For example, in an evaluation of a computer technology, one type of basic objeet might be a “system,” and another type might be a “developer.” These two elements might be connected by an “implemented” relation. Instances of these types can then be manipulated in a shared information space. The structures that may be built within any particular information space are specified by a schema, a collection of Aquanet basic object and relation types. [10] presents a more extensive description of the tool and its data model. Figure 1 shows a limited view of a much larger Aquanet information space. A user can zoom or scroll this view to see more of the space, which can extend in all directions. Objects shown in the primary view are drawn according to a user-specified graphic appearance that is associated with each type of basic object and relation. For example, the seleetion an instance of a System object is portrayed on the computer screen as purple rectangle that displays the object’s name, which in this ease is “Atlas.” As is apparent in the figure, objects may overlap, users can manipulate the stacking order to see obscured objects. In Figure 1, the view onto the information space is partially obscured by a separate scrollable window that shows the selected System’s internal structure, its slots. In this ease, the slots “Name,” “Commercial?: “Language-pairs,” and “Performance Data” and their values are visible in the smaller window. Like many other spatially-oriented systems, the Aquanet information space can contain multiple references to the same object. We call these references virtual copies. All of the copies share the same graphic appearance, and when one is selected, all visible copies are highlighted. This mechanism becomes important in our later discussion of informal relations. 54 ACM ECHT CONFERENCE Figure 1. A portion of an Aquanet main view with a separate window onto the contents of a node.	computer monitor;data model;database schema;domain of discourse;graphical user interface;hypertext;integrated development environment;knowledge representation and reasoning;notecards;relation (database);roots;stacking	Catherine C. Marshall;Russell A. Rogers	1992		10.1145/168466.168490	human–computer interaction;data model;computer science;database;world wide web;technology assessment	HCI	-32.37934276769184	-31.096120930388423	128622
b9e32c564540b17d571e5edf30f4429a822dfbbb	peeling the flow: a sketch-based interface to generate stream surfaces	seeding curves;stream surfaces;sketch based interface;flow visualization	We present a user-centric approach for stream surface generation. Given a set of densely traced streamlines over the flow field, we design a sketch-based interface that allows users to draw simple strokes directly on top of the streamline visualization result. Based on the 2D stroke, we identify a 3D seeding curve and generate a stream surface that captures the flow pattern of streamlines at the outermost layer. Then, we remove the streamlines whose patterns are covered by the stream surface. Repeating this process, users can peel the flow by replacing the streamlines with customized surfaces layer by layer. Our sketch-based interface leverages an intuitive painting metaphor which most users are familiar with. We present results using multiple data sets to show the effectiveness of our approach, and discuss the limitations and future directions.	adobe streamline;densely packed decimal;streamsurface	Jun Tao;Chaoli Wang	2016		10.1145/3002151.3002158	flow visualization;computer science;theoretical computer science;computer graphics (images)	HCI	-29.91769433827902	-34.660144039129044	128887
63c7c1c9df4eb115464d21af9bcd5197844ee904	map-centred exploratory approach to multiple criteria spatial decision making	decision models;decision support;decision support tool;geographic information system;multiple criteria;data mining;decision problem;spatial decision support;group decision making	Spatial decision support is one of the central functions ascribed to Geographical Information Systems (GIS). One of the foci of developing decision support capabilities of GIS has been the integration of maps with multiple criteria decision models. Progress in this area has been slow due to a limited role played by maps as decision support tools. In this paper we present new prototype spatial decision support tools emphasising the role of maps as a source of structure in multiple criteria spatial decision problems. In these tools the role of map goes beyond the mere display of geographic decision space and multicriterion evaluation results. Maps becomes a ‘visual index’ through which the user orders decision options, assigns priorities to decision criteria, and augments the criterion outcome space by map-derived heuristic knowledge. As the additional means of structuring multicriterion spatial decision problems we present an experimental use of data mining, integrated with dynamic maps and multiple criteria decision models, in order to reduce a problem’s dimensionality. We conclude the paper with future research directions emphasising map-based support for group decision making.	algorithm;cognitive complexity;data mining;decision analysis;decision problem;decision support system;encode;electronic organizer;exploit (computer security);geographic information system;heuristic (computer science);high-level programming language;interactive proof system;interactivity;kepler;level of measurement;map;parallel coordinates;performance;prototype	Piotr Jankowski;Natalia V. Andrienko;Gennady L. Andrienko	2001	International Journal of Geographical Information Science	10.1080/13658810010005525	decision model;r-cast;group decision-making;optimal decision;influence diagram;decision support system;intelligent decision support system;decision analysis;decision engineering;computer science;knowledge management;decision tree;decision problem;data mining;decision rule;mathematics;geographic information system;management science;evidential reasoning approach;business decision mapping	AI	-32.17243306015202	-28.093649060462358	128947
6af62a850016580ccf7c7755c236adf1f97ed227	evolvable fashion-based cellular automata for generating cavern systems	level generation system evolvable fashion based cellular automata generating cavern system complex image cavern like level map competition matrix cell state toroidal grid level maps tile fashion based representation evolved automaton rule;automata sociology statistics games evolutionary computation technological innovation computer architecture;matrix algebra cellular automata	Cellular automata can be used to rapidly generate complex images. This study introduces fashion-based cellular automata as a new representation for generating cavern-like level maps. Fashion-based automata are defined by a competition matrix that defines the benefit to a given cell state of having a neighbor of each possible cell state. A simple fitness function permits this type of automata to be evolved to produce a variety of level maps. A parameter study is performed and a variety of level maps are evolved with a toroidal grid, ensuring that the level maps tile. The parameter study demonstrates a robustness of the fashion based representation to the variation of parameters. The appearance of a given cavern-like level is encoded in the evolved automaton rule permitting the creation of many levels with a similar character simply by varying initial conditions. The cellular automata rules function in local neighborhoods meaning that the level generation system scales smoothly to any desired level map size.	cellular automaton;fitness function;initial condition;map;procedural generation;smoothing;toroidal graph	Daniel A. Ashlock	2015	2015 IEEE Conference on Computational Intelligence and Games (CIG)	10.1109/CIG.2015.7317958	stochastic cellular automaton;simulation;continuous spatial automaton;growcut algorithm;quantum finite automata;computer science;artificial intelligence;asynchronous cellular automaton;machine learning;automata theory;ω-automaton;mobile automaton;timed automaton;algorithm	Comp.	-27.56411573828224	-24.28551496934245	129109
677479dffc172ecb1c80e1d2c29996634c3d36a0	visual signature of high-dimensional geometry in parallel coordinates	mathematics computing;geometry based techniques;computational geometry;computer graphics applications;interactive exploration 3d projected high dimensional geometry interactive rotation statistical analysis geometric structures blue noise sampling continuous parallel coordinates plot construction high dimensional geometric surfaces mathematical equations embedded visual signatures;geometry visualization data visualization three dimensional displays transforms mathematical model equations;data visualisation;computer graphicsapplications;mathematical software;visualization in mathematics;sampling methods;mathematical software parallel coordinates geometry based techniques coordinated and multiple views visualization in mathematics computer graphicsapplications;interactive systems;coordinated and multiple views;sampling methods computational geometry data visualisation interactive systems mathematics computing;parallel coordinates	Although we can interactively rotate a 3D projected high-dimensional geometry and observe its dynamic changes, this traditional visualization method is limited and highly sensitive to the choice of viewing direction. Parallel-coordinates plots supplement this visualization scenario by providing statistical analysis of the geometry for distinct pairs of co-dimensions. Such analysis results in visual signatures that embed geometric structures such as symmetry, and thus allows us to overview the status of the missing dimensions while exploring the projected geometry. This paper presents a blue-noise sampling approach for efficient construction of continuous parallel-coordinates plots of high-dimensional geometric surfaces defined by mathematical equations. We employ the parallel-coordinates plots with the embedded visual signatures to assist the interactive exploration of high-dimensional geometries, typically for 2-manifold embedded in 4-space. While we interactively explore the 3D projected geometry, we can observe dynamic changes on its visual signature. Various geometric properties can also be identified and visualized. Moreover, we can interactively brush the plots, and see their counterparts in the 3D projection. Assorted geometric properties such as curvature can further be used to enhance the visual signature.	3d projection;brushing and linking;colors of noise;compiler;embedded system;graphics processing unit;interactivity;multi-touch;parallel coordinates;real-time clock;real-time computing;sampling (signal processing);type signature;viewing cone	Xiaoqi Yan;Chi-Fu Lai;Chi-Wing Fu	2014	2014 IEEE Pacific Visualization Symposium	10.1109/PacificVis.2014.41	computer vision;computer science;theoretical computer science;computer graphics (images)	Visualization	-28.423870776426014	-32.87736503621964	129175
c82198e0592e380779492465cbacadc259d4903d	classifying visual knowledge representations: a foundation for visualization research	computer graphics;computerised picture processing;knowledge representation;sorting;visual perception;cluster analysis;cognitive processing effort;diagrams;graphs;hierarchical sorting data;homogeneous clusters;icons;maps;networks;spatial information;tables;visual information processing;visual knowledge representations classification;visualization research	This research is an exploratory effort to classify visual representations into homogeneous clusters. Our goal is to determine the type of knowledge conveyed by various visual representations. We collected hierarchical sorting data from twelve subjects. Five principal groups of visual representations emerged from a cluster analysis of sorting data: graphs and tables, maps, diagrams, networks, and icons. Two dimensions appear to distinguish these clusters: the amount of spatial information and cognitive processing effort. Our future research will continue to identify properties that characterize knowledge expressed with visual representations.	cluster analysis;cognition;diagram;geographic information system;map;sorting;table (database)	Gerald L. Lohse;Henry H. Rueter;Kevin Biolsi;Neff Walker	1990			knowledge representation and reasoning;computer vision;two-dimensional space;visual analytics;information visualization;cognition;visual perception;computer science;sorting;data science;machine learning;data mining;spatial analysis;cluster analysis;human visual system model;computer graphics;data visualization;computer graphics (images)	HCI	-27.754704597455873	-31.72927850374125	129568
9b8ca95adebbb0d2bd6a54181394043ccb6b1ac1	a bike traffic analyzer for the determination of cycle lanes		This paper presents the construction of a tool for the analysis of cyclist traffic in a medium sized city, such as Puerto Madryn. For this, an application domain model for the cyclist traffic is elaborated. The objective of the model is to build the knowledge that allows to determine the most suitable routes to place in that city cycle lanes. The nucleus of the proposal is the analysis of information of trips, that allow to synthesize journeys with their respective lengths, frequencies, densities and weights. In addition to the theoretical model, a tool for analysis of captured data and a generator of synthetic trips is presented.	application domain;crowdsourcing;domain model;ecosystem;information model;mobile app;prototype;synthetic intelligence;theory	Leo Ordínez;Damián Barry;Alex Torrico;Emanuel Mallon;Jose Luis Devia;Lucas Abella;Nieves Alamo	2017	2017 36th International Conference of the Chilean Computer Science Society (SCCC)	10.1109/SCCC.2017.8405125	machine learning;simulation;application domain;data modeling;trips architecture;artificial intelligence;computer science;spectrum analyzer	EDA	-19.3052271533429	-31.638511271992282	129633
faa94e35f6f6459338bd889577cf469a841d811e	visual tools for information retrieval	hierarchical structure;electronic mail;financial portfolio management gui information retrieval visualization tool visual query language visual retrieval tools large information spaces query outliner query spreadsheet boolean queries query overview navigation tool electronic mail filtering human resource management;visualization tool;visual retrieval tools;building block;database management systems;information retrieval;query outliner;financial portfolio management;information filtering;vector space;query spreadsheet;information visualization;navigation tool;query languages;navigation;visualization;visual languages;graphical user interfaces;human factors;electronic mail filtering;large information spaces;organizing;displays;information retrieval visualization human resource management database languages organizing displays navigation electronic mail information filtering information filters;gui;graphic user interface;query overview;boolean queries;information filters;database languages;human resource management;visual languages database management systems graphical user interfaces query languages;visual query language	This paper introduces a novel representation that can be used as a visualization tool as well as a visual query language to help users search for information. High-level visual retrieval tools are described that enable users to explore, manage, and relate large information spaces to their interests. The following tools are developed: 1) The Query OutIiner enables users to structure and edit complex queries. 2) The Query Spreadsheet is a novel representation that visualizes all the possible relationships among N variables, and i t allows users to specify Boolean queries graphically. Arbitrarily complex queries can be created by using the query spreadsheets as building blocks and organizing them in a hierarchical structure. 3 ) The Qite y Overoiew displays the complete structure of a complex query and it can be used as a navigation tool. The presented visual framework has applications in such areas as information retrieval, electronic mail filtering, human resource management or financial portfolio management.	boolean algebra;email;information retrieval;organizing (structure);query language;query string;spreadsheet	Anselm Spoerri	1993		10.1109/VL.1993.269592	sargable;query optimization;query expansion;web query classification;ranking;computer science;query by example;data mining;database;rdf query language;web search query;information retrieval;query language;spatial query	HCI	-29.88688257841756	-33.144859315956694	129934
711671d26caba298d883c588178cde42cffc576a	visual analysis of complex networks and community structure	graph drawing;call graph;network visualization;complex network;community structure;visual analysis;software framework;bibliometric analysis;visual analytics;visual processing	Many real-world domains can be represented as complex networks.A good visualization of a large and complex network is worth more than millions of words. Visual depictions of networks, which exploit human visual processing, are more prone to cognition of the structure of such complex networks than the computational representation. We star by briefly introducing some key technologies of network visualization, such as graph drawing algorithm and community discovery methods. The typical tools for network visualization are also reviewed. A newly developed software framework JSNVA for network visual analysis is introduced. Finally,the applications of JSNVA in bibliometric analysis and mobile call graph analysis are presented.	algorithm;bibliometrics;call graph;cluster analysis;cognition;complex network;graph drawing;java;sensor;social network;software framework	Bin Wu;Qi Ye;Yi Wang;Ran Bi;Lijun Suo;Deyong Hu;Shengqi Yang	2009		10.1007/978-3-642-02469-6_93	network science;visual analytics;interactive visual analysis;computer science;artificial intelligence;data science;machine learning;data mining;mathematics;graph drawing;world wide web	Visualization	-27.677755157596142	-36.27154182253453	130213
a4d8eda7a02e0c3af59c52bce6f232f476dc093e	modular mathematical modelling of biological systems	bio dsl modelling modules;biological modelling;functional programming;module systems;mathematical modelling;domain specific languages	Mathematical models are frequently used to model biological systems, particularly within the field of cardiac electrophysiology. Such systems are typically modelled in a continuous fashion using ordinary differential equations (ODEs) and simulated using custom computer programs created in general purpose languages. Several domain specific languages (DSLs) have been created to ease the difficulty in programming biological models, including CellML. However models in such DSLs are monolithic, interdependent systems, hindering possibilities for reuse and specialisation. In this paper we introduce the Ode language; a typed DSL for describing ODE-based biological models in a structured manner. The type system is used to validate models and includes automated checking and conversion of units of measure. We introduce a module system influenced by parameterised modules from OCaml that allows specialised instantiation at compile-time. Module parameterisation provides great flexibility, enabling the creation of reusable, abstracted model components. These components may be composed and specialised to create larger models. The type system is used to generate module interfaces that guide successful module composition. Parameterised modules may be used, for instance, to abstract a models stimulus protocol or modify its parameters. Several examples are given and the implementation details are discussed.	biological system;mathematical model	Mandeep Gill;Steve McKeever;David J Gavaghan	2012			computer science;theoretical computer science;algorithm	Logic	-26.835309908160703	-26.945612849559552	130433
cc3bfd4ec7db31c6973432e310c789a9ec3f6773	a robust system integration for autonomous evacuation navigation		During an emergency evacuation, there are two subsystems involved: fire alarm control panel system (FACPS) and building floor plan system (BFPS). Fire indicator in FACPS reacts as proactive fire notification. Once detected any abnormalities, it sends the signal to the system, and alarm will trigger continuously. Thereafter, emergency evacuations take into the place immediately, without providing any information on the location of the hazard. The second subsystem, BFPS has to follow the standards regulation as visual static emergency navigation. However, in reality, it does not help the occupants to navigate out of the building towards the safest route. At present, both systems operate independently with specific functions, but based on logic thinking; it should be linked to each other. This argument is referring to the actual scenario in the event of fire; FACPS causes the disruption of the original BFPS. Consequently, this gap has led the evacuation process become more complex and challenging, especially for unfamiliar occupant. Therefore, this study proposed robust system integration for autonomous evacuation navigation (AEN) by integrates both systems, and adapting systems thinking (ST) approach. System integration (SI) is a combination of systems into one coherent system, linked the components, and finally able to achieve its purpose and mission. On the other hand, ST supersedes SI and explores the full pattern of the subsystem behavior, interrelate each other, and provide the outcome. As a result, it manages to eliminate human as an agent and non-compliance problem. At the meantime, FACPS provides the location of hazard as an input for BFPS. Through dynamic approach, floor plan layout system updates and blocks the hazardous location simultaneously. Finally, it provides a dynamic navigation to solve wayfinding problem, especially for unfamiliar occupants towards the safe and shortest route.	system integration	Khyrina Airin Fariza Abu Samah;Burairah Hussin;Abd. Samad Hasan Basari	2014		10.3233/978-1-61499-434-3-692	simulation;system integration;systems thinking;emergency evacuation;computer science;floor plan	Robotics	-19.331820505620236	-24.223329931535076	130550
510633577f86c538b1518a24b88759f68eec88ae	closing the loop: an agenda- and justification-based framework for selecting the next discovery task to perform	databases;erbium;ai architectures;patient rehabilitation agenda based framework justification based framework next discovery task selection justification based architecture discovery systems general discovery strategies background knowledge user interests prototype discovery program autonomous machine learning knowledge discovery in databases hamb protein crystallization;biology computing;health care data mining inference mechanisms learning artificial intelligence user interfaces very large databases macromolecules biology computing patient care;performance evaluation;knowledge discovery in databases;prototypes;general discovery strategies;patient rehabilitation;user interests;justification based framework;inference mechanisms;protein crystallization;justification based architecture;data mining;patient care;learning systems;hamb;autonomous agent;proteins;performance evaluation encoding prototypes proteins crystallization machine learning databases learning systems humans erbium;machine learning;autonomous machine learning;crystallization;background knowledge;macromolecules;humans;very large databases;learning artificial intelligence;next discovery task selection;encoding;user interfaces;discovery systems;prototype discovery program;agenda based framework;health care	We propose and evaluate an agendaand justifi cationbased architecture for discovery systems that selects the next tasks to perform. This framework has many desirable properties: (1) it facilit ates the encoding of general discovery strategies using a variety of background knowledge, (2) it reasons about the appropriateness of the tasks being considered, and (3) it tailors its behavior toward a user’s interests. A prototype discovery program called HAMB demonstrates that both reasons and estimates of interestingness contribute to performance in the domains of protein crystalli zation and patient rehabili tation.	autonomous robot;closing (morphology);experiment;heuristic (computer science);norm (social);prototype	Gary Livingston;John M. Rosenberg;Bruce G. Buchanan	2001		10.1109/ICDM.2001.989543	macromolecule;erbium;computer science;knowledge management;artificial intelligence;data science;autonomous agent;machine learning;data mining;prototype;crystallization;user interface;health care;encoding;protein crystallization	ML	-25.89424554680353	-28.020844879547685	130626
a94d76980912d655c3d34a7a29f328d18bb0de2c	behavioural markers: bridging the gap between art of analysis and science of analytics in criminal intelligence		Studying how intelligence analysts use interaction in visualization systems is an important part of evaluating how well these interactions support analysis needs, like generating insights or performing tasks. Intelligence analysis is inherently a fluid activity involving transitions between mental and interaction states through analytic processes. A gap exists to complement these transitions at micro-analytic level during data exploration or task performance. We propose Behavioural markers (BMs) which are representatives of the action choices that analysts make during their analytical processes as the bridge between human cognition and computation through semantic interaction. A low level semantic action sequence computation technique has been proposed to extract these BMs from captured process log. Our proposed computational technique can supplement the problems of existing qualitative approaches to extract such BMs.		Junayed Islam;B. L. William Wong	2017	2017 European Intelligence and Security Informatics Conference (EISIC)	10.1109/EISIC.2017.30	data visualization;visualization;human–computer interaction;visual analytics;semantics;intelligence analysis;cognition;creativity;analytics;computer science	AI	-25.601356728439523	-35.14608870395718	130690
e405dc9c585dce3955b85699f11d0403d16fcc22	estimating micro-populations through social media analytics	knowledge and data engineering tools and techniques;super (very large) computers;correlation and regression analysis	Estimation of crowd sizes or the occupancy of buildings and skyscrapers can often be essential. However, traditional ways of estimation through manual counting, image processing or in the case of skyscrapers, through total water usage are awkward, inefficient and often inaccurate. Social media has developed rapidly in the last decade. In this work, we provide novel solutions to estimate the population of suburbs and skyscrapers—so-called micro-populations, through the use of social media. We develop a big data solution leveraging large-scale harvesting and analysis of Twitter data. By harvesting real-time tweets and clustering tweets within suburbs and skyscrapers, we show how micro-populations can be calculated. To validate this, we construct linear and spatial models for the suburbs in four cities of Australia using census data and geospatial data models (shapefiles). Our prediction of micro-population shows that Twitter can indeed be used for population prediction with a high degree of accuracy.	asg software solutions;autocorrelation;belief revision;big data;cluster analysis;data model;geotagging;image processing;linear model;multiple document interface;population;preprocessor;real-time clock;shapefile;social media analytics;spatial analysis	Richard O. Sinnott;Wei Wang	2017	Social Network Analysis and Mining	10.1007/s13278-017-0433-6	geospatial analysis;occupancy;data mining;data science;cluster analysis;social media analytics;big data;shapefile;social media;population;computer science	AI	-21.408604879766354	-32.99950934956894	130726
ac1951e2937eee8b56ef350783f8a7ad1eee9903	matlab script for analyzing and visualizing scanline data	3d;discontinuity;computer code;visualization;clustering;2d	Scanline surveys consist of directional and qualitative measurements of rock discontinuities. These surveys are used in geologic and engineering investigations of fractured rock masses. This paper introduces a new MATLAB script developed for visualizing results from scanline surveys as traces in 2D and disks in 3D. The script is also able to cluster orientation data and to present statistical summaries and to reflect the change in degree of rock brokenness along the scanline. Advantages of this new script are that it can present undulating discontinuities as wavy surfaces and different discontinuity properties using color codes. An intensity rose diagram is utilized to visualize interdependency of certain properties and orientation. This new script has a potential for preprocessing vast amounts of scanline and oriented drill core logging data before using it in 3D discontinuity network modeling. The script is demonstrated using data concerning rock fracturing gathered from a dimension stone quarry in Southern Finland. & 2011 Elsevier Ltd. All rights reserved.	code;degree (graph theory);diagram;interdependence;matlab;preprocessor;reflections of signals on conducting lines;scan line;scanline rendering;tracing (software)	M. Markovaara-Koivisto;E. Laine	2012	Computers & Geosciences	10.1016/j.cageo.2011.07.010	2d computer graphics;simulation;visualization;computer science;discontinuity;cluster analysis;3d computer graphics;source code;computer graphics (images)	HCI	-27.73599995969008	-32.59169027246556	130999
4d9e1a0e16dda6422294fb1979eb2f7a790106f8	interactive tools for pattern discovery	pattern discovery;real-world pattern recognition problem;methodological alternative;effective method;data proximity relationship;data geometry;interactive tools;core classification task;rapid trial;common challenge;graphical software;non-comparable group;pattern recognition;data visualisation	Real-world pattern recognition problems contain rich context that must be taken into account in solution development. Beyond the core classification tasks, there are several common challenges including the need to correlate noncomparable groups of variables while preserving data proximity relationships within each group, visualization of data geometry, rapid trial of many methodological alternatives, and integration with existing infrastructure. We explore the effective methods and tools to meet with these challenges. We describe a graphical software, Mirage, as an experiment to address such concerns.	effective method;graphical user interface;pattern recognition	Tin Kam Ho	2004	Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004.	10.1109/ICPR.2004.1334282	computer science;data science;theoretical computer science;machine learning;data mining;data visualization	Visualization	-26.63596717393287	-34.33850916899715	131033
4aa030094219a173891e6c5f0437c2ff6b2d6879	the graph landscape: using visual analytics for graph set analysis	graphs;multidimensional data;visualization;analysis	In a variety of research and application areas, graphs are an important structure for data modeling and analysis. While graph properties can have a crucial influence on the performance of graph algorithms, and thus on the outcome of experiments, often only basic analysis of the graphs under investigation in an experimental evaluation is performed and a few characteristics are reported in publications. We present Graph Landscape, a concept for the visual analysis of graph set properties. The Graph Landscape aims to support researchers to explore graphs and graph sets regarding their properties, to allow to select good experimental test sets, analyze newly generated sets, compare sets and assess the validity (or range) of experimental results and corresponding conclusions.	algorithm;benchmark (computing);data modeling;experiment;graph property;graph theory;prototype;requirement;server (computing);test set;user interface;visual analytics;world wide web	Andrew Kennedy;Karsten Klein;An Nguyen;Florence Ying Wang	2017	J. Visualization	10.1007/s12650-016-0374-6	graph (abstract data type);visualization;visual analytics;data science;computer science;graph	ML	-23.676196494934825	-35.08990431493945	131254
3049ed70f251ef60a6ac90d90959676a5a608700	validation of the mr simulation approach for evaluating the effects of immersion on visual analysis of volume data	volume data analysis;virtual reality computerised tomography data analysis data visualisation rendering computer graphics;virtual reality immersion micro ct data analysis volume visualization 3d visualization cave virtual environments;mice;3d medical image;computed tomography;cave;3d visualization;field of regard component;training;head tracking component;head tracking;immersive virtual reality systems;virtual reality;controlled experiment;virtual environments;three dimensional;computer graphic;stereoscopic rendering component;data visualisation;micro ct;data analysis;immersion effect;visualization;three dimensional displays data visualization mice visualization rendering computer graphics training head;immersion;paleontological data;medical image;display system;perceived task performance;three dimensional displays;immersive virtual reality systems immersion effect visual analysis volume data analysis volume visualization 3d medical image seismic data paleontological data immersive vr system head tracking component field of regard component stereoscopic rendering component x ray microscopic computed tomography dataset perceived task performance display system;immersive virtual reality;visual analysis;data visualization;computerised tomography;volume visualization;head;virtual environment;x ray microscopic computed tomography dataset;rendering computer graphics;immersive vr system;adolescent adult animals computer graphics databases factual extremities female fossils humans imaging three dimensional male mice task performance and analysis tissue scaffolds user computer interface x ray microtomography young adult;seismic data;x rays;empirical research;volume data	In our research agenda to study the effects of immersion (level of fidelity) on various tasks in virtual reality (VR) systems, we have found that the most generalizable findings come not from direct comparisons of different technologies, but from controlled simulations of those technologies. We call this the mixed reality (MR) simulation approach. However, the validity of MR simulation, especially when different simulator platforms are used, can be questioned. In this paper, we report the results of an experiment examining the effects of field of regard (FOR) and head tracking on the analysis of volume visualized micro-CT datasets, and compare them with those from a previous study. The original study used a CAVE-like display as the MR simulator platform, while the present study used a high-end head-mounted display (HMD). Out of the 24 combinations of system characteristics and tasks tested on the two platforms, we found that the results produced by the two different MR simulators were similar in 20 cases. However, only one of the significant effects found in the original experiment for quantitative tasks was reproduced in the present study. Our observations provide evidence both for and against the validity of MR simulation, and give insight into the differences caused by different MR simulator platforms. The present experiment also examined new conditions not present in the original study, and produced new significant results, which confirm and extend previous existing knowledge on the effects of FOR and head tracking. We provide design guidelines for choosing display systems that can improve the effectiveness of volume visualization applications.	field of regard;head-mounted display;immersion (virtual reality);mixed reality;motion capture;scientific visualization;simulation;vr - veterans rand health survey;virtual reality	Bireswar Laha;Kriti Sensharma;James D. Schiffbauer;Doug A. Bowman	2012	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2012.42	computer vision;visualization;computer science;data mining;multimedia;data visualization;statistics;immersion;computer graphics (images)	Visualization	-32.57548427728537	-36.773959892941406	131632
2d0133ac7505731ca520e1849e738f21f27a2f99	exploring relationship between taxi volume and flue gases' concentrations	urban mobility;flue gases concentrations;linear regression;taxi gps traces;time series analysis;spatiotemporal analysis	With the rapid increase in size and population of urban areas, it becomes important to understand urban environmental influencers so that better informed decisions can be made for more sustainable urban environments. Taxis represent one of the urban dynamics from which city planners can gain a better understanding of urban mobility as well as its relationship with other environmental elements. In this work, an analysis of the relationship between flue gases? concentrations (represented by nitrogen dioxide) and taxi volume in Lisbon, Portugal was carried out from which a strong correlation between the two was observed. Based on four months of data, we found that the flue gases' concentrations varied with taxi volume and in particular, taxi volume can be used to estimate the change in flue gases' concentrations of the next hour.		Marco Veloso;Santi Phithakkitnukoon;Carlos Bento	2013		10.1145/2494091.2497353	linear regression;time series;statistics	HCI	-19.385322648210874	-33.27101532288777	131857
ba40998de0f0cf91fe84f259c7f52d63f35844e9	mixed narrative and dialog content planning based on bdi agents	social simulation;search algorithm;bdi agents;state space	There exist various narrative systems, focused on different parts of the complex process of story generation. Some of them are oriented to content planning, and some to sentence planning, with different properties and characteristics. In this paper we propose a system based on BDI agents that generates stories (creating content, performing content planning and simple sentence planning) with narrative parts and dialogs. The content for the story is generated in a multiagent social simulation system, and the content planning is based on rules and a state space search algorithm based on the system representation of the reader’s perception of the story.	agent-based model;search algorithm;social simulation;state space search;dialog	Carlos León;Samer Hassan;Pablo Gervás;Juan Pavón	2007		10.1007/978-3-540-75271-4_16	computer science;artificial intelligence;multimedia;communication	AI	-31.037219128019363	-24.393723670061032	131896
a5177ec503ea96f43f020ac33ce57a80b008d6c4	a viewpoint approach to symbolic music transformation		This paper presents a general approach to the transformation of symbolic music. The method is based on viewpoints, which enable the representation of musical surfaces by sequences of abstract features. Along the transformation process, some of these sequences are conserved while some others are variable and can be replaced by generated ones. The initial piece is therefore seen as a template which is instantiated at each transformation. The method is illustrated in the paper with the particular case of transformations occurring at the harmonic level. New chord sequences are generated by sampling from a statistical model in a particular style. The pitch of the notes constituting the template piece are then transformed according to the generated chord sequence.	algorithm;onset (audio);sampling (signal processing);statistical model;viewpoint	Louis Bigo;Darrell Conklin	2015		10.1007/978-3-319-46282-0_13	arithmetic;pure mathematics;mathematics	DB	-27.214508314431075	-27.3920026742444	131941
918ceff40eb6e85ed2aa4b8d3c2d6056c9b0ad39	machine learning as an objective approach to understanding music	human critic;median land distance error;objective approach;objective machine;geographical origin;geographical knowledge;geographical ethnomusicology;alternative approach;understanding music;population distribution overlay;best-performing prediction method;comparable random trial	Traditional research into the arts has almost always been based around the subjective judgment of human critics. We propose an alternative approach based on the use of objective machine learning programs. To illustrate this approach we investigated the distribution of music from around the world: geographical ethnomusicology. To ensure that our understanding of geographical ethnomusicology is objective and operational, we cast the problem as training a machine learning program to predict the geographical origin of pieces of music. We collected 1,142 pieces of music from 73 countries, and described them using 2 different sets of standard audio descriptors using MARSYAS. To predict the location of origin of the music we developed several methods designed to deal with the spherical surface topology based upon a modified k-nearestneighbour. We investigate the utility of a priori geographical knowledge in the predictions: a land and sea mask, and a population distribution overlay. Our best-performing algorithm so far achieved a median land distance error of 1,506km, with comparable random trials having mean of medians 3,190km this is significant at P < 0.001.	algorithm;machine learning	Q Claire;Ross King	2012		10.1007/978-3-642-37382-4_5	geography;artificial intelligence;machine learning;data mining	ML	-21.18770820347909	-32.61148548617563	131972
d8964d40153b255bda7b29a218e37b312f25ffc9	matching shapes: a case study in time-varying images	arbre recherche;time varying;research tree;decomposition;image processing;segmentation;traitement image;algorithme;algorithm;algorritmo;pattern recognition;image analysis;reconnaissance forme;analyse image	Presentation d'une procedure pour adapter des formes le long d'une sequence d'images variant dans le temps. Chaque frontiere de forme est tout d'abord decomposee en segments convexes et ensuite une correspondance entre les segments frontieres de deux formes contigues est etablie au moyen d'un arbre de recherche. Description des details de la decomposition et des algorithmes d'association. Un exemple illustre la procedure		Maria Francesca Costabile;Concettina Guerra;Goffredo G. Pieroni	1985	Computer Vision, Graphics, and Image Processing	10.1016/0734-189X(85)90127-6	computer vision;image analysis;image processing;computer science;decomposition;segmentation	Vision	-22.179952891153924	-37.753398962741606	131978
3fbb55ae80393453d5c6f52181f6da9751215c81	semantic analytics visualization	complex relationships;documento electronico;sistema interactivo;web documents;image numerique;ontologie;affichage;multimedia;realite virtuelle;metadata;visualizacion;realidad virtual;query processing;3d visualization;bepress selected works;laser;traitement requete;securite informatique;semantic web rdf semantic associations semantic analytics ontologies virtual reality complex relationships national security applications visualization;interrogation base donnee;virtual reality;interrogacion base datos;semantics;intelligence artificielle;data mining;semantica;semantique;three dimensional;information presentation;immersive environment;systeme conversationnel;document electronique;computer security;heterogeneous information;visualization;hierarchical classification;national security applications;marcador;pointer;display;digital media;visualisation;semantic associations;fouille donnee;interactive system;laser pointer;senal numerica;seguridad informatica;imagen numerica;metadonnee;classification hierarchique;semantic web;signal numerique;pointeur;artificial intelligence;ontologia;ontologies;tratamiento pregunta;metadatos;digital image;inteligencia artificial;digital signal;clasificacion jerarquizada;busca dato;ontology;database query;semantic analytics;electronic document;rdf;semantic association	In this paper we present a new tool for semantic analytics through 3D visualization called “Semantic Analytics Visualization” (SAV). It has the capability for visualizing ontologies and meta-data including annotated webdocuments, images, and digital media such as audio and video clips in a synthetic three-dimensional semi-immersive environment. More importantly, SAV supports visual semantic analytics, whereby an analyst can interactively investigate complex relationships between heterogeneous information. The tool is built using Virtual Reality technology which makes SAV a highly interactive system. The backend of SAV consists of a Semantic Analytics system that supports query processing and semantic association discovery. Using a virtual laser pointer, the user can select nodes in the scene and either play digital media, display images, or load annotated web documents. SAV can also display the ranking of web documents as well as the ranking of paths (sequences of links). SAV supports dynamic specification of sub-queries of a given graph and displays the results based on ranking information, which enables the users to find, analyze and comprehend the information presented quickly and accurately.	association rule learning;challenge–response spam filtering;database;digital media;experiment;immersion (virtual reality);interactivity;ontology (information science);pointer (computer programming);real life;real-time locating system;requirement;semantic analytics;semi-supervised learning;semiconductor industry;synthetic intelligence;usability;video clip;virtual reality;web page	Leonidas Deligiannidis;Amit P. Sheth;Boanerges Aleman-Meza	2006		10.1007/11760146_5	analytics;visualization;computer science;artificial intelligence;ontology;data mining;database;semantics;virtual reality;world wide web;semantic analytics	Visualization	-33.590358872785096	-28.04160979719631	132003
0cfb835ceea2028acb7069144d20df5f7582c317	automatic rule ordering for dynamic scripting	knowledge base;reinforcement learning	The goal of adaptive game AI is to enhance computercontrolled game-playing agents with (1) the ability to selfcorrect mistakes, and (2) creativity in responding to new situations. Dynamic scripting is a reinforcement learning technique that realises fast and reliable online adaptation of game AI. It employs knowledge bases which contain rules that can be included in game scripts. To be successful, dynamic scripting requires a mechanism to order the rules that are selected for scripts. So far, rule ordering was achieved by a manuallytuned priority value for each rule. In the present research, we propose three mechanisms to order rules automatically for dynamic scripting. We performed experiments in which we let dynamic scripting, using each of the three mechanisms, play against manually-designed tactics. Our results show that dynamic scripting with automatic rule ordering generates game AI that is at least as effective as dynamic scripting with manually-tuned priority values. Moreover, it has the ability to generate novel game AI with significantly increased effectiveness. The costs are a slight decrease in learning efficiency. So, we may conclude that automatic rule ordering is a valuable enhancement for dynamic scripting.	artificial intelligence (video games);experiment;knowledge base;reinforcement learning;rule 90	Timor Timuri;Pieter Spronck;H. Jaap van den Herik	2007			machine learning;artificial intelligence;reinforcement learning;computer science;knowledge base;scripting language	AI	-25.722243826474173	-25.44633969993155	132446
991399e91504c340cea8cbfe0e525620fc4ce703	applying 3d dynamic visualisation to (palaeo) geomorphic reconstruction: modelling a tenth century jökulhlaup at sólheimajökull glacier, south iceland	glaciology;icelandic hazard mitigation authorities 3d dynamic visualisation geomorphic reconstruction tenth century jökulhlaup modelling solheimajökull glacier south iceland glacial outburst flood volcvis customised visualisation platform computer gaming technology geomorphological markers sedimentary markers glacial history interactive multiperspective prototype model three dimensional prototype model visual simulation data sharing;data visualisation;geophysics computing;solid modelling data visualisation geophysics computing glaciology;solid modelling	At Sólheimajökull glacier in southern Iceland, field evidence has been collected of a Tenth Century jökulhlaup (or glacial outburst flood). It was an exceptional event in terms of generation, scale, magnitude and geomorphic impact. Although now fragmented and piecemeal, many of its direct (and indirect) geomorphological and sedimentary markers have been identified, mapped and dated to unravel the sequence of events played out during this significant episode in the glacial history. 'VolcVis', an innovative, customised visualisation platform using computer gaming technology is developed and applied for the first time in coalescing and displaying field results from Sólheimajökull, creating an interactive, multi-perspective, three-dimensional (3D) prototype model. A visual simulation of Sólheimajökull's Tenth Century physical environment places the flood into geomorphic and topographic context. This ability to dynamically display and interpret field data presents new possibilities for testing hypotheses, and for data sharing with Icelandic hazard mitigation authorities and the general public.	3d computer graphics;augmented reality;flood fill;pc game;prototype;simulation;topography	Laura M. Booth;John P. Isaacs	2013	2013 17th International Conference on Information Visualisation	10.1109/IV.2013.78	geomorphology;geography;archaeology	Visualization	-23.68564298860011	-28.807931214061135	132525
a36b0efbc9e288a53e5d3c2279610c471fde160c	an event oriented data management method for displaying genealogy with a new function for direct descent family lines	segment intersections;software;direct descent family lines;free layout;history;complex multiplication;search algorithm;data management;layout;intuitive graphical editor genealogy hidden node direct descent family lines segment intersections search algorithm free layout;family trees event oriented data management method genealogy display software direct descent family lines white base model data structure;data structures;history data handling data structures;hidden node;joining processes;genealogy;informatics;intuitive graphical editor;data handling;switches;software switches educational institutions layout informatics joining processes data structures;data structure	"""A lot of existing genealogy display software cannot perfectly display complex relations, including historical science and ethnology. Therefore, we have constructed a new software so that it can. Our software uses an event oriented data management method, the """"White Base"""" (Widespread Hands to Interconnect Basic Elements). It is a hidden node for integrating the relations, including a married couple and their children. Using the White Base, the number of references is less than the existing data structure, and complex multiple marriages with segment intersections can be displayed perfectly. This method, however, cannot manage some different line styles of the family trees. To cope with this difficulty, a new function is installed on the previous software. As a result, normal family trees and """"Direct Descent Family Lines"""", can be switched automatically and seamlessly without changing the White Base model. Our improved prototype software that can show the effectiveness of our research is presented."""	data structure;descent;family tree;prototype	Seiji Sugiyama;Atsushi Ikuta;Miyuki Shibata;Tohru Matsuura	2011	2011 Second International Conference on Culture and Computing	10.1109/Culture-Computing.2011.38	computer science;artificial intelligence;theoretical computer science;algorithm	SE	-29.49800226257097	-29.516890601947143	132644
1a7e2d063ea4966db386afc5145e256a3e8933b9	online learning and mining human play in complex games	games roads monte carlo methods learning artificial intelligence manuals data models cities and towns;settlers of catan online learning human play mining complex games hybrid model knowledge mining human game play agent complex win lose board game;multi agent systems computer games data mining	We propose a hybrid model for automatically acquiring a policy for a complex game, which combines online learning with mining knowledge from a corpus of human game play. Our hypothesis is that a player that learns its policies by combining (online) exploration with biases towards human behaviour that's attested in a corpus of humans playing the game will outperform any agent that uses only one of the knowledge sources. During game play, the agent extracts similar moves made by players in the corpus in similar situations, and approximates their utility alongside other possible options by performing simulations from its current state. We implement and assess our model in an agent playing the complex win-lose board game Settlers of Catan, which lacks an implementation that would challenge a human expert. The results from the preliminary set of experiments illustrate the potential of such a joint model.	experiment;heuristic (computer science);monte carlo method;monte carlo tree search;online machine learning;quickdraw 3d;random search;simulation;text corpus;win–loss analytics	Mihai Sorin Dobre;Alex Lascarides	2015	2015 IEEE Conference on Computational Intelligence and Games (CIG)	10.1109/CIG.2015.7317942	non-cooperative game;video game design;combinatorial game theory;game design;simulation;win-win game;artificial intelligence;game mechanics;machine learning;metagaming;game developer;multimedia;screening game;simulations and games in economics education;sequential game	AI	-25.96787623667085	-25.090399706162874	132993
77c0eed5a70b0bcd2700cce4f9d8c1e3cd81f8e7	an analysis framework for ontology querying tools	ontology tools;ontology querying;analysis framework;user interaction	While knowledge querying is a key capability of ontologies, the query language recommended by W3C, SPARQL, is not easy to use for some user types, e.g., casual users and domain experts. To improve this drawback, user-friendly Ontology Query Tools (OQTs) have been introduced. However, there is, to our knowledge, no comprehensive framework for researchers and practitioners to compare the capabilities of the wide range of available OQTs. In this paper we introduce, based on a systematic literature review, a framework that allows researchers and practitioners to classify and compare OQTs regarding their capabilities and their support for relevant user types and scenarios. We evaluate the framework based on a real-world use case. Major result of the evaluation was that the framework was found useful and usable by users from the target audience to identify the most suitable OQTs for their context.	ontology (information science);query language;sparql;systematic review;usability	Fajar J. Ekaputra;Estefanía Serral;Dietmar Winkler;Stefan Biffl	2013		10.1145/2506182.2506183	upper ontology;computer science;ontology;data mining;database;world wide web;process ontology	HCI	-30.292790265942408	-31.044342766397005	133336
4dd563500953ef9499a3fe332a6e8699fd451970	cognitive approach to bio-inspired medical image understanding	databases;in depth interpretation;image recognition;cognitive systems;image analysis systems;understanding based image analysis systems;cognitive informatics;ubias;ubias systems understanding based image analysis systems;data visualisation;data analysis;medical image;medical image processing;semantically oriented data analysis processes;ubias systems understanding based image analysis systems cognitive informatics bio inspired systems;image analysis;understanding based image analysis systems bio inspired medical image understanding cognitive categorisation systems cognitive informatics visual data analysis image analysis systems semantically oriented data analysis processes in depth interpretation ubias;bio inspired systems;cognitive categorisation systems;bio inspired medical image understanding;databases image recognition;medical image processing cognitive systems data analysis data visualisation;visual data analysis	The paper describes an idea of creation of cognitive categorisation systems used in the cognitive informatics. In particular systems for visual data and image analysis will be shown. Cognitive categorisation systems may execute semantically-oriented data analysis processes, and allow to analyse the semantic contents of patterns from analysed data sets. Cognitive data analysis processes lead to the in-depth interpretation and understanding of various types of data. This publication presents a selected class of cognitive categorisation systems called the UBIAS (Understanding Based Image Analysis Systems), also referred to as image analysis systems.	british informatics olympiad;categorization;cognition;cognitive science;computer vision;expert system;image analysis;information system;knowledge base	Lidia Ogiela;Marek R. Ogiela	2010	2010 IEEE Fifth International Conference on Bio-Inspired Computing: Theories and Applications (BIC-TA)	10.1109/BICTA.2010.5645125	computer vision;computer science;machine learning;data mining	SE	-27.613460834104576	-31.492350763013686	133443
f4e7493cd44d2b67265b8e97b218eb9511d160bf	intelligent agents for the game of go	bernstein races;evaluation function;pragmatics;ontology technique;high dimensionality;monte carlo methods ontologies discrete time systems pragmatics computational modeling mathematical model;poolrave techique intelligent agents game of go monte carlo tree search mcts evaluation function ontology technique bernstein races contextual monte carlo technique;discrete time systems;monte carlo tree search;trees mathematics;software agents;mcts;computational modeling;intelligent agents;trees mathematics games of skill monte carlo methods software agents;games of skill;game of go;intelligent agent;mathematical model;poolrave techique;ontologies;monte carlo;monte carlo methods;contextual monte carlo technique	Monte-Carlo Tree Search (MCTS) is a very efficient recent technology for games and planning, particularly in the high-dimensional case, when the number of time steps is moderate and when there is no natural evaluation function. Surprisingly, MCTS makes very little use of learning. In this paper, we present four techniques (ontologies, Bernstein races, Contextual Monte-Carlo and poolRave) for learning agents in Monte-Carlo Tree Search, and experiment them in difficult games and in particular, the Game of Go.	algorithm;artificial neural network;computational intelligence;computer go;evaluation function;experiment;extrapolation;integrated development environment;intelligent agent;life & death;monte carlo method;monte carlo tree search;numerical analysis;ontology (information science);partial template specialization;performance tuning;phil bernstein;quickdraw 3d;reinforcement learning;scalability;simulation;supervised learning	Jean-Baptiste Hoock;Chang-Shing Lee;Arpad Rimmel;Fabien Teytaud;Mei-Hui Wang;Olivier Teytaud	2010	IEEE Computational Intelligence Magazine	10.1109/MCI.2010.938360	combinatorial game theory;simulation;computer science;artificial intelligence;theoretical computer science;game mechanics;machine learning;monte carlo tree search;intelligent agent;monte carlo method	AI	-26.534015896177724	-25.049529632035114	133659
ed8402519ee207efc375f3a0acda0dd594e77e48	challenges of using text classifiers for causal inference		Causal understanding is essential for many kinds of decision-making, but causal inference from observational data has typically only been applied to structured, low-dimensional datasets. While text classifiers produce low-dimensional outputs, their use in causal inference has not previously been studied. To facilitate causal analyses based on language data, we consider the role that text classifiers can play in causal inference through established modeling mechanisms from the causality literature on missing data and measurement error. We demonstrate how to conduct causal analyses using text classifiers on simulated and Yelp data, and discuss the opportunities and challenges of future work that uses text data in causal inference.		Zach Wood-Doughty;Ilya Shpitser;Mark Dredze	2018			causal inference;machine learning;artificial intelligence;missing data;observational study;computer science;causality	NLP	-25.70746080037409	-35.863578298757965	134192
2ccdfb61f4720ae3fa5e723dd4abd2601a170b1f	supporting information management in digital libraries with map-based interfaces	digital library;digital libraries;map region labelling;map contents;map based interfaces;information management software libraries visualization labeling interactive systems clustering methods ground penetrating radar geophysical measurement techniques context modeling two dimensional displays;map region summarization;self organising feature maps;information management;cartography;map region summarization information management digital libraries map based interfaces self organising map map contents map region labelling;self organising feature maps cartography digital libraries information management;self organising map	The self-organising map (SOM) has been proposed as an alternative interface for exploring digital libraries (DL), in addition to conventional search and browsing. With advanced visualisations assisting the user in understanding the contents of the map and its structure, as well as advanced interaction modes as zooming, panning and area selection, the SOM becomes a feasible alternative to classical search and browse interfaces. Several applications show the SOMs utility for this task. However, there are still shortcomings in helping the user understanding the map - there are insufficient methods developed for describing the map to support the user in the analysis of the map contents. In this paper, we give an overview of existing techniques and applications of SOMs in digital libraries, and present recent work in assisting the user in exploring the map by automatically describing maps using advanced labelling and summarization of map regions. Therewith, the SOM becomes an attractive tool for information management.	digital library;information management;library (computing)	Rudolf Mayer;Angela Roiger;Andreas Rauber	2007		10.1109/ICDIM.2007.4444200	computer vision;digital library;computer science;data mining;multimedia;world wide web	DB	-30.784793600745367	-32.89184612105748	134193
976f5d3a9effa3cc8b26d35f96bd7429e138bf8a	metadata mapper: a web service for mapping data between independent visual analysis components, guided by perceptual rules	systeme temps reel;4230;interfaces;0130c;scientific data;imagerie;web service;algorithm visualization;visualization;imagery;visualisation;region of interest;visual analysis;web services;imagineria;real time systems	The explosion of online scientific data from experiments, simulations, and observations has given rise to an avalanche of algorithmic, visualization and imaging methods. There has also been enormous growth in the introduction of tools that provide interactive interfaces for exploring these data dynamically. Most systems, however, do not support the realtime exploration of patterns and relationships across tools and do not provide guidance on which colors, colormaps or visual metaphors will be most effective. In this paper, we introduce a general architecture for sharing metadata between applications and a “Metadata Mapper” component that allows the analyst to decide how metadata from one component should be represented in another, guided by perceptual rules. This system is designed to support “brushing [1],” in which highlighting a region of interest in one application automatically highlights corresponding values in another, allowing the scientist to develop insights from multiple sources. Our work builds on the component-based iPlant Cyberinfrastructure [2] and provides a general approach to supporting interactive, exploration across independent visualization and visual analysis components.	algorithm;brushing and linking;color;component-based software engineering;cyberinfrastructure;experiment;mapper;region of interest;simulation;web service	Bernice E. Rogowitz;Naim Matasci	2011		10.1117/12.881734	web service;visual analytics;visualization;computer science;data mining;multimedia;world wide web;metadata repository	Visualization	-33.251203129348674	-28.07817062554358	134221
c1222475e8435e4fceb296a47de6ed88e44e8542	traffic related observations by line sensing techniques	3d geographic routing;moving object;gdstr;intelligent transport system;sensor network;image acquisition;sensor networks;cost effectiveness	The use of Wireless Multimedia Sensor Networks (WMSNs) in Intelligent Transportation Systems (ITS) can offer cost effective solutions for gathering data on urban traffic, vehicle velocity, parking, etc. These applications demand real-time image acquisition and computational intensive processing in order to collect relevant information. We present our hardware and software solution for detecting moving objects and evaluating their velocity based on line sensor technology which guarantees fast processing, low storage and bandwidth requirements.	real-time clock;requirement;sensor;velocity (software development)	Mangesh Chitnis;Claudio Salvadori;Matteo Petracca;Giuseppe Lipari;Paolo Pagano	2010		10.1145/1869983.1870029	embedded system;simulation;wireless sensor network;computer science;key distribution in wireless sensor networks;computer security;intelligent sensor	Robotics	-19.32182405538732	-29.40316468853572	134352
f83299737cf128b46dad2b50366c37868cc6e6f1	visualizing dynamic call graphs	e 1 data;data structures;graphs and networks	Visualizing time-varying call graphs is challenging due to vast amounts of data at many dimensions to be displayed: Hierarchically organized vertices with attributes, directed or undirected edges with weights, and time. In this paper, we introduce a novel overview representation that shows dynamic graphs as a timelineand pixelbased aggregated view targeting the preservation of a viewer’s mental map by encoding the time-varying data into a static diagram. This view allows comparisons of dynamic call graphs on different levels of hierarchical granularity. Our data extraction and visualization system uses this overview as a starting point for further investigations by applying existing dynamic graph visualization techniques that show the graph structures and properties more clearly. These more task-specific visualizations show the dynamic graph data from different perspectives such as curved node-link diagrams or glyph-based representations combined by linking and brushing. Intermediate analysis steps can be stored and rebuilt at any time by using corresponding thumbnail representations.	archive;brushing and linking;diagram;eurographics;extensibility;glyph;graph (discrete mathematics);graph drawing;interactivity;mental mapping;pixel;scalability;software system;thumbnail;timeline	Michael Burch;Christoph Müller;Guido Reina;Hansjörg Schmauder;Miriam Greis;Daniel Weiskopf	2012		10.2312/PE/VMV/VMV12/207-214	combinatorics;discrete mathematics;data structure;computer science;theoretical computer science;modular decomposition;complex network	Visualization	-28.78766124308094	-34.72114407740254	134454
078dcfe885400fc206548c0f4c3cb83bf949f6bd	histogram equalization and specification for high-dimensional data visualization using radviz		In our turbine performance assessment, we need to provide an effective visual analytics tool in handling high-dimensional datasets. We have employed RadViz in 2D exploratory data analysis. However, with the increase of dataset size and dimensionality, the clumping of projected data points towards the origin in RadViz causes low space utilization, which largely degenerates the visibility of the feature characteristics. In this study, to better evaluate the hidden patterns in the center region, we propose histogram-based techniques to manipulate the radial distribution of data points in RadViz. We present RadViz in the polar coordinate system for convenient radial operations. Based on this, we define the radial equalization method to automatically spread out the frequency and the radial specification method to shape the distribution based on the user's requirement. Furthermore, we utilize the information in high-dimensional space as histogram and reference point to design and control the radial distribution of RadViz. Computational experiments have been conducted on turbine performance simulation data. Our proposed techniques are shown advantageous in query result display and outlier detection with a set of high-dimensional datasets.	anomaly detection;bus bunching;computation;data point;data visualization;experiment;histogram equalization;image histogram;numerical analysis;performance prediction;radial (radio);radial basis function;requirement;sensor;simulation;user requirements document;visual analytics	Yan-Chao Wang;Qian Zhang;Feng Lin;Chi-Keong Goh;Xuan Wang;Seah Hock Soon	2017		10.1145/3095140.3095155	anomaly detection;data point;computer science;clustering high-dimensional data;artificial intelligence;data visualization;computer vision;visualization;exploratory data analysis;data mining;histogram;histogram equalization	DB	-27.220804941853498	-33.03768444728817	134999
f41f5153cf4d9fffe04209e45a16cb10c5900f50	personnalisation d'analyses décisionnelles sur des données multidimensionnelles	olap en francais;query personalization;analyse decisionnelle;h informatique;user preference;preference utilisateur;analysis context;olap;recommandation de requete;decision support analysis;recommender system;personnalisation de requete;context trees matching;contexte d analyse	This thesis investigates OLAP analysis personalizat ion within multidimensional databases. OLAP analyse is modeled through a graph where nodes represent the analysis contexts and graph edges represent the user operations. The anal ysis context regroups the user query as well as result. It is well described by a specific tree structure that is independent on the visualization structures of data and query language s. We provided a model for user preferences on the multidimensional schema and valu es. Each preference is associated with a specific analysis context. Based on previous models , we proposed a generic framework that includes two personalization processes. First proce ss, denoted query personalization, aims to enhancing user query with related preferences in or der to produce a new one that generates a personalized result. Second personalization process is query recommendation that allows helping user throughout the OLAP data exploration p hase. Our recommendation framework supports three recommendation scenarios, i.e., assisting user in query composition, suggesting the forthcoming query, and suggesting alternative q ueries. Recommendations are built progressively basing on user preferences. In order to implement our framework, we developed a prototype system that supports query personalization and query recommendation processes. We present experimental results showing the efficiency and the effectiveness of our approaches.		Houssem Jerbi	2012			library science;philosophy	DB	-32.6004590676784	-28.53085085130838	135489
656d206282aa9845962aa7d63902d6eb690b7a2b	pedestrian-flow analysis system for improving layout of exhibitions		A system for practical pedestrian-track analysis at an actual exhibition is demonstrated. Track data obtained at the exhibition was uploaded to a spatio-temporal database, and the key features of the technical exhibition were determined. New knowledge derived from these features was successfully applied to improve the layout of the next event.		Akinori Asahara;Nobuo Sato;Masatsugu Nomiya	2015		10.1007/978-3-319-22363-6_25	knowledge extraction;data mining;exhibition;pedestrian;computer science;upload	EDA	-21.94330241668487	-34.19964235436929	135630
3459332eaeb4d609690ef03f8e61a2d97c0b6287	leveraging wi-fi signals to monitor human queues	queue monitoring;sensors;pervasive computing;smart phones;smartphones leveraging wi fi signals monitor human queues wi fi infrastructure wi fi signal patterns;smartphones;monitoring;transportation;ieee 802 11 standards;ieee 802 11 standards monitoring smart phones pervasive computing transportation sensors queueing analysis;wireless lan smart phones;wi fi;queue monitoring smartphones wi fi pervasive computing;queueing analysis	A new approach exploits existing Wi-Fi infrastructure to extract unique Wi-Fi signal patterns from the smartphones of people in lines to estimate wait times. The approach can work under real-world queue scenarios in various environments without requiring a specialized infrastructure or incurring manpower overhead. Furthermore, it only requires that a small fraction of people waiting in line use Wi-Fi on their smartphones.	overhead (computing);smartphone	Yan Wang;Yingying Chen;Richard P. Martin	2014	IEEE Pervasive Computing	10.1109/MPRV.2014.28	embedded system;transport;real-time computing;human–computer interaction;computer science;sensor;ubiquitous computing;computer network	Mobile	-19.857797905982512	-31.222640535958853	135739
bb2684dcba337d86f0d0493cc809daf25bf47fc6	the encourage operators to promote manual flight operations- a pandemic in modern aviation		Advances in technology have enabled increasingly sophisticated automation to be introduced into the flight decks of modern airplanes. Generally, this automation was added to accomplish worthy objectives such as reducing flightcrew workload, adding additional capability, or increasing fuel economy. To a large extent, these objectives have been achieved. Safety also stood to benefit from the increasing amounts of highly reliable automation. Indeed, the current generation of highly automated transport category airplanes has generally demonstrated an improved safety record relative to the previous generation of airplanes. Vulnerabilities do exist, though, and further safety improvements should be made. To provide a safety target to guide the aviation industry, the Secretary of Transportation and others have expressed the view that the aviation industry should strive for the objective of none accidents. Training standards and currency in manual flying skills may well have deteriorated, but are these changes in proportion to the tasks and situations typical of modern operations, or really at the root of handling related safety concerns [9].		Edgard Thomas Martins;Isnard Thomas Martins;Marcelo Márcio Soares	2014		10.1007/978-3-319-07635-5_31	simulation;engineering;aeronautics;transport engineering	SE	-19.542168980651216	-25.450468750498214	136036
bfe18b14eacffa76e42b07f386f27239f56f6d47	visual knowledge annotation and management by using qualitative spatial information	anotacion;technologie communication;analisis cualitativo;vision ordenador;contenu image;consensus;ontologie;image content;multimedia;image processing;analisis espacial;ingenierie connaissances;interrogation base donnee;procesamiento imagen;interrogacion base datos;qualitative analysis;annotation;intelligence artificielle;acquisition connaissances;traitement image;computer vision;internet;analyse qualitative;consenso;busqueda por contenido;knowledge acquisition;artificial intelligence;ontologia;vision ordinateur;inteligencia artificial;communication technology;spatial analysis;adquisicion de conocimientos;contenido imagen;content based retrieval;ontology;database query;recherche par contenu;analyse spatiale;spatial information;tecnologia comunicacion;knowledge engineering	The wide use of the Internet and the increasingly improvement of communication technologies have led users to need to manage multimedia information. In particular, there is an ample consensus about the necessity of new computational systems capable of processing images and “understand” what they contain. Such systems would ideally allow to retrieve multimedia content, to improve the way of storing it or to process the images to get some information interesting for the user. This paper presents a methodology for semi-automatically extracting knowledge from 2D still visual multimedia content, that is, images. The knowledge is acquired through the combination of several approaches: computer vision (to get and to analyse low level features), qualitative spatial analysis (to obtain high level information from low level features), ontologies (to represent knowledge), and MPEG-7 (to describe the information in a standard-way and make the system capable of performing queries and retrieve multimedia content).		Pedro José Vivancos Vicente;Jesualdo Tomás Fernández-Breis;Rodrigo Martínez-Béjar;Rafael Valencia-García	2006		10.1007/11961239_1	computer vision;image processing;computer science;artificial intelligence;knowledge engineering;ontology;spatial analysis;multimedia	AI	-33.36646709855942	-27.60473448625213	136066
818e9feceacd44ae7fefe0128ffbb75dc50342f0	clustering to reduce spatial data set size		Traditionally it had been a problem that researchers did not have access to enough spatial data to answer pressing research questions or build compelling visualizations. Today, however, the problem is often that we have too much data. Spatially redundant or approximately redundant points may refer to a single feature (plus noise) rather than many distinct spatial features. We can use density-based clustering to compress such spatial data into a set of representative features. This paper demonstrates how to reduce the size of a spatial data set of GPS latitude-longitude coordinates using the Python programming language and its scikitlearn implementation of the DBSCAN density-based clustering algorithm. DBSCAN works very well in low-dimension space, such as the two-dimensional feature space in this geospatial example. All of the code discussed here is available in a public repository1 along with the data.		Geoff Boeing	2018	CoRR		machine learning;fold (higher-order function);spatial analysis;cluster analysis;artificial intelligence;mathematics	DB	-26.55221133126168	-32.21637353024813	136407
f328d455484828a64d9fea53af45ac76dfddddf7	an android-based iot system for vehicle monitoring and diagnostic		In this study, a driver behavior analysis tool and an in-vehicle sensor data monitoring system are presented. The study offers a system based on low cost hardware and advanced software capabilities. The embedded system utilizes the information provided by in-car sensors using the Controller Area Network (CAN), an Inertial Measurement Unit (IMU) and a GPS. By combining this information, the driving performance and driving characteristics are determined. Thanks to the GPS position data, instantaneous speed and vehicle information will be displayed on a map based on location. In addition, dozens of vehicle-related sensor data can be accessed by users over the remote server.	can bus;cloud computing;cloud database;embedded system;global positioning system;internet access;sensor;server (computing);virtual private server	Ercument Turk;Moharram Challenger	2018	2018 26th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2018.8404378	humanoid robot;computer science;global positioning system;artificial intelligence;embedded system;computer vision;can bus;android (operating system);software;assisted gps;inertial measurement unit;server	Mobile	-22.115725605183904	-28.972013420696076	136416
1b7b1908173a360a10e4a4b9fa97a5359be2e4bc	answer set programming for procedural content generation: a design space approach	new genera;generators;answer set programming;programming games generators syntactics aerospace electronics concrete algorithm design and analysis;game context answer set programming procedural content generation procedural content generator latent design space domain independent procedure game content domains reference evolutionary content generator generative content design problems;game design;design space;procedural content generation;answer set pro gramming;logic programming;syntactics;games;aerospace electronics;constraint programming;logic programs;programming;algorithm design;algorithm design and analysis;procedural content generation answer set programming constraint programming game design logic programming;concrete	Procedural content generators for games produce artifacts from a latent design space. This space is often only implicitly defined, an emergent result of the procedures used in the generator. In this paper, we outline an approach to content generation that centers on explicit description of the design space, using domain-independent procedures to produce artifacts from the described space. By concisely capturing a design space as an answer set program, we can rapidly define and expressively sculpt new generators for a variety of game content domains. We walk through the reimplementation of a reference evolutionary content generator in a tutorial example, and review existing applications of answer set programming to generative-content design problems in and outside of a game context.	amigaone x1000;answer set programming;chromatic polynomial;color;const (computer programming);declarative programming;download;emergence;flood fill;iteration;iterative design;mathematical optimization;maxima and minima;metaprogramming;pareto efficiency;procedural generation;programming paradigm;python;regular expression;requirement;sampling (signal processing);solver;sourceforge;stable model semantics	Adam M. Smith;Michael Mateas	2011	IEEE Transactions on Computational Intelligence and AI in Games	10.1109/TCIAIG.2011.2158545	algorithm design;simulation;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;algorithm	AI	-27.258851827129586	-25.35325578299543	137141
194acaa749e0709ef03ab3c1eedb8f6ead371b71	animated visual vibrations as an uncertainty visualisation technique	uncertainty visualisation;stereo vision;visual features;vibrating textures	Research into the visualisation of imprecise data is a relatively new field in visualisation. Work is beginning to appear detailing the process of visualising uncertainty in data. Continuing previous work by the author, this paper seeks to extend techniques used to visualise uncertainty from the spatial to the temporal domain, by using visual vibrations to indicate the level of imprecision at a visualised data point. The paper contains an analysis of the present visual features used to indicate imprecision, and then details a methodology for using visual vibrations to display the uncertainty contained in visualised data. Novel additions include addressing chart junk issues outlined by Tufte, additions of perceptual factors and extension to stereo vision applications.	chartjunk;data point;scientific visualization;stereopsis;volume rendering	Ross Brown	2004		10.1145/988834.988849	computer vision;simulation;computer science;stereopsis;multimedia;computer graphics (images)	HCI	-27.383382496870688	-34.23955400689601	137478
cf28f2536cefcdc195cd6170a1f80216e7ae1bf3	stadtpilot: first fully autonomous test drives in urban traffic	road traffic;highway safety;mobile robots;legal factors;urban areas;intelligent vehicles;vehicles safety roads software feature extraction wheels law;braunschweig germany;road vehicles mobile robots road safety road traffic;road safety;system architecture;safety concept autonomous test drives urban traffic stadtpilot project autonomous driving braunschweig inner city ring road leonie autonomous vehicle legal issues homologation process public traffic;road vehicles	The Stadtpilot project aims at autonomous driving on Braunschweig's inner city ring road. For this purpose, an autonomous vehicle called “Leonie” has been developed. In October 2010, after two years of research, “Leonie's” abilities were presented in a public demonstration. This vehicle is one of the first worldwide to show the ability of driving autonomously in real urban traffic scenarios. This paper describes the legal issues and the homologation process for driving autonomously in public traffic in Braunschweig, Germany. It also dwells on the Safety Concept, the system architecture and current research activities.	autonomous car;autonomous robot;bus mastering;collision detection;global positioning system;stadtpilot;system safety;systems architecture	Tobias Nothdurft;Peter Hecker;Sebastian Ohl;Falko Saust;Markus Maurer;Andreas Reschka;Jürgen Rüdiger Böhmer	2011	2011 14th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2011.6082883	vehicle information and communication system;engineering;civil engineering;automotive engineering;transport engineering	Robotics	-21.383901281918185	-25.753759468678805	138363
312929e90b0e929a3a58568793be0a579b1b740f	sketch-based guided modeling of 3d buildings from oriented photos	photogrammetry;3d modeling;guidance	Capturing urban scenes using photogrammetric methods has become an interesting alternative to laser scanning in the past years. For the reconstruction of CAD-ready 3D models, two main types of interactive approaches have become prevalent: One uses the generated 3D point clouds to reconstruct polygonal surfaces, while the other focuses on 2D interaction in the photos to define edges and faces.  We propose a novel interactive system that combines and enhances these approaches in order to optimize current reconstruction and modeling workflows. Our main interaction target are the photos, allowing simple 2D interactions and edge-based snapping. We use the underlying segmented point cloud to define the 3D context in which the sketched polygons are projected whenever possible. An intuitive visual guiding interface gives the user feedback on the accuracy to expect with the current state of modeling to keep the necessary interactions at a minimum level.	3d modeling;acm transactions on graphics;algorithm;cvpr;cloud computing;comet (programming);computation;computer graphics;computer vision;computer-aided design;comstock–needham system;data-driven documents (d3.js);eurographics;fundamental fysiks group;geodetic datum;hartley (unit);interaction;interactivity;linear algebra;mach;machine learning;mobile device;photogrammetry;point cloud;r language;siggraph;sampling (signal processing);server (computing);sketch;smartphone;stereopsis;switzerland;symposium on geometry processing;variational principle	Michael Schwärzler;Lisa-Maria Kellner;Stefan Maierhofer;Michael Wimmer	2017		10.1145/3023368.3023374	computer vision;simulation;photogrammetry;computer graphics (images)	Graphics	-32.82790379986676	-35.47523780487771	138458
3b117aa5f4bc46eadea8a300796cf56c5feee696	guest editorial introduction to the special issue on visual analysis for its		Sensing technologies, social media, and large-scale computing infrastructures have produced a variety of traffic and transportation data, e.g., human mobility, mobile trajectories, mobile phone calls, traffic, and geographical data. Despite the wealth of research on intelligent transportation systems, contemporary analytical tools are often inadequate for handling the data with the character of large volume, sparseness, and heterogeneity, let alone for supporting interactive visual analysis for data-intensive applications. Visual analytics can build bridges between the capability of data processing and human intelligence to promote addressing various transportation problems. On one hand, by employing visual channels to represent datasets and transforming various types of data into appropriate visual components, visualization can enhance understanding and analysis. On the other hand, an interactive interface allows users to investigate and directly access selected data points or features, discover interesting patterns or events, and engage in visual reasoning that allows users to gain insights, e.g., it is desirable to only show the most relevant portions of a dataset while giving directions for potential exploration.		Gennady L. Andrienko;Natalia V. Andrienko;Wei Chen;Ross Maciejewski;Ye Zhao	2017	IEEE Trans. Intelligent Transportation Systems	10.1109/TITS.2017.2724764	artificial intelligence;data point;interactive visual analysis;visual reasoning;visualization;computer vision;data mining;visual analytics;mobile phone;intelligent transportation system;human intelligence;computer science	Robotics	-26.379939584498832	-33.065717621271915	138692
4676ec376afc1275ced5d97da735ab304324dd3e	visualization of structured nonuniform grids	atmospheric science;weather data rendering atmospheric data 3d visualization structured nonuniform grids atmospheric science researchers research weather forecasters graphics hardware grid mapping gpu texture based slicing systems;weather visualization;research needs;grid computing atmospheric techniques meteorological radar data visualisation geophysics computing computer graphic equipment rendering computer graphics;3d visualization;meteorological radar;volume rendering;computer graphic equipment;weather forecasting;grid structures;forecasting model;data visualisation;weather forecasting data visualization rendering computer graphics predictive models meteorological radar atmospheric modeling computational modeling atmospheric measurements radar measurements numerical models;geophysics computing;graphics hardware;numerical model;application sharing;volume visualization weather visualization grid structures volume rendering;volume visualization;atmospheric techniques;rendering computer graphics;grid computing;3d structure	Operational forecasters and weather researchers need accurate visualization of atmospheric data from both computational models and observed data. Although these two applications share some requirements, they have different needs and goals. We've developed a visualization tool for atmospheric science researchers and research weather forecasters that allows the 3D visualization of measured radar data and rendered numerical model data to show the 3D structures as well as how the weather event would look when observed in the field. Our system lets us load the original data directly onto the graphics hardware, with the grid mapping from the rendering space to the grid space programmed on the GPU. This method is flexible enough to handle the grids important in meteorological research and enables the application of advanced visualization methods available in texture-based slicing systems. The visually accurate rendering of weather data can be useful for training weather spotters, evaluating forecasting models, training forecasters to interpret radar data, and comparing sensor data to observed weather events.	computational model;graphics hardware;graphics processing unit;imagery;mathematical model;numerical analysis;projections and predictions;radar;requirement;volume rendering	Kirk Riley;Yuyan Song;Martin Kraus;David S. Ebert;Jason J. Levit	2006	IEEE Computer Graphics and Applications	10.1109/MCG.2006.25	simulation;visualization;weather forecasting;computer science;data science;graphics hardware;volume rendering;data visualization;grid computing;computer graphics (images)	Visualization	-24.711914473279034	-30.631649558028098	138902
a912531481f77233d0220ddd1a784ea3a78155e4	path planning for automated robotic rescue system	graph search;computer languages;man made invasion;disktra path planning robotic rescue graph search breadth first;tsunami;flood;typhoons;mobile robot;path planning;mobile robotics;wireless network;biological system modeling;service robots;poor quality;mobile robots;floods artificial intelligence robots biological system modeling computer languages;artificial intelligent;automated robotic rescue system;disktra;suitable algorithm;robots;breadth first;artificial intelligence;robotic rescue;suitable algorithm path planning automated robotic rescue system water borne disaster flood tsunami typhoons tornados poor quality technological scarcity man made invasion looting hijacking artificial intelligence mobile robotics wireless network;floods;tornados;hijacking;water borne disaster;technological scarcity;service robots mobile robots path planning;looting	In the South Asian region, rivers are the meaning of life. Nearly four thousand years ago people start living there around the delta of Ganges. Still rivers and canals are the main source of food, water, livelihood and also a means of transportation. But water can also make things bitter. In the time of water borne disasters like flood, tsunami; and other disasters like typhoons, tornados; people get stuck into the water. Because of poor quality of living and technological scarcity these people often suffer for long times. To help people in these areas we present a system that can rescue them to a safe place in shortest possible time with the least cost. The same system can also be used in times of accidents and man-made invasions like looting and hijacking. This proposed system is actually comprised of Artificial Intelligence (AI) and Mobile Robotics. It uses sensors, transmitters, receivers and wireless network to communicate and perform. Now firstly the system is proposed by us and then different algorithms are compared, to find out the suitable algorithm which will ensure the minimum time and cost needed.	algorithm;artificial intelligence;mobile robot;motion planning;page hijacking;sensor;transmitter	A. H. M. Iftekharul Ferdous;S. M. Masudur Rahman Al-Arif;Mohammad Sohrab Hasan Nizami;Md. Mohiuddin Abdul Quadir;Mohammad Woli Ullah	2012	Proceedings of the 2012 IEEE 16th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2012.6221896	mobile robot;simulation;computer science;artificial intelligence	Robotics	-23.930643200691662	-27.599542020544945	138990
8d8eb55dfaab1241a9a6e0612e36d5176b664d0f	gem: a python package for graph embedding methods		Many physical systems in the world involve interactions between different entities and can be represented as graphs. Understanding the structure and analyzing properties of graphs are hence paramount to developing insights into the physical systems. Graph embedding, which aims to represent a graph in a low dimensional vector space, takes a step in this direction. The embeddings can be used for various tasks on graphs such as visualization, clustering, classification and prediction.		Palash Goyal;Emilio Ferrara	2018	J. Open Source Software	10.21105/joss.00876	programming language;graph embedding;python (programming language);computer science	ML	-27.659816530876554	-36.33239292728797	139267
65b8be0ca99721e1e0955c3586be1f3b9fff9680	whitelisting system state in windows forensic memory visualizations	single page web application;information visualization;d3 js;memory forensics;forensic visualization tools;incident response	Examiners in the field of digital forensics regularly encounter enormous amounts of data and must identify the few artifacts of evidentiary value. One challenge these examiners face is manual reconstruction of complex datasets with both hierarchical and associative relationships. The complexity of this data requires significant knowledge, training, and experience to correctly and efficiently examine. Current methods provide text-based representations or low-level visualizations, but levee the task of maintaining global context of system state on the examiner. This research presents a visualization tool that improves analysis methods through simultaneous representation of the hierarchical and associative relationships and local detailed data within a single page application. A novel whitelisting feature further improves analysis by eliminating items of less interest from view. Results from a pilot study demonstrate that the visualization tool can assist examiners to more accurately and quickly identify artifacts of interest.		Joshua A. Lapso;Gilbert L. Peterson;James S. Okolica	2017	Digital Investigation	10.1016/j.diin.2016.12.002	information visualization;computer science;data science;operating system;data mining;world wide web;computer security	HCI	-27.029109986142902	-32.06052666443161	139303
107983e8e6318091813eea0988422c90d82a3841	opavion: mining and visualization in large graphs	anomaly detection;interactive visualization;graph mining;degree distribution;visualization;connected component;cloud computing	Given a large graph with millions or billions of nodes and edges, like a who-follows-whom Twitter graph, how do we scalably compute its statistics, summarize its patterns, spot anomalies, visualize and make sense of it? We present OPAvion, a graph mining system that provides a scalable, interactive workflow to accomplish these analysis tasks. OPAvion consists of three modules: (1) The Summarization module (Pegasus) operates off-line on massive, disk-resident graphs and computes graph statistics, like PageRank scores, connected components, degree distribution, triangles, etc.; (2) The Anomaly Detection module (OddBall) uses graph statistics to mine patterns and spot anomalies, such as nodes with many contacts but few interactions with them (possibly telemarketers); (3) The Interactive Visualization module (Apolo) lets users incrementally explore the graph, starting with their chosen nodes or the flagged anomalous nodes; then users can expand to the nodes' vicinities, label them into categories, and thus interactively navigate the interesting parts of the graph.  In our demonstration, we invite our audience to interact with OPAvion and try out its core capabilities on the Stack Overflow Q&A graph that describes over 6 million questions and answers among 650K users.	anomaly detection;connected component (graph theory);degree distribution;google questions and answers;interaction;interactive visualization;interactivity;online and offline;pagerank;pegasus;scalability;stack overflow;structure mining	Leman Akoglu;Duen Horng Chau;U. Kang;Danai Koutra;Christos Faloutsos	2012		10.1145/2213836.2213941	anomaly detection;degree distribution;connected component;visualization;interactive visualization;cloud computing;computer science;theoretical computer science;data mining;database;graph;world wide web;graph operations;graph database	ML	-28.52935216052422	-35.36632580429941	139307
b66bb4f3ac1d5519d40a602205b6e4cf0da27736	5ws model for big data analysis and visualization	data visualization receivers analytical models educational institutions data models visualization mobile communication;analytical models;bigdata visualization;data dimensions;security of data big data data analysis data visualisation;data density;receivers;data visualisation;data analysis;visualization;bigdata pattern;big data;data visualization;mobile communication;bigdata analysis;security of data;conference proceeding;bigdata visualization bigdata analysis bigdata pattern data dimensions data density;network security iscx2012 dataset 5ws model big data analysis big data visualization traditional database management tools visual clustering;data models	Big Data, which contains image, video, text, audio and other forms of data, collected from multiple datasets, is difficult to process using traditional database management tools or applications. In this paper, we establish the 5Ws model by using 5Ws data dimension for Big Data analysis and visualization. 5Ws data dimension stands for, What the data content is, Why the data occurred, Where the data came from, When the data occurred, Who received the data and How the data was transferred. This framework not only classifies Big Data attributes and patterns, but also establishes density patterns that provide more analytical features. We use visual clustering to display data sending and receiving densities which demonstrate Big Data patterns. The model is tested by using the network security ISCX2012 dataset. The experiment shows that this new model with clustered visualization can be efficiently used for Big Data analysis and visualization.	big data;cluster analysis;database;network security	Jinson Zhang;Mao Lin Huang	2013	2013 IEEE 16th International Conference on Computational Science and Engineering	10.1109/CSE.2013.149	data modeling;visualization;mobile telephony;interactive visual analysis;computer science;data science;data warehouse;data mining;database;data analysis;world wide web;data visualization	DB	-24.358569480277215	-34.30869799073957	139402
588b4a031fed82183be1e87b777faf0f8d628c01	reliable and low-cost cyclist collision warning system for safer commute on urban roads	pragmatics;sensors;acoustics;laser radar;roads;alarm systems;hardware	Collision warning and avoidance is a well-established area of research for the automotive industry. However, there is little research towards vitally important collision warning systems for cyclists, who are increasingly jeopardized by motorists on urban roads, especially as quiet, fast electric vehicles become more popular. This paper describes the hardware and software of a low-cost collision warning system for cyclists. Installed on the back of a bike seat, the system consists of a single-beam laser rangefinder and two ultrasonic sensors that detect oncoming vehicles from behind, two handlebar eccentric mass vibrators that provide left and right haptic feedback to the cyclist, and a taillight that warns oncoming vehicles. Executed by an Arduino microcontroller, its software consists of a fuzzy rule-based inference system (FIS), which computes the collision risk and generates appropriate warning signals in a similar way to how a cyclist would assess collision risk based on the distance, velocity and direction of an approaching vehicle. The device was prototyped and statistically evaluated by a survey taken from a pool of seven participants. The participants tested the system before and after receiving initial training. The experimental results demonstrate the efficacy of the proposed system in warning cyclists in an intuitive manner, without distracting them.	arduino;experiment;fuzzy logic;fuzzy rule;global positioning system;haptic technology;inference engine;logic programming;microcontroller;sensor;serial ata;velocity (software development)	Jessica Van Brummelen;Bara J. Emran;Kurt Yesilcimen;Homayoun Najjaran	2016	2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2016.7844814	lidar;embedded system;simulation;computer science;sensor;computer security;pragmatics	Robotics	-19.826930348598477	-27.98752008618406	139501
edcdb2974122dcd39168bb40cbdafd10e7c755f4	flight deck automation and task management	aircraft control;human factors aircraft control safety;manufacturing automation accidents aerospace control air safety aerospace safety human factors design automation aircraft propulsion automatic control technology management;human factors;safety;task management;advanced technology aircraft flight deck automation task management attention allocation	INTRODUCTION The last two decades have brought significant change to the commercial transport aircraft flight deck. Complex functions once performed by human pilots are now routinely performed by automated systems. Autoflight systems control aircraft altitude, heading, and speed as selected by the pilots. Flight management systems (FMSs) allow the human flightcrew to pre-program flight paths, complete with altitude and speed restrictions, then couple through the autoflight systems to fly those paths accurately and economically.	course (navigation)	Ken Funk;Candy Suroteguh;Jennifer Wilson;Beth Lyall	1998		10.1109/ICSMC.1998.725523	simulation;computer science;human factors and ergonomics	Robotics	-22.076944371122107	-25.16067835607939	139732
81c0257d5398a9b0974f06fb83053601ce7ec2cb	georss based emergency response information sharing and visualization	emergency information;central map;geographic information systems;spatial information;emergency response information visualization;georss;emergency response information;emergency services;geographically encoded objects;emergency response;really simple syndication;information services;rss feeds;pool information;emergency response information sharing;georss technology;emergency response team;emergency event;real time	Spatial information played a very important role in these emergency responses. Map can easily show where and how the emergency event is happening. In order to map the emergency response information on real time, Geographically Encoded Objects for RSS (Really Simple Syndication) feeds which called GeoRSS technology is used. GeoRSS technology is a way to encode location in RSS feeds. GeoRSS could provide an easy way for emergency response teams to pool information onto one central map. An example demo of forest fire will be shown how to share and visualizing the emergency information based on GeoRSS. In the end, we will talk about the tendency of the GeoRSS and the future work.	encode;georss;rss;web syndication	An Zhang;Qingwen Qi;Lili Jiang	2007	Third International Conference on Semantics, Knowledge and Grid (SKG 2007)	10.1109/SKG.2007.80	computer science;data mining;rss;spatial analysis;geographic information system;internet privacy;world wide web;computer security;information system	Robotics	-22.86564376244922	-33.139997113211756	139743
2953d1a30de9b21962a8ea643c59256ef7695380	an architecture for biological information extraction and representation	filtering;software tool;information extraction;text mining;information retrieval;structure formation;heterogeneous data;information discovery;software architecture;information representation;interactive text mining;management tool;biological data;user guided information extraction;object model;bioinformatics;heterogeneous data sources	Technological advances in biomedical research are generating a plethora of heterogeneous data at a high rate. There is a critical need for extraction, integration and management tools for information discovery and synthesis from these heterogeneous data. In this paper, we present a general architecture, called ALFA, for information extraction and representation from diverse biological data. The ALFA architecture consists of: (i) a networked, hierarchical object model for representing information from heterogeneous data sources in a standardized, structured format; and (ii) a suite of integrated, interactive software tools for information extraction and representation from diverse biological data sources. As part of our research efforts to explore this space, we have currently prototyped the ALFA object model and a set of interactive software tools for searching, filtering, and extracting information from scientific text. In particular, we describe BioFerret, a meta-search tool for searching and filtering relevant information from the web, and ALFA Text Viewer, an interactive tool for user-guided extraction, disambiguation, and representation of information from scientific text. We further demonstrate the potential of our tools in integrating the extracted information with experimental data and diagrammatic biological models via the common underlying ALFA representation.	biological models;biomedical research;data sources;diagram;genetic heterogeneity;information discovery;information extraction;search engine;word-sense disambiguation	Aditya Vailaya;Peter Bluvas;Robert Kincaid;Allan Kuchinsky;Michael L. Creech;Annette Adler	2004	Bioinformatics	10.1145/967900.967924	filter;software architecture;text mining;object model;biological data;structure formation;computer science;data science;machine learning;data mining;database;world wide web;information extraction;information retrieval	HPC	-31.372150111700126	-28.86271031458066	139804
3bf90776fb2d87787a81e492bee06717b85ccc35	design of a user-oriented application for the exploration of medical datasets	user interface;interactive visualization;software systems;development process;health professionals;medical visualization;nuclear medicine;data handling;work in progress	In this paper we describe the experiences we have made when designing a user-oriented software system allowing the interactive visual analysis of medical datasets. We give an overview of the work in progress regarding the system and explain how data handling as well as interactive exploration of medical datasets of different modalities is supported. All design decisions made within the development process of the proposed system have been made in cooperation with health professionals from the domains of radiology as well as nuclear medicine.		Timo Ropinski;Jennis Meyer-Spradow;Frank Steinicke;Klaus H. Hinrichs	2006	Elektrotechnik und Informationstechnik	10.1007/s00502-006-0331	visual analytics;information visualization;interactive visualization;human–computer interaction;computer science;data science;group method of data handling;work in process;data mining;user interface;software development process;software system	NLP	-28.15261585809978	-31.07722305156756	140046
0d21d67295d1d93c0b0b445f2f0e5589d8db6f77	mexica-impro: a computational model for narrative improvisation		This paper describes a system that dynamically generate narratives through improvisation. MEXICA-impro is based on a cognitive account of the creative process called engagement-reflection. Its architecture defines a framework where two agents participate in a simulated improvisation session to generate the plot of a story in which each one draws knowledge from two different databases representing cultural backgrounds. A worked example is explained in detail to show how this approach produces novel stories that could not be generated before.	computation;computational model;database;impro-visor	Rafael Pérez y Pérez;Santiago Negrete;Eduardo Peñalosa;Rafael Ávila;Vicente Castellanos-Cerda;Christian Lemaître	2010			natural language processing;architecture;improvisation;communication;narrative;cognition;computer science;artificial intelligence;plot (narrative)	AI	-31.536532488094153	-24.638303010177353	140091
877d57a2169c471e0d4f2623e9a506777a76ca18	exploring human-robot trust: insights from the first 1000 subjects	egress choke point human robot trust emergency evacuation situation automatic alarm;robots fires context modeling predictive models human robot interaction inductors game theory;rescue robots fires human robot interaction	Our work explores the possibility of using robots to aid humans in emergency evacuation situations [1, 2] Contrary to popular belief, the greatest risk to people during an emergency is not panic. Rather, it is the tendency to disregard automatic alarms and wait for further instructions [3]. Robots offer the possibility of providing individualized directions during an emergency. We believe that tailored directions will encourage people to take the emergency seriously. Robots might also alleviate congestion at egress choke points, an issue which has led to increased fatalities in some fires. During a fire, for example, a robot might direct some portion of evacuees to alternative egress points, thus easing congestion at these choke points and improving survivability.	egress filtering;humans;network congestion;robot	Alan R. Wagner	2015	2015 International Conference on Collaboration Technologies and Systems (CTS)	10.1109/CTS.2015.7210395	simulation;artificial intelligence;operations research;computer security	Robotics	-20.32258298786099	-25.932141831561825	140824
574579108183bab208f4713a3feead4e9e337d7c	research on technology for reducing sudden pedestrian or cyclist accidents with vehicles	signal generators;traffic accident;road accidents;magnetic field;rfid technology;pedestrian cyclist accident prevention;road traffic;rfid tag;safety driving support system;support system;vehicle driving vehicle safety road accidents rfid tags signal generators magnetic fields technical activities guide tag intelligent transportation systems radiofrequency identification repeaters;lf signal generator;sudden vehicle traffic accidents;lf signal generator pedestrian cyclist accident prevention rfid technology safety driving support system sudden vehicle traffic accidents;road safety;signal generators driver information systems radiofrequency identification road accidents road safety road traffic road vehicles;driver information systems;radiofrequency identification;road vehicles	We are currently studying a new application system of RFID technology for a safety driving support system for reducing the number of sudden vehicle traffic accidents involving pedestrians or cyclists near intersections. [1], [2] We have investigated an experimental system that senses the existence and position of pedestrians and cyclists using an active tag, sends the sensed data to an on-board device of a vehicle near their position and alerts the driver. The active tag can be carried by pedestrians or installed on bicycles. When the tag enters the area of magnetic field generated by the LF-signal generator, it is excited and transmits the tag ID, together with the position data, to indicate the precise position of the object. The moving direction and speed of the pedestrian or cyclist can be calculated from the position data sensed by the RFID tag passing over appropriately separated two LF-signal generators. The occurrence risk of a sudden traffic accident can be estimated from the relation of positions and speeds between the pedestrian/cyclist and the vehicle moving near the intersection. Then it can alert the driver of a vehicle. We report the summary of our system and the collection and analysis results of the basic data based on the system which aims at the reduction of traffic accidents resulting from the sudden appearance of a pedestrian or a cyclist in a vehicle path.	caller id;experimental system;norm (social);on-board data handling;pedestrian detection;radio wave;radio-frequency identification	Hideo Oda;Claudia Hentschel;Yoshiharu Okamoto	2007	2007 IEEE Intelligent Transportation Systems Conference	10.1109/ITSC.2007.4357641	engineering;automotive engineering;transport engineering;computer security	Robotics	-19.23080811840187	-28.758160314735726	140993
4719b1b37fb41d5e76e313280ba83ad5dc0094f3	sma4td: a social media analysis methodology for trajectory discovery in large-scale events		The widespread use of social media platforms allows scientists to collect huge amount of data posted by people interested in a given topic or event. This data can be analyzed to infer patterns and trends about people behaviors related to a topic or an event on a very large scale. Social media posts are often tagged with geographical coordinates or other information that allows identifying user positions, this way enabling mobility pattern analysis using trajectory mining techniques. This paper describes SMA4TD, a methodology for discovering behavior and mobility patterns of users attending large-scale public events, by analyzing social media posts. The methodology is demonstrated through two case studies. The first one is an analysis of geotagged tweets for learning the behavior of people attending the 2014 FIFA World Cup. The second one is a mobility pattern analysis on the Instagram users who visited EXPO 2015. In both cases, a very high correlation (Pearson coefficient 0.7–0.9) was measured between official attendee numbers and those produced by our analysis. This result shows the effectiveness of the proposed methodology and confirms its accuracy.	social media	Eugenio Cesario;Fabrizio Marozzo;Domenico Talia;Paolo Trunfio	2017	Online Social Networks and Media	10.1016/j.osnem.2017.10.002	urban computing;data mining;pearson product-moment correlation coefficient;trajectory;social media;social network;geography	ML	-19.207872355927197	-35.213826887706745	141198
f1f309227e1ab8f62c1226af9d6262f39ba1fcd8	icarus: minimizing human effort in iterative data completion		An important step in data preparation involves dealing with incomplete datasets. In some cases, the missing values are unreported because they are characteristics of the domain and are known by practitioners. Due to this nature of the missing values, imputation and inference methods do not work and input from domain experts is required. A common method for experts to fill missing values is through rules. However, for large datasets with thousands of missing data points, it is laborious and time consuming for a user to make sense of the data and formulate effective completion rules. Thus, users need to be shown subsets of the data that will have the most impact in completing missing fields. Further, these subsets should provide the user with enough information to make an update. Choosing subsets that maximize the probability of filling in missing data from a large dataset is computationally expensive. To address these challenges, we present ICARUS, which uses a heuristic algorithm to show the user small subsets of the database in the form of a matrix. This allows the user to iteratively fill in data by applying suggested rules based on their direct edits to the matrix. The suggested rules amplify the users’ input to multiple missing fields by using the database schema to infer hierarchies. Simulations show ICARUS has an average improvement of 50% across three datasets over the baseline system. Further, in-person user studies demonstrate that naive users can fill in 68% of missing data within an hour, while manual rule specification spans weeks. PVLDB Reference Format: Protiva Rahman, Courtney Hebert, Arnab Nandi. ICARUS: Minimizing Human Effort in Iterative Data Completion. PVLDB, 11 (13): 2263-2276, 2018. DOI: https://doi.org/10.14778/3275366.3275374	algorithm;analysis of algorithms;baseline (configuration management);computer simulation;data point;data pre-processing;database schema;geo-imputation;heuristic (computer science);iterative method;missing data;sukumar nandi;the matrix;usability testing	Protiva Rahman;Courtney Hebert;Arnab Nandi	2018	PVLDB	10.14778/3275366.3275374	data mining;imputation (statistics);database schema;heuristic (computer science);missing data;hierarchy;matrix (mathematics);inference;icarus;computer science	DB	-31.4168622718614	-31.524727338741183	141230
619ee8b02a941d13ff0226bc1a8a4e77cfb86310	leveraging spatial join for robust tuple extraction from web pages	spatial join;tuple extraction;wrapper	Extracting tuples from HTML pages has been an important issue in various web applications. Commercial tuple extraction systems have enjoyed some success to extract tuples by regarding HTML pages as tree structures and exploiting XPath queries to find attributes of tuples in the HTML pages. However, such systems would be vulnerable to small changes on the web pages. In this paper, we propose a robust tuple extraction system which utilizes spatial relationships among elements rather than the XPath queries. Spatial information (e.g., 2-D coordinates) of elements are maintained in the DOM tree when a web page is rendered in a browser. Our system regards elements in the rendered page as spatial objects in the 2-D space and executes spatial joins to extract target elements. Since humans also identify an element in a web page by its relative spatial location, our system extracting elements by their spatial relationships could possibly be as robust as manual extraction. To specify and execute spatial joins, we propose a new query language, RAQuery, based on topological relationships between any spatial objects in the 2-D space. We then propose spatial join algorithms that efficiently process the RAQuery using novel notions of group match and prunable relation group. We next propose a tuple construction algorithm to build tuples from the extracted elements obtained by the spatial joins, which can construct tuples even when there are no boundary HTML elements specified for the tuples in the web page. Extensive experimental results using real HTML pages confirm that our solutions are far more robust than existing tuple extraction systems without sacrificing performance.	web page	Wook-Shin Han;Wooseong Kwak;Hwanjo Yu;Jeong-Hoon Lee;Min-Soo Kim	2014	Inf. Sci.	10.1016/j.ins.2013.09.027	tuple;computer science;tuple space;data mining;database;world wide web	DB	-29.26832069101091	-29.150371790890485	141358
39b592ce38340e072536263910d7e42670200493	evolving interesting maps for a first person shooter	first person shooters;search based;procedural content generation;games;evolutionary algorithms;player experience;evolutionary algorithm;first person shooter;fitness function	We address the problem of automatically designing maps for first-person shooter (FPS) games. An efficient solution to this procedural content generation (PCG) problem could allow the design of FPS games of lower development cost with near-infinite replay value and capability to adapt to the skills and preferences of individual players. We propose a search-based solution, where maps are evolved to optimize a fitness function that is based on the players’ average fighting time. For that purpose, four different map representations are tested and compared. Results obtained showcase the clear advantage of some representations in generating interesting FPS maps and demonstrate the promise of the approach followed for automatic level design in that game genre.	cartography;cube 2: sauerbraten;experiment;first person shooter;fitness function;floating point systems;level design;map;numerical analysis;procedural generation;replay value;usability testing	Luigi Cardamone;Georgios N. Yannakakis;Julian Togelius;Pier Luca Lanzi	2011		10.1007/978-3-642-20525-5_7	simulation;engineering;artificial intelligence;multimedia	AI	-27.870319948953163	-24.835901285917828	141402
3f92a52c6823d7be1a7672be56333b3379a778b0	temporal graph algebra		Graph representations underlie many modern computer applications, capturing the structure of such diverse networks as the Internet, personal associations, roads, sensors, and metabolic pathways. While analysis of static graphs is a well-explored field, new emphasis is being placed on understanding and representing the ways in which networks change over time. Current research is delving into graph evolution rate and mechanisms, the impact of specific events on network evolution, and spatial and spatio-temporal patterns. However, systematic support for evolving graph querying and analytics still lacks. Our goal is to fill this gap, giving users an ability to concisely express a wide range of common analysis tasks.  In this paper we combine advances in graph databases and in temporal relational databases and propose an evolving graph model, including a representation called TGraph and an algebra called TGA, that adheres to point-based semantics. TGA includes principled temporal generalizations of conventional graph operators, as well as novel operators that support exploratory analysis of evolving graphs at different levels of temporal and structural granularity.	computer;graph algebra;graph database;internet;relational database;sensor;truevision tga	Vera Zaychik Moffitt;Julia Stoyanovich	2017		10.1145/3122831.3122838	database;graph (abstract data type);operator (computer programming);graph algebra;graph database;relational database;computer science;theoretical computer science;graph rewriting;generalization;machine learning;artificial intelligence;analytics	DB	-29.573612355169534	-32.10604416548503	141687
00c31127d4f16e6413eda2925434b5fd586aed70	a tale of three cities: looking at the trending feature on foursquare	foursquare location based social networks trending social computing;trending pattern foursquare trending feature temporal pattern categorical trend new york city pittsburgh erie food based venue nightlife venue;social computing;cities and towns market research social network services educational institutions usa councils blogs sociology;social networking online;trending;foursquare;location based social networks	This study examines and compares the temporal patterns and categorical trends of Foursquare's trending feature in three cities in the U.S. The three cities in our experiment are New York City, NY, Pittsburgh, PA and Erie, PA. We show that large cities like New York City trend more often and more consistently through time, while trending in smaller cities is influenced by holidays and weekend events. We also examine common categories of venues that trend in our test cities and see a similar theme in each city favoring food-based venues, nightlife venues and other venues. The purpose of this work is to gain a basic understanding of trending patterns in different cities and to understand why certain venues trend and others do not.		Cristina Robles;Jessica G. Benner	2012	2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on Social Computing	10.1109/SocialCom-PASSAT.2012.123	computer science;social computing	SE	-19.833436785452975	-35.456440951983524	142025
05d00d99619f90009c3148132c74cd2e14995e08	mining and visualizing eye movement data		Eye movement data has a spatio-temporal nature which makes the design of suitable visualization techniques a challenging task. Moreover, eye movement data is typically recorded by tracking the eyes of various study participants in order to achieve significant results about applied visual task solution strategies. If we have to deal with vast amounts of eye movement data, a data preprocessing in form of data mining is useful since it can be applied to compute a set of rules. Those aggregate, filter, and hence reduce the original data to derive patterns in it. The generated rule sets are still large enough to serve as input data for a visual analytics system. In this paper we describe a visual analysis model for eye movement data combining data mining and visualization with the goal to get an impression about point-of-interest (POI) and area-of-interest (AOI) correlations in eye movement data on different levels of spatial and temporal granularities. Those correlations can support a data analyst to derive visual patterns that can be mapped to data patterns, i.e., visual scanning strategies with different probabilities of a group of eye tracked people. We show the usefulness of our data mining and visualization system by applying it to datasets recorded in a formerly conducted eye tracking experiment investigating the readability of metro maps.	aggregate data;algorithm;data mining;data pre-processing;eye tracking;interactive visualization;map;point of interest;preprocessor;visual analytics	Michael Burch	2017		10.1145/3139295.3139304	computer vision;visualization;visual search;creative visualization;visual analytics;data pre-processing;artificial intelligence;information visualization;eye movement;eye tracking;computer science	ML	-26.471412585604327	-33.696457740021756	142207
cc777b7ab414fd61a8749569cbee58b5f65338c1	assessing the accuracy of volunteered geographic information arising from multiple contributors to an internet based collaborative project		The recent rise of neogeography and citizen sensing has increased the opportunities for the use of crowdsourcing as a means to acquire data to support geographical research. The value of the resulting volunteered geographic information is, however, often limited by concerns associated with its quality and the degree to which the contributing data sources may be trusted. Here, information on the quality of sources of volunteered geographic information was derived using a latent class analysis. The volunteered information was on land cover interpreted visually from satellite sensor images and the main focus was on the labeling of 299 sites by seven of the 65 volunteers who contributed to an Internet-based collaborative project. Using the information on land cover acquired by the multiple volunteers it was shown that the relative, but not absolute, quality of the data from different volunteers could be characterized accurately. Additionally, class-specific variations in the quality of the information provided by a single volunteer could be characterized by the analysis. The latent class analysis, therefore, was able to provide information on the quality of information provided on an interand intra-volunteer basis.	crowdsourcing;geographic information system;internet;john d. wiley;latent class model;volunteered geographic information	Giles M. Foody;Linda M. See;Steffen Fritz;Marijn Van der Velde;Christoph Perger;Christian Schill;Doreen S. Boyd	2013	Trans. GIS	10.1111/tgis.12033	geography;data mining;volunteered geographic information;internet privacy;information retrieval	HCI	-22.265787820658222	-32.38878648246725	142380
15b4a00e2bec5ee225052109beb4cbe4f1deca48	the livehoods project: utilizing social media to understand the dynamics of a city	social computing;smart cities;check ins;location based;computer science;foursquare;urban computing;mobile computing;urban design;social media;location based social networks;geography	Studying the social dynamics of a city on a large scale has traditionally been a challenging endeavor, often requiring long hours of observation and interviews, usually resulting in only a partial depiction of reality. To address this difficulty, we introduce a clustering model and research methodology for studying the structure and composition of a city on a large scale based on the social media its residents generate. We apply this new methodology to data from approximately 18 million check-ins collected from users of a location-based online social network. Unlike the boundaries of traditional municipal organizational units such as neighborhoods, which do not always reflect the character of life in these areas, our clusters, which we call Livehoods, are representations of the dynamic areas that comprise the city. We take a qualitative approach to validating these clusters, interviewing 27 residents of Pittsburgh, PA, to see how their perceptions of the city project onto our findings there. Our results provide strong support for the discovered clusters, showing how Livehoods reveal the distinctly characterized areas of the city and the forces	cluster analysis;social dynamics;social media;social network	Justin Cranshaw;Raz Schwartz;Jason I. Hong;Norman M. Sadeh	2012			social science;simulation;urban design;social media;computer science;sociology;mobile computing;world wide web;social computing	HCI	-19.590475446885627	-35.42458288969331	142497
1c1bb5945c32d5917c79a6b326ba49a27c4d50a3	a user study in similarity measures for graph drawing	orthogonality;dessin;graph drawing;user study;graphe interactif;estiramiento;similitude;etirage;dibujo;drawing;indexing;pictural drawing;browsing damage;indexation;ramoneo;similarity;indizacion;similitud;similarity measure;abroutissement;human perception;orthogonalite;ortogonalidad	The need for a similarity measure for comparing two drawings of graphs arises in problems such as interactive graph drawing and the indexing or browsing of large sets of graphs. Many applications have been based on intuitive ideas of what makes two drawings look similar — for example, the idea that vertex positions should not change much. In this paper, we formally define several of these intuitive ideas of similarity and present the results of a user study designed to evaluate how well these measures reflect human perception of similarity. Communicated by Michael Kaufmann: submitted February 2001;revised January 2002 and June 2002. Research supported in part by the National Science Foundation under grants CCR– 9732327, CCR–0098068 and CDA–9703080, and by the U.S. Army Research Office under grant DAAH04-96-1-0013. Work completed while the first author was at Brown University. Bridgeman and Tamassia, Similarity Measures , JGAA, 6(3) 225-254 (2002) 226	graph drawing;journal of graph algorithms and applications;similarity measure;usability testing	Stina S. Bridgeman;Roberto Tamassia	2000		10.1007/3-540-44541-2_3	similarity;orthogonality;computer science;similitude;data mining;mathematics;geometry;graph drawing;information retrieval;drawing	NLP	-29.856103059506683	-36.835716210226295	142566
8dc00ae105ae268a3818a642be7288afd1ca55a0	from visualization to visual mining: application to environmental data	data visualization ocean temperature data engineering animation data analysis data mining decision making human computer interaction information analysis sea surface;visual mining;human computer interaction;heterogeneous data;information management data acquisition data analysis data mining data visualisation decision making environmental science computing;data mining;scientific visualization;environmental science computing;immersive visualization visual mining environmental data acquisition environmental data management environmental data analysis environmental data dissemination decision making visualization tools human computer interaction bioinformatics software visualization;data visualisation;data analysis;visualization technique;information management;environmental data;comprehension visual mining environmental data scientific visualization;technological change;data acquisition;comprehension;software visualization	In the last decade, the technological changes in environmental data acquisition, management, analysis, and dissemination have been astounding. However, extracting patterns and knowledge for decision-making is still tedious essentially because the human capacity to comprehend such large amount of heterogenous data. Visualization tools are required to allow identifying relationships and patterns that are not evident from raw data. Several techniques have been proposed; most often they are borrowed from other fields such as human computer interaction (HCI) and recently bio-informatics and software visualization. This paper discusses some of the limitations of the existing visualization techniques while introducing the concept of visual mining. An illustrative exemplar from immersive visualization is given.	bioinformatics;british informatics olympiad;data acquisition;human computer;human–computer interaction;software visualization	Elaheh Mozzafari;Ahmed Seffah	2008	First International Conference on Advances in Computer-Human Interaction	10.1109/ACHI.2008.29	software visualization;technological change;comprehension;visual analytics;scientific visualization;information visualization;human–computer interaction;computer science;data science;data mining;information management;data acquisition;data analysis	Visualization	-28.8157019594326	-30.845385943338577	142657
7dd89c427c8313da4715c45a3875ec258b687bde	an improved diversity visualization system for multivariate data	data visualization;visual analytics;big data;visual information seeking mantra	Exploring and analyzing data is becoming increasingly difficult due to the growth of data. Visual analytics tools can be an attractive solution to support the process to derive insights from data. Currently, there are many visual representation methods to visualize the diversity in multivariate data sets. However, most of these applications focus on visual representation problems, and these solutions support limited interactive components for users to effectively explore and analyze data on screen. In this paper, the adaptive diversity table (ADT) is proposed to solve the visual representation problems (occlusion and technique interference). Furthermore, it integrates the mantra techniques to support users to accomplish seven important tasks (i.e. overview, zoom, filter, details-on-demand, relate, history, and extract) that are useful for high dimensional data exploration and data analysis. Experimental results show that the proposed ADT is a better visual representation as compared to other prior techniques. Majority of the respondents prefers to use the proposed ADT over the other visual representation methods. User studies also show that the proposed ADT is more useful as it enables the respondents to be more efficient in analyzing the data sets provided.	interference (communication);usability testing;visual analytics	Mee-Chin Wee	2017	J. Visualization	10.1007/s12650-016-0380-8	big data;data visualization;data science;data mining;visualization;visual analytics;multivariate statistics;computer science	Visualization	-27.065273357393036	-34.48407669835956	142721
03d7a42fbaaaf6e69e93a43cf8faf30504ef93f3	parallel graphics and visualization	guest editorial;parallel graphics	Computer Graphics and Visualization are two fields that continue to evolve at a fast pace, always addressing new application areas and achieving better and faster results. The volume of data processed by such applications keeps getting larger and the illumination and light transport models used to generate pictorial representations of this data keep getting more sophisticated. Richer illumination and light transport models allow the generation of richer images that convey more information about the phenomenons or virtual worlds represented by the data and are more realistic and engaging to the user. The combination of large data sets, rich illumination models and large, sophisticated displays results in huge workloads that cannot be processed sequentially and still maintain acceptable response times. Parallel processing is thus an obvious approach to such problems, creating the field of Parallel Graphics and Visualization. The Eurographics Symposium on Parallel Graphics and Visualization (EGPGV) gathers together researchers from all over the world to foster research focused on theoretical and applied issues critical to parallel and distributed computing and its application to all aspects of computer graphics, virtual reality, scientific and engineering visualization. This special issue is a collection of five papers selected from those presented at the 7th EGPGV, which took place in Lugano, Switzerland, in May, 2007. The research presented in this symposium has evolved over the years, often reflecting the evolution of the underlying systems’ architectures. While papers presented in the first few events focused on Single Instruction Multiple Data and Massively Parallel Multi-Processing systems, in recent years the focus was mainly on Symmetric Multiprocessing machines and PC clusters, often also including the utilization of multiple Graphics Processing Units. The 2007 event witnessed the first papers addressing multicore processors, thus following the general trend of computer systems’ architecture. The paper by Wald, Ize and Parker discusses acceleration structures for interactive ray tracing of dynamic scenes. They propose the utilization of Bounding Volume Hierarchies (BVH), which for deformable scenes can be rapidly updated by adjusting the bounding primitives while maintaining the hierarchy. To avoid a significant performance penalty due to a large mismatch between the scene	bounding volume hierarchy;central processing unit;computer architecture;computer graphics;distributed computing;eurographics;illumination (image);image;multi-core processor;parallel processing (dsp implementation);ray tracing (graphics);simd;switzerland;symmetric multiprocessing;virtual reality;virtual world	Bruno Raffin;Han-Wei Shen;Dirk Bartz	2005	Parallel Computing	10.1016/j.parco.2005.02.002	scientific visualization;information visualization;interactive visualization;computer science;parallel rendering;real-time computer graphics;graphics software;computer graphics;3d computer graphics;computer graphics (images)	Visualization	-28.19025928304072	-32.002967689839316	143226
e87968e3a08a3ff535f16563b285dead1f920543	continuous plan management support for space missions: the raxem case	space missions	This paper describes R AXEM , an AI-based system developed to support human mission planners in the daily task to pl an uplink commands for an interplanetary spacecraft. The inte lligent environment of RAXEM has been designed to support the users in analyzing the problem and taking planning decisions as a res ult of an interactive process. The system combines different ingr edients like integrating flexible automated algorithms, promoting user active participation during problem solving, and guaranteeing co ntinuity of work practice. The paper touches upon all these aspects and c omments on how a key factor for success has been the integration of intelligent technology to continuously support mission pl an management.	algorithm;mental substance;problem solving;telecommunications link	Amedeo Cesta;Gabriella Cortellessa;Michel Denis;Alessandro Donati;Simone Fratini;Angelo Oddi;Nicola Policella;Erhard Rabenau;Jonathan Schulster	2008		10.3233/978-1-58603-891-5-703	simulation;computer science;artificial intelligence;space exploration	Robotics	-33.44186619240205	-24.039874706924138	143239
ccba541f725a4367b379bddb5e0f7c317c2f5112	guest editorial: infovis 2005	pediatrics;application software;computer graphics;data analysis;data visualization;computer displays;data visualization data analysis computer science computer graphics information analysis computer displays application software pediatrics frequency educational institutions;computer science;frequency;information analysis	THREE papers in this issue of IEEE Transactions on Visualization and Computer Graphics (TVCG) are expanded versions of ones presented at InfoVis 2005. These examples of the cutting edge of information visualization research showcase the diversity and depth of the field, illustrating new display techniques as well as novel application domains for information visualization systems. The three papers focus on the visualization of three different styles of data: graph-based data, time series data, and categorical data. The techniques developed and described in these papers may also be applicable to data from a variety of problem areas and the authors include both design motivations in their work as well as illustrative examples of the application of the techniques. “Drawing Directed Graphs Using Quadratic Programming,” by Tim Dwyer, Yehuda Koren, and Kim Marriott, won the InfoVis 2005 Best Paper Award. In this paper, the authors introduce a new method for drawing directed graphs that combines constraint programming techniques with a high performance force-directed placement algorithm. The technique is useful for highlighting hierarchies in directed graphs while retaining beneficial properties of force-directed placement strategies such as proximity and symmetry relations. The authors also describe experiments that show this new visualization technique can convey the structure of large digraphs better than the most widely used hierarchical graph drawing method. “Designing for Social Data Analysis,” by Martin Wattenberg and Jesse Kriss, explores how an information visualization tool may become part of a dynamic online social environment. The authors focus on the area of baby naming and provide a delightful tool called the NameVoyager, a Web-based system that allows people to explore historical trends in the names that parents give to their children. The NameVoyager garnered huge interest on the Web when it was deployed and the authors explore how the system facilitates a form of social data analysis. The paper describes design decisions and implementation issues that arose for the system and it considers some of the reasons why the system became so popular. The paper concludes by discussing the design of an extension to the system for a more complex data set. “Parallel Sets: Interactive Exploration and Visual Analysis of Categorical Data,” by Robert Kosara, Fabian Bendix, and Helwig Hauser, applies a variation of the well-known parallel coordinates visualization technique for representing categorical data. The introduced technique shows data frequencies instead of individual data points and uses boxes and parallelograms within the parallel coordinates style plot. The authors include a rich set of interaction techniques with the visualization that allow viewers to examine many different perspectives on the data. They illustrate the power of their visualization through sample analysis scenarios with two example data sets.	categorical variable;computer graphics;constraint programming;data point;directed graph;experiment;force-directed graph drawing;information visualization;interaction technique;knuth–bendix completion algorithm;parallel coordinates;prankvsprank;quadratic programming;social data analysis;time series;whole earth 'lectronic link;world wide web	John T. Stasko;Matthew O. Ward	2006	IEEE Trans. Vis. Comput. Graph.	10.1109/TVCG.2006.70	computing;scientific visualization;information visualization;visualization;human–computer interaction;computer science;data science;graphics software;data analysis;computer graphics;data visualization;statistics	Visualization	-28.8263217663309	-32.61893631142009	143562
4a2f139ede96ad18657b4f57fa4a53626cb663d2	general human activity patterns		We investigate the dynamics and interplay between human communication, movement, and social proximity by analyzing data collected from smartphones distributed among 638 individuals. The main question we consider is: to what extent do individuals act according to patterns shared across an entire population? Based on statistics of the entire population, we successfully predict 71% of the activity and 85% of the inactivity involved in communication, movement, and social proximity. We find that individual level statistics only result in marginally better predictions, indicating a high degree of shared activity patterns across the population. Finally, we predict short-term activity patterns using a generalized linear model, which suggests that a simple linear description might be sufficient to explain a wide range of actions, whether they be of social or of physical character.	activity recognition;generalized linear model;population;smartphone	Anders Mollgaard;Sune Lehmann;Joachim Mathiesen	2016	CoRR		simulation;social psychology	ML	-20.29309413598913	-37.22989394991944	143704
3a6d8fd9bf6a3a8d345a36bf3aa7f712e3c4263e	beyond query by example	multimedia similarity;similarity queries;feature space;spatiotemporal relations;query by example	This paper considers some of the problems we found trying to extract meaning from images in database applications, and proposes some ways to solve them. We argue that the meaning of an image is an ill-defined entity, and it is not in general possible to derive from an image the meaning that the user of the database wants. Rather, we should be content with a correlation between the intended meaning and simple perceptual clues that databases can extract. Rather than working on the impossible task of extracting unambiguous meaning from images, we should provide the user with the tools he needs to drive the database in the areas of the feature space where “interesting” images are. MEANINGLESS RESPONSES It is a common experience for the user of image databases to be somehow frustrated by the results of their searches. Consider Fig. 1. This is the	database;feature vector;query by example	Simone Santini;Ramesh C. Jain	1998		10.1145/290747.290800	sargable;query optimization;query expansion;web query classification;feature vector;computer science;query by example;machine learning;pattern recognition;database;web search query;information retrieval;query language;spatial query	ML	-31.908610787216404	-32.75954985190808	144155
5ea8cded7938c7393ddc36d88b50e17703ad1d51	a comparison of software for architectural simulation of natural light	architectural design;design process;tropical climate;energy efficient;user interface;architectural design process;user support;point of view;simulation tool;computer simulation	This paper reports a study with daylighting simulation in the architectural design process, through the evaluation of two simulation tools – ECOTECT 5.5 (as interface to RADIANCE) and RELUX2006 VISION. This study was developed from the architect’s point of view and in the context of the design process. The evaluation was conducted taking into account criteria such as User Interface, Geometry, Output, Daylight Parameters, Material Description, Processing, Validation, and User Support. Among these criteria, User Interface is especially important for the architect. It is the best way to overcome the natural barriers in using digital processes in architectural design, with the objective of reaching environmental comfort and energy efficiency. The methodology used includes a large number of simulations in tropical climate, aiming at testing the simulation tools in different daylight conditions in Brazil. The results of this evaluation show a great potential for improving the use of simulation tools in the design process, through a better understanding of these tools.	3d modeling;computation;daylight;simulation software;software architecture;user interface	Evangelos Christakou;Neander Silva	2007		10.1007/978-1-4020-8741-7_25	user interface design;computer simulation;simulation;design process;human–computer interaction;computer science;operating system;software engineering;efficient energy use;user interface	HCI	-31.55672233011993	-26.54301796786504	144466
12ab9b2614c47797382cfe0a1e0f8347bbc34a07	artificial inmune system based art	visual art;artificial immune system	Creating visual art using biologically inspired techniques is a new and exciting field. We describe an interactive image generation system based on an Artificial Immune System (AIS). In our system the user guides image evolution by cueing the system about the aesthetic content of selected areas of images in the current population.	artificial immune system;evolutionary art;experiment;glossary of computer graphics;human–computer interaction;interactive art;long short-term memory;processor affinity;relevance	Juan Romero;Estanislao Sanmartín;Penousal Machado;Antonino Santos	2005			artificial intelligence;machine learning;human–computer interaction;artificial immune system;computer science;population	HCI	-28.371802177778818	-24.868239044542545	144476
9cf3a6b8533db55d89cf2052c9a9273ba1fad1a0	people's interruptibility in-the-wild: analysis of breakpoint detection model in a large-scale study		"""In the advancing ubiquitous computing where users have been having an increasing amount of push-style information provision from lots of intelligent proactive services, detecting the users' current attentional status and/or interruptibility has been a significant issue. In our previous study[7] on interruptibility detection in """"Yahoo! JAPAN"""" real world product for 21 days with more than 680,000 users, the result showed significant lower user response time in exchange for notification delivery delay for about 4 minutes on average. In this paper, we further analyze the features in the interruptibility detection model trained and updated during this study in nightly basis for 21 days and report the results."""	breakpoint;control theory;feature vector;response time (technology);sensor;ubiquitous computing	Kota Tsubouchi;Tadashi Okoshi	2017		10.1145/3123024.3124556	breakpoint;ubiquitous computing;data mining;computer science;response time	HCI	-19.647828527746938	-31.033490114839726	144811
fb85d8c1cef359a107bd00505c036fafbd8c2e8c	row manipulation in the heterogenous tabular forms with an octal grid model	graph theory;user interfaces graph theory;algorithms tabular forms octgrids;heterogeneous table row manipulation heterogenous tabular forms octal grid model multiple row deletion algorithm octgrid graph model;tabular forms;algorithms;user interfaces;octgrids	We propose combined algorithms such as a multiple row deletion algorithm based on octgrid graph model for a heterogeneous table.	algorithm;octal;table (information)	Takeo Yaku;Shinji Koka;Koichi Anada;Yuki Shindo;Kensei Tsuchida	2011	2011 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)	10.1109/VLHCC.2011.6070426	combinatorics;computer science;theoretical computer science;algorithm	Embedded	-29.664401107293084	-33.32848273923565	144903
9ba6a01e7e6f1067d966be98f6916a2bece5b4d6	is there a crowd? experiences in using density-based clustering and outlier detection		The massive growth of GPS equipped smartphones coupled with the increasing importance of Social Media has led to the emergence of new loca- tion-based services over LBSNs (Location-based Social Networks) which allow citizens to act as social sensors reporting about their locations. This proactive social reporting might be beneficial for researchers in a wide number of scena- rios like the one addressed in this paper: monitoring crowds in the city involv- ing an assembly of individuals in term of size, duration, motivation, cohesion and proximity. We introduce a methodology for crowd-detection that combines social data mining, density-based clustering and outlier detection into a solution that can operate on-the-fly to predict public crowds, i.e. to foresee, in short term, the formation of potential multitudes based on the prior analysis of the re- gion. Twitter is mined to analyze geo-tagged data in New York at New Year's Eve, so that those predictable public crowds are discovered.	anomaly detection	Mohamed Ben Kalifa;Rebeca P. Díaz Redondo;Ana Fernández Vilas;Rafael López Serrano;Sandra Servia Rodríguez	2014		10.1007/978-3-319-13817-6_16	geography;data mining;world wide web;computer security	ML	-19.970647470186798	-34.098415716819964	145130
8e1ed74898b748783f496d4ebf853c76ed580f7d	bramble: a web-based framework for interactive rdf-graph visualisation	004 informatik	Most graph visualisation tools for RDF data are desktop applications focused on loading complete ontologies and metadata from a file and allowing users to filter out information if needed. Recently both scientific and commercial frameworks have started to shift their focus to the web, however they still rely on plugins such as Java and rarely handle larger collections of RDF statements efficiently. In this abstract we present a framework which visualises RDF graphs in a native browser environment, leveraging both the SVG standard and JavaScript technology to provide a responsive user interface. Graphs can be directly expanded, modified and explored. Users select nodes and edges from a central data repository containing millions of statements. The resulting graph can be shared with other users retaining full interactivity for collaborative work or presentation purposes.	desktop computer;interactivity;java;javascript;ontology (information science);plug-in (computing);research data archiving;scalable vector graphics;user interface	Nikolas Schmitt;Mathias Niepert;Heiner Stuckenschmidt	2010			computer science;data mining;database;world wide web	Web+IR	-31.625490139599954	-31.137613218395508	145176
8eb3c42988b3637eeacfc5f49c67966f2941739c	the future of computer science	john e hopcroft 计算机科学 数据结构 算法设计 算法分析 the future of computer science	Computer science is undergoing a fundamental change and is reshaping our understanding of the world. An important aspect of this change is the theory and applications dealing with the gathering and analyzing of large real-world data sets. In this paper, we introduce four research projects in which processing and interpreting large data sets is a central focus. Innovative ways of analyzing such data sets allow us to extract useful information that we would never have obtained from small or synthetic data sets, thus providing us with new insights into the real world.	algorithm;computer science;social network;sparse matrix;synthetic data	John E. Hopcroft;Sucheta Soundarajan;Liaoruo Wang	2011	Int. J. Software and Informatics		computer science;artificial intelligence;data science;data mining	ML	-23.682970431707645	-32.56263637670116	145541
712fa8239d5705290225221fcadedece50bf46d7	benchmarking state-of-the-art classification algorithms for credit scoring: an update of research	hg finance;credit scoring;hd28 management industrial management;data mining;forecasting benchmark;or in banking;qa76 computer software	Many years have passed since Baesens et al. published their benchmarking study of classification algorithms in credit scoring [Baesens, B., Van Gestel, T., Viaene, S., Stepanova, M., Suykens, J., & Vanthienen, J. (2003). Benchmarking state-of-the-art classification algorithms for credit scoring. Journal of the Operational Research Society, 54(6), 627-635.]. The interest in prediction methods for scorecard development is unbroken. However, there have been several advancements including novel learning methods, performance measures and techniques to reliably compare different classifiers, which the credit scoring literature does not reflect. To close these research gaps, we update the study of Baesens et al. and compare several novel classification algorithms to the state-of-the-art in credit scoring. In addition, we examine the extent to which the assessment of alternative scorecards differs across established and novel indicators of predictive accuracy. Finally, we explore whether more accurate classifiers are managerial meaningful. Our study provides valuable insight for professionals and academics in credit scoring. It helps practitioners to stay abreast of technical advancements in predictive modeling. From an academic point of view, the study provides an independent assessment of recent scoring methods and offers a new baseline to which future approaches can be compared.	algorithm;bag-of-words model;baseline (configuration management);benchmark (computing);big data;computer hardware;cross-validation (statistics);data quality;design of experiments;ead socket;ensemble forecasting;experiment;external validity;feature selection;heterogeneous system architecture;holism;lr parser;no silver bullet;power supply unit (computer);predictive modelling;programming paradigm;radio frequency;simulation;standard operating procedure;statistical classification;technical standard;test template framework;the industry standard	Stefan Lessmann;Bart Baesens;Hsin-Vonn Seow;Lyn C. Thomas	2015	European Journal of Operational Research	10.1016/j.ejor.2015.05.030	computer science;data science;data mining;management science	ML	-23.25863394542347	-30.051711637878398	145597
320bac5fd2f72bfee3b8008320de5c6ea4a735b4	simulation for design, test and evaluation, and training: reconciling the differences	digital simulation;military computing;real-time systems;weapons;mcdonnell douglas;us army;engineering simulator;fidelity;helicopter component;life cycle;operational mission environment;operational test;performance;real-time man-in-the-loop simulation;simulation technology limitations;training devices;training simulators;weapon system	"""A concept is presented which describes the role of s imulat ion (more p roper ly , r ea l t ime manin t he l oop simulation) across the entire life cycle of a weapon system. Novel aspects of the concept include the potential for the selective use of the developer ' s """"engineer ing"""" simulator during operational test and evaluation (OT&E) as well as the merits of a tightly coupled approach to the design of the e n g i n e e r i n g s i m u l a t o r and that of r e l a t ed t r a in ing dev ices / s imula tors . Lest the role of the e n g i n e e r i n g simulator be overstated with respect to its role in systems integration, a clear distinction is made between the role of the engineering simulator and that of a """"systems integration facility"""" (SIF). Parallels between t h e prime's use of such a concep t and the use of such a concep t to ach ieve integration among different Gove rnmen t laboratories is discussed. Lastly, the issue of """"fideli ty"""" is discussed with respect to current simulation technology limitations and their known effects upon performance outcomes."""	association for computers and the humanities;emoticon;parallels desktop for mac;simulation;system integration	Ronald G. Hughes	1990			computer simulation;biological life cycle;simulation;performance;computer science;engineering;technical report;computational model;system testing;system integration;computer engineering	AI	-23.05323532127251	-24.672057113258234	145719
dcd492ef578a6af191b5cca4f304499dbed3676d	visual data fusion for applications of high-resolution numerical weather	energy demand prediction;weather forecasting;data fusion;user tasks;graphics design;visualization;demographics;meteorology	Non-traditional applications of scientific data challenge the typical approaches to visualization. In particular, popular scientific visualization strategies fail when the expertise of the data consumer is in a different field than the one that generated the data and data from the user’s domain must be utilized as well. This problem occurs when predictive weather simulations are used for a number of weather-sensitive applications. A data fusion approach is adopted for visualization design and utilized for specific example problems. CR Categories and Subject Descriptions: I.3.8 [Computer Graphics Applications], I.6 [Simulation and Modeling], H.5 [Information Interfaces and Presentation], J.2 [Earth and Atmospheric Sciences] Additional	computer graphics;numerical weather prediction;scientific visualization;simulation	Lloyd Treinish	2000		10.1145/375213.375306	simulation;visualization;weather forecasting;computer science;data science;data mining;sensor fusion;computer graphics (images)	Visualization	-24.80807921899042	-30.55999200034347	145829
88dea69fd87e2269ba9e380b05225a632de344a5	improving an interactive visualization of transition systems	simulation and modeling;graph drawing;3d visualization;cone trees;user interface;interactive visualization;computer graphic;model validation;transition systems;information interfaces and presentation;3d structure	A transition system can be used to model the behaviour of a software system. A popular way of analysing this behaviour is by studying the corresponding transition system. An interactive visualization technique for showing the global structure of a transition system has been proposed by Van Ham et al. This technique clusters states and forms these clusters into a 3D structure similar to a cone tree, with the emphasis on symmetry. The technique has been used by analysts to study real-world systems. In this paper we solve a number of problems related to the symmetry of the visual representation and the misrepresentation of cluster sizes. This results in more effective and less misleading visualizations. In addition, we also extend the original technique by providing simulation facilities and a more effective state and cluster marking technique. These enhance the way in which a user can interact with the visualization.	interactive visualization;item unique identification;music visualization;simulation;software system;transition system;world-system	Bas Ploeger;Carst Tankink	2008		10.1145/1409720.1409739	simulation;information visualization;visualization;interactive visualization;computer science;theoretical computer science;regression model validation;graph drawing;user interface;computer graphics (images)	SE	-33.58132688632436	-32.14909987493956	145922
9de6edf90ddc70c15179e8d5742a5efd5232e523	bookaidee: managing evacuees from natural disaster by rfid tagged library books	bookaidee;rfid;natural disaster;library;evacuees	BookAidee is a system to manage people who evacuate into public school buildings from disaster. The system identifies people by using already implemented structure of school library books that have RFID tags. These tags are used for connecting the person into the system database. We have implemented the system in server and client applications and tested the feasibility.	book;radio-frequency identification;server (computing)	Markus Liuska;Emmi Makkonen;Itiro Siio	2013		10.1007/978-3-642-39215-3_15	engineering;world wide web;computer security;cartography	HCI	-22.581411835569465	-28.94470689765834	145997
f0ec5b0992ab63ad2ca9ee4bd2c85730953715a1	a qualitative evaluation of maptime, a program for exploring spatiotemporal point data	qualitative methods;change maps;small multiples;focus groups;animation;interviews;mapping point data;qualitative evaluation	The purpose of this paper is twofold: (1) to provide a user evaluation of MapTime, a software package for exploring spatiotemporal data associated with point locations, and (2) to examine some cognitive issues associated with the display of a dynamic geographic phenomenon - the change in population for cities over time. The methodology consists of a combination of individual interviews and focus groups conducted for three distinct groups of participants: novices, geography students, and domain experts. Some of the key findings are (1) that people do not naturally think of time lines in association with time (clocks and calendars are more common), which raises questions about the use of a linear time line for controlling animations; (2) that pictographic symbols tend to be preferred over geometric symbols for static maps, but pictographic symbols are apt to be too complex for animated maps; (3) that animations, small multiples, and change maps all have important roles to play in examining spatiotemporal da...		Terry A. Slocum;Robert S. Sluter;Fritz C. Kessler;Stephen C. Yoder	2004	Cartographica	10.3138/92T3-T928-8105-88X7	anime;computer vision;simulation;interview;geography;qualitative research;focus group;communication;cartography	HCI	-24.40986948009686	-33.84658123659481	146262
290c9156ac383f5e306ce77d67fac5c9adfe70c5	special issue on spatiotemporal modeling and analysis		Localization technologies such as navigation systems or mobile phones have steadily conquered our everyday life over the past fifteen years. We have become used to knowing exactly where we are. The challenge of today is to know where the others are and where they are going. How often have we wished for a small device telling us whether to hurry or whether to keep our pace when we were late for a bus— possibly the bus was delayed as well? How often have we yearned for a navigation system telling us a different detour than everybody else? Clearly, the answers to these questions require intelligent systems which know about the schedule of an individual as well as of the current and future status of the whole system. It requires intelligent modeling and analysis methods to extract such information from spatiotemporal data. This special issue provides an overview of current developments in spatiotemporal data mining, focusing in particular on trajectory data. Besides the overview article, the contribution of M. Sester et al. is a good starting point. It describes methods at the basis of trajectory data analysis, namely the detection of stops, the classification of the mode of transportation as well as the detection of typical paths. The articles by H.-P. Kriegel et al., N. Andrienko et al. and S. Rinzivillo et al. present methods to analyze global move-	artificial intelligence;data mining;global optimization;mobile phone;spatiotemporal database	Christine Kopp;Michael May;Stefan Wrobel	2012	KI - Künstliche Intelligenz	10.1007/s13218-012-0216-1	simulation;navigation system;trajectory;computer science;intelligent decision support system;everyday life	ML	-20.97426740360099	-30.98604319476312	146337
2c027b1e1c3784368ee3801a8d5a896916ccd0aa	predicting episodes of non-conformant mobility in indoor environments		Traditional mobility prediction literature focuses primarily on improved methods to extract latent patterns from individual-specific movement data. When such predictions are incorrect, we ascribe it to 'random' or 'unpredictable' changes in a user's movement behavior. Our hypothesis, however, is that such apparently-random deviations from daily movement patterns can, in fact, of ten be anticipated. In particular, we develop a methodology for predicting Likelihood of Future Non-Conformance (LFNC), based on two central hypotheses: (a) the likelihood of future deviations in movement behavior is positively correlated to the intensity of such trajectory deviations observed in the user's recent past, and (b) the likelihood of such future deviations increases if the user's strong-ties have also recently exhibited such non-conformant movement behavior. We use extensive longitudinal indoor location data (spanning 4+ months) from an urban university campus to validate these hypotheses, and then show that these features can be used to build an accurate non-conformance predictor: it can predict non-conformant mobility behavior two hours in advance with an AUC ≥ 0.85, significantly outperforming the baseline. We also show that this prediction methodology holds for a representative outdoor public-transport based mobility dataset. Finally, we use a real-world mobile crowd-sourcing application to show the practical impact of such non-conformance: failure to identify such likely anomalous movement behavior causes workers to suffer a noticeable drop in task completion rates and reduces the spatial spread of successfully completed tasks.		Kasthuri Jayarajah;Archan Misra	2018	IMWUT	10.1145/3287050	predictability;machine learning;artificial intelligence;computer science	HCI	-19.24075627903603	-34.47399907759335	146710
006789eae25bd846ca090641dbcd0601ae02aa7c	visualizing intelligence information using correlation graphs	modelizacion;utilisation information;correlacion;uso informacion;text;information model;graph drawing;process capability;information use;system modeling;interrogation base donnee;event structure;interrogacion base datos;systematique;texte;probabilistic approach;information presentation;modelisation;data storage;visualization;sistematica;estructura acontecimiento;enfoque probabilista;approche probabiliste;modelo mental;estructura datos;intelligence analysis;data visualization;taxonomy;pattern recognition;modele mental;computing systems;visualisation donnee;structure donnee;reconnaissance forme;correlation;structure evenement;reconocimiento patron;texto;graph visualization;modeling;data structure;database query;domain specificity;mental model	This paper presents a new information model to help intelligence analysts in organizing, querying, and visualizing the information present in large volumes of unstructured data sources such as text reports, multi-media, and human discourse. Our primary goal is to create a system that would combine the human pattern recognition abilities of intelligence analysis with the storage and processing capabilities of computers. Our system models the collective mental map of intelligence analysts in the form of the Correlation Graph, a modified graph data structure with objects and events as nodes and subjective probabilistic correlations between them as edges. Objects are entities such as people, places, and things. Events are actions that involve the objects. A taxonomy is also associated with the model to enable intelligence domain specific querying of the data. Graph drawing techniques are used to visualize the information represented by the correlation graph. Through real world examples, we demonstrate that the resulting information model can be used for efficient representation, presentation, and querying to discover novel patterns in the intelligence data via graph visualization techniques.	algorithm;computer;data mining;data structure;entity;graph (abstract data type);graph drawing;information model;link analysis;mental mapping;organizing (structure);pattern recognition;relational database;taxonomy (general)	Vivek Verma;Nikhil Gagvani	2005		10.1117/12.604040	computer science;artificial intelligence;theoretical computer science;data mining	AI	-27.821750251472263	-31.55200555961235	146844
7eeaa0dcbfb376c3e76235f44a39fad18046d7e6	making complex document structures accessible through templates	usual usage;real-life structure definition;graph structure;sgml school;graphical tool;graph type;complex document structure;edge type;usage template;proposed graph type model;structure definition;sgml;graphical tools;hierarchy;user interfaces;parameterization;computer architecture;teamwork;writing;graphs;graph theory;document structure;logic programming;prototypes;markup languages;graph operations	We address two problems of technical authors in structured environments: (1) Structure definitions of the SGML school are limiting: they require one primary hierarchy and do not cater for link types and (2) Real-life structure definitions are too large to be comprehended easily. As solutions, we propose graph types and usage templates.The edge types and inheritance of the proposed graph type model are useful modeling tools. We give examples for structures that can be expressed more precisely and with gain for the author using graph structures. There are also graphical tools available to define graph types and to specify operations on graphs.Templates can be used as a simple parameterization mechanism. A template illustrates the usual usage of a substructure, as opposed to the minimal one required by a structure definition, or the maximal one allowed by it.We also present a prototype authoring application based on these ideas.	data visualization;graph (discrete mathematics);graph operations;graph theory;maximal set;prototype;regular expression;standard generalized markup language	Felix H. Gatzemeier;Oliver Meyer	2000		10.1145/504800.504873	human–computer interaction;computer science;graph theory;theoretical computer science;document structure description;data mining;database;graph;world wide web;graph database;graph rewriting	Graphics	-31.19064033374968	-32.02350851161993	146893
5f520d3a73216de8fbdbf8292cee8e7b4202175f	collective response of human populations to large-scale emergencies	emergency response;social systems;social communication;decomposition;pedestrian safety;communications;poison control;injury prevention;real time;cell phones;emergencies;safety literature;traffic safety;information services;injury control;home safety;cooperative behavior;social network;large scale;injury research;safety abstracts;human factors;behavior change;social networks;occupational safety;safety;safety research;mobility pattern;accident prevention;violence prevention;humans;bicycle safety;behavior;poisoning prevention;falls;ergonomics;human activity;suicide prevention;telecommunications	Despite recent advances in uncovering the quantitative features of stationary human activity patterns, many applications, from pandemic prediction to emergency response, require an understanding of how these patterns change when the population encounters unfamiliar conditions. To explore societal response to external perturbations we identified real-time changes in communication and mobility patterns in the vicinity of eight emergencies, such as bomb attacks and earthquakes, comparing these with eight non-emergencies, like concerts and sporting events. We find that communication spikes accompanying emergencies are both spatially and temporally localized, but information about emergencies spreads globally, resulting in communication avalanches that engage in a significant manner the social network of eyewitnesses. These results offer a quantitative view of behavioral changes in human activity under extreme conditions, with potential long-term impact on emergency detection and response.	abnormal behavior;accident caused by earthquake;avalanches;emergencies [disease/finding];human activities;population;real-time clock;social network;sports;stationary process	James P. Bagrow;Dashun Wang;Albert-László Barabási	2011		10.1371/journal.pone.0017680	biology;human factors and ergonomics;social network	HCI	-19.52338636726945	-36.474950991784375	147214
10e1b5cdeacc1f8aaae67c5aea49bce59b64cc06	graphics and visualization: the essential features for the classification of systems	essential features	Advances in computer graphics in the recent twenty years have stimulated different schemes to classify research directions and systems. In the early days, graphics systems were identified to be vector or raster graphics in terms of technology. Sutherland`s Sketchpad system was the first example that allowed to distinguish between passive and interactive computer graphics. Dimensions of the geometric data model classified systems to be a 2D or 3D system. This scheme was used by standardization activities in computer graphics during the last decade. However, the approaches of standard committees to develop a reference model for computer graphics have shown very clearly that the variety of systems and the complexity within one graphics system prevents from the establishment of an easy-to-understand model. Taxonomies in scientific visualization (MzCo-87) focussed on the integration of different disciplines like computer graphics and computer vision, and the use of available, mostly heterog eneous system components and peripherals. At least, scientific visualization has shown very clearly that computer graphics today is very different from drawing and image processing. Our understanding (Felg-90) of scientific visualization comprises outstanding system requirements like: massive amounts of complex and multidimensional data to be processed, peripheral and algorithmic means for interactive data exploration, manifold alternative (physical and logical) visual (but also non-visual) data presentation techniques, and computational models for physical phenomena. Consequently, scientific visualization requires a correspondence between the human perception and the abstract computer-internal representation of the physical world. Visualization in scientific computing needs this correspondence, virtual reality even requires more! Virtual reality presumes integrated presentation, feedback and simulation techniques and demands realtime! Realtime in this context is defined as the evaluation of the computational model to present continuity for the human perception. Realtime is obtained by an image refresh rate of at least 10 frames per second for the visual senses and by an 8 kHz sample rate for the ausitive senses. (IGD)	graphics	José L. Encarnação;Peter Astheimer;Wolfgang Felger;Thomas Frühauf;Martin Göbel;Stefan Müller	1993			computer vision;scientific visualization;information visualization;multimedia;biological data visualization;computer graphics (images)	HPC	-28.90891286322472	-30.10118999995381	147512
85b12db12cb1210ea1e210766c68ee09648eb68e	interactive 3d visualization of ensemble weather forecasts		This thesis investigates the feasibility of interactive 3D visualization of ensemble weather predictions. Weather forecasting requires meteorologists to explore large amounts of numerical weather prediction data, and to assess the uncertainty of the predictions. Visualization methods that facilitate fast and intuitive exploration of the data hence are of particular importance. I present Met.3D, a new open-source tool for the interactive 3D visualization of numerical ensemble weather predictions. The tool has been developed with the primary motivation to support weather forecasting during aircraft-based atmospheric field campaigns, however, is applicable to further forecasting, research and teaching activities. My work approaches challenging topics related to the visual analysis of numerical atmospheric model output – 3D visualisation, ensemble visualization, and how both can be used in a meaningful way suited to weather forecasting. Met.3D builds a bridge from proven 2D visualization methods commonly used in meteorology to 3D visualization by combining both visualization types in a 3D context. I address the issue of spatial perception in the 3D view and present approaches to using the ensemble to allow the user to assess forecast uncertainty. Interactivity is key to the approach. Met.3D uses modern graphics technology to achieve interactive visualization on standard consumer hardware. The tool supports forecast data from the European Centre for Medium Range Weather Forecasts (ECMWF) and can operate directly on ECMWF hybrid sigma-pressure level grids. I describe the system architecture and the employed visualization algorithms, and analyse the impact of the ECMWF grid topology on computing 3D ensemble statistical quantities. Focussing on a particular use case, I present the application of Met.3D to forecasting warm conveyor belt (WCB; large scale air streams associated with mid-latitude low pressure systems) situations. Motivated by forecast requirements of the T-NAWDEX-Falcon 2012 campaign, a method to predict 3D probabilities of the spatial occurrence of WCBs has been developed. Probabilities are derived from Lagrangian particle trajectories computed on the forecast wind fields of the ECMWF ensemble prediction system. Integration of the method into Met.3D facilitates interactive visualization of WCB features and derived probabilities in the context of the ECMWF ensemble forecast. I investigate the sensitivity of the method with respect to trajectory seeding and grid spacing of the forecast wind field. Furthermore, I propose a visual analysis method to quantitatively analyse the contribution of ensemble members to a probability region and, thus, to assist the forecaster in interpreting the obtained probabilities. A case study, revisiting a forecast case from T-NAWDEX-Falcon, illustrates the practical application of Met.3D and demonstrates the use of 3D and uncertainty visualization for weather forecasting and for planning flight routes in the medium forecast range.	algorithm;atmospheric model;ensemble forecasting;falcon;graphics;interactive visualization;interactivity;numerical analysis;numerical weather prediction;open-source software;random seed;requirement;sigma coordinate system;systems architecture;visual analytics;visualization (graphics)	Marc Rautenhaus	2015			visualization;simulation;weather research and forecasting model;conveyor belt;weather forecasting;engineering	Visualization	-24.637288460080782	-30.552878906729074	147629
04db5777cc382b7ba1a40b87bf227e74007d6878	knowledge and reasoning in spatial analysis	a1 alkuperaisartikkeli tieteellisessa aikakauslehdessa;gis;spatial sciences;spatiotemporal analysis;geography	Abstract#R##N##R##N#Reasoning is an essential part of any analysis process. Especially in visual analytics, the quality of the results depends heavily on the knowledge and reasoning skills of the analyst. In this study, we consider how to make the results transparent by visualizing the reasoning and the knowledge, so that persons from outside can trace and verify them. The focus of this study is in spatial analysis and a case study was carried out on a process of off-road mobility analysis. In the case study, linked views of a map and a PCP were identified as reasoning artifacts. The knowledge used by the analyst was formed by these artifacts and the tangible pieces of information identified in them, along with the mental models of the analyst′s mind. To make the results transparent, the tangible pieces of information were marked with sketches and the mental models were presented in causal graphs because it was found that causality was central to the reasoning process in the case study. The causal graph allows the reasoning of the analyst to be studied, as well as traced back to its origin.	spatial analysis	Andreas Hall;Paula Ahonen-Rainio;Kirsi Virrantaus	2014	Trans. GIS	10.1111/tgis.12049	geomatics;qualitative reasoning;geography;computer science;artificial intelligence;data mining;database;cartography;remote sensing	HCI	-25.90072761878714	-30.36109456771955	147631
a29f96a968a58d5dcd8eb4cfed07d4707f83fa6e	gamygdala: an emotion engine for games	computer games gamygdala emotional appraisal engine game developers nonplayer characters npc event coding annotated emotional consequences cognitive appraisal model game events occ model black box game ai emotion support psychological model affective computing;psychological model computer games affective computing;games appraisal computational modeling engines artificial intelligence psychology cognition;psychology;appraisal;computational modeling;engines;games;cognition;artificial intelligence;computer games;psychological model;psychology cognition computer games;affective computing	In this paper we present GAMYGDALA, an emotional appraisal engine that enables game developers to easily add emotions to their Non-Player Characters (NPC). Our approach proposes a solution that is positioned between event coding of affect, where individual events have predetermined annotated emotional consequences for NPCs, and a full blown cognitive appraisal model. Instead, for an NPC that needs emotions the game developer defines goals and annotates game events with a relation to these goals. Based on this input, GAMYGDALA produces an emotion for that NPC according to the well-known OCC model. In this paper we provide evidence for the following: GAMYGDALA provides black-box Game-AI independent emotion support, is efficient for large numbers of NPCs, and is psychologically grounded.	artificial intelligence (video games);black box;emotion engine;np-completeness;nearest centroid classifier;optimistic concurrency control;physics engine;programmer;simulation;video game developer;whole earth 'lectronic link	Alexandru Popescu;Joost Broekens;Maarten van Someren	2014	IEEE Transactions on Affective Computing	10.1109/T-AFFC.2013.24	psychology;games;simulation;cognition;computer science;artificial intelligence;machine learning;affective computing;computational model;social psychology	SE	-26.807247396298607	-25.322803751235615	148016
fbfe22fc0fbd21b961bfc81c3328b04cf42f6125	a moving least squares based approach for contour visualization of multi-dimensional data	paper;nvidia geforce gtx 285;cuda;visualization;nvidia;computer science;graphics	Analysis of high dimensional data is a common task. Often, small multiples are used to visualize 1 or 2 dimensions at a time, such as in a scatterplot matrix. Associating data points between different views can be difficult though, as the points are not fixed. Other times, dimensional reduction techniques are employed to summarize the whole dataset in one image, but individual dimensions are lost in this view. In this paper, we present a means of augmenting a dimensional reduction plot with isocontours to reintroduce the original dimensions. By applying this to each dimension in the original data, we create multiple views where the points are consistent, which facilitates their comparison. Our approach employs a combination of a novel, graph-based projection technique with a GPU accelerated implementation of moving least squares to interpolate space between the points. We also present evaluations of this approach both with a case study and with a user study.	contour line;data point;graph drawing;information visualization;interpolation;moving least squares;small multiple;usability testing	Chris Muelder;Nick Leaf;Carmen Sigovan;Kwan-Liu Ma	2014	CoRR		computer vision;visualization;computer science;graphics;theoretical computer science;computer graphics (images)	Visualization	-28.04103272701774	-33.77382459955525	148317
d0b403de81ce1bbddcb8bfeb627feaec6d813d74	proposal of traffic accident prevention system with chronological variations of wireless signals and sensors on mobile nodes		The researches of the traffic accident preventions have recently focused with the rapid developments of ITS (Intelligent Transportation System). However, it is supposed that most of the approaches treated with the car accidents by the car navigation systems while the accidents by pedestrians or bicycles have rapidly increased. Therefore, this paper proposes the traffic accident prevention system with chronological variations of Wireless and Sensors on the Mobile phones. In the proposed systems, the mobile devices continuously observe the wireless signals and sensors such as gyro sensors, and the rapid approaching objects are detected by the proposed methods based on the Markov Chain algorithm. Then, the prototype system and the experiments are introduced in the paper, and the results are discussed for the effectiveness of the proposed systems and the future studies.	sensor	Shoma Takeuchi;Noriki Uchida;Yoshitaka Shibata	2017		10.1007/978-3-319-61542-4_6	computer security;computer science;computer network;wireless;intelligent transportation system;mobile device;markov chain	Mobile	-19.84820313608157	-28.799855130265275	148339
30492d91c8ac2e476a25bf7ddf445be00b3d2fe3	crowdprobe: non-invasive crowd monitoring with wi-fi probe		Devices with integrated Wi-Fi chips broadcast beacons for network connection management purposes. Such information can be captured with inexpensive monitors and used to extract user behavior. To understand the behavior of visitors, we deployed our passive monitoring system---CrowdProbe, in a multi-floor museum for six months. We used a Hidden Markov Models (HMM) based trajectory inference algorithm to infer crowd movement using more than 1.7 million opportunistically obtained probe request frames.  However, as more devices adopt schemes to randomize their MAC addresses in the passive probe session to protect user privacy, it becomes more difficult to track crowd and understand their behavior. In this paper, we try to make use of historical transition probability to reason about the movement of those randomized devices with spatial and temporal constraints. With CrowdProbe, we are able to achieve sufficient accuracy to understand the movement of visitors carrying devices with randomized MAC addresses.	broadcast domain;hidden markov model;markov chain;randomized algorithm	Hande Hong;Girisha Durrel De Silva;Mun Choon Chan	2018	IMWUT	10.1145/3264925	computer science	HCI	-19.723615210720556	-31.417101389395576	148413
8e851230805a2c59dc3453179f3b1d3e7211a8b2	context-aware reminder system to support medication compliance	context awareness;sensor systems;sensors;system analysis and design;actuators;medical computing;engines;medication reminder;assistive technology;medication compliance medication reminder assistive technology context awareness;ubiquitous computing;user interfaces actuators medical computing sensors ubiquitous computing;containers cellular phones engines radiofrequency identification sensor systems system analysis and design;actuators context aware reminder system user medication compliance medication reminder system patient forgetfulness user behavior sensors;user interfaces;radiofrequency identification;medication compliance;cellular phones;containers	We propose a medication reminder system which supports users' medication compliance. Poor compliance of medication causes significant problems including worsening disease and increase of healthcare costs. One common reason for poor compliance is patients' forgetfulness. We identified four types of failures caused by forgetfulness which requires the system to consider various users' behaviors other than users' consumption of medication, while existing medication reminder systems consider only users' consumption of medication. The architecture of the system is designed to work with various sensors and actuators, which enable the system to consider vast variety of users' behaviors. We describe the design process of the system initiated by the identifying failures. One example of implementation is also shown including the development of sensors and actuators.	as-interface;sensor;systems design;usability	Daisuke Asai;Jarrod Orszulak;Richard Myrick;Chaiwoo Lee;Joseph F. Coughlin;Olivier L. de Weck	2011	2011 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/ICSMC.2011.6084164	embedded system;simulation;computer science;sensor;user interface;computer security;ubiquitous computing;structured systems analysis and design method;actuator	Robotics	-30.326572533149765	-25.378190800485097	148494
370971f5c45f76570130f669b665f7ce3efc508f	diagrammatic representation and inference	data mining;user interface;human computer interaction;discrete mathematics;knowledge discovery;artificial intelligent	We present an algorithm for automatically laying out metro map style schematics using a force-directed approach, where we use a localized version of the standard spring embedder forces combined with an octilinear magnetic force. The two types of forces used during layout are naturally conflicting, and the existing method of simply combining these to generate a resultant force does not give satisfactory results. Hence we vary the forces, emphasizing the standard forces in the beginning to produce a well distributed graph, with the octilinear forces becoming prevalent at the end of the layout, to ensure that the key requirement of line angles at intervals of 45◦ is obtained. Our method is considerably faster than the more commonly used search-based approaches, and we believe the results are superior to the previous force-directed approach. We have further developed this technique to address the issues of dynamic schematic layout. We use a Delaunay triangulation to construct a schematic “frame”, which is used to retain relative node positions and permits full control of the level of mental map preservation. This technique is the first to combine mental map preservation techniques with the additional layout criteria of schematic diagrams. To conclude, we present the results of a study to investigate the relationship between the level of mental map preservation and the user response time and accuracy.	connectivity (graph theory);delaunay triangulation;diagram;evolutionary algorithm;evolutionary computation;experiment;fitness function;force-directed graph drawing;genetic representation;heuristic (computer science);in the beginning... was the command line;iterative and incremental development;mathematical optimization;mental mapping;response time (technology);resultant;schematic;usability testing	Tim Dwyer;Helen C. Purchase;Aidan Delaney	2014		10.1007/978-3-662-44043-8	diagrammatic reasoning	HCI	-29.980207039379042	-36.39794452435416	148712
f69aae1629c1714570dbc7754064c9e8d354943e	development of information terminal 'it scarecrow' for rural station	public transport;public transportation;mobile phone;gps;local community;rural community;design;information design	This paper explains the development of an information terminal for a rural station and its background system. The information terminal, which we call 'IT scarecrow', displays traffic information based on a train location system. It is designed like a scarecrow to blend into a rural station. The service the system provides depends mainly on passengers' surveys and discussions with the rural community. In addition, we tried to make the system at low cost.  In the spring of 2007, we made some preliminary system tests followed by an experiment in an actual station. As a result, we learned what the critical conditions for the next implementation should be. The IT scarecrow is consulted as a representative of communication between a railway and a local community. We hope the system will expand and also that it be implemented as a mobile guidance system.	autonomous decentralized system;autonomous robot;chi;control system;decentralised system;guidance system;requirement;shin megami tensei: nocturne;system testing	Fuminori Tsunoda;Go Yanagisawa;Koichi Wakasugi;Katsushi Nagumo;Takayuki Matsumoto;Takeshi Nakagawa;Mariko Utsunomiya	2008		10.1145/1358628.1358645	simulation;telecommunications;public transport	AI	-31.707023492150107	-37.439579786890164	149014
b63cdae8c0c9bcf1c15d7dd8cd23e729dae55c42	a concept for visualizing psychophysiological data in human computer interaction: the featureplotter		This paper introduces a graphical concept and an implementation for visualizing psychophysiological data in human computer interaction. Psycho- biological measurements result in huge datasets, which are mandatory for the development of semi-automatic or automated emotion classification and hence a reliable planning and decision-making system called companion system. The mentioned amount of data calls for the need of making dependencies and coherences in those datasets visible for the human eye in addition to algorithmic pattern recognition and feature selection. Seeing through the data by exploring it playfully helps experts understanding the data structure and provokes non- specialists' curiosity.	human computer;human–computer interaction	Falko Pross;Dilana Hazer;Harald C. Traue;Holger Hoffmann	2015		10.1007/978-3-319-20612-7_10	computer vision;computer science;artificial intelligence;data mining	HCI	-25.597697670066797	-35.399349355297616	149352
064318a7540f1dc84b427c10f0ae261fdf84ae9e	development of the virtual flight deck (vfd) simulation environment	real time;multi body dynamics;ship motion;dynamic interface analysis;mathematical model;flight deck;simulation environment;software implementation	In the study of shipboard helicopter operations, simulations have been used in a variety of areas. Most of these simulations involve software implementation of mathematical models that run faster than real-time to produce meaningful results over a long span of time. When human operators or in-service hardware is brought into the simulation, however, the real-time requirement becomes a central issue. The Virtual Flight Deck - Real-Time (VFD-RT) simulation environment is built as an extension to previously-developed mathematical models to meet this real-time requirement. The VFD-RT uses a centralized model to connect the components of the simulation and relies on the Microsoft Windows message system as a means of communication between the different parts of the environment. This paper discusses the development and some limitations of the VFD-RT environment.	centralized computing;communications protocol;entity;mathematical model;microsoft windows;mock object;motion simulator;operating system;programming language;real-time clock;real-time transcription;relay;simulation;timer;vacuum fluorescent display	Kin Wing Tsui;Robert G. Langlois	2008			embedded system;real-time computing;simulation;computer science;engineering;operating system;mathematical model;statistics	Embedded	-22.95587410803316	-25.811913860732346	149437
e245c96027bd543914f3cc7fe9cb79f58e975ac5	cars talk to phones: a dsrc based vehicle-pedestrian safety system	vehicles smart phones safety global positioning system sensors ieee 802 11 standards legged locomotion;traffic engineering computing alarm systems collision avoidance mobile radio road safety smart phones;dedicated short range communications dsrc vehicle pedestrian safety system pedestrian traffic accident possible collision warning vehicle communication over the air performance spectrum congestion channel congestion telecommunication security	The prevalence of smartphones presents a unique opportunity to develop a system that can have a significant impact on reducing the annual 400,000 fatalities from pedestrian traffic accidents. This system gives 360 degrees, extended range, NLOS view where both the driver and the pedestrian are warned of a possible collision. This, the first of its kind, system was developed from a two year collaborative research effort between Honda and Qualcomm to leverage DSRC so vehicles can communicate with smartphones to preempt a possible collision between a pedestrian (with a smartphone) and an approaching vehicle. This paper describes the pedestrian and vehicle-based algorithms and gives an overview of how this system warns both the driver and the pedestrian so they can take evasive action and prevent a collision. We present the results from our field tests where we demonstrate several pedestrian safety scenarios and present the over- the-air performance data collected in the field tests. Finally, we discuss remaining challenges and present possible approaches to reducing false positives, minimizing spectrum and channel congestion and improving security and localization.	algorithm;network congestion;smartphone	Xinzhou Wu;Radovan Miucic;Sichao Yang;Samir Al-Stouhi;James Misener;Sue Bai;Wai-hoi Chan	2014	2014 IEEE 80th Vehicular Technology Conference (VTC2014-Fall)	10.1109/VTCFall.2014.6965898	embedded system;engineering;automotive engineering;computer security	Mobile	-19.68246382725044	-28.178361489449447	149452
098ef8831febecc33680b507f0abfde4b5fb6efc	visualizing populated ontologies with ontotrix	graphs;exploratory visualization;matrices;semantic web;ontologies	Research on visualizing Semantic Web data has yielded many tools that rely on information visualization techniques to better support the user in understanding and editing these data. Most tools structure the visualization according to the concept definitions and interrelations that constitute the ontology’s vocabulary. Instances are often treated as somewhat peripheral information, when considered at all. These instances, that populate ontologies, represent an essential part of any knowledge base. Understanding instance-level data might be easier for users because of their higher concreteness, but instances will often be orders of magnitude more numerous than the concept definitions that give them machine-processable meaning. As such, the visualization of instance-level data poses different but real challenges. The authors present a visualization technique designed to enable users to visualize large instance sets and the relations that connect them. This visualization uses both node-link and adjacency matrix representations of graphs to visualize different parts of the data depending on their semantic and local structural properties. The technique was originally devised for simple social network visualization. The authors extend it to handle the richer and more complex graph structures of populated ontologies, exploiting ontological knowledge to drive the layout of, and navigation in, the representation embedded in a smooth zoomable environment. Visualizing Populated Ontologies with OntoTrix	adjacency matrix;data structure;ontology (information science);peripheral;population;semantic web;vocabulary	Benjamin Bach;Gennady Legostaev;Emmanuel Pietriga	2010	Int. J. Semantic Web Inf. Syst.	10.4018/ijswis.2013100102	information visualization;computer science;ontology;artificial intelligence;semantic web;data mining;database;graph;world wide web;information retrieval;matrix	Visualization	-28.98966411650783	-35.16501204169697	150330
8fd5e88a19335a0d42aecd21e5c86162958e47cb	a web portal for regional projection of weather forecast using grid middleware	distributed data;weather forecast;high resolution;high dimensionality;differential equation;weather forecasting;grid middleware;data mining;web portals;web portal;data mining algorithm;statistical downscaling;grid computing;problem solving environment;problem solving environments	Weather forecast is a complex multi-disciplinary problem which requires a cascade of different scientific tools, from differential equation solvers to high-dimensional statistical and data-mining algorithms. The demand for high-resolution predictions is continuously increasing due to the multiple applications in hydrology, agronomy, etc., which require regional meteorological inputs. To fill the gap between the coarse-resolution lattices used by global weather models and the regional needs of applications, a number of statistical downscaling techniques have been proposed. In this paper we describe a Web portal which integrates the necessary tools with Grid middleware allowing for distributed data access and computing. The portal is part of the ENSEMBLES EU-funded project and allows end users to interactively downscale weather predictions using a web browser. Both the architecture and the usage of the portal are described in this paper.	algorithm;atmospheric model;data access;data mining;downscaling;grid computing;image resolution;interactivity;middleware;numerical weather prediction;region of interest;statistical model;glite	Antonio S. Cofiño;D. San-Martín;José Manuel Gutiérrez	2007		10.1007/978-3-540-72588-6_11	weather forecasting;computer science;data mining;database;world wide web;differential equation;quantum mechanics;grid computing	HPC	-25.093405435345932	-30.695971814463547	150461
5c06e7cc1e66f2056412222a0b8d45a2a6e4929f	statistical analysis and graphical display of multivariate data on the macintosh	statistical analysis;multivariate data	Two Macintosh programs written for multivariate data analysis and multivariate data graphical display are presented. MacMul includes principal component analysis (PCA), correspondence analysis (CA) and multiple correspondence analysis (MCA), with a complete, original and unified set of numerical aids to interpretation. GraphMu is designed for drawing collections of elementary graphics (curves, maps, graphical models) thus allowing comparisons between variables, individuals, and principal axes planes of multivariate methods. Both programs are self-documented applications and make full use of the user-oriented graphical interface of the Macintosh to simplify the process of analysing data sets. An example is described to show the results obtained on a small ecological data set.		Jean Thioulouse	1989	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/5.4.287	biology;multivariate statistics	ML	-27.750024696003297	-29.798791621656335	150494
1d3f159c6b14775be88b0f5e8718fa1046a40077	modeling temporal effects of human mobile behavior on location-based social networks	human mobile behavior;temporal effect;location prediction;location based social networks	The rapid growth of location-based social networks (LBSNs) invigorates an increasing number of LBSN users, providing an unprecedented opportunity to study human mobile behavior from spatial, temporal, and social aspects. Among these aspects, temporal effects offer an essential contextual cue for inferring a user's movement. Strong temporal cyclic patterns have been observed in user movement in LBSNs with their correlated spatial and social effects (i.e., temporal correlations). It is a propitious time to model these temporal effects (patterns and correlations) on a user's mobile behavior. In this paper, we present the first comprehensive study of temporal effects on LBSNs. We propose a general framework to exploit and model temporal cyclic patterns and their relationships with spatial and social data. The experimental results on two real-world LBSN datasets validate the power of temporal effects in capturing user mobile behavior, and demonstrate the ability of our framework to select the most effective location prediction algorithm under various combinations of prediction models.	algorithm;location-based service;social network	Huiji Gao;Jiliang Tang;Xia Hu;Huan Liu	2013		10.1145/2505515.2505616	simulation;data mining	ML	-19.1553633510525	-35.96990524136812	150552
8f109dfd779f7c2079bd611e0f0ef3f79305c9a5	vgm: visual graph mining	support vector machines;kernel methods;data management;graph kernels;data mining;support vector;graph mining;software package;graph algorithm;graphic user interface;kernel method;nearest neighbor search;support vector machine;applied research	As more and more graph data become available in various application domains, graph mining is of ever increasing importance in data management.Graph kernels are a novel and successful method for data mining in graphs. Unfortunately, implementing graph kernels is not trivial, and few applied researchers have therefore used graph kernels so far. In this demonstration, we present a Java software package called Visual Graph Mining (VGM). VGM allows the user to classify graphs using graph kernels and Support Vector Machines in a graphical user interface that is easy to learn and use. It is linked to LIBSVM for Support Vector Machine computations, yet can be easily transferred to other Support Vector Machine packages. Furthermore, VGM provides basic data mining features such as Nearest Neighbor search, graph algorithms such as Dijkstra, Floyd-Warshall, and computes and visualizes product graphs and topological indices of graphs.VGM 's homepage can be found at: http://www.cip.ifi.lmu.de/~boettger/sigmod.	application domain;computation;data mining;floyd–warshall algorithm;graph kernel;graph theory;graphical user interface;java;nearest neighbor search;structure mining;support vector machine;topological index;video game music	Karsten M. Borgwardt;Sebastian Böttger;Hans-Peter Kriegel	2006		10.1145/1142473.1142570	support vector machine;data management;computer science;theoretical computer science;machine learning;data mining;graph kernel;graph;graph database;graph rewriting	ML	-27.50471608496055	-36.63138347863267	151452
fc99ec8b04e486043f0758b68d65db42a4b419ba	extending kddml with a visual metaphor for the kdd process	knowledge flow;satisfiability;data mining;visual programming;knowledge discovery process;graphic user interface;knowledge discovery in database;markup language	The spreading application of data mining techniques is clearly represented by the large number of suites supporting the knowledge discovery process. The latter can be viewed as real visual programming environments. Based on this assumption, we define some requirements which a typical data mining high-level graphical user interface should satisfy, in order to guarantee a good level of interactivity and expressiveness. The aim of this study is to use these requirements during the engineering and development of visual knowledge flow abstraction for the existing KDDML (Knowledge Discovery in Databases Markup Language) system. We introduce some features not only directly related to the visual metaphor, but also to the whole system, here intended as a real visual programming environment for the knowledge discovery process.	data mining	Valerio Grossi;Andrea Romei	2008		10.1007/978-3-540-85891-1_17	software mining;computer science;data science;data mining;database;knowledge extraction	ML	-30.166210290772387	-31.094547632039514	151777
4e7fd3a01d5ed1b4afbba8e7927884176bbeb355	turn-based evolution in a simplified model of artistic creative process	art;computational creativity;creative process;aesthetics;evolution	Evolutionary computation has often been presented as a possible model for creativity in computers. In this paper, evolution is discussed in the light of a theoretical model of human artistic process, recently presented by the author. Some crucial differences between human artistic creativity and natural evolution are observed and discussed, also in the light of other creative processes occurring in nature. As a tractable way to overcome these limitations, a new kind of evolutionary implementation of creativity is proposed, based on a simplified version of the previously presented model, and the results of initial experiments are presented and discussed. Artistic creativity is here modeled as an iterated turn-based process, alternating between a conceptual representation and a material representation of the work-to-be. Evolutionary computation is proposed as a heuristic solution to the principal steps in this process, translating back and forth between the two kinds of representation. Those steps are: implementation, going from concept to material form, and re-conceptualization, forming a new conceptual representation based on the current material form. The advantages and disadvantages of this approach are discussed, and concluding from the initial experiments, it is a very promising path, well worth further exploration.		Palle Dahlstedt	2015	Evolutionary Intelligence	10.1007/s12065-014-0123-5	computational creativity;computer science;artificial intelligence;machine learning;evolution	AI	-28.903608764927707	-25.527877857432074	151785
469e503b0ee73d2c711af3c5967f0f9781f12522	domain visualization using vxinsight® for science and technology management	description systeme;system description;science and technology;procesamiento informacion;visualizacion;vxord;information retrieval;information scientifique technique;information mapping;cartografia informacion;data mining;sandia;visualization;visualisation;estudio caso;fouille donnee;vxinsight;information representation;information processing;etude cas;cartographie information;descripcion sistema;scientific technical information;classification automatique;representation information;bibliographic records;relevance information retrieval;traitement information;automatic classification;informacion cientifica tecnica;clasificacion automatica;busca dato;scientific and technical information	* Sandia is a multiprogram laboratory operated by Sandia Corporation, a Lockheed Martin Company, for the United States Department of Energy under Contract DE-AC04-94AL85000. We present the application of our knowledge visualization tool, VxInsight, to enable domain analysis for science and technology management within the enterprise. Data mining from sources of bibliographic information is used to define subsets of information relevant to a technology domain. Relationships between the individual objects (e.g. articles) are identified using citations, descriptive terms, or textual similarities. Objects are then clustered using a forcedirected placement algorithm to produce a terrain view of the many thousands of objects. A variety of features which allow exploration and manipulation of the landscapes and which give detail-on-demand, enable quick and powerful analysis of the resulting landscapes. Examples of domain analyses used in S&T management at Sandia are given.	algorithm;chuck;computer multitasking;data mining;database;domain analysis;floor and ceiling functions;information retrieval;map;programmer;scott meyers;similarity measure;subject matter expert turing test;subject-matter expert;text corpus;thesaurus;toad data modeler;visualization (graphics);vxinsight	Kevin W. Boyack;Brian N. Wylie;George S. Davidson	2002	JASIST	10.1002/asi.10066	visualization;information processing;computer science;artificial intelligence;data mining;information retrieval	Visualization	-32.652343408349935	-28.0124736028726	151803
b20c05de8e4d67900bcaaefb6380c7bcafb85b78	analyzing parameter influence on time-series segmentation and labeling	labeling visualization compounds image color analysis accuracy time series analysis data visualization;time series data visualisation decision making interactive systems;decision making parameter influence time series segmentation time series labeling reconstructing process multiple sensor multivariate time series automated algorithm parameter dependency manual inspection visual analysis approach quality criteria visual design interactive design temporal pattern	Reconstructing processes from measurements of multiple sensors over time is an important task in many application domains. For the reconstruction, these multivariate time-series can be automatically processed. However, the outcomes of automated algorithms often vary in quality and show strong parameter dependencies, making manual inspections and adjustments of the results necessary. We propose a visual analysis approach to support the user in understanding parameters' influences on these results. With our approach the user can identify and select parameter settings that meet certain quality criteria. The proposed visual and interactive design helps to identify relationships and temporal patterns, supports subsequent decision making, and promotes higher accuracy as well as confidence in the results.	algorithm;application domain;interactive design;sensor;time series;visual analytics	Martin Rohlig;Martin Luboschik;Heidrun Schumann;Markus Bögl;Bilal Alsallakh;Silvia Miksch	2014	2014 IEEE Conference on Visual Analytics Science and Technology (VAST)	10.1109/VAST.2014.7042524	computer vision;computer science;machine learning;data mining	Visualization	-26.015862195243926	-33.79257068390228	151862
1fce686ebf20240413c809c619c1b54c903f32c3	genetic evolution of l and fl-systems for the production of rhythmic sequences	rhythm;genetics;fl systems;rhythmic indicators;l systems;genetic algorithm;genetic algorithms	Music composition with algorithms inspired by nature has led to the creation of systems that compose music with rich characteristics. Nevertheless, the complexity imposed by unsupervised algorithms may arguably be considered as undesired, especially when considering the composition of rhythms. This work examines the composition of rhythms through L and Finite L-systems (FL-systems) and presents an interpretation from grammatical to rhythmic entities that expresses the repetitiveness and diversity of the output of these systems. Furthermore, we utilize a supervised training scheme that uses Genetic Algorithms (GA) to evolve the rules of L and FL-systems, so that they may compose rhythms with certain characteristics. Simple rhythmic indicators are introduced that describe the density, pauses, self similarity, symmetry and syncopation of rhythms. With fitness evaluations based on these indicators we assess the performance of L and FL-systems and present results that indicate the superiority of the FL-system in terms of adaptability to certain rhythmic tasks.	entity;genetic algorithm;l (complexity);l-system;self-similarity;software release life cycle	Maximos A. Kaliakatsos-Papakostas;Andreas Floros;Nikolaos Kanellopoulos;Michael N. Vrahatis	2012		10.1145/2330784.2330855	genetic algorithm;computer science;artificial intelligence;machine learning;algorithm	AI	-27.42710309022899	-26.393603610967865	151879
f127a2bc4ff28567c1a3000e80f8abaafaedfe16	exploiting cctv camera system for advanced passenger services on-board trains	early smoke fire alarm;video camera network;video camera system;smart systems on board trains	This work proposes to exploit the on-board closed-circuit television (CCTV) security system to enable advanced services not only for surveillance, but also for safety, automatic climate control, e-ticketing. The new system has minimal hardware and installation cost overheads, since it exploits the already installed CCTV cameras. In addition, for each wagon, an embedded acquisition and processing node (EAP) is used, composed by a video multiplexer, and by a digital signal processor that implements algorithms for advanced services such as: smoke detection, to give an early alarm in case of a fire, or people detection for people counting, or fatigue detection for the driver. The information is then transmitted from each EAP node to the train information system. The final terminals can be the tablets of the train staff, and/or visualization displays in each wagon in case of fire alarms for the passengers.	algorithm;automatic control;closed-circuit television;digital signal processor;embedded system;information system;mathematical optimization;multiplexer;on-board data handling;people counter;protection mechanism;sensor;signal processing;streaming media;tablet computer;transmitter;video processing	Sergio Saponara;Luca Pilato;Luca Fanucci	2016	2016 IEEE International Smart Cities Conference (ISC2)	10.1109/ISC2.2016.7580748	embedded system;simulation;engineering;manual fire alarm activation;computer security	Robotics	-22.035655234743093	-28.89864980026449	152156
33a433f2c71e71b8e0a41b0185c27aeb760c325c	describing temporal correlation spatially in a visual analytics environment	temporal correlation;visual databases data visualisation geographic information systems interactive systems spatial data structures time series;spatial aggregation;interactive visualization;statistical significance;spatial structure;correlation time series analysis visual analytics data visualization;time series;calendars;data visualisation;confidence interval;crime analysis;temporal trend;time series analysis;geographic information systems;image color analysis;region of interest;data visualization;spatial data structures;correlation;visual analytics;correlation coefficient;interactive systems;confidence interval data value spatial data structure interactive visual analytics system temporal linear correlation spatial aggregation temporal region calendar view window correlation coefficient time series geospatial viewing window choropleth map;noise;visual databases	In generating and exploring hypotheses, analysts often want to know about the relationship between data values across time and space. Often, the analysis begins at a world level view in which the overall temporal trend of the data is analyzed and linear correlations between various factors are explored. However, such an analysis often fails to take into account the underlying spatial structure within the data. In this work, we present an interactive visual analytics system for exploring temporal linear correlations across a variety of spatial aggregations. Users can interactively select temporal regions of interest within a calendar view window. The correlation coefficient between the selected time series is automatically calculated and the resultant value is displayed to the user. Simultaneously, a linked geospatial viewing window of the data provides information on the temporal linear correlations of the selected spatial aggregation level. Linear correlation values between time series are displayed as a choropleth map using a divergent color scheme. Furthermore, the statistical significance of each linear correlation value is calculated and regions in which the correlation value falls within the 95% confidence interval are highlighted. In this manner, analysts are able to explore both the global temporal linear correlations, as well as the underlying spatial factors that may be influencing the overall trend.	coefficient;interactivity;region of interest;resultant;time series;visual analytics	Abish Malik;Ross Maciejewski;Erin Hodgess;David S. Ebert	2011	2011 44th Hawaii International Conference on System Sciences	10.1109/HICSS.2011.144	computer vision;computer science;data science;time series;data mining;data visualization;statistics	Visualization	-26.43320373651051	-33.33387859595976	152219
07bc660528dd1ccd0231036b67a0dd6fc0c7d9d7	audification: the use of sound to display multivariate data	multivariate data		audification	Gregory Kramer;Stephen Ellison	1991			statistics;audification;multivariate statistics;computer science	Visualization	-28.62699815311568	-29.04220749236653	152311
64b237e29c221fd0ea10205699dbd1bc3b2652ee	knowledge generation through human-centered information visualization	human computer interaction;semantic data;information visualization;human centered visualization;wastewater treatment plant;visualization technique;visual representation;computer and information sciences computer science;datavetenskap datalogi;computer science;data och informationsvetenskap;visual interfaces;wastewater treatment;domain specificity	One important intention of human-centered information visualization is to represent huge amounts of abstract data in a visual representation that allows even users from foreign application domains to interact with the visualization, to understand the underlying data, and finally, to gain new, application-related knowledge. The visualization will help experts as well as non-experts to link previously or isolated knowledge-items in their mental map with new insights. Our approach explicitly supports the process of linking knowledge-items with three concepts. At first, the representation of data items in an ontology categorizes and relates them. Secondly, the use of various visualization techniques visually correlates isolated items by graph-structures, layout, attachment, integration, or hyperlink techniques. Thirdly, the intensive use of visual metaphors relates a known source domain to a less known target domain. In order to realize a scenario of these concepts, we developed a visual interface for non-experts to maintain complex wastewater treatment plants. This domain-specific application is used to give our concepts a meaningful background.	attachments;computer animation;computer data storage;diagram;domain-specific language;hyperlink;information system;information visualization;information visualization reference model;interaction;mental mapping;multiplexing;natural user interface;ontology (information science);simulation;virtual reality;visual comparison	Katja Einsfeld;Achim Ebert;Andreas Kerren;Matthias Deller	2009	Information Visualization	10.1057/ivs.2009.15	semantic data model;computer vision;visual analytics;information visualization;visualization;interactive visualization;human–computer interaction;interactive visual analysis;computer science;artificial intelligence;machine learning;data mining;sewage treatment;multimedia;data visualization	Visualization	-30.385890897308595	-32.0544341958953	152491
ef6fcd60ac995e60d5ade754cd6617511f6f110c	morphological transformations of binary images with arbitrary structuring elements	mathematical morphology;morfologia matematica;image processing;binary image;dilatacion;procesamiento imagen;traitement image;algorithme;algorithm;erosion;dilatation;estructura datos;image binaire;imagen binaria;structurant;structure donnee;data structure;morphologie mathematique;algoritmo	Cet article propose un algorithme souple et performant pour déterminer des dilatations et érosions d'images binaires avec des éléments structurants quelconques. La premiére étape consiste en un suivi des contours de l'image considérée et en leur codage sous forme de boucles. Dans un deuxième temps, l'élément structurant, représénté sous la forme d'une structure de donnée appropriée, est efficacement propagé le long de ces boucles. L'algorithme s'avère extrêmement rapide quel que soit l'élément structurant employé. En outre, même lorsque cet élément est une forme simple, comme un carré ou un hexagone, les temps de calculs sont inférieurs à ceux de la plupart des implémentations existantes. La fin de l'article est consacrée à des exemples d'application, qui prouvent que l'utilisation d'élément structurants quelconques présente un grand intérêt pratique en morphologie mathématique.	binary image	Luc Vincent	1991	Signal Processing	10.1016/0165-1684(91)90025-E	computer vision;morphological skeleton;mathematical morphology;data structure;binary image;erosion;image processing;computer science;calculus;mathematics;structuring element;algorithm	Arch	-22.179300624415852	-37.74563781311258	152578
75133301d2f98edb81290f3c8c9a09238dbe527a	a polyline-based visualization technique for tagged time-varying data	pattern clustering;level of detail control;information visualization;data visualization meteorology temperature distribution time series analysis image color analysis shape clouds;data visualisation;information visualization polyline based visualization technique tagged time varying data large scale time varying data level of detail control data cluster;tagged timevarying data;level of detail control information visualization tagged timevarying data;pattern clustering data visualisation	We have various interesting time-varying data in our daily life, such as weather data (e.g., temperature and air pressure) and stock prices. Such time-varying data is often associated with other information: for example, temperatures can be associated with weather, and stock prices can be associated with social or economic incidents. Meanwhile, we often draw large-scale time-varying data by multiple polylines in one space to compare the time variation of multiple values. We think it should be interesting if such time-varying data is effectively visualized with their associated information. This paper presents a technique for polyline-based visualization and level-of-detail control of tagged time-varying data. Supposing the associated information is attached as tags of the time-varying values, the technique generates clusters of the time-varying values grouped by the tags, and selects representative values for each cluster, as a preprocessing. The technique then draws the representative values as polylines. It also provides a user interface so that users can interactively select interesting representatives, and explore the values which belong to the clusters of the representatives.	color;experiment;information;interactivity;level of detail;preprocessor;tag (metadata);time series;user interface	Sayaka Yagi;Yumiko Uchida;Takayuki Itoh	2012	2012 16th International Conference on Information Visualisation	10.1109/IV.2012.28	computer science;data science;data mining;world wide web	Visualization	-26.55779430261997	-33.28510097669569	152637
53c99ba7a9fb458e0f88c4eb26b014fd8227745b	panoramicdata: data analysis through pen & touch	filtering;multidimensional data panoramicdata data analysis multidimensional datasets interrelated tasks column sets data transformation data presentation exploratory process coping strategies side by side displays visual data exploration hybrid pen and touch system interactive displays direct ui support data aggregation data filtering data brushing unbounded whiteboard metaphor interactive visual display networks sql functionally complete logic filtering natural user experience;visual languages data analysis data visualisation light pens relational databases sql touch sensitive screens;data analysis;image color analysis;data visualization;relational databases;data visualization multidimensional systems data analysis relational databases image color analysis filtering;visual analytics;user interfaces;interaction design;pen and touch;multidimensional systems;coordinated and multiple views	Interactively exploring multidimensional datasets requires frequent switching among a range of distinct but inter-related tasks (e.g., producing different visuals based on different column sets, calculating new variables, and observing the interactions between sets of data). Existing approaches either target specific different problem domains (e.g., data-transformation or data-presentation) or expose only limited aspects of the general exploratory process; in either case, users are forced to adopt coping strategies (e.g., arranging windows or using undo as a mechanism for comparison instead of using side-by-side displays) to compensate for the lack of an integrated suite of exploratory tools. PanoramicData (PD) addresses these problems by unifying a comprehensive set of tools for visual data exploration into a hybrid pen and touch system designed to exploit the visualization advantages of large interactive displays. PD goes beyond just familiar visualizations by including direct UI support for data transformation and aggregation, filtering and brushing. Leveraging an unbounded whiteboard metaphor, users can combine these tools like building blocks to create detailed interactive visual display networks in which each visualization can act as a filter for others. Further, by operating directly on relational-databases, PD provides an approachable visual language that exposes a broad set of the expressive power of SQL including functionally complete logic filtering, computation of aggregates and natural table joins. To understand the implications of this novel approach, we conducted a formative user study with both data and visualization experts. The results indicated that the system provided a fluid and natural user experience for probing multi-dimensional data and was able to cover the full range of queries that the users wanted to pose.	addresses (publication format);brushing and linking;computation;coping behavior;database;functional completeness;imagery;interaction;interactivity;microsoft windows;numerous;problem domain;sql;undo;unique identifier;usability testing;user experience;user interface;visual language	Emanuel Zgraggen;Robert C. Zeleznik;Steven M. Drucker	2014	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2014.2346293	filter;computer vision;visual analytics;multidimensional systems;interactive visual analysis;relational database;computer science;interaction design;data mining;database;data analysis;user interface;world wide web;data visualization;statistics	Visualization	-29.545374103584365	-33.81491915920721	152724
e5afbb6acd6026582de60cfef1eae054145b75cc	a visual data exploration framework for complex problem solving based on extended cognitive fit theory	task;cognitive fit;information visualization;complex problem solving;computer security;data visualization;visual data exploration;problem solving	In this paper, we present a visual data exploration framework for complex problem solving. This framework consists of two major components: an enhanced task flow diagram and data visualization window. Users express their problem solving process and strategies using the enhanced task flow diagram, while multiple frames of visualizations are automatically constructed in the data visualization window and are organized as a tree map. This framework is based an extended Cognitive Fit Theory, which states that a data visualization should be constructed as a cognitive fit for specific tasks and a set of data variables. It also states that the structure of multiple data visualizations should match the structure of the corresponding tasks. Therefore, in our framework, data is presented in either visual or non-visual format based on the cognitive characteristic of the corresponding task. As users explore various problem solving strategies by editing the task flow diagram, the corresponding data visualizations are automatically updated for the best cognitive fit. This visual data exploration framework is particularly beneficial for users who need to conduct specific and complex tasks with large amount of data. As a case study, we present a computer security data visualization prototype.	problem solving	Ying Zhu;Xiaoyuan Suo;G. Scott Owen	2009		10.1007/978-3-642-10520-3_83	data flow diagram;computer vision;visual analytics;information visualization;computer science;theoretical computer science;machine learning;data mining;data visualization	AI	-29.828649040261503	-32.9823364275118	153256
93b4fce37b35c0fe0abe1030692205c2edc961de	graphical fisheye views of graphs	hierarchical structure;fisheye view;information visualization;fisheye views;planar graph	A fisheye lens is a very wide angle lens that shows places nearby in detail while also showing remote regions in successively less detail. This paper describes a system for viewing and browsing planar graphs using a software analog of a fisheye lens. We first show how to implement such a view using solely geometric transformations. We then describe a more general transformation that allows hierarchical, structured information about the graph to modify the views. Our general transformation is a fundamental extension to the previous research in fisheye views.	fisheye;graphical user interface;planar graph	Manojit Sarkar;Marc H. Brown	1992		10.1145/142750.142763	computer vision;information visualization;computer science;planar graph	HCI	-30.584901593203412	-34.91205161948326	153333
3a96046d9d54f955ba44ec2c83ea6866bcedca46	exploring spatiotemporal dynamics of urban fires: a case of nanjing, china		Urban fire occurs within the built environment, usually involving casualties and economic losses, and affects individuals and socioeconomic activities in the surrounding neighborhoods. A good understanding of the spatiotemporal dynamics of fire incidents can offer insights into potential determinants of various fire events, therefore enabling better fire risk estimation which can assist with future allocation of prevention resources and strategic planning of mitigation programs. Using a twelve-year (2002–2013) dataset containing the urban fire events in Nanjing, China, this research explores the spatiotemporal dynamics of urban fires using a range of exploratory spatial data analysis (ESDA) approaches. Of particular interest here are the fire incidents involving residential properties and local facilities due to their relatively higher occurrence frequencies. The results indicate that the overall amount of urban fires has greatly increased in the last decade and the spatiotemporal distribution of fire events varies among different incident types. The identified spatiotemporal patterns of urban fires in Nanjing can be linked to the urban development strategies and how they have been reflected in reality in recent years.	fire;spatial analysis	Xiaoxiang Zhang;Jing Yao;Katarzyna Sila-Nowicka	2018	ISPRS Int. J. Geo-Information	10.3390/ijgi7010007	environmental resource management;built environment;socioeconomic status;strategic planning;spatiotemporal analysis;china;geography;spatial analysis;urban planning	HCI	-19.24654724207839	-32.90279296798159	153811
6717ec8122cc498576a529fe70300ec364a1200d	contextual snapshots: enriched visualization with interactive spatial annotations	linked views;annotations;provenance;spatial selections	Spatial selections are a ubiquitous concept in visualization. By localizing particular features, they can be analyzed and compared in different views. However, the semantics of such selections are often dependent on other parameter settings and it can be difficult to reconstruct them without additional information. In this paper, we present the concept of contextual snapshots as an effective means for managing spatial selections in visualized data. The selections are automatically associated with the context in which they have been created. Contextual snapshots can be also used as the basis for interactive integrated and linked views, which enable in-place investigation and comparison of multiple visual representations of data. Our approach is implemented as a flexible toolkit with well-defined interfaces for integration into existing systems. We demonstrate the power and generality of our techniques by applying them to several distinct scenarios such as the visualization of simulation data and the analysis of historical documents.	historical document;in-place algorithm;linked list;simulation	Peter Mindek;Stefan Bruckner;Eduard Gröller	2013		10.1145/2508244.2508251	computer science;data mining;world wide web;information retrieval	Visualization	-29.988273990779383	-33.866620866109656	154090
0589a3db71674116565deae1255fbef4a3467163	a scalable framework for information visualization	information structure;hierarchy;high dimensionality;graphs data visualisation graphical user interfaces;graphical interface;3 dimensional visualization space scalable information visualization framework heterogeneous information spaces arbitrary levels of detail preprocessing information quantities frame of reference information sets dynamic hierarchy computation user controlled refinement unstructured information spaces focus context technique complex hierarchy graphs information structures graphical interface textual similarities high dimensional information space;focus context technique;information space;information visualization;graphs;data visualisation;graphical user interfaces;level of detail;clustering;multi dimensional information space;3 dimensional;data visualization tree graphs computer science computer interfaces control systems computer graphics filtering merging extraterrestrial measurements navigation;frame of reference;focus context	Thispaperdescribesmajorconceptsof a scalableinformation visualizationframework. We assumethat theexploration of heterogenousinformationspacesat arbitrary levelsof detail requiresa suitablepreprocessingof informationquantities,thecombination of different graphical interfacesand the illustration of the frame of referenceof giveninformationsets.Theinnovativefeaturesof our systemincludedynamichierarchy computationandusercontrolled refinementof thosehierarchiesfor preprocessingunstructured informationspaces,a new Focus+Context techniquefor visualizingcomplex hierarchy graphs,a new paradigmfor visualizing informationstructureswithin their frameof referenceanda new graphicalinterfacethatutilizestextualsimilaritiesto arrange objectsof high dimensionalinformation spacein 3-dimensional	clutter;graphical user interface;information visualization	Matthias Kreuseler;Norma López;Heidrun Schumann	2000		10.1109/INFVIS.2000.885088	computer vision;information visualization;computer science;theoretical computer science;data mining;graphical user interface;data visualization	Visualization	-29.61965266756802	-33.462410245841674	154152
92827c56d60e11a0a2cfc318e4efed40b37824d7	iceage: interactive clustering and exploration of large and high-dimensional geodata	computadora;tratamiento datos;computers;maps;hierarchical clustering;distribucion espacial;geography physical;human computer interaction;systeme information geographique;high dimensionality;mapa;hierarchical subspace clustering;north america;america del norte;amerique du nord;ordinateur;technology;interactive visualization;data processing;traitement donnee;physical sciences;analisis grupo;etats unis;feature space;estados unidos;carte;multi dimensional;interpretacion;conference item;cluster analysis;spatial pattern;science technology;visualization technique;spatial distribution;geographic information systems;analyse groupe;clustering method;interpretation;computer science;computer science information systems;distribution spatiale;spatial clustering and ordering;visualization and interaction;spatial clustering;geographic knowledge discovery;physical geography;distance;knowledge discovery	The unprecedented large size and high dimensionality of existing geographic datasets make the complex patterns that potentially lurk in the data hard to ®nd. Clustering is one of the most important techniques for geographic knowledge discovery. However, existing clustering methods have two severe drawbacks for this purpose. First, spatial clustering methods focus on the speci®c characteristics of distributions in 2-or 3-D space, while general-purpose high-dimensional clustering methods have limited power in recognizing spatial patterns that involve neighbors. Second, clustering methods in general are not geared toward allowing the human-computer interaction needed to effectively tease-out complex patterns. In the current paper, an approach is proposed to open up thè`black box'' of the clustering process for easy understanding, steering, focusing and interpretation, and thus to support an effective exploration of large and high dimensional geographic data. The proposed approach involves building a hierarchical spatial cluster structure within the high-dimensional feature space, and using this combined space for discovering multi-dimensional (combined spatial and non-spatial) patterns with ef®cient computational clustering methods and highly interactive visualization techniques. More speci®cally, this includes the integration of: (1) a hierarchical spatial clustering method to generate a 1-D spatial cluster ordering that preserves the hierarchical cluster structure, and (2) a density-and grid-based technique to effectively support the interactive identi®cation of interesting subspaces and subsequent searching for clusters in each subspace. The implementation of the proposed approach is in a fully open and interactive manner supported by various visualization techniques.	accessibility;cluster analysis;clustering high-dimensional data;computation;discretization;feature vector;general-purpose modeling;geographic information system;human–computer interaction;incidence matrix;interactive visualization;interpretation (logic);level of measurement;numerical analysis;scientific visualization;spatiotemporal pattern	Diansheng Guo;Donna Peuquet;Mark Gahegan	2003	GeoInformatica	10.1023/A:1025101015202	correlation clustering;constrained clustering;interactive visualization;data processing;geography;fuzzy clustering;interpretation;flame clustering;computer science;data science;consensus clustering;cure data clustering algorithm;data mining;hierarchical clustering;cluster analysis;brown clustering;distance;biclustering;cartography;hierarchical clustering of networks;clustering high-dimensional data;technology;conceptual clustering	DB	-26.09701092561053	-29.720677185142403	154159
016b2e1e6c82d540322da8b494108f989c1d85d0	visual decision-making: using treemaps for the analytic hierarchy process	analytic hierarchy process;decision support;direct manipulation;anchored instruction;site selection;information space;optimal solutions;sensitivity analysis;intelligent learning environments;macrocontext microworlds;heuristic techniques;trip planning	The Analytic Hierarchy Process (AHP), a decision-making method based upon division of problem spaces into hierarchies, is visualized through the use of treemaps, which pack large amounts of hierarchical information into small screen spaces. Two direct manipulation tools, presented metaphorically as a “pump” and a “hook,” were developed and applied to the treemap to support AHP sensitivity analysis. The problem of construction site selection is considered in this video. Apart from its traditional use for problem/ information space visualization, the treemap also serves as a potent visual tool for “what if’ type analysis.	analytical hierarchy;direct manipulation interface;television;treemapping	Toshiyuki Asahi;David Turo;Ben Shneiderman	1995		10.1145/223355.223747	analytic hierarchy process;simulation;decision support system;computer science;artificial intelligence;machine learning;sensitivity analysis;analytic network process	Visualization	-29.3112964979169	-28.146116614453874	154804
25a471a794e70a823832894a82a90f72796fc0ef	extracting and visualizing semantic structures in retrieval results for browsing	lsa;digital library;digital libraries;browsing;information visualization;conceptual clustering;boltzman algorithm;data analysis;science citation index;latent semantic analysis	The paper introduces an approach that organizes retrieval results semantically and displays them spatially for browsing. Latent Semantic Analysis as well as cluster techniques are applied for semantic data analysis. A modified Boltzman algorithm is used to layout documents in a two-dimensional space for interactive exploration. The approach was implemented to visualize retrieval results from two different databases: the Science Citation Index Expanded and theDido Image Bank.	algorithm;citation index;database;latent semantic analysis	Katy Börner	2000		10.1145/336597.336672	semantic computing;computer science;data mining;probabilistic latent semantic analysis;world wide web;information retrieval	Web+IR	-30.533890943252405	-34.05322782725658	154927
08e4cff5a9022d2629d15282ceb708db7da6ff66	assessing the effectiveness of different visualizations for judgments of positional uncertainty	uncertainty;human judgment;visualization;positioning;heuristics	Many techniques have been proposed for visualizing uncertainty in geospatial data. Previous empirical research on the effectiveness of visualizations of geospatial uncertainty has focused primarily on user intuitions rather than objective measures of performance when reasoning under uncertainty. Framed in the context of Google’s blue dot, we examined the effectiveness of four alternative visualizations for representing positional uncertainty when reasoning about self-location data. Our task presents a mobile mapping scenario in which GPS satellite location readings produce location estimates with varying levels of uncertainty. Given a known location and two smartphone estimates of that known location, participants were asked to judge which smartphone produces the better location reading, taking uncertainty into account. We produced visualizations that vary by glyph type (uniform blue circle with border vs. Gaussian fade) and visibility of a centroid dot (visible vs. not visible) to produce the four visualization formats. Participants viewing the uniform blue circle are most likely to respond in accordance with the actual probability density of points sampled from bivariate normal distributions and additionally respond most rapidly. Participants reported a number of simple heuristics on which they based their judgments, and consistency with these heuristics was highly predictive of their judgments.	bivariate data;gps satellite blocks;glyph;heuristic (computer science);mobile mapping;smartphone	Grant McKenzie;Mary Hegarty;Trevor J. Barrett;Michael F. Goodchild	2016	International Journal of Geographical Information Science	10.1080/13658816.2015.1082566	simulation;visualization;uncertainty;geography;computer science;heuristics;data mining;mathematics;statistics	HCI	-21.263623526888537	-32.5027954697519	155170
9d67fe06cb48a231dfb1a3b0a9dc5a2418a942dd	beyond sights: large scale study of tourists' behavior using foursquare data	social network services;continents;social networking online behavioural sciences computing graph theory recommender systems;tourists location based social networks characterization foursquare;sensors;graph model tourist behavior foursquare check in london new york rio de janeiro tokyo recommendation system location based social network lbsn;tourists;global positioning system;business;characterization;cities and towns;foursquare;cities and towns social network services business global positioning system conferences continents sensors;conferences;location based social networks	In this paper, we show how we can use Foursquare check-ins to understand the behavior of tourists that would be hard using traditional methods, such as surveys. For that, we analyze the behavior of tourists and residents in four popular cities around the world in four continents: London, New York, Rio de Janeiro, and Tokyo. We perform a spatio-temporal study of properties of the behavior of these two classes of users (tourists and residents). We have identified, for instance, that some locations have features that are more correlated with the tourists' behavior, and also that even in places frequented by tourists and residents there are clear distinction in the patterns of behavior of these groups of users. Our study also enables to identify which and when sights are popular. Our results could be useful in several cases, for example, to help in the development of new place recommendation systems for tourists, or to help city planners to better support tourists in their cities.	recommender system;spatiotemporal database;winsock	Ana Paula Gomes Ferreira;Thiago H. Silva;Antonio Alfredo Ferreira Loureiro	2015	2015 IEEE International Conference on Data Mining Workshop (ICDMW)	10.1109/ICDMW.2015.234	global positioning system;sensor	Robotics	-19.318521345692677	-35.01822761719558	155176
23275f575999df8d47e6476a741f3a04e186e584	visualizing node attribute uncertainty in graphs	reseau social;networks;4230;0130c;imagerie;carta de datos;scientific visualization;conference paper;prototipo;social network;visualization;imagery;visualisation;imagen borrosa;social networks;blurred image;mappage;visual analysis;mapping;imagineria;image floue;visual system;prototype;red social	Visualizations can potentially misrepresent information if they ignore or hide the uncertainty that are usually present in the data. While various techniques and tools exist for visualizing uncertainty in scientific visualizations, there are very few tools that primarily focus on visualizing uncertainty in graphs or network data. With the popularity of social networks and other data sets that are best represented by graphs, there is a pressing need for visualization systems to show uncertainty that are present in the data. This paper focuses on visualizing a particular type of uncertainty in graphs – we assume that nodes in a graph can have one or more attributes, and each of these attributes may have an uncertainty associated with it. Unlike previous efforts in visualizing node or edge uncertainty in graphs by changing the appearance of the nodes or edges, e.g. by blurring, the approach in this paper is to use the spatial layout of the graph to represent the uncertainty information. We describe a prototype tool that incorporates several uncertainty-to-spatial-layout mappings and describe a scenario showing how it might be used for a visual analysis task.	fisheye;graph (discrete mathematics);interaction;invenio;parallel coordinates;prototype;scientific visualization;social network	Nathaniel Cesario;Alex T. Pang;Lisa Singh	2011		10.1117/12.872677	computer vision;scientific visualization;visualization;computer science;artificial intelligence;data mining;social network	HCI	-28.711495688459166	-35.00358439365911	155221
4e793cc0bc5fc37b5975ae8e21bcee5fed15e9c6	interactive data exploration with a supercomputer	interaction process;exploratory data visualization;interactive data exploration;scientific data;supercomputer;parallel programming;better understanding;massively parallel processor;oldest datasets;exploratory data visualisation;computer graphics;data analysis;visualization technique;exploratory visualization;process tukey;exploratory data;workstations;multidimensional systems;data visualization;shape;computer science;gray scale;data visualisation	Scientific data of high-dimensionality is particularly difficult to understand if there are complex (and perhaps unknown) interactions among parameters. In such situations, the scientist can turn to a process Tukey has called exploratory data visualization. In exploratory data visualisation, we typically do not know exactly what we are looking for; instead, we explore the data with a variety of visualization techniques that can help us understand the nature of the data by demonstrating patterns in it. Given the complexity of the data and the large number of ways to map the data to a display, exploratory visualization can be truly effective only if it can also be interactive. In this paper we describe an experiment in exploratory data visualization using a massively parallel processor. With this approach we were able to find new features in some of our oldest datasets and to create more vivid presentations of familiar features in these datasets. Our experience has also led us to a better understanding of the nature of exploratory visualization and has resulted in some formal representations of the interaction process in this environment.	data visualization;goodyear mpp;interaction;parallel computing;supercomputer	Stuart D. Smith;Georges G. Grinstein;R. Daniel Bergeron	1991			computational science;visual analytics;scientific visualization;information visualization;visualization;interactive visualization;computer science;theoretical computer science;parallel rendering;data analysis;computer graphics;data visualization;statistics;data;computer graphics (images)	Visualization	-28.279772235106982	-32.29219740776913	155701
36f26f349bbd6ffb7cb527761596d8de1ed67ad8	multi-agent approach for return route support system simulation		We propose a system that supports stranded commuters caused by a large-scale disaster. When a large-scale disaster breaks out, buildings may collapse and roads may be damaged and the public transportation systems would be paralyzed. Thus, people working in the city center have to walk back home on foot. The problem is that when those people start walking, the situation along the routes for returning home may be different from that of the pre-disaster. Not only may it be the first time for most of them to walk home, but also the return route may be extremely complex due to many detours. They have to look for alternative routes whenever bridges collapse and fires break out. Making situation become worse, modern people intensively use navigation systems, those systems may be unavailable due to the paralyzed Internet. A large scale disaster may destroy base stations of wireless phones, and even if it does not completely destroy them, extreme congestion may paralyze the communication infrastructure so that not only net-surfing using smartphone, but also collecting information by e-mail may become impossible. To deal with such situations, we are designing a system that provides those unfortunate pedestrians appropriate return routes to their homes without depending on the communication infrastructures. Instead, our proposed system only depends on smartphones of those pedestrians and constructs mobile ad hoc networks (MANET) to collect and disperse useful information. We employ multiple mobile agents extensively for information collection and dispersion. In order to demonstrate the feasibility of our system, we have constructed a preliminary prototype of the simulation system and have conducted numerical experiments.	email;experiment;hoc (programming language);internet;mobile agent;network congestion;numerical analysis;prototype;safe area (television);simulation;smartphone	Shouhei Taga;Tomofumi Matsuzawa;Munehiro Takimoto;Yasushi Kambayashi	2016		10.5220/0005819602690274	the internet;computer science;mobile ad hoc network;public transport;wireless;risk management;mobile agent;computer security;base station	HCI	-20.529472517445733	-28.16850364133521	155769
76d6c85090e0ce178f632fa8e49d75e6c2c4c82f	itree: exploring time-varying data using indexable tree	database indexing;multiple coordinated views itree time varying data analysis data visualization cost effective data querying data compacting data indexing data classification time activity curve representation hierarchical symbolic representation data hierarchy visual representation data sets symbolic view spatial view;query processing;query processing data analysis data visualisation database indexing query languages;query languages;data visualisation;data analysis;data visualization indexing visualization histograms market research earthquakes transforms	Significant advances have been made in time-varying data analysis and visualization, mainly in improving our ability to identify temporal trends and classify the underlying data. However, the ability to perform cost-effective data querying and indexing is often not incorporated, which posts a serious limitation as the size of time-varying data continue to grow. In this paper, we present a new approach that unifies data compacting, indexing and classification into a single framework. We achieve this by transforming the time-activity curve representation of a time-varying data set into a hierarchical symbolic representation. We further build an indexable version of the data hierarchy, from which we create the iTree for visual representation of the time-varying data. A hyperbolic layout algorithm is employed to draw the iTree with a large number of nodes and provide focus+context visualization for interaction. We achieve effective querying, searching and tracking of time-varying data sets by enabling multiple coordinated views consisting of the iTree, the symbolic view and the spatial view.	algorithm;block size (cryptography);breakpoint;data hierarchy;force-directed graph drawing;reflections of signals on conducting lines;simple api for xml;transfer function;visual analytics;volume rendering	Yi Gu;Chaoli Wang	2013	2013 IEEE Pacific Visualization Symposium (PacificVis)	10.1109/PacificVis.2013.6596138	information visualization;computer science;data mining;database;information retrieval	Visualization	-27.84559487855122	-33.432373241012506	155914
d6e4ff9514c182c1167a66d67e539c238c9ff198	shaping city neighborhoods leveraging crowd sensors	thematic maps;geographic summarization;clustering;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;smart city;social media;urban data	Location-based social networks (LBSN) are capturing large amount of data related to whereabouts of their users. This has become a social phenomenon, that is changing the normal communication means and it opens new research perspectives on how to compute descriptive models out of this collection of geo-spatial data. In this paper, we propose a methodology for clustering location-based information in order to provide first glance summaries of geographic areas. The summaries are a composition of fingerprints, each being a cluster, generated by a new subspace clustering algorithm, named GeoSubClu, that is proposed in this paper. The algorithm is parameter-less: it automatically recognizes areas with homogeneous density of similar points of interest and provides clusters with a rich characterization in terms of the representative categories. We measure the validity of the generated clusters using both a qualitative and a quantitative evaluation. In the former, we benchmark the results of our methodology over an existing gold standard, and we compare the achieved results against two baselines. We then further validate the generated clusters using a quantitative analysis, over the same gold standard and a new geographic extent, using statistical validation measures. Results of the qualitative and quantitative experiments show the robustness of our approach in creating geographic clusters which are significant both for humans (holding a F-measure of 88.98% over the gold standard) and from a statistical point of view.	algorithm;baseline (configuration management);benchmark (computing);cartography;cluster analysis;clustering high-dimensional data;computer cluster;experiment;fingerprint;jaccard index;knowledge base;location-based service;map;noise shaping;point of view (computer hardware company);point of interest;sensor;social network;sparse matrix;statistical model;streaming simd extensions;taxonomy (general);usability;user interface	Guiseppe Rizzo;Rosa Meo;Ruggero G. Pensa;Giacomo Falcone;Raphaël Troncy	2017	Inf. Syst.	10.1016/j.is.2016.06.009	simulation;social media;computer science;artificial intelligence;data science;machine learning;data mining;database;cluster analysis;world wide web;computer security;thematic map;statistics	AI	-20.037700104056377	-35.68622556981604	156039
597ff26368a4e84eb65b632f5e23a74e109e50d1	guest editorial: data management and analysis in location-based social networks		Social networks are prevalent on the Internet and become a hot research topic attracting many professionals from a variety of fields. The advances in location-acquisition and mobile communication technologies empower people to use location data with existing online social networks. The dimension of location helps bridge the gap between the physical world and online social networking services. Furthermore, people in an existing social network can expand their social structure with the new interdependency derived from their locations. This Special Issue focuses on the following important research questions in location based social networks. First, how to acquire quality location data which requires matching GPS locations obtained to map locations. Second, how to capture the correlations between the spatial and temporal aspects of the GPS trajectories. Third, how to mine and query the location data effectively and efficiently. Finally, how to deal with location privacy issues in all these tasks. This special issue is	global positioning system;interdependence;internet;privacy;social network;social structure	Rui Zhang;Timos K. Sellis;Yu Zheng;Mohamed F. Mokbel	2015	Distributed and Parallel Databases	10.1007/s10619-015-7177-y	data management;distributed computing;computer science;social network	HCI	-19.133247312693452	-35.77488233476486	156361
33b5d9f8c3e306199edbe6d8fa6185dcaaecf606	an exploration of grammatical encodings to model six nations rugby match outcomes	grammar;training;computational modeling;games;business;encoding;fans	We explore the application of grammar-based Genetic Programming, specifically Grammatical Evolution, to the problem of modeling the outcome of Six Nations Rugby matches. A series of grammars are developed in attempts to generate different forms of predictive rules, which might be useful in pre-match and mid-match scenarios. A number of interesting models are generated and their utility discussed.	application domain;decision tree;genetic programming;grammatical evolution;overfitting	Michael O'Neill;Anthony Brabazon;David Fagan	2016	2016 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2016.7744353	games;simulation;computer science;artificial intelligence;machine learning;grammar;computational model;encoding	Robotics	-26.696412102146688	-25.285209321535365	156367
a274a23077c4a33711e2bd8e1159f4d4fdc5bf51	avatar-centric risk evaluation	path planning avatar centric risk evaluation hazard detection hazard prevention socio economic impact emergency response data visualization data simulation risk detection emergency assessment sensor data virtual environment risk mitigation;path planning;cultural heritage;hazards earthquakes terrorism environmental economics uncertainty data visualization data analysis avatars virtual environment path planning;risk evaluation;risk management;hazards;video game;data visualisation;hazards avatars data visualisation risk management disasters;economic impact;data visualization;avatars;virtual environment;risk mitigation;temporal change;disasters;modeling and analysis	Hazard detection and prevention of natural and man-made disasters at critical civil infrastructure is becoming increasingly important. Recent events, such as earthquakes and terrorist attacks, clearly demonstrated the societal and economical impact stemming from the limitations and uncertainty within currently deployed emergency response systems. We present a new data visualization and simulation platform that facilitates risk detection, emergency response and assessment in hazardous situations. The platform is based on the acquisition, modeling and analysis of sensor data, to capture objects and temporal changes in the observed spaces. Avatars are acquired, inserted and tracked in a virtual environment, enabling the simulation of multiple perilous situations and assisting in determining possible risk mitigation strategies. While the initial research focus is on algorithms and techniques in the field of hazard detection and prevention using path planning, the results can also be applied to diverse fields such as media contents development, cultural heritage, e-learning, teleconferencing, animation and video gaming.	algorithm;avatar (computing);data visualization;emergency response systems;motion planning;risk assessment;scalability;simulation;stemming;virtual reality	Maria-Cruz Villa-Uriol;Falko Kuester;Oscar García Pañella;J. Andres Fernandez Munuera	2005	Seventh IEEE International Symposium on Multimedia (ISM'05)	10.1109/ISM.2005.40	economic impact analysis;disaster;simulation;risk management;hazard;computer science;cultural heritage;virtual machine;data mining;motion planning;management;computer security;data visualization;statistics	Embedded	-23.685148471671035	-28.766559076077744	156625
2d279fa10cfce887dcf4e3aba4730dfe4b347ddd	visual soccer analytics: understanding the characteristics of collective team movement based on feature-driven analysis and abstraction	journal_article;sport analytics;soccer analysis;visual analytics	With recent advances in sensor technologies, large amounts of movement data have become available in many application areas. A novel, promising application is the data-driven analysis of team sport. Specifically, soccer matches comprise rich, multivariate movement data at high temporal and geospatial resolution. Capturing and analyzing complex movement patterns and interdependencies between the players with respect to various characteristics is challenging. So far, soccer experts manually post-analyze game situations and depict certain patterns with respect to their experience. We propose a visual analysis system for interactive identification of soccer patterns and situations being of interest to the analyst. Our approach builds on a preliminary system, which is enhanced by semantic features defined together with a soccer domain expert. The system includes a range of useful visualizations to show the ranking of features over time and plots the change of game play situations, both helping the analyst to interpret complex game situations. A novel workflow includes improving the analysis process by a learning stage, taking into account user feedback. We evaluate our approach by analyzing real-world soccer matches, illustrate Konstanzer Online-Publikations-System (KOPS) URL: http://nbn-resolving.de/urn:nbn:de:bsz:352-0-309987 Erschienen in: ISPRS International Journal of Geo-Information ; 4 (2015), 4. S. 2159-2184 http://dx.doi.org/10.3390/ijgi4042159	artificial intelligence;drag and drop;interaction;interdependence;sensemaking;sensor;similarity search;subject matter expert turing test;subject-matter expert;visual analytics	Manuel Stein;Johannes Häussler;Dominik Jäckle;Halldór Janetzko;Tobias Schreck;Daniel A. Keim	2015	ISPRS Int. J. Geo-Information	10.3390/ijgi4042159	simulation;engineering;data mining;multimedia	HCI	-25.686812616388618	-34.55476234129659	156767
b052cb965bf61412d114d6e72c28337917c19fd7	geo-sensor(s) for potential prediction of earthquakes: can earthquake be predicted by abnormal animal phenomena?		With the advancement of physical sensors and scientific modelling, we fortunately are able to track, monitor and even predict most of natural destructive forces, e.g. hurricanes and tornadoes. Compared to other natural disasters, earthquakes are particularly traumatic because they occur without explicit and timely warning and therefore are extremely difficult, if at all possible, to detect timely. Meanwhile, anomalous animal behaviours have been widely observed the day even several days before an Earthquake. Therefore, animals can be used as intelligent geosensors to tell or estimate when and where an earthquake will potentially occur. This paper presents a framework synthesizing crowdsourcing reports of anomalous animal behaviour from both active sources (designed mobile app and websites) and passive sources (social networks like Twitter, Facebook) for earthquake early prediction. To demonstrate the effectiveness of the proposed framework, a proof-of-concept prototype is then developed to collect, visualize, analyse and mine such crowdsourcing data to detect a potential earthquake. ARTICLE HISTORY Received 6 August 2017 Accepted 31 January 2018	crowdsourcing;geo (microformat);mobile app;prototype;sensor;social network	Kai Cao;Qunying Huang	2018	Annals of GIS	10.1080/19475683.2018.1450785	geography;remote sensing;data mining;big data;scientific modelling;emergency management;volunteered geographic information;social network;social media;natural disaster;crowdsourcing	Web+IR	-20.98148816859213	-33.50832236545239	157027
04ffac19c187b80b2c5073925cdd5d6cd42f280a	the tag genome: encoding community knowledge to support novel interaction	selected works;information retrieval;data mining;conversational recommenders;machine learning;bepress;recommender systems;tagging	This article introduces the tag genome, a data structure that extends the traditional tagging model to provide enhanced forms of user interaction. Just as a biological genome encodes an organism based on a sequence of genes, the tag genome encodes an item in an information space based on its relationship to a common set of tags. We present a machine learning approach for computing the tag genome, and we evaluate several learning models on a ground truth dataset provided by users. We describe an application of the tag genome called Movie Tuner which enables users to navigate from one item to nearby items along dimensions represented by tags. We present the results of a 7-week field trial of 2,531 users of Movie Tuner and a survey evaluating users’ subjective experience. Finally, we outline the broader space of applications of the tag genome.	data structure;ground truth;machine learning;tv tuner card;tag cloud	Jesse Vig;Shilad Sen;John Riedl	2012	TiiS	10.1145/2362394.2362395	computer science;machine learning;data mining;world wide web;information retrieval;recommender system	HCI	-30.996797316653907	-34.38545413403425	157104
8ca89666816636a9fd509d5a68b61e388529ec07	using synchronised tag clouds for browsing data collections	data visualisation;data browsing;tag clouds;search service	Tag clouds have become a popular means of visualising and browsing data, especially in Web 2.0 applications. We show how they can be used to provide flexible and intuitive interfaces to web search services over data collections by using multiple synchronised tag clouds to browse that data. A data collection can have alternative tag clouds and a tag cloud alternative visualisations, with the choice of tag cloud and visualisation at any time controlled by a combination of user selection, developer specification and default system behaviour. A search interface is defined by an augmented data model that specifies the viewer classes, their associated tag clouds and the visualisations of these tag clouds. We demonstrate the approach by describing how we implemented a web application to browse data related to researchers and their publications.	browsing;data model;faceted classification;sql;tag cloud;usability testing;web 2.0;web application;web search engine	Alexandre de Spindler;Stefania Leone;Michael Nebeling;Matthias Geel;Moira C. Norrie	2011		10.1007/978-3-642-21640-4_17	computer science;database;world wide web;tag cloud;information retrieval;data visualization	Web+IR	-31.06040077132718	-33.87575653386388	157285
1b9bf12340bd3c7232c673f2a966f3ad61a1ab53	paras: interactive parameter space exploration for association rule mining	visual mining;association rules;interestingness parameters	We demonstrate our PARAS technology for supporting interactive association mining at near real-time speeds. Key technical innovations of PARAS, in particular, stable region abstractions and rule redundancy management supporting novel parameter space-centric exploratory queries will be showcased. The audience will be able to interactively explore the parameter space view of rules. They will experience near real-time speeds achieved by PARAS for operations, such as comparing rule sets mined using different parameter values, that would otherwise take hours of computation and much manual investigation. Overall, we will demonstrate that the PARAS system provides a rich experience to data analysts through parameter tuning recommendations while significantly reducing the trial-and-error interactions.	association rule learning;computation;interaction;interactivity;mined;performance tuning;real-time clock;real-time computing;real-time transcription;rule 90	Abhishek Mukherji;Xika Lin;Christopher R. Botaish;Jason Whitehouse;Elke A. Rundensteiner;Matthew O. Ward;Carolina Ruiz	2013		10.1145/2463676.2465245	association rule learning;computer science;data science;machine learning;data mining;database	HCI	-25.785369532611266	-34.46866949111763	157298
210c5fc8bf0cd37ae191b9bcae028d3412006c91	analyzing complex ftms simulations: a case study in high-level visualization of ion motions	motion analysis;analytical models;time dependent;motion control;trapped ions data visualisation fourier transform spectrometers fourier transforms physics computing rendering computer graphics;ftms simulation;particle visualization;motion features particle visualization motion;trapped ions;camera control;fourier transform spectrometers;motion;data mining;analytical models motion analysis data visualization rendering computer graphics cameras animation data mining motion control fourier transforms mass spectroscopy;physics computing;visual motion;parameterized camera control mechanism;data visualisation;fourier transform mass spectrometry ftms simulation particle visualization rendering ion motion computer animation dynamic property parameterized camera control mechanism;dynamic property;fourier transforms;animation;data visualization;mass spectroscopy;computer animation;fourier transform mass spectrometry;rendering computer graphics;cameras;motion features;rendering ion motion;dynamic properties	Current practice in particle visualization renders particle position data directly onto the screen as points or glyphs. Using a camera placed at a fixed position, particle motions can be visualized by rendering trajectories or by animations. Applying such direct techniques to large, time dependent particle data sets often results in cluttered images in which the dynamic properties of the underlying system are difficult to interpret. In this case study we take an alternative approach to the visualization of ion motions. Instead of rendering ion position data directly, we first extract meaningful motion information from the ion position data and then map this information onto geometric primitives. Our goal is to produce high-level visualizations that reflect the physicists' way of thinking about ion dynamics. Parameterized geometric icons are defined to encode motion information of clusters of related ions. In addition, a parameterized camera control mechanism is used to analyze relative instead of only absolute ion motions. We apply the techniques to simulations of Fourier transform mass spectrometry (FTMS) experiments. The data produced by such simulations can amount to 5.104 ions and 105 timesteps. This paper discusses the requirements, design and informal evaluation of the implemented system	animation;computer simulation;encode;experiment;glyph;high- and low-level;imagery;instrument - device;interaction;ions;mass spectrometry;motion;physical object;rendering (computer graphics);requirement	Wojciech Burakiewicz;Robert van Liere	2006	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2006.118	motion control;anime;fourier transform;computer vision;simulation;fourier transform ion cyclotron resonance;computer science;motion;data mining;mathematics;computer animation;data visualization;statistics;computer graphics (images)	Visualization	-28.305301568091245	-32.84950906814019	157658
7300ec10241cb0e4cfb3e91e9404fdd89b86c662	understanding user attributes from calling behavior: exploring call detail records through field observations	calling behavior;call detail records;demographic attributes;article	Mobile phones are arguably one of the most prolific sources of large-scale human mobility data. The availability of this data has generated a massive body of research focused on understanding the dynamics and patterns of human mobility. However, it is increasingly evident that additional value can be derived from such data. This paper proposes a novel approach for understanding the attributes of mobile users by analyzing calling behavior derived from field survey data, in combination with call detail records (CDRs). Our survey reveals distinctive traits in calling behavior that correspond to user attributes. Analysis results demonstrate that frequent call locations, the variability in call time distributions, and the locations from which calls are made around midday are all keys to distinguishing gender. In addition, the location of calls initiated during the morning hours is a key to analyzing income levels for males.	mobile phone;spatial variability	Ayumi Arai;Apichon Witayangkurn;Hiroshi Kanasugi;Teerayut Horanont;Xiaowei Shao;Ryosuke Shibasaki	2014		10.1145/2684103.2684107	data mining;world wide web	HCI	-19.235169013293923	-34.641151745578185	157884
0d263696014aa975b760f929957344f1c6566039	web-linkage viewer: finding graph structures in the web	finding graph structures;web-linkage viewer	Web -linkage Viewer is a system that draws the Web-links, dividing into the global-links and the local-links, and placing the top nodes of sites in the Web and the global-links on a spherical surface and the local-links as trees in  cones emanating from the spherical surface, to display graph structures in the Weblinks understandably as Figure 1. We define  the site as follows to define the global-links and the local-links, instead of the ambiguous concept in daily life.  	world wide web	Yasuhito Asano;Hiroshi Imai;Masashi Toyoda;Masaru Kitsuregawa	2002		10.1007/3-540-45703-8_41	graph database	ECom	-32.26149153319375	-34.6870239503931	157955
8e57c48f4775f22ac67ebcdd9745dc1665313e84	analyzing structural characteristics of object category representations from their semantic-part distributions	freehand sketch;semantic part;visualization;object category representation	Studies from neuroscience show that part-mapping computations are employed by human visual system in the process of object recognition. In this paper, we present an approach for analyzing semantic-part characteristics of object category representations. For our experiments, we use category-epitome, a recently proposed sketch-based spatial representation for objects. To enable part-importance analysis, we first obtain semantic-part annotations of hand-drawn sketches originally used to construct the epitomes. We then examine the extent to which the semantic-parts are present in the epitomes of a category and visualize the relative importance of parts as a word cloud. Finally, we show how such word cloud visualizations provide an intuitive understanding of category-level structural trends that exist in the category-epitome object representations. Our method is general in applicability and can also be used to analyze part-based visual object representations for other depiction methods such as photographic images.	category theory;computation;experiment;human visual system model;outline of object recognition;tag cloud	Ravi Kiran Sarvadevabhatla;R. Venkatesh Babu	2016		10.1145/2964284.2967190	computer vision;method;visualization;computer science;artificial intelligence;theoretical computer science	ML	-28.315592124883334	-37.23648153132224	158018
f0c86e351486798e50ec4a986df906fcf60c2f1c	interactive fusion and tracking for multi-modal spatial data visualization	methodology and techniques;interaction techniques;i 3 6 computer graphics methodology and techniques interaction techniques;i 3 6 computer graphics;categories and subject descriptors according to acm ccs	Scientific data acquired through sensors which monitor natural phenomena, as well as simulation data that imitate time-identified events, have fueled the need for interactive techniques to successfully analyze and understand trends and patterns across space and time. We present a novel interactive visualization technique that fuses ground truth measurements with simulation results in real-time to support the continuous tracking and analysis of spatiotemporal patterns. We start by constructing a reference model which densely represents the expected temporal behavior, and then use GPU parallelism to advect measurements on the model and track their location at any given point in time. Our results show that users can interactively fill the spatio-temporal gaps in real world observations, and generate animations that accurately describe physical phenomena.	algorithm;central processing unit;computer graphics;data structure;data visualization;eurographics;graphics processing unit;ground truth;interactive media;interactive visualization;interactivity;interpolation;john d. wiley;missing data;nearest neighbor search;parallel computing;preprocessor;real-time clock;reference model;region of interest;sensor;shader;simulation	Mai El-Shehaly;Denis Gracanin;Mohamed A. Gad;Hicham G. Elmongui;Kresimir Matkovic	2015	Comput. Graph. Forum	10.1111/cgf.12637	computer vision;simulation;computer science;artificial intelligence;theoretical computer science;operating system;algorithm;computer graphics (images)	Visualization	-27.622603310441068	-35.756448218702765	158027
e030ac0018042e199f58ac36db59d8040a69e930	formalising visual languages	multiple representation;visual sentence;visual reasoning;computer display;graphical user interfaces visual languages pattern recognition computer graphics computer displays;remuneration;users;computer graphics;image converters;interpreted image;ambiguity control visual language formalisation pattern recognition image generation visual reasoning visual human computer communication full screen image management computer display icon interpretation handling multiple representations users diverse tasks computational meaning visual sentence interpreted image visual language user computer dialogue;user computer dialogue;visual human computer communication;satisfiability;full screen image management;icon interpretation handling;visual languages;graphical user interfaces;image generation;ambiguity control;pixel;visual language formalisation;computational meaning;data visualization;computer displays;digital images image generation image converters computer displays pixel remuneration pattern recognition face data visualization humans;visual language;diverse tasks;pattern recognition;face;humans;multiple representations;digital images	We propose a formalisation of visual languages which allows a uniform approach to satisfying the needs of pattern recognition, image generation, and visual reasoning faced in visual human-computer communication. Such needs comprise managing the full screen image as seen on the computer display, handling interpretation of icons even when ambiguous, or generating multiple representations to convey one same meaning as required by different users for diverse tasks. We also formalise the way the machine associates a computational meaning with an image (including the whole screen image), and conversely, the way it generates an image on the screen from a computation. A definition of visual sentence as interpreted image is proposed, and the visual language is viewed as a set of visual sentences in a user-computer dialogue. Examples of how the proposed formalism is suitable for ambiguity control and multiple representations of meanings are provided.	computation;computer monitor;glossary of computer graphics;pattern recognition;semantics (computer science);visual language	Paolo Bottoni;Maria Francesca Costabile;Stefano Levialdi;Piero Mussio	1995		10.1109/VL.1995.520784	natural language processing;visual rhetoric;computer vision;computer science;human visual system model;communication	Vision	-32.67671736669155	-32.90897747282378	158405
6968da238236f12558fa58d0940027ca9d74370d	an integrated in-situ approach to impacts from natural disasters on critical infrastructures	power systems;mobile communication media visual analytics monitoring context power systems;media;monitoring;social networking online decision support systems disasters emergency management mobile computing;mobile communication;inproceedings;visual analytics;context;crisis management integrated in situ approach natural disasters real time situational awareness operational risk management visual analytics control room system network infrastructures social media analysis mobile in situ analysis critical infrastructure monitoring cascading effect detection root cause analysis crisis response management unified views analytical tools decision support system planning system qualitative analysis	Natural disasters can have a devastating effect on critical infrastructures, especially in case of cascading effects among multiple infrastructures such as the electric power grid, the communication network, and the road network. While there exist detailed models for individual types of infrastructures such as electric power grids, these do not encompass the various interconnections and interdependencies to other networks. Cascading effects are hard to discover and often the root causes of problems remain unclear. In order to enable real-time situational awareness for operational risk management one needs to be aware of the broader context of events. In this paper, we present a unique visual analytics control room system that integrates the separate visualizations of the different network infrastructures with social media analysis and mobile in-situ analysis to help to monitor the critical infrastructures, detecting cascading effects, performing root cause analyses, and managing the crisis response. Both the social media analysis and the mobile in-situ analysis are important components for an effective understanding of the crisis and an efficient crisis response. Our system provides a mechanism for conjoining the available information of different infrastructures and social media as well as mobile in-situ analysis in order to provide unified views and analytical tools for monitoring, planning, and decision support. A realistic use case scenario based on real critical infrastructures as well as our qualitative study with crisis managers shows the potential of our approach.	decision support system;existential quantification;interdependence;mobile device;real-time web;risk management;sensor;simulation;social media;telecommunications network;visual analytics	Sebastian Mittelstädt;Xiaoyu Wang;Todd Eaglin;Dennis Thom;Daniel A. Keim;William J. Tolone;William Ribarsky	2015	2015 48th Hawaii International Conference on System Sciences	10.1109/HICSS.2015.136	visual analytics;simulation;media;mobile telephony;computer science;knowledge management;electric power system;world wide web;computer security	HCI	-19.582937943667428	-32.193306144355795	158861
b884bf27535a7dd5c6dcad3e65e989cc16dab7c8	a method of hierarchical time-series data visualization	hierarchy;time series;data visualization;air quality	In this paper, we propose a new method of visualizing hierarchy and time-series data. We use the node-linked technology to show hierarchy structures, rectangles from the left to right to represent the time-series data and a pie chart to represent statistical information about the time-series data. The method is designed to display and compare the corresponding data of each layer, and then observe the differences between the nodes at each layer and the trends of the thing. We applied this method in the urban air quality data visualization and achieved good results.	data visualization;time series	Ning Li;Zhifang Jiang;Zixiang Liu;Xiangxu Meng	2013		10.1145/2493102.2493121	computer science;data science;data mining;data hierarchy;database	HCI	-26.37535473836154	-32.983839022317376	159200
79303b0d2a5b7ddb3b11a3c45af0d25f8f2d958f	digital library framework for progressive compressed 3d models	search and retrieval;forma libre;free surface;surface libre;multimedia;modelo 3 dimensiones;metadata;data compression;signature inverse;digital library;modele 3 dimensions;free form;three dimensional model;stockage donnee;systeme numerique;data storage;forme libre;biblioteca electronica;digital system;3d model;manufacturing;metadonnee;superficie libre;sistema numerico;almacenamiento datos;electronic library;metadatos;compresion dato;bibliotheque electronique;compression donnee;graphic design	With the growth in computing, storage, and networking infrastructure, it is becoming feasible for multimedia professionals, such as graphic designers in commercial, manufacturing, scientific, and entertainment areas, to work with 3D models of objects of their interest. As a result, the volume of 3D models available in digital form is rapidly growing. However, we lack a digital library system for these models, where they can be stored, searched and retrieved efficiently. As the size of data representing a 3D model is usually large, it presents a number of challenges in building an efficient digital library system. In this paper, we propose a digital library framework that is designed to provide storage services for 3D models, search and discovery services, and progressive retrieval services. The key to the digital library framework is a representation of a 3D model based on 'surface signatures'. This representation scheme captures the shape information of any free-form surface and encodes it into a 2D image corresponding to a certain point on the surface. The original object can be reconstructed from the intersection of the inverse mapping of few signatures with accuracy that depends on the location of the selected points and the number of signatures used in representing the object. This compressed representation allows for efficient storage and is amenable for progressive retrieval. Also, the 3-D objects can be checked for similarities in the compressed domain.© (2002) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	3d modeling;digital library	Hesham Anan;Kurt Maly;Mohammad Zubair	2002		10.1117/12.460167	simulation;computer science;multimedia;computer graphics (images)	Vision	-33.306474871471075	-25.953829991580054	159296
294a7230eb4565e5cec552eae4116cb0bb1e56d5	comparing visualizations for tracking off-screen moving targets	moving object;edgeradar;visualization;control system;visualization technique;moving targets;halo;navigation system;off screen visualization	In games, aircraft navigation systems and in control systems, users have to track moving targets around a large workspace that may extend beyond the users. viewport. This paper presents on-going work that investigates the effectiveness of two different off-screen visualization techniques for accurately tracking off-screen moving targets. We compare the most common off-screen representation, Halo, with a new fisheye-based visualization technique called EdgeRadar. Our initial results show that users can track off-screen moving objects more accurately with EdgeRadar over Halos. This work presents a preliminary but promising step toward the design of visualization techniques for tracking off-screen moving targets.	control system;fisheye;viewport;workspace	Sean Gustafson;Pourang Irani	2007		10.1145/1240866.1241014	halo;computer vision;simulation;visualization;computer science;control system;computer graphics (images)	HCI	-31.487504808207852	-36.56820806869017	159471
c57ef524530cb5983e4331745ff5d0a5b8cb4e55	using mobile phone data to explore spatial-temporal evolution of home-based daily mobility patterns in shanghai	decision support systems	This paper aims at investigating home-based daily mobility patterns in Shanghai. The dataset consists of Data over Signaling (DoS) from 107,100 anonymous mobile phone subscribers in Shanghai over 9 days in different seasons, which contains spatial-temporal information of subscribers. Daily mobility pattern is characterized as motif of the individual's daily trajectory in this paper. Homes of subscribers are recognized with a priori knowledge. Motifs are extracted from each individuals' daily trajectories. In this way, we have revealed the spatial-temporal evolution of home-based daily mobility patterns in Shanghai. We find that the spatial distribution of home-based daily mobility patterns inside the enclosed area of Middle Ring Road in weekdays diffuses to the enclosed area of Outer Ring Road in weekends. However, the spatial distribution of home-based daily mobility patterns in the areas outside Outer Ring Road seems to be invariant to weekdays and weekends and is more active than that inside the enclosed area of Outer Ring Road. These active areas include affordable housing communities, such as New Gucun Big Homeland and Xinkai Homeland. The phenomenon presented in this paper may correlate with socioeconomic factors in different regions of Shanghai and worth further investigation.	mobile phone;motif	Zhicheng Liu;Jinbin Yu;Weiting Xiong;Jian Lu;Junyan Yang;Qiao Wang	2016	2016 International Conference on Behavioral, Economic and Socio-cultural Computing (BESC)	10.1109/BESC.2016.7804481	geography;telecommunications;advertising;cartography	Robotics	-19.13028700716095	-34.1328895639094	159522
c2cf19e6463f6d50d258730e878f0b497aa1d699	exploiting reverse correlation for the generation of virtual characters from personality traits	oceans;correlation genetic algorithms face genetics character generation oceans three dimensional displays;genetics;physical attributes virtual character generation online reverse correlation technique virtual character appearance virtual character personality traits crowdsourcing interactive genetic algorithms training phase genetic evolution;three dimensional displays;character generation;genetic algorithms;face;virtual reality graphical user interfaces outsourcing;crowdsourcing reverse correlation virtual characters interactive genetic algorithms;correlation	Judging from appearance, most people assign personality traits to virtual characters. This paper presents a platform capable of generating online Reverse Correlation experiments for studying the relations between the appearance of virtual characters and their assumed personality. The method used by the platform, which leverages crowdsourcing and interactive genetic algorithms, can be used to generate virtual characters starting from a description of their personality. The platform requires a training phase to gather the beliefs and convictions that people have when judging a person from his/her appearance. The method is validated through two experiments. The first experiment provides evidence on how effective the method is in improving the mapping through genetic evolution. The second experiment illustrates how the method relates to the technique of Reverse Correlation to infer which physical attributes contribute to the perception of a specific trait.	crowdsourcing;experiment;genetic algorithm;interactive evolutionary computation;spike-triggered average;text-based (computing);webplatform	Fabrizio Nunnari;Alexis Héloir	2015	2015 7th International Conference on Intelligent Technologies for Interactive Entertainment (INTETAIN)	10.4108/icst.intetain.2015.259583	face;computer vision;genetic algorithm;artificial intelligence;multimedia;correlation	Vision	-27.509443865358502	-25.881921020152838	159642
2796941172dbb68842f1b7925907bca2001f1395	visual analysis of azureus using verso	automatic control;application software;anomaly detection design;anomaly detection;azureus program;packaging;data mining;software engineering;software engineering data visualisation security of data;data visualisation;evolution analysis;navigation;verso;image representation;displays;packaging displays automatic control animation statistics application software image representation data mining particle separators navigation;animation;visual analysis;software package;statistics;particle separators;visual analysis software package evolution analysis anomaly detection design verso azureus program;security of data	In this challenge report, we will see how to use VERSO in order to analyse Azureus. We answer the challenge through two separate main goals which represent two possible tasks available in VERSO. The first task is design anomaly detection and the second task is evolution analysis.	anomaly detection;vuze	Guillaume Langelier;Karim Dhambri	2007	2007 4th IEEE International Workshop on Visualizing Software for Understanding and Analysis	10.1109/VISSOF.2007.4290720	anime;packaging and labeling;navigation;anomaly detection;application software;computer science;engineering;data science;operating system;software engineering;automatic control;data mining;data visualization;computer graphics (images)	SE	-32.54210663797776	-29.748276175418084	160202
e1407666a63c6acd4389238f4a2093b726a1bf5b	network modeling grounded on information theory accurately predicts future research collaborators			information theory	Konstantinos Lilolios	2009			information theory;network model;artificial intelligence;computer science	NLP	-24.05418315468157	-28.066499367012728	160239
b9dcb0d963892fbe325df775dc358cdef035a809	"""multiscale visualization using data cubes """"infovis 2002 best paper"""""""	filtering;data cube;polarization;filters;large data sets;data visualization relational databases switches polarization data analysis pattern analysis filters filtering visual databases;relational database;data visualisation;data analysis;multiscale pan and zoom systems;level of detail;data visualisation data structures relational databases;data structures;design pattern;zoom graph;data visualization;data cubes;pattern analysis;relational databases;visual abstraction;switches;multiscale visualizations;relational databases multiscale pan and zoom systems large data sets visual abstraction multiscale visualizations data cubes zoom graph;visual databases	Most analysts start with an overview of the data before gradually refining their view to be more focused and detailed. Multiscale panand-zoom systems are effective because they directly support this approach. However, generating abstract overviews of large data sets is difficult, and most systems take advantage of only one type of abstraction: visual abstraction. Furthermore, these existing systems limit the analyst to a single zooming path on their data and thus a single set of abstract views. This paper presents: (1) a formalism for describing multiscale visualizations of data cubes with both data and visual abstraction, and (2) a method for independently zooming along one or more dimensions by traversing a zoom graph with nodes at different levels of detail. As an example of how to design multiscale visualizations using our system, we describe four design patterns using our formalism. These design patterns show the effectiveness of multiscale visualization of general relational databases.	cubes;design pattern;relational database;semantics (computer science)	Chris Stolte;Diane Tang;Pat Hanrahan	2002		10.1109/INFVIS.2002.1173141	relational database;computer science;theoretical computer science;data mining;database;data visualization;data cube;statistics	HCI	-28.63772897351225	-33.01809654844353	160338
0d4ced42fd90acb5918c1c48cb68b12722bda583	visual traffic jam analysis based on trajectory data	gps trajectories;computer graphics computer simulation geographic information systems models statistical motor vehicles pattern recognition automated user computer interface;pedestrian safety;poison control;injury prevention;road traffic;traffic visualization road traffic trajectory urban areas global positioning system data visualization cities and towns data mining traffic control traffic jam propagation;traffic control;safety literature;urban traffic congestion;traffic safety;injury control;data mining;journal;high level description;home safety;data visualisation;data analysis;injury research;traffic conditions;trajectory data;safety abstracts;urban areas;trajectory;human factors;traffic jams;traffic information systems;global positioning system;interactive system;traffic visualization;pattern matching;期刊论文;occupational safety;safety;data visualization;traffic jam propagation;safety research;cities and towns;accident prevention;traffic information systems data analysis data visualisation global positioning system interactive systems pattern matching;violence prevention;bicycle safety;visual traffic jam analysis beijing taxi gps trajectories visual exploration high level traffic jam description traffic jam propagation graphs spatially related events temporally related events automatic traffic jam event detection road segment traffic speed trajectory matching road network traffic jam information extraction gps trajectories interactive system visual urban traffic congestion analysis trajectory data;poisoning prevention;falls;interactive systems;ergonomics;suicide prevention;road traffic trajectory urban areas global positioning system data visualization cities and towns data mining traffic control;propagation graph	In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.	concatenation;global positioning system;graph - visual representation;gray platelet syndrome;high- and low-level;interactivity;jam;network congestion;plasma cleaning;software propagation;taxi	Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Huub van de Wetering	2013	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2013.228	simulation;floating car data;global positioning system;computer science;suicide prevention;trajectory;injury prevention;traffic congestion reconstruction with kerner's three-phase theory;pattern matching;data mining;data analysis;computer security;data visualization;statistics	Visualization	-22.96787993303149	-33.95526598210607	160365
e506aad9b7b8f225dcde98017827ea9a31100654	automatic price negotiation on the web: an agent-based web application using fuzzy expert system	model view controller;agent based;fuzzy rules;on line auction;fuzzy expert system;internet auction;design pattern;unified modeling language;fuzzy inference;intelligent agent;price negotiation;user satisfaction;java	Research highlights? Instantly getting negotiated price without waiting. ? Conducting price negotiation at any time. ? Determining strategy rules easily. ? Using customizable negotiation strategies defined by users. A traditional internet auction is restricted by the limitation of time. It is necessary to conduct an internet auction in a certain time period. The final trading price is determined until this certain period ends. This study improves this situation by removing the time limitation. Based on the fuzzy inference theory, this paper proposes an agent-based price negotiation system for on-line auctions. Mainly, three agents are used in the study: a seller agent, a buyer agent, and a mediator agent. The proposed system provides an easy-to-use environment and good customizability for users (buyers or sellers) to customize their price negotiation strategies using user-defined fuzzy rules. The final negotiated price is immediately determined after the buyer sends his bids to the proposed system. This study develops a Java-based computer package to implement the price negotiation system where Model-View-Controller (MVC) design pattern is employed in design of the package. Unified Modeling Language (UML) is also utilized to describe the structures and behaviors of the package. To validate the proposed system, this study built an on-line auction website with the proposed price negotiation mechanism for internet users to buy or sell their merchandises. An evaluation was finally conducted to investigate the users' satisfaction with the proposed system.Briefly, the proposed system is featured by: (1) instantly getting negotiated price without waiting; (2) conducting price negotiation at any time; (3) determining strategy rules easily, and (4) using customizable negotiation strategies defined by users.	agent-based model;expert system;web application	Che-Chern Lin;Shen-Chien Chen;Yao-Ming Chu	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.09.142	unified modeling language;computer science;artificial intelligence;design pattern;model–view–controller;java;intelligent agent	AI	-30.93679364064097	-25.938000398225526	160944
11c3902f7321b96eee430ce31f1f3137e2b094ac	exploring the possibilities of embedding heterogeneous data attributes in familiar visualizations	hybrid visualization;space exploration;layout;hybrid visualization multi dimensional data;qa75 electronic computers computer science;visualization;data visualization layout visualization space exploration context joining processes encoding;data visualization;joining processes;encoding;context;multi dimensional data	Heterogeneous multi-dimensional data are now sufficiently common that they can be referred to as ubiquitous. The most frequent approach to visualizing these data has been to propose new visualizations for representing these data. These new solutions are often inventive but tend to be unfamiliar. We take a different approach. We explore the possibility of extending well-known and familiar visualizations through including Heterogeneous Embedded Data Attributes (HEDA) in order to make familiar visualizations more powerful. We demonstrate how HEDA is a generic, interactive visualization component that can extend common visualization techniques while respecting the structure of the familiar layout. HEDA is a tabular visualization building block that enables individuals to visually observe, explore, and query their familiar visualizations through manipulation of embedded multivariate data. We describe the design space of HEDA by exploring its application to familiar visualizations in the D3 gallery. We characterize these familiar visualizations by the extent to which HEDA can facilitate data queries based on attribute reordering.	embedding;generic drugs;imagery;interactive visualization;numerous;question (inquiry);table (information)	Mona Hosseinkhani Loorak;Charles Perin;Christopher Collins;M. Sheelagh T. Carpendale	2017	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2016.2598586	layout;computer vision;information visualization;visualization;computer science;theoretical computer science;space exploration;data mining;data visualization;encoding	Visualization	-29.365419284091335	-33.77953649663288	161453
9668c43aadac718461ebb7ac1d4402d53f7e5b1f	constrained evolutionary art: interactive flag design	directed evolution;interactive flag design;genomics;art;genetic operator;pediatrics;object oriented programming;data mining;evolution biology;user interfaces art interactive programming object oriented programming;genotype representation;genetic operators;image color analysis;design pattern;design patterns;art space exploration history education educational institutions genetics speech processing pixel design engineering material properties;user interaction;user interfaces;user interaction constrained evolutionary art interactive flag design design patterns genotype representation genetic operators;interactive programming;constrained evolutionary art;bioinformatics;image similarity	The field of evolutionary art is generally concerned with evolving patterns that have little constraint. This paper describes an evolutionary art system that is constrained to form flag designs, following a set of common design patterns. The resulting genotype representation, genetic operators and forms of user interaction are chosen to allow an exploration of “flag space”, as well as allowing the user to rapidly focus on aspects of specific designs. The utility of the approach is demonstrated by evolving flag designs using image similarity and by user-directed evolution.	design pattern;evolutionary art;genetic operator	Peter A. Whigham;Colin Aldridge;Michel de Lange	2009	2009 IEEE Congress on Evolutionary Computation	10.1109/CEC.2009.4983213	genomics;software design pattern;simulation;directed evolution;computer science;bioinformatics;artificial intelligence;theoretical computer science;genetic operator;machine learning;design pattern;object-oriented programming;user interface	AI	-28.414839631497614	-26.339296607794477	161748
9761ba6b7d3b6306a7037617d7eb2d567455e56c	smart solutions for risk prevention through analysis of people movements	settore inf 01 informatica	The high number of accidents in living areas, work environments, and ambient, in general, can benefit of prevention mechanisms able to identify the causes and the indications which precede accidents, and to put in place strategies to avoid risks whenever this is possible. To this aim, this paper presents a risk management architecture for monitoring movements within a smart ambient and managing possible risks. In particular, we present a methodology for movement analysis aimed at detecting and preventing risks. Results from experimentations are discussed.		Maria Grazia Fugini;Stefano Pinardi;Claudia Raibulet	2011		10.1007/978-3-642-27916-4_2	telecommunications;computer science;operations research	HCI	-19.574715021351242	-26.657601571117194	161790
3633850c75fdcaeb3db8285ebbea31b9dc5cdba7	rapid and reliable adaptation of video game ai	automatic control;reliable adaptation adaptive behavior game ai rapid adaptation real time strategy rts games;learning effectiveness;performance evaluation;rapid adaptation;ai;computational intelligence;reliable adaptation;adaptive control;programmable control;testing;adaptive behavior;games artificial intelligence testing humans computational intelligence programmable control adaptive control automatic control performance evaluation artificial neural networks;indexing terms;video game;game development;domain knowledge;adaptive game;artificial neural networks;real time strategy;adaptive behaviour;real time strategy rts games;games;artificial intelligence video game ai adaptive game real time strategy;artificial intelligence;humans;computer games;game ai;computer games artificial intelligence	Current approaches to adaptive game AI typically require numerous trials to learn effective behavior (i.e., game adaptation is not rapid). In addition, game developers are concerned that applying adaptive game AI may result in uncontrollable and unpredictable behavior (i.e., game adaptation is not reliable). These characteristics hamper the incorporation of adaptive game AI in commercially available video games. In this paper, we discuss an alternative to these current approaches. Our alternative approach to adaptive game AI has as its goal adapting rapidly and reliably to game circumstances. Our approach can be classified in the area of case-based adaptive game AI. In the approach, domain knowledge required to adapt to game circumstances is gathered automatically by the game AI, and is exploited immediately (i.e., without trials and without resource-intensive learning) to evoke effective behavior in a controlled manner in online play. We performed experiments that test case-based adaptive game AI on three different maps in a commercial real-time strategy (RTS) game. From our results, we may conclude that case-based adaptive game AI provides a strong basis for effectively adapting game AI in video games.	artificial intelligence (video games);experiment;game engine;real-time locating system;test case;video game developer	Sander Bakkes;Pieter Spronck;H. Jaap van den Herik	2009	IEEE Transactions on Computational Intelligence and AI in Games	10.1109/TCIAIG.2009.2029084	non-cooperative game;game design;games;simulation;index term;adaptive control;computer science;artificial intelligence;game mechanics;adaptive behavior;machine learning;computational intelligence;automatic control;multimedia;software testing;screening game;sequential game;video game development;domain knowledge;game testing	AI	-26.057692035591845	-25.751288892136326	161833
73f9a34abb8c69fd2dc2b751c2e5848cacda4cc8	quarry: picking from examples to explore big data	search;visualization;big data;query generation	Analysts use scripts, visualization tools, and spreadsheets as they process and understand data. We focus on two phases of analysts' work: discovery, where the field definitions are understood, and profiling, where assumptions are tested by searching, observing, and running counts on data. Lack of data exploration and understanding can lead to faulty assumptions and misinterpretation. In practice, analysts use SQL queries and scripts to subset big data, reducing it for visualization or spreadsheet pivots. However, due to large-size and high-dimensional data, it is challenging to determine precise subsets of interest without thorough data exploration and discovery. We reduce the cost of previewing subsets by combining search with an information rich visualization of high-dimensional data. To enable discovery and profiling, Quarry supports (1) rapid query generation and visualized search; and (2) defining and previewing subsets of data for potential export for further processing. This work presents the design of Quarry and results from a formative study involving 11 analysts/data scientists and a dataset with 80 columns and 15 million rows.	big data;characters per line;column (database);data science;profiling (computer programming);sql;spreadsheet	Rhema Linder;Eunyee Koh	2015		10.1145/2702613.2732933	big data;visualization;computer science;data science;data mining;world wide web	ML	-26.712888468528647	-32.400287109892794	162099
338b8236b3465779762a12c8987f24d5c6ca409d	distributed perception algorithm		In this paper we describe the Distributed Perception Algorithm (DPA) which is partly inspired by the schooling behaviour of ‘golden shiner’ fish (Notemigonus crysoleucas). These fish display a preference for shaded habitat and recent experimental work has shown that the fish use both individual and distributed perception in navigating their environment. We assess the contribution of each element of the DPA and also benchmark its results against those of canonical PSO.	algorithm;benchmark (computing);habitat;particle swarm optimization;shading	Anthony Brabazon;Wei Cui	2016		10.1007/978-3-319-41009-8_39	computer science;artificial intelligence;machine learning;algorithm;perception;golden shiner	Robotics	-28.029231896924266	-24.02434181685775	162162
9f1832e18406c743eee757e24c37d5e46e1839ad	conflict negotiation among personal calendar agents	personal assistants;user interface;cognitive agents;distributed constraint optimization;scheduling;conflict resolution;user interfaces	We will demonstrate distributed conflict resolution in the context of personalized meeting scheduling. The demonstration will show how distributed constraint optimization can be used to facilitate interaction between cognitive agents and their users. The system is part of the CALO personal cognitive assistant that will also be explored during the demonstration.	calo;constrained optimization;distributed constraint optimization;mathematical optimization;personalization;scheduling (computing)	Pauline M. Berry;Cory Albright;Emma Bowring;Ken Conley;Kenneth Nitz;Jonathan P. Pearce;Bart Peintner;Shahin Saadati;Milind Tambe;Tomás E. Uribe;Neil Yorke-Smith	2006		10.1145/1160633.1160918	simulation;human–computer interaction;computer science;knowledge management;conflict resolution;user interface	AI	-33.50724433745945	-24.346447802098353	162320
eda8ebacbfa653432626bdb641c4b31ec88a9a02	integration of a dynamic model in a driving simulator to meet requirements of various levels of automatization	vehicle dynamics vehicles computational modeling dynamics software gears;real time systems digital simulation driver information systems human factors intelligent transportation systems realistic images;automated lateral control dynamic model driver assistant systems realistic modelling driving dynamics single track model double track model multibody model dynamic truck driving simulator real time capability realistic driving behaviour simulator compatibility automated driving automated longitudinal control	To enable the development of driver assistant systems in a driving simulator, a realistic modelling of the driving dynamics is required. A simple approach to the dynamics is using a single-track model or a double-track model. A more detailed and more realistic approach is a multi-body model. To this end, a multi-body model was integrated in the dynamic truck driving simulator and evaluated. The requirements are real-time capability, realistic driving behaviour and simulator compatibility. We increased the immersion into the simulation via realistic dynamic behaviour. Due to the multi-body model, the dynamics at starting, cornering and braking are accurately computed. Against the background of automated driving, we created opportunities for further functional extensions such as automated longitudinal and lateral control.	autonomous car;driving simulator;extensibility;immersion (virtual reality);lateral thinking;mathematical model;real-time clock;real-time computing;requirement;semiconductor industry;simulation;usability testing	Lydia Gauerhof;Anito Bilic;Christian Knies;Frank Diermeyer	2016	2016 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2016.7535400	control engineering;embedded system;simulation;engineering	Embedded	-21.80911299526384	-24.22332184162896	162619
f6174f63e9a8e750f056bc40e3a277caa8b1d61f	data mining in astronomical databases	physical model;pattern recognition;astrophysics;data mining;scientific research;prediction model;information extraction	A Virtual Observatory (VO) will enable transparent and e cient access, search, retrieval, and visualization of data across multiple data repositories, which are generally heterogeneous and distributed. Aspects of data mining that apply to a variety of science user scenarios with a VO are reviewed. 1 Science Requirements for Data Mining What is data mining and why is applicable to scienti c research? Data mining is de ned as an information extraction activity whose goal is to discover hidden facts contained in databases. Data mining has taken the business community by storm and there is consequently now a vast array of resources and research techniques available for exploitation by the scienti c communities. It is useful therefore to examine a categorization of data mining thrusts and their sub-components, since these are likewise applicable to the scienti c exploration of large astronomical databases. Data mining is used to nd patterns and relationships in data by using sophisticated techniques to build models { abstract representations of reality. A good model is a useful guide to understanding that reality and to making decisions. There are two main types of data mining models: descriptive and predictive. Descriptive models describe patterns in data and are generally used to create meaningful subgroups or clusters. Predictive models are used to forecast explicit values, based upon patterns determined from known results. There is another di erentiation of data mining into two categories that we nd particularly appropriate to knowledge discovery in large astronomical databases: event-based mining and relationship-based mining. At the risk of trivializing some fairly sophisticated techniques, we classify event-based mining scenarios into four orthogonal categories: Known events / known algorithms { use existing physical models (descriptive models) to locate known phenomena of interest either spatially or temporally within a large database. Known events / unknown algorithms { use pattern recognition and clustering properties of data to discover new observational (in our case, astrophysical) relationships among known phenomena. Unknown events / known algorithms { use expected physical relationships (predictive models) among observational parameters of astrophysical phenomena to predict the presence of previously unseen events within a large complex database.	algorithm;categorization;cluster analysis;data mining;database;information extraction;pattern recognition;predictive modelling;requirement;scenario (computing);virtual observatory	Kirk D. Borne	2000	CoRR		scientific method;physical model;data mining;predictive modelling;information extraction	ML	-25.240142518112908	-31.130590367095333	162862
e66cc90524d7a5857e0bf4e22ac7f090ab02b5de	demonstrating a data access-based context ontology with an online racing game controller application		The number of sensors used in the world of technology is increasing at an accelerated rate. The communication between vehicles, drivers and the environment have been leveraged to allow for easier driving with a decreased workload and risk of injury. Sensing, analyzing, predicting and reacting to road conditions are the prerequisites of a smart car. Context-awareness is the key feature of a smart car and is also an essential concept in pervasive computing. This paper uses the classification of popular modern day automobile “smart features” to demonstrate a novel context ontology that is based on ways that data is accessed in computer systems in general. An in-lab prototype was designed and implemented by way of controlling an online racing game with a custom-made game wheel, which demonstrates awareness and actuation in all of the context categories within the proposed ontology.	context awareness;data access;game controller;prototype;sensor;ubiquitous computing	Jannatun Naher;Gabriel Popoola;Corey A. Graves	2017	2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)	10.1109/UIC-ATC.2017.8397447	control theory;computer science;distributed computing;workload;ontology;ubiquitous computing;ontology (information science);data access;context-aware services;context model	HCI	-30.294696256898263	-25.357565488208717	163705
54c1f45b670e6d2d56dd36ab4fdd9f0025d7aac6	spatial querying of geographical data with pen-input scopes	maps;pen and touch interaction;gis interfaces;geospatial querying	Querying geographical data on map applications running on touch devices is mainly performed by typing queries using virtual keyboards. Some of those devices are additionally equipped with styli to facilitate freehand sketching and an-notating. As shown by prior work, such hand-drawn sketches can also be used for intuitive and effective spatial querying of geographical data. Building on that groundwork, we present a set of pen-based techniques to selectively convert map annotations into spatial queries with implicitly or explicitly specified scopes. We show how those techniques can be used for trip-planning tasks involving route-finding and searching of points of interest. In a controlled user study comparing the usability and efficiency of the techniques for different querying patterns, we establish participants' general preference for explicit input scopes and obtain indications that, provided handwriting is correctly recognised, input times are comparable to that of a standard (soft) keyboard-based interface. Based on those results and participant feedback, we propose a number of enhancements and extensions to inform the design of future pen-based map applications.	adobe freehand;pen computing;point of interest;stylus (computing);usability testing;virtual keyboard	Fabrice Matulic;David Caspar;Moira C. Norrie	2014		10.1145/2669485.2669513	computer science;data mining;database;world wide web	HCI	-31.491890425377314	-34.63494479208914	163872
3750762f6cefb0f4276430bbbf4ce26ec71468ca	analyzing high-dimensional data with motion graphics	proyeccion;interfase usuario;analyse multivariable;interpolation;affichage graphique;multivariate analysis;motion graphics;analisis datos;user interface;grande dimension;grand tour;real time;interpolacion;large dimension;graphic display;data analysis;62h30;projection;temps reel;high dimensional data;62h25;tiempo real;6204;analisis multivariable;analyse donnee;visualizacion grafica;interface utilisateur;68u05;guided tour;gran dimension;6207;high interaction interfaces;projections;exploratory data analysis	Some new methods for analyzing high-dimensional data, based on real-time graphics, are described. Three-dimensional point cloud rotations provide the canonical example of the applications of motion graphics to data analysis. Similarly, motion may be used to good effect to explore data of arbitrarily high dimension. This will be demonstrated by describing how a data analyst guides a projection plane as it moves through high-dimensional data space.	graphics	Catherine Hurley;Andreas Buja	1990	SIAM J. Scientific Computing	10.1137/0911068	computer vision;simulation;interpolation;computer science;real-time computer graphics;mathematics;statistics;computer graphics (images)	HPC	-27.690149864247232	-30.004150412703822	163897
83f0ec281eabb7f34e043829c34df114939d759e	iparking - a real-time parking space monitoring and guiding system	parking space management;image recognition;wireless transmission;cloud computing	Abstract Shortage and imbalance of parking spaces have become serious problems in recent years. Drivers may choose nearby illegal area for parking when available parking spaces are all out of sight. To mitigate problems such as illegal parking, iParking, a real-time parking space monitoring and guiding system, is proposed in this paper. The paper lays emphasis on roadside parking. In the proposed system, the availability of parking spaces is recognized through image analysis, where the images come from the event recorders embedded in cars on the roads. Upon receipt of a parking request, the system searches for a nearest parking space, and then directly navigates the requesting driver to the available parking space. The system is expected to benefit all drivers and the government, and to improve safety and traffic on the roads.	device driver;embedded system;image analysis;real-time clock;real-time transcription	Ching-Fei Yang;You-Huei Ju;Chung-Ying Hsieh;Chia-Ying Lin;Meng-Hsun Tsai;Hui-Ling Chang	2017	Vehicular Communications	10.1016/j.vehcom.2017.04.001	sight;simulation;economic shortage;parking guidance and information;computer science;cloud computing;government;computer security;receipt	Mobile	-20.011133115706823	-29.0622309694991	164117
0c56e14997adcc209bed8d388179631741068e47	procedural generation of complex stable structures for angry birds levels	generators;cloning;birds;periodic structures;games;stability analysis;algorithm design and analysis	This paper presents a procedural content generation algorithm for the physics-based puzzle game Angry Birds. The proposed algorithm creates complex stable structures using a variety of 2D objects. These are generated without the aid of pre-defined substructures or composite elements. The structures created are evaluated based on a fitness function which considers several important structural aspects. The results of this analysis in turn affects the likelihood of particular objects being chosen in future generations. Experiments were conducted on the generated structures in order to evaluate the algorithm's expressivity. The results show that the proposed method can generate a wide variety of 2D structures with different attributes and sizes.	algorithm;directed acyclic graph;experiment;fitness function;mathematical optimization;population;procedural generation;top-down and bottom-up design	Matthew Stephenson;Jochen Renz	2016	2016 IEEE Conference on Computational Intelligence and Games (CIG)	10.1109/CIG.2016.7860410	games;algorithm design;von neumann stability analysis;simulation;computer science;artificial intelligence;machine learning;cloning;algorithm	Visualization	-27.150009803795196	-25.659443169004557	164164
d524f42a41b0642af108dcc0df386104682ef262	interpretation and visualization of user history in a spatial hypertext system	visual knowledge builder;spatial hypertext;history;asynchronous collaboration;branching history;vkb;visualization;visualization technique;awareness;user activity records;human activity	We describe a new history mechanism based on experiences with the use of recorded interaction history in the Visual Knowledge Builder (VKB). Problems with the use of history in prior systems include difficulty in locating activity of interest in large tasks, the problem of history records being at a system activity level rather than a human activity level, and difficulty in supporting navigation and comprehension in the branching histories used to represent alternative directions. To support comprehension of the history, we describe automatic history clustering to group low-level system events into a more human-level representation of activity and the extraction of information for summarizing these groups of events. To further support navigation and comprehension of history, the mechanism includes multiple visualization techniques to match diverse uses of history. The new history mechanism is integrated into VKB 3.	cluster analysis;digital history;experience;high- and low-level;hypertext	DoHyoung Kim;Frank M. Shipman	2010		10.1145/1810617.1810663	awareness;visualization;human–computer interaction;computer science;multimedia;world wide web	HCI	-23.758714836708794	-33.791364765662635	164185
bdb20706c63477dd83f9ccce0342bca902669616	assessment of adequate overtaking margin (aom) for an overtaking assistance system	driver assistance;automotive engineering;sensor systems;sensor phenomena and characterization;road accidents;road traffic driver information systems road accidents;road traffic;prototypes;adequate overtaking margin;road accident;visualization;roads;lead;overtaking accident;vehicle crash testing;statistics;system testing;driver circuits;haptic interfaces;overtaking assistance system;road accident adequate overtaking margin overtaking assistance system overtaking accident driver assistance;driver information systems;wheels;road accidents system testing driver circuits prototypes haptic interfaces vehicle crash testing statistics sensor phenomena and characterization sensor systems automotive engineering	On two-lane rural roads, a large number of overtaking accidents happen. In most cases fatalities or serious casualties are the consequence. Often, inaccurate assessment of the traffic situation is identified as the major cause. Hence, the development of a driver assistance concept for these scenarios promises a high safety benefit. This paper shows the results of tests conducted on a test track determining the major parameters for gaining maximum driver-acceptance of such a system.	architecture design and assessment system;associate-o-matic;experiment;margin (machine learning);margin classifier;prototype	Andree Hohm;Hermann Winner	2010	2010 IEEE Intelligent Vehicles Symposium	10.1109/IVS.2010.5548146	simulation;engineering;automotive engineering;transport engineering	Embedded	-19.204346739445604	-27.31594735019472	164750
49f3eba0223fe865b99d66480690f4baf0823f86	interactive graph query language for multidimensional data in collaboration spotting visual analytics framework		Human reasoning in visual analytics of data networks relies mainly on the quality of visual perception and the capability of interactively exploring the data from different facets. Visual quality strongly depends on networks’ size and dimensional complexity while network exploration capability on the intuitiveness and expressiveness of user frontends. The approach taken in this paper aims at addressing the above by decomposing data networks into multiple networks of smaller dimensions and building an interactive graph query language that supports full navigation across the sub-networks. Within sub-networks of reduced dimensionality, structural abstraction and semantic techniques can then be used to enhance visual perception further.	color vision;interactivity;query language;visual analytics	Adam Agocs;Dimitris Dardanis;Jean-Marie Le Goff;Dimitris Proios	2017	CoRR		computer science;human–computer interaction;curse of dimensionality;query language;visual analytics;spotting;expressivity;abstraction;visual perception;graph	Visualization	-30.7794294753203	-33.272958339858185	164763
679ebe81eb335c4aefd8b30d7b7f82e2bb2b529a	visual analytics on the financial market: pixel-based analysis and comparison of long-term investments	explorative interactive technique;financial data processing;financial data analysis visual data mining;investments;application software;financial market visual analytics;time series;data mining;investment;financial data;investment strategies;data visualisation;data analysis;financial data analysis;visualization technique;time series analysis;pixel based visualization technique;visual data mining;self organizing feature maps;decision making process;region of interest;financial time series data analysis;financial time series;data visualization;financial market;inproceedings;visual analytics;long term investment;time series data analysis data mining data visualisation decision making financial data processing interactive systems investment;interactive systems;information analysis;knowledge discovery financial market visual analytics long term investment pixel based visualization technique decision making process explorative interactive technique financial time series data analysis;interaction technique;knowledge discovery	In this paper, we describe solutions how pixel-based visualization techniques can support the decision making process for investors on the financial market. We especially focus on explorative interactive techniques where analysts try to analyze large amounts of financial data for long-term investments, and show how visualization can effectively support an investor to gain insight into large amounts of financial time series data. After presenting methods for improving the traditional performance/risk computation in order to take user-specific regions of interest into account, we present a novel visualization approach that demonstrates how changes in these regions of interest affect the ranking of assets in a long-term investment strategy.	computation;dbpedia;decision support system;distortion;fingerprint recognition;personalization;pixel;region of interest;spaces;time series;user (computing);visual analytics	Hartmut Ziegler;Tilo Nietzschmann;Daniel A. Keim	2008	2008 12th International Conference Information Visualisation	10.1109/IV.2008.80	data science;marketing;data mining;business	Visualization	-27.25934654823462	-32.5589070189754	165062
78457a776b50533e0e25c3988a833375258e2eb5	visualizing the quality of dimensionality reduction	article letter to editor;quality assessment;nonlinear dimensionality reduction;projection;data visualization;framework;co ranking matrix	Many different evaluation measures for dimensionality reduction can be summarized based on the co-ranking framework [6]. Here, we extend this framework in two ways: (i) we show that the current parameterization of the quality shows unpredictable behavior, even in simple settings, and we propose a different parameterization which yields more intuitive results; (ii) we propose how to link the quality to point-wise quality measures which can directly be integrated into the visualization.	dimensionality reduction;interactivity;the matrix	Bassam Mokbel;Wouter Lueks;Andrej Gisbrecht;Michael Biehl;Barbara Hammer	2012	Neurocomputing	10.1016/j.neucom.2012.11.046	projection;computer science;data science;software framework;machine learning;data mining;nonlinear dimensionality reduction;data visualization	Vision	-26.867252917237533	-34.55199449645995	165724
080bab9904d442dc7375bc8cf88c978bcb6a0d83	selltrend: inter-attribute visual analysis of temporal transaction data	selltrend;historical trend analysis;multiple attributes;categorical event sequences;trend analysis;inter attribute visual analysis;information visualization;time series visualization;time series;companies;books;multiple views;historical trend analysis selltrend inter attribute visual analysis temporal transaction data analysis airline travel purchase requests multi variate temporal event sequences categorical event sequences time series visualization;failure analysis;categorical data investigative analysis transaction analysis information visualization multiple views time series data multiple attributes;data visualisation;data analysis;investigative analysis;feedback;transaction data;logistics;time series analysis;airline travel purchase requests;transaction analysis;visual analysis;data visualization;cities and towns;time series data;temporal transaction data analysis;travel industry data analysis data visualisation time series;data visualization time series analysis failure analysis information analysis books cities and towns data analysis feedback companies logistics;visual system;multi variate temporal event sequences;information analysis;categorical data;experience design;travel industry	We present a case study of our experience designing SellTrend, a visualization system for analyzing airline travel purchase requests. The relevant transaction data can be characterized as multi-variate temporal and categorical event sequences, and the chief problem addressed is how to help company analysts identify complex combinations of transaction attributes that contribute to failed purchase requests. SellTrend combines a diverse set of techniques ranging from time series visualization to faceted browsing and historical trend analysis in order to help analysts make sense of the data. We believe that the combination of views and interaction capabilities in SellTrend provides an innovative approach to this problem and to other similar types of multivariate, temporally driven transaction data analysis. Initial feedback from company analysts confirms the utility and benefits of the system.	faceted classification;feedback;imagery;numerous;time series;transaction data;benefit	Zhicheng Liu;John T. Stasko;Timothy Sullivan	2009	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2009.180	computer science;data science;transaction data;time series;data mining;mathematics;data visualization;statistics	Visualization	-26.267240021048014	-33.53863670817682	165836
850cd481573926c4d018503edf17050af332067d	snap-together visualization: can users construct and operate coordinated visualizations?	user interface;conceptual model	"""Multiple coordinated visualizations enable users to rapidly explore complex information. However, users often need unforeseen combinations of coordinated visualizations. Snaptogether visualization (Snap) enables users to rapidly and dynamically construct coordinated}visualization interfaces, customized for their data, without programming. Users load data into desired visualizations, then construct coordinations between them for brushing and linking, overview and detail view, drill down, etc. Snap formalizes a conceptual model of visualization coordination based on the relational data model. Visualization developers can easily Snap-enable their independent visualizations using a simple API. Empirical evaluation reveals bene""""ts, cognitive issues and usability concerns with coordination concepts and Snap. Two user studies explore coordination construction and operation. Data-savvy users successfully, enthusiastically and rapidly constructed powerful coordinated}visualization interfaces of their own. Operating an overview-anddetail coordination reliably improved user performance by 30}80% over detail-only and uncoordinated interfaces for most tasks. ( 2000 Academic Press"""	application programming interface;brushing and linking;cpu cache;data drilling;data model;diagram;open database connectivity;operating system;relational model;requirement;scrolling;software architecture;speedup;usability testing;user interface	Chris North;Ben Shneiderman	2000	Int. J. Hum.-Comput. Stud.	10.1006/ijhc.2000.0418	human–computer interaction;computer science;conceptual model;data mining;user interface;world wide web	HCI	-31.3960533876228	-32.06775737118657	165879
2fa28919b2c650fedde4ed07ba071b13908de014	analysis of driver behaviors while using in-vehicle traffic light with partial deployment of v2i communication		An in-vehicle traffic light system was proposed to assist drivers at intersections, by displaying traffic light inside vehicles based on vehicular communication. Driving simulator experiments have demonstrated that the system can be an effective method to provide assistance for drivers. However, previous studies assumed that all the vehicles were equipped with vehicular communication devices and the proposed in-vehicle traffic light, which is still impossible in the actual driving environment. Therefore, it is necessary to evaluate the availability of the system in a driving condition when both in-vehicle traffic light equipped and unequipped vehicles exist. This study implemented the in-vehicle traffic light system with a real electric vehicle at a signalized intersection, based on V2I communication. An experiment involving 12 participants and two vehicles were performed, to analyze the influences on driver behaviors while applying the in-vehicle traffic light in a partial deployment environment. It was observed that the application of in-vehicle traffic light in a preceding vehicle could significantly reduce the maximum deceleration of its following vehicle, even when the following vehicle was unequipped with the system.	deployment environment;device driver;driving simulator;effective method;experiment;simulation;software deployment	Bo Yang;Rencheng Zheng;Tsutomu Kaizuka;Kimihiko Nakano	2018	2018 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2018.8500424	software deployment;real-time computing;global positioning system;effective method;electric vehicle;deployment environment;driving simulator;computer science	Mobile	-19.851787600478463	-28.073754091699456	165994
fa4f2563cbdfa1102497ab88bca8a98465a65515	learning functional compositions of urban spaces with crowd-augmented travel survey data	travel survey;multi output regression;urban analytics	Regions in urban environments often afford a mixture of different utilities. Their identification allows urban planners to leverage important insights on the emerging functional dynamics of cities. With the increasing availability of human mobility data and other forms of online digital breadcrumbs, we can now characterize urban regions with multi-source features. In this work, we form a comprehensive view of urban regions by fusing features depicting their temporal, spatial, and demographic aspects. Aggregating 47K explicitly stated trip purposes into their respective destination regions, we obtain multi-dimensional ground-truths on the functionalities of urban spaces. Given fused features and training labels, we can perform supervised learning, via multi-output regression, to estimate the functional composition of urban spaces. With 14 functional dimensions, our approach using crowd-augmented travel survey predictors delivers a mean absolute error of 3.9, approximately half of the error resulting from a mean-based straw man approach (mean absolute error of 7.9). Clustering estimated regional functionalities, we find highly coherent cluster assignments (adjusted Rand Index of 0.81) compared to clustering directly on regional functionality labels. Finally, we provide an illustrative case-study where clustering of estimated region functionalities can be used to intuitively differentiate prototypical spatial neighbourhoods of a large metropolitan.	approximation error;cluster analysis;coherence (physics);mean squared error;multi-source;rand index;supervised learning	Zack Zhu;Jing Yang;Chen Zhong;Julia Seiter;Gerhard Tröster	2015		10.1145/2820783.2820832	simulation;geography;machine learning;data mining;cartography	ML	-20.18528795796472	-33.620754306904075	166028
735762290da16163e6f408e1dd138d47ae400745	cityspectrum: a non-negative tensor factorization approach	human mobility;non negative tensor factorization	People flow at a citywide level is in a mixed state with several basic patterns (e.g. commuting, working, commercial), and it is therefore difficult to extract useful information from such a mixture of patterns directly. In this paper, we proposed a novel tensor factorization approach to modeling city dynamics in a basic life pattern space (CitySpectral Space). To obtain the CitySpectrum, we utilized Non-negative Tensor Factorization (NTF) to decompose a people flow tensor into basic life pattern tensors, described by three bases i.e. the intensity variation among different regions, the time-of-day and the sample days. We apply our approach to a big mobile phone GPS log dataset (containing 1.6 million users) to model the fluctuation in people flow before and after the Great East Japan Earthquake from a CitySpectral perspective. In addition, our framework is extensible to a variety of auxiliary spatial-temporal data. We parametrize a people flow with a spatial distribution of the Points of Interest (POIs) to quantitatively analyze the relationship between human mobility and POI distribution. Based on the parametric people flow, we propose a spectral approach for a site-selection recommendation and people flow simulation in another similar area using POI distribution.	apache poi;global positioning system;mobile phone;national transfer format;point of interest;quantum fluctuation;quantum state;sed;simulation	Zipei Fan;Xuan Song;Ryosuke Shibasaki	2014		10.1145/2632048.2636073	simulation;computer science;artificial intelligence	ML	-20.106084437024982	-33.97404981620842	166090
ae6229f4602cff714f16e3006af44c94b8836735	from tabular data to metaphoric landscape visualisation - a template-based approach			table (information)	Farhan Mohamed;Min Chen;Phil W. Grant	2010		10.2312/LocalChapterEvents/TPCG/TPCG10/175-182	natural language processing;computer science;programming language;algorithm	ML	-33.03038427816049	-31.60947198119113	166221
352429f7773f202479c49f4627e79f0dc36e817e	unsupervised extraction of graph-stream structure for purpose of knowledge retrieval and information fusion	algorytmy;algorithms	Technologically inevitable introduction of various kinds of sensors to our life resulted in the production of huge amount of data delivered as streams. An improper acquisition of information may lead to errors caused by mixing observations coming from different processes threads. Some remedy can bring a proper representation of information. Hence, this paper introduces a graph–stream structure representing performance of complex multi–threaded process. The proposed network representation can separate information describing multiple threads and allows for modeling causal relationships between them. It gives separated and segregated information opening opportunity for development of qualitatively better and simpler knowledge retrieval algorithms. Further, the paper delivers a method for this representation extraction from multivariate data stream. It would be done by a clustering algorithm particularly designed for this purpose and evaluated quantitatively and qualitatively on example sets of data.	algorithm;array data structure;causal filter;causality;cluster analysis;diagram;directed acyclic graph;information processing;modal logic;streams;sensor;synergy	Radoslaw Ziembinski	2015		10.15439/2015F288	computer science;machine learning;pattern recognition;information retrieval	AI	-23.53706884468111	-32.37059379717227	166701
58a85eabed3a0c9e596e1158bd3ee54eaae4e7b4	recognizing city identity via attribute analysis of geo-tagged images	article	After hundreds of years of human settlement, each city has formed a distinct identity, distinguishing itself from other cities. In this work, we propose to characterize the identity of a city via an attribute analysis of 2 million geo-tagged images from 21 cities over 3 continents. First, we estimate the scene attributes of these images and use this representation to build a higher-level set of 7 city attributes, tailored to the form and function of cities. Then, we conduct the city identity recognition experiments on the geo-tagged images and identify images with salient city identity on each city attribute. Based on the misclassification rate of the city identity recognition, we analyze the visual similarity among different cities. Finally, we discuss the potential application of computer vision to urban planning.	computation;computer vision;experiment	Bolei Zhou;Liu Liu;Aude Oliva;Antonio Torralba	2014		10.1007/978-3-319-10578-9_34	computer science;artificial intelligence;data mining	Vision	-20.415539618836018	-35.22115006093819	166791
265438e816d01fcf4d55efabcc790120722b76db	sensepresence: infrastructure-less occupancy detection for opportunistic sensing applications	acoustic sensing;occupancy detection accuracy sensepresence infrastructure less occupancy detection opportunistic sensing applications infrastructure less multimodal smartphone sensor based techniques zero configuration multimodal smartphone sensor based techniques fine grained occupancy information acoustic sensors human conversation motion sensors speaker estimation algorithm unsupervised clustering locomotive model;accelerometer sensing;speaker estimation;occupancy counting;accelerometer sensing occupancy counting opportunistic sensing acoustic sensing speaker estimation;sensors accelerometers microphones context estimation mel frequency cepstral coefficient;opportunistic sensing;smart phones pattern clustering	Predicting the occupancy related information in an environment has been investigated to satisfy the myriad requirements of various evolving pervasive, ubiquitous, opportunistic and participatory sensing applications. Infrastructure and ambient sensors based techniques have been leveraged largely to determine the occupancy of an environment incurring a significant deployment and retrofitting costs. In this paper, we advocate an infrastructure-less zero-configuration multimodal smartphone sensor-based techniques to detect fine-grained occupancy information. We propose to exploit opportunistically smartphones' acoustic sensors in presence of human conversation and motion sensors in absence of any conversational data. We develop a novel speaker estimation algorithm based on unsupervised clustering of overlapped and non-overlapped conversational data to determine the number of occupants in a crowded environment. We also design a hybrid approach combining acoustic sensing opportunistically with locomotive model to further improve the occupancy detection accuracy. We evaluate our algorithms in different contexts, conversational, silence and mixed in presence of 10 domestic users. Our experimental results on real-life data traces collected from 10 occupants in natural setting show that using this hybrid approach we can achieve approximately 0.76 error count distance for occupancy detection accuracy on average.	acoustic cryptanalysis;algorithm;ambient network;client–server model;cluster analysis;microphone;modality (human–computer interaction);multimodal interaction;participatory sensing;people counter;pervasive informatics;real life;requirement;sensor;server (computing);smartphone;software deployment;tracing (software);unsupervised learning;zero-configuration networking	Md Abdullah Al Hafiz Khan;H. M. Sajjad Hossain;Nirmalya Roy	2015	2015 16th IEEE International Conference on Mobile Data Management	10.1109/MDM.2015.41	embedded system;speech recognition;telecommunications	Mobile	-20.00327102622972	-31.31444972701509	166950
92c5f7d6f042203733fb187a52aa538a993054f5	conceptcloud: a tagcloud browser for software archives	software repositories;browsing;tag clouds;formal concept analysis	ConceptCloud is an interactive browser for SVN and Git repositories. Its main novelty is the combination of an intuitive tag cloud interface with an underlying concept lattice that provides a formal structure for navigation. This combination allows users to explore repositories serendipitously, without predefined search goals and along different navigation paths. ConceptCloud can derive different lattice types for a repository and supports concurrent navigation in multiple linked tag clouds that can each be individually customized, which allows multi-faceted repository explorations.	faceted classification;formal concept analysis;subversion;tag cloud	Gillian J. Greene;Bernd Fischer	2014		10.1145/2635868.2661676	computer science;formal concept analysis;database;world wide web;tag cloud;information retrieval	HCI	-31.497369446590852	-33.515893133135606	167549
38d2be9911f40e3cc486dea19e86f387fe43e741	hierarchical pixel bar charts	information resources;electronic commerce;multidimensional data visualization;business graphics;hierarchical visualization;information visualization;data type;web service;data mining;graphs;data visualisation;data mining data visualisation electronic commerce technical presentation business graphics information resources graphs very large databases;very large multiattributes data sets;technical presentation;data visualization bars data mining computer society computer graphics web services multidimensional systems data analysis large screen displays;highly aggregated data hierarchical pixel bar charts data type categorical data x y plots numerical data data records multidimensional data visualization data mining hierarchical visualization very large databases categorical data dimensions e business web services presentation graphics;visual data exploration and data mining;very large databases;categorical data	Simple presentation graphics are intuitive and easy-to-use, but only show highly aggregated data. Bar charts, for example, only show a rather small number of data values and x-y-plots often have a high degree of overlap. Presentation techniques are often chosen depending on the considered data type—bar charts, for example, are used for categorical data and x-y plots are used for numerical data. In this article, we propose a combination of traditional bar charts and x-y-plots, which allows the visualization of large amounts of data with categorical and numerical data. The categorical data dimensions are used for the partitioning into the bars and the numerical data dimensions are used for the ordering arrangement within the bars. The basic idea is to use the pixels within the bars to present the detailed information of the data records. Our so-called pixel bar charts retain the intuitiveness of traditional bar charts while applying the principle of x-y charts within the bars. In many applications, a natural hierarchy is defined on the categorical data dimensions such as time, region, or product type. In hierarchical pixel bar charts, the hierarchy is exploited to split the bars for selected portions of the hierarchy. Our application to a number of real-world e-business and Web services data sets shows the wide applicability and usefulness of our new idea.	algorithm;categorical variable;chart;data point;data structure;diagram;e-commerce;electronic business;graphics;level of measurement;mathematical optimization;numerical analysis;nyquist plot;optimization problem;pixel;product type;web service	Daniel A. Keim;Ming C. Hao;Umeshwar Dayal	2002	IEEE Trans. Vis. Comput. Graph.	10.1109/TVCG.2002.1021578	web service;information visualization;motion chart;categorical variable;data type;computer science;data science;data mining;database;graph;data visualization	Visualization	-28.497502290800757	-33.182636643531794	167689
aabe5e7269ee833d1fb4dea5917411342d9eeb59	modelling trees and their interaction with the environment: a survey	atmospheric science;virtual reality;geometric algorithms;spectrum;data type;graphics data structures and data types;languages and systems;physically based modelling;geometric algorithm;earth and atmospheric sciences;data structure;environmental factor	In this paper, we summarize some of the techniques used for modelling certain elements of nature such as trees. We describe some of the current methods in their order of appearance in the classification spectrum given in this survey. We discuss the geometrical and biological aspects that help us to identify the position of the work in our spectrum. The paper also identifies the interaction capability of the current techniques with the environmental factors and external forces. r 2005 Elsevier Ltd. All rights reserved.	simulation;tree (data structure);virtual reality	Soner I. Sen;Andrew M. Day	2005	Computers & Graphics	10.1016/j.cag.2005.08.025	spectrum;computer vision;simulation;data structure;data type;computer science;artificial intelligence;data science;theoretical computer science;virtual reality;programming language;computer graphics (images);mechanical engineering	AI	-33.38412836007369	-31.462506891125024	167727
b79201848f2a000223e9dea7db898a96c019317e	computer-aided multi-scale materials and product design	computer-aided multi-scale material;product design	The success of computer-aided design (CAD) tools in engineering design has been witnessed in the past four decades. Advanced CAD tools have become a critical enabling technology in product design since they help build virtual prototypes of complex products (e.g. automobiles, airplanes, and electronic appliances). In today’s CAD-enabled design processes, design engineers select availablematerials from databases to realize desired product functionality. Material databases are constructed by materials scientists and engineers based on the experimentally tested physical properties of existing materials. Therefore, the available ‘degrees of freedom’ for design engineers to control and optimize the performance of products are restricted to geometry and topology only. To offer design engineers more degrees of freedom, the additional dimension of material properties in the design solution space is highly valuable. Customizable materials can provide extra flexibility to realize the increasingly intricate product functionality. In other words, materials selection should be replaced by materials design to better meet stakeholders’ requirements in modern product realization. It can be envisioned that design engineers will perform product and materials design aided by multi-scale CAD software tools in the near future. They can not only perform the traditional geometry construction and structural analysis in such a multiscale CAD environment, but also customize thematerial properties for some local region of the design by simply zooming into the specific region to specify material compositions or crystalline configurations. Design occurs concurrently at multiple length scales, including nano-,meso-,micro-, andmacro-scales. Extensive problem-specific materials customization is thus achievable. Design decisions made at the microscopic levels determine the physical properties of newmaterials and the behavior of products. Materials design is integrated with geometry and topology design at the macroscopic level. Multi-scale CAD software tools help engineers to set functional objectives at different scales, construct material-inclusive product models, simulate and optimize design, and guide laboratory efforts to implement materials and target behaviors of final products. The value of a multi-scale CAD environment lies in its seamless knowledge integration across disciplinary boundaries. The conventional material selection approach that design engineers usually take is based on the isolated databases that were built without the input of problem-specific needs. Such a one-directional bottomup approach to discover, devise, and deploy new materials has a long development cycle and is not cost-effective. Even the materials science and engineering community has realized that the ‘lack of design’ limits the rapid advancement of engineering materials. Therefore, a systems engineering approach to integrate processing, structure, property, and performance for materials design has been adopted (see: Olson, G. B., ‘‘Computational design of hierarchically structured materials’’, Science, 1997, Vol. 277, No. 5330, pp. 1237–1242). A new term of Integrated Computational Materials Engineering (ICME) was coined to capture the top-down and target-oriented design process for materials that employs modern computational power to represent fine-grainedmicrostructures, to simulatemulti-level properties, and to devise fabrication processes of newmaterials. Most recently a newMaterials Genome Initiative was kicked off in the U.S.A. to develop a new materials innovation infrastructure of computational and experimental tools along with digital data to accelerate materials development. Various technical challenges to realize the new computational infrastructure for materials design also provide research opportunities, such as (i) how to rigorously quantify microstructure-property-processing relationships and establish highlevel abstraction of materials knowledge, (ii) how to effectively extract useful information and knowledge out of abundant characterization data, (iii) how to integrate information and knowledge gained from simulation at individual scales for multi-scale systemsdesign, (iv) how to improve efficiency and accuracy in such multi-scale simulation schemes, (v) how to extend available design methodologies such as data mining, analysis, and optimization in materials design, and (vi) how to quantify uncertainties in the design process, specifically variability caused by inherent randomness and incertitude due to the lack of perfect knowledge, in order to improve the robustness of design. In this special issue, the paper entitled ‘‘Key computational modeling issues in Integrated Computational Materials Engineering ’’, authored by Panchal, J.H., Kalidindi, S.R., and McDowell, D.L. provides an extended overview of the major ongoing research elements in ICME, includingmaterials databases for information collected from characterization, microstructure knowledge systems that represent and visualize high-level knowledge about materials, multi-scale modeling for materials design, uncertainty quantification andmanagement. Similar to the conventional CAD at bulk scale as the first tool for virtual prototyping, the primary function of multi-scale CAD is to allow for the efficient construction and interactive modification of geometric models for microstructures at small scales. Existing boundary-representation based parametric modeling approaches have become inefficient in model construction at nanoandmesoscales where geometry and topology are highly complex, because a great number of control points are required. New modeling and representation techniques are thus needed. For example, an implicit modeling approach can efficiently represent superporousmicrostructures with intricate topology. To designmaterial properties, the local control of shapes in microstructures is no longer important. It is more critical to allow design engineers to modify the overall structure globally in a representative volume	boundary representation;computation;computer-aided design;data mining;database;digital data;emoticon;engineering design process;experiment;feasible region;heart rate variability;high- and low-level;knowledge integration;knowledge-based systems;mathematical optimization;parametric model;randomness;requirement;seamless3d;simulation;software design;structural analysis;systems engineering;top-down and bottom-up design;uncertainty quantification	Yan Wang;Imre Horváth	2013	Computer-Aided Design	10.1016/j.cad.2012.07.013		EDA	-32.84434262770182	-25.846471785856902	168122
c580270c9595743568f44644071e35d327b66273	design and hil setup of an autonomous vehicle for crowded environments	vehicles sensors autonomous automobiles navigation software packages;sensors;hardware in the loop simulations autonomous vehicle crowded environments intelligent transportation vehicles autonomous people transportation indoor areas outdoor areas pedestrians freezing robot problem simulink simulations;navigation;vehicles;road vehicles collision avoidance intelligent robots intelligent transportation systems mobile robots pedestrians;autonomous automobiles;software packages	Within the last decade, we are witnessing the introduction of intelligent vehicles on our roadways. There is a similar need of intelligent transportation vehicles inside buildings such as airports or shopping malls. These intelligent vehicles can transfer elderly, disabled, or people with heavy luggage. This paper describes an intelligent vehicle that can autonomously transport people in indoor and outdoor areas where pedestrians exist. During operation along pedestrians, detecting them and updating trajectories to avoid collision is not always feasible. In some cases, this leads to a vehicle that is unable to move. In literature, this problem is labeled as the freezing robot problem. This paper proposes an approach to solve this problem by interaction with pedestrians. In order to validate the approach, Simulink simulations and hardware in the loop simulations are performed with different environment scenarios.	autonomous robot;hil bus;hardware-in-the-loop simulation;sensor;simulink	S. Yaren Gelbal;Erdinç Altug;E. Faruk Kececi	2016	2016 IEEE International Conference on Advanced Intelligent Mechatronics (AIM)	10.1109/AIM.2016.7576961	embedded system;simulation;engineering;transport engineering	Robotics	-20.4170330584075	-27.79034244918513	168177
3be223b2fbfa9a8b584b9e5586ba70cc3dac3763	a systems engineering method for analysis and simulation of standard operating procedures	flightdeck operations;human machine interactions;formal methods;standard operating procedures	Standard Operating Procedures (SOPs) define flightdeck operations by prescribing the sequence of actions for flight crew to complete each segment of the mission. Well-designed procedures allow the flight crew to perform the required sequence of actions in a feasible progression within the operationally allowable time window. Current practices for developing procedures rely on judgments of domain experts and are tested by experts in simulators. This approach is expensive, time consuming, and dependent on subjective assessments. This paper describes the application of a formal model that complements the work of domain experts by assessing the cueing and timing of SOPs' interactions using a combination of sequence diagram and Monte Carlo simulations to support time-to-complete analysis. The method is demonstrated by a case-study comparing two alternative procedures for a four-engine turbofan aircraft.	color gradient;formal language;interaction;monte carlo method;sequence diagram;simulation;standard operating procedure;systems engineering	Houda Kerkoub Kourdali;Lance Sherry	2016		10.1145/2950112.2964580	simulation;formal methods;computer science;artificial intelligence;operations research	Graphics	-24.1739568833695	-24.938071783208862	168190
7c9982fe1e77bb3e553a03b45e2fab06eee02cc8	the design of a collision avoidance system for use by pilots operating on the airport ramp and in taxiway areas	taxiways;human computer interaction;pedestrian safety;airport ramp and taxiways;poison control;injury prevention;scenario based design;collaborative prototyping;cockpit;safety literature;traffic safety;injury control;airport surface traffic control;crash avoidance systems;home safety;collision avoidance systems;injury research;safety abstracts;human factors;operability;occupational safety;safety;safety research;flight operations;accident prevention;violence prevention;collision avoidance;user interfaces computer science;bicycle safety;participatory design;procedures;ground collisions;poisoning prevention;air pilots;falls;ergonomics;suicide prevention;flight crew	Ground collisions have serious implications from both a safety and a commercial perspective. This paper reports on human computer interaction (HCI) research related to the advancement of a collision avoidance system, for use by Pilots operating on the airport ramp and in taxiway areas. Primarily, this paper focuses on the key findings of this research and the emerging HCI design solution.	human computer;human–computer interaction;ramp simulation software for modelling reliability, availability and maintainability	Joan Cahill;Peter Redmond;Sofiane Yous;Gerard Lacey;William Butler	2012	Cognition, Technology & Work	10.1007/s10111-012-0240-9	procedure;operability;simulation;medicine;environmental health;human–computer interaction;engineering;suicide prevention;human factors and ergonomics;injury prevention;transport engineering;cockpit;computer security;mechanical engineering	HCI	-21.784123363667135	-24.979410169325526	168243
7e6c844fd558159b02e241d4ad03adef91ba3461	modeldb: a system for machine learning model management	electronic medical records;entity linking;entity recognition;online learning;natural language processing	"""Building a machine learning model is an iterative process. A data scientist will build many tens to hundreds of models before arriving at one that meets some acceptance criteria (e.g. AUC cutoff, accuracy threshold). However, the current style of model building is ad-hoc and there is no practical way for a data scientist to manage models that are built over time. As a result, the data scientist must attempt to """"remember"""" previously constructed models and insights obtained from them. This task is challenging for more than a handful of models and can hamper the process of sensemaking. Without a means to manage models, there is no easy way for a data scientist to answer questions such as """"Which models were built using an incorrect feature?"""", """"Which model performed best on American customers?"""" or """"How did the two top models compare?"""" In this paper, we describe our ongoing work on ModelDB, a novel end-to-end system for the management of machine learning models. ModelDB clients automatically track machine learning models in their native environments (e.g. scikit-learn, spark.ml), the ModelDB backend introduces a common layer of abstractions to represent models and pipelines, and the ModelDB frontend allows visual exploration and analyses of models via a web-based interface."""	data science;end-to-end principle;hoc (programming language);iteration;machine learning;pipeline (computing);sensemaking;web application;scikit-learn	Manasi Vartak	2016		10.1145/2939502.2939516	computer science;artificial intelligence;data science;data mining	ML	-24.89796409719681	-37.854969164511736	168555
5749a23f6f06c7c4802e43d7015ae629ad36ef9d	characterizing users’ visual analytic activity for insight provenance	harvest visual analytic system user visual analytic activity characterization information visualization manually recorded insight provenance automatically recorded event based insight provenance semantic building block action type categorization;action type categorization;h 5 0 information systems information interfaces and presentation general;manuals;harvest visual analytic system;investments;semantic building block;analytic activity;building block;critical level;catalogs;information visualization;h 5 0 information systems information interfaces and presentation general taxonomy information visualization analytic activity visual analytics insight provenance;insight provenance;data visualisation;visualization;human factors;cognition;manually recorded insight provenance;data visualization;taxonomy;automatically recorded event based insight provenance;humans;information system;user visual analytic activity characterization;visual analytics;information interfaces and presentation;visual analytics taxonomy information analysis data visualization investments mice prototypes information systems humans visual perception;human factors cognition data visualisation	Insight provenance - a historical record of the process and rationale by which an insight is derived - is an essential requirement in many visual analytics applications. While work in this area has relied on either manually recorded provenance (e.g., user notes) or automatically recorded event-based insight provenance (e.g., clicks, drags, and key-presses), both approaches have fundamental limitations. Our aim is to develop a new approach that combines the benefits of both approaches while avoiding their deficiencies. Toward this goal, we characterize userspsila visual analytic activity at multiple levels of granularity. Moreover, we identify a critical level of abstraction, Actions, that can be used to represent visual analytic activity with a set of general but semantically meaningful behavior types. In turn, the action types can be used as the semantic building blocks for insight provenance. We present a catalog of common actions identified through observations of several different visual analytic systems. In addition, we define a taxonomy to categorize actions into three major classes based on their semantic intent. The concept of actions has been integrated into our labpsilas prototype visual analytic system, HARVEST, as the basis for its insight provenance capabilities.	algorithm;categorization;design rationale;high- and low-level;ibm 7950 harvest;information needs;multitier architecture;prototype;requirement;taxonomy (general);usability testing;visual analytics	David Gotz;Michelle X. Zhou	2008	2008 IEEE Symposium on Visual Analytics Science and Technology	10.1109/VAST.2008.4677365	cognition;visualization;computer science;data science;data mining;world wide web;information system;data visualization	Visualization	-28.83782819957625	-31.436997241974286	168749
e6b14dd60bec0d2b632382e7a0e77c9b9a90be58	application of keyword map to decision support through exploratory search	interactive information retrieval;decision support;dvd;motion pictures;exploratory search;interactive information visualization system;multiple relevance controller;information retrieval;probability density function;user s behavior;interactive systems data visualisation decision making decision support systems information retrieval;information visualization;data mining;data visualisation;decision support keyword map decision making exploratory search interactive information visualization system multiple relevance controller;shape;image color analysis;decision support systems;decision making systems engineering and theory displays weight control springs data analysis animation bars data visualization information retrieval;user behavior;interactive systems;keyword map;user s behavior interactive information retrieval exploratory search decision making	This paper examines users behavior in decision making through exploratory search on a keyword map. The keyword map is a kind of interactive information visualization system, which displays relationships between objects (keywords). The system has been studied for analyzing data. The keyword map has a multiple relevance controller for analyzing relationship between keywords, which is represented by multiple attributes, from various viewpoints. A user can adjust weights of attributes according to his/her interest, using the controller. We expect that the keyword map can support compensatory/non-compensatory decision strategies by the multiple relevance controller. We perform an experiment for confirming user's behavior during exploratory search on the keyword map. Experimental result shows a user operates flexibly the multiple relevance controller according to his/her decision strategies.	decision support system;exploratory search;information visualization;relevance	Tomoki Kajinami;Toshiyuki Ogasawara;Jyouji Komiya;Yasufumi Takama	2008	2008 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2008.4811615	probability density function;decision support system;shape;computer science;data mining;world wide web;information retrieval	Robotics	-30.188536473698587	-33.034159868584	168941
c40093aef35741b36b4e2a7c8a7a564bb975e273	guided genetic programming.	computer program;genetic program	This paper argues that genetic programming has not made good on its promise to generate computer programs automatically. It then describes an approach that would allow that promise to be fulfilled by running a genetic programming engine under human guidance.	admissible numbering;computer program;emoticon;fitness function;genetic programming	Russ Abbott	2003			genetic program;genetic programming;machine learning;computer program;computer science;artificial intelligence	AI	-27.16119300693107	-24.56812181277695	168961
09625f46c980a5a875cf229b8265811d93cf8c07	information visualization: data infrastructure architectures	national security;distributed system;local derived metadata management information visualization data infrastructure architectures scientific visualization informational entities national agendas information analysis processes scientific databases media types discovery understanding situation assessments data infrastructure architecture distributed multimedia information spaces information agents metadata transformations;metadata management;distributed databases data visualisation multimedia systems;distributed multimedia;information space;information visualization;scientific database;multimedia systems;scientific visualization;data visualisation;distributed databases;information agent;information analysis;situation assessment;data visualization space technology reflection manufacturing industries national security information analysis manufacturing processes image databases visual databases audio databases	Information Visualization extends the scope of scientific visualization from physical phenomena to informational entities. This broadening is a direct reflection of the needs expressed by industry, national security, health and other national agendas to include all forms of information within the information analysis processes. It includes; masses of text, forms, and documents; business, manufacturing, and scientific data bases; videos; audio; imagery; and most importantly the interactions with all these media &pes used to enable an enhanced process of discovery understanding, and presentation of situation assessments. In order for information visualization to become a reality a rich, flexible data infrastructure must be established. This paper dejnes the scope of information visualization, the emerging opportunities and uses, the related and supporting technologies, and presents a data infrastructure architecture. This architecture supports full distributed multimedia information spaces including technologies such as information agents, metadata transformations, and local derived metadata management which turns data and information into knowledge. keywords: Information visualization, scientific visualization, interaction, metadata, multimedia, distributed systems, information analysis, analyst. Information Visualization: Scope Information Visualization offers significant capability to those who must identify, explore, discover, analyze, and develop understandings of complex situations including diverse types of information (e.g. from text to video, to sound) from increasingly large heterogenous data sources. As a common component of information visualization, envisioning information is one of the most studied and documented technologies, being an integration of science and art: 2 To envision information-what bright and splendid vision can result-is to work at the intersection of image, word, number, and art. The instruments are those writing and typography, of managing large data sets and statistical analysis, of line and layout and color ... . -E.R. Tufte, 1990 [ l ] Yet from the information analyst’s perspective, envisioning the information is only part of the picture. Information visualization also is: ... not just drawing and viewing the image but is the process of interacting with your data and model. -J.J. Thomas, 1993 [2] ... the study, development, and use of computer graphic representation and supporting technologies that facilitates the visual communication of knowledgethat makes the computer images speak to us. -P.R. Keller and M.M. Keller, 1993 [3] In short the process of information analysis from a user’s perspective is a craft (Figure 1). and engineering supported by science and communication. Figure 1. Information Analysis Process Two key points in this process must be emphasized. First, the information analysis craft is a process based to a large extent on the creative talents of analysts to identify, explore, and develop understandings of complex situations. The process is supported by some automated tools, but the information analyst is and will remain the critical resource. Second, the process of information analysis has constraints similar to other disciplines, e.g., reduced time and budgets, hzzy information. These constraints drive the need for some established common communication (language/symbology) and methods so information analysts can build on each other’s 0-8186-6330-8/94 $04.00	computer graphics;data infrastructure;database;distributed computing;document;entity;information visualization;interaction;scientific visualization;video	James J. Thomas;Shaw Bohn;James C. Brown;Kelly Pennock;Anne Schur;James A. Wise	1994		10.1109/SSDM.1994.336967	information infrastructure;scientific visualization;information visualization;computer science;national security;data mining;database;information design;data analysis;situation analysis;information retrieval	Visualization	-29.190154441697963	-30.234175340779526	169007
5bf3a6386946766dcca6f37e0e1e0af3dbb35446	attribute signatures: dynamic visual summaries for analyzing multivariate geographical data	interactive data analysis;multi variate data;geographic information;ga mathematical geography cartography;uk attribute signatures dynamic visual summaries multivariate geographical data analysis visual analysis geographically referenced datasets attribute characteristics interactive visual methods interactive graphics geographic variability attribute statistics statistical measures graphical configurations continuous location variation continuous scale variation discrete location variation discrete scale variation multiple statistical summaries multiple attributes census geography london;geographic information systems;statistics;cities and towns;statistical analysis data visualisation geographic information systems graphical user interfaces interactive systems;geovisualization;visual analytics;visual analytics urban areas spatial resolution statistics geographic information systems;z665 library science information science;spatial resolution	The visual analysis of geographically referenced datasets with a large number of attributes is challenging due to the fact that the characteristics of the attributes are highly dependent upon the locations at which they are focussed, and the scale and time at which they are measured. Specialized interactive visual methods are required to help analysts in understanding the characteristics of the attributes when these multiple aspects are considered concurrently. Here, we develop attribute signatures-interactively crafted graphics that show the geographic variability of statistics of attributes through which the extent of dependency between the attributes and geography can be visually explored. We compute a number of statistical measures, which can also account for variations in time and scale, and use them as a basis for our visualizations. We then employ different graphical configurations to show and compare both continuous and discrete variation of location and scale. Our methods allow variation in multiple statistical summaries of multiple attributes to be considered concurrently and geographically, as evidenced by examples in which the census geography of London and the wider UK are explored.	antivirus software;censuses;concurrency (computer science);electronic signature;geography;graphical user interface;graphics;interactivity;spatial variability;emotional dependency	Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes	2014	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2014.2346265	geovisualization;visual analytics;image resolution;computer science;data science;data mining;information retrieval;statistics	Visualization	-26.14443264070172	-33.19409530006468	169083
0807b85ff9ade53ff08b4cc8d26119270f1c3bde	understanding data science lifecycle provenance via graph segmentation and summarization		Along with the prosperous data science activities, the importance of provenance during data science project lifecycle is recognized and discussed in recent data science systems research. Increasingly modern data science platforms today have nonintrusive and extensible provenance ingestion mechanisms to collect rich provenance and context information, handle modifications to the same file using distinguishable versions, and use graph data models (e.g., property graphs) and query languages (e.g., Cypher) to represent and manipulate the stored provenance/context information. Due to the schema-later nature of the metadata, multiple versions of the same files, and unfamiliar artifacts introduced by team members, the “provenance graph” is verbose and evolving, and hard to understand; using standard graph query model, it is difficult to compose queries and utilize this valuable information. In this paper, we propose two high-level graph query operators to address the verboseness and evolving nature of such provenance graphs. First, we introduce a graph segmentation operator, which queries the retrospective provenance between a set of source vertices and a set of destination vertices via flexible boundary criteria to help users get insight about the derivation relationships among those vertices. We show the semantics of such a query in terms of a context-free grammar, and develop efficient algorithms that run orders of magnitude faster than state-of-the-art. Second, we propose a graph summarization operator that combines similar segments together to query prospective provenance of the underlying project. The operator allows tuning the summary by ignoring vertex details and characterizing local structures, and ensures the provenance meaning using path constraints. We show the optimal summary problem is PSPACE-complete and develop effective approximation algorithms. The operators are implemented on top of a property graph backend. We evaluate our query methods extensively and show the effectiveness and efficiency of the proposed methods.	approximation algorithm;context-free grammar;context-free language;cypher query language;data model;data science;high- and low-level;pspace;pspace-complete;prospective search;systems development life cycle;systems theory;vertex (geometry)	Hui Miao;Amol Deshpande	2018	CoRR		automatic summarization;operator (computer programming);metadata;semantics;approximation algorithm;data science;vertex (geometry);query language;data modeling;computer science	DB	-27.016261745483853	-36.490838062929754	169211
b35e7958dc597bcdcb6501805863181fc66b677e	geographic visualization of risk as decision support in emergency situations	emergency situation;decision support;risk management;decision support geovisualization interactivity risk assessment emergency situation;data visualisation;risk management data visualisation decision making decision support systems emergency services geography;decision support systems;visualization inspection buildings usability prototypes emergency services personnel;interactivity;risk assessment;geovisualization;risk visualization design risk geographic visualization decision support emergency situations decision makers risk information;emergency services;geography	We investigate how geographic visualization can be used as a means to facilitate understanding of risk in emergency situations. Specifically, we identify the need of decision makers regarding access to risk information; introduce a visualization solution that aims to satisfy these needs; and evaluate this solution in terms of its ability to generate insight. A description of how the solution can be implemented is included. Our findings indicate that geographic visualization is an effective means for facilitating understanding of risk in emergency situations, but that the effectiveness of the concept depends on the visualization design. A set of guidelines towards risk visualization design is proposed.	geographic information system;geovisualization	Aslak Wegner Eide;Ketil Stølen	2012	2012 5th International Conference on Human System Interactions	10.1109/HSI.2012.39	decision support system;engineering;knowledge management;data mining;computer security	Visualization	-26.60302236462104	-28.76358954868025	169476
129cf82a83bc3131b8dbe430a0c0656484d4a82a	dynamic multiscale visualization of flight data	movement data visualization flight visualization graph visualization graph bundling;data visualization image color analysis animation airports scalability trajectory airplanes	We present a novel set of techniques for visualization of very large data sets encoding flight information obtained from Air Traffic Control. The aims of our visualization are to provide a smooth way to explore the available information and find outlier spatio-temporal patterns by navigating between fine-scale, detail, views on the data and coarse overviews of large areas and long time periods. To achieve this, we extend and adapt several image-based visualization techniques, including animation, density maps, and bundled graphs. In contrast to previous methods, we are able to visualize significantly more information on a single screen, with limited clutter, and also create real-time animations of the data. For computational scalability, we implement our method using GPU-accelerated techniques. We demonstrate our results on several real-world data sets ranging from hours over a country to one month over the entire world.	cuda;clutter;computational complexity theory;graphics processing unit;information design;map;pixel;real-time clock;scalability;scientific visualization;shader;smoothing	Tijmen R. Klein;Matthew van der Zwan;Alexandru Telea	2014	2014 International Conference on Computer Vision Theory and Applications (VISAPP)	10.5220/0004685701040114	computer vision;simulation;information visualization;computer science;computer graphics (images)	Visualization	-28.126854980776606	-35.366019934859764	169506
1c700d90eea0466cdf6972aa6a4c86acfa744a68	towards air quality estimation using collected multimodal environmental data		This paper presents an open platform, which collects multimodal environmental data related to air quality from several sources including official open sources, social media and citizens. Collecting and fusing different sources of air quality data into a unified air quality indicator is a highly challenging problem, leveraging recent advances in image analysis, open hardware, machine learning and data fusion and is expected to result in increased geographical coverage and temporal granularity of air quality data.	atmospheric dispersion modeling;image analysis;kriging;machine learning;multimodal interaction;open platform;open-source hardware;social media;statistical model;user-generated content;web mapping	Anastasia Moumtzidou;Symeon Papadopoulos;Stefanos Vrochidis;Yiannis Kompatsiaris;Konstantinos Kourtidis;George Hloupis;Ilias Stavrakas;Konstantina Papachristopoulou;Christodoulos Keratidis	2016		10.1007/978-3-319-50237-3_7	simulation;data science;data mining	AI	-21.535675755822847	-32.24884169291089	169608
b4eefba25459571c1f63d3072920d6c0c42ce9f4	towards a visualization framework for service selection in cloud e-marketplaces		In spite of the success of many commercial cloud service e-marketplaces, the search results from these platforms are usually presented as an unordered list of icons representing the services that best fit users' keyword-based queries. The drawback of such presentation mechanisms is that users are not able to immediately discriminate among the cloud services for easy decision making. A number of cloud service selection frameworks have been proposed, however, some of these frameworks do not enable users to make comparisons among services. In this paper, we introduce a visualization framework for cloud service selection. Our framework takes into cognizance the set of cloud services that matches a user's request and based on QoS attributes, users can interact with the results via bubble graph visualization to compare and contrast the search results to ascertain the best alternative. The bubble graph enables the exploration of services in a unified view of the QoS space, exhibiting both high object coherence and correlation. The result from our experiments shows that our framework simplifies decision making as users can identify services that best fit their requirements quicker and easier compared to tabular formats.	cloud computing;curve fitting;experiment;graph drawing;html element;requirement;table (information)	Azubuike Ezenwoke;Olawande Daramola;Matthew Adigun	2017	2017 IEEE International Conference on Web Services (ICWS)	10.1109/ICWS.2017.100	data mining;bubble;quality of service;visualization;database;computer science;cloud computing;graph drawing;spite;graph	Visualization	-29.727231481934204	-28.978975167102796	169786
4cbff14f17616d7d79ad3b9f3689db6a9cb4eeb9	real world representation of a road network for route planning in gis	geographic information system;road network;impedance model;ahp;network analysis;gis;analytic network process;sensitivity analysis;information system;route planning;analytical hierarchical process;virtual worlds	This paper addresses a methodology to properly represent a road network in the geographic information system (GIS) for network analysis. Over the years, the real world has become too complex to model properly within a given information system, such as GIS. Ideally, when the real world is represented as accurately as possible, a GIS can answer a question in its virtual world that coincides with the exact answer in the real world. However, existing methods related to impedance modeling for each segment of a road network in a route planning analysis that includes only a distance or time variable do not give proper results. Hence, this study investigates how a road network can represent the real world in a GIS and offer route planning tools. To address this, first, additional realistic variables are taken into account. These include weather, sight-seeing information, road type, and so on. Second, to combine these variables, an impedance model (IM) using the analytical hierarchical process (AHP) method is proposed. Finally, all of the models are implemented and verified with a sensitivity analysis. The models were successfully implemented in this work. All of the paths of the route planning analysis were successfully matched with the drivers' paths that would normally be chosen in reality. It is anticipated that the use of other techniques such as analytical network process (ANP) in addition to AHP would be useful to overcome the aforementioned problem.	geographic information system	Abolghasem Sadeghi-Niaraki;Masood Varshosaz;Kyehyun Kim;Jason J. Jung	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.12.123	enterprise gis;analytic hierarchy process;simulation;network analysis;computer science;artificial intelligence;machine learning;data mining;route planning software;geographic information system;sensitivity analysis;information system;analytic network process	AI	-26.528061506704017	-28.60377586564845	170036
2c73a4146090c5666328e9a41a4afb19d451f1a3	distributed emissions monitoring system	environmental issues;automobiles;environmental issue;emission rate;air pollution measurement;automobile speed;camera distributed emissions monitoring system air pollution environmental issue automobile emission automobile speed;monitoring system;monitoring;automatic detection;streaming media;automobiles air pollution measurement;air pollution;weed control;distributed databases;vehicles;automobile emission;cameras;cameras air pollution streaming media monitoring distributed databases vehicles pollution;camera;distributed emissions monitoring system;pollution	Nowadays, people more and more interested in the quality of their lives. In this reason, the air pollution is the most import environmental issues around Seoul, Korea metropolitan areas. People often think that large portion of air pollution is come from automobilepsilas emission. Before we control traffics, we need to figure out emission rates on certain area. In this paper we discuss distributed emission monitoring system. By using this system we will automatically detect volume, type, and speed of automobile by using camera. Based on this information we will analyze emission and results will be provided on the portal system.	adobe air	Jin You Lin	2008	2008 Fourth International Conference on Networked Computing and Advanced Information Management	10.1109/NCM.2008.256	simulation;pollution;weed control;distributed database;air pollution	Robotics	-20.78781652877072	-29.40617826554878	170395
78775852fff496dae37efb3ffca12e0dfe4707be	color linesview:anapproach tovisualization of families of function graphs	sorting;color;function graphs;scattering;multiple views;data visualisation;color lines view;visualization;aggregates;displays;visual analysis;data visualization;performance analysis;visual analysis procedures;sorting data visualisation graph colouring;pattern analysis;visual analysis procedures color lines view visualization function graphs rectangular view point colors sorting;computer science;point colors;multidimensional systems;data visualization sorting pattern analysis color multidimensional systems scattering displays computer science aggregates performance analysis;graph colouring;rectangular view	Data sets often include information that can be represented as a mapping that describes how a dependent variable depends on an independent variable. Such a mapping, usually represented as a function graph, can be parameterized to provide a family of function graphs. The challenge is how to efficiently aggregate individual function graph views to represent the whole family and allow visual analysis and search for patterns. We propose a novel view, called the color lines view, which provides a two dimensional, rectangular view where each line represents a single function graph. The points on the line correspond to values of the independent variable. The point colors represent the value of the dependent variable. The lines, placed next to each other in parallel, show a family of function graphs. The color lines view offers sorting and brushing features which support visual analysis procedures that are difficult to perform with previously existing views.	avl tree;aggregate data;application domain;brushing and linking;color;computer cluster;convex function;graph of a function;human–computer interaction;pixel;sorting;usability	Kresimir Matkovic;Denis Gracanin;Zoltan Konyha;Helwig Hauser	2007	2007 11th International Conference Information Visualization (IV '07)	10.1109/IV.2007.35	computer vision;combinatorics;computer science;theoretical computer science	Visualization	-28.705980309666163	-33.61831402788284	170769
e434a49c703d3f98b6f750fd090591f2f39b6b6a	foofah: a programming-by-example system for synthesizing data transformation programs	heuristic;programming by example;a algorithm;program synthesis;data transformation	Advancements in new data analysis and visualization technologies have resulted in wide applicability of data-driven decision making. However, raw data from various sources must be wrangled into a suitable form before they are processed by the downstream data tools. People traditionally write data transformation programs to automate this process, and such work is cumbersome and tedious.  We built a system called FOOFAH for helping the user easily synthesize a desired data transformation program. Our system minimizes the user's effort by only asking for a small illustrative example comprised of the raw input data and the target transformed output; FOOFAH then synthesizes a program that can perform the desired data transformation. This demonstration showcases how the user can apply FOOFAH to real-world data transformation tasks.	downstream (software development);programming by example	Zhongjun Jin;Michael R. Anderson;Michael J. Cafarella;H. V. Jagadish	2017		10.1145/3035918.3058732	heuristic;a* search algorithm;computer science;theoretical computer science;programming language;data transformation;algorithm	AI	-31.38699030283441	-30.566493879824662	170782
44f7ac9faf5cfb8e5df00e78412ba10bcef20143	effects of real-time imaging on decision-making in a simulated incident command task	feedback;fixation;sense making;presence;crisis management	Eight Incident Commanders (ICs) took part in a simulation exercise to determine the impact of real-time imaging feedback on situation assessment and decision-making in an uncertain and high-tempo environment. The imaging feedback simulated the video feed from an unmanned aerial vehicle (UAV) that allows incident command centers to monitor developments at the crisis site. Nearly all of the ICs failed to detect important changes in the situation that were not captured in the imaging but that were available via other, more traditional data sources. It appears that the ICs placed an inappropriately high level of trust in the imaging data, resulting in a narrowing of their data search activities and limited cross-checking between the data sources being used. This research helps anticipate and guard against undesirable effects of introducing similar technologies on training and operational procedures in a variety of domains.	aerial photography;high-level programming language;real-time locating system;real-time transcription;simulation;unmanned aerial vehicle;video	John M. McGuirl;Nadine B. Sarter;David D. Woods	2009	IJISCRAM	10.4018/jiscrm.2009010105	fixation;real-time computing;simulation;pathology;engineering;feedback;computer security	Robotics	-22.53401595011129	-27.356152957134938	170812
1dde9fee3341a209ef4c6745f00df4af2662d69d	spatial media fusion project	spatial data;text analysis;multimedia data;multimedia databases;photo video data spatial media fusion project spatial data meta data multimedia data spatial connections spatial keys spatial relationships multimedia content circulation geographic coordinate spatial referenced data geographic coordinates japanese addresses camera parameters text data;spatial relationships;cameras uniform resource locators geographic information systems earth internet information retrieval spatial databases information science motion pictures search engines;text analysis visual databases multimedia databases content based retrieval;content based retrieval;visual databases	Most information includes some kinds of spatial data such as the address of a restaurant and the position of a person carrying a portable phone. The spatial data are useful as meta data of multimedia data because they provide spatial connections between multimedia data. The spatial data are called spatial keys because they join different contents with spatial relationship. The spatial media fusion project started last year to construct a framework of multimedia contents’ circulation based on the spatial keys. A geographic coordinate (x,y) is one kind of spatial data, but there are other kinds of spatial data, called spatial referenced data, which can be converted to geographic coordinates. We particularly focus on Japanese addresses and camera parameters as spatial referenced data. Using two kinds of spatial referenced data, we integrated text data and photo/video data in the form of spatial keys.	geographic coordinate system;spatial analysis;text corpus	Masatoshi Arikawa;Koji Okamura	2000		10.1109/DLRP.2000.942188	spatial data infrastructure;object-based spatial database;computer science;spatial reference system;geospatial analysis;data mining;database;spatial database;information retrieval;spatial query	DB	-33.650446300812746	-36.199035732527406	171211
7fe0a0ee75627cc6516a01079972fe7dec0d2498	clique: situational awareness through behavior	electronic mail;statistical analysis data analysis data visualisation;data analysis;facsimile;behavioral algorithms transactional data data analysis;data visualization electronic mail data models facsimile terrorism us government advertising;data visualization;behavioral algorithms;pattern representation clique visual analytic environment situational awareness transactional data statistical behavior models behavioral algorithm behavioral detection techniques anomaly detection techniques visual representation;us government;transactional data;terrorism;data models;advertising	Clique, a visual analytic environment for transactional data, uses statistical behavior models to highlight anomalies. By leveraging a behavioral algorithm, Clique can help data analysts gain awareness into large, time-varying, and streaming datasets such as network flow. Through behavioral- and anomaly-detection techniques, applications provide insight into the nature of activity through visual representations of typical and atypical patterns. Insight gained via behavior algorithms can then act as jump-off points into further investigation.	algorithm;anomaly detection;dynamic data;flow network	Daniel M. Best;B. Ann Cox	2015	IT Professional	10.1109/MITP.2015.57	data modeling;computer science;data science;theoretical computer science;transaction data;data mining;terrorism;data analysis;computer security;data visualization	HCI	-24.80438858918401	-34.54917419853419	171359
ebf82c12d7e7fd50b11b7eb6cc2273b9441596b2	divide and conquer treemaps: visualizing large trees with various shapes	enclosure partitioning;hierarchical data;information visualization;journal article;treemaps;tree visualization	Most existing treemaps achieve the space utilization of a single geometrical area, mostly rectangle. Limiting visualization to rectangles could block the human capability on graph recognition, including orientation, shape and differentiation etc. To relax rectangular constraint, we propose a flexible enclosure approach with three algorithms. It partitions large hierarchical structures within a confined display area with different shapes for realtime applications. Our approach is based on the combination of Divide-and-Conquer method and the treemap paradigm. The partitioning algorithms generate three types of layouts with polygonal, angular and rectangular titling, which are flexible to be used separately or combined. We present technical details including the visualization results in the experiments and in the cases studies with real data sets. We evaluated the visualization based on graph drawing aesthetics and optimization criteria. Our usability study shows that (1) treemaps with layout variability support utilization of human capability in graph perception and (2) treemaps adopted in different shaped containers could have a positive impact on user satisfaction and awareness during visual data exploration. & 2015 Elsevier Ltd. All rights reserved.	algorithm;angularjs;experiment;graph drawing;heart rate variability;mathematical optimization;programming paradigm;real-time computing;treemapping;usability testing	Jie Liang;Quang Vinh Nguyen;Simeon J. Simoff;Mao Lin Huang	2015	J. Vis. Lang. Comput.	10.1016/j.jvlc.2015.10.009	treemapping;information visualization;computer science;theoretical computer science;data mining;database;hierarchical database model	Visualization	-31.740369761570133	-35.639560830226856	171595
1c2b83814df2211ff363bd51c61d3b6d7a85cbfd	pocketparker: pocketsourcing parking lot availability	parking;smartphone sensing;conference paper;crowdsourcing	Searching for parking spots generates frustration and pollution. To address these parking problems, we present PocketParker, a crowdsourcing system using smartphones to predict parking lot availability. PocketParker is an example of a subset of crowdsourcing we call pocketsourcing. Pocketsourcing applications require no explicit user input or additional infrastructure, running effectively without the phone leaving the user's pocket. PocketParker detects arrivals and departures by leveraging existing activity recognition algorithms. Detected events are used to maintain per-lot availability models and respond to queries. By estimating the number of drivers not using PocketParker, a small fraction of drivers can generate accurate predictions. Our evaluation shows that PocketParker quickly and correctly detects parking events and is robust to the presence of hidden drivers. Camera monitoring of several parking lots as 105 PocketParker users generated 10;827 events over 45 days shows that PocketParker was able to correctly predict lot availability 94% of the time.	activity recognition;algorithm;crowdsourcing;smartphone;software deployment	Anandatirtha Nandugudi;Taeyeon Ki;Carl Nuessle;Geoffrey Challen	2014		10.1145/2632048.2632098	simulation;computer science;parking guidance and information;computer security;crowdsourcing	HCI	-19.44788781938345	-31.198683298820608	171791
3ed268474fd74ca47a45363ce8c4f594d03de0f9	ahpsver: a web-based system for hydrologic forecast verification	computadora;tratamiento datos;computers;maps;base donnee;interfaces;mapa;north america;america del norte;amerique du nord;ordinateur;base dato;data processing;traitement donnee;relational database;data bases;etats unis;hydrological modeling;estados unidos;carte;interfase;multi dimensional;internet;hydrologic model;interface;web based system;modele hydrologique;hydrologic model verification;dynamic website	Hydrologic forecast verification is a complicated endeavor due to the size and multi-dimensionality of the data sets involved. Finding an effective way to examine and interpret these data sets in ways that are meaningful to forecasters and forecast users is a central challenge in determining how good the forecasts are. We have developed the (AHPSVER) system to address these issues. The AHPSVER system consists of two components. The first is a comprehensive archive of verification data. The second component is a fully dynamic, relational database back-ended website that allows users to view the verification data in individual, customized ways. The system uses a mapsand forms-based interface to make interaction with users easy. The system outputs several types of graphs complemented with context-sensitive help. These graphs are pre-computed when possible (saving time and computation resources) and otherwise generated by the system on demand. These allow geographically diverse users to conduct individual, customized, and interactive analyses of the forecast verification data set. r 2007 Elsevier Ltd. All rights reserved.	archive;computation;context-sensitive grammar;context-sensitive help;precomputation;relational database;web application	Anton Kruger;Shashank G. Khandelwal;Allen Bradley	2007	Computers & Geosciences	10.1016/j.cageo.2006.10.005	simulation;data processing;computer science;interface;data mining;database;functional verification	AI	-28.398906055800097	-28.524215318870237	171855
e7eff2f79eac3cd32eb33360548ab15560351b5a	assessment and support of error recognition in automated driving	fakultat fur mathematik informatik und statistik;ddc 004;ddc 000	Technical progress in the field of automated driving research is about to alter the way of driving from manual control toward supervision of automated control. The increasing dissemination of advanced driver assistance systems brings more and more people into contact with (semi-)automated systems that do not only warn against certain dangers and intervene if necessary, but are also able to take over parts of the driving task. Automated vehicles have the potential to increase traffic safety, efficiency and to reduce the driver’s workload. This requires systems working with absolute perfection that sense and interpret the environment correctly at any time and transform this information into adequate actions. However, such systems are not yet available today. Therefore it is necessary that the driver supervises automated vehicle control systems in order to be able to recognize automation errors and to intervene. Even if there is still a long way to go, it is worth taking a look at the ramifications an automated driving task implies.	xiii	Wolfgang Spießl	2011			computer science;electrical engineering;artificial intelligence;performance art	HCI	-23.54653198882497	-26.270158307409243	172157
79317a9742ec64f883030432ffc13ac99dd7feb5	clockmap: enhancing circular treemaps with temporal glyphs for time-series data	categories and subject descriptors according to acm ccs h 5 2 information interfaces and presentation user interfaces graphical user interfaces gui;inproceedings	Treemaps are a powerful method to visualize especially time-invariant hierarchical data. Most attention is drawn to rectangular treemaps, because their space-filling layouts provide good scalability with respect to the amount of data that can be displayed. Since circular treemaps sacrifice the space-filling property and since higher level circles only approximately match the aggregated size of their descendants, they are rarely used in practice. However, for drawing circular glyphs their shape preserving property can outweigh these disadvantages and facilitate comparative tasks within and across hierarchy levels. The interactive ClockMap visualization effectively supports the user in exploring and finding patterns in hierarchical time-series data through drill-down, semantic zoom and details-on-demand. In this study, the technique’s applicability is demonstrated on a real-world dataset about network traffic of a large computer network and its advantages and disadvantages are discussed in the context of alternative layouts.	analytic signal;data drilling;eurographics;experiment;glyph;hierarchical database model;network packet;network security;network traffic control;scalability;time series;time-invariant system;treemapping;usability testing	Fabian Fischer;Johannes Fuchs;Florian Mansmann	2012		10.2312/PE/EuroVisShort/EuroVisShort2012/097-101	computer science;theoretical computer science;world wide web;engineering drawing	HCI	-28.984632901292017	-34.516557424138206	172174
12bf0b1201ddf1b9ac493cfc24ff7573fd98521f	on geometry and transformation in map-like information visualization	maps;geographic information science;mapa;visualizacion;information geographique;geographic information;computational techniques;visual design;information mapping;geometry;transformacion;geometrie;information visualization;cartografia informacion;carte;visualization;biblioteca electronica;visualisation;visualization technique;information representation;multidimensional scaling;cartographie information;self organized map;geometria;electronic library;transformation;representation information;cognitive linguistics;bibliotheque electronique	A number of visualization techniques have been put forward that implement a map metaphor to display abstract, non-georeferenced information. This paper refers to these as map-like information visualizations that are distinguished from other information visualization approaches in a number of ways. It interprets some of the principles underlying these techniques within a framework informed by geographic information science (GIScience). Recent geographic efforts in this research area have linked ideas about the nature of geographic information to cognitive schemata proposed by cognitive linguists. This paper draws on the arguments that have emerged from those efforts regarding the nature and usefulness of geographic metaphors. It proposes to discuss particular projection techniques, like multidimensional scaling or selforganizing maps, with reference to the geometric primitives they employ. These primitives will drive the choice of geometric and symbolic transformations that are necessary to achieve a particular visualization. Designers of map-like visualizations are thus challenged to seriously consider the implications of particular computational techniques and the consequences of symbolization choices.	computation;geographic information science;geometric primitive;image scaling;information visualization;map;multidimensional scaling;organizing (structure);self-organization;self-organizing map	André Skupin	2002		10.1007/3-540-36222-3_12	computer vision;information visualization;visualization;computer science;artificial intelligence;theoretical computer science;machine learning;database;mathematics;cognitive linguistics;algorithm	HCI	-26.02938388073126	-29.612343976561345	172204
3714e5c9d03b13716f844bbb51436b534c5977b2	user-centered design of a visual data mapping tool	end user development;user centered design;information content;observational study;visual data mapping tool;observational studies;business documents;mental model;semantic analysis	Understanding the meaning and the type of a business document received by a company is important in order to determine an appropriate response. We have developed a visual tool allowing ordinary users to express mappings between arriving documents and their elements on one side and the different document types on the other. The tool is used to set up and continuously update an automatic semantic analysis mechanism which determines the document type from a set of information items contained in the document, thus allowing automatic processing associated with the types to be applied to the arriving document instances. The activities performed by end users within the visual data mapping tool are quite complex and require user-centric design to ensure tool is useful and usable. In this paper we describe the user-centric process informing the design of the tool. We conducted two workshops to discover the mental models of our users regarding the information content in their documents and their requirements towards the design of the tool. Subsequently, these findings were used to design and implement the visual data mapping tool. The resulting system was evaluated by target end users who proficiently demonstrated the usability of the developed concepts and features.	mental model;requirement;self-information;semantic analysis (compilers);usability;user-centered design	Abdallah Namoune;Usman Wajid;Nikolay Mehandjiev;Ali Owrak	2012		10.1145/2254556.2254646	human–computer interaction;computer science;data mining;world wide web;information retrieval;observational study;statistics;design document listing	HCI	-32.36610970617138	-33.59020449766924	172324
a536cee3c32a754a9f0ff40adaee73e9eab3ec1a	a data model for lifecycle management of natural hazards engineering data		Natural Hazards engineering data derives from sophisticated experimental design and contains a complex array of relationships. Representing and publishing these data is challenging, as the domain lacks a metadata schema and specialized vocabulary. To build the functionalities required to curate and publish datasets within the DesignSafe-CI, an end-to-end research data lifecycle platform (https://www.designsafe-ci.org), the curation team took a multi-step approach. First, the team undertook modeling of the research processes of seven kinds of experimental projects and corresponding hazard types that are supported by the CI. Researchers in the space were asked to draw and describe their research workflows, noting the equipment, the processes involved and their output data, the software used to analyze the data, and the documentation that are indispensable for proper data interpretation and reuse. To derive a generic experimental data model, the team analyzed these workflows and identified common processes as well as the relationships between those. The activity arrived at core metadata elements that represent the steps and methods involved in Natural Hazards projects, as well as sets of user-suggested vocabularies specific per experiment type. The resultant data model emphasizes the datasets structure and the provenance of the multiple data outputs obtained from different configurations within an experimental project. Definitions for the core metadata and vocabularies are maintained in the community metadictionary YAMZ (www.yamz.net). In the DesignSafe-CI portal the data model was implemented as interactive functions that allow users to progressively tell the story of their project by categorizing, describing, and relating data from an experiment. Using the metadata and the vocabularies users can start and stop working with their data at any time: selecting and deselecting files, adding or removing categories, and editing descriptions. As users go about curating their files in the interface, the network of relations of the experiments is formed in the back-end through a middleware metadata API. This allows rendering the experiments graphically as a tree showing the links between processes, data, and descriptive tags and narratives; helping users arrive to the decision of publishing. At the point of publication, the final data and metadata transitions to a Fedora 4 repository. For this, we mapped each of the elements and terms from the data model to three metadata schemes: Dublin Core, to describe the experimental project; PROV to represent provenancial relationships among processes and their outputs; and DataCite for metadata that will be passed in the minting of Digital Object Identifiers (DOIs). Mapping across these schemes results in multi-structured metadata that standardizes elements and vocabularies. Beyond description and contextual Proc. Int’l Conf. on Dublin Core and Metadata Applications 2017 74 information as minimum requirements to publish scientific data, this data model emphasizes the structure of the experiments and uses terms familiar to users in the domain to facilitate data reuse. Its mapping to standard schemas enable proper publication, exchange, and web exposure of the data, and allows queries that relate the components. Friendly user evaluations conducted for the preliminary release of the curation and publishing pipelines suggest that they are intuitive and will be complemented with a larger study in the Fall.		Maria Esteva;Ashley Adair;Sivakumar Ayeegoundanpalay Kulasekaran;Josue Balandrano Coronel;Craig Jansen	2017			systems engineering;data model;metadata;natural hazard;engineering;application lifecycle management	DB	-32.30684868938571	-31.039297198499312	172407
d5691daf5467a3ab65be0bf535837d6915016b2b	improving layout quality by mixing treemap-layouts based on data-change characteristics			treemapping	Joseph Bethge;Sebastian Hahn;Jürgen Döllner	2017		10.2312/vmv.20171261	computer graphics (images);computer science;visualization	EDA	-33.31093569648499	-32.74688069656304	172507
2a2a61be586b43194bea3dd15e67bad8d3ae2108	evolutionary composition using music theory and charts	music style evolutionary composition system music theory music charts artificial intelligence automatic composition ai technology evolutionary algorithms human sensation subjective feedback fitness function;evolutionary computation;genetic algorithms biological cells bars sociology statistics rhythm;creative intelligence evolutionary computation automatic composition music theory fitness function computational creativity;music artificial intelligence evolutionary computation;artificial intelligence;music	With the development of human science and technology, applications of computer are more and more comprehensive. Using artificial intelligence (AI) to drawing, thinking, and problem solving becomes a significant topic. Recently, research on automatic composition using AI technology and especially evolutionary algorithms is blooming and has received promising results. A common issue at the current evolutionary composition systems is their requirement for subjective feedback of human sensation as evaluation criterion, which is vulnerable to the fatigue and decreased sensitivity after long-time listening. This paper proposes using music theory with the information from music charts in the evaluation criterion to address this issue. Specifically, we generate the weighted rules based on music theory for the fitness function. The weights are determined according to the download numbers from music charts. These weights obtained can interpret the music style and render an objective measure of compositions. Experimental results show that the proposed method can effectively achieve satisfactory compositions.	artificial intelligence;bloom (shader effect);chart;download;evolutionary algorithm;evolutionary computation;fitness function;problem solving;resultant;software release life cycle	Chien-Hung Liu;Chuan-Kang Ting	2013	2013 IEEE Symposium on Computational Intelligence for Creativity and Affective Computing (CICAC)	10.1109/CICAC.2013.6595222	evolutionary music;interactive evolutionary computation;computer science;artificial intelligence;machine learning;pop music automation;communication	AI	-27.67985494564095	-25.906089099604305	172662
c2dac1f24a7089a0b4d69dff679acec450a07998	depth functions as a quality measure and for steering multidimensional projections	interdisciplinar;dimensionality reduction;depth functions;non parametric statistics;quality measures;visual analytics	The analysis of multidimensional data has been a topic of continuous research for many years. This type of data can be found in several different areas of science. A common task while analyzing such data is to investigate patterns by interacting with spatializations of the data in a visual domain. Understanding the relation between the underlying dataset characteristics and the technique used to provide its visual representation is of fundamental importance since it can provide a better intuition on what to expect from the spatialization. In this paper, we propose the usage of concepts from non-parametric statistics, namely depth functions, as a quality measure for spatializations. We evaluate the action of multidimensional projection techniques on such estimates. We apply both qualitative and quantitative analyses on four different multidimensional techniques selected according to the properties they aim to preserve. We evaluate them with datasets of different characteristics: synthetic, real world, high dimensional; and contaminated with outliers. As a straightforward application, we propose to use depth information to guide multidimensional projection techniques which rely on interaction through control point selection and positioning. Even for techniques which do not intend to preserve any centrality measure, interesting results can be achieved by separating regions possibly contaminated with outliers. & 2016 Elsevier Ltd. All rights reserved.	case preservation;centrality;computation;control point (mathematics);homology (biology);interaction;parallel coordinates;persistent homology;synthetic intelligence;usability testing	Douglas Cedrim;Viktor Vad;Afonso Paiva;Eduard Gröller;Luis Gustavo Nonato;Antônio Castelo Filho	2016	Computers & Graphics	10.1016/j.cag.2016.08.008	nonparametric statistics;computer vision;econometrics;visual analytics;computer science;artificial intelligence;machine learning;data mining;mathematics;statistics;dimensionality reduction	DB	-26.919559548573307	-34.79552562157277	173072
7abb683c34fb31a04d86dc382c2ee4b1d2a56c20	exploring linear projections for revealing clusters, outliers, and trends in subsets of multi-dimensional datasets		Abstract Identifying patterns in 2D linear projections is important in understanding multi-dimensional datasets. However, local patterns, which are composed of partial data points, are usually obscured by noises and missed in traditional quality measure approaches that measure the whole dataset. In this paper, we propose an interactive interface to explore 2D linear projections with visual patterns on subsets. First, we propose a voting-based algorithm to recommend optimal projection, in which the identified pattern looks the most salient. Specifically, we propose three kinds of point-wise quality metrics of 2D linear projections for outliers, clusterings, and trends, respectively. For each sampled projection, we measure its importance by accumulating the metrics of selected points. The projection with the highest importance is recommended. Second, we design an exploring interface with a scatterplot, a projection trail map, and a control panel. Our interface allows users to explore projections by specifying interested data subsets. At last, we employ three datasets and demonstrate the effectiveness of our approach through three case studies of exploring clusters, outliers, and trends.		Jiazhi Xia;Le Gao;Mizuho Hamakawa;Ying Zhao;Yi Chen;Xiaoyan Kui;Yixiong Liang	2018	J. Vis. Lang. Comput.	10.1016/j.jvlc.2018.08.003	data mining;data point;outlier;computer science;artificial intelligence;pattern recognition	DB	-27.06474642536645	-34.55830166190494	173129
4f175212597e483067af0b379ae030168f0755e2	isa 2011 workshop report: a report on the third international workshop on indoor spatial awareness: (chicago, illinois - november 1, 2011)	two dimensions;office building;indoor environment	Large indoor spaces such as office complexes and shopping malls have become an important part of our daily lives and research into indoor space is increasingly attracting attention from academia and industry. Indoor space differs from outdoor space in several important aspects such as layout, topology, constraints, or access restrictions. Techniques that are successful for outdoor spaces, for example GPS positioning, do not work well in indoor environments and require new approaches. Similarly, giving directions in outdoor spaces usually requires only two dimensions, whereas indoor navigation often involves the third dimension as office buildings and shopping malls typically have several floors.	constraint (mathematics);global positioning system;network topology;spatial–temporal reasoning	Lars Kulik;Ralf Hartmut Giiting;Hua Lu	2012	SIGSPATIAL Special	10.1145/2189403.2189407	two-dimensional space;simulation	HCI	-21.370847189757995	-31.413826870207096	173218
bd93ec086fbf2ace83828909c1c63293e720be67	composite density maps for multivariate trajectories	moving object;risk map;geographic information system;kernel density estimation;time series cartography data visualisation;time series;trajectories;domain knowledge;geographical information systems;multivariate time series;data visualisation;computer architecture;computational modeling;trajectory;image color analysis;trajectory computer architecture data visualization image color analysis computational modeling;kernel density estimate;data visualization;cartography;and raster maps trajectories kernel density estimation multivariate data geographical information systems;and raster maps;maritime use cases composite density maps multivariate trajectories multivariate time series visual analysis multiple density fields block diagram;use case;multivariate data;high risk	We consider moving objects as multivariate time-series. By visually analyzing the attributes, patterns may appear that explain why certain movements have occurred. Density maps as proposed by Scheepens et al. [25] are a way to reveal these patterns by means of aggregations of filtered subsets of trajectories. Since filtering is often not sufficient for analysts to express their domain knowledge, we propose to use expressions instead. We present a flexible architecture for density maps to enable custom, versatile exploration using multiple density fields. The flexibility comes from a script, depicted in this paper as a block diagram, which defines an advanced computation of a density field. We define six different types of blocks to create, compose, and enhance trajectories or density fields. Blocks are customized by means of expressions that allow the analyst to model domain knowledge. The versatility of our architecture is demonstrated with several maritime use cases developed with domain experts. Our approach is expected to be useful for the analysis of objects in other domains.	aggregate function;computation;customize;diagram;map;movement;physical object;subject-matter expert;time series	Roeland Scheepens;Niels Willems;Huub van de Wetering;Gennady L. Andrienko;Natalia V. Andrienko;Jarke J. van Wijk	2011	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2011.181	kernel density estimation;computer vision;computer science;trajectory;machine learning;data mining;mathematics;data visualization;statistics	Visualization	-26.635301881302837	-32.96265545095191	173267
bef924c0201c8786996498a8c4bcb39dbf4606fe	simulation-aided design of man/machine interfaces in automated industries	job stress;environmental conditions;system performance;human factors;process control;man machine interface;technical report;individual difference;computer simulation;task allocation	This paper describes the potential use of new computer simulation techniques for human factors designers in automated industrial process control. Problems in communications, operational procedures, and task allocation between the operator, computers and other machines can be identified from the simulation results and resolved. Also the simulation can show the system performance, individual operator workload with allocations of time into task classes, and provide the mechanism for testing sensitivities to learning, individual differences, motivation, environmental conditions, and job stress. Design strategies with computer simulation and coupled man-in-the-loop simulation are discussed.	computer simulation;computer-aided design;human factors and ergonomics;systems design	Gary I. Davis;James R. Buck	1981			computer simulation;human–machine interface;simulation;human–computer interaction;computer science;engineering;technical report;process control;world wide web	Robotics	-24.873219772412142	-24.231045516174692	173303
a322024aea16cc9a25d6b5340cecb51bc59f1160	multivariate image analysis in biomedicine	man machine interaction;interaction analysis;data mining;data analysis;artificial neural networks;medical image;multimodal imaging;medical imaging;explorative data analysis;clinical study;multimodal display;interactive data exploration;image analysis;high throughput;optical microscopy;artificial neural network	In recent years, multivariate imaging techniques are developed and applied in biomedical research in an increasing degree. In research projects and in clinical studies as well m-dimensional multivariate images (MVI) are recorded and stored to databases for a subsequent analysis. The complexity of the m-dimensional data and the growing number of high throughput applications call for new strategies for the application of image processing and data mining to support the direct interactive analysis by human experts. This article provides an overview of proposed approaches for MVI analysis in biomedicine. After summarizing the biomedical MVI techniques the two level framework for MVI analysis is illustrated. Following this framework, the state-of-the-art solutions from the fields of image processing and data mining are reviewed and discussed. Motivations for MVI data mining in biology and medicine are characterized, followed by an overview of graphical and auditory approaches for interactive data exploration. The paper concludes with summarizing open problems in MVI analysis and remarks upon the future development of biomedical MVI analysis.		Tim W. Nattkemper	2004	Journal of biomedical informatics	10.1016/j.jbi.2004.07.010	high-throughput screening;computer science;bioinformatics;artificial intelligence;data science;machine learning;data mining;optical microscope;data analysis;artificial neural network	ML	-28.109013373803855	-31.143961642809106	173309
4129f56f9fbb3a94a22494f54122c4c67758d6b3	basic study on navigation aid system when pilot trainee crosses sea route	human computer interaction;ship maneuvering simulator navigation aid system education marine pilot;navigation aid system;ships computer based training computerised navigation human computer interaction marine engineering;ship simulator training navigation aid system third grade pilot trainee sea route;ships;ship maneuvering simulator;computer based training;marine engineering;marine pilot;computerised navigation	This study aimed to improve the navigation skill of third grade pilot trainee in ship simulator training. In this study, navigation aid system when the pilot trainee crossed sea route in the ship simulator training was developed. The effectiveness of developed system was showed with the simulator experimental results.	experiment;simulation;u.s. route shield;user interface	Tadatsugi Okazaki;Saharu Shigeta;Toshiki Kato	2012	2012 Fifth International Conference on Emerging Trends in Engineering and Technology	10.1109/ICETET.2012.44	simulation;engineering;transport engineering;marine engineering	Robotics	-31.590375053826087	-37.620719540812395	173614
d0f62816cd3e546b80d43a3d4b29adf93e2f5e20	erkennung von fußgängerstreifen aus orthophotos		Crosswalks are an essential part of pedestrian navigation. Unfortunately, they are recorded only sparsely in OpenStreetMap. This leads to non-optimal routes. To counteract this problem, the topic of this project is to automate the process of finding crosswalks on orthophotos (satellite images). The result is an application which finds yellow crosswalks along streets and extracts their coordinates. The recognition is implemented with a neural network. It has achieved a recognition rate of over 80 % with a false discovery rate of less than 10 %. This process could be shared on a large number of computer by using a queuing system that makes the processing of so much data possible. After that, the coordinates were added to the crowdsourcing system MapRoulette. With this solution the coordinates of the crosswalks can be integrated in OpenStreetMap to help improve pedestrian navigation. It is possible to expand this solution so that the algorithm can be applied to other objects.		Stefan Keller;Severin Bühler;Samuel Kurath	2016	AGIT Journal	10.14627/537622023	geography;cartography		-22.395562635963206	-31.374966056954086	174146
50bcde2973a17bf72187ffd9583e087d44fb66d6	netlens: iterative exploration of content-actor network data	iterative refinement;user interface;usability study;information retrieval;digital library;interaction style;query refinement;information visualization;data model;incremental data exploration;content actor network data;graphic user interface;data exploration;iterative query refinement;information interfaces and presentation;user interfaces	Networks have remained a challenge for information retrieval and visualization because of the rich set of tasks that users want to accomplish. This paper offers an abstract content-actor network data model, a classification of tasks, and a tool to support them. The NetLens interface was designed around the abstract content-actor network data model to allow users to pose a series of elementary queries and iteratively refine visual overviews and sorted lists. This enables the support of complex queries that are traditionally hard to specify. NetLens is general and scalable in that it applies to any dataset that can be represented with our abstract data model. This paper describes NetLens applying a subset of the ACM Digital Library consisting of about 4,000 papers from the CM I conference written by about 6,000 authors. In addition, we are now working on a collection of half a million emails, and a dataset of legal cases	data model;digital library;email;information retrieval;network model;scalability	Hyunmo Kang;Catherine Plaisant;Bongshin Lee;Benjamin B. Bederson	2006	2006 IEEE Symposium On Visual Analytics Science And Technology	10.1057/palgrave.ivs.9500143	digital library;information visualization;computer science;machine learning;data mining;database;user interface;information retrieval	Visualization	-31.145215922958695	-31.261751714429852	174331
c4aa5030b678d77bcb942dce4eee09803b613ff1	can simulation technology enable a paradigm shift in process control?: modeling for the rest of us	virtual process;process dynamic modeling and simulation;dynamic model;chemical engineering;operator training simulators;paradigm shift;model building;process control;dynamic simulation;process simulation;control strategy;industrial engineering	Commercial process simulation software makes it easy for experts to develop very complex models with thousands of equations. But how well re these models used? Remember the admonition of Box [Box, G. E. P. (1979). Robustness in scientific model building. In R. L. Launer & G. N. ilkinson (Eds.), Robustness in statistics (pp. 201–236). New York: Academic Press], “All models are wrong, but some are useful”. Are case runs ust captured in a report and then filed away? Is the expert the only one who can run additional cases? We believe that process dynamics simulation hould be ubiquitous in chemical engineering practice and education. Undergraduate engineers should experience unit operations through a virtual rocess simulator. In industry, engineers must be able to quickly build dynamic models to study operability and design control strategies. We feel hat DuPont has undergone a paradigm shift where engineers are much more likely to use dynamic simulation as part of their day-to-day work. his paper illustrates some of the features that process dynamic simulators need to enable this paradigm shift. 2006 Elsevier Ltd. All rights reserved.	computation;computational mathematics;computer;cyclic redundancy check;differential algebraic equation;dynamic simulation;graphics;han unification;heuristic;hybrid intelligent system;john d. wiley;method of lines;numerical analysis;numerical method;operability;process modeling;programming paradigm;r language;simulation software;virtual reality	Robert K. Cox;Julie F. Smith;Yiannis Dimitratos	2006	Computers & Chemical Engineering	10.1016/j.compchemeng.2006.05.020	paradigm shift;dynamic simulation;simulation;model building;process simulation;computer science;engineering;artificial intelligence;industrial engineering;process control;chemical engineering	SE	-23.314267876049968	-25.239145337467235	174571
c00beff36f5af109ae4ad91fd9e815cce5d9754d	representation of temporal intervals and relations: information visualization aspects and their evaluation	mathematics;human computer interaction;knowledge representation temporal reasoning user interfaces;turning;application software;user interface;user study;information visualization;user interface temporal intervals temporal relations information visualization temporal reasoning system;real world application;temporal relations;human computer interaction turning user interfaces displays multimedia databases visual databases data visualization mathematics computer science application software;displays;data visualization;multimedia databases;temporal reasoning system;temporal intervals;computer science;knowledge representation;user interfaces;temporal reasoning;visual databases	A crucial component for turning any temporal reasoning system into a real-world application that can be adopted by a wide base of users is given by its user interface. After analyzing and discussing the state of the art for the visualization of temporal intervals and relations, this paper proposes three new solutions, also evaluating them with a proper user study.	information visualization;reasoning system;usability testing;user interface	Luca Chittaro;Carlo Combi	2001		10.1109/TIME.2001.930692	human–computer interaction;computer science;theoretical computer science;data mining	HCI	-31.4920792312373	-32.77398036839298	174591
88f4cc7ede66244898d0f36a40b9506db5ea40f2	augmented reality sandpit simulating ant colonies		The way ants navigate their environment and forage for food is an intricate process. A common way ant species navigate is by using pheromone chemical trails leading to and from food sources. This paper summarizes an augmented reality sandpit project that aims to show the creation and evolution of these pheromone trails within a colony in an interactive way. A complex yet accessible simulation was built to allow users to move sand in a real sandpit while seeing virtually projected images on top of the sandpit change accordingly to showcase emergent ant colony behavior. A demo video of the project is available at https://www.youtube.com/watch?v=63Kx_xVEZkk.		Lachlan M. Smith;Jon McCormack;Zixiang Xiong	2018	2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)	10.1109/ICMEW.2018.8551581		Visualization	-30.57606703861529	-27.301352950185304	174895
3b6f130b85721a5d7ca348813f4e1e96ead0412f	user modeling for adaptive visualization systems	colour vision;data structures;data visualisation;database management systems;human factors;user modelling;adaptive visualization systems;color memory;color perception;color ranking;data model;fine motor coordination;games;interactive computer tests;interpretation aim;mental rotation;problem domain/task model;resource model;scientific data;scientific visualizations;user modeling	Meaningful scientific visualizations benefit the interpretation of scientific data, concepts and processes. To ensure meaningful visualizations, the visualization system needs to adapt to desires, disabilities and abilities of the user, interpretation aim, resources (hardware, software) available, and the form and content of the data to be visualized. We suggest to describe these characteristics by four models: user model, problem domain/task model, resource model and data model. This paper makes suggestions for the generation of a user model as a basis for an adaptive visualization system.We propose to extract information about the user by involving the user in interactive computer tests and games. Relevant abilities tested are color preception, color memory, color ranking, mental rotation, and fine motor coordination.	computer hardware;data model;problem domain;user modeling	Gitta Domik;Bernd Gutkauf	1994			computer vision;scientific visualization;simulation;user modeling;computer user satisfaction;object model;visual system;data model;computational geometry;computer science;geometric modeling;operating system;mental rotation;data mining;multimedia;motor coordination;data visualization;data;computer graphics (images)	Visualization	-32.17463503070052	-32.89049102528146	175558
12590c0fe7898407aa2e84d19f0bd072463acf0d	subliminal persuasion and its potential for driver behavior adaptation	traffic accidents;tactile car seat driver behavior adaptation subliminal persuasion mental overload traffic accidents traffic hazards road safety conscious awareness cognitive load driving economy eco driving strategy vehicle mileage vibration patterns tactor elements car seat vibrotactile instructions driven assistance safety belt interface;mental overload;traffic accident;tactor elements;road accidents;sustainable transportation;real time;statistical significance;vibrotactile instructions;vehicles fuels visualization olfactory belts safety real time systems;vehicle mileage;vibrotactile stimulation driving economy safety belt interface subliminal persuasion tactile driver seat;tactile sensors belts cognition driver information systems haptic interfaces road accidents road safety road vehicles sensor fusion;traffic hazards;tactile driver seat;driven assistance;belts;eco driving strategy;tactile car seat;visualization;fuels;vibration;tactile perception;subliminal persuasion;cognition;safety;vibration patterns;car seat;tactile sensors;driving economy;motivation;drivers;vehicles;safety belt interface;cognitive load;driver behavior;sensor fusion;olfactory;haptic interfaces;road safety;vibrotactile stimulation;conscious awareness;driver information systems;driver behavior adaptation;road vehicles;real time systems	Mental overload is a problem drivers are increasingly exposed to in today's complex task of vehicle operation and is one of the causes of traffic accidents or hazards. To keep road safety high but allow for additional information to be forwarded to the driver, we propose to employ subliminal persuasion: a technique where the information is transferred below the level of conscious awareness. Thus, the driver becomes aware of the information, but his/her cognitive load is unaltered. To analyze the potential of this approach, we have designed a case study implementing an “eco-driving” strategy operating in the background. Driving economy is thereby estimated based on vehicles' mileage gathered in real time from numerous sensors in and around the car, and information is conveyed to the driver with very light, not attentively perceivable, vibration patterns originating from tactor elements integrated into the safety belt or the car seat. The main research hypothesis followed in this paper and investigated in real driving studies is that drivers would operate their vehicles more economically on vibrotactile instructions perceived inattentively, as compared with the case without any notifications. Indeed, results indicate an improvement in driving economy for segments driven with subliminal feedback compared with routes driven without assistance but not without qualifications. Statistical significance has been proven for the safety belt interface, whereas it has not been substantiated for the tactile car seat. (However, more research is needed to validate the applicability of subliminal persuasion across a wider range of driving and in-vehicle tasks.).	baseline (configuration management);compiler;device driver;experiment;notification system;sensor;simulation;subliminal channel	Andreas Riener	2012	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2011.2178838	sustainable transport;simulation;motivation;cognition;visualization;computer science;engineering;vibration;olfaction;automotive engineering;sensor fusion;statistical significance;cognitive load;computer security;tactile sensor	Robotics	-19.194917495065212	-26.760909009810547	175685
7529bbce18b1c3584ce8be65275878342f480a85	the visual funding navigator: analysis of the nsf funding information	relational data;interactive visualization;hierarchical data;visual navigation;cascaded rectangles;large scale;time series data visualization;treemaps;visual analysis;national science foundation;time series data	This paper presents an interactive visualization toolkit for navigating and analyzing the National Science Foundation (NSF) funding information. Our design builds upon an improved 2.5D treemap layout and the stacked graph to contribute customized techniques for visually navigating and interacting with the hierarchical data of NSF programs and proposals. Furthermore, an incremental layout method is adopted to handle information on a large scale. The improved treemap visualization will help to visually analyze the static funding related data and the stacked graph is utilized to analyze the time-series data. Through these visual analysis techniques, research trends of NSF, popular NSF programs are quickly identified.	2.5d;hierarchical database model;ibm notes;interaction;interactive visualization;time series;treemapping;vtk	Shixia Liu;Nan Cao;Hao Lv;Hui Su	2006		10.1145/1183614.1183778	treemapping;interactive visualization;relational database;computer science;data science;machine learning;time series;data mining;database;world wide web;information retrieval;hierarchical database model	Visualization	-28.466239070091916	-33.35218256777997	175776
20c40f60a69153775a6ee9c84e2bc66154bf9924	a methodology to predicate human-being's movement based on movement group	social network services;movement group;real data mining;mobile communications human being movement predication movement group individual mobility traffic variance cellular base stations user location;conferences social network services;data mining;base station;mobile communication;entropy;location prediction;real data mining movement group entropy location prediction;mobile computing;conferences;mobile user	Individual mobility is a popular research topic in mobile communications. One interesting question is: is the movement of human-beings independent although they may not want to follow with each other? This paper explores the phenomenon of group movement by analyzing the traffic variance among cellular base stations. We find that the entropy of group movement is less than the sum of individual's and the trajectory of group movement is somehow steady. Applying this conclusion, we proposed a methodology to predict a user's location based on group movement. Our verification based on real mobile user data shows that this method has sound accuracy.	entropy (information theory);human–computer interaction;individual mobility	Zhe Guo;Zheng Yan;Furong Wang	2010	2010 IEEE/ACM Int'l Conference on Green Computing and Communications & Int'l Conference on Cyber, Physical and Social Computing	10.1109/GreenCom-CPSCom.2010.65	simulation;geography;data mining;mobility model;world wide web	Mobile	-19.49232787998546	-35.905088666960964	175871
e63d844f6f09ddf199d013f5537654195d9dcd34	urban photograph localization using the instreet application—accuracy and performance analysis	urban environment;geolocalization;street view;safety;geotagging	The paper proposes a solution to the problem of geolocation of photographs by using an algorithm to compare their content against a geolocated database of street view images, and analyzing the performance of the algorithm. The algorithm makes it possible to pinpoint the location where a photograph was taken. In order to solve this problem, we propose an algorithm based on MPEG-7 features. The paper also describes the results of optimizing the performance of the algorithm and its accuracy. We show that the algorithm scales with the size of the reference database at least up to 130 km2, which was the largest urban area we tested the algorithm on.	algorithm;bibliographic database;central processing unit;experiment;geolocation;google street view;graphical user interface;graphics processing unit;mpeg-7;profiling (computer programming);prototype;region of interest;supercomputer;thread (computing)	Michal Grega;Seweryn Lach	2013	Multimedia Tools and Applications	10.1007/s11042-013-1538-1	simulation;computer science;operating system;geotagging;computer graphics (images)	HPC	-33.655896902972316	-35.2538455110758	175973
82ba84d993e255e96bcfe8cfbfe8adbbef198a25	name profiler toolkit		The Name Profiler Toolkit is a visual analytics system designed to enable the interactive exploration and analysis of forename and surname geographical distributions across the United States. The toolkit utilizes 78 million records from US public telephone directories, links the location data to demographic data from the US Census Bureau and Zillow, and allows users to interactively compare distributions of names and name attributes. Using the forename and surname data as a case study, the authors developed a methodology for exploring joint probability distributions of categorical spatial data and demonstrate how such data can be linked to secondary sources of information (such as income and age) to derive further insights from the data.	censuses;first name;interactivity;last name;published directory;secondary source;ultrasonography;visual analytics	Feng Wang;Brett Hansen;Ryan Simmons;Ross Maciejewski	2017	IEEE Computer Graphics and Applications	10.1109/MCG.2017.3621224	data science;data mining;visual analytics;census;data visualization;categorical variable;computer science;geographic information system;density estimation;information visualization;spatial analysis	Visualization	-26.65310240914403	-31.60063772583313	176346
c75f907d02853da2c7f2498899e64e85eb601db8	fidelity and complexity of standing group conversation simulations: a framework for the evolution of multi agent systems through bootstrapping human aesthetic judgments	complexity theory;visual fidelity standing group conversation simulations bootstrapping human aesthetic judgments rule based multi agent systems social simulations game artificial intelligence virtual environments spatio temporal dynamics building blocks parameter space bootstrapping a priori human judgment aesthetic quality genetic algorithm scorer fitness function machine learning system human evaluations optimal rule parameter combinations human scored training data rule complexity;training;multi agent systems;computational modeling;statistical analysis;machine learning;dynamics;computational complexity;bootstrapping;genetic algorithms;humans;humans complexity theory computational modeling genetic algorithms machine learning training dynamics;learning artificial intelligence;statistical analysis bootstrapping computational complexity genetic algorithms learning artificial intelligence multi agent systems	Simple rule based Multi Agent Systems are widely used in the fields of social simulations and game artificial intelligence in order to incorporate the complexity and richness of action and interaction into the characters in the virtual environments while keeping computational cost low. This paper presents an approach to synthesize the spatio-temporal dynamics of groups in standing conversation: four simple spatial rules form the building-blocks and a framework to automatically evolve rule and the parameter space by bootstrapping a-priori human judgment on the aesthetic quality of the simulations is introduced. The framework consists of a Genetic Algorithm and a scorer (fitness function) developed based on a machine learning system trained using human evaluations. The results of the study suggest that the framework is capable of deriving optimal rule and parameter combinations utilizing only a relatively small set of human scored training data. Further, the relationship between rule-complexity and visual fidelity is explored.	algorithmic efficiency;artificial intelligence (video games);evolutionary algorithm;fitness function;genetic algorithm;machine learning;rule 90;social simulation;virtual reality	Erandi Lakshika;Michael Barlow;Adam Easton	2012	2012 IEEE Congress on Evolutionary Computation	10.1109/CEC.2012.6256473	dynamics;simulation;genetic algorithm;computer science;artificial intelligence;machine learning;multi-agent system;computational complexity theory;computational learning theory;computational model;bootstrapping	AI	-26.845069745960494	-25.287686354953575	176389
1d3c80515c69c1c31234573aaf3e340b0b8b243e	3darclens: a technique for the exploration of geographical networks	geography data analysis data visualisation;i 3 3 computer graphics picture image generation line and curve generation;3d visualisation technique 3darclens technique geographical network exploration geographical datasets motion analysis spatial relations analysis 3d graph layouts;lenses three dimensional displays cameras visualization navigation data visualization electronic mail	Many geographical dataseis can be depicted as a graph layered over a map for motion and spatial relations analyses. In this work we present a novel and real-time exploration system that interactively distorts 3D graph layouts without information loss. The 3D visualisation technique is camera dependent. Therefore, it is affected by all three navigation axes, in contrast to traditional interactions in 2D spaces.	distortion;interaction;interactivity;real-time clock;visualization (graphics)	Alberto Debiasi;Bruno Simões;Raffaele de Amicis	2014	2014 IEEE Conference on Visual Analytics Science and Technology (VAST)	10.1109/VAST.2014.7042512	computer vision;multimedia;computer graphics (images)	Visualization	-29.336520866225026	-34.73232514594517	176624
0131314ce3be377848bb99a01871c4c3093cb4bd	reactive vega: a streaming dataflow architecture for declarative interactive visualization	streaming data;biological patents;systems;optimisation data flow graphs data visualisation formal specification;biomedical journals;interactive performance reactive vega streaming dataflow architecture declarative interactive visualization system architecture declarative visual design interaction design data visualization single declarative specification dataflow graph scene graph elements interaction events first class streaming data sources expressive interactive visualizations time varying scalar relational data hierarchical data compile time optimization run time optimization;text mining;europe pubmed central;interaction;citation search;information visualization;citation networks;runtime;computer architecture;indexes;visualization;research articles;abstracts;open access;data visualization;life sciences;data visualization visualization data models encoding indexes runtime computer architecture;clinical guidelines;streaming data information visualization systems toolkits declarative specification optimization interaction;optimization;full text;encoding;rest apis;declarative specification;orcids;europe pmc;biomedical research;data models;toolkits;bioinformatics;literature search	We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system.	benchmark (computing);data visualization;data-flow analysis;dataflow architecture;declarative programming;graph - visual representation;hierarchical database model;imagery;interaction design;interactive visualization;run time (program lifecycle phase);scene graph;specification;streaming media;systems architecture	Arvind Satyanarayan;Ryan Russell;Jane Hoffswell;Jeffrey Heer	2016	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2015.2467091	database index;data modeling;text mining;interaction;information visualization;visualization;computer science;theoretical computer science;data mining;database;system;programming language;data visualization;encoding;statistics	Visualization	-29.581568547756785	-33.69173521853925	177069
1682cdd6e1b4cd5d03cfc6ec6872dd91fe125586	assessing the attractiveness of places with movement data	moving objetcts trajectories;spatio temporal information analysis;attractiveness of places	Attractiveness of places has been studied by several sciences, giving rise to distinct ways for assessing it. However, the attractiveness evaluation methods currently available lack versatility to analyze diverse attractiveness phenomena in different kinds of places and spatial scales. This article describes a novel method, called M-Attract, to assess the attractiveness of interesting places, based on movement data. M-Attract examines trajectory episodes (e.g., stop, pass) that happen in places and their encompassing regions to compute their attractiveness. It is more flexible than state-of-the-art methods, with respect to land parcels, parameters, and measures used for attractiveness assessment. The proposed method has been extensively evaluated in experiments with real data, which demonstrate its contributions to analyze attractiveness of places and identify relevant phenomena in the geographic space.	algorithm;dynamic data;emoticon;experiment;information privacy;spatial scale;ti advanced scientific computer	Andre Salvaro Furtado;Renato Fileto;Chiara Renso	2013	JIDM		computer vision;geography;communication;social psychology	ML	-22.18178234492729	-34.585755742486235	177130
aae194dab228081cf911520f4bc3f7fec74e2466	helping computers understand geographically-bound activity restrictions	proceedings paper;space usage rules sur;location aware technologies	"""The lack of certain types of geographic data prevents the development of location-aware technologies in a number of important domains. One such type of """"unmapped"""" geographic data is space usage rules (SURs), which are defined as geographically-bound activity restrictions (e.g. """"no dogs"""", """"no smoking"""", """"no fishing"""", """"no skateboarding""""). Researchers in the area of human-computer interaction have recently begun to develop techniques for the automated mapping of SURs with the aim of supporting activity planning systems (e.g. one-touch """"Can I Smoke Here?"""" apps, SUR-aware vacation planning tools). In this paper, we present a novel SUR mapping technique -- SPtP -- that outperforms state-of-the-art approaches by 30% for one of the most important components of the SUR mapping pipeline: associating a point observation of a SUR (e.g. a 'no smoking' sign) with the corresponding polygon in which the SUR applies (e.g. the nearby park or the entire campus on which the sign is located). This paper also contributes a series of new SUR benchmark datasets to help further research in this area."""	benchmark (computing);cartography;human–computer interaction;location awareness;space–time tradeoff	Marcus Soll;Philipp Naumann;Johannes Schöning;Pavel Andreevich Samsonov;Brent J. Hecht	2016		10.1145/2858036.2858053	simulation;human–computer interaction;computer science;data mining;management;operations research;world wide web	HCI	-22.36870527351051	-31.39241245000687	177511
38a26e0b2ab4084d3bd11a18b9fa926d5855d0c5	checking models for activity recognition		Model checking is well established in system design and business process modelling. Model checking ensures and automatically proves safety and soundness of models used in day-to-day systems. However, the need for model checking in activity recognition has not been realised. Models for activity recognition can be built by prior knowledge. They can encode typical behaviour patterns and allow causal reasoning. As these models are manually designed they suffer from modelling errors. To address the problem, we discuss different classes of sensible properties and evaluate three different models for activity recognition. In all cases, modelling errors and inconsistencies have been found.	activity recognition;business process;causal filter;encode;model checking;multimodal interaction;process modeling;systems design	Martin Nyolt;Kristina Yordanova;Thomas Kirste	2015			model checking;computer science;machine learning;data mining;algorithm	AI	-25.051989137594187	-27.303669871859597	177541
540232bb2196b622251126b7981c17bba66b5cbe	data visualization sliders	dynamic graphics;discrete data;user interface;selection;information visualization;high interaction;data visualization;thresholding	Computer sliders are a generic user input mechanism for specifying a numeric value from a range. For data visualization, the effectiveness of sliders may be increased by using the space inside the slider as • an interactive color scale, • a barplot for discrete data, and • a density plot for continuous data. The idea is to show the selected values in relation to the data and its distribution. Furthermore, the selection mechanism may be generalized using a painting metaphor to specify arbitrary, disconnected intervals while maintaining an intuitive user-interface.	data visualization;discrete mathematics;user interface	Stephen G. Eick	1994		10.1145/192426.192472	selection;simulation;information visualization;computer science;theoretical computer science;operating system;thresholding;user interface;data visualization;computer graphics (images)	HCI	-28.991332289770547	-33.9744892556091	177612
20d4cfec3682d9135eb01c41cab1c170adb9ea9b	an architectural proposal to explore the data of a private community through visual analytic		In this document, a proposal is made to study the data that will be generated in the private and anonymous community of the WYRED project, in order to extract knowledge about how their users interact, both between them, and with the platform. To do this, it is started with the creation of a system that will generate a set of test data, as close as possible to the original. With this information and considering the impact of privacy when dealing with the data of the project, a flexible and complete architecture has been proposed for the development of interactive visualizations that will allow to visualize the previously generated data. Finally, a use case is presented where the suitability of the visual analytic is demonstrated to perform analysis of the data of the project and to extract knowledge, in a simple way.	data acquisition;data anonymization;ecosystem;in the beginning... was the command line;interactive visualization;microkernel;privacy;requirement;synchronization (computer science);test data;usability	Jorge Durán-Escudero;Francisco J. García-Peñalvo;Roberto Therón	2017		10.1145/3144826.3145398	architecture;knowledge management;data mining;test data generation;software architecture;test data;social network;computer science	DB	-30.96385537840339	-29.721105006319974	177733
df58cd2575e0f4552d408ab2ddb85e6db1b7e110	"""""""watch the document on the wall!"""" an analytical model for health care documents on large displays"""	health care documents;tiled display;high resolution;document model medical imaging;document model;telemedicine;large data sets;conceptual framework;high resolutions displays;medical image;large displays;analytical model;health care	"""Very large, high-resolutions displays, such as tiled display walls with resolutions ranging from tens of mega pixels up to 100+ mega pixels enables visualization of data in ways never before possible. Even if the technology is still emerging and faces challenges such as interaction problems and development of rendering technology, both hardware and software, the potentials for visualizing large data sets are still very exciting. Within this thematic framework, we provide an introduction to the current state of research on use of very large, high-resolution displays and a general discussion of the role of scale/size of documents as basis for discussion and a conceptual framework for analysis of """"large documents"""", specifically for medical-imaging related documents."""		Niels Windfeld Lund;Bernt Ivar Olsen;Otto J. Anshus;Tore Larsen;John Markus Bjørndalen;Gunnar Hartvigsen	2007		10.1007/978-3-540-77010-7_37	image resolution;computer science;data science;conceptual framework;database;multimedia;law;world wide web;health care;computer graphics (images)	HCI	-29.081357721503565	-30.110032336373855	177809
01980158674cfcb21eaa410c2a4ce9919147c8a3	knoocks: new visualization approach for ontologies	owl lite;visualization approach;cropcircles;information visualization;ontologies artificial intelligence;data visualisation;shared knowledge;knowledge sharing;user interface design;ontologies;knowledge blocks;user interface design information visualization knoocks owl lite ontologies requirements;ontologies requirements;knoocks;ontologies artificial intelligence data visualisation;cropcircles visualization approach ontologies knowledge sharing knowledge blocks	Ontologies are becoming popular in various communities. They give users the possibilities to understand, exchange, analyze or share knowledge of a specific domain. However ontologies can be very large and complex and therefore visualizations should help the user to understand and manipulate ontologies easily. Most visualizations concentrate on the structure of ontologies. For users, instances are often more interesting, because they represent the real world objects. This paper presents Knoocks (knowledge blocks) as a visualization approach which focuses on instances related to their structure. An evaluation which compared Knoocks with Jambalaya and CropCircles showed its benefits in visualizing instances.	ontology (information science)	Simone Kriglstein;Renate Motschnig	2008	2008 12th International Conference Information Visualisation	10.1109/IV.2008.16	idef5;computer science;knowledge management;data mining;world wide web	HCI	-30.666184494840387	-31.96354288355861	177929
031f1486b651953de4251f0d28c4b63945380d87	modelling and experimental study for automated congestion driving		Taking a collaborative approach in automated congestion driving with a Traffic Jam Assist system requires the driver to take over control in certain traffic situations. In order to warn the driver appropriately, warnings are issued (“pay attention” vs. “take action”) due to a control transition strategy that reacts to lane change manoeuvres by surrounding traffic. This paper presents the#N#outcome of a driving simulator study regarding the evaluation of a control transition strategy. The strategy was found to provide adequate support to drivers. However, driver acceptance can be increased. A refined model is proposed.	network congestion	Joseph A. Urhahne;Patrick Piastowski;Mascha C. van der Voort	2015		10.1007/978-3-319-27857-5_70	simulation;computer security	SE	-19.133178448240628	-25.73301227299556	177951
189fa973bc09cf3f3416e875fc853c3c489edeb0	multimodal trajectory predictions for autonomous driving using deep convolutional networks		Autonomous driving presents one of the largest problems that the robotics and artificial intelligence communities are facing at the moment, both in terms of difficulty and potential societal impact. Self-driving vehicles (SDVs) are expected to prevent road accidents and save millions of lives while improving the livelihood and life quality of many more. However, despite large interest and a number of industry players working in the autonomous domain, there is still more to be done in order to develop a system capable of operating at a level comparable to best human drivers. One reason for this is high uncertainty of traffic behavior and large number of situations that an SDV may encounter on the roads, making it very difficult to create a fully generalizable system. To ensure safe and efficient operations, an autonomous vehicle is required to account for this uncertainty and to anticipate a multitude of possible behaviors of traffic actors in its surrounding. In this work, we address this critical problem and present a method to predict multiple possible trajectories of actors while also estimating their probabilities. The method encodes each actor’s surrounding context into a raster image, used as input by deep convolutional networks to automatically derive relevant features for the task. Following extensive offline evaluation and comparison to state-of-the-art baselines, as well as closed course tests, the method was successfully deployed to a fleet of SDVs.	artificial intelligence;autonomous car;autonomous robot;autonomous system (internet);baseline (configuration management);convolutional neural network;multimodal interaction;online and offline;raster graphics;robotics	Henggang Cui;Vladan Radosavljevic;Fang-Chieh Chou;Tsung-Han Lin;Thi Truc Minh Nguyen;Tzu-Kuo Huang;Jeff Schneider;Nemanja Djuric	2018	CoRR		engineering;simulation;societal impact of nanotechnology;baseline (configuration management);livelihood;multitude;trajectory;artificial intelligence;robotics	AI	-20.028530102145325	-26.906869559634583	178069
3eb437fb18b2b0e65efa68d397feef7929b7d564	implementing 3d visualizations of eeg signals in artistic applications	computer graphics;medical signal processing brain computer interfaces computer graphics electroencephalography;electroencephalography data visualization neurofeedback three dimensional displays geometry visualization matrix converters;neurofeedback eeg 3d visualization opengl;brain computer interfaces;electroencephalography;opengl visualizations 3d visualizations eeg signals artistic applications low cost brain computer interfaces bci visual representations auditory representations cognitive activity neural interactivity clinicians visual feedback auditory feedback neurological disorders neuroelectric activity electroencephalography 3d geometric data artificial spatial spectral representations eeg data;medical signal processing	The increasing availability of low-cost brain-computer interfaces (BCIs) is extending the possibilities of visual or auditory representations of cognitive activity. These representations are valuable to artists who seek to develop neural interactivity in their work; to scientists who seek new ways to visualize and develop new perspectives on neural functioning; and to clinicians who can harness visual and auditory feedback for treatment of neurological disorders. We describe a method that transforms the neuroelectric activity measured with electroencephalography (EEG) into 3-dimensional geometric data. The method makes use of OpenGL in order to construct artificial spatial-spectral representations of EEG data. We provide several examples in which this method is implemented in OpenGL visualizations.	brain–computer interface;computer vision;electroencephalography;heat map;high- and low-level;image processing;interactivity;max;opengl;sampling (signal processing);the matrix;triangle strip;vertex (geometry);vertex normal;xfig	Kameron R. Christopher;Ajay Kapur;Dale Anthony Carnegie;Gina M. Grimshaw	2013	2013 28th International Conference on Image and Vision Computing New Zealand (IVCNZ 2013)	10.1109/IVCNZ.2013.6727042	brain–computer interface;computer vision;electroencephalography;computer science;multimedia;computer graphics;computer graphics (images)	Robotics	-27.959655587404168	-37.6391991400825	178098
1154555bda11f2742744c23671a85ef911012291	connected vehicle safety science, system, and framework	traffic accidents;m2m based proactive driver assistance system;mirrors;passive information visualization;m2m based neighbor map building;motorcycles trajectory cameras visualization safety mirrors;intelligent transportation system;driver behavior prediction;proactive warning mechanism m2m based proactive driver assistance system vehicle safety science intelligent transportation system sensor coverage traffic accidents driver behavior modeling driver behavior prediction m2m based neighbor map building passive information visualization;internet of things;data visualisation;visualization;motorcycles;trajectory;safety;connected vehicle;sensor coverage;driver information systems data visualisation;internet of things connected vehicle intelligent transportation system driver assistance system;proactive warning mechanism;driver information systems;cameras;vehicle safety science;driver behavior modeling;driver assistance system	In this paper, we propose a framework to develop an M2M-based (machine-to-machine) proactive driver assistance system. Unlike traditional approaches, we take the benefits of M2M in intelligent transportation system (ITS): 1) expansion of sensor coverage, 2) increase of time allowed to react, and 3) mediation of bidding for right of way, to help driver avoiding potential traffic accidents. To develop such a system, we divide it into three main parts: 1) driver behavior modeling and prediction, which collects grand driving data to learn and predict the future behaviors of drivers; 2) M2M-based neighbor map building, which includes sensing, communication, and fusion technologies to build a neighbor map, where neighbor map mentions the locations of all neighboring vehicles; 3) design of passive information visualization and proactive warning mechanism, which researches on how to provide user-needed information and warning signals to drivers without interfering their driving activities.	behavior model;connected car;human–computer interaction;information visualization;m2m (eclipse);machine to machine;proactive parallel suite;system integration	Kuan-Wen Chen;Hsin-Mu Tsai;Chih-Hung Hsieh;Shou-de Lin;Chieh-Chih Wang;Shao-Wen Yang;Shao-Yi Chien;Chia-han Lee;Yu-Chi Su;Chun-Ting Chou;Yuh-Jye Lee;Hsing-Kuo Kenneth Pao;Ruey-Shan Guo;Chung-Jen Chen;Ming-Hsuan Yang;Bing-Yu Chen;Yi-Ping Hung	2014	2014 IEEE World Forum on Internet of Things (WF-IoT)	10.1109/WF-IoT.2014.6803165	embedded system;intelligent transportation system;simulation;visualization;human–computer interaction;computer science;trajectory;computer security;internet of things;data visualization	Robotics	-22.075727233480144	-32.87329969928735	178432
efc2814861dcf820d348582a3f929e2f49b2044c	interactive data mining for large-scale image databases based on formal concept analysis	image features;image processing;personal computer;image database;data mining;large scale;visualization;human machine interface;lattice structure;formal concept analysis	In order to perform an interactive data-mining for huge image databases efficiently, a visualization inter- face based on Formal Concept Analysis (FCA) is pro- posed. The proposed interface system provides an in- tuitive lattice structure enabling users freely and eas- ily to select FCA attributes and to view different as- pects of the Hasse diagram of the lattice of a given image database. The investigation environment is im- plemented using C ++ and the OpenCV library on a personal computer (CPU = 2.13 GHz, MM = 2G B). In visualization experiments using 1,000 Corel Image Gallery images, we test image features such as color, edge, and face detectors as FCA attributes. Experi- mental analysis confirms the effectiveness of the pro- posed interface and its potential as an efficient data- mining tool.	data mining;database;formal concept analysis	Takanari Tanabata;Kazuhito Sawase;Hajime Nobuhara;Barnabás Bede	2010	JACIII	10.20965/jaciii.2010.p0303	human–machine interface;visualization;image processing;computer science;crystal structure;formal concept analysis;data science;machine learning;digital image processing;data mining;database;automatic image annotation;feature	ML	-31.214013868948502	-33.17711698077568	178760
f92f4791dbaa2683d5473c9080145db5fbe4286d	the centrality of pivotal points in the evolution of scientific networks	heart disease;betweenness centrality;change detection;research fronts;interactive visualization;information visualization;turning point;intellectual turning points;knowledge domain visualization	In this paper, we describe the development of CiteSpace as an integrated environment for identifying and tracking thematic trends in scientific literature. The goal is to simplify the process of finding not only highly cited clusters of scientific articles, but also pivotal points and trails that are likely to characterize fundamental transitions of a knowledge domain as a whole. The trails of an advancing research field are captured through a sequence of snapshots of its intellectual structure over time in the form of Pathfinder networks. These networks are subsequently merged with a localized pruning algorithm. Pivotal points in the merged network are algorithmically identified and visualized using the betweenness centrality metric. An example of finding clinical evidence associated with reducing risks of heart diseases is included to illustrate how CiteSpace could be used. The contribution of the work is its integration of various change detection algorithms and interactive visualization capabilities to simply users' tasks.	algorithm;betweenness centrality;comparison of command shells;interactive visualization;lutz pathfinder;scientific literature	Chaomei Chen	2005		10.1145/1040830.1040859	information visualization;interactive visualization;computer science;artificial intelligence;data science;machine learning;data mining;betweenness centrality;world wide web;change detection;statistics	ML	-23.76766635370818	-32.76764715362971	178876
2a05ba0aab6fac3e0ae3044f48cfbbce9c0d550c	learning inexpensive parametric design models using an augmented genetic programming technique	genetic program;genetic programming;data mining;parametric design;metamodels;meta models;knowledge elicitation;design model induction	Previous applications of genetic programming ~GP! have been restricted to searching for algebraic approximations mapping the design parameters ~e.g., geometrical parameters! to a single design objective ~e.g., weight!. In addition, these algebraic expressions tend to be highly complex. By adding a simple extension to the GP technique, a powerful design data analysis tool is developed. This paper significantly extends the analysis capabilities of GP by searching for multiple simple models within a single population by splitting the population into multiple islands according to the design variables used by individual members. Where members from different islands “cooperate,” simple design models can be extracted from this cooperation. This relatively simple extension to GP is shown to have powerful implications to extracting design models that can be readily interpreted and exploited by human designers. The full analysis method, GP heuristics extraction method, is described and illustrated by means of a design case study.	approximation;genetic programming;heuristic (computer science);information extraction;linear algebra;parametric design	Peter C. Matthews;David W. F. Standingford;Carren M. E. Holden;Ken M. Wallace	2006	AI EDAM	10.1017/S089006040606001X	genetic programming;computer science;artificial intelligence;machine learning;algorithm	HCI	-29.670870020405424	-26.638371931890113	178937
bc2ef52f40bc736a4c971194b1037a1509271634	analysis of advanced meter infrastructure data of water consumption in apartment buildings	malfunction;leaks;machine learning;advanced meter infrastructure;water	We present our experience of using machine learning techniques over data originating from advanced meter infrastructure (AMI) systems for water consumption in a medium-size city. We focus on two new use cases that are of special importance to city authorities. One use case is the automatic identification of malfunctioning meters, with a focus on distinguishing them from legitimate non-consumption such as during periods when the household residents are on vacation. The other use case is the identification of leaks or theft in the unmetered common areas of apartment buildings. These two use cases are highly important to city authorities both because of the lost revenue they imply and because of the hassle to the residents in cases of delayed identification. Both cases are inherently complex to analyze and require advanced data mining techniques in order to achieve high levels of correct identification. Our results provide for faster and more accurate detection of malfunctioning meters as well as leaks in the common areas. This results in significant tangible value to the authorities in terms of increase in technician efficiency and a decrease in the amount of wasted, non-revenue, water.	automatic identification and data capture;data mining;machine learning;smart meter	Einat Kermany;Hanna Mazzawi;Dorit Baras;Yehuda Naveh;Hagai Michaelis	2013		10.1145/2487575.2488193	water;simulation;computer science;machine learning;computer security	ML	-19.347188183753293	-32.15213829364209	179024
474d91eccc7559ba9dbe35e17a0640d83cae4bcc	making sense of emergent narratives: an architecture supporting player-triggered narrative processes	games engines real time systems user generated content registers coherence uncertainty;emergent narrative;minecraft emergent narratives player triggered narrative processes emergent games procedural content generation techniques interpretation engine interactive narratives;procedural content generation;emergent game;minecraft;interactive storytelling;minecraft interactive storytelling emergent narrative emergent game procedural content generation;interactive systems computer games	Emergent games have the particularity to allow more possible situations to emerge than progression games do. Coupled with procedural content generation techniques they also tend to increase the number of possible situations that players can encounter., However, in case the player is not creative or lucky enough these many emergent situations can have a low narrative value. This article addresses this problem through an architecture that gives players more responsibilities towards the story by allowing them to trigger Narrative Processes. A Narrative Process is a script capable of making meaningful modifications to the story in real time. Our proposed architecture relies on an Interpretation Engine whose role is to make sense of the emergent world as it is changing and inform the Narrative Processes with high level story concepts such as actors and places., We first cover the basics of emergent games and interactive narratives and then present the architecture behind the Narrative Processes as well as the Interpretation Engine. We conclude by a discussion of the potential impact of our architecture on the fundamental characteristics of emergent games.	algorithm;cluster analysis;color gradient;emergent;high-level programming language;interaction;interactive storytelling;procedural generation	Simon Chauvin;Guillaume Levieux;Jean-Yves Donnart;Stéphane Natkin	2015	2015 IEEE Conference on Computational Intelligence and Games (CIG)	10.1109/CIG.2015.7317936	simulation;computer science;emergent gameplay;multimedia	AI	-31.601330964868776	-24.662403528803328	179685
22da437d14dd2a093f96e87a2a20771b7017c623	revisiting algorithmic lateral inhibition and accumulative computation	membrane potential;bottom up;info eu repo semantics article;computer vision;working memory;lateral inhibition;ingenierias	Certainly, one of the prominent ideas of Professor Mira was that it is absolutely mandatory to specify the mechanisms and/or processes underlying each task and inference mentioned in an architecture in order to make operational that architecture. The conjecture of the last fifteen years of joint research of Professor Mira and our team at University of Castilla-La Mancha has been that any bottom-up organization may be made operational using two biologically inspired methods called “algorithmic lateral inhibition”, a generalization of lateral inhibition anatomical circuits, and “accumulative computation”, a working memory related to the temporal evolution of the membrane potential. This paper is dedicated to the computational formulations of both methods, which have led to quite efficient solutions of problems related to motion-based computer vision.	bottom-up parsing;computation;computer vision;lateral thinking;linear algebra	Antonio Fernández-Caballero;María T. López;Miguel Angel Fernández;José M. López-Valles	2009		10.1007/978-3-642-02264-7_7	simulation;membrane potential;lateral inhibition;computer science;artificial intelligence;machine learning;top-down and bottom-up design;working memory;algorithm	Robotics	-23.10735388098259	-36.98549420974554	179906
5bb311ea1801a71b6f5f2d4d3c1ef28b2ae0414a	towards utilizing gpus in information visualization: a model and implementation of image-space operations	toy industry;shader programming;programming environments;image resolution;high level abstract data type;computer graphics;interaction;abstract data types;information visualization;abstract data type;computer industry;indexing terms;low level floating point model;high performance visualization;coprocessors;visual programming;tree graphs;data visualisation;gpu shader languages;visualization technique;gpu acceleration;displays;pipelines;drag and drop interface;data visualization;drag and drop interface gpu shader languages information visualization image space operation high level abstract data type low level floating point model visual programming environment;high performance visualization gpu acceleration shader programming interaction;floating point;visual programming environment;drag and drop;image space operation;high performance;visual programming abstract data types coprocessors data visualisation;computer buffers;multivariate data;data visualization pipelines programming environments computer graphics computer buffers image resolution computer industry toy industry tree graphs displays	Modern programmable GPUs represent a vast potential in terms of performance and visual flexibility for information visualization research, but surprisingly few applications even begin to utilize this potential. In this paper, we conjecture that this may be due to the mismatch between the high-level abstract data types commonly visualized in our field, and the low-level floating-point model supported by current GPU shader languages. To help remedy this situation, we present a refinement of the traditional information visualization pipeline that is amenable to implementation using GPU shaders. The refinement consists of a final image-space step in the pipeline where the multivariate data of the visualization is sampled in the resolution of the current view. To concretize the theoretical aspects of this work, we also present a visual programming environment for constructing visualization shaders using a simple drag-and-drop interface. Finally, we give some examples of the use of shaders for well-known visualization techniques.	abstract data type;drag and drop;float;graphics processing unit;high- and low-level;imagery;information visualization;integrated development environment;interface device component;programming languages;refinement (computing);sampling - surgical action;shader;shading language;visual programming language	Bryan McDonnel;Niklas Elmqvist	2009	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2009.191	computer vision;information visualization;computer hardware;computer science;theoretical computer science;programming language;abstract data type;data visualization;statistics;computer graphics (images)	Visualization	-31.54089110981019	-28.31269308348636	180301
5f383776bca390212e9edc89ddea35bbcb3d601c	towards quantitative visual analytics with structured brushing and linked statistics	methodology and techniques;interaction techniques;i 3 6 computer graphics	Until now a lot of visual analytics predominantly delivers qualitative results—based, for example, on a continuous color map or a detailed spatial encoding. Important target applications, however, such as medical diagnosis and decision making, clearly benefit from quantitative analysis results. In this paper we propose several specific extensions to the well-established concept of linking and brushing in order to make the analysis results more quantitative. We structure the brushing space in order to improve the reproducibility of the brushing operation, e.g., by introducing the percentile grid. We also enhance the linked visualization with overlaid descriptive statistics to enable a more quantitative reading of the resulting focus+context visualization. Additionally, we introduce two novel brushing techniques: the percentile brush and the Mahalanobis brush. Both use the underlying data to support statistically meaningful interactions with the data. We illustrate the use of the new techniques in the context of two case studies, one based on meteorological data and the other one focused on data from the automotive industry where we evaluate a shaft design in the context of mechanical power transmission in cars.	brushing and linking;circular shift;color mapping;computer graphics;eurographics;interaction;john d. wiley;relative change and difference;visual analytics;whole earth 'lectronic link	S. Rados;Rainer Splechtna;Kresimir Matkovic;Mario Duras;Eduard Gröller;Helwig Hauser	2016	Comput. Graph. Forum	10.1111/cgf.12901	analytics;human–computer interaction;interactive visual analysis;computer science;data science;computer graphics (images)	Visualization	-27.83863503341377	-33.618463727212266	180515
f0cb8d0f7cbc8e801738811bfcdc480608228235	binary and polytomous responses modeling: multiple-campaign ad-targeting without personal user information		We present a vertical introduction to campaign optimization; that is, the ability to predict the user response to an ad campaign without any users' profiles on average and for each exposed ad. In practice, we present an approach to build a polytomous model, multi response, composed by several hundred binary models using generalized linear models. The theory has been introduced twenty years ago and it has been applied in different fields since then. Here, we show how we optimize hundreds campaigns and how this large number of campaigns may overcome a few characteristic caveats of single campaign optimization. We discuss the problem and solution of training and calibration at scale. We present statistical performance as {\em coverage}, {\em precision} and {\em recall} used in classification. We present also a discussion about the potential performance as throughput: how many decisions can be done per second streaming the bid auctions also by using dedicated hardware.	polytomy	Paolo D'Alberto	2015	CoRR		simulation;computer science;data science;data mining;statistics	NLP	-23.278902771861784	-30.127099000238832	180658
88059f838475afb02afcd6ed84bbdcec844770ed	datameadow: a visual canvas for analysis of large-scale multivariate data	informatics computer and systems science;cognitive science;dynamic query slider;starplot;informationsteknologi;informatik data och systemvetenskap;human computer interaction;small multiples multivariate data visual analytics parallel coordinates dynamic queries iterative analysis starplot;information systems;direct manipulation interface;direct manipulation;informationsbehandling;information technology;large scale systems data visualization visual analytics multidimensional systems filtering history mice bars protocols feedback;computer and information science;data processing;multidimensional data;user interfaces data analysis data structures data visualisation interactive systems;information visualization;small multiples;software engineering;direct manipulation interface data meadow visual canvas large scale multivariate data analysis visual analytics data visualization dataroses graphical set representation dynamic query slider;data visualisation;natural sciences;data analysis;large scale;informatics and systems science;informatik och systemvetenskap;data och systemvetenskap;datalogi;data dependence;multidimensional datasets;data structures;data meadow visual canvas;informatik;dynamic query;information processing;data visualization;dynamic queries;dataroses graphical set representation;datavetenskap;computer and systems science;iterative analysis;informatics;starplots;progressive analysis;computer science;programvaruteknik;large scale multivariate data analysis;visual analytics;multivariate visualization;interactive systems;user interfaces;informationsteknik;multivariate data;kognitionsvetenskap;databehandling;parallel coordinates	Supporting visual analytics of multiple large-scale multidimensional datasets requires a high degree of interactivity and user control beyond the conventional challenges of visualizing such datasets. We present the DataMeadow, a visual canvas providing rich interaction for constructing visual queries using graphical set representations called DataRoses. A DataRose is essentially a starplot of selected columns in a dataset displayed as multivariate visualizations with dynamic query sliders integrated into each axis. The purpose of the DataMeadow is to allow users to create advanced visual queries by iteratively selecting and filtering into the multidimensional data. Furthermore, the canvas provides a clear history of the analysis that can be annotated to facilitate dissemination of analytical results to outsiders. Towards this end, the DataMeadow has a direct manipulation interface for selection, filtering, and creation of sets, subsets, and data dependencies using both simple and complex mouse gestures. We have evaluated our system using a qualitative expert review involving two researchers working in the area. Results from this review are favorable for our new method.		Niklas Elmqvist;John T. Stasko;Philippas Tsigas	2007		10.1109/VAST.2007.4389013	computer vision;multivariate statistics;parallel coordinates;computer science;data science;machine learning;data mining;database;data analysis;user interface;informatics;information system;data visualization;statistics	HCI	-28.458753788252697	-33.45303571232626	180908
312d79227f273320b6c43f2dcf184ccecc44c3a8	managing uncertainty: modeling users in location-tracking applications	managing uncertainty;moving object;belief networks;user modelling;query processing tracking belief networks ubiquitous computing uncertainty handling user modelling;location tracking;uncertainty modeling;query processing;uncertainty management;uncertainty handling;uncertainty target tracking costs pervasive computing senior citizens advertising road accidents layout application software predictive models;user modeling;ubiquitous computing;location tracking applications;ru application uncertainty management technique location tracking application belief networks pervasive computing user modelling human controlled moving object roving user;tracking;belief network;bayesian networks	Uncertainty-management techniques that ignore the distinctiveness of individuals will either fail or incur a high cost in system resources. Location-tracking applications must consider the individual user's characteristics, habits, and preferences to estimate his or her location more effectively. We discuss human-controlled moving objects, called roving users. A typical RU application tracks each RU's location to answer queries about the person's whereabouts at any particular time. We also discuss about the belief networks that models the user habits. We also discuss about the belief networks that models the user habits.	bayesian network;location-based service	Wegdan Abdelsalam;Yasser Ebrahim	2004	IEEE Pervasive Computing	10.1109/MPRV.2004.1321030	simulation;human–computer interaction;computer science;knowledge management;bayesian network;data mining;ubiquitous computing	HCI	-29.8756727921587	-24.475398337157916	181319
046517f9727e3a3b081b0907f9156828aa5a6587	facilitating interactive search and navigation in videos	video navigation;interactive video search;interactive video;interactive search;video exploration;video browsing	We present a tool that can efficiently facilitate interactive navigation and search in videos. In addition to browsing a video by shots it also allows a user to navigate through a video with extended seeker bars showing time-related content abstractions. Users having a rough knowledge about the content characteristics of scenes to be found can efficiently use these extended seeker bars to quickly find these scenes by interactive navigation. Moreover, users can easily perform similarity queries by utilizing content knowledge that has been gained during the browsing/navigation process. These queries can also be stored and reused for search in other videos having similar/same content. Furthermore, the tool can execute many queries at once and visualize the results as semantic events in a different seeker bar. Our tool provides a real alternative for situations where a user currently needs to employ a common video player for the task of search and navigation.	raster bar	Klaus Schöffmann	2010		10.1145/1873951.1874300	computer vision;computer science;multimedia;world wide web	HCI	-31.279393839075716	-34.0177472555769	181331
ed763186e804801cd1dbe83010e7a2f9e92275ea	system for monitoring and guarding vehicles on parking areas		The paper deals with design and realization of the system monitoring vehicles at the open type of parking area. Design and realization of such a system, with the use of video-cameras and relevant SW and HW equipment, help to warn the vehicle’s owner about movement of his/her vehicle (in an adverse case of its theft). Information about movement is sent by email or SMS message. The system analyzing images from cameras has been implemented on the basis of the approved utility model PUV 96-2015 “Automated system for monitoring and guarding vehicles on parking areas” utilizing knowledge about image processing and computer vision. The system has been implemented and tested within the University of Žilina Campus. The system is available to the end users in the form of Internet web-page which makes it accessible from any ICT device.		Dusan Nemec;Ales Janota;Rastislav Pirník	2017		10.1007/978-3-319-66251-0_25	parking guidance and information;image processing;the internet;computer security;end user;short message service;system monitoring;information and communications technology;computer science	HCI	-22.235181744546946	-28.95254743132773	181378
2db77c495a0b607f8cf09fe855ea607126d9ff2c	interactively exploring logs and mining models with clustering, filtering, and relabeling		Real-life event logs often contain many data quality issues, which obstruct existing discovery algorithms from discovering meaningful process models and process analysts from conducting further process analysis. In this paper, we present an integrated tool that provides support for dealing with three of these data issues: logs comprising recordings of multiple heterogeneous variants of a process; traces containing multitude of deviating events in an infrequent context; event labels being imprecise. The tool is called Log to Model Explorer and helps users in interactively and iteratively exploring and preprocessing a log by clustering, filtering and event relabeling, enabling them to discover more meaningful process models.	algorithm;cluster analysis;data quality;graph labeling;interactivity;preprocessor;tracing (software)	Xixi Lu;Dirk Fahland;Wil M. P. van der Aalst	2016			data mining;filter (signal processing);cluster analysis;preprocessor;computer science;data quality;process modeling	HCI	-25.484283345961355	-34.01606475279059	181608
b3f86948a0ea21049ff3f294ee2e3cbf269c9b1b	crime data mining: combining socio-economic and spatial analysis		Public security is an important issue for a society. With the massive increase in electronic data availability over the last few years, characterising and predicting crime has become a task that can be approached using different data mining techniques. However, previous studies have concentrated on the spatial patterning of crimes without investigating potential predictors or causes. In this paper, we use a range of data mining techniques to analyse criminality using a data base of crimes from the municipality of General de Escobedo in Nuevo León, México. We show that different types of crime domestic violence, residential robberies and business robberies have quite different profiles, both from the point of view of the characteristics of the robberies themselves and from the underlying socio-demographic and socio-economic factors that influence them. We create predictive models for these three crime types and discuss how the results can be used to predict and reduce crime risk.	data mining;database;point of view (computer hardware company);predictive modelling;spatial analysis	Ricardo Ruíz;Christopher R. Stephens;Santiago Roel Rodríguez	2015	Research in Computing Science		data mining	ML	-19.251298246801966	-33.04603825920528	181634
46fce6667a07578ae0c85cf790b936ed566c3759	using gameplay semantics to procedurally generate player-matching game worlds	adaptive game worlds;semantics;procedural content generation	The use of procedural content generation to support adaptive games is starting to gain momentum in current research. However, there are still many open issues to tackle, namely the reusability of methodologies. Our research focuses on reusable and generic methods for linking the procedural generation of 3D game worlds with gameplay, as measured by player modelling techniques. As the interface for that link, we propose the use of gameplay semantics, a knowledge representation technique that allows our case-based generator to match content to player models. We present and discuss the implementation of our proposed method in an existing game, Stunt Playground. Gameplay semantics is created by designers in a generic way and is then used to procedurally generate player-matching Stunt Playground game worlds, both at the design and game stage. Current results show that our approach can automatically create such adaptive game content, thus effectively bridging game world designers, procedural generation and gameplay.	bridging (networking);game semantics;knowledge representation and reasoning;procedural generation	Ricardo Lopes;Tim Tutenel;Rafael Bidarra	2012		10.1145/2538528.2538531	first playable demo;game design;simulation;level design;computer science;theoretical computer science;emergent gameplay;game mechanics;game art design;multimedia;game design document	HCI	-28.097391380669563	-25.661439940445003	181713
c68284141f91eca44334fbaaddb722c1e9d1cd44	implementation of a real-time data driven system to provide queue alerts to stakeholders		Queueing frequently occurs in advance of interstate work zones, and back-of-queue crashes are of concern to all agencies. This paper reports on a real-time, probe vehicle data-based system for generating texts/emails to alert the Indiana Department of Transportation to interstate work zone queueing in real-time. Six work zones were identified for this study. When average speeds drop below 72 km/h (45 MPH), queue monitoring algorithms are triggered and an alert is sent to selected individuals. Still camera images, work schedules, and crash reports were used to ground-truth the alert system. During the summer of 2016, this algorithm was first deployed in 7 work zones with 13 users receiving text messages. On average, there were 8 text messages per day per work zone. The paper concludes by recommending the use of probe vehicle data for queue monitoring due to the scalable, cost effective nature of the technology and the ability to rapidly deploy monitored areas. Ongoing work is focused on improving the robustness of the algorithm and providing severity filtering to reduce the number of alerts for senior managers interested in receiving information on only the most severe conditions.	algorithm;content-control software;email;google summer of code;ground truth;real-time computing;real-time data;real-time locating system;real-time transcription;scalability	Michelle Mekker;Howell Li;John McGregor;Mischa Kachler;Darcy M. Bullock	2017	2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2017.8317648	real-time data;real-time computing;simulation;robustness (computer science);still camera;scalability;queueing theory;schedule;engineering;queue;crash	Robotics	-21.75496104998927	-28.007530561438728	182048
c592377cda11cdbd3acca2717603398358bb2e56	visualizing and exploring software version control repositories using interactive tag clouds over formal concept lattices		Context: version control repositories contain a wealth of implicit information that can be used to answer many questions about a project’s development process. However, this information is not directly accessible in the repositories and must be extracted and visualized.#R##N##R##N#Objective: the main objective of this work is to develop a flexible and generic interactive visualization engine called ConceptCloud that supports exploratory search in version control repositories.#R##N##R##N#Method: ConceptCloud is a flexible, interactive browser for SVN and Git repositories. Its main novelty is the combination of an intuitive tag cloud visualization with an underlying concept lattice that provides a formal structure for navigation. ConceptCloud supports concurrent navigation in multiple linked but individually customizable tag clouds, which allows for multi-faceted repository browsing, and scriptable construction of unique visualizations.#R##N##R##N#Results: we describe the mathematical foundations and implementation of our approach and use ConceptCloud to quickly gain insight into the team structure and development process of three projects. We perform a user study to determine the usability of ConceptCloud. We show that untrained participants are able to answer historical questions about a software project better using ConceptCloud than using a linear list of commits.#R##N##R##N#Conclusion: ConceptCloud can be used to answer many difficult questions such as “What has happened in this project while I was away?” and “Which developers collaborate?”. Tag clouds generated from our approach provide a visualization in which version control data can be aggregated and explored interactively.	software versioning;tag cloud;version control	Gillian J. Greene;Marvin Esterhuizen;Bernd Fischer	2017	Information & Software Technology	10.1016/j.infsof.2016.12.001	world wide web;exploratory search;data mining;computer science;software;software versioning;visualization;tag cloud;usability;formal concept analysis;interactive visualization	HCI	-31.517641050244382	-33.305466309080906	182336
248959e2efc03564fb257b75b590779213723e4e	towards unambiguous edge bundling: investigating confluent drawings for network visualization	topology;clutter;complex networks;power graph;graph theory data visualisation;systematics;network visualization;bundling network visualization edge compression confluent power graph;bundling;layout;confluent;visualization;edge compression;network analysis unambiguous edge bundling network visualization confluent drawings node link diagrams network connectivity edge bundling techniques edge clutter coalescing lines spatial proximity undirected networks layout method sand box environment interactive exploration edge compression techniques power graphs metro style;australia;visualization clutter layout australia topology systematics complex networks	In this paper, we investigate Confluent Drawings (CD), a technique for bundling edges in node-link diagrams based on network connectivity. Edge-bundling techniques are designed to reduce edge clutter in node-link diagrams by coalescing lines into common paths or bundles. Unfortunately, traditional bundling techniques introduce ambiguity since edges are only bundled by spatial proximity, rather than network connectivity; following an edge from its source to its target can lead to the perception of incorrect connectivity if edges are not clearly separated within the bundles. Contrary, CDs bundle edges based on common sources or targets. Thus, a smooth path along a confluent bundle indicates precise connectivity. While CDs have been described in theory, practical investigation and application to real-world networks (i.e., networks beyond those with certain planarity restrictions) is currently lacking. Here, we provide the first algorithm for constructing CDs from arbitrary directed and undirected networks and present a simple layout method, embedded in a sand box environment providing techniques for interactive exploration. We then investigate patterns and artifacts in CDs, which we compare to other common edge-bundling techniques. Finally, we present the first user study that compares edge-compression techniques, including CD, power graphs, metro-style, and common edge bundling. We found that users without particular expertise in visualization or network analysis are able to read small CDs without difficulty. Compared to existing bundling techniques, CDs are more likely to allow people to correctly perceive connectivity.	algorithm;anatomy, regional;bigraph;clutter;compression;confluence (abstract rewriting);confluent and reticulate papillomatosis;diagram;drawings (art);embedded system;embedding;graph (discrete mathematics);graph - visual representation;graph drawing;human-readable medium;imagery;modal logic;morphologic artifacts;network topology;node - plant part;numerous;planar graph;scientific visualization;social network;sparse matrix;stars, celestial;trees (plant);usability testing	Benjamin Bach;Nathalie Henry Riche;Christophe Hurter;Kim Marriott;Tim Dwyer	2017	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2016.2598958	confluency;layout;combinatorics;visualization;computer science;theoretical computer science;clutter;distributed computing;systematics;graph drawing;complex network	Visualization	-29.151580524383913	-35.542376322664936	182370
2f629906117f8cbd0451ebe4bf807445f048f79a	brain power	nervous system;layout;neuroscience;shape;retina;spatiotemporal phenomena;biological information theory;cerebral cortex;artificial intelligence;neurons	2 1094-7167/03/$17.00 © 2003 IEEE IEEE INTELLIGENT SYSTEMS history. AI pioneers saw the promise of looking to real nervous systems for inspiration—von Neumann thought that this would lead us to new computation methods that depend more on correlations than numerical accuracy. Many initiatives are underway to strengthen this relationship. Perhaps recent advances in neuroscience will inspire our construction of artificial systems by increasing our understanding of the biology of natural ones. I have touched on this theme in previous editorials, but I was struck again at a recent workshop by how much we might learn from one another.	artificial intelligence;computation;ieee intelligent systems;numerical analysis	Nigel Shadbolt	2003	IEEE Intelligent Systems	10.1109/MIS.2003.1200718	layout;shape;computer science;nervous system;cognitive science	Embedded	-23.15301090699901	-37.010668150675485	182648
e71200257c95d0e37d3e95107716ea88470f747b	spatial data mining for highlighting hotspots in personal navigation routes	kernel density estimation;density based spatial clustering of applications with noise dbscan;spatial data mining;gps traces;clustering algorithms;activity dairy data	"""Rapid developments in the availability and access to spatially referenced information in a variety of areas have induced the need for better analytical techniques to understand the various phenomena. In particular, the authors’ analysis is an insight into a wealth of geographical data collected by individuals as activity dairy data. The attention is drawn on point datasets corresponding to GPS traces driven along a same route in different days. In this paper, the authors explore the presence of clusters along the route, trying to understand the origins and motivations behind that to better understand the road network structure in terms of ‘dense’ spaces along the network. Therefore, the attention is focused on methods to highlight such clusters and see their impact on the network structure. Spatial clustering algorithms are examined (DBSCAN) and a comparison with other non-parametric density based algorithm (Kernel Density Estimation) is performed. Different tests are performed over the urban area of Trieste (Italy), considering both multiple users and different origin/destination journeys. DOI: 10.4018/jdwm.2012070103 46 International Journal of Data Warehousing and Mining, 8(3), 45-61, July-September 2012 Copyright © 2012, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. of clusters along the route, trying to understand the origins and motivations behind that in order to better understand the road network structure in terms of ‘dense’ spaces along the network; these representing road congestion, rather than the presence of junctions or other factors affecting individual mobility. In this paper the attention is therefore focused on methods to highlight such clusters and see their impact on the network structure. Spatial clustering algorithms are examined (DBSCAN) and a comparison with other nonparametric density based algorithm (Kernel Density Estimation) is performed. Tests are performed on different journeys and by different users over the urban area of Trieste (Italy). The paper is organized as follows. In the paragraph “Spatial data mining” a survey of the characteristics of Data Mining techniques and the challenges of their application and performances in spatial environments are reported. A paragraph on “Time geography” follows, focusing on the definition of this research topic, in which people’s behaviors in space are also referred to a particular time and therefore on how today’s computational power, GIS software and location applications on personal devices to collect positional and temporal data allows the analysis of people’s movement over space and time, also rising new issues in terms of methods and instruments to be implemented. In the chapter on “Spatial clustering algorithms” the attention is drawn on the algorithms used in this paper for the analysis on individual personal data, in particular the DBSCAN algorithm and the Kernel Density Estimation. A gallery of applications of the two procedures follows in “Some comparisons between DBSCAN and KDE,” where the routes taken in different days are analyzed and compared in application of the two methods. In the “Conclusions” an overall comment is provided, while in the end of the paper some “Future research directions” are outlined. SPATIAL DATA MINING In recent years geographic data collection devices linked to location-aware technologies such as the global positioning system allow researchers to collect huge amounts of data. Other devices such as cell phones, in-vehicle navigation systems and wireless Internet clients can capture data on individual movement patterns. This explosive growth of spatial data and widespread use of spatial databases emphasize the need for the automated discovery of spatial knowledge. The process of extracting information and knowledge from these massive geo-referenced databases is known as Geographic Knowledge Discovery (GKD) or Spatial Data Mining. It may be useful to understand spatial data, to discover relationships between spatial and non spatial data, to build knowledge-bases. This has a wide application in Geographic Information Systems (GIS), image analysis and other different areas where spatial data are used. The nature of geographic entities, their complexity, relationships, and data means that standard Knowledge Discovery in Databases (KDD) or Data Mining techniques are not sufficient (Koperski, 1998) or at least their usefulness is limited. In fact the data inputs of Spatial Data Mining include extended objects such as points, lines, and polygons. Specific reasons are the nature of geographic space, the complexity of spatial objects and relationships as well as their transformations over time, the heterogeneous and sometimes ill-structured nature of geo-referenced data, and the nature of geographic knowledge. Spatial objects are embedded in a continuous space that serves as a measurement framework for all other attributes. This framework generates a wide spectrum of implicit distance, directional and topological relationships, particularly if the objects are greater than one dimension (such as lines, polygons 15 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/spatial-data-mining-highlightinghotspots/67573?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Library Science, Information Studies, and Education, InfoSci-Select, InfoSci-Knowledge Discovery, Information Management, and Storage eJournal Collection, InfoSci-Surveillance, Security, and Defense eJournal Collection, InfoSci-Journal Disciplines Engineering, Natural, and Physical Science, InfoSci-Journal Disciplines Computer Science, Security, and Information Technology, InfoSciSelect. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2"""	algorithm;client (computing);cluster analysis;dbscan;data mining;embedded system;entity;geographic information system;global positioning system;image analysis;individual mobility;information science;kernel density estimation;librarian;library science;location awareness;mobile phone;multi-user;network congestion;performance;personally identifiable information;spatial database;time geography;tracing (software);web page	Gabriella Schoier;Giuseppe Borruso	2012	IJDWM	10.4018/jdwm.2012070103	kernel density estimation;computer science;data science;machine learning;data mining;cluster analysis	ML	-19.221080818790025	-34.79468442733983	182736
a7fcdeb9188cb0f69d4c46bd01c79d0c6bc49b71	identifying nearly equally spaced isosurfaces for volumetric data sets		Isosurfaces are an important visual representation of volumetric data sets and isosurface extraction and rendering remains one of the most popular methods for volume visualization. Previous works identify a small set of representative isosurfaces from a set of sample ones, providing a concise description of the underlying volume. However, these methods do not lend themselves to equally spaced isosurfaces, i.e., keeping the same distance between neighboring isosurfaces, which can be advantageous from the user’s perspective in terms of visual summarization and interactive exploration. In this paper, we present a new solution that efficiently identifies a set of nearly equally spaced isosurfaces for a given volume data set. Our approach includes an estimation stage of linear interpolation and a refinement stage of binary search in order to balance the tradeoff between quality and performance. The refinement stage can incorporate spike and/or jump treatments to possibly improve the convergence. Experimenting with multiple data sets of different sizes and characteristics, we perform both quantitative and qualitative studies, demonstrate the efficiency and effectiveness of our approach, and summarize our findings.	action potential;binary search algorithm;experiment;isosurface;linear interpolation;refinement (computing);scientific visualization	Martin Imre;Jun Tao;Chaoli Wang	2018	Computers & Graphics	10.1016/j.cag.2018.02.002	computer science;computer vision;rendering (computer graphics);automatic summarization;binary search algorithm;small set;linear interpolation;machine learning;visualization;isosurface;artificial intelligence;data set	Visualization	-27.03982886725996	-35.46812649265133	183111
dd4e97c9e302981d27c4de710628dde397651178	development of a visualization method for motion-characteristic distribution of japanese folk dances - a case study of the bon odori dance		This study proposes a method to systematically visualize the motion-characteristic distribution of Japanese folk dances passed down in a certain area. This is accomplished by adopting an approach that involves analyzing motion-capture data collected from the dances. The visualization process in the proposed method consists of three stages. The first stage is the modeling of the relationship among motion-capture data, folk dances, and the settlements in which folk dances have been passed down. This relationship is modeled as a hierarchical-structure model. The second stage is the extraction of motion characteristics from motion-capture data streams. The motion characteristics of each data stream are summarized as a fourteen-dimensional feature vector. The third stage is the visualization of the motion-characteristic distribution of the dances investigated. Each of the dances is mapped on a two-dimensional scatter plot in accordance with the feature quantities obtained in the second stage. Information on the hierarchicalstructure model constructed in the first stage is also displayed. The analysis results for the distribution of Bon Odori dances showed that the proposed method could have almost completely visualized the motion-characteristic distribution of sample folk dances, while also demonstrating consistency with the knowledge of the dances acquired in the previous studies.	feature vector;motion capture	Takeshi Miura;Takaaki Kaiga;Takeshi Shibata;Madoka Uemura;Katsubumi Tajima;Hideo Tamamoto	2018	JIP	10.2197/ipsjjip.26.74	visualization;multimedia;folk dance;theoretical computer science;dance;computer science	Visualization	-25.79194452233171	-33.187135489571745	183581
44cb1910be9b2362b2b6bb757f4eeab62546c177	conceptualizing visual uncertainty in parallel coordinates	visual uncertainty analysis;data type;visual representation;visual form;conceptualizing visual uncertainty;effective visual representation;information visualization pipeline;data-space uncertainty;different effect;visual uncertainty;different perspective;parallel coordinates	Uncertainty is an intrinsic part of any visual representation in visualization, no matter how precise the input data. Existing research on uncertainty in visualization mainly focuses on depicting data-space uncertainty in a visual form. Uncertainty is thus often seen as a problem to deal with, in the data, and something to be avoided if possible. In this paper, we highlight the need for analyzing visual uncertainty in order to design more effective visual representations. We study various forms of uncertainty in the visual representation of parallel coordinates and propose a taxonomy for categorizing them. By building a taxonomy, we aim to identify different sources of uncertainty in the screen space and relate them to different effects of uncertainty upon the user. We examine the literature on parallel coordinates and apply our taxonomy to categorize various techniques for reducing uncertainty. In addition, we consider uncertainty from a different perspective by identifying cases where increasing certain forms of uncertainty may even be useful, with respect to task, data type and analysis scenario. This work suggests that uncertainty is a feature that can be both useful and problematic in visualization, and it is beneficial to augment an information visualization pipeline with a facility for visual uncertainty analysis.	categorization;glossary of computer graphics;information visualization;parallel coordinates;taxonomy (general)	Aritra Dasgupta;Min Chen;Robert Kosara	2012	Comput. Graph. Forum	10.1111/j.1467-8659.2012.03094.x	computer vision;uncertainty analysis;computer science;artificial intelligence;data mining	Visualization	-27.302508191023367	-34.14918627569397	183931
10338a8728d4d1bff6d4fe0673481e363f9d3c90	random methods for fast exploration of the raw video material	databases;video databases;hierarchical structure;user evaluation;database tree structure;database access method;yarn;visual mining tool;probability;raw video material;database exploration;browsing;database;video retrieval;video retrieval data mining random processes tree data structures video databases;interactive method;usa councils;tree data structures;data mining;hierarchical organisation;video content retrieving;navigation;visualization;user interactive navigational support;raw materials visual databases multimedia databases displays yarn space technology image databases data visualization expert systems application software;visualisation;random processes;exploration;database tree structure random visualization method raw video material database access method visual mining tool user interactive navigational support video browsing system video content retrieving database exploration;random visualization method;direction selectivity;rushes;access method;random access;hierarchical organisation rushes database exploration browsing visualisation;video browsing system	In this work we propose a visualization and access method for exploring a database of raw video material, where the span of information stored can be huge and difficult to understand at a glance. Developed visual mining tool presents the overview of the hierarchically structured repository in a intuitive way and provides interactive navigational support for the user. Browsing through the un-annotated content is enabled by two complementary interactive methods, a direct selection and a random access, both supported by visual display of the preview nodes. User evaluation aims at demonstrating how the hierarchical random visualization assists the process of accessing and retrieving content relevant to the user.	browsing;cluster analysis;database;hierarchical clustering;random access;sequential access;statistical model;tree structure;uncompressed video	Tijana Janjusevic;Sergio Benini;Ebroul Izquierdo;Riccardo Leonardi	2009	2009 20th International Workshop on Database and Expert Systems Application	10.1109/DEXA.2009.80	stochastic process;visualization;computer science;data mining;database;multimedia;programming language;world wide web	Visualization	-30.40576247371549	-33.01271803509294	183953
d2f04d254226f0c068b162a15497ecea14dce02a	groups and group-instantiations in mobile communities - detection, modeling and applications	information space;mobile communication;social groups;similarity measure	The paper investigates techniques for the detection and modeling of groups of people in a mobile community also interacting in the real world. In this scenario, the concept of contextual manifestations or instantiations of existing social groups is of special significance. In view of detecting and modeling of groups and their instantiations, several examples for classes of data (locationand velocity-data, natural language interest phrases and text-based communication-data) in the information spaces of mobile communities are investigated. Similarity measures between people are constructed and verified by empiric means or through stochastic simulation. On this basis, special clustering approaches for the detection and modeling of groups are developed and tested. The paper concludes with a discussion on possible applications for the methods which have been developed.	cluster analysis;interaction;natural language;sensor;simulation;text-based (computing);velocity (software development)	Georg Groh	2007			social group;social science;mobile telephony;computer science;artificial intelligence;data mining	Web+IR	-19.604143698852678	-36.090447247406495	184014
66fcd9beec1225a76c6162e4fe79535933ab904d	creating a multi-purpose first person shooter bot with reinforcement learning	learning;reinforcement learning;rule based;learning artificial intelligence computer games;multipurpose first person shooter bot;artificial intelligent;accuracy;distance measurement;navigation;games;artificial intelligence;artificial intelligence reinforcement learning multipurpose first person shooter bot;first person shooter;learning artificial intelligence;artificial intelligence navigation network topology statistics testing displays machine learning multiagent systems robots machine learning algorithms;computer games;obituaries	Reinforcement learning is well suited to first person shooter bot artificial intelligence as it has the potential to create diverse behaviors without the need to implicitly code them. This paper compares three different reinforcement learning approaches to create a bot with a universal behavior set. Results show that using a hierarchical or rule based approach, combined with reinforcement learning, is a promising solution to creating first person shooter bots that offer a rich and diverse behavior set.	artificial intelligence;experiment;finite-state machine;first person shooter;first-person (video games);floating point systems;hard coding;map;multi-purpose viewer;portals;rl (complexity);reinforcement learning;the fight: lights out	Michelle McPartland;Marcus Gallagher	2008	2008 IEEE Symposium On Computational Intelligence and Games	10.1109/CIG.2008.5035633	games;navigation;error-driven learning;simulation;computer science;artificial intelligence;machine learning;accuracy and precision;reinforcement learning	AI	-26.709801708091472	-25.114914314944016	184171
85e342ddc703674d8c565544c2a9292e120b0d5a	noizcrowd: a crowd-based data gathering and management system for noise level data		Many systems require access to very large amounts of data to properly function, like systems allowing to visualize or predict meteorological changes in a country over a given period of time, or any other system holding, processing and displaying scientific or sensor data. However, filling out a database with large amounts of valuable data can be a difficult, costly and time-consuming task. In this paper, we present techniques to create large amounts of data by combining crowdsourcing, data generation models, mobile computing, and big data analytics. We have implemented our methods in a system, NoizCrowd, allowing to crowdsource noise levels in a given region and to generate noise models by using state-of-the-art noise propagation models and array data management techniques. The resulting models and data can then be accessed using a visual interface.	android;big data;crowdsourcing;database;interpolation;management system;map;missing data;mobile app;mobile computing;mobile device;noise (electronics);online and offline;real-time clock;scalability;smartphone;software propagation	Mariusz Wisniewski;Gianluca Demartini;Apostolos Malatras;Philippe Cudré-Mauroux	2013		10.1007/978-3-642-40276-0_14	computer science;data science;data mining;database	DB	-21.526467978378342	-32.79357353366137	184267
067ed3dee11aaa75ee02d69bd62b9fa8128cbf03	a visual analytics approach for exploring individual behaviors in smartphone usage data	smartphone usage data;smart phones data analysis human factors mobile computing;personal visualization individual behaviors smartphone usage data visual analytics;data visualization visual analytics mobile communication market research data mining layout color;personal visualization;visual analytics;smart phone usage data visual analytics individual behavior pattern;individual behaviors	The percentage of individuals frequently using their smartphones in work and life is increasing steadily. The interactions between individuals and their smartphones can produce large amounts of usage data, which contain rich information about smartphone owners usage habits and their daily life. In this paper, a visual analytic tool is proposed to discover and understand individual behavior patterns in smartphone usage data. Four cooperated visualization views and many interactions are provided in this tool to visually explore the temporal features of various interactive events between smartphones and their users, the hierarchical associations among event types, and the detailed distributions of massive event sequences. In the case studies, plenty of interesting patterns are discovered by analyzing the data of two smartphone users with different usage styles.	cluster analysis;interaction;smartphone;usage data;visual analytics	Mingming Lu;Dan Meng;Yanni Peng;Yong Li;Ying Zhao;Xiaoping Fan;Fangfang Zhou	2016	2016 IEEE Pacific Visualization Symposium (PacificVis)	10.1109/PACIFICVIS.2016.7465275	analytics;interactive visual analysis;computer science;multimedia;internet privacy;world wide web	HCI	-24.24035636191145	-34.92469397787625	184272
83b692f53b944a53ee56d305e987f7311f161fac	a crowd simulation based uav control architecture for industrial disaster evacuation	sensors;toxic gas crowd simulation based uav control architecture industrial disaster evacuation unmanned aerial vehicle uav fleet management module uav trajectory planning module crowd simulation module closed control loop uav gas leakage detection scheduling;microscopy;trajectory;planning;sensors planning trajectory wireless sensor networks microscopy;trajectory control autonomous aerial vehicles emergency management;wireless sensor networks	In past decades, we have witnessed lots of gas leakage diasters all over the world, causing serious casualties, property damage and severe negative social impact. During evacuation after gas leakage incident, the poisonous gas shall be accurately detected. Accordingly, the evacuation routine shall be carefully planned and warned to the evacuating people. Unmanned aerial vehicle (UAV) has been widely regarded as a promising tool to support crowd evacuation. In this paper, aiming at providing an efficient UAV control system for crowd evacuation, we propose a crowd simulation based UAV control system to direct crowd evacuation from the polluted area. The architecture mainly consists of a UAV fleet management module, UAV trajectory planning module, and a crowd simulation module. The architecture forms a closed control loop, emphasizing the inter-operation between the real scenario and the simulation scenario. A case study on UAV gas leakage detection scheduling is given. The results show that the proposed architecture can provide efficient way to help pedestrian in the environment to evacuate and avoid to be infected by the toxic gas.	aerial photography;algorithm;automated planning and scheduling;control system;correctness (computer science);crowd simulation;scheduling (computing);spectral leakage;systems architecture;unmanned aerial vehicle	Muzhou Xiong;Deze Zeng;Hong Yao;Yong Li	2016	2016 IEEE 83rd Vehicular Technology Conference (VTC Spring)	10.1109/VTCSpring.2016.7504062	planning;computer vision;simulation;wireless sensor network;computer science;engineering;sensor;microscopy;trajectory;computer security	Robotics	-20.581878137366605	-27.814474284416853	184522
d2d08febd589033334064ad4b430a038c6e97a1c	celerina - a generative music system using aesthetical reduction applied to simple cellular automata	cellular automata	Celerina is the software core of a realtime system for dynamic music generation. Several one-dimensional binary cellular automata generate melodic patterns that are subsequently reduced and processed to form musical motifs and gestures. The music generated by Celerina is set to conform with such musical styles as jazz, classical or	automata theory;cellular automaton;dynamic music;real-time computing	John Flury;Daniel Bisig	2006			artificial intelligence;generative grammar;melody;machine learning;dynamics (music);natural language processing;cellular automaton;software;mobile automaton;computer science;growcut algorithm;gesture	ML	-27.24283583587191	-27.33263575944764	184553
80db26f33ddd7c20a8a9a16f365588a841207aec	the roles of perception for volume visualization and designing volume visualization methods based on perceptual factors	visual depth;vergence;accommodation	In the context of medical volume visualization, it is useful to study how effectively the visualization depicts anatomical structures and how well features of anatomical structures can be discerned in order to make decisions. So it is important to know what factors affect the understanding of rendered images and further to design more effective rendering algorithms under considering these factors. However, they are not fully evaluated. These are important for users to get better understanding of a 3D data set, and to help to develop effective visualization methods. Because visualization renditions are perceived through human visual perception, visual perception has important effects on mental models. This paper aims to analyze the roles of perception for volume visualization and use the perceptual analysis results to design volume visualization methods.	algorithm;mental model;scientific visualization	Jianlong Zhou	2005		10.1145/1080402.1080462	computer vision;accommodation;visual analytics;computer science;vergence;multimedia;computer graphics (images)	Visualization	-32.82101070849341	-36.70172578444558	184569
d9bd200b35c2194fb6f154f9e619c21b18bba862	optimal viewpoint finding for 3d visualization of spatio-temporal vehicle trajectories on caution crossroads detected from vehicle recorder big data	3d	Traffic accidents are still troubling our society. The number of drive recorders sold has increased, and therefore we can collect large-scale vehicle recorder data to be used to support traffic safety. We have developed a system for detecting potentially risky crossroads on the basis of vehicle recorder data, road shapes, and weather information. Visualization combining space and time in a single display called a “space time cube (STC)” helps us to understand and analyze spatio-temporal mobility data on caution crossroads. The STC enables us to simultaneously explore not only shapes and positions of vehicle trajectories but also their temporal distributions. However, it is difficult for users to manually find good viewpoints for understanding such characteristics of trajectories. In this paper, we propose an optimal viewpoint selection method for visualizing spatio-temporal characteristics of vehicle trajectories on a large set of crossroads using an STC. Major contributions of this paper are as follows: (1) We provide an algorithm based on viewpoint entropy weighted by angles of trajectories with a horizontal line as a measure of a viewpoint quality on a projected 2D image. (2) We demonstrate our solution can be adapted to crossroads with different trajectory shapes. We also extend the proposed method to find an optimal viewpoint for multiple crossroads. (3) We verify the proposed method through users' evaluations. (4) We construct an overviewing catalog of potentially risky crossroads detected from real vehicle recorder big data to discuss and analyze them with stakeholders.	algorithm;big data;crowdsourcing;mid atlantic crossroads;sensor;visualization (graphics)	Masahiko Itoh;Daisaku Yokoyama;Masashi Toyoda;Masaru Kitsuregawa	2017	2017 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2017.8258329	artificial intelligence;data visualization;machine learning;spacetime;visualization;computer science;big data;trajectory;space time	Visualization	-23.87227937152434	-34.22667477365438	184574
cb70af625d0214caeb7bbe7890dca9867d2c50c3	research report: volume rendering for relational data	user interfaces relational databases rendering computer graphics data visualisation data structures query processing;relational data;external query sliders;information visualization volume rendering relational data dense scatterplots plotting data points categorical variables nonaxis dimensions unknown values table data structure voxel external query sliders multivariate data;query processing;volume rendering;categorical variables;scattering data visualization rendering computer graphics relational databases data structures silicon graphics stacking data compression shape;data points;information visualization;voxel;data visualisation;data structures;unknown values;plotting;table;relational databases;rendering computer graphics;data structure;user interfaces;dense scatterplots;multivariate data;nonaxis dimensions	A method for efficiently volume rendering dense scatterplots of relational data is described. Plotting difficulties that arise from large numbers of data points, categorical variables, interaction with non-axis dimensions, and unknown values, are addressed by this method. The domain of the plot is voxelized using binning and then volume rendering. Since a table is used as the underlying data structure, no storage is wasted on regions with no data. The opacity of each voxel is a function of the number of data points in a corresponding bin. A voxel's color is derived by averaging the value of one of the variables for all the data points that fall in a bin. Other variables in the data may be mapped to external query sliders. A dragger object permits a user to select regions inside the volume.	volume rendering	Barry G. Becker	1997		10.1109/INFVIS.1997.636791	data structure;relational database;computer science;data mining;database;statistics;computer graphics (images)	Visualization	-28.122701763357043	-33.090577510071775	184659
f969516c9528a391d8e1b9367b11b92167dd48a8	ontological interaction modeling and semantic rule-based reasoning for user interface adaptation	swrl;modality;human computer interaction hci;technical report;ontology;rule based reasoning	"""The paper aims to show how reasoning on ontology can be helpful for user interface adaptation. From a set of user characteristics and interface parameters, it is possible to deduct the most suitable and adaptable interfaces for him/her. To do so, Semantic Web Rule Language (SWRL) rules are used to derive the appropriate interface for a specific user, considering different factors related to his/her abilities, preferences, skills, etc. A use case, in handicrafts domain, is presented; different input and output interaction modalities (writing, selection, text, speech, etc) are proposed to a handcraft woman according to her sensory perception and motor skills. The modalities are structured within what we called """"interaction ontology""""."""	input/output;semantic web rule language;user interface;user profile	Fatma Zohra Lebib;Hakima Mellah;Linda Mohand-Oussaïd	2016		10.5220/0005854303470354	natural language processing;computer science;knowledge management;technical report;ontology;data mining;reasoning system;world wide web	AI	-33.47266499011244	-25.369802143617797	184728
fcb6e92a03a0abe7f8d56427f83a02f661149c18	an outdoor-indoor coupled simulation framework for climate change-conscious urban neighborhood design	climate change conscious urban neighborhood design;envi met;ecotect;three dimensional virtual neighborhood;ccworldweathergen;environmental simulation	Only recently, research communities and professional organizations have started to incorporate the factor of climate change in software-based environmental simulation with a view to inform climate adaptation planning and design. Based on the results from simulating a neighborhood design proposed for New Cairo, Egypt, we develop a conceptual framework and an environmental simulation workflow aimed at achieving Climate Change-conscious Urban Neighborhood Design (C3UND). Central to the C3UND approach is the coupling of neighborhood outdoor simulation and building indoor simulation and taking into account climate change scenarios as projected by today's meteorological modeling. Utilizing two existing software systems, ENVI-met for urban neighborhood outdoor simulation and Ecotect for building indoor simulation, we demonstrate how a workflow can be implemented to play out climate change scenarios on urban neighborhoods and the buildings located within. The C3UND simulation framework and workflow was further applied to a neighborhood site at the Sheffield University campus in England with weather data input of the present day (2012) and of the 2050s generated by the CCWorldWeatherGen tool. Our current study suggests that environmental simulation of climate change scenarios at an urban neighborhood scale is currently achievable but not without considerable gaps. Use of additional three-dimensional virtual neighborhood models, for instance, is required to bring outdoor and indoor simulation outcomes together through graphic overlay to enable more intuitive and holistic understanding of potential climate change impacts. The implications of the C3UND framework for sustainable urban and architecture design are discussed, leading to a list of research questions to be further investigated.	simulation	Chengzhi Peng;Amr Elwan	2014	Simulation	10.1177/0037549714526293	simulation	EDA	-31.53139204670978	-26.61331901529634	185047
71e522a0e97f8ecd0d3e4bfcd199eb99da87bc6e	the challenges of visualizing and modeling environmental data	pollution;volume visualization techniques;grid-based visualization;environmental science computing;unevenly distributed samples;environmental data visualization;environmental data;rendering;three-dimensional grid;data modeling;3d grid;streamlines;value;hue;glyphs;three dimensional;lighting	Existing volume visualization techniques are typically applied to a three-dimensional grid. This presents some challenging problems in the visualization of environmental data. This data often consists of unevenly distributed samples. Typically a two-step approach is used to visualize environmental data. First the unevenly distributed sample data are modeled onto a uniform 3-D grid. This grid model is subsequently rendered using conventional grid-based visualization techniques. This paper discusses some of the limitations of this approach and highlights areas where further research is needed to improve the accuracy of visualization for environmental applications.	data modeling;scientific visualization;unevenly spaced time series	Yingcai Xiao;John P. Ziebarth;Chuck Woodbury;Eric Bayer;Bruce Rundell;Jeroen van der Zijp	1996	Proceedings of Seventh Annual IEEE Visualization '96		data modeling;pollution;rendering;computer science;data science;data mining;computer graphics (images)	Visualization	-25.36946683416688	-30.927623670171005	185369
5ac1a30e9198d74ae3bbc9e54b16b91508ecb7f4	quality evaluation of visual data mining tools		Visual Data Mining (VDM) is an upcoming issue on traffic engineering and on network management in general. The parameter sets in analysing network data are becoming more complex and even more in number. This causes the problem of how to display this data and how to hint on possible problems. The VDM-Concept deals on the one hand with the fact of increasing the amount of data. On the other hand, it will open up the possibility even for non-experts to understand the elaborated information that are available within the data. The VDM consists of a pipline with three elements: Filtering, Mapping and Rendering. Within this paper we want to describe the filtering as the main element of VDM. We will present a concept, how data could be analysed via filtering and what should be done to implement a VDM-filter within the INTERMON environment. A VDM-Filter is a set of sub-filters, that could be chained to produce a complex VDM-Filter on the need of the viewer. The chaining of filters has to be done via graphical user interface and should be discussed here as well. Another main topic within the filter concept is the handling of Data Objects. These Data Objects traverses the sub-filter chain, and contains the all data, that is produced within the traversed sub-filters. Every sub-filter is able to access every data that was produced by previous filters. This sub-filter connection must also be managed by the graphical user interface. This article mainly concentrates on a generalised and configurable design for a filter VDM system. The design is not tied to any specific application, but allows to adopt to many tasks which demand for a data mining and user feedback loop. The design will be used for network analysis in the INTERMON project ([1]), which should be seen here as an example application for the VDM concept. 1 Visual Data Mining for Network Analysis The classical Data Mining approach from the artificial intelligence research field was lately extended with the visualisation aspect. This introduced a human viewer centered approach to use enhanced graphical methods for the presentation of the data mining output and give the opportunity to interact with the data mining filters. Two concepts are integrated into the general VDM approach: The feedback based knowledge discovery process and the visualisation concentrated filtering, mapping and rendering pipeline. The first process is based on the cross-industrial software process model for data mining (CRISP-DM). This CRISP-DM model ([2])was developed as a data independent guide for knowledge discovery in huge amounts of data. The second concept is derived from models for data preparation and visualisation ([3]). Main idea here is to process the raw data through a pipeline (F-M-R), where each stage performs the functionality to present the data in an innovative manner. At the end of the pipeline the viewer controls the output.	artificial intelligence;data mining;dm-crypt;feedback;graphical user interface;graphics pipeline;list of graphical methods;overhead (computing);pipeline (computing);process modeling;quality of service;rendering (computer graphics);scientific visualization;software development process;vienna development method	Edwige P. Fangseu Badjio	2005			information retrieval;data mining;computer science	ML	-29.939516924641325	-31.266707702846876	185574
7e307c14035546003116ef9c6f98b57ce5b67bcc	reducing infovis cluttering through non uniform sampling, displacement, and user perception	0705k;clutter;non uniform sampling;echantillonnage;nonuniform sampling;sampling;data analysis;visualization;fouillis echo;muestreo no uniforme;visualisation;echantillonnage non uniforme;analyse donnee;muestreo	Clutter affects almost any kind of visual technique and can obscure the structure present in the data even in small datasets, making it hard for users to find patterns and reveal relationships. In this paper we present a general strategy to analyze and reduce clutter using a special kind of sampling, together with an ad-hoc displacement technique and perceptual issues collected through a user study. The method, defined for 2D scatter plots, is flexible enough to be used in quite different contexts. In particular, in this paper we prove its usefulness against scatter plot, radviz, and parallel coordinates visualizations.	clutter;displacement mapping;hoc (programming language);information visualization;nonuniform sampling;parallel coordinates;sampling (signal processing);usability testing	Enrico Bertini;Luigi Dell'Aquila;Giuseppe Santucci	2006		10.1117/12.642748	computer vision;nonuniform sampling;simulation;visualization;computer science;computer graphics (images)	HCI	-27.712557667862296	-30.129389313492492	185909
5998b01892de3f2bc20214b0de333ea992a3c52a	m-fire: a metaphor-based framework for information representation and exploration	visual navigation;web site design;visual representation;semantic web;navigation system	An open problem in the construction of an environment for visualizing and navigating information in the context of the Semantic Web is to guarantee a satisfactory compromise between expressivity and domainindependence. In this paper we first introduce M-FIRE, a configurable framework for instantiating visualization and navigation systems based on the adoption of custom metaphors: metaphors drive the process for obtaining a visual representation of a given piece of information and define how queries are generated upon user actions. Then, the paper describes in detail how presentation is achieved. The possible applications for our framework range from semantic browsing to ontology-enabled Web site design.	semantic web;web design	Matteo Golfarelli;Andrea Proli;Stefano Rizzi	2006		10.1007/978-3-540-74063-6_17	computer vision;computer science;artificial intelligence;semantic web;database;multimedia;world wide web	Web+IR	-31.60629488505409	-33.71506340954922	186069
a6907b26d2de7a46d7d4aef0492dd320bd241cd6	polymorphic cataloguing and viewing system for using digital archives: mosaic-ii	visual interface digital content polymorphic view directed graph visualization;visualization;information retrieval systems cataloguing computer animation data visualisation directed graphs;visual interface;visualization three dimensional displays data structures usability context image edge detection;image edge detection;digital content;polymorphic view;three dimensional displays;data structures;directed graph;usability;context;visualized graph polymorphic cataloguing system digital archives mosaic ii system digital content viewing system polymorphic relationships visualization visual interface directed graph graph node graph edge relation catalogue 3d graphics animation	We propose a digital content viewing system which visualizes the polymorphic relationships among digital content interactively and uses it as a visual interface. The relationships are expressed by associating of two content and grouping and shown by directed graphs. On the graphs, nodes mean the content files or the groups, and edges mean correspondences or group members. The graphs are archived as relation catalogues separately from content files. We visualize the relations of content on a directed graph. To visualize the graphs, we use a method of locating nodes by horizontal directions and height. Nodes linked with a target node will be located on a horizontal circle and their height is decided by their relation catalogue. After deciding the node location, nodes and links are drawn using 3D graphics and animation. The visualization result called “polymorphic view” is used as a visual interface for selecting content. Selecting content on the visualized graph will expand new links and new content nodes additionally. We can show another content by tracing graph links. It becomes easy to understand the relations between digital content, because we can change the direction and size of the directed graph. We developed a content viewer system (MoSaIC-II) using the polymorphic view as a visual interface and we can see the usability of the polymorphic view.	3d computer graphics;archive;digital recording;directed graph;interactivity;ncsa mosaic;usability	Hiroyo Ishikawa;Hideo Saito;Yamato Miyashita;Kunitake Kaneko	2014	2014 International Conference on Virtual Systems & Multimedia (VSMM)	10.1109/VSMM.2014.7136649	computer vision;directed graph;visualization;usability;data structure;computer science;theoretical computer science;world wide web	HCI	-32.89836163804607	-34.52829384835935	186488
3a6954440b682627823a31debe74a4e166e58afc	identifying event impacts by monitoring the news media	information resources;social aspects of automation disasters information resources;droughts;disaster management;wild fires event impacts news media monitoring social impacts tornado wildfire financial markets disaster management epidemiology information fusion temporal patterns natural disasters heat waves droughts;news media monitoring;tornado;temporal patterns;event impacts;event detection;time series;social aspects of automation;epidemiology;natural disasters;time series event detection;social impacts;temporal pattern;heat waves;natural disaster;financial market;financial markets;social impact;information fusion;wildfire;new media;wild fires;heat wave;disasters	Assessing the potential property and social impacts of an event, such as tornado or wildfire, continues to be a challenging research area. From financial markets to disaster management to epidemiology, the importance of understanding the impacts that events create cannot be understated. Our work describes an approach to fuse information from multiple sources, then to analyze the information cycles to identify prior temporal patterns related to the impact of an event. This approach is then applied to the analysis of news reports from multiple news sources pertaining to several different natural disasters. Results show that our approach can project the severity of the impacts of certain natural disasters, such as heat waves on droughts and wild fires. In addition, results show that specific types of disaster consistently produce similar impacts when each time they occur.	tornado	Robert M. Patton;Thomas E. Potok	2008	2008 12th International Conference Information Visualisation	10.1109/IV.2008.49	meteorology;simulation;geography	SE	-21.20997433479113	-33.77069524755048	186658
abb1b37cfeb4d420d22768d7aee25abb65023e6f	traffic management center use of incident detection algorithms: findings of a nationwide survey	traffic management center;detectors;automatic incident detection;systeme intelligent;medicion automatica;freeway management system software traffic management center automatic incident detection decision support system intelligent transportation system;traffic engineering computing decision support systems road traffic traffic control;systeme aide decision;road traffic;intelligent transportation systems;gestion trafic;sistema inteligente;intelligent transportation system;traffic control;intelligence artificielle;automatic measurement;sistema ayuda decision;prise decision;mesure automatique;traffic management;decision maker;decision support system;automatic detection;transportation;decision support systems;detection algorithm;intelligent systems;intelligent system;vehicle detectors;gestion trafico;artificial intelligence;algorithms;traffic engineering computing;freeway management system software;traffic control centers;inteligencia artificial;detection algorithms intelligent transportation systems remote monitoring road vehicles performance analysis algorithm design and analysis robustness detectors software algorithms traffic control;toma decision;transportation decision support systems detectors intelligent systems	The focus of this paper is the context in which the decision makers for traffic management centers (TMCs) choose whether to include and/or use automatic incident detection (AID) algorithms. A survey was conducted of TMC professionals in positions to make, influence, or provide input to decisions regarding TMC operational policies as well as decisions regarding priorities for future system enhancements. Analysis of the survey results not only provides an understanding of the reasons behind the limited implementation of AID algorithms but also allows a direct comparison between the conventional incident detection methods and the AID technology on the basis of measured and/or perceived performance. It was observed that 90% of the survey respondents feel that the current methods of incident detection are insufficient either at present (70%) or will be so in the future (20%). This finding alone motivates a need to redouble research efforts aimed at developing robust and accurate automatic detection methods. In this regard, this paper presents promising directions to overcome past AID algorithm deficiencies	algorithm;perceived performance;traffic message channel	Billy M. Williams;Angshuman Guin	2007	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2007.894193	intelligent transportation system;simulation;decision support system;computer science;engineering;artificial intelligence;transport engineering;computer security	SE	-22.59424139695678	-26.410873828511672	186877
c05db7f49673f595687e1f28a0e9510adabf2045	geographic information systems		The power of a GIS comes from the ability to relate different information in a spatial context and to reach a conclusion about this relationship. Most of the information we have about our world contains a location reference, placing that information at some point on the globe. When rainfall information is collected, it is important to know where the rainfall is located. This is done by using a location reference system, such as longitude and latitude, and perhaps elevation. Comparing the rainfall information with other information, such as the location of marshes across the landscape, may show that certain marshes receive little rainfall. This fact may indicate that these marshes are likely to dry up, and this inference can help us make the most appropriate decisions about how humans should interact with the marsh. A GIS, therefore, can reveal important new information that leads to better decisionmaking. Geographic Information Systems (GIS) Poster http://egsc.usgs.gov/isb/pubs/gis_poster/	geographic coordinate system;geographic information system;our world	Bernhard Seeger;Peter Widmayer	2004		10.1201/9781420035179.ch55	data mining;geospatial analysis;geographic information system;local information systems;geoportal;gis and public health;computer science	HCI	-20.819580358332782	-32.41420372771522	187495
049bd56ba248e65ef0e926c8b57c1fe812754a98	a distributed cognition based tool for information trajectory analysis	titan analysis cognition distributed prototype;titan;air traffic control;software tool;cognition trajectory prototypes information processing air traffic control media data models;prototypes;software tools cognition information analysis multi agent systems;data model;media;software tool distributed cognition based tool information trajectory analysis air traffic control information processing;multi agent systems;trajectory;cognition;information processing;software tools;analysis;distributed;distributed cognition;off the shelf;prototype;information analysis;data models	"""Distributed cognition is a useful approach to study the interaction between agents (humans or artefacts) in a system, such as the collaboration involved in air traffic control. When taking a distributed cognition perspective, information processing can be directly observed. This provides the opportunity to explore how information moves through a system, and to identify specific areas where (pervasive) technology can be introduced. However, the analysis involved can not be simply used """"off-the-shelf"""" and must be tailored to a specific scenario. Furthermore, the amount of time spent conducting the analysis is often quite significant. This motivates the need for a software tool to support this kind of analysis, to guide the researcher, and reduce the amount of time spent on analysis. This paper presents a prototype of such a tool."""	distributed cognition;information processing;pervasive informatics;programming tool;prototype	Stuart Moran;Keiichi Nakata;Satoru Inoue	2011	2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2011.111	simulation;human–computer interaction;information processing;computer science;artificial intelligence;multi-agent system;data mining;database;prototype;world wide web	SE	-30.141271675389664	-28.070125410540722	187509
25dadc5eacaf7b8df20fbe6f7185a9ba01fb4dd6	qr codes & gps functions - new applications in taiwan	standards;government;servers;smart phones cameras global positioning system law administration mobile computing police qr codes;gps functions quick response codes qr codes taiwan law enforcement system manual sign in system taipei city police department tried electronic sign in system infrared ray scanning system police officers smartphones digital cameras global positioning system;abstracts;moon;global positioning system gps police mobile quick response code qr code radio frequency identification electronic map;radiofrequency identification;servers radiofrequency identification abstracts standards government moon	Before the Law Enforcement system was adopted, the conventional manual sign-in system had been used for patrolling. In 2012, the Taipei City Police Department tried to set up an electronic sign-in system by launching a new infrared ray scanning system. But the device was based on heavy equipment and thus cast doubt on the practicability for police officers conducting routine operations. This study aims to assess the possibility of integrating smartphones with digital cameras, the Global Positioning System and maps into the electronic sign-in system.	digital camera;global positioning system;map;qr code;smartphone	Chia-Rong Su;Ching-Ter Chang;Chih-Yung Chen;Chang-Shu Tu	2014	2014 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2014.7009683	simulation;telecommunications;computer science;natural satellite;computer security;government	Robotics	-19.38162064068189	-29.2693875021671	187563
8a2eec3318b85e1663d27cfeab6cbd61004b7491	automatic annotation placement for interactive maps	gis;large display;situation map;annotation placement	Situation maps play an important role in planning and decision making in emergency response centers. Important information such as operating units or hazards is usually shown on these maps. Arranging the huge amount of in-formation can be challenging for operators, as this information should always be visible while not occluding im-portant regions of the underlying geographic map. As large interactive whiteboards are increasingly replacing tradition-al analog maps, new ways to assist with arranging information can be provided. In this paper, we present a new approach for placing annotations automatically on top of a map. For finding the optimal placement, our metrics are based on geographic features, on the users' sketched input, and on the annotations geometry itself. Moreover, we also added additional features to minimize occlusions for multiple annotations. First results were highly promising and showed that our approach improves input performance while keeping an optimal view of the map.	hazard (computer architecture);interactive whiteboard;map	Daniel Kaneider;Thomas Seifried;Michael J Haller	2013		10.1145/2512349.2512809	computer vision;computer science;data mining;world wide web	HCI	-33.242421182219125	-34.571548060893335	187622
12a92fd032fdd7f1f7af3441ac74082084a4d922	visualizing categorical data in vista	lenguaje programacion;graphic method;statistical package;programming language;analisis datos;analisis correspondencia;multiple correspondence analysis;modele loglineaire;test homogeneidad;data analysis;visualization;loglinear model;methode graphique;graphical representation;correspondence analysis;test homogeneite;data visualization;langage programmation;analyse correspondance;categorical data analysis;metodo grafico;homogeneity test;analyse donnee;visualisation donnee;statistical packages;paquet statistique;categorical data;modelo loglineal;programming languages;donnee categorielle;dato categorico	This paper presents the modules in the statistical package ViSta related to categorical data analysis. These modules are: visualization of frequency data with mosaic and bar plots, correspondence analysis, multiple correspondence analysis and loglinear analysis. All these methods are implemented in ViSta with a big emphasis on plots and graphical representations of data, as well as interactivity for the user with the system. These provide a system that has shown to be easy, useful, and powerful, both for novice and experienced users.	categorical variable;graphical user interface;interactivity;list of statistical packages;multiple correspondence analysis	Pedro M. Valero-Mora;Forrest W. Young;Michael Friendly	2003	Computational Statistics & Data Analysis	10.1016/S0167-9473(02)00289-X	econometrics;visualization;categorical variable;computer science;data mining;correspondence analysis;data analysis;multiple correspondence analysis;data visualization;statistics	ML	-27.80155595208731	-29.587672039225623	188001
3e2bf8c6cb02dce72b85707970dd881bb9d29298	potential application of contextual information processing to data mining	data mining	Contextual processing is a new emerging field based on the notion that information surrounding an event lends new meaning to the interpretation of the event. Data mining is the process of looking for patterns of knowledge embedded in a data set. The process of mining data starts with the selection of a data set. This process is often imprecise in its methods as it is difficult to know if a data set for training purposes is truly a high quality representation of the thematic event it represents. Contextual dimensions by their nature have a particularly germane relation to quality attributes about sets of data used for data mining. This paper reviews the basics of the contextual knowledge domain and then proposes a method by which context and data mining quality factors could be merged and thus mapped. It then develops a method by which the relationships among mapped contextual quality dimensions can be empirically evaluated for similarity. Finally, the developed similarity model is utilized to propose the creation of contextually based taxonomic trees. Such trees can be utilized to classify data sets utilized for data mining based on contextual quality thus enhancing data mining analysis methods and accuracy.	data mining;display resolution;embedded system;information processing;list of system quality attributes;phylogenetic tree;software quality	Gregory Vert;Anitha Chennamaneni;S. Sitharama Iyengar	2010			information integration;data mining;information processing;concept mining;data set;thematic map;computer science	ML	-23.432321379468654	-35.94299421419953	189062
7fa61295e91d81b36a490c49e8e2c29f29f9480d	visual browsing of remote and distributed data	distributed data;information visualization;visual data exploration;visual data mining;interfaces	Data repositories around the world hold many thousands of data sets. Finding information from these data sets is greatly facilitated by being able to quickly and efficiently browse remote data sets. In this note, we introduce the Iconic Remote Visual Data Exploration tool(IRVDX), which is a visual data mining tool used for exploring the features of remote and distributed data without the necessity of downloading the entire data set. IRVDX employs three kinds of visualizations: one provides a reduced representation of the data sets, which we call Dataset Icons. These icons show the important statistical characteristics of data sets and help to identify relevant data sets from distributed repositories. Another one is called the Remote Dataset Visual Browser that provides visualizations to browse remote data without downloading the complete data set to identify its content. The final one provides visualizations to show the degree of similarity between two data sets and to visually determine whether a join of two remote data sets will be meaningful.	browsing;data mining;download	Parthasarathy Krishnaswamy;Stephen G. Eick;Robert L. Grossman	2004	IEEE Symposium on Information Visualization	10.1109/INFVIS.2004.73	computer science;data science;data mining;world wide web	ML	-31.485663417836378	-31.396380353416873	189182
43b90c00ccca0af892e6633ce92008a50c7f2d35	novelty and interestingness measures for design-space exploration	interestingness;novelty;exploration measure;surrogate model	Measures of novelty and interestingness are frequently encountered in the context of developmental robotics, being derived from human psychology. This work addresses these measures from the viewpoint of enhancing design-space exploration in black-box optimization. We provide a unifying notational and naming scheme with the intent of facilitating comparison, implementation, and application in the domain of design optimization. Initial analysis shows a promising interestingness measure for being tried on real-world design problems.	black box;developmental robotics;flickr;mathematical optimization;multidisciplinary design optimization	Edgar Reehuis;Markus Olhofer;Michael T. M. Emmerich;Bernhard Sendhoff;Thomas Bäck	2013		10.1145/2463372.2463557	computer science;artificial intelligence;machine learning;surrogate model;data mining;mathematics	Robotics	-28.617739371866794	-27.12873992348921	189582
589b66060597927401f40718bfc31679e9c03405	mastering the information age - solving problems with visual analytics		Data Nodes, Edges Display Interactive Display Visual Analogues VisualItems in ItemRegistry User Figure 6.3: The Information Visualisation Reference Model, adapted from Heer et al.[57] 6.2 State of the Art 93 a visual analytics issue that should be better tackled by all the visualisation communities. Blending different kinds of visualisations in the same application is becoming Blending different kinds of visualisations is currently difficult more frequent. Scientific visualisation and geographic visualisation need information visualisation because they manage multi-valued data with complex topologies that can be visualised using their canonical geometry. In addition, they can also be explored with more abstract visual representations to avoid geometric artefacts. For example, census data can be visualised as a coloured map but also as a multi-dimensional dataset where the longitude and latitude are two attributes among others. Clustering this data by some similarity measure will then reveal places that can be far away in space but behave similarly in term of other attributes (e.g., level of education, level of income, size of houses etc.), similarity that would not be visible on a map. On top of these visualisation systems, a user interface allows control of the overall application. User interfaces are well understood but they can be very different in styles. 3D systems use specific types of interfaces that are very different to traditional desktop interfaces. Moreover, information visualisation systems tend to deeply embed the interaction with the visualisation, offering special kinds of controls either directly inside the visualisations (e.g., range sliders on the axes of parallel coordinates) or around it but with special kinds of widgets (e.g., range sliders for performing range-queries). Interoperability can thus be described at several levels. At the data management level, at the architecture model level and at the interface level. 6.2.2 Data Management All visual analytics applications start with data that can be either statically collected or dynamically produced. Depending on the nature of the data, visual analytics applications have used various ways of managing their storage. In order of sophistication, they are: Flat files using ad-hoc formats, Structured file formats such as XML, Specialised NoSQL systems, including Cloud Storage, Standard or extended transactional databases (SQL), Workflow or dataflow systems integrating storage, distribution and data processing. We will now consider these data storage methods, paying particular attention to Data Management for visual analytics can rely on different levels of sophistication the levels of service required by visual analytics, such as: Persistence (they all provide it by definition), Typing, Distribution, Atomic transactions, Notification, Interactive performance, Computation.	alpha compositing;bus mastering;cloud storage;computation;computer data storage;database;dataflow;desktop computer;geographic coordinate system;hoc (programming language);information visualization;interoperability;nosql;parallel coordinates;persistence (computer science);reference model;sql;scientific visualization;similarity measure;typing;user interface;visual analytics;xml	Daniel A. Keim;Jörn Kohlhammer;Geoffrey P. Ellis;Florian Mansmann	2010				DB	-29.709970678034352	-30.776537960431547	189611
e6b9cd555d9c34a93c43c82ef2bc2970e16a85c2	visualization of the occurrence trend of infectious diseases using twitter		We propose a system for visualizing the epidemics of infectious diseases. We apply factuality analysis both to disease detection and location estimation for accurate visualization. We tested our methods for several infectious diseases, and show that our method performs well on various diseases.		Ryusei Matsumoto;Minoru Yoshida;Kazuyuki Matsumoto;Hironobu Matsuda;Kenji Kita	2018			natural language processing;artificial intelligence;visualization;computer science	ML	-21.49230524728888	-33.75377140230908	189722
07bb9855ad8ffccf420a2c96c25eb3e0413a5df3	physical indicators of cyber attacks against a rescue robot	mobile robots computer crime vehicles wheels emergency services conferences;rescue robots emergency response cyber security;computer crime;mobile robots;qa75 electronic computers computer science;vehicles;security of data emergency services robots;conferences;ta engineering general civil engineering general;wheels;emergency services;arduino based robot cyber attacks rescue robot emergency situation emergency response procedure on site communication network detection mechanisms defense mechanisms	Responding to an emergency situation is a challenging and time critical procedure. The primary goal is to save lives and this is directly related to the speed and efficiency at which help is provided to the victims. Rescue robots are able to benefit an emergency response procedure by searching for survivors, providing access to inaccessible areas and establishing an on-site communication network. This paper investigates how a cyber attack on a rescue robot can adversely affect its operation and impair an emergency response operation. The focus is on identifying physical indicators of an ongoing cyber attack, which can help to design more efficient detection and defense mechanisms. A number of experiments have been conducted on an Arduino based robot, under different cyber attack scenarios. The results show that the cyber attack's effects have physical features that can be used in order to improve the robot's robustness against this type of threat.	angularjs;arduino;denial-of-service attack;encoder;experiment;identifier;real-time clock;rescue robot;self-awareness;telecommunications network;threat (computer);wheels	Tuan Vuong;Avgoustinos Filippoupolitis;George Loukas;Diane Gan	2014	2014 IEEE International Conference on Pervasive Computing and Communication Workshops (PERCOM WORKSHOPS)	10.1109/PerComW.2014.6815228	mobile robot;embedded system;simulation;rescue robot;computer science;artificial intelligence;computer security;computer network	Robotics	-21.1093808897119	-26.888347240220213	189985
bf59cad6065ef9050717a746e769a39e423bba41	infocrible: edition interactive de visualisations compactes	interactive tools for information visualization;information visualization;specialized development frameworks	We introduce an information visualization editor, which allows both the exploration of a data set and the exploration of possible visualizations of this data set. This environment relies on the definition of Compact Visualizations, which are a very large class of visualizations that depend from a relatively small number of parameters. This environment can either be targeted as a visual exploration tool for advanced users, or as a development environment to define and export quickly specifically targeted customizable visualizations, to be manipulated by end users.	information visualization;music visualization	Thomas Baudel	2002		10.1145/777005.777033	human–computer interaction;computer science;data science;multimedia	HCI	-30.60322443148263	-31.09457926996888	190271
369e71d3eeec20752b698c967ca7d2ea3af6d1bd	visual analytics for multimedia: challenges and opportunities	data visualization;interactive image classification;visual analytics;multimedia analytics	Understanding huge multimedia collections is a huge challenge. Given a set of hundreds of thousands or millions of images, how to to understand its contents and how to find the images that are relevant for the task at hand? Using a combination of automated methods, visualization, and interaction, known as visual analytics, is probably the only way to go, combining the strengths of man and machine. An overview is given of trends in data visualization and visual analytics is given, and examples of recent work in multimedia analytics are presented. Exploiting meta-data, using interaction with relatively simple visual representations, and alignment with the work flow of users are promising routes, but scalability and evaluation are still challenging.	data visualization;scalability;visual analytics;way to go	Jarke J. van Wijk	2016		10.1145/2964284.2984750	analytics;visual analytics;web analytics;interactive visual analysis;computer science;data science;data mining;multimedia;cultural analytics;software analytics;semantic analytics;data visualization	Visualization	-30.841005330323224	-29.849809258163884	190687
ec09a578748bf1d09e9a5cc86d2dbc8a0e64bbee	phyllotrees: phyllotactic patterns for tree layout	categories and subject descriptors according to acm ccs h 5 2 information interfaces and presentation user interfaces graphical user interfaces gui i 3 6 computer graphics methodology and techniques interaction techniques	Motivations for drawing hierarchical structures are probably as diverse as datasets to visualize. This ubiquity of tree structures has lead to a manifold of tree layout algorithms and tree visualization systems. While many tree layouts exist, increasingly massive data sets, expanding computational power, and still relatively limited display space make tree layout algorithms a topic of ongoing interest. We explore the use of nature’s phyllotactic patterns to inform the layout of hierarchical data. These naturally occurring patterns provide a non-overlapping, optimal packing when the total number of nodes is not known a priori. We present PhylloTrees, a family of expandable tree layouts based on these patterns.	algorithm;angularjs;hierarchical database model;information visualization;patterns in nature;set packing	Petra Isenberg;M. Sheelagh T. Carpendale;Anand Agarawala	2006		10.2312/VisSym/EuroVis06/059-066	computer science;theoretical computer science;data mining;database	ML	-28.999484964948717	-34.50945274466744	191028
2bba33cf2692bb882b66d728060a00d445c102a6	theoretical analysis of uncertainty visualizations	0705k;cognitive theory;information visualization;data analysis;visualization;visualisation;theoretical analysis;analyse donnee	Although a number of theories and principles have been developed to guide the creation of visualizations, it is not always apparent how to apply the knowledge in these principles. We describe the application of perceptual and cognitive theories for the analysis of uncertainty visualizations. General principles from Bertin, Tufte, and Ware are outlined and then applied to the analysis of eight different uncertainty visualizations. The theories provided a useful framework for analysis of the methods, and provided insights into the strengths and weaknesses of various aspects of the visualizations.	theory	Torre Zuk;M. Sheelagh T. Carpendale	2006		10.1117/12.643631	information visualization;visualization;computer science;data science;data mining	HCI	-25.797102830484008	-35.26651406454316	191222
1d0096e9121a8139e532bf15b2ed5ab090105ccf	navigating hierarchies with structure-based brushes	hierarchical structure;data analysis user interfaces data visualisation;exploratory data analysis structure based brushes interactive selection exploratory visualization subsets brushing hierarchically structured data sets visual representation level of detail proximity based coloring structural relationships anomalies hierarchical visualization techniques hierarchical parallel coordinates tree maps;data visualisation;hierarchical representation;data analysis;level of detail;visualization technique;design and implementation;visual representation;navigation brushes displays computer science information analysis data visualization data analysis tree data structures taxonomy;user interfaces;exploratory data analysis;parallel coordinates	Interactive selection is a critical component in exploratory visualization, allowing users to isolate subsets of the displayed information for highlighting, deleting, analysis, or focussed investigation. Brushing, a popular method for implementing the selection process, has traditionally been performed in either screen space or data space. In this paper, we introduce the concept of a structure-based brush, which can be used to perform selection in hierarchically structured data sets. Our structure-based brush allows users to navigate hierarchies by specifying focal extents and level-of-detail on a visual representation of the structure. Proximity-based coloring, which maps similar colors to data that are closely related within the structure, helps convey both structural relationships and anomalies. We describe the design and implementation of our structure-based brushing tool. We also validate its usefulness using two distinct hierarchical visualization techniques, namely hierarchical parallel coordinates and tree-maps.	brushing and linking;color space;data drilling;dataspaces;distortion;focal (programming language);glossary of computer graphics;graph coloring;interaction;interactivity;keyboard technology;level of detail;location-based service;map;parallel coordinates;zooming user interface	Ying-Huey Fua;Matthew O. Ward;Elke A. Rundensteiner	1999		10.1109/INFVIS.1999.801858	information visualization;parallel coordinates;interactive visual analysis;computer science;theoretical computer science;machine learning;level of detail;data mining;data analysis;exploratory data analysis;user interface;data visualization;statistics	Visualization	-29.19109500098438	-34.02017773251408	191685
52324764c5b89b13b0777d9ac2bc070ede714853	the fundamental structures of dynamic social networks	social systems;complex networks;human dynamics;computational social science;human mobility	Social systems are in a constant state of flux, with dynamics spanning from minute-by-minute changes to patterns present on the timescale of years. Accurate models of social dynamics are important for understanding the spreading of influence or diseases, formation of friendships, and the productivity of teams. Although there has been much progress on understanding complex networks over the past decade, little is known about the regularities governing the microdynamics of social networks. Here, we explore the dynamic social network of a densely-connected population of ∼1,000 individuals and their interactions in the network of real-world person-to-person proximity measured via Bluetooth, as well as their telecommunication networks, online social media contacts, geolocation, and demographic data. These high-resolution data allow us to observe social groups directly, rendering community detection unnecessary. Starting from 5-min time slices, we uncover dynamic social structures expressed on multiple timescales. On the hourly timescale, we find that gatherings are fluid, with members coming and going, but organized via a stable core of individuals. Each core represents a social context. Cores exhibit a pattern of recurring meetings across weeks and months, each with varying degrees of regularity. Taken together, these findings provide a powerful simplification of the social network, where cores represent fundamental structures expressed with strong temporal and spatial regularity. Using this framework, we explore the complex interplay between social and geospatial behavior, documenting how the formation of cores is preceded by coordination behavior in the communication networks and demonstrating that social behavior can be predicted with high precision.	bluetooth;complex network;documented;file spanning;geolocation;image resolution;interaction;level of detail;social dynamics;social media;social network;social structure;social system;software documentation;telecommunications network;meeting	Vedran Sekara;Arkadiusz Stopczynski;Sune Lehmann	2016	Proceedings of the National Academy of Sciences of the United States of America	10.1073/pnas.1602803113	social dynamics;dynamic network analysis;social system;human dynamics;complex network	Web+IR	-20.51568222572129	-36.86444981570212	191726
ea21292f291185850ce151c7653bbf0298cbdb65	be prepared [sociotechnical systems in disaster environments]	virtual reality robots socio economic effects disasters human factors;virtual reality;human factors;robots;humans earthquakes robotics and automation decision making sociotechnical systems robots hazards costs personnel floods;risk reduction sociotechnical systems simulation disaster environments robotics;socio economic effects;disasters	Disasters present one of the most challenging environments that human decision-makers face. In an extreme event, such as a catastrophic earthquake in a metropolitan region, when life-saving efforts are most urgent and operations in the disaster field environment are most dangerous, the need for sociotechnical forms of decision support is critical. The severity of this problem is growing as the world population increases and more people move into environments that are exposed to greater risks of natural hazards [1]. Recent earthquakes have resulted in extraordinary losses in life and property in communities that were inadequately prepared. The death toll of over 20,000 lives and the cost of more than US$4.6 billion in property damage following the Gujarat (India) earthquake of 26 January 2001 are only the latest reports of losses from a series of damaging earthquakes [2]. In such an event, the existing information infrastructure to support decision making for local emergency responders is damaged or unavailable during the immediate aftermath [3]-[5]. The existing resources of equipment, tools, and training available for immediate response are inadequate, and local personnel struggle against massive odds with limited resources and less time. The losses continue to mount; Jeggle [6] sums the losses for four major disasters in 1999 at US$50 billion: Turkish earthquakes, US$12 billion; the Taiwan earthquake, US$14 billion; Venezuelan floods, US$15 billion; and the French winter storm, US$9 billion [7].	catastrophic interference;decision support system;half-life 2: episode one;sociotechnical system	Louise K. Comfort	2002	IEEE Robot. Automat. Mag.	10.1109/MRA.2002.1035209	robot;disaster;simulation;computer science;engineering;knowledge management;artificial intelligence;virtual reality	ML	-23.028537285880173	-24.248280016526508	191857
39c426876dd800c7e4d380d7d589876bfa5f285a	exploring structural analysis of place networks using check-in signals	social network services;community detection location based social networks social network analysis;communities cities and towns layout educational institutions social network services clustering algorithms computer science;layout;travel recommendations structural analysis place networks check in signals location based social networks geographic places urban computing mobile networking urban planning user profiling;clustering algorithms;social networking online geographic information systems mobile computing;cities and towns;computer science;communities	The huge amount of check-in data obtained through location-based social networks (LBSNs) provides a great opportunity to learn the characteristics of a geographic area through the users' collective check-in behavior. In this paper, we explore structure analysis of place networks, in which vertices are geographic places while the links between places are formed based on the user's check-in history. Specifically, we apply Louvain community detection algorithm on the place networks to obtain a set of place clusters (or communities). We found that these communities can be used to discover geographic layouts in the city and can uncover interesting patterns by analyzing geographically distant places within the same community. These results suggest that structural analysis of place networks is a promising approach for urban computing and has many implications of mobile networking, urban planning, user profiling and travel recommendations.	algorithm;location-based service;louvain modularity;social network;structural analysis;urban computing;vertex (geometry)	Xiang Ding;Jing Xu;Guanling Chen	2013	2013 IEEE Global Communications Conference (GLOBECOM)	10.1109/GLOCOM.2013.6831563	layout;computer science;data mining;internet privacy;cluster analysis;world wide web	HCI	-19.170189445634914	-35.69401409344416	192473
ab0ff664e1a51b3005ab687e027dfc0e3fbd12a5	visualisation and exploration of scientific data using graphs	extraction information;utilisation information;marine sediment;graph theory;remote access;interfaz grafica;uso informacion;metal pesado;teoria grafo;acceso remoto;navegacion informacion;information extraction;information use;graphical interface;navigation information;analyse tendance;acces a distance;interactive visualization;scientific data;information browsing;database;base dato;trend analysis;semantics;outlier;data mining;semantica;semantique;theorie graphe;metal lourd;observacion aberrante;fouille donnee;contaminacion;comportement utilisateur;heavy metal contamination;base de donnees;species composition;observation aberrante;contamination;user behavior;heavy metal;interface graphique;busca dato;extraccion informacion;comportamiento usuario;analisis tendencia	We present a prototype application for graph-based data exploration and mining, with particular emphasis on scientific data. The application has a Flash-based graphical interface and uses semantic information from the data sources to keep this interface as intuitive as possible. Data can be accessed from local and remote databases and files. The user can generate a number of graphs that represent different views of the data. Graphs can be explored using an interactive visual browser, or graph-analytic algorithms. We demonstrate the approach using marine sediment data, and show that differences in benthic species compositions in two Antarctic bays are related to heavy metal contamination.	adobe flash;algorithm;data mining;database;drive bay;graph (discrete mathematics);graphical user interface;prototype	Ben Raymond;Lee Belbin	2006		10.1007/11677437_2	outlier;interactive visualization;trend analysis;computer science;graph theory;operating system;data mining;graphical user interface;database;semantics;contamination;world wide web;information extraction;statistics;data	ML	-33.46184724833027	-28.10370391286857	192662
b136d08f69d81e5ab5a5eaeaa049697d3c46e483	omega-stat: an environment for implementing intelligent modeling strategies		Omega-Stat, a new data analysis and modeling paradigm, is built on Lisp-Stat—an object-oriented statistical programming environment. It contains extensible, reusable-component libraries for performing data management, multivariate analyses, modeling, and dynamic graphics. A point-and-click user interface allows instant access to all objects, including analysis and graphics objects. Modeling is done by adding new model objects, i.e., extended datasets, to a tree structure originally containing prototypes for linear, generalized linear, and nonlinear models. Knowledge, and methods for accessing this knowledge, are embedded within model objects and edge objects linking these models. This representation allows the modeling process to be studied by following the analysis trails of expert analysts. The objective is to provide an expert consultant that is accessible as part of man/machine interaction. Modeling strategies can then be built into Omega-Stat, by using prior knowledge and data-analytic heuristics, to guide the process of constructing the model tree and the iterative search for an “optimal” model.	intelligent agent;omega	E. James Harner;Hanga C. Galfalvy	1995		10.1007/978-1-4612-2404-4_32	machine learning;stat;artificial intelligence;multivariate analysis;data management;computer science;tree structure;heuristics;graphics;extensibility;user interface	Robotics	-30.32169172540022	-30.83284848998355	192701
2218eddb2357f132b74883a24594132a71ad9fc3	vistree: generic decision tree inducer and visualizer	decision tree;interactive visualization;visual interaction;data mining;prediction model;decision tree induction;information gain;open source software	Decision tree is one of the most popular and commonly used technique for predictive modeling. Interpretability and understandability makes decision trees an attractive option among various classification induction algorithms. There are several freewares available for decision tree induction which can be used in data mining education and practice. However, these freewares have limited capability to interactively visualize the induced tree and experiment with the induction process.#R##N##R##N#In this paper, we describe the design of a generic decision tree inducer and visualizer which gives options for multiple splitting criteria (e.g. information gain, gain ratio etc.) and pruning criteria (e.g. minimum error pruning, cost complexity pruning etc.) for decision tree induction. The induced tree can be visualized interactively by the user and even saved for future visualization and comparison with another tree. These options are available through a user friendly GUI. The performance statistics for the induced tree can also be viewed by the user. The package has been designed using open source softwares including JDK 1.6, Netbeans 6.5 and Prefuse (for visualization of the constructed tree).	decision tree	Vasudha Bhatnagar;Eman Zaman;Yayati Rajpal;Manju Bhardwaj	2010		10.1007/978-3-642-12038-1_15	interactive visualization;decision tree learning;computer science;theoretical computer science;machine learning;decision tree;incremental decision tree;data mining;predictive modelling;kullback–leibler divergence;id3 algorithm	Crypto	-26.148825473790385	-36.801552800334186	192856
5fb8389d79e471848943ba96605aadb686d67ff4	evaluating the allocation of border security system of systems requirements	system of systems	The Customs and Border Protection (CBP) organization must secure the homeland by preventing illegal entry into the United States. In order to successfully accomplish this task, a System of Systems (SoS) of airborne, ground, fixed, mobile, manned, and unmanned capabilities must act together in order to successfully accomplish the objective. However, it may be difficult to identify a specific SoS configuration that will meet the objective and quantify the requirements allocated for each specific system. This paper offers a methodology to evaluate the SoS phases to detect, track, identify, decide, act, and assess the actions of CBP forces. This methodology is exercised to quantify the system contributions to the CBP SoS and the interfaces needed for each system. © 2013 The Authors. Published by Elsevier B.V. Selection and/or peer-review under responsibility of Georgia Institute of Technology. System of Systems, System Methodologies	airborne ranger;apple sos;recommender system;requirement;system of systems;unmanned aerial vehicle	David Flanigan;Peggy Brouse	2013		10.1016/j.procs.2013.01.066	simulation;computer security	Embedded	-24.028506605059313	-25.579282671247846	193047
3d7fd06cc5c6e808330b1b0b6b05c3568fdb914b	bridging the gaps: joining information sources with splunk	velocity;effective connectivity;general and miscellaneous mathematics computing and information science;information sources;learning;system configuration;log analysis;miners;multiple scales;algorithms;configuration;supercomputers;information theory	Supercomputers are composed of many diverse components, operated at a variety of scales, and function as a coherent whole. The resulting logs are thus diverse in format, interrelated at multiple scales, and provide evidence of faults across subsystems. When combined with system configuration information, insights on both the downstream effects and upstream causes of events can be determined. However, difficulties in joining the data and expressing complex queries slow the speed at which actionable insights can be obtained. Effectively connecting data experts and data miners faces similar hurdles. This paper describes our experience with applying the Splunk log analysis tool as a vehicle to combine both data, and people. Splunk’s search language, lookups, macros, and subsearches reduce hours of tedium to seconds of simplicity, and its tags, saved searches, and dashboards offer both operational insights and collaborative vehicles.	bridging (networking);coherence (physics);data mining;downstream (software development);log analysis;supercomputer;system configuration	Jon Stearley;Sophia Corwell;Ken Lord	2010			simulation;computer science;theoretical computer science;data mining	HPC	-30.578779502569887	-29.032806789330884	193165
c639276290ccd1d4eb4c265c294d4882cfefbae3	artificial art made by artificial ants	swarm intelligence;cooperative behavior;interactive genetic algorithm;self organization;point of view	We present how we have considered the artificial ant paradigm as a tool for the generation of music and painting. From an aesthetic perspective, we are interested in demonstrating that swarm intelligence and self organization can lead to spatio-temporal structures that can reach an artistic dimension. In our case, the use of artificial pheromones can lead to the creation of melodies thanks to a cooperative behavior of the ant-agents but also to the emergence of abstract paintings thanks to competitive behaviors within the artificial colonies. The user’s point of view is also taken into account through interactive genetic algorithms.	artificial ants;emergence;genetic algorithm;interactive evolutionary computation;programming paradigm;self-organization;swarm intelligence	Nicolas Monmarché;Isabelle Mahnich;Mohamed Slimane	2008		10.1007/978-3-540-72877-1_11	swarm robotics;simulation;swarm intelligence;engineering;artificial intelligence;machine learning;artificial intelligence system	AI	-28.24562256875947	-24.616120521346755	193232
9bfc34ca3d3dd17ecdcb092f2a056da6cb824acd	visual analytics of spatial interaction patterns for pandemic decision support	decision support;computational techniques;spatial interaction;spatial data mining;graph partitioning;pandemic;visual analytics	This article may be used for research, teaching, and private study purposes. Any substantial or systematic reproduction, redistribution, reselling, loan, sub-licensing, systematic supply, or distribution in any form to anyone is expressly forbidden. The publisher does not give any warranty express or implied or make any representation that the contents will be complete or accurate or up to date. The accuracy of any instructions, formulae, and drug doses should be independently verified with primary sources. The publisher shall not be liable for any loss, actions, claims, proceedings, demand, or costs or damages whatsoever or howsoever caused arising directly or indirectly in connection with or arising out of the use of this material. Population mobility, i.e. the movement and contact of individuals across geographic space, is one of the essential factors that determine the course of a pandemic disease spread. This research views both individual-based daily activities and a pandemic spread as spatial interaction problems, where locations interact with each other via the visitors that they share or the virus that is transmitted from one place to another. The research proposes a general visual analytic approach to synthesize very large spatial interaction data and discover interesting (and unknown) patterns. The proposed approach involves a suite of visual and computational techniques, including (1) a new graph partitioning method to segment a very large interaction graph into a moderate number of spatially contiguous subgraphs (regions); (2) a reorderable matrix, with regions 'optimally' ordered on the diagonal, to effectively present a holistic view of major spatial interaction patterns; and (3) a modified flow map, interactively linked to the reorderable matrix, to enable pattern interpretation in a geographical context. The implemented system is able to visualize both people's daily movements and a disease spread over space in a similar way. The discovered spatial interaction patterns provide valuable insight for designing effective pandemic mitigation strategies and supporting decision-making in time-critical situations.	computation;consortium;decision support system;flow map;graph partition;holism;interactivity;iterative method;nl (complexity);numerical aperture;population;primary source;simulation;spatial analysis;subject-matter expert;the matrix;visual analytics;window of opportunity	Daoxing Guo	2007	International Journal of Geographical Information Science	10.1080/13658810701349037	visual analytics;simulation;geography;computer science;graph partition;machine learning;data mining;pandemic	Visualization	-24.444578233164652	-33.874036084766686	193450
2fca3aeb8b59f4cf26df1ffb2dffdc3c4924c8a3	navigation recommendations for exploring hierarchical graphs		Navigation is a key interaction when analyzing graphs by means of interactive visualization. Particularly for unknown graphs, the user often faces situations where it is not entirely clear where to go next. For hierarchical graphs, the user may also ponder whether it is useful to look at the data at a higher or lower level of abstraction. In this paper, we present a novel approach for recommending places in a hierarchical graph that are worth visiting next. A flexible definition of interestingness based on the notion of a degree of interest (DOI) allows us to recommend horizontal navigation in terms of the graph layout and also vertical navigation in terms of the level of abstraction. The actual recommendation is communicated to the user through unobtrusive visual cues that are embedded into the visual representation of the graph. A proof-of-concept implementation has been integrated into an existing graph visualization system.	embedded system;graph (discrete mathematics);graph drawing;graphical user interface;interactive visualization;recommender system;usability	Stefan Gladisch;Heidrun Schumann;Christian Tominski	2013		10.1007/978-3-642-41939-3_4	computer vision;artificial intelligence;computer science;human–computer interaction;graph layout;graph drawing;abstraction;information visualization;interactive visualization;graph	HCI	-30.462847360963874	-35.61407978495075	194091
1b26daca827207b92d6017f556b5f93d6cd09789	generic tools for data analysis and visualisation		This position paper discusses challenges that need to be overcome in order to build generic tools for data analysis and visualisation. Its intention is to stimulate discussion among the CUBIST workshop participants, not to present results. In the Star Trek television programs, data analysis is usually accomplished by speaking to the computer and asking it to analyse some problem. The computer then provides a succinct, coherent and relevant analysis of the data which allows the Star Trek crew to make their decisions. In reality, although humanity has made some progress with implementing Star Trek technology1, achieving automated computerised data analysis is probably at least as difficult as implementing automated natural language processing because the computer would need to understand the problem within its full context. A more achievable but still difficult goal would be to build data analysis software that collaborates with human users during the data preprocessing and modelling stages and then automates the rest of the analysis. In recent years, great advances have been made with respect to the availability of large toolkits for data analytical methods, visualisation, storage and retrieval. Thus, although the general problem is difficult (or impossible), many of the building blocks for achieving somewhat more modest solutions are available, even using low cost or free, open source tools. With respect to using Formal Concept Analysis (Ganter & Wille, 1999) as a tool for data analysis, drawing from our own experience in past projects (Priss & Old, 2010), the most labour-intensive part of using FCA is usually the preprocessing stage during which one builds the formal contexts from the raw data or during which one decides how to select smaller data sets if the original data is too large to be visualised in a single lattice. In our experience each new data set provides new challenges. One usually has to write scripts or use other computational means to preprocess the data. It is not always possible to reuse methods (or scripts) from one project directly for the next one. In some cases (Endres et al 2010), a custom application has to be purpose-built for the data. Ideally, there should be methods and tools which speed-up the data preprocessing stage. It would be nice if it was possible to apply FCA quickly to any new data set that one encounters in order to explore the data. So, with respect to FCA, the general problem of building a generic data analysis tool can be scaled down to the problem of building a generic data preprocessing tool which makes it easier to apply FCA to any 1 For example, we finally have Star Trek’s PADDs in the form of modern tablet computers, such as Apple’s iPad, and there is a list of further “Star Trek Technologies that Actually Came True” available at http://electronics.howstuffworks.com/10-star-trek-technologies.htm. given data set. Additionally, it would be desirable if FCA tools could be more easily integrated with existing tools for data preprocessing, mining, extraction, modelling and so on to allow for a combination of methods.	coherence (physics);data mining;data pre-processing;formal concept analysis;list of toolkits;natural language processing;open-source software;preprocessor;scientific visualization;star trek project;star trek:;tablet computer;word lists by frequency;ipad	Uta Priss	2011			visualization;software engineering;raw data;data pre-processing;formal concept analysis;software;scripting language;data set;preprocessor;computer science	ML	-30.683938963766185	-30.199579893002912	194400
8e21f3b776f573d878cf575966af1e6a92932d2e	information space partitioning using adaptive voronoi diagrams	voronoi diagrams;optimization;voronoi diagram;usability testing;space partitioning;treemaps;satisfiability	Received: 1 March 2006 Revised: 26 July 2006 Accepted: 14 August 2006 Online publication date: 17 May 2007 Abstract In this paper, we present and evaluate a Voronoi method for partitioning continuous information spaces. We define the formal characteristics of the problem and discuss several well-known partitioning methods and approaches. We submit that although they all partially solve the problem, they all have shortcomings. As an alternative, we offer an approach based on an adaptive version of the multiplicatively weighted Voronoi diagram. The diagram is 'adaptive' because it is computed backwards; that is, the generators' weights are treated as dependent rather than independent variables. We successfully test this adaptive solution using both ideal-typical (artificial) and empirical data. Since the resultant visualizations are meant to be used by human subjects, we then discuss the results of a usability experiment, positioning the adaptive solution against a commonly used rectangular solution and the classic nonweighted Voronoi solution. The results indicate that in terms of usability, both the rectangular and the adaptive Voronoi solution outperform the standard Voronoi solution. In addition, although subjects are better able to gage rectangular area relationships, only the adaptive Voronoi solution satisfies all geometric constraints of weight-proportional partitioning. Information Visualization (2007) 6, 123--138. doi:10.1057/palgrave.ivs.9500152	algorithm;converge;disk partitioning;equivalence partitioning;image scaling;information visualization;numerical analysis;ordinal data;rené sommer;resultant;space partitioning;usability;weighted voronoi diagram	René F. Reitsma;Stanislav Trubin	2007	Information Visualization	10.1057/palgrave.ivs.9500152	mathematical optimization;weighted voronoi diagram;voronoi diagram;centroidal voronoi tessellation;computer science;theoretical computer science;lloyd's algorithm;machine learning	AI	-29.834824840429466	-36.19247349835583	195257
215b0649dafc2b4d9b0b218c664cb61d6173473b	improving the visualization of hierarchies with treemaps: design issues and experimentation	computer animation;data visualisation;tree data structures;trees (mathematics);animation;experimental results;hierarchy display;information visualization situations;labeling;layout algorithms;nesting offsets;novice treemap users;real data;small multiple displays	Controlled experiments with novice treemap users and real data highlight the strengths of treemaps and provide direction for improvement. Issues discussed include experimental results, layout algorithms, nesting offsets, labeling, animation and small multiple displays. Treemaps prove to be a potent tool for hierarchy display. The principles discussed are applicable to many information visualization situations.	algorithm;experiment;information visualization;offset (computer science);sequence labeling;small multiple;treemapping	David Turo;Briana Johnson	1992			anime;computer vision;labeling theory;simulation;human–computer interaction;computer science;technical report;operating system;data mining;computer animation;tree;data visualization;statistics;system integration;computer graphics (images)	Visualization	-30.082211173406808	-35.05037012962911	195742
b55f46079d4de321d3c6d0d0837bb90aa7b051f0	visual trajectory pattern mining: an exploratory study in baggage handling systems		There is currently a huge amount of data being collected about movements of objects. Such data is called spatiotemporal data and paths left by moving-objects are called trajectories. Recently, researchers have been targeting those trajectories for extracting interesting and useful knowledge by means of pattern analysis and data mining. But, it is difficult to analyse huge datasets of trajectories without summarizing them and visualizing them for the knowledge seeker and for the decision makers. Therefore, this research paper focuses on utilizing visual techniques and data mining analysis of trajectory patterns in order to help extract patterns and knowledge in an interactive approach. The research study proposes a research framework which integrates multiple data analysis and visualization techniques in a coherent architecture in support of interactive trajectory pattern visualization for the decision makers. An application case-study of the techniques is conducted on an airport’s baggage movement data within the Baggage Handling System (BHS). The results indicate the feasibility of the approach and its methods in visually analysing trajectory patterns in an interactive approach which can support the decision maker.	data mining;exploratory testing	Ayman Al-Serafi;Ahmed Elragal	2014		10.1007/978-3-319-08976-8_12	computer vision;simulation;data mining	ML	-23.49120226505605	-34.45069526312866	195846
46fe0c9e504bdefa70b45b1d1ae674690b61b2c0	melt 2016 workshop report: the sixth acm sigspatial international workshop on mobile entity localization, tracking and analysis: burlingame, ca, usa - october 31, 2016		Dynamic location data is pouring into servers that provide location based services and tracking. This data is valuable for making inferences about the motions, intentions, preferences, and futures of the tracked entities. The data is also useful for understanding the aggregate environment, such as road maps, dynamic patterns, popular events, and expected behavior.	aggregate data;entity;futures and promises;location-based service;map;server (computing)	Sarana Nutanong	2017	SIGSPATIAL Special	10.1145/3124104.3124115	computer science;data science;data mining;location-based service;futures contract;server	DB	-22.479572665788496	-33.14790373859767	195868
dd2e494aa7c8a372437f5d7d13cfe3e9ce192ef8	epidemiology and wireless communication: tight analogy or loose metaphor?	communication system;wireless network;wireless communication;social network;community networks;interaction based;infectious disease;communication;network;epidemic	The analogy between viral dynamics in humans and in computers is a detailed and useful one. At first glance, the extension to infectious disease epidemiology on human social networks and communication in wireless networks is also a compelling analogy. Mathematical epidemiology has a long history and seems to offer a biological inspiration for communication network design. In this paper, however, we argue that while epidemiology as a metaphor may hold insights into communication networks, the relationship is not concrete enough to permit us to adapt solutions from one domain to another. Our conclusion is that it is certain new mathematics and methodologies, rather than the results themselves, that are most likely to generalize well to communication systems.		Stephen Eubank;V. S. Anil Kumar;Madhav V. Marathe	2007		10.1007/978-3-540-92191-2_9	simulation;computer science;artificial intelligence;communication	EDA	-26.001953805112493	-27.160215484489434	196304
580f28f527d6325d7def480cc85e5c1cc4ab38f8	wysiwyp: what you see is what you pick	radiology;transfer functions;volume rendering;3d rendering;geometry;biomedical imaging;rendering computer graphics transfer functions equations image color analysis biomedical imaging data visualization geometry;data visualisation;data analysis;wysiwyg;wysiwyg picking volume rendering;rendering computer graphics data analysis data visualisation medical image processing radiology;image color analysis;medical image processing;medical imaging data;data visualization;volume picking;radiologists;what you see is what you pick 3d data analysis slice based visualizations radiologists medical imaging data 3d rendering volume picking wysiwyp;wysiwyp;picking;rendering computer graphics;slice based visualizations;what you see is what you pick;3d data analysis	Scientists, engineers and physicians are used to analyze 3D data with slice-based visualizations. Radiologists for example are trained to read slices of medical imaging data. Despite the numerous examples of sophisticated 3D rendering techniques, domain experts, who still prefer slice-based visualization do not consider these to be very useful. Since 3D renderings have the advantage of providing an overview at a glance, while 2D depictions better serve detailed analyses, it is of general interest to better combine these methods. Recently there have been attempts to bridge this gap between 2D and 3D renderings. These attempts include specialized techniques for volume picking in medical imaging data that result in repositioning slices. In this paper, we present a new volume picking technique called WYSIWYP (“what you see is what you pick”) that, in contrast to previous work, does not require pre-segmented data or metadata and thus is more generally applicable. The positions picked by our method are solely based on the data itself, the transfer function, and the way the volumetric rendering is perceived by the user. To demonstrate the utility of the proposed method, we apply it to automated positioning of slices in volumetric scalar fields from various application areas. Finally, we present results of a user study in which 3D locations selected by users are compared to those resulting from WYSIWYP. The user study confirms our claim that the resulting positions correlate well with those perceived by the user.	3d rendering;choose (action);digital video recorder;engineering;imagery;largest;list of common shading algorithms;medical imaging;observable;radiation;rendering (computer graphics);repositioning (procedure);simulation;transfer function;usability testing;viewing cone;volume rendering;volumetric display;wysiwyg	Alexander Wiebel;Frans Vos;David Foerster;Hans-Christian Hege	2012	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2012.292	computer vision;3d rendering;computer science;mathematics;multimedia;transfer function;data analysis;volume rendering;data visualization;statistics;computer graphics (images)	Visualization	-32.615016193421425	-36.6200643388814	196372
9422cd1efe49606cf68c879f2aec42ae66b06749	emergency situation awareness: twitter case studies		The Emergency Situation Awareness (ESA) system provides all-hazard situation awareness information for emergency managers using content gathered from the public Twitter API. It collects, filters and analyses Tweets from specific regions of interest in near-real-time, enabling effective alerting for unexpected incidents and monitoring of emergency events with results accessible via an interactive website.		Robert Power;Bella Robinson;John Colton;Mark A. Cameron	2014		10.1007/978-3-319-11818-5_19	knowledge management;internet privacy;computer security	NLP	-22.136370007876604	-27.863602051274707	196469
ea70ab4b945613d035e9b82f341ee0a7f558e87f	new metaphors for a visual query language	query language;database querying;graphic congestion;metaphors;user interface;universal quantification;object oriented semantic data model;industrial setting;set combination;query languages;semantic data model;vista query language;operating system;end users;database languages visual databases data models data visualization operating systems object oriented databases computer graphics computer interfaces multimedia databases acoustic scattering;object oriented;industrial setting visual query language metaphors vista query language database querying end users concept visualization object oriented semantic data model set comparison set combination explicit joins universal quantification graphic congestion user interface;explicit joins;concept visualization;set comparison;visual query language	Metaphors have been proved useful in ,fhcilitating learning and using an operating system or various other tools. The purpose of this paper is to show through the VISTA(*) query language, the benefits of using metaphors in the field of database quer,ying by end users. Within VISTA, metaphors help in visualizing concepts of the object-oriented semantic data model and in .facilitating the expression of operations known to be dincult. The user is placed in a room and querying consists of direct and natural manipulations on objects of this room. Moreover, VISTA brings an answer lo problems such as set comparison and combination, explicit joins, universul quantijlcation, and graphic congestion. Another benefit of this work lies in the implementation of the user in& ' r .f ace in an industrial setting.	automatic computing engine;network congestion;operating system;query language;semantic data model	Bruno Bélières;Claude Trépied	1996		10.1109/DEXA.1996.558301	computer science;theoretical computer science;operating system;data mining;database;programming language;world wide web;query language	DB	-31.864124935457326	-32.54699953813443	196829
7994ffd49870fae6d1f0e709dd8375c64a2a2490	animated geo-temporal clusters for exploratory search in event data document collections	human computer information retrieval information visualisation visual analytics;history navigation encyclopedias electronic publishing internet data visualization;pattern clustering computer animation data visualisation document handling document image processing information retrieval;equivalent text based exploratory search engine animated geo temporal clusters event data document collections visual analytics technique coordinated timeline map views animation geo referenced search results spatio temporal data	This paper presents a novel visual analytics technique developed to support exploratory search tasks for event data document collections. The technique supports discovery and exploration by clustering results and overlaying cluster summaries onto coordinated timeline and map views. Users can also explore and interact with search results by selecting clusters to filter and re-cluster the data with animation used to smooth the transition between views. The technique demonstrates a number of advantages over alternative methods for displaying and exploring geo-referenced search results and spatio-temporal data. Firstly, cluster summaries can be presented in a manner that makes them easy to read and scan. Listing representative events from each cluster also helps the process of discovery by preserving the diversity of results. Also, clicking on visual representations of geo-temporal clusters provides a quick and intuitive way to navigate across space and time simultaneously. This removes the need to overload users with the display of too many event labels at any one time. The technique was evaluated with a group of nineteen users and compared with an equivalent text based exploratory search engine.	cluster analysis;exploratory search;text-based (computing);timeline;visual analytics;web search engine	Paul Craig;Néna Roa-Seïler;Ana Delia Olvera Cervantes	2014	2014 18th International Conference on Information Visualisation	10.1109/IV.2014.69	computer science;data mining;world wide web;information retrieval	Visualization	-28.38942989460796	-34.667869145595034	196883
bf16efd28f7122b18aa44308a7c961cd221b42fd	tweetvista: an ai-powered interactive tool for exploring conversations on twitter	tweet2vec;conversation clusters;semantic clusters;interactive tool;twitter	We present TweetVista, an interactive web-based tool for mapping the conversation landscapes on Twitter. TweetVista is an intelligent and interactive desktop web application for exploring the conversation landscapes on Twitter. Given a dataset of tweets, the tool uses advanced NLP techniques using deep neural networks and a scalable clustering algorithm to map out coherent conversation clusters. The interactive visualization engine then enables the users to explore these clusters. We ran three case studies using datasets about the 2016 US presidential election and the summer 2016 Orlando shooting. Despite the enormous size of these datasets, using TweetVista users were able to quickly and clearly make sense of the various conversation topics around these datasets.	algorithm;artificial neural network;cluster analysis;coherence (physics);deep learning;desktop computer;interactive visualization;natural language processing;scalability;web application	Prashanth Vijayaraghavan;Soroush Vosoughi;Ann Yuan;Deb Roy	2017		10.1145/3030024.3040979	computer science;data science;multimedia;world wide web	NLP	-30.71122179660654	-29.789169423916242	197079
20098b394f1060dbfd2420a0511763ace6158816	applying causal inference to understand emergent behavior	coding error;iterative application;explanation exploration;valid behavior;subject matter expert;semi-automatic model adaptation;previous work;causal inference procedure;emergent behavior;new insight;mean squared error;simulation;reverse engineering;causal inference;cumulant;causality	Emergent behaviors in simulations require explanation, so that valid behaviors can be separated from design or coding errors. Validation of emergent behavior requires accumulation of insight into the behavior and the conditions under which it arises. Previously, we have introduced an approach, Explanation Exploration (EE), to gather insight into emergent behaviors using semi-automatic model adaptation. We improve our previous work by iteratively applying causal inference procedures to samples gathered from the semi-automatic model adaptation. Iterative application of causal inference procedures reveals the interactions of identified abstractions within the model that cause the emergent behavior. Uncovering these interactions gives the subject matter expert new insight into the emergent behavior and facilitates the validation process.	causal filter;causal inference;emergent;interaction;semiconductor industry;simulation;subject matter expert turing test;subject-matter expert;tree accumulation	Ross Gore;Paul F. Reynolds	2008	2008 Winter Simulation Conference		simulation;causality;causal inference;computer science;artificial intelligence;machine learning;mean squared error;subject-matter expert;reverse engineering;statistics;emergence;cumulant	AI	-25.17063902738718	-27.65019454779814	197349
5035f2db8f6813882ee23ad5802b53c050c03bc7	real-time procedural terrain generation through swarm behaviours		This paper explores research in progress on Swarm Intelligence related to Procedural Terrain Generation. Our aim is to develop means to provide useful and real-time terrain deformation using Swarm algorithms. We feel this could prove interesting for enhancing the experience of gameplay in some game genres such as Real Time Strategy (RTS), simulation or even platform games.	algorithm;destructible environment;real-time clock;real-time transcription;scenery generator;simulation;swarm intelligence	Ángel Fernández Cabezas;Tommy Thompson	2013			terrain;simulation;swarm behaviour;computer science	Robotics	-27.89173063913942	-24.815207478964005	197493
9b77ef8d73cd8d42e8ddf32bba2f343fadd09d7d	jackvr: a virtual reality training system for landing oil rigs		We propose JackVR, an interactive immersive simulation prototype aiming to train domain experts to land jackup oil rigs. Jackup rigs are among the most common offshore drilling units for extracting oil, but the process of landing the rigs is mostly challenging because of the unpredictable sea and weather conditions, lack of clear vision, and the possible risk of damaging the ocean floor. We designed JackVR to support oil engineers and technicians by allowing them to practice landing the oil rig within a safe and semi-realistic training environment. Furthermore, the design explores various superimposed spatial indicators that provide visual warnings on unexpected task conditions. The implemented prototype supports two modes for training, and utilizes the ray-casting interaction technique to enable seamless and direct control of the rig. . . . Fig. 1. JackVR’s Concept: immersive landing of oil rigs with Ray selection technique 2 Authors Suppressed Due to Excessive Length	data drilling;immersion (virtual reality);interaction technique;prototype;ray casting;seamless3d;semiconductor industry;simulation;topography;virtual reality	Ahmed E. Mostafa;Kazuki Takashima;Mario Costa Sousa;Ehud Sharlin	2015		10.1007/978-3-319-27863-6_42	computer vision;training system;computer science;simulation;artificial intelligence;interaction technique;immersion (virtual reality);virtual reality;offshore drilling	Visualization	-31.896823328991847	-37.182100533981654	197782
18170667b7d7ae68af9b4f9dba9e83534728aed9	rapid adaptation of video game ai	games artificial intelligence humans graphics instruments collaboration teamwork artificial neural networks evolutionary computation testing;video games;rapid adaptation;probability density function;data mining;domain knowledge;video games rapid adaptation artificial intelligence domain knowledge;springs;adaptation model;games;artificial intelligence;humans;computer games;computer games artificial intelligence	Current approaches to adaptive game AI require either a high quality of utilised domain knowledge, or a large number of adaptation trials. These requirements hamper the goal of rapidly adapting game AI to changing circumstances. In an alternative, novel approach, domain knowledge is gathered automatically by the game AI, and is immediately (i.e., without trials and without resource-intensive learning) utilised to evoke effective behaviour. In this paper we discuss this approach, called dasiarapidly adaptive game AIpsila. We perform experiments that apply the approach in an actual video game. From our results we may conclude that rapidly adaptive game AI provides a strong basis for effectively adapting game AI in actual video games.	artificial intelligence (video games);display resolution;evaluation function;experiment;game engine;requirement	Sander Bakkes;Pieter Spronck;H. Jaap van den Herik	2008	2008 IEEE Symposium On Computational Intelligence and Games	10.1109/CIG.2008.5035624	applications of artificial intelligence;game design;navigation mesh;games;probability density function;simulation;turns, rounds and time-keeping systems in games;computer science;artificial intelligence;game mechanics;machine learning;multimedia;artificial intelligence, situated approach;domain knowledge;game testing	AI	-26.145064184225564	-25.7554122800814	197870
50f15b26a844a772451c6ebf872b9989729f3164	using semantic clustering to support situation awareness on twitter: the case of world views	social media analytics;user-support tools;data clustering;information systems;crisis response;computational social science;fake news	In recent years, situation awareness has been recognised as a critical part of effective decision making, in particular for crisis management. One way to extract value and allow for better situation awareness is to develop a system capable of analysing a dataset of multiple posts, and clustering consistent posts into different views or stories (or, ‘world views’). However, this can be challenging as it requires an understanding of the data, including determining what is consistent data, and what data corroborates other data. Attempting to address these problems, this article proposes Subject-Verb-Object Semantic Suffix Tree Clustering (SVOSSTC) and a system to support it, with a special focus on Twitter content. The novelty and value of SVOSSTC is its emphasis on utilising the Subject–Verb–Object typology in order to construct semantically consistent world views, in which individuals—particularly those involved in crisis response—might achieve an enhanced picture of a situation from social media data. To evaluate our system and its ability to provide enhanced situation awareness, we tested it against existing approaches, including human data analysis, using a variety of real-world scenarios. The results indicated a noteworthy degree of evidence (e.g., in cluster granularity and meaningfulness) to affirm the suitability and rigour of our approach. Moreover, these results highlight this article’s proposals as innovative and practical system contributions to the research field.	biological anthropology;cluster analysis;social media;suffix tree clustering	Charlie Kingston;Jason R. C. Nurse;Ioannis Agrafiotis;Andrew Milich	2018	Human-centric Computing and Information Sciences	10.1186/s13673-018-0145-6	suffix tree clustering;computational sociology;data science;multimedia;social media analytics;cluster analysis;information system;social media;situation awareness;rigour;computer science	Web+IR	-23.244802529009824	-35.6796093369812	197872
6474833e579800c8a1f6fc05aa3a91006b291bda	the representation of neural data using visualization	spikes;visualization environment;data filtering;journal article;scaling up;multi dimensional;data visualisation;neural data;human genome project;spike train;analysis;spike train analysis;brain function;spike trains;information visualisation	Currently, the focus of research within Information Visualisation is steering towards genomic data visualisation [21] due to the level of activity that the Human Genome Project [11] has generated. However, the Human Brian project [10], renowned within Neuroinformatics, is equally challenging and exciting. Its main aim is to increase current understanding of brain function such as memory, learning, attention, emotions and consciousness. It is understood that this task will require the “integration of information from the level of the gene to the level of behaviour”. The work presented in this paper focuses on the visualisation of neural data. More specifically, the data being analysed is multi-dimensional spike train data. Traditional methods, such as the ‘raster plot’ and the ‘crosscorrelogram’, are still useful but they do not scale up for larger assemblies of neurons. In this paper, a new innovative method called the Tunnel is defined. Its design is based on the principles of Information Visualisation; overview the data, zoom and filter data, data details on demand [18]. The features of this visualisation environment are described. This includes data filtering, navigation and a ‘flat map’ overview facility. Additionally, a ‘coincidence overlay map’ is presented. This map washes the Tunnel with colour, which encodes the coincidence of spikes.	action potential;brian;consciousness;data visualization;information visualization;neuroinformatics;tunneling protocol;virtual private network	Martin A. Walter;Liz J. Stuart;Roman Borisyuk	2004	Information Visualization	10.1057/palgrave.ivs.9500071	computer vision;simulation;information visualization;computer science;artificial intelligence;machine learning;analysis;data mining;data visualization	ML	-27.256047177357765	-31.83375699486192	197911
21f40ec7fe04973d90e3c15bfc5b465eadafdaa1	constructing a taxonomy of fine-grained human movement and activity motifs through social media		Profiting from the emergence of web-scale social data sets, numerous recent studies have systematically explored human mobility patterns over large populations and large time scales. Relatively little attention, however, has been paid to mobility and activity over smaller time-scales, such as a day. Here, we use Twitter to identify people’s frequently visited locations along with their likely activities as a function of time of day and day of week, capitalizing on both the content and geolocation of messages. We subsequently characterize people’s transition pattern motifs and demonstrate that spatial information is encoded in word choice.	activity recognition;emergence;geolocation;population;social media	Morgan R. Frank;Jake Ryland Williams;Lewis Mitchell;James P. Bagrow;Peter Sheridan Dodds;Christopher M. Danforth	2014	CoRR		simulation;data mining	HCI	-20.20370637991622	-37.20694360933719	197947
813931d64537bbdbcc1943d5cfd0fc0a793f0d0d	fork: fine grained occupancy estimator using kinect on arm embedded platforms		Occupancy estimation is very useful for a wide range of smart building applications including energy efficiency, safety, and security. In this demonstration, we present a novel solution called FORK, which uses a Kinect depth sensor for estimating occupancy in real-time. Unlike other camera-based solutions, FORK is much less privacy invasive (even if the sensor is compromised) and it does not require a powerful machine like a Microsoft XBOX or an Intel® Core™ i7 processor to process the depth data. Our system performs the entire depth data processing on a cheaper and lower-power ARM processor, in real-time. In order to do that, FORK uses a novel lightweight human model by leveraging anthropometric properties of human bodies for detecting individuals. We will show how FORK detects, tracks, and counts occupants accurately in real-time.	arm architecture;anthropometry;embedded system;fork (software development);kinect;real-time clock;sensor;structured-light 3d scanner	Sirajum Munir;Le Tran;Jonathan Francis;Charles Shelton;Ripudaman Singh Arora;Craig Hesling;Matias Quintana;Anand P. Krishnan;Anthony Rowe;Mario Berges	2017		10.1145/3137133.3141461	occupancy;building automation;estimator;embedded system;fork (system call);arm architecture;computer science	Mobile	-23.0054119725727	-29.22086651067342	198564
2bf7df63bf9c2736ba57a3c4586a4fc2dcd72205	transportation application of social media: travel mode extraction	legged locomotion;public transportation;data mining;urban areas;twitter	At the present time, social media is not only used for connecting people in a virtual environment, but is also considered as a reach source of information for organizations and public service agencies to facilitate their policy and decision making processes. As an example, such crowdsourced data can be considered as a complementary source for analyzing people choices. In this study, we attempt to show how social media data can be used (and utilized) in order to extract travel mode choice which can be used as complementary source of information to improve traditional costly methods such as House Travel Surveys (HTS). The contents of Twitter data posted in Melbourne metropolitan areas have been analyzed to determine travel mode choices information. The results show, walking and driving modes are the most frequent travel modes extracted from Twitter data while public mode of transportations such as bus and taxi are rarely detected. Future research is required to extend this approach by considering and validating socio-demographic metrics of social media users so as to utilize social media data as complementing source of information for HTS.	crowdsourcing;data pre-processing;database;high-throughput satellite;information source;plasma cleaning;preprocessor;social media;virtual reality	Mojtaba Maghrebi;Alireza Abbasi;S. Travis Waller	2016	2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2016.7795779	simulation;engineering;travel behavior;advertising;computer security	DB	-21.715945849521585	-34.03434637316834	198643
7aa8d54f76645bf9d3b19796543dbc98515b6227	visualization for information exploration and analysis: keynote presentation	information exploration;visual representation;extensible 3d graphics;sense making;visual analytics;software visualization	Making sense of data becomes more challenging as the data grows larger and becomes more complex. If a picture truly can be worth a thousand words, then clever visualizations of data should hold promise in helping people with sense-making tasks. I firmly believe that visual representations of data can help people to better explore, analyze, and understand it, thus transforming the data into information. In this talk, I will explain how visualization and visual analytics help people make sense of data and I will provide many such examples. I also will describe my present research into visualization for investigative analysis. This project explores how visual analytics can help investigators examine a large document collection in order to discover embedded stories and narratives scattered across the documents in the collection.	archive;embedded system;information;music visualization;sensemaking;visual analytics	John T. Stasko	2008		10.1145/1409720.1409721	software visualization;analytics;visual analytics;information visualization;interactive visual analysis;computer science;data science;data mining;cultural analytics;programming language;world wide web;data visualization	HCI	-30.637614803029926	-30.137301929529794	198681
a6b61ccea8e9954e6357ec05e50d4d74f29f97f6	path patterns visualization in semantic graphs		Graphs with a large number of nodes and edges are difficult to visualize. Semantic graphs add to the challenge since their nodes and edges have types and this information must be mirrored in the visualization. A common approach to cope with this difficulty is to omit certain nodes and edges, displaying sub-graphs of smaller size. However, other transformations can be used to abstract semantic graphs and this research explores a particular one, both to reduce the graph’s size and to focus on its path patterns. Antigraphs are a novel kind of graph designed to highlight path patterns using this kind of abstraction. They are composed of antinodes connected by antiedges, and these reflect respectively edges and nodes of the semantic graph. The prefix “anti” refers to this inversion of the nature of the main graph constituents. Antigraphs trade the visualization of nodes and edges by the visualization of graph path patterns involving typed edges. Thus, they are targeted to users that require a deep understanding of the semantic graph it represents, in particular of its path patterns, rather than to users wanting to browse the semantic graph’s content. Antigraphs help programmers querying the semantic graph or designers of semantic measures interested in using it as a semantic proxy. Hence, antigraphs are not expected to compete with other forms of semantic graph visualization but rather to be used a complementary tool. This paper provides a precise definition both of antigraphs and of the mapping of semantic graphs into antigraphs. Their visualization is obtained with antigraphs diagrams. A web application to visualize and interact with these diagrams was implemented to validate the proposed approach. Diagrams of well-known semantic graphs are also presented and discussed. 2012 ACM Subject Classification Computing methodologies → Semantic networks, Humancentered computing → Graph drawings	abstract semantic graph;browsing;diagram;graph drawing;graph theory;programmer;semantic network;web application	José Paulo Leal	2018		10.4230/OASIcs.SLATE.2018.15	computer science;natural language processing;artificial intelligence;visualization;graph	HCI	-29.938947448187754	-35.18783197070784	198789
0d2589271bc7343c9415833e67e2a5ae5d853aa0	representation and analysis of spatial resources in construction simulation	spatial resource;construction;spatial resources;space resource;discrete event simulation;space resources;possible space conflict;different simulation model;visual display;resource allocation;cell-based method;construction simulation;conflict analysis;digital simulation;explicit method;space representation;simulation research;engineering workstations;simulation model	Space is one of the resources that may cause crucial problems during construction. Discrete event simulation has been widely used in construction to allocate resources and improve productivity or mitigate conflicts. However, simulation research that provides an explicit method to investigate possible space conflicts is still limited. This paper suggests a cell-based method to represent space resources in construction simulation, which enables conflict analysis and visual display of the worksite and the occupation of spaces. Different simulation models are compared to identify their limitations in space representation.	explicit and implicit methods;simulation	Cheng Zhang;Tarek M. Zayed;Amin Hammad;Gabriel A. Wainer	2005	Proceedings of the Winter Simulation Conference, 2005.		simulation;construction;resource allocation;computer science;knowledge management;theoretical computer science;discrete event simulation;simulation modeling	SE	-26.197969060709955	-28.418464899045013	199024
294454502a925f426544f11230a4a24b36cb84e5	generative design in architecture using an expert system	architectural design;expert systems;logic programming;interaction pattern;pattern language;3 dimensional;logic programs;generative systems;design methodology;expert system	The mathematician-architect Christopher Alexander has devised a theory of objective architectural design. He believes that all architectural forms can be described as interacting patterns, all possible relationships of which are governed by generative rules. These form a ‘pattern language’ capable of generating forms appropriate for a given environmental context. The complexity of interaction among these rules leads to difficulties in their representation by conventional methods. This paper presents a Prolog-based expert system which implements Alexander's design methodology to produce perspective views of partially and fully differentiated 3-dimensional architectural forms.	acorn eurocard systems;design tool;experience;experiment;expert system;high- and low-level;humans;input/output;integrated development environment;interaction;introspection;knowledge-based systems;level of detail;pattern language;prolog;raster graphics;theory;user interface	Eric Gullichsen;Ernest Chang	1985	The Visual Computer	10.1007/BF01910018	generative systems;three-dimensional space;design methods;architectural pattern;computer science;artificial intelligence;machine learning;interaction design pattern;pattern language;logic programming;expert system;algorithm;generative design	HCI	-32.70376346880996	-24.467598456179932	199127
7e391d2041ef2f165f2b3a8c5584d77171a38358	a heterogeneous fleet of vehicles for automated humanitarian missions	simulation;mobile robots;cyber physical systems;emergency services computational modeling vehicles unmanned aerial vehicles land vehicles;visualization;computational modeling;land vehicles;scientific computing;virtual integration;vehicles;operations;model based design;modeling;unmanned aerial vehicles;humanitarian;wireless control;emergency services;scientific computing humanitarian cyber physical systems operations virtual integration modeling simulation wireless control model based design visualization	An automated emergency response system and an experimental framework for its design and validation are presented here. The system consists of a high-level mission optimization and a fleet of heterogeneous autonomous vehicles. The fleet includes ground vehicles for setting up local stations, fixed-wing aircraft for assessing infrastructure damage and performing surveillance, and rotorcraft for delivering emergency supplies. Internet technology provides a unifying environment for the vehicles, optimization module, operators, and emergency responders with support for computational integration in cyberspace.	autonomous robot;binocular disparity;computation;computational resource;computer engineering;computer science;cyber-physical system;cyberspace;geographic coordinate system;google earth;high- and low-level;internet protocol suite;mathematical optimization;programming paradigm;testbed;waypoint	Pieter J. Mosterman;David Escobar Sanabria;Enes Bilgin;Kun Zhang;Justyna Zander	2014	Computing in Science & Engineering	10.1109/MCSE.2014.58	mobile robot;computational science;simulation;systems modeling;visualization;computer science;cyber-physical system;computational model;model-based design;computer security	Robotics	-22.780258054315603	-24.304322287599074	199342
00967886fa42fa01c55d2bf4cc16f62300bc968c	virtual environments for shipboard firefighting training	fire effects;performance evaluation;shipboard firefighting training;feasibility tests immersive virtual environment shipboard firefighting training uss shadwell navy full scale fire research ship fire test ship mission rehearsal head mounted display 3d joystick user navigation user interaction fire effects smoke effects;fire fighting;information technology;training;virtual reality;mission rehearsal;telecommunication computing;missions;full scale fire research ship;smoke ships virtual reality computer based training fires naval engineering computing interactive devices engineering education;navigation;uss shadwell;navy;ships;smoke effects;marine vehicles;engineering education;computer based training;3d joystick;fire test ship;space missions;system testing;feasibility tests;user navigation;tires;naval engineering computing;smoke;virtual environment;test equipment;fires marine vehicles navigation virtual environment information technology tires space missions performance evaluation system testing telecommunication computing;fires;user interaction;shipboard;interactive devices;immersive virtual environment;feasibility studies;head mounted display	A virtual environment (VE) of portions of the ex-USS Shadwell , the Navy's full-scale fire research and test ship, has been developed to study the feasibility of using immersive VE as a tool for shipboard firefighting training and mission rehearsal. The VE system uses a headmounted display and 3D joystick to allow users to navigate through and interact with the environment. Fire and smoke effects are added to simulate actual firefighting conditions. This paper describes the feasibility tests that were performed aboard the Shadwell and presents promising results of the benefits of VE training over conventional training methods.	full scale;joystick;simulation;unix system services;virtual reality	David L. Tate;Linda E. Sibert;Tony King	1997		10.1109/VRAIS.1997.583045	navigation;simulation;engineering education;computer science;virtual machine;optical head-mounted display;space exploration;virtual reality;information technology;system testing;smoke	HCI	-31.612677364116017	-37.62421035303684	199557
