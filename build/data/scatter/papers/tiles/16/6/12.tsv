id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
3c13a063a5c92018fa808fd2bb7671e86b434bc9	a two-tiered on-demand resource allocation mechanism for vm-based data centers	optimisation;software prototyping;servers tiered on demand resource allocation vm based data center shared virtual computing environment dynamic load quality requirement static resource allocation enterprise data center virtual machine dynamic resource allocation method optimization global resource allocation local resource allocation concurrent application critical application time varying capacity demand rainbow xen based prototype cpu utilization;resource allocation;resource management;client server systems;computer centres;algorithm;servers;virtual machines client server systems computer centres concurrency theory multiprocessing systems optimisation resource allocation software prototyping;virtual machines;heuristic algorithms;期刊论文;model;optimization;multiprocessing systems;resource management servers dynamic scheduling optimization heuristic algorithms algorithm design and analysis data models;algorithm design and analysis;on demand resource allocation;model data centers virtual machines on demand resource allocation optimization algorithm;dynamic scheduling;data models;concurrency theory;data centers	In a shared virtual computing environment, dynamic load changes as well as different quality requirements of applications in their lifetime give rise to dynamic and various capacity demands, which results in lower resource utilization and application quality using the existing static resource allocation. Furthermore, the total required capacities of all the hosted applications in current enterprise data centers, for example, Google, may surpass the capacities of the platform. In this paper, we argue that the existing techniques by turning on or off servers with the help of virtual machine (VM) migration is not enough. Instead, finding an optimized dynamic resource allocation method to solve the problem of on-demand resource provision for VMs is the key to improve the efficiency of data centers. However, the existing dynamic resource allocation methods only focus on either the local optimization within a server or central global optimization, limiting the efficiency of data centers. We propose a two-tiered on-demand resource allocation mechanism consisting of the local and global resource allocation with feedback to provide on-demand capacities to the concurrent applications. We model the on-demand resource allocation using optimization theory. Based on the proposed dynamic resource allocation mechanism and model, we propose a set of on-demand resource allocation algorithms. Our algorithms preferentially ensure performance of critical applications named by the data center manager when resource competition arises according to the time-varying capacity demands and the quality of applications. Using Rainbow, a Xen-based prototype we implemented, we evaluate the VM-based shared platform as well as the two-tiered on-demand resource allocation mechanism and algorithms. The experimental results show that Rainbow without dynamic resource allocation (Rainbow-NDA) provides 26 to 324 percent improvements in the application performance, as well as 26 percent higher average CPU utilization than traditional service computing framework, in which applications use exclusive servers. The two-tiered on-demand resource allocation further improves performance by 9 to 16 percent for those critical applications, 75 percent of the maximum performance improvement, introducing up to 5 percent performance degradations to others, with 1 to 5 percent improvements in the resource utilization in comparison with Rainbow-NDA.	algorithm;central processing unit;data center;dynamic dispatch;elegant degradation;feedback;global optimization;input/output;load balancing (computing);mathematical optimization;memory management;multitier architecture;openvms;overhead (computing);prototype;rainbow 100;requirement;scheduling (computing);server (computing);services computing;virtual machine;z/vm	Ying Song;Yuzhong Sun;Weisong Shi	2013	IEEE Transactions on Services Computing	10.1109/TSC.2011.41	data modeling;algorithm design;data center;real-time computing;dynamic priority scheduling;resource allocation;computer science;virtual machine;resource management;operating system;static memory allocation;database;distributed computing;resource allocation;server;computer network	HPC	-19.85456669346512	62.323312310163324	70872
46fdd796e8cab3e6f9203f25caa7dc26a84f3eca	lottery-based pricing scheme for peer to peer networks	history;peer to peer network;pricing;resource management;p2p;technology management;pricing peer to peer computing costs resource management technology management telecommunication network management bandwidth scalability environmental economics history;environmental economics;bandwidth;scalability;p2p networks;peer to peer computing;peer to peer;free riding;telecommunication network management	Users in Peer-to-Peer (P2P) networks tend to exploit the maximum resources they are able to obtain, offering minimum resources in response. This behavior undermines the goal of P2P in spreading files through the network and imposes the concept of free-riding. In this paper we propose a Lottery-based pricing mechanism to enhance the sharing level in P2P network and help increasing the number of objects disseminated. The scheme is an extension of the traditional micropayment mechanism. Our scheme provides higher payoff for peers who contribute to the P2P network and higher cost for peers who act selfishly and choose not to share resources. Finally, we present our simulation results to demonstrate the performance of our proposed mechanism.	micropayment;peer-to-peer;peer-to-peer file sharing;simulation	Manaf Zghaibeh;Fotios C. Harmantzis	2006	2006 IEEE International Conference on Communications	10.1109/ICC.2006.254822	pricing;scalability;simulation;computer science;technology management;resource management;peer-to-peer;free riding;computer security;bandwidth;computer network	DB	-25.280365631816903	73.47613622968994	70942
9f3bae0cba415df01a39670f476245af6efaeb1f	a comparitive study of predictive models for cloud infrastructure management	predictive modeling;resource management;measurement uncertainty;holt winter;servers;resource allocation cloud computing;predictive models;predictive models servers cloud computing data models measurement uncertainty;arima predictive modeling cloud computing resource management holt winter;autoregressive integrated moving average model predictive models cloud infrastructure management cloud service providers resource consumption provision resource deprovision resources predictive approach resource management holt winter model arima model public web server data set request rate;arima;cloud computing;data models	Cloud service providers, monitor average resource (for e.g. CPU) consumption and based on predefined limits (for e.g. CPU-Idle-time > 500 milliseconds), provision or de-provision resources. Traditionally this is a reactive approach and doesn't fully address the wide range of enterprise use cases. Implementation of predictive approach to resource management has been rarely reported even though they could perform potentially better than their counterpart. Identification of a suitable model for predicting the performance of the system under a load is an ideal precursor in managing resources on a cloud environment. The current study compares the performance of two such predictive models namely Holt-Winter and ARIMA using a public web server data set Request rate was used as the metric to monitor resource consumption. The experiment results show that Holt-Winter model performs better than a few selected ARIMA models, which could be subsequently used for managing resources on cloud if the data request rates follow a similar pattern.	ai winter;autoregressive integrated moving average;central processing unit;cloud computing;curve fitting;predictive modelling;queueing theory;server (computing);web server	Mahesh Balaji;G. Subrahmanya V. R. K. Rao;Cherukuri Aswani Kumar	2014	2014 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing	10.1109/CCGrid.2014.32	exponential smoothing;data modeling;predictive analytics;autoregressive integrated moving average;simulation;cloud computing;computer science;resource management;operating system;data mining;database;predictive modelling;server;statistics;measurement uncertainty	Metrics	-24.223652425019267	61.162946374323376	71050
09bb74d7d7259253d77a008da35b3044f2b533a6	decentralized energy demand regulation in smart homes	pricing;home appliances;scheduling algorithms;energy consumption;aggregates;schedules;smart homes	Smart grids offer better energy management at consumer premises as well as energy companies side using bi- directional communication and control. Energy companies can balance energy supply and demand to a large extent, with the advent of smart homes. They can also nudge consumers to shift their demands to off-peak hours for load balancing and monetary benefits. We propose a decentralized demand scheduling algorithm that minimizes consumer discomfort and electricity cost of a household. Our algorithm utilizes only aggregated energy consumption of a household to derive optimal appliance level demand schedules. Furthermore, a low-complexity energy disaggregation algorithm is proposed to derive fine- grained appliance information and consumer preferences. We propose three important coefficients related to energy usage of consumers. We utilize them to derive optimal day- ahead demand schedules. The decentralized algorithm is empirically evaluated using real-world energy usage data from open datasets, which include our own deployment. Our proposed scheduling algorithm saves up to 30% energy cost. This work is one of the first to derive day-ahead schedules using real-world data from multiple households.	algorithm;coefficient;embedded system;load balancing (computing);nudge (instant messaging);raspberry pi 3 model b (latest version);real-time clock;scalability;schedule (computer science);scheduling (computing);smart tv;software deployment;usage data;variable pricing	S. N. Akshay Uttama Nambi;Antonio Reyes Lua;R. Venkatesha Prasad	2016	2016 IEEE Global Communications Conference (GLOBECOM)	10.1109/GLOCOM.2016.7841718	pricing;schedule;computer science;scheduling	Robotics	-21.38328087678541	63.528490596578386	71238
3d7c1f6c975493755993d0a7adda53b2cf009ad4	a decentralized approach for monitoring timing constraints of event flows	timing violation;event flows;distributed system;timing constraints;timing distributed processing fault diagnosis real time systems system monitoring;run time monitoring;timing fault specification;distributed processing;system monitoring;end to end timing constraint violations;deployed systems;run time path;timing monitoring real time systems context hardware receivers fault detection;real time systems run time monitoring timing constraints timing violation distributed systems;receivers;distributed real time system;monitoring;diagnostic information decentralized approach timing constraints event flows run time monitoring framework end to end timing constraint violations distributed real time systems event flow paths timing fault checks run time detection timing violation run time path time consumption software module timing fault handler timing fault specification deployed systems;time consumption;diagnostic information;fault detection;timing fault handler;run time monitoring framework;software module;event flow paths;distributed systems;timing fault checks;distributed real time systems;decentralized approach;run time detection;context;fault diagnosis;hardware;real time systems;timing;time constraint	This paper presents a run-time monitoring framework to detect end-to-end timing constraint violations of event flows in distributed real-time systems. The framework analyzes every event on possible event flow paths and automatically inserts timing fault checks for run-time detection. When the framework detects a timing violation, it provides users with the event flow's run-time path and the time consumption of each participating software module. In addition, it invokes a timing fault handler according to the timing fault specification, which allows our approach to aid the monitoring and management of the deployed systems. The experimental results show that the framework correctly detects timing constraint with insignificant overhead and provides related diagnostic information.	end-to-end principle;overhead (computing);real-time clock;real-time computing	Hyoseung Kim;Shinyoung Yi;Wonwoo Jung;Hojung Cha	2010	2010 31st IEEE Real-Time Systems Symposium	10.1109/RTSS.2010.11	embedded system;system monitoring;real-time computing;computer science;distributed computing;fault detection and isolation	Embedded	-28.21846147278942	65.88366437484048	71423
45cd8e2dff56c0f3840d3f759c9a5ccec2d04a1f	predictive and dynamic resource allocation for enterprise applications	forecasting;workload prediction algorithm;resource allocation;enterprise systems;resource management;prediction algorithms;resource allocation enterprise resource planning;multiserver solution dynamic resource allocation predictive resource allocation enterprise applications enterprise systems workload prediction algorithm switching policies;predictors;qa76 electronic computers computer science computer software;dynamic resource allocation;switching policies;switches servers prediction algorithms forecasting predictive models resource management dynamic scheduling;qa75 electronic computers computer science;servers;moving average;predictive resource allocation;switching policies predictors dynamic resource allocation enterprise applications;enterprise resource planning;internet services;predictive models;enterprise system;multiserver solution;enterprise applications;switches;dynamic scheduling;qa76 computer software	Dynamic resource allocation has the potential to provide significant increases in total revenue in enterprise systems through the reallocation of available resources as the demands on hosted applications change over time. This paper investigates the combination of workload prediction algorithms and switching policies: the former aim to forecast the workload associated with Internet services, the latter switch resources between applications according to certain system criteria. An evaluation of two well known switching policies – the proportional switching policy (PSP) and the bottleneck aware switching policy (BSP) – is conducted in the context of seven workload prediction algorithms. This study uses real-world workload traces consisting of approximately 3.5M requests, and models a multi-tiered, cluster-based, multi-server solution. The results show that a combination of the bottleneck aware switching policy and workload predictions based on an autoregressive, integrated, moving-average model can improve system revenue by as much as 43%.	algorithm;authentication;autoregressive integrated moving average;autoregressive model;control system;enterprise resource planning;enterprise system;ibm tivoli workload scheduler;kerrison predictor;moving-average model;server (computing);tracing (software);web service	M. Al-Ghamdi;Adam P. Chester;Stephen A. Jarvis	2010	2010 10th IEEE International Conference on Computer and Information Technology	10.1109/CIT.2010.463	enterprise system;real-time computing;simulation;computer science;resource management;statistics	HPC	-23.18573065876169	63.15014136695028	71475
b6e087f0851dc588b253bf8bfea9d9574be91b2f	resilience metrics for service-oriented networks: a service allocation approach	service oriented networks;graph theoretic model;reliability;theoretical model;service system;resilience metrics;service orientation;efficient algorithm;resilience metrics service allocation service distribution optimization of service systems;topological structure;service distribution;data mining;edge failures;resilience algorithm design and analysis peer to peer computing computational modeling reliability data mining computer architecture;computer architecture;software architecture;computational modeling;resilience;web services software architecture;web services;service distribution resilience metrics service oriented networks service allocation graph theoretic model node failures edge failures topological structure;service allocation;peer to peer computing;connected component;algorithm design and analysis;node failures;minimum cut;optimization of service systems	We develop a graph-theoretic model for service-oriented networks and propose metrics that quantify the resilience of such networks under node and edge failures. These metrics are based on the topological structure of the network and the manner in which services are distributed over the network. We present efficient algorithms to determine the maximum number of node and edge failures that can be tolerated by a given service-oriented network. These algorithms rely on known algorithms for computing minimum cuts in graphs. We also present efficient algorithms for optimally allocating services over a given network so that the resulting service-oriented network can tolerate single node or edge failures. These algorithms are derived through a careful analysis of the decomposition of the underlying network into appropriate types of connected components.	algorithm;connected component (graph theory);graph theory;service-oriented architecture;service-oriented device architecture	Daniel J. Rosenkrantz;Sanjay Goel;S. S. Ravi;Jagdish Gangolly	2009	IEEE Transactions on Services Computing	10.1109/TSC.2009.18	web service;algorithm design;software architecture;connected component;minimum cut;computer science;data mining;reliability;network simulation;distributed computing;computational model;law;psychological resilience;computer network;service system	Theory	-19.841228579451823	66.48475666666184	71518
4443520504263a656a773e1b62cf6018c8c95686	resource allocation for cloud-assisted mobile applications	ray tracing cloud computing mobile computing resource allocation middleware;resource allocation;battery powered devices;resource management;tablets;netbooks;smartphones;cost analysis;public domain software;servers;computational modeling;resource management computational modeling servers mobile communication cloud computing mobile handsets;mobile communication;ray tracing;mobile handsets;cloud assisted mobile applications;resource allocation cloud computing java middleware mobile computing public domain software ray tracing;middleware;java applications;cloud computing resources;cost analysis resource allocation cloud assisted mobile applications mobile devices netbooks smartphones tablets battery powered devices cloud computing resources middleware java applications sunflow open source ray tracing application amazon ec2;mobile computing;amazon ec2;mobile application;mobile devices;cloud computing;open source ray tracing application;java;sunflow	Mobile devices such as netbooks, smartphones, and tablets have made computing ubiquitous. However, such battery powered devices often have limited computing power for the benefit of an extended runtime. Nevertheless, despite the reduced processing power, users expect to perform the same types of operations as they could do using their desktop or laptop computers. We address mobile devices's lack of computing power by leveraging cloud computing resources. We present a middleware that relocates computing-intensive parts of Java applications to cloud re-sources. Consequently, our middleware enables the execution of computing-intensive applications on mo-bile devices. We present a case study on which we adapt Sunflow, an open-source ray tracing application, to use our middleware and show the results obtained by deploying it on Amazon EC2. We show, via simulations, a cost analysis of using the different resource allocation strategies available on our solution.	amazon elastic compute cloud (ec2);cloud computing;desktop computer;java platform, micro edition;laptop;middleware;mobile device;netbook;open-source software;ray tracing (graphics);service-level agreement;simulation;smartphone;software as a service;speedup;sunflow;tablet computer	Marvin Ferber;Thomas Rauber;Mário Henrique C. Torres;Tom Holvoet	2012	2012 IEEE Fifth International Conference on Cloud Computing	10.1109/CLOUD.2012.75	embedded system;ray tracing;real-time computing;mobile telephony;cloud computing;resource allocation;computer science;cost–benefit analysis;resource management;operating system;middleware;mobile device;java;mobile computing;computational model;public domain software;server	HPC	-24.029569342672286	66.44880062097928	72226
a16726979d5cd6072753810730c596476ab24737	secure interoperation in a multidomain environment employing rbac policies	criterio optimalidad;multidomaine;internet protocol;distributed system;controle acces;systeme reparti;programacion entera;policy integration;protocolo internet;index terms secure interoperation;authorisation;multidomain;securite informatique;protocole internet;role based access control;indexing terms;programmation en nombres entiers;computer security;open systems authorisation internet integer programming;access control policy;sistema repartido;internet;integer programming;optimality criterion multidomain application environment secure interoperation internet based enterprise policy integration framework heterogeneous role based access control integer programming;seguridad informatica;algorithme reparti;algoritmo repartido;optimality criterion;access control;critere optimalite;integer program;access control information security data security multilevel systems application software collaboration resource management computer society internet merging;open systems;security policy;distributed algorithm;securite interoperation;secure interoperation;role based access control rbac;multidomain index terms secure interoperation policy integration role based access control rbac	Multidomain application environments where distributed multiple organizations interoperate with each other are becoming a reality as witnessed by emerging Internet-based enterprise applications. Composition of a global coherent security policy that governs information and resource accesses in such environments is a challenging problem. In this paper, we propose a policy integration framework for merging heterogeneous role-based access control (RBAC) policies of multiple domains into a global access control policy. A key challenge in composition of this policy is the resolution of conflicts that may arise among the RBAC policies of individual domains. We propose an integer programming (IP)-based approach for optimal resolution of such conflicts. The optimality criterion is to maximize interdomain role accesses without exceeding the autonomy losses beyond the acceptable limit.	approximation algorithm;autonomous robot;autonomy;coherence (physics);computation;enterprise software;heuristic (computer science);integer programming;inter-domain;interoperability;interoperation;iteration;lagrangian relaxation;linear programming relaxation;mathematical optimization;optimality criterion;optimization problem;overhead (computing);polynomial;real-time transcription;requirement;role-based access control;simulated annealing;tabu search;time complexity	Basit Shafiq;James B. D. Joshi;Elisa Bertino;Arif Ghafoor	2005	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2005.185	internet protocol;distributed algorithm;the internet;integer programming;index term;computer science;security policy;access control;role-based access control;data mining;database;distributed computing;authorization;open system;world wide web;computer security	DB	-27.712947964200414	69.7960594703967	72784
0a6bd0a8ccf34ebe2704b521ad8342c5dc60aec1	performance prediction for black-box components using reengineered parametric behaviour models	integrated approach;component based software engineering;repeated measures;performance prediction;file sharing	In component-based software engineering, the response time of an entire application is often predicted from the execution durations of individual component services. However, these execution durations are specific for an execution platform (i.e. its resources such as CPU) and for a usage profile. Reusing an existing component on different execution platforms up to now required repeated measurements of the concerned components for each relevant combination of execution platform and usage profile, leading to high effort. This paper presents a novel integrated approach that overcomes these limitations by reconstructing behaviour models with platform-independent resource demands of bytecode components. The reconstructed models are parameterised over input parameter values. Using platform-specific results of bytecode benchmarking, our approach is able to translate the platform-independent resource demands into predictions for execution durations on a certain platform. We validate our approach by predicting the performance of a file sharing application.	application programming interface;behavioral modeling;benchmark (computing);central processing unit;circa;component-based software engineering;file sharing;java class library;java bytecode;list of java apis;parameter (computer programming);performance prediction;platform-specific model;response time (technology);run time (program lifecycle phase);upload	Michael Kuperberg;Klaus Krogmann;Ralf H. Reussner	2008		10.1007/978-3-540-87891-9_4	repeated measures design;real-time computing;simulation;computer science;component-based software engineering;operating system;programming language;file sharing	SE	-25.026620435621634	61.017916328982594	72788
a0d032749e73ffb67ac9711ec405b7812f783435	high-performance benchmarking with web polygraph	benchmarking;http;intermediaries;performance;design and implementation;proxies;high performance;web proxy;simulation model	This paper presents the design and implementation of Web Polygraph, a tool for benchmarking HTTP intermediaries. We discuss various challenges involved in simulating Web traffic and in developing a portable, high performance tool for generating such traffic. Polygraph’s simulation models, as well as our experiences with developing and running the benchmark, may be useful for Web proxy developers, performance analysts, and researchers interested in Web traffic simulation.	benchmark (computing);hypertext transfer protocol;proxy server;simulation;web traffic	Alex Rousskov;Duane Wessels	2004	Softw., Pract. Exper.	10.1002/spe.576	hypertext transfer protocol;web modeling;simulation;web analytics;performance;computer science;engineering;operating system;intermediary;simulation modeling;world wide web;computer security;benchmarking	Web+IR	-21.14604644103913	71.85924427258847	72869
48bbc61daf473c27c8c060987ae950e68047c3a9	mobiles on cloud nine: efficient task migration policies for cloud computing systems	elektroteknik och elektronik;electrical engineering electronic engineering information engineering;wireless access infrastructure task migration policies cloud computing systems mobile cloud computing architecture shared resource contention reduction;guidelines;datalogi;wireless communication mobile cloud computing task migration;computer science;radio access networks cloud computing mobile computing mobile radio	Due to limited processing and energy resources, mobile devices outsource their computationally intensive tasks to the cloud. However, clouds are shared facilities and hence task execution time may vary significantly. In this paper, we investigate the potential of task migrations to reduce contention for the shared resources of a mobile cloud computing architecture in which local clouds are attached to wireless access infrastructure (e.g. wireless base stations or access points). We devise online migration strategies that at each time make migration decisions according to the instantaneous load and the anticipated execution time. We explicitly take into account the interaction of co-located tasks in a server and the cost of migrations. We propose three classes of migration policies, ranging from fully uncoordinated ones, in which each user or server autonomously makes its migration decisions, up to cloud-wide ones, where migration decisions are made by the cloud provider. The key underlying idea is that a migration should occur only if it is beneficial for the processing time of the task, including the migration delay.	algorithm;cloud computing architecture;computer architecture;eisenstein's criterion;mobile cloud computing;mobile device;outsourcing;run time (program lifecycle phase);server (computing);wireless access point;z/vm	Lazaros Gkatzikis;Iordanis Koutsopoulos	2014	2014 IEEE 3rd International Conference on Cloud Networking (CloudNet)	10.1109/CloudNet.2014.6968993	cloud computing security;real-time computing;cloud computing;computer science;distributed computing;computer network	Embedded	-23.19612644464663	66.99107489709583	73050
2cd4844ca1e4429b5e8d09cc053dc85cf9e75584	on maximizing provider revenue in market-based compute grids	analytical models;service provider revenue maximization;nist;computational grid;service provider;tractable analytical model;processor scheduling;resource allocation;resource management;utility function;computational modeling;admitted job scheduling;aggregates;scheduling;revenue maximization;milling machines;market based compute grids;scheduling grid computing resource allocation;numerical models;grid computing resource management admission control analytical models processor scheduling aggregates computational modeling milling machines nist numerical models;willingness to pay;linear user utility function;grid computing;resource management market based compute grids service provider revenue maximization admitted job scheduling admission control tractable analytical model linear user utility function resource allocation;analytical model;admission control	Market-based compute grids encompass service providers offering limited resources to potential users with varying demands and willingness to pay. Providers face difficult decisions about which jobs to admit and when to schedule admitted jobs. For this reason, researchers investigate various heuristics for admission control and scheduling that aim to yield high revenue for providers. Such research has no framework within which to understand the revenue bounds associated with various workloads. This paper proposes a tractable analytical model for joint optimization of job admission and scheduling strategies aimed at provider revenue maximization. We show how solving this model yields maximum provider revenue given a linear user utility function. Our model can be used to understand the operating limits of heuristics for admission control and scheduling, and can also be used to investigate the implication of varying job.	cobham's thesis;expectation–maximization algorithm;heuristic (computer science);job stream;mathematical optimization;scheduling (computing);utility	Vladimir Marbukh;Kevin Mills	2007	International Conference on Networking and Services (ICNS '07)	10.1109/ICNS.2007.84	service provider;simulation;nist;resource allocation;computer science;resource management;operating system;management science;computational model;scheduling;grid computing	Robotics	-22.922393742564587	63.81711306603201	73584
0237d4eecfe2077dee2a4c790ae1a5796bf82742	compute power market: towards a market-oriented grid	job deployment;renting;information resources;service consumers;commodity market model;distributed memory systems;electronic commerce;internet wide computational resources;markets;market server;power market;personal computer;market model;processor scheduling;resource allocation;pricing;computational economy;dp industry;resource manager;resource management;job deployment compute power market market oriented grid cpm market based resource management job scheduling system grid computing internet wide computational resources low end personal computing devices metacomputing environment computational market renting special services resource consumers resource providers economic models commodity market model contract net tendering auction resource pricing service consumers decentralized computation market grid environment market server market resource agent market resource broker market trader scheduler negotiation;low end personal computing devices;compute power market;special services;economic model;market resource broker;metacomputing environment;job scheduling system;economic models;resource pricing;grid computing power markets processor scheduling resource management internet metacomputing power generation economics environmental economics pricing computer architecture;computer architecture;power markets;internet computing;internet;auction;computational market;scheduling;cpm;market based resource management;market oriented grid;scheduler;environmental economics;grid environment;market orientation;resource broker;contract net tendering;market trader;metacomputing;grids;resource consumers;grid computing;market resource agent;job scheduling;distributed memory systems internet electronic commerce resource allocation information resources dp industry scheduling;decentralized computation market;negotiation;power generation economics;resource providers	The Compute Power Market (CPM) is a market-based resource management and job scheduling system for grid computing on Internet-wide computational resources, particularly low-end personal computing devices. It transforms the metacomputing environment into a computational market wherein one can solve problems by renting computational power, storage, and special services from idle resources (computers). The CPM primarily comprises of markets, resource consumers, resource providers and their interactions. It supports various economic models (commodity market model, contract-net/ tendering, and auction) for resource pricing and mapping between service consumers and providers. This paper proposes a decentralized computation market with multiple markets and numerous consumers and providers spread across the grid environment. The paper further discusses the basic architecture and the components involved in markets, consumers and providers namely, a Market Server, a Market Resource Agent, a Market Resource Broker and a Market Trader and scheduler used for negotiation and job deployment.	computation;computational resource;contract net protocol;entropia universe;game server;geographical distance;grid computing;information system;interaction;internet;job scheduler;legion (software);metacomputing;personal computer;procurement;seti@home;scheduling (computing);software deployment;traders	Rajkumar Buyya;Sudharshan S. Vazhkudai	2001		10.1109/CCGRID.2001.923245	computer science;economic model;resource management;operating system	ECom	-23.649594419335084	64.93981137131493	73619
574f02746c631115ee495ca66530f852ee170350	dynamic optimization of power and performance for virtualized server clusters	optimal solution;virtualization;performance management;server clusters;dynamic control;power optimization;power consumption;optimization model;dynamic optimization	In this paper we present an optimization solution for power and performance management in a platform running multiple independent applications. Our approach assumes a virtualized server environment and includes an optimization model and strategy to dynamically control the cluster power consumption, while meeting the application's workload demands.	mathematical optimization;server (computing)	Vinicius Petrucci;Orlando Loques;Daniel Mossé	2010		10.1145/1774088.1774144	embedded system;performance management;real-time computing;virtualization;computer science;operating system;management;power optimization	HPC	-20.598130110834028	62.946032075453495	74006
9d8690dbfd946b0ec80cc2a9a3ada9ddfe9243d9	cost minimization for deadline-constrained bag-of-tasks applications in federated hybrid clouds	deadline constrained;bag of tasks applications;federated hybrid clouds;binary linear programming;cost minimization;scheduling	A mathematical programming model is proposed for a resource allocation problem in federated clouds, where bag-of-tasks (BoT) applications are assigned to instance types with different costs and performance levels. The proposed model is a binary linear programming problem containing deadline and resource constraints in the cloud federations and by the objective of minimizing the total cost of applications. These constraints and objective are explicitly expressed using mathematical functions, and the model is solved with the CPLEX solver. This paper also discusses a post-optimality analysis that deals with stability in assignment problems. Numerical results show that the optimal cost and optimal solutions in the cloud federations are lower and more stable, respectively, than those presented by single-provider clouds. In contrast to optimality in single-provider clouds, that in the cloud federations is less sensitive to input data.		Somayeh Abdi;Latif Pourkarimi;Mahmood Ahmadi;Farzad Zargari	2017	Future Generation Comp. Syst.	10.1016/j.future.2017.01.036	real-time computing;simulation;computer science;operating system;distributed computing;scheduling	Arch	-19.55027217789662	64.31749372681594	74122
170c133bb5e5061e5bfe8574e8ab0eaafd4f69b0	an efficient multicast protocol for content-based publish-subscribe systems	distributed algorithms;electrical capacitance tomography;protocols;multicast communication;client server systems distributed algorithms multicast communication protocols;rivers;multicast algorithms;cpu utilization;link matching;publish subscribe system;client server systems;multicast protocols publish subscribe floods electrical capacitance tomography multicast algorithms milling machines rivers wide area networks table lookup matched filters;content based publish subscribe systems;multicast protocols;distributed environment;publish subscribe;milling machines;multicast protocol;matched filters;scalability;floods;table lookup;distributed algorithm;content based subscribers;geographic distribution;wide area networks;cpu utilization multicast protocol content based publish subscribe systems distributed environment scalability content based subscribers distributed algorithm link matching	The publish/subscribe (or pub/sub) paradigm is a simple and easy to use model for interconnecting applications in a distributed environment. Many existing pub/sub systems are based on pre-defined subjects, and hence are able to exploit multicast technologies to provide scalability and availability. An emerging alternative to subject-based systems, known as content-based systems, allow information consumers to request events based on the content of published messages. This model is considerably more flexible than subject-based pub/sub, however it was previously not known how to efficiently multicast published messages to interested content-based subscribers within a network of broker (or router) machines. This shortcoming limits the applicability of content-based pub/sub in large or geographically distributed settings. In this paper, we develop and evaluate a novel and efficient technique for multicasting within a network of brokers in a content-based subscription system, thereby showing that content-based pub/sub can be deployed in large or geographically distributed settings.	exploit (computer security);flooding algorithm;hop-by-hop transport;locality of reference;multicast;private network;programming paradigm;publish–subscribe pattern;queueing theory;router (computing);routing;scalability;system testing;undo	Guruduth Banavar;Tushar Deepak Chandra;Bodhi Mukherjee;Jay Nagarajarao;Robert E. Strom;Daniel C. Sturman	1999		10.1109/ICDCS.1999.776528	communications protocol;distributed algorithm;scalability;computer science;cpu time;database;distributed computing;publish–subscribe pattern;matched filter;world wide web;distributed computing environment;computer network	Security	-20.276640492166646	69.86276982335224	74770
dba2c29d1c9c0e8d672d7f1e61360ea7b391d862	a payment scheme in crowdsourcing		Crowdsourcing coordinates a large group of workers online to do self-contained small tasks that are published by job requesters on a crowdsourcing platform. Many papers propose incentive strategies to motivate workers to participate in crowdsourcing. In this paper, we shift the focus from the workers to the job requesters by addressing two of their issues: how to design a good payment scheme to maximize profit and how to select qualified workers to do the job. We use a widely-adopted payment formula consisting of a base salary and extra bonus. We first formulate the problem as an optimization problem and then provide a general solution in which we show that the pay rate can be the same to all the workers. Next we instantiate the solution with a concrete example to derive more concrete results and propose a worker selection algorithm WS. In WS, we not only consider workers' workload demands but also their past working performance to guarantee crowdsourcing quality. Simulation results show that a job requester can pay much less to get the job done in a crowdsourcing environment and our worker selection algorithm is efficient in that it only searches a tiny space to find the solution to the optimization problem. Our effort here provides an evidence to support the benefits of using crowdsourcing in our daily lives.	crowdsourcing;mathematical optimization;optimization problem;selection algorithm;simulation	Xiao Chen;Kaiqi Xiong	2017	2017 IEEE International Conference on Communications (ICC)	10.1109/ICC.2017.7996432	workload;remuneration;computer network;algorithm design;salary;computer science;incentive;payment;crowdsourcing;optimization problem	DB	-22.26651195782303	64.78148235737375	74975
e2bbfbe18ea9d9b406aafec0544070ef78e0cbad	energy efficient content-based image retrieval for mobile systems	databases;grid powered server content based image retrieval resource constrained mobile system computation intensive application offloading computation;energy efficiency;resource constrained mobile system;performance evaluation;energy efficiency image retrieval content based retrieval image databases spatial databases mobile computing personal digital assistants network servers grid computing feature extraction;image databases;energy efficient;mobile computing content based retrieval grid computing image retrieval;computation intensive application;grid powered server;personal digital assistants;servers;network servers;energy consumption;feature extraction;spatial databases;offloading computation;mobile handsets;bandwidth;mobile systems;content based image retrieval;mobile computing;grid computing;content based retrieval;energy saving;image retrieval	This paper presents a method to save energy for mobile systems that perform content-based image retrieval (CBIR). CBIR is a computation-intensive application and a resource-constrained mobile system may save energy by offloading computation to a grid-powered server. We develop three offloading schemes based on different conditions to save energy for CBIR on mobile systems. We implement a CBIR algorithm on an HP iPAQ hw6945 and physically measure the energy savings.	algorithm;computation;content-based image retrieval;ipaq;mobile device;server (computing)	Yu-Ju Hong;Karthik Kumar;Yung-Hsiang Lu	2009	2009 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2009.5118095	image retrieval;computer science;theoretical computer science;operating system;database;efficient energy use;mobile computing;world wide web	Embedded	-22.280733165051984	67.60234728408935	75189
f0260e70657910ed0e1d5e27561f1bc0656f5c30	multi-objective optimization for data placement strategy in cloud computing		In cloud computing, the data of processing and the data of transfering is charged at for the service of the provider. So, it is important to reduce the cost and to improve the performance for the consumer of the cloud computing. At present, the existing optimization algorithms only focus on one aspect , such as reducing the move of data, the processing time, the transferring time, the processing cost or the transferring cost. This paper makes a model for the multi-objective data placement and uses a particle swarm optimization algorithm to optimize the time and cost in cloud computing. The mode applied processors interaction graph to map the data of the task and the data center. The simulation experimental result manifests that the proposed method is more effective in time and cost.	cloud computing;multi-objective optimization	Lizheng Guo;Zongyao He;Shuguang Zhao;Na Zhang;Junhao Wang;Changyun Jiang	2012		10.1007/978-3-642-34041-3_18	utility computing	HPC	-19.593754732832746	63.16291041297823	75274
fe4c04aea5c063dfe335c702116e5b938b8fbf58	sna based qos and reliability in fog and cloud framework		Fog and Cloud computing are ubiquitous computing paradigms based on the concepts of utility and grid computing. Cloud service providers permit flexible and dynamic access to virtualized computing resources on pay-per-use basis to the end users. The users having mobile device will like to process maximum number of applications locally by defining fog layer to provide infrastructure for storage and processing of applications. In case demands for resources are not being satisfied by fog layer of mobile device then job is transferred to cloud for processing. Due to large number of jobs and limited resources, fog is prone to deadlock at very large scale. Therefore, Quality of Service (QoS) and reliability are important aspects for heterogeneous fog and cloud framework. In this paper, Social Network Analysis (SNA) technique is used to detect deadlock for resources in fog layer of mobile device. A new concept of free space fog is proposed which helps to remove deadlock by collecting available free resource from all allocated jobs. A set of rules are proposed for a deadlock manager to increase the utilization of resources in fog layer and decrease the response time of request in case deadlock is detected by the system. Two different clouds (public cloud and virtual private cloud) apart from fog layer and free space fog are used to manage deadlock effectively. Selection among them is being done by assigning priorities to the requests and providing resources accordingly from fog and cloud. Therefore, QoS as well as reliability to users can be provided using proposed framework. Cloudsim is used to evaluate resource utilization using Resource Pool Manager (RPM). The results show the effectiveness of proposed technique.	cloud computing;cloudsim;concurrency control;deadlock;distance fog;grid computing;heterogeneous computing;job stream;mobile device;quality of service;response time (technology);service layer;service-level agreement;social network analysis;ubiquitous computing;virtual private cloud	Sandeep K. Sood	2018	World Wide Web	10.1007/s11280-018-0525-x	grid computing;data mining;cloudsim;computer science;ubiquitous computing;deadlock;quality of service;distributed computing;mobile device;cloud computing;deadlock prevention algorithms	HPC	-20.085727517118272	63.99002010776857	75745
a8666b20312d0b6f4450228b96faf5cca4876206	managed control of composite cloud systems	service provider;usage management;resource allocation;management control;system of systems;system of systems usage management cloud computing;quality of service control systems cloud computing measurement monitoring complexity theory resource management;management strategy;infrastructure as a service;usage management strategy composite cloud systems cloud providers service domain cloud resource management quality of service metric measurement;utility programs;utility programs cloud computing quality of service resource allocation service oriented architecture;quality of service;service oriented architecture;cloud computing	Cloud providers have just begun to provide primitive functionality enabling users to configure and easily provision resources, primarily in the infrastructure as a service domain. In order to effectively manage cloud resources in an automated fashion, systems must automate quality-of-service (QoS) metric measurement as a part of a larger usage management strategy. Collected metrics can then be used within control loops to manage and provision cloud resources. This basic approach can be scaled to monitor the use of system artifacts as well as simple QoS parameters, and can also address the needs of large systems spanning the boundaries of single service providers though the problem seems to moving toward intractability.	cloud computing;computational complexity theory;control flow;control system;entity;file spanning;framing (world wide web);heuristic (computer science);ontology (information science);quality of service;reference implementation;requirement;streaming media;system monitoring;systems architecture	Christopher C. Lamb;Pramod A. Jamkhedkar;Gregory L. Heileman;Chaouki T. Abdallah	2011	2011 6th International Conference on System of Systems Engineering	10.1109/SYSOSE.2011.5966592	service provider;cloud computing security;service level requirement;service level objective;service catalog;cloud computing;service product management;differentiated service;computer science;systems engineering;knowledge management;service delivery framework;operating system;service design;cloud testing;software as a service;utility computing;data as a service;management;world wide web	Embedded	-28.167025008768736	61.01999639754752	75763
cd9deaf9e847b7b20b2b1f609de24c360aa25210	mobile cloud-based big healthcare data processing in smart cities		In recent years, the Smart City concept has become popular for its promise to improve the quality of life of urban citizens. The concept involves multiple disciplines, such as Smart health care, Smart transportation, and Smart community. Most services in Smart Cities, especially in the Smart healthcare domain, require the real-time sharing, processing, and analyzing of Big Healthcare Data for intelligent decision making. Therefore, a strong wireless and mobile communication infrastructure is necessary to connect and access Smart healthcare services, people, and sensors seamlessly, anywhere at any time. In this scenario, mobile cloud computing (MCC) can play a vital role by offloading Big Healthcare Data related tasks, such as sharing, processing, and analysis, from mobile applications to cloud resources, ensuring quality of service demands of end users. Such resource migration, which is also termed virtual machine (VM) migration, is effective in the Smart healthcare scenario in Smart Cities. In this paper, we propose an ant colony optimization-based joint VM migration model for a heterogeneous, MCC-based Smart Healthcare system in Smart City environment. In this model, the user’s mobility and provisioned VM resources in the cloud address the VM migration problem. We also present a thorough performance evaluation to investigate the effectiveness of our proposed model compared with the state-of-the-art approaches.	ant colony optimization algorithms;big data;cloudlet;computation;context awareness;crowdsourcing;data-intensive computing;edge computing;mathematical optimization;mobile app;mobile cloud computing;performance evaluation;provisioning;quality of service;real-time clock;run time (program lifecycle phase);sensor;smart city;tag cloud;the quality of life;time complexity;time-sharing;virtual machine;z/vm	Md. Mofijul Islam;Md. Abdur Razzaque;Mohammad Mehedi Hassan;Walaa N. Ismail;Biao Song	2017	IEEE Access	10.1109/ACCESS.2017.2707439	internet privacy;computer security	AI	-22.911383245481566	68.04879908439818	75814
8768404a1517fe2e53813c8687da36653e3bab2a	centralized and distributed architectures: approximation of the response time in a video surveillance system of road traffic by logarithm, power and linear functions		In this article, we propose mathematical models that result in logarithmic, power and linear functions for the predictive evaluation of the response times of video surveillance systems in smart cities. Most of the QoS measurements and evaluations used in the current literature are hardware based and do not take into account the influence of the technical architecture. We have therefore proposed a decomposition process of video surveillance systems to obtain mathematical approximations of each treatment time. The integration of these components guided us towards generic mathematical models validated by experimentation. The measurements resulting from the experiment were approached with logarithmic, power and linear functions before adopting the most precise model between distributed and centralized architectures. The comparison between these architectures shows a much lower response time for the distributed architecture especially with the determination coefficient (R^2) of the functions.	approximation;centralized computing;linear function;responsiveness	Papa Samour Diop;Ahmath Bamba Mbacke;Gervais Mendy	2017		10.1007/978-3-319-67910-5_26	distributed computing;architecture;linear function;computer network;mathematical model;smart city;quality of service;logarithm;computer science;data transmission;response time;real-time computing	Arch	-24.422361049961314	63.09875473481962	75932
4e8999854fdc3bfcdd043e1fdbfe96e965c27d19	characterizing power and energy usage in cloud computing systems	energy efficiency;server cloud configuration energy usage characterization power characterization cloud computing system data center large scale cloud system operational cost energy efficiency electrical specification system software cloud testbed energy profiling power profiling;file servers;servers benchmark testing hardware power demand cloud computing memory management energy consumption;memory management;system configuration;energy efficient;test bed;power aware computing;large scale;data center;green cloud systems;power usage modeling;energy consumption;power profiling;green cloud systems power profiling power usage modeling energy efficiency;systems and applications;power aware computing cloud computing file servers;cloud computing	Power and energy are primary concerns in the design and management of modern cloud computing systems and data centers. Operational costs for powering and cooling large-scale cloud systems will soon exceed acquisition costs. To improve the energy effciency of cloud computing systems and applications, it is critical to profile the power usage of real systems and applications. Many factors influence power and energy usage in cloud systems, including each components electrical specification, the system usage characteristics of the applications, and system software. In this work, we present the power profiling results on a cloud test bed. We combine hardware and software that achieves power and energy profiling at server granularity. We collect the power and energy usage data with varying server/cloud configurations, and quantify their correlation. Our experiments reveal conclusively how different system configurations affect the server/cloud power and energy usage.	cloud computing;computer cooling;data center;experiment;profiling (computer programming);server (computing);testbed;usage data	Ziming Zhang;Song Fu	2011	2011 IEEE Third International Conference on Cloud Computing Technology and Science	10.1109/CloudCom.2011.29	embedded system;real-time computing;cloud computing;power usage effectiveness;computer science;operating system;cloud testing;efficient energy use	Arch	-21.534855882520585	61.28135295767488	76193
b8d53b67aea5483b22e60e915c5192f9839da7d2	impact of variable priced cloud resources on scientific workflow scheduling	spot instances;performance;scientific workflows;scheduling;cost;grid computing;cloud computing	We analyze the problem of provisioning Cloud instances to large scientific workflows that do not benefit from sufficient Grid resources as required by their computational requirements. We propose an extension to the dynamic critical path scheduling algorithm to deal with the general resource leasing model encountered in today's commercial Clouds. We analyze the availability of the cheaper and unreliable Spot instances and study their potential to complement the unavailability of Grid resources for large workflow executions. Experimental results demonstrate that Spot instances represent a 60% cheaper but equally reliable alternative to Standard instances provided that a correct user bet is made.	scheduling (computing)	Simon Ostermann;Radu Prodan	2012		10.1007/978-3-642-32820-6_35	cloud computing;performance;computer science;operating system;data mining;database;distributed computing;scheduling;grid computing	HPC	-19.143708455267433	61.72325815942036	76944
ca3186e3b4f0ffddb5975f18d04d7e9052c89818	ionn: incremental offloading of neural network computations from mobile devices to edge servers		Current wisdom to run computation-intensive deep neural network (DNN) on resource-constrained mobile devices is allowing the mobile clients to make DNN queries to central cloud servers, where the corresponding DNN models are pre-installed. Unfortunately, this centralized, cloud-based DNN offloading is not appropriate for emerging decentralized cloud infrastructures (e.g., cloudlet, edge/fog servers), where the client may send computation requests to any nearby server located at the edge of the network. To use such a generic edge server for DNN execution, the client should first upload its DNN model to the server, yet it can seriously delay query processing due to long uploading time. This paper proposes IONN (Incremental Offloading of Neural Network), a partitioning-based DNN offloading technique for edge computing. IONN divides a client's DNN model into a few partitions and uploads them to the edge server one by one. The server incrementally builds the DNN model as each DNN partition arrives, allowing the client to start offloading partial DNN execution even before the entire DNN model is uploaded. To decide the best DNN partitions and the uploading order, IONN uses a novel graph-based algorithm. Our experiments show that IONN significantly improves query performance in realistic hardware configurations and network conditions.	algorithm;artificial neural network;centralized computing;cloud computing;cloudlet;computation;content delivery network;database;deep learning;edge computing;experiment;mobile device;pre-installed software;server (computing);upload	Hyuk-Jin Jeong;Hyeon-Jae Lee;Chang Hyun Shin;Soo-Mook Moon	2018		10.1145/3267809.3267828	real-time computing;computer science;computer network;cloud computing;cloudlet;mobile computing;mobile device;computation offloading;server;upload;edge computing	DB	-23.66847591214732	67.35870329781787	77248
bd80bbe4c89287748791a8386fe7fd4f6bd3391e	semantic and locality aware consistency for mobile cooperative editing		This paper presents CoopSLA (Cooperative Semantic Locality Awareness), a consistency model for cooperative editing applications running in resource-constrained mobile devices. In CoopSLA, updates to different parts of the document have different priorities, depending on the relative interest of the user in the region where the update is performed; updates that are considered relevant to the user are propagated frequently, while less important ones are postponed. As a result, the system makes a more intelligent usage of the network resources, since 1) fewer accesses to the network are issued, 2) bandwidth savings are obtained by merging the delayed updates, and 3) reduced bandwidth available is used more efficiently by propagating more relevant updates sooner. These properties are of vital importance in the mobile environments we are addressing, in which devices have limited bandwidth and battery power. We have implemented a collaborative version of Tex editor TexMaker using the CoopSLA approach. We present evaluation results that support our claim that CoopSLA is very effective in reducing the overhead of replica synchronization without imposing limitations to application models.	consistency model;eventual consistency;experiment;locality of reference;middleware;mobile device;overhead (computing)	André Pessoa Negrão;João Costa Seco;Paulo José Azevedo Vianna Ferreira;Luís Veiga	2012		10.1007/978-3-642-33606-5_23	database;world wide web;information retrieval		-19.400018312226326	69.93012610985681	77541
2a29e5f7805a91a28aa5a5e860e8780caf707db4	meeting future needs in mobile computing		The mobile consumer market continues to demand new features, increased performance and extended battery life. These demands must be balanced with cost and other practical concerns. To create a successful next-generation product, we should carefully predict the computations required and create a design without excessive performance and cost. To do this, we consider industry trends and the range of compute engines that can be leveraged on mobiles. We contrast computational capabilities of embedded devices with the evolving requirements of new and existing mobile equipment and applications. In addition to considering how to match next-generation devices with the needs, we will also consider what part of the system should be on-device versus in the cloud.	cloud computing;computation;embedded system;mobile computing;requirement	Michael Polley	2018		10.1145/3177102.3178567	leverage (finance);battery (electricity);computation;real-time computing;mobile computing;cloud computing;computer science	Mobile	-25.550411982931685	67.21124060955032	77595
841535171dd00d18676273a446100ab30c76dd99	scalable and efficient update dissemination for distributed interactive applications	groupware;computer games groupware information dissemination interactive systems distributed object management;distributed interactive applications;limited bandwidth resources distributed interactive applications multiplayer games scalable efficient update dissemination wide area distributed systems response time communication latency shared object replication shared object caching shared objects consistency client interests multicast channels heuristic based algorithm;wide area distributed system;delay multicast algorithms internet distributed computing bandwidth unicast educational institutions heuristic algorithms games virtual reality;multiplayer game;distributed object management;information dissemination;computer games;interactive systems	Distributed interactive applications such as multiplayer games will become increasingly popular in wide area distributed systems. To provide the response time desired by users despite high and unpredictable communication latency in such systems, shared objects will be replicated or cached by clients that participate in the applications. Any updates to the shared objects will have to be disseminated to clients that actually use the objects to maintain consistency. We address the problem of efficient and scalable update dissemination in an environment where client interests can change dynamically and the number of multicast channels available for update dissemination is limited. We present a heuristic based algorithm that can group objects and clients in a way that it handles limited bandwidth resources. We show that our algorithm can produce better results than several algorithms that have been developed in the past for update dissemination.		Tianying Chang;George V. Popescu;Christopher F. Codella	2002		10.1109/ICDCS.2002.1022251	real-time computing;computer science;distributed computing;distributed object;world wide web;collaborative software;computer network	DB	-22.462097937982367	71.53063109927457	77843
01926c45142703d01a7a3d44356c2e3d8c7d00f3	a capacity planning process for performance assurance of component-based distributed systems (abstracts only)	distributed system;kronecker products;modeling technique;capacity planning;service provider;performance estimation;optimization of iterative methods;web portal;numerical methods;software component;service level agreement;high performance;analytical model	For service providers of multi-tiered component-based applications, such as web portals, assuring high performance and availability to their customers without impacting revenue requires effective and careful capacity planning that aims at minimizing the number of resources, and utilizing them efficiently while simultaneously supporting a large customer base and meeting their service level agreements. This paper presents a novel, hybrid capacity planning process that results from a systematic blending of 1) analytical modeling, where traditional modeling techniques are enhanced to overcome their limitations in providing accurate performance estimates; 2) profile-based techniques, which determine performance profiles of individual software components for use in resource allocation and balancing resource usage; and 3) allocation heuristics that determine minimum number of resources to allocate software components. Our results illustrate that using our technique, performance (i.e., bounded response time) can be assured while reducing operating costs by using 25% less resources and increasing revenues by handling 20% more clients compared to traditional approaches.	alpha compositing;component-based software engineering;computer performance;distributed computing;heuristic (computer science);portals;response time (technology);service-level agreement	Nilabja Roy;Abhishek Dubey;Aniruddha S. Gokhale;Lawrence W. Dowdy	2011	SIGMETRICS Performance Evaluation Review	10.1145/2160803.2160831	service provider;numerical analysis;computer science;component-based software engineering;operating system;programming language;computer network	HPC	-22.76767750305781	63.16756539714569	77878
d5f4b1dd45af2660ecb331092df96fc0722d2363	classified power capping with distribution trees in cloud computing	computers;dynamic structure;peer to peer computing power demand servers cloud computing computers power measurement hardware;power management design;service level agreements;power distribution units;power aware computing cloud computing computer centres;power distribution;computer centres;power aware computing;data center;servers;sla;distribution trees;pdu;power budgeting;dynamic capabilities;power management;power capping;service level agreement;peer to peer computing;cloud computing power capping distribution trees;online service;power demand;sla power capping distribution trees cloud computing power management data centers dynamic structure online service power budgeting dynamic capabilities power distribution units pdu power management design service level agreements;power measurement;cloud computing;dynamic properties;hardware;data centers	Power management is becoming very important in data centers. Cloud computing is also one of the newest promising data center techniques which is appealing to many big companies. As cloud computing is different from current data centers in terms of power management due to a dynamic structure and property for its online service. Power budgeting, in terms of its important role in power management, provides powerful solutions for cloud computing with dynamic capabilities. To be specific, existing methods for data centers are based on power distribution units (PDU) divided by fixed locations on physical levels. However, it is not suitable for cloud with the dynamic property. We propose a power management design based at the logical level which uses a distribution tree with classified power capping by different service or workload types. By setting multiple trees, we can differentiate and analyze the effect of workload types and Service Level Agreements (SLAs) in terms of power characteristics.	cloud computing;data center;frequency capping;online service provider;power management;service-level agreement	Zhengkai Wu;Junyao Zhang;Christopher Giles;Jun Wang	2011	2011 IEEE Sixth International Conference on Networking, Architecture, and Storage	10.1109/NAS.2011.52	embedded system;data center;real-time computing;computer science;operating system;distributed computing;law;computer network	HPC	-22.02965872266466	62.96921796145967	78493
e9dfa1563f99efbf7971b3e8bc1afe57dd27aa91	performance management of peer-to-peer distributed hash tables		P2P networking is a distributed model where entities play both the client and server role. One major problem addressed in this model is the discovery, searching and routing in a dynamic distributed environment. Among the different envisaged solutions, Distributed Hash Tables (DHT) are very promising. They allow the build of robust content addressable networks. Despite good theoretical performance properties, infrastructures which implement the model need a performance management framework able to monitor them in case of a concrete deployment. In this article we propose a generic performance management information model for DHTs. Our contribution uses a standard management approach based on the Common Information Model (CIM) Metric model.	distributed hash table;peer-to-peer	Guillaume Doyen;Emmanuel Nataf;Olivier Festor	2005		10.1007/0-387-31170-X_17	double hashing;hash function;merkle tree;sha-2;secure hash algorithm;consistent hashing;secure hash standard;hash chain;hash buster;database;hash list;hash tree	Networks	-33.63414341335553	66.54444624982426	78895
f6d561f7a482b40fdf787a160e041a375c7fbf70	the incentive secure mechanism based on quality of service in p2p network	trust;service provider;effective contribution value;p2p network;voluntary contributions;success rate;p2p networks;quality of service;free rider;physical properties	In order to overcome the disadvantages of appearing the free-rider phenomenon and security issues due to the characteristics of anonymity and voluntary contributions resources in P2P network, this article firstly proposes a new strategy that based on trust value and considers both the quality and the number of shared resources to avoid the phenomenon of free rider. In the new strategy, we can calculate the trust value of the files in accordance with the consumer nodes’ trust values, obtain nodes’ effective contribution values, and select the node that has bigger trust value as service provider node. Moreover, the network can be divided into several regions according to the physical distances between nodes in the network. The nodes locating nearer are allocated the same region that is called cluster. In every cluster,we can select several nodes that have goodphysical properties and stability as management node to store and process all the information in the cluster and communicate with other management nodes in other clusters. In order to reduce overhead of network communication, encourage the nodes to makemore transactions in the same cluster. Simulations prove that this strategy can guarantee the quality of service as well as restrain free-rider phenomenon, so as to enhance the utilization of resources and the success rate of transaction. © 2010 Elsevier Ltd. All rights reserved.	computer cluster;computer simulation;download;emergence;hotspot (wi-fi);overhead (computing);peer-to-peer;quality of service	Yuhua Liu;Yuling Li;Naixue N. Xiong;Jong Hyuk Park;Yangsun Lee	2010	Computers & Mathematics with Applications	10.1016/j.camwa.2009.12.037	service provider;free rider problem;quality of service;trustworthy computing;computer security;physical property;quantum mechanics	OS	-25.73439263931527	73.49588702067759	78973
31d8563b7ce15d2f7c5b99bf76c8e295f499ccb2	qos-aware service composition: a survey	service composition;web services quality of service;concurrent computing;availability;qos aware service composition;internet of service;time factors;quality of service time factors optimization availability classification algorithms concurrent computing;classification algorithms;web services;internet of services;optimization;quality of service;quality of service qos aware service composition internet of service;binding;binding qos aware service composition service composition	Service compositions build new services by orchestrating a set of existing services. In the Internet of Services there may be many functional similar services, but with different Quality of Service (QoS). Thus a significant research problem in service compositions is how to select the composition’s composite services that the overall QoS of the composition is being maximized. This paper summarizes, classifies and evaluates major research efforts in this area and gives an overview about further open research questions.	expectation–maximization algorithm;genetic algorithm;heuristic (computer science);internet protocol suite;loss function;mathematical optimization;np-hardness;open research;optimization problem;quality of service;query plan;service composability principle;time complexity	Anja Strunk	2010	2010 Eighth IEEE European Conference on Web Services	10.1109/ECOWS.2010.16	web service;availability;mobile qos;quality of service;concurrent computing;differentiated service;computer science;service delivery framework;service design;database;services computing;programming language;law;world wide web;computer network;service system	DB	-20.554728290528285	65.16679657707512	79022
16607132592aa6b4d7b401ac73cc7f7c63ae1c6b	improved algorithms for distributed entropy monitoring	distributed monitoring;entropy functions;communication cost;data streams	Modern data management systems often need to deal with massive, dynamic and inherently distributed data sources. We collect the data using a distributed network, and at the same time try to maintain a global view of the data at a central coordinator using a minimal amount of communication. Such applications have been captured by the distributed monitoring model which has attracted a lot of attention in recent years. In this paper we investigate the monitoring of the entropy functions, which are very useful in network monitoring applications such as detecting distributed denial-of-service attacks. Our results improve the previous best results by Arackaparambil et al. in ICLP 1: 95–106 (2009). Our technical contribution also includes implementing the celebrated AMS sampling method (by Alon et al. in J Comput Syst Sci 58(1): 137–147 1999) in the distributed monitoring model, which could be of independent interest.	algorithm;denial-of-service attack;international conference on logic programming;sampling (signal processing);sensor;vhdl-ams	Jiecao Chen;Qin Zhang	2016	Algorithmica	10.1007/s00453-016-0194-z	simulation;computer science;data mining;distributed computing;algorithm;statistics	DB	-29.32977771841838	69.28485159904923	79632
0d9e3708e19aa08fdb8f93650bb11830c1fda7ad	meeting deadlines for approximation processing in mapreduce environments		To provide timely results for big data analytics, it is crucial to satisfy deadline requirements for MapReduce jobs in today’s production environments. Much effort has been devoted to the problem of meeting deadlines, and typically there exist two kinds of solutions. The first is to allocate appropriate resources to complete the entire job before the specified time limit, where missed deadlines result because of tight deadline constraints or lack of resources; the second is to run a pre-constructed sample based on deadline constraints, which can satisfy the time requirement but fail to maximize the volumes of processed data. In this paper, we propose a deadline-oriented task scheduling approach, named ‘Dart’, to address the above problem. Given a specified deadline and restricted resources, Dart uses an iterative estimation method, which is based on both historical data and job running status to precisely estimate the real-time job completion time. Based on the estimated time, Dart uses an approach–revise algorithm to make dynamic scheduling decisions for meeting deadlines while maximizing the amount of processed data and mitigating stragglers. Dart also efficiently handles task failures and data skew, protecting its performance from being harmed. We have validated our approach using workloads from OpenCloud and Facebook on a cluster of 64 virtual machines. The results show that Dart can not only effectively meet the deadline but also process near-maximum volumes of data even with tight deadlines and limited resources.	algorithm;approximation;big data;dart (programming language);earliest deadline first scheduling;existential quantification;iterative method;mapreduce;real-time clock;requirement;scheduling (computing);virtual machine	Minghao Hu;Changjian Wang;Yuxing Peng	2017	Frontiers of Information Technology & Electronic Engineering	10.1631/FITEE.1601056	mathematical optimization;scheduling (computing);dynamic priority scheduling;time limit;real-time computing;big data;computer science;dart;virtual machine	Embedded	-19.707870131527883	60.8236089120674	80495
163042ca868135cd8e3fdae0f0a79d383f7f93f2	feasibility analysis of the scheme of internet of things based on two-level supply chain dynamics	computer algorithm;two-level supply chain dynamics;a scheme of internet of things	At this stage, due to the continuous development of computer technology, whether in the online shopping or a variety of commercial exchanges with a use of the network, Internet of things is one of the most important operating intermediaries. But as people become more and more enthusiastic about online shopping, it is more and more difficult for the traditional Internet of things to meet the needs. In this paper, a scheme of Internet of things based on two-level supply chain dynamics was established to deal with these problems. In this paper, a rigorous computer algorithm was used to make analysis and summarizing, so that a new Internet of things based on two-level supply chain dynamics was established. Through our tests, the algorithm calculates the data correctly, which can meet the requirements on use.	internet of things	Ming Luo;Guohua Zhou	2018	Wireless Personal Communications	10.1007/s11277-018-5506-y	computer network;computer science;supply chain;distributed computing;internet of things	Mobile	-27.210347913079264	69.00460340208781	80585
8a33490c48bf20405925a77cf82b65e0fb4040b2	network topologies for scalable multi-user virtual environments	hierarchical system;groupware;server workstations network topologies messaging protocols scalable multi user virtual environments message distribution techniques hierarchical system designs message processing rate simultaneous users;virtual reality;client server systems;multi user;network topology;transport protocols;system design;multi access systems;client server systems virtual reality multi access systems network topology transport protocols groupware;multi user virtual environment;virtual environment;network topology virtual reality	This paper investigates trade-oos of diierent network topologies and messaging protocols for multiuser virtual environment systems. We present message distribution techniques appropriate for constructing scal-able multiuser systems for a variety of network characteristics. Hierarchical system designs utilizing servers that manage message distribution for entities in separate regions of a virtual environment are described that scale to arbitrary numbers of simultaneous users. Experimental results show that the rate of messages processed by server workstations in this system design are less than using previously described approaches.	entity;multi-user;network topology;server (computing);systems design;virtual reality;workstation	Thomas A. Funkhouser	1996		10.1109/VRAIS.1996.490531	computer science;virtual machine;artificial intelligence;operating system;distributed computing;virtual reality;hierarchical control system;virtual circuit;transport layer;network topology;computer network;systems design	Visualization	-23.487640558979532	71.47258867718031	80935
7f2793dfe4d9eedae8c9560326c4cea18ebec671	apsaras: efficient allocation of physical devices for android testing	testing avalanche photodiodes androids humanoid robots resource management scheduling;resource allocation;wait time fairness scheduling apsaras platform physical device allocation android testing mobile application testing operating system version resource scheduling policy;scheduling strategy;testing platform;physical devices;testing platform physical devices resource allocation scheduling strategy;smart phones android operating system mobile computing program testing resource allocation scheduling	Physical devices are valuable resources for mobile application testing, especially for compatibility testing on diverse Android devices with customized specifications of manufacturers and different operating system versions. In order to cover as many kinds of devices as possible, large quantity of physical devices are needed. Therefore, how to allocate mobile devices efficiently among testing tasks becomes a problem for engineers. We address this challenge by proposing efficient resource scheduling policy across diverse application testing frameworks. Specifically, we abstract the components of testing platforms into valid testing models. Based on the testing models, a Wait-time Fairness scheduling strategy is proposed to efficiently allocate devices among testing jobs. We have implemented our approach in a platform called Apsaras and conducted experiments on 80 physical Android devices. Results show that our approach, comparing with traditional testing methods, can carry out testing jobs more efficiently and more fairly.	android;compatibility testing;experiment;fairness measure;job stream;mobile application testing;mobile device;operating system;scheduling (computing);software testing;web testing	Tianchi Liu;Chun Cao;Jie Chen;Ziling Lu;Xiaoxing Ma	2016	2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)	10.1109/COMPSAC.2016.65	embedded system;real-time computing;simulation;software performance testing;resource allocation;engineering;operating system;cloud testing;software testing;management	SE	-24.466870119453603	66.45907546597142	81133
c213aebf9b9a47d380c11c79392a5edcbe8d9e62	ialm: an interaction-enable application layer multicast protocol for live teaching	groupware;collaborative learning scenario;client admission algorithm interaction enable application layer multicast protocol live teaching video interactive behavior audio interactive behavior collaborative learning scenario;collaborative work;multicast algorithms;application software;interaction;computer aided instruction;audio interactive behavior;video interactive behavior;delay effects;interaction enable application layer multicast protocol;collaborative learning;network servers;multicast protocols;streaming media;data transmit unit;client admission algorithm;live teaching;centralized control;peer to peer computing;effective interaction;interactive systems;teaching computer aided instruction groupware interactive systems multicast protocols;live teaching data transmit unit interaction application layer multicast;teaching;application layer multicast;multicast protocols education peer to peer computing multicast algorithms delay effects streaming media network servers centralized control collaborative work application software	In this paper, an interaction-enable application layer multicast protocol is introduced for a scalable live teaching system. With a simple and effective interaction-enable algorithm, the proposed protocol abates the additional application layer relay time to enable the video and audio interactive behavior, which takes an important part in a collaborative learning scenario. Besides, the peculiar join request distribution of the learner in live teaching is also considered, and a new client admission algorithm is adopted in the protocol to enhance the judgment efficiency. Based on the above approaches, a real live teaching system is realized.	algorithm;ibm notes;interactivity;join (sql);multicast;relay;requirement;scalability;server (computing);simulation	Weizhan Zhang;Qinghua Zheng;Hao Ying;Wenjiang Liu;Yi Che	2007	2007 11th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2007.4281576	collaborative learning;application software;interaction;multicast;resource reservation protocol;computer science;internet group management protocol;distributed computing;world wide web;computer network	Vision	-23.071662563117076	71.91569793269387	82417
d1e75522c8dbcc64f5179f5815845e171c4e08df	online density grid pattern analysis to classify anomalies in cloud and nfv systems		Technologies like machine-to-machine communication, autonomous driving or virtual reality applications form an increasingly diverse service landscape. This entails individual and dynamic requirements regarding scalability, availability, latency or throughput from the underlying IT infrastructure. To meet those, telecommunication and network providers started a transformation process towards virtualized technologies like network function virtualization (NFV). However, this drastically increases the infrastructure complexity to a point where more autonomous management is required. In order to meet the reliability of dedicated hardware, virtualized solutions are in demand of autonomous recovery and remediation systems. For critical network systems, actions must be selected very cautiously to not disrupt the operational process. To enable a precise handling, anomaly situations need to be accurately identified based on monitoring data streams. Therefore, we present a supervised machine learning method for an online classification of anomaly states based on similarities between anomaly type-specific density grid patterns. For evaluation, we created an extensive NFV testbed running a virtual implementation of the IP multimedia subsystem. Applying our method to classify various synthetically injected anomaly situations, the results reveal an average overall accuracy of 0.94. Further results also show that the classification model is applicable for identifying previously unknown anomaly situations. Thus, our approach provides a valuable step towards autonomous maintenance of virtualized IT infrastructures.		Alexander Acker;Florian Schmidt;Anton Gulenko;Odej Kao	2018	2018 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)	10.1109/CloudCom2018.2018.00063	scalability;real-time computing;virtualization;information technology management;cloud computing;latency (engineering);data stream mining;ip multimedia subsystem;distributed computing;testbed;computer science	HPC	-27.369148955968537	62.63659920874424	83012
36aa289e05cb0c030e2c9fc82466188891260741	v-cache: towards flexible resource provisioning for multi-tier applications in iaas clouds	cache storage;capacity management computers;resource allocation;flexible resource provisioning memory resources cpu resources cloud cache based resource provisioning approach capacity management scheme wikibench benchmarks rubis benchmarks vmware based cloud testbed reinforcement learning algorithm genetic algorithm caching proxy v cache machine learning caching tier multitier website structural reorganization virtual machines capacity planning cluster applications application management resource elasticity elastic application performance infrastructure as a service clouds iaas clouds;client server systems;resource allocation cache storage capacity management computers client server systems cloud computing genetic algorithms learning artificial intelligence;genetic algorithms;learning artificial intelligence;servers throughput sociology statistics benchmark testing biological cells genetic algorithms;cloud computing	Although the resource elasticity offered by Infrastructure-as-a-Service (IaaS) clouds opens up opportunities for elastic application performance, it also poses challenges to application management. Cluster applications, such as multi-tier websites, further complicates the management requiring not only accurate capacity planning but also proper partitioning of the resources into a number of virtual machines. Instead of burdening cloud users with complex management, we move the task of determining the optimal resource configuration for cluster applications to cloud providers. We find that a structural reorganization of multi-tier websites, by adding a caching tier which runs on resources debited from the original resource budget, significantly boosts application performance and reduces resource usage. We propose V-Cache, a machine learning based approach to flexible provisioning of resources for multi-tier applications in clouds. V-Cache transparently places a caching proxy in front of the application. It uses a genetic algorithm to identify the incoming requests that benefit most from caching and dynamically resizes the cache space to accommodate these requests. We develop a reinforcement learning algorithm to optimally allocate the remaining capacity to other tiers. We have implemented V-Cache on a VMware-based cloud testbed. Experiment results with the RUBiS and WikiBench benchmarks show that V-Cache outperforms a representative capacity management scheme and a cloud-cache based resource provisioning approach by at least 15% in performance, and achieves at least 11% and 21% savings on CPU and memory resources, respectively.	application lifecycle management;cache (computing);central processing unit;cloud computing;elasticity (cloud computing);genetic algorithm;heterogeneous computing;ibm notes;machine learning;multitier architecture;provisioning;proxy server;reinforcement learning;semiconductor consolidation;testbed;throughput;virtual machine	Yanfei Guo;Palden Lama;Jia Rao;Xiaobo Zhou	2013	2013 IEEE 27th International Symposium on Parallel and Distributed Processing	10.1109/IPDPS.2013.12	parallel computing;real-time computing;genetic algorithm;cloud computing;resource allocation;computer science;operating system;distributed computing;world wide web;computer network	HPC	-21.750259543235185	63.51441684685644	83439
a382d1ad8a7b254a5f4be4ba7c99ccdb0cd469a5	sumo: analysis and optimization of amazon ec2 instances	amazon web services;optimization;analysis;public clouds;toolkit	The analysis and optimization of public clouds gains momentum as an important research topic, due to their widespread exploitation by individual users, researchers and companies for their daily tasks. We identify primitive algorithmic operations that should be part of a cloud analysis and optimization tool, such as resource profiling, performance spike detection and prediction, resource resizing, and others, and we investigate ways the collected monitoring information can be processed towards these purposes. The analyzed information is valuable in driving important virtual resource management decisions. We also present an open-source tool we developed, called SuMo,which contains the necessary functionalities for collecting monitoring data from Amazon Web Services (AWS), analyzing them and providing resource optimization suggestions. SuMo makes easy for anyone to analyze AWS instances behavior, incorporating a set of basic modules that provide profiling and spikef detection functionality. It can also be used as a basis for the development of new such analytic procedures for AWS. SuMo contains a Cost and Utilization Optimization (CUO) mechanism, formulated as an Integer Linear Programming (ILP) problem, for optimizing the cost and the utilization of a set of running Amazon EC2 instances. This CUO mechanism receives information on the currently used set of instances (their number, type, utilization) and proposes a new set of instances for serving the same load that minimizes cost and maximizes utilization and performance efficiency.	algorithm;algorithmic efficiency;amazon elastic compute cloud (ec2);amazon web services;bottleneck (software);cloud computing;experiment;linear programming;linux;mathematical optimization;open-source software;operating system;optimizing compiler;profiling (computer programming);program optimization;sensor;synthetic data;web service	Panagiotis C. Kokkinos;Theodora A. Varvarigou;Aristotelis Kretsis;Polyzois Soumplis;Emmanouel A. Varvarigos	2014	Journal of Grid Computing	10.1007/s10723-014-9311-x	simulation;computer science;operating system;analysis;data mining;database;distributed computing	DB	-24.761934388292627	60.88269720072585	83456
6b25e3723db72e4f326f11328c8b19a28da5b482	design of energy-efficient cloud systems via network and resource virtualization		Data centers play a crucial role in the delivery of cloud services by enabling on-demand access to the shared resources such as software, platform and infrastructure. Virtual machine (VM) allocation is one of the challenging tasks in data center management since user requirements, typically expressed as service-level agreements, have to be met with the minimum operational expenditure. Despite their huge processing and storage facilities, data centers are among the major contributors to greenhouse gas emissions of IT services. In this paper, we propose a holistic approach for a large-scale cloud system where the cloud services are provisioned by several data centers interconnected over the backbone network. Leveraging the possibility to virtualize the backbone topology in order to bypass IP routers, which are major power consumers in the core network, we propose a mixed integer linear programming (MILP) formulation for VM placement that aims at minimizing both power consumption at the virtualized backbone network and resource usage inside data centers. Since the general holistic MILP formulation requires heavy and long-running computations, we partition the problem into two sub-problems, namely, intra and inter-data center VM placement. In addition, for the inter-data center VM placement, we also propose a heuristic to solve the virtualized backbone topology reconfiguration computation in reasonable time. We thoroughly assessed the performance of our proposed solution, comparing it with another notableMILP proposal in the literature; collected experimental results show the benefit of the proposed management scheme in terms of power consumption, resource utilization and fairness for medium size data centers. Copyright © 2013 John Wiley & Sons, Ltd.	algorithm;central processing unit;cloud computing;computation;data center;fairness measure;heuristic;holism;integer programming;internet access;internet backbone;john d. wiley;linear programming;mapreduce;mathematical optimization;numerical analysis;optimization problem;programming paradigm;prototype;requirement;routing;service-level agreement;testbed;user requirements document;virtual machine;virtualize	Burak Kantarci;Luca Foschini;Antonio Corradi;H. T. Mouftah	2015	Int. Journal of Network Management	10.1002/nem.1838	real-time computing;simulation;computer security;computer network	Metrics	-21.36251856996192	63.05049216727276	83470
4430734e56f9865f73c23f187a545e860a59e174	a stochastic model to investigate data center performance and qos in iaas cloud computing systems	responsiveness;analytical models;resiliency analysis data center performance cloud data center management iaas cloud computing systems vm placement performance evaluation quality of service stochastic reward nets srn;stochastic reward net;software performance evaluation;responsiveness cloud computing stochastic reward nets cloud oriented performance metrics resiliency;multiplexing;resiliency;computational modeling;stochastic reward nets;software performance evaluation cloud computing;stochastic processes;multiplexing analytical models cloud computing load modeling stochastic processes quality of service computational modeling;quality of service;load modeling;cloud oriented performance metrics;cloud computing	Cloud data center management is a key problem due to the numerous and heterogeneous strategies that can be applied, ranging from the VM placement to the federation with other clouds. Performance evaluation of cloud computing infrastructures is required to predict and quantify the cost-benefit of a strategy portfolio and the corresponding quality of service (QoS) experienced by users. Such analyses are not feasible by simulation or on-the-field experimentation, due to the great number of parameters that have to be investigated. In this paper, we present an analytical model, based on stochastic reward nets (SRNs), that is both scalable to model systems composed of thousands of resources and flexible to represent different policies and cloud-specific strategies. Several performance metrics are defined and evaluated to analyze the behavior of a cloud data center: utilization, availability, waiting time, and responsiveness. A resiliency analysis is also provided to take into account load bursts. Finally, a general approach is presented that, starting from the concept of system capacity, can help system managers to opportunely set the data center parameters under different working conditions.	autonomic computing;burst error;channel capacity;cloud computing;data center;experiment;performance evaluation;platform as a service;quality of service;responsiveness;scalability;semiconductor consolidation;simulation;software as a service;software performance testing;system configuration	Dario Bruneo	2014	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2013.67	stochastic process;parallel computing;real-time computing;simulation;quality of service;cloud computing;computer science;operating system;database;distributed computing;computational model;computer security;multiplexing;psychological resilience;computer network	HPC	-22.895260318802297	62.96291780570375	83517
584a64b40774415d58036d2872a62e9d66e15ccc	cost-efficient deployment of fog computing systems at logistics centers in industry 4.0		In Industry 4.0, the factories become increasingly smart and efficient through intelligent cyber-physical systems based on the deployment of Internet of Things (IoT), mobile devices, and cloud computing systems. In practice, the cloud computing system in a factory is managed in a centralized way, and hence may not afford heavy computing loads from thousands of IoT devices in the factory. An approach to address this issue is to deploy fog/edge computing resources nearby IoT devices in a distributed way to provide real-time computing responses on sites. This paper investigates deployment of an intelligent computing system consisting of a cloud center, gateways, fog devices, edge devices, and sensors attached to facilities in a logistics center. Except for locations of the cloud center and sensors that have been determined based on the factory layout, this paper establishes an integer programing model for deploying gateways, fog devices, edge devices in their respective potential sites, so that the total installation cost is minimized, under the constraints of maximal demand capacity, maximal latency time, coverage, and maximal capacity of devices. This paper further solves this NP-hard facility location problem by a metaheuristic algorithm that incorporates discrete monkey algorithm to search for good quality solutions and genetic algorithm to increase computational efficiency. Simulation verifies high performance of the proposed algorithm in deployment of intelligent computing systems in moderate-scale instances of intelligent logistics centers.	centralized computing;cloud computing;cyber-physical system;edge computing;edge device;facility location problem;fog computing;genetic algorithm;industry 4.0;internet of things;interrupt latency;logistics;maximal set;metaheuristic;mobile device;np-hardness;real-time clock;real-time computing;sensor;simulation;software deployment	Chun-Cheng Lin;Jhih-Wun Yang	2018	IEEE Transactions on Industrial Informatics	10.1109/TII.2018.2827920	software deployment;edge device;real-time computing;computer science;cloud computing;logistics center;industry 4.0;cost efficiency;mobile device;distributed computing;edge computing	Robotics	-22.197404870729365	67.31184083315483	83911
17d60babbbb1974739873dbde8becc1a63fdafaf	compiler optimizations as a countermeasure against side-channel analysis in msp430-based devices	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;hiding countermeasure;msp430;uk phd theses thesis;compiler optimization;life sciences;side channel attacks;embedded system security;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	Ambient Intelligence (AmI) requires devices everywhere, dynamic and massively distributed networks of low-cost nodes that, among other data, manage private information or control restricted operations. MSP430, a 16-bit microcontroller, is used in WSN platforms, as the TelosB. Physical access to devices cannot be restricted, so attackers consider them a target of their malicious attacks in order to obtain access to the network. Side-channel analysis (SCA) easily exploits leakages from the execution of encryption algorithms that are dependent on critical data to guess the key value. In this paper we present an evaluation framework that facilitates the analysis of the effects of compiler and backend optimizations on the resistance against statistical SCA. We propose an optimization-based software countermeasure that can be used in current low-cost devices to radically increase resistance against statistical SCA, analyzed with the new framework.	16-bit;algorithm;ambient intelligence;attribute–value pair;cardiac arrest;computer architecture simulator;coupling (computer programming);dynamic logic (digital electronics);embedded system;embedding;encryption;extravasation;fault injection;hl7publishingsubsection <operations>;hamming weight;information leakage;keeloq;llvm;malware;mathematical optimization;microcontroller;microprocessor;optimizing compiler;personally identifiable information;physical access;side-channel attack;simulators;spectral leakage;ti msp430;valproic acid;executing - querystatuscode;orders - hl7publishingdomain	Pedro Malagón;Juan-Mariano de Goyeneche;Marina Zapater;José Manuel Moya;Zorana Bankovic	2012		10.3390/s120607994	embedded system;telecommunications;computer science;bioinformatics;engineering;electrical engineering;side channel attack;data mining;optimizing compiler;world wide web;computer security	Security	-32.69437214716242	68.30686099110638	85375
8c938847221b974abfe1f2045ff8af898f6a9d00	an adaptive vm reservation scheme with prediction and task allocation in cloud		In a cloud environment, it is important for cloud broker to provide a cost-effective VM utilization. In this paper, we suggest a predicting scheme that can be applied for RVM provision by calculating demands. And there are some resource difference with respect to user’s needs on the process measuring clients’ needs. We also propose a method called M-C-VMA to handle the cost caused by the difference between real user demand and RVM provision. Performance evaluation showed that the proposed heuristic with VM Replacement is more efficient than C-VMA in cost performance. When M-C-VMA works on the VM allocation procedure, the result shows the higher RVM utilization than the not-modified method and consequently, it can lead the cost-efficient operation in broker system.	cost efficiency;heuristic;performance evaluation	Jisoo Choi;Yun-Gi Ha;Gyu-Beom Choi;Chan-Hyun Youn	2015		10.1007/978-3-319-38904-2_6	parallel computing;real-time computing;computer network	HPC	-19.539668221898303	62.40155673512603	85508
2817f914f34e33a84ff2216a9ea6d7731a68c626	a dynamic programming offloading algorithm for mobile cloud computing	heuristic algorithms dynamic programming mobile handsets cloud computing bandwidth hamming distance algorithm design and analysis;dynamic programming;energy efficiency computational offloading mobile cloud computing dynamic programming randomization hamming distance;hamming distance;heuristic algorithms;mobile handsets;bandwidth;power aware computing battery management systems cloud computing computational complexity dynamic programming mobile computing;energy use minimization dynamic programming offloading algorithm mobile cloud computing computational offloading mobile device battery power dynamic programming with hamming distance termination denoted dph randomization network transmission bandwidth;algorithm design and analysis;cloud computing	Computational offloading is an effective method to address the limited battery power of a mobile device, by executing some components of a mobile application in the cloud. In this paper, a novel offloading algorithm called `Dynamic Programming with Hamming Distance Termination' (denoted DPH) is presented. Our algorithm uses randomization and a hamming distance termination criterion to find a nearly optimal offloading solution quickly. The algorithm will offload as many tasks as possible to the cloud when the network transmission bandwidth is high, thereby improving the total execution time of all tasks and minimizing the energy use of the mobile device. The algorithm can find very good solutions with low computational overhead. A novel and innovative approach to fill the dynamic programming table is used to avoid unnecessary computations, resulting in lower computation times compared to other schemes. Furthermore, the algorithm is extensible to handle larger offloading problems without a loss of computational efficiency. Performance evaluation shows that the proposed DPH algorithm can achieve near minimal energy while meeting an application's execution time constraints, and it can find a nearly optimal offloading decision within a few iterations.	computation;digital planar holography;dynamic programming;effective method;hamming distance;heuristic (computer science);iteration;mathematical optimization;mega man network transmission;mobile app;mobile cloud computing;mobile device;network performance;optimization problem;overhead (computing);performance evaluation;randomized algorithm;run time (program lifecycle phase);simulation	Haleh Shahzad;Ted H. Szymanski	2016	2016 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2016.7726790	algorithm design;real-time computing;hamming distance;cloud computing;computer science;theoretical computer science;operating system;dynamic programming;distributed computing;bandwidth	Mobile	-21.72444125200653	67.03663875574014	85872
68094ba312fbd6c7877c966dee337ff57c7ccd33	a novel approach for cloud service composition ensuring global qos constraints optimization		The continuous rise of the customers expectations for service-oriented computing model has made the current scenario more dynamic and challenging. As a result of market changes, such as fluctuations in demands, creates massive application services for the end user over the internet. Although, we have number of cloud services, provided by many cloud service providers, but the biggest challenge arises when individual services have to be combined in order to fulfil complex service requirement of end users. Moreover, day to day increase in cloud service providers also leads to increase in number of concrete services for each individual application that has to be solved which results in the creation of huge datasets. Therefore, our objective has become to find an optimal cloud service composition that satisfies all QoS (Quality of Service) constraints, considering the scenario when the dataset is large. This paper introduces a hybrid approach (PSO-ABC) which resolves demerits of others optimization algorithm when it comes to solves cloud service composition problem for large datasets. This algorithm never stagnates, fall on local optimum. In addition to this it converges fast and proved to be efficient for the cloud service composition problem.		Rashda Khanam;R. V. R. Kumar;B. Satyanarayana Kumari	2018	2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2018.8554787	control engineering;task analysis;end user;computer science;the internet;cloud computing;local optimum;quality of service;distributed computing;linear programming;particle swarm optimization	HPC	-20.335007462178773	65.18428330569542	86038
6ac3fe6fabf741ddc10e80ba768d2fc99d083e84	tradeoffs between power management and tail latency in warehouse-scale applications	google;kernel;quality of service computer centres power aware computing;servers benchmark testing google hardware production kernel;servers;production;benchmark testing;workload per workload basis power management warehouse scale applications data center computing energy efficiency servers power reduction server designs energy proportional computing quality of service qos google sleep selection algorithms tail latency degradation web search dynamic voltage and frequency scaling dvfs;svilen kanev harvard;hardware	The growth in datacenter computing has increased the importance of energy-efficiency in servers. Techniques to reduce power have brought server designs close to achieving energy-proportional computing. However, they stress the inherent tradeoff between aggressive power management and quality of service (QoS) - the dominant metric of performance in datacenters. In this paper, we characterize this tradeoff for 15 benchmarks representing workloads from Google's datacenters. We show that 9 of these benchmarks often toggle their cores between short bursts of activity and sleep. In doing so, they stress sleep selection algorithms and can cause tail latency degradation or missed potential for power savings of up to 10% on important workloads like web search. However, improving sleep selection alone is not sufficient for large efficiency gains on current server hardware. To guide the direction needed for such large gains, we profile datacenter applications for susceptibility to dynamic voltage and frequency scaling (DVFS). We find the largest potential in DVFS which is cognizant of latency/power tradeoffs on a workload-per-workload basis.	benchmark (computing);computation;data center;dynamic frequency scaling;dynamic voltage scaling;e-services;elegant degradation;feature toggle;i/o bound;image scaling;power management;quality of service;selection algorithm;server (computing);web search engine	Svilen Kanev;Kim M. Hazelwood;Gu-Yeon Wei;David M. Brooks	2014	2014 IEEE International Symposium on Workload Characterization (IISWC)	10.1109/IISWC.2014.6983037	embedded system;benchmark;parallel computing;kernel;real-time computing;computer science;operating system;server	Arch	-20.52965992284046	60.96402097023951	86146
8a6cc456e6174df03ed6db9ea26eafc566fe5397	an fpga-assisted cloud framework for massive ecg signal processing	ecg;r peak detection;cloud;fpga;wavelet transforms;servers;electrocardiography;field programmable gate arrays;cloud computing;hardware	Current aging society has seen huge increases in portable devices sending massive volume of signals to medical servers. To address inefficient and unscalable signal processing on generic servers and clients, in this paper, we present an FPGA(field programmable gate array)-assisted cloud system providing an efficient framework for electrocardiogram (ECG) telemedicine including real-time data acquisition, transmission and analyzing over the Internet. We explore the requirements of massive cloud signal processing supporting a large number of connections or channels from cloud clients. A prototype system was composed of a client-server platform and an FPGA hardware system with PCI-E endpoint and ECG R-peak detection modules. A streaming micro-architecture for hardware system is proposed to detect ECG pattern from scalable number of channels. Evaluation results show that our streaming system design has good performance in terms of real-time, scalability and latency.	centralized computing;client–server model;cloud computing;communication endpoint;data acquisition;field-programmable gate array;image scaling;internet;memory controller;microarchitecture;personal digital assistant;prototype;real-time clock;real-time data;requirement;scalability;sensor;server (computing);signal processing;streaming algorithm;systems design	Shengyan Zhou;Yongxin Zhu;Chaojun Wang;Xiaoqi Gu;Jun Yin;Jiang Jiang;Guoguang Rong	2014	2014 IEEE 12th International Conference on Dependable, Autonomic and Secure Computing	10.1109/DASC.2014.45	embedded system;real-time computing;computer hardware;computer science	Embedded	-28.118289390761714	68.11398917292561	86319
8b05ef093110904e43f54a091662b1d155a10951	self-expressive management of business-critical workloads in virtualized datacenters	workload changes self expressive business critical workload management virtualized data centers mnemos resource management scheduling architecture portfolio scheduling topology aware virtual resource management state information;processor scheduling;virtualized datacenters;resource management;resource management monitoring big data computer architecture processor scheduling dynamic scheduling resource management data centers;business critical workloads;self expressive scheduling;computer architecture;monitoring;big data;workload scheduling;self awareness;mnemos;self awareness self expressive computing resource management self expressive scheduling business critical workloads virtualized datacenters workload scheduling job scheduling mnemos;self expressive computing;job scheduling;virtualisation business data processing computer centres resource allocation risk analysis;dynamic scheduling;data centers	The Mnemos resource management and scheduling architecture uses portfolio scheduling, topology-aware virtual-resource management, and state information to self-adapt to significant workload changes and to analyze risks. Simulations with real-world workload traces reveal the potential for significant cost savings.	computer simulation;scheduling (computing);tracing (software)	Vincent van Beek;Jesse Donkervliet;Tim Hegeman;Stefan Hugtenburg;Alexandru Iosup	2015	Computer	10.1109/MC.2015.206	data center;real-time computing;big data;self-awareness;dynamic priority scheduling;computer science;resource management;job scheduler;operating system;distributed computing	OS	-22.170707903247084	61.6180922960449	87049
c7992b82d1e16849727a7d0add13f43162595d20	smart spot instances for the supercloud	resource management;hybrid cloud;cross cloud	In this paper, we explore the use of live VM migration to take advantage of spot markets such as provided by Amazon and Google. These markets provide an exciting low cost alternative to regular VM instances, but the threats of price spikes and premature termination severely limit their usability. Migration can address these threats: spot market instances facing price hikes or termination can migrate to other instance types, including regular ones. Reliability can be further improved by replication. In this paper we investigate various design options and present some preliminary results of experiments with dynamic programming techniques, both using simulation and using a realistic deployment. We find that in unstable markets we can achieve significant savings at low overhead and while maintaining good reliability.	amazon elastic compute cloud (ec2);control theory;dynamic programming;experiment;overhead (computing);scheduling (computing);simulation;software deployment;usability;user space;virtual machine	Qin Jia;Zhiming Shen;Weijia Song;Robbert van Renesse;Hakim Weatherspoon	2016		10.1145/2904111.2904114	simulation;engineering;operations management;computer security	OS	-24.78336176952333	62.315392829091635	87107
b0102b09b31e626b075109d96f38da647a8e2e1f	optimizing resource utilization of a data center	resource management;prediction algorithms;servers;tutorials;time series analysis;predictive models;resource management servers prediction algorithms tutorials data models predictive models time series analysis;data center resource management resource utilization resource allocation workload prediction;data models	To provision IT solutions with reduced operating expenses, many businesses are moving their IT infrastructures into public data centers or are starting to build their own private data centers. Data centers can provide flexible resource provisioning in order to accommodate the workload demand. In this paper, we present a comprehensive survey of most relevant research activities on resource management of data centers that aim to optimize the resource utilization. We first describe the resource overprovisioning problem in current data centers. Then, we summarize two important components in the resource management platform and present the benefit of accurately predicting the workload in resource management. Afterwards, we classify existing resource management in a data center into three categories: 1) virtual machine-based, 2) physical machine-based, and 3) application-based resource management mechanisms. We discuss the performance degradation for implementing these three kinds of resource management in a heterogeneous data center. Finally, we present three important issues arose in the data center resource management and some potential approaches to address the issues. This paper presents a timely survey on resource management in a data center, and provides a comprehensive reference for further research in this field.	algorithm;categorization;data center;elegant degradation;information privacy;learning relationship management;optimizing compiler;provisioning;virtual machine;z/vm	Xiang Sun;Nirwan Ansari;Ruopeng Wang	2016	IEEE Communications Surveys & Tutorials	10.1109/COMST.2016.2558203	data modeling;simulation;prediction;resource leveling;data management;resource allocation;computer science;resource management;time series;data mining;database;predictive modelling;human resource management system;server;statistics	HPC	-24.018559190323515	61.18466675473651	87188
1afcff13547570faf678489fdb18c491cb506d51	dewdrop: an energy-aware runtime for computational rfid	iterative task;wisp crfid tag;available energy;heavy task;task demand;energy-aware runtime;computational rfid;next task iteration;best rate;task rate;crfid run-time;rf energy	Computational RFID (CRFID) tags embed sensing and computation into the physical world. The operation of the tags is limited by the RF energy that can be harvested from a nearby power source. We present a CRFID runtime,Dewdrop, that makes effective use of the harvested energy. Dewdrop treats iterative tasks as a scheduling problem to balance task demands with available energy, both of which vary over time. It adapts the start time of the next task iteration to consistently run well over a range of distances between tags and a power source, for different numbers of tags in the vicinity, and for light and heavy tasks. We have implemented Dewdropon top of the WISP CRFID tag. Our experiments show that, compared to normal WISP operation, Dewdropdoubles the operating range for heavy tasks and significantly increases the task rate for tags receiving the least energy, all without decreasing the rate in other situations. Using offline testing, we find that Dewdropruns tasks at better than 90% of the best rate possible.	computation;experiment;iteration;online and offline;radio frequency;radio-frequency identification;scheduling (computing);wisp	Michael Buettner;Ben Greenstein;David Wetherall	2011			embedded system;real-time computing;simulation;computer science;operating system;distributed computing	Mobile	-22.882519399509754	66.55869080599946	87518
08c2649dee7ba1ab46106425a854ca3af869c2f0	lest we remember: cold boot attacks on encryption keys	temperature ambiante;sistema operativo;core storage;random access memory;memoria acceso directo;encryption;enfriamiento;retention;temperatura ambiente;securite informatique;memoria central;cifrado;memoire centrale;refroidissement;computer security;forensic science;operating system;cryptage;predictability;criptografia;cryptography;police scientifique;memoire acces direct;seguridad informatica;security key;cryptographie;systeme exploitation;dynamic random access memory;ciencia forense;predictabilidad;cle securite;room temperature;predictabilite;memoire acces direct dynamique;cooling;retencion;llave seguridad	Contrary to widespread assumption, dynamic RAM (DRAM), the main memory in most modern computers, retains its contents for several seconds after power is lost, even at room temperature and even if removed from a motherboard. Although DRAM becomes less reliable when it is not refreshed, it is not immediately erased, and its contents persist sufficiently for malicious (or forensic) acquisition of usable full-system memory images. We show that this phenomenon limits the ability of an operating system to protect cryptographic key material from an attacker with physical access to a machine. It poses a particular threat to laptop users who rely on disk encryption: we demonstrate that it could be used to compromise several popular disk encryption products without the need for any special devices or materials. We experimentally characterize the extent and predictability of memory retention and report that remanence times can be increased dramatically with simple cooling techniques. We offer new algorithms for finding cryptographic keys in memory images and for correcting errors caused by bit decay. Though we discuss several strategies for mitigating these risks, we know of no simple remedy that would eliminate them.	algorithm;cold boot attack;computer cooling;computer data storage;cryptography;data degradation;disk encryption;dynamic random-access memory;experiment;key (cryptography);laptop;malware;memory refresh;motherboard;operating system;physical access;remanence	J. Alex Halderman;Seth D. Schoen;Nadia Heninger;William Clarkson;William Paul;Joseph A. Calandrino;Ariel J. Feldman;Jacob Appelbaum;Edward W. Felten	2008	Commun. ACM	10.1145/1506409.1506429	embedded system;predictability;telecommunications;computer science;cryptography;operating system;forensic science;room temperature;computer security;encryption;algorithm	Security	-33.295320006962164	65.64411749326817	87579
6f406b685782b3a3ee5177154266b65406d8fb7f	self-adaptive workload classification and forecasting for proactive resource provisioning	assurance of service level objectives;arrival rate;time series analysis;workload forecasting;proactive resource provisioning	As modern enterprise software systems become increasingly dynamic, workload forecasting techniques are gaining an importance as a foundation for online capacity planning and resource management. Time series analysis offers a broad spectrum of methods to calculate workload forecasts based on history monitoring data. Related work in the field of workload forecasting mostly concentrates on evaluating specific methods and their individual optimisation potential or on predicting QoS metrics directly. As a basis, we present a survey on established forecasting methods of the time series analysis concerning their benefits and drawbacks and group them according to their computational overheads. In this paper, we propose a novel self-adaptive approach that selects suitable forecasting methods for a given context based on a decision tree and direct feedback cycles together with a corresponding implementation. The user needs to provide only his general forecasting objectives. In several experiments and case studies based on real-world workload traces, we show that our implementation of the approach provides continuous and reliable forecast results at run-time. The results of this extensive evaluation show that the relative error of the individual forecast points is significantly reduced compared with statically applied forecasting methods, for example, in an exemplary scenario on average by 37%. In a case study, between 55 and 75% of the violations of a given service level objective can be prevented by applying proactive resource provisioning based on the forecast results of our implementation. Copyright © 2014 John Wiley & Sons, Ltd.	provisioning	Nikolas Roman Herbst;Nikolaus Huber;Samuel Kounev;Erich Amrehn	2014	Concurrency and Computation: Practice and Experience	10.1002/cpe.3224	real-time computing;simulation;demand forecasting;computer science;operating system;time series;database;distributed computing;statistics	HPC	-23.1729879628659	61.34688389696723	87730
bc786e0856737cfe214dcf251d831b30dd7fea89	cbr-based negotiation rbac model for enhancing ubiquitous resources management	case based reasoning management;rbac;information management;negotiation based rbac;ubiquitous rbac;role assignment management	With the progress of new technologies of information management, Ubiquitous Resource Management (URM) is a dominant areas of research which requires efficient access management approaches. There have been huge challenges of controlling access to ubiquitous resources among collaborative multi-servers based on the negotiating security policies on URMs. However, the traditional access control mechanisms were insufficient to meet the requirements of role assignment management for URMs that allow accessing services via huge clients. Therefore, Ubiquitous RBAC (Role-based Access Control) with CBR (case-based reasoning) based negotiation technique is proposed in this paper. The novel RBAC scheme could efficiently manage not only one ubiquitous server, but also multiple ubiquitous servers on the cooperation domain through supporting both negotiating role assignment (NRA) task and cooperative role assignment (CRA) task in URM-platform by using a spiral negotiating process. Furthermore, it solves the difficulties in reducing the costs of ubiquitous computing resources, e.g., the role reassigned rate, handover rate, bandwidth, and power consumption, etc. Due to the ease of use and its efficiency in negotiating and managing the user-to-role as well as virtual role assignment by applying CBR approach, it is a highly powerful strategy of information management for conducting the innovative research and design for ubiquitous RBAC scheme.	case-based reasoning;role-based access control	Shian-Shyong Tseng;Hsing-Chung Chen;Li-Ling Hu;Yen-Tsung Lin	2017	Int J. Information Management	10.1016/j.ijinfomgt.2016.05.009	computer science;knowledge management;role-based access control;information management;world wide web;computer security	HCI	-32.163707807523714	60.99101965607875	87765
8fe947a8c910e1e71dc1871b06c6e5a7e4ad090b	power-performance trade-offs in iaas cloud: a scalable analytic approach	stochastic submodel approach;power consumption characteristics;computer model;physical machine pool configuration power performance trade offs iaas cloud scalable analytic model infrastructure as a service cloud tiered service offering response time power consumption characteristics stochastic submodel approach;response time;infrastructure as a service cloud;physical machine pool configuration;power aware computing;computational modeling;stochastic processes cloud computing power aware computing;stochastic processes;power demand computational modeling delay steady state markov processes;markov process;power performance trade offs;markov processes;scalable analytic model;iaas cloud;power demand;tiered service offering;cloud computing;steady state	Optimizing for performance is often associated with higher costs in terms of capacity, faster infrastructure, and power costs. In this paper, we quantify the power-performance trade-offs by developing a scalable analytic model for joint analysis of performance and power consumption for a class of Infrastructure-as-a-Service (IaaS) clouds with tiered service offerings. The tiered service offerings are provided by configuring physical machines into three pools with different response time and power consumption characteristics. Using interacting stochastic sub-models approach, we quantify power-performance trade-offs. We summarize our modeling approach and highlight key results on the effects of physical machine pool configurations on consumed power and achievable performance in terms of response time and ability to service requests. The approach developed here can be used to manage power consumption and performance by judiciously configuring physical machine pools.	cloud computing;glossary of computer graphics;interaction;mathematical optimization;optimizing compiler;queueing theory;rejection sampling;response time (technology);scalability;scheduling (computing)	Rahul Ghosh;Vijay K. Naik;Kishor S. Trivedi	2011	2011 IEEE/IFIP 41st International Conference on Dependable Systems and Networks Workshops (DSN-W)	10.1109/DSNW.2011.5958802	stochastic process;real-time computing;simulation;computer science;distributed computing;markov process;statistics	HPC	-22.52859379083458	62.68566631086452	88199
2cdba3b1759ba3baa431b6d91ba0b0704fb2a994	a performance and profit oriented data replication strategy for cloud systems	databases;time factors;estimation;bandwidth;economics;cloud computing;data models	In today's world, tenants of cloud systems expect timely responses to queries that process ever-increasing sizes of data. However, most cloud providers offer their services without any performance guarantees to their tenants. In this paper we propose a data replication strategy that aims to satisfy performance guarantees for the tenant while ensuring profitability of the cloud provider. Our strategy estimates the response time of the queries, as well as the expenditures that affect the profitability of the cloud provider. The decision of whether to perform replication is determined by the fulfillment of these two criteria. Validity of the proposed strategy is provided by means of a simulation study.	cloud computing;database;replication (computing);response time (technology);service-level agreement;simulation	Uras Tos;Riad Mokadem;Abdelkader Hameurlain;Tolga Ayav;Sebnem Bora	2016	2016 Intl IEEE Conferences on Ubiquitous Intelligence & Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Cloud and Big Data Computing, Internet of People, and Smart World Congress (UIC/ATC/ScalCom/CBDCom/IoP/SmartWorld)	10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0125	data modeling;estimation;simulation;cloud computing;computer science;operating system;data mining;database;computer security;bandwidth;statistics;computer network	DB	-23.77328300129681	63.919199329510256	88276
7027d6b2a1b2f2a0c5c84d334b47824ce44e774d	a synchronization and flow control scheme for interactive multimedia-on-demand (mod) systems	control systems streaming media buffer storage multimedia systems graphics communication channels internet sun workstations network servers;multi stream;multimedia systems;interactive multimedia;synchronisation multimedia systems interactive systems user interfaces;synchronisation;vcr like user interactions;sun sparc workstations synchronization control flow control scheme interactive multimedia on demand systems vcr like user interactions multi stream environment media units client buffers user interaction media transmission presentation status processing considerations control schemes interactive multimedia communication distributed multi stream environment mod system;multimedia communication;synchronization control;flow control;user interaction;interactive systems;user interfaces	Synchronization control with VCR-like user interactions in the multi-stream environment is very complicated and difficult. The main reasons are that: (i) those media units stored in the client buffers and flowing in the networks may be either useful or useless when the user interaction is issued, and (ii) the servers' media transmission should be adjusted according to the presentation status of the client. Additionally, different VCR-like user interactions have their own processing considerations, which result in different control schemes for different VCR-like user interactions. We propose some control schemes to handle interactive multimedia communication in the distributed multi-stream environment and develop an MOD system on SUN SPARC workstations accordingly.	flow control (data);synchronization (computer science)	Chung-Ming Huang;Chian Wang;Hsu-Yang Kung	2000		10.1109/ICPADS.2000.857681	synchronization;real-time computing;interactive systems engineering;telecommunications;computer science;operating system;flow control;distributed computing;multimedia;interactive media;user interface;computer network	OS	-22.98485697240935	71.6619249688052	88390
f4cb23176b4a8377e3819ab11c6d276c39974d69	a model-based scalability optimization methodology for cloud applications		Complex applications composed of many interconnected but functionally independent services or components are widely adopted and deployed on the cloud to exploit its elasticity. This allows the application to react to load changes by varying the amount of computational resources used. Deciding the proper scaling settings for a complex architecture is, however, a daunting task: many possible settings exists with big repercussions in terms of performance and cost. In this paper, we present a methodology that, by relying on modeling and automatic parameter configurators, allows to understand the best way to configure the scalability of the application to be deployed on the cloud. We exemplify the approach by using an existing service-oriented framework to dispatch car software updates.	amazon elastic compute cloud (ec2);amazon web services;artificial intelligence;best, worst and average case;cloud computing;complex systems;computation;computational resource;dynamic dispatch;elasticity (data store);exemplification;experiment;image scaling;interrupt latency;mathematical model;modality (human–computer interaction);non-uniform memory access;patch (computing);profiling (computer programming);scalability;service-oriented architecture;service-oriented device architecture	Jia-Chun Lin;Jacopo Mauro;Thomas Brox Røst;Ingrid Chieh Yu	2017	2017 IEEE 7th International Symposium on Cloud and Service Computing (SC2)	10.1109/SC2.2017.32	task analysis;architecture;scalability;software;cloud computing;functionally independent;scaling;exploit;computer science;distributed computing	Arch	-23.75699292955034	61.119108349449164	89013
b8c05768e4448f38f95c27de983bbab800b10799	heuristic performance evaluation for load balancing in cloud		Cloud computing introduces a new level of flexibility and scalability for providers and clients, because it addresses challenges such as rapid change in Information Technology (IT) scenarios and the need to reduce costs and time in infrastructure management. However, to be able to offer quality of service (QoS) guarantees without limiting the number of requests accepted, providers must be able to dynamically and efficiently scale service requests to run on the computational resources available in the data centers. Load balancing is not a trivial task, involving challenges related to service demand, which can change instantly, performance modeling, deployment and monitoring of applications in virtualized IT resources. In this way, the aim of this paper is to develop and evaluate the performance of different load balancing heuristics for a cloud environment in order to establish a more efficient mapping between the service requests and the virtual machines that will execute them, and to ensure the quality of service as defined in the service level agreement. By means of experiments, it was verified that the proposed algorithms presented better results when compared with traditional and artificial intelligence heuristics.	algorithm;artificial intelligence;cloud computing;computational resource;data center;experiment;heuristic (computer science);load balancing (computing);performance evaluation;performance prediction;quality of service;scalability;service-level agreement;software deployment;virtual machine	Bruno G. Batista;Natan B. Morais;Bruno Tardiole Kuehne;Rafael M. D. Frinhani;Dionisio Machado Leite Filho;Maycon L. M. Peixoto	2018	2018 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCS.2018.00099	real-time computing;task analysis;quality of service;scalability;service-level agreement;cloud computing;load management;load balancing (computing);heuristics;computer science	HPC	-22.49656995542964	62.3945219976291	89046
7bc75daf804e6f123bcdde414a77d46ec000d4e6	grid-based quasi-monte carlo applications	monte carlo technique;quasi monte carlo;grid computing;monte carlo	s — In this paper, we extend the techniques used in Grid-based Monte Carlo applications to Grid-based quasi-Monte Carlo applications. These techniques include an N-out-of-M strategy for efficiently scheduling subtasks on the Grid, lightweight checkpointing for Grid subtask status recovery, a partial result validation scheme to verify the correctness of each individual partial result, and an intermediate result checking scheme to enforce the faithful execution of each subtask. Our analysis shows that the extremely high uniformity seen in quasirandom sequences prevents us from applying many of our Grid-based Monte Carlo techniques to Gridbased quasi-Monte Carlo applications. However, the use of scrambled quasirandom sequence becomes a key to tackling this problem, and makes many of the techniques we used in Gridbased Monte Carlo applications effective in Grid-based quasi-Monte Carlo applications. All the techniques we will describe here contribute to performance improvement and trustworthiness enhancement for large-scale quasi-Monte Carlo applications on the Grid, which eventually lead to a high-performance Grid-computing infrastructure that is capable of providing trustworthy quasi-Monte Carlo computation services.	application checkpointing;circuit complexity;computation;correctness (computer science);data validation;grid computing;low-discrepancy sequence;middleware;monte carlo method;quasi-monte carlo method;real life;scheduling (computing);trust (emotion)	Yaohang Li;Michael Mascagni	2005	Monte Carlo Meth. and Appl.	10.1515/1569396054027265	quasi-monte carlo method;hybrid monte carlo;theoretical computer science;monte carlo molecular modeling;mathematics;monte carlo integration;statistics;monte carlo method	HPC	-31.027926796180587	65.29776025858727	89347
24fed1fbd9d4aa958fc48bfabd22a388ad68655c	parallel space saving on multi- and many-core processors	data stream;frequent items;many core;multi core	In this paper we deal with parallel shared-memory algorithm s for frequent items. In data mining, this problem is usually associated to two contexts, the on–l ine (stream) and the off–line setting, the difference being that in the former case we are restricted to a single scan of the input. In practice, this implies that verifying the frequent items that have bee n found in order to discard false positives is not allowed, while in the latter case a parallel scan of the input can be used to determine the actual frequent items. Finding frequent items is also referred to a s hot list analysis[1] or market basket analysis[2]. In the context of data bases, the problem is usually called an iceberg query[3], [4]. The name arises from the fact that the number of frequent items is ofte n very small (the tip of an iceberg) when compared to the large amount of input data (the iceberg). Given an arrayA of n elements and a value 2 ≤ k ≤ n, a frequent item or k-majority element is an element occurring in A more thann/k times. Thek-majority problem requires finding all of the k-majority elements. For k = 2, the problem reduces to the well known majority problem [ 5] [6] [7]. The k-majority problem has been solved sequentially first by Misra and Gries [8]. In their paper, it is shown how to solve it in timeO(n log k). Besides being important from a theoretical perspective, a lgorithms for this problem are also extremely useful in practical context s such as, for instance, in all of the cases (such as electronic voting) where a quorum of more than n/k of all of the votes received is required for a candidate to win; another good example is extracting es sential characteristics of network traffic streams passing through internet routers: the frequency es timation of internet packet streams [ 9] is indeed an instance of the k-majority problem. Another example is monitoring internet packets in order to i nfer network congestion [ 10], [11]. The problem also arises in the context of the analysis of web q uery logs [ 12], and is relevant	algorithm;central processing unit;data mining;database;david gries;misra c;majority problem (cellular automaton);manycore processor;network congestion;network packet;network traffic control;shared memory;timation;verification and validation;whole earth 'lectronic link	Massimo Cafaro;Marco Pulimeno;Italo Epicoco;Giovanni Aloisio	2018	Concurrency and Computation: Practice and Experience	10.1002/cpe.4160	parallel computing;xeon;computer science;distributed computing;xeon phi;multi-core processor	Theory	-32.67708678033667	62.23913049799207	90146
d6cf81b306faa2867756da08482b7ccb1e358918	large-scale qos-aware service composition integrating chained dynamic programming and hybrid pruning		Providing both optimal QoS and a minimum number of services simultaneously is a promising perspective of QoS-aware service composition, whereas most existing research studies are still unfavorable toward making an ideal trade-off between quality and efficiency, particularly in large-scale scenarios. To address this issue, this paper proposes a composition mechanism that effectively and efficiently minimizes the number of services in the composition result while achieving the optimal global QoS. We first transform the composition task into an equivalent one with decreased computing complexity, after which a chained dynamic programming algorithm, Chain-DP, is proposed to extract the optimal QoS with the minimum number of services. Finally, we further optimize the efficiency of the algorithm by adopting a global-local strategy of pruning. Experimental results on Web Service Challenge 2010’s datasets show that the proposed method outperforms the state-of-the-art approach by generating solutions containing fewer services for the optimal QoS with higher efficiency and better generalization on large-scale datasets.	approximation algorithm;dynamic programming;exact algorithm;experiment;quality of service;service composability principle;web service	Shi-Liang Fan;Kai-Yu Peng;Yu-Bin Yang	2018		10.1007/978-3-319-94289-6_13	computer science;data mining;pruning;quality of service;web service;dynamic programming;distributed computing;composition (visual arts)	AI	-20.15147580099513	65.2842803761173	90153
3b9725ad0e3a078e9add5a37ea1ac323f7322d75	correlating instrumentation data to system states: a building block for automated diagnosis and control	bayesian network;service level;performance management;building block;perforation;web service	This paper studies the use of statistical induction techniques as a basis for automated performance diagnosis and performance management. The goal of the work is to develop and evaluate tools for offline and online analysis of system metrics gathered from instrumentation in Internet server platforms. We use a promising class of probabilistic models (Tree-Augmented Bayesian Networks or TANs) to identify combinations of system-level metrics and threshold values that correlate with high-level performance states—compliance with Service Level Objectives (SLOs) for average-case response time—in a threetier Web service under a variety of conditions. Experimental results from a testbed show that TAN models involving small subsets of metrics capture patterns of performance behavior in a way that is accurate and yields insights into the causes of observed performance effects. TANs are extremely efficient to represent and evaluate, and they have interpretability properties that make them excellent candidates for automated diagnosis and control. We explore the use of TAN models for offline forensic diagnosis, and in a limited online setting for performance forecasting with stable workloads.	bayesian network;best, worst and average case;build automation;cobham's thesis;high- and low-level;machine learning;online and offline;queueing theory;response time (technology);server (computing);service-level agreement;statistical machine translation;testbed;tree structure;web service	Ira Cohen;Jeffrey S. Chase;Moisés Goldszmidt;Terence Kelly;Julie Symons	2004			web service;performance management;simulation;service level;computer science;operating system;bayesian network;data mining	OS	-24.20660918010367	61.912743431229636	90575
4d061503e14936bfe2450c914f4880aab2fd9b61	adaptive energy-aware algorithms for minimizing energy consumption and sla violation in cloud computing		In cloud computing, high energy consumption and service-level agreements (SLAs) violation are the challenging issues considering that the demand for computational power is growing rapidly, thereby requiring large-scale cloud data centers. Although, there are many existing energy-aware approaches focusing on minimizing energy consumption while ignoring the SLA violation at the time of a virtual machine (VM) selection from overloaded hosts. Also, they do not consider that the current network traffic causes performance degradation and thus may not really reduce SLA violation under a variety of workloads. In this context, this paper proposes three adaptive models, namely, gradient descent-based regression (Gdr), maximize correlation percentage (MCP), and bandwidth-aware selection policy (Bw), that can significantly minimize energy consumption and SLA violation. Energy-aware methods for overloaded host detection and VM selection from an overloaded host are necessary to improve the energy efficiency and SLA violation of a cloud data center after migrating all VM from underloaded host turn to idle host, which switch to energy-saving mode is also beneficial. Gdr and MCP are adaptive energy-aware algorithms based on the robust regression model, for overloaded host detection. A Bw dynamic VM selection policy selects VM according to the network traffic from the overloaded host under SLAs. Experimental results on the real workload traces show that the proposed algorithms reduce energy consumption while maintaining the required performance levels in a cloud data center using a CloudSim simulator to validate the proposed algorithms.	algorithm;cloud computing;cloudsim;computation;data center;elegant degradation;gradient descent;network traffic control;service-level agreement;tracing (software);virtual machine	Rahul Yadav;Weizhe Zhang;Omprakash Kaiwartya;Prabhat Ranjan Singh;Ibrahim A. Elgendy;Yu-Chu Tian	2018	IEEE Access	10.1109/ACCESS.2018.2872750	green computing;computer network;dynamic priority scheduling;distributed computing;energy consumption;efficient energy use;cloud computing;cloudsim;computer science;algorithm;data center;server	HPC	-21.73313381512871	62.08687738101738	90814
6b53717f7da482c016cac08b9ed2aea3a6ab501c	managing performance and resources in software systems using nonlinear predictive control	mathematical model;resource allocation;electronic commerce;mimo;control systems;predictive control;resource management;software systems;e commerce	Management of quality of service performance and resources in a shared resource environment is vital to many business domains to achieve business objectives. These management systems provide agreed levels of quality of service to their clients while allocating limited available resources among them. It is well known that the behavior of such software systems illustrate nonlinear characteristics, imposing difficulties to model and control the system. This paper proposes a nonlinear model predictive control technique for managing the performance and resources in such a shared resource environment. In particular, a block-oriented Wiener model is utilized to represent the software system as a multi-input and multi-output model in series with static nonlinear components at the outputs. Then a predictive control system is designed by compensating the estimated nonlinearities with their inverse. The simulation results show that the proposed nonlinear model predictive control mechanism has significantly improved the performance and resource management at runtime over the linear predictive control counterpart.	concurrency control;control system;nonlinear system;quality of service;run time (program lifecycle phase);series and parallel circuits;simulation;software system	Tharindu Patikirikorala;Liuping Wang;Alan W. Colman;Jun Han	2012	2012 American Control Conference (ACC)		e-commerce;control engineering;real-time computing;simulation;resource allocation;computer science;engineering;control system;mathematical model;control theory;mathematics;model predictive control;statistics;software system;mimo	Robotics	-24.83615458787275	62.2009826749261	91281
f93a33630f09e03d7b6fe8963b107e0d1342edef	imig: toward an adaptive live migration method for kvm virtual machines	adaptive model;article;energy saving;cloud computing;live migration	With the energy and power costs increasing alongside the growth of the IT infrastructures, achieving workload concentration and high availability in cloud computing environments is becoming more and more complex. Virtual machine (VM) migration has become an important approach to address this issue, particularly; live migration of the VMs across the physical servers facilitates dynamic workload scheduling of the cloud services as per the energy management requirements, and also reduces the downtime by allowing the migration of the running instances. However, migration is a complex process affected by several factors such as bandwidth availability, application workload and operating system configurations, which in turn increases the complications in predicting the migration time in order to negotiate the service-level agreements in a real datacenter. In this paper, we propose an adaptive approach named improved MIGration (iMIG), in which we characterize some of the key metrics of the live migration performance, and conduct several experiments to study the impacts of the investigated metrics on the Kernel-based VM (KVM) functionalities, as well as the energy consumed by both the destination and the source hosts. Our results reveal the importance of the configured parameters: speed limit, TCP buffer size and max downtime, along with the VM properties and also their corresponding impacts on the migration process. Improper setting of these parameters may either incur migration failures or causes excess energy consumption. We witness a few bugs in the existing Quick EMUlator (QEMU)/KVM parameter computation framework, which is one of most widely used KVM frameworks based on QEMU. Based on our observations, we develop an analytical model aimed at better predictions of both the migration time and the downtime, during the process of VM deployment. Finally, we implement a suite of profiling tools in the adaptive mechanism based on the qemu-kvm-0.12.5 version, and our experiment results prove the efficiency of our approach in improving the live migration performance. In comparison with the default migration approach, our approach achieves a 40% reduction in the migration latency and a 45% reduction in the energy consumption.	algorithm;cloud computing;computation;data center;downtime;experiment;high availability;offset binary;operating system;qp state machine frameworks;requirement;scheduling (computing);service-level agreement;software bug;software deployment;system migration;virtual machine	Jianxin Li;Jieyu Zhao;Yi Li;Lei Cui;Bo Li;Lu Liu;John Panneerselvam	2015	Comput. J.	10.1093/comjnl/bxu065	simulation;cloud computing;computer hardware;computer science;operating system;computer graphics (images)	HPC	-21.813601520314283	61.826218958164986	91391
b4d93502da2ff659ac65902c340fb04fd4f4551c	green latency-aware data deployment in data centers: balancing latency, energy in networks and servers	energy efficient;latency aware;data deployment	Two concerns exist in service provisioning by data centers. One is that users require to experience low latency while accessing data from the data centers. The other is to reduce the power consumed by network transport and servers in the data centers. In this paper, we tackle the problem of green data deployment in the data centers, taking into account the three factors of latency, energy consumption of the data centers and the network transport.	data center;provisioning;server (computing);software deployment	Yuqi Fan;Hongli Ding;Donghui Hu	2014		10.1145/2627566.2627584	real-time computing;computer science;operating system;efficient energy use;computer network	Metrics	-21.423516791808	62.8385033419307	91401
c9fd828b97b0edc47bdc083f036b184424eecacb	explore virtual machine deployment to mobile cloud computing for multi-tenancy and energy conservation in wireless network		Mobile cloud computing (MCC) is becoming one of the primary applications and research directions of pervasive computing. Previous studies generally focuses on the following two kinds of paradigms. One is that mobile users offload computing tasks into traditional clouds to achieve collaboration processing. The other is that multiple mobile devices, as “helpers”, casually provide computing services for other mobile “requesters”. However, with the extraordinary development of mobile devices, new problems of resource utilization and multi-tenancy of mobile devices are emerging. Based on this, we propose a novel MCC paradigm combining virtual machine (VM) technologies to improve the resource utilization of mobile devices, achieve multi-tenancy and thereby obtain the more efficient MCC environment as well as a broader MCC research field. To achieve it, the VM deployment problem must be addressed firstly. The heuristic deployment approach VD-ABC based on an improved artificial bee colony algorithm is proposed. It combines with Boltzmann selection policy, to obtain the optimal solution of VM deployment. In terms of the traits of wireless network in MCC, the mapping from the obtained solution to the final VM deployment is achieved. Simulation results show that VD-ABC has a better energy saving performance while minimizing the service response latency.	abc;artificial bee colony algorithm;boltzmann machine;experiment;heuristic;hill climbing;holographic principle;mobile cloud computing;mobile device;multitenancy;organizing (structure);pervasive informatics;programming paradigm;simulation;software deployment;ubiquitous computing;verification and validation;virtual machine	Yan Ding;Gaochao Xu;Chunyi Wu;Liang Hu;Yunan Zhai;Jia Zhao	2017	Cluster Computing	10.1007/s10586-017-1054-6	distributed computing;software deployment;wireless network;real-time computing;mobile cloud computing;ubiquitous computing;virtual machine;computer network;computer science;multitenancy;mobile computing;mobile device	Mobile	-24.351376015160138	67.56778683493636	91766
45f5c07317d2cdc902eb226007e06412fc4d05c2	energy-efficient and network-aware offloading algorithm for mobile cloud computing	energy efficiency;mobile cloud computing;mobile clone;qa75 electronic computers computer science;offloading algorithm;mobile cloudlet	We propose a new system architecture for mobile cloud computing (MCC) that includes a middle layer sitting between mobile devices and their cloud infrastructure or clones. This middle layer is composed of cloudlets and is thus called a cloudlet layer. Cloudlets are deployed next to IEEE 802.11 access points and serve as a localized service point in close proximity to mobile devices to improve the performance of mobile cloud services. On top of this new architecture, an offloading algorithm is proposed with the main aim of deciding whether to offload to a clone or a cloudlet. The decision-making takes into consideration the energy consumption for task execution and the network status while satisfying certain task response time constraints. We also introduce a data caching mechanism at cloudlets to further improve the overall MCC performance. Simulation results demonstrate the effectiveness and efficiency of the proposed system architecture and offloading algorithm in terms of response time and energy consumption.		Chathura M. Sarathchandra Magurawalage;Kun Yang;Liang Hu;Jianming Zhang	2014	Computer Networks	10.1016/j.comnet.2014.06.020	embedded system;real-time computing;computer science;operating system;distributed computing;efficient energy use;mobile computing;computer network	Metrics	-24.006481763781036	67.74537559933252	91916
42df8b8041bf261ba2e48facdd20d7efc707b0dc	application of supply chain mechanisms to an on demand operating environment	supply chain	With the introduction of the On Demand Operating Environment (ODOE), traditional capacity planning methodologies are being replaced by just in time resource allocation. This paper examines the application of supply chain mechanisms to dynamically coordinate the available compute capacity/resources with the service capacity/resources requirements. After reaching the ideal condition with a complete adaptation of the capacity offer to the dynamic capacity demand, the tasks of the ODOE systems are reduced to a simple order scheduling and to the logistical configuration and supervision (or monitoring) of service flow.	computer cluster;internet;just-in-time compilation;logistics;operating environment;requirement;response time (technology);scheduling (computing);server (computing);throughput	Sam Nokes;Dave Cohen	2006			supply chain risk management;process management;supply chain;operating environment;business	Embedded	-26.017199430937765	62.599839942006675	91942
47565f9bdc61c4c8db971ab2b42ab6bc397b2205	dice: internet delivery of immersive voice communication for crowded virtual spaces	grid summarization;immersive voice communication;online game;client server system;high density;access bandwidth restrictions;immersive voice communication virtual environments networked games virtual reality;brute force server model;web and internet services;bepress selected works;battlefields;audio streams;virtual reality;client server systems;networked games;bandwidth layout avatars web server computer architecture web and internet services peer to peer computing costs computational efficiency scalability;layout;virtual environments;virtual market;computer architecture;audio coding;angular clustering;crowded virtual spaces;internet;virtual reality dice internet delivery immersive voice communication crowded virtual spaces scalable system design realistic voice communication service virtual market battlefields online games voice spatial rendering avatars peer to peer computing brute force server model server based architecture audio streams access bandwidth restrictions client server system angular clustering grid summarization audio scene virtual environments networked games;voice communication;server based architecture;system design;internet delivery;games;realistic voice communication service;avatars;bandwidth;scalable system design;dice;speech communication;scalability;web server;network game;peer to peer computing;virtual environment;computer games;rendering computer graphics;avatars computer games voice communication audio coding internet rendering computer graphics client server systems;computational efficiency;peer to peer;virtual space;voice spatial rendering;online games;spatial audio;communication service;audio scene	This paper develops a scalable system design for the creation, and delivery over the Internet, of a realistic voice communication service for crowded virtual spaces. Examples of crowded spaces include virtual market places or battlefields in online games. A realistic crowded audio scene including spatial rendering of the voices of surrounding avatars is impractical to deliver over the Internet in a peer-to-peer manner due to access bandwidth limitations and cost. A brute force server model, on the other hand, will face significant computational costs and scalability issues. This paper presents a novel server-based architecture for this service that performs simple operations in the servers (including weighted mixing of audio streams) to cope with access bandwidth restrictions of clients, and uses spatial audio rendering capabilities of the clients to reduce the computational load on the servers. This paper then examines the performance of two components of this architecture: angular clustering and grid summarization. The impact of two factors, namely a high density of avatars and realistic access bandwidth limitations, on the quality and accuracy of the audio scene is then evaluated using simulation results.	angularjs;avatar (computing);brute-force search;cluster analysis;computation;internet;peer-to-peer;scalability;server (computing);simulation;surround sound;systems design	Paul Boustead;Farzad Safaei;Mehran Dowlatshahi	2005	IEEE Proceedings. VR 2005. Virtual Reality, 2005.	10.1109/VR.2005.29	layout;games;scalability;the internet;simulation;computer science;virtual machine;speech;operating system;dice;virtual reality;multimedia;world wide web;bandwidth;web server;systems design	Networks	-22.63447870531682	74.13184954419714	92451
6f31d37db8ba4e7b386586b04b7b7e995a4668b6	an autonomic approach for resource provisioning of cloud services	resource provisioning;mape loop;learning automata;cloud services;cloud computing	Recently, there has been a significant increase in the use of cloud-based services that are offered in software as a service (SaaS) models by SaaS providers, and irregular access of different users to these cloud services leads to fluctuations in the demand workload. It is difficult to determine the suitable amount of resources required to run cloud services in response to the varying workloads, and this may lead to undesirable states of over-provisioning and under-provisioning. In this paper, we address improvements to resource provisioning for cloud services by proposing an autonomic resource provisioning approach that is based on the concept of the control monitor-analyze-plan-execute (MAPE) loop, and we design a resource provisioning framework for cloud environments. The experimental results show that the proposed approach reduces the total cost by up to 35 %, the number of service level agreement (SLA) violations by up to 40 %, and increases the resource utilization by up to 25 % compared with the other approaches.	autonomic computing;autonomic networking;cloud computing;cloudsim;provisioning;service-level agreement;software as a service	Mostafa Ghobaei Arani;Sam Jabbehdari;Mohammad Ali Pourmina	2016	Cluster Computing	10.1007/s10586-016-0574-9	real-time computing;cloud computing;computer science;operating system;distributed computing;services computing;computer network	HPC	-23.43173629433072	62.3107405474089	92472
ef681d066c5b17506558f00c33704362f5722259	edge computing – edge 2018		Edge computing systems (Cloudlet, Fog Computing, Multi-access Edge Computing) provide numerous benefits to information technology: reduced latency, improved bandwidth, battery lifetime, etc. Despite all the benefits, edge computing systems have several issues that could significantly reduce the performance of certain applications. Indeed, current edge computing technologies do not assure ultra-low latency for real-time applications and they encounter overloading issues for data processing. To solve the aforementioned issues, we propose Home Edge Computing (HEC): a new three-tier edge computing architecture that provides data storage and processing in close proximity to the users. The term “Home” in Home Edge Computing does not restrain our work to the homes of the users, we take into account other places where the users could connect to the Internet such as: companies, shopping malls, hospitals, etc. Our three-tier architecture is composed of a Home Server, an Edge Server and a Central Cloud which we also find in traditional edge computing architectures. The Home Server is located within the vicinities of the users which allow the achievement of ultra-low latency for applications that could be processed by the said server; this also help reduce the amount of data that could be treated in the Edge Server and the Central Cloud. We demonstrate the validity of our architecture by leveraging the EdgeCloudSim simulation platform. The results of the simulation show that our proposal can, in fact, help achieve ultra-low latency and reduce overloading issues.	crc-based framing;cloudlet;computer architecture;computer data storage;edge computing;fog computing;home server;multitier architecture;operator overloading;real-time transcription;server (computing);simulation	Liang-Jie Zhang	2018		10.1007/978-3-319-94340-4		HPC	-24.278075271891453	68.10711290879516	92559
105fc8ac35549725c75165cf1901dd1361dc0699	intelligent daily scheduler		It is quite evident that everyone has certain objectives to be completed and quite a few expectations to be met. Accomplishments of these targets require proper planning in addition to an individual's abilities. Smartphones have seen substantial growth over the past decade and there is perceptible evidence of people relying on them. Although there are solutions in the form of to-do list applications to mitigate the scheduling problem, they provide little insight regarding an individual's time organization. Most of the existing applications just provide the feature of recording the tasks and users themselves need to set the time at which these tasks have to be executed. In our application focus is laid on learning the leisure time of the user by indirectly monitoring day to day activities through the app. Free time as predicted by the model and the list of tasks to be performed together form the input to the scheduling algorithm. The scheduling algorithm then allocates time for each task ensuring load balancing by evenly distributing the tasks across the week and the user is notified of their personalized final schedule.		J. Geetha;B. Akanksh;A. S. Kiran Koushik	2018	2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2018.8554485	task analysis;control engineering;real-time computing;data collection;scheduling (computing);job shop scheduling;computer science;load balancing (computing);load management;schedule	HCI	-26.378094516381566	65.12573533152373	92939
d5abb0b90162e013f0e1f501e7371404f9b5b221	multilayer perceptron and stacked autoencoder for internet traffic prediction		Internet traffic prediction is an important task for many applications, such as adaptive applications, congestion control, admission control, anomaly detection and bandwidth allocation. In addition, efficient methods of resource management can be used to gain performance and reduce costs. The popularity of the newest deep learning methods has been increasing in several areas, but there is a lack of studies concerning time series prediction. This paper compares two different artificial neural network approaches for the Internet traffic forecast. One is a Multilayer Perceptron (MLP) and the other is a deep learning Stacked Autoencoder (SAE). It is shown herein how a simpler neural network model, such as the MLP, can work even better than a more complex model, such as the SAE, for Internet traffic prediction.	autoencoder;multilayer perceptron	Tiago Prado Oliveira;Jamil Salem Barbar;Alexsandro Santos Soares	2014		10.1007/978-3-662-44917-2_6	machine learning;computer network	AI	-26.15161685190827	63.90326882784929	93084
969093c077c9fdedd5896732bb4f7cab6426424a	energy efficiency measurements of mobile virtualization systems		The energy efficiency has become an important aspect in data centers and large server systems, including the ones used in infrastructure for mobile applications service providers. Virtualization is one of the main research directions for both large scale data centers and applications servers. Furthermore, virtualization is also popular on desktop systems and is now considered in embedded systems. The next step will be to use virtualization on battery powered systems or mobile devices, where power consumption is an important aspect. This paper explores how virtualization influences the power consumption of both physical systems and virtual systems and which is the most efficient way to implement virtualized applications. The paper proposes a test bench and a set of test cases which can be further used to evaluate and compare different virtualization solutions together with several power management mechanisms using specific energy efficiency metrics.	central processing unit;data center;desktop computer;embedded system;hardware virtualization;input/output;l4linux;laptop;mobile app;mobile device;multi-core processor;power management;server (computing);test bench;test case;ubuntu	Marius Marcu;Dacian Tudor	2011		10.1007/978-3-642-30244-2_8	embedded system;operating system;computer network	OS	-24.335062105919214	66.60122049287656	93349
1dbddcd1017a6324cf7dfa2f63edd5b6f8c97fcc	rpeca-rumor propagation based eventual consistency assessment algorithm		Replicating data across servers or storages in different data centers allows using data closer to the client and reducing latency for applications, In addition, it also increases the availability in the event of one or some datacenters failure. Hence, replica consistency among all nodes is a major consideration when designing high-availability across-domain datacenters. Even lots of mechanisms are proposed to reach this consistency target, we believe knowing the degree of consistency is helpful to an application developer as the dimension of uncertainty is reduced: The quality of service (QoS) becomes, to some degree, predictable. For this purpose, this paper proposes a novel algorithm called RPECA which can be applied to monitor consistency behaviors in a cost-efficient way. RPECA is based on theory of rumor propagation in complex networks. In this paper, we focus on the probability of each node's specific status in the network (Ignorant, Spreader or Stifler). Based on the discrete-time markov chain model technique, we apply a set of topology-independent equa- tions to describe the microscope dynamic property of each node at any given time. Besides, we construct the whole phase diagram of the rumor spreading process in SF and small-world networks to simulate consistency behavior. In the experimental part, on one hand, the numerical results of our RPECA method could almost coincide with the empirical results of Monte Carlo (MC) simula- tions, which proves that our algorithm could simulated the whole phase diagram correctly. On the other hand, since the numerical results could be solved with less iterations, our RPECA algorithm could significantly outperform MC method with respect to time complexity.	algorithm;eventual consistency;software propagation	Dong Zhang;Zhiyuan Su;Kaiyuan Qi;Guomao Xin;Peng Wei	2015		10.1007/978-3-319-23216-4_5	real-time computing;computer science;theoretical computer science;consistency model;distributed computing	NLP	-25.401336785562343	62.89918812096995	93908
050e77e4648019e85f113f3332a69fcb4ae801b6	introducing cpu time as a scarce resource in p2p systems to achieve fair use in a distributed dns	p2p system;domain name system cpu time p2p systems distributed dns peer to peer systems scarce resource trading;domain name system;cpu time;peer to peer systems;resource allocation;scarce resource trading;resource allocation peer to peer computing;resource sharing;peer to peer computing resource management central processing unit robustness informatics grid computing large scale systems information systems computer networks distributed computing;a priori information;self organization;peer to peer computing;distributed dns;peer to peer;p2p systems	Peer-to-peer (P2P) systems are flexible, robust, and self-organizing resource sharing infrastructures which are typically designed in a fully decentralized manner. However, a key problem of such systems are peers overusing a resource. This paper presents a fully decentralized scheme to achieve fair use in P2P systems, which does not require a priori information about a peer. The approach developed is based on a scarce resource trading scheme (SRTCPU), which utilizes CPU time as a form of payment. SRTCPU provides an incentive to offer CPU time in return of consuming a scarce resource. A distributed DNS has been implemented as an example application that uses SRTCPU.	central processing unit;organizing (structure);peer-to-peer;self-organization	Thomas Bocek;David Hausheer;Reinhard Riedl;Burkhard Stiller	2006	Proceedings IEEE INFOCOM 2006. 25TH IEEE International Conference on Computer Communications	10.1109/INFOCOM.2006.49	shared resource;self-organization;resource allocation;computer science;operating system;cpu time;database;distributed computing;domain name system;computer network	Embedded	-20.443909836996525	69.58873740128024	93913
7126766a4f607bf39dee114223c01724d2c860a2	resource-efficient hardware implementation of a neural-based node for automatic fingerprint classification		Modern mobile communication networks and Internet of Things are paving the way to ubiquitous and mobile computing. On the other hand, several new computing paradigms, such as edge computing, demand for high computational capabilities on specific network nodes. Ubiquitous environments require a large number of distributed user identification nodes enabling a secure platform for resources, services and information management. Biometric systems represent a useful option to the typical identification systems. An accurate automatic fingerprint classification module provides a valuable indexing scheme that allows for effective matching in large fingerprint databases. In this work, an efficient embedded fingerprint classification node based on the fusion of a Weightless Neural Network architecture and a technique, namely Virtual Neuron, which efficiently maps a neural network architecture into hardware resources, is presented. The key novelty of the proposed paper is a new neural-based classification methodology that can leverage devices and sensors with limited number of resources, allowing for resource-efficient hardware implementations. Furthermore, the classifier efficiency and the accuracy have been optimized to obtain high classification rate with the best trade-off between minimum area on chip and execution time. The proposed neural-based classifier analyzes a directional image, which is extracted from the original fingerprint image without any enhancement, and classifies the processed item into the five NIST NBIS classes. This approach has been designed for FPGA devices, by exploiting pipeline techniques for execution time reduction. Experimental results, based on a 10-fold cross-validation strategy, show an overall average classification rate of 90.08% on the whole official FVC2002DB2 database.	ambient intelligence;artificial neural network;authentication;biometrics;cross-validation (statistics);database;edge computing;embedded system;field-programmable gate array;fingerprint;fingerprint recognition;information management;internet of things;mhealth;map;mobile computing;mobile device;network architecture;neuron;pipeline (computing);run time (program lifecycle phase);sensor;smart environment;telecommunications network;weightless (wireless communications)	Vincenzo Conti;Leonardo Rundo;Carmelo Militello;Giancarlo Mauri;Salvatore Vitabile	2017	JoWUA		computer network;computer science;theoretical computer science;fingerprint	Mobile	-31.092155815214493	67.01035688140928	93944
1e690c7306f6be6b95ae83099b43dc517936b700	cloud service negotiation: concession vs. tradeoff approaches	concession approaches;tradeoff approaches;cloud service negotiation;service provider;functional properties;service providers cloud service negotiation concession approach tradeoff approach cloud service security cloud service reliability cloud service availability automated negotiation conflict resolution nonfunctional properties social benefit service consumers;success rate;social benefit;reliability proposals cloud computing quality of service radiation detectors arrays educational institutions;concession approaches cloud service negotiation tradeoff approaches;automated negotiation;cloud computing	For Cloud services, their non-functional properties like availability, reliability and security are important differentiators. However, service consumers and service providers may conflict over non-functional properties. In fact, the conflicts can be resolved via automated negotiation, which is considered as the most flexible approach to procure products and services. In this paper, we propose tradeoff approaches for Cloud service negotiation, and compare them with concession ones. As opposed to concession ones, tradeoff approaches do not reduce one's utility, but still can create a proposal attractive to its opponent. Indeed, simulation results show that tradeoff approaches outperform concession ones in terms of both individual utility and social benefit. However, simulation results also demonstrate that tradeoff approaches under perform concession ones in terms of success rate.	cloud computing;platform as a service;procurement;simulation	Xianrong Zheng;Patrick Martin;M. Kathryn Brohman	2012	2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (ccgrid 2012)	10.1109/CCGrid.2012.94	service provider;simulation;cloud computing;computer science;operating system;computer security	Arch	-24.610629508363473	65.30389891624856	94100
ddfaa76dbe8132e9dcebe0dac9e90e10a76eab0c	resource management model and resourcediscovery algorithm for p2pgrid	resource management model;p2pgrid;genetic ant algorithm	Grid and peer-to-peer (P2P) are both hot topics respectively. However, the convergence of the two systems is increasingly visible: the two research communities started to acknowledge each other by forming multiple research groups that study the potential lessons that exchanged. P2P research focuses more and more on providing infrastructure and diversifying the set of applications; Grid research is starting to pay particular attention to increasing scalability. Therefore, P2P technology can improve the scalability of traditional Grid. In this paper, we firstly describe a P2PGrid resource management model, then propose a genetic ant algorithm to discovery resource efficiently in the P2PGrid environment. Theoretical analysis and simulations prove that the algorithm can improve the performance of resource discovery in P2PGrid .	algorithm	Zenggang Xiong;Xuemin Zhang;Li Liu	2011	JNW	10.4304/jnw.6.8.1187-1194	simulation;computer science;knowledge management;management science	EDA	-30.654695973419066	61.29937900675357	94312
b004b9da56e304c3364d2ff6228ac8e7f09270d6	group buying based incentive mechanism for mobile crowd sensing	smart phones mobile communication aggregates global positioning system cost accounting intelligent sensors;smart phones incentive schemes;two phase group buying based auction mechanism group buying based incentive mechanism mobile crowd sensing smart phones	Mobile crowd sensing (MCS) has become a promising paradigm to perceive the environment with the help of smart phones. A monetary award is an effective method to incentivize participants to contribute good quality data. However, the reward for long-term data collection in the wide area could be unaffordable for a MCS requester. In this paper, we enable data requesters to recruit sensing workers in a group buying way. Requesters with similar data demand can form a group to share the payment and sensing data, which reduces cost and increases the coverage of sensing data. Agents from different groups compete in buying sensing data from sensing workers. We propose TGBA, a Two-phase Group Buying based Auction mechanism for MCS. In phase I, requesters submit bids to their group agent, the group agent decides the winners and clearing prices. In phase II, group agents attend the auction for recruiting workers. TGBA is computationally efficient and possesses good economic properties such as individual rationality, budget balance and truthfulness.	algorithm;algorithmic efficiency;crowdsourcing;effective method;multi categories security;programming paradigm;rationality;simulation;smartphone;two-phase commit protocol;two-phase locking	Liqun Huang;Yanmin Zhu;Jiadi Yu;Min-You Wu	2016	2016 13th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)	10.1109/SAHCN.2016.7732996	internet privacy;computer security	Mobile	-27.400587478926507	71.9788232826465	94325
c754a5113a391a3a02e9bfe9fcf13a349c325d57	an algorithm to optimize electrical flows of private cloud infrastructures	reliability;measurement;virtualisation cloud computing computer centres power aware computing;optimization energy flow model dependability and sustainability evaluation power load distribution algorithm in depth search;computer architecture;computational modeling;energy consumption;environment impact electrical flow optimization private cloud infrastructures cloud computing energy consumption application layer management virtualization services software layer data center power system power load distribution algorithm in depth search plda d power distribution optimization private cloud electrical infrastructures energy flow model efm power infrastructures tier ii electrical architecture;cloud computing computational modeling reliability energy consumption measurement load modeling computer architecture;load modeling;cloud computing	The reduction of cloud computing energy consumption can be related to the application layer management with virtualization services, or a software layer. All clouds demand a power infrastructure with high availability. A data center power system is generally classified according to four redundancy levels, named tier I to IV. This paper proposes a power load distribution algorithm in depth search (PLDA-D) to optimize the power distribution of private cloud electrical infrastructures. The PLDA-D adopts the Energy Flow Model (EFM) as the basis to design power infrastructures. The EFM is a model that computes sustainability impacts and cost issues while it respects the restrictions of each component to provide energy. In addition, a case study illustrates the applicability of the proposed PLDA-D through the analysis of a private cloud running over a data center made up of tier II electrical architecture. Considerable results were achieved though the evaluation of the proposed algorithm. For instance, a reduction of 2.95% in energy consumption as well as an improvement of over 17% on the environment impact.	algorithm;cloud computing;data center;high availability;load balancing (computing);multitier architecture	João Ferreira;Jamilson Dantas;Jean Araujo;Danilo Mendonca;Paulo Romero Martins Maciel;Gustavo Rau de Almeida Callou	2015	2015 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/SMC.2015.144	real-time computing;simulation;cloud computing;computer science;cloud testing;reliability;distributed computing;computational model;measurement;statistics	HPC	-21.76365901718311	62.526220289437276	94601
30c5dda335ddf9a75f9f7b9ff704ceef49e33697	joint task offloading scheduling and transmit power allocation for mobile-edge computing systems		Mobile-edge computing (MEC) has emerged as a prominent technique to provide mobile services with high computation requirement, by migrating the computation- intensive tasks from the mobile devices to the nearby MEC servers. To reduce the execution latency and device energy consumption, in this paper, we jointly optimize task offloading scheduling and transmit power allocation for MEC systems with multiple independent tasks. A low-complexity sub-optimal algorithm is proposed to minimize the weighted sum of the execution delay and device energy consumption based on alternating minimization. Specifically, given the transmit power allocation, the optimal task offloading scheduling, i.e., to determine the order of offloading, is obtained with the help of flow shop scheduling theory. Besides, the optimal transmit power allocation with a given task offloading scheduling decision will be determined using convex optimization techniques. Simulation results show that task offloading scheduling is more critical when the available radio and computational resources in MEC systems are relatively balanced. In addition, it is shown that the proposed algorithm achieves near-optimal execution delay along with a substantial device energy saving.	algorithm;computation;computational resource;convex optimization;edge computing;flow shop scheduling;mathematical optimization;mobile device;scheduling (computing);serial digital video out;simulation;weight function	Yuyi Mao;Jun Zhang;Khaled Ben Letaief	2017	2017 IEEE Wireless Communications and Networking Conference (WCNC)	10.1109/WCNC.2017.7925615	embedded system;parallel computing;real-time computing;computer science	Embedded	-22.081310438625714	66.99639395564881	94613
101f90b9b7485535cec6b6f85a509a3503ebde75	performance measurement and interference profiling in multi-tenant clouds	cpu steal time cloud computing co tenant interference performance measurement performance variation;runtime interference cloud computing measurement benchmark testing virtual machine monitors resource management;performance variation;co tenant interference;xen based multitenant cloud environment performance interference profiling system multitenant clouds cloud based services large scale organizations operational cost reduction medium organizations small organizations capacity planning shared cpu caches memory bandwidth hard disks network bandwidth cpu time allocation high level cpu multiplexing performance low level cpu multiplexing performance application performance prediction amazon ec2 m3 medium model instance cloud subscribers cloud service providers multitenant performance measurement;resource allocation cloud computing cost reduction;performance measurement;cpu steal time;cloud computing	The ongoing rush for cloud-based services by small, medium, and large-scale organizations to reduce operational cost and to have more flexibility in the deployment and management of business applications cannot be overemphasized. However, the performance of in-cloud applications is often quite disappointing and unpredictable. Cloud users often perceive the sub optimal and unpredictable performance as anomalies as it is hard to conduct capacity planning based on such unreliable measurements. Performance interference due to resource sharing has been well studied in literature. Representative work includes the study of shared CPU caches, memory bandwidth, hard disks, network bandwidth, and the fair allocation CPU time. There lacks a comprehensive understanding of the complex interplay for shared resource under contention such as CPU. In this research work, we focus on predicting application performance by establishing a mathematical relationship between the high-level performance and the low-level CPU multiplexing. We design a synthetic workload with controllable CPU demands to emulate interference workloads in the cloud. We begin our measurements in a controlled environment to study the impact of CPU allocation on application performance. Based on the results from our experiments, we established the interdependency between CPU steal time, and application performance, and confirms that the percentage of CPU steal time influence application performance, even when workloads of equal parameters were submitted for processing on the same system platform. Our experimental results were evaluated against similar experimental results we performed on Amazon EC2 m3.medium model instance. We confirmed that the workload runtime duration on Amazon EC2 m3. medium model instance are significantly been impacted by high CPU steal time percentage due to interference from co-tenants. Therefore, the workload runtime slowdown percentage on submitted workloads on Amazon EC2.medium model instance is the hidden cost incurred by Cloud subscribers in term of time lost. Cloud service providers should pay close attention to CPU steal time percentage as part of system optimization efforts on Xen based cloud platform. We present Multi-tenant Performance Measurement and Interference Profiling system, a Xen based multi-tenant cloud environment designed for performance measurement and profiling.	amazon elastic compute cloud (ec2);cpu cache;central processing unit;cloud computing;dhrystone;experiment;hard disk drive;high- and low-level;interdependence;interference (communication);mathematical optimization;memory bandwidth;multiplexing;multitenancy;profiling (computer programming);program optimization;software deployment;statistical interference	Anthony O. Ayodele;Jia Rao;Terrance E. Boult	2015	2015 IEEE 8th International Conference on Cloud Computing	10.1109/CLOUD.2015.128	performance measurement;real-time computing;simulation;cloud computing;computer science;cpu modes;operating system;cpu shielding	HPC	-22.15307333943203	60.86028503029934	94772
2fee98f00595c457916b9b64e3b322426c42f1c8	a method of recovering hbase records from hdfs based on checksum file		Data recovery is a key problem in disaster recovery and digital forensics fields. The HDFS (Hadoop Distributed File System) is widely used for storing high-volume, velocity and variety dataset. However, previous work about data recovery mainly focuses on personal computers or mobile phones, and few attentions have been taken to HFDS. This paper analyzes the feature of HDFS and proposes a recovery method based on checksum file in order to address the records recovery problem of HBase, which is a common application on HDFS. We first carve out the Data blocks of HFile (HBase data file) using the corresponding checksum file, then analyze the format of HBase table records to extract them from the carved Data blocks. The experiments demonstrate that our method can restore HBase records effectively. The recovery rate is nearly 100% when the cluster size is 4 KB and 2 KB.	apache hbase;apache hadoop;checksum	Lin Zeng;Ming Xu;Jian Xu;Ning Zheng;Tao Yang	2016		10.1007/978-3-319-59288-6_12	computer science;distributed file system;file carving;disaster recovery;data file;database;operating system;data recovery;digital forensics;checksum	OS	-31.5696099188712	63.5994057519193	94879
8d95c8ada3bc53718c841c40be8a5a978ee54c4c	cost effective approaches for content placement in cloud cdn using dynamic content delivery model		Cloud﻿providers﻿give﻿storage﻿access﻿and﻿efficient﻿content﻿placement﻿and﻿delivery﻿services﻿to﻿content﻿ providers﻿ by﻿ optimizing﻿ cloud-based﻿ content﻿ delivery.﻿ The﻿ cost-efficient﻿ model﻿ should﻿ not﻿ only﻿ consider﻿the﻿content﻿delivery﻿cost﻿but﻿also﻿the﻿storage﻿cost﻿associated﻿with﻿the﻿cloud﻿network.﻿In﻿ this﻿article,﻿a﻿novel﻿cloud-based﻿content﻿delivery﻿model﻿is﻿proposed﻿that﻿uses﻿shared﻿storage﻿models﻿ for﻿cost﻿optimization﻿in﻿content﻿delivery.﻿Shared﻿storages﻿are﻿placed﻿in﻿different﻿areas﻿of﻿the﻿content﻿ delivery﻿network﻿and﻿an﻿efficient﻿replica﻿placement﻿strategy﻿is﻿employed﻿using﻿optimization﻿techniques.﻿ Different﻿content﻿delivery﻿schemes﻿are﻿used﻿in﻿proposed﻿model﻿for﻿different﻿situations﻿and﻿overall﻿ content﻿delivery﻿cost﻿ is﻿optimized.﻿Experimental﻿results﻿show﻿better﻿performance﻿and﻿lesser﻿cost﻿ in﻿terms﻿of﻿storage,﻿traffic﻿and﻿latency﻿and﻿also﻿satisfy﻿Quality-of-Service﻿(QoS)﻿and﻿Quality-ofExperience﻿(QoE)﻿in﻿content﻿delivery﻿using﻿PSO﻿when﻿compared﻿to﻿ACO﻿and﻿GA. KEywoRDS Ant Colony Optimization Algorithm, Cloud Computing, Content Delivery, Genetic Algorithm, Particle Swarm Optimization Algorithm, Shared Storage	ant colony optimization algorithms;cloud computing;content delivery network;genetic algorithm;particle swarm optimization;quality of service	S. Sajithabanu;S. R. Balasundaram	2018	IJCAC	10.4018/IJCAC.2018070106	computer network;cloud computing;computer science;dynamic web page	HPC	-19.374135697493713	64.41787404184097	95658
0da76a3d5a0771720e622ac5566be998d6020244	strategy-proof dynamic resource pricing of multiple resource types on federated clouds	large scale;dynamic pricing;resource sharing;computational efficiency;supply and demand	There is growing interest in large-scale resource sharing with emerging architectures such as cloud computing, where globally distributed and commoditized resources can be shared and traded. Federated clouds, a topic of recent interest, aims to integrate different types of cloud resources from different providers, to increase scalability and reliability. In federated clouds, users are rational and maximize their own interest when consuming and contributing shared resources, while globally distributed resource supply and demand changes as users join and leave the cloud dynamically over time. In this paper, we propose a dynamic pricing scheme for multiple types of shared resources in federated clouds and evaluate its performance. Fixed pricing, currently used by cloud providers, does not reflect the dynamic resource price due to the changes in supply and demand. Using simulations, we compare the economic and computational efficiencies of our proposed dynamic pricing scheme with fixed pricing. We show that the user utility is increased, while the percentage of successful buyer requests and the percentage of allocated seller resources is higher with dynamic pricing.	cloud computing;scalability;simulation;tag cloud	Marian Mihailescu;Yong Meng Teo	2010		10.1007/978-3-642-13119-6_30	shared resource;computer science;supply and demand	HPC	-23.453039177113542	64.82881222029451	96231
8201c92ec38146cd25ae05a5c97508b07948d926	modeling the performance of heterogeneous iaas cloud centers	analytical models;heterogeneous clouds;virtual reality cloud computing computer centres probability stochastic processes;probability;resource management;virtual reality;computer centres;servers;computational modeling;stochastic processes;numerical models;delays computational modeling servers analytical models probability numerical models resource management;performance modeling;capacity planning heterogeneous iaas cloud centers performance modeling cloud computing centers shared resources heterogeneous resources stochastic performance model heterogeneous physical resource virtual resource task characteristics key performance metrics task blocking probability;heterogeneous clouds cloud computing performance modeling;delays;cloud computing	Performance modeling of cloud computing centers is a challenging task due to complexity, shared resources and large scale of such systems. Introducing heterogeneous resources and workloads make the analysis even more complicated. In this paper, we propose a layered stochastic performance model applicable to cloud centers with wide range of heterogeneous physical and virtual resources as well as task characteristics without sacrificing the scalability, granularity and simplicity. Under various parameters and configurations, key performance metrics such as task blocking probability and total delay incurred on user tasks are obtained. The results also reveal practical insights into capacity planning for cloud computing centers.	blocking (computing);cloud computing;erlang (unit);interaction;performance prediction;random-access memory;scalability;server (computing);stochastic process	Hamzeh Khazaei;Jelena V. Misic;Vojislav B. Misic;Nasim Beigi Mohammadi	2013	2013 IEEE 33rd International Conference on Distributed Computing Systems Workshops	10.1109/ICDCSW.2013.18	real-time computing;simulation;cloud computing;computer science;resource management;operating system;probability;distributed computing;virtual reality;computational model;server;statistics	HPC	-22.72854317519824	62.59210228488531	96294
521a51e0352f8e676739ceeff785adbcb4d66318	resource allocation techniques based on availability and movement reliability for mobile cloud computing	availability;resource allocation;mobile cloud;fault tolerance;movement reliability	The researches on utilizing mobile devices as resources in mobile cloud environments have been gained attentions recently because of the enhanced computer power of mobile devices with the advent of dual cores chips. In this paper, propose a resource allocation technique which offers reliable resource allocation considering the availability of mobile resources and movement reliability of mobile resources. We also demonstrate the performance of our technique through the experiments.	mobile cloud computing	Ji Su Park;Heon-Chang Yu;Eunyoung Lee	2012		10.1007/978-3-642-28073-3_27	availability;fault tolerance;real-time computing;resource allocation;computer network	HPC	-23.61182386212104	67.69832180904946	96569
5fa4c7df3426b2278969b1e8d761975a342a3d9d	services de répartition de charge pour le cloud : application au traitement de données multimédia. (load distribution services for the cloud : a multimedia data management example.)		"""Nowadays, progresses in algorithmics and computing infrastructures allow to extract more and more adequate and useful information from sensor networks or web services data. These big data computing platforms have to face several challenges. A data partitioning issue ; storage of large volumes imposes aggregating several machines capacity. From this problem arises a second issue : to compute these data, tasks must be distributed efficiently in order to avoid overloading networks and machines capacities. The research work carried in this thesis consists in developping new load balancing algorithms for big data computing software. The first designed algorithm, named WACA (Workload And Cache Aware algorithm) enhances computing latency by using summaries for locating data in the system. The second algorithm, named CAWA for """"Cost AWare Algorithm"""", takes advantage of cost information available on so-called """"Cloud Computing"""" platforms by studying services execution history. Performance evaluation of these algorithms required designing a Cloud Infrastructure simulator named """"Simizer"""", to allow testing prior to real setting deployment. This deployement can be carried out transparently thanks to a web service monitoring and distribution framework called """"Cloudizer"""", also developped during this thesis work and was used to assess these algorithms on the Amazon Elastic Compute Cloud platform. These works are set in the context of data computing platform project called """"Multimedia for Machine to Machine"""" (MCube). This project requires a software infrastructure fit to store and compute a large volume of pictures and sounds, collected from sensors. The specifics of the data computing programs used in this project required the development of an automated execution environement adaptation service."""	algorithm;algorithmics;amazon elastic compute cloud (ec2);big data;cloud computing;function overloading;image;load balancing (computing);mcube;machine to machine;performance evaluation;sensor;software as a service;software deployment;web service	Sylvain Lefebvre	2013				HPC	-22.230074221938164	62.855031400177744	96909
8b821731a0c6c2a67fa757dc7605fb585fbda94d	automatic cloud resource scaling algorithm based on long short-term memory recurrent neural network	resource provisioning;virtualized resources;ijacsa volume 7 issue 12;cloud resource scaling;thesai;recurrent neural networks;auto scaling;cloud computing	Scalability is an important characteristic of cloud computing. With scalability, cost is minimized by provisioning and releasing resources according to demand. Most of current Infrastructure as a Service (IaaS) providers deliver thresholdbased auto-scaling techniques. However, setting up thresholds with right values that minimize cost and achieve Service Level Agreement is not an easy task, especially with variant and sudden workload changes. This paper has proposed dynamic threshold based auto-scaling algorithms that predict required resources using Long Short-Term Memory Recurrent Neural Network and auto-scale virtual resources based on predicted values. The proposed algorithms have been evaluated and compared with some of existing algorithms. Experimental results show that the proposed algorithms outperform other algorithms. Keywords—auto-scaling; cloud computing; cloud resource scaling; recurrent neural networks; resource provisioning; virtualized resources	algorithm;artificial neural network;autoscaling;cloud computing;elasticity (cloud computing);image scaling;long short-term memory;provisioning;recurrent neural network;scalability;service-level agreement;slashdot	Ashraf A. Shahin	2016	CoRR	10.14569/IJACSA.2016.071236	real-time computing;simulation;cloud computing;computer science;recurrent neural network;operating system;machine learning;distributed computing;computer network	HPC	-23.415189469730404	62.213954620711526	97083
d8281e6b881160fec62ec678c9572f372e87d478	broker-based resource management in dynamic multi-cloud environment		Cloud computing is being largely embraced by small, medium and large business organisations to host interactive web-based applications, as they provide unlimited services compared with the classical computing approach. However, providing uninterrupted service at an economical price with efficient utilisation of resources is the challenge faced by cloud service providers especially in serving users spread across the globe. Services from many different clouds can be reaped to address resource availability issues and impart the desired QoS. This paper presents a resource management approach for deploying three-tier applications over a broker-based multi-cloud environment. Strategies for quick cloud site selection, dynamic resource adaptation, and two-level load balancing with high availability are considered as part of this approach. Experiments are carried out on an extended cloudsim simulator using realistic session workloads that are synthesised based on different statistical distributions. Performance ev...		Naidila Sadashiv;M. Kumar S. DilipKumarS.	2018	IJHPCN	10.1504/IJHPCN.2016.10006750	computer science;computer network;site selection;resource management;distributed computing;high availability;cloudsim;quality of service;cloud computing;load balancing (computing)	HPC	-24.079287858812812	63.241496915325484	97121
fd7ab6df75049f077b0406c00075d5d0777c1691	building web-base sip analyzer with ajax approach	ajax;ip telephony industry;request response model;session initiation protocol;real time;web servers;sip;web applications;protocols network servers streaming media web server portable computers liquid crystal displays internet telephony application software monitoring programming profession;online front ends;sip ajax libpcap packet analyzer;web browsers;waiting time;ajax approach;ip networks;ip telephony industry ajax approach web applications request response model web browsers web servers session initiation protocol;libpcap;ip telephony;packet analyzer;signalling protocols;signalling protocols ip networks online front ends	Web applications are generally less interactive than desktop applications. Due to the simple request-response model between Web browsers and Web servers, users usually experience frequent waiting during a session whenever the Web applications need to get data from the server. After a browser sends out a request and await the response to return from the server, no further requests can be taken during this waiting time. In this paper we propose integrating the Ajax approach to the design of a Web-base analyzer for session initiation protocol (SIP), which is a popular protocol in IP telephony industry. By getting data asynchronously from the server, this Web-base analyzer can monitor the SIP messages on the server in real-time without reloading.	ajax (programming);desktop computer;embedded system;expect;real-time transcription;request–response;server (computing);web application;world wide web;xml appliance	Quincy Wu;Yan-Hsiang Wang	2007	21st International Conference on Advanced Information Networking and Applications Workshops (AINAW'07)	10.1109/AINAW.2007.117	ajax;sip trunking;telecommunications;computer science;web api;operating system;web page;database;session initiation protocol;world wide web;computer security;web server;application server;computer network	DB	-21.17172324380067	72.63536915710618	97181
287057ae64dc24b31d346afd3aa7b19dddacc735	qoe-aware elasticity support in cloud-native 5g systems	virtualisation 5g mobile communication cloud computing quality of experience;elasticity;random access memory;resource management;5g mobile communication;cloud computing elasticity random access memory resource management streaming media 5g mobile communication;streaming media;cloud native 5g systems cloud based 5g mobile systems etsi nfv mano framework elastic infrastructure quality of experience resource utilization virtualized environment scale down resources scale up resources cloud infrastructure service quality cloud resources qoe aware elasticity support;cloud computing	Typically, maintaining static pool of cloud resources to meet peak requirements with good service quality makes the cloud infrastructure costly. To cope with this, this paper proposes an approach that enables a cloud-infrastructure to automatically and dynamically scale-up or scale-down resources of a virtualized environment aiming for efficient resource utilization and improved quality of experience (QoE) of the offered services. The QoE-aware approach ensures a truly elastic infrastructure, capable of handling sudden load surges while reducing resource and management costs. The paper also discusses the applicability of the proposed approach within the ETSI NFV MANO framework for cloud-based 5G mobile systems.	autonomic computing;client-side;cloud computing;elasticity (cloud computing);network function virtualization;real life;real-time clock;requirement;responsiveness;testbed	Sunny Dutta;Tarik Taleb;Adlen Ksentini	2016	2016 IEEE International Conference on Communications (ICC)	10.1109/ICC.2016.7511377	cloud computing security;real-time computing;cloud computing;computer science;resource management;operating system;cloud testing;elasticity;world wide web;computer network	Embedded	-27.288471337180248	61.015949753102106	97233
074d992f42de37e0a4a5d7f1b3f3d3f885171bc9	performance evaluation of glite grids through gspns	performance measure;generalized stochastic petri nets;business innovating technology;glite middleware;performance evaluation;service provider;measurement;service level agreements;resource management;distributed computing;aerospace industry;glite grids;management strategy;generalized stochastic petri nets performance evaluation glite grids grid computing dynamic virtual organizations business innovating technology qos requirements service level agreements sla;qos requirements;performance measurements;sla;stochastic processes;business data processing;virtual organization;performance analysis;load management;dynamic virtual organizations;middleware;quality of service grid computing performance analysis stochastic processes petri nets distributed computing measurement resource management aerospace industry load management;service level agreement;profitability;petri nets;point of view;quality of service;mpi based jobs;service level agreement grid computing glite middleware mpi based jobs generalized stochastic petri nets performance measurements;grid computing;stochastic processes business data processing grid computing performance evaluation petri nets quality of service;generalized stochastic petri net	Grid Computing supports the shared and coordinated use of several resources in dynamic Virtual Organizations. In the last few years, it is evolving into a business-innovating technology that is driving commercial adoption. Such a new scenario calls for powerful strategies able to guarantee stringent QoS requirements in order to meet Service Level Agreements (SLAs) between customers and providers. For this reason, it is necessary to analyze and predict performance with respect to different load conditions or management strategies. In this paper, we present a methodology to analyze performance in gLite Grids through the use of Generalized Stochastic Petri Nets (GSPNs). We introduce a cluster-level model of a typical gLite site taking into account the coexistence between normal and MPI-based jobs. We investigate the influence of different strategies (e.g., scheduling) on the performance of the whole site, highlighting aspects related to both customer and provider point of views. We also provide a business-oriented performance analysis introducing two different SLA typologies and highlighting how the site configuration may influence the expected profit of the service provider.	business requirements;coexist (image);concurrency (computer science);grid computing;job stream;mathematical optimization;middleware;performance evaluation;petri net;quality of service;requirement;scheduling (computing);service-level agreement;glite	Dario Bruneo;Marco Scarpa;Antonio Puliafito	2010	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2010.35	service provider;real-time computing;quality of service;computer science;resource management;operating system;middleware;database;distributed computing;aerospace;petri net;grid computing;measurement;profitability index	HPC	-23.21299874756967	62.99765641292198	98038
89d62d2610b582577498d0fb8e5aae70b1e5cd3c	task scheduling and assignment methods for cloud enterprises		In the frame of Cloud Manufacturing, Cloud Enterprise interoperability represents a key role in the organization, and management of the tasks required for manufacturing the products ordered. Indeed, Cloud Enterprises need to interoperate with their Associated Phyical Providers in order to negotiate their availability for performing the tasks required, to assign and schedule these. The current paper proposes new methods for scheduling and assigning the tasks aiming at manufacturing the products ordered while dealing with the large-scale demand, service and resource clusters faced in Cloud Manufacturing. The discussed methods focus on mid-term scheduling, batch manufacturing, and includes new optimization algorithms based on continuous-time modeling and Constraint Programing for scheduling the necessary tasks, assigning these to Associated Physical Providers, and managing the renewable and non-renewable manufacturing resource allocation while considering the lowest setup and linear costs of all the Associated Physical Providers.	schedule (project management);scheduling (computing)	Tehani Mou;Lanshun Nie;De-chen Zhan;Xiaofei Xu	2012		10.1007/978-1-4471-2819-9_37	fair-share scheduling;parallel computing;real-time computing;dynamic priority scheduling;two-level scheduling;deadline-monotonic scheduling;distributed computing	HPC	-26.459614145760806	62.277535922637135	98106
429ddaa111e8ae6dd0d87e9084073ca50ad32be1	a novel scheduling approach of e-learning content on cloud computing infrastructure	cloud computing;computer aided instruction;eigenvalues and eigenfunctions;optimisation;scheduling;web layers;application layers;cloud computing infrastructure;database layers;e-learning content;e-learning ecosystem;optimal load distribution;positive symmetric square matrix eigenvalue;scheduling approach;semidefinite optimization problem;virtualization	E-learning ecosystem based on cloud computing infrastructure constantly gains a popularity in a wide research and consumer popularity. There are multiple reasons for this, including the dynamic adaptability of clouds to the changing demands, their ability to provide resources per need basis and the support for virtualization. By additionally bringing the robust security and chargeback model in it, the cloud becomes a real next generation engine for all e-learning aspects, including database, application and web layers. However, and especially in a hybrid public cloud environments, the right allocation scheme of an e-learning content is critical if the given service level agreement has to be fulfilled. It is by far not enough to distribute content accordingly to the provided amount of processing power of computational nodes and corresponding storage systems. If the content scheduler does not take into account the throughput of the network communication links, the whole system become saturated with waiting times and the response of the cloud based e-learning system degrades. Our approach is to consider both processing power of computational nodes and communication links. The idea is to minimize SLEM, the magnitude of the second largest eigenvalue of the positive symmetric square matrix with elements representing time activities of computational nodes and communication links in parallel processing environment. It shows that this minimization problem can be recast as a semi-definite optimization problem, with ability to find an optimal load distribution of e-learning content.	chargeback;cloud computing;computation;ecosystem;hardware virtualization;load balancing (computing);mathematical optimization;optimization problem;parallel computing;scheduling (computing);semiconductor industry;service-level agreement;symmetric algebra;throughput	Drasko Tomic;Osman Muftic;Berislav Biocic	2011	2011 Proceedings of the 34th International Convention MIPRO		real-time computing;computer science;theoretical computer science;distributed computing	Metrics	-20.167499799370667	63.82909929428223	98179
3e0bcdfb2761f6dd2d6571bd272e4e468b66f705	glenda: green label towards energy proportionality for iaas data centers	green label;information systems retrieval efficiency;general and reference metrics;hardware power and energy;keywords cloud computing;ccs concepts computer systems organization cloud comput ing;green computing;data centers	As cloud services multiply rapidly, so does the computing centers dedicated to them, and consequently their power consumption. Although this consumption is hampering data centers' expansion, these infrastructures have not yet reached energy proportionality, thus wasting significant amounts of energy. Numerous energy metrics have been propose as incentives towards greener infrastructures, but none of them currently gives direct insights about the energy proportionality and green energy usage of data centers. In this paper, we propose GLENDA: a Green Label towards Energy proportioNality for IaaS DAta centers. We validate our metric by using traces from real infrastructures, and show that our label gets a better grade when increasing energy efficiency, increasing utilization rates, and using distributed renewable generation. We expect this new metric to become a useful reference for Cloud providers towards green data centers.	best practice;cloud computing;data center;fossil;plan 9 from bell labs;power usage effectiveness;tracing (software)	David Guyon;Anne-Cécile Orgerie;Christine Morin	2017		10.1145/3077839.3084028	simulation;computer science;world wide web;computer security	OS	-25.712447689342536	60.604307890711816	98400
b46bf5cfc2f721557c28d2809d6704dce1af1abc	an automated tool profiling service for the cloud	genomics;profiling;cloud provisioning;production genomics gateway automated tool profiling service cloud computing resource capacity optimal instance selection;cloud computing logic gates monitoring genomics bioinformatics production;logic gates;monitoring;cloud provisioning profiling cloud computing;production;cloud computing;bioinformatics;resource allocation cloud computing program diagnostics	Cloud providers offer a diverse set of instance types with varying resource capacities, designed to meet the needs of a broad range of user requirements. While this flexibility is a major benefit of the cloud computing model, it also creates challenges when selecting the most suitable instance type for a given application. Sub-optimal instance selection can result in poor performance and/or increased cost, with significant impacts when applications are executed repeatedly. Yet selecting an optimal instance type is challenging, as each instance type can be configured differently, application performance is dependent on input data and configuration, and instance types and applications are frequently updated. We present a service that supports automatic profiling of application performance on different instance types to create rich application profiles that can be used for comparison, provisioning, and scheduling. This service can dynamically provision cloud instances, automatically deploy and contextualize applications, transfer input datasets, monitor execution performance, and create a composite profile with fine grained resource usage information. We use real usage data from four production genomics gateways and estimate the use of profiles in autonomic provisioning systems can decrease execution time by up to 15.7% and cost by up to 86.6%.	amazon web services;autonomic computing;cloud computing;credential;identity management;profiling (computer programming);provisioning;requirement;rich internet application;run time (program lifecycle phase);scheduling (computing);software deployment;terminate (software);usage data;user requirements document	Ryan Chard;Kyle Chard;Bryan Ng;Kris Bubendorfer;Alex Rodriguez;Ravi K. Madduri;Ian T. Foster	2016	2016 16th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid)	10.1109/CCGrid.2016.57	genomics;real-time computing;logic gate;cloud computing;computer science;operating system;cloud testing;data mining;database;distributed computing;profiling;world wide web	HPC	-24.4536308463233	60.836855890647	98651
dca98c9728c5d32948e23b9f20d8af3d19ba3bb4	sounde: a hybrid structure of service discovery system for decentralized e-commerce	p2p system;layered architecture;electronic commerce;service provider;b2b;e commerce;peer to;sounde;govnode;sophinode service discovery;peer to peer computing topology business analytical models humans computer science acoustical engineering service oriented architecture logic electronic commerce;govnode decentralized e commerce peer to peer service discovery sounde;decentralized e commerce;dht based topology;file sharing;service discovery;govnode sounde decentralized e commerce p2p systems b2b dht based topology sophinode service discovery;peer to peer computing;peer to peer;p2p systems;peer to peer computing electronic commerce;peer	Existing P2P systems are mostly confined to the domain of file sharing systems, which in many aspects differ from decentralized e-commerce, e.g., peer behavior mode and capability diversity. Therefore, we researched on the distinct properties of decentralized e-commerce, especially for B2B level e-commerce, and accordingly, propose a decentralized e-commerce oriented service discovery system, named SOUNDE. The system can be viewed as a two-layer architecture, with the upper layer composed of many e-commerce domains forming a DHT-based topology, then each domain composed of all the related peers in that specific commerce domain, including service requesters and service providers of it, forming an unstructured topology which applies SophiNode service discovery algorithms. Meanwhile, we also put forward GovNode, which plays the role of joint between the two layers. Gathering all the peers within same commerce industry into a logic subnet (commerce domain), then all domains into DHT structure, the fundamental purpose of SOUNDE is to diminish the searching scope of each service query, (i. e. reduce the network load), and allow the system to scale. At the end, we present our simulation and analyze the results	algorithm;discovery system;distributed hash table;e-commerce payment system;file sharing;service discovery;simulation;subnetwork	Dalu Zhang;Jiawen Mou;Zhe Yang	2006	2006 IEEE International Conference on e-Business Engineering (ICEBE'06)	10.1109/ICEBE.2006.96	e-commerce;service provider;computer science;multitier architecture;database;distributed computing;service discovery;world wide web;file sharing;computer network	DB	-24.592934727329418	73.3209988802369	99138
107335a45128ab8302aec599d38b9c0b2475ea39	leveraging the grid for the autonomic management of complex infrastructures	grid computing and applications;network management;auto- nomic computing;complex network;reaction time;grid computing	Autonomic Management of complex IT infrastructures requires multiple different types of analysis to be performed on large data sets in order to promptly detect anomalies and attacks and take appropriate actions. The requirements in terms of computing power can be so high that new solutions must be devised in order to reduce reaction times. This paper describes how Grid technologies can be leveraged in the Autonomic Management of complex IT infrastructures, such as complex networks with tens of border firewalls. In particular, we show how an Autonomic Manager can benefit from the large computing power and storage space made available by the Grid. We designed the architecture of an Autonomic Manager which makes use of Grid resources to collect and store data and to perform analysis. We then implemented the core part of the system (LoGrid), which collects data in CBE standard format, processes them using Grid resources and feeds back the results in CBE format to the Autonomic Manager. We tested our implementation in a reference scenario and found that the use of the Grid for the Autonomic Management of complex IT infrastructure is feasible and convenient.	autonomic computing;complex network;firewall (computing);middleware;overhead (computing);requirement	Silvio Salza;Yuri Di Carlo;Flavio Lombardi;Roberto Puccinelli	2006			grid;grid computing;network management station;information technology management;complex network;architecture;data set;distributed computing;computer science	HPC	-27.30250469173006	62.50291084830616	99205
a8accafe639e515b05ae11259a7945b7c0af2e06	an energy optimizing scheduler for mobile cloud computing environments	mobile handsets energy consumption virtual machining cloud computing delays optimization mobile communication;scheduling cloud computing energy consumption mobile computing power aware computing;offloading mobile cloud computing cloud computing task scheduler;task assignment energy optimizing scheduler mobile cloud computing environments mobile devices computation time minimization energy consumption minimization task related constraints user defined constraints cyber foraging system centralized broker node task scheduling problem	In mobile cloud computing, mobile devices seek to minimize computation time and/or energy consumption based on task related or user defined constraints. In earlier work [1], we proposed to minimize the total energy consumption across all the mobile devices in a cyber foraging system using a scheduler that runs in a centralized broker node, in situations where a large number of mobile devices could be expected. In this paper, we extend our earlier task scheduling problem for a large number of mobile devices to a mobile cloud computing environment. We optimally solve the task scheduling problem for task assignment to minimize the total energy consumption across the mobile devices subject to user defined constraints. Our task scheduler model at the centralized broker optimally offloads tasks and provides significant reduction in energy consumption compared to the energy consumption when tasks are offloaded from the centralized scheduler without optimization.	centralized computing;computation;cyber foraging;mathematical optimization;mobile cloud computing;mobile device;scheduling (computing);time complexity;windows task scheduler	Manjinder Nir;Ashraf Matrawy;Marc St-Hilaire	2014	2014 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2014.6849266	embedded system;real-time computing;cloud computing;computer science;cloud testing;distributed computing;utility computing;mobile computing	Mobile	-22.064422236726635	66.89292780680073	99259
0c5c4a3d10a113e557df526cd961e68f93ef4c18	predictive resource management of multiple monitoring applications	telecommunication traffic monitoring telecommunication network management;network monitoring system predictive resource management black boxes input traffic load shedding based resource management scheme educational network multiple concurrent monitoring real world traffic traces;load shedding;monitoring feature extraction aggregates accuracy resource management correlation radiation detectors;network monitoring;input traffic;load shedding based resource management scheme;radiation detectors;resource management load shedding network monitoring;resource manager;resource management;radiation detector;accuracy;telecommunication traffic;monitoring system;predictive resource management;monitoring;real world traffic traces;aggregates;feature extraction;black boxes;multiple monitors;network monitoring system;educational network;correlation;multiple concurrent monitoring;telecommunication network management	We propose a predictive resource management scheme for network monitoring systems that can proactively shed excess load while maintaining the accuracy of monitoring applications within bounds defined by the operator. The main novelty of our scheme is that it considers monitoring applications as black boxes, with arbitrary (and highly variable) input traffic and processing cost. This way, the monitoring system preserves a high degree of flexibility, increasing the range of applications and network scenarios where it can be used. We implemented our load-shedding-based resource management scheme in an existing network monitoring system and deployed it in a large research and educational network. We present experimental evidence of the performance and robustness of our system with multiple concurrent monitoring applications during long-lived executions and using real-world traffic traces.	black box;offset binary;tracing (software)	Pere Barlet-Ros;Gianluca Iannaccone;Josep Sanjuàs-Cuxart;Josep Solé-Pareta	2011	IEEE/ACM Transactions on Networking	10.1109/TNET.2010.2089469	real-time computing;simulation;computer science;resource management;operating system;particle detector;computer security;computer network	OS	-28.103863216107438	64.94364757389992	99944
4bee969ded3667d026e2bb0bde0c0b1e26f59743	computation offloading cost estimation in mobile cloud application models	mobile cloud computing;application models;computation offloading;offloading cost;computation offloading cost entities	Mobile cloud computing requires specialized application development models that can facilitate development of cloud-enabled applications. This paper presents a mathematical model to calculate the computation offloading cost (time and energy consumption) of mobile cloud application models to facilitate in the development of mobile cloud computing simulators. It demonstrates the usage of the proposed model, and shows the impact of the cost incurring parameters on the overall computational time and energy consumption of the applications. The proposed model can assist cloud-powered applications to make context-aware offloading decisions and facilitate the development of mobile cloud computing simulators, which unfortunately, does not exist to date.	computation offloading;software as a service	Atta ur Rehman Khan;Mazliza Othman;Abdul Nasir Khan;Junaid Shuja;Saad Mustafa	2017	Wireless Personal Communications	10.1007/s11277-017-4757-3	real-time computing;computer science;energy consumption;mobile cloud computing;cloud computing;computation offloading;cost estimate	Mobile	-23.232225220019558	66.06337938522093	100017
d9178633e5c2323d1ca4b38ee7b4ec875aa0a8a0	automated extraction of network traffic models suitable for performance simulation	model extraction;network traffic;mutli scale decomposition;modeling	Data centers are increasingly becoming larger and dynamic due to virtualization. In order to leverage the performance modeling and prediction techniques, such as Palladio Component Model or Descartes Modeling Language, in such a dynamic environments, it is necessary to automate the model extraction. Building and maintaining such models manually is not feasible anymore due to their size and the level of details. This paper is focused on traffic models that are an essential part of network infrastructure. Our goal is to decompose real traffic dumps into models suitable for performance prediction using Descartes Network Infrastructure modeling approach. The main challenge was to efficiently encode an arbitrary signal in the form of simple traffic generators while maintaining the shape of the original signal. We show that a typical 15 minute long tcpdump trace can be compressed to 0.4-15% of its original size whereas the relative median of extraction error is close to 0% for the most of the 69 examined traces.	encode;modeling language;network packet;performance prediction;simulation;tracing (software);tcpdump	Piotr Rygielski;Viliam Simko;Felix Christian Alexander Sittner;Doris Aschenbrenner;Samuel Kounev;Klaus Schilling	2016		10.1145/2851553.2851570	traffic generation model;real-time computing;simulation;systems modeling;computer science;engineering;data mining	Metrics	-28.633097929712086	62.33083963047933	100102
16e5e6084bd81a2e2533545aef20d6af10be5074	cyclic ranking in single-resource peer-to-peer exchange	peer-to-peer cooperation;incentives;reputation;fairness;provision cycles;structural ranking;measurements;performance	Peer-to-peer (P2P) sharing systems use incentives for resource exchange to encourage cooperation and ensure fairness. In bilateral strategies, such as BitTorrent Tit-for-Tat or deficit-based FairTorrent, individual decisions of peers utilize direct observations. It may result in low performance and unfair treatment. In this paper, we study a novel exchange strategy that applies Cyclic Ranking (CR). In addition to direct observations, a peer utilizes provision cycles—a shared history of effective exchanges. The PageRank algorithm runs for the locally collected cycles and computes the numerical ranks to estimate the reputation. The CR strategy incrementally augments known incentive-aware strategies. For evaluation we implement CR-BitTorrent and CR-FairTorrent variants. Our simulation model captures the dependence on network bandwidth and the number of seeders as well as selfishness and stability of the participants. The initial experiments show improved fairness and download times, compared to the original BitTorrent and FairTorrent. The performance of selfish and unstable peers decreases by as much as 50%. The CR strategy suits well in environments where direct reciprocity has Andrei Gurtov gurtov@acm.org Joakim Koskela jookos@gmail.com Dmitry Korzun dkorzun@cs.karelia.ru 1 Linköping University, Linköping, Sweden 2 Aalto University, Espoo, Finland 3 Petrozavodsk State University, Petrozavodsk, Russia shown little effect. Contrasted to existing solutions, the CR strategy rewards longevity and stability of peers.		Andrei V. Gurtov;Joakim Koskela;Dmitry G. Korzun	2018	Peer-to-Peer Networking and Applications	10.1007/s12083-017-0578-0	reciprocity (social psychology);peer-to-peer;pagerank;computer science;distributed computing;incentive;reputation;bittorrent;download;ranking	Networks	-25.930158850848017	72.98175887024091	100106
a1ad27bd99c27a51b7b557040d46934385b0068e	a universal distributed indexing scheme for data centers with tree-like topologies	cloud storage system;会议论文;two layer index;data center network	The indices in the distributed storage systems manage the stored data and support diverse queries efficiently. Secondary index, the index built on the attributes other than the primary key, facilitates a variety of queries for different purposes. In this paper, we propose U-Tree, a universal distributed secondary indexing scheme built on cloud storage systems with tree-like topologies. U-Tree is composed of two layers, the global index and the local index. We build the local index according to the local data features, and then assign the potential indexing range of the global index for each host. After that, we use several techniques to publish the meta-data about local index to the global index host. The global index is then constructed based on the collected intervals. We take advantage of the topological properties of tree-like topologies, introduce and compare the detailed optimization techniques in the construction of two-layer indexing scheme. Furthermore, we discuss the index updating, index tuning, and the fault tolerance of U-Tree. Finally, we propose numerical experiments to evaluate the performance of U-Tree. The universal indexing scheme provides a general approach for secondary index on data centers with tree-like topologies. Moreover, many techniques and conclusions can be applied to other DCN topologies.	cloud storage;clustered file system;data center;database;dynamic circuit network;experiment;fault tolerance;index (publishing);mathematical optimization;numerical analysis;polynomial-time approximation scheme;unique key	Yuang Liu;Xiaofeng Gao;Guihai Chen	2015		10.1007/978-3-319-22849-5_33	computer science;data mining;database;world wide web	DB	-20.3902639728942	69.0444617300454	101654
b2a81fa69c8720fa5adfaca1dbdfd5651173837b	guest editorial introduction to the special issue on adaptive learning systems in communication networks	communication networks;neural networks;adaptive learning system;adaptive systems learning systems intelligent networks communication networks fault detection neural networks fault diagnosis web and internet services ip networks adaptive signal processing;web and internet services;learning systems;adaptive signal processing;adaptive systems;community networks;fault detection;ip networks;intelligent networks;fault diagnosis		telecommunications network	Alexander G. Parlos;Chuanyi Ji;Thomas Parisini;Marco Baglietto;Amir F. Atiya;Kimberly C. Claffy	2005	IEEE Trans. Neural Networks	10.1109/TNN.2005.857081	adaptive filter;intelligent network;computer science;adaptive system;machine learning;distributed computing;artificial neural network;fault detection and isolation;computer network	Arch	-30.981145095230882	66.00812136813853	102559
ba119859ff35f937ce98052ab2f8b87e9a9dd095	workload-aware vm consolidation in cloud based on max-min ant system		With the increasing consumption of energy in cloud data center, the cloud providers pay more attention to the green cloud computing for saving energy. The most effective way in green cloud computing is using virtual machine (VM) consolidation to pack VMs into a smaller amount of physical machines (PMs), which can save energy by switching off the idle PMs. However, in traditional static workload approach, VMs are over-provisioned with a static capacity to guarantee peak performance, which increases the unnecessary energy consumption. In this paper, we propose an innovative approach WAVMC to achieve efficient VM consolidation by using multi-dimensional time-varying workloads based on the Max-Min Ant System (MMAS). In the MMAS, we employ the complementary of both workload patterns and multi-dimensional resources usage as heuristic factors. Extensive simulations on production workloads demonstrate that the proposed model outperforms state-of-the-art baselines in active server counts and resources wastage.	ant colony optimization algorithms;semiconductor consolidation	Hongjie Zhang;Guansheng Shu;Shasha Liao;Xi Fu;Jing Li	2017		10.1007/978-3-319-68505-2_16	workload;real-time computing;computer science;energy consumption;cloud computing;distributed computing;data center;ant;virtual machine;heuristic;idle	EDA	-19.94827310788442	62.15596976164098	102680
5f70021855215147733ff0d41544108515d61bc4	self-adaptive resource allocation for continuous task offloading in pervasive computing		Task offloading has proven its potential in pervasive environments in numerous systems. In particular, code offloading has gained popularity as it allows to spontaneously forward work packages to remote resources. While for discrete tasks there are multiple systems that allow for code offloading already, stream processing has gained less research attention. In this paper, we propose a self-adaptive resource allocation approach for continuous task offloading. First, we tackle the issue of communication overhead by predicting future workload. We minimize not only the number of resource requests but also the scheduling delay. Second, we introduce a learning-based resource allocation mechanism that matches jobs and resource providers. The goal of the allocation mechanism is to assign jobs only to those resources that can finish a job in time. We use a code profiler to analyze the complexity of algorithms and perform machine learning to assign jobs to resources. Our results show that we can reduce the total communication overhead by more than 90 percent and assign jobs successfully with an F-Measure of .863.	algorithm;computational complexity theory;job stream;machine learning;overhead (computing);profiling (computer programming);scheduling (computing);stream processing;ubiquitous computing	Sunyanan Choochotkaew;Hirozumi Yamaguchi;Teruo Higashino;Dominik Schäfer;Janick Edinger;Christian Becker	2018	2018 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)	10.1109/PERCOMW.2018.8480400	work package;resource management;distributed computing;task analysis;workload;stream processing;computer science;ubiquitous computing;scheduling (computing);resource allocation	HPC	-19.604289609466157	61.84287751013517	102778
33309ca4bb07e0ba1594aa701b956a02069d8e3d	an energy optimization algorithm of date centers base on price volatility	tariff interval;mobile cloud computing;energy optimization;price volatility	Optimizing the energy consumption of date centers has become a focus of attention in mobile cloud computing. However, the existing researches on energy management are rarely associated with the effect of price volatility. In this paper we propos an algorithm of energy optimization base on price volatility. The tariff interval is set base on the world time zones and energy optimization is iterative calculations using dynamic price method, a dependencies hierarchical strategy of tasks base on this policy is proposed and designed. By increasing the parallelism and execution dependencies of tasks, the amount of data movement and idle probability of data center nodes is reduced. The experimental results show that the algorithm can significantly minimize energy consumption while improving the efficiency of system.	algorithm;volatility	Liang Hao;Gang Cui;Wende Ke;Bindi You	2014		10.1007/978-3-319-07782-6_67	simulation;energy minimization	Theory	-20.573975700178227	62.77826625214265	102781
a9f6ac5d62176a93c12403474fc11d51d836fedc	scalable linear programming based resource allocation for makespan minimization in heterogeneous computing systems	high performance computing;heterogeneous computing;resource management;bag of tasks;scheduling;linear programming	Resource management for large-scale high performance computing systems poses difficult challenges to system administrators. The extreme scale of these modern systems require task scheduling algorithms that are capable of handling at least millions of tasks and thousands of machines. Highly scalable algorithms are necessary to efficiently schedule tasks to maintain the highest level of performance from the system. In this study, we design a novel linear programming based resource allocation algorithm for heterogeneous computing systems to efficiently compute high quality solutions for minimizing makespan. The novel algorithm tightly bounds the optimal makespan from below with an infeasible schedule and from above with a fully feasible schedule. The new algorithms are highly scalable in terms of solution quality and computation time as the problem size increases because they leverage similarity in tasks and machines. This novel algorithm is compared to existing algorithms via simulation on a few example systems. © 2015 Elsevier Inc. All rights reserved.	analysis of algorithms;batch processing;computation;display resolution;genetic algorithm;heterogeneous computing;heuristic (computer science);ibm websphere extreme scale;image scaling;lp-type problem;linear programming;makespan;maxima and minima;scalability;scheduling (computing);simulation;supercomputer;system administrator;time complexity	Kyle M. Tarplee;Ryan Friese;Anthony A. Maciejewski;Howard Jay Siegel	2015	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2015.07.002	mathematical optimization;parallel computing;real-time computing;computer science;linear programming;resource management;operating system;distributed computing;scheduling;symmetric multiprocessor system	HPC	-19.279903363356198	62.95613219728915	102899
b7f61ad344c515deaac6a64f16ffc06b629bfa90	economic models for management of resources in grid computing	application development;cluster computing;north america;south america;grid computing environment;resource manager;economic model;world wide grid;objective function;virtual enterprise;grid computing;cost model;geographic distribution;supply and demand	The accelerated development in Grid and peer-to-peer computing has positioned them as promising next generation computing platforms. They enable the creation of Virtual Enterprises (VE) for sharing resources distributed across the world. However, resource management, application development and usage models in these environments is a complex undertaking. This is due to the geographic distribution of resources that are owned by different organizations. The resource owners of each of these resources have different usage or access policies and cost models, and varying loads and availability. In order to address complex resource management issues, we have proposed a computational economy framework for resource allocation and for regulating supply and demand in Grid computing environments. The framework provides mechanisms for optimizing resource provider and consumer objective functions through trading and brokering services. In a real world market, there exist various economic models for setting the price for goods based on supply-and-demand and their value to the user. They include commodity market, posted price, tenders and auctions. In this paper, we discuss the use of these models for interaction between Grid components in deciding resource value and the necessary infrastructure to realize them. In addition to normal services offered by Grid computing systems, we need an infrastructure to support interaction protocols, allocation mechanisms, currency, secure banking, and enforcement services. Furthermore, we demonstrate the usage of some of these economic models in resource brokering through Nimrod/G deadline and cost-based scheduling for two different optimization strategies on the World Wide Grid (WWG) testbed that contains resources located on five continents: Asia, Australia, Europe, North America, and South America.	algorithm;algorithmic efficiency;computation;computational steering;existential quantification;experiment;file spanning;grid computing;mathematical optimization;next-generation network;on the fly;peer-to-peer;problem solving;programming paradigm;quality of service;requirement;scalability;scheduling (computing);simulation;testbed;user requirements document;world wide web	Rajkumar Buyya;Heinz Stockinger;Jonathan Giddy;David Abramson	2001	CoRR		semantic grid;computer cluster;resource allocation;computer science;economic model;resource management;operating system;supply and demand;utility computing;rapid application development;drmaa;grid computing;resource	HPC	-22.656941923883593	65.04557997931956	103051
3e69c82ac66c08f3e0c0ef031b70bb5650cf538b	framework for energy-aware lossless compression in mobile services: the case of e-mail	context aware;electronic mail;mobile device;data compression;mobile communication computational efficiency context compression algorithms energy consumption costs mobile computing decision making throughput data communication;compression algorithms;lossless compression;data communication;power aware computing;general solution;mobile service;energy consumption;energy aware;mobile communication;communication cost;context aware policies energy aware lossless compression mobile services e mail energy consumption battery lifetime mobile devices proxy server;mobile computing;computational efficiency;proxy server;context;energy saving;power measurement;throughput;power aware computing data compression electronic mail energy consumption mobile computing	Energy consumption caused by wireless transmission poses a big challenge to the battery lifetime of mobile devices. While the potential of using lossless compression for saving energy has been long acknowledged, no general solution has been proposed for applying lossless compression to energy adaptation for mobile services. We propose a proxy-based energy adaptation framework, in which the data to be transmitted is losslessly compressed on a proxy server according to context-aware policies. The context includes factors relevant to computational and communication cost, as well as the user's preferences. We showcase a context-aware policy which aims at minimizing client-side energy consumption caused by transmission and decompression. Using our framework, we implement an energy-aware mobile e-mail service, and present power measurement results that show significant energy savings.	client-side;computation;email;lossless compression;mega man network transmission;mobile device;proxy server;server (computing)	Yu Xiao;Matti Siekkinen;Antti Ylä-Jääski	2010	2010 IEEE International Conference on Communications	10.1109/ICC.2010.5502590	data compression;embedded system;real-time computing;computer science;operating system;mobile computing;statistics;computer network	Mobile	-23.20023531370883	67.68827888668649	103704
eb0085d6cafae29a57948bfca051cdcd53b45125	a new approach to cold start in peer to peer file sharing networks	game theory;service provider;internet architecture;file sharing;p2p networks;peer to peer;free riding	ion—Solving free riding and selecting a reliable service provider in P2P networks has been separately investigated in last few years. Using trust has shown to be one of the best ways of solving these problems. But using this approach to simultaneously deal with both problems makes it impossible for newcomers to join the network and the expansion of network is prevented. In this paper we used the game theory to model the behavior of peers and developed a mechanism in which free riding and providing bad service are dominated strategies for peers. At the same time newcomers can participate and are encouraged to be active in the network. The proposed model has been simulated and the results showed that the trust value of free riders and bad service providers converge to a finite value and trust of peers who provide good service is monotonically increased despite the time they join the network.	cold start;converge;game theory;peer-to-peer	Ehsan Hosseini;Mohammad Ali Nematbakhsh	2009	CoRR		service provider;game theory;computer science;internet privacy;free riding;world wide web;computer security;file sharing;computer network	Metrics	-25.802988309176637	73.32777904621635	103969
dac7f5dce10512eb8989700e1682e3a53a08b4da	competitive cloud resource procurements via cloud brokerage	game theory cloud computing;game theory;nash equilibrium;conference_paper;resource allocation;procurement;pricing;pricing scheme design;distributed learning cloud computing resource allocation pricing scheme design game theory;distributed learning;clouds;games;nash equilibrium iaas cloud markets tenant consumers demand quantities service quality tenant demand correlation cloud brokerage services cloud resource multiplexing cloud providers competitive cloud resource procurements noncooperative game modeling static game surplus optimal demand responses pricing strategies;pricing games procurement nash equilibrium delays clouds cloud computing;delays;cloud computing	In current IaaS cloud markets, tenant consumers non-cooperatively compete for cloud resources via demand quantities, and the service quality is offered in a best effort manner. To better exploit tenant demand correlation, cloud brokerage services provide cloud resource multiplexing so as to earn profits by receiving volume discounts from cloud providers. A fundamental but daunting problem facing a tenant consumer is competitive resource procurements via cloud brokerage. In this paper, we investigate this problem via non-cooperative game modeling. In the static game, to maximize the experienced surplus, tenants judiciously select optimal demand responses given pricing strategies of cloud brokers and complete information of the other tenants' demands. We also derive Nash equilibrium of the non-cooperative game for competitive resource procurements. Performance evaluation on Nash equilibrium reveals insightful observations for both theoretical analysis and practical cloud resource procurements scheme design.	best-effort delivery;cloud computing;multiplexing;nash equilibrium;performance evaluation	Xin Jin;Yu-Kwong Kwok;Yong Yan	2013	2013 IEEE 5th International Conference on Cloud Computing Technology and Science	10.1109/CloudCom.2013.92	pricing;games;game theory;simulation;procurement;cloud computing;resource allocation;nash equilibrium	Metrics	-23.383846344616387	65.1398033352365	104159
2ab32a2624dff43a0e5cb87e96f4d1011fc12fd3	soft caching: web cache management techniques for images	cache storage;visual databases internet cache storage storage management;image resolution;storage management;visual communication;proxy caching;web cache management techniques;soft caching;telecommunication traffic;network servers;internet traffic;internet;resolution level;explosives;system testing;bandwidth;resolution level soft caching web cache management techniques internet traffic web browsing proxy caching;web server;web browsing;web caching;internet web server network servers image resolution visual communication telecommunication traffic bandwidth system testing explosives delay;visual databases	The vast majority of current Internet traffic is generated by web browsing applications. Proxy caching, which allows some of the most popular web objects to be cached at intermediate nodes within the network, has been shown to provide substantial performance improvements. In this paper we argue that image-specific caching strategies are desirable and will result in improved performance over approaches treating all objects alike. We propose that Soft Caching, where an image can be cached at one of a set of levels of resolutions, can benefit the overall performance when combined with cache management strategies that estimate, for each object, both the bandwidth to the server where the object is stored and the appropriate resolution level demanded by the user. We formalize the cache management problem under these conditions and describe an experimental system to test these techniques. INTRODUCTION AND MOTIVATION The explosive growth in Internet traffic has made it critical to look for ways of accommodating the increasing number of users while preventing excessive delays, congestion and widespread blackouts. Increased transmission capacity and more sophisticated pricing will help in the long run relieve current bottlenecks but an immediate goal in both research and commercial environments has been to define methods which can provide a more efficient utilization of existing resources. For the past several years a large proportion of Internet traffic has been generated by web-browsing. This has led to a great deal of effort being devoted to studying web caching techniques [l]. Consider the basic interaction in web browsing, where a client requests an object2 that is stored at a server host. While caching is useful both at the server (for example some pages might be kept in RAM memory) and the client (where recently accessed files are saved to disk), we concentrate here on proxy based caching. In this environment clients can designate a host to serve as a proxy for all or some of their requests (e.g., http, ftp, etc). The proxy acts as 'Martin Vetterli is also with Department of EECS, University of California, Berkeley, 'In the web context an object is a file (text, image, audio, executable) which is available CA 94720, USA to be downloaded by a client. 0-7803-3780-8/97/$10.00 0 1 997 IEEE 475 a cache by temporarily storing on local disks, or memory, objects which were requested by the clients. When one of the clients sharing the proxy generates a request, the proxy searches its local storage for the requested object. If the object is available locally (hit) it is sent to the client, otherwise (miss) the request is passed on to the remote server (or to another proxy server, if the proxy cache belongs to a hierarchy of caches.) Obviously caching will improve the overall performance of the system as long as the hit ratio, i.e. the ratio of locally available information to total volume of requests, is sufficiently high. However, unlike traditional low level caching, as used in most current computer architectures, a relatively low hit ratio suffices to make using a web caching system worthwhile. This is true because the overhead of a miss (getting the object from the remote server) can be very high compared to the speed of a local search and transfer and thus the savings on a few hits are sufficient to make up for the overhead needed for searching the cache storage first. The potential benefits of caching have sparked commercial and research interest. Several companies offer a proxy server among their products [a, 31 while government-funded projects have resulted in a freely available cache implementation [4, 11. Web caching can be divided into two main classes, namely, push, where the server places information in the network caches [5], and pull, where proxies operate independently of the servers and store information as a function of clients requests. In this work we concentrate on pull-based environments, which are also the most popular in terms of implementation and research interest [a, 3, 41. There are several aspects which clearly differentiate web caching from traditional caching environments. For example the above mentioned low hit ratio requirement, but also the fact that computation and memory at the proxy come relatively cheap and thus sophisticated cache management strategies are possible, including algorithms with different approaches for each class of objects. Another significant difference is that the bandwidths to the various servers are different (and indeed can change over time) and thus the cost of a miss does not depend on the size of the object alone. The goal of this paper is to motivate that increased levels of performance can be achieved with web caching strategies specifically geared towards images.	algorithm;bsd;bandwidth (signal processing);bottleneck (software);cpu cache;cache (computing);computation;computer architecture;computer science;executable;experimental system;hit (internet);hypertext transfer protocol;ibm 2780/3780;internet;local search (optimization);network congestion;overhead (computing);proxy server;random-access memory;server (computing);web cache;web navigation;web storage	Antonio Ortega;Fabio Carignano;Serge Ayer;Martin Vetterli	1997		10.1109/MMSP.1997.602680	the internet;explosive material;internet traffic;image resolution;cache stampede;cache;computer science;cache invalidation;database;smart cache;internet privacy;system testing;world wide web;bandwidth;web server;visual communication	Web+IR	-20.695501711303667	70.91998507530937	104256
6a6dbfa00a7d1a5de6945b94e25efc7081f98dc4	fcms: a fuzzy controller for cpu and memory consolidation under sla constraints	server consolidation;fuzzy control;resource management;virtualized cloud applications;feedback control;cloud computing	SummaryrnCloud providers (CPs) rely on server consolidation (the allocation of several virtual machines [VMs] on the same physical server) to minimize their costs. Maximizing the consolidation level is thus become 1 of the major goals of cloud providers. This is a challenging task because it requires the ability of estimating, in a resource contention scenario, multidimensional resource demands for multitier cloud applications that must meet service-level agreements (SLAs) in face of nonstationary workloads. In this paper, we cope with the problem of jointly allocating CPU and memory capacity to (a) precisely estimate their capacity required by each VM to meet its SLAs and (b) coordinate their allocation to limit the negative effects due to the interactions of dynamic allocation mechanisms, which, if ignored, can lead to SLA violations. We tackle this problem by devising FCMS, a feedback fuzzy controller that is able to dynamically adjust the CPU and memory capacity allocated to each VM in a coordinated way, to precisely match the needs induced by the incoming workload. By means of an extensive experimental evaluation, we show that FCMS is able to achieve the above goals and works better than existing state-of-the-art alternative solution in all the considered experimental scenarios.	apache cassandra;central processing unit;cloud computing;fuzzy control system;image scaling;interaction;multitier architecture;redis;resource contention;scalability;semiconductor consolidation;service-level agreement;stationary process;testbed	Cosimo Anglano;Massimo Canonico;Marco Guazzone	2017	Concurrency and Computation: Practice and Experience	10.1002/cpe.3968	embedded system;real-time computing;cloud computing;computer science;resource management;operating system;feedback	DB	-23.064879791411812	61.42811183124979	104405
2068f481cff3080f4b2e36af764abcd5daf73b64	enforcing truthful-rating equilibria in electronic marketplaces	theoretical model;social welfare;distributed computing;consumer electronics peer to peer computing feedback informatics games distributed computing conferences;consumer electronics;electronic marketplace;feedback;games;initial condition;informatics;peer to peer computing;service provision;lower bound;conferences	Reputation-based mechanisms and policies are vulnerable to the submission of untruthful ratings. In this paper, we define and analyze a game-theoretic model that captures the dynamics and the rational incentives in a competitive e-marketplace in which providers and clients exchange roles. We also study how we can enforce equilibria where ratings are submitted truthfully. We employ a mechanism prescribing that each service provision is rated by both the provider and the client, while this rating is included in the calculation of reputation only in case of agreement. First, we analyze the case where fixed monetary penalties are induced to both raters in case of disagreement. We prove that, under certain assumptions on the initial conditions, the system is led to a stable equilibrium where all participants report truthfully their ratings. We also investigate the introduction of non-fixed penalties to provide the right incentives for truthful reporting. We derive lower bounds on such penalties that depend on the participant’s reputation values. Thus, by employing a punishment that is tailored properly for each participant, this approach can limit the unavoidable social welfare losses due to the penalties for disagreement.	e-commerce;game theory;initial condition	Thanasis G. Papaioannou;George D. Stamoulis	2006	26th IEEE International Conference on Distributed Computing Systems Workshops (ICDCSW'06)	10.1109/ICDCSW.2006.45	games;simulation;telecommunications;computer science;social welfare;feedback;database;distributed computing;upper and lower bounds;informatics;computer security;initial value problem;computer network	ECom	-28.360474323082215	73.10294877059188	104503
180c200409040885509bd97063e96052cf890c7d	an intelligent power consumption model for virtual machines under cpu-intensive workload in cloud environment		Cloud computing has gained enormous popularity by providing high availability and scalability as well as on-demand services. However, with the continuous rise of energy consumption cost, the virtualized environment of cloud data centers poses a challenge to today’s power monitoring system. Software-based power monitoring is gaining prevalence since power models can work precisely by exploiting soft computing methodologies like genetic programming and swarm intelligence for model optimization. However, traditional power models barely consider virtualization and have drawbacks like high error rate, low feasibility as well as insufficient scalability. In this paper, we first analyze the power signatures of virtual machines in different configurations through experiments. Then we propose a virtual machine (VM) power model, named CAM,which is able to adapt to the reconfiguration of VMs and provide accurate power estimating under CPU-intensive workload. We also propose two training methodologies corresponding to two typical situations for model training. CAM can estimate the power of a single VM as well as a physical server hosting several heterogeneous VMs. We exploited public Linux benchmarks to evaluateCAM.The experimental results show Communicated by V. Loia. W. Wu and W. Lin contributed equally to this work. B Weiwei Lin linww@scut.edu.cn Wentai Wu cswuwt@mail.scut.edu.cn 1 School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China 2 College of Computer and Electronic Information, Guangdong University of Petrochemical Technology, Maoming, China that CAMproduced very small errors in power estimating for both VMs (4.26% on average) and the host server (0.88% on average).	algorithm;antivirus software;central processing unit;cloud computing;cloudsim;computer science;data center;data deduplication;emoticon;encryption;experiment;genetic programming;high availability;input/output;linux;local interconnect network;mathematical optimization;openvms;real-time clock;scalability;scheduling (computing);server (computing);simulation;soft computing;swarm intelligence;virtual machine;word lists by frequency	Wentai Wu;Weiwei Lin;Zhiping Peng	2017	Soft Comput.	10.1007/s00500-016-2154-6	scalability;workload;computer science;virtualization;energy consumption;high availability;cloud computing;real-time computing;virtual machine;soft computing	HPC	-20.015521703190203	61.35780237398674	104693
b3f1e14c4f748d3b84cc7b219047b7848bdff527	multicuckoo: multi-cloud service composition using a cuckoo-inspired algorithm for the internet of things applications		Internet of things (IoT) applications aim to provide access to widespread interconnected networks of smart devices, services, and information. This can be achieved by integrating IoT and cloud computing (CC). By using cloud computing service composition (SC), multiple services from various providers can be combined to meet users’ requirements. However, SC is known for its complexity and is classified as an NP-hard problem; such problems are usually approached using heuristics, such as bio-inspired algorithms. This paper aims at developing a bio-inspired algorithm that mimics the behavior of cuckoo birds (which examine the nests of other birds to find eggs similar to their own) to find a composite service that fulfills a user’s request in a multi-cloud environment (MCE). Previous work on cuckoo-inspired algorithms has generally utilized metaheuristics, which try to fit a “good” solution to a general optimization problem. In contrast, we propose a problem-dependent heuristic that considers the SC problem and its particularities in MCE. The proposed algorithm, MultiCuckoo, was thoroughly evaluated based on a well-controlled experimental framework that benchmarks the performance of the new algorithm to other outstanding SC algorithms, including the all clouds combination algorithm, base cloud combination algorithm, and combinatorial optimization algorithm for multiple cloud service Composition. The results show that our algorithm is more efficient in terms of decreasing the number of examined services, the composed clouds, and the running time in comparison to the benchmark algorithms.	algorithm;benchmark (computing);british informatics olympiad;cloud computing;combinatorial optimization;heuristic (computer science);internet of things;linuxmce;mathematical optimization;metaheuristic;np-hardness;optimization problem;requirement;service composability principle;service-oriented modeling;smart device;time complexity;tinymce	Heba A. Kurdi;Juan José Parra Jordán;Lina Altoaimy;Syed Hassan Ahmed;Kamal Youcef-Toumi	2018	IEEE Access	10.1109/ACCESS.2018.2872744	combinatorial optimization;distributed computing;web service;quality of service;algorithm;heuristics;computer science;cloud computing;metaheuristic;optimization problem;benchmark (computing)	HPC	-19.570531858225554	64.6855425857696	104862
0a4d917a7c7ce6ee3433c8a2aecfb18e3b624705	optimizing distributed execution of ws-bpel processes in heterogeneous computing environments	heterogeneous computing	Workflow-structured Web service composition is an emerging computing paradigm for constructing next-generation large-scale distributed applications within and across organizational boundaries. Mapping such application workflows in heterogeneous environments and optimizing their performance in terms of quick response and high scalability are vital to the success of these distributed applications. Workflows with complex execution semantics and dependencies are typically modeled as directed acyclic graphs. We construct cost models to estimate data processing and transfer overheads and formulate the restricted workflow mapping for minimum total execution time as an NP-complete optimization problem. We propose a heuristic approach to this problem that recursively computes and maps the critical path to network nodes using a dynamic programming-based procedure. The performance superiority of the proposed approach is illustrated by an extensive set of simulations and further verified by experimental results from a real network in comparison with existing methods.	algorithm;business process execution language;critical path method;directed acyclic graph;distributed computing;dynamic programming;heterogeneous computing;heuristic;map;mathematical model;mathematical optimization;np-completeness;optimization problem;optimizing compiler;performance prediction;programming language;programming paradigm;real-time clock;real-time computing;recursion;run time (program lifecycle phase);scalability;service composability principle;simulation;state (computer science);stateless protocol;testbed;web service	Chase Qishi Wu;Yi Gu;Liang Bao;Wei Jia;Huichen Dai;Ping Chen	2009		10.1007/978-3-642-10625-5_49	parallel computing;utility computing;grid computing;autonomic computing	HPC	-20.065979710206367	64.85216577384011	105003
5c5be6d1cc75af2f355be0263e9075eaf874c002	quantifying cloud performance and dependability: taxonomy, metric design, and emerging challenges		In only a decade, cloud computing has emerged from a pursuit for a service-driven information and communication technology (ICT), becoming a significant fraction of the ICT market. Responding to the growth of the market, many alternative cloud services and their underlying systems are currently vying for the attention of cloud users and providers. To make informed choices between competing cloud service providers, permit the cost-benefit analysis of cloud-based systems, and enable system DevOps to evaluate and tune the performance of these complex ecosystems, appropriate performance metrics, benchmarks, tools, and methodologies are necessary. This requires re-examining old system properties and considering new system properties, possibly leading to the re-design of classic benchmarking metrics such as expressing performance as throughput and latency (response time). In this work, we address these requirements by focusing on four system properties: (i) elasticity of the cloud service, to accommodate large variations in the amount of service requested, (ii) performance isolation between the tenants of shared cloud systems and resulting performance variability, (iii) availability of cloud services and systems, and (iv) the operational risk of running a production system in a cloud environment. Focusing on key metrics for each of these properties, we review the state-of-the-art, then select or propose new metrics together with measurement approaches. We see the presented metrics as a foundation toward upcoming, future industry-standard cloud benchmarks.	cloud computing;dependability;devops;ecosystem;elasticity (cloud computing);evolutionary taxonomy;heart rate variability;production system (computer science);requirement;response time (technology);throughput	Nikolas Roman Herbst;André Bauer;Samuel Kounev;Giorgos Oikonomou;Erwin Van Eyk;George Kousiouris;Athanasia Evangelinou;Rouven Krebs;Tim Brecht;Cristina L. Abad;Alexandru Iosup	2018	TOMPECS	10.1145/3236332	data science;throughput;temporal isolation among virtual machines;devops;benchmarking;cloud computing;response time;distributed computing;computer science;information and communications technology;dependability	Metrics	-21.907300722183777	60.82899899547827	105703
b923c062eea5acb5443acb783a818b0588706e5b	fuzzy logic based energy aware vm consolidation		Global need of computing is growing day by day and as a result cloud based services are getting more prominent for its pay-as-you-go modality. However, cloud based datacenters consume considerable amount of energy which draws negative attention. To sustain the growth of cloud computing, energy consumption is now a major concern for cloud based datacenters. To overcome this problem, cloud computing algorithm should be efficient enough to keep energy consumption low and at the same time provide desired QoS. Virtual machine consolidation is one such technique to ensure energy-QoS balance. In this research, we explored Fuzzy logic and heuristic based virtual machine consolidation approach to achieve energy-QoS balance. Fuzzy VM selection method has been proposed to select VM from an overloaded host. Additionally, we incorporated migration control in Fuzzy VM selection method. We have used CloudSim toolkit to simulate our experiment and evaluate the performance of the proposed algorithm on real-world work load traces of PlanetLab VMs. Simulation results demonstrate that the proposed method provides best performance in all performance metrics while consuming least energy.	fuzzy logic;semiconductor consolidation	Mohammad Alaul Haque Monil;Rashedur M. Rahman	2015		10.1007/978-3-319-23237-9_4	embedded system;real-time computing;simulation;engineering	EDA	-21.37483933748716	62.33141323601873	105773
3c39ed28512e2c3343099dbdeead3aa8a502ca7e	local optimization of global objectives: competitive distributed deadlock resolution and resource allocation	distributed server client architectures;network throughput;performance guarantee;communication networks;independent set;resource allocation;distributed processing;resource management;distributed computing;system recovery contracts resource management computer architecture computer network management communication networks distributed computing bandwidth computer science admission control;client server systems;contracts;route selection;local optimization;maximum fractional independent set;computer architecture;system recovery;globally optimum performance;global objectives;community networks;competitive distributed deadlock resolution;scheduling;computer network management;bandwidth management;bandwidth;computer science;communication networking;client server systems resource allocation telecommunication networks scheduling distributed processing;distributed bandwidth management;job scheduling;telecommunication networks;minimum fractional coloring local optimization global objectives competitive distributed deadlock resolution resource allocation distributed server client architectures distributed bandwidth management communication networks distributed computing communication networking globally optimum performance maximum fractional independent set admission control network throughput job scheduling;admission control;minimum fractional coloring	"""The work is motivated by deadlock resolution and resource allocation problems, occurring in distributed server-client architectures. We consider a very general setting which includes, as special cases, distributed band-width management in communication networks, as well as variations of classical problems in distributed computing and communication networking such as deadlock resolution and \dining philosophers"""". In the current paper, we exhibit rst local solutions with globally-optimum performance guarantees. An application of our method is distributed bandwidth management in communication networks. In this setting, deadlock resolution (and maximum fractional independent set) corresponds to admission control maximizing network throughput. Job scheduling (and minimum fractional coloring) corresponds to route selection that minimizes load."""	bandwidth management;deadlock;distributed computing;fractional coloring;graph coloring;independent set (graph theory);job scheduler;job shop scheduling;local search (optimization);program optimization;scheduling (computing);server (computing);telecommunications network;throughput	Baruch Awerbuch;Yossi Azar	1994		10.1109/SFCS.1994.365690	bandwidth management;throughput;real-time computing;independent set;resource allocation;computer science;local search;resource management;job scheduler;deadlock;concurrency control;distributed computing;edge chasing;scheduling;deadlock prevention algorithms;bandwidth;computer network	Theory	-20.252307109190816	66.57767187035537	105966
ee66ad9c2bf7b3fe5c5f1b083f1e785bbca2d1b6	learning-based data envelopment analysis for external cloud resource allocation	cloud computing;resource allocation;data envelopment analysis;q-learning	A mature cloud system needs a complete resource allocation policy which includes internal and external allocation. They not only enable users to have better experiences, but also allows the cloud provider to cut costs. In the other words, internal and external allocation are indispensable since a combination of them is only a total solution for whole cloud system. In this paper, we clearly explain the difference between internal allocation (IA) and external allocation (EA) as well as defining the explicit IA and EA problem for the follow up research. Althoughmany researchers have proposed resource allocation methods, they are just based on subjective observations which lead to an imbalance of the overall cloud architecture, and cloud computing resources to operate sequentially. In order to avoid an imbalanced situation, in previous work, we proposed Data Envelopment Analysis (DEA) to solve this problem; it considers all of a user’s demands to evaluate the overall cloud parameters. However, although DEA can provide a higher quality solution, it requires more time. So we use the Q-learning and Data Envelopment Analysis (DEA) to solve the imbalance problem and reduce computing time. As our simulation results show, the proposed DEA+Qlearning will provide almost best quality but too much calculating time.	cloud computing;computation;data center;data envelopment analysis;input/output;q-learning;separable polynomial;simulation;time complexity	Hsin-Hung Cho;Chin-Feng Lai;Timothy K. Shih;Han-Chieh Chao	2016	MONET	10.1007/s11036-016-0728-2	simulation;operations research	HPC	-22.420971796755484	64.82579634415153	106447
95dee811b8c49d54ed2bb438c83865d707d50263	automated fine-grained cpu provisioning for virtual machines	virtualization;performance management;resource allocation;cloud computing	Ideally, the pay-as-you-go model of Infrastructure as a Service (IaaS) clouds should enable users to rent just enough resources (e.g., CPU or memory bandwidth) to fulfill their service level objectives (SLOs). Achieving this goal is hard on current IaaS offers, which require users to explicitly specify the amount of resources to reserve; this requirement is nontrivial for users, because estimating the amount of resources needed to attain application-level SLOs is often complex, especially when resources are virtualized and the service provider colocates virtual machines (VMs) on host nodes. For this reason, users who deploy VMs subject to SLOs are usually prone to overprovisioning resources, thus resulting in inflated business costs.  This article tackles this issue with AutoPro: a runtime system that enhances IaaS clouds with automated and fine-grained resource provisioning based on performance SLOs. Our main contribution with AutoPro is filling the gap between application-level performance SLOs and allocation of a contended resource, without requiring explicit reservations from users. In this article, we focus on CPU bandwidth allocation to throughput-driven, compute-intensive multithreaded applications colocated on a multicore processor; we show that a theoretically sound, yet simple, control strategy can enable automated fine-grained allocation of this contended resource, without the need for offline profiling. Additionally, AutoPro helps service providers optimize infrastructure utilization by provisioning idle resources to best-effort workloads, so as to maximize node-level utilization.  Our extensive experimental evaluation confirms that AutoPro is able to automatically determine and enforce allocations to meet performance SLOs while maximizing node-level utilization by supporting batch workloads on a best-effort basis.	best-effort delivery;central processing unit;cloud computing;colocation centre;control theory;memory bandwidth;multi-core processor;online and offline;provisioning;runtime system;service-level agreement;thread (computing);throughput;virtual machine	Davide B. Bartolini;Filippo Sironi;Donatella Sciuto;Marco D. Santambrogio	2014	TACO	10.1145/2637480	performance management;parallel computing;real-time computing;virtualization;cloud computing;resource allocation;computer science;operating system;distributed computing	OS	-22.36402928496659	60.74824035224954	106901
4da004ffe4c491cee5562d74c5b83701c201030d	addressing the stranded power problem in datacenters using storage workload characterization	stranded power;storage characterization;workload characterization;power efficiency;datacenter power provisioning;power allocation	Datacenter operators face unique challenges to optimally provision power among deployed servers. Allocated server power is frequently over-provisioned and this results in stranding of available datacenter power capacity. Standardized power efficiency benchmarks like SPECpower_ssj2008 can be used for determining power allocation, in conjunction with methodologies to estimate the contribution from the disk subsystem. In this paper, we explore a trace-driven methodology for determining power contribution of the storage components. We show the benefits of this methodology as opposed to typical power provisioning used in the industry.	data center;performance per watt;provisioning;specpower;server (computing)	Sriram Sankar;Kushagra Vaid	2010		10.1145/1712605.1712639	embedded system;real-time computing;simulation;electrical efficiency;engineering;operating system	Arch	-21.403680586830543	61.20792212217033	107285
0961a85461a471ba34fc2e5e9cd6c4098e1e6bfe	on data staging strategies for mobile accesses to cloud services	optimal solution;cache storage;mobile access;resource constraint;complexity theory;measurement;time complexity;design and development;information retrieval;efficient algorithm;service oriented architecture cache storage cloud computing computational complexity information retrieval mobile computing;nickel;cloud;resource constraints cloud data staging and caching mobile access;dynamic program;optimization problem;computational complexity;heuristic algorithms;network model;mobile communication complexity theory heuristic algorithms algorithm design and analysis measurement schedules nickel;mobile communication;schedules;communication cost;simulation study;time complexity data staging strategy mobile access cloud service time efficient algorithm vantage location communication bandwidth storage resource homogeneous cost model network model caching cost communication cost;service oriented architecture;mobile computing;data staging and caching;algorithm design;algorithm design and analysis;cost model;heuristic algorithm;resource constraints;cloud computing;mobile user	In this paper, we design and develop time-efficient algorithms that identify vantage locations to stage a shared data item for the ease of mobile accesses. As mobile users will be charged on the use of communication bandwidth as well as on the fraction of the time the storage resources are kept busy on their respective data, we aim to provide such access for a class of mobile users using Cloud services with minimum total cost. To this end, we adopt a homogeneous cost model and network model used in [1], and consider this problem under a practical restriction that the maximum number of instant copies is bounded by a given constant k. We first study this optimal problem without constraints and then investigate the constrained version by limiting the relationship between the communication cost C and caching (storage) cost S of a copy of the requested data and point out the limitation of this method. For arbitrary C and S, we propose three heuristic algorithms to this problem. All the proposed algorithms are built upon the optimal solution (using dynamic programming (DP)) without constraints on the number of copies, but leverage different strategies to respect the constraint while minimizing the cost. We shown that they have the same time complexity but exhibit different actual performance in different situations. We validate our findings via extensive simulation studies.	algorithm;analysis of algorithms;cloud computing;data item;disk staging;dynamic programming;heuristic;internet printing protocol;network model;pp (complexity);platform as a service;shortest path problem;simulation;time complexity;veritas cluster server	Yang Wang;Bharadwaj Veeravalli;Chen-Khong Tham	2011	2011 Fourth IEEE International Conference on Utility and Cloud Computing	10.1109/UCC.2011.40	algorithm design;real-time computing;cloud computing;computer science;theoretical computer science;operating system;distributed computing;mobile computing	DB	-20.140715552989178	67.34838522088137	107456
be085f7aa9d087a4e432273a5e7acdf985248d1d	cloud scheduling optimization: a reactive model to enable dynamic deployment of virtual machines instantiations	virtual machine scheduling;virtual machine dynamic deployment;virtual machine migration;cloud computing	This study proposes a model for supporting the decision making process of the cloud policy for the deployment of virtual machines in cloud environments. We explore two configurations, the static case in which virtual machines are generated according to the cloud orchestration, and the dynamic case in which virtual machines are reactively adapted according to the job submissions, using migration, for optimizing performance time metrics. We integrate both solutions in the same simulator for measuring the performance of various combinations of virtual machines, jobs and hosts in terms of the average execution and total simulation time. We conclude that the dynamic configuration is prosperus as it offers optimized job execution performance.	cloud computing;cloudsim;elasticity (cloud computing);intercloud;interoperability;job stream;meta-scheduling;openvms;quality of service;run time (program lifecycle phase);scheduling (computing);simulation;software deployment;system time;testbed;universal instantiation;virtual machine;z/vm	Nik Bessis;Stelios Sotiriadis;Fatos Xhafa;Eleana Asimakopoulou	2013	Informatica, Lith. Acad. Sci.		real-time computing;temporal isolation among virtual machines;cloud computing;computer science;virtual machine;operating system;distributed computing;virtual finite-state machine	HPC	-22.771806537662638	61.91962370676072	107542
83510978860fd69f3c5bd5a5448ff3f249fc167e	a grid accounting model based on event-trigged mechanism and user behavior	user modelling;trigger mechanism;accounting model;event trigged mechanism;pricing;computer model;computational modeling delay effects pricing monitoring resource management couplings cloud computing;resource manager;resource management;accounting;delay effects;computational modeling;user modelling accounting delays grid computing;monitoring;average time delay reduction grid accounting model event trigged mechanism user behavior grid computing cloud computing accounting service quality accounting log files accounting information collection tight coupling relationship;grid accounting;user behavior;event trigged;couplings;grid computing;delays;cloud computing;grid accounting grid computing event trigged mechanism user behavior	Accounting system is one of the building blocks in the grid computing and cloud computing environments. Despite its growing significance, the quality of accounting service suffers from several problems, including the tight coupling relationship between the accounting methods and the accounting log files, slow updates, and ignorance on the impact of user behavior. To address the above problem, an accounting model based on event-trigged mechanism and user behavior was designed. The event-trigged mechanism was used to collect the accounting information. This method relieves the tight coupling relationship between the accounting methods and the log files, thus improves the speed and efficiency of collecting the accounting information. The model also introduces an accounting policy based on users' behavior. In this policy, the user behavior is evaluated, and the user's weight factor is computed, consequently, the user could get reward or punishment accordingly. The experimental results show that the proposed accounting model reduces the average time delay of collecting the accounting information, differentiates incentives according to user behavior, and improves the quality of accounting services.		Xu Zhao;Taiqiang Lv;Yiduo Mei;Lingping Zeng;Xiaoshe Dong	2011		10.1109/ChinaGrid.2011.26	real-time computing;simulation;throughput accounting;computer science;accounting method;distributed computing	ECom	-23.892584013621903	63.87694157589267	107584
57d0d645ec289bf5595959abbc605ed2e42c30fc	qknober: a knob-based fairness-efficiency scheduler for cloud computing with qos guarantees		Fairness and efficiency are generally two important metrics for users in modern cloud computing. Due to the heterogeneous resource demands of CPU and memory for users’ tasks, it cannot achieve the strict 100% fairness and the maximum efficiency at the same time. Quantitatively showing the fairness degradation/loss becomes essentially important in the design of any fairness-efficiency tradeoff scheduler. Existing fairness-efficiency schedulers (e.g., Tetris) can balance such a tradeoff elastically by relaxing fairness constraint for improved efficiency using the knob. However, their approaches are insensitive to the fairness degradation under different knobs, which makes several drawbacks. First, it cannot quantitatively tell how much relaxed fairness can be guaranteed (i.e., QoS of fairness guarantee) given a knob value. Second, it fails to meet several essential properties such as sharing incentive. To address these issues, we propose a new fairness-efficiency scheduler, QKnober, to balance the fairness and efficiency elastically and flexibly using a tunable fairness knob. QKnober is a fairness-sensitive scheduler that can maximize the system efficiency while guaranteeing the (theta )-soft fairness by modeling the whole allocation as a combination of fairness-purpose allocation and efficiency-purpose allocation. Moreover, QKnober satisfies fairness properties of sharing incentive, envy-freeness and pareto efficiency given a proper knob. We have implemented QKnober in YARN and evaluated it using real experiments. The results show that QKnober can achieve good performance and fairness.	cloud computing;control knob;fairness measure;quality of service;scheduling (computing)	Shanjiang Tang;Ce Yu;Chao Sun;Jian Xiao;Yinglong Li	2018		10.1007/978-3-030-03596-9_60	real-time computing;quality of service;pareto efficiency;computer science;cloud computing;incentive	Theory	-21.277073838901785	60.866627378192916	107630
3f8691e008f3b9db579633109901ed9fa2c6f8be	modeling the location selection of mirror servers in content delivery networks	k center;profile correlation;cdn isp collaboration	For a provider of a Content Delivery Network (CDN), the location selection of mirror servers is a complex optimization problem. Generally, the objective is to place the nodes centralized such that all customers have convenient access to the service according to their demands. It is an instance of the k-center problem, which is proven to be NP-hard. Determining reasonable server locations directly influences run time effects and future service costs. We model, simulate, and optimize the properties of a content delivery network. Specifically, considering the server locations in a network infrastructure with prioritized customers and weighted connections. A simulation model for the servers is necessary to analyze the caching behavior in accordance to the targeted customer requests. We analyze the problem and compare different optimization strategies. For our simulation, we employ various realistic scenarios and evaluate several performance indicators. Our new optimization approach shows a significant improvement. The presented results are generally applicable to other domains with k-center problems, e.g., the placement of military bases, the planning and placement of facility locations, or data mining.	centralized computing;content delivery network;data mining;digital distribution;disk mirroring;facility location problem;mathematical optimization;metric k-center;np-hardness;optimization problem;run time (program lifecycle phase);server (computing);simulation	Peter Hillmann;Tobias Uhlig;Gabi Dreo Rodosek;Oliver Rose	2016	2016 IEEE International Congress on Big Data (BigData Congress)	10.1109/BigDataCongress.2016.68	real-time computing;simulation;engineering;world wide web	Metrics	-22.22175200128079	63.98126951069642	108199
500bd3bf3f0ebbd4d043e3014e8c794867bda60f	maximizing system reachability for p2p-based interactive spatial audio applications in networked virtual environments	p2p;network capacity;peer to peer streaming;decomposition algorithm;load balancing;many to many interaction;peer to peer streaming spatial audio many to many interaction load balancing;load balance;peer to peer computing;peer to peer;networked virtual environment;spatial audio;peer to peer computing educational institutions	We are interested to provide interactive spatial audio services for networked virtual environments (NVEs) in a peer-to-peer manner. The objective is to maximize the system reachability via efficiently utilizing the network capacities of users. We first propose a helper decomposition algorithm to construct an abstraction layer which consists of helpers formed by participating users. Each user selects a set of helpers that forward the audio streams on behalf of the user. We prove that the system reachability is Schur-concave on the loads of non-occupied helpers. We then propose a game-theoretic algorithm, termed water-fitting, to maximize the system reachability by rapidly balancing the loads of non-occupied helpers. The simulation results show that the proposed algorithms can achieve a near-optimal system reachability with respect to churn, avatar mobility and unpredictable speaking activity.	abstraction layer;algorithm;concave function;game theory;peer-to-peer;reachability;schur-convex function;simulation;surround sound;virtual reality	Ke Liang;Roger Zimmermann	2011	2011 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2011.6012020	real-time computing;computer science;load balancing;distributed computing;dead peer detection;world wide web	Robotics	-23.426520058392665	74.00311771478184	108699
7477e0f0c6e0d9c8b09669a0e3530b3b525784e3	an analytical model for estimating cloud resources of elastic services	elasticity;resource management;performance modeling and analysis;auto scaling;capacity engineering;cloud computing	In the cloud, ensuring proper elasticity for hosted applications and services is a challenging problem and far from being solved. To achieve proper elasticity, the minimal number of cloud resources that are needed to satisfy a particular service level objective (SLO) requirement has to be determined. In this paper, we present an analytical model based on Markov chains to predict the number of cloud instances or virtual machines (VMs) needed to satisfy a given SLO performance requirement such as response time, throughput, or request loss probability. For the estimation of these SLO performance metrics, our analytical model takes the offered workload, the number of VM instances as an input, and the capacity of each VM instance. The correctness of the model has been verified using discrete-event simulation. Our model has also been validated using experimental measurements conducted on the Amazon Web Services cloud platform.	amazon web services;cloud computing;correctness (computer science);data center;elasticity (cloud computing);elasticity (data store);heart rate variability;interrupt latency;location-based service;markov chain;quantum fluctuation;response time (technology);simulation;streaming media;testbed;throughput;virtual machine;web service	Khaled Salah;Khalid Elbadawi;Raouf Boutaba	2015	Journal of Network and Systems Management	10.1007/s10922-015-9352-x	real-time computing;simulation;cloud computing;computer science;resource management;elasticity;computer security	Metrics	-23.876521975070972	62.68859995736031	108881
42b01e57ade5c3b9108ff4e5fa76e062ec7eceb6	integrating load balancing into channelization strategy in publish/subscribe	control systems;publish subscribe channelization strategy routing messages subscription management load balancing mechanism channel based approach pub sub system balancing control initiation algorithm event brokers load scheduling algorithm channel splitting system loads;application software;routing;resource allocation;bismuth;routing messages;conference management;load scheduling algorithm;balancing control initiation algorithm;pub sub system;channel based approach;load balancing mechanism;scheduling middleware resource allocation;scheduling algorithm;optical propagation;channelization strategy;scheduling;publish subscribe;load management;event brokers;load balancing;merging;pub sub;subscriptions;middleware;load balance;subscription management;balance control;load balancing pub sub channel based routing;channel based routing;load management routing subscriptions costs scheduling algorithm radiofrequency identification optical propagation application software conference management control systems;radiofrequency identification;system loads;channel splitting	In Pub/Sub systems, channel-based approaches to routing the subscriptions and events have many advantages such as fewer routing messages, lower costs for subscription management, etc. But a potential issue embedded in this kind of approach, i.e. loadings on different event brokers are apt to unbalancing, is ignored more or less. In this paper, we design a load balancing mechanism and integrate it into a channel-based approach in a Pub/Sub system. In particular, we define a balancing state in a Pub/Sub system, and then propose the balancing control initiation algorithm which decides not only whether to perform load balancing among event brokers but also whether to adjust the number of event brokers. Also we present the load scheduling algorithm which can achieve load balancing by channel splitting, merging and migration. We conduct the experiments by taking loads with different distributions as input to reveal the capability of dealing with changing loads. The experimental data prove that our mechanism can help balance the system loads efficiently and dynamically start or shut down event brokers when facing overloads or insufficient loads.	algorithm;channelization (telecommunications);computation;embedded system;experiment;load balancing (computing);routing;scheduling (computing)	Haibiao Chen;Beihong Jin;Fengliang Qi	2010	2010 24th IEEE International Conference on Advanced Information Networking and Applications	10.1109/AINA.2010.43	real-time computing;computer science;control system;load balancing;operating system;database;distributed computing;publish–subscribe pattern;scheduling;computer network	DB	-21.219668048944406	69.57461176652792	109158
7a5e244d5b7f2f3720023c38c131b0a8b9845150	when is it convenient to predict the web services completion time?	service requestor;service instance;realistic web service scenario;web services completion time;service convenience value;web service scenario;service requesters;bind logical operation;different service;web service;convenient instance	When multiple distributed instances of the same Web service exist, a great challenge is represented by allowing the service requesters to select the most convenient instances at execution time. In the Web service scenario, the requesters represent the critical decision making point about what service instance to use. For this reason they need information to estimate the behavior of different services to perform an aware selection, instead of a random one. This work formally defines the select logical operation as a new step of the bind logical operation. Then it contributes to the comprehension of the conditions under which is convenient, for a service requestor, to spend a little time using prediction mechanisms for collecting service convenience values. Moreover we propose some simulation results obtained modelling a realistic Web service scenario.	web service;world wide web	Edgardo Ambrosi;Marco Bianchi;Giovanni Felici	2006				HCI	-25.303412158083226	62.91286208517425	110125
b3d9409be3e4097fc46799c6581aeea394db7dd4	real-time multi-cloud management needs application awareness	cloud management;performance models;layered queueing;optimization	Current cloud management systems have limited awareness of the user application, and application managers have no awareness of the state of the cloud. For applications with strong real-time requirements, distributed across new multi-cloud environments, this lack of awareness hampers response-time assurance, efficient deployment and rapid adaptation to changing workloads. This paper considers what forms this awareness may take, how it can be exploited in managing the applications and the clouds, and how it can influence cloud architecture.	cloud management;real-time clock;real-time transcription;requirement;software deployment	John W. Chinneck;Marin Litoiu;C. Murray Woodside	2014		10.1145/2568088.2576763	simulation;engineering;knowledge management;management science	OS	-26.652740965490587	61.09848410056322	110279
baad2032861ab2c3aded9e63c41563204f7ef340	a biomorphic model for automated cloud adaptation	cloud comptuing;chemicals;biomorphic model;stem cells;general timer distribution biomorphic model automated cloud adaptation bio inspired cloud computing biomorphic model adaptive cloud behaviour cellular differentiation blank server web server cloud deployment system biological process automated cloud scaling signal detection node activation;cloud;biological system modeling;cloud computing chemicals biological system modeling servers adaptation models stem cells computational modeling;master thesis;computing;biomorphic;bio;servers;scaling;computational modeling;inspired;web scaling;adaptation models;nature inspired computing;web scaling biomorphic model cloud comptuing nature inspired computing;signal detection cloud computing;cloud computing	Although there is an extensive amount of research covering in the area of Cloud computing, the field of bioinspired cloud computing is underinvestigated when compared to the general research area. This study tries to find answers on how a biomorphic model can be implemented in the cloud in order to achieve adaptive cloud behaviour. The process of cellular differentiation where cells transform from one type to another, is chosen to be the foundation model for a developed technical model. We define analogies to the cloud where stem cells are blank servers and web servers are cells with a specific function. With a combination of configuration management, version control and cloud deployment systems, an imitation of this biological process is applied in the cloud. The use of automated cloud scaling as a case of adaptive behaviour is the main goal of the research. One approach has been developed for mapping the biological model to the cloud which consists of a prototype where the signal detection and node activation is being triggered by using the concept of random generated timers. The obtained performance results were varying, depending on the general timer distribution, providing new ideas for future improvements and different algorithm proposals.	adaptive behavior;adaptive system;algorithm;cloud computing;configuration management;detection theory;image scaling;prototype;software deployment;timer;version control;web server	Gyorgi Stoykov;Anis Yazidi	2015	2015 IEEE/ACM 8th International Conference on Utility and Cloud Computing (UCC)	10.1109/UCC.2015.34	simulation;cloud computing;computer science;theoretical computer science;operating system;cloud testing;distributed computing	HPC	-25.6805108022701	62.239524792314946	110524
0ff6238781274a64b618a8fa3e91fda7810e57dd	a new reformulation of the load balancing problem in cloud computing based on tsp and aco		In the space of a few years, cloud computing has experienced remarkable growth. Indeed, its economic model based on demand of hardware and software according to technical criteria (CPU utilization, memory, bandwidth...) or package has strongly contributed to the liberalization of computing resources in the world. However, the development of cloud computing requires the optimization of performance of the different services offered by cloud providers in order to ensure a high level of security, availability and responsiveness. One major aspect for dealing with performance issues in cloud computing is the load balancing. In fact, an efficient load balancing contributes to the decrease of costs and maximizes availability of resources. In this paper, we present a new reformulation of the load balancing problem based on the traveling salesman problem, and for an optimized solution we suggest Ant Colony Optimization algorithm.	algorithm;ant colony optimization algorithms;central processing unit;cloud computing;high-level programming language;load balancing (computing);mathematical optimization;optimization problem;responsiveness;travelling salesman problem	Chouaib Moussaddaq;Abdellah Ezzati;Rachid Elharti	2017		10.1145/3090354.3090409	ant colony optimization algorithms;cpu time;utility computing;travelling salesman problem;cloud computing;software;computer science;economic model;load balancing (computing);distributed computing	HPC	-20.07853389623987	63.43072177574711	110982
44ee65c188b929306067059ead43bb994fbebd23	minimizing response latency via efficient virtual machine placement in cloud systems	stochastic requests;cloud systems;virtual machine placement;m m 1 queueing system	As more and more applications migrate into clouds, the placement of virtual machines for these applications has much impact on the performance of cloud systems. A number of virtual machine (VM) placement techniques have been proposed over recent years. However, most of the existing works on VM placement ignore the response latency of the requests from tenants. In this paper, we investigate the techniques of VM placement with stochastic requests from the tenants to minimize the total (average) response latency. We first model the requests for each application from the corresponding tenant as independent Poisson stream. Moreover, the VMs are modeled as simple M/M/1 queueing systems. Then, we define the problem of VM placement for minimizing the total response delay (VMMD) and show it is NP-hard. We propose three heuristic algorithms, namely, Greedy, Local Adjustment (LA) and Simulated Annealing (SA). We conduct abundant simulation experiments to evaluate the performance of our proposed algorithms. The simulation results show that the proposed algorithms are efficient in decreasing the total response latency of the requests from tenants. Especially, the SA heuristic, which decreases the total response latency about 68% at most, shows the best performance on minimizing the total response latency in cloud systems.	experiment;greedy algorithm;heuristic;np-hardness;simulated annealing;simulation;virtual machine	Hou Deng;Liusheng Huang;Chenkai Yang;Hongli Xu;Bing Leng	2015	2015 IEEE 34th International Performance Computing and Communications Conference (IPCCC)	10.1109/PCCC.2015.7410297	parallel computing;real-time computing;computer science;operating system;distributed computing;computer network	HPC	-19.752676318810384	62.727642998449085	111040
36b1578844dfd4e31efab57259d5e22636b0470c	towards an intrusion detection system for battery exhaustion attacks on mobile computing devices	intrusion detection batteries mobile computing pervasive computing dna computing computer crime energy consumption cancer bluetooth memory management;memory management;cancer;pervasive computing;linear regression model;mobile computer;linear regression model intrusion detection system battery exhaustion attacks mobile computing devices denial of service attack power consumption;computer crime;intrusion detection;regression analysis mobile computing security of data;energy use;denial of service attack;energy consumption;batteries;regression analysis;mobile computing devices;dna computing;bluetooth;power consumption;mobile computing;security of data;battery exhaustion attacks;intrusion detection system	Mobile computers are subject to a unique form of denial of service attack known as a battery exhaustion attack, in which an attacker attempts to rapidly drain the battery of the device. In this paper we present our first steps in the design of an intrusion detection system for these attacks, a system that takes into account the performance, energy, and memory constraints of mobile computing devices. This intrusion detection system uses several parameters, such as CPU load and disk accesses, to estimate the power consumption using a linear regression model, allowing us to find the energy used on a per process basis, and thus identifying processes that are potentially battery exhaustion attacks.	central processing unit;computer;denial-of-service attack;intrusion detection system;mobile computing	Daniel C. Nash;Thomas L. Martin;Dong S. Ha;Michael S. Hsiao	2005	Third IEEE International Conference on Pervasive Computing and Communications Workshops	10.1109/PERCOMW.2005.86	intrusion detection system;embedded system;host-based intrusion detection system;computer science;operating system;mobile computing;computer security;computer network	Mobile	-29.91074703205579	67.61615225739354	111055
7747f0c4081527fdead83df071d56b609090e997	large scale cloudlets deployment for efficient mobile cloud computing	deployment;mobile cloud computing;network performance;wireless communication;cloudlet	Interest in using Mobile Cloud Computing (MCC) for compute intensive mobile devices jobs such as multimedia applications has been growing. In fact, many new research efforts were invested to maximize the mobile intensive jobs offloading to the cloud within the cloud system coverage area. However, a large scale MCC deployment challenges and limitations are not considered. In this paper, a large scale Cloudlet-based MCC system deployment is introduced, aiming at reducing the power consumption and the network delay of multimedia applications while using MCC. The proposed deployment offers a large coverage area that can be used by mobile devices while they are moving from one location to another to reduce broadband communication needs. Practical experimental results and simulated results using show that using the proposed model reduces the power consumption of the mobile devices as well as reducing the communication latency when the mobile device requests a job to be performed remotely while satisfying the high quality of service requirements of mobile users.	cloudlet;display resolution;mobile cloud computing;mobile device;non-functional requirement;software deployment;system deployment	Lo'ai Ali Tawalbeh;Yaser Jararweh;Fadi Ababneh;Fahd Dosari	2015	JNW	10.4304/jnw.10.01.70-76	embedded system;real-time computing;mobile search;computer science;operating system;mobile technology;distributed computing;network performance;mobile computing;software deployment;computer security;wireless;computer network	Mobile	-24.27193624736444	67.35614616493748	111474
e9c8ebabe7ce40c87e5459eca6d394d1af2fa19c	workload modelling of stateful protocols using hmms		There are several techniques for generating a workload consisting of a series of operations presented to a target device. Each has advantages and drawbacks when evaluated in terms of accuracy with respect to the real workload being modeled and computational or storage resources required to generate it. For workloads corresponding to “stateful” protocols, some techniques cannot be applied, as they fail to capture important ordering relationships between operations or fail to avoid generating an illegal sequence of operations as dictated by the protocol. This paper describes a new workload modeling and generation technique using Hidden Markov Models. The technique provides an accurate model of a workload while minimizing the resources required during simulated workload generation as well as conforming to stateful protocol sequencing restrictions. The application of the technique as applied to modeling CIFS network filesystem protocol workloads is presented, along with preliminary experimental results validating its effectiveness.	clustered file system;computation;hidden markov model;markov chain;server message block;state (computer science);stateless protocol	Swami Ramany;R. J. Honicky;Darren Sawyer	2005			real-time computing;workload;stateful firewall;hidden markov model;computer science	Embedded	-32.85597565205705	64.10511371326734	111829
1ffc8c9e3096e6be818b5ead1647e5d150c82436	a graph-based approach for automatic service activation and deactivation on the osgi platform	graph theory;resource utilization;resource utilization efficiency;osgi platform;service activator graph based approach automatic service activation automatic service deactivation software management platform osgi platform resource utilization efficiency;graph based osgi resource constrained device eager resource allocation service activation;performance evaluation;resource constrained device;resource allocation;software management;graph based approach;resource manager;resource management;eager resource allocation;data mining;runtime;home network;automatic service deactivation;monitoring;resource allocation graph theory mobile computing;service activator;heuristic algorithms;graph based;resource management home appliances middleware embedded software home automation prototypes surveillance performance evaluation consumer electronics computer architecture;service activation;osgi;software management platform;mobile computing;automatic service activation;embedded device;automation	More and more mobile and embedded devices, such as home appliances and network devices, have selected OSGi as the software management platform. As a result, the resource management of the OSGi platform has become a critical issue. This paper focuses on how to enhance the efficiency of resource utilization in terms of the service activation and deactivation. We propose the service activator (SA), which is designed as an OSGi bundle, to on-demand activate and deactivate OSGi services, so that the resources required by services can be allocated and deallocated automatically. This involves a graph-based representation of services dependencies and two new algorithms. We have implemented the SA on an OSGi implementation (Knopflerfish); a home network prototype with a home surveillance scenario is presented to demonstrate the feasibility. Furthermore, a simulator is developed to further evaluate the SA in terms of several scenarios; the results show that the SA performs well for a wide range of bundles, and the processing overhead is low.	algorithm;central processing unit;component-based software engineering;embedded system;experiment;garbage collection (computer science);graph (discrete mathematics);memory management;mobile device;osgi;overhead (computing);programming paradigm;prototype;simulation;software project management	Chin-Yang Lin;Cheng-Liang Lin;Ting-Wei Hou	2009	IEEE Transactions on Consumer Electronics	10.1109/TCE.2009.5277987	embedded system;in situ resource utilization;real-time computing;resource allocation;computer science;resource management;operating system;automation;devices profile for web services	Mobile	-21.74541951717393	67.13536154458012	112627
12b08c7e32d0dcc5f1e0d4446943bb454b239141	a service-oriented architecture for electric power transmission system asset management	modeling and forecasting;asset management;growth and development;real time data;power plant;information integration;power system;high voltage;electric power;service oriented architecture	In electric power transmission systems, the assets include transmission lines, transformers, power plants and support structures. Maintaining these assets to reliably deliver electric energy at low prices is critical for a nation’s growth and development. Towards this end, we describe a novel service-oriented architecture for sensing, information integration, risk assessment, and decisionmaking tasks that arise in operating modern high-voltage electric power systems. The proposed framework integrates real-time data acquisition, modeling, and forecasting functionalities provided by relatively autonomous, loosely coupled entities that constitute the power industry to determine operational policies, maintenance schedules and facility reinforcement plans required to ensure reliable operation of power systems.	autonomous robot;data acquisition;dynamic data;emoticon;entity;ibm power systems;incremental backup;interoperability;loose coupling;performance evaluation;prototype;quality of service;real-time data;risk assessment;service-oriented architecture;service-oriented device architecture;service-oriented software engineering;software architecture;transformers;transmission line	Jyotishman Pathak;Yuan Li;Vasant Honavar;James D. McCalley	2006		10.1007/978-3-540-75492-3_3	power station;real-time data;real-time computing;simulation;electric power;computer science;high voltage;information integration;service-oriented architecture;electric power system	Embedded	-28.698409249926776	61.50033531982648	112851
9fdc5f8ad0323ccd202db6dbf335cddf25330b5c	swayam: distributed autoscaling to meet slas of machine learning inference services with resource efficiency		Developers use Machine Learning (ML) platforms to train ML models and then deploy these ML models as web services for inference (prediction). A key challenge for platform providers is to guarantee response-time Service Level Agreements (SLAs) for inference workloads while maximizing resource efficiency. Swayam is a fully distributed autoscaling framework that exploits characteristics of production ML inference workloads to deliver on the dual challenge of resource efficiency and SLA compliance. Our key contributions are (1) model-based autoscaling that takes into account SLAs and ML inference workload characteristics, (2) a distributed protocol that uses partial load information and prediction at frontends to provision new service instances, and (3) a backend self-decommissioning protocol for service instances. We evaluate Swayam on 15 popular services that were hosted on a production ML-as-a-service platform, for the following service-specific SLAs: for each service, at least 99% of requests must complete within the response-time threshold. Compared to a clairvoyant autoscaler that always satisfies the SLAs (i.e., even if there is a burst in the request rates), Swayam decreases resource utilization by up to 27%, while meeting the service-specific SLAs over 96% of the time during a three hour window. Microsoft Azure's Swayam-based framework was deployed in 2016 and has hosted over 100,000 services.	autoscaling;machine learning;microsoft azure;service-level agreement;web service	Arpan Gujarati;Sameh Elnikety;Yuxiong He;Kathryn S. McKinley;Björn B. Brandenburg	2017		10.1145/3135974.3135993	workload;web service;resource efficiency;machine learning;exploit;inference;autoscaling;service level;computer science;artificial intelligence	OS	-24.013456899578646	62.043845770800225	112936
5474108e9817df053f81fa2ee3e6720f0f2b8480	an improved estimation of distribution algorithm for cloud computing resource scheduling		This paper focuses on cloud computing resource scheduling on the Soft as a Service layer and aims at minimizing the user costs by regarding the deadline as a constraint for scheduling independent tasks. Existing works with evolutionary computation approaches fail to describe the interactions among independent tasks. To overcome this problem, an improved Markov-chain-based estimation of distribution algorithm is proposed, and the concept of virtual machine selection diversity is created to construct the probabilistic model rationally. Moreover, one heuristic rule related to the investigated problem is created to keep the population maintaining a high diversity in the evolution process. The experiment results show that the proposed algorithm not only obtains the best solution quality but also has competitive convergence among all compared algorithms.	cloud computing;estimation of distribution algorithm;evolutionary computation;heuristic;interaction;marginal model;markov chain;scheduling (computing);service layer;software as a service;statistical model;virtual machine	Haisheng Sun;Chuang Liu;Huaping Chen;Rui Xu	2018	2018 Tenth International Conference on Advanced Computational Intelligence (ICACI)	10.1109/ICACI.2018.8377508	evolutionary computation;mathematical optimization;estimation of distribution algorithm;cloud computing;service layer;scheduling (computing);virtual machine;heuristic;population	AI	-19.650526899690288	64.81175057086048	113336
d6834fd2eb4a74c81ecf637041cfe1c13b005ead	efficient solar provisioning for net-zero internet-scale distributed networks		Internet-scale Distributed Networks (IDNs) are global distributed systems consisting of a network of hundreds of thousands of servers located in hundreds of data centers around the world. A Content Delivery Network (CDN) is an example of an IDN that delivers content globally through a large network of servers. IDNs consume large amounts of energy and their energy requirements are projected to increase significantly in the future. With carbon emissions from data centers increasing every year, energy solutions for data centers powered by renewables are critical for the sustainability of data centers and for the environment. In this paper, we study the benefits of using solar energy to green IDNs. We study the impact of leveraging global data center locations with high solar potential on the number of solar panels needed to power a CDN. We develop optimal algorithms and heuristics to help minimize the number of solar panels provisioned across the CDN, while making it net-zero. We empirically evaluate our algorithms using extensive load traces from Akamai's global CDN and solar data from PVWatts. Overall, with unrestricted load movement, we can reduce the number of solar panels by 36%, 68%, and 82% for net-zero year, month and week respectively. Our results show that our algorithms can significantly reduce the number of solar panels we need to power our CDN, thereby making sustainability of Internet-scale distributed networks more achievable.	air cooling;algorithm;computer cooling;content delivery network;data center;distributed computing;heuristic (computer science);internationalized domain name;internet;power usage effectiveness;powera;provisioning;requirement;top500;tracing (software)	Vani Gupta;Prashant J. Shenoy;Ramesh K. Sitaraman	2018	2018 10th International Conference on Communication Systems & Networks (COMSNETS)	10.1109/COMSNETS.2018.8328221	content delivery network;renewable energy;computer network;the internet;energy consumption;provisioning;computer science;data center;solar energy;server	HPC	-21.41190162182357	62.773932378206695	113414
3ffe13ea0b08910ee099a2f971e76fa41bda5657	a fine-grained flow control model for cloud-assisted data broadcasting	cloud assisted data broadcasting;fair queue;fine grained flow control;user end devices;impact energy;impact power;proportional integral derivative pid controller;time division multiplexing;quality of service;energy metric;heterogeneous network	Cloud-assisted data broadcasting is an emerging application where cloud computing assists data broadcasting to extend the capacity of system computing and improve the interactivity of the conventional media. However, with the increase in scale, it brings the difficulty on the complexity to provide the sufficient quality of service for diverse receivers. In order to obtain a fine-grained flow rate as well as the system stability, we propose a model based on parallel scheduling, fair queue and Proportional-Integral-Derivative (PID) controller to cope with these challenges. PID controller takes advantage of the feedback of the statistical output stream and automatically adjusts the transmission flow so that the system can achieve the fine-grained multiplexing performance. Meanwhile, we adopt a set of novel metrics to monitor and measure the quality of flow control in order to weaken the negative impact of coarse-grained flow to user-end devices to the minimum level. Extensive simulations and evaluations have illustrated the superiority of the proposed model in the performance and the quality of service in terms of proposed measurement metrics. Author	algorithm;cloud computing;control theory;datacasting;flow control (data);interactivity;load (computing);multiplexing;pid;quality of service;scheduling (computing);simulation	Ning Yu;Feng Gu;Xuan Guo;Zaobo He	2015			real-time computing;simulation;computer science;distributed computing	Networks	-21.468004800249673	60.96626746783271	113459
6333872723e44a07c64dcc9f2af6668bbaa94302	stackelberg game based incentive mechanisms for multiple collaborative tasks in mobile crowdsourcing	incentive mechanism;mobile croudsourcing;stackelberg game;multiple collaborative tasks	In this paper, we tackle the problem of stimulating users to join mobile crowdsourcing applications with personal devices such as smartphones and tablets. Wireless personal networks facilitate to exploit the communication opportunity and makes diverse spare-resource of personal devices utilized. However, it is a challenge to motivate sufficient users to provide their resource of personal devices for achieving good quality of service. To address this problem, we propose an incentive framework based on Stackelberg game to model the interaction between the server and users. Traditional incentive mechanisms are applied for either single task or multiple dependent tasks, which fails to consider the interrelation among various tasks. In this paper, we focus on the common realistic scenario with multiple collaborative tasks, where each task requires a group of users to perform collaboratively. Specifically, participants would consider task priority and the server would design suitable reward functions to allocate the total payment. Considering the information of users' costs and the types of tasks, four incentive mechanisms are presented for various cases to the above problem, which are proved to have the Nash equilibrium solutions in all cases for maximizing the utility of the server. Moreover, online incentive mechanisms are further proposed for real time tasks. Through both rigid theoretical analysis and extensive simulations, we demonstrate that the proposed mechanisms have good performance and high computational efficiency in real world applications.	crowdsourcing	Shuyun Luo;Yongmei Sun;Yuefeng Ji;Dong Zhao	2016	MONET	10.1007/s11036-015-0659-3	simulation;computer science;distributed computing;stackelberg competition;computer security	HCI	-23.564710595237415	74.43551362616272	113499
f85a33463409977083a34b455cf1afb9e493db52	service scheduling in cloud computing based on queuing game model	queue game;optimal queue length;service scheduling;cloud computing	Cloud Computing allows application providers seamlessly scaling their services and enables users scaling their usage according to their needs. In this paper, using queuing game model, we present service scheduling schemes which are used in software as a service (SaaS). The object is maximizing the Cloud Computing platform’s (CCP’s) payoff via controlling the service requests whether to join or balk, and controlling the value of CCP’s admission fee. Firstly, we treat the CCP as one virtual machine (VM) and analyze the optimal queue length with a fixed admission fee distribution. If the position number of a new service request is bigger than the optimal queue length, it balks. Otherwise, it joins in. Under this scheme, the CCP’s payoff can be maximized. Secondly, we extend this achievement to the multiple VMs situation. A big difference between single VM and multiple VMs is that the latter one needs to decide which VM the service requests turn to for service. We use a corresponding algorithm solve it. Simulation results demonstrate the good performance of our schemes.	cloud computing	Fuhong Lin;Xianwei Zhou;Daochao Huang;Wei Song;Dongsheng Han	2014	TIIS	10.3837/tiis.2014.05.003	embedded system;real-time computing;cloud computing;computer science;operating system;distributed computing;computer security;computer network	HPC	-22.330845229448375	64.24886696899989	113551
4d16337cc0431cd43043dfef839ce5f0717c3483	a scalable and privacy-aware iot service for live video analytics		We present OpenFace, our new open-source face recognition system that approaches state-of-the-art accuracy. Integrating OpenFace with inter-frame tracking, we build RTFace, a mechanism for denaturing video streams that selectively blurs faces according to specified policies at full frame rates. This enables privacy management for live video analytics while providing a secure approach for handling retrospective policy exceptions. Finally, we present a scalable, privacy-aware architecture for large camera networks using RTFace.	facial recognition system;open-source software;privacy;scalability;streaming media;video content analysis	Junjue Wang;Brandon Amos;Anupam Das;Padmanabhan Pillai;Norman M. Sadeh;Mahadev Satyanarayanan	2017		10.1145/3083187.3083192	streams;facial recognition system;computer science;computer network;scalability;cloud computing;frame rate;architecture;edge computing;analytics	Networks	-31.917258063138988	62.99280859216891	114149
fc597d6f3bd8ccfaac2dcb1ae2e7c6d4c6df9890	cloud based virtualization for a calorie measurement e-health mobile application	intelligent decision mechanism;androids;cloud servers cloud based virtualization calorie measurement e health mobile application smart phones health fitness complex mobile applications computational power storage capacity eat healthy stay healthy computational intensive algorithms deep learning food image recognition cloud resources virtual swap mobile sessions intelligent decision mechanism task distribution image processing;virtualisation cloud computing image recognition learning artificial intelligence medical information systems mobile computing smart phones;time measurement;mobile cloud computing;mobil e saglik uygulamasi;intelligent decision mechanism in cloud cloud based virtualization model mobile e health application virtual swap mobile cloud computing;androids humanoid robots time measurement servers;mobil bulut bilisim;virtual swap;servers;humanoid robots;mobile e health application;akilli karar mekanizmasi;intelligent decision mechanism in cloud;cloud based virtualization model;article	Smartphones have transformed people approach towards technology. It not only empowers them to use it for communication but also for tracking and maintaining health-fitness via mobile applications. With the increasing number of complex mobile applications, the mobile, with its limited resources (in terms of the computational power and storage capacity) cannot efficiently run these applications autonomously. Similarly our e-health mobile application (Eat Healthy Stay Healthy) requires a platform to run highly computational intensive algorithms like the deep learning (for recognizing food images) and calorie measurement would need higher processing power to perform optimally. We propose a cloud based virtualization model that provides our e-health application with the required computational power that it needs to perform efficiently and at the same time would also give it the flexibility to make use of the various cloud resources. Our model comprises of concepts like virtual swap between various mobile sessions that assist the system for faster processing and intelligent decision mechanism for distributing the task of image processing to cloud servers. By implementing intelligent decision mechanism, the final calorie computation significantly improved by 20.5% while implementing deep learning in cloud.	algorithm;computation;deep learning;image processing;mobile app;paging;smartphone	Sri Vijay Bharat Peddi;Abdulsalam Yassine;Shervin Shirmohammadi	2015	2015 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)	10.1109/ICMEW.2015.7169853	embedded system;real-time computing;simulation;computer science;humanoid robot;operating system;server;time	Mobile	-23.586379806839954	67.15022344590045	114189
f05f2dbde810b26f2f08e22b9c7ed945d1787ca9	dynamic fractional resource scheduling for cluster platforms	resource scheduling;virtual machine;virtual machine technology;cluster computing;memory management;measurement;cluster platforms;processor scheduling;virtual machining;resource management;homogeneous computational clusters;dynamic fractional resource scheduling;simulation experiment;thesis;homogeneous cluster computing platforms;virtual machines;scheduling;heuristic algorithms;dynamic scheduling processor scheduling resource management virtual machining space technology runtime costs supercomputers investments measurement;resource sharing;node resources;user centred design;user centric performance metric;workstation clusters;offline setting;online setting;job scheduling;dfrs;workstation clusters scheduling user centred design virtual machines;dynamic scheduling;online setting dynamic fractional resource scheduling cluster platforms dfrs homogeneous cluster computing platforms virtual machine technology node resources user centric performance metric resource sharing offline setting	We propose a novel approach, called Dynamic Fractional Resource Scheduling (DFRS), to share homogeneous cluster computing platforms among competing jobs. DFRS leverages virtual machine technology to share node resources in a precise and controlled manner. A key feature of this approach is that it defines and optimizes a user-centric metric of performance and fairness. We explain the principles behind DFRS and its advantages over the current state of the art, develop a model of resource sharing, and summarize results from two different simulation experiments: one comparing various heuristics in an off-line setting and another comparing our heuristics to current technology in an on-line setting. Finally, we summarize our conclusions and describe our plans for future research.	computer cluster;experiment;fairness measure;heuristic (computer science);online and offline;simulation;virtual machine	Mark Stillwell	2010	2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)	10.1109/IPDPSW.2010.5470799	real-time computing;computer science;operating system;distributed computing	Arch	-19.443549713045098	61.1934051817412	114251
3ba0cb77b2cf9bd183768223301a59528a24905d	hybrid power control and electricity cost management for distributed internet data centers in cloud computing	minimisation;minimization;nonlinear programming;power aware computing cloud computing computer centres minimisation nonlinear programming;computer centres;power aware computing;servers;electricity servers power demand minimization optimization electricity supply industry heuristic algorithms;heuristic algorithms;power management;electricity cost minimization;electricity;optimization;electricity supply industry;power demand;internet data centers;power management internet data centers cloud computing electricity cost minimization;electricity cost reduction hybrid power control electricity cost management distributed internet data centers cloud computing internet services internet data centers idc energy consumption mass power consumption cloud providers electricity cost minimization problem electricity prices time diversities location diversities operation cost saving server level power control scheme power consumption reduction total cost minimization nonlinear optimization problem heuristic algorithm design;cloud computing	Along with the increasing Internet services and cloud computing in recent years, more and more data and computation are migrated to or hosted on the Internet data centers (IDCs). Meanwhile, the energy consumed by IDCs has been skyrocketing. Such mass power consumption has brought extremely heavy burden on cloud providers. While most of the previous work focuses on reducing energy consumption, this paper addresses the electricity cost minimization problem. Since the electricity prices exhibit time and location diversities in many countries, we can take the advantage of these diversities to save on operation cost. Further, we exploit server-level power control scheme to effective reduce the power consumption. We formulate the total cost minimization as a non-linear optimization problem. Then we design a heuristic algorithm to efficiently solve the problem. Extensive evaluations show that our algorithm can obviously reduce the electricity cost.	algorithm;cloud computing;computation;data center;experiment;game-maker;heuristic (computer science);linear programming;mathematical optimization;nonlinear programming;nonlinear system;optimization problem;power management;server (computing);web service	Hui Dou;Yong Qi;Peijian Wang	2013	2013 10th Web Information System and Application Conference	10.1109/WISA.2013.81	real-time computing;simulation;operations management;business	HPC	-20.68199661557967	63.21825263493451	114306
69a3686c470fa2b5e990d5f88f9bf994e38dbaab	business-driven long-term capacity planning for saas applications	capacity planning cloud computing software as a service;capacity planning;measurement;profitability cloud computing;contracts;capacity planning cloud computing measurement contracts quality of service planning;electronic commerce business driven long term capacity planning saas applications software as a service information technology departments computing service quality of service levels cloud computing context iaas providers infrastructure as a service business driven heuristics synthetic e commerce workloads;planning;software as a service;quality of service;cloud computing	Capacity Planning is one of the activities developed by Information Technology departments over the years, it aims at estimating the amount of resources needed to offer a computing service. This activity contributes to achieving high Quality of Service levels and also to pursuing better economic results for companies. In the Cloud Computing context, one plausible scenario is to have Software-as-a-Service (SaaS) providers that build their IT infrastructure acquiring resources from Infrastructure-as-a-Service (IaaS) providers. SaaS providers can reduce operational costs and complexity by buying instances from a reservation market, but then need to predict the number of instances needed in the long-term. This work investigates how important is the capacity planning in this context and how simple business-driven heuristics for long-term capacity planning impact on the profit achieved by SaaS providers. Simulation experiments were performed using synthetic e-commerce workloads. Our analysis show that proposed heuristics increase SaaS provider profit, on average, at 9.6501 percent per year. Analysing such results we demonstrate that capacity planning is still an important activity, contributing to the increase of SaaS providers profit. Besides, a good capacity planning may also avoid bad reputation due to unacceptable performance, which is a gain very hard to measure.	baseline (configuration management);cloud computing;e-commerce;experiment;failure;heuristic (computer science);quality of service;simulation;software as a service;synthetic intelligence	David Candeia;Ricardo Araújo Santos;Raquel Vigolvino Lopes	2015	IEEE Transactions on Cloud Computing	10.1109/TCC.2015.2424877	service provider;planning;quality of service;cloud computing;computer science;knowledge management;operating system;software as a service;measurement	HPC	-23.795130759975397	64.31950485738274	114598
da5abbd6d848a5e137e8f0b0564d92d6cc81d6ba	cloud-based data analytics framework for autonomic smart grid management	media;computer architecture;smart grids;software fault tolerance big data cloud computing data analysis electric vehicles power engineering computing smart meters smart power grids;autonomic systems;smart grids media smart meters autonomic systems electricity computer architecture cloud computing;smart meter cloud based data analytics framework autonomic smart grid management electricity generation grid power demand monitoring big data problem electric vehicle ev;electricity;smart meters;cloud computing	Global energy problems necessitate an urgent transformation of the existing electrical generation grid into a smart grid, rather than a gradual evolution. A smart grid is a real-time bi-directional communication network between end users and their utility companies which monitors power demand and manages the provisioning and transport of electricity from all generation sources. As a crucial part of this transformation, increasing numbers of smart meters generate correspondingly increasing amounts of data every day. Analyzing this data to extract insight into, and to maintain control over energy usage has become a big data problem - one which cannot be handled manually, and which requires autonomic computing solutions. In this paper, we examine electric vehicles (EVs) as a use case to investigate how to use social media, sensing data, and big data analytics to optimize smart grid management. We discuss the requirements to realize such an approach and describe an autonomic system architecture and a possible design. We believe the proposed architecture and strategy will help optimize how provisioning is performed in a smart grid, even when smart meters are not available.	autonomic computing;big data;provisioning;real-time clock;requirement;smart meter;social media;systems architecture;telecommunications network	Yu Bo Qin;Jim Housell;Ivan Rodero	2014	2014 International Conference on Cloud and Autonomic Computing	10.1109/ICCAC.2014.39	embedded system;real-time computing;engineering;smart grid;computer security;internet of things	HPC	-28.543082970132083	61.512185810401775	114742
0a016375e86744c2124eb8bff1906b266680cff1	towards energy efficient data centers: a dvfs-based request scheduling perspective	energy conservation;processor scheduling;resource allocation;servers power demand algorithm design and analysis energy consumption heuristic algorithms computer architecture optimization;computer centres;power aware computing;computational complexity;power consumption;resource allocation cloud computing computational complexity computer centres energy conservation power aware computing power consumption processor scheduling;power saving dvfs based request scheduling energy efficiency cloud computing internet services data centers energy consumption cpu frequency total energy reduction dynamic voltage and frequency scaling computing capacity servers dynamic resource allocation np hard first fit decreasing algorithm ffd algorithm;cloud computing	Energy efficiency is a critical issue for cloud computing as more and more Internet services are deployed in data centers. It is observed that the energy consumption increases significantly as the CPU frequency gets higher. To reduce the total energy, Dynamic Voltage and Frequency Scaling (DVFS) technique is proposed to make the CPUs working at proper frequencies. However, lower frequency will reduce the computing capacity of the servers, which leads to using more servers. It is a challenging problem to make a tradeoff between the number of servers and the frequency of each server for a given workload. In this paper, we prove that the problem of dynamic resource allocation based on DVFS with the target of minimizing energy consumption is NP-Hard. And we propose two algorithms based on different basic ideas to solve this problem. We also compare our algorithms to the well-known First Fit Decreasing (FFD) algorithm, and the simulation results show that we can get 12%-14% power saving on average although we use 1.2x-1.3x number of servers compared to FFD.	algorithm;central processing unit;cloud computing;data center;dynamic frequency scaling;dynamic voltage scaling;free-form deformation;heuristic;np-hardness;scheduling (computing);server (computing);simulation;web service;whole earth 'lectronic link	Weicheng Huai;Zhuzhong Qian;Xin Li;Sanglu Lu	2013	2013 Seventh International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing	10.1109/IMIS.2013.57	parallel computing;real-time computing;energy conservation;cloud computing;resource allocation;computer science;operating system;distributed computing;computational complexity theory	HPC	-19.350771743448277	62.72189741749338	114820
2852cd3b856675fc559c0524d1e19939d5cff956	budget-based control for interactive services with adaptive execution	adaptive control;response time;interactive services;scheduling algorithms;partial execution;web search;optimization;feedback control	We study the problem of managing a class of interactive services to meet a response time target while achieving high service quality. We focus here on interactive services that support adaptive execution, such as web search engines and finance servers. With adaptive execution, when a request receives more processing time, its result improves, posing new challenges and opportunities for resource management.  We propose a new budget-based control model for interactive services with adaptive execution. The budget represents the amount of resources assigned to all pending requests. The budget-based control model consists of two components: (1) a hybrid control mechanism, which combines adaptive and integral controllers and controls the budget in order to meet the response time target with small steady-state error, fast settling time and little runtime overhead, and (2) an optimization procedure, which takes advantage of adaptive execution to maximize the total response quality of all pending requests under a given budget.  We implement and evaluate the budget-based control model experimentally in Microsoft Bing, a commercial web search engine. The experimental results show that it achieves more accurate control of mean response time and higher response quality than traditional static and dynamic admission control techniques that control the queue length. We also apply the model to a finance server that estimates option prices, and conduct a simulation study. The simulation results show large benefits for budget-based control. For example, under the same response time and quality requirements, the budget-based model accommodates double the system throughput compared to a traditional queue-based control model.	e-services;experiment;mathematical optimization;overhead (computing);requirement;response time (technology);server (computing);settling time;simulation;steady state;throughput;web search engine	Yuxiong He;Zihao Ye;Qiang Fu;Sameh Elnikety	2012		10.1145/2371536.2371557	real-time computing;simulation;adaptive control;computer science;operating system;feedback;database;distributed computing;scheduling;response time;computer security;computer network	OS	-19.650741122701618	67.66271620618993	115342
3e3c8c3ff6ccfbb9d20b465d0fd9707540774035	page-based anomaly detection in large scale web clusters using adaptive mapreduce (extended abstract)	anomaly detection;real time;large scale;user behavior	While anomaly detection systems typically work on single server, most commercial web sites operate cluster environments, and user queries trigger transactions scattered through multiple servers. For this reason, anomaly detectors in a same server farm should communicate with each other to integrate their partial profile. In this paper, we describe a real-time distributed anomaly detection system that can deal with over one billion transactions per day. In our system, base on Google MapReduce algorithm, an anomaly detector in each node shares profiles of user behaviors and propagates intruder information to reduce false alarms. We evaluated our system using web log data from www.microsoft.com. The web log data, about 250GB in size, contains over one billion transactions recorded in a day.		Junsup Lee;Sung Deok Cha	2008		10.1007/978-3-540-87403-4_28	anomaly detection;real-time computing;computer science;data mining;world wide web;computer security	Theory	-32.75877559417089	62.12802975560786	115544
97ea92535b20ce388f0a1541cd0d8f66602cc93c	cosac: coordinated session-based admission control for multi-tier internet applications	web sites belief networks electronic commerce inference mechanisms internet learning artificial intelligence telecommunication computing telecommunication congestion control;databases;belief networks;three tier e commerce website;bayesian network;tpc w benchmark;electronic commerce;e commerce;telecommunication congestion control;bayesian methods;multitier measurement based admission control;telecommunication computing;inference mechanisms;probabilistic inference;coordinated session based admission control;multitier website;servers;internet;machine learning;three tier e commerce website cosac coordinated session based admission control multitier architecture internet multitier website multitier measurement based admission control mbac machine learning bayesian network probabilistic inference tpc w benchmark;cosac;measurement based admission control;admission control internet throughput application software web server computer architecture bayesian methods machine learning databases computer science;web sites;mbac;internet application;probabilistic logic;learning artificial intelligence;multitier architecture;throughput;admission control	Popular Internet applications deploy a multi-tier architecture, with each tier provisioning a certain functionality to its preceding tier. The session-based admission control approach (SBAC) designed for a single Web server is not effective for a multi-tier architecture. This is due to the fact that the bottleneck in a multi-tier website dynamically shifts among tiers as client access patterns change. Admission control based on only the bottleneck tier is not efficient as different sessions impose different resource consumptions at the different tiers. In this paper, we propose a multi-tier measurement based admission control (MBAC), which pro-actively accepts different session mixes based on the utilization state of all tiers. More significantly, we design a novel coordinated session-based admission control approach (CoSAC) based on a machine learning technique. It uses a Bayesian network to correlate the states of all tiers. The probability with which a session is admitted is determined by the probabilistic inference of the network after applying the evidence in terms of utilization and processing time at each tier to the network. We compare CoSAC with MBAC and a blackbox approach tailored from SBAC, using the industry standard TPC-W benchmark in a typical three-tier e-commerce website. Experimental results demonstrate the superior performance of CoSAC with respect to the effective session throughput.	bayesian network;benchmark (computing);e-commerce;internet;machine learning;multitier architecture;provisioning;server (computing);tpc-w;technical standard;the industry standard;throughput;web server	Sireesha Muppala;Xiaobo Zhou	2009	2009 Proceedings of 18th International Conference on Computer Communications and Networks	10.1109/ICCCN.2009.5235319	e-commerce;throughput;the internet;bayesian probability;computer science;multitier architecture;operating system;bayesian network;database;probabilistic logic;world wide web;server;computer network	DB	-24.17010752227582	63.58910001286742	115553
552f1dff8a6bdad62281650f5d0e7ccd6946abc5	energy efficient resource allocation for heterogeneous workload in cloud computing		Cloud computing is an internet based technology that provisions the resources automatically on the pay per use basis. With the development of cloud computing, the amount of customers and requirement of resources increases exponentially. In order to balance the load, the tasks must be equally distributed among multiple computing servers thereby, fulfilling Quality of Service (QoS) with maximum profit to cloud service providers. In addition, cloud servers consume huge amount of electrical energy leading to increased expenditure and environment degradation. Therefore, certain solutions are needed that results in efficient resource utilization while minimizing the environmental influence. In the paper, we present a survey of load balancing algorithms along with their limitations and propose a framework for an energy efficient resource allocation and load balancing for heterogeneous workload in cloud computing along with the validation of the framework using CloudSim toolkit.	algorithm;cloud computing;cloudsim;elegant degradation;genetic algorithm;internet;load balancing (computing);mathematical optimization;maximum throughput scheduling;quality of service;semiconductor consolidation;virtual machine	Surbhi Malik;Poonam Saini;Sudesh Rani	2016		10.1007/978-981-10-3153-3_9	workload;quality of service;real-time computing;business;cloud computing;energy consumption;cloudsim;load balancing (computing);resource allocation;server	HPC	-21.409243818649923	62.55087302939849	115698
3a6b12fd50af84f45291db5e67b11196b3fc5fa4	using dynamic configuration to manage a scalable multimedia distribution system	distributed application;distributed system;fault tolerant;distributed networks;resource manager;corba;multimedia application;qos aware resource management;large scale;multimedia distribution;middleware;distribution dynamics;mobile agent;quality of service;dynamic configuration	Multimedia applications and interfaces will change radically the way computer systems will look like in the coming years. Radio and TV broadcasting will assume a digital format and their distribution networks will be integrated to the Internet. Existing hardware and software infrastructures, however, are unable to provide all the scalability,  ̄exibility, and quality of service (QoS) that these applications require. We present a framework for building scalable and  ̄exible multimedia distribution systems that greatly improves the possibilities for the provision of quality of service in large-scale networks. We show how to use architectural-awareness, mobile agents, and a CORBA-based framework to support dynamic (re)con®guration, ef®cient code distribution, and fault-tolerance. This approach can be applied not only for multimedia distribution, but also for any QoS-sensitive distributed application. q 2001 Elsevier Science B.V. All rights reserved.	client–server model;common object request broker architecture;data rate units;distributed computing;experiment;fault tolerance;internet;interrupt;mobile agent;payload (computing);quality of service;scalability;server (computing);testbed;unicast	Fabio Kon;Roy H. Campbell;Klara Nahrstedt	2001	Computer Communications	10.1016/S0140-3664(00)00293-0	fault tolerance;real-time computing;mobile qos;quality of service;computer science;resource management;operating system;common object request broker architecture;middleware;mobile agent;distributed computing;wireless multimedia extensions;computer network	OS	-21.957445964390224	72.96675699313356	115701
30ee566b48799471cfbc260a581a1909bd933f68	sla analytics for adaptive service provisioning in the cloud	instruments;measurement;predictive elasticity management service level agreements sla analytics adaptive service provisioning instrumentation deployment cycles hybrid cloud platforms cloud service provisioning quality of service qos management qos analytics;quality of service business monitoring measurement context cloud computing instruments;monitoring;business;quality of service;telecommunication network management cloud computing contracts quality of service;context;cloud computing	Service level agreements (SLAs) are considered not only a central tool for managing QoS compliance, but also a differentiating factor between service implementations. In today's application environments with fast instrumentation deployment cycles in hybrid Cloud platforms, managing QoS compliance poses tremendous challenges, including how to deliver solutions that live up to promised QoS properties and preemptively identify provisioning risks before they lead to violations. Current approaches are usually reactive, i.e. the application infrastructure reacts to changes in QoS metrics, with a huge focus on compliance enforcement after violations have occurred. Cloud service provisioning demands a proactive approach to QoS management, with support for robust predictive scaling of service capacity based on multiple metrics, including business goals as well as infrastructure-level and QoS metrics. This paper presents an approach for adaptive service provisioning in the Cloud based on QoS analytics. A major contribution of the approach is the development of an analytics engine for predictive elasticity management of Cloud service provisioning that integrates in-depth mining of SLA compliance history with knowledge of business context, e.g. workload variability, a customer's business goals, application performance, and service operational context. In this work-in-progress report, we describe the proposed framework and discuss possible implementation and deployment scenarios.	cloud computing;elasticity (cloud computing);heart rate variability;high- and low-level;image scaling;provisioning;quality of service;service-level agreement;software deployment	Obinna Anya;Heiko Ludwig;Mohamed Mohamed;Samir Tata	2016	NOMS 2016 - 2016 IEEE/IFIP Network Operations and Management Symposium	10.1109/NOMS.2016.7502967	service level requirement;service level objective;mobile qos;quality of service;cloud computing;computer science;service delivery framework;operating system;world wide web;computer security;provisioning;measurement;computer network	Metrics	-27.485308427262257	61.190524688845315	115843
67648694785c15e800fd9af7894903b649141258	secure computation for big data	efficient secure computation;practical constraint;generic secure computation;big data;immediate practical need;secure search;massive data;massive data set;secure computation;linear computation	Secure computation has been a powerful and important research area in cryptography since the first breakthrough results in the 1980s. For many years this area was purely theoretical, as the feasibility results have not been considered even close to practical. Recently, it appears to have turned a corner, with several research efforts showing that secure computation for large classes of functions, and even generic secure computation, has the potential to become truly practical. This shift is brought on by algorithmic advancements and new cryptographic tools, alongside advancements in CPU speed, parallelism, and storage capabilities; it is further motivated by the explosion of new potential application domains for secure computation. A compelling motivation for making secure computation practical is provided by the burgeoning field of Big Data, representing the deluge of data being generated, collected, and stored all around us. Protocols for secure computation on big data can provide critical value for many business, medical, legal, and personal applications. However, conventional approaches to secure computation are inherently insufficient in this setting, where even linear computation can be too prohibitive. In this talk I discuss challenges and solutions related to secure computation for big data, following two thrusts: – Overcoming inherent theoretical bounds of (in)efficiency; and – Satisfying immediate practical needs in a theoretically sound way. Both goals require the development of new models of secure computation, allowing for theoretically and practically meaningful relaxations of the standard model. In particular, I discuss a few works I have participated in over the last decade, which address the challenge of achieving efficient secure computation for massive data. I also share some experiences from the last few years working on secure search over massive data sets. This research has externally imposed practical constraints, such as strict performance requirements. I focus on my perspective as a theoretical cryptographer and discuss some open cryptographic challenges in this emerging domain.	big data;central processing unit;cryptography;parallel computing;requirement;secure multi-party computation;turned a	Tal Malkin	2013		10.1007/978-3-642-36594-2_20	telecommunications;computer science;electrical engineering;secure two-party computation;theoretical computer science;mathematics;distributed computing;computer security;algorithm	Security	-33.471525303604885	73.18332098264389	116206
1fe422b6131dd4c5d7b38024f00da8be8ab6b09f	wide-area analytics with multiple resources		Running data-parallel jobs across geo-distributed sites has emerged as a promising direction due to the growing need for geo-distributed cluster deployment. A key difference between geo-distributed and intra-cluster jobs is the heterogeneous (and often constrained) nature of compute and network resources across the sites. We propose Tetrium, a system for multi-resource allocation in geo-distributed clusters, that jointly considers both compute and network resources for task placement and job scheduling. Tetrium significantly reduces job response time, while incorporating several other performance goals with simple control knobs. Our EC2 deployment and trace-driven simulations suggest that Tetrium improves the average job response time by up to 78% compared to existing data-locality-based solutions, and up to 55% compared to Iridium, the recently proposed geo-distributed analytics system.	computation;computer cluster;fairness measure;job scheduler;job shop scheduling;locality of reference;makespan;response time (technology);scheduling (computing);simulation;software deployment	Chien-Chun Hung;Ganesh Ananthanarayanan;Leana Golubchik;Minlan Yu;Mingyang Zhang	2018		10.1145/3190508.3190528	computer science;job scheduler;real-time computing;software deployment;distributed computing;response time;resource (disambiguation);netflow;network monitoring;analytics	OS	-20.412455017304854	61.02269751409684	116256
ac35bed8edab862fd3fbcaea644231ef0a9296d8	performance evaluation of media losses in the continuous media toolkit	prototyping environment;software metrics;high rate;user needs;electronic mail;losses;performance evaluation;user driven approach;performance loss quality of service humans testing prototypes delay aggregates computer science intelligent systems electronic mail;case studies;top down;continuous media;prototypes;user study;frames;software performance evaluation;testing;time;satisfiability;multimedia systems;time delay;performance tests;timing delays;media;media losses;timing delays performance evaluation media losses continuous media toolkit user driven approach top down approach quality of service multimedia systems case study software metrics validation user study prototyping environment experiments audio video;audio;quality;aggregates;aggregates materials;intelligent systems;experiments;video frames;top down approach;software metrics software performance evaluation multimedia systems delays;validation;humans;computer science;video;quality of service;demonstrations;performance loss;low rate;quality of service issue;continuum mechanics;drops;tool kits;delays;continuous media toolkit	This paper shows a methodology for user-driven, top down approach .to research in quality of service issues in multimedia systems. As a case study, we show a development of metrics, validation by means of a user study, and a performance evaluation of a prototyping environments. What is used, the Berkeley Continuous Media Toolkit (CMT) is a popular environment that satisfies this need. Form a human user's perspective, in order for multimedia demonstrations to be comprehensible, the number of audio or video frames dropped and the timing delays in the ones that are displayed, need to be kept to a minimum. Therefore, it is important to know the frame dropping characteristics of CMT. In a series of experiments we monitored the variation of these parameters with respect processor and network loads. It was observed that loads affect aggregate frame drops at lower rates and consecutive frame drops at higher rates. Because at a higher rates a large number of consecutive frames are dropped, the ones that are played appear in a more timely manner. As a solution to observed problems, we present some QoS based approaches to control drop and delay parameters. •This work is partially supported by Air Force contract number F30602-96-C-0130 to Honeywell Inc, via subcontract number B09030541/AF to the University of Minnesota and DOD MURI grant DAAH04-96-10341 to Cornell University Submitted to the International Workshop on Multimedia Software Engineering (MSE'98) Key Phrases: Quality of Service, User Centric QoS Research, Continuous media, Performance evaluation	aggregate data;bulldozer (microarchitecture);experiment;frame language;lossy compression;open road tolling;performance evaluation;provisioning;quality of service;scott continuity;server (computing);software engineering;software transactional memory;streaming media;testbed;top-down and bottom-up design;usability testing	Duminda Wijesekera;Srivatsan Varadarajan;Shwetal S. Parikh;Jaideep Srivastava;Anil Nerode	1998		10.1109/MMSE.1998.722944	embedded system;real-time computing;simulation;intelligent decision support system;computer science;electrical engineering;operating system;top-down and bottom-up design;multimedia	Metrics	-22.33312782119995	70.67440685409433	116609
b9c2c52955f448a52d7893b5eb8b33e8592c29dd	hope: enabling efficient service orchestration in software-defined data centers	software defined data center;power management;management workloads	"""The functional scope of today's software-defined data centers (SDDC) has expanded to such an extent that servers face a growing amount of critical background operational tasks like load monitoring, logging, migration, and duplication, etc. These ancillary operations, which we refer to as management operations, often nibble the stringent data center power envelope and exert a tremendous amount of pressure on front-end user tasks. However, existing power capping, peak shaving, and time shifting mechanisms mainly focus on managing data center power demand at the """"macro level"""" -- they do not distinguish ancillary background services from user tasks, and therefore often incur significant performance degradation and energy overhead.  In this study we explore """"micro-level"""" power management in SDDC: tuning a specific set of critical loads for the sake of overall system efficiency and performance. Specifically, we look at management operations that can often lead to resource contention and energy overhead in an IaaS SDDC. We assess the feasibility of this new power management paradigm by characterizing the resource and power impact of various management operations. We propose HOPE, a new system optimization framework for eliminating the potential efficiency bottleneck caused by the management operations in the SDDC. HOPE is implemented on a customized OpenStack cloud environment with heavily instrumented power infrastructure. We thoroughly validate HOPE models and optimization efficacy under various user workload scenarios. Our deployment experiences show that the proposed technique allows SDDC to reduce energy consumption by 19%, reduce management operation execution time by 25.4%, and in the meantime improve workload performance by 30%."""	benchmark (computing);cmos;cloud computing;cloud management;data deduplication;deployment environment;elegant degradation;frequency capping;functional testing;hope (programming language);java hotspot virtual machine;load management;mathematical optimization;nibble;orchestration (computing);overhead (computing);path integral formulation;power management;program optimization;programming paradigm;prototype;randomness;resource contention;run time (program lifecycle phase);scheduling (computing);snapshot (computer storage);software deployment;software-defined data center;tails;tracing (software);z/vm	Yang Hu;Chao Li;Longjun Liu;Tao Li	2016		10.1145/2925426.2926257	parallel computing;real-time computing;simulation;computer science;operating system;software-defined data center	HPC	-21.51995369953467	61.04871797847044	116748
daa68765074df05f54873e1dbccc063cd8f55512	network health and e-science in commercial clouds	network health;network tomography;cloud computing	This paper explores the potential for improving the performance of e-Science applications on commercial clouds through the detailed examination, and characterization, of the underlying cloud network using network tomography. Commercial cloud providers are increasingly offering high performance and GPUenabled resources that are ideal for many e-Science applications. However, the opacity of the cloud’s internal network, while a necessity for elasticity, limits the options for e-Science programmers to build efficient and high performance codes. We introduce health indicators, markers, metrics, and score as part of a network health system that provides a model for describing the overall network health of an eScience application. We then explore the suitability of a range of tomographic techniques to act as health indicators using two testbeds—the second of which spanned one hundred AWS instances. Finally, we evaluate our work using a real-world medical image reconstruction application. © 2015 Elsevier B.V. All rights reserved.	amazon web services;cloud computing;code;data-intensive computing;e-science;elasticity (cloud computing);intranet;iterative reconstruction;locality of reference;network performance;programmer;software deployment;software performance testing;spatial variability;tomography	Ryan Chard;Kris Bubendorfer;Bryan Ng	2016	Future Generation Comp. Syst.	10.1016/j.future.2015.06.001	simulation;network tomography;cloud computing;computer science;artificial intelligence;operating system;data mining;database;distributed computing;computer security	OS	-28.892790104359744	63.405847269634336	117143
72bd40d1fb314a2a6b45e4a81e382e36b312b89a	customer-satisfaction-aware optimal multiserver configuration for profit maximization in cloud computing	server speed;service request;optimisation;queueing theory cloud computing customer satisfaction optimisation pricing profitability quality of service;service provider;queuing model;pricing;probability density function;queueing theory;multiserver configuration;waiting time cloud computing multiserver system pricing model profit queuing model response time server configuration service charge service level agreement;service amount;business cost;response time;random variables;multiserver system;server configuration;service charge;customer satisfaction;optimization problem;profit;servers;m m m queuing model;application workload;computational modeling;consumer satisfaction;time factors;expected net business gain;waiting time;business;cloud computing economics;pricing model;service level agreement;service penalty;profitability;power consumption;quality of service;servers cloud computing time factors computational modeling business random variables power demand;expected net business gain multiserver configuration profit maximization cloud computing economics service provider service charge business cost pricing model service amount application workload service level agreement consumer satisfaction quality of service service penalty m m m queuing model optimization problem probability density function server speed power consumption service request;power demand;profit maximization;cloud computing	Along with the development of cloud computing, an increasing number of enterprises start to adopt cloud service, which promotes the emergence of many cloud service providers. For cloud service providers, how to configure their cloud service platforms to obtain the maximum profit becomes increasingly the focus that they pay attention to. In this paper, we take customer satisfaction into consideration to address this problem. Customer satisfaction affects the profit of cloud service providers in two ways. On one hand, the cloud configuration affects the quality of service which is an important factor affecting customer satisfaction. On the other hand, the customer satisfaction affects the request arrival rate of a cloud service provider. However, few existing works take customer satisfaction into consideration in solving profit maximization problem, or the existing works considering customer satisfaction do not give a proper formalized definition for it. Hence, we first refer to the definition of customer satisfaction in economics and develop a formula for measuring customer satisfaction in cloud computing. And then, an analysis is given in detail on how the customer satisfaction affects the profit. Lastly, taking into consideration customer satisfaction, service-level agreement, renting price, energy consumption, and so forth, a profit maximization problem is formulated and solved to get the optimal configuration such that the profit is maximized.	cloud computing;customer relationship management;emergence;entropy maximization;expectation–maximization algorithm;quality of service;queueing theory;service-level agreement	Junwei Cao;Kai Hwang;Keqin Li;Albert Y. Zomaya	2013	IEEE Transactions on Sustainable Computing	10.1109/TPDS.2012.203	service provider;pricing;random variable;optimization problem;probability density function;profit;quality of service;cloud computing;computer science;operating system;customer satisfaction;queueing theory;computational model;response time;server;statistics;profitability index;computer network	HPC	-23.22426021637268	64.05293622916831	117259
bdeef9626dcf3e6d442b7d3e9e8518143689fca8	workload factoring with the cloud: a game-theoretic perspective	outsourcing;game theory;nash equilibrium;resource allocation;price of anarchy;resource allocation cloud computing game theory network servers;resource allocation workload factoring cloud computing game theory load splitting usage pattern noncooperative game nash equilibrium price of anarchy admission control;servers;network servers;time factors;games;time factor;non cooperative game;nash equilibrium games cloud computing time factors delay servers outsourcing;cloud computing;admission control	Cloud computing is an emerging paradigm in which tasks are assigned to a combination (“cloud”) of servers and devices, accessed over a network. Typically, the cloud constitutes an additional means of computation and a user can perform workload factoring, i.e., split its load between the cloud and its other resources. Based on empirical data, we demonstrate that there is an intrinsic relation between the “benefit” that a user perceives from the cloud and the usage pattern followed by other users. This gives rise to a non-cooperative game, which we model and investigate. We show that the considered game admits a Nash equilibrium. Moreover, we show that this equilibrium is unique. We investigate the “price of anarchy” of the game and show that, while in some cases of interest the Nash equilibrium coincides with a social optimum, in other cases the gap can be arbitrarily large. We show that, somewhat counter-intuitively, exercising admission control to the cloud may deteriorate its performance. Furthermore, we demonstrate that certain (heavy) users may “scare off” other, potentially large, communities of users. Accordingly, we propose a resource allocation scheme that addresses this problem and opens the cloud to a wide range of user types.	anarchy;cloud computing;computation;game theory;integer factorization;nash equilibrium;programming paradigm;server (computing)	Amir Nahir;Ariel Orda;Danny Raz	2012	2012 Proceedings IEEE INFOCOM	10.1109/INFCOM.2012.6195654	non-cooperative game;games;game theory;simulation;cloud computing;resource allocation;computer science;distributed computing;computer security;price of anarchy;nash equilibrium;server;outsourcing	Metrics	-23.010583045524324	64.15059889458874	117542
396812f27b54893b26b807efbc11cec35694b1b8	smart-evac: big data-based decision making for emergency evacuation	emergency management analytic hierarchy process big data cloud computing decision support systems;cloud;emergency evacuation;analytic hierarchy processing;wireless communication;cloud computing big data wireless sensor networks wireless communication medical services real time systems emergency services;medical services;cloud emergency evacuation disaster risk reduction cloud computing big data analytic hierarchy processing;big data;disaster risk reduction;immediate priority based health care smart evac big data decision making emergency evacuation system natural disaster disaster risk reduction system drr system cloud computing data volume data velocity data variety analytical hierarchy process ahp cloud based basic health care facilities ambulatory medical services;wireless sensor networks;cloud computing;emergency services;real time systems	Smart-Evac manages emergency evacuation systems after a natural disaster. Unlike existing disaster risk reduction (DRR) systems, Smart-Evac takes cloud computing and big data characteristics into consideration during decision making. The authors consider human anxiety to be a major contributor to network congestion immediately following a disaster. They envision tracing clusters of trapped peoples where network usage is comparatively high. The Smart-Evac system ranks these clusters based on volume, velocity, and variety (the 3Vs of big data). Based on this ranking, the system provides immediate evacuation service to the top-listed clusters to mitigate the exponential rise of network congestion. The system used the analytical hierarchy process (AHP) to achieve the proper ranking of the clusters to support decision makers efficiently. In addition, Smart-Evac provides immediate cloud-based basic healthcare facilities and ambulatory medical services to victims after successful evacuation. Immediate priority-based healthcare in turn reduces the haphazard rush to nearby hospitals.	analytical hierarchy;big data;cloud computing;deficit round robin;network congestion;smart tv;time complexity;velocity (software development)	Soumen Moulik;Sudip Misra;Mohammad S. Obaidat	2015	IEEE Cloud Computing	10.1109/MCC.2015.47	simulation;big data;cloud computing;computer science;operating system;data mining;computer security	HPC	-22.876403128887148	68.37731020444325	118345
194cb4a731e266c1e3fa26d222aa57fa28156f42	architecture and implementation of intelligent control systems for smart consumer appliances via internet	fuzzy neural nets;fuzzy control;consumer electronics;intelligent control;smart consumer electronics intelligent control systems smart consumer appliances internet computer communication networks field programmable logic devices intelligent neuro fuzzy control systems;home automation intelligent control neurocontrollers fuzzy control fuzzy neural nets field programmable gate arrays internet consumer electronics telecontrol;control system;internet;community networks;neuro fuzzy;intelligent control computer architecture art computer networks communication networks programmable logic devices intelligent systems intelligent networks communication system control control systems;field programmable logic;telecontrol;neurocontrollers;utility computing;field programmable gate arrays;home automation	This paper outlines the architecture and state of art technology of utilizing computer communication networks and field programmable logic devices to implement intelligent neuro-fuzzy control systems for smart consumer electronics.	control system;intelligent control;internet	Fei-Yue Wang;Yuetong Lin;Qinglong Wu;Peter M. Fu;Christopher Yeo	2000		10.1109/ICSMC.2000.885059	embedded system;home automation;the internet;computer science;control system;artificial intelligence;neuro-fuzzy;utility computing;internet of things;field-programmable gate array;intelligent control	Robotics	-31.02957192558476	65.92436854588615	118650
66c754d29dbc097f172feb783be45de6c711f967	defining computational resources prices based on the expectations equilibrium of consumers and providers from a desktop grid	grid market computational resource prices desktop grid price adjustment computational resources supply and demand law economical market consumer services supplier submitted resources testing analysis service provider;market grid users expectations grid computing supply and demand;market grid users expectations;indexes resource management computational modeling supply and demand availability equations computers;supply and demand consumer behaviour customer services grid computing pricing;grid computing;supply and demand	This paper proposes a dynamic approach for price adjustment of computational resources ruled by a Desktop Grid. The adopted strategies are based on the supply and demand law commonly applied in economical markets. Thus, allows one to dynamically set the prices according to the previous requested consumer's services and supplier's submitted resources. The testing analysis results show how the equilibrium expectation from the consumer and service providers are preponderant in the processes of obtaining fairer values in their negotiations. The reached individual satisfactions established by the well succeed sharing are appraised, in order to endure it or not in the grid market based on its influences.	computation;computational resource;desktop computer;high availability;whole earth 'lectronic link	L. A. Gois;G. B. Casella;E. C. M. Ishikawa	2014	2014 28th International Conference on Advanced Information Networking and Applications Workshops	10.1109/WAINA.2014.76	computer science;supply and demand;grid computing	HPC	-23.59321606129491	64.89385957031926	118660
fa126de45c42beb55614412d52b7830a4346b909	integrating predictive analysis in self-adaptive pervasive systems. (intégration de l'analyse prédictive dans des systèmes auto-adaptatifs)		Over the last years there is increasing interest in software systems that can cope with the dynamics of ever-changing environments. Currently, systems are required to dynamically adapt themselves to new situations in order to maximize performance and availability. Pervasive systems run in complex and heterogeneous environments using resource constrained devices where arising events may compromise the quality of the system. As a result, it is desirable to count on mechanisms to adapt the system according to problematic events occurring in the running context. Recent literatures surveys have shown that dynamic adaptation is typically performed in a reactive way and therefore software systems are not able to anticipate recurrent problematic situations. In some situations, this could lead to resource waste and transient unavailability of the system. In contrast, a proactive approach does not simply act in response to the environment, but exhibit goal-directed behavior by taking the initiative in an attempt to improve the system performance or quality of service. In this thesis we advocate for a proactive approach to dynamic adaptation. The benefits of combining predictive analysis with self-adaptive approach can be summarized as follows: 1) avoiding unnecessary adaptation and oscillatory behavior 2) managing allocation of exhaustible resources, and 3) proactivity in front of seasonal behavior. Focusing on the MAPE-K architecture, in this thesis we propose to enhance dynamic adaptation by integrating a Predict activity between the Analyze and Plan activities of the MAPE-K loop. We leverage ideas and techniques from the area of predictive analysis to operationalize the Predict activity. We advocate for achieving proactive self-adaptation by integrating predictive analysis into two phases of the software process. At design time, we propose a predictive modeling process, which includes the following activities: define goals, collect data, select model structure, prepare data, build candidate predictive models, training, testing and cross-validation of the candidate models and selection of the “best” models based on a measure of model goodness. At runtime, we consume the predictions from the selected predictive models using the running system actual data. Depending on the input data and the time allowed for learning algorithms, we argue that the software system can foresee future possible input variables of the system and adapt proactively in order to accomplish middle and long term goals and requirements. The proposal has been validated with a case study from the environmental monitoring domain. Validation through simulation has been done based on real data extracted from public environmental organizations. The answers to several research questions demonstrated the feasibility of our approach to guide the proactive adaptation of pervasive systems at runtime.	algorithm;computer performance;cross-validation (statistics);machine learning;predictive modelling;proactive parallel suite;quality of service;requirement;run time (program lifecycle phase);simulation;software development process;software system;ubiquitous computing;unavailability	Ivan Dario Paez Anaya	2015				SE	-23.904181184373822	60.70916742511577	119335
bcb387dbb1fce6354b4e6f34b8ccd1d09b297b37	energy-efficient virtual machines placement	libraries;green cloud;virtual machines cloud computing computer centres evolutionary computation knapsack problems power aware computing;consumed energy reduction energy efficient virtual machines placement computer systems data centers consumption vm cloud computing environment evolutionary computation heuristic knapsack problem;virtualization;virtual machines consolidation green cloud cloud computing power efficiency;power efficiency;virtual machining;resource management;virtual machining virtualization cloud computing computational modeling resource management containers libraries;virtual machines consolidation;computational modeling;containers;cloud computing	Energy efficiency on computer systems is a topic that is gaining a lot of interest. Even more in the cloud computing era, where data centres consumption corresponds to near 1.5% of total world wide power consumption. In this paper we present two novel approaches for virtual machines (VMs) placement consolidation. The two approaches aim to maximize the placed VMs on a host and therefore minimize the number of hosts used on a cloud computing environment. The first proposed approach is based on the Knapsack problem and the second one is based on an Evolutionary Computation heuristic. Both strategies have shown consumed energy reduction starting from 40.33% and up to 92.21% compared to a strategy that does not consider energy efficiency.	ant colony optimization algorithms;best, worst and average case;cloud computing;evaluation function;evolutionary computation;genetic algorithm;heuristic;heuristic (computer science);input/output;iterated function;iteration;knapsack problem;multithreading (computer architecture);openvms;particle swarm optimization;program optimization;run time (program lifecycle phase);semiconductor consolidation;simulated annealing;simulation;tabu search;thread (computing);triplet state;virtual machine;watts humphrey	Albert P. M. De La Fuente Vigliotti;Daniel M. Batista	2014	2014 Brazilian Symposium on Computer Networks and Distributed Systems	10.1109/SBRC.2014.1	real-time computing;simulation;temporal isolation among virtual machines;cloud computing;computer science;virtual machine;cloud testing;distributed computing;utility computing	HPC	-19.2279584222644	63.36882202439285	120127
b6c6ed43fc87259f7cd82005333258accbf4ab89	a new quality chart to improve the efficiency of cloud resource management	quality chart cloudsim experiments ewma chart moving range chart violation situations early violation signal searching detecting mechanisms service efficiencies cloud resource management;cloud resource management;software quality cloud computing resource allocation;control charts monitoring process control cloud computing quality of service resource management performance analysis;service level agreement cloud resource management;service level agreement	This study attempts to upgrade the service efficiencies of cloud management by proposing different quality approaches. We design two detecting mechanisms to search the early violation signal by a different quality level of confidence. This research attempts to prevent assignable variables existed in violation situations. We proposed and verified the Moving Range Chart and EWMA Chart by utilizing CLOUDSIM experiments.	chart;cloud management;cloudsim;experiment;markov chain;sensor;service-level agreement	Chen-Fang Tsai;Shin-Li Lu;Jen-Hsiang Chen	2015	2015 IEEE 12th International Conference on e-Business Engineering	10.1109/ICEBE.2015.79	computer science;data mining;database;computer security	Robotics	-24.485879525594893	63.38994499669862	120490
89f57afa3baacc544d0c6173ac8ca6b654f91617	quac: quality-aware contract-based incentive mechanisms for crowdsensing		Crowdsensing is a sensing method which involves participants from general public to collect sensed data from their mobile devices, and also contribute and utilize a common database. To ensure a crowdsensing system to operate properly, there must be certain effective and efficient incentive mechanism to attract users and stimulate them to submit sensing data with high quality. Intuitively, the agreement on the qualities and payments in crowdsensing systems can be best modeled as a contract. However, none of existing incentive mechanisms consider data quality through effective contract design. In this paper, we design two quality-aware contract-based incentive mechanisms for crowdsensing, named QUAC-F and QUAC-I, under full information model and incomplete information model, respectively, which differ in the level of users' information known to the system. Both QUAC-F and QUAC-I are guaranteed to maximize the platform utility while satisfying individual rationality and incentive compatibility. We evaluate the performance of our designed mechanisms based on a real dataset.	amazon mechanical turk;crowdsensing;data quality;display resolution;information model;loss function;mobile device;rationality;risk aversion;the turk	Ming Li;Jian Lin;Dejun Yang;Guoliang Xue;Jian Tang	2017	2017 IEEE 14th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)	10.1109/MASS.2017.45	complete information;information model;data mining;incentive compatibility;distributed computing;rationality;incentive;computer science;data modeling;data quality;crowdsourcing	Mobile	-27.5812494949375	71.7849632103426	120880
41123700316379bbee1e68bf452f10dfdc7274fd	evaluating timeliness and accuracy trade-offs of supervised machine learning for adapting enterprise dre systems in dynamic environments	distributed system;distributed real time embedded;system dynamics;dynamic environments;supervised machine learning;dynamic environment;machine learning;adaptation;support vector machine;quality of service;empirical evaluation;distributed real time embedded systems;quantitative evaluation;artificial neural network	Several adaptation approaches have been devised to ensure end-to-end quality-of-service (QoS) for enterprise distributed systems in dynamic operating environments. Not all approaches are applicable, however, for the stringent accuracy, timeliness, and development complexity requirements of distributed real-time and embedded (DRE) systems. This paper empirically evaluates constant-time supervised machine learning techniques, such as artificial neural networks (ANNs) and support vector machines (SVMs), and presents a composite metric to support quantitative evaluation of accuracy and timeliness for these adaptation approaches.	artificial neural network;distributed computing;embedded system;end-to-end principle;machine learning;quality of service;real-time clock;requirement;supervised learning;support vector machine	Joe Hoffert;Douglas C. Schmidt;Aniruddha S. Gokhale	2011	Int. J. Comput. Intell. Syst.	10.1080/18756891.2011.9727832	support vector machine;real-time computing;quality of service;computer science;machine learning;data mining;system dynamics;artificial neural network;adaptation	Embedded	-28.04926018165969	63.02892137603221	121017
a6ee6d52a87c7e231c0e37e9c2cfb53ad314420a	how much does a vm cost? energy-proportional accounting in vm-based environments	biological system modeling;power demand servers computational modeling biological system modeling cloud computing energy consumption atmospheric modeling;servers;computational modeling;virtual machines cloud computing computer centres costing energy consumption;energy consumption;heterogeneous data centers vm cost energy proportional accounting vm based environments energy consumption air conditioning computing infrastructure networking infrastructure virtual machine pay as you go models cloud providers epave;atmospheric modeling;power demand;cloud computing	The costs of current data centers are mostly driven by their energy consumption (specifically by the air conditioning, computing and networking infrastructure). Yet, current pricing models are usually static and rarely consider the facilities' energy consumption per user. The challenge is to provide a fair and predictable model to attribute the overall energy costs per virtual machine (VM). Current pay-as-you-go models of Cloud providers allow users to easily know how much their computing will cost. However, this model is not fully transparent as to where the costs come from (e.g., energy). In this paper we introduce EPAVE, a model for Energy-Proportional Accounting in VM-based Environments. EPAVE allows transparent, reproducible and predictive cost calculation for users and for Cloud providers. We show these characteristics of EPAVE by a number of use cases in heterogeneous data centers and discuss the applicability of EPAVE.	data center;experiment;multi-user;multitenancy;power usage effectiveness;single user mode;user space;virtual machine	Mascha Kurpicz;Anne-Cécile Orgerie;Anita Sobe	2016	2016 24th Euromicro International Conference on Parallel, Distributed, and Network-Based Processing (PDP)	10.1109/PDP.2016.70	embedded system;atmospheric model;real-time computing;simulation;cloud computing;computer science;operating system;computational model;server;computer network	HPC	-22.55939676513049	61.94052171994149	121116
cf753e8b1ba34bce7e1492b87e7a1eb5573b8ca2	predictive analytics for fog computing using machine learning and geni		Fog computing is a rapidly emerging paradigm concerned with providing energy- and latency-aware solutions to users by moving computing and storage capabilities closer to end users via fog networks. A major challenge associated with such a goal is ensuring that forecasts about network quality are not only accurate but also have small operational overhead. Machine Learning is a popular approach that has been used to model network parameters of interest. However, due to the small amount of public datasets and testbeds available, designing reproducible models becomes cumbersome and more likely to under-perform during deployment. For these reasons, we seek to design an exploratory testbed for benchmarking the forecasting strength of a suite of supervised learning models aimed at inferring network quality estimates. To create a realistic fog computing sandbox, we deployed an image processing ensemble of services in the GENI infrastructure. The nodes in GENI have varying hardware specifications for the purpose of generating compute-intensive workloads on heterogeneous systems. Our experimental results suggest that machine learning can be used to accurately model important network quality parameters and outperforms traditional techniques. Moreover, our results indicate that the training and prediction times for each model is suitable for deployment in latency-sensitive environments.	algorithm;communications protocol;dnp3;end-to-end principle;feature selection;fog computing;image processing;machine learning;overhead (computing);programming paradigm;real-time transcription;scheduling (computing);software deployment;software-defined networking;supervised learning;testbed	Jon Patman;Meshal Alfarhood;Shakibul Islam;Mauro Lemus;Prasad Calyam;Kannappan Palaniappan	2018	IEEE INFOCOM 2018 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2018.8407027	cloud computing;supervised learning;benchmarking;predictive analytics;machine learning;edge computing;software deployment;testbed;sandbox (computer security);artificial intelligence;computer science	Metrics	-27.44681183222905	63.42932341865391	121627
7cfb8fff2003abb2213054cec27bd149b33564c8	energy and makespan tradeoffs in heterogeneous computing systems using efficient linear programming techniques	linear programming high performance computing scheduling resource management bag of tasks energy aware heterogeneous computing vector optimization;high performance computing;heterogeneous computing;processor scheduling;resource management;scheduling linear programming minimisation parallel processing pareto optimisation power aware computing resource allocation;approximation methods optimization linear programming power demand processor scheduling scheduling multicore processing;bag of tasks;energy aware;scheduling;multicore processing;linear programming;vector optimization;optimization;approximation methods;power demand;pareto front energy tradeoff makespan tradeoff heterogeneous computing system linear programming technique resource management high performance computing system hpc system task scheduling algorithm	Resource management for large-scale high performance computing systems pose difficult challenges to system administrators. The extreme scale of these modern systems require task scheduling algorithms that are capable of handling at least millions of tasks and thousands of machines. These large computing systems consume vast amounts of electricity leading to high operating costs. System administrators try to simultaneously reduce operating costs and offer state-of-the-art performance; however, these are often conflicting objectives. Highly scalable algorithms are necessary to schedule tasks efficiently and to help system administrators gain insight into energy/performance trade-offs of the system. System administrators can examine this trade-off space to quantify how much a difference in the performance level will cost in electricity, or analyze how much performance can be expected within an energy budget. In this study, we design a novel linear programming based resource allocation algorithm for a heterogeneous computing system to efficiently compute high quality solutions for simultaneously minimizing energy and makespan. These solutions are used to bound the Pareto front to easily trade-off energy and performance. The new algorithms are highly scalable in both solution quality and computation time compared to existing algorithms, especially as the problem size increases.	algorithm;analysis of algorithms;computation;display resolution;heterogeneous computing;ibm websphere extreme scale;linear programming;makespan;pareto efficiency;scalability;scheduling (computing);supercomputer;system administrator;time complexity	Kyle M. Tarplee;Ryan Friese;Anthony A. Maciejewski;Howard Jay Siegel;Edwin K. P. Chong	2016	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2015.2456020	multi-core processor;parallel computing;real-time computing;computer science;linear programming;resource management;operating system;distributed computing;vector optimization;scheduling;symmetric multiprocessor system	HPC	-19.4956743789996	62.97805625037194	121810
e4365037cbf4b4c4a94801f6f9a2b013d3f330e4	graph embedding to allocate network resources for service composition	distributed application;graph theory;optical network;service composition;resource management optical fiber networks optical fiber communication large scale systems context aware services context resource virtualization bandwidth availability performance evaluation;resource allocation;resource allocation graph theory optical fibre networks quality of service;satisfiability;optical fibre networks;large scale;online embedding algorithm network resource allocation service composition optical communications optical networks qos temporal virtualized resources workflow graph;optical communication;graph embedding;graph model;quality of service	Recent developments in optical communications have led to the creation of large scale optical networks allowing its users to run distributed applications with high QoS requirements. In this context, this paper focuses on a strategy of reservation of temporal virtualized resources in an high bandwidth optical network for service composition. In this strategy, the service composition requirements are modeled by a specific workflow graph with constraints. To satisfy such demands, the workflow graph is embedded in a graph modeling the network in which the availability of resources is scheduled in consecutive equal time periods. We first present the models of workflow and network graphs we use and the theoretical problems we focus on. Then, we describe an online embedding algorithm and we evaluate its performances on various demand scenarii.	algorithm;distributed computing;embedded system;graph embedding;performance;requirement;service composability principle;simulation	Dominique Barth;Christian Cadéré;Dominique Verchère;Sandrine Vial	2010	2010 IEEE International Conference on Communications	10.1109/ICC.2010.5502596	graph embedding;quality of service;resource allocation;computer science;graph theory;theoretical computer science;distributed computing;optical communication;computer network;satisfiability	HPC	-19.792712904292483	66.29294072981861	122313
5747d0535c20b673a0632e5a745233587c9a8ebf	healthedge: task scheduling for edge computing with health emergency and human behavior consideration in smart homes		Nowadays, a large amount of services are deployed on the edge of the network from the cloud since processing data at the edge can reduce response time and lower bandwidth cost for applications such as healthcare in smart homes. Resource management is very important in the edge computing since it is able to increase the system efficiency and improve the quality of service. A common approach for resource management in edge computing is to assign tasks to the remote cloud or edge devices just according to several factors such as energy, bandwidth consumption, and latency. However, the approach is insufficiently efficient and falls short in meeting the requirements of handling health emergency when being applied in smart homes for healthcare. In this paper, we propose a task scheduling approach called HealthEdge that sets different processing priorities for different tasks based on the collected data on human health status and determines whether a task should run in a local device or a remote cloud in order to reduce its total processing time as much as possible. Based on a real trace from five patients, we conduct a trace-driven experiment to evaluate the performance of HealthEdge in comparison with other methods. The results show that HealthEdge can optimally assign tasks between the network edge and cloud, which can reduce the task processing time, reduce bandwidth consumption and increase local edge workstation utilization.	cloud computing;data center;edge computing;heuristic;np-hardness;priority queue;quality of service;requirement;response time (technology);scheduling (computing);server (computing);simulation;workstation	Haoyu Wang;Jiaqi Gong;Yan Zhuang;Haiying Shen;John Lach	2017	2017 IEEE International Conference on Big Data (Big Data)	10.1109/NAS.2017.8026861	latency (engineering);edge device;data mining;quality of service;real-time computing;resource management;response time;scheduling (computing);computer science;cloud computing;edge computing	HPC	-22.772274435678064	68.07464292441074	122325
b79578cb4923aaa07e7728ca2b2c0088eefff1bd	eco-efficient cloud resource monitoring and analysis		This paper presents an approach for monitoring cloud computing resources by using customized monitoring metrics. In addition, based on the monitoring results, this approach includes a data mining analysis for making assumptions regarding consumed power of infrastructure and virtual machines (VMs) aiming at a reduced carbon footprint.	cloud computing;data mining;virtual machine	Axel Tenschert;Pavel Skvortsov;Michael Gienger	2014			cloud computing;data mining;virtual machine;carbon footprint;computer science	HPC	-25.616188436335538	60.64885861453143	122437
40e90fc88db26955bec6e087e83269ad66010a7a	joint admission control and provisioning for virtual machines	servers admission control joints memory cloud computing virtual machining dynamic programming;simulation based adp algorithm virtual machine deployment cloud provider data center joint admission control and vm provisioning scheme markov decision process vm admission and placement decision cp operating revenue mdp problem standard dynamic programming technique simulation based approximate dynamic programming algorithm;virtual machines cloud computing computer centres dynamic programming markov processes	In current data centers, cloud providers (CPs) need to make decisions on virtual machine (VM) deployment requests that arrive dynamically over time under the constraint of limited physical resources to host VMs. Existing schemes to solve this problem either do not consider the dynamic characteristic of requests when solving the VM provisioning problem or separate admission control and VM provisioning into two independent problems. Both approaches can result in substantially sub-optimal revenue outcomes. In this paper, we propose a joint admission control and VM provisioning scheme based on a Markov Decision Process (MDP) framework to optimize the VM admission and placement decision in an integrated manner to maximize the CP's operating revenue. Because of the large number of physical servers in data centers, the MDP problem is computationally intractable to standard dynamic programming techniques. We propose a simulation-based approximate dynamic programming (ADP) algorithm to effectively solve the problem. Simulation results show that the new joint admission control and VM provisioning algorithm can substantially increase the revenue generated for CPs.	approximation algorithm;cloud computing;computational complexity theory;data center;decision problem;dynamic programming;greedy algorithm;markov chain;markov decision process;provisioning;simulation;software deployment;usb on-the-go;virtual machine	Liu Liu;Jie Xu;Hong-Fang Yu;Xuetao Wei	2015	2015 IEEE International Conference on Communications (ICC)	10.1109/ICC.2015.7248343	real-time computing;computer science;operating system;distributed computing;computer network	Embedded	-22.65020406929372	63.86355465326261	122557
2b03df037b5b98f417ae9862f1dd8ed0d2fac788	elastman: elasticity manager for elastic key-value stores in the cloud	slo;datorsystem;computer systems;elasticity controller;feedforward control;cloud storage;feedback control;cloud computing	The increasing spread of elastic Cloud services, together with the pay-as-you-go pricing model of Cloud computing, has led to the need of an elasticity controller. The controller automatically resizes an elastic service in response to changes in workload, in order to meet Service Level Objectives (SLOs) at a reduced cost. However, variable performance of Cloud Virtual Machines and nonlinearities in Cloud services, such as the diminishing reward of adding a service instance with increasing the scale, complicates the controller design. We present the design and evaluation of ElastMan, an elasticity controller for Cloud-based elastic key-value stores. ElastMan combines feedforward and feedback control. Feedforward control is used to respond to spikes in the workload by quickly resizing the service to meet SLOs at a minimal cost. Feedback control is used to correct modeling errors and to handle diurnal workload. To address nonlinearities, our design of ElastMan leverages the near-linear scalability of elastic Cloud services in order to build a scale-independent model of the service. We have implemented and evaluated ElastMan using the Voldemort key-value store running in an OpenStack Cloud environment. Our evaluation shows the feasibility and effectiveness of our approach to automation of Cloud service elasticity.	attribute–value pair;cloud computing;elasticity (cloud computing);feed forward (control);feedback;feedforward neural network;key-value database;reduced cost;scalability;service-level agreement	Ahmad Al-Shishtawy;Vladimir Vlassov	2013		10.1145/2494621.2494630	embedded system;real-time computing;simulation;engineering;cloud testing	OS	-23.786620466728838	61.69404424786008	122738
052571b98fd3ececd3901df5249773000ca09fd8	multi-resource fair sharing for datacenter jobs with placement constraints		Providing quality-of-service guarantees by means of fair sharing has never been more challenging in datacenters. Due to the heterogeneity of machine configurations, datacenter jobs frequently specify placement constraints, restricting them to run on a particular class of machines meeting specific hardware/software requirements. In addition, jobs have diverse demands across multiple resource types, and may saturate any of the CPU, memory, or storage resources. Despite the rich body of recent work on datacenter scheduling, it remains unclear how multi-resource fair sharing is defined and achieved for jobs with placement constraints. In this paper, we propose a new sharing policy called Task Share Fairness (TSF). With TSF, jobs are better off sharing the datacenter, and are better off reporting demands and constraints truthfully. We have prototyped TSF on Apache Mesos and confirmed its service guarantees in a 50-node EC2 cluster. Trace-driven simulations have further revealed that TSF speeds up 60% of tasks over existing fair schedulers.	central processing unit;data center;fairness measure;job stream;pareto efficiency;prototype;quality of service;requirement;scheduling (computing);simulation;software requirements;world-system	Wei Wang;Baochun Li;Ben Liang;Jun Li	2016	SC16: International Conference for High Performance Computing, Networking, Storage and Analysis		parallel computing;kernel;real-time computing;quality of service;computer science;resource management;operating system;distributed computing;scheduling;computer network;memory management	HPC	-21.328453186266582	60.580975709505225	123384
55027bf2303f9d640ca685391189759d00115509	reputation-aware recruitment and credible reporting for platform utility in mobile crowd sensing with smart devices in iot	internet of things (iot);mobile crowd sensing (mcs);individual rationality;social welfare;truthfulness	The Internet of things (IoT) comprises a huge collection of electronic devices connected to the Internet to ensure the dependable exchange of sensing information. It involves mobile workers (MWs) who perform various activities to support enormous online services and applications. In mobile crowd sensing (MCS), a massive amount of sensing data is also generated by smart devices. Broadly, in the IoT, verifying the credibility and truthfulness of MWs' sensing reports is needed for MWs to expect attractive rewards. MWs are recruited by paying monetary incentives that must be awarded according to the quality and quantity of the task. The main problem is that MWs may perform false reporting by sharing low-quality reported data to reduce the effort required. In the literature, false reporting is improved by hiring enough MWs for a task to evaluate the trustworthiness and acceptability of information by aggregating the submitted reports. However, it may not be possible due to budget constraints, or when malicious reporters are not identified and penalized properly. Recruitment is still not a refined process, which contributes to low sensing quality. This paper presents Reputation, Quality-aware Recruitment Platform (RQRP) to recruit MWs based on reputation for quality reporting with the intention of platform profit maximization in the IoT scenario. RQRP comprises two main phases: filtration in the selection of MWs and verifying the credibility of reported tasks. The former is focused on the selection of suitable MWs based on different criteria (e.g., reputation, bid, expected quality, and expected platform utility), while the latter is more concerned with the verification of sensing quality, evaluation of reputation score, and incentives. We developed a testbed to evaluate and analyze the datasets, and a simulation was performed for data collection scenario from smart sensing devices. Results proved the superiority of RQRP against its counterparts in terms of truthfulness, quality, and platform profit maximization. To the best of our knowledge, we are the first to study the impact of truthful reporting on platform utility.	awards;data collection;e-services;entropy maximization;internet of things;malware;mobile health unit;money;not-for-profit insurance plans;rewards;simulation;smart device;testbed;trust (emotion);verification and validation;verification of theories;verifying specimen;filtration	Waquar Ahmad;Shengling Wang;Ata Ullah;Muhammad Shabir	2018		10.3390/s18103305	computer security;electronic engineering;engineering;internet of things;reputation	Mobile	-27.637328617795514	71.7585731207033	123540
a7944374a218b69fe033fec3ef80434425a37173	a monte carlo based computation offloading algorithm for feeding robot iot system		Ageing is becoming an increasingly major problem in European and Japanese societies. We have so far mainly focused on how to improve the eating experience for both frail elderly and caregivers by introducing and developing the eating aid robot, Bestic, made to get the food from plate to the mouth for frail elderly or person with disabilities. We expand the functionalities of Bestic to create food intake reports automatically so as to decrease the undernutrition among frail elderly and workload of caregivers through collecting data via a vision system connected to the Internet of Things (IoT) system. Since the computation capability of Bestic is very limited, computation offloading, in which resource intensive computational tasks are transferred from Bestic to an external cloud server, is proposed to solve Bestic’s resource limitation. In this paper, we proposed a Monte Carlo algorithm based heuristic computation offloading algorithm, to minimize the total overhead of all the Bestic users after we show that the target optimization problem is NP-hard in a theorem. Numeric results showed that the proposed algorithm is effective in terms of system-wide overhead.		Cheng Zhang;Takumi Ohashi;Miki Saijo;Jorge Solis;Yukio Takeda;Ann-Louise Lindborg;Ryuta Takeda;Yoshiaki Tanaka	2018		10.1007/978-3-030-05755-8_17	monte carlo method;cloud computing;computation;monte carlo algorithm;algorithm;heuristic;theory of computation;optimization problem;computer science;computation offloading	Robotics	-22.9508843579632	66.57476895293584	123560
6c37a732fe73b2dcb3460bca7262b28dae865ff4	poster abstract: decentralized fog computing resource management for offloading of periodic tasks		Fog computing is recognized as a promising approach for meeting the computational and delay requirements of a variety of emerging applications in the Internet of Things. This work presents a game theoretical treatment of the resource allocation problem in a fog computing system where wireless devices periodically generate computationally intensive tasks, and aim at minimizing their own cost. I . I N T R O D U C T I O N The emerging paradigm of fog computing brings computing resources close to the network edge. Placing computing resources at the network edge in close proximity of end users and devices may reduce the communication delays and the response times, and is expected to enable a variety of emerging Internet of Things (IoT) applications [1]. Applications that could benefit most are those in need of periodic execution of computationally intensive tasks on energy limited devices, which could be offloaded to fog computing resources, such as surveillance and augmented reality [2], [3]. The proximity of computing resources to devices is a prerequisite for predictable and low response times, but it may not be sufficient. In lack of resource management, when many devices attempt to offload computations simultaneously over a shared communication resource, such as a wireless access point, the communication delays may increase and may become unpredictable. Furthermore, computing resources should be allocated so as to match the assignment of communication resources and computational requirements, to ensure low response times. Thus, the joint management of communication and computing resources is essential for ensuring predictable and low response times for computation offloading. Joint resource management for fog computing systems, is, however challenging for several reasons. First, fog computing systems are expected to consist of devices that are heterogeneous in terms of their computational capabilities and battery capabilities, and thus devices could have different preferences over the energy consumption and the application response times. Second, the different devices may generate computational tasks that are very different in terms of the amount of data needed to be transmitted and in terms of their complexity. Furthermore, there may be many devices that periodically generate computational tasks with low response time requirements, and thus the tasks have to be scheduled over time and across communication resources. Finally, devices may be autonomous, and hence resource management should respect their individual preferences. Fig. 1. An example of a fog computing system that consists of N = 5 devices, T = 2 time slots, and A = 2 APs. In this work we address the problem of managing the communication and computing resources in a fog computing system for computation offloading, and we use game theoretical tools for designing an efficient decentralized algorithm for coordinating the decisions of devices with periodic tasks. I I . S Y S T E M M O D E L A N D P R O B L E M F O R M U L AT I O N We consider a fog computing system that consists of a set N of devices that generate computationally intensive tasks periodically every T time units, a set A of APs and an edge cloud. We consider that each device can choose one time slot from the set T ={1, 2, . . . , T} to perform the computation, and within the chosen time slot it can decide whether or not to offload the computation to the cloud via one of the APs a ∈ A. We denote by di ∈ Di the decision of device i, where Di ={A∪{0}×T }, and 0 corresponds to local computing. Task model: Device i’s task <Di, Li> is characterized by two parameters, the mean size Di of the input data and by the complexity Li, which is defined as the mean number of CPU cycles required to perform the computation. Communication model: When it offloads the task, each device i has to transmit the input data of size Di via one of the APs. We consider that the uplink rate that device i can achieve if it offloads the task via AP a in time slot t is a non-incrasing function of the number of devices that offload via the same AP a in the same time slot t. Thus, the time needed for device i to transmit Di amount of data via AP a in time slot t and the corresponding energy consumption are non-decreasing functions of the number of devices that offload via the same AP a in the same time slot t. Computation model: In the case of local computing, we consider that the computational capability F 0 i of device i is the same in each time slot t. Hence, the time needed for device i to perform its task and the corresponding energy	algorithm;augmented reality;autonomous robot;cpu socket;central processing unit;computation offloading;fog computing;internet of things;programming paradigm;requirement;response time (technology);telecommunications link;wireless access point	Sladana Josilo;György Dán	2018		10.1109/INFCOMW.2018.8406995	task analysis;distributed computing;resource management;periodic graph (geometry);edge computing;resource allocation;wireless;computer science;internet of things	Embedded	-23.169343159936798	67.16314533840954	123603
b681c60024a38ba9059bada0fb4b1ab7ad625fec	an inter-cloud outsourcing model to scale performance, availability and security	optimisation;outsourcing;availability;security cloud federation outsourcing optimization model service provisioning sla performance availability;resource allocation;performance;service provisioning;security of data cloud computing optimisation resource allocation;sla;optimization problem intercloud outsourcing model security horizontal cloud federation optimal resource selection allocation policy service level agreement;cloud federation;security;availability security outsourcing load modeling resource management time factors optimization;security of data;optimization model;cloud computing	This paper presents a model of a horizontal cloud federation and studies the optimal resource selection and allocation policy a service provider should put in place to scale the performance, availability and security guarantees offered to customers. The proposed model considers: (i) resources located in different zones, characterized by different hourly costs and specific performance, availability, and security properties, (ii) service provider customers, dispersed in various zones(characterized by different latencies), and demanding services with different QoS levels defined in Service Level Agreements(SLAs). From this model we define an optimization problem allowing to determine the optimal distribution of the incoming load and the proper allocation of outsourced resources that satisfies the SLAs and that minimizes the outsourcing costs, thus allowing the maximization of the SP revenue. Experiments show how the optimal policy scales the service provider capabilities when the workload grows 10 times and more.	expectation–maximization algorithm;mathematical optimization;optimization problem;outsourcing	Emiliano Casalicchio;Luca Silvestri	2012	2012 IEEE Fifth International Conference on Utility and Cloud Computing	10.1109/UCC.2012.16	availability;cloud computing;performance;business service provider;resource allocation;computer science;information security;computer security;outsourcing	Metrics	-22.38673086007905	63.76870758766896	123691
a42c2ffd44d70a13e1d85bd565b59ce6522e12aa	a hadoop extension to process mail folders and its application to a spam dataset	electronic mail postal services educational institutions internet programming servers;spam;mail;hadoop mail spam;big data processing hadoop extension mail folder spam dataset web 2 0 e mail spam traffic data mining;unsolicited e mail big data data mining internet;hadoop	Even as the web 2.0 grows, e-mail continues to be one of the most used forms of communication in the Internet, being responsible for the generation of huge amounts of data. Spam traffic, for example, accounts for terabytes of data daily. It becomes necessary to create tools that are able to process these data efficiently, in large volumes, in order to understand their characteristics. Although mail servers are able to receive and store messages as they arrive, applying complex algorithms to a large set of mailboxes, either for characterization, security reasons or for data mining goals is challenging. Big data processing environments such as Hadoop are useful for the analysis of large data sets, although originally designed to handle text files in general. In this paper we present a Hadoop extension used to process and analyze large sets of e-mail, organized in mailboxes. To evaluate it, we used gigabytes of real spam traffic data collected around the world and we showed that our approach is efficient to process large amounts of mail data.	algorithm;apache hadoop;big data;data mining;email;gigabyte;internet;programmer;random access;spamming;terabyte;web 2.0	Pedro Henrique B. Las-Casas;Vinícius Vitor dos Santos Dias;Renato A. C. Ferreira;Wagner Meira;Dorgival O. Guedes	2014	2014 International Symposium on Computer Architecture and High Performance Computing Workshop	10.1109/SBAC-PADW.2014.25	spam;computer science;spamming;data mining;internet privacy;world wide web	Arch	-32.76064944559163	62.17522896104286	123912
44758785ca60106850fb4b3a4b1951062a45eaac	a dynamic resource overbooking mechanism in fog computing		Fog Computing (FC - similarly edge computing) as new computing paradigm can support distributed domain-specific or area-specific applications with cloud-like quality of service (QoS). This promising paradigm thus can find its wide applications in various industrial scenarios and smart cities in which the resource requirements will be divided into peak-hour or non-peak-hour. To deal with such features of applications, a flexible resource allocation approach based on pricing model can be critical for the success of such paradigm. To the best of our knowledge, we have not seen such pricing based resource allocation approach ever been reported for FC scenarios. In this paper, we propose a novel pricing based dynamic resource allocation model through overbooking mechanism, and it is realized through three steps: 1) According to different QoS requirements of user tasks, methods of on-demand billing, daily billing, and auction billing are designed, in which we allow the resource to be overbooked; 2) For auction billing, we design an auction approach including pricing rule and winner determination rule. We prove that our auction approach guarantees individual rationality, computational efficiency, and truthfulness. 3) To overbook as much resource as possible with a high degree of QoS satisfaction of on-demand and daily billing, we overbook the resource based on a resource utilization prediction using neural network and service level agreement violation feedback. In the end, we validate the mechanism with real-world data trace. Experimental results show that our auction approach achieves desirable properties, and our dynamic resource overbooking mechanism maximizes the profit of nodes with a high degree of QoS satisfaction of on-demand and daily billing and a high resource utilization prediction accuracy rate.		Fuming Zhang;Zhiqing Tang;Mingcheng Chen;Xiaojie Zhou;Weijia Jia	2018	2018 IEEE 15th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)	10.1109/MASS.2018.00023	artificial neural network;quality of service;service-level agreement;rationality;computer science;distributed computing;resource allocation;edge computing	HPC	-21.83030504054338	64.77076760864468	124004
aa12a9f7f0fd8870d543c6d5cb1362d010cf38c8	constructing dependable smart grid networks using network functions virtualization	virtualization;dependability;network function virtualization;advanced metering infrastructure	Smart meters enable a fine-granular monitoring of power consumption and distributed power production in costumers’ premises, which are used to predict the power requirements for the near future. The goals are to offer more security of supply as well as to minimize the power requirement estimation errors. However, to benefit from this information, the communication infrastructure that transmits the energy-related data needs to fulfill stringent requirements with respect to dependability, while remaining monetarily feasible. This paper discusses the usage of network function virtualization (NFV) technologies and constructs a virtual advanced metering infrastructure (AMI) network to transmit energy-related information in a dependable and cost-effective way. After the discussion of dependability requirements of AMI and the shortcomings of current approaches, the reliability and availability of a new architecture based on NFV is analyzed using analysis. Finally, a cost model is developed to compare the Virtual Network Function approach to current AMIs.	analysis of algorithms;computation;dependability;level of detail;management information system;mean time to recovery;network function virtualization;observable;overhead (computing);quality of service;requirement;semiconductor consolidation;smart tv;smart meter;testbed;transfer function	Michael Niedermeier;Hermann de Meer	2016	Journal of Network and Systems Management	10.1007/s10922-016-9380-1	embedded system;network functions virtualization;real-time computing;virtualization;computer science;dependability;computer security;computer network	Networks	-29.416873581293157	62.279055740141594	124071
719389b1c3e04eba37f90c9689764789352f9cf5	pyramid codes to the rescue: a preliminary evaluation for cloud storage systems	intrusion detection;security middleware;cloud computing;multilayer cooperation	"""In this paper, we study the tradeoffs between storage overhead, repair locality, and performance of erasure-correcting codes implemented in real-world distributed storage systems. In particular, we focus on a recent family of codes with locality called """"pyramid codes"""" and compare it against Reed-Solomon codes with the aim of showing quantitative results demonstrating the benefits of small locality."""	cloud storage;clustered file system;folded reed–solomon code;locality of reference;overhead (computing);reed–solomon error correction	Roberta Barbi	2016		10.1145/3009925.3009933	real-time computing;engineering;distributed computing;computer security	OS	-30.35250312752152	68.60515330290525	124208
c5eae419f94fc5ada1576ea147e61ea78baa1999	research on cryptographic algorithms for embedded real-time systems: a perspective of measurement-based analysis	cryptographic algorithms;embedded real time system;data processing;power aware computing cryptography embedded systems energy consumption;energy consumption real time systems algorithm design and analysis data processing;embedded systems;power aware computing;energy consumption;cryptography;security critical applications cryptographic algorithms measurement based analysis battery powered security critical systems energy related characteristics common security algorithms data sensitive embedded real time systems multidimensional analysis framework energy consumption symmetric algorithms asymmetric algorithms hash algorithms mathematical models arm9 embedded platform μc osii;security;algorithm design and analysis;cryptographic algorithms embedded real time system energy consumption security;real time systems	Security and energy are two main concerns for embedded systems, especially in battery-powered security-critical systems. In this paper, we make efforts to identify energy-related characteristics of common security algorithms for data-sensitive embedded real-time systems. Different to traditional researches, this paper focuses on the influences of size of protected data on energy-related factors. We present a multi-dimensional analysis framework that reveals potential features of energy consumption from the angles of power, speed, and unit energy cost. The energy features of most popular cryptographic algorithms including symmetric, asymmetric, and hash algorithms are well studied. In addition, some mathematical models are also built to help explain and investigate these features. All the analysis is based on empirical data measured from an ARM9 embedded platform which runs security-critical tasks under μC/OSII. We believe this paper could provide some useful information to help the design of security-critical applications in embedded real-time systems.	arm architecture;algorithm;cryptography;embedded system;hash function;mathematical model;real-time clock;real-time computing;real-time operating system	Wei Jiang;Zhenlin Guo;Yue Ma;Nan Sang	2012	2012 IEEE 14th International Conference on High Performance Computing and Communication & 2012 IEEE 9th International Conference on Embedded Software and Systems	10.1109/HPCC.2012.218	cryptographic primitive;embedded system;parallel computing;real-time computing;data processing;computer science;cryptography;theoretical computer science;operating system;distributed computing;algorithm	Embedded	-30.000717029576897	67.84276909479988	124250
1bcbd915fd355220aab5b6ea24ca46d05ee24b66	phd forum: not so cooperative caching	game theory;computer networks;peer to peer computing games cooperative caching object recognition nash equilibrium internet silicon;game theory computer networks;ibr autonomous selfish ndn peering domains named data networking dubbed not so cooperative caching nscc selfish nodes caching capability node access cost reduction data fetching local cache neighboring caches access price model realistic access price model node pairs decision making mistreatment free object placement implicit cooperation selfish behaving domains nash equilibrium object placement identification mistreatment free object placements cooperation performance improvement game theoretic approach global object placement	This work proposes a scheme to promote autonomous and selfish NDN (Named Data Networking) peering domains to cooperate in caching, here dubbed Not So Cooperative Caching (NSCC). We consider a network comprised of selfish nodes; each is with a caching capability and an objective of reducing its own access cost by fetching data from local cache or from neighboring caches. The challenge is to determine what objects to cache at each node so as to induce low individual node access costs, and the realistic access “price” model which allows various access “prices” of different node pairs further complicates the decision making. NSCC attempts to identify mistreatment-free object placement to incur implicit cooperation even among these selfishly behaving domains, and to further identify Nash equilibrium object placement from mistreatment-free object placements so that no domain can unilaterally change its placement and benefit while the others keep theirs unchanged, and to improve the cooperation performance with respect to fairness So far, using a game-theoretic approach NSCC seeks a global object placement in which the individual node access costs are reduced as compared to that when they operate in isolation and achieves Nash equilibrium. Our preliminary experiments with IBR verified its effectiveness. And we discuss the specific issues of NSCC's implementation in NDN.	autonomous robot;cpu cache;cache (computing);cooperative multitasking;experiment;fairness measure;game theory;image-based modeling and rendering;nash equilibrium;peering	Xiaoyan Hu;Jian Gong	2013	2013 21st IEEE International Conference on Network Protocols (ICNP)	10.1109/ICNP.2013.6733656	game theory;simulation;computer science;distributed computing;computer security;computer network	Robotics	-25.24161687280541	73.54322922933527	124832
41765bacab92c4876aba076fd7653bdcdd3c35a1	building autonomically scalable services on wide-area shared computing platforms	highly available systems;capacity planning;computer crashes;resource allocation fault tolerant computing peer to peer computing;operant conditioning;model system;resource allocation;resource manager;system performance;dynamic control;resource availabilities model;fault tolerant computing;estimation;aggregates;autonomic replication;computer crashes capacity planning predictive models estimation load modeling aggregates buildings;predictive models;resource availability;prediction model;scalable services;peer to peer computing;load modeling;highly available systems scalable services autonomic replication resource availabilities model system performance;buildings;node crash autonomically scalable service wide area shared computing platform autonomically resilient services resource allocation fair share basis platform wide resource manager resource capacity planetlab adaptive load distribution service replication dynamic control autonomic service capacity scaling flash crowd;flash crowds	We present here mechanisms and models for building autonomically scalable and resilient services on wideâ€area shared computing platforms in which resources at a node are allocated to competing users on fairâ€share basis. There is no platformâ€wide resource manager for the placement of users on different nodes. Building scalable services in such environments poses unique challenges due to fluctuations in the available resource capacities and node crashes. The service load may surge in a short time due to flash crowds. We present here models for estimating the service capacity under varying operating conditions. Autonomic scaling of service capacity is performed by dynamic control of the degree of service replication based on the estimated service capacity and the observed load. Furthermore adaptive load distribution mechanisms are needed because of the varying service capacities of the individual replicas. We present the results of our evaluations of these mechanisms on Planet Lab.	autonomic computing;experiment;grid computing;image scaling;load balancing (computing);offset binary;scalability;slack variable;usage data	Vinit Padhye;Anand R. Tripathi	2011	2011 IEEE 10th International Symposium on Network Computing and Applications	10.1109/NCA.2011.54	real-time computing;computer science;resource management;operating system;machine learning;distributed computing;computer performance;predictive modelling;computer network	HPC	-23.032701760834584	60.7922568236324	124914
9700d491915a88cc07ecc94b380a4f4eb86649f8	rational behavior in peer-to-peer profile obfuscation for anonymous keyword search: the multi-hop scenario	multi hop peer to peer profile obfuscation;private information retrieval;anti profiling;user private information retrieval;location privacy;anonymous keyword search	Web search engines (WSEs) have become an essential tool for searching the huge amount of information stored in the World Wide Web. WSEs try to build query profiles of their users, in order to increase the accuracy of the results provided to users and also to fine-tune advertising. Profiling the query interests of users clearly encroaches on their privacy. There are several anti-profiling approaches in web search, among which those relying on peer-to-peer profile obfuscation stand out. In this paper, we analyze the multi-hop peer-to-peer profile obfuscation game, in which a peer forwards her query to a second peer, who may submit it on behalf of the first peer or just forward it to a third peer, and so on. We describe several privacy utility functions for peers and a rational protocol in terms of a generic privacy utility function. It turns out that rational behavior leads peers to helping each other.	bounce address;cryptography;game theory;peer-to-peer;privacy;profiling (computer programming);requirement;retry;search algorithm;timeout (computing);user requirements document;utility;web search engine;world wide web	Josep Domingo-Ferrer;Úrsula González-Nicolás	2012	Inf. Sci.	10.1016/j.ins.2012.02.067	private information retrieval;computer science;data mining;internet privacy;world wide web	Web+IR	-25.907117596947284	73.70220790546453	125340
1d81fd5e67306598a5cee1e93333f45edcefa819	hierarchical resource allocation and consolidation framework in a multi-core server cluster using a markov decision process model		This paper investigates a service level agreements (SLAs)-based resource allocation problem in a server cluster. The objective is to maximise the total profit, which is the total revenue minus the operational cost of the server cluster. The total revenue depends on the average request response time, whereas the operating cost depends on the total energy consumption of the server cluster. A joint optimisation framework is proposed, comprised of request dispatching, dynamic voltage and frequency scaling (DVFS) for individual cores of the servers, as well as server- and core-level consolidations. Each DVFS-enabled core in the server cluster is modelled by using a continuous-time Markov decision process (CTMDP). A near-optimal solution comprised of a central manager and distributed local agents is presented. Each local agent employs linear programming-based CTMDP solving method to solve the DVFS problem for the corresponding core. On the other hand, the central manager solves the request dispatch problem and finds the optimal number of ON cores and servers, thereby achieving a desirable tradeoff between service response time and power consumption. To reduce the computational overhead, a two-tier hierarchical solution is utilized. Experimental results demonstrate the outstanding performance of the proposed algorithm over the baseline algorithms.		Pu Zhao;Xue Lin;Yanzhi Wang;Shuang Chen;Massoud Pedram	2017	IET Cyper-Phys. Syst.: Theory & Appl.	10.1049/iet-cps.2017.0060	energy consumption;real-time computing;request–response;linear programming;computer cluster;markov decision process;distributed computing;server;computer science;resource allocation;service level	Metrics	-21.38624861069067	64.02425374488323	125775
c10c540482b2e78ade3ec88151ccdf6b645e5eac	mils-cloud: a sensor-cloud-based architecture for the integration of military tri-services operations and decision making	mils cloud hierarchical architecture utility service cc cloud computing wsn wireless sensor networks distributed sensor nodes decision making military tri service integration sensor cloud based architecture;delays cloud computing military aircraft computer architecture wireless sensor networks companies decision making;sensor cloud cloud architecture systems cloud computing cc systems military communications;companies;military aircraft;computer architecture;wireless sensor networks cloud computing decision making military computing;wireless sensor networks;delays;cloud computing	Spatially distributed sensor nodes in wireless sensor networks (WSNs) can be used to monitor large unmanned areas. However, there are many limitations to WSNs, and the influence and accessibility of the sensors in these networks are limited to localized areas. Another popular technology today is cloud computing (CC). CC can provide a potent and scalable processing and storage infrastructure that can be used to perform the analysis of online as well as offline data streams provided by the sensors. It is possible to virtualize the sensor networks to provide these networks as a utility service. In this paper, we propose “Mils-Cloud,” which is a sensor-cloud architecture utilizing this infrastructure for developing architecture for the integration of military tri-services in a battlefield scenario. We propose a hierarchical architecture of sensor-cloud with users having different levels of priority. The results show that reserving about 20%-25% of resources actually boosts the performance of the system for priority users without compromising the availability for normal users.	access time;accessibility;automaton;bottleneck (software);cloud computing;e-services;learning automata;markov chain;markov decision process;mathematical optimization;multiple independent levels of security;network interface controller;online and offline;performance evaluation;recommender system;scalability;sensor;transmitter;triangular function;unmanned aerial vehicle;virtualize	Sudip Misra;Anuj Singh;Subarna Chatterjee;Mohammad S. Obaidat	2016	IEEE Systems Journal	10.1109/JSYST.2014.2316013	embedded system;wireless sensor network;cloud computing;computer science;engineering;operating system;key distribution in wireless sensor networks;computer security;computer network	Mobile	-23.882877466265903	67.80710315286268	126588
648e3e6ca25ebec7b7ba0c7f768e20c4a431c8b5	r-music, a collaborative music dj for ad hoc networks	ad hoc networks;client-server systems;groupware;music;ad hoc network;client-server architecture;collaborative music;personal digital music player;r-music;stationary high fidelity speaker system;vote balancing mechanism;wireless interface	We present r-MUSIC, client-server architecture for sharing music through a persistent resource in which the music data is not shared among users, but is streamed from personal digital music players to a stationary high fidelity speaker system. The client side of this system is installed on the personal digital music players. Users' music selections are transmitted through a wireless interface to the r-MUSIC server, which mediates a song title queue. Users call referenda on songs in the queue, and then vote on the popularity of songs, to mediate if and when they will be played. Our architecture includes a vote balancing mechanism that prevents users and their songs from becoming either too dominant or isolated. The power of this system is that an ad hoc group can share music without the need for a formal mediator. Mediation occurs entirely through collaboration.	client-side;client–server model;hoc (programming language);isolation (database systems);loudspeaker;matchware mediator;personal digital assistant;server (computing);stationary process;streaming media	Ursula Wolz;Michael Massimi;Eric Tarn	2004	Proceedings of the Fourth International Conference onWeb Delivering of Music, 2004. EDELMUSIC 2004.	10.1109/WDM.2004.1358111	wireless ad hoc network;computer science;multimedia;internet privacy;world wide web	Mobile	-23.72840113297649	71.72871993144302	126987
1edb070e3530f1a02ecd76f6621f7719d13b2109	holistic configuration management at facebook	control theory;dynamic systems;adaptive software	Facebook's web site and mobile apps are very dynamic. Every day, they undergo thousands of online configuration changes, and execute trillions of configuration checks to personalize the product features experienced by hundreds of million of daily active users. For example, configuration changes help manage the rollouts of new product features, perform A/B testing experiments on mobile devices to identify the best echo-canceling parameters for VoIP, rebalance the load across global regions, and deploy the latest machine learning models to improve News Feed ranking. This paper gives a comprehensive description of the use cases, design, implementation, and usage statistics of a suite of tools that manage Facebook's configuration end-to-end, including the frontend products, backend systems, and mobile apps.	a/b testing;configuration management;daily active users;echo suppression and cancellation;end-to-end encryption;experiment;holism;machine learning;mobile app;mobile device;personalization;self-balancing binary search tree	Chunqiang Tang;Thawan Kooburat;Pradeep Venkatachalam;Akshay Chander;Zhe Wen;Aravind Narayanan;Patrick Dowell;Robert Karl	2015		10.1145/2815400.2815401	real-time computing;simulation;operating system;dynamical system;world wide web	OS	-29.85613107739823	63.620789777881974	127901
181cb3796ba3cb470fba6137929a00677ce476cc	sigact news logic column 21	sigact news logic column	In this issue, Kramer, Goré, and Okamoto investigate how to use a logic of belief and knowledge to define the concepts of weak and strong trust relations as well as trust domains, and apply these definitions to security applications, such as trusted-third parties, the Web of Trust, public-key infrastructures, and identity-based cryptography. I am always looking for contributions. If you have any suggestion concerning the content of the Logic Column, or if you would like to contribute by writing a column yourself, feel free to get in touch with me.	acm sigact;id-based cryptography;kramer graph;public-key cryptography;ws-trust;web of trust;world wide web	Riccardo Pucella	2010	SIGACT News	10.1145/1753171.1753192		AI	-33.26067568237368	71.81483272751403	128859
510364da7d8fef838ba9188bb686257a0d4112e1	a hybrid approach to qos-aware service composition	service composition;service provider;fluctuations;case base reasoning;web services case based reasoning genetic algorithms integer programming quality of service;qos aware service composition;hybrid approach;time factors;integer programming;cognition;genetic algorithms qos aware service composition integer programming case based reasoning;web services;genetic algorithm;ip networks;genetic algorithms;quality of service costs web services linear programming genetic algorithms delay fluctuations computer science throughput availability;case based reasoning;quality of service;integer program	QoS-aware service composition intends to maximize the QoS of a composite service when selecting service providers. This paper proposes a service composition scheme that uses a combination of Integer Programming, case-based reasoning, and, genetic algorithms techniques. The scheme reduces the service composition costs by reusing existing compositions. Experiments show that, compared with solutions purely based on Integer Programming, the proposed scheme is effective in reducing the time for carrying out service composition.	case-based reasoning;experiment;genetic algorithm;integer programming;quality of service;query plan;service composability principle;service-oriented modeling;solver	Xinfeng Ye;Rami Mounla	2008	2008 IEEE International Conference on Web Services	10.1109/ICWS.2008.29	genetic algorithm;integer programming;computer science;theoretical computer science;database;distributed computing;law	Robotics	-20.467432705796206	65.57439325814038	129082
181bc76000ef49f5ba7043cc02f3e3633032fa2b	meta-learning based architectural and algorithmic optimization for achieving green-ness in predictive workload analytics	meta learning;predictive workload analytics;energy optimization	Predictive workload analytics for server systems has been the focus of recent research in energy-aware computing, with many algorithmic and architectural techniques proposed to analyze, predict, and optimize server workloads in order to build energy-aware IT systems. These techniques, though effective in optimizing server workloads, often ignore the green-ness aspect 'in' the technique itself and incur heavy computational costs in their operations. In this paper, we propose a meta-learning based architecture for building server workload prediction mechanism using which the computational cost of holistic predictive workload analytics can be optimized, and green-ness 'in' the analytics can be achieved. We also present an algorithmic optimization of the proposed meta-learning architecture for handling concept drift in server workloads, thereby also achieving improved greenness 'by' the analytics. Our experiments show that the proposed meta-learning based architecture substantially reduces the total computational cost of workload prediction mechanism, with a minor decrease of 0.5--1.3% in the accuracy, and the proposed algorithmic optimization significantly improves accuracy of the workload prediction mechanism in concept drift scenarios by 8.1%.	algorithmic efficiency;computation;concept drift;earthbound;experiment;holism;mathematical optimization;server (computing)	Nidhi Singh;Shrisha Rao	2013		10.1145/2480362.2480582	real-time computing;simulation;computer science;data mining;energy minimization	DB	-21.967058353285523	61.70724247743974	129290
d4e89af6dce65602724927ca58196cab8033004b	an infrastructure service recommendation system for cloud applications with real-time qos requirement constraints	quality of service real time systems games cloud computing decision making optimization;computing;decision support optimization service selection web based services;web based services decision support optimization service selection	The proliferation of cloud computing has revolutionized the hosting and delivery of Internet-based application services. However, with the constant launch of new cloud services and capabilities almost every month by both big (e.g., Amazon Web Service and Microsoft Azure) and small companies (e.g., Rackspace and Ninefold), decision makers (e.g., application developers and chief information officers) are likely to be overwhelmed by choices available. The decision-making problem is further complicated due to heterogeneous service configurations and application provisioning QoS constraints. To address this hard challenge, in our previous work, we developed a semiautomated, extensible, and ontology-based approach to infrastructure service discovery and selection only based on design-time constraints (e.g., the renting cost, the data center location, the service feature, etc.). In this paper, we extend our approach to include the real-time (run-time) QoS (the end-to-end message latency and the end-to-end message throughput) in the decision-making process. The hosting of next-generation applications in the domain of online interactive gaming, large-scale sensor analytics, and real-time mobile applications on cloud services necessitates the optimization of such real-time QoS constraints for meeting service-level agreements. To this end, we present a real-time QoS-aware multicriteria decision-making technique that builds over the well-known analytic hierarchy process method. The proposed technique is applicable to selecting Infrastructure as a Service (IaaS) cloud offers, and it allows users to define multiple design-time and real-time QoS constraints or requirements. These requirements are then matched against our knowledge base to compute the possible best fit combinations of cloud services at the IaaS layer. We conducted extensive experiments to prove the feasibility of our approach.	amazon web services;analytical hierarchy;archive;artificial intelligence;cloud computing;curve fitting;data center;decision support system;end-to-end principle;experiment;knowledge base;mathematical optimization;microsoft azure;mobile app;network congestion;ordinal data;provisioning;quality of service;real-time clock;real-time locating system;real-time transcription;recommender system;requirement;service discovery;service-level agreement;throughput;web service;whole earth 'lectronic link	Miranda Zhang;Rajiv Ranjan;Michael Menzel;Surya Nepal;Peter E. Strazdins;Wei Jie;Lizhe Wang	2017	IEEE Systems Journal	10.1109/JSYST.2015.2427338	computer network;mobile qos;service delivery framework;real-time computing;service catalog;web service;service discovery;computer science;cloud computing;services computing;provisioning	Embedded	-25.531334421847312	64.56815048407996	129298
96720e68b2f20146302604420ddffc63aad13416	a resource scheduling algorithm of cloud computing based on energy efficient optimization methods	energy conservation;cluster energy efficient cloud computing;cluster;energy consumption cloud computing hardware servers scheduling algorithms energy measurement monitoring;energy efficient;resource allocation;resource allocation resource scheduling algorithm energy efficient optimization methods computational architecture ubiquitous services hardware resources software resources resource pool optimized resource utilization energy consumption optimization cloud computing environment energy conservation strategies infrastructure components power consumption task types component power adjustment methods;resource allocation cloud computing energy conservation;cloud computing	Cloud computing has been emerging as a flexible and powerful computational architecture to offer ubiquitous services to users. It accommodates interconnected hardware and software resources in a unified way, which is different to traditional computational environments. A variety of hardware and software resources are integrated together as a resource pool, the software is no longer resided in a single hardware environment, it is performed upon the schedule of the resource pool for optimized resource utilization. The optimization of energy consumption in the cloud computing environment is the question how to use various energy conservation strategies to efficiently allocate resources. In this paper, we study the relationship between infrastructure components and power consumption of the cloud computing environment, and discuss the matching of task types and component power adjustment methods, and then we present a resource scheduling algorithm of Cloud Computing based on energy efficient optimization methods. The experimental results demonstrate that, for jobs that not fully utilized the hardware environment, using our algorithm can significantly reduce energy consumption.	algorithm;cloud computing;mathematical optimization;scheduling (computing)	Liang Luo;Wenjun Wu;Dichen Di;Fei Zhang;Yizhou Yan;Yaokuan Mao	2012	2012 International Green Computing Conference (IGCC)	10.1109/IGCC.2012.6322251	parallel computing;real-time computing;cloud computing;resource allocation;computer science;distributed computing;utility computing	HPC	-20.655598988241184	62.89982287954131	129359
037bbf1b0f1ec6d36e002be16b0c77e69466b14e	an enhanced virtual object management scheme for personalized ubiquitous computing services at peer-to-peer	computers;dht p2p;software;mobility management mobile radio;dht p2p ubiquitous computing middleware virtual object management device description;ubiquitous computing computational modeling peer to peer computing software middleware aerospace electronics computers;virtual reality mobility management mobile radio peer to peer computing ubiquitous computing;virtual reality;p2p;virtual object management;personalized ubiquitous computing services virtual object management peer to peer virtual personal world virtual object discovery user preferences user behavior performance verification p2p networks;performance improvement;computational modeling;aerospace electronics;ubiquitous computing;middleware;p2p networks;peer to peer computing;peer to peer;device description	This paper presents an enhanced virtual object management scheme for a personalized ubiquitous computing service, Virtual Personal World (VPW), at peer-to-peer. In the proposed scheme, more detailed descriptions for virtual objects are added in addition to the existing definitions on communications and data of them, and then two phases of virtual object discovery scheme are applied. Therefore, the management scheme can be individualized more effectively according to users' preferences and behaviors and provide a fast way of finding virtual objects. For performance verification, we have implemented a prototype of the proposed scheme as a part of VPW and compare the speed of finding virtual objects in the proposed scheme with those in other DHT P2P networks. Simulation results shows that the proposed scheme can achieve performance improvements compared with other P2P networks.	distributed hash table;peer-to-peer;personalization;prototype;simulation;ubiquitous computing	Cheong-Ghil Kim;Dong Wook Kim;Choong Pyo Hong;Shin-Dug Kim	2010	2010 International Conference on High Performance Computing & Simulation	10.1109/HPCS.2010.5547056	computer science;operating system;peer-to-peer;middleware;distributed computing;virtual reality;multimedia;computational model;world wide web;ubiquitous computing	HPC	-21.171086739796046	74.48751312149687	129421
970dc906d49e9194a75fa2ffb56afd71a5fdb466	distributed approach to the holistic resource management of a mobile cloud network	telecommunication;kommunikationssystem;fog computing;distributed algorithm;cloud computing	The Mobile Cloud Network is an emerging cost and capacity heterogeneous distributed cloud topological paradigm that aims to remedy the application performance constraints imposed by centralised cloud infrastructures. A centralised cloud infrastructure and the adjoining Telecom network will struggle to accommodate the exploding amount of traffic generated by forthcoming highly interactive applications. Cost effectively managing a Mobile Cloud Network computing infrastructure while meeting individual application's performance goals is non-trivial and is at the core of our contribution. Due to the scale of a Mobile Cloud Network, a centralised approach is infeasible. Therefore, in this paper a distributed algorithm that addresses these challenges is presented. The presented approach works towards meeting individual application's performance objectives, constricting system-wide operational cost, and mitigating resource usage skewness. The presented distributed algorithm does so by iteratively and independently acting on the objectives of each component with a common heuristic objective function. Systematic evaluations reveal that the presented algorithm quickly converges and performs near optimal in terms of system-wide operational cost and application performance, and significantly outperforms similar naïve and random methods.		William Tarneberg;Alessandro Vittorio Papadopoulos;Amardeep Mehta;Johan Tordsson;Maria Kihl	2017	2017 IEEE 1st International Conference on Fog and Edge Computing (ICFEC)	10.1109/ICFEC.2017.10	simulation;engineering;data mining;distributed computing	HPC	-26.54477196710847	62.935992013291525	129813
38a06878a7d2ae423af5d4e1f97fccf625647cc4	extending cometcloud to process dynamic data streams on heterogeneous infrastructures	resource allocation cloud computing petri nets quality of service;failure rate cometcloud dynamic data stream processing heterogeneous infrastructures concurrent data stream processing distributed cloud infrastructure reference net based interpreter petri net coordination action heterogeneous computational resources quality of service requirements workflow interpreter resource allocation deal locating resources execution cost;sensors;data stream;qa75 electronic computers computer science;computational modeling;monitoring;quality of service cloud computing monitoring throughput computational modeling sensors data models;quality of service;data stream quality of service dynamic resource management;dynamic resource management;cloud computing;data models;throughput	Coordination of multiple concurrent data stream processing, carried out through a distributed Cloud infrastructure, is described. The coordination (control) is carried out through the use of a Reference net (a particular type of Petri net) based interpreter, implemented alongside the Comet Cloud system. One of the benefits of this approach is that the model can also be executed directly to support the coordination action. The proposed approach supports the simultaneous processing of data streams and enables dynamic scale-up of heterogeneous computational resources on demand, while meeting the particular quality of service requirements (throughput) for each data stream. We assume that the processing to be applied to each data stream is known a priori. The workflow interpreter monitors the arrival rate and throughput of each data stream, as a consequence of carrying out the execution using Comet Cloud. We demonstrate the use of the control strategy using two key actions - allocating and deal locating resources dynamically based on the number of tasks waiting to be executed (using a predefined threshold). However, a variety of other control actions can also be supported and are described in this work. Evaluation is carried out using a distributed Comet Cloud deployment - where the allocation of new resources can be based on a number of different criteria, such as: (i) differences between sites, i.e. Based on the types of resources supported (e.g. GPU vs. CPU only, FPGAs, etc), (ii) cost of execution, (iii) failure rate and likely resilience, etc.	autonomic computing;central processing unit;computation;computational resource;control theory;dynamic data;executable;failure rate;field-programmable gate array;graphics processing unit;model of computation;non-functional requirement;petri net;queueing theory;reference architecture;software deployment;stream processing;supercomputer;throughput	Rafael Tolosana-Calasanz;Javier Diaz Montes;Omer F. Rana;Manish Parashar	2014	2014 International Conference on Cloud and Autonomic Computing	10.1109/ICCAC.2014.22	real-time computing;computer science;database;distributed computing	HPC	-23.63598531543769	61.83099142058877	130256
4b9767ece618f2b3566844f38fd833eb5859b9f6	implementing a novel load-aware auto scale scheme for private cloud resource management platform	measurement;cloud computing virtual machining measurement monitoring prediction algorithms servers resource management;virtual machining;resource management;prediction algorithms;resource management cloud computing auto scale prediction dynamic scalability openstack;servers;monitoring;cloud computing	Resources dynamical allocation and management is always an important feature in cloud computing. Auto Scale allows users to scale their cloud resources capacity according to elastic loads timely, which has been widely used in mature public cloud. For private cloud, there are some different features from public cloud. It is more flexible to use Auto Scale technique to provide QoS guarantees and ensure system health. In this paper, we design a novel Auto Load-aware Scale scheme for private cloud environment. We describe scale in and scale out strategy based on prediction algorithm. We implement our scheme on OpenStack platform. Both simulation and experiments are carried out to evaluate our work. The experiments show that our scheme has better performance in resource utilization while providing high SLA levels.	algorithm;cloud computing;experiment;quality of service;scalability;service-level agreement;simulation	Jie Bao;ZhiHui Lv;Jie Wu;Shiyong Zhang;YiPing Zhong	2014	2014 IEEE Network Operations and Management Symposium (NOMS)	10.1109/NOMS.2014.6838340	real-time computing;simulation;prediction;cloud computing;computer science;resource management;operating system;cloud testing;world wide web;server;measurement	Embedded	-23.283318083847377	62.20657501263352	130277
90aaeb48b0c7287be1c6881b75d7266ccc8b304f	auto-scaling techniques for elastic data stream processing	learning artificial intelligence algorithm design and analysis engines adaptation models time series analysis stock markets monitoring;big data;big data auto scaling techniques elastic data stream processing system constant overprovisioning	Typical use cases like financial trading or monitoring of manufacturing equipment pose huge challenges regarding end to end latency as well as throughput towards existing data stream processing systems. Established solutions like Apache S4 or Storm need to scale out to a large set of hosts to meet these challenges. An ideal system can react to workload changes by on demand acquisition or release of hosts. Thereby, it can handle unexpected peak loads as well as improve the average utilization of the system. This property is called elasticity. The major challenge for an elastic scaling system is to find the right point in time to scale in or out. To determine this right point is difficult, because it depends on constantly changing system and workload characteristics. In this demonstration, we apply three alternative auto-scaling techniques known from other domains on top of an existing elastic data stream processing system. A user of the demonstration can experience the influence of the chosen auto-scaling technique on the latency and the system utilization using a real-world use case based on different workloads from the Frankfurt stock exchange.		Thomas Heinze;Valerio Pappalardo;Zbigniew Jerzak;Christof Fetzer	2014		10.1109/ICDEW.2014.6818344	real-time computing;simulation;big data;computer science;data mining;database	OS	-24.576116882248755	60.81369663577004	130359
774ac50eeca1c767f6dba778b311d271e82f4692	probabilistic verification of hierarchical leader election protocol in dynamic systems	distributed computing;hierarchical leader election protocol;dynamic systems;probabilistic model checking	Leader election protocols are fundamental for coordination problems—such as consensus—in distributed computing. Recently, hierarchical leader election protocols have been proposed for dynamic systems where processes can dynamically join and leave, and no process has global information. However, quantitative analysis of such protocols is generally lacking. In this paper, we present a probabilistic model checking based approach to verify quantitative properties of these protocols. Particularly, we employ the compositional technique in the style of assume-guarantee reasoning such that the sub-protocols for each of the two layers are verified separately and the correctness of the whole protocol is guaranteed by the assume-guarantee rules. Moreover, within this framework we also augment the proposed model with additional features such as rewards. This allows the analysis of time or energy consumption of the protocol. Experiments have been conducted to demonstrate the effectiveness of our approach.	communications protocol;consensus (computer science);control system;correctness (computer science);distributed computing;dynamical system;experiment;formal verification;holism;leader election;model checking;routing;statistical model	Yu Zhou;Nvqi Zhou;Tingting Han;Jiayi Gu;Weigang Wu	2018	Frontiers of Computer Science	10.1007/s11704-018-6173-6	dynamical system;machine learning;artificial intelligence;correctness;computer science;probabilistic logic;theoretical computer science;statistical model;leader election	Logic	-29.772008440553645	70.5551050901382	130856
293110cfba05e29c7ccccf1d3698d780c7fb3e67	an integrated dynamic resource scheduling framework in on-demand clouds		The biggest advantage of employing virtualization in cloud is the ability to provision resource flexibly which makes “pay-as-use” model possible. However, since the workload of virtual machine constantly changes, it is still a challenge that efficiently schedule resource by migrating virtual machines among lots of hosts, especially with multi-objective to meet, like power and QoS constraints. In this paper, we present a dynamic resource scheduling solution, named Smart-DRS, which can well determines when to schedule, which to schedule, and where to schedule. It is an integrated framework that aims to deal well with hotspot mitigation, load balancing and server consolidation which are classic problems to solve in on-demand clouds. The experimental results show that our framework strikes a balance between efficiency, overhead and instantaneity.	accessible surface area;algorithm;computation;dspace;data center;load balancing (computing);mathematical optimization;overhead (computing);quality of service;scalability;scheduling (computing);semiconductor consolidation;server (computing);virtual machine	Lei Xu;Zonghui Wang;Wenzhi Chen	2014	J. Inf. Sci. Eng.			HPC	-19.923788275540634	62.94006529691633	130986
0a9de15a37c6b7b5a933e5270829530d0b53aa7d	energy-aware online scheduling: ensuring quality of service for iaas clouds	power consumption minimization energy aware online scheduling quality of service iaas cloud infrastructure as a service cloud computing energy efficient algorithms job execution time slack factor income maximization;power demand resource management measurement quality of service educational institutions energy efficiency processor scheduling;scheduling cloud computing energy conservation power aware computing quality of service;scheduling cloud computing service level agreement energy efficiency	This work focuses on the analysis of energy-efficient algorithms for online scheduling in the Infrastructure as a Service (IaaS) type of Cloud computing. The scheduling model is based on service levels that guarantee the quality of service. Each service level is associated to a price per unit of job execution time and a slack factor, which determines the deadline for delivering the results. Once a batch job is submitted to the system, the provider has to decide whether the arriving job can be accepted or must be rejected and processed on external resources. The system maintains the quality of service guarantees for all already accepted jobs. After proposing an original formulation of the problem, we study various schedulers that provide good compromise between income maximization and power consumption minimization. Our experiments and analysis have shown that we can generate schedules with power consumption reduction without degrading the service quality.	batch processing;cloud computing;expectation–maximization algorithm;experiment;quality of service;run time (program lifecycle phase);schedule (computer science);scheduling (computing);slack variable;tag cloud	Andrei Tchernykh;Luz Lozano;Pascal Bouvry;Johnatan E. Pecero;Uwe Schwiegelshohn;Sergio Nesmachnow	2014	2014 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCSim.2014.6903786	service level requirement;real-time computing;dynamic priority scheduling;distributed computing;least slack time scheduling;data as a service	HPC	-19.260938337822502	62.607918032132744	131053
1cdd5670a0c9cbf4656554f739e576c95b3481ac	caesara - combined architecture for energy saving by auto-adaptive resource allocation		Energy consumption of data centers increased continously during the last decades. As current techniques for improving their energy efficiency are usually limited to one type of data center components, it is difficult to employ them for a holistic optimization which may utilize synergies between all components. This paper introduces architecture and working principles of the novel energy management system CAESARA that applies a holistic view for evaluating an energy-efficient virtual machine placement in current virtualization environments for minimizing the number of running energy-consuming physical machines. In contrast to existing solutions, our placement algorithm does not only aggregate load to a minimum number of servers it also discovers which servers act as most energy-efficient migration targets in conjunction with their environment (e.g. their cooling equipment). This paper presents the architecture of CAESARA and defines properties for an energy-efficient virtual machine placement algorithm. As the placement algorithm uses an energy-aware metric, it is the basis for an innovative system, which may optimize the energy efficiency of data centers in a holistic way by including any infrastructural energy consumption.	aggregate data;computer cooling;data center;greedy algorithm;heuristic;holism;local optimum;mathematical optimization;np-completeness;synergy;synthetic intelligence;value (ethics);virtual machine	Daniel Versick;Djamshid Tavangarian	2013			real-time computing;architecture;virtualization;data center;efficient energy use;server;energy consumption;computer science;virtual machine;resource allocation	PL	-20.72188037517069	63.15683863225363	131141
e514f6eb0f1262f33f4330e5cd0c767ee45cd368	autonomic management of application workflows on hybrid computing infrastructure	application management;application heterogeneity;application state;application objective;hybrid computing infrastructure;appropriate mix;complex application workflows;autonomic management;runtime framework;high-end hpc system;autonomic system;application requirement	In this paper, we present a programming and runtime framework that enables the autonomic management of complex application workflows on hybrid computing infrastructures. The framework is designed to address system and application heterogeneity and dynamics to ensure that application objectives and constraints are satisfied. The need for such autonomic system and application management is becoming critical as computing infrastructures become increasingly heterogeneous, integrating different classes of resources from high-end HPC systems to commodity clusters and clouds. For example, the framework presented in this paper can be used to provision the appropriate mix of resources based on application requirements and constraints. The framework also monitors the system/application state and adapts the application and/or resources to respond to changing requirements or environment. To demonstrate the operation of the framework and to evaluate its ability, we employ a workflow used to characterize an oil reservoir executing on a hybrid infrastructure composed of TeraGrid nodes and Amazon EC2 instances of various types. Specifically, we show how different applications objectives such as acceleration, conservation and resilience can be effectively achieved while satisfying deadline and budget constraints, using an appropriate mix of dynamically provisioned resources. Our evaluations also demonstrate that public clouds can be used to complement and reinforce the scheduling and usage of traditional high performance computing infrastructure.	amazon elastic compute cloud (ec2);application lifecycle management;autonomic computing;central processing unit;computational model;experiment;greedy algorithm;requirement;scheduling (computing);state (computer science);supercomputer;teragrid	Hyunjoo Kim;Yaakoub El Khamra;Ivan Rodero;Shantenu Jha;Manish Parashar	2011	Scientific Programming	10.3233/SPR-2011-0319	real-time computing;simulation;cloud computing;computer science;operating system;distributed computing;utility computing;autonomic computing	HPC	-26.591355178847095	60.84941969274106	131451
74e6710188e3deeee13304c10e2e93dc1e807998	offloading in internet of vehicles: a fog-enabled real-time traffic management system		Fog computing has been merged with Internet of Vehicle (IoV) systems to provide computational resources for end users, by which low latency can be guaranteed. In this paper, we put forward a feasible solution that enables offloading for real-time traffic management in fog-based IoV systems, aiming to minimize the average response time for events reported by vehicles. First, we construct a distributed city-wide traffic management system, in which vehicles close to road side units can be utilized as fog nodes. Then, we model parked and moving vehicle-based fog nodes according to a queueing theory, and draw the conclusion that moving vehicle-based fog nodes can be modeled as an $M/M/1$ queue. An approximate approach is developed to solve the offloading optimization problem by decomposing it into two subproblems and scheduling traffic flows among different fog nodes. Performance analyses based on a real-world taxi-trajectory datasets are conducted to illustrate the superiority of our method.	approximation algorithm;computational resource;fog computing;internet;management system;mathematical optimization;optimization problem;queueing theory;real-time clock;real-time transcription;response time (technology);scheduling (computing);trajectory optimization	Xiaojie Wang;Zhaolong Ning;Lei Wang	2018	IEEE Transactions on Industrial Informatics	10.1109/TII.2018.2816590	the internet;computer science;real-time computing;response time;scheduling (computing);latency (engineering);cloud computing;queueing theory;edge computing;server	Metrics	-22.554077650405826	68.119161041642	131729
a7c77538a96c6caaa897a48479156d6e7cf67b21	mobility management for untethered immersive communications	radio links mobility management mobile radio multimedia communication;mobility management mobile radio;wireless devices;mobile device;selected works;mobile wireless device;layout;wireless communication;multimedia immersive communication;streaming media;system design;games;multimedia communication;mobile communication;mobility management;avatars;bepress;power consumption;peer to peer computing;virtual environment;link capacity;multimedia immersive communication mobile wireless device link capacity power consumption mobility management;mobile radio mobility management;mobile radio mobility management streaming media avatars layout mobile communication virtual environment wireless communication delay peer to peer computing games;radio links	In this paper we propose a system design for delivery of immersive communications to mobile wireless devices based on a distributed proxy model. It is demonstrated that this architecture addresses key technical challenges for the delivery of these services, that is, constraints on link capacity and power consumption in mobile devices. However, additional complexity is introduced with respect to mobility management. The paper proposes three possible methods for updating proxy assignments in response to mobility and compares the performance of these methods	mobile device;mobile phone;systems architecture;systems design	Mehran Dowlatshahi;Farzad Safaei	2006	2006 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2006.262755	layout;games;mobile telephony;telecommunications;computer science;virtual machine;operating system;mobile device;multimedia;mobility model;wireless;computer network;systems design	Robotics	-22.825395455516777	74.36739399322343	131989
ea448446d574c164d08a1349c60b730830dad0c4	towards cloud sensing enabled target localization	wireless sensor networks cloud computing;cost accounting wireless sensor networks sensors integrated circuits vectors bayes methods games;wsn cloud sensing enabled target localization sensing as a service wireless sensor networks bilateral trading mechanism sensing service provider fusion center sensor management resource costs service provisioning expected total gain incentive compatibility information gain	In this paper, we introduce “cloud sensing” as a paradigm for enabling sensing-as-a-service in the context of target localization in wireless sensor networks (WSNs). We present a bilateral trading mechanism consisting of a sensing service provider (fusion center) that “sells” information regarding the target through sensor management, and a user who seeks to “buy” information regarding the target. Our mechanism, aware of resource costs involved in service provisioning, maximizes the expected total gain from the trade while assuring individual rationality and incentive compatibility. The impossibility of achieving ex post efficiency is also shown in the paper. Design of the mechanism enables the study of the tradeoff between information gain and the costs of the WSN for sensor management. Simulation results provide insights into the dynamics of the proposed model.	bilateral filter;experiment;internationalization and localization;kullback–leibler divergence;multi-user;programming paradigm;provisioning;rationality;simulation	Nianxia Cao;Swastik Brahma;Pramod K. Varshney	2014	2014 52nd Annual Allerton Conference on Communication, Control, and Computing (Allerton)	10.1109/ALLERTON.2014.7028501	simulation;engineering;key distribution in wireless sensor networks;computer security;computer network	Robotics	-27.555765168921244	71.81206275570841	132098
913fdff94a31861b9eaf9d35b895aebe5fb3f47a	popf: a consensus algorithm for jcledger		JointCloud is a new generation of cloud computing model which facilitates developers to customize cloud services. JCLedger is a blockchain based distributed ledger for JointCloud computing which can make cloud resources exchange more reliable and convenient, and it is the combination of JointCloud and BlockChain. One of the most important elements for creating JCLedger is the consensus algorithm. PoW (Proof of Work) is the consensus algorithm for Bitcoin, which is proved to be quite safe but needs much computing power. The original PoW is not suitable for JCLedger because the identities of participants are not equal in computing power, which may lead to accounting monopoly, and the throughput cannot satisfy the requirement of the massive and high-frequency transactions in JointCloud. In this paper, we propose a PoW based consensus algorithm called Proof of Participation and Fees (PoPF), which can save much computing power and handled transactions more efficiently for JCLedger. In our design, only the candidates have the opportunities for mining and the candidates are chosen according to the ranking which is determined by two factors: the times of the participant to be the accountant and the fees the participant has paid. The difficulty for candidates of solving the PoW hash puzzle is different (the higher ranking means easier for mining). The simulation experiment shows that the distribution of accountants is well-balanced, that is to say, the unequal computing power of participants in JointCloud is shielded, and all the users who have enough contribution in JCLedger will have the opportunities to be accountants.	bitcoin;chandra–toueg consensus algorithm;cloud computing;monopoly;proof-of-work system;prospective search;simulation;smart contract;the times;throughput	Xiang Fu;Huaimin Wang;Peichang Shi;Haibo Mi	2018	2018 IEEE Symposium on Service-Oriented System Engineering (SOSE)	10.1109/SOSE.2018.00034	throughput;proof-of-work system;cloud computing;hash function;distributed ledger;monopoly;blockchain;distributed computing;algorithm;computer science;ranking	SE	-26.94566337787247	73.00854388370455	132498
71ee40f804638d7a0a6a49c071e314f9aebd0b8e	modelling performance & resource management in kubernetes	analytical models;capacity management;virtual machining;microbilling;computational modeling;monitoring;petri nets;containers;cloud computing;qa76 computer software	Containers are rapidly replacing Virtual Machines (VMs) as the compute instance of choice in cloud-based deployments. The significantly lower overhead of deploying containers (compared to VMs) has often been cited as one reason for this. We analyse performance of the Kubernetes system and develop a Reference net-based model of resource management within this system. Our model is characterised using real data from a Kubernetes deployment, and can be used as a basis to design scalable applications that make use of Kubernetes.	cloud computing;overhead (computing);scalability;software deployment	Victor Medel Gracia;Omer F. Rana;José A. Bañares;Unai Arronategui	2016	2016 IEEE/ACM 9th International Conference on Utility and Cloud Computing (UCC)	10.1145/2996890.3007869	embedded system;real-time computing;simulation;cloud computing;computer science;operating system;capacity management;computational model;petri net	HPC	-24.000913460830375	62.33961934944303	132834
0ec08c4f4d81c98da398b15d2b1309b5e075116f	improving resource utilisation in the cloud environment using multivariate probabilistic models	resource management vectors cloud computing heuristic algorithms gaussian distribution mathematical model algorithm design and analysis;probability;resource allocation;resource management;amazon ec2 resource utilisation cloud environment multivariate probabilistic models resource provisioning virtual machine vm cloud computing environments static scheduling approaches physical machines pm heuristics metrics ic cloud;computer architectures operating systems;vectors;virtual machines;heuristic algorithms;mathematical model;algorithms;heuristics;resource management algorithms cloud computing heuristics resource allocation;algorithm design and analysis;gaussian distribution;virtual machines cloud computing probability resource allocation;cloud computing	Resource provisioning based on virtual machine (VM) has been widely accepted and adopted in cloud computing environments. A key problem resulting from using static scheduling approaches for allocating VMs on different physical machines (PMs) is that resources tend to be not fully utilised. Although some existing cloud reconfiguration algorithms have been developed to address the problem, they normally result in high migration costs and low resource utilisation due to ignoring the multi-dimensional characteristics of VMs and PMs. In this paper we present and evaluate a new algorithm for improving resource utilisation for cloud providers. By using a multivariate probabilistic model, our algorithm selects suitable PMs for VM re-allocation which are then used to generate a reconfiguration plan. We also describe two heuristics metrics which can be used in the algorithm to capture the multi-dimensional characteristics of VMs and PMs. By combining these two heuristics metrics in our experiments, we observed that our approach improves the resource utilisation level by around 8% for cloud providers, such as IC Cloud, which accept user-defined VM configurations and 14% for providers, such as Amazon EC2, which only provide limited types of VM configurations.	algorithm;amazon elastic compute cloud (ec2);cloud computing;experiment;heuristic (computer science);lisp machine;provisioning;scheduling (computing);simulation;statistical model;virtual machine	Sijin He;Li Guo;Moustafa Ghanem;Yike Guo	2012	2012 IEEE Fifth International Conference on Cloud Computing	10.1109/CLOUD.2012.66	normal distribution;algorithm design;real-time computing;simulation;cloud computing;resource allocation;computer science;virtual machine;resource management;operating system;heuristics;probability;mathematical model;distributed computing	HPC	-22.054531744788722	62.58020433192307	133044
260c1e001a0077f30b09d0ec4f27278175722721	self-awareness for heterogeneous mpsocs: a case study using adaptive, reflective middleware		Self-awareness has a long history in biology, psychology, medicine, engineering and (more recently) computing. In the past decade this has inspired new self-aware strategies for emerging computing substrates (e.g., complex heterogeneous MPSoCs) that must cope with the (often conflicting) challenges of resiliency, energy, heat, cost, performance, security, etc. in the face of highly dynamic operational behaviors and environmental conditions. Earlier we had championed the concept of CyberPhysical-Systems-on-Chip (CPSoC), a new class of sensor-actuator rich many-core computing platforms that intrinsically couples on-chip and cross-layer sensing and actuation to enable self-awareness. Unlike traditional MPSoCs, CPSoC is distinguished by an intelligent co-design of the control, communication, and computing (C3) system that interacts with the physical environment in real-time in order to modify the system's behavior so as to adaptively achieve desired objectives and Quality-of-Service (QoS). The CPSoC design paradigm enables self-awareness (i.e., the ability of the system to observe its own internal and external behaviors such that it is capable of making judicious decision) and (opportunistic) adaptation using the concept of cross-layer physical and virtual sensing and actuations applied across different layers of the hardware/software system stack. The closed loop control used for adaptation to dynamic variation -- commonly known as the observe-decide-act (ODA) loop -- is implemented using an adaptive, reflective middleware layer.  In this talk I will present a case study of this adaptive, reflective middleware layer using a holistic approach for performing resource allocation decisions and power management by leveraging concepts from reflective software. Reflection enables dynamic adaptation based on both external feedback and introspection (i.e., self-assessment). In our context, this translates into performing resource management actuation considering both sensing information (e.g., readings from performance counters, power sensors, etc.) to assess the current system state, as well as models to predict the behavior of other system components before performing an action. I will summarize results leveraging our adaptive-reflective middleware toolchain to i) perform energy-efficient task mapping on heterogeneous architectures, ii) explore the design space of novel HMP architectures, and iii) extend the lifetime of mobile devices.	holism;host media processing;introspection;manycore processor;middleware;mobile device;power management;programming paradigm;quality of service;real-time clock;self-awareness;sensor;software system;system on a chip;toolchain;unconventional computing	Nikil D. Dutt	2018		10.1145/3194554.3200203	power management;real-time computing;resource management;software system;toolchain;quality of service;computer science;software;resource allocation;middleware	Mobile	-29.872939662923102	61.25115749816506	133107
6ed7f6aeedcb88b024791705e77d3e075b92d065	energy efficient algorithm for vnf placement and chaining		This paper addresses energy efficient VNF placement and chaining over NFV enabled infrastructures. VNF placement and chaining are formulated as a decision tree search to overcome this NP-Hard problem complexity. The proposed approach is an extension of the Monte Carlo Tree Search(MCTS) method to achieve energy savings using physical resourceconsolidation and sharing VNFs between multiple tenants. A realcloud testbed and extensive simulations are used to assessperformance and ability to scale with problem size. Evaluationresults show significant reduction in energy consumption of theproposed placement solution compared to related work. The polynomialcomplexity of our proposal is highlighted by the simulation results.	algorithm;analysis of algorithms;cloud computing;data center;decision tree;monte carlo tree search;np-hardness;network function virtualization;performance evaluation;scalability;semiconductor consolidation;simulation;testbed	Oussama Soualah;Marouen Mechtri;Chaima Ghribi;Djamal Zeghlache	2017	2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)	10.1109/CCGRID.2017.84	distributed computing;real-time computing;cloud computing;decision tree;efficient energy use;computer science;energy consumption;testbed;server;chaining;monte carlo tree search	EDA	-20.48021138549259	63.76064996863493	133835
9bf302e4c90ec080b4907a7dd495e1970a3d964c	a workflow scheduling method for cloudlet management in mobile cloud		Cloudlet has emerged as a new paradigm to improve the ability to perform complex computations in mobile cloud computing. However, cloudlet suffers from the challenge of inefficient resource utilization as most of the times it operates below optimum resource utilization conditions. This results in waste of vital resources and increase in computation cost. So keeping in view this challenge, in this paper, a Workflow Scheduling Method (WSM) for cloudlet is proposed, which leverages Genetic Algorithm (GA) for efficient work flow tasks scheduling. Extensive experiments are performed to compare WSM with state of the art work flow task management method MCGA and Benchmark algorithm GA. Experimental evaluation shows that WSM outperforms both techniques and reduce the time cost of workflows and optimize the resource utilization of the cloudlet.		Jie Zhang;Lianyong Qi;Yuan Yuan;Xiaolong Xu;Wan-Chun Dou	2018	2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)	10.1109/SmartWorld.2018.00167	task management;distributed computing;genetic algorithm;computer science;mobile cloud computing;computation;scheduling (computing);cloud computing;workflow;cloudlet	HPC	-19.12187000995201	63.035360500626844	133849
5dab3b579b7a4c5add6e32446f0f01864b5963a8	communication protocols for secure distributed computation of binary functions	tratamiento paralelo;computadora;traitement parallele;ordinateur;distributed processing;communication complexity;distributed computing;complexite communication;partial information;computer;parallel computation;network topology;calculateur processus;calculo paralelo;calculo repartido;communication protocol;calculador proceso;process computer;topologie circuit;calcul parallele;traitement reparti;calcul reparti;parallel processing;tratamiento repartido	A common task in parallel processing is the distributed computation of a function by a number of processors, each of which possesses partial information relevant to the value of that function. In this paper we develop communication protocols which allow for such computation to take place while maintaining the value of the function secret to an eavesdropper. Of interest is the communication complexity of such protocols. We begin by considering two processors and two channels, one secret and one public, and present a protocol which minimizes the number of bits exchanged over the secret channel, while maintaining =-uncertainty about the value of the function for the eavesdropper. We show that all binary functions can be kept =-secret using a constant number of bits independent of the size of their domain. We then generalize our results to N processors communicating over a network of arbitrary topology. ] 2000 Academic Press	central processing unit;communication complexity;communications protocol;computation;distributed computing;parallel computing	Eytan Modiano;Anthony Ephremides	2000	Inf. Comput.	10.1006/inco.2000.2865	communications protocol;parallel processing;computer science;theoretical computer science;communication complexity;distributed computing;secure multi-party computation;network topology;algorithm	Theory	-30.768813740744097	72.96222891484976	134016
4ddd2f497000da29b7e44007ce516d2c8d6c9513	edge cognitive computing based smart healthcare system		Abstract With the rapid development of medical and computer technologies, the healthcare system has seen a surge of interest from both the academia and industry. However, most healthcare systems fail to consider the emergency situations of patients, and are unable to provide a personalized resource service for special users. To address this issue, in this paper, we propose the Edge-Cognitive-Computing-based (ECC-based) smart-healthcare system. This system is able to monitor and analyze the physical health of users using cognitive computing. It also adjusts the computing resource allocation of the whole edge computing network comprehensively according to the health-risk grade of each user. The experiments show that the ECC-based healthcare system provides a better user experience and optimizes the computing resources reasonably, as well as significantly improving in the survival rates of patients in a sudden emergency.	cognitive computing	Min Chen;Wei Li;Yixue Hao;Yongfeng Qian;Iztok Humar	2018	Future Generation Comp. Syst.	10.1016/j.future.2018.03.054	real-time computing;distributed computing;health care;user experience design;computer science;resource allocation;edge computing;cognitive computing	HPC	-23.38927993874763	68.49898256905661	134025
4872601165e1f27dae7707e36e40ce539b227bfb	a workload-aware energy model for virtual machine migration	vm migration;data centre energy consumption workload aware energy model virtual machine migration vm migration;memory management;virtual machining;linear regression;computational modeling;energy consumption;energy consumption power demand memory management computational modeling virtual machining predictive models hardware;energy aware computing;predictive models;virtual machines computer centres power aware computing;energy aware computing vm migration linear regression;power demand;hardware	Energy consumption has become a significant issue for data centres. Assessing their consumption requires precise and detailed models. In the latter years, many models have been proposed, but most of them either do not consider energy consumption related to virtual machine migration or do not consider the variation of the workload on (1) the virtual machines (VM) and (2) the physical machines hosting the VMs. In this paper, we show that omitting migration and workload variation from the models could lead to misleading consumption estimates. Then, we propose a new model for data centre energy consumption that takes into account the previously omitted model parameters and provides accurate energy consumption predictions for paravirtualised virtual machines running on homogeneous hosts. The new model's accuracy is evaluated with a comprehensive set of operational scenarios. With the use of these scenarios we present a comparative analysis of our model with similar state-of-the-art models for energy consumption of VM Migration, showing an improvement up to 24% in accuracy of prediction.	central processing unit;data center;manycore processor;multi-core processor;qualitative comparative analysis;semiconductor consolidation;simulation;virtual machine;z/vm	Vincenzo De Maio;Gabor Kecskemeti;Radu Prodan	2015	2015 IEEE International Conference on Cluster Computing	10.1109/CLUSTER.2015.47	embedded system;parallel computing;real-time computing;computer hardware;computer science;linear regression;operating system;predictive modelling;computational model;memory management	HPC	-21.126040431020375	61.3414136658104	134981
b0240196e384efe7c490d7c9791d9b8f0c4908ca	espm: an optimized resource distribution policy in virtual user environment	virtual machine;resource utilization;queuing model;multi resource load balancing;system performance;desktop virtualization;user requirements;load balance;migration policy	Desktop virtualization technology offers powerful opportunities to deliver and manage desktops and to respond to various user requirements based on virtual clusters. The optimization of resource distribution has become a hot topic, when virtual machines substitute the traditional tasks in the cluster. Virtual User Environment (VUE) is our implementation based on the concept of Virtual Desktop Infrastructure (VDI). This paper describes the ESPM (Expanding, Squeezing, Placement and Migration) policy to increase the resource utilization of the virtual cluster and shorten the response time of users in rush hours in VUE. The expanding policy aims to expand the coverage of service when users flood into the system; the squeezing policy aims to maintain the resource utilization at a high level; the placement and migration policy solve the multi-resource load balancing problem in order to achieve better system performance. Experiments and simulations show the good performance of ESPM. © 2010 Elsevier B.V. All rights reserved.	desktop virtualization;experiment;greedy algorithm;high-level programming language;load balancing (computing);moe;mathematical optimization;np-hardness;performance tuning;requirement;response time (technology);simulation;user interface;user requirements document;virtual desktop;virtual machine;x86 virtualization	Xiaofei Liao;Hai Jin;Xiaojie Yuan	2010	Future Generation Comp. Syst.	10.1016/j.future.2010.06.001	in situ resource utilization;parallel computing;real-time computing;simulation;computer science;virtual machine;load balancing;user requirements document;operating system;database;distributed computing;computer performance;computer security	HPC	-19.816496031128874	62.45455510373445	135004
221d89a43e64347296a44bf0ec4e570dc2cd56d7	help me: opportunistic smart rescue application and system	disaster recovery;dictionaries servers availability ad hoc networks databases middleware routing;wireless lan disasters emergency services middleware mobile ad hoc networks pattern classification pattern matching smart phones web services;opportunistic networks;smart phones;self learning applications;mobile ad hoc networks;pattern matching;web services;pattern classification;disaster recovery opportunistic networks ad hoc applications self learning applications;ad hoc applications;middleware;wireless lan;ipad application disaster survivors rescue forces critical communication infrastructures self learning opportunistic ad hoc system smartphone based ad hoc communications wi fi helpme smartphone peers transparent on the fly requests classification transparent on the fly requests matching smart forwarding hop by hop basis power conservative manner haggle middleware neighbor discovery interest based forwarding iphone application helpme cloud based server user profiling user personalized apps creation missing persons services web service;disasters;emergency services	Communicating during disaster times is crucial for both survivors and rescue forces. While fast reaction is critical communication infrastructures, wired and cellular, are often lost, and cannot be restored in a timely fashion. In this paper we present HelpMe, a self learning opportunistic ad-hoc system, which enables smartphone-based ad-hoc communications at disaster times over Wi-Fi. HelpMe smartphone peers communicate using a sophisticated mechanism that performs a transparent on-the-fly classification and matching of requests to peers in the formed opportunistic ad-hoc network. Matching is further leveraged for a smart forwarding, enabling the request to reach the best matching user in the vicinity. Our system enables best peers matching across an opportunistic ad-hoc network on a hop-by-hop basis, in a timely and power conservative manner. Location coordinates are sent with each request. The client is built on top of the Haggle middleware, leveraging its neighbor discovery and interest-based forwarding. The HelpMe client is fully implemented as an iPhone application on top of the Haggle middleware. The HelpMe system consists also of a HelpMe cloud-based server, used only when communication is available before and after the crisis. The server is used for profiling users and creating personalized apps for the users. When communication is restored, it can be leveraged for collecting information for missing persons services. The server is implemented as a web service. We tested the system using several iPhone / iPad clients communicating over Wi-Fi and showed that our settings not only enable a best match, but also enable willing users to become hub nodes in the formed opportunistic network. The system is self-adjusting and supports on the fly settings modifications.	algorithm;cloud computing;dictionary;hoc (programming language);hop-by-hop transport;location-based service;middleware;on the fly;personalization;profiling (computer programming);routing;server (computing);smartphone;usb hub;web service;ipad	Osnat Mokryn;Dror Karmi;Akiva Elkayam;Tomer Teller	2012	2012 The 11th Annual Mediterranean Ad Hoc Networking Workshop (Med-Hoc-Net)	10.1109/MedHocNet.2012.6257129	engineering;internet privacy;world wide web;computer network	Mobile	-19.933388642440203	72.08865429621846	135399
e1ed225212ff51039906ea054a9940cf33ee10e7	a predictive method for identifying optimum cloud availability zones	availability predictive models vectors quality of service training data models;predictive analytics;cloud;availability zones;multiple data centers;performance analysis;unpublished zone behavior prediction optimum cloud availability zones cloud service providers business applications quality of service qos;performance analysis availability zones multiple data centers cloud predictive analytics;quality of service business data processing cloud computing	Cloud service providers enable enterprises with the ability to place their business applications into availability zones across multiple locations worldwide. While this capability helps achieve higher availability with smaller failure rates, business applications deployed across these independent zones may experience different Quality of Service (QoS) due to heterogeneous physical infrastructures. Since the perceived QoS against specific requirements are not usually advertised by cloud providers, selecting an availability zone that would best satisfy the user requirements is a challenge. In this paper, we introduce a predictive approach to identify the cloud availability zone that maximizes satisfaction of an incoming request against a set of requirements. The predictive models are built from historical usage data for each availability zone and are updated as the nature of the zones and requests change. Simulation results show that our method successfully predicts the unpublished zone behavior from historical data and identifies the availability zone that maximizes user satisfaction against specific requirements.	computer user satisfaction;experiment;machine learning;predictive modelling;quality of service;requirement;selection (genetic algorithm);simulation;software analytics;usage data;user requirements document	Merve Unuvar;Yurdaer N. Doganata;Malgorzata Steinder;Asser N. Tantawi;Stefania Tosi	2014	2014 IEEE 7th International Conference on Cloud Computing	10.1109/CLOUD.2014.20	predictive analytics;cloud computing;computer science;operating system;data mining;computer security	Visualization	-23.7743178837181	63.71546677290074	135478
663aef84d4fb2d534b4bce9d5a2309c3be5099c6	towards distributed software-defined environments		Service-based access models coupled with recent advances in application deployment technologies can support emerging dynamic and data-driven applications. However, due to evolving application requirements and the dynamicity of the underlying resources, it is necessary to support flexible and opportunistic composition of services in order to satisfy application needs. The goal of this work is to provide a programmable and dynamic framework that can support these applications. The framework uses software-defined environment concepts to drive the process of dynamically composing infrastructure services from multiple providers. The resulting distributed software-defined environment autonomously evolves over the application life cycle while meeting objectives and constraints set by the users, applications, and/or resource providers. We present two different approaches for programming resources and controlling the composition process, one that is based on a rule engine and another that leverages constraint programming. Preliminary results demonstrate the framework operation and performance using simulations and real experiments running Docker containers across multiple clouds.	business rules engine;constraint programming;distributed computing;docker;ecosystem;experiment;real-time clock;real-time computing;requirement;scheduling (computing);service composability principle;simulation;software deployment	Moustafa AbdelBaky;Javier Diaz Montes;Manish Parashar	2017	2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)		software deployment;software development;distributed computing;resource management;real-time computing;software framework;constraint programming;computer science;dynamic priority scheduling;software;application lifecycle management	HPC	-26.63477149938233	61.88533481452374	135570
daea3aa2c4f85a0d97030a3a668629bb91702e5f	data integrity analysis of disk array systems with analytic modeling of coverage	modelizacion;system reliability;disk arrays;fiabilidad;reliability;fiabilite systeme;storage system;data integrity;analisis sistema;analisis datos;availability;taux erreur;disponibilidad;raid;sistema informatico;integrite;computer system;integridad;failure mode;capacite stockage;power supply;fiabilidad sistema;modelisation;data analysis;fault tolerant system;integrity;capacidad almacenaje;almacenamiento;storage capacity;fiabilite;systeme memoire;dependability;defaillance;stockage;sistema tolerando faltas;system analysis;error rate;analyse donnee;systeme tolerant les pannes;systeme informatique;analyse systeme;failures;indice error;sistema memoria;modeling;disponibilite;storage;fallo;analytical model;disk array	Detailed dependability models of various disk array organizations are developed taking into account both the hard disk failures and transient errors. Various error and failure modes of individual disks and the disk array are identified. A small proportion of transient errors account for uncovered failures in a disk array. This leads to analytic computation of probability of disk failures based on several factors including byte error rate of a disk and ECC code etc. Traditionally used measures like M’ITDL and data availability remain virtually unchanged with change in mean recovery time. New dependability measures such as degraded capacity time are considered to bring out the effect of mean recovery time on dependability of disk arrays. Our analysis also reveals that mirrored disk organization has higher MlTDL than other disk array organizations if the only failure mode considered is data loss while catastrophic errors are ignored. However, if catastrophic errors are taken into account, then RAID-3,4,5 organizations have higher data-integrity than other disk array schemes. We also develop models that take into account the reliability of support hardware components and different placement schemes for arranging support hardware such as power supply. Our analysis reveals that RAID-l benefits the most from orthogonal placement of support hardware.	byte;coat of arms;computation;computer cooling;consistency model;data integrity;dependability;disk array;disk storage;elegant degradation;failure cause;failure rate;hard disk drive;host adapter;ibm research - almaden;overhead (computing);power supply;qr code;scalability;standard raid levels	Manish Malhotra;Kishor S. Trivedi	1995	Perform. Eval.	10.1016/0166-5316(93)E0041-3	embedded system;real-time computing;disk array;computer science;operating system;computer security	OS	-33.19258086800327	65.62041330464683	135814
44d928c5988f84520d002e2550097376b3e74346	commensal cuckoo: secure group partitioning for large-scale services	distributed hash table;large scale system;large scale	We present commensal cuckoo,* a secure group partitioning scheme for large-scale systems that maintains the correctness of many small groups, despite a Byzantine adversary that controls a constant (global) fraction of all nodes. In particular, the adversary is allowed to repeatedly rejoin faulty nodes to the system in an arbitrary adaptive manner, e.g., to collocate them in the same group. Commensal cuckoo addresses serious practical limitations of the state-ofthe- art scheme, the cuckoo rule of Awerbuch and Scheideler, tolerating 32x--41x more faulty nodes with groups as small as 64 nodes (as compared to the hundreds required by the cuckoo rule). Secure group partitioning is a key component of highly-scalable, reliable systems such as Byzantine faulttolerant distributed hash tables (DHTs).	adversary (cryptography);collocation;correctness (computer science);distributed hash table;scalability	Siddhartha Sen;Michael J. Freedman	2012	Operating Systems Review	10.1145/2146382.2146389	real-time computing;computer science;chord;theoretical computer science;cuckoo hashing	Security	-31.74707695207534	67.93967472714883	135958
d2ac2dcdaadbcc7b47e673485d7d0531c94bfd8d	computation-and-storage-efficient key tree management protocol for secure multicast communications	estensibilidad;informatica movil;distributed system;largeur bande;gestion memoire;systeme reparti;confidencialidad;mise a jour;informatique mobile;key tree management;mobile device;protocole transmission;data integrity;batch production;resource allocation;integrite donnee;structure arborescente;storage management;metodo arborescente;storage structure;securite informatique;resource management;multidestinatario;procede discontinu;metric;indice aptitud;confidentiality;actualizacion;computer security;indice aptitude;confidentialite;gestion recursos;protocolo transmision;gestion memoria;sistema repartido;produccion por lote;estructura arborescente;capability index;criptografia;cryptography;seguridad informatica;tree structure;anchura banda;production par lot;security key;batch process;communication cost;gestion ressources;bandwidth;cryptographie;tree structured method;procedimiento discontinuo;metrico;estructura memoria;methode arborescente;extensibilite;structure memoire;scalability;asignacion recurso;group key management;allocation ressource;cle securite;mobile computing;secure multicast;data confidentiality;multidestinataire;metrique;updating;multicast;llave seguridad;transmission protocol	In secure multicast communication, group key management plays an essential role for the guarantee of data confidentiality and integrity. Because communication bandwidth is a limited resource, most group key management schemes for scalable secure multicast communications have focused on reducing the number of update messages, i.e., communication cost. To alleviate the scalability problem, a key tree structure was proposed and many group key management schemes have since adopted this approach. Though a key tree structure reduces communication cost, it often requires, as a tradeoff, a more powerful computing capability for executing several cryptography algorithms and having enough storage for various kinds of keys, i.e., computation cost and storage cost, respectively. However, in mobile devices with limited computation power and storage space, it is crucial to minimize simultaneously the overheads of computation and storage as well as that of communication. In this paper, we propose a computation-andstorage-efficient key tree structure, and a key tree management protocol for secure multicast communication. By considering the resource information of each group member’s device, the proposed protocol manages the key tree structure to maximize the efficiency of the computation and storage costs, and to minimize the increment of the communication cost. Through analysis and simulations using three kinds of cost metrics, it demonstrated that the proposed protocol saves computation and storage costs at the expense of a very small increase in communication cost as a tradeoff when the number of total members and the ratio of members leaving in a batch update interval are moderately large. 2009 Elsevier B.V. All rights reserved.	algorithm;computation;confidentiality;cryptography;group key;key management;mobile device;scalability;secure multicast;simulation;tree structure	Dong-Hyun Je;Jun-Sik Lee;Yongsuk Park;Seung-Woo Seo	2010	Computer Communications	10.1016/j.comcom.2009.08.007	multicast;confidentiality;telecommunications;computer science;resource management;operating system;distributed computing;mobile computing;computer security	Security	-30.84562022384171	69.71027865861298	136251
334e236c3dc153d8ff1c19e97e360ccce63e9a82	tpc-w: a benchmark for e-commerce	information resources;electronic commerce;e commerce;internet;web server hardware business benchmark testing navigation transaction databases time measurement delay throughput degradation;scalability e commerce site benchmark tpc benchmark w hardware configuration software configuration web servers commerce servers database servers;transaction processing;information resources electronic commerce transaction processing internet	The design of e-commerce sites presents many challenges, including scalability. One needs to know how the performance—measured in terms of response time and throughput—varies as more and more users access an e-commerce site. Will performance degrade significantly beyond a given load level or will the site be able to deliver acceptable performance even as the load surges? What is the maximum number of transactions that can be processed per second? Can the site be upgraded in a straightforward way (e.g., by adding more servers or replacing existing servers by more powerful ones) to support higher traffic volumes or is an architectural change required? These are some typical questions that must be answered when analyzing the scalability of transactional Web sites.	benchmark (computing);e-commerce;response time (technology);scalability;server (computing);tpc-w;throughput;world wide web	Daniel A. Menascé	2002	IEEE Internet Computing	10.1109/MIC.2002.1003136	e-commerce;the internet;transaction processing;computer science;operating system;data mining;database;distributed computing;world wide web;server;computer network	DB	-19.279395273227177	70.41839620849066	136355
b26ed97150d1b4c7c1fb45a3e59152a78b6e7dcd	minimizing environmental footprints of data centers under budget and service requirement constraints		The energy consumption of data centers (DCs) has been increasing, which will continue due to the increase of Internet traffic and stringent service level agreements (SLAs). Analogously, the protection of global and local environments has also driven the regulation authorities to encourage energy consumers, especially corporate entities, for the usage of green energy sources. However, the green energy is usually more expensive (up to four to five times for some cases) than the traditional energy generated from coal and petroleum. One essential problem for managing DCs, according to the greenness tendency, is to minimize the environmental penalty (or equivalently to maximize the greenness) by dispatching the requests to proper DCs under the SLA and budget constraints. This paper presents optimization techniques for dynamic workload balancing for cloud-scale data center (DC) management. We present a model for commonly found electricity tariffs for green energy and provide an efficient heuristic algorithm to maximize its usage while incorporating its intermittent availability. We evaluate the presented solution with real-life traces of electricity prices and DC workloads. Extensive evaluations support our solution’s potential to minimize the environmental penalty for Internet service providers under the budget while fulfilling their SLAs.	computation;computer cooling;data center;entity;greedy algorithm;heuristic (computer science);holism;internet;load balancing (computing);mathematical optimization;networking hardware;real life;service-level agreement;tracing (software)	Waqaas Munawar;Jian-Jia Chen;Minming Li	2014		10.5220/0004934202220232	real-time computing;systems engineering	Metrics	-21.107683767537807	62.98305291082535	136825
65f392ea232878e416b077605427ff62d7fe0677	energy-efficient management of data center resources for cloud computing: a vision, architectural elements, and open challenges	080504 ubiquitous computing;cluster computing;performance evaluation;energy efficient;cost saving;resource allocation;data center;scheduling algorithm;pay as you go;quality of service;carbon footprint;cloud computing	Cloud computing is offering utility-oriented IT services to users worldwide. Based on a pay-as-you-go model, it enables hosting of pervasive applications from consumer, scientific, and business domains. However, data centers hosting Cloud applications consume huge amounts of energy, contributing to high operational costs and carbon footprints to the environment. Therefore, we need Green Cloud computing solutions that can not only save energy for the environment but also reduce operational costs. This paper presents vision, challenges, and architectural elements for energy-efficient management of Cloud computing environments. We focus on the development of dynamic resource provisioning and allocation algorithms that consider the synergy between various data center infrastructures (i.e., the hardware, power units, cooling and software), and holistically work to boost data center energy efficiency and performance. In particular, this paper proposes (a) architectural principles for energy-efficient management of Clouds; (b) energy-efficient resource allocation policies and scheduling algorithms considering quality-of-service expectations, and devices power usage characteristics; and (c) a novel software technology for energy-efficient management of Clouds. We have validated our approach by conducting a set of rigorous performance evaluation study using the CloudSim toolkit. The results demonstrate that Cloud computing model has immense potential as it offers significant performance gains as regards to response time and cost saving under dynamic workload scenarios.	algorithm;cloud computing;cloudsim;computer cooling;data center;emoticon;holism;memory management;performance evaluation;pervasive informatics;provisioning;quality of service;response time (technology);scheduling (computing);synergy	Rajkumar Buyya;Anton Beloglazov;Jemal H. Abawajy	2010			cloud computing security;data center;real-time computing;simulation;quality of service;cloud computing;computer cluster;resource allocation;computer science;operating system;cloud testing;distributed computing;utility computing;efficient energy use;scheduling;world wide web	HPC	-21.43632947182643	61.92356561680776	136872
4a48bc65fa1f2e258d9756c0d761ebf8f729d449	a case for coalitions in data swarming systems	analytical models;dynamic coalition formation process data swarming system capacity allocation strategy data sharing bittorrent tit for tat choking strategy random choking strategy unchoke all strategy cooperative game theory;capacity allocation;convergence;game theory;computer model;resource manager;resource management;data model;coalition formation;computational modeling;cooperative game theory;mathematical model analytical models resource management equations steady state data models computational modeling;mathematical model;tit for tat;data handling;peer to peer computing;peer to peer computing convergence data handling game theory;analytical model;data models;steady state	We present an argument in favor of forming coalitions of peers in a data swarming system consisting of peers with different upload capacities. A coalition is a set of peers with the same upload capacity that explicitly cooperate with other peers inside the coalition via choking and capacity allocation strategies. Further, each peer interacts with other peers outside its coalition via potentially distinct choking and capacity allocation strategies. This paper focuses on the efficiency of different choking strategies, assuming that peers do not share data with other peers outside their coalitions. We first develop an analytical model that accurately predicts the performance of a coalition of peers adopting BitTorrent's Tit-for-Tat choking strategy. Our model highlights a number of inefficiencies of Tit-for-Tat strategy. Accordingly, we propose a random choking strategy, and show that it can help a coalition achieve near-optimal performance and it significantly outperforms not only Tit-for-Tat strategy but also unchoke-all strategy. Using cooperative game theory, we prove the existence of stable coalitions, and demonstrate the convergence of the dynamic coalition formation process when peers use our cooperation-aware better response strategy. Using extensive simulations, we demonstrate significant performance benefits due to coalition formation.	bittorrent;game theory;interaction;simulation;swarm;upload;vii	Honggang Zhang;Sudarshan Vasudevan;Ran Li;Donald F. Towsley	2011	2011 19th IEEE International Conference on Network Protocols	10.1109/ICNP.2011.6089058	data modeling;simulation;convergence;data model;computer science;resource management;group method of data handling;mathematical model;distributed computing;tit for tat;steady state;computational model;computer security;computer network	Robotics	-25.169076770986266	73.29279679976626	137053
29ee54f79813d0c5d54ed34017d24508df8b89a3	a game theoretic method for resource allocation in scientific cloud	game theory;nash equilibrium;resource allocation;scheduling;cloud computing	Due to the widespread use of cloud services, the need for proper and dynamic distribution will redouble the resources. One of the most complex problems in cloud environments is resource allocation such that on one hand the resource provider should obtain maximum utilization and on the other hand users want to lease best resources based on his time and budget constraints. Many studies which presented new methods for solving this NP-complete problem have used heuristic algorithm. Based on economic aspects of cloud environments, using market oriented model for solving allocation problem can decrease the complexity and converge it to the best solution in minimum time. In this paper a method has been proposed based on auction theory that it has used a non-cooperative game theory mechanism in an incomplete information environment. This game try to select best bidder for selling resource to it. At the end of the paper, the proposed algorithm was experienced in cloudsim and the simulated results showed that the authors' suggested model converge to the best response at Nash equilibrium point.		Amin Nezarat;Gh. Dastghaibifard	2016	IJCAC	10.4018/IJCAC.2016010102	mathematical optimization;simulation;economics;resource allocation;management science	HPC	-22.234839182190477	65.05836215622466	137369
33a0081a60ae44d465a22feb6e71ed38671bf746	an implementation of pc state management in ip networks	protocols;random access memory;processor scheduling;remote wakeup pc state power consumption wol;servers;servers ip networks ports computers random access memory power demand protocols processor scheduling;it devices pc state management ip networks remote waking up personal computers udp wake on lan wol;ip networks;ports computers;telecommunication network management ip networks local area networks;power demand	In this paper, an implementation of remote waking-up Personal Computers (PCs) through UDP and Wake On LAN (WOL) is presented. With the implementation, PCs can be sus pende d w hile it is in idle time. Also, PCs can be waked up interactively from remote site when users want to perform required tasks. There is a few barriers to wake a PC up from remote site using WOL. By providing a solution for the barriers, PCs can be in low power states while required tasks can be performed as necessary after the wakeup. Proposed implementation can be applied to IT devices that have similar architecture and communication interface to PCs.	interactive media;internet protocol suite;network packet;state management;wake;wake-on-lan	Sungwon Byon;Eunjung Kwon;Eui-Suk Jung;Yong-Tae Lee;Won Ryu	2015	2015 International Conference on Information and Communication Technology Convergence (ICTC)	10.1109/ICTC.2015.7354699	embedded system;real-time computing;computer science;computer network	Mobile	-21.43781616261565	72.83348330451216	137442
89cd195b40b510f668310eba421550cf9ea24bf8	service monitoring and management on multicore platforms	end to end qos;angel thread mechanism;scheduling computer network management multiprocessing systems quality of service resource allocation;service orientation;resource allocation;service management;end to end qos management architecture;monitoring multicore processing service oriented architecture costs companies quality of service scheduling algorithm resource management yarn technology management;service components;architecture scheduling service monitoring service management multicore platforms multicore processors resource modeling service oriented infrastructure multicore architecture service components end to end qos management architecture angel thread mechanism service qos;scheduling;architecture scheduling;computer network management;service monitoring;service qos;multicore processors;service oriented infrastructure;multicore platforms;multiprocessing systems;multicore architecture;quality of service;resource modeling	With the trend of platformization and the advent of multicore processors, we need to extend the traditional resource modeling in service-oriented infrastructure to enable a better adoption of platform-level features such as multicores. For service processes that are run on multiple servers, each on a multicore architecture, an end-to-end approach should be used to ensure a consistent QoS from all service components. In this paper, we propose an end-to-end QoS management architecture for coordinating the performances of service components. Our research considers modern performance enhancing technologies, namely, multicore and virtualization, and proposes an angel thread mechanism to manage service QoS. We also study scheduling approaches for the architecture	central processing unit;end-to-end principle;multi-core processor;performance;quality of service;scheduling (computing);service-oriented device architecture;service-oriented infrastructure	Kwei-Jay Lin;Shih-Wei Liao	2006	2006 IEEE International Conference on e-Business Engineering (ICEBE'06)	10.1109/ICEBE.2006.88	multi-core processor;real-time computing;mobile qos;quality of service;resource allocation;service management;computer science;operating system;distributed computing;management;scheduling;computer network	Embedded	-26.896035981934034	61.01025375695318	137547
f2431b9dac1f5ab8fd07276b76bcbf228302a14e	on the use of fuzzy logic controllers to comply with virtualized application demands in the cloud	publikationer;konferensbidrag;artiklar;rapporter	As virtualization technologies enable real-time CPU allocation, it is important to build controllers that adjust the allocation in a timely fashion avoiding resource saturation and hence, dissatisfaction of the end users of services. In this work, adaptive neuro-fuzzy inference, trained on Kalman and H∞ filters, has been used to adjust the CPU allocations based on observations of past utilization. When evaluating the performance of the proposed controller it is demonstrated that it provides even better performance than the filters it is trained on. In addition, there are no assumptions on the noise characteristics and due to the fact that the neuro-fuzzy controller can, in general, capture non-linear level processes, our controller is more robust than linear model based approaches, such as the Kalman and the H∞ filters.	adaptive neuro fuzzy inference system;care-of address;central processing unit;cloud computing;complex systems;data center;fuzzy control system;fuzzy logic;inference engine;linear model;logic control;mathematical model;multi-core processor;multiprocessing;multitier architecture;neuro-fuzzy;nonlinear system;programming paradigm;real-time computing;real-time web;semiconductor consolidation;simulation	K. M. Deliparaschos;Themistoklis Charalambous;Evangelia Kalyvianaki;Christos Makarounas	2016	2016 European Control Conference (ECC)	10.1109/ECC.2016.7810362	control engineering;real-time computing;simulation;engineering	Robotics	-24.750106188535014	62.08478433694426	137579
005706ac1a6b370b4f6c365de59d05d22bfc5c51	using approximate dynamic programming to optimize admission control in cloud computing environment	markov processes;cloud computing;computer centres;decision making;dynamic programming;markov decision process framework;admission control optimization;admission policy;application deployment requests;approximate dynamic programming;cloud computing environment;data centers;physical servers;revenue improvements	In this work, we optimize the admission policy of application deployment requests submitted to data centers. Data centers are typically comprised of many physical servers. However, their resources are limited, and occasionally demand can be higher than what the system can handle, resulting with lost opportunities. Since different requests typically have different revenue margins and resource requirements, the decision whether to admit a deployment, made on time of submission, is not trivial.  We use the Markov Decision Process (MDP) framework to model this problem, and draw upon the Approximate Dynamic Programming (ADP) paradigm to devise optimized admission policies. We resort to approximate methods because typical data centers are too large to solve by standard methods. We show that our algorithms achieve substantial revenue improvements, and they are scalable to large centers.	approximation algorithm;cloud computing;data center;dynamic programming;markov chain;markov decision process;physical symbol system;programming paradigm;requirement;runge–kutta methods;scalability;software deployment;usb on-the-go	Zohar Feldman;Michael Masin;Asser N. Tantawi;Diana Arroyo;Malgorzata Steinder	2011	Proceedings of the 2011 Winter Simulation Conference (WSC)		mathematical optimization;simulation;computer science;theoretical computer science;distributed computing;markov process;approximation algorithm;statistics	Metrics	-22.614368345932874	63.83920428937038	137847
fc8caaa2027a8524da89534101d2a5828e309ed2	the evaluation of security algorithms on mobile platform	power consumption android security encryption algorithms;security algorithms mobile network energy consumption device battery android platform mobile device encryption algorithms power consumption battery capacity security demand security threats network communications mobile platform;androids;encryption;android;security of data android operating system mobile computing power aware computing;android operating system;power aware computing;humanoid robots;batteries;encryption batteries algorithm design and analysis androids humanoid robots classification algorithms;classification algorithms;encryption algorithms;power consumption;mobile computing;security;security of data;algorithm design and analysis	The rapid development of mobile platform leads to growing demand for network communications, which suffer from increasingly severe security threats as well. Considering the urgent security demand and the limitation of battery capacity, the power consumption of the encryption algorithms plays a pivotal role for mobile device. Aiming at the above problem, this paper proposes a performance evaluation system on Android platform, which can evaluate the state parameters of device battery. Our work provides elaborate analysis and exploration of 10 security algorithms' energy consumption through extensive simulation results. With the popularity of mobile network and the rapid increase of related applications, it is significant to reduce the power consumption of security encryption algorithms on mobile devices in both academic field and industry.	algorithm;android;encryption;mobile device;performance evaluation;simulation	Hong Yao;Lu Lian;Yuanyuan Fan;Qingzhong Liang;Xuesong Yan	2013	2013 IEEE 9th International Conference on Mobile Ad-hoc and Sensor Networks	10.1109/MSN.2013.64	embedded system;computer science;security service;internet privacy;mobile computing;computer security;encryption;computer network	Mobile	-29.587302236095898	67.53914354011754	137899
142bf658c12b2cadeebad1585c295819ccd0671c	low-power pervasive wi-fi connectivity using wiscan	energy efficiency;wi fi scans;wi fi connectivity	Pervasive Wi-Fi connectivity is attractive for users in places not covered by cellular services (e.g., when traveling abroad). However, the power drain of frequent Wi-Fi scans undermines the device's battery life, preventing users from staying always connected and fetching synced emails and instant message notifications (e.g., WhatsApp). We study the energy overhead of scan and roaming in detail and refer to it as the scan tax problem. Our findings show that the main processor is the primary culprit of the energy overhead. We propose a simple and effective architectural change of offloading scans to the Wi-Fi radio. We design and build WiScan to fully exploit the gain of scan offloading. Our experiments demonstrate that WiScan achieves 90%+ of the maximal connectivity, while saving 50-62% energy for seeking connectivity.	central processing unit;email;experiment;instant messaging;low-power broadcasting;maximal set;overhead (computing);pervasive informatics;whatsapp messenger	Tianxing Li;Chuankai An;Ranveer Chandra;Andrew T. Campbell;Xia Zhou	2015		10.1145/2750858.2807515	embedded system;telecommunications;operating system;efficient energy use;computer security;computer network	HCI	-26.403448616418533	68.0165643749472	138036
022178df6db24ff86964cd6e1dec40ffa71d100a	benchmark applications used in mobile cloud computing research: a systematic mapping study	benchmark;mobile computing;application;cloud computing	Mobile cloud computing (MCC) integrates mobile computing and cloud computing aiming to extend the capabilities of mobile devices through offloading techniques. In MCC, many controlled experiments have been performed using mobile applications as benchmarks. Usually, these applications are used to validate proposed algorithms, architectures or frameworks. The task of choosing a specific benchmark to evaluate MCC proposals is difficult because there is no standard applications list. This paper presents a systematic mapping study for benchmarks used in MCC research. Taking 5 months of work, we have read 763 papers from MCC field. We catalogued the applications and characterized them considering three facets: category (e.g., games, imaging tools); evaluated resource (e.g., time, energy); and platform (e.g., Android, iPhone). The mapping study evidences research gaps and research trends. Providing a list of downloadable standardized benchmarks, this work can aid better choices to guide more reliable research studies since the same application could be used for different scientific purposes.	algorithm;android;benchmark (computing);cloud research;download;experiment;mobile app;mobile cloud computing;mobile computing;mobile device;scientific literature;self-replicating machine;software framework	Francisco Airton Silva;Germano Zaicaner;Eder Quesado;Matheus Dornelas;Bruno Silva;Paulo Romero Martins Maciel	2016	The Journal of Supercomputing	10.1007/s11227-016-1674-2	parallel computing;real-time computing;simulation;benchmark;cloud computing;computer science;operating system;data mining;distributed computing;mobile computing	HPC	-24.584927796336423	66.49427027023648	138654
524f38a0911c335024ad99af97a75cd48b9336c9	a price-based task scheduling for grid computing	computers;commodity market;microeconomic way;processor scheduling grid computing personal digital assistants macroeconomics resource management economics distributed computing microeconomics sun computer network management;demand supply economic model;processor scheduling;pricing;biological system modeling;utility function;controller area networks;demand supply economic model price based task scheduling grid computing grid economy macroeconomy commodity market microeconomic way;economic model;price based task scheduling;scheduling grid computing pricing;computational modeling;medical services;chapters;scheduling;economics;task scheduling;indium;grid computing;functions;macroeconomy;arsenic;beryllium;utility function grid computing grid economy;grid economy	In this paper, we present some principles of grid economy, why it's useful to scheduling task and what is involved in a Grid computing. And we present some results obtained with a framework that use the two model of economy to form a price of a service based, in a macroeconomic way is attributed a initial price for a resource based in your computation characteristics, this is a commodities market, and the microeconomic way, with the node varying your local price based on the demand/supply economic model.	computation;grid computing;scheduling (computing)	Marcelo Massocco Cendron;Carlos Becker Westphall	2008	Seventh International Conference on Networking (icn 2008)	10.1109/ICN.2008.125	arsenic;pricing;beryllium;computer science;economic model;operating system;indium;computational model;scheduling;function;grid computing	HPC	-23.544111613891815	64.86298651867071	139735
00d30ae256227c57ee9af7804bf2c547e0d62ced	generic cloud platform multi-objective optimization leveraging models@run.time	search based algorithms;multi objective optimization;models run time;saas	Cloud computing promises scalable hosting by offering an elastic management of virtual machines which run on top of hardware data centers. This elastic management as a cornerstone of PaaS (Platform As A Service) has to deal with trade-offs between conflicting requirements such as cost and quality of service. Solving such trade-offs is a challenging problem. Indeed, most of PaaS providers consider only one optimization axis or ad-hoc multi-objective resolution techniques using domain specific heuristics.  This paper aims at proposing a generic approach to build cloud optimization by combining modeling and search based paradigms. Our approach is two-fold: 1) To reason about a cloud environment, we use a Models@run.time approach to have an abstraction layer of a cloud configuration that supports monitoring capabilities and represents cloud intrinsic parameters like cost, load information, etc. 2) We use a search-based algorithm to navigate through cloud candidate configuration solutions in order to solve the Cloud Multi-objective Optimization Problem (CMOP).  We validate our approach based on a case study that we define with our cloud provider partner EBRC as representative of a dynamic management problem of heterogeneous distributed cloud nodes. We implement a prototype of our PaaS supervision framework using Kevoree, a Models@run.time platform. The prototype shows the efficiency of our approach in terms of finding possible cloud configurations in reasonable time. The prototype is flexible since it enables an easy reconfiguration of the cloud customer optimization objectives.	abstraction layer;algorithm;apache axis;camera resectioning;cloud computing;data center;fold (higher-order function);heuristic (computer science);hoc (programming language);kevoree;mathematical optimization;multi-objective optimization;optimization problem;platform as a service;prototype;quality of service;requirement;scalability;virtual machine	Donia El Kateb;François Fouquet;Grégory Nain;Jorge Augusto Meira;Michel Ackerman;Yves Le Traon	2014		10.1145/2554850.2555044	real-time computing;simulation;computer science;operating system;multi-objective optimization;software as a service;database;distributed computing;world wide web	Embedded	-21.006549663995873	65.31766868035832	139956
c99560dfc1c1267283a1e069044cd2ec377f4dff	bus-based cloudlet cooperation strategy in vehicular networks		Mobile computation offloading is an emerging technology to migrate resource-intensive computations from resource-limited mobile devices (MDs) to resource-rich devices (such as a cloud server) via wireless access. Accessing to remote cloud server usually introduces a long delay to first deliver parameters to the server and then retrieve the results back. For applications that are time sensitive, offloading to nearby cloudlets is preferred. However, the link duration between an MD and a single cloudlet can be very limited in a vehicular network. As a result, offloading actions taken by an MD may fail due to link breakage caused by mobility. Meanwhile, some vehicles, such as buses, always follow relatively fixed routes, and their locations can be predicted much easier than other vehicles. By taking advantage of this fact, we propose a bus-based cloudlet cooperation strategy, where the bus-based cloudlets act as computation service providers for the MDs in vehicles, and an application generated by an MD includes a series of tasks that have dependency among each other. The proposed bus-based cloudlet cooperation strategy (BCCS) finds the optimal set of tasks to be offloaded to each cloudlet. Experimental results show that the proposed BCCS strategy can reduce both the energy consumption of the MDs and completion time of the applications.	bus (computing);cloudlet;computation offloading;mobile device;molecular dynamics;server (computing);simulation;virtual private server	Zhe Wang;Zhangdui Zhong;Dongmei Zhao;Minming Ni	2017	2017 IEEE 86th Vehicular Technology Conference (VTC-Fall)	10.1109/VTCFall.2017.8288301	computer network;service provider;vehicular ad hoc network;cloud computing;cloudlet;mobile device;wireless;computation offloading;computer science;server	Mobile	-22.374431734745727	68.71732104114531	140987
3a3e78de0c02ce750754d86a12960b2d301d6800	filtering observations to improve resource control in virtual computer and network systems		The Autonomic Resource Control Architecture (ARCA) we have designed in previous work is intended to provide elastic resource adaptation in virtual computer and network systems by automating management tasks in edge/branch virtual networks. Our objective is to reduce the time required to continuously estimate or anticipate the amount of resources that a system requires by considering its workload together with event data notified by external detectors. However, analyzing such amount of data can take a long time and thus delay management decisions and system adaptation. Moreover, too frequent changes in the amount of allocated resources can hassle the underlying controllers. In this paper we propose a method to resolve these problems by filtering input data items to reduce their rate while smoothing non-persistent spikes to reduce the volatility of resource allocations. We evaluate it by running an algorithmic model with a set of input data following a Pareto distribution, analyzing the accuracy of different variations of the proposed method. We found that the accuracy of the resulting allocations is improved by 13% to 30%, depending on the specific configuration of the proposed method.	amazon elastic compute cloud (ec2);autonomic computing;big data;effective method;kalman filter;memory management;network function virtualization;pareto efficiency;provisioning;sensor;smoothing;software-defined networking;virtual machine;volatility	Pedro Martinez-Julia;Ved P. Kafle;Hiroaki Harai	2018	NOMS 2018 - 2018 IEEE/IFIP Network Operations and Management Symposium	10.1109/NOMS.2018.8406176	resource management;resource allocation;workload;architecture;computer science;distributed computing;process control;control system;smoothing;virtual machine	Mobile	-23.934333083407477	61.56022115246396	141377
5599dedcd2b37619cf206d922d31424f53f60978	system support for computer mediated multimedia collaborations	model combination;building block;asynchronous collaboration;multimedia application;spectrum;synchronous and asynchronous collaborations;media streaming;access control;semantic relations;multimedia collaboration management	Future advances in networking and storage will enable a wide spectrum of computer mediated structured collaborations among individuals. In this paper, we present a model that can capture diverse types of structured collaborations. The model combines both efficiency and power via a hierarchy of three abstractions, at the lowest level of which are streams for media communication modulated by access rights of participants within collaborations. The higher two levels of abstractions are sessions, which represent collections of semantically related media streams, and conferences, which represent temporally related sequences of sessions. Using these abstractions, the model supports unification of both synchronous and asynchronous collaborations, sophisticated access control, and intra-group and inter-group collaborations, yielding a powerful set of building blocks for constructing multimedia applications and a rich environment for carrying out structured multimedia collaborations.	access control;modulation;temporal logic;unification (computer science)	Harrick M. Vin;P. Venkat Rangan;Mon-Song Chen	1992		10.1145/143457.143480	spectrum;computer science;access control;distributed computing;multimedia;world wide web	HPC	-23.869112907947315	71.43640894877494	142518
9732b6eca54e194260d09b14c47d80d778d3f2dc	chargeback for cloud services	cloudonomics;chargeback;cloud computing;empirical research	With pay-per-use pricing models, elastic scaling of resources, and the use of shared virtualized infrastructures, cloud computing offers more efficient use of capital and agility. To leverage the advantages of cloud computing, organizations have to introduce cloud-specific chargeback practices. Organizations have to allocate IT service costs to business users in a way that reflects service consumption. To help organizations become effective users of cloud services, this article provides an overview of the factors that influence chargeback in the cloud services. This is an initial work that determines the factors influencing the chargeback in the cloud services. The findings of this research facilitate organizations to realize the implications of the cloud for their	chargeback;cloud computing;grid computing;image scaling;requirement;service-level agreement;synergy	Thijs Baars;Ravi Khadka;Hristo Stefanov;Slinger Jansen;Ronald Batenburg;Eugene van Heusden	2014	Future Generation Comp. Syst.	10.1016/j.future.2014.08.002	simulation;cloud computing;computer science;operating system;empirical research;chargeback;computer security	HCI	-26.32771573353215	60.48445370030145	142683
1e4bb32647b0500500d8db8f4acbed14225dfba6	virtual machine proactive scaling in cloud systems	virtual machines cloud computing computer centres quality of service;virtual machine;performance prediction models;cloud sim simulator virtual machine proactive scaling cloud systems cloud computing data centers quality of services qos;computer centres;virtual machines;cloudsim cloud computing virtual machine performance prediction models smm;smm;cloudsim;quality of service;history load modeling predictive models mathematical model computational modeling adaptation models monitoring;cloud computing	Although the investment in Cloud Computing incredibly grows in the last few years, the offered technologies for dynamic scaling in Cloud Systems don't satisfy neither nowadays fluky applications (i.e. social networks, web hosting, content delivery) that exploit the power of the Cloud, nor the energy challenges caused by its data-centers. In this work we propose a proactive model based on an application behaviors prediction technique to predict the future workload behavior of the virtual machines (VMs) executed at Cloud hosts. The predicted information can help VMs to dynamically and proactively be adapted to satisfy the provider demands in terms of increasing the utilization and decreasing the power consumption, and to enhance the services in terms of improving the performance with respect to the Quality of Services (QoS) requirements and dynamic changes demands. We have tested the proposed model using Cloud Sim simulator, and the experiments show that our model is able to avoid undesirable situations caused by dynamic changes such as (peak loads, low utilization) and can decrease the losses of energy consumption, overheating, and resources wastage up to 45% on average.	cloud computing;cloudsim;digital distribution;experiment;heuristic (computer science);image scaling;requirement;simulation;social network;virtual machine;web hosting service	Ahmed Sallam;Keqin Li	2012	2012 IEEE International Conference on Cluster Computing Workshops	10.1109/ClusterW.2012.17	real-time computing;simulation;cloud computing;computer science;virtual machine;operating system;cloud testing;distributed computing	HPC	-23.664136986924248	62.459166605427676	142919
31f43890cd28a84b3c633caaea3d6394109ba671	fast statistical spam filter by approximate classifications	spam;bloom filter;bayesian approach;bayesian filter;false negative;approximation;memory access;false positive rate;spam filtering;bayesian filtering;data structure;acceleration techniques	Statistical-based Bayesian filters have become a popular and important defense against spam. However, despite their effectiveness, their greater processing overhead can prevent them from scaling well for enterprise-level mail servers. For example, the dictionary lookups that are characteristic of this approach are limited by the memory access rate, therefore relatively insensitive to increases in CPU speed. We address this scaling issue by proposing an acceleration technique that speeds up Bayesian filters based on approximate classification. The approximation uses two methods: hash-based lookup and lossy encoding. Lookup approximation is based on the popular Bloom filter data structure with an extension to support value retrieval. Lossy encoding is used to further compress the data structure. While both methods introduce additional errors to a strict Bayesian approach, we show how the errors can be both minimized and biased toward a false negative classification.We demonstrate a 6x speedup over two well-known spam filters (bogofilter and qsf) while achieving an identical false positive rate and similar false negative rate to the original filters.	anti-spam techniques;approximation algorithm;archive;bayesian network;bloom filter;bogofilter;central processing unit;communications of the acm;cryptographic hash function;dnsbl;data structure;dictionary;distortion;email filtering;graham scan;hypertext transfer protocol;ieee transactions on information theory;ip traceback;image scaling;jones calculus;linux;lookup table;lossy compression;md5;moving picture experts group;naive bayes spam filtering;network packet;open-source software;overhead (computing);particle filter;perl mongers;scalability;sourceforge;spamassassin;spambayes;spamming;speedup;statistical machine translation;web cache	Kang Li;Zhenyu Zhong	2006		10.1145/1140277.1140317	spam;data structure;bayesian probability;false positive rate;computer science;theoretical computer science;bloom filter;machine learning;approximation;data mining;programming language	Metrics	-32.04837173782671	66.70243747189608	143110
0753fd8edd7806f4f39ae7a275878de4a4db3c62	cloudmonitor: profiling power usage	energy conservation;resource monitoring;software engineering cloud computing data handling energy conservation power aware computing;power metering;energy efficient computing;software engineering;cost modelling;power aware computing;servers;computational modeling;monitoring;cost modelling cloud computing energy efficient computing power metering resource monitoring;hardware cloud computing servers monitoring data models computational modeling;energy efficient application cloudmonitor tool power usage profiling cloud computing platform hardware monitoring device power usage data gathering software based power estimation deployment energy cost cloud provider software developer;data handling;cloud computing;data models;hardware	In Cloud Computing platforms the addition of hardware monitoring devices to gather power usage data can be impractical or uneconomical due to the large number of machines to be metered. CloudMonitor, a monitoring tool that can generate power models for software-based power estimation, can provide insights to the energy costs of deployments without additional hardware. Accurate power usage data leads to the possibility of Cloud providers creating a separate tariff for power and therefore incentivizing software developers to create energy-efficient applications.	algorithm;cloud computing;software developer;system monitor;usage data	James W. Smith;Ali Khajeh-Hosseini;Jonathan Stuart Ward;Ian Sommerville	2012	2012 IEEE Fifth International Conference on Cloud Computing	10.1109/CLOUD.2012.112	embedded system;data modeling;real-time computing;energy conservation;cloud computing;computer science;operating system;group method of data handling;computational model;server	EDA	-25.030021351572852	61.04374234787498	143179
45dc186b5e475c45ac11f34e0ca447c73f189586	game-based incentive mechanisms for cooperation in p2p networks	erbium;game theory educational institutions peer to peer computing computer networks radio access networks conference management technology management engineering management biological system modeling robustness;game based incentive mechanism;incentive mechanism;free rider game cooperation incentive mechanism;game theory;peer to peer network;resource allocation game theory peer to peer computing;resource allocation;cooperation;biological system modeling;network performance;peer to peer network cooperation;games;resource sharing;game;resource sharing game based incentive mechanism peer to peer network cooperation;economics;p2p networks;peer to peer computing;free rider;conferences	Peer-to-Peer networks are gaining popularity as architecture for sharing resources. However, these systems easily suffer from a high level of free-riders, whereby some users consume resources without providing any resources. In order to reduce the free-riders and promote the cooperation among peers, we propose an incentive mechanism for cooperation based on game theory. Simulations show that the proposed mechanism can significantly improve the network performance as well as effectively alleviate peers only consuming resources in P2P networks.	computer simulation;game theory;high-level programming language;network performance;peer-to-peer	Fu Xie;Fengming Liu;Rongrong Yang;Ran Lu	2008	2008 Fourth International Conference on Natural Computation	10.1109/ICNC.2008.100	public relations;simulation;economics;knowledge management	HPC	-25.223418633519444	73.53641019926928	143781
59746e5235a2ccf1821d7c335722a4efe49275e7	an algebraic qos-based resource allocation model for competitive multimedia applications	algebraic approach;resource constraint;system configuration;multimedia applications;resource allocation;resource manager;resource management;multimedia application;quality of service	A new class of multimedia applications require new mechanisms to consider various Quality of Services with respect to resource constraints so that they could support reliable services and utilize available resources optimally. In this paper we present a new analytical and generic resource management model that is QoS-based. The approach for resource allocation and relevant algorithms is based on a mathematically proved model that manages resource and QoS allocation intelligently so that the total system utility of is maximized. We use the constructs of application benefit functions and resource demand functions to represent the system configuration and to solve the resource allocation problems. Extensive surveys on the related work including systematic and analytical approaches are also presented.	algorithm;quality of service;system configuration	Wonjun Lee;Jaideep Srivastava	2001	Multimedia Tools and Applications	10.1023/A:1009645328053	simulation;quality of service;resource allocation;computer science;knowledge management;resource management;resource allocation;human resource management system	Metrics	-21.3938341369833	65.94367354464445	144177
6979d15a6d7df2c843a8b9df1ca2dc84884dc30e	power-efficient resource-guaranteed vm placement and routing for time-aware data center applications	bandwidth guarantees;power efficient data centers;time aware tenant requests;multi tier applications;optimization;vm placement	Power efficiency and performance guarantees have become major concerns of data center cloud providers as they significantly affect providers’ economic benefits. Providing guaranteed resources necessitates developing a user-friendly and concise request model which accurately abstracts the required server and network resources for a tenant application. We propose as the required server and network resources for a tenant application. We propose a time-aware tenant application (TTA) request model which enables a tenant to express an application request by specifying its resource requirement graph (server resources for VMs and bandwidth) associated with its estimated required time duration. We investigate the powerefficient resource-guaranteed virtual machine (VM)-placement and routing problem for dynamically arriving TTA requests. The problem requires provisioning of the specified resources in a data center for the required time duration of requests by selecting an appropriate set of servers for VM placement and routes for their communication, so as to maximize the number of accepted requests while consuming as low power as possible. We develop a mixed integer linear programming optimization problem formulation based on the multi-component utilization-based power model. Since this problem which is a combination of routing and VMplacement problem, is computationally prohibitive, we develop two algorithms which select servers and routes based on: (1) our proposed goodness function and pre-computed candidate paths, and (2) minimum power cost paths, respectively. We demonstrate the effectiveness of the proposed algorithms in terms of power saving and acceptance ratio through simulation	aggregate data;algorithm;data center;integer programming;linear programming;mathematical optimization;openvms;optimization problem;place and route;precomputation;provisioning;routing;server (computing);simulation;usability;virtual machine	Aissan Dalvandi;Gurusamy Mohan;Kee Chaing Chua	2015	Computer Networks	10.1016/j.comnet.2015.06.017	real-time computing;computer science;operating system;distributed computing;computer security;computer network	Arch	-21.022372133675074	64.01527198762747	144182
681f8aa5222f4c4ab8cc25f0f53649c40b0c57ce	relocating a data center using extended distance srdf: a user experience	data center;user experience		data center;user experience	Mark P. Grinnell;Jim Feurig	1997			world wide web;user experience design;data center;human–computer interaction;computer science	Theory	-19.883334382745097	73.7536120987242	144557
2fe1702b7a769d5bd69ec3911b64f66ec3ad54c8	an sla-based resource allocation for iot applications in cloud environments	cpu scheduling;iot cloud;service level agreement;message broker	In an IoT cloud, the message broker service allows point to multi-point communication between IoT devices and applications. The service is governed by Service Level Agreements (SLA) that specify, among other requirements, the volume of messages served during an enforcement period. For simplicity, current SLAs do not provide detailed information about message arrival patterns, making enforcement of the SLA a difficult problem for the providers. In this paper, we propose a new, two-step SLA by introducing sub-periods for measurement and control within the total enforcement period. Our proposed SLA retains the simplicity of the current SLA and provides additional controls for the providers to enforce it. We present the conformance of the new SLA as a resource allocation problem for cloud providers and propose a buffering, scheduling and rate limiting mechanism to enforce it. We verify that the solution achieves conformance, analyze the tradeoffs of the solution and evaluate via simulation the effects of system parameters such as capacity, number of sub-periods and enforcement period.	cloud computing;conformance testing;data center;emoticon;message broker;rate limiting;requirement;scheduling (computing);server (computing);service-level agreement;simulation	Anand Singh;Yannis Viniotis	2016	2016 Cloudification of the Internet of Things (CIoT)	10.1109/CIOT.2016.7872913	real-time computing;computer science;operating system;distributed computing;message broker;scheduling;computer security;computer network	Networks	-23.515290011776568	63.0084439845104	144684
1e8ab90d55752208952e1a3107bc748a1dba8daf	f2c: enabling fair and fine-grained resource sharing in multi-tenant iaas clouds	virtual machine;random access memory;iaas;fairness;memory management;virtual machines cloud computing resource allocation;resource management;biological system modeling;xen platform f2c fair resource sharing fine grained resource sharing multitenant iaas clouds cooperative resource management system infrastructure as a service clouds group buying mechanisms real product service markets cloud tenant group tenant coalition resource capacity resource pool sharing virtual machines vm pay as you use cloud environments reciprocal resource fairness rrf resource allocation mechanism complementary mechanisms hierarchical mechanisms intertenant resource trading intratenant weight adjustment;virtual machine cloud computing fairness iaas resource sharing;resource management cloud computing indexes biological system modeling random access memory economics memory management;indexes;期刊论文;resource sharing;economics;cloud computing	This paper presents F2C, a cooperative resource management system for Infrastructure-as-a-Service (IaaS) clouds. Inspired by group-buying mechanisms in real product and service markets, F2C advocates a group of cloud tenants (called tenant coalition) to buy resource capacity in bulk and share the resource pool in the form of virtual machines (VMs). Tenant coalitions leads to vast opportunities for fine-grained resource sharing among multiple tenants. However, resource sharing, especially for multiple resource types, poses several challenging problems in pay-as-you-use cloud environments, such as sharing incentive, free-riding, lying and economic fairness. To address those problems, we propose Reciprocal Resource Fairness (RRF) , a novel resource allocation mechanism to enable fair sharing on multiple resource types within a tenant coalition. RRF is implemented in two complementary and hierarchical mechanisms: inter-tenant resource trading and intra-tenant weight adjustment. RRF satisfies several highly desirable properties to ensure fairness. We implement F2C in Xen platform. The experimental results show F2C is promising for both cloud providers and tenants. For cloud providers, F2C improves VM density and cloud providers' revenue by 2.2X compared to the current IaaS cloud models. For tenants, F2C improves application performance by 45 percent and guarantees 95 percent economic fairness among multiple tenants.	cloud computing;fairness measure;multitenancy;virtual machine;f2c	Haikun Liu;Beixin Julie He	2016	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2015.2499769	shared resource;database index;simulation;cloud computing;computer science;virtual machine;resource management;operating system;distributed computing;computer security;memory management	HPC	-23.594676786089558	64.86846013265543	145249
aa41df67f35909856ca11076c1bb9a4d741eba68	exploring the impact of inaccuracy and imprecision of qos assumptions on proactive constraint-based qos prediction for service orchestrations	experimental validation;quality of service;service orchestration;prediction;constraints;quality of prediction;cognition;prototypes;lower bound;sla;upper bound;constraint satisfaction problems;measurement;accuracy;service oriented architecture	Constraint-based Quality of Service (QoS) prediction is a method for predicting violations of Service Level Agreements (SLAs) in an executing instance of a service orchestration. It uses assumptions about the ranges of QoS values for component services in the orchestration. Experiments suggest that the method, when given correct component QoS assumptions, produces highly accurate predictions according to a series of quality-of-prediction metrics, and that it does so well ahead of the time when the prediction is to happen. We study the behavior of this method when the component QoS assumptions become incorrect or too vague. We conclude that the effect is a graceful deterioration in prediction quality, unless gross (order-of-magnitude) imprecisions are introduced. However, the method is very sensitive to the loss of information on the lower bounds for component QoS values, since the knowledge of the upper bounds is not sufficient for failure prediction.	approximation;experiment;failure cause;kerrison predictor;list of system quality attributes;orchestration (computing);prototype;quality of service;run time (program lifecycle phase);sensitivity and specificity;sensor;service-level agreement;vagueness	Dragan Ivanovic;Manuel Carro;Manuel V. Hermenegildo	2012	2012 4th International Workshop on Principles of Engineering Service-Oriented Systems (PESOS)		reliability engineering;real-time computing;computer science;data mining	Embedded	-25.116408512617642	61.4899961691983	145456
de67de58267e813e56a294f66b709a0b7151557a	storage strife	binary format;storage strife	Beware keeping data in binary format	binary file;strife	George Neville-Neil	2011	ACM Queue	10.1145/1978862.1978883	computer security;world wide web;computer science	OS	-33.041740426264525	67.00287020129014	145811
fdf1c8763807fb7f450aa8226de027e374ad3694	virtual machine resource allocation for multimedia cloud: a nash bargaining approach	optimization;resource allocation;nash bargaining solution	Recently, multimedia cloud is being considered as a new effective serving mode in multimedia domain. It can provide a flexible stack of powerful Virtual Machine (VM) resources of cloud like CPU, memory, storage, network bandwidth etc. on demand to manage media services and applications (e.g. image/video retrieval, video transcoding, streaming, video rendering, sharing and delivery) at lower cost. However, one major issue here is how to efficiently allocate VM resources dynamically based on applications’ QoS demands and support energy and cost savings by optimizing the number of servers in use. In order to solve this problem, we propose a cost effective and dynamic VM allocation model based on Nash bargaining solution. With various simulations it is shown that the proposed mechanism can reduce the overall cost of running servers while at the same time guarantee QoS demand and maximize resource utilization in various dimensions of server resources. c © 2014 The Authors. Published by Elsevier B.V. Selection and peer-review under responsibility of the Program Chairs of EICM-2014..	algorithm;central processing unit;cloud computing;experiment;nash equilibrium;overhead (computing);provisioning;quality of service;server (computing);simulation;streaming media;video renderer;virtual machine	Mohammad Mehedi Hassan;Atif Alamri	2014		10.1016/j.procs.2014.07.074	real-time computing;simulation;computer science;operating system;computer network	Metrics	-21.69688232307608	64.34303627756277	145834
f919cc6eb7c82912d68ee9d90fa8ab367f0b6885	a miso model for power consumption in virtualized servers	control theory;energy aware system;modeling techniques;system identification;power management	Energy efficiency is always a concern in hosting servers. When any new development is added to a host server, the power consumption of the host server must be theoretically and empirically re-evaluated. Because of the ongoing development trends in computing systems at the hardware, software and middleware levels, deriving a direct mathematical model for quantifying the power consumption of a host server is difficult. Therefore, a system identification is used to construct the power consumption model for virtualized hosting servers. To date, three types of system identifications have been used in the literature for defining the power consumption model: the first-principles, the black-box and the gray-box identification approaches. To the best of our knowledge, the majority of these approaches are apparently used to model the power consumption in a single-input single-output (SISO) system model, in which a hardware component is reconfigured to meet the power budget target. In this paper, to accommodate the ongoing development trends in computing systems, we propose a multi-input single-output (MISO) model for modeling the power consumption of virtualized hosting servers. We use the black-box system identification method, and we utilize the Auto-Regressive eXogenous (ARX) mathematical model to construct the MISO power model. We compare our MISO power model with the SISO power model that is used in existing state-of-the-art works. Empirically, our MISO power model exhibits higher accuracy than the existing SISO power model in predicting power consumption. Using our model, we can achieve approximately 98 % accuracy in predicting the power consumption of virtualized hosting servers.	arx;black box;display lag;experiment;fits;initial condition;input lag;mathematical model;middleware;sampling (signal processing);server (computing);simulation interoperability standards organization;soft-in soft-out decoder;system analysis;system dynamics;system identification;virtual machine	Fawaz Al Hazemi;Yuyang Peng;Chan-Hyun Youn	2015	Cluster Computing	10.1007/s10586-015-0436-x	real-time computing;simulation;system identification;computer science;operating system;object-modeling technique;computer network	HPC	-24.945930113956468	61.673938143073	146274
1c4226f53c87db52af3808731a99dec83b997ab4	polygravity: traffic usage accountability via coarse-grained measurements in multi-tenant data centers		Network usage accountability is critical in helping operators and customers of multi-tenant data centers deal with concerns such as capacity planning, resource allocation, hotspot detection, link failure detection, and troubleshooting. However, the cost of measurements and instrumentation to achieve flow-level accountability is non-trivial. We propose Polygravity to determine tenant traffic usage via lightweight measurements in multi-tenant data centers. We adopt a tomogravity model widely used in ISP networks, and adapt it to a multi-tenant data center environment. By integrating datacenter-specific domain knowledge, sampling-based partial estimation and gravity-based internal sinks/sources estimation, Polygravity addresses two key challenges for adapting tomogravity to a data center environment: sparse traffic matrices and internal traffic sinks/sources. We conducted extensive evaluation of our approach using realistic data center workloads. Our results show that Polygravity can determine tenant IP flow usage with less than 1% average relative error for tenants with fine-grained domain knowledge. In addition, for tenants with coarse-grained domain knowledge and with partial host-based sampling, Polygravity reduces the relative error of sampling-based estimation by 1/3.	approximation error;data center;java hotspot virtual machine;multitenancy;sampling (signal processing);sparse matrix	Hyun Wook Baek;Cheng Jin;Guofei Jiang;Cristian Lumezanu;Jacobus E. van der Merwe;Ning Xia;Qiang Xu	2017		10.1145/3127479.3129258	real-time computing;computer science;simple network management protocol;domain knowledge;capacity planning;sampling (statistics);resource allocation;computer network;hotspot (wi-fi);multitenancy;data center	Metrics	-28.6198999863703	64.05636057999342	146537
5cc1e6f232f9bf05837726133d2294f79d5d438a	entropy4cloud: using entropy-based complexity to optimize cloud service resource management		In cloud service resource management system, complexity limits the system's ability to better satisfy the application's quality of service requirements, e.g., cost budget, average response time, and reliability. Numerousness, diversity, variety, uncertainty, etc., are some of the complexity factors that lead to the variation between expected plan and actual running performance of cloud applications. In this paper, after defining the complexity clearly, we identify the origin of complexity in cloud service resource management system through the study of “Local Activity Principle.” In order to manage complexity, an entropy-based methodology is presented to use, which covers identifying, measuring, analyzing, and controlling (avoid and reduce) of complexity. Finally, we implement such idea in a popular cloud engine, Apache Spark, for running analysis as a service. Experiments demonstrate that the new entropy-based resource management approach can significantly improve the performance of spark applications. Compare with the fair scheduler in Apache Spark, our proposed entropy scheduler is able to reduce overall cost by 23%, improve the average service response time by 15–20%, and minimized the standard deviation of service response time by 30–45%.	apache spark;cloud computing;non-functional requirement;response time (technology);scheduling (computing)	Huankai Chen;Frank Z. Wang;Na Helian	2018	IEEE Transactions on Emerging Topics in Computational Intelligence	10.1109/TETCI.2017.2755691	resource management;data mining;cloud computing;permission;redistribution (cultural anthropology);computer science;computational intelligence	OS	-19.316470021474984	62.51920931240071	146608
d870dee93567f7846385aabed39851f968cdb05c	availability analysis of cloud computing centers	capacity planning availability analysis cloud computing center performance analysis quality of service qos guarantee analytical submodel task blocking probability total delay;quality of service cloud computing probability	Accurate availability and performance analysis are important requirements to guarantee quality of services (QoS) for cloud users. In this paper, we integrate an availability model in overall analytical sub-models of cloud system. Each sub-model captures a specific aspect of cloud centers. The key performance metrics such as task blocking probability and total delay incurred on user tasks are obtained. Our results can be used by an admission control to prevent the cloud center from entering unstable regime of operation. The results also reveal practical insights into capacity planning for cloud computing centers.	blocking (computing);cloud computing;control theory;erlang (unit);interaction;planning;requirement;stochastic process	Hamzeh Khazaei;Jelena V. Misic;Vojislav B. Misic;Nasim Beigi Mohammadi	2012	2012 IEEE Global Communications Conference (GLOBECOM)	10.1109/GLOCOM.2012.6503402	real-time computing;simulation;computer science;cloud testing;distributed computing;computer network	HPC	-23.197379651031945	63.06615730520883	146838
333150db4e0cad38399a8557404db4e2e654cafb	an innovative self-adaptive configuration optimization system in cloud computing	analytical models;slas;resource scheduling;measurement;dynamic reconfiguration;queuing theory;resource scheduling cloud computing optimization cloud service configuration slas;queueing theory;computer model;satisfiability;service model;computational modeling;pay as you go;statistical analysis;statistical analysis cloud computing genetic algorithms queueing theory;execution environment;cloud service configuration;cost effectiveness;predictive models;genetic algorithms;optimization;optimization computational modeling cloud computing throughput predictive models measurement analytical models;prediction model;statistical techniques;statistic techniques innovative selfadaptive configuration optimization system cloud computing computational service model computing resources innovative architecture genetic algorithm queuing theory;optimal algorithm;conference proceeding;analytical model;fitness function;cloud computing;throughput	Cloud computing has emerging as an extremely popular and cost-effective computational service model using pay-as-you-go executing environments that scale transparently to the user. However, cloud providers should tackle the challenge of configuring their systems to provide maximal performance while minimizing customer's cost of computing resources, which satisfy the customers' various workload requirements. To solve the above challenge, in this paper, we propose an innovative architecture of self-adaptive configuration optimization system which supports dynamic reconfiguration when workloads change. In addition, we develop an optimization algorithm by using genetic algorithm for this system. By using queuing theory and statistic techniques, we model and compute the SLAs metrics which are defined as the fitness function in the optimization algorithm. This optimization system can guide cloud customers to purchase appropriate resources and make decision of deployment configuration such as scale, scheduling and capacity.	cloud computing;computation;fitness function;genetic algorithm;mathematical optimization;maximal set;queueing theory;requirement;scheduling (computing);software deployment	Jing Jiang;Jie Lu;Guangquan Zhang	2011	2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing	10.1109/DASC.2011.112	computer simulation;simulation;computer science;theoretical computer science;operating system;machine learning;distributed computing;predictive modelling;queueing theory;statistics	HPC	-22.467342115364108	63.21937937262471	146878
533e86a4494452704f788a2b2ffeaa515242754f	optical signal processing and stealth transmission for privacy	traffic analysis optical signal processing optical stealth transmission techniques optical encryption encryption keys;optical transmitters;encryption;optical fibers;optical signal processing optical fibers encryption optical receivers optical transmitters noise;optical signal processing;optical information processing cryptography;optical receivers;interference cancellation optical encryption key distribution photonic neurons optical steganography amplified spontaneous emission;noise	Optical encryption, key generation, and optical stealth transmission techniques for protecting the privacy of communication in optical networks are proposed and summarized. The signal processing methods based on fiber components provide ways to encrypt data and generate encryption keys at the speed of data transmission in optical fibers. Private and confidential communication is achieved without compromising the capacity and bandwidth of the optical network. Optical stealth transmission can hide the signal in plain sight. Because an eavesdropper can neither read the data nor detect the existence of the transmitted signal, optical stealth transmission provides a higher level of privacy. A hybrid system which includes both the public channels and stealth channels can effectively provide anonymous communication and defend against traffic analysis.	adaptive server enterprise;amplifier;confidentiality;domain analysis;encryption;hybrid system;key distribution;key generation;key space (cryptography);lightwave 3d;neuromorphic engineering;neuron;noise (electronics);optical computing;optical fiber;privacy;signal processing;stealth;steganography;tor messenger;traffic analysis;video post-processing	Ben Wu;Bhavin J. Shastri;Prateek Mittal;Alexander N. Tait;Paul R. Prucnal	2015	IEEE Journal of Selected Topics in Signal Processing	10.1109/JSTSP.2015.2424690	optical transport network;optical burst switching;telecommunications;computer science;noise;optical fiber;optical performance monitoring;computer security;encryption;optical cross-connect;computer network;optical communications repeater	Security	-31.33077608885458	71.66203124178212	146902
d1ee3e526a4ea4ddcec21a63ae1d5b39d883252b	an effective dynamic programming offloading algorithm in mobile cloud computing system	offloading algorithm mobile cloud computing application partitioning;mobile handsets servers mobile communication dynamic programming heuristic algorithms algorithm design and analysis cloud computing;mobile computing cloud computing dynamic programming;network performance dynamic programming offloading algorithm mobile cloud computing system mobile application dpoa mobile devices application program characteristics cloud server efficiency	Mobile applications are providing increasingly richer functionalities, which generally result in high computational complexity and thus high energy consumption of mobile devices. In this article, to alleviate the computational burden of mobile devices, we present a Dynamic Programming based Offloading Algorithm (DPOA) to quickly find the optimal partitioning between executing subcomponents of a mobile application at the mobile device and the cloud server, taking into account the CPU speed of mobile device, network performance, the characteristics of an application program, and the efficiency of cloud server. DPOA solves the offloading optimization problem with much lower complexity than the Branch & Bound used in [1][2], while significantly reducing the execution time of mobile application proved by the simulations.	branch and bound;central processing unit;computational complexity theory;dynamic programming;mathematical optimization;mobile app;mobile cloud computing;mobile device;network performance;online algorithm;optimization problem;run time (program lifecycle phase);server (computing);simulation;time complexity;virtual private server	Yanchen Liu;Myung J. Lee	2014	2014 IEEE Wireless Communications and Networking Conference (WCNC)	10.1109/WCNC.2014.6952554	real-time computing;cloud computing;theoretical computer science;distributed computing;mobile computing;provisioning	Mobile	-21.848192301499665	66.99149722247617	147034
d12d7e228aa5b1c6e05b9a75cc5b8e4062cbdb03	towards professionally user-adaptive large medical image transmission processing in mobile telemedicine systems		To effectively and efficiently reduce the transmission costs of large medical image in (mobile) telemedicine systems, we design and implement a professionally user-adaptive large medical image transmission method called UMIT. Before transmission, a preprocessing step is first conducted to obtain the optimal image block (IB) replicas based on the users’ professional preference model and the network bandwidth at a master node. After that, the candidate IBs are transmitted via slave nodes according to the transmission priorities. Finally, the IBs can be reconstructed and displayed at the users’ devices. The proposed method includes three enabling techniques: (1) user’s preference degree derivation of the medically useful areas, (2) an optimal IB replica storage scheme, and (3) an adaptive and robust multi-resolution-based IB replica selection and transmission method. The experimental results show that the performance of our proposed UMIT method is both efficient and effective, minimizing the response time by decreasing the network transmission cost.	master/slave (technology);mega man network transmission;nmap security scanner;preprocessor;response time (technology)	Yanping Zhuang;Nan Jiang;Qing Li;Hua Hu;Dickson K. W. Chiu	2016	Multimedia Systems	10.1007/s00530-016-0526-5	real-time computing;simulation;telecommunications;computer science;electrical engineering;operating system;world wide web;computer network	Mobile	-23.382553853499747	69.78772463214841	147136
e98899b493e771f63dff140ef4fb4e77e115b31f	building models of computation of service-oriented software via monitoring performance indicators (short paper)	performance indicators service oriented software model of computation service interface;service oriented architecture estimation theory;computational modeling mathematical model monitoring software programming data models random access memory;service oriented software;service interface;source code service oriented software performance indicator monitoring pricing policy cost precalculator resource consumption estimation;performance indicators;model of computation	The typical pricing policy, offered by service providers, is on a pay-as-you-go basis, which is proportional to the resources consumed by services. However, providers do not expose the specification of the resource consumption of services. Thus, providers offer cost pre-calculators that are service-agnostic. Such cost pre-calculators take into account upper bounds of provided facilities, instead of an estimation of the resource consumption of a service. To help service providers in specifying the resource consumption of services, we propose an initial version of an automated approach that captures the resource consumption of services. To make it in an independent way of the used measurement units and of the infrastructure over which a service is hosted, our approach builds for a service a mathematical model of computation, estimating its computational performance that is directly related to its resource consumption. Our approach moves beyond the state-of-the-art, since it automatically builds a model of computation based on the interface of a service, instead of its source code, and based on the monitoring of the execution of a service by using its executable files, instead of the monitoring or the theoretical analysis of its source code. The evaluation of our approach in a set of basic case studies shows promising results.	mathematical model;model of computation;refinement (computing);service-oriented device architecture	Dionysis Athanasopoulos;Barbara Pernici	2015	2015 IEEE 8th International Conference on Service-Oriented Computing and Applications (SOCA)	10.1109/SOCA.2015.21	model of computation;service level requirement;real-time computing;simulation;service product management;computer science;service delivery framework;operating system;performance indicator;software engineering;software as a service;database;data as a service	SE	-24.841282336978292	61.157794674186576	147815
488df3dd1f35fa9babb30d8a2be624965b6ef61e	gsma based automated negotiation model for grid scheduling	grid scheduling;resource utilization;protocols;sla lifecycle;processor scheduling;resource allocation;information technology;resource management;ws agreement;contracts;ws agreement specification gsma based automated negotiation model grid scheduling grid environment resource utilization grid sla management architecture sla lifecycle deviation based resource ordering algorithm sla negotiation process;grid;software architecture;scheduling algorithm;engines;monitoring;scheduling;virtual organization service level agreement ws agreement grid negotiation;virtual organization;grid sla management architecture;success rate;grid environment;ws agreement specification;deviation based resource ordering algorithm;software architecture grid computing resource allocation scheduling;service level agreement;grid computing;gsma based automated negotiation model;negotiation;automated negotiation;throughput;sla negotiation process	In order to coordinate multiple resource providers in grid environment to meet a common objective, support for negotiation is needed to establish a contract between the users and the resource providers that clearly states the QoS required, restrictions on resource utilization and penalties during violation of the objective. In this paper, we propose an architecture called GSMA (grid SLA management architecture) that supports entire operations in SLA lifecycle such as negotiation, creation, monitoring, violation, enforcement and destroy. We propose a deviation based resource ordering algorithm (DRS) and successfully automates the SLA negotiation process with backing up of resource support. The negotiation process is implemented based on WS Agreement specification. Simulation results against gridway meta scheduler shows improved performance interms of average SLA creation time, success rate and throughput.	algorithm;quality of service;scheduling (computing);service-level agreement;simulation;throughput	Ponnuram Balakrishnan;S. Thamarai Selvi;Gnanapragasam Rajesh Britto	2008	2008 IEEE International Conference on Services Computing	10.1109/SCC.2008.59	real-time computing;database;distributed computing;business	HPC	-24.15184363713278	63.243897293311875	147906
b99d1dc199534232caa4d8c8acdb4070c80be921	virtual machine boot time model	booting cloud computing computational modeling bandwidth kernel resource management virtual machine monitors	Cloud computing by far brings a lot of undeniable advantages. Accordingly, many research works aim to evaluate the characteristics of cloud systems on many aspects such as performance, workload, cost, provisioning policies, and resources management. In order to setup a cloud system for running rigorous experiments, ones have to overcome a huge amount of challenges and obstacles to build, deploy, and manage systems and applications. Cloud simulation tools help researchers to focus only on the parts they are interesting about without facing the aforementioned challenges. However cloud simulators still do not provide accurate models for Virtual Machine (VM) operations. This leads to incorrect results in evaluating real cloud systems. Following previous works on live-migration, we present in this paper an experiment study we conducted in order to propose a first-class VM boot time model. Most cloud simulators often ignore the VM boot time or give a naive model to represent it. After studying the relationship between the VM boot time and different system parameters such as CPU utilization, memory usage, I/O and network bandwidth, we introduce a first boot time model that could be integrated in current cloud simulators. Through experiments, we also confirmed that our model correctly reproduced the boot time of a VM under different resources contention.	booting;central processing unit;cloud computing;cloudsim;desktop virtualization;experiment;hard disk drive performance characteristics;input/output;provisioning;simgrid;simulation;the times;virtual machine	Thuy-Linh Nguyen;Adrien Lèbre	2017	2017 25th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP)	10.1109/PDP.2017.58	embedded system;parallel computing;real-time computing;simulation;computer science;operating system;distributed computing	HPC	-22.20960362531205	60.55743880541042	148002
148bbdae770cc7b948ab22f052eef88a4a770c56	distributed management of exclusive resources in collaborative multimedia systems	distributed algorithms;groupware;multicast communication;teleconferencing;resource allocation;distance learning;audio video;transport layer;multimedia systems;reliable multicast;internet;resource allocation groupware multimedia communication distributed algorithms multicast communication internet distance learning teleconferencing;multimedia communication;internet application;resource allocation algorithm distributed management exclusive resources collaborative multimedia systems internet applications desktop conferencing interactive distance learning audio channels video channels shared applications distributed algorithm transport layer reliable multicasting composite resources primitive resources token session coordinator resource holder failure conditions;distributed algorithm;distributed management;resource management collaboration multimedia systems internet computer aided instruction video sharing videoconference distributed algorithms multicast algorithms permission	Collaborative multimedia systems encompass many Internet applications such as desk-top conferencing and interactive distance learning. These applications often contain resources , such as audio, video and shared applications, that must be accessed exclusively by one participant at a time. In this paper, we present a distributed algorithm that manages the access to these exclusive resources. The algorithm is based on the assumption that the transport layer provides reliable multicasting. Resources are classiied into two main classes: primitive and composite. Composite resources consist of a set of two or more primitive resources. A token is associated with each resource unit, and a participant must obtain the resource's token before using the resource. To use a resource, certain permissions may be needed from certain entities such as the session coordinator, the current resource holder and, in some cases, the resource itself. Resources that are not used by any participant are held by a special entity called the free resource holder. The participant processes in our algorithm uses two types of multicast messages, one to request resources and the other to grant resources. The algorithm guarantees that at any given time, the resource is held by exactly one participant, either an actual participant or the free resource holder. The token of any resource will never be lost under all possible failure conditions.	composite video;deadlock;distributed algorithm;entity;graphical user interface;multicast;operating system;propagation delay;race condition;software propagation;succession;web resource	Hussein M. Abdel-Wahab;Alaa Youssef;Kurt Maly	1998		10.1109/ISCC.1998.702469	distance education;distributed algorithm;the internet;teleconference;reliable multicast;resource allocation;computer science;distributed computing;world wide web;human resource management system;transport layer;computer network	OS	-23.43616295864195	71.632504693534	148135
7b37dec23e64e12bb1acf69ac1f0c0377f4ec20c	resource and performance prediction at high utilization for n-tier cloud-based service systems	benchmark;performance;cloud;prediction;resource	One of the key objectives of cloud computing systems is to meet the service level agreements (SLAs) under conditions of high resource utilization. Cloud service providers often need to design policies for resource sharing and performance optimization. As a result, being able to predict the performance and resource utilizations prior to implementing these policies is important to the dynamic provisioning of services by cloud providers. It is a significant and difficult challenge due to the fact that requests for resources often interact with each other in complex ways. Moreover, the dynamics of the cloud environment bring more problems to predicting the performance of a running query or workload. Hence, an accurate situation-aware model which can capture the complex interactions among resource requests is useful for addressing this challenge. To this end, we propose an efficient and highly accurate resource and performance prediction framework which takes into account the interactions among concurrently running resource requests for n-tier service systems. The proposed framework extends the Gaussian process and kernel canonical correlation analysis techniques and is able to dynamically adapt to variations in workload and physical resource usage. The proposed framework has been trained and evaluated extensively with a realistic multi-tier cloud application benchmark - the RUBiS benchmark system. The results demonstrate that the framework yields highly accurate performance and resource usage predictions, especially under high resource utilization conditions.	benchmark (computing);cloud computing;gaussian process;interaction;mathematical optimization;multitier architecture;performance prediction;performance tuning;provisioning;service-level agreement;software as a service	Wenbin Zhang;Yuliang Shi;Yongqing Zheng;Lei Liu;Li-zhen Cui	2017		10.1145/3014812.3014857	real-time computing;simulation;engineering;knowledge management	HPC	-23.13315089041297	61.65744996154508	148250
b282eef730cf0c00f6630c738296a7292a682218	learn-as-you-go with megh: efficient live migration of virtual machines		Cloud providers leverage live migration of virtual machines to reduce energy consumption and allocate resources efficiently in data centers. Each migration decision depends on three questions: when to move a virtual machine, which virtual machine to move and where to move it? Dynamic, uncertain, and heterogeneous workloads running on virtual machines make such decisions difficult. Knowledge-based and heuristics-based algorithms are commonly used to tackle this problem. Knowledge-based algorithms, such as MaxWeight scheduling algorithms, are dependent on the specifics and the dynamics of the targeted Cloud architectures and applications. Heuristics-based algorithms, such as MMT algorithms, suffer from high variance and poor convergence because of their greedy approach. We propose an online reinforcement learning algorithm called Megh. Megh does not require prior knowledge of the workload rather learns the dynamics of workloads as-it-goes. Megh models the problem of energy- and performance-efficient resource management during live migration as a Markov decision process and solves it using a functional approximation scheme. While several reinforcement learning algorithms are proposed to solve this problem, these algorithms remain confined to the academic realm as they face the curse of dimensionality. They are either not scalable in real-time, as it is the case of MadVM, or need an elaborate offline training, as it is the case of Q-learning. These algorithms often incur execution overheads which are comparable with the migration time of a VM. Megh overcomes these deficiencies. Megh uses a novel dimensionality reduction scheme to project the combinatorially explosive state-action space to a polynomial dimensional space with a sparse basis. Megh has the capacity to learn uncertain dynamics and the ability to work in real-time without incurring significant execution overhead. Megh is both scalable and robust. We implement Megh using the CloudSim toolkit and empirically evaluate its performance with the PlanetLab and the Google Cluster workloads. Experiments validate that Megh is more cost-effective, converges faster, incurs smaller execution overhead and is more scalable than MadVM and MMT. An empirical sensitivity analysis explicates the choice of parameters in experiments.	algorithm;dimensionality reduction;experiment;mpeg media transport;polynomial;real-time clock;real-time computing;reinforcement learning;scalability;virtual machine	Debabrota Basu;Xiayang Wang;Yang Hong;Haibo Chen;Stéphane Bressan	2017	2017 IEEE 37th International Conference on Distributed Computing Systems (ICDCS)	10.1109/ICDCS.2017.173	live migration;cloudsim;computer science;reinforcement learning;cloud computing;markov decision process;virtual machine;planetlab;distributed computing;heuristics	HPC	-22.662624577363104	62.47478222753477	148270
339e42b53f6f255b2c47909670146f176914465c	predicting inter-data-center network traffic using elephant flow and sublink information	sublink datacenter network network management network traffic prediction elephant flow;wavelet transforms;predictive models wavelet transforms internet bandwidth autoregressive processes;internet;autoregressive processes;bandwidth;predictive models	With the ever increasing number of large scale Internet applications, inter-data-center (inter-DC) data transfers are becoming more and more common. Traditional inter-DC transfers suffer from both low utilization and congestion, and traffic prediction is an important method to optimize these transfers. Inter-DC traffic is harder to predict than many other types of network traffic because it is dominated by a few large applications. We propose a model that significantly reduces the prediction errors. In our model, we combine wavelet transform with artificial neural network to improve prediction accuracy. Specifically, we explicitly add information of sublink traffic and elephant flows, the least predictable yet dominating traffic in inter-DC network, into our prediction model. To reduce the amount of monitoring overhead for the elephant flow information, we add interpolation to fill in the unknown values in the elephant flows. We demonstrate that we can reduce prediction errors over existing methods by 5%~30%. Our prediction is in production as part of the traffic scheduling system at Baidu, one of the largest Internet companies in China, helping to reduce the peak network bandwidth.	artificial neural network;data center;elephant flow;internet;interpolation;network congestion;network packet;network switch;network traffic control;overhead (computing);provisioning;sampling (signal processing);scheduling (computing);stationary wavelet transform	Yi Li;Hong Liu;Wenjun Yang;Dianming Hu;Xiaojing Wang;Wei Xu	2016	IEEE Transactions on Network and Service Management	10.1109/TNSM.2016.2588500	traffic generation model;network traffic control;the internet;simulation;computer science;data mining;predictive modelling;law;bandwidth;computer network;wavelet transform	Networks	-26.02072494303557	63.88494722407688	148376
5c8a83cbd03f0e20acdc3c0c47da95e1d2573561	improved genetic algorithm based approach for qos aware web service composition	harmony search web service web service composition qos genetic algorithm simulated annealing;optimization techniques genetic algorithm qos web service composition xml quality of service response time optimal execution plan np hard problem;genetic algorithms quality of service sociology statistics web services simulated annealing heuristic algorithms;web service;simulated annealing;qos;web service composition;genetic algorithm;xml computational complexity genetic algorithms quality of service web services;harmony search	Use of web services is one of the most rapidly developing technologies. Since web services are defined by XML- based standards to overcome platform dependency, they are very eligible to integrate with each other in order to establish new services. This composition enables us to reuse existing services, which results in less cost and time consumption. One of the recent problems with web service composition is to maximize the overall Quality of Service (QoS) of the composed service. Most common elements of QoS are response time, availability, reliability, throughput and cost (price). Since the selection of the optimal execution plan that maximizes the composition's overall QoS is a NP hard problem, applying optimization techniques is very popular. In this work, we propose an improved Genetic Algorithm based approach to optimize the overall QoS of the composed service. Experimental results indicate improvement for QoS of the composition built by the proposed methods.	fitness function;genetic algorithm;harmony search;heuristic (computer science);mathematical optimization;memetic algorithm;multi-objective optimization;overhead (computing);parallel computing;quality of service;query plan;rate of convergence;response time (technology);run time (program lifecycle phase);service composability principle;simulated annealing;throughput;web service	A. Erdinc Yilmaz;Pinar Senkul	2014	2014 IEEE International Conference on Web Services	10.1109/ICWS.2014.72	web service;mobile qos;genetic algorithm;quality of service;simulated annealing;harmony search;computer science;data mining;database;law;world wide web	HPC	-19.86505911107345	64.93781967755122	148668
47cf2761a062406a3e29fa60c3d16c6b1aaeb483	statistical service assurances for applications in utility grid environments	resource utilization;resource management grid computing admission control application software computational modeling web and internet services information technology computer applications workstations scheduling;information use;grid computing statistical service assurances utility grid environments admission control resource reservation information technology business applications statistical demand profile central limit theorem statistical multiplexing application resource requirements resource utilization information data center servers simulation correlations application resource demands;information technology;resource manager;telecommunication congestion control;business communication;satisfiability;information services;time of day;resource reservation;information services statistical analysis telecommunication congestion control business communication network servers information technology information use;data center;network servers;statistical analysis;utility computing;grid computing	In this paper we focus on techniques to support admission control and advance resource reservation for applications acquiring information technology (IT) resources from utility grid environments. Utility grid environments offer programmatic access to resources for complex multi-tier applications. In particular we consider business applications which require resources continuously but that have resource demands that change regularly based on factors such as time of day and day of week. We present a statistical demand profile approach for characterizing time varying application resource requirements along with a method that provides statistical assurances regarding the number of resources needed to satisfy the combined requirements of many applications over time. We illustrate the feasibility of our approach with a case study that uses resource utilization information from 48 data center servers. Simulation experiments explore the sensitivity of the assurances to correlations between application resource demands and the precision of the demand profiles.	aggregate data;data center;distortion;experiment;grid computing;ibm service management framework;multiplexing;multitier architecture;quality of service;requirement;simulation;time-sharing	Jerome A. Rolia;Xiaoyun Zhu;Martin F. Arlitt;Artur Andrzejak	2002		10.1109/MASCOT.2002.1167084	data center;in situ resource utilization;real-time computing;computer science;resource management;operating system;distributed computing;utility computing;business communication;information technology;information system;grid computing;computer network;satisfiability	HPC	-23.410156820868206	63.70983558955457	148748
99bf195f48a392b264d0050d8a1c83f7f9412912	using cloudsim to model and simulate cloud computing environment	cloud infrastructure cloudsim cloud computing environment future internet of services service providers user requirement energy consumption energy efficiency mechanism datacenter profit making applications;simulation;profitability cloud computing computer centres digital simulation power aware computing;computational modeling cloud computing power demand resource management servers educational institutions computer architecture;computer centres;power aware computing;energy effective;profitability;cloudsim;green computing cloudsim cloud computing simulation energy effective;digital simulation;green computing;cloud computing	Cloud computing will be a major technology in the development of the future Internet of Services. Service providers want to remove the bottle neck of the cloud computing system in order to satisfy user requirement. And in order to save energy consumption they also need to apply new energy-efficiency mechanism and observe its effects on a data center. As it is difficult to test new mechanism in real cloud computing environment and researchers often cannot reach the real cloud environment, simulation to model the mechanism and evaluate the results is necessary. Simulating a data center avoids spending time and effort to configure a real testing environment. Moreover, as real machines are not used for testing purposes, their computational power can be allocated to profit-making applications. This paper introduces a simulation framework called CloudSim which provides simulation, power to manage services and modeling of cloud infrastructure. And we have also discussed about how to extend it to simulation your own mechanism in cloud computing.	algorithm;cloud computing;cloudsim;computation;data center;future internet;internet protocol suite;simulation;user requirements document	Long Wang;Yuqing Lan;Qingxin Xia	2013	2013 Ninth International Conference on Computational Intelligence and Security	10.1109/CIS.2013.75	cloud computing security;green computing;real-time computing;simulation;cloud computing;computer science;operating system;end-user computing;cloud testing;distributed computing;utility computing;profitability index	HPC	-23.486623343277397	63.050620831049905	149376
f0c08c7d4a64e967c5b9d0cdc6f43fb5df26889b	evaluating quorum systems over the internet	analytical models;distributed system;protocols;quorum system;image segmentation;history;name servers;performance evaluation;computer crashes;network partitions;distributed processing;simulation;dynamic quorum systems;signatures;quorum systems evaluation;group communication;mutual exclusion;fault tolerant computing;computational modeling;life history;internet;fault tolerance quorum systems evaluation internet distributed system distributed databases replicated databases name servers mutual exclusion distributed access control signatures simulation wide area group communication protocol global clock generic quorum system evaluator static quorum systems dynamic quorum systems network partitions;static quorum systems;internet history computer crashes distributed databases web server access control computational modeling analytical models access protocols image segmentation;wide area group communication protocol;global clock;fault tolerance;generic quorum system evaluator;distributed databases;access protocols;distributed access control;protocols internet distributed processing fault tolerant computing computer network reliability performance evaluation;access control;web server;replicated databases;computer network reliability	Quorum systems serve as a basic tool providing a uniform and reliable way to achieve coordination in a distributed system. They are useful for distributed and replicated databases, name servers, mutual exclusion, and distributed access control and signatures. Traditionally, two basic methods have been used to evaluate quorum systems: the analytical approach, and simulation. This paper proposes a third, empirical approach. We collected 6 months’ worth of connectivity and operability data of a system consisting of 14 real computers using a wide area group communication protocol. The system spanned two geographic sites and three different Internet segments. We developed a mechanism that merges the local views into a unified history of the events that took place, ordered according to an imaginary global clock. We then developed a tool called the Generic Quorum-system Evaluator (GQE), which evaluates the behavior of any given quorum system over the unified, real-life history. We compared fourteen dynamic and static quorum systems. We discovered that as predicted, dynamic quorum systems behave better than static systems. However we found that many assumptions taken by the traditional approaches are unjustified: crashes are strongly correlated, network partitions do occur, even within a single Internet segment, and we even detected a brief simultaneous crash of all the participating computers.	access control;antivirus software;communications protocol;computer;database;distributed computing;imaginary time;internet;interpreter (computing);mutual exclusion;operability;quorum (distributed computing);real life;simulation	Yair Amir;Avishai Wool	1996		10.1109/FTCS.1996.534591	computer science;database;distributed computing;computer security	Networks	-23.506753122906176	72.4017578028144	149676
50d9dc9b953bad90248be470590dfbad032382de	i/o-conscious and prediction-enabled virtual machines scheduling	virtualization;job shop scheduling;processor scheduling;virtual machining;prediction algorithms;virtual machine monitors	Virtual machine (VM) technology plays an important role in modern cluster and cloud computing environments due to its advantages in application isolation, resource partition and load consolidation. Since a large number of VMs usually run simultaneously in these environments, VMs scheduling is key to achieve resources efficiency. Unfortunately, most existing scheduling strategies are complicated, with unacceptable overhead in a large-scale virtualization environment. Further more, they tend to produce biased results without considering the I/O characteristics of VMs and physical machines (PMs). To deal with the issue, this paper proposes a new strategy for scheduling VMs over physical clusters. Taking into consideration the I/O characteristics, the proposed strategy can obtain better scheduling results while with lower overhead. Moreover, a prediction algorithm is suggested, which, when combined with the proposed strategy, can further improve the scheduling results. The proposed strategy and prediction algorithm have been implemented and evaluated with the SPEC CPU 2006 and Netperf benchmarks. The experimental results show that the average completion time of SPEC reduces by about 23%, whereas the standard deviation of Netperf average bandwidth decreases from 10.9 to 4.2.	algorithm;benchmark (computing);central processing unit;cloud computing;experiment;hardware virtualization;input/output;lisp machine;netperf;overhead (computing);specfp;scheduling (computing);semiconductor consolidation;smoothing;time complexity;virtual machine	Jinlei Jiang;Xun Zhao;Yongwei Wu;Weimin Zheng	2016	2016 IEEE International Conference on Computer and Information Technology (CIT)	10.1109/CIT.2016.92	fair-share scheduling;fixed-priority pre-emptive scheduling;job shop scheduling;parallel computing;real-time computing;earliest deadline first scheduling;virtualization;temporal isolation among virtual machines;flow shop scheduling;prediction;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;two-level scheduling;database;distributed computing;round-robin scheduling;i/o scheduling;statistics	HPC	-19.409939417135988	60.765478187544815	150006
edafd289e60940b15ff02a5874084856dcb7a049	resource provisioning for cloud computing	operant conditioning;performance model;service level agreement;heuristic algorithm;cloud computing	In resource provisioning for cloud computing, an important issue is how resources may be allocated to an application mix such that the service level agreements (SLAs) of all applications are met. A performance model with two interactive job classes is used to determine the smallest number of servers required to meet the SLAs of both classes. For each class, the SLA is specified by the relationship: Prob [response time ≤ x] ≥ y. Two server allocation strategies are considered: shared allocation (SA) and dedicated allocation (DA). For the case of FCFS scheduling, analytic results for response time distribution are used to develop a heuristic algorithm that determines an allocation strategy (SA or DA) that requires the smallest number of servers. The effectiveness of this algorithm is evaluated over a range of operating conditions. The performance of SA with non-FCFS scheduling is also investigated. Among the scheduling disciplines considered, a new discipline called probability dependent priority is found to have the best performance in terms of requiring the smallest number of servers.	algorithm;cloud computing;heuristic (computer science);provisioning;response time (technology);scheduling (computing);server (computing);service-level agreement	Ye Hu;Johnny S. Wong;Gabriel Iszlai;Marin Litoiu	2009		10.1145/1723028.1723041	heuristic;real-time computing;simulation;cloud computing;computer science;operating system;operant conditioning;database;distributed computing	Metrics	-21.981044591706233	62.495316025188785	150218
322334c99e9c03ca6d28f231ce9dc069db073751	cyber security cryptography and machine learning		We propose a method for stealthy, covert, fiber-optic communication. In this method, the power of the transmitted signal is spread and lowered below the noise level both in time as well as in frequency domains which makes the signal “invisible”. The method is also efficient in jamming avoidance.	computer security;cryptography;fiber-optic communication;machine learning;noise (electronics);radio jamming	Itai Dinur;Shlomi Dolev;Sachin Lodha	2018		10.1007/978-3-319-94147-9	theoretical computer science;internet privacy;computer security	ML	-31.355649277791805	71.65095437478398	150873
483f83223b913a3585b1e3ee06a597000eafa9d0	improvements on block size control method for adaptive parallel downloading	file servers;fault tolerant;pipeline processing file servers internet parallel processing;size control programmable control adaptive control network servers file servers mirrors fault tolerance acceleration bandwidth pipeline processing;network control technologies block size control method adaptive parallel downloading fault tolerance network service;network control;internet;point of view;network services;parallel processing;control method;pipeline processing	Although the traditional downloading programs usually select one server and retrieves a file from the server, it is more practical to select more servers (e.g. mirror servers) and to fetch different parts of a file from the servers in parallel from the point of view of downloading time and fault-tolerance of network service. We have already proposed an adaptive parallel downloading method, which enables us to stabilize and accelerate the downloading time even in the network environments with various bandwidths. Since we found a little room for improvement in the method, this paper describes an improved method. The new method has the following features: (1) independence of the number of mirror servers and (2) introduction of request pipelining into parallel downloading. Based on practical experiments from the viewpoint of downloading speed and stability of downloading time, we confirm that the improved method is more effective than the previous methods. There is a possibility that the improved method become one of the most important network control technologies for network assurance.	block size (cryptography);disk mirroring;download;experiment;fault tolerance;internet;pipeline (computing);point of view (computer hardware company);server (computing);testbed;throughput	Junichi Funasaka;Kazuhiro Nagayasu;Kenji Ishida	2004	24th International Conference on Distributed Computing Systems Workshops, 2004. Proceedings.	10.1109/ICDCSW.2004.1284101	embedded system;file server;parallel processing;fault tolerance;real-time computing;the internet;computer science;operating system;database;distributed computing;server;computer network	HPC	-20.22420953571731	71.27453750296397	151857
053f5e966e3417bd3702f619d6290db053acad19	data center energy cost minimization: a spatio-temporal scheduling approach	telecommunication power management cloud computing computer centres cost reduction electricity supply industry deregulation energy consumption power aware computing resource allocation scheduling spatiotemporal phenomena;electricity load management servers delays portals minimization internet;resource allocation;cost reduction;telecommunication power management;computer centres;power aware computing;energy consumption;scheduling;real life electricity price data center energy cost minimization spatio temporal scheduling approach cloud computing internet data center energy consumption deregulated electricity markets temporal energy price variation geographic energy price variation distributed idc spatio temporal load balancing approach;spatiotemporal phenomena;cloud computing;electricity supply industry deregulation	Cloud computing is supported by an infrastructure known as Internet data center (IDC). As cloud computing thrives, the energy consumption and cost for IDCs are exploding. There is growing interest in energy cost minimization for IDCs in deregulated electricity markets. In this paper we study how to leverage both geographic and temporal variation of energy price to minimize energy cost for distributed IDCs. To this end, we propose a novel spatio-temporal load balancing approach. Using reallife electricity price and workload traces, extensive evaluations demonstrate that the proposed spatio-temporal load balancing approach significantly reduces energy cost for distributed IDCs.	cloud computing;data center;dynamic circuit network;load balancing (computing);scheduling (computing);tracing (software)	Jianying Luo;Lei Rao;Xue Liu	2013	2013 Proceedings IEEE INFOCOM	10.1109/INFCOM.2013.6566791	real-time computing;simulation;cloud computing;resource allocation;computer science;operating system;scheduling	HPC	-21.032035305601827	63.10661505867286	152085
963f0f15599c95bff96143a08bbbb82e0f2f6bf9	a game-theoretical approach to incentive design in collaborative intrusion detection networks	groupware;game theory;incentive compatibility;nash equilibrium;resource allocation game theoretical approach incentive design collaborative intrusion detection networks intrusion detection systems collective knowledge sharing intrusion assessment trust management nash equilibrium iterative algorithm;collective knowledge sharing;resource allocation;resource management;trust management;collaboration;intrusion detection;iterative algorithm;gold;collaborative intrusion detection networks;collaboration intrusion detection collaborative work nash equilibrium environmental management game theory iterative algorithms discrete event simulation convergence of numerical methods resource management;intrusion assessment;security of data game theory groupware resource allocation;games;intrusion detection systems;numerical experiment;incentive design;peer to peer computing;copper;existence and uniqueness;free riding;security of data;intrusion detection system;game theoretical approach;discrete event simulation	Traditional intrusion detection systems (IDSs) work in isolation and may be easily compromised by new threats. An intrusion detection network (IDN) is a collaborative IDS network intended to overcome this weakness by allowing IDS peers to share collective knowledge and experience, hence improve the overall accuracy of intrusion assessment. In this work, we design an incentive model based on trust management by using game theory for peers to collaborate truthfully without free-riding in an IDN environment. We show the existence and uniqueness of a Nash equilibrium under which peers can communicate in an incentive compatible manner. Using duality of the problem, we develop an iterative algorithm that converges geometrically to the equilibrium. Our numerical experiments and discrete event simulation demonstrate the convergence to the Nash equilibrium and the incentives of the resource allocation design.	algorithm;control system;dynamic problem (algorithms);experiment;game theory;internationalized domain name;intrusion detection system;iterative method;nash equilibrium;numerical analysis;simulation;trust management (information system);vii	Quanyan Zhu;Carol J. Fung;Raouf Boutaba;Tamer Basar	2009	2009 International Conference on Game Theory for Networks	10.1109/GAMENETS.2009.5137424	simulation;computer science;distributed computing;computer security	Mobile	-29.158056585248737	72.70039281894124	152210
0aab4f6f01b217909accc47f60cef1ef2da22865	providing green slas in high performance computing clouds	software;optimisation;renewable energy sources;green products;contracts;high performance computing clouds greedy heuristics scheduling policies provider profits power sources job scheduling optimization based framework control infrastructure power distribution green energy green sla service renewable energy service level agreements energy source oblivious services cloud providers quantifiable green cloud services marketing tools carbon emission reduction sustainability goals enterprises climate change clean services clean products;environmental science computing;green products air pollution schedules batteries optimization servers software;servers;sustainable development air pollution cloud computing contracts environmental science computing green computing optimisation parallel processing renewable energy sources;air pollution;batteries;schedules;optimization;parallel processing;sustainable development;green computing;cloud computing	Demand for clean products and services is increasing as society is becoming increasingly aware of climate change. In response, many enterprises are setting explicit sustainability goals and implementing initiatives to reduce carbon emissions. Quantification and disclosure of such goals and initiatives have become important marketing tools. As enterprises and individuals shift their workloads to the cloud, this drive toward quantification and disclosure will lead to demand for quantifiable green cloud services. Thus, we argue that cloud providers should offer a new class of green services, in addition to existing (energy-source-oblivious) services. This new class would provide clients with explicit service-level agreements (which we call Green SLAs) for the percentage of renewable energy used to run their workloads. In this paper, we first propose an approach for High Performance Computing cloud providers to offer such a Green SLA service. Specifically, each client job specifies a Green SLA, which is the minimum percentage of green energy that must be used to run the job. The provider earns a premium for meeting the Green SLA, but is penalized if it accepts the job but violates the Green SLA. We then propose (1) a power distribution and control infrastructure that uses a small amount of hardware to support Green SLAs, (2) an optimization-based framework for scheduling jobs and power sources that maximizes provider profits while respecting Green SLAs, and (3) two scheduling policies based on the framework. We evaluate our framework and policies extensively through simulations. Our main results show the tradeoffs between our policies, and their advantages over simpler greedy heuristics. We conclude that a Green SLA service that uses our policies would enable the provider to attract environmentally conscious clients, especially those who require strict guarantees on their use of green energy.	cloud computing;greedy algorithm;green book (cd standard);heuristic (computer science);job stream;mathematical optimization;referring expression generation;scheduling (computing);service-level agreement;simulation;supercomputer	Md. E. Haque;Kien Le;Iñigo Goiri;Ricardo Bianchini;Thu D. Nguyen	2013	2013 International Green Computing Conference Proceedings	10.1109/IGCC.2013.6604503	simulation;engineering;environmental resource management;operations management	HPC	-21.298202311262724	62.24591501343655	153197
261b3871f4d60459cd13835a11182d8ab623ebb1	efficient access to multimedia resources in distributed systems of distance learning	resource allocation computer aided instruction distance learning multimedia computing;resource allocation;computer aided instruction;distance learning;load balancing distance learning multimedia learning resources efficient access;load balancing distributed systems multimedia learning resources distance learning systems;multimedia computing;computer aided instruction multimedia communication load management streaming media educational institutions bandwidth	This work proposes an approach to improve the effectiveness of access to multimedia learning resources of distance learning systems on the basis of the load balancing.	distributed computing;load balancing (computing)	Irina Pavlovna Bolodurina;Denis Igorevich Parfenov;Alexander Shukhman	2013	2013 IEEE Global Engineering Education Conference (EDUCON)	10.1109/EduCon.2013.6530263	computer science;theoretical computer science;distributed computing;multimedia;synchronous learning	Visualization	-22.930655812607192	71.72853586722918	153697
4a2b05ee657639d0a66c1097bd3f31d629fa4a5a	capitalizing on free riders in p2p networks	indexation;file sharing;p2p networks;free riding	Free riding is a common phenomenon in P2P networks. Although several mechanisms have been proposed to handle free riding— mostly to exclude free riders, few of them have actually been adopted in practical systems. This may be attributed to the fact that they are nontrivial, and that completely eliminating free riders could jeopardize the sheer power created by the huge volume of participants in a P2P network. Rather than excluding free riders, in this paper we incorporate and utilize them to provide global index service to the files shared by other peers. The simulation results indicate that our model can significantly boost the search efficiency of a plain Gnutella, and the model is quite resistant to system churn rate and the ratio of free riding.	gnutella;peer-to-peer;simulation	Yuh-Jzer Joung;Terry Hui-Ye Chiu;Shy Min Chen	2007		10.1007/978-3-540-74466-5_56	simulation;computer science;internet privacy;free riding;computer security;file sharing	Metrics	-26.034317170741016	73.32794569650142	153838
48516d8687d3b04ecf7f01d22133c87757790615	performance evaluation of a saas cloud under different levels of workload computational demand variability and tardiness bounds		Abstract As the paradigm shift toward Software as a Service (SaaS) continues to gain momentum, there is a growing focus on the performance of SaaS clouds from both academia and industry. In this paper, we evaluate the performance of a SaaS cloud under various tardiness bounds and different levels of workload computational demand variability. The workload consists of bag-of-tasks jobs, which are scheduled on the underlying virtualized host environment. The jobs have soft deadlines and different levels of variability in their computational demands. A multi-tier SLA is employed, which imposes a soft and a hard tardiness bound on each job. Furthermore, the employed pricing scheme is based on the provided level of Quality of Service (QoS). The performance of the SaaS cloud is evaluated by simulation, in an attempt to shed light on how it is affected by the tardiness bound and the computational demand variability of the workload.		Georgios L. Stavrinides;Helen D. Karatza	2019	Simulation Modelling Practice and Theory	10.1016/j.simpat.2018.11.006	tardiness;real-time computing;workload;computer science;quality of service;software as a service;cloud computing	Metrics	-21.5206585908538	61.35836962056062	153915
d771e6e6215a963a9e25c1ec5c2c9bfdeccf227e	analyzing resource trade-offs in hardware overprovisioned supercomputers		Hardware overprovisioned systems have recently been proposed as a viable alternative for a power-efficient design of next-generation supercomputers. A key challenge for such systems is to determine the degree of overprovisioning, which refers to the number of extra nodes that need to be installed under a given power constraint. In this paper, we first show that the degree of overprovisioning depends on dynamic parameters, such as the job mix as well as the global power constraint, and that static decisions can result in limited system throughput. We then study an exhaustive combination of adaptive resource management strategies that span three job scheduling algorithms, four power capping techniques, and three node boot-up mechanisms to understand the trade-off space involved. We then draw conclusions about how these strategies can adaptively control the degree of overprovisioning and analyze their impact on job throughput and power utilization.	algorithm;booting;frequency capping;isoelastic utility;job scheduler;on-off keying;pipeline (computing);power management;scheduling (computing);simulation;supercomputer;throughput	Ryuichi Sakamoto;Tapasya Patki;Thang Cao;Masaaki Kondo;Koji Inoue;Masatsugu Ueda;Daniel A. Ellsworth;Barry Rountree;Martin Schulz	2018	2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS)	10.1109/IPDPS.2018.00062	computer science;distributed computing;resource management;throughput;computer hardware;scheduling (computing);job scheduler;benchmark (computing)	Arch	-21.17866818410829	61.08265672575826	154000
b1cfd8f89529c897c541446acd13f1a03d572252	compressing soap messages by using differential encoding	differential encoding;major drawback;art binary;soap compression;network bandwidth;new experimental concept;soap andintroduce;soap message;detailed surveyof state;enormous demand;compressing soap messages;classical approach;corba;java;simple object access protocol;data compression;internet;web services;web service;binary codes;message passing;bandwidth;xml;computer networks;transport protocols;encoding	A major drawback of using SOAP for application integration is its enormous demand for network bandwidth. Compared to classical approaches like Java-RMI and CORBA, SOAP messages typically cause more than three times more network traffic. In this paper we will give a detailed survey of state of the art binary encoding strategies for SOAP and introduce a new experimental concept for SOAP compression, which makes use of the commonly available WSDL description of a SOAP Web service.	autoregressive integrated moving average;binary file;common object request broker architecture;encoder;hypertext transfer protocol;java remote method invocation;mobile device;netbsd gzip / freebsd gzip;network traffic control;overhead (computing);soap;wbxml;web services description language;web service;xml	Christian Werner;Carsten Buschmann;Stefan Fischer	2004	Proceedings. IEEE International Conference on Web Services, 2004.	10.1109/ICWS.2004.1314780	web service;computer science;operating system;database;distributed computing;programming language;law;world wide web	HPC	-20.8233715851977	71.10007986074405	154194
f529bdac1d039d5a93de088d9e7587a3bcfe0e96	value-driven resource assignment in object-oriented real-time dependable systems	unifi;verification;software metrics;value driven resource assignment;system accomplishment level;performability metric;value driven admission policy;degradation;reliability;software metrics object oriented programming real time systems software fault tolerance resource allocation;performance evaluation;object oriented real time dependable systems;planner component;component failures;redundant execution techniques;processor scheduling;resource allocation;performability;real time;resource management;performance index;system resources;software fault tolerance;dependable computing;object oriented programming;performance metric;firenze;dependable systems;system organisation;redundant execution techniques value driven resource assignment object oriented real time dependable systems transient overloads component failures flexible management system resources real time systems performability metric system accomplishment level planner component value driven admission policy performability index optimal utilisation system organisation load sets;bonding;scheduling algorithm;time factors;affidabili;ricerca;resilient computing lab;object oriented;dependability;object oriented real time systems;load sets;transient overloads;validation;performability index;rcl;affidabilita;optimal utilisation;quality of service;florence;sistemi;assessment;real time systems performance evaluation time factors scheduling algorithm bonding degradation quality of service quality management resource management processor scheduling;quality management;flexible management;real time systems	This paper deals with object-oriented real-time dependable systems required to achieve the best usage of the resources even under adverse circumstances as transient overloads or component failures. Various possible tradeoffs among the different application requirements must be considered to allow a flexible management of system resources. On the basis of a simple formulation of the concept of object value in real-time systems we propose a performability metric that represents a suitable measure of system accomplishment level. A planner component is defined which is responsible for implementing a valuedriven admission policy that maximises the performability index and hence achieves the optimal utilisation of available system resources. The numerical evaluation of a system organisation taken as an example is performed for different load sets and various redundant execution tech-	dependability;numerical analysis;real-time clock;real-time computing;real-time transcription;requirement	Andrea Bondavalli;Felicita Di Giandomenico;Ivan Mura	1997		10.1109/WORDS.1997.609930	reliability engineering;real-time computing;computer science;distributed computing	Embedded	-22.983940860548095	62.76928809857685	154383
c2cb029fde7a7c3bca0e6fac6c69ce9b909ad990	a redesign methodology for storage management virtualization	servers resource management storage area networks investment optimization virtualization computers;redesign methodology san storage area network modeling server storage unification virtualization based server consolidation heterogeneous storage element underutilized server server sprawl problem corporate activity information technology service storage management virtualization;storage management;storage area networks;simulation server sprawl storage area network unification optimization;storage management storage area networks	The growth of business has escalated the need to employ information technologies services rapidly to support the mounting corporate activities. Each time a new service was needed; a new server along with the relevant software and storage elements was deployed. This situation has led to what is often referred to as the “server sprawl problem,” where many underutilized servers with heterogeneous storage elements are inaugurated whereas the total operational cost is high. In this paper we propose a redesign methodology to address this problem by using virtualization-based server consolidation and modeling servers' storage unification through storage area network (SAN). Our redesign methodology attempts to maximize the average servers' utilizations and ultimately to reduce the operational cost and to guarantee an acceptable level of performance. Extensive simulations to study the servers' utilizations and the performance have been carried out to validate the redesign tactic. The experimental results have revealed the efficiency of the proposed redesign method.	loss function;optimization problem;overhead (computing);semiconductor consolidation;server (computing);server sprawl;service-level agreement;simulation;storage area network;tabu search;unification (computer science);virtual machine	Tahani Hussain;Sami J. Habib	2013	2013 IFIP/IEEE International Symposium on Integrated Network Management (IM 2013)		file server;real-time computing;storage area network;converged storage;computer science;operating system;emc invista;database;information repository;storage virtualization;computer network;server farm	Arch	-21.538332237573808	63.29131870476473	154814
a6a2b9e55d44bd57390c29c8abf734244056f2e5	sibyl: host load prediction with an efficient deep learning model in cloud computing		Prediction of host load is essential in Cloud computing for improving resource utilization and achieving service-level agreements. However, accurate prediction of host load remains a challenge in Clouds because the type of load varies differently. Furthermore, selecting metrics for host load prediction is also a difficult task. With so many metrics in the Cloud systems, it is hard to determine which metrics are going to be useful. To address these challenges, this paper proposes an efficient deep learning model named Sibyl to improve the accuracy and efficiency of prediction. Sibyl includes two parts: a metrics selection module and a neural network training module. Sibyl first selects metrics by filtering out irrelevant metrics. Afterwards, Sibyl applies a powerful neural network model built with bidirectional long short-term memory to predict actual load one-step-ahead. We use Sibyl to analyze a 40-day load trace from a data center with 176 machines. Experiments show that Sibyl can reduce training metrics while maintaining prediction accuracy. Besides, Sibyl significantly improves prediction accuracy compared to other state-of-the-art methods based on autoregressive integrated moving-average and long short-term memory.		Zhiyuan Zhang;Xuehai Tang;Jizhong Han	2018		10.1007/978-3-030-05054-2_17	time series;computer science;distributed computing;data mining;cloud computing;deep learning;filter (signal processing);artificial neural network;autoregressive model;data center;sibyl;artificial intelligence	HPC	-24.26708742461925	61.66273296290526	154848
2496cb2840716e97b08bf93200ac9d33dbc8e260	phase-aware predictive thermal modeling for proactive load-balancing of compute clusters	resource allocation computer centres learning artificial intelligence power aware computing;server cluster environment phase aware predictive thermal modeling proactive load balancing compute clusters high density computing environments cooling infrastructure datacenters energy costs information technology integration infrastructure management integration continuous monitoring energy requirements compute equipment cooling equipment online thermal profile calculation accuracy measurement phase aware workload placement scheme thermal variance reduction compute nodes phase aware machine learning approach server thermal profile forecasting cluster level thermal variance prediction intel xeon class server platform sensors machine monitoring capability power assessment thermal assessment compute utilization assessment thermal balance intelligent placement algorithms thermal impact predetermination;resource allocation;computer centres;predictive models servers thermal sensors genetic algorithms temperature measurement mathematical model;power aware computing;learning artificial intelligence	The increasing trend of high density computing environments have exacerbated the cooling infrastructure of the modern datacenters which contributes to mounting energy costs due to uncoordinated operation. By integrating information technology and infrastructure management through continuous monitoring, a balance between energy requirements of compute and cooling equipment can be achieved. Building an online thermal profile calculation with certain measure of accuracy is a complex problem due to the number of variables involved. In this paper we propose a phase-aware workload placement scheme that helps in reducing thermal variance in a cluster of compute nodes. We use a phase-aware machine learning approach to forecast server thermal profile which is then used for predicting the cluster-level thermal variance. We leverage Intel Xeon class server platform sensors and machine monitoring capability for fine grained assessment of power, thermal and compute utilization. We are able achieve thermal balance by applying intelligent placement algorithms by predetermining the thermal impact of a variation in workload's utilization on a prospective cluster of server using the forecasted temperature. Results from a prototype implementation on a typical server-cluster environment have demonstrated accurate thermal prediction and significant reduction in thermal variance.	algorithm;cluster analysis;computer cluster;computer cooling;data center;dynamical system;load balancing (computing);machine learning;mathematical optimization;multi-objective optimization;prospective search;prototype;requirement;sensor;server (computing);software release life cycle;thermal profiling;variance reduction	Rahul Khanna;Jaiber John;Thanunathan Rangarajan	2012	2012 International Conference on Energy Aware Computing	10.1109/ICEAC.2012.6471016	embedded system;real-time computing;simulation;computer science	HPC	-21.872345223956632	62.08908448498568	155778
6c68672ee84c49e7f976dd3b5e72f5dda3a8cee3	qos-oriented service management in clouds for large scale industrial activity recognition	resource limitation;large scale industrial environments large scale industrial activity recognition industrial enterprises supervision services quality services security services safety guarantee services activity recognition framework computer vision machine learning tools recognition rates multiple cameras redundancy training set requirements time series classification models general resource limitations real time performance decentralized approach real time enabled framework service based infrastructures qos oriented service management mechanisms cloud environments cloud infrastructure;hidden markov model;real time;service management;time series;qos;computer vision;large scale;hidden markov models;redundancy;machine learning;monitoring;industrial workflows;pattern recognition;workflow management software;cloud infrastructure;learning artificial intelligence;quality of service;workflow management software cameras cloud computing computer vision gesture recognition learning artificial intelligence quality of service redundancy security of data time series;qos activity recognition industrial workflows service management cloud infrastructure;security of data;gesture recognition;cameras;monitoring computer vision hidden markov models cameras real time systems pattern recognition quality of service;cloud computing;real time systems;activity recognition	Motivated by the need of industrial enterprises for supervision services for quality, security and safety guarantee, we have developed an Activity Recognition Framework based on computer vision and machine learning tools, attaining good recognition rates. However, the deployment of multiple cameras to exploit redundancies, the large training set requirements of our time series classification models, as well as general resource limitations together with the emphasis on real-time performance, pose significant challenges and lead us to consider a decentralized approach. We thus adapt our application to a new and innovative real-time enabled framework for service-based infrastructures, which has developed QoS-oriented Service Management mechanisms in order to allow cloud environments to facilitate real-time and interactivity. Deploying the Activity Recognition Framework in a cloud infrastructure can therefore enable it for large scale industrial environments.	activity recognition;cloud computing;computer vision;exploit kit;interactivity;machine learning;quality of service;real-time clock;real-time transcription;requirement;software deployment;test set;time series	Athanasios Voulodimos;Dimosthenis Kyriazis;Spyridon V. Gogouvitis;Anastasios D. Doulamis;Dimitrios I. Kosmopoulos;Theodora A. Varvarigou	2011	2011 International Conference of Soft Computing and Pattern Recognition (SoCPaR)	10.1109/SoCPaR.2011.6089156	real-time computing;simulation;quality of service;cloud computing;computer science;machine learning;data mining;hidden markov model	Robotics	-28.115136148116825	63.04753030371224	155868
288752c025c81ecee23ca0664b0fe4ea34e68d3c	a policy-oriented secured service for the e-commerce applications in cloud	information technology;e-commerce;cloud computing;policy-oriented service;trust and security policy	The communication process is very easy today due to the rapid growth of information technology. In addition, the development of cloud computing technology makes it easier than earlier days by facilitating the large volume of data exchange anytime and from anywhere in the world. E-businesses are successfully running today due to the development of cloud computing technology. Specifically in cloud computing, cloud services are providing enormous support to share the resources and data in an efficient way with less cost expenses for businessmen. However, security is an essential issue for cloud users and services. For this purpose, many security policies have been introduced by various researchers for enhancing the security in e-commerce applications. However, the available security policies are also failing to provide the secured services in the society and e-commerce applications. To overcome this disadvantage, we propose a new policy-oriented secured service model for providing the security of the services in the cloud. The proposed model is the combination of a trust aware policy scheduling algorithm and an effective and intelligent re-encryption scheme. Here, the dynamic trust aware policy-oriented service for allocating the cloud user’s request by the cloud service provider and an effective and re-encryption scheme is used that uses intelligent agent for storing the data in the cloud database securely. The proposed model assures the scalability, reliability, and security for the stored e-commerce data and service access.	access control;anytime algorithm;cloud computing;cloud database;database security;e-commerce;encryption;failure;intelligent agent;scalability;scheduling (computing)	M. S. Murali Dhar;R. Manimegalai	2018	Personal and Ubiquitous Computing	10.1007/s00779-018-1138-1	computer security;human–computer interaction;e-commerce;intelligent agent;computer science;service provider;scalability;data exchange;cloud computing;information technology;security policy	HPC	-32.31263433143374	60.805059775471726	155972
511dda02d39dc8107ac385ea8a572970e2eb9b7b	face recognition using distributed, mobile computing	resource allocation ad hoc networks bluetooth face recognition mobile computing;face recognition mobile computing distributed computing;face face recognition databases performance evaluation mobile handsets bluetooth load management;eigenfaces technique face recognition mobile computing distributed computing blue hoc mobile devices bluetooth wireless ad hoc network load balancing method	This paper describes a distributed computing framework called Blue-Hoc, that uses mobile devices connected using a Bluetooth, wireless ad hoc network. For a network composed of different devices, we have developed a load balancing method to optimize performance of BlueHoc. The eigenfaces technique for face recognition is implemented and used to benchmark performance. With four devices and an 80 subject face database, we can achieve a speedup (including all overheads) of 1.37× without load balancing and with a 40 subject database a speedup of 1.08× with load balancing. Because of fixed communications and initialization costs, the speedup factor can grow as the number of subjects in the recognition system grows. Consequently, by aggregating the computing capabilities of local mobile devices, BlueHoc provides an effective solution for distributed mobile computing.	benchmark (computing);bluetooth;distributed computing;eigenface;facial recognition system;hoc (programming language);load balancing (computing);mobile computing;mobile device;speedup	Gregorio Hinojos;Phillip L. De Leon	2014	2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2014.6853985	real-time computing;mobile ad hoc network;computer science;distributed computing;mobile computing;computer network	Mobile	-22.25158291387811	67.53393607002644	156255
ad08418759f4972195b2cc40706950c69fd97878	multi-objective decision-making for mobile cloud offloading: a survey		Running very complex applications on mobile devices is still challenging since they are constrained by limited resources, such as memory capacity, network bandwidth, processor speed, and battery power. Mobile Cloud Computing (MCC) is a combination of cloud computing and mobile internet, which could effectively alleviate the resource constraints of mobile devices. How to efficiently offload computation-intensive parts of mobile applications from mobile devices to capable cloud servers is one of the keys. In mobile environments, the resource heterogeneity of mobile devices and cloud services, the interruption of heterogeneous wireless networks, the complexity of mobile applications, and the characteristic of transferring a large amount of data, are the major bottlenecks that have prevented this technology from being widely used. This paper takes these constraints into an account at the same time and explores methods of multi-objective decision making for time- and energy-aware task offloading for MCC. It is designed to ensure the right computational tasks are executed in the right way, at the right time and place.	bottleneck (software);clock rate;computation;interrupt;mobile app;mobile cloud computing;mobile device	Huaming Wu	2018	IEEE Access	10.1109/ACCESS.2018.2791504	the internet;distributed computing;computer network;wireless network;computer science;mobile cloud computing;cloud computing;mobile computing;mobile telephony;mobile device;server	Mobile	-23.285325177062553	67.49391808564958	156405
615060c75f3e0d71ec0443ed5fa3c4fd30d7d573	self-adaptive resource management system in iaas clouds	resource management;network topology;virtual machine monitors;energy consumption;heuristic algorithms;optimization;cloud computing	Resource management in cloud infrastructures is one of the most challenging problems due to the heterogeneity of resources, variability of the workload and scale of data centers. Efficient management of physical and virtual resources can be achieved considering performance requirements of hosted applications and infrastructure costs. In this paper, we present a self-adaptive resource management system based on a hierarchical multi-agent based architecture. The system uses novel adaptive utilization threshold mechanism and benefits from reinforcement learning technique to dynamically adjust CPU and memory thresholds for each Physical Machine (PM). It periodically runs a Virtual Machine (VM) placement optimization algorithm to keep the total resource utilization of each PM within given thresholds for improving Service Level Agreement (SLA) compliance. More-over, the algorithm consolidates VMs into the minimum number of active PMs in order to reduce the energy consumption. Experimental results on real workload traces show that our recourse management system can provide substantial improvement over other approaches in terms of performance requirements, energy consumption and the number of VM migrations.	agent-based model;algorithm;benchmark (computing);central processing unit;cloud computing;data center;heart rate variability;management system;mathematical optimization;multi-agent system;network packet;performance tuning;planetlab;q-learning;reinforcement learning;requirement;service-level agreement;tracing (software);virtual machine;z/vm	Fahimeh Farahnakian;Rami Bahsoon;Pasi Liljeberg;Tapio Pahikkala	2016	2016 IEEE 9th International Conference on Cloud Computing (CLOUD)	10.1109/CLOUD.2016.0079	real-time computing;simulation;cloud computing;computer science;resource management;operating system;distributed computing;network topology	HPC	-22.64235728373237	61.941716672474904	156491
cb61d0cd2d3307438098482a32c9eb617e7e1cbf	on economic and computational-efficient resource pricing in large distributed systems	distributed system;pricing grid computing large scale systems peer to peer computing;performance evaluation;peer to peer network;pricing;resource management;biological system modeling;distributed computing;large scale system;planetlab resource pricing large distributed systems large scale systems peer to peer networks grids cloud computing economic properties;distributed computing pricing resource management computational modeling large scale systems peer to peer computing cloud computing aggregates mechanical factors performance evaluation;mechanical factors;computational modeling;dynamic pricing;aggregates;simulation analysis;economics;peer to peer computing;mechanism design;computational efficiency;grid computing;meteorology;large scale systems;dynamic scheduling;cloud computing	There is growing interest in large-scale systems where globally distributed and commoditized resources can be shared and traded, such as peer-to-peer networks, grids, and cloud computing. Users of these systems are rational and maximize their own interest when consuming and contributing shared resources, even if by doing so they affect the overall efficiency of the system. To manage rational users, resource pricing and allocation can provide the necessary incentives for users to behave such that the overall efficiency can be maximized. In this paper, we propose a dynamic pricing mechanism for the allocation of shared resources, and evaluate its performance. In contrast with several existing trading models, our scheme is designed to allocate a request with multiple resource types, such that the user does not have to aggregate different resource types manually. We formally prove the economic properties of our pricing scheme using the mechanism design framework. We perform both theoretical and simulation analysis to evaluate the economic and computational efficiency of the allocation and the scalability of the mechanism. Our simulations are validated against a prototype implementation on PlanetLab.	aggregate data;algorithm;algorithmic efficiency;centralized computing;cloud computing;computation;distributed computing;mathematical optimization;memory management;optimization problem;peer-to-peer;planetlab;prototype;scalability;simulation	Marian Mihailescu;Yong Meng Teo	2010	2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing	10.1109/CCGRID.2010.124	pricing;mechanism design;simulation;cloud computing;dynamic priority scheduling;computer science;resource management;operating system;distributed computing;management science;computational model;grid computing	HPC	-23.553737304418025	64.77636097680178	157224
74551fb9c85df8f96623f956c4d2d4eb9a59f883	efficient and adaptive image data handling within a mobile environment				Jian Zhang	1999			real-time computing;group method of data handling;computer science	Robotics	-25.578128324615452	69.8857694934718	157407
56f91642ff60db6cd99eff0e4f06af6fd8152301	qos prediction for web services based on restricted boltzmann machines	web service;two layers model;restricted boltzmann machines	Recently, reliability prediction of Web services has become very important in related research communities. Especially, predicting the Quality of Service (QoS) for active users has been a hot issue of research and application. On the other hand, with the rapidly growing in number of service providers and users, resulting in a large number of data sets. It has a big impact to the QoS such as managing and monitoring for describing functional and nonfunctional characteristics of Web services. Therefore, we will certainly struggle at processing large data sets in the future, unless the issues are resolved quickly before it happens. In that context, QoS prediction on big data set is an urgent problem to be solved. In this paper, we present a new model for handling this problem based on a Restricted Boltzmann Machines, it is called Two Layers Model (TLM) and also proposed to add a new method for evaluating prediction of the field of web service quality. We use this model to cope with large data sets and the model has been used by the efficient learning and inference procedures for predicting QoS values of Web services. Our experiments were performed on two data sets in the WSDREAM data set and the experimental results have proved the effectiveness of the proposed model.	quality of service;restricted boltzmann machine;web service	Le Van Thinh	2017	JoSSR	10.1007/s12927-017-0010-6	service provider;data mining;quality of service;web service;big data;boltzmann machine;inference;data set;computer science	ML	-20.4852954474472	65.66379759311195	158594
0f4de51a9885fc116a012acadebc6fb4bf2e0e06	job allocation strategies for energy-aware and efficient grid infrastructures	energy metrics;performance evaluation;grid;energy efficiency trade off;allocation policies	Complex distributed architectures, like Grid, supply effective platforms to solve computations on huge datasets, often at the cost of increased power consumption. This energy issue affects the sustainability of the infrastructures and increases their environmental impact. On the other hand, due to Grid heterogeneity and scalability, possible power savings could be achieved if effective energy-aware allocation policies were adopted. These policies are meant to implement a better coupling between application requirements and the Grid resources, also taking energy parameters into account. In this paper, we discuss different allocation strategies which address jobs submitted to Grid resources, subject to efficiency and energy constraints. Our aim is to analyse the potential benefits that can be obtained from the adoption of a metric able to capture both performance and energy-savings. Based on an experimental study, we simulated two alternative scenarios aimed at comparing the behaviour of different strategies for allocating jobs to resources. Moreover we introduced the Performance/Energy Trade-off function as a useful means to evaluate the tendency of an allocation strategy towards efficiency or power consumption. Our conclusion seems to suggest that performance and energy-savings are not always enemies, and these objectives may be combined if suitable energy metrics are adopted.	code;computation;computational resource;economic complexity index;experiment;grid computing;job stream;load (computing);load balancing (computing);polyethylene terephthalate;quality of service;requirement;round-robin scheduling;scalability;scheduling (computing);simulation;software deployment;system configuration	Antonella Galizia;Alfonso Quarati	2012	Journal of Systems and Software	10.1016/j.jss.2012.01.050	simulation;computer science;engineering;database;management science;grid	HPC	-21.12544885376015	62.00532580424935	158635
8c09e3d1c562efce432befe5b5726d5899b0f4ff	a new mechanism for resource monitoring in grid computing	grid resource information monitoring;information retrieval;resource manager;resource management;distributed computing;large scale;grid computing;grid resource information retrieving	Grid computing is a technology for distributed computing. To manage a large scale of Grid resources for dynamic access, resource management is a key component. In this paper, a Grid Resource Information Monitoring (GRIM) prototype is introduced. To support the constantly changing resource states in the GRIM prototype, the push-based data delivery protocol named Grid Resource Information Retrieving (GRIR) is provided. There is a trade-off between information fidelity and updating transmission cost. The more frequent the reporting is, the more precise the information will be. But there will be more overheads. The offset-sensitive mechanism, the time-sensitive mechanism, and the hybrid mechanism in GRIR are used to achieve a high degree of data accuracy while decreasing the cost of updating messages. Experimental results show that the proposal alleviates both the update transmission cost and the loss of data accuracy compared to prior methods.	grid computing	Wu-Chun Chung;Ruay-Shiung Chang	2009	Future Generation Comp. Syst.	10.1016/j.future.2008.04.008	semantic grid;computer science;resource management;data mining;database;distributed computing;world wide web;drmaa;grid computing	HPC	-19.598665297334264	69.87465877228554	159579
5bf34a13e254b1b9ae49798afd111b3b5ccecbce	towards deploying decommissioned mobile devices as cheap energy-efficient compute nodes		The performance of mobile phone processors has been steadily increasing, causing the performance gap between server and mobile processors to narrow with mobile processors sporting superior performance per unit energy. Fueled by the slowing of Moore’s Law, the overall performance of single-chip mobile and server processors have likewise plateaued. These trends and the glut of used and partially broken smartphones which become environmental e-waste motivate creating cloud servers out of decommissioned mobile phones. This work proposes creating a compute dense server built out of used and partially broken smartphones (e.g. screen can be broken). This work evaluates the total cost of ownership (TCO) benefit of using servers based on decommissioned mobile devices and analyzes some of the architectural design trade-offs in creating such servers.	central processing unit;electronic waste;mobile device;mobile phone;moore's law;server (computing);smartphone;total cost of ownership	Mohammad Shahrad;David Wentzlaff	2017			mobile processor;efficient energy use;total cost of ownership;distributed computing;cloud computing;mobile phone;mobile device;performance gap;computer science;server	Mobile	-26.152237841883625	67.86292764028833	159635
60cb322b5ea9243022028a3fbd66081e972976a8	stable, scalable, decentralized p2p file sharing with non-altruistic peers	p2p system;cluster computing;p2p;information network;internet architecture;bittorrent;file sharing	P2P systems provide a scalable solution for distributing large files in a network. The file is split into many chunks, and peers contact other peers to collect missing chunks to eventually complete the entire file. The so-called ‘rare chunk’ phenomenon, where a single chunk becomes rare and prevents peers from completing the file, is a threat to the stability of such systems. Practical systems such as BitTorrent overcome this issue by requiring a global search for the rare chunk, which necessitates a centralized mechanism. We demonstrate a new system based on an approximate rare-chunk rule, allowing for completely distributed file sharing while retaining scalability and stability. We assume non-altruistic peers and the seed is required to make only a minimal contribution.	approximation algorithm;bittorrent;centralized computing;chunking (computing);file sharing;heuristic (computer science);instability;list of code lyoko episodes;locality of reference;peer-to-peer;rare events;scalability;simulation;upload	Barlas Oguz;Venkat Anantharam;Ilkka Norros	2011	CoRR		self-certifying file system;torrent file;bittorrent;computer cluster;computer science;operating system;ssh file transfer protocol;journaling file system;peer-to-peer;database;distributed computing;bittorrent tracker;open;file system fragmentation;global namespace;world wide web;file sharing;computer network	Networks	-31.567811101764413	67.87557152456	160378
a51f79ed824aaeb225d486a236e21834e490e72a	promo - a scalable and efficient framework for online data delivery	information system;systeme information;sistema informacion	Web enabled application servers have had to increase the sophistication of their server capabilities in order to keep up with the increasing demand for client customization. Typical applications include RSS feeds, stock prices and auctions on the commercial Internet, and increasingly, the availability of Grid computational resources. Web data delivery technology has not kept up with these demands. There still remains a fundamental trade-off between the scalability of both performance and ease of implementation on the server side, with respect to the multitude and diversity of clients, and the required customization to deliver the right service/data to the client at the desired time. Current data delivery solutions can be classified as either push or pull solutions, each suffering from different drawbacks. Push is not scalable, and reaching a large numbers of potentially transient clients is typically expensive in terms of resource consumption and implementation by a server. In some cases, where there is a mismatch with client needs, pushing information may overwhelm the client with unsolicited information. Pull, on the other hand, can increase network and server workload and often cannot meet client needs. Several hybrid push-pull solutions have also been presented in the past. In this demonstration we present $\mathcal{P}ro\mathcal{M}o$, a scalable and efficient hybrid data delivery solution.		Haggai Roitman;Avigdor Gal;Louiqa Raschid	2006		10.1007/11780991_38	real-time computing;computer science;operating system;database;distributed computing;world wide web;computer security;information system	ML	-30.62550954072112	62.6571222776635	160896
a3692c8088b7633866fc51c46879c05657d21dde	resource management for service level aware cloud applications.	automatic control;control engineering;datorsystem;computer systems;reglerteknik;datalogi;computer science	Resource allocation in clouds is mostly done assuming hard requirements, time-sensitive applications either receive the requested resources or fail. Given the dynamic nature of workloads, guarantee ...		Cristian Klein;Martina Maggio;Karl-Erik Årzén;Francisco Hernández-Rodriguez	2013			real-time computing;simulation;computer science;operating system;automatic control;distributed computing	HPC	-23.48417928486426	61.84088674653692	160914
0e2317ee2f9f5694e7b0b06bc61cc2ec33f584c3	a truthful mechanism for value-based scheduling in cloud computing	mechanism design;approximation algorithms;cloud computing;resource allocation;scheduling algorithms	We introduce a novel pricing and resource allocation approach for batch jobs on cloud systems. In our economic model, users submit jobs with a value function that specifies willingness to pay as a function of job due dates. The cloud provider in response allocates a subset of these jobs, taking into advantage the flexibility of allocating resources to jobs in the cloud environment. Focusing on social-welfare as the system objective (especially relevant for private or in-house clouds), we construct a resource allocation algorithm which provides a small approximation factor that approaches 2 as the number of servers increases. An appealing property of our scheme is that jobs are allocated nonpreemptively, i.e., jobs run in one shot without interruption. This property has practical significance, as it avoids significant network and storage resources for checkpointing. Based on this algorithm, we then design an efficient truthful-in-expectation mechanism, which significantly improves the running complexity of black-box reduction mechanisms that can be applied to the problem, thereby facilitating its implementation in real systems.	cloud computing;scheduling (computing)	Navendu Jain;Ishai Menache;Joseph Naor;Jonathan Yaniv	2011		10.1007/978-3-642-24829-0_17	real-time computing;computer science;operations management;distributed computing	HPC	-22.242747637738443	64.45145505011125	161617
b148ef1439410b830c9d44b1c0f5a9cc305c0a96	a job response time prediction method for production grid computing environments		P a g e 2 o f 1 7 8 Abstract A major obstacle to the widespread adoption of Grid Computing in both the scientific community and industry sector is the difficulty of knowing in advance a job submission running cost that can be used to plan a correct allocation of resources. Traditional distributed computing solutions take advantage of homogeneous and open environments to propose prediction methods that use a detailed analysis of the hardware and software components. However, production Grid computing environments, which are large and use a complex and dynamic set of resources, present a different challenge. In Grid computing the source code of applications, programme libraries, and third-party software are not always available. In addition, Grid security policies may not agree to run hardware or software analysis tools to generate Grid components models. The objective of this research is the prediction of a job response time in production Grid computing environments. The solution is inspired by the concept of predicting future Grid behaviours based on previous experiences learned from heterogeneous Grid workload trace data. The research objective was selected with the aim of improving the Grid resource usability and the administration of Grid environments. The predicted data can be used to allocate resources in advance and inform forecasted finishing time and running costs before submission. The proposed Grid Computing Response Time Prediction (GRTP) method implements several internal stages where the workload traces are mined to produce a response time prediction for a given job. In addition, the GRTP method assesses the predicted result against the actual target job’s response time to inference information that is used to tune the methods setting parameters. The GRTP method was implemented and tested using a cross-validation technique to assess how the proposed solution generalises to independent data sets. The training set was taken from the Grid environment DAS (Distributed ASCI Supercomputer). The two testing sets were taken from AuverGrid and Grid5000 Grid environments Three consecutive tests assuming stable jobs, unstable jobs, and using a job type method to select the most appropriate prediction function were carried out. The tests offered a significant increase in prediction performance for data mining based methods applied in Grid computing environments. For instance, in Grid5000 the GRTP method answered 77 percent of job prediction requests with an error of less than 10 percent. While in the same environment, the		Ariel Goyeneche	2010				HPC	-24.197495513590887	60.578579579454	161757
dfe62ec5e63eb853647574eea670655915323756	optimizing run-time soa governance through context-driven slas and dynamic monitoring	graph theory;optimisation;service level;context information;measurement;context monitoring service oriented architecture cloud computing feedback loop measurement q factor;service orientation;monitoring;run time control optimization run time soa governance context driven sla dynamic monitoring cloud environment volatile context information governance feedback loop service oriented system run time governance capability service level agreement contextual rdf graph machine readable specification monitoring requirement dynamic context monitoring capability context requirement service level objectives;feedback loop;execution environment;cost efficiency;ubiquitous computing;service level agreement;ubiquitous computing cloud computing computerised monitoring graph theory optimisation service oriented architecture;computerised monitoring;service oriented architecture;context;q factor;cloud computing	End-users increasingly demand the provisioning of secure, scalable, reliable, flexible, resilient, and cost-efficient infrastructures, platforms, and software. However, the preservation of these properties, particularly in SOA and cloud environments, is extremely affected by distributed, heterogeneous, transient, and volatile context information. We envision the implementation of governance feedback loops, an innovative approach that equips service-oriented systems with run-time governance capabilities able to control the fulfillment of service level agreements (SLA) under changing execution environments. However, the effectiveness of our approach depends on the capability of governance infrastructures to guarantee the consistency between monitoring strategies, governance objectives, and context situations. To advance our vision, this paper proposes (i) contextual RDF graphs, a machine-readable specification of monitoring requirements that enable governance feedback loops with dynamic context monitoring capabilities; and (ii) context-driven SLAs, an extension of SLAs where context requirements are explicitly mapped to service level objectives (SLO) to optimize the run-time control of contracted obligations.	cost efficiency;feedback;human-readable medium;optimizing compiler;provisioning;requirement;soa governance;scalability;service-level agreement;service-oriented architecture;service-oriented software engineering;software testing controversies	Norha M. Villegas;Hausi A. Müller;Gabriel Tamura	2011	2011 International Workshop on the Maintenance and Evolution of Service-Oriented and Cloud-Based Systems	10.1109/MESOCA.2011.6049036	real-time computing;computer science;database;distributed computing	SE	-28.16933659891733	60.88486963867816	161871
75948e3409116280d9f1e324f4cb39a23b0d1ec2	qos-aware service selection algorithms for pervasive service composition in mobile wireless environments	model specification;networks;service composition;service selection;mobile wireless networks;cost effectiveness;algorithms;mobile wireless network;quality of service;pervasive service;ontology	The successful application of pervasive services running in mobile wireless networks and devices relies on its ability to provide efficient and cost-effective QoS (Quality of Service) support. This paper proposes a comprehensive QoS model specifically for pervasive services. It considers not only user-perceived factors but also mobile wireless network characteristics. The corresponding formula to calculate each QoS criterion is also devised. In particular, this paper formulates the QoS-aware service selection problem for pervasive service composition and proposes some solutions to the problem, i.e., global-search-based LOSSA (local optimal service selection algorithm) and limited broadcast based LOSSA-k. The evaluation results of the algorithms have shown the effectiveness of the QoS model and the efficiency of the proposed LOSSAs.	expectation propagation;mobile phone;national supercomputer centre in sweden;pervasive informatics;quality of service;selection algorithm;service composability principle;web service	Kun Yang;Alex Galis;Hsiao-Hwa Chen	2010	MONET	10.1007/s11036-009-0189-y	mobile qos;cost-effectiveness analysis;quality of service;computer science;service delivery framework;ontology;world wide web;computer security;specification;computer network	Mobile	-25.078296451901306	69.30131837088197	162130
2e0ab5bddec1bb01b21eff9d7e7a479b499f420e	e&#xb3;: a multiobjective optimization framework for sla-aware service composition	optimisation;multiobjective genetic algorithms;service level agreements;optimization of services composition;computational complexity;aggregates;multiobjective genetic algorithms optimization of services composition quality of service service level agreements;multiobjective genetic algorithm e 3 multiobjective optimization framework sla aware service composition service oriented architecture quality of service service level agreement qos aware service composition problem np hard problem;optimization;quality of service concrete throughput optimization service oriented architecture aggregates marketing and sales;quality of service;service oriented architecture;service oriented architecture computational complexity optimisation quality of service;concrete;throughput;marketing and sales	In Service-Oriented Architecture, each application is often designed as a set of abstract services, which defines its functions. A concrete service(s) is selected at runtime for each abstract service to fulfill its function. Since different concrete services may operate at different quality of service (QoS) measures, application developers are required to select an appropriate set of concrete services that satisfies a given Service-Level Agreement (SLA) when a number of concrete services are available for each abstract service. This problem, the QoS-aware service composition problem, is known NP-hard, which takes a significant amount of time and costs to find optimal solutions (optimal combinations of concrete services) from a huge number of possible solutions. This paper proposes an optimization framework, called E3, to address the issue. By leveraging a multiobjective genetic algorithm, E3 heuristically solves the QoS-aware service composition problem in a reasonably short time. The algorithm E3 proposes can consider multiple SLAs simultaneously and produce a set of Pareto solutions, which have the equivalent quality to satisfy multiple SLAs.	aggregate data;amazon elastic compute cloud (ec2);genetic algorithm;heuristic;mathematical optimization;microsoft azure;monte carlo method;multi-objective optimization;np-hardness;optimization problem;pareto efficiency;quality of service;run time (program lifecycle phase);sql server compact;service composability principle;service-level agreement;service-oriented architecture;throughput	Hiroshi Wada;Junichi Suzuki;Yuji Yamano;Katsuya Oba	2012	IEEE Transactions on Services Computing	10.1109/TSC.2011.6	throughput;quality of service;concrete;computer science;service-oriented architecture;management science;computational complexity theory;computer network	SE	-20.60505371318486	65.09583382399559	162362
bb986fd68abd01b2e79eb49a55c7c15b222e6290	adam a testbed for distributed virtual environments	consistency algorithm distributed virtual environment adam;measurement tool;optimized production technology;adam;dve;distributed processing;testbed distributed virtual environment dve simulation consistency;simulation;virtual reality;testbed;computational modeling;internet;games;distributed virtual environment;virtual reality distributed processing;bandwidth;data consistency;algorithm design and analysis;consistency;delay games computational modeling internet bandwidth optimized production technology algorithm design and analysis;consistency algorithm	In distributed virtual environments (DVEs) the data on which the hosts operate is not consistent at all times. To restore data consistency, the DVE has to employ a consistency algorithm. Unfortunately, all existing DVEs have been built for specific application scenarios, which makes it impossible to compare the consistency algorithms and to choose a suitable candidate for a new scenario. To overcome this, we have created a modular simulator-based DVE testbed named Adam with the ability to plug in different application scenarios as well as different consistency algorithms and network constraints. The testbed also contains a large set of measurement tools. Our testbed currently supports two application scenarios and several of the most common consistency algorithms found in the literature. We can compare the solutions on an objective scale and confirm that optimistic consistency typically outperforms loose consistency.	algorithm;computational complexity theory;consistency model;digital video effect;eventual consistency;experiment;microsoft outlook for mac;multicast;peer-to-peer;scalability;simulation;swarm;testbed;virtual reality	Jan Sablatnig;Jiehua Chen;Ruedi Seiler;Sven Grottke;Andreas Köpke;Adam Wolisz	2008	2008 The 28th International Conference on Distributed Computing Systems Workshops	10.1109/ICDCS.Workshops.2008.65	adam;real-time computing;simulation;computer science;distributed computing;virtual reality;consistency;data consistency;bandwidth;testbed	HPC	-22.426701511082218	71.43316709538354	162392
0b56c5c990051e879d341671d85408fbf519c7c8	automated control of multiple virtualized resources	server consolidation;control application;time varying;control theory;virtualization;service level;resource allocation;resource manager;resource management;multi input multi output;data center;automated control;application qos	Virtualized data centers enable sharing of resources among hosted applications. However, it is difficult to satisfy service-level objectives(SLOs) of applications on shared infrastructure, as application workloads and resource consumption patterns change over time. In this paper, we present AutoControl, a resource control system that automatically adapts to dynamic workload changes to achieve application SLOs. AutoControl is a combination of an online model estimator and a novel multi-input, multi-output (MIMO) resource controller. The model estimator captures the complex relationship between application performance and resource allocations, while the MIMO controller allocates the right amount of multiple virtualized resources to achieve application SLOs. Our experimental evaluation with RUBiS and TPC-W benchmarks along with production-trace-driven workloads indicates that AutoControl can detect and mitigate CPU and disk I/O bottlenecks that occur over time and across multiple nodes by allocating each resource accordingly. We also show that AutoControl can be used to provide service differentiation according to the application priorities during resource contention.	central processing unit;control system;data center;input/output;mimo;resource contention;tpc-w	Pradeep Padala;Kai-Yuan Hou;Kang G. Shin;Xiaoyun Zhu;Mustafa Uysal;Zhikui Wang;Sharad Singhal;Arif Merchant	2009		10.1145/1519065.1519068	data center;real-time computing;virtualization;simulation;service level;resource allocation;computer science;resource management;operating system;distributed computing	OS	-23.047678256540046	61.3907481531611	162559
a3415af5d6163bedbee058d776d71c1906f7bece	the wide-area virtual service migration problem: a competitive analysis approach	wide area networks computational intelligence computer networks telecommunications telecommunications services;virtualisation internet quality of service;internet;quality of service;servers algorithm design and analysis virtualization prediction algorithms heuristic algorithms substrates bandwidth;online algorithm wide area virtual service migration problem competitive analysis approach network virtualization software defined networking distributed systems statistical assumptions sap server quality of service qos;virtualisation	Today's trend toward network virtualization and software-defined networking enables flexible new distributed systems where resources can be dynamically allocated and migrated to locations where they are most useful. This paper proposes a competitive analysis approach to design and reason about online algorithms that find a good tradeoff between the benefits and costs of a migratable service. A competitive online algorithm provides worst-case performance guarantees under any demand dynamics, and without any information or statistical assumptions on the demand in the future. This is attractive especially in scenarios where the demand is hard to predict and can be subject to unexpected events. As a case study, we describe a service (e.g., an SAP server or a gaming application) that uses network virtualization to improve the quality of service (QoS) experienced by thin client applications running on mobile devices. By decoupling the service from the underlying resource infrastructure, it can be migrated closer to the current client locations while taking into account migration costs. We identify the major cost factors in such a system and formalize the wide-area service migration problem. Our main contributions are a randomized and a deterministic online algorithm that achieve a competitive ratio of $O(\log {n})$ in a simplified scenario, where $n$  is the size of the substrate network. This is almost optimal. We complement our worst-case analysis with simulations in different specific scenarios and also sketch a migration demonstrator.	best, worst and average case;competitive analysis (online algorithm);coupling (computer programming);distributed computing;mobile device;online algorithm;quality of service;randomized algorithm;risk management;server (computing);simulation;software-defined networking;thin client	Marcin Bienkowski;Anja Feldmann;Johannes Grassler;Gregor Schaffrath;Stefan Schmid	2014	IEEE/ACM Transactions on Networking	10.1109/TNET.2013.2245676	competitive analysis;the internet;quality of service;computer science;operating system;distributed computing;world wide web;computer network	Metrics	-20.335631289829305	61.782140803692684	162658
91c6ff67bba2e39fec13237f15d098e621343712	cooperative caching framework for mobile cloud computing	cooperative cache;mobile cloud computing;cloudlet;article	Due to the advancement in mobile devices and wireless networks mobile cloud computing, which combines mobile computing and cloud computing has gained momentum since 2009. The characteristics of mobile devices and wireless network makes the implementation of mobile cloud computing more complicated than for fixed clouds. This section lists some of the major issues in Mobile Cloud Computing. One of the key issues in mobile cloud computing is the end to end delay in servicing a request. Data caching is one of the techniques widely used in wired and wireless networks to improve data access efficiency. In this paper we explore the possibility of a cooperative caching approach to enhance data access efficiency in mobile cloud computing. The proposed approach is based on cloudlets, one of the architecture designed for mobile cloud	data access;hoc (programming language);illinois tool works incorporated, et al. v. independent ink, incorporated;m. satyanarayanan;misra c;mobile cloud computing;mobile computing;mobile device;numerical aperture;sio (software);unified model;web cache;zipf's law	Preetha Theresa Joy;K. Poulose Jacob	2013	CoRR		cloud computing;computer science;distributed computing;internet privacy;world wide web	Mobile	-20.776727808809085	73.944816415226	162847
8e2c918604a0a10a14c3aaba1ce173ace773e644	mobile computation bursting: an application partitioning and offloading decision engine		Most of the today's Smartphones use multithreading and execute several application jobs in parallel. The Mobile Computation Bursting (MCB) exploits this nature of the Smartphones and aims at partitioning the jobs of a mobile application into different clusters consisting of high computation jobs from that which requires less computation, based on their frequency requirement to compute a task. The nature of a job, i.e., the frequency requirement is identified by Probability Distribution Function (PDF), that represents the number of cycles required for each job to complete the task. The novel algorithm proposed in this paper classifies these jobs using the density-based clustering algorithm using KL divergence. The offloading algorithm proposed in this paper decides whether to execute the cluster in the device or offload to the Cloud. The interaction and transportation of code and data between the mobile device and Cloud get communicated via a mobile agent, thus providing service to mobile users, even when the device moves away from the vicinity of the wireless network. The Mobile Computation Bursting technique is compared with the traditional offloading algorithms, and the results reveal that MCB proves to be more efficient and beneficial to offload the computation to Cloud.	algorithm;cluster analysis;computation;decision support system;job stream;kernel density estimation;kullback–leibler divergence;mobile agent;mobile app;mobile device;multithreading (computer architecture);portable document format;similarity measure;smartphone;thread (computing)	Anuradha Ravi;Sateesh Kumar Peddoju	2018		10.1145/3154273.3154299	computer science;wireless network;cloud computing;computation;cluster analysis;distributed computing;multithreading;mobile cloud computing;mobile agent;mobile device	Mobile	-23.830534439925636	66.94235206349948	163085
e6d44bdfda6a4118240d5de63a54f53c01000236	twinkle: a fast resource provisioning mechanism for internet services	vm;virtual machine;virtual machine monitor;image storage;random access memory;amazon ec2 style cloud computing service;tpc w;web and internet services;rubis;internet service;qos;twinkle;virtual machine monitors;servers virtual machine monitors web and internet services ash image storage operating systems random access memory;servers;operating system;virtual machines;twinkle fast resource provisioning mechanism internet service amazon ec2 style cloud computing service vm virtual machine tpc w rubis qos;ash;on the fly;internet services;quality of service;virtual machines cloud computing quality of service;flash crowds;cloud computing;fast resource provisioning mechanism;operating systems	A key benefit of Amazon EC2-style cloud computing service is the ability to instantiate a large number of virtual machines (VMs) on the fly during flash crowd events. Most existing research focuses on the policy decision such as when and where to start a VM for an application. In this paper, we study a different problem: how can the VMs and the applications inside be brought up as quickly as possible? This problem has not been solved satisfactorily in existing cloud services. We develop a fast start technique for cloud applications by restoring previously created VM snapshots of fully initialized application. We propose a set of optimizations, including working set estimation, demand prediction, and free page avoidance, that allow an application to start running with only partially loaded memory, yet without noticeable performance penalty during its subsequent execution. We implement our system, called Twinkle, in the Xen hypervisor and employ the two-dimensional page walks supported by the latest virtualization technology. We use the RUBiS and TPC-W benchmarks to evaluate its performance under flash crowd and failure over scenarios. The results indicate that Twinkle can provision VMs and restore the QoS significantly faster than the current approaches.	amazon web services;autoscaling;cloud computing;hypervisor;image scaling;internet protocol suite;moe;on the fly;overhead (computing);provisioning;slashdot effect;snapshot (computer storage);software development;tpc-w;twinkle;virtual machine;web service;working set;x86 virtualization;z/vm	Jun Zhu;Zhefu Jiang;Zhen Xiao	2011	2011 Proceedings IEEE INFOCOM	10.1109/INFCOM.2011.5935302	real-time computing;computer science;virtual machine;operating system;world wide web;computer network	HPC	-24.53051175454296	62.4101647072959	163325
727ed3576352cf250aa854651d1168a1780c3faa	providing responsiveness requirement based consistency in dve	probability density function;virtual reality;maintenance engineering;data mining;strontium;synchronization;distributed virtual environment;delay effects virtual environment distributed processing computer science games distance learning electronic commerce safety research and development real time systems;consistency maintenance;overall response;real time systems;requirement satisfaction distributed virtual environment responsiveness requirement model consistency maintenance methods	Consistency and responsiveness are two important factors in providing the sense of reality in Distributed Virtual Environment (DVE). However, it is not easy to optimize both aspects because of the trade-off between these two factors. As a result, most existing consistency maintenance methods ignored the responsiveness requirements, or just assumed a simple responsiveness requirement model which cannot meet the real need of DVE systems. In this paper, we first present a new responsiveness requirement model. The model can describe requirement satisfaction situation of each node. Base on this model, we propose a responsiveness requirement based consistency method. The method can adjust the utilization of time resource according to the requirements of different nodes and improve the overall responsiveness performance by at least 20%. Therefore, it provides a good support to increase the applicability of DVE systems.	asynchronous i/o;consistency model;digital video effect;fairness measure;mathematical optimization;requirement;responsiveness	Wei Zhang;Hangjun Zhou;Yuxing Peng;Sikun Li	2009	2009 15th International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2009.52	maintenance engineering;synchronization;probability density function;real-time computing;simulation;strontium;telecommunications;computer science;distributed computing;virtual reality;statistics	DB	-22.45869242052787	70.73674006054618	163387
84ba6a2c7e0bef4467dd36903490a598a8bbde77	design and implementation of a multi-objective optimization mechanism for virtual machine placement in cloud computing data center		Cloud computing is becoming a popular way of supplying and using computing resources. A cloud-computing data center is equipped with a large number of physical resources and must manage an even larger number of virtual machines (VMs). The center’s VM placement strategy affects the utilization of physical resources, and consequently, it influences operational costs. Our goal is to develop a multi-objective optimization mechanism for VM placement that satisfies various constraints and results in the lowest operational cost. The number of possible combinations of VMs and hosts can be extremely large. For the mechanism to be practical, the number of possible combinations must be reduced. We reduced computational overheads by classifying VM hosts into a relatively small number of equivalent sets. Simulation results show that expected operational costs can be significantly reduced by applying the proposed mechanism.	cloud computing;data center;mathematical optimization;multi-objective optimization;optimization mechanism;reduction (complexity);simulation;virtual machine	Soichi Shigeta;Hiroyuki Yamashima;Tsunehisa Doi;Tsutomu Kawai;Keisuke Fukui	2012		10.1007/978-3-319-03874-2_3	real-time computing;cloud computing;computer science;operating system;distributed computing	HPC	-20.657514245215857	63.05985917528106	163947
9db071db27b9c1030eb81f0395a4c16b84de2013	premonition of storage response class using skyline ranked ensemble method	machine learning algorithms;som storage response time arima ensemble method skyline query random forest svm;biological system modeling;time series storage management;predictive models time factors adaptation models biological system modeling sensitivity computer architecture machine learning algorithms;arima storage response class premonition skyline ranked ensemble method tertiary storage areas time series data forecasting models;computer architecture;sensitivity;time factors;predictive models;adaptation models	Tertiary storage areas are integral parts of compute environment and are primarily used to store vast amount of data that is generated from any scientific/industry workload. Modelling the possible pattern of usage of storage area helps the administrators to take preventive actions and guide users on how to use the storage areas which are tending towards slower to unresponsive state. Treating the storage performance parameters as a time series data helps to predict the possible values for the next `n' intervals using forecasting models like ARIMA. These predicted performance parameters are used to classify if the entire storage area or a logical component is tending towards unresponsiveness. Classification is performed using the proposed Skyline ranked Ensemble model with two possible classes, i.e. high response state and low response state. Heavy load scenarios were simulated and close to 95% of the behaviour were explained using the proposed model.	autoregressive integrated moving average;computer data storage;nat friedman;netapp filer;network topology;overhead (computing);pareto efficiency;random forest;response time (technology);sensitivity and specificity;time series	Kumar Dheenadayalan;V. N. Muralidhara;Pushpa Datla;G. Srinivasaraghavan;Maulik Shah	2014	2014 21st International Conference on High Performance Computing (HiPC)	10.1109/HiPC.2014.7116886	sensitivity;computer science;data science;machine learning;data mining;predictive modelling;statistics	HPC	-24.399188618552902	60.956221112501474	164491
4403efa99100c62bef0da5542efa826b603899ac	an intrusion detection system for wireless process control systems	request response communication;wireless sensor;traffic pattern;publikationer;model based intrusion detection system;data gathering;network security;monitoring scada systems wireless sensor networks wireless communication process control security intrusion detection;konferensbidrag;intrusion detection;attack detection wireless process control system wireless sensor network network security model based intrusion detection system traffic pattern request response communication;sensor network;wireless sensor network;attack detection;wireless communication;telecommunication traffic;monitoring;telecommunication security;artiklar;process control;rapporter;scada systems;security;wireless sensor networks process control telecommunication security telecommunication traffic;wireless sensor networks;wireless process control system;process control system;intrusion detection system	A recent trend in the process control system (PCS) is to deploy sensor networks in hard-to-reach areas. Using wireless sensors greatly decreases the wiring costs and increases the volume of data gathered for plant monitoring. However, ensuring the security of the deployed sensor network, which is part of the overall security of PCS, is of crucial importance. In this paper, we design a model-based intrusion detection system (IDS) for sensor networks used for PCS. Given that PCS tends to have regular traffic patterns and a well-defined request-response communication, we can design an IDS that models normal behavior of the entities and detects attacks when there is a deviation from this model. Model-based IDS can prove useful in detecting unknown attacks.	distributed control system;entity;intrusion detection system;protocol stack;request–response;sensor;simulation;simulink;testbed;wiring	Tanya Roosta;Dennis K. Nilsson;Ulf Lindqvist;Alfonso Valdes	2008	2008 5th IEEE International Conference on Mobile Ad Hoc and Sensor Systems	10.1109/MAHSS.2008.4660125	embedded system;wireless sensor network;computer science;process control;computer security;computer network	Mobile	-28.320508413425202	66.48509410313368	164653
7cb42c5d72edd0332cd6f4a2fd77cec6dd65da74	cost efficient datacenter selection for cloud services	optimisation;telecommunication network reliability;electricity costs cost efficient datacenter cloud services geographically distributed infrastructures reliability performance user requests network bandwidth statistical multiplexing optimization framework real world traffic traces;bandwidth electricity optimization benchmark testing covariance matrix electricity supply industry cloud computing;bandwidth allocation;multiplexing;computer centres;telecommunication traffic;statistical analysis;bandwidth;electricity;optimization;electricity supply industry;benchmark testing;telecommunication traffic bandwidth allocation cloud computing computer centres geography multiplexing optimisation statistical analysis telecommunication network reliability;covariance matrix;cloud computing;geography	Many cloud services nowadays are running on top of geographically distributed infrastructures for better reliability and performance. They need an effective way to direct the user requests to a suitable datacenter, in a cost efficient manner. Previous work focused mostly on the electricity cost of datacenters. The approaches favor datacenters at locations with cheaper electricity prices. In this paper, we augment the picture by considering another significant cost contributor: network bandwidth. We propose to utilize statistical multiplexing to strategically bundle demands at different locations. The anti-correlation between demands effectively smooths out the aggregated bandwidth usage, thereby saving the bandwidth cost calculated by burstable billing methods that charge the peak bandwidth usage. We present an optimization framework that models the realistic environment and practical constraints a cloud faces. We develop an efficient distributed algorithm based on dual decomposition and the subgradient method, and evaluate its effectiveness and practicality using real-world traffic traces and electricity costs.	burstable billing;cloud computing;cost efficiency;data center;distributed algorithm;electronic billing;lagrangian relaxation;mathematical optimization;multiplexing;subgradient method;tracing (software)	Hong Xu;Baochun Li	2012	2012 1st IEEE International Conference on Communications in China (ICCC)	10.1109/ICCChina.2012.6356938	covariance matrix;simulation;cloud computing;computer science;operating system;electricity;bandwidth;multiplexing;statistics;computer network;bandwidth allocation	HPC	-20.992284409742947	63.81692830056777	164905
35c87a3e37952d147d9a04bf7a20556e9692dfb9	modeling a session-based bots' arrival process at a web server		The paper deals with the problem of modeling key features of the Web traffic generated by Internet bots, observed at the input of a Web server. Based on real log data of an online store, a set of bot sessions was prepared and analyzed. Three session features connected with bots’ arrival process at the server were analyzed: session interarrival time, request interarrival time, and the number of requests in session. Distributional models for these bot session features were developed using regression analysis and validated through graphical comparisons of histograms for the empirical data and simulated values. As a result, interarrival times of bot sessions and interarrival times of requests in bot sessions were modeled by a Weibull and a Pareto distribution, respectively, and the numbers of requests in session were modeled by a function being a combination of a sigmoid and exponential distributions. The aim of our analysis was to develop a model of a session-based bot arrival process on a Web server which may be then implemented in a bot traffic generator integrated with a Web server simulator.	online shopping;pareto efficiency;server (computing);sigmoid function;time complexity;web server;web traffic;world wide web	Grazyna Suchacka;Daria Wotzka	2017		10.7148/2017-0605	world wide web;web server;computer science;distributed computing	Web+IR	-21.110081279843264	71.95429647437615	165011
9380b78f27f2bec1788587c21320bb50c909b7a5	a learning automata-based ensemble resource usage prediction algorithm for cloud computing environment		Abstract Infrastructure as a service (IaaS) providers are interested in increasing their profit by gathering more and more customers besides providing more efficiency in cloud resource usage. There are several approaches to reach the resource usage efficiency goal such as dynamic consolidation of virtual machines (VMs). Resource management techniques such as VM consolidation must be aware of the current and future resource usage of the cloud resources. Hence, applying prediction models for current cloud resource management is a must. While cloud resource usage varies widely time to time and server to server, determining the best time-series model for predicting cloud resource usage depend not only on time but the cloud resource usage trend. Thus, applying ensemble prediction algorithms that combine several prediction models can be suitable to reach the mentioned goal. In this paper, an ensemble cloud resource usage prediction algorithm based on Learning Automata (LA) theory is proposed that combines state of the art prediction models, and it determines weights for individual constituent models. The proposed algorithm predicts by combining the prediction values of all constituent models based on their performance. The extensive experiments on CPU load prediction of several VMs gathered from the dataset of the CoMon project indicated that the proposed approach outperforms other ensemble prediction algorithms.	algorithm;automata theory;cloud computing;learning automata	Ali Asghar Rahmanian;Mostafa Ghobaei Arani;Sajjad Tofighy	2018	Future Generation Comp. Syst.	10.1016/j.future.2017.09.049	resource management;predictive modelling;data mining;cloud computing;virtual machine;algorithm;computer science;distributed computing;learning automata	HPC	-19.79877838924643	61.90137301795703	165018
8caa7b3fa09be94115429b9add182efa275ada96	task granularity policies for deploying bag-of-task applications on global grids	task group deployment;lightweight task;meta scheduler;task granularity;grid computing;qa75 5 76 95 electronic computers computer science	Deploying lightweight tasks individually on grid resources would lead to a situation where communication overhead dominates the overall application processing time. The communication overhead can be reduced if we group the lightweight tasks at the meta-scheduler before the deployment. However, there is a necessity to limit the number of tasks in a group in order to utilise the resources and the interconnecting network in an optimal manner. In this paper, we propose policies and approaches to decide the granularity of a task group that obeys the task processing requirements and resourcenetwork utilisation constraints while satisfying the user’s QoS requirements. Experiments on bag-of-task applications reveal that the proposed policies and approaches lead towards an economical and efficient way of grid utilisation. © 2012 Elsevier B.V. All rights reserved.	cloud computing;computer science;data-intensive computing;endeavour software project management;experiment;grid computing;meta-scheduling;overhead (computing);quality of service;requirement;run time (program lifecycle phase);scheduling (computing);simulation;software deployment;software engineering	Nithiapidary Muthuvelu;Christian Vecchiola;Ian Chai;Chikkannan Eswaran;Rajkumar Buyya	2013	Future Generation Comp. Syst.	10.1016/j.future.2012.03.022	parallel computing;real-time computing;simulation;computer science;operating system;task analysis;database;distributed computing;grid computing	HPC	-19.35385727708158	62.10393243350948	165656
4047315bad44f18abddb7e7aebc21baf0c741eef	elasticity controller for cloud-based key-value stores	elasticity;voldemort;key value store;sensors;sensors actuators cloud computing control engineering computing control system synthesis feedback identification quality of service;actuators;elasticity mathematical model sensors actuators benchmark testing cloud computing monitoring;datorsystem;computer systems;distributed key value store elastic services quality of service requirements qos cloud environment pay as you go pricing model feedback elasticity controller design cloud based key value store control theoretic approach voldemort touchpoints sensors actuators system identification;feedback;control system synthesis;identification;control engineering computing;voldemort cloud computing elasticity feedback control key value store;quality of service;feedback control;cloud computing	Clouds provide an illusion of an infinite amount of resources and enable elastic services and applications that are capable to scale up and down (grow and shrink by requesting and releasing resources) in response to changes in its environment, workload, and Quality of Service (QoS) requirements. Elasticity allows to achieve required QoS at a minimal cost in a Cloud environment with its pay-as-you-go pricing model. In this paper, we present our experience in designing a feedback elastically controller for a key-value store. The goal of our research is to investigate the feasibility of the control theoretic approach to the automation of elasticity of Cloud-based key-value stores. We describe design steps necessary to build a feedback controller for a real system, namely Voldemort, which we use as a case study in this work. The design steps include defining touchpoints (sensors and actuators), system identification, and controller design. We have designed, developed, and implemented a prototype of the feedback elasticity controller for Voldemort. Our initial evaluation results show the feasibility of using feedback control to automate elasticity of distributed key-value stores.	as-interface;attribute–value pair;control system;control theory;controller (computing);elasticity (data store);electromagnetically induced transparency;environment variable;feedback;key-value database;prototype;quality of service;requirement;scheduling (computing);self-balancing binary search tree;system identification	Ala Arman;Ahmad Al-Shishtawy;Vladimir Vlassov	2012	2012 IEEE 18th International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2012.45	real-time computing;simulation;computer science;operating system;feedback;distributed computing;computer security;computer network	Robotics	-23.671260775248527	61.87903867243473	165759
70d59cedba245abb080333ea45e4e8169b0a53c8	considering resource demand misalignments to reduce resource over-provisioning in cloud datacenters		Previous resource provisioning strategies in cloud datacenters allocate physical resources to virtual machines (VMs) based on the predicted resource utilization pattern of VMs. The pattern for VMs of a job is usually derived from historical utilizations of multiple VMs of the job. We observed that these utilization curves are usually misaligned in time, which would lead to resource over-prediction and hence over-provisioning. Since this resource utilization misalignment problem has not been revealed and studied before, in this paper, we study the VM resource utilization from public datacenter traces to verify the existence of the utilization misalignments. Then, to reduce resource over-provisioning, we propose three VM resource utilization pattern refinement algorithms to improve the original generated pattern by lowering the cap of the pattern, reducing cap provision duration and varying the minimum value of the pattern. These algorithms can be used in any resource provisioning strategy that considers predicted resource utilizations of VMs of a job. We then adopt these refinement algorithms in an initial VM allocation mechanism and test them in trace-driven experiments and real-world cluster experiments. The experimental results show that each improved mechanism can increase resource efficiency up to 74%, and reduce the number of PMs needed to satisfy tenant requests up to 47% while conforming the SLO requirement.	algorithm;data center;experiment;ibm notes;microsoft research;provisioning;refinement (computing);simulation;tracing (software);virtual machine	Liuhua Chen;Haiying Shen	2017	IEEE INFOCOM 2017 - IEEE Conference on Computer Communications	10.1109/INFOCOM.2017.8057084	computer network;resource efficiency;resource management;real-time computing;distributed computing;computer science;cloud computing;virtual machine;provisioning;cluster analysis	HPC	-21.856416257021476	62.020867461655286	166043
6239e2e7e8df758c543b9bd870276c8108db5c19	environment for performing collaborative distributed virtual environments with qos	simulation collaborative distributed virtual environments system resource mangement end user service quality control dvecom mandatory property guarantees synchronization consistency sudden system overload smooth degradation end user requirements representation degradation profile selection rendering strategy api collaborative work;groupware;profile selection;degradation;sudden system overload;rendering strategy api;collaborative work;distributed processing;simulation;collaboration;virtual reality;collaborative distributed virtual environments;smooth degradation;testing;dvecom;synchronisation;representation degradation;end user requirements;synchronization;distributed processing groupware quality of service virtual reality synchronisation application program interfaces;displays;application program interfaces;end user service quality control;distributed virtual environment;virtual environment;quality of service;environmental management;mandatory property guarantees;collaboration quality of service collaborative work virtual environment degradation testing collaborative software displays environmental management quality management;consistency;quality management;collaborative software;system resource mangement	The spread of virtual environments is creating a new set of challenges in the management of system resources for guaranteeing quality of service (QoS). This paper describes an implementation of end-user QoS control to a distributed virtual environment platform called DVECOM. In particular, we describe how to guarantee mandatory properties, such as synchronization and consistency, how to reduce the impact on the application in case of a sudden overload in the system, and how we master this degradation to guarantee a smooth degradation according to the end-user's requirements. This representation degradation is driven by the user's choices and profile-selected through the offered rendering strategy API. We also present our evaluation of the QoS implementation, describing some interesting results we achieved in a simulation of collaborative work in the system.		Zièd Choukair;Damien Retailleau;Magnus Hellstrom	2000		10.1109/ICPADS.2000.857689	synchronization;quality management;real-time computing;simulation;computer science;operating system;database;distributed computing;virtual reality;collaborative software	HPC	-22.484821873874413	70.7467901762995	166141
2593a0b68a1dffb1b3ae2f3b4f40c6baf11ecf52	modeling multi-attribute demand for sustainable cloud computing with copulae		As cloud computing gains in popularity, understanding the patterns and structure of its loads is increasingly important in order to drive effective resource allocation, scheduling and pricing decisions. These efficiency increases are then associated with a reduction in the data center environmental footprint. Existing models have only treated a single resource type, such as CPU, or memory, at a time. We offer a sophisticated machine learning approach to capture the joint-distribution. We capture the relationship among multiple resources by carefully fitting both the marginal distributions of each resource type as well as the non-linear structure of their correlation via a copula distribution. We investigate several choices for both models by studying a public data set of Google datacenter usage. We show the Burr XII distribution to be a particularly effective choice for modeling the marginals and the Frank copula to be the best choice for stitching these together into a joint distribution. Our approach offers a significant fidelity improvement and generalizes directly to higher dimensions. In use, this improvement will translate directly to reductions in energy consumption.	algorithm;central processing unit;cloud computing;coupling (computer programming);data center;frank ostrowski;information privacy;job stream;machine learning;marginal model;nonlinear system;scheduling (computing)	Maryam Ghasemi;Benjamin Lubin	2015			econometrics;simulation;computer science;artificial intelligence;machine learning;statistics	Metrics	-22.22076021514824	62.45592153393946	166809
bd048c07fac500aa16349d46110736a4b782fccc	multi-objective optimizations in geo-distributed data analytics systems		In geographically distributed data centers, data analytics systems have recently been developed and optimized for such geo-distributed environments. With respect to various system operators’ requirements on data analytics, existing studies have optimized systems for individual goals such as resource efficiency, per-job latency and fairness. However, the optimizations with multiple objectives simultaneously have been overlooked. Even worse, some objectives can be translated to discordant actions and their relationship can be impacted by the unique features of geo-distributed data analytics systems. For example, we have observed clear trade-off between fairness and resource efficiency. In this paper, we develop an efficient framework for multi-objective optimizations on geo-distributed data analytics systems. Specifically, we develop GeoSpark, an extension to Spark, which automatically performs a multi-objective optimization according to the system operators’ preferences on different objectives. The multi-objective optimization is inherently intractable especially for large-scale workloads. Therefore, we propose an efficient online heuristic to approximate the optimal scheduling plan while achieving a lower bound guarantee in the worst case. Evaluation using synthetic workload shows that GeoSpark effectively performs the multi-objective optimizations based on system operators’ preferences on different objectives. GeoSpark achieves up to 30% makespan reduction, 28% job latency reduction and better fairness guarantee compared with existing schedulers in Apache Spark in the geo-distributed setting.	apache spark;approximation algorithm;best, worst and average case;data center;dhrystone;fairness measure;heuristic;makespan;mathematical optimization;multi-objective optimization;requirement;scheduling (computing)	Zhaojie Niu;Beixin Julie He;Amelie Chi Zhou;Chiew Tong Lau	2017	2017 IEEE 23rd International Conference on Parallel and Distributed Systems (ICPADS)	10.1109/ICPADS.2017.00074	workload;task analysis;operator (computer programming);real-time computing;scheduling (computing);latency (engineering);job shop scheduling;distributed computing;data analysis;computer science;heuristic	DB	-19.189492972588805	61.841691897202026	166817
506d1949e94df8c9d375dd4162cf11df40a20218	a data-driven approach based on auto-regressive models for energy-efficient clouds		The steadily increasing success of Cloud Computing is causing a huge rise in its electrical power consumption, contributing to higher energy costs, as well as to the greenhouse effect and the global warming. One of the most common key strategies to reduce the power consumption of data centers is the consolidation of virtual machines, whose effectiveness strongly depends on a reliable forecasting of future computational resource needs. In fact, servers are typically configured to handle peak workload conditions even if they are often under-utilized, that results in a wastefulness of resources and inefficient energy consumption. Motivated by these issues, this paper describes a data-driven approach based on auto-regressive models to dynamically forecast virtual machine workloads, for energy-aware allocations of virtual machines on Cloud physical nodes. Virtual machine migrations across physical servers are periodically done on the basis of the estimated virtual machine demands, by minimizing the number of active servers. Experimental results show encouraging benefits in terms of energy saving, while satisfying performance constraints and service level agreement established with users.	central processing unit;cloud computing;computational resource;data center;qualitative comparative analysis;random-access memory;semiconductor consolidation;service-level agreement;synthetic intelligence;tracing (software);virtual machine	Albino Altomare;Eugenio Cesario	2017	2017 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)		distributed computing;real-time computing;workload;energy consumption;service-level agreement;efficient energy use;cloud computing;computer science;computational resource;virtual machine;server	HPC	-21.131869637845117	62.26292999532694	167309
93c97035e44eaf6384906365006c13dc99bb1871	improving serviceability for virtual clusters in bandwidth-constrained datacenters	vm placement;network bandwidth reservation	Virtual cluster is a useful resource descriptive model, in terms of virtual machines (VMs) and link bandwidth, for many data center applications that require predictable performance. Bandwidth-constrained data centers often use reservation schemes to statically allocate underlying physical resources to virtual clusters. However, due to highly varying workloads, existing reservation schemes may place VMs improperly, causing a waste of bandwidth reservation and eventually leading to rejecting new virtual cluster requests even the VM capacity is sufficient. In this paper, we propose a mechanism to detect and rectify such bandwidth-wasting VM placements via VM reshuffling. To compute a new VM placement accommodating new requests as many as possible, we formulate an optimization problem, with the objective of minimizing the reservations of limited bandwidth. The problem is NP-hard. We propose two efficient algorithms for a practical special case and the general case of the problem respectively. To evaluate our mechanism, we conduct simulation with the settings close to real data center environments. The results show that our mechanism with VM reshuffling achieves a significant reduction in rejecting virtual cluster requests and increases data center throughput over various high loads.	algorithm;data center;mathematical optimization;np-hardness;optimization problem;simulation;throughput;virtual machine	Jiann-Min Ho;Pi-Cheng Hsiu;Ming-Syan Chen	2015	2015 IEEE 8th International Conference on Cloud Computing	10.1109/CLOUD.2015.99	parallel computing;real-time computing;computer science;operating system	HPC	-20.202325664826184	62.07162987826308	167474
be1a4e75f55a1ef94adb014236351ad20ddb2d3d	supporting autonomic management of clouds: service clustering with random forest	cloud computing clustering algorithms prediction algorithms feature extraction radio frequency security training;training;prediction algorithms;radio frequency;unsupervised learning cloud computing data privacy fault tolerant computing pattern clustering;similarity learning cloud computing autonomic computing sla random forest;feature extraction;clustering algorithms;security;unsupervised random forest formulation service clustering autonomic computing cloud computing data driven approaches machine learning cloud systems;cloud computing	A promising solution for the management of services in clouds, as fostered by autonomic computing, is to resort to self-management. However, the obfuscation of underlying details of services in cloud computing, also due to privacy requirements, affects the effectiveness of autonomic managers. Data-driven approaches, in particular those relying on service clustering based on machine learning techniques, can assist the autonomic management and support decisions concerning, e.g., the scheduling and deployment of services. Unfortunately, applying such approaches is further complicated by the coexistence of different types of data within the information provided by the monitoring of cloud systems: both continuous (e.g., CPU load) and categorical (e.g., VM instance type) data are available. Current approaches deal with this problem in a heuristic fashion. In this paper, instead, we propose an approach that uses all types of data, and learns in a data-driven fashion the similarities and patterns among the services. More specifically, we design an unsupervised formulation of random forest to calculate service similarities and provide them as input to a clustering algorithm. For the sake of efficiency and to meet the dynamism requirement of autonomic clouds, our methodology consists of two steps: 1) off-line clustering and 2) on-line prediction. Using datasets from real-world clouds, we demonstrate the superiority of our solution with respect to others and validate the accuracy of the on-line prediction. Moreover, to show applicability of our approach, we devise a service scheduler that uses similarity among services, and evaluate its performance in a cloud test-bed using realistic data.	algorithm;autonomic computing;central processing unit;cloud computing;cluster analysis;coexist (image);experiment;feature selection;heuristic;machine learning;memory footprint;online and offline;radio frequency;random forest;requirement;scheduling (computing);self-management (computer science);service-level agreement;software deployment;testbed;unsupervised learning;vii;z/vm	Rafael Brundo Uriarte;Francesco Tiezzi;Sotirios A. Tsaftaris	2016	IEEE Transactions on Network and Service Management	10.1109/TNSM.2016.2569000	prediction;cloud computing;feature extraction;computer science;information security;theoretical computer science;data mining;distributed computing;utility computing;cluster analysis;radio frequency;computer network;autonomic computing	DB	-27.525435477356872	63.094860298297476	167679
c7c2b70aa272d90ef2fcb1551a74c2a84e1f4647	cost models - pillars for efficient cloud computing: position paper	optimisation;efficiency;cost models;cloud computing	Cost models are fundamental building blocks for cloud computing. Cloud providers offer a very wide portfolio of services, while Cloud clients access them against some financial arrangement. There is a fundamental tradeoff between what Cloud provider can offer in terms of resources (software or hardware), services (e.g., storage, e-mail) cost and what Cloud clients are willing to pay. The Cloud cost models today are distinct based on service models: Infrastructure as a Service (IaaS), Platform as a Service (PaaS) and Software as a Service (SaaS). The need to forecast the cost over a period of time imposes building of cost models, which have to be accurate and error free. In this paper, we make a survey and analyse existing cost models in cloud computing and discuss open issues related to the subject.	cloud computing;email;platform as a service;software as a service	Catalin Negru;Valentin Cristea	2013	IJISTA	10.1504/IJISTA.2013.055102	cloud computing security;simulation;cloud computing;computer science;cloud testing;utility computing;efficiency;world wide web;computer security	Metrics	-26.138665507065397	60.52160640773088	167774
194cbfacf27739ff1118b98cd7ff71fa0fdcacbc	constructing trust networks based on small-world theories	social network services;graph theory;trust network;small world theory;small world;distance measurement;computational modeling;clustering coefficient;average path length security small world theory degree clustering coefficient;degree;computer networks ubiquitous computing social network services computer security information security pervasive computing systems engineering and theory national security routing diseases;average path length;ubiquitous computing;small world theories trust networks ubiquitous computing;small world network;security;security of data;buildings;ubiquitous computing security of data;small world theories;trust networks;ubiquitous computing environment	Trust relationships between agents provide a strong foundation for realizing security in ubiquitous computing environments. This approach is inspired by real-life networks. Furthermore, many studies show that real-life networks have the ldquosmall-world phenomenonrdquo. Small-world networks are networks with high clustering and short average path length. These two properties often mean that we can easily find a short path between any two agents in such networks, which is an expected property of trust networks. In this paper, based on the existing small-world theories, we research how to construct a small-world trust network. Analyses demonstrate that the approach in this paper is efficient and effective.	average path length;cluster analysis;real life;theory;ubiquitous computing;web of trust	Jun Zheng;Yan Qin;Jianyong Zhu;Xinyou Li	2008	2008 The 9th International Conference for Young Computer Scientists	10.1109/ICYCS.2008.469	evolving networks;average path length;computer science;information security;graph theory;theoretical computer science;clustering coefficient;distributed computing;small-world network;computational model;world wide web;ubiquitous computing;complex network;degree;computer network	AI	-32.87793644609661	70.33629423359878	168094
697d701cab53141c489297fbfabe5b24cf577ba8	analysis of task allocation based on social utility and incompatible individual preference	computers;nickel;resource management;internet;robots;intelligent sensors	This paper proposes a task allocation method in which, although social utility is attempted to be maximized, agents also give weight to individual preferences based on their own specifications and capabilities. Due to the recent advances in computer and network technologies, many services can be provided by appropriately combining multiple types of information and different computational capabilities. The tasks that are carried out to perform these services are executed by allocating them to appropriate agents, which are computational entities having specific functionalities. However, these tasks are huge and appear simultaneously, and task allocation is thus a challenging issue since it is a combinatorial problem. The proposed method, which is based on our previous work, allocates resources/tasks to the appropriate agents by taking into account both social utility and individual preferences. We experimentally demonstrate that the appropriate strategy to decide the preference depends on the type of task and the features of the reward function as well as the social utility.	computation;entity;experiment;heterogeneous computing;norm (social);reinforcement learning;ruby document format	Naoki Iijima;Masashi Hayano;Ayumi Sugiyama;Toshiharu Sugawara	2016	2016 Conference on Technologies and Applications of Artificial Intelligence (TAAI)	10.1109/TAAI.2016.7880161	simulation;computer science;knowledge management;social psychology	AI	-27.194220110071075	70.85426815639251	168186
d55e67122905b6b30783b1a2bbbabde8cbdfdd88	predictive load balancing in cloud computing environments based on ensemble forecasting	forecasting;time series forecasting;virtualisation cloud computing computer centres contracts fault tolerant computing power aware computing resource allocation time series virtual machines;cloud sim predictive load balancing cloud computing environments ensemble forecasting on demand computing resources usage pay as you use energy consumption nonoptimal server utilisation virtualisation service quality return on investment dynamic algorithms virtual machine migration vm allocation time series cpu utilisation proactive vm migration policy utilising forecasts pruf cloud data centres predictive overload detection cloud computing simulation toolkit;cloud computing predictive overload detection time series forecasting ensemble forecasting proactive vm migration;time series analysis;heuristic algorithms;predictive models;proactive vm migration;quality of service;cloud computing time series analysis forecasting heuristic algorithms predictive models quality of service;ensemble forecasting;predictive overload detection;cloud computing	Cloud Computing allows the on-demand usage of computing resources in a pay-as-you-use manner. One major problem for Cloud providers is the trade-off between the huge amount of energy consumption resulting from the non optimal utilisation of their servers, and meeting the service level agreements. Virtualisation allows for a better utilisation of existing servers while maintaining the required quality of service, increasing the return on investment. Consequently, dynamic algorithms are needed that determine an optimal plan for the live migration and allocation of Virtual Machines (VM) during run time. The contribution of this paper is as follows: First, we present our forecast module for time series to future utilisation of VMs. Second, we demonstrate how forecasts of CPU utilisation can be used beneficially in Cloud Computing environments. We propose a novel proactive VM migration policy utilising forecasts(PRUF) in Cloud data centres using an predictive overload detection. It uses short-term VM utilisation forecasts based on an ensemble forecasting approach to estimate which host will be overloaded when the next migration process is triggered. A study in the cloud computing simulation toolkit Cloud Sim shows that our predictive approach reduces the number of service level agreement violations and the performance degradation due to VM migrations compared to VM migration algorithms implemented in Cloud Sim.	algorithm;central processing unit;cloud computing;cloudsim;dynamic problem (algorithms);elegant degradation;ensemble forecasting;load balancing (computing);proactive parallel suite;quality of service;run time (program lifecycle phase);semiconductor consolidation;server (computing);service-level agreement;simulation;terms of service;time series;virtual machine;z/vm	Matthias Sommer;Michael Klink;Sven Tomforde;Jörg Hähner	2016	2016 IEEE International Conference on Autonomic Computing (ICAC)	10.1109/ICAC.2016.16	real-time computing;simulation;cloud computing;computer science;operating system;time series;statistics;computer network	HPC	-22.165429198665457	62.170362978534236	168539
d7dd64aca4e93c17b93f49eb041980d9f21b1959	an analytical model to achieve elasticity for cloud-based firewalls	analytical models;elasticity;firewalls computing;cloud firewalls;firewalls computing cloud computing analytical models time factors elasticity mathematical model numerical models;virtual machines cloud computing computer centres firewalls markov processes queueing theory resource allocation;performance modeling cloud computing firewalls cloud firewalls scalability elasticity;time factors;firewall rulebase interrogation elasticity cloud based applications cloud based firewalls architectural framework elastic virtual firewall service cloud datacenters markov chain queueing theory cloud based firewall service load balancer sla response time system input parameters virtual machines;firewalls;mathematical model;scalability;numerical models;performance modeling;cloud computing	Elasticity for cloud-based services and applications has been studied in the literature to some extent. However, the literature is lacking thorough study on elasticity for cloud-based firewalls. This paper proposes an architectural framework for an elastic virtual firewall service to be deployed at cloud datacenters. The paper presents an analytical model based on Markov chain and queueing theory that can be used to achieve elasticity for cloud-based firewalls. In particular, the model captures the behavior of a cloud-based firewall service comprising a load balancer and a variable number of virtual firewalls. From the analytical model, we then derive closed-form formulas to estimate the minimal number of virtual firewalls required to satisfy a given SLA response time. The model takes as input key system input parameters that include workload, processing capacity of load balancer and virtual machines, as well as firewall rulebase interrogation.	amazon elastic compute cloud (ec2);cloud computing;elasticity (cloud computing);elasticity (data store);enterprise architecture framework;firewall (computing);key;load balancing (computing);markov chain;numerical analysis;queueing theory;response time (technology);service-level agreement;simulation;virtual machine	Khaled Salah	2015	2015 IEEE 40th Conference on Local Computer Networks (LCN)	10.1109/LCN.2015.7366299	application firewall;real-time computing;scalability;simulation;cloud computing;computer science;operating system;cloud testing;mathematical model;elasticity;computer security;computer network	Metrics	-23.392282231608963	62.97149658199984	168604
40a7e61228e3e5ad7aa0cd1d8a87d1b54e9581c0	on the energy proportionality of scale-out workloads		Our increasing reliance on the cloud has led to the emergence of scale-out workloads. These scale-out workloads are latency-sensitive as they are user driven. In order to meet strict latency constraints, they require massive computing infrastructure, which consume significant amount of energy and contribute to operational costs. This cost is further aggravated by the lack of energy proportionality in servers. As Internet services become even more ubiquitous, scaleout workloads will need increasingly larger cluster installations. As such, we desire an investigation into the energy proportionality and the mechanisms to improve the power consumption of scale-out workloads. Therefore, in this paper, we study the energy proportionality and power consumption of clusters in the context of scale-out workloads. Towards this end, we evaluate the potential of power and resource provisioning to improve the energy proportionality for this class of workloads. Using data serving, web searching and data caching as our representative workloads, we first analyze the component-level power distribution on a cluster. Second, we characterize how these workloads utilize the cluster. Third, we analyze the potential of power provisioning techniques (i.e., active low-power, turbo and idle low-power modes) to improve the energy proportionality of scale-out workloads. We then describe the ability of active low-power modes to provide trade-offs in power and latency. Finally, we compare and contrast power provisioning and resource provisioning techniques. Our study reveals various insights which will help improve the energy proportionality and power consumption of scale-out workloads.	emergence;internet;logic level;low-power broadcasting;provisioning;scalability;web search engine;web service	Balaji Subramaniam;Wu-chun Feng	2015	CoRR		parallel computing;real-time computing;simulation;computer science;operating system	OS	-20.832577441173893	61.239812024827145	168783
7a05312f1fd9c59c891efda72631d7242747ead2	weighted sum model for multi-objective query optimization for mobile-cloud database environments		In a mobile-cloud database environment, different users on multiple mobile devices request services executed on a cloud. During those requests, queries are executed to obtain data, stored on the cloud and partly in caches on the mobile devices. The process of choosing an optimal query execution plan during a query optimization process is difficult because of multiple objectives involved regarding multiple non-static pricing models and different user constrains, such as monetary cost, query execution time and mobile device energy consumption. This paper provides a strategy of how to incorporate those various objectives in this decision process, based on a weighted-sum model, to achieve a good query execution plan. The experimental performance studies show that comparing with strategies, the proposed strategy is able to achieve its goal while incurs almost no additional overhead.	cpu cache;cloud computing;cloud database;mathematical optimization;mobile device;overhead (computing);query optimization;query plan;run time (program lifecycle phase)	Florian Helff;Le Gruenwald;Laurent d'Orazio	2016			real-time computing;cloud computing;performance studies;weighted sum model;data mining;energy consumption;mobile device;query optimization;cloud database;computer science	DB	-21.493978502189705	65.94685445923952	169381
26751610f1a9e53a98681cae70e78063d0204048	a social compute cloud: allocating and sharing infrastructure resources via social networks	social cloud computing;user sharing preferences social compute cloud infrastructure resource allocation infrastructure resource sharing social network platform digital communities social relationship representation social relationship documentation social relationship exploration friend relationships virtualized containers personal computer smart device social community welfare allocation fairness algorithmic runtime cloud computing infrastructures;resource management;preference based resource allocation;computational modeling;social networks;facebook;resource management computational modeling cloud computing facebook educational institutions supply and demand;preference based resource allocation social cloud computing social networks cloud computing;electronic computers computer science;social networking online cloud computing microcomputers resource allocation;supply and demand;cloud computing	Social network platforms have rapidly changed the way that people communicate and interact. They have enabled the establishment of, and participation in, digital communities as well as the representation, documentation and exploration of social relationships. We believe that as `apps' become more sophisticated, it will become easier for users to share their own services, resources and data via social networks. To substantiate this, we present a social compute cloud where the provisioning of cloud infrastructure occurs through “friend” relationships. In a social compute cloud, resource owners offer virtualized containers on their personal computer(s) or smart device(s) to their social network. However, as users may have complex preference structures concerning with whom they do or do not wish to share their resources, we investigate, via simulation, how resources can be effectively allocated within a social community offering resources on a best effort basis. In the assessment of social resource allocation, we consider welfare, allocation fairness, and algorithmic runtime. The key findings of this work illustrate how social networks can be leveraged in the construction of cloud computing infrastructures and how resources can be allocated in the presence of user sharing preferences.	access control;algorithm;best-effort delivery;cloud computing;cluster analysis;command-line interface;documentation;experiment;fairness measure;memory management;np-hardness;personal computer;provisioning;simulation;smart tv;smart device;social network;system call;user (computing)	Simon Caton;Christian Haas;Kyle Chard;Kris Bubendorfer;Omer F. Rana	2014	IEEE Transactions on Services Computing	10.1109/TSC.2014.2303091	cloud computing security;simulation;cloud computing;computer science;knowledge management;resource management;operating system;supply and demand;computational model;world wide web;social computing;computer network;social network	Metrics	-26.104662921442284	64.46751973125212	169499
5095615bdd6d0471992266507d2c55667766cb18	a microscope for the data centre	energy efficiency;data collection;data processing;cyber physical systems;data distribution;energy consumption;wsns;data centres;messaging systems;cps;data acquisition;wireless sensor networks	Data centres are large energy consumers. A large portion of this power consumption is due to the control of physical parameters of the data centre (such as temperature and humidity). However, these physical parameters are tightly coupled with computations, and even more so in upcoming data centres, where the location of workloads can vary substantially due, for example, to workloads being moved in the cloud infrastructure hosted in the data centre. Therefore, managing the physical and compute infrastructure of a large data centre is an embodiment of a cyber-physical system (CPS). In this paper, we describe a data collection and distribution architecture that enables gathering physical parameters of a large data centre at a very high temporal and spatial resolution of the sensor measurements. We detail this architecture and define the structure of the underlying messaging system that is used to collect and distribute the data.	business logic;cloud computing;cyber-physical system;data center;electronic billing;instrumentation (computer programming);inter-process communication;international symposium on fundamentals of computation theory;systems architecture;word lists by frequency	Nuno Pereira;Stefano Tennina;João Loureiro;Ricardo Severino;Bruno Saraiva;Manuel Filipe Santos;Filipe Pacheco;Eduardo Tovar	2015	IJSNet	10.1504/IJSNET.2015.070400	embedded system;real-time computing;wireless sensor network;data processing;computer science;operating system;data mining;efficient energy use;data acquisition;cyber-physical system;computer network;data collection	DB	-29.65615523338593	65.07006135114864	170139
0711c1d1b963125e2a4d9a2e4f2c632a26daaea1	dual time-scale distributed capacity allocation and load redirect algorithms for cloud systems	capacity allocation;resource management;cloud systems;sla;load balancing;performance modeling	Resource management remains one of the main issue in cloud computing because system resources have to be continuously allocated to handle workload fluctuations while guaranteeing Service Level Agreements (SLA) to the end users. In this paper, we propose capacity allocation algorithms able to coordinate multiple distributed resource controllers operating in geographically distributed cloud sites. Capacity allocation solutions are integrated with a load redirection mechanism which, when necessary, distributes incoming requests among different sites. The overall goal is to minimize the costs of allocated resources in terms of virtual machines, while guaranteeing SLA constraints expressed as a threshold on the average response time. We propose a distributed solution which integrates workload prediction and distributed non-linear optimization techniques. Experimental results show how the proposed solutions improve other heuristics proposed in literature without penalizing SLAs, and they are close to the global optimum which can be obtained by an oracle with a perfect knowledge about the future offered load.	algorithm;amazon elastic compute cloud (ec2);amazon web services;autonomic computing;cloud computing;experiment;global optimization;heuristic (computer science);linear programming;mathematical optimization;memory management;nonlinear programming;nonlinear system;optimization problem;oracle database;prototype;redirection (computing);response time (technology);sara (computer);service-level agreement;simulation;url redirection;virtual machine	Danilo Ardagna;Sara Casolari;Michele Colajanni;Barbara Panicucci	2012	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2012.02.014	parallel computing;real-time computing;simulation;computer science;load balancing;resource management;operating system;distributed computing;computer network	HPC	-22.97232225550231	62.45860194265511	170266
3e9cc5988a86035ea3cbf83477712f1fc635b202	consolidation of multi-tier workloads with performance and reliability constraints	nonlinear optimization model multitier workloads performance constraints reliability constraints hardware virtualization operational cost data centers consolidation model average response time constraints active clusters;performance evaluation;nonlinear programming;computer centres;performance evaluation computer centres fault tolerant computing nonlinear programming;fault tolerant computing;servers fault tolerance fault tolerant systems time factors power demand noise measurement	Server consolidation leverages hardware virtualization to reduce the operational cost of data centers through the intelligent placement of existing workloads. This work proposes a consolidation model that considers power, performance and reliability aspects simultaneously. There are two main innovative contributions in the model, focused on performance and reliability requirements. The first contribution is the possibility to guarantee average response time constraints for multi-tier workloads. The second contribution is the possibility to model active/active clusters of servers, with enough spare capacity on the fail-over servers to manage the load of the failed ones. At the heart of the proposal is a non-linear optimization model that has been linearized using two different exact techniques. Moreover, a heuristic method that allows for the fast computation of near optimal solutions has been developed and validated.	computation;computer performance;data center;failover;hardware virtualization;heuristic;linear programming;mathematical optimization;multitier architecture;nonlinear programming;nonlinear system;requirement;response time (technology);semiconductor consolidation	Andrea Sansottera;Davide Zoni;Paolo Cremonesi;William Fornaciari	2012	2012 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCSim.2012.6266893	embedded system;parallel computing;real-time computing;nonlinear programming;operating system;distributed computing;computer network	HPC	-20.777684704007704	63.1902352420544	171052
b04f89c2b9455d9fa51d5582f682b7724aa96cb5	esp: a machine learning approach to predicting application interference		Independent applications co-scheduled on the same hardware will interfere with one another, affecting performance in complicated ways. Predicting this interference is key to efficiently scheduling applications on shared hardware, but forming accurate predictions is difficult because there are many shared hardware features that could lead to the interference. In this paper we investigate machine learning approaches (specifically, regularization) to understand the relation between those hardware features and application interference. We propose ESP, a highly accurate and fast regularization technique for application interference prediction. To demonstrate this practicality, we implement ESP and integrate it into a scheduler for both single and multi-node Linux/x86 systems and compare the scheduling performance to state-of-the-art heuristics. We find that ESP-based schedulers increase throughput by 1.25-1.8× depending on the scheduling scenario. Additionally, we find that ESP's accurate predictions allow schedulers to avoid catastrophic decisions, which heuristic approaches fundamentally cannot detect.	esp game;feature selection;heuristic (computer science);interference (communication);linear model;linux;machine learning;schedule (computer science);scheduling (computing);throughput;x86	Nikita Mishra;John D. Lafferty;Henry Hoffmann	2017	2017 IEEE International Conference on Autonomic Computing (ICAC)	10.1109/ICAC.2017.29	real-time computing;throughput;distributed computing;data modeling;heuristics;x86;scheduling (computing);computer science;interference (wave propagation);artificial intelligence;heuristic;machine learning	Arch	-27.16377804614207	63.70533040594939	171428
8bbc0801b4b42386dd1038e9f0f3f3c16bc99ad7	self-adaptive sla-driven capacity management for internet services	analytical models;processor sharing self adaptive sla internet services dynamic capacity management queuing based performance model scheduling disciplines;capacity management;service level;scheduling computer network management internet;difference operator;cost function;self adaptive sla;web and internet services;scheduling disciplines;real time;web and internet services cost function contracts performance analysis queueing analysis analytical models surges throughput probability distribution delay;contracts;processor sharing;surges;dynamic capacity management;queuing based performance model;internet;scheduling;probability distribution;computer network management;performance analysis;performance model;internet services;cost effectiveness;cost model;optimization model;queueing analysis;throughput	This work considers the problem of hosting multiple third-party Internet services in a cost-effective manner so as to maximize a provider's business objective. For this purpose, we present a dynamic capacity management framework based on an optimization model, which links a cost model based on SLA contracts with an analytical queuing-based performance model, in an attempt to adapt the platform to changing capacity needs in real time. In addition, we propose a two-level SLA specification for different operation modes, namely, normal and surge, which allows for per-use service accounting with respect to requirements of throughput and tail distribution response time. The cost model proposed is based on penalties, incurred by the provider due to SLA violation, and rewards, received when the service level expectations are exceeded. Finally, we evaluate approximations for predicting the performance of the hosted services under two different scheduling disciplines, namely FCFS and processor sharing. Through simulation, we assess the effectiveness of the proposed approach as well as the level of accuracy resulting from the performance model approximations	analysis of algorithms;approximation;data center;mathematical optimization;requirement;response time (technology);scheduling (computing);service-level agreement;simulation;throughput;web service	Bruno D. Abrahao;Virgílio A. F. Almeida;Jussara M. Almeida;Alex Zhang;Dirk Beyer;Fereydoon Safai	2006	2006 IEEE/IFIP Network Operations and Management Symposium NOMS 2006	10.1109/NOMS.2006.1687584	probability distribution;throughput;real-time computing;the internet;cost-effectiveness analysis;service level;computer science;operating system;capacity management;law;scheduling;computer security;computer network	DB	-23.0335914836189	63.46808912957817	171573
6ed03730be93e7813253ea026fb88d85a5182841	remote management of narwhal client agents using the enterprise management protocol	data structures space technology web server transport protocols availability technology management environmental management communication system traffic control load management scalability;protocols;shared networking resources remote management narwhal client agents the enterprise management protocol transport protocol independent base networked devices networked applications temp client resident intermediary broker intelligent traffic routing intermediary services load sharing requests remote administrative control domain specific policies;telecommunication control;client server systems;telecommunication traffic;telecommunication network routing;telecommunication services protocols telecommunication network management client server systems telecommunication traffic telecommunication network routing telecommunication control intelligent networks;load sharing;telecommunication services;transport protocol;intelligent networks;domain specificity;distributed management;telecommunication network management	The Enterprise Management Protocol (TEMP) and its affiliated infrastructure provide a highly scalable, transport protocol-independent base for enabling the management of networked devices, systems and, most importantly, applications. The functionality and benefits of TEMP are illustrated through a case study of the remote management of Narwhal Client Agents. Narwhal is a technology that provides a local (i.e., client-resident) intermediary broker that can intelligently route the traffic among intermediaries. Its benefits include (1) improved availability of intermediary services, (2) load sharing requests across several intermediaries, (3) bypass intermediaries whenever possible, and (4) remote administrative control enabling the implementation of domain-specific policies to utilize the shared, limited networking resources.	entity;image scaling;scalability;user interface;world wide web	Geoff Carpenter;Germán S. Goldszmidt	2000		10.1109/NOMS.2000.830378	communications protocol;intelligent network;systems management;telecommunications;computer science;telecommunications service;network management application;world wide web;computer security;transport layer;computer network	OS	-20.394906659042256	69.76427906489054	171927
d2c8fe61de5bf7f2b82a9ca7a90e464a524ce067	energy consumption prediction based on time-series models for cpu-intensive activities in the cloud	energy consumption prediction;time series segmentation;cloud computing;time series model	Due to the increasing energy consumption in cloud data centers, energy saving has become a vital objective in designing the underlying cloud infrastructures. A precise energy consumption model is the foundation of many energy-saving strategies. This paper focuses on exploring the energy consumption of virtual machines running various CPU-intensive activities in the cloud server using two types of models: traditional time-series models, such as ARMA and ES, and time-series segmentation models, such as sliding windows model and bottom-up model. We have built a cloud environment using OpenStack, and conducted extensive experiments to analyze and compare the prediction accuracy of these strategies. The results indicate that the performance of ES model is better than the ARMA model in predicting the energy consumption of known activities. When predicting the energy consumption of unknown activities, sliding windows segmentation model and bottom-up segmentation model can all have satisfactory performance but the former is slightly better than the later.	central processing unit;cloud computing	Juan Li;Xiao Liu;Zhou Zhao;Jin Liu	2015		10.1007/978-3-319-27140-8_52	embedded system;real-time computing;simulation;cloud computing;computer science;operating system;time series	HCI	-22.88327473541532	61.297848546770716	172112
cba8fb849f10ea6197241a8e5d09a6661274157f	evaluation of a sector-hash based rapid file detection method for monitoring infrastructure-as-a-service cloud platforms	virtual machines cloud computing cryptography data handling digital forensics feature extraction parallel processing;computer forensics;file detection computer forensics cloud computing anti forensics sector hashes;forensics computers monitoring image restoration distributed databases file systems cloud computing;sector hashes;file detection;mapreduce sector hash based rapid file detection method infrastructure as a service cloud platform iaas cloud platform monitoring computer forensics cloud computing virtual machine parallel distributed processing xen hypervisor;cloud computing;anti forensics	Current computer forensics tools have some limitations on anti-forensics attacks, cloud computing, and a large increase in the size of forensics targets. To solve these problems, this paper proposes a system that preserves storage data on virtual machines by acquiring all data sectors with time stamps. The proposed system can restore a previous state of a block device at any date and time that is specified by an investigator. The proposed system aims to monitor users' behavior in Infrastructure-as-a-Service (IaaS) cloud platforms. This paper also presents a rapid file detection system that finds a target file from a large collection of the acquired data sectors by using sector-hashes and parallel distributed processing. This system enables investigators to track and to find a target file that is related to incidents or crimes in the cloud. First, this paper reports the preliminary experiments of a sector-hash based file detection method on three major operating systems for evaluating its effectiveness. We present a design and an implementation of the proposed monitoring and target file detection system by using Xen hypervisor and MapReduce. We report results of its performance evaluation. Finally, we discuss possible methods to improve the performance and the limitations of the current proposed mechanism.	anti-computer forensics;apache hadoop;byte;cloud computing;computer forensics;connectionism;device driver;distributed computing;experiment;hypervisor;mac os x 10.2 jaguar;mapreduce;microsoft windows;mysql;operating system;performance evaluation;server (computing);virtual machine	Manabu Hirano;Hayate Takase;Koki Yoshida	2015	2015 10th International Conference on Availability, Reliability and Security	10.1109/ARES.2015.15	self-certifying file system;cloud computing;computer science;operating system;world wide web;computer security;network forensics	HPC	-31.642236421984034	63.609148902477706	172299
ad8252f50ba18a7b5989951b24073a333a706377	a flexible resource allocation mechanism with performance guarantee in cloud computing		With the advent of virtualization technologies, cloud computing is experiencing an explosive growth. Resource allocation issue plays an important role in the commercial cloud platforms. However, the existing studies have not fully considered the heterogeneous demands from different cloud tenants. To tackle this, we design a more flexible cloud resource allocation mechanism which can maximize the profit of the cloud provider and support three general types of resource requirements from the cloud tenants. In this work, we assume that both the VMs (Virtual Machines) supplied by the cloud provider and the jobs submitted by the cloud tenants are heterogeneous, and the jobs from tenants will bid for the usage of VMs in 3 types: 1) fixed time intervals, 2) continuous time intervals in particular time ranges and 3) some time intervals summed to no more than certain values within particular time ranges. We proved that the studied optimal allocation problem is NP-complete. To allocate VMs to different types of jobs efficiently, we first release the studied problem into a linear programming (LP). Since linear programming can be solved optimally, we further use the coloring technology to transfer the optimal solution of the linear programming into a feasible solution of the allocation problem we studied. We proved that the proposed approximation allocation mechanism has an approximation factor of max_1 ≤ m ≤ M (c_m+1)^c_m/(c_m +1)^c_m-c_m^c_m, where M denotes the number of types of heterogeneous VMs and c_m is the number of VMs belong to the m-th type. The evaluation results corroborate our theoretical analysis, and show that the proposed methods achieve high efficiency. To the best of our knowledge, there have not yet been any studies jointly considered all these three types of job requirements and give a near-optimal allocation mechanism with performance guarantee.	approximation;cloud computing;graph coloring;job stream;linear programming;mathematical optimization;np-completeness;requirement	Meixuan Li;Yu-e Sun;He Huang;Jingmei Cui	2018	2018 4th International Conference on Big Data Computing and Communications (BIGCOM)	10.1109/BIGCOM.2018.00036	artificial intelligence;virtualization;machine learning;big data;computer science;linear programming;cloud computing;virtual machine;resource allocation;distributed computing	HPC	-20.122286353680323	63.843399006329086	172332
5515e7271d48ca0cc87c737989070ff592922a3a	self-organized formation and evolution of peer-to-peer networks	incentive mechanism;network formation and evolution;distributed data management;efficiency;distributed computing;stability;self organization;peer to peer networks;article	Peer-to-peer P2P networks are social networks for pooling network and information resources and are considered superior conduits for distributed computing and data management. In this paper, we utilize the theories of social networks and economic incentives to investigate the formation of P2P networks with rational participating agents active peers. The paper proposes a framework for multilevel formation dynamics, including an individual level content-sharing decision and group selection and a group level membership admission, splitting, and interconnection. It is found that if the network size the number of peer nodes is sufficiently large, the stable self-selected equilibrium free-riding ratio could be nonzero, contrary to the common belief that everybody should free ride. The efficient welfare-maximizing free-riding ratio is not necessarily zero; that is, a certain degree of free riding is beneficial and should be tolerated. The sharing level in a network increases decreases with the download upload capacities of its peer nodes. In addition, the heterogeneity of content availability and upload capacity discourages sharing activities. Although the sharing level of a stable group is typically lower than that of an efficient group, the self-formed network may have a larger or smaller group size than what is efficient, depending on the structure of the group admission decision process. It is also observed that self-organized interconnections among groups lead to network inefficiency because the network may be over-or underlinked. To recover the efficiency loss during the formation process, we propose internal transfer mechanisms to force stable networks to become efficient.	peer-to-peer	Yung-Ming Li;Yong Tan;Prabuddha De	2013	INFORMS Journal on Computing	10.1287/ijoc.1120.0517	self-organization;simulation;stability;computer science;dynamic network analysis;mathematics;distributed computing;efficiency;statistics	Theory	-25.27509796623653	73.40086395254708	172351
8e54d26f837787c016d3051c376a6a443497c563	the storage performance analyzer: measuring, monitoring, and modeling of i/o performance in virtualized environments (invited demonstration paper)	virtualization;tool;measuring;performance;i o;monitoring;modeling;storage;automation	The ever-increasing I/O resource demands pose significant challenges for today's system environments to meet performance requirements. The resource demand effects are even magnified in modern virtualized environments where workloads are consolidated to save hardware and operating costs. Tool-supported analysis approaches can help to understand I/O performance characteristics and avoid I/O performance and interference issues. In this demo paper, we present the Storage Performance Analyzer (SPA) - a tool for automated I/O performance analysis. SPA is equipped with tailored features for virtualized environments allowing to measure, monitor, and model both I/O performance and interference effects in modern environments. SPA is open-source and available for common operating systems.	hardware virtualization;input/output;interference (communication);open-source software;operating system;performance analyzer;requirement	Qais Noorshams;Axel Busch;Samuel Kounev;Ralf H. Reussner	2015		10.1145/2668930.2693845	input/output;embedded system;real-time computing;virtualization;simulation;systems modeling;performance;computer science;engineering;operating system;automation;measurement	Metrics	-21.513022559967517	60.90872045866218	172653
171b213f854cb28cf860dfeb71527b72a68661fb	a methodology for performance modeling of distributed event-based systems	modeling event based systems pub sub performance;transport information monitoring;modeling technique;software performance evaluation distributed processing;distributed processing;performance;system traffic;distributed computing;model performance;software performance evaluation;event based systems;monitoring;mean event delivery latency distributed event based systems transport information monitoring event driven supply chain management ubiquitous sensor rich environments quality of service system traffic;ubiquitous sensor rich environments;performance model;pub sub;event driven supply chain management;performance prediction;predictive models;object oriented modeling quality of service delay scalability distributed computing supply chain management real time systems computer science predictive models monitoring;scalability;mean event delivery latency;computer science;quality of service;modeling;quality of service issue;event based system;object oriented modeling;supply chain management;distributed event based systems;real time systems	Distributed event-based systems (DEBS) are gaining increasing attention in new application areas such as transport information monitoring, event-driven supply-chain management and ubiquitous sensor-rich environments. However, as DEBS increasingly enter the enterprise and commercial domains, performance and quality of service issues are becoming a major concern. While numerous approaches to performance modeling and evaluation of conventional request/reply-based distributed systems are available in the literature, no general approach exists for DEBS. This paper is the first to provide a comprehensive methodology for workload characterization and performance modeling of DEBS. A workload model of a generic DEBS is developed and operational analysis techniques are used to characterize the system traffic and derive an approximation for the mean event delivery latency. Following this, a modeling technique is presented that can be used for accurate performance prediction. The paper is concluded with a case study of a real life system demonstrating the effectiveness and practicality of the proposed approach.	approximation;debs;distributed computing;event-driven programming;performance prediction;quality of service;real life;request–response	Samuel Kounev;Kai Sachs;Jean Bacon;Alejandro P. Buchmann	2008	2008 11th IEEE International Symposium on Object and Component-Oriented Real-Time Distributed Computing (ISORC)	10.1109/ISORC.2008.51	embedded system;real-time computing;supply chain management;scalability;simulation;systems modeling;quality of service;performance;computer science;operating system;distributed computing;predictive modelling;publish–subscribe pattern	Embedded	-25.227469032204993	62.69681134072214	173007
6a0b86eab1dc7f7b2b00cb8e3be64e16f6e6c465	load balancing method for data management using high availability distributed clusters		Recently, users for various information and communication technology services have been increased with the advancement of terminals and the development of network infrastructure. Hence, systems using distributed data store are becoming widespread to improve scalability, fault tolerance and high reliability. For example, MAGONIA® server architecture, a part of NetroSphere Concept handles large-scale traffic by load-balancing. Basic functions include data redundancy for improvement of the reliability as well as system management in a dynamic scale. In previous studies, distributed data stores supported retrieval of attribute values by inverted index, but there are cases where bias to the index occurred. In this research, we propose a method to divide the hash value of an index in an application conforming to MAGONIA to equalize the load. In addition, a method to determine the bit length to divide is also shown. Then, we evaluate applicability of these proposed methods by actual machine and simulation.	bit-length;computer terminal;data redundancy;data store;fault tolerance;hash function;high availability;inverted index;load balancing (computing);scalability;server (computing);simulation;systems management	Shota Furuya;Kiyoshi Ueda	2017	2017 23rd Asia-Pacific Conference on Communications (APCC)	10.23919/APCC.2017.8303970	inverted index;real-time computing;computer science;systems management;architecture;scalability;hash function;distributed data store;distributed database;load balancing (computing)	DB	-20.406625481750414	68.99941955783123	174590
4b8ceae01bff234a4e052ede5d45e863e7ad1959	optimization decomposition approach for layered qos scheduling in grid computing	service composition;computational grid;optimization modeling;resource allocation;optimization decomposition;layered qos scheduling;cross layer;quality of service;grid computing;user satisfaction;grid system;optimization model;base layer	The paper presents optimization decomposition based layered Quality of Service (QoS) scheduling for computational grid. Cross layer joint QoS scheduling is studied by considering the global problem as decomposed into three sub-problems: resource allocation at the fabric layer, service composing at the collective layer, and user satisfaction degree at the application layer. The paper proposes a complete solution from optimization modeling, Lagrange relaxation based decomposition, to solutions for each sub-problem Lagrange relaxation based decomposition. These aspects match the vertical organization of the considered grid system: each layer trade with adjacent layers to find a global optimum of the whole grid system. Through multi-layer QoS joint optimization approach, grid global QoS optimization can be achieved. The cross layer policy produces an optimal set of grid resources, service compositions, and user's payments at the fabric layer, collective layer and application layer, respectively, to maximize global grid QoS. The owner of each layer obtains inputs from other layers, tries to maximize its own utility and provides outputs back to other layers. This iterative process lasts until presumably all layers arrive at the same solution.	grid computing;quality of service;scheduling (computing)	Chunlin Li;Layuan Li	2007	Journal of Systems Architecture	10.1016/j.sysarc.2007.01.014	mathematical optimization;real-time computing;quality of service;resource allocation;computer science;distributed computing;network layer;grid computing	HPC	-20.865941179355072	64.62059559854373	174753
cfea902b7b0f658a80f7a64b926245ee17f37fe6	dynamic adaptation of temporal event correlation for qos management in distributed systems	statistical approach;distributed system;temporal event correlation;controller;propagation delay quality of service delay estimation quality management event detection availability computer crime clocks network servers prototypes;network resource;event propagation delay;denial of service attack;event correlation;controller dynamic adaptation temporal event correlation quality of service qos management distributed system denial of service attack event propagation delay network resource server resource real time measurement statistical approach;telecommunication security computer network management quality of service real time systems security of data;real time measurement;computer network management;telecommunication security;qos management;server resource;quality of service;dynamic adaptation;security of data;real time systems	Temporal event correlation is essential to managing quality of service in distributed systems, especially correlating events from multiple components to detect problems with availability, performance, and denial of service attacks. Two challenges in temporal event correlation are: (1) handling lost events and (2) dealing with inaccurate clocks. We show that both challenges are related to event propagation delays that result from contention for network and server resources. We develop an approach to adjusting the timer values of event correlation rules based on propagation delays in order to reduce missed alarms and false alarms. Our approach has three parts: an infrastructure for real-time measurement of propagation delay, a statistical approach to estimating propagation delays, and a controller that uses estimates of propagation delays to update timer values in temporal rules. Our approach eliminates the need for manual adjustments of timer values. Further, studies of a prototype implementation suggest that our approach produces results that are at least as good as an optimal fixed adjustment in timer values	denial-of-service attack;distributed computing;event correlation;heart rate variability;propagation delay;propagation of uncertainty;prototype;quality of service;real-time clock;server (computing);software propagation;timer	Rean Griffith;Joseph L. Hellerstein;Gail E. Kaiser;Yixin Diao	2006	200614th IEEE International Workshop on Quality of Service	10.1109/IWQOS.2006.250486	real-time computing;controller;quality of service;computer science;event correlation;computer security;denial-of-service attack;computer network	Embedded	-28.118763525418576	66.19669901868963	175212
dbc06ac87b640485b549438f9e103cfd7f940e0a	modeling the autoscaling operations in cloud with time series data	google;time series cloud computing resource allocation;measurement;time series;cloud operation;time series analysis cloud computing monitoring measurement indexes data models google;indexes;monitoring;time series analysis;autoscaling;time series autoscaling cloud operation modeling;modeling;google cluster trace data autoscaling operation cloud computing time series data cloud operations cloud resource provisioning cloud resource de provisioning cloud providers workload pattern;cloud computing;data models	Autoscaling involves complex cloud operations that automate the provisioning and de-provisioning of cloud resources to support continuous development of customer services. Autoscaling depends on a number of decisions derived by aggregating metrics at the infrastructure and the platform level. In this paper, we review existing autoscaling techniques deployed in leading cloud providers. We identify core features and entities of the autoscaling operations as variables. We model these variables that quantify the interactions between these entities and incorporate workload time series data to calibrate the model. Hence the model allows proactive analysis of workload patterns and estimation of the responsiveness of the autoscaling operations. We demonstrate the use of this model with Google cluster trace data.	autoscaling;cloud computing;entity;interaction;petri net;provisioning;responsiveness;time series	Mehran N. A. H. Khan;Yan Liu;Hanieh Alipour;Samneet Singh	2015	2015 IEEE 34th Symposium on Reliable Distributed Systems Workshop (SRDSW)	10.1109/SRDSW.2015.20	real-time computing;computer science;time series;data mining;world wide web;statistics	DB	-24.563006937554132	61.729450174012044	175239
573e7d852c0d3254c201f44390e68948d37f2c83	a performance isolation technique ensuring sla of web systems having primary-backup web switch			backup;service-level agreement	Changhoon Kang;Kiejin Park;Sungsoo Kim	2005			world wide web;temporal isolation among virtual machines;web service;web server;backup;computer science	Security	-19.21893723287154	72.7135222310015	175279
ca8661b3b5d76169eb9bddbfcad8c0c74990e0ad	analysis of the influence of application deployment on energy consumption		Energy efficiency for data centers has been recently an active research field. Several efforts have been made at the infrastructure and application levels to achieve energy efficiency and reduction of CO2 emissions. In this paper we approach the problem of application deployment to evaluate its impact on the energy consumption of applications at runtime. We use queuing networks to model different deployment configurations and to perform quantitative analysis to predict application performance and energy consumption. The results are validated against experimental data to confirm the correctness of the models when used for predictions. Comparisons between different configurations in terms of performance and energy consumption are made to suggest the optimal configuration to deploy applications on cloud environments.	software deployment	Marco Gribaudo;Thi Thao Nguyen Ho;Barbara Pernici;Giuseppe Serazzi	2014		10.1007/978-3-319-15786-3_6	cloud computing;reliability engineering;green computing;software deployment;experimental data;efficient energy use;energy consumption;correctness;computer science	HCI	-21.65873867607316	61.873803026288854	175712
05900107daee689d2bb16ff19862fd09b98871e9	decentralized auction-based pricing with peermart	current supplies;web and internet services;pricing;economic efficiency;p2p;commerce;peermart;p2p overlay network design decentralized auction based pricing mechanism peermart broker functionality;redundancy;resilience;overlay network;telecommunication networks pricing peer to peer computing commerce supply and demand;robustness;ip networks;scalability;p2p networks;decentralized auction based pricing mechanism;peer to peer computing;pricing power generation economics scalability robustness peer to peer computing current supplies resilience web and internet services ip networks redundancy;p2p overlay network design;peer to peer;telecommunication networks;power generation economics;broker functionality;supply and demand	Auction-based pricing mechanisms offer the flexibility of setting prices for goods dynamically and efficiently based on current supply and demand. This paper presents PeerMart, a new mechanism which combines the economic efficiency of auction-based pricing with the technical performance and resilience of P2P networks. PeerMart supersedes the need for a central auctioneer by distributing broker functionality over all peers in the network. A structured and redundant P2P overlay network design is applied to achieve scalability and robustness even in the presence of malicious peers.	experiment;malware;network planning and design;overhead (computing);overlay network;peer-to-peer;prototype;scalability;switzerland	David Hausheer;Burkhard Stiller	2005	2005 9th IFIP/IEEE International Symposium on Integrated Network Management, 2005. IM 2005.	10.1109/INM.2005.1440807	pricing;auction algorithm;scalability;overlay network;computer science;peer-to-peer;supply and demand;redundancy;economic efficiency;auction theory;psychological resilience;robustness;computer network	Networks	-24.912810239430577	73.24309047516105	176047
1eb9ac5ca7d8c4885ebb523f4560b165e838651f	characterizing web application performance for maximizing service providers' profits in clouds	cloudsim web application service provider profit cloud technique predictive performance model service level agreement sla profit driven model resource management;service provider;computer model;resource manager;resource management;simulation experiment;servers;computational modeling;time factors;monitoring;web services;performance model;multi tier web application performance modeling;mathematical model;time factor;service level agreement;profitability;multi tier web application performance modeling cloud computing resource management;web services cloud computing;mathematical model computational modeling resource management time factors monitoring cloud computing servers;cloud computing	A number of challenges in implementing cloud technique related to further improving Web application performance and decreasing the cost. In order to achieve high profits, cloud-based web application providers must carefully balance cloud resources and dynamic workloads. However, this task is usually difficulty because of the complex nature of most web application. In this paper, we presented a predictive performance model to analyze such applications and to determine when and how much resource to allocate to each tier of an application. In addition, we proposed a new profit model to describe revenues specified by the Service Level Agreement (SLA) and costs generated by leased resources. Furthermore, we employed profit driven model to guide our resource management algorithms to maximize the profits earned to the service providers. We also designed and implemented a simulation experiment on CloudSim that adopts our proposed methodology. Experimental results indicated that our model faithfully captures the performance and resources are allocated properly in response to the changing workload, thus the goal of maximizing the profit has been achieved.	algorithm;cloud computing;cloudsim;multitier architecture;service-level agreement;simulation;web application	Xi Chen;Haopeng Chen;Qing Zheng;Wenting Wang;Guodong Liu	2011	2011 International Conference on Cloud and Service Computing	10.1109/CSC.2011.6138519	service provider;web service;simulation;cloud computing;computer science;knowledge management;resource management;mathematical model;computational model;world wide web;server;profitability index	HPC	-23.467720801225994	63.65866479588817	176382
28412a580a91ca1c98b437612d1b7652426ed3ea	reactive resource provisioning heuristics for dynamic dataflows on cloud infrastructure	high velocity data;resource management;cloud;dataflows;runtime;elastic resource provisioning reactive resource provisioning heuristics dynamic dataflow cloud infrastructure low latency analysis high velocity data streams distributed continuous dataflow systems autonomic methods qos optimization problem runtime resource provisioning centralized greedy heuristics sharded greedy heuristics variable sized bin packing algorithm genetic algorithm based heuristic large scale simulation study vm performance aws public cloud ga based heuristic cloud resource performance data applications;scheduling;runtime adaptation;bandwidth;optimization;cloud computing throughput quality of service optimization runtime ports computers bandwidth;ports computers;runtime adaptation dataflows stream processing cloud resource management scheduling high velocity data;virtual machines cloud computing data flow computing genetic algorithms quality of service resource allocation;quality of service;stream processing;cloud computing;throughput	The need for low latency analysis over high-velocity data streams motivates the need for distributed continuous dataflow systems. Contemporary stream processing systems use simple techniques to scale on elastic cloud resources to handle variable data rates. However, application QoS is also impacted by variability in resource performance exhibited by clouds and hence necessitates autonomic methods of provisioning elastic resources to support such applications on cloud infrastructure. We develop the concept of “dynamic dataflows” which utilize alternate tasks as additional control over the dataflow's cost and QoS. Further, we formalize an optimization problem to represent deployment and runtime resource provisioning that allows us to balance the application's QoS, value, and the resource cost. We propose two greedy heuristics, centralized and sharded, based on the variable-sized bin packing algorithm and compare against a Genetic Algorithm (GA) based heuristic that gives a near-optimal solution. A large-scale simulation study, using the linear road benchmark and VM performance traces from the AWS public cloud, shows that while GA-based heuristic provides a better quality schedule, the greedy heuristics are more practical, and can intelligently utilize cloud elasticity to mitigate the effect of variability, both in input data rates and cloud resource performance, to meet the QoS of fast data applications.	amazon web services;autonomic computing;benchmark (computing);bin packing problem;centralized computing;cloud computing;data flow diagram;data rate units;dataflow;elasticity (cloud computing);fairness measure;genetic algorithm;greedy algorithm;heart rate variability;heuristic (computer science);mathematical optimization;optimization problem;provisioning;quality of service;referring expression generation;scheduling (computing);set packing;shard (database architecture);simulation;software deployment;software release life cycle;spatial variability;stream processing;throughput;time complexity;tracing (software);velocity (software development)	Alok Gautam Kumbhare;Yogesh L. Simmhan;Marc Frîncu;Viktor K. Prasanna	2015	IEEE Transactions on Cloud Computing	10.1109/TCC.2015.2394316	parallel computing;real-time computing;cloud computing;computer science;resource management;operating system;distributed computing	Embedded	-22.50063040074624	62.01675830185577	176407
1e7ef76ee910f03572fb72e8566aeef3f2ff6ed2	a service oriented monitoring framework for soft real-time applications	architectural design;service orientation;real time;distributed processing;service oriented architecture decision making distributed processing interactive programming monitoring multimedia systems quality of service real time systems;qos guarantee;distributed computing;multimedia systems;soft real time;real time systems monitoring service oriented architecture service level agreement quality of service;service oriented monitoring;interactive multimedia;indexes;monitoring;distributed environment;image color analysis;real time interactive multimedia applications;film postproduction;film postproduction service oriented monitoring soft real time applications distributed computing service oriented infrastructures quality of service real time interactive multimedia applications decision making;service level agreement;service oriented infrastructures;virtual environment;quality of service;monitoring indexes quality of service real time systems virtual environment image color analysis cloud computing;service oriented architecture;interactive programming;cloud computing;soft real time applications;real time systems	The advancements in distributed computing have driven the emergence of Service Oriented infrastructures that allow for on-demand provision of ICT assets. Taking into consideration the complexity of distributed environments, significant challenges exist in providing and managing the offered on-demand resources with the required level of Quality of Service (QoS), especially for real-time interactive multimedia applications. Monitoring mechanisms are a fundamental part in service-based platforms that support realtime QoS guarantees by providing coherent and consistent real-time attributes at various levels of the infrastructure (application, network, storage, processing). In this paper we present an architectural design and implementation of a complete monitoring framework for measuring QoS at both application and infrastructure levels targeting trigger events for runtime adaptability of resource provisioning estimation and decision-making. We also demonstrate the operation of the implemented mechanism and evaluate its effectiveness using an application scenario, namely Film Postproduction.	aggregate data;cloud computing;coherence (physics);distributed computing;emergence;experiment;future internet;high- and low-level;interactivity;provisioning;quality of service;real-time clock;real-time computing;real-time transcription;service-oriented architecture	Gregory Katsaros;George Kousiouris;Spyridon V. Gogouvitis;Dimosthenis Kyriazis;Theodora A. Varvarigou	2010	2010 IEEE International Conference on Service-Oriented Computing and Applications (SOCA)	10.1109/SOCA.2010.5707182	database index;embedded system;real-time computing;mobile qos;quality of service;cloud computing;computer science;virtual machine;operating system;service-oriented architecture;distributed computing;interactive media;distributed computing environment	Embedded	-27.18817639707826	61.00196477099498	177025
f4293ff5dbfc0543facd0fba64896e0624271ace	scheduling cloud platform managed live-migration operations to minimize the makespan		Live-migration of virtual machines (VMs) has become an indispensable management operation of cloud platforms. The cloud platforms need to migrate multiple co-located and live VMs from one physical node to another for power saving, load balancing and maintenance. Such live-migration operations are critical to the running services, and thus should be completed as fast as possible. State-of-the-art live-migration techniques optimize the migration performance of single or multiple VMs by concentrating on Virtual Machine Monitor (VMM), little attention has been given to the cloud platforms which control and schedule the multiple migration operations. In this paper, we consider the problem of scheduling migration operations to minimize the makespan.	cloud computing;makespan;scheduling (computing)	Xiaoyong Yuan;Ying Li;Yanqi Wang;Kewei Sun	2014		10.1007/978-3-662-44917-2_61	real-time computing;johnson's rule;distributed computing	Mobile	-20.03082395162239	60.549070924970025	177445
de33698f7b2264bf7313f43d1de8c2d19e2a2f7a	an optimization approach for utilizing cloud services for mobile devices in cloud environment		Abstract. Mobile cloud computing has emerged aiming at assisting mobile devices in processing computationally or data intensive tasks using cloud resources. This paper presents an optimization approach for utilizing cloud services for mobile client in mobile cloud, which considers the benefit of both mobile device users and cloud datacenters. The mobile cloud service provisioning optimization is conducted in parallel under the deadline, budget and energy expenditure constraint. Mobile cloud provider runs multiple VMs to execute the jobs for mobile device users, the cloud providers want to maximize the revenue and minimize the electrical cost. The mobile device user gives the suitable payment to the cloud datacenter provider for available cloud resources for optimize the benefit. The paper proposes a distributed optimization algorithm for utilizing cloud services for mobile devices. The experiment is to test convergence of the proposed algorithm and also compare it with other related work. The experiments study the impacts of job arrival rate, deadline and mobility speeds on energy consumption ratio, execution success ratio, resource allocation efficiency and cost. The experiment shows that the proposed algorithm outperforms other related work in terms of some performance metrics such as allocation efficiency.	algorithm;algorithmic efficiency;data center;data-intensive computing;experiment;ibm notes;mathematical optimization;mobile cloud computing;mobile device;provisioning;queueing theory	Chunlin Li;Layuan Li	2015	Informatica, Lith. Acad. Sci.		cloud testing	Mobile	-22.015398629858176	64.43633638803782	177759
8773aefb6000c5841262db6e398ee4c8731e9051	xunleiprobe: a sensitive and accurate probing on a large-scale p2sp system	content management;selection model;measurement tool;protocols;servers peer to peer computing buildings probes protocols estimation computational efficiency;transport protocols content management peer to peer computing;p2p;probes;china xunleiprobe sensitive probing accurate probing large scale p2sp system p2p content distribution system http downloading ftp downloading bit torrent like systems p2p networks xunlei tracker measurement method peer to peer network peer to server and peer;transport protocols;large scale;servers;content distribution;estimation;probing;p2p networks;xunlei peer to peer probing;peer to peer computing;xunlei;computational efficiency;peer to peer;buildings	Xunlei [1] is a new P2P content distribution system which is popular in China. It composes traditional HTTP/FTP downloading and P2P content distribution features which attract many people including researchers. Xunlei's network is Bit Torrent-like and the measurement is more difficult than other P2P networks [2]. There are many constrains on Xunlei tracker, so we can not obtain information from tracker easily. Besides this, the measurement will encounter some challenges that skew the results. Most of previous works on Bit Torrent system are based on tracker logs. However, we can not obtain tracker logs of Xunlei. As far as we know, there is no proposal about precise and detailed measurement method that probes the network directly in this area. Face to the challenges, we analyze the constrains that appear in most Bit Torrent-like systems and propose a stratified random selection model to describe the behavior of tracker. Based on the model, we design a measurement tool called XunleiProbe. With the help of our solutions that increase the accuracy of our results, we measure a popular swarm for about 22 hours. The results show that the average peer coverage of our tool can reach about 93%.	bittorrent tracker;digital distribution;download;hypertext transfer protocol;peer-to-peer;swarm;xunlei	Yong Zhao;Zhibin Zhang;Li Guo;Binxing Fang	2011	2011 12th International Conference on Parallel and Distributed Computing, Applications and Technologies	10.1109/PDCAT.2011.83	communications protocol;estimation;content management;computer science;operating system;peer-to-peer;database;internet privacy;world wide web;transport layer;server;statistics;computer network	Metrics	-20.649200614790633	72.57085922775225	177800
7f636035e48069345bef69d5a3e9b1dacdb54e81	a virtual machine re-packing approach to the horizontal vs. vertical elasticity trade-off for cloud autoscaling	horizontal elasticity;datorsystem;computer systems;autonomous computing;datalogi;autoscaling;vertical elasticity;computer science;cloud computing	An automated solution to horizontal vs. vertical elasticity problem is central to make cloud autoscalers truly autonomous. Today's cloud autoscalers are typically varying the capacity allocated by increasing and decreasing the number of virtual machines (VMs) of a predefined size (horizontal elasticity), not taking into account that as load varies it may be advantageous not only to vary the number but also the size of VMs (vertical elasticity). We analyze the price/performance effects achieved by different strategies for selecting VM-sizes for handling increasing load and we propose a cost-benefit based approach to determine when to (partly) replace a current set of VMs with a different set. We evaluate our repacking approach in combination with different auto-scaling strategies. Our results show a range of 7% up to 60% cost saving in total resource utilization cost of our sample applications and workloads.	autonomous robot;autoscaling;elasticity (cloud computing);elasticity (data store);image scaling;set packing;spectrum reallocation;virtual machine	Mina Sedaghat;Francisco Hernández-Rodriguez;Erik Elmroth	2013		10.1145/2494621.2494628	real-time computing;simulation;computer science;operations management	HPC	-22.333116303407543	60.9690121351023	178091
8709652182d559dabbd0a37086d6b911debb87cc	skycds: a resilient content delivery service based on diversified cloud storage	multi cloud storage;virtualization;risk management;pub sub overlay;content delivery;diversification	Cloud-based storage is a popular outsourcing solution for organizations to deliver contents to end-users. However, there is a need for contingency plans to ensure service provision when the provider either suffers outages or is going out of business. This paper presents SkyCDS: a resilient content delivery service based on a publish/subscribe overlay over diversified cloud storage. SkyCDS splits the content delivery into metadata and content storage flow layers. The metadata flow layer is based on publish–subscribe patterns for insourcing the metadata control back to content owner. The storage layer is based on dispersal information over multiple cloud locations with which organizations outsource content storage in a controlled manner. In SkyCDS, the content dispersion is performed on the publisher side and the content retrieving process on the end-user side (the subscriber), which reduces the load on the organization side only to metadata management. SkyCDS also lowers the overhead of the content dispersion and retrieving processes by taking advantage of multi-core technology. A new allocation strategy based on cloud storage diversification and failure masking mechanisms minimize side effects of temporary, permanent cloud-based service outages and vendor lock-in. We developed a SkyCDS prototype that was evaluated by using synthetic workloads and a study case with real traces. Publish/subscribe queuing patterns were evaluated by using a simulation tool based on characterized metrics taken from experimental evaluation. The evaluation revealed the feasibility of SkyCDS in terms of performance, reliability and storage space profitability. It also shows a novel way to compare the storage/delivery options through risk assessment.	cloud storage;digital distribution	José Luis González;Jesús Carretero;Víctor Jesús Sosa Sosa;Luis Miguel Sánchez;Borja Bergua	2015	Simulation Modelling Practice and Theory	10.1016/j.simpat.2015.03.006	diversification;virtualization;converged storage;risk management;computer science;operating system;internet privacy;information repository;world wide web;computer security;computer network	OS	-19.1835177887115	68.80057501534215	178481
7917fec5604db71afc5288791e2fc180880a98b1	on using policies for managing service provisioning in agent-based heterogenous environments for mobile users	automatic control;control systems;access network;agent based;mobile agents;heterogeneous environment;user preferences;agent based heterogenous environment;mobile users;telecommunication traffic;internet;access networks service provisioning management agent based heterogenous environment mobile users internet domain network resource configuration network traffic;network traffic;subscriber loops;service provisioning management;access networks;web services;environmental management automatic control control systems quality of service quality management internet telecommunication traffic scalability web services handheld computers;scalability;quality of service;telecommunication traffic mobile computing mobile agents internet subscriber loops;mobile computing;environmental management;network resource configuration;service provision;handheld computers;quality management;internet domain;mobile user	Today's Internet domains are controlled more and more by policies. Each domain is composed of several access networks with their capabilities, devices, users and a specific behavior defined by policies. These policies control service provisioning, and automate network resource configuration. However, the growth in the mobility nature of users, the difference between the service requested by the user and the one offered by the access network, the heterogeneity of access networks and service parameters lead to the problem of adapting the service to the user and access network's behavior. We present in this paper an approach that combines agents, policies, and profiles. The agents gather relevant information in order to build up profiles helping adapt the requested service, and the policies control both the behavior of the devices and the agents in the system. Policies defined by the administrator are static and can't deal with all events occurring in the domain. New policies are then generated automatically when the corresponding service is agreed on by the network and the user after a negotiation process, when new tasks are defined, or when changing the behavior of the agents in the system. The key point is to tailor the service and policies according to the users preferences, the network capabilities and in the limit of the existing services with a limited delay and overhead in the network traffic to achieve a good scalability.	access network;agent-based model;computation;entity;fits;internet;java;mobile agent;network packet;overhead (computing);parallel computing;provisioning;quality of service;requirement;scalability;serialization;system administrator;xml	Mohamed Ganna;Eric Horlait	2005	Sixth IEEE International Workshop on Policies for Distributed Systems and Networks (POLICY'05)	10.1109/POLICY.2005.19	service delivery framework;distributed computing;service discovery;business;computer security;computer network	Metrics	-19.185969689069335	70.10641664209409	178490
24de24abe2187e9d6651f59b8136a3bcf59f0456	a fast and scalable mechanism for web service composition		In recent times, automated business processes and web services have become ubiquitous in diverse application spaces. Efficient composition of web services in real time while providing necessary Quality of Service (QoS) guarantees is a computationally complex problem and several heuristic based approaches have been proposed to compose the services optimally. In this article, we present the design of a scalable QoS-aware service composition mechanism that balances the computational complexity of service composition with the QoS guarantees of the composed service and achieves scalability. Our design guarantees a single QoS parameter using an intelligent search and pruning mechanism in the composed service space. We also show that our methodology yields near optimal solutions on real benchmarks. We then enhance our proposed mechanism to guarantee multiple QoS parameters using aggregation techniques. Finally, we explore search time versus solution quality tradeoff using parameterized search algorithms that produce better-quality solutions at the cost of delay. We present experimental results to show the efficiency of our proposed mechanism.	benchmark (computing);business process;computational complexity theory;elegant degradation;heuristic;marginal model;quality of service;run time (program lifecycle phase);scalability;search algorithm;service composability principle;web service;world wide web	Soumi Chattopadhyay;Ansuman Banerjee;Nilanjan Banerjee	2017	TWEB	10.1145/3098884	business process;computer science;quality of service;scalability;parameterized complexity;computational complexity theory;web service;real-time computing;search algorithm;heuristic;distributed computing	AI	-20.23115433700159	65.16332617850608	178526
70e6d92c68c63485737b588d9e2789dadc535f80	selection of services for data-centric cloud applications: a qos based approach	multiobjective optimization service selection data centric cloud applications qos cloud service cloud based software applications quality of service;quality of service cloud computing;cloud service selection;qos parameters;range searching cloud computing cloud service selection qos parameters;quality of service q factor cloud computing business algorithm design and analysis time factors security;quality of service;range searching;cloud computing	"""In recent days, the numbers of services deployed on the cloud are growing at a dramatic pace. At the same time, a cloud can host very large number of services with the similar functionality, provided by different providers. Moreover, many applications may use the same service to perform a specific type of task. Therefore, it is essential to select appropriate cloud service as per the applications requirements from a large pool of available services. Thus, selection of services for cloud based software applications is a challenging task and demand high level of research attention. From the computational perspective, the service selection mechanism is required to be optimum enough in order to increase the overall performance of the cloud. In this paper, a novel service selection mechanism has been proposed which is based on the """"quality of service"""" (QoS) parameters of the cloud services. Beside the multi-objective optimization, the proposed algorithm is capable to explore multiple cloud services based on user specified QoS values."""	algorithm;cloud computing;computation;high-level programming language;mathematical optimization;multi-objective optimization;quality of service;refinement (computing);requirement;selection algorithm;service composability principle;service-level agreement	Amit Kr Mandal;Suvamoy Changder;Anirban Sarkar	2013	2013 2nd International Conference on Advanced Computing, Networking and Security	10.1109/ADCONS.2013.31	panorama9;cloud computing security;mobile qos;cloud computing;computer science;cloud testing;distributed computing;data as a service;world wide web;computer network	HPC	-20.706020129483257	64.80975609350648	178530
af7ce610862e6c23ff68580ec06296fa7eac7404	building a microscope for the data center	bookpart	Managing the physical and compute infrastructure of a large data center is an embodiment of a Cyber-Physical System (CPS). The physical parameters of the data center (such as power, temperature, pressure, humidity) are tightly coupled with computations, even more so in upcoming data centers, where the location of workloads can vary substantially due, for example, to workloads being moved in a cloud infrastructure hosted in the data center. In this paper, we describe a data collection and distribution architecture that enables gathering physical parameters of a large data center at a very high temporal and spatial resolutionof the sensor measurements. We think this is an important characteristic to enable more accurate heat-flow models of the data center andwith them, _and opportunities to optimize energy consumption. Havinga high resolution picture of the data center conditions, also enables minimizing local hotspots, perform more accurate predictive maintenance (pending failures in cooling and other infrastructure equipment can be more promptly detected) and more accurate billing. We detail this architecture and define the structure of the underlying messaging system that is used to collect and distribute the data. Finally, we show the results of a preliminary study of a typical data center radio environment. Building a Microscope for the Data Center Nuno Pereira, Stefano Tennina, Eduardo Tovar CISTER/INESC-TEC, ISEP, Polytechnic Institute of Porto, Porto, Portugal, nap@isep.ipp.pt, sota@isep.ipp.pt, emt@isep.ipp.pt Abstract. Managing the physical and compute infrastructure of a large data center is an embodiment of a Cyber-Physical System (CPS). The Managing the physical and compute infrastructure of a large data center is an embodiment of a Cyber-Physical System (CPS). The physical parameters of the data center (such as power, temperature, pressure, humidity) are tightly coupled with computations, even more so in upcoming data centers, where the location of workloads can vary substantially due, for example, to workloads being moved in a cloud infrastructure hosted in the data center. In this paper, we describe a data collection and distribution architecture that enables gathering physical parameters of a large data center at a very high temporal and spatial resolution of the sensor measurements. We think this is an important characteristic to enable more accurate heat-flow models of the data center and with them, find opportunities to optimize energy consumption. Having a high resolution picture of the data center conditions, also enables minimizing local hotspots, perform more accurate predictive maintenance (pending failures in cooling and other infrastructure equipment can be more promptly detected) and more accurate billing. We detail this architecture and define the structure of the underlying messaging system that is used to collect and distribute the data. Finally, we show the results of a preliminary study of a typical data center radio environment.		Nuno Pereira;Stefano Tennina;Eduardo Tovar	2012		10.1007/978-3-642-31869-6_54	computer science	ML	-29.650022957202	65.07333778563945	178933
41bba6e02e291b4a452881def1c35159c3b85f14	energy-efficient networking solutions in cloud-based environments: a systematic literature review	energy efficiency;cloud;article letter to editor;networking;systematic literature review	The energy consumed by data centers hosting cloud services is increasing enormously. This brings the need to reduce energy consumption of different components in data centers. In this work, we focus on energy efficiency of the networking component. However, how different networking solutions impact energy consumption is still an open question. We investigate the state of the art in energy-efficient networking solutions in cloud-based environments. We follow a systematic literature review method to select primary studies. We create a metamodel based on the codes extracted from our primary studies using the Coding analytical method. Our findings show three abstraction levels of the proposed networking solutions to achieve energy efficiency in cloud-based environments: Strategy, Solution, and Technology. We study the historical trends in the investigated solutions and conclude that the emerging and most widely adopted one is the Decision framework.	cloud computing;code;data center;metamodeling;systematic review	Fahimeh Alizadeh Moghaddam;Patricia Lago;Paola Grosso	2015	ACM Comput. Surv.	10.1145/2764464	simulation;systematic review;cloud computing;computer science;operating system;multimedia;efficient energy use;world wide web	Mobile	-26.082810089634698	66.14152186236997	179279
046dc8d95617651c855a588f04dbb7cc0797eec5	convergence of ipsec in presence of resets	internet protocol;convergence protocols internet cryptography authentication system software computer security software standards;protocols;message passing ip networks protocols;security association;message passing;ip networks;message passing ipsec security standard internet protocol sequence number save operation fetch operation	IPsec is the current security standard for the Internet Protocol IP. According to this standard, a selected computer pair (p, q) in the Internet can be designated a “security association”. This designation guarantees that all sent IP messages whose original source is computer p and whose ultimate destination is computer q cannot be replayed in the future (by an adversary between p and q) and still be received by computer q as fresh messages from p. This guarantee is provided by adding increasing sequence numbers to all IP messages sent from p to q. Thus, p needs to always remember the sequence number of the last sent message, and q needs to always remember the sequence number of the last received message. Unfortunately, when computer p or q is reset these sequence numbers can be forgotten, and this leads to two bad possibilities: unbounded number of fresh messages from p can be discarded by q, and unbounded number of replayed messages can be accepted by q. In this paper, we propose two operations, “SAVE” and “FETCH”, to prevent these possibilities. The SAVE operation can be used to store the last sent sequence number in persistent memory of p once every Kp sent messages, and can be used to store the last received sequence number in persistent memory of q once every Kq received messages. The FETCH operation can be used to fetch the last stored sequence number for a computer when that computer wakes up after a reset. We show that the following three conditions hold when SAVE and FETCH are adopted in both p and q. First, when p is reset, at most 2Kp sequence numbers will be lost but no fresh message sent from p to q will be discarded if no message reorder occurs. Second, when q is reset, the number of discarded fresh messages is bounded by 2Kq. In either case, no replayed message will be accepted by q.	adversary (cryptography);ipsec;internet;next-generation network;persistent memory;security association	Chin-Tser Huang;Mohamed G. Gouda;E. N. Elnozahy	2003		10.1109/ICDCSW.2003.1203526	internet protocol;communications protocol;message passing;security association;telecommunications;computer science;operating system;database;distributed computing;computer security;anti-replay;computer network	Security	-33.489722099573825	68.97346642133203	179330
6d9afe815b8047fb88248b05e0f48fd324f4791b	smart visible sets for networked virtual environments	real time visualization;focusing;dynamic subsets;computer graphics;spatial coherence;geometry;virtual reality;client server systems;virtual reality computer games visibility client server systems computer networks rendering computer graphics;potentially visible sets;computer graphic;computer networks;visual importance metric real time visualization networked complex virtual environments computer graphics potentially visible sets pre computed visibility smart visible set dynamic subsets client position ordering mechanism dynamic sets;visibility;organizing;dynamic sets;pre computed visibility;data visualization;bandwidth;client position;virtual environment;smart visible set;ordering mechanism;computer games;networked complex virtual environments;rendering computer graphics;networked virtual environment;visual importance metric;computer graphics virtual environment delay geometry data visualization hardware focusing bandwidth spatial coherence organizing;hardware;potentially visible set	The real-time visualization of complex virtual environments across the network is a challenging problem in Computer Graphics. The use of pre-computed visibility associated to regions in space, such as in the Potentially Visible Sets (PVS) approach, may reduce the amount of data sent across the network. However, a PVS for a region may still be complex, and further partitions of the PVS are necessary. In this paper we introduce the concept of a Smart Visible Set (SVS), which corresponds to (1) a partition of PVS information into dynamic subsets that take into account client position, and (2) an ordering mechanism that enumerates these dynamic sets using a visual importance metric. Results comparing the SVS and the PVS approach are presented.	algorithm;client–server model;computation;computer graphics;computer performance;emoticon;frustum;network traffic control;overhead (computing);precomputation;real-time clock;server (computing);simulation;smart card;virtual reality	Fábio O. Moreira;João Luiz Dihl Comba;Carla Maria Dal Sasso Freitas	2002		10.1109/SIBGRA.2002.1167168	computer vision;simulation;computer science;computer graphics (images)	Visualization	-24.617556156533496	71.25789679603335	179480
d7fb6797b386c301f4d515609a7923757cf44418	model based estimation and verification of mobile device performance	quality attributes;mobile device;queuing model;model performance;system level modeling;regression model;design framework;performance analysis;software component;use case verification;use case	Performance is an important quality attribute that needs to be planned and managed proactively. Abstract models of the system are not very useful if they do not produce reasonably accurate metrics. Detailed models are time consuming and expensive to build as well as to simulate. In order to strike a right balance, a framework is proposed in this paper that takes advantage of the flexibility of abstract modeling and intricacies of detailed modeling. Performance is modeled and verified per use case using a hierarchical queuing model of the system. Each component job is represented through characterization functions and service requests. Characterization functions may be parametric regression models derived from job measurements on system level model. A co-design framework is used to simulate and measure the performance of software components. The use case simulator analyzes the performance and verifies the use case requirements.	component-based software engineering;computer architecture simulator;mobile device;queueing theory;requirement;simulation	Gopalakrishna Raghavan;Ari Salomaki;Raimondas Lencevicius	2004		10.1145/1017753.1017764	use case;use-case analysis;embedded system;real-time computing;simulation;computer science;component-based software engineering;operating system;mobile device;programming language;electro-mechanical modeling;regression analysis	Metrics	-24.735267721971077	61.397469132589634	179814
a4c130da248a488fac690b7e5872cb13092cb560	threshold-based negotiation framework for grid resource allocation				Tugrul Çavdar;Muhammet Talha Kakiz	2017	IET Communications	10.1049/iet-com.2017.0352	management science;mathematics;computer network;grid;negotiation;resource allocation;knowledge management	HPC	-24.38783921136663	69.60912297159858	179871
bbc706d77a7df1655bdddf73e0fa92f36afc5366	dependency mining for service resilience at the edge		Edge computing paradigm is prone to failures as it trades reliability against other quality of service properties such as low latency and geographical prevalence. Therefore, software services that run on edge infrastructure must rely on failure resilience techniques for uninterrupted delivery. Unique combination of hardware, software, and network characteristics of edge services is not addressed by existing techniques that are designed or tailored for cloud services. In this work, we propose a novel method for evaluating the resilience of replicated edge services, which exploits failure dependencies between edge servers to forecast probability of service interruption. This is done by analyzing historical failure logs of individual servers, modeling temporal dependencies as a dynamic Bayesian network, and inferring the probability that certain number of servers fail concurrently. Furthermore, we propose two replica scheduling algorithms that optimize different criteria in resilient service deployment, namely failure probability and cost of redundancy.		Atakan Aral;Ivona Brandic	2018	2018 IEEE/ACM Symposium on Edge Computing (SEC)	10.1109/SEC.2018.00024	real-time computing;redundancy (engineering);software deployment;computer security;computer science;quality of service;cloud computing;fault tolerance;latency (engineering);server;edge computing	Metrics	-25.595876129451018	62.06259520596621	180029
ab7d218bac74de22751077b1c7e254ef96dce1ec	towards virtualization of on-demand web service composition using an improved ranking algorithm			algorithm;web service	Muawyah Akash;Michel Bercovier;Ami Marowka;Elan Pavlov	2004			virtualization;database;web service;ranking;composition (visual arts);computer science	NLP	-27.018676007588287	66.45322779567076	180377
5037d7f38ac6f5b5221b30f1e13e5743356b5df8	on false data injection attack against multistep electricity price in electricity market in smart grid	false data injection attacks electricity market multistep electricity price fairness of electricity consumption load balance;generators;electricity price false data injection attack multistep electricity price policy energy saving load balance electricity consumption smart grid two dimensional mep model electricity market operation;smart grids;smart power grids power consumption power markets pricing;mathematical model;electricity;load modeling;electricity mathematical model load modeling equations generators data models smart grids;data models	The concept of Multistep Electricity Price (MEP) policy has been introduced by many countries to promote energy saving, load balance and fairness in electricity consumption. However, with the development of smart grid, how to determine the electricity quantity and price scaled to multiple steps has not been fully investigated. To address this issue, in this paper we study a two-dimensional MEP model to formally analyze and determine the desirable electricity quantity and price in multiple steps. In this model, the step is scaled by both electricity quantity and the time when the electricity is used. Based on the proposed MEP model, we further investigate the vulnerability of the electricity market operation and investigate false data injection attacks against electricity price and charges to consumers. Through simulation study, our data show that the proposed MEP models can achieve the fairness in electricity consumption, balance in load between peak time and non-peak time and improvement of resource utilization. Our data also indicates that false data injection attacks can only partially compromise prices in the MEP model, leading to a limited impact on users' charges.	code injection;consistency model;fairness measure;load balancing (computing);media-embedded processor;osi model;simulation	Jie Lin;Wei Yu;Xinyu Yang	2013	2013 IEEE Global Communications Conference (GLOBECOM)	10.1109/GLOCOM.2013.6831164	electricity market;computer science;electricity retailing;mathematical model;electricity;stand-alone power system;statistics	AI	-24.307201062122363	64.45877125646817	180568
7cd41d5bfd993288fc2ec5b9fd11b7ec3e105f46	autonomic performance and power control for co-located web applications in virtualized datacenters	co located multi service applications;distributed fuzzy mimo control;joint performance and power control;resource management;interference;power control resource allocation machine learning based self adaptive modeling energy efficiency distributed control structure middleware appleware power consumption user perceived performance resource sharing co located virtual machines virtualized data centers co located web applications;computer architecture;servers;computational modeling;autonomic systems;virtualized servers;virtualisation computer centres energy conservation internet learning artificial intelligence middleware power aware computing resource allocation virtual machines;scalability;servers resource management scalability computational modeling interference power control computer architecture;co located multi service applications joint performance and power control autonomic systems virtualized servers distributed fuzzy mimo control;colocated multi service applications;power control	In a datacenter, complex and time-varying interactions between various tiers and services of web applications, and the contention of shared resources among co-located virtual machines have significant impact on the user perceived performance and power consumption of the underlying system. We propose and develop APPLEware, an autonomic middleware for joint performance and power control of co-located web applications in virtualized datacenters. It features a distributed control structure that provides predictable performance and energy efficiency for large complex systems. It applies machine learning based self-adaptive modeling to capture the complex and time-varying relationship between the application performance and allocation of resources to various application components, in the face of highly dynamic and bursty workloads. The distributed controllers coordinate with each other and allocate resources to meet the service level agreements of applications in an agile and energy-efficient manner. Experimental results based on a testbed implementation with benchmark applications and large scale simulations demonstrate APPLEware's effectiveness, energy efficiency and scalability.	agile software development;autonomic computing;benchmark (computing);complex systems;component-based software engineering;control flow;data center;distributed control system;interaction;machine learning;middleware;perceived performance;scalability;service-level agreement;simulation;testbed;virtual machine;web application	Palden Lama;Yanfei Guo;Changjun Jiang;Xiaobo Zhou	2016	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2015.2453971	real-time computing;scalability;telecommunications;power control;computer science;resource management;operating system;database;distributed computing;interference;computational model;server;computer network	HPC	-23.367436314305483	61.27965131577014	180834
94e39b83241814e805b88678164dc40150573503	brokering slas for end-to-end qos in cloud computing	slas;cloud broker;quality of service;cloud computing	In this paper, we present a brokering logic for providing precise end-to-end QoS levels to cloud applications distributed across a number of different business actors, such as network service providers (NSP) and cloud providers (CSP). The broker composes a number of available offerings from each provider, in a way that respects the QoS application constraints while minimizing costs incurred by cloud consumers.	cloud computing;cryptographic service provider;end-to-end principle;geometric programming;heuristic;mathematical optimization;quality of service;requirement;simulation	Tommaso Cucinotta;Diego Lugones;Davide Cherubini;Karsten Oberle	2014		10.5220/0004959706100615	quality of service;cloud computing;computer science;operating system;cloud testing;distributed computing;world wide web;computer network	Metrics	-21.531427072923446	65.45993501637683	180843
fb96d930b3c63d700e820bc834729403f00d02a8	pricing and incentives in peer-to-peer networks	communications society;theoretical model;pareto efficiency;game theory;incentive schemes peer to peer networks content production game theoretic model pareto efficiency non cooperative equilibria linear pricing schemes;peer to peer network;pricing;non cooperative equilibria;ieee communications society;resource management;usa councils;pricing peer to peer computing costs game theory usa councils user generated content production communications society ip networks scalability;content production;linear pricing schemes;game theoretic model;games;computer network management;production;cost effectiveness;ip networks;book reviews;network management;scalability;incentive schemes;p2p networks;peer to peer computing;user generated content;peer to peer;peer to peer networks;pricing computer network management game theory incentive schemes peer to peer computing	Peer-to-peer (P2P) networks offer a cost effective and easily deployable framework for sharing user-generated content. However, intrinsic incentive problems reside in P2P networks as the transfer of content incurs costs both to uploaders and to downloaders while the benefit accrues only to downloaders. We investigate the issues of incentives in content production and sharing over P2P networks using a game theoretic model. Peers do not share produced content at all at non-cooperative equilibria whereas Pareto efficiency requires peers to fully share produced content. There is also a divergence in the total amount of produced content between non-cooperative equilibria and Pareto efficiency. By imposing full sharing, we decompose the inefficiency of non-cooperative equilibria into two parts, inefficiency due to no sharing and inefficiency due to underproduction. As a method to remedy the incentive problems in P2P networks, two classes of pricing schemes, MP pricing schemes and linear pricing schemes, are proposed. We show that the proposed pricing schemes can achieve Pareto efficiency as non-cooperative equilibria. We also examine a linear pricing scheme that maximizes the revenue of the network manager.	game theory;pareto efficiency;peer-to-peer;user-generated content	Jaeok Park;Mihaela van der Schaar	2010	2010 Proceedings IEEE INFOCOM	10.1109/INFCOM.2010.5461952	network management;pricing;games;game theory;scalability;cost-effectiveness analysis;computer science;resource management;user-generated content;computer network	ECom	-25.115958772448202	73.46622013491712	181294
00c4632d2d926acabc18574c9c5b870709ae9450	learning iot in edge: deep learning for the internet of things with edge computing	machine learning;edge computing;cloud computing;feature extraction;task analysis;computational modeling;servers	Deep learning is a promising approach for extracting accurate information from raw sensor data from IoT devices deployed in complex environments. Because of its multilayer structure, deep learning is also appropriate for the edge computing environment. Therefore, in this article, we first introduce deep learning for IoTs into the edge computing environment. Since existing edge nodes have limited processing capability, we also design a novel offloading strategy to optimize the performance of IoT deep learning applications with edge computing. In the performance evaluation, we test the performance of executing multiple deep learning tasks in an edge computing environment with our strategy. The evaluation results show that our method outperforms other optimization solutions on deep learning for IoT.	deep learning;edge computing;internet of things;mathematical optimization;performance evaluation	He Li;Kaoru Ota;Mianxiong Dong	2018	IEEE Network	10.1109/MNET.2018.1700202	distributed computing;task analysis;feature extraction;deep learning;internet of things;cloud computing;computer science;server;edge computing;artificial intelligence	HPC	-27.375056080148607	63.60934844968559	181716
eebc84e9b9e740ef6d13eefffdf2a176eba45b6c	towards power consumption reduction by user behavior monitoring at application level	adaptation model monitoring optimization argon containers hardware computational modeling	This paper gives an overview about our ongoing research which aims at adaptive power consumption optimization in enterprise systems where cost for operating the cooling systems has almost reached near server operating cost. Our methodology focuses at application level. This level can best describe user applications dependence on the underlying system and can play an effective role in power management decisions. We will also present our initial level experimentation which can set a solid base for our research.		Imran Asad Gul;Wilhelm Hasselbring	2010			embedded system;real-time computing;simulation;engineering	HCI	-21.51553523230954	61.91418443029719	181875
3402b366ae89ebfc5616bd9c406deeb0d74295b3	a methodology for the evaluation of high response time on e-commerce users and sales	business modeling;e commerce;web performance;resource management;conversion rates	The widespread adoption of high speed Internet access and it’s usage for everyday tasks are causing profound changes in users’ expectations in terms of Web site performance and reliability. At the same time, server management is living a period of changes with the emergence of the cloud computing paradigm that enables scaling server infrastructures within minutes. To help set performance objectives for maximizing user satisfaction and sales, while minimizing the number of servers and their cost, we present a methodology to determine how user sales are affected as response time increases. We begin with the characterization of more than six months of Web performance measurements, followed by the study of how the fraction of buyers in the workload is higher at peak traffic times, to then build a model of sales through a learning process using a five year sales dataset. Finally, we present our evaluation of high response time on users for popular applications found in the Web.	autonomic computing;cloud computing;e-commerce payment system;elegant degradation;emergence;hypertext transfer protocol;image scaling;internet access;load (computing);load profile;machine learning;online service provider;online shopping;production system (computer science);programming paradigm;provisioning;response time (technology);server (computing);web performance;world wide web	Nicolás Poggi;David Carrera;Ricard Gavaldà;Eduard Ayguadé;Jordi Torres	2014	Information Systems Frontiers	10.1007/s10796-012-9387-4	e-commerce;business model;simulation;computer science;marketing;resource management;operating system;data mining;database;world wide web;computer security	Metrics	-19.68573007992453	73.3912672807859	182295
d7459814fef788974755eb59fab8e343da625449	energy efficiency techniques in cloud computing: a survey and taxonomy	energy efficiency;multicores;resource scheduling;virtualization;virtual machines vms;resource management system rms;consolidation;data center;information and communication technology ict;cloud computing	The increase in energy consumption is the most critical problem worldwide. The growth and development of complex data-intensive applications have promulgated the creation of huge data centers that have heightened the energy demand. In this article, the need for energy efficiency is emphasized by discussing the dual role of cloud computing as a major contributor to increasing energy consumption and as a method to reduce energy wastage. This article comprehensively and comparatively studies existing energy efficiency techniques in cloud computing and provides the taxonomies for the classification and evaluation of the existing studies. The article concludes with a summary providing valuable suggestions for future enhancements.	cloud computing;data center;data-intensive computing;evolutionary taxonomy	Tarandeep Kaur;Inderveer Chana	2015	ACM Comput. Surv.	10.1145/2742488	consolidation;data center;real-time computing;virtualization;simulation;cloud computing;computer science;operating system;database;distributed computing;efficient energy use	HPC	-25.991270235460227	65.95242887413536	182678
2c93d96201c0a4eb46afd045e879610d17b79dc5	application of predictive simulation in development of adaptive workflows	customer services;digital simulation;museums;workflow management software;adaptive workflows;context aware workflows;customer service workflows;digital service design;museum;predictive simulation;proactive adaptation;reactive adaptation;runtime simulation	Context aware workflows are adapted to changing circumstances to meet their execution performance requirements. Adaptation can be performed reactively or proactively. Predictive or runtime simulation can be used to adapt workflows proactively. This paper proposes an approach for using the predictive simulation in improving efficiency of customer service workflows. The predictive simulation is invoked during the workflow execution to evaluate expected workflow performance in the current context and to adapt workflow execution accordingly. Efficiency of the predictive simulation is evaluated experimentally using an example of the digital service design at the museum. It is shown on the basis of simulation results that the proactive adaptation is more efficient than the reactive adaptation, especially, in the case of high visitor flow.	experiment;predictive modelling;requirement;simulation	Janis Grabis	2014	Proceedings of the Winter Simulation Conference 2014		real-time computing;simulation;computer science;knowledge management	HPC	-24.20648717992743	62.09533314178978	182702
8231100b207205887cf5e8c3fc8c00c659581b98	secure multiparty graph computation	anonymization;protocols social network services privacy cryptography computer science electronic mail;social networking online cryptographic protocols network theory graphs;anonymization multiparty computation social networks;social networks;weighted edges secure multiparty graph computation online networked data universal topological characteristics social networks sensitive network data inaccessibility hate networks trust networks sexual relationship networks secure multiparty protocol information theoretically secure protocol k anonymity test self loop checking;multiparty computation	The recent explosion of online networked data and the discovery of universal topological characteristics in real world networks has led to the emergence of a new domain of research, namely, social networks. However, much research in this domain remains unexplored due to the inaccessibility of data of sensitive networks, which include hate networks, trust networks and sexual relationship networks. This paper proposes a secure multiparty protocol which allows a set of parties to compute the underlying network on them. The proposed protocol is information theoretically secure, and its security is further enhanced by a list of security tests, which includes k-anonymity test, check for self loops and weighted edges. Although some solutions have been proposed for this problem earlier, the practicality of each one of those is questionable.	computation;emergence;social network;web of trust	Varsha Bhat Kukkala;Sudarshan Iyengar;Jaspal Singh Saini	2016	2016 8th International Conference on Communication Systems and Networks (COMSNETS)	10.1109/COMSNETS.2016.7439973	evolving networks;computer science;secure two-party computation;theoretical computer science;distributed computing;internet privacy;computer security;computer network;social network	DB	-32.95743045065804	70.37582523160431	183591
0c0c31bba51092b8120b6368ee5159f025e46914	noise aware scheduling in data centers	renewable energy;battery;power management;server heterogeneity	As the demand for large scale computing is rapidly increasing to serve billions of users across the world, more powerful and densely packed server configurations are being used. Often in developing countries, and in small and medium enterprises, it is hard to place such servers in sound-proof server rooms. Hence, servers are typically placed in close proximity to employees. The noise from the cooling fans in servers adversely affects employees' health, and reduces their productivity. In this paper, we provide a framework for computer architects to measure the acoustic profile in a data center along with the temperature profile, and estimate the sound power levels at points of interest. Additionally, we studied the noise levels obtained upon using algorithms targeted at homogenizing the temperature profile. We found that these algorithms result in high noise levels, sometimes above the permissible levels. So, we propose two heuristics to redistribute workloads in a data center such that noise can be reduced at certain target locations. We obtain a noise reduction of 2-13 dB when compared with uniform workload distribution, and upto 16 dB as compared to temperature aware workload placement, with a reduction of at least 5-6 dB in 75% of the cases. The performance overhead is limited to 1%.	acoustic cryptanalysis;algorithm;computer cooling;data center;heuristic (computer science);noise reduction;overhead (computing);point of interest;scheduling (computing);server (computing)	Hameedah Sultan;Arpit Katiyar;Smruti R. Sarangi	2016		10.1145/2925426.2926268	renewable energy;embedded system;parallel computing;real-time computing;simulation;operating system;battery	HPC	-26.124729465364506	67.84733714764327	184143
7e5f51094c5d9ab68e370c7b62dcdf4c685122f6	video communication for networked communities: challenges and opportunities	togetherness;social network services;teleconferencing;social communication;group video conferencing;service aware networking;network topology;media;streaming media cameras media network topology communities social network services real time systems;streaming media;video communication social networking online teleconferencing;social networking online;video communication systems networked community video conferencing social networking group communication robust video communication session arbitrary network;communities;video communication;communication orchestration;cameras;real time systems;communication orchestration social communication togetherness service aware networking group video conferencing	While advances in commercial video conferencing and social networking are driving more people to communicate using video, it is still difficult to achieve a sense of co-presence - that is to make the technology transparent to its users - when mediating ad hoc interactions between groups of people in different locations. This paper presents an ambitious plan to define and demonstrate a platform for group communication that allows participants to create a robust video communication session that is centred on a shared activity and to which participants can join or leave in an arbitrary manner using an arbitrary device specification on an arbitrary network. We describe two representative applications in which co-presence is not currently well supported. We then explain the key technical capabilities which we believe must be developed in order to build our platform, highlighting how they extend the state of the art in the dynamic control of video communication systems and the configuration of key components within the network. We conclude by explaining how our novel platform will be implemented and evaluated over the next 3 years.	cost efficiency;hoc (programming language);interaction;interactive media;session (computer science);simulation;socialization;video;while	Tim Stevens;Ian Kegel;Doug Williams;Pedro Torres;Pablo César;Phil Stenton;Rene Kaiser;Marian Florin Ursu;Manolis Falelakis;Nikolaus Färber	2012	2012 16th International Conference on Intelligence in Next Generation Networks	10.1109/ICIN.2012.6376018	computer science;multimedia;world wide web;computer network	Mobile	-22.683162033510754	73.45858466286863	184210
448b2cc44c2e5fe7d3f9848d1015afd9cad27bc1	robust large-scale spectrum auctions against false-name bids	会议论文;spectrum auctions;false name proofness;cognitive radio networks	Auction is a promising approach for dynamic spectrum access in Cognitive Radio Networks. Existing auction mechanisms are mainly proposed to be strategy-proof to stimulate bidders to reveal their valuations of spectrum truthfully. However, they would suffer significantly from a new cheating pattern named false-name bids, where a bidder can manipulate the auction by submitting bids under multiple fictitious names. We show such false-name bid cheating is easy to make but hard to be detected in dynamic spectrum auctions. To resolve this issue, we propose ALETHEIA, a novel flexible, false-name-proof auction framework for large-scale dynamic spectrum access. ALETHEIA has the following important features: (1) it not only guarantees strategy-proofness but also resists false-name bids, (2) it enables spectrum reuse across a large number of bidders, (3) it provides the bidders the flexibility of diverse demand formats, and (4) it incurs low computational overhead. Simulation results show that ALETHEIA achieves both high spectrum redistribution efficiency and auction efficiency.	cognitive radio;computation;overhead (computing);simulation	Qinhui Wang;Baoliu Ye;Bin Tang;Tianyin Xu;Song Guo;Sanglu Lu;Weihua Zhuang	2015	IEEE Transactions on Mobile Computing	10.1145/2746285.2746307	spectrum auction;auction algorithm;cognitive radio;vickrey auction;combinatorial auction;generalized second-price auction;unique bid auction;computer science;vickrey–clarke–groves auction;common value auction;english auction;auction theory;computer network	Mobile	-27.069091086758966	73.01045719610252	184224
62638d0d4a1a366d749d151b34a80c1044ad2ef6	enhanced gridsim architecture with load balancing	communication overhead;load balancing;gridsim;grid computing;enhanced gridsim architecture	Grid is a network of computational resources that may potentially span many continents. Maximization of the resource utilization hinges on the implementation of an efficient load balancing scheme, which provides (i) minimization of idle time, (ii) minimization of overloading, and (iii) minimization of control overhead. In this paper, we propose a dynamic and distributed load balancing scheme for grid networks. The distributed nature of the proposed scheme not only reduces the communication overhead of grid resources but also cuts down the idle time of the resources during the process of load balancing. We apply the proposed load balancing approach on Enhanced GridSim in order to gauge the effectiveness in terms of communication overhead and response time reduction. We show that significant savings are delivered by the proposed technique compared to other approaches such as centralized load balancing and no load balancing.	centralized computing;computational resource;expectation–maximization algorithm;load balancing (computing);operator overloading;overhead (computing);response time (technology)	Kalim Qureshi;Attiqa Rehman;Paul D. Manuel	2010	The Journal of Supercomputing	10.1007/s11227-010-0402-6	network load balancing services;parallel computing;real-time computing;computer science;load balancing;distributed computing;computer security;grid computing	HPC	-20.394273168453353	63.03162468575471	185044
87ed7d26022e8e5ebad07895fe9969584a2c4761	orchestrating connectivity services to support elastic operations in datacenter federations	federated datacenters;energy costs minimization;inter datacenter networks;article	Datacenter federations are able to manage appropriately the green energy resources available in each datacenter (DC) thanks to their geographically distributed infrastructure, thus reducing energy expenditure. Scheduling algorithms can compute virtual machine migration, transferring huge amounts of raw data from one DC to another to minimize operational costs and ensuring a certain Quality of Experience. Because green energy availability greatly depends on weather conditions, in this work we present a statistical model to improve green solar energy availability estimation accuracy and we use it in a mixed integer linear programming formulation to compute optimal virtual machine placement. Optical connections can be used to provide connectivity services of enough capacity to support those migrations. In particular, elastic optical networks can provide connections with multi-granular bitrate, which can be adapted on demand. DC resource managers can request optical connections and control their capacity. However, that scheme involves the resource managers to implement algorithms and interfaces to deal with network specifics and complexity. To solve that issue, in this paper we propose coordinating transfer-based inter-DC connectivity services; inter-DC connectivity is requested in terms of volume of data and completion time. We analyze cost savings when each connectivity model is applied in a DC federation. For the sake of a compelling analysis, exhaustive simulation experiments are carried out considering realistic scenarios. Results show that the notification-based model can save up to 20 % of energy costs and more than 40 % of communication costs in the evaluated scenarios.	algorithm;data center;experiment;federation (information technology);integer programming;linear programming formulation;norm (social);scheduling (computing);simulation;statistical model;virtual machine	Adrian Asensio;Marc Ruiz;Luis Velasco	2015	Photonic Network Communications	10.1007/s11107-015-0498-y	real-time computing;simulation;telecommunications;computer science;distributed computing;computer network	HPC	-21.76410568649481	63.37696976733937	185148
e10a86f976dad8f0581750f83c93f147cdda5d87	adaptive resource selection for grid-enabled network services	resource selection;performance evaluation;application software;processor scheduling;high speed networks;queueing theory;adaptive site selection heuristics;resource management;application software fluid dynamics high speed networks software packages packaging software performance hardware resource management processor scheduling computer science;site selection;adaptive resource selection;packaging;software performance;computer networks;grid enabled network services;multi level queue based selection adaptive resource selection grid enabled network services high speed networks packaging interface technologies high demand network services adaptive site selection heuristics weight queue length based heuristic;weight queue length based heuristic;performance evaluation computer networks queueing theory;fluid dynamics;computer science;high demand network services;network services;interface technologies;high performance;software packages;hardware;multi level queue based selection	Due to the popularity of high-speed networks and advances in packaging and interface technologies, there has been significant efforts for providing high performance applications as network services that can be accessed remotely across the network, thus promoting sharing of both software and hardware. For highdemand network services, in particular, it will often be the case that the network services are installed at multiple sites so that each participating site can handle parts of client requests. We label such services as Gridenabled network services. In this paper, we present two adaptive site selection heuristics that do not depend on accurate predictions of completion times of service	algorithm;component-based software engineering;encapsulation (networking);heuristic (computer science);performance;resource management (computing);simulation	Byoung-Dai Lee;Jon B. Weissman	2003		10.1109/NCA.2003.1201140	packaging and labeling;application software;real-time computing;simulation;intelligent computer network;software performance testing;computer science;resource management;operating system;network simulation;distributed computing;services computing;queueing theory;computer network;fluid dynamics	Networks	-19.855678038471673	70.93154043898905	185418
f7aa05f12e779b770e5d4a2eb1535906bb38477f	analysis and evaluation of i/o hypervisor scheduling	vm i o hypervisor scheduling cloud services i o requests physical cpu virtualized resource consolidation i o resources virtual machines physical hosts i o operations ioh;scheduling i o hypervisor cloud computing virtualization;virtualization;i o hypervisor;virtualisation cloud computing input output programs processor scheduling virtual machines;virtual machining;resource management;virtual machine monitors;servers;scheduling algorithms;scheduling;virtual machine monitors servers cloud computing resource management scheduling algorithms virtual machining;cloud computing	Hypervisors' smooth operation and efficient performance has an immediate effect in the supported Cloud services. We investigate scheduling algorithms that match I/O requests originated from virtual resources, to the physical CPUs that do the actual processing. We envisage a new paradigm of virtualized resource consolidation, where I/O resources required by several Virtual Machines (VMs) in different physical hosts, are provided by one (or more) external powerful dedicated appliance(s), namely the I/O Hypervisor (IOH). For this reason I/O operations are transferred from the VMs to the IOH, where they are executed. We propose and evaluate a number of scheduling algorithms for this hypervisor model, concentrating on providing guaranteed fairness among the virtual resources. A simulator has been built that describes this model and is used for the implementation and the evaluation of the algorithms. We also analyze the performance of the different hypervisor models and highlight the importance of fair scheduling.	algorithm;algorithmic efficiency;central processing unit;cloud computing;experiment;fair-share scheduling;fairness measure;hypervisor;i/o scheduling;input/output;programming paradigm;queuing delay;scheduling (computing);semiconductor consolidation;simulation;virtual machine	Konstantinos Kontodimas;Panagiotis C. Kokkinos;Yossi Kuperman;Emmanouel A. Varvarigos	2015	2015 IEEE/ACM 8th International Conference on Utility and Cloud Computing (UCC)	10.1109/UCC.2015.19	fair-share scheduling;embedded system;real-time computing;storage hypervisor;computer science;resource management;operating system;two-level scheduling;scheduling	HPC	-21.831860464087356	60.65709891590112	185434
0d998c8d61131a3854532b1168edce19c76ddf95	investigating transparent web proxies in cellular networks		Users increasingly use mobile devices as their primary mean s to access the Internet. While it is well known that cellular network operators employ middleboxes, the details of their behavior and their impact on performance for representative Web workloads are poorly understood. This paper presents an analysis of proxy behavior and how transparent Web proxies interact with HTTP traffic in four major US cell carriers. We find that all four carriers use these proxies to interpose on HTTP traffic, but they vary in terms of whether they perform object caching, traffic redirection, i mage compression, and connection reuse. For example, some transparent proxies unilaterally lower the quality of imag es, which improves object fetch time but may hurt user satisfaction. We also find that these proxies do not necessarily enhance performance for mobile Web workloads in terms of object fetch times; namely, we observe noticeable benefits only when flow sizes are large and the path between the server and proxy exhibits large latency and/or loss.	hypertext transfer protocol;internet;middlebox;mobile device;proxy server;server (computing)	Xing Xu;Yurong Jiang;Tobias Flach;Ethan Katz-Bassett;David R. Choffnes;Ramesh Govindan	2015		10.1007/978-3-319-15509-8_20	the internet;computer science;image compression;latency (engineering);web performance;computer network;mobile web;mobile device;cellular network;fetch	Metrics	-19.43303907491878	74.4110035510002	185549
93bbb97c42077bc373b498b1967f3a491af33419	bazaar-extension: a cloudsim extension for simulating negotiation based resource allocations	bazaar sla negotiation cloud market;cloud computing resource management genetic algorithms pricing receivers virtual machining;bazaar score bazaar extension cloudsim extension negotiation based resource allocation simulation negotiation process auctioning protocol electronic negotiation mechanism price increment fair transparent resource allocation offer counteroffer negotiation protocol supermarket approach genetic algorithm based negotiation strategy;resource allocation cloud computing contracts genetic algorithms	Negotiation processes taking place between two or more parties need to agree on a viable execution mechanism. Auctioning protocols have proven useful as electronic negotiation mechanisms in the past. Auctions are a way of determining the price of a resource in a dynamic way. Additionally, auctions have well defined rules such as winner and loser determination, time restrictions or minimum price increment. These restrictions are necessary to ensure fair and transparent resource allocation. However, these rules are limiting flexibility of consumers and providers. In this paper we introduce a novel negotiation based resource allocation mechanisms using the offer-counteroffer negotiation protocol paradigm. This allocation mechanism shows similarities to the supermarket approach as consumer and provider are able to communicate directly. Further, the price is determined in a dynamic way similar to auctioning. We developed a Bazaar-Extension for CloudSim which simulates negotiation processes with different strategies. In this paper we introduce and analyze a specific Genetic Algorithm based negotiation strategy. For the comparison of the efficiency of resource allocations a novel Bazaar-Score was used.	bilateral filter;cloudsim;genetic algorithm;handshaking;programming paradigm;simulation;utility	Benedikt Pittl;Werner Mach;Erich Schikuta	2016	2016 IEEE International Conference on Services Computing (SCC)	10.1109/SCC.2016.62	operations management;microeconomics;business;commerce	AI	-24.445068659801397	65.25863941360491	185603
bccb7907a32a698bbf582f14d107f846545a323a	late breaking: processor selection for optimum middleware price/performance			middleware	David Kra	2011			real-time computing;economics;middleware	Logic	-27.140567522068725	64.86147771690848	186304
0f30ee631876a2de81b4bb58c51ca01da927cae5	a system for online power prediction in virtualized environments using gaussian mixture models	virtual machine;workload characterization;virtualization;prediction error;measurement;gaussian processes;virtualized environment;training;virtual machining;regression virtualization power workload characterization gaussian mixture models;voice mail;runtime;computer architecture;power aware computing;online power prediction;servers;gaussian mixture model;regression;predictive models power system modeling energy consumption voice mail virtual manufacturing costs runtime energy management virtual machining cooling;virtual machines;physical machine online power prediction virtualized environment gaussian mixture models architectural metrics virtual machine;energy consumption;gaussian mixture models;predictive models;physical machine;power consumption;virtual environment;power system modeling;power demand;architectural metrics;power;virtual manufacturing;benchmark testing;cooling;energy management;virtual machines computer architecture gaussian processes power aware computing	In this paper we present a system for online power prediction in virtualized environments. It is based on Gaussian mixture models that use architectural metrics of the physical and virtual machines (VM) collected dynamically by our system to predict both the physical machine and per VM level power consumption. A real implementation of our system shows that it can achieve average prediction error of less than 10%, outperforming state of the art regression based approaches at negligible runtime overhead.	mixture model;overhead (computing);virtual machine	Gaurav Dhiman;Kresimir Mihic;Tajana Simunic	2010	Design Automation Conference	10.1145/1837274.1837478	embedded system;real-time computing;simulation;computer science;engineering;virtual machine;operating system	EDA	-21.367849461106623	61.54838494457129	186365
5f96fa3c4ee96c54cc0ab43d27e2828f1fe0eca1	a model for availability of quality of service in distributed multimedia systems	distributed system;availability;distributed multimedia system;quality requirement;multimedia distributed systems;quality of service;asset allocation	In this paper we introduce a new model for the definition and the implementation of quality of service (QoS) in distributed multimedia systems. The model provides both the users and the provider/manager of the system with a framework for the high level description of the system's configuration and operation, as well as with an application/user specific definition of QoS. The model maps this high level QoS description to quality requirements for the individual resources that compose the overall service. The implementation of the QoS of the overall service is done by providing probability of availability guarantees for certain levels of QoS. Given some constraints on the total assets available for the implementation of a specific service, the model optimally allocates these assets to the system resources in order to implement a specific user/application QoS profile. The model is reduced to a General Asset Allocation Problem (GA2P) and we solve the GA2P in a provably optimal way for a wide range of realistic services.	entropy maximization;high-level programming language;loss function;optimization problem;quality of service;requirement;system configuration	Athanasios G. Malamos;Elias N. Malamas;Theodora A. Varvarigou;Sudhir R. Ahuja	2002	Multimedia Tools and Applications	10.1023/A:1013956019587	availability;real-time computing;mobile qos;quality of service;computer science;service delivery framework;asset allocation;distributed computing;computer security;computer network	Networks	-21.471501226005227	65.74779491618138	186528
79ae22028f9e2c991f0a74856b8c11e8d6926105	integrated global and local quality-of-service adaptation in distributed, heterogeneous systems	resource limitation;video streaming;resource limitations and fluctuations;heterogeneous systems;quality of service adaptation;resource manager;engineering and technology;teknik och teknologier;distributed resource management;network architecture;quality of service;networked architectures;heterogenous systems	In this paper we have developed a method for an efficient Quality-ofService provision and adaptation in dynamic, heterogeneous systems, based on our Matrix framework for resource management. It integrates local QoS mechanisms of the involved devices that deal mostly with short-term resource fluctuations, with a global adaptation mechanism that handles structural and long-term load variations on the system level. We have implemented the proposed approach and demonstrated its effectiveness in the context of video streaming.	care-of address;quality of service;streaming media	Larisa Rizvanovic;Damir Isovic;Gerhard Fohler	2007		10.1007/978-3-540-77092-3_20	real-time computing;simulation;network architecture;quality of service;computer science;resource management;distributed computing;human resource management system;computer network	HPC	-27.072934117049716	61.46083379293514	186534
8285b91352f7e6b507c5e3798070cb996086da48	efficacité énergétique dans le calcul très haute performance : application à la tolérance aux pannes et à la diffusion de données. (energy efficiency in very high-performance computing : application to fault tolerance and data broadcasting)		"""High-Performance Computing (HPC) infrastructures have experienced a rapid growth, particularly these last years. This growth has been driven by the increased need in terms of computational power expressed by scientists in various fields. However, their increasing size makes them important electricity consumers since they already consume several megawatts. In order to consume """"less"""" and better"""", we proposed a framework which permits to choose the less energy consuming versions of the services before pre-executing the application. In addition, our framework relies on a smart grid in order to schedule resource reservations on these computing infrastructures. This framework, called SESAMES, is adapted to two services required in high performance computing : fault tolerance and data broadcasting. Experimental validations have shown that we can reduce the energy consumption of both services by relying on accurate energy estimations provided SESAMES for any execution context and for any platform equipped with wattmeters. Our estimation methodology is based on a description of the execution context and on a platform calibration that consists of gathering energy measurements. Simulations have shown that the multi-criteria reservation scheduler proposed in SESAMES, simultaneously reduces the energy consumption, the financial cost and the environmental impact of these reservations, while respecting the constraints imposed by the user and the energy supplier."""		Mohammed el Mehdi Diouri	2013				HPC	-21.41876786351309	62.00040044279812	187272
bad2408e2ef8cd811986e2a7657d1a8f2f939f82	heterogeneous resource allocation in shared datacenters	sharing incentive;fairness;resource management throughput memory management quality of service optimization silicon servers;resource allocation;system utilization heterogeneous resource allocation shared datacenters resource allocation models qos coupled resources;heterogeneous resources;envy freedom;qos;sharing incentive data center resource allocation heterogeneous resources qos fairness envy freedom;data center;resource allocation computer centres quality of service	Allocating heterogeneous resource types among multiple clients in a shared datacenter is challenging. Traditional resource allocation models have largely been designed to provide QoS for a single resource type, and result in poor utilization and fairness when applied to multiple coupled resources. In this paper we present a new formal model for allocating multiple resource types among clients to provide both fairness and high system utilization. The model and algorithms are validated with empirical results.	algorithm;data center;experiment;fairness measure;linux;quality of service;server (computing);simulation;spectral edge frequency;throughput	Mohammad Shahriar Parvez Khan;Peter J. Varman	2016	2016 45th International Conference on Parallel Processing Workshops (ICPPW)	10.1109/ICPPW.2016.58	data center;real-time computing;quality of service;max-min fairness;resource allocation;computer science;distributed computing;computer network	HPC	-21.779817392266704	61.01646059620502	187494
65a571f39c7870e94a731dec14abb02c8a10e9aa	profit-based file replication in data intensive cloud data centers		Many of the applications running in cloud data center are data intensive, processing large amount of data inside the data center. File replication, which brings data files closer to the computing virtual machines (VMs), is an effective strategy that reduces data access latencies and bandwidth consumption, thus saving energy in data centers. In this paper, we formulate and study the file replication problem (FRP) in data center, with the goal of minimizing the total energy consumption of data file access inside data centers. In contrast to all the existing work of data replication in data centers, which are mainly heuristic based, we design a time-efficient approximation algorithm with performance guarantee for energy consumption in file replication. In particular, our file replication algorithm is based on a novel concept called “profit”, and optimizes over a submodular function that can be computed efficiently. Our algorithm yields the total profit of file replication at least half of what is achieved by an optimal replication solution. We also design two energy- and time-efficient heuristic file replication algorithms. Via extensive simulations using CloudSim, a popular simulation framework for cloud computing, we compare all the algorithms under different network scenarios. We show that the approximation algorithm outperforms the other two under different network parameters, while all three effectively reducing the total energy consumptions of data access in data centers.	approximation algorithm;cloud computing;cloudsim;data access;data center;data-intensive computing;functional reactive programming;heuristic;program optimization;replication (computing);simulation;submodular set function;virtual machine	Muhannad Alghamdi;Bin Tang;Yutian Chen	2017	2017 IEEE International Conference on Communications (ICC)	10.1109/ICC.2017.7996728	data file;computer network;submodular set function;real-time computing;data center;replication (computing);approximation algorithm;cloudsim;cloud computing;computer science;data access;distributed computing	HPC	-20.192449382095234	62.848266581606076	187639
a0af9755e8c0e98fb343b8c907ef64905aa982b6	dependable virtual network mapping	network virtualization;90b18;68m15;stochastic petri nets;dependability;grasp;68m10	Virtualized networks are a promising approach to deal with the current ossification problem of Internet. A major challenge is related to virtual network (VN) mapping, as it is a NP-hard problem. Thus, several heuristics have been proposed aiming to achieve efficient allocation, but they do not consider dependability issues, which directly impact quality of service. This paper proposes a Greedy Randomized Adaptive Search Procedure (GRASP) based algorithm for dependable virtual network mapping, considering availability as the adopted metric. Redundancy policies are also adopted in order to meet VN requests with high availability constraints. Experiments demonstrate the impacts whenever dependability is taken into accountsss in the allocation as well as the trade-off between VN’s availability and cost.	coexist (image);dependability;diagram;grasp;greedy algorithm;greedy randomized adaptive search procedure;heuristic (computer science);high availability;internet;np-hardness;network mapping;quality of service;randomized algorithm;stochastic petri net;substitution-permutation network	Victor Lira;Eduardo Antonio Guimarães Tavares;Stenio F. L. Fernandes;Paulo Romero Martins Maciel	2014	Computing	10.1007/s00607-014-0431-8	embedded system;real-time computing;stochastic petri net;computer science;dependability;grasp;distributed computing	HPC	-19.725512211424636	65.0849090776698	188451
580d47e41a403f36616cfb9528af43719ceb3978	an incentive-compatible mechanism for efficient distribution of bulk contents on peer-to-peer networks	p2p system;game theory;incentive compatibility;network protocol;peer to peer network;distributed processing;content distribution;service differentiation;p2p networks;mechanism design;peer to peer;peer to peer networks;incentive mechanism design	In recent years, the rapid growth of peer-to-peer (P2P) networks has provided a new paradigm for content distribution. To improve the efficiency of a P2P system, it is important to provide incentives for the peers to participate and contribute their resources. Various attempts have been made to reward/penalize peers by providing service differentiation based on a requesting peer’s history or reputation. However, in a truly distributed, non-cooperative environment, maintaining and preventing the untruthful revealing of such information within the community impose larger computation and communication overheads to the system. These problems are further magnified when large-volume contents are being distributed because of the length distribution processes and the update of history or reputation has to keep up with the distribution process. In this paper, we address the incentive provisioning problem for distribution of large-volume content in P2P networks, and present a “seeing-is-believing” incentive-compatible mechanism (protocol) in which a peer will decide how much resources will be assigned to which neighbors based on what it has experienced. The protocol applies a utility-based resource-trading concept where peers will maximize their contributions for a fair or better return, and we show that by adopting this protocol, the system will achieve Cournot Equilibrium. Furthermore, our protocol is lightweight, completely decentralized, and cheat-proof. Experimental S. G. M. Koo ( ) Department of Mathematics and Computer Science, University of San Diego, CA 92110, USA e-mail: koo@sandiego.edu C. S. G. Lee School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN 47907, USA e-mail: csglee@purdue.edu results illustrate significant improvements on the distribution efficiency of our protocol over other adopted alternatives.	algorithm;bittorrent;bundle adjustment;computation;computer engineering;computer science;digital distribution;email;nash equilibrium;overhead (computing);peer-to-peer;programming paradigm;provisioning;simulation;telecommunications link	Simon G. M. Koo;C. S. George Lee	2007	Telecommunication Systems	10.1007/s11235-006-9021-1	mechanism design;game theory;communications protocol;incentive compatibility;computer science;distributed computing;dead peer detection;computer security;computer network	Networks	-25.815310420031835	73.8370979261633	188470
023e8e8e871f8ab1392e725ae3a64ccece5f98c0	statistics-driven workload modeling for the cloud	databases;distributed system;kernel canonical correlation analysis;decision support;cluster computing;generators;statistics driven workload modeling;measurement;cost function;resource manager;data processing;query optimization;cloud computing job shop scheduling databases predictive models processor scheduling large scale systems resource management computer science costs computer industry;satisfiability;statistical model;workload generator;resource use;parallel databases;accuracy;data analysis;large scale;cloud computing applications;pay as you go;internet;statistical analysis;optimal scheduling;system design;execution environment;data intensive computations;model development;internet services;production;performance prediction;predictive models;prediction model;statistical modeling;data intensive computing;statistical analysis data analysis internet;system management;statistical modeling statistics driven workload modeling data intensive computations cloud computing applications workload generator;cloud computing;hardware	A recent trend for data-intensive computations is to use pay-as-you-go execution environments that scale transparently to the user. However, providers of such environments must tackle the challenge of configuring their system to provide maximal performance while minimizing the cost of resources used. In this paper, we use statistical models to predict resource requirements for Cloud computing applications. Such a prediction framework can guide system design and deployment decisions such as scale, scheduling, and capacity. In addition, we present initial design of a workload generator that can be used to evaluate alternative configurations without the overhead of reproducing a real workload. This paper focuses on statistical modeling and its application to data-intensive workloads.	abstraction layer;apache hadoop;cloud computing;complexity;computation;data-intensive computing;distributed computing;heart rate variability;heuristic (computer science);job scheduler;job stream;mathematical optimization;maximal set;norm (social);overhead (computing);parallel computing;performance prediction;precondition;profiling (computer programming);program optimization;prototype;requirement;response time (technology);scheduling (computing);software deployment;statistical model;systems design;virtual machine	Archana Ganapathi;Yanpei Chen;Armando Fox;Randy H. Katz;David A. Patterson	2010	2010 IEEE 26th International Conference on Data Engineering Workshops (ICDEW 2010)	10.1109/ICDEW.2010.5452742	statistical model;real-time computing;data processing;computer science;theoretical computer science;data mining;database;predictive modelling;statistics	DB	-22.360907120597048	62.22154836809083	188499
1e5c75cce3dd23be16022478673c7a363cf7a6ca	lsmac: an improved load sharing network service dispatcher	electronic commerce;e commerce;efficient implementation;load sharing;network services	The rapid growth of the Internet is changing the way we do business. Electronic Commerce (or E-Commerce) is already a reality and will expand rapidly in the near future. However, the success of E-Commerce depends heavily on the scalability and availability of the servers. Cluster-based servers using commodity hardware have been accepted as a good alternative to expensive specialized hardware for building scalable services. In this paper, we summarize the two clustering architectures: IP-based clustering and MAC-based clustering. A new efficient implementation of the MAC-based clustering architecture is presented and its performance in clustering Web servers was measured using the WebStone benchmark and was found to be superior to that of existing MAC-based clustering implementations.	benchmark (computing);checksum;cluster analysis;commodity computing;computer cluster;dynamic web page;e-commerce payment system;experiment;fault tolerance;high availability;internet;mac address;needham–schroeder protocol;network packet;prototype;routing;scalability;server (computing);software deployment;super-server;universal networking language;web server	Xuehong Gan;Byrav Ramamurthy	2000	World Wide Web	10.1023/A:1019225512000	e-commerce;computer science;database;world wide web;computer network	DB	-19.92973709630374	71.0199311519626	189285
1b9dba89cfe509b2554d122c3972e385a3a97947	panoptic, privacy over edge-clouds		The increasing capabilities of smartphones is paving way to novel applications through the crowd-sourcing of these untapped resources, to form hyperlocal meshes commonly known as edge-clouds. While a relevant body-of-work is already available for the underlying networking, computing and storage facilities, security and privacy remain second class citizens. In this paper we present Panoptic, an edge-cloud system that enables the search for missing people, similar to the commonly known Amber alert system, in high density scenarios where wireless infrastructure might be limited (WiFi and LTE), e.g. concerts, while featuring privacy and security by design. Since the limited resources present in the mobile devices, namely battery capacity, Panoptic offers a computing offloading that tries to minimize data leakage while offering acceptable levels of performance. Our results show that it is achievable to run these algorithms in an edge-cloud configuration and that it is beneficial to use this architecture to lower data transfer through the wireless infrastructure while enforcing privacy. Results from our experimental evaluation show that the security layer does not impose a significant overhead, and only accounts for 2% of the total execution time for an edge cloud comprised by, but not limited to, 8 devices.	algorithm;british undergraduate degree classification;cloud computing;compaq lte;computer vision;crowdsourcing;dawning information industry;mobile device;network architecture;overhead (computing);privacy;run time (program lifecycle phase);secure by design;smartphone;software deployment;spectral leakage;uncontrolled format string	Tadeu Freitas;João Rodrigues;Diogo Bogas;Miguel Coimbra;Rolando Martins	2018	2018 IEEE 6th International Conference on Future Internet of Things and Cloud (FiCloud)	10.1109/FiCloud.2018.00054	architecture;data transmission;wireless;cloud computing;information privacy;computer network;mobile device;hyperlocal;secure by design;computer science	Mobile	-26.663388008943524	67.91586834487843	189852
67b0afe16569ab28fe12dcaac510e00b3e6cc4f1	virt-lm: a benchmark for live migration of virtual machine (abstracts only)	virtual machine;kronecker products;evaluation method;optimization of iterative methods;data center;evaluation methodology;energy consumption;numerical methods	Virtualization technology has been widely applied in data centers and IT infrastructures, with advantages of server consolidation and live migration. Through live migration, data centers could flexibly move virtual machines among different physical machines to balance workloads, reduce energy consumption and enhance service availability. Today's data centers can grow to a huge scale. This implies that frequent live migration would be desirable for the economic use of hardware resources. Then, the performance of the live migration strategy will be an issue. So, we need a reliant evaluation method to choose the software and hardware environments that will produce the best live migration performance.  However, there is not a complete live migration benchmark available currently. In addition, the existing evaluation methodologies select different metrics, different workloads and different test means. Thus, it is difficult to compare their results.  In this paper we first survey the current research and their evaluation methods on live migration. We then summarize the critical issues for the live migration evaluation and also raise other unreported potential problems.  We propose our solutions and present an implementation in our live migration benchmark -- Virt-LM. This is a benchmark for comparing live migration performance among different software and hardware environments in a data center scenario. We detail its design and provide some experimental results to validate its effectiveness.	benchmark (computing);data center;live usb;semiconductor consolidation;server (computing);virtual machine;x86 virtualization	Dawei Huang;Deshi Ye;Qinming He;Jianhai Chen;Kejiang Ye	2011	SIGMETRICS Performance Evaluation Review	10.1145/2160803.2160836	embedded system;data center;real-time computing;simulation;numerical analysis;computer science;virtual machine;operating system	HPC	-21.863798283324872	60.86768301745525	190266
7e7fac00cca7e49d34d89ac37fd90207bf2f0cb0	data intensive dynamic scheduling model and algorithm for cloud computing security	cloud;data storage;scheduling algorithm;data intensive;security	As cloud is growing immensely, different types of data are getting more and more dynamic in terms of security. Ensuring high level of security for all data in storages is highly expensive and time consuming. Unsecured services on data are also becoming vulnerable for malicious threats and data leakage. The main reason for this is that, the traditional scheduling algorithms for executing different services on data stored in cloud usually sacrifice security privilege in order to achieve deadline. To provide adequate security without sacrificing cost and deadline for real time data- intensive cloud system, security aware scheduling algorithm has become an effective and important feature. Existing systems also merely provide efficient security aware scheduling and security for data. In order to ensure adequate security for different data storages in cloud, in this paper we have proposed a three tier security framework. We have analyzed mathematically the security overhead for different security services such as confidentiality, integrity as well as authenticity and shown that our framework can provide adequate level of security and enhance the processing speed of security services without taking additional overhead in time. We have also proposed a scheduling algorithm to ensure security for data intensive applications. The simulation results show that the proposed algorithm gives better success rate with adequate security in comparisons with existing algorithms. This algorithm ensures security of data and applications as well as confirms the job to be scheduled within deadline.	algorithm;cloud computing security;scheduling (computing)	Md. Rafiqul Islam;Mansura Habiba	2014	JCP	10.4304/jcp.9.8.1796-1808	software security assurance;computer security model;cloud computing security;real-time computing;security information and event management;security engineering;cloud computing;computer science;information security;operating system;computer data storage;security service;distributed computing;security testing;scheduling;computer security	EDA	-30.57972085099551	64.2604298134385	190549
4c89656a977cf93e5d3f564c609bf6272e3a2d4e	integrated scheduling for make-to-order multi-factory manufacturing: an agent-based cloud-assisted approach		The fourth revolution currently envisioned for manufacturing is characterized by the interconnection of distributed manufacturing facilities and the provision of their services through cloud computing. Customers will be allowed to customize products in a make-to-order strategy and select among the available facilities and services. This paper addresses the integrated scheduling of customer orders for a multi-factory, make-to-order manufacturing environment. Distributed facilities are represented as autonomous agents that generate the schedule through goal-oriented negotiations. Scheduling agents are abstracted from facilities-related data, which are made available along with auxiliary scheduling tools in the cloud. In this way, the proposed scheduling provides a generic solution that generates efficient schedules flexibly.	scheduling (computing)	Iman Badr	2015		10.1007/978-3-319-30337-6_25	two-level scheduling;scheduling;computer-integrated manufacturing	Robotics	-26.535751595785097	62.20643948126803	190585
b58c2a7f49e1a4269eb1af617909118732b21a91	machine learning approaches in improving service level agreement-based admission control for a software-as-a-service provider in cloud	saas with machine learning;machine learning associated sla based resource provisioning;cloud with machine learning techniques;ann better performance than svm	Software as a Service (SaaS) offers reliable access to software applications to the end users over the Internet without direct investment in infrastructure and sof tware. SaaS providers utilize resources of internal data centres or rent resources from a public Infrastruct ure as a Service (IaaS) provider in order to serve their customers. Internal hosting can ample cost of admin istration and maintenance whereas hiring from an Ia S provider can impact the service quality due to its variable performance. To surmount these drawbacks, we propose pioneering admission control and scheduling algorithms for SaaS providers to effectively utili ze public Cloud resources to maximize profit by minimi zing cost and improving customer satisfaction level . There is a drawback in this method is strength of t he algorithms by handling errors in dynamic scenari o of cloud environment, also there is a need of machine learning method to predict the strategies and produ ce the according resources. The admission control provided by trust model that is based on SLA uses different strategies to decide upon accepting user requests s o hat there is minimal performance impact, avoidin g SLA penalties that are giving higher profit. Machin e learning method aims at building a distributed sy stem for cloud resource monitoring and prediction that i ncludes learning-based methodologies for modelling a d optimization of resource prediction models. The lea rning methods are Artificial Neural Network (ANN) a nd Support Vector Machine (SVM) are two typical machin e learning strategies in the category of regression computation. These two methods can be employed for modelling resource state prediction. In addition, w e conduct a widespread evaluation study to analyze wh ich solution matches best in which scenario to maxi ize SaaS provider’s profit. Results obtained through ou r extensive simulation shows that our proposed algo rithms provide significant improvement (up to 40% cost sav ing) over literature reference ones.	algorithm;artificial neural network;bandwidth (signal processing);binary prefix;cloud computing;computation;computation (action);fastest;floppy disk;huwe1 gene;handling (psychology);i/o controller hub;large-conductance calcium-activated potassium channels;machin-like formula;machine learning;mathematical optimization;oxford spelling;resource allocation;response time (technology);scenari;scheduling (computing);scheduling - hl7 publishing domain;service-level agreement;simulation;software as a service;support vector machine;time complexity;liking	R. S. Mohana;P. Thangaraj	2013	JCS	10.3844/jcssp.2013.1283.1294	simulation;artificial intelligence;operating system;machine learning;data mining;computer security;computer network	ML	-23.66577942919736	62.53581857968866	190899
5fc92ad36d811f3a2b1624cb4c0d2823f421ffaf	youchoose: choosing your storage device as a performance interface to consolidated i/o service	storage system;performance interface;model performance;machine learning;model;i o qos;service level agreement;quality of service;trace driven simulation;service quality	Currently the QoS requirements for storage systems are usually presented in the form of service-level agreement (SLA) to bound I/O measures such as latency and throughput of I/O requests. However, SLA is not an effective performance interface for users to specify their required I/O service quality for two major reasons. First, for users it is difficult to determine appropriate latency and throughput bounds to ensure their required application performance without resource over-provisioning. Second, for storage system administrators it is a challenge to estimate a user’s real resource demand because the specified SLA measures are not consistently correlated with the user’s resource demand. This makes resource provisioning and scheduling less informative and can greatly reduce system efficiency.  We propose the concept of reference storage system (RSS), which can be a storage system chosen by users and whose performance can be measured offline and mimicked online, as a performance interface between applications and storage servers. By designating an RSS to represent I/O performance requirement, a user can expect the performance received from a shared storage server servicing his I/O workload is not worse than the performance received from the RSS servicing the same workload. The storage system is responsible for implementing the RSS interface. The key enabling techniques are a machine learning model that derives request-specific performance requirements and an RSS-centric scheduling that efficiently allocates resource among requests from different users. The proposed scheme, named as YouChoose, supports the user-chosen performance interface through efficiently implementing and migrating virtual storage devices in a host storage system. Our evaluation based on trace-driven simulations shows that YouChoose can precisely implement the RSS performance interface, achieve a strong performance assurance and isolation, and improve the efficiency of a consolidated storage system consisting of different types of storage devices.	computer data storage;file server;information;input/output;machine learning;online and offline;provisioning;rss;requirement;scheduling (computing);server (computing);service-level agreement;simulation;system administrator;throughput	Xuechen Zhang;Yuehai Xu;Song Jiang	2011	TOS	10.1145/2027066.2027069	embedded system;real-time computing;converged storage;quality of service;computer science;operating system;database;world wide web;service quality	OS	-22.802774117395447	61.15940789159966	191156
1eb73f49cb0ab4e0961aa44f4b02da3220039d29	mmpp characterization of web application traffic	analytical models;computing environments mmpp characterization web application traffic markov modulated poisson process;tpc w;bismuth;mmpp;servers;computational modeling;time factors;internet;stochastic processes;synthetic workload;mathematical model;benchmark testing computational modeling servers time factors bismuth mathematical model analytical models;markov processes;stochastic processes internet markov processes;burstiness;benchmark testing;tpc w burstiness mmpp synthetic workload	Web application traffic has been shown to exhibit burstiness. The traditional model based on Poisson process is unable to capture the burstiness in traffic. On the other hand, the Markov-modulated Poisson process (MMPP) has been successfully used to model bursty traffic in a variety of computing environments. In this paper, we conduct experiments to investigate the effectiveness of MMPP as a traffic model in the context of resource provisioning in web applications. We first extend an available workload generator to produce a synthetic trace of job arrivals with controlled burstiness. We next consider an existing algorithm, as well as a variant of this algorithm, to fit an MMPP to the synthetic trace; each of them is used to obtain values for the MMPP parameters. The effectiveness of MMPP is then evaluated by comparing the performance results through simulation, using as input the synthetic trace and job arrivals generated by the estimated MMPP.	algorithm;approximation error;dhrystone;experiment;markov chain;modulation;provisioning;response time (technology);simulation;synthetic data;synthetic intelligence;web application	Ali Rajabi;Johnny W. Wong	2012	2012 IEEE 20th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems	10.1109/MASCOTS.2012.22	stochastic process;benchmark;real-time computing;the internet;simulation;computer science;bismuth;mathematical model;markov process;computational model;server;statistics;computer network	Metrics	-21.21662753886204	71.6274524160053	191911
50c7fc4a5298b14431d14df0b68eac255ca900e7	improving performance and availability of services hosted on iaas clouds with structural constraint-aware virtual machine placement	virtual machine;optimisation;servers availability strontium optimization virtual machining algorithm design and analysis complexity theory;iaas;formal specification;approximate algorithm;complexity theory;formal model;availability;performance;virtual machining;datacenter;formal model hosted service availability iaas clouds structural constraint aware virtual machine placement virtualization based datacenters optimization problem approximation algorithms;vm placement availability clouds datacenter iaas optimization performance structural constraints;strontium;computer centres;optimization problem;approximation theory;servers;virtual machines;clouds;structural constraints;optimization;service oriented architecture;vm placement;virtual machines approximation theory cloud computing computer centres formal specification optimisation service oriented architecture;algorithm design;algorithm design and analysis;simulation environment;cloud computing	The increasing popularity of modern virtualization-based datacenters continues to motivate both industry and academia to provide answers to a large variety of new and challenging questions. In this paper we aim to answer focusing on one such question: how to improve performance and availability of services hosted on IaaS clouds. Our system, structural constraint-aware virtual machine placement (SCAVP), supports three types of constraints: demand, communication and availability. We formulate SCAVP as an optimization problem and show its hardness. We design a hierarchical placement approach with four approximation algorithms that efficiently solves the SCAVP problem for large problem sizes. We provide a formal model for the application (to better understand structural constraints) and the datacenter (to effectively capture capabilities), and use the two models as inputs to the placement problem. We evaluate SCAVP in a simulated environment to illustrate the efficiency and importance of the proposed approach.	approximation algorithm;cloud computing;data center;mathematical model;mathematical optimization;optimization problem;tag cloud;virtual machine;virtual reality	Deepal Jayasinghe;Calton Pu;Tamar Eilam;Malgorzata Steinder;Ian Whalley;Ed C. Snible	2011	2011 IEEE International Conference on Services Computing	10.1109/SCC.2011.28	real-time computing;simulation;computer science;distributed computing	DB	-21.07247514268076	64.94398433109882	192416
93184f741cf04603c69e790a75af58f462469e89	analysis on resource utilization patterns of office computer	resource utilization			Jinwei Wang;Yuzhong Sun;Jianping Fan	2005			resource management;distributed computing;computer science	Arch	-26.93631061668756	65.32870619888851	192697
27a693acee22752fa66f442b8d52b7f3c83134c7	optimal multiserver configuration for profit maximization in cloud computing	companies;customer satisfaction;computational modeling;optimization;economics;quality of service;cloud computing	As cloud computing becomes more and more popular, understanding the economics of cloud computing becomes critically important. To maximize the profit, a service provider should understand both service charges and business costs, and how they are determined by the characteristics of the applications and the configuration of a multiserver system. The problem of optimal multiserver configuration for profit maximization in a cloud computing environment is studied. Our pricing model takes such factors into considerations as the amount of a service, the workload of an application environment, the configuration of a multiserver system, the service-level agreement, the satisfaction of a consumer, the quality of a service, the penalty of a low-quality service, the cost of renting, the cost of energy consumption, and a service provider's margin and profit. Our approach is to treat a multiserver system as an M/M/m queuing model, such that our optimization problem can be formulated and solved analytically. Two server speed and power consumption models are considered, namely, the idle-speed model and the constant-speed model. The probability density function of the waiting time of a newly arrived service request is derived. The expected service charge to a service request is calculated. The expected net business gain in one unit of time is obtained. Numerical calculations of the optimal server size and the optimal server speed are demonstrated.	cloud computing;entropy maximization;expectation–maximization algorithm;mathematical optimization;optimization problem;quality of service;queueing theory;server (computing);service-level agreement	Jing Mei;Keqin Li;Keqin Li	2013	IEEE Transactions on Parallel and Distributed Systems	10.1109/TSUSC.2017.2667706	service level requirement;customer to customer;voice of the customer;customer;customer lifetime value;marketing;operations management;customer equity;customer intelligence;business;customer profitability;customer satisfaction;customer service assurance;customer retention;service quality;commerce;customer advocacy	Metrics	-23.173660731975865	63.99117112641788	192826
d7e12b207f57dd14d5ee169171902461d1bb9aef	quality-of-service aware resource allocation for virtual machines	virtual machining;resource management;servers;time factors;quality of service;cloud computing	We propose a quality of service (QoS) aware resource allocation algorithm for virtual machines (VMs) in cloud servers. The proposed scheme consists of two parts: a service profiler that describes the relationship between QoS and resource utilization, and a resource controller that determines an appropriate VM resource configuration. The performance of the proposed VM resource allocation scheme is evaluated on an OpenStack-based testbed. The experimental results show that the proposed scheme successfully identifies the VM with the highest resource demand, and increases the amount of the scarce resources to improve the QoS provided by the VM.	algorithm;cloud storage;quality of service;testbed;virtual machine	Chiwook Jeong;Taejin Ha;JongWon Kim;Hyuk Lim	2017	2017 International Conference on Information Networking (ICOIN)	10.1109/ICOIN.2017.7899502	real-time computing;quality of service;cloud computing;resource allocation;computer science;resource management;operating system;database;server;computer network	HPC	-22.53906957832041	61.99225355432556	192903
ac6a6511b350211e42d4b13403dee5c0b4f7764f	bin packing with linear usage costs		Bin packing is a well studied problem involved in many applications. The classical bin packing problem is about minimising the number of bins and ignores how the bins are utilised. We focus in this paper, on a variant of bin packing that is at the heart of efficient management of data centres. In this context, servers can be viewed as bins and virtual machines as items. The efficient management of a data-centre involves minimising energy costs while ensuring service quality. The assignment of virtual machines on servers and how these servers are utilised has a huge impact on the energy consumption. We focus on a bin packing problem where linear costs are associated to the use of bins to model the energy consumption. We study lower bounds based on Linear Programming and extend the bin packing global constraint with cost information.	algorithm;bin packing problem;data center;linear programming;linear programming relaxation;mathematical optimization;semiconductor consolidation;set packing;virtual machine	Hadrien Cambazard;Deepak Mehta;Barry O'Sullivan;Helmut Simonis	2015	CoRR		mathematical optimization;bin packing problem;mathematics	Theory	-20.583656930297842	63.82566172231141	192930
beb56e247e8e7152b9fcf95c8e50df9ae7c44d84	a guided tour of data-center networking	data center;user experience;guided tour	A good user experience depends on predictable performance within the data-center network.	data center;user experience	Dennis Abts;Bob Felderman	2012	Commun. ACM	10.1145/2184319.2184335	data center;user experience design;simulation;computer science;multimedia;world wide web	Networks	-19.76743809167921	73.82488257643249	193064
cc2a6eda66a97a707acc7ee3e326e2920743aeb7	a game-theoretic resource manager for rt applications	silicon;convergence;game theory;resource allocation;software management;resource management;resource management linux bandwidth convergence quality of service silicon real time systems;reglerteknik;scheduling resource management real time systems real time applications sched_deadline;computational complexity;scheduling;sched_deadline;bandwidth;linux;real time applications;sched_deadline linux scheduling class game theoretic resource manager rt applications resource management qos aware applications overall quality maximization linux implementation resource assignment quality setting linear time complexity;software quality computational complexity game theory linux resource allocation scheduling software management;quality of service;software quality;real time systems	"""The management of resources among competing QoS-aware applications is often solved by a resource manager (RM) that assigns both the resources and the application service levels. However, this approach requires all applications to inform the RM of the available service levels. Then, the RM has to maximize the """"overall quality"""" by comparing service levels of different applications which are not necessarily comparable. In this paper we describe a Linux implementation of a game-theoretic framework that decouples the two distinct problems of resource assignment and quality setting, solving them in the domain where they naturally belong to. By this approach the RM has linear time complexity in the number of the applications. Our RM is built over the SCHED_DEADLINE Linux scheduling class."""	coupling (computer programming);experiment;game theory;linux;quality of service;real-time clock;scheduling (computing);time complexity	Martina Maggio;Enrico Bini;Georgios C. Chasparis;Karl-Erik Årzén	2013	2013 25th Euromicro Conference on Real-Time Systems	10.1109/ECRTS.2013.17	game theory;real-time computing;quality of service;convergence;resource allocation;computer science;resource management;operating system;distributed computing;silicon;computational complexity theory;scheduling;linux kernel;bandwidth;software quality	Embedded	-20.41198264264373	65.84842665018826	193291
d5247e2bd43aa8a1175646f1151554a5ae963381	a sla-based cloud resource provisioning optimisation mechanism for multi-tenant applications	slas;resource provisioning;round robin scheduling;service level agreements;cloud resources;resource utilisation;sla constraints;sla;multi tenant applications;期刊论文;defragmentation optimisation;cloud computing	As cloud resources exhibit the characteristics of dynamic and scalability, an increasing number of service providers deploy their multi-tenant applications to Cloud. For cloud service providers, how to arrange the allocation of application resources reasonably, in order to not only satisfy the service level agreements (SLAs) of diverse tenants, but also maximise their resource utilisation, has become a major challenge. In this paper, we propose a SLA-based resource provisioning optimisation mechanism for multi-tenant applications. Based on the invoking relationships among services and the workload of service instances, the mechanism divides the tenants’ SLA into SLA constraints, and maps each SLA constraint to the corresponding service. In addition, the mechanism uses an optimised round-robin scheduling policy to improve the resource utilisation of each service instance, and employs a defragmentation optimisation algorithm to control the scale of service instances and increase the overall resource utilisation. The experimental results show that the proposed mechanism is feasible and effective.	cloud computing;division algorithm;machine learning;map;mathematical optimization;multitenancy;provisioning;round-robin scheduling;scalability;scheduling (computing);service-level agreement;single-instance storage	Yuliang Shi;Chao Yu;Jie Wang;Huayang Yu;Qingzhong Li	2015	IJAACS	10.1504/IJAACS.2015.073189	real-time computing;cloud computing;computer science;operating system;distributed computing;round-robin scheduling;computer network	HPC	-21.350237848223472	63.77024628891172	193337
fe60ac1fbb67bc25cf392b74288579fa4e84fff7	topology-aware key management scheme for secure overlay multicast	sensibilidad contexto;key management;distributed system;virtual network;replication;gestion memoire;systeme reparti;context aware;confidencialidad;shared memory;encryption;batch production;routing;memoria compartida;storage management;securite informatique;multidestinatario;routage;procede discontinu;cifrado;data replication;overlay multicast;data encryption;replicacion;confidentiality;computer security;confidentialite;gestion memoria;sistema repartido;produccion por lote;cryptage;criptografia;cryptography;seguridad informatica;production par lot;batch process;cryptographie;procedimiento discontinuo;information system;sensibilite contexte;multicast routing;multidestinataire;systeme information;red virtual;multicast;memoire partagee;reseau virtuel;key distribution;sistema informacion;enrutamiento	Recently, the research focus of multicast has been put on overlay multicast In overlay multicast, while the multicast routing, data replication and group management have been extensively studied, an important but less studied problem is security In particular, adding confidentiality to overlay multicast is needed To achieve confidentiality, data encryption keys are shared among the multicast group members There is a need for key distribution scheme to solve the rekeying overhead We introduce the key management solution called KTOM And, we propose the use of periodic batch rekeying in KTOM.	key management;multicast	Jong-Hyuk Roh;Seunghun Jin;Kyoon-Ha Lee	2006		10.1007/11919568_73	shared memory;routing;replication;multicast;overlay network;confidentiality;ip multicast;inter-domain;reliable multicast;protocol independent multicast;computer science;cryptography;pragmatic general multicast;key management;internet group management protocol;distributed computing;distance vector multicast routing protocol;source-specific multicast;key distribution;computer security;encryption;information system;xcast;computer network;multicast address	Security	-30.918360521731795	69.65648338504337	193914
00c1d00ee317486eada6accee58d1e10946fe057	sprnt: an aggressive approach to dynamically schedule resources with limited service failure in vm-based data centers	cloud computing measurement engines servers encyclopedias;measurement;servers;engines;cloud computing resource provisioning virtualization data center;encyclopedias;cloud computing	Effective virtualized resource provisioning is one of the most challenging tasks of the cloud computing system. Especially when visits to an online service are rapidly increasing, state-of-the-art approaches cannot response to the workload changes in time. In this paper we introduce SPRNT, a framework that accelerates the resource provisioning. By using SPRNT, the cloud system can quickly adapt to the explosively increasing workload and ensure that the SLA is not violated. The experimental results show that SPRNT can deal with the tremendously increasing of the workload and can also reduce the over-provisioned resources efficiently and effectively.	amazon elastic compute cloud (ec2);cloud computing;experiment;microsoft azure;money;online service provider;provisioning;rl (complexity);service-level agreement	Jinzhao Liu;Yue-Zhi Zhou	2013	2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing	10.1109/HPCC.and.EUC.2013.266	real-time computing;thin provisioning;cloud computing;computer science;operating system;distributed computing;utility computing;world wide web;encyclopedia;server;measurement	HPC	-24.09801327476549	62.195016086490476	194013
3553ba05ed405de648ce355a90b9101ace2e406c	an approach to iot service optimal composition for mass customization on cloud manufacturing		For implementing mass customization on cloud manufacturing (CMfg), Internet of Things (IoT)-enabled service optimal composition (ISOC) is a key technology used to effectively composite a manufacturing cloud service with selected IoT services to satisfy the users’ customized production requirements. The solving of the ISOC problem is done inefficiently in the context of the growing scale of IoT services and increasing sophistication of the ISOC execution path, being partly due to insufficient investigation of accumulated empirical knowledge (EK) of IoT services. In this paper, we propose an EK-oriented genetic algorithm (EK-GA) for the large-scale IoT service composition. First, by fully considering the distinctive features of IoT service and service domain features, the EK of IoT services are richly explored to divide the service space. Second, EK-oriented optimization strategies in the initial population, operators, and fitness function are presented to improve the local and global search abilities of the genetic algorithm for solving ISOC problems. Finally, the effectiveness of EK-GA for solving real-world ISOC problems in a private CMfg is verified through three types of experiments. By exploiting EK of IoT services for ISOC problems, this work makes novel contributions for mass customization on CMfg and enriches the practice of EK-oriented intelligence optimization.	cloud computing;cloud manufacturing;experiment;fitness function;genetic algorithm;information security operations center;internet of things;mathematical optimization;requirement;service composability principle;software release life cycle	Tianyang Li;Ting He;Zhongjie Wang;Yufeng Zhang	2018	IEEE Access	10.1109/ACCESS.2018.2869275	computer network;genetic algorithm;web service;cloud manufacturing;quality of service;cloud computing;mass customization;computer science;distributed computing;population;fitness function	Robotics	-20.083723610773006	65.41418022184021	194125
2ffff54e633361d71bcd171ac01854d5efa1ecd1	long-term multi-resource fairness for pay-as-you use computing systems		"""Many current computing systems such as clouds and supercomputers charge users for their resource usages. A user’s demand is often changing over time, indicating that it is difficult to keep the high resource utilization all the time for cost efficiency. Resource sharing is a classical and effective approach for high resource utilization. In view of the heterogeneous resource demands of users’ workloads, multi-resource allocation fairness is a must for resource sharing in such <italic>pay-as-you-use computing systems</italic>. However, we find that, existing multi-resource fair policies such as Dominant Resource Fairness (DRF), implemented in currently popular resource management systems such as Apache YARN <xref ref-type=""""bibr"""" rid=""""ref4"""">[4]</xref> and Mesos <xref ref-type=""""bibr"""" rid=""""ref23"""">[23]</xref> , are <italic>not</italic> suitable for the pay-as-you-use computing systems. We show that this is because of their <italic>memoryless</italic> characteristic that can cause the following problems in the pay-as-you-use computing systems: 1). users can get resource benefits by cheating; 2). users might not be able to get the total amount of resources that they are entitled to in terms of their resource contributions. In this paper, we propose a new policy called H-MRF, which generalizes DRF and Asset Fairness with the long-term notion. We show that it can address these problems and is suitable for pay-as-you-use computing systems. We have implemented it into YARN by developing a prototype called <italic>MRYARN</italic>. Finally, we evaluate H-MRF using both testbed and simulated experiments. The experimental results show that there are about <inline-formula><tex-math notation=""""LaTeX"""">$1.1\sim 1.5$</tex-math> <alternatives><inline-graphic xlink:href=""""tang-ieq1-2788880.gif""""/></alternatives></inline-formula> sharing benefit degrees and <inline-formula><tex-math notation=""""LaTeX"""">$1.2\times \sim 1.8\times$</tex-math><alternatives> <inline-graphic xlink:href=""""tang-ieq2-2788880.gif""""/></alternatives></inline-formula> performance improvement for users with H-MRF, better than existing fair schedulers."""	anisotropic filtering;apache hadoop;cloud computing;cost efficiency;cross-reference;experiment;fairness measure;markov random field;multiprogram research facility;prototype;scale (map);supercomputer;testbed;xlink	Shanjiang Tang;Zhaojie Niu;Beixin Julie He;Bu-Sung Lee;Ce Yu	2018	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2017.2788880	cheating;real-time computing;computer science;cloud computing;distributed computing;performance improvement;resource management;shared resource;cost efficiency;testbed;supercomputer	HPC	-20.503021175538443	60.83581749629935	194142
5df53a74c903ea5d578f4f1d86d106a0c7c96403	truthful greedy mechanisms for dynamic virtual machine provisioning and allocation in clouds	silicon;real workload traces truthful greedy mechanisms dynamic virtual machine provisioning vm allocation cloud providers auction based models integer program winning users;virtual machines cloud computing electronic commerce greedy algorithms integer programming;resource management;greedy heuristics;mechanical factors;dynamic resource allocation;cost accounting;vectors;truthful mechanism;virtual machine provisioning;approximation methods;greedy heuristics cloud computing truthful mechanism virtual machine provisioning dynamic resource allocation;resource management cost accounting silicon mechanical factors approximation methods vectors dynamic scheduling;dynamic scheduling;cloud computing	A major challenging problem for cloud providers is designing efficient mechanisms for virtual machine (VM) provisioning and allocation. Such mechanisms enable the cloud providers to effectively utilize their available resources and obtain higher profits. Recently, cloud providers have introduced auction-based models for VM provisioning and allocation which allow users to submit bids for their requested VMs. We formulate the dynamic VM provisioning and allocation problem for the auction-based model as an integer program considering multiple types of resources. We then design truthful greedy and optimal mechanisms for the problem such that the cloud provider provisions VMs based on the requests of the winning users and determines their payments. We show that the proposed mechanisms are truthful, that is, the users do not have incentives to manipulate the system by lying about their requested bundles of VM instances and their valuations. We perform extensive experiments using real workload traces in order to investigate the performance of the proposed mechanisms. Our proposed mechanisms achieve promising results in terms of revenue for the cloud provider.	approximation algorithm;cloud computing;experiment;greedy algorithm;integer programming;prototype;provisioning;run time (program lifecycle phase);simulation;tracing (software);virtual machine	Mahyar Movahed Nejad;Lena Mashayekhy;Daniel Grosu	2015	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2014.2308224	real-time computing;simulation;cloud computing;dynamic priority scheduling;computer science;resource management;operating system;distributed computing;silicon;cost accounting	Metrics	-21.764409414046504	64.60247781351944	194647
374c7154eb8724862d44401acc90ee6bd610a83f	dynamic voltage and frequency scaling-aware dynamic consolidation of virtual machines for energy efficient cloud data centers		1Laboratorio de Sistemas Integrados (LSI), Departamento de Ingeniería Electrónica, Universidad Politécnica de Madrid, Madrid, Spain 2CCS Center for Computational Simulation, Universidad Politécnica de Madrid, Madrid, Spain 3DACYA, Universidad Complutense de Madrid, Madrid, Spain 4Cloud Computing and Distributed Systems (CLOUDS) Laboratory, Department of Computing and Information Systems, The University of Melbourne, Melbourne, Australia Correspondence Patricia Arroba, Laboratorio de Sistemas Integrados (LSI), Departamento de Ingeniería Electrónica, Universidad Politécnica de Madrid, Spain. Email: parroba@die.upm.es Funding Information Spanish Ministry of Economy and Competitiveness, Grant/Award Number: TEC2012-33892, IPT-2012-1041-430000, RTC-2014-2717-3; Australian Research Council (ARC) Summary Computational demand in data centers is increasing because of the growing popularity of Cloud applications. However, data centers are becoming unsustainable in terms of power consumption and growing energy costs so Cloud providers have to face the major challenge of placing them on a more scalable curve. Also, Cloud services are provided under strict Service Level Agreement conditions, so trade-offs between energy and performance have to be taken into account. Techniques as Dynamic Voltage and Frequency Scaling (DVFS) and consolidation are commonly used to reduce the energy consumption in data centers, although they are applied independently and their effects on Quality of Service are not always considered. Thus, understanding the relationship between power, DVFS, consolidation, and performance is crucial to enable energy-efficient management at the data center level. In this work, we propose a DVFS policy that reduces power consumption while preventing performance degradation, and a DVFS-aware consolidation policy that optimizes consumption, considering the DVFS configuration that would be necessary when mapping Virtual Machines to maintain Quality of Service. We have performed an extensive evaluation on the CloudSim toolkit using real Cloud traces and an accurate power model based on data gathered from real servers. Our results demonstrate that including DVFS awareness in workload management provides substantial energy savings of up to 41.62% for scenarios under dynamic workload conditions. These outcomes outperforms previous approaches, that do not consider integrated use of DVFS and consolidation strategies.	cloud computing;cloudsim;computation;data center;dynamic voltage scaling;elegant degradation;email;frequency scaling;information system;quality of service;scalability;semiconductor consolidation;service-level agreement;simulation;tracing (software);virtual machine	Patricia Arroba;José Manuel Moya;José Luis Ayala;Rajkumar Buyya	2017	Concurrency and Computation: Practice and Experience	10.1002/cpe.4067	embedded system;real-time computing;simulation	HPC	-20.110196573659493	61.40603617497692	194682
38c965e472ed851ac56728d31630e044e69334ce	black-box determination of cost models' parameters for federated stream-processing systems	parametric model;optimization technique;heterogeneous event based systems;optimization techniques;performance model;cost models;stream processing;performance modeling;event based system;self management;cost model	For distribution and deployment of queries in distributed stream-processing environments, it is vital to estimate the expected costs in advance. Having heterogeneous Stream-Processing Systems (SPSs) running on various hosts, the parameters of a cost model for an operator must be determined by measurements for each relevant combination of an SPS and hardware.  This paper presents a black-box method that determines the parameters of appropriate cost models that regard system-specific behavior. For some SPSs, there might not be any appropriate cost model available due to the lack of internal knowledge. If no cost model is available for any reason, we provide and apply a non-parametric model.	analysis of algorithms;black box;ibm 1401 symbolic programming system;parametric model;spss;software deployment;stream processing	Michael Daum;Frank Lauterwald;Philipp Baumgärtel;Niko Pollner;Klaus Meyer-Wegener	2011		10.1145/2076623.2076654	simulation;stream processing;parametric model;computer science;data mining;database	DB	-25.39903503368402	61.86365479249304	194701
6347283e45d87cda9178f3b240c0d104a110284f	resource allocation for session-based two-dimensional service differentiation on e-commerce servers	electronic commerce;processing rate allocation scheme;resource allocation;e commerce;resource manager;resource management;client server systems;two dimensional service differentiation;two dimensional service differentiation model;online transaction;resource management quality of service navigation computer society time measurement costs admission control protection impedance computer science;qos;performance metric;resource allocation client server systems electronic commerce quality of service;e commerce server;weighted sums;rate allocation;waiting time;slowdown;resource management two dimensional service differentiation session slowdown rate allocation;resource managemnet;service differentiation;optimization;square root proportional rate allocation scheme;quality of service;resource allocation e commerce server quality of service qos two dimensional service differentiation model online transaction intersession model processing rate allocation scheme 2d proportional slowdown differentiation optimization square root proportional rate allocation scheme;2d proportional slowdown differentiation;session;intersession model	A scalable e-commerce server should be able to provide different levels of quality of service (QoS) to different types of requests based on clients' navigation patterns and the server capacity. E-commerce workloads are composed of sessions. In this paper, we propose a session-based two-dimensional (2D) service differentiation model for online transactions: intersession and intrasession. The intersession model aims to provide different levels of QoS to sessions from different customer classes, and the intrasession model aims to provide different levels of QoS to requests in different states of a session. A primary performance metric of online transactions is slowdown. It measures the waiting time of a request relative to its service time. We present a processing rate allocation scheme for 2D proportional slowdown differentiation. We then introduce service slowdown as a systemwide QoS metric of an e-commerce server. It is defined as the weighted sum of request slowdown in different sessions and in different session states. We formulate the problem of 2D service differentiation as an optimization of processing rate allocation with the objective of minimizing the service slowdown of the server. We prove that the derived rate allocation scheme based on the optimization guarantees client requests' slowdown to be square-root proportional to their prespecified differentiation weights in both intersession and intrasession dimensions. We evaluate this square-root proportional rate allocation scheme and a proportional rate allocation scheme via extensive simulations. Results validate that both schemes can achieve predictable, controllable, and fair 2D service differentiation on e-commerce servers. The square-root proportional rate allocation scheme provides 2D service differentiation at a minimum cost of service slowdown	algorithm;automatic differentiation;batch processing;computer;differentiated service;e-commerce payment system;emoticon;end-to-end principle;feedback;general-purpose modeling;lottery scheduling;mathematical optimization;mega man network transmission;operating system;parallel computing;programming paradigm;proportional share scheduling;provisioning;quality of service;robot;scalability;scheduling (computing);scheme;server (computing);server-side;service pack;simulation;web server;web service;weight function	Xiaobo Zhou;Jianbin Wei;Cheng-Zhong Xu	2006	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2006.111	real-time computing;quality of service;computer science;resource management;operating system;database;distributed computing;computer network	Metrics	-19.511143642360317	68.18603857634913	194976
ff98526863905e65e9253e0118eeac4482212ef3	cost-efficient algorithms for critical resource allocation in cloud federations	complexity theory;virtual machining;resource management;image edge detection;mathematical model;optimization;cloud computing	Gomory-Hu based algorithms are proposed to select hosting resources and place services in a multiple providers federation context. The algorithms, use the Gomory-Hu tree, to detect critical nodes and edges in the end user requests to make selection and placement decisions. The algorithms take into account the providers' internal costs and network connectivity costs and hosting costs by the federation members. The algorithms are shown to be scalable and near-optimal through numerical simulations and evaluations.	algorithm;cloud computing;gomory–hu tree;holographic principle;numerical analysis;scalability;simulation	Makhlouf Hadji;Benjamin Aupetit;Djamal Zeghlache	2016	2016 5th IEEE International Conference on Cloud Networking (Cloudnet)	10.1109/CloudNet.2016.11	simulation;computer science;theoretical computer science;distributed computing	Robotics	-19.436403132526525	66.33506651720633	195108
bbaea3f6a401d3447c53a95cb362eaec23ff0b63	adaptive resource utilization prediction system for infrastructure as a service cloud		Infrastructure as a Service (IaaS) cloud provides resources as a service from a pool of compute, network, and storage resources. Cloud providers can manage their resource usage by knowing future usage demand from the current and past usage patterns of resources. Resource usage prediction is of great importance for dynamic scaling of cloud resources to achieve efficiency in terms of cost and energy consumption while keeping quality of service. The purpose of this paper is to present a real-time resource usage prediction system. The system takes real-time utilization of resources and feeds utilization values into several buffers based on the type of resources and time span size. Buffers are read by R language based statistical system. These buffers' data are checked to determine whether their data follows Gaussian distribution or not. In case of following Gaussian distribution, Autoregressive Integrated Moving Average (ARIMA) is applied; otherwise Autoregressive Neural Network (AR-NN) is applied. In ARIMA process, a model is selected based on minimum Akaike Information Criterion (AIC) values. Similarly, in AR-NN process, a network with the lowest Network Information Criterion (NIC) value is selected. We have evaluated our system with real traces of CPU utilization of an IaaS cloud of one hundred and twenty servers.		Qazi Zia Ullah;Hassan Shahzad;Gul Muhammad Khan	2017		10.1155/2017/4873459	computer science;artificial intelligence;machine learning;real-time computing;quality of service;cpu time;cloud computing;autoregressive model;artificial neural network;data mining;akaike information criterion;autoregressive integrated moving average;server	HPC	-24.057403544658666	61.523709229495076	195420
165de3c5fa36601fae1ee938363173cdd346dbcd	analysis of a pool management scheme for cloud computing centers	blocking probability;analytical models;random access memory;probability;response time;interacting markov models cloud computing performance analysis response time blocking probability pool management schema power consumption;computational modeling;time factors;stochastic processes;pool management schema;performance analysis;virtualisation capacity planning manufacturing cloud computing probability stochastic processes;delay computational modeling analytical models cloud computing time factors random access memory stochastic processes;power consumption;interacting markov models;power consumption pool management scheme cloud computing centers analytical performance model stochastic submodels resource virtualization realistic servicing equilibrium arrangement capacity planning servicing delays task rejection probability;capacity planning manufacturing;virtualisation;cloud computing	In this paper, we propose an analytical performance model that addresses the complexity of cloud centers through distinct stochastic submodels, the results of which are integrated to obtain the overall solution. Our model incorporates the important aspects of cloud centers such as pool management, compound requests (i.e., a set of requests submitted by one user simultaneously), resource virtualization and realistic servicing steps. In this manner, we obtain not only a detailed assessment of cloud center performance, but also clear insights into equilibrium arrangement and capacity planning that allows servicing delays, task rejection probability, and power consumption to be kept under control.	algorithm;cloud computing;experiment;interaction;mathematical optimization;numerical analysis;programming tool;queueing theory;rejection sampling;response time (technology);server (computing);service-level agreement;software deployment;steady state;virtual machine;x86 virtualization	Hamzeh Khazaei;Jelena V. Misic;Vojislav B. Misic;Saeed Rashwand	2013	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2012.182	stochastic process;parallel computing;real-time computing;simulation;cloud computing;computer science;operating system;probability;database;distributed computing;computational model;response time;statistics;computer network	HPC	-22.905464037733594	63.08196315939001	195894
1a58fa8cfb1b0d44a06a0fa5ce90be4e373e50df	it ain't what you charge, it's the way that you do it: a user perspective of network qos and pricing	shared networks;user confidence;application software;costing;pricing;pricing quality of service quality management ip networks video sharing econometrics predictive models computer science educational institutions application software;internet;computer network management;video sharing;ip networks;predictive models;econometrics;user behavior;computer science;user perceptions;point of view;quality of service;network qos;management;user confidence network qos pricing shared networks internet quality of service management user perceptions;quality management;computer network management costing quality of service internet	Shared networks, such as the Internet, are fast becoming able to support heterogeneous applications and a diverse user community. In this climate, it becomes increasingly likely that some form of pricing mechanism will be necessary in order to manage the Quality of Service (QoS) requirements of different applications. So far, research in this area has focussed on technical mechanisms for implementing QoS and charging. This paper reports a series of studies in which users’ perceptions of QoS, and their attitudes to a range of pricing mechanisms, were investigated. We found that users’ knowledge and experience of networks, and the real-world Task they perform with applications, determine their evaluation of QoS and attitude to payment. Users’ Payment Behavior is governed by their level of Confidence in the performance of salient QoS parameters. User Confidence, in turn, depends on a number of other factors. In conclusion, we argue that charging models that undermine User Confidence are not only undesirable from the users’ point of view, but may also lead to user behavior that may have a negative impact on QoS.	heterogeneous computing;internet;point of view (computer hardware company);quality of service;requirement;virtual community	Anna Bouch;M. Angela Sasse	1999		10.1109/INM.1999.770713	pricing;quality management;application software;mobile qos;the internet;simulation;quality of service;computer science;predictive modelling;management;world wide web;computer security;activity-based costing;computer network	ECom	-24.07988457488821	64.22530092788112	196020
ee1d2fc50e0845b08bbe0a5bfa88b09f7d622347	towards optimal placement of monitoring units in time-varying networks under centralized control		The increasing penetration of software-defined communication networks with centralized control has made network management a highly demanding task. Common monitoring approaches in the context of such convoluted high-speed networks have become a serious challenge in terms of complexity and resource management. Management functions rely on monitoring information such as the flow size distribution (FSD), to perform crucial activities such as load balancing and resource provisioning. In this paper, we propose a solution as to how one can utilize limited monitoring resources to estimate the FSD for distinct flows characterized by origin-destination pairs. We provide a method to dynamically adapt placement of monitoring units with some extracted knowledge about the change in FSD’s with time.	centralized computing;time-varying network	Sounak Kar;Rhaban Hark;Amr Rizk;Ralf Steinmetz	2018		10.1007/978-3-319-74947-1_7	real-time computing;telecommunications network;resource management;network management;provisioning;load balancing (computing);business	ML	-27.099679039891107	62.47286190883283	196096
bf56304833bd7bc3867d9c2288baf734dd872f91	power-aware dynamic deployment under cpu utilization guarantee for application server cluster	application server cluster;power-aware;cpu utilization;dynamic frequency scaling;differential evolution	Application server cluster (cluster for short) is generally designed to handle peak load, resulting in an excessive waste of energy; hence, its deployment should be dynamically adjusted according to changing load. In this paper, we propose a power-aware dynamic deployment scheme for application server cluster, which aims to minimize cluster’s power consumption under given target of CPU utilization guarantee. Firstly, we present an approach to guarantee server’s CPU utilization equal to a given target value through load allocation and Dynamic Frequency Scaling (DFS), deduce the power models of Discrete DFS (D-DFS) and Equivalent Continuous DFS (EC-DFS) manner, and analyze the power and continuity advantages of EC-DFS. Then, combining DFS, server Dynamic Switching On/Off and probability-based request scheduling, we transform cluster’s power-aware dynamic deployment problem to a programming problem, whose variable number is less than other similar researches. Finally, an efficient Differential Evolution-based solving algorithm is proposed to solve the problem. Test results verify the advantages of EC-DFS, and demonstrate the effectiveness of our deployment scheme and solving algorithm.	application server;central processing unit;software deployment	Zhi Qiang Xiong;Qinkun Zhang;Lingru Cai;Changsheng Zhu;Weihong Cai	2018	Wireless Personal Communications	10.1007/s11277-017-5207-y	distributed file system;differential evolution;cpu time;real-time computing;computer science;software deployment;dynamic frequency scaling;scheduling (computing);application server	OS	-19.811111673526277	62.85743455377341	196209
1dcbc5715db194c163783a679347b86ec94b978e	how to make profit: exploiting fluctuating electricity prices with albatross, a runtime system for heterogeneous hpc clusters		The ongoing evolution of the power grid towards a highly dynamic supply system poses challenges as renewables induce new grid characteristics. The volatility of electricity sources leads to a fluctuating electricity price, which even becomes negative when excess supply occurs. Operators of high-performance--computing (HPC) clusters therefore can consider the highly dynamic variations of electricity prices to provide an energy-efficient and economic operation.  This paper presents Albatross, a runtime system for heterogeneous HPC clusters. To ensure an energy-efficient and economic processing of HPC workloads, our system exploits heterogeneity at the hardware level and considers dynamic electricity prices. We have implemented Albatross and evaluate it on a heterogeneous HPC cluster in our lab to show how the power demand of the cluster decreases when electricity prices are high (i.e., excess demand at the grid). When electricity prices are low or negative (i.e., excess supply to the grid), Albatross purposefully increases the workload and, thus, power demand of the HPC cluster---to make profit.	computation (action);computer cluster;genetic heterogeneity;offset binary;runtime system;supercomputer;volatility;workload	Timo H&#246;nig;Christopher Eibel;Adam Wagenh&#228;user;Maximilian Wagner;Wolfgang Schr&#246;der-Preikschat	2018		10.1145/3217189.3217193	workload;runtime system;grid;real-time computing;renewable energy;power management;albatross;excess supply;supercomputer;business	HPC	-21.025848922934372	61.63887292244822	196542
8be0b6391caf605f076c158f90a677f9442dd73d	structural optimization of reduced ordered binary decision diagrams for sla negotiation in iaas of cloud computing	iaas;robdd structural optimization;term rewriting;sla negotiation;cloud computing	In cloud computing, an automated SLA is an electronic contract used to record the rights and obligations of service providers and customers for their services. SLA negotiation can be a time-consuming process, mainly due to the unpredictable rounds of negotiation and the complicated possible dependencies among SLAs. The operation of negotiating SLAs can be facilitated when SLAs are translated into Reduced Ordered Binary Decision Diagrams (ROBDDs). Nevertheless, an ROBDD may not be optimally structured upon production. In this paper, we show how to reduce the number of 1-paths and nodes of ROBDDs that model SLAs, using ROBDD optimization algorithms. In addition, we demonstrate the reduction of 1-paths via the application of Term Rewriting Systems with mutually exclusive features. Using the latter, ROBDDs can be generated accurately without redundant 1-paths. We apply the principles onto the negotiation of IaaS SLAs via simulation, and show that negotiation is accelerated by assessing fewer SLA proposals (1-paths), while memory consumption is also reduced.	algorithm;binary decision diagram;cloud computing;dspace;mathematical optimization;outsourcing;requirement;rewriting;service-level agreement;services computing;simulation	Kuan Lu;Ramin Yahyapour;Edwin Yaqub;Constantinos Kotsokalis	2012		10.1007/978-3-642-34321-6_18	cloud computing;computer science;operating system;database;distributed computing;computer security	AI	-24.68678957962567	65.36829321554917	197062
2326c1362e22dce02bce05ad5647374f1e2c148a	elastman: autonomic elasticity manager for cloud-based key-value stores	key value store;datorsystem;computer systems;elasticity controller;cloud computing	The increasing spread of elastic Cloud services, together with the pay-as-you-go pricing model of Cloud computing, has led to the need of an elasticity controller. The controller automatically resizes an elastic service in response to changes in workload, in order to meet Service Level Objectives (SLOs) at a reduced cost. However, variable performance of Cloud virtual machines and nonlinearities in Cloud services complicates the controller design. We present the design and evaluation of ElastMan, an elasticity controller for Cloud-based elastic key-value stores. ElastMan combines feedforward and feedback control. Feedforward control is used to respond to spikes in the workload by quickly resizing the service to meet SLOs at a minimal cost. Feedback control is used to correct modeling errors and to handle diurnal workload. We have implemented and evaluated ElastMan using the Voldemort key-value store running in a Cloud environment based on OpenStack. Our evaluation shows the feasibility and effectiveness of our approach to automation of Cloud service elasticity.	attribute–value pair;autonomic computing;cloud computing;elasticity (cloud computing);feed forward (control);feedback;feedforward neural network;key-value database;reduced cost;service-level agreement;virtual machine	Ahmad Al-Shishtawy;Vladimir Vlassov	2013		10.1145/2462902.2462925	embedded system;real-time computing;simulation;cloud computing;computer science;operating system;cloud testing;distributed computing;associative array	OS	-23.75069452263596	61.68878369701858	197253
f0e65fcf3990460625a115ad8d8178fb13544f65	demand response aware cluster resource provisioning for parallel applications	energy conservation;smart grid technologies demand response aware cluster resource provisioning parallel applications data center energy consumption cooling techniques data center energy efficiency electricity market conditions grid efficiency network stress dr programs;servers delays clustering algorithms time factors suspensions electricity electricity supply industry;demand side management;smart power grids building management systems computer centres demand side management energy conservation energy consumption power markets;computer centres;power markets;smart power grids;energy consumption;building management systems	Data center energy consumption is significant and accounts for about 2% of total energy use in the U.S. recently. A range of approaches, from cooling techniques to workload consolidation have been taken to improve data center energy efficiency. In contrast to most methods published so far, this paper treats a data centre as a consumer in an electricity market. Our intention is to make data centres more responsive to electricity market conditions with minimal impact on their performance. In electricity markets, Demand Response(DR) is a method for improving grid efficiency by encouraging consumers to adjust their demand during price peaks or network stress. Significant consumption and cost savings can potentially be made via implementing DR programs involving a large set of consumers. Traditionally, DR has been a largely manual process, however, automated DR is becoming increasingly prevalent due to the deployment of smart grid technologies. In this paper, we treat the server cluster in a data centre as an energy consumer that participates DR activities. We give two algorithms to enable the cluster to automatically adjust the number of active servers to respond to DR requests while maintaining acceptable system performance. We evaluate our algorithms using real traces.	algorithm;cloud computing;complex event processing;computer cluster;computer cooling;data center;provisioning;semiconductor consolidation;server (computing);software deployment;tracing (software)	Chen Wang;Martin de Groot	2012	2012 IEEE Third International Conference on Smart Grid Communications (SmartGridComm)	10.1109/SmartGridComm.2012.6485971	simulation;electricity market;operations management;smart grid;business;commerce	HPC	-21.123426978933505	62.125153335475744	198180
60c6e10cb153d999e62fcfdf31a6198ce62e611f	keep your promise: mechanism design against free-riding and false-reporting in crowdsourcing	warranties;game theory;incentive mechanisms;outsourcing cloud computing design game theory mobile computing;incentive mechanisms crowdsourcing free riding false reporting game theory;internet of things;computational modeling;games;mobile communication;false reporting;free riding;crowdsourcing;game theory dff mechanism design free riding false reporting mobile crowdsourcing cloud computing;crowdsourcing games warranties computational modeling internet of things game theory mobile communication	Crowdsourcing is an emerging paradigm where users can have their tasks completed by paying fees, or receive rewards for providing service. A critical problem that arises in current crowdsourcing mechanisms is how to ensure that users pay or receive what they deserve. Free-riding and false-reporting may make the system vulnerable to dishonest users. In this paper, we design schemes to tackle these problems, so that each individual in the system is better off being honest and each provider prefers completing the assigned task. We first design a mechanism EFF which eliminates dishonest behavior with the help from a trusted third party for arbitration. We then design another mechanism DFF which, without the help from any third party, discourages dishonest behavior. We also prove that DFF is semi-truthful, which discourages dishonest behavior such as free-riding and false-reporting when the rest of the individuals are honest, while guaranteeing transaction-wise budget-balance and computational efficiency. Performance evaluation shows that within our mechanisms, no user could have a utility gain by unilaterally being dishonest.	crowdsourcing;digital forensics framework (dff);ext js javascript framework;numerical analysis;performance evaluation;programming paradigm;semiconductor industry;trusted third party	Xiang Zhang;Guoliang Xue;Ruozhou Yu;Dejun Yang;Jian Tang	2015	IEEE Internet of Things Journal	10.1109/JIOT.2015.2441031	games;game theory;simulation;mobile telephony;crowdsourcing software development;human–computer interaction;computer science;internet privacy;free riding;computational model;computer security;internet of things;crowdsourcing;computer network	ECom	-27.70163635378142	72.96511564198236	198521
d136a547923e430abaaad0ba5798823a07542fb0	dynamic server consolidation algorithms: a profit model for evaluation and an improvement	dynamic server consolidation;stability;profit model	Dynamic Server Consolidation (DSC) uses the live migration facility of virtualization technology to consolidate virtual machines (VMs) on fewer physical machines (PMs) when demand is low, to use minimal PMs without violating the Service Level Agreements (SLAs). The implicit goal of DSC is to maximize the data center profit, or minimize the cost, which is generally approximated in terms of PM operational cost and some direct cost given to migrations. In this paper we propose a profit model in which costs of actions, such as VM migrations, manifest as SLA penalties and increased operating costs, rather than some direct artificial costs given to them. The model can be used as an important tool to evaluate different consolidation algorithms, in terms of single cost metric. We also propose an algorithm for DSC, based on the stability of VM placements, which is an improved form of an existing algorithm, and use our metric to compare the two algorithms for different values of cost parameters. In most cases our algorithm reduces costs by upto 28%.	approximation algorithm;apriori algorithm;data center;differentiated services;lisp machine;semiconductor consolidation;server (computing);service-level agreement;virtual machine;x86 virtualization	Anshu Yadav;Varsha Apte	2016		10.1145/2833312.2833446	embedded system;real-time computing;simulation;stability;operating system;computer security	DB	-23.054159807240243	62.29957138764886	198885
a76d37ebe509b069618c3817e6b44f3760b1f5e9	accurate dns query characteristics estimation via active probing	active probing;dns;dns query characteristics	As the hidden backbone of today's Internet, the Domain Name System (DNS) provides name resolution service for almost every networked application. To exploit the rich DNS query information for traffic engineering or user behavior analysis, both passive capturing and active probing techniques have been proposed in recent years. Despite its full visibility of DNS behaviors, the passive capturing technique suffers from prohibitive management cost and results in tremendous privacy concerns towards its largescale and collaborative deployment. Comparatively, the active probing technique overcomes these limitations, providing broad-view and privacy-preserving DNS query analysis at the cost of constrained visibility of fine-grained DNS behavior. This paper aims to accurately estimate DNS query characteristics based on DNS cache activities, which can be acquired via active probing on a large scale at negligible management cost and minimized privacy concerns. Specifically, we have made three contributions: (1) we propose a novel solution, which integrates the renewal theory-based DNS caching formulation and the hyper-exponential distribution model. The solution offers great flexibility to model various domains; (2) we perform a large-scale real-world DNS trace measurement, and demonstrate that our solution significantly improves the estimation accuracy; (3) we apply our solution to estimate the malware-infected host population in remote management networks. The experimental results have demonstrated that our solution can achieve high estimation accuracy and outperforms the existing	internet backbone;malware;software deployment;time complexity	Xiaobo Ma;Junjie Zhang;Zhenhua Li;Jianfeng Li;Jing Tao;Xiaohong Guan;John C. S. Lui;Donald F. Towsley	2015	J. Network and Computer Applications	10.1016/j.jnca.2014.09.016	computer science;internet privacy;world wide web;computer security;domain name system	Metrics	-29.00633985141319	64.26522044453864	199094
defaf286ebd5a19094c190e50dbdf6f5f73c1441	predictive edge computing with hard deadlines		Edge computing is a promising approach for localized data processing for many edge applications and systems including Internet of Things (IoT), where computationally intensive tasks in IoT devices could be divided into sub-tasks and offloaded to other IoT devices, mobile devices, and/or servers at the edge. However, existing solutions on edge computing do not address the full range of challenges, specifically heterogeneity; edge devices are highly heterogeneous and dynamic in nature. In this paper, we develop a predictive edge computing framework with hard deadlines. Our algorithm; PrComp (i) predicts the uncertain dynamics of resources of devices at the edge including energy, computing power, and mobility, and (ii) makes sub-task offloading decisions by taking into account the predicted available resources, as well as the hard deadline constraints of tasks. We evaluate Prcomp on a testbed consisting of real Android-based smartphones, and show that it significantly improves energy consumption of edge devices and task completion delay as compared to baselines.		Yuxuan Xing;Hulya Seferoglu	2018	2018 IEEE International Symposium on Local and Metropolitan Area Networks (LANMAN)	10.1109/LANMAN.2018.8475056	distributed computing;edge device;task analysis;energy consumption;computer science;android (operating system);mobile device;testbed;server;edge computing	Embedded	-23.300058866185086	67.21953165033338	199681
08bc054616f2a723de75fdc6d403b3d1a184c8e3	adaptive memory-aware chunk sizing techniques for data-intensive queries over web services	concept drift;regression tree;data streams	Modern applications of Web Services (WSs) that involve the processing of large amounts of data tend to transmit data in chunks. Several performance control techniques have been proposed to dynamically select the appropriate chunk size with a view to minimize the communication cost. However, when the data consumer is slower than the data producer, the consumer applications may suffer from memory shortage if high volumes of data arrive in the incoming buffers. To this end, we propose a specific approach to coupling performance control with congestion control features, in order to consider both performance and memory overflow issues in an integrated manner. The performance results with real data show that we can combine these controllers effectively and efficiently, so that no memory overflow occurs at the expense of negligible performance degradation.	control system;data-intensive computing;elegant degradation;hypertext transfer protocol;internet protocol suite;network congestion;overhead (computing);run time (program lifecycle phase);soap;web service	Anastasia Theodouli;Anastasios Gounaris	2013		10.1145/2480362.2480522	real-time computing;computer science;artificial intelligence;concept drift;operating system;machine learning;decision tree;data mining;database;data stream mining;world wide web;computer security	HPC	-25.854525460393262	63.73018420923506	199829
